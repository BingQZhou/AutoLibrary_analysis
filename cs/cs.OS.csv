,title,abstract
0,Virtualization: A double-edged sword,"  Virtualization became recently a hot topic once again, after being dormant
for more than twenty years. In the meantime, it has been almost forgotten, that
virtual machines are not so perfect isolating environments as it seems, when
looking at the principles. These lessons were already learnt earlier when the
first virtualized systems have been exposed to real life usage.
  Contemporary virtualization software enables instant creation and destruction
of virtual machines on a host, live migration from one host to another,
execution history manipulation, etc. These features are very useful in
practice, but also causing headaches among security specialists, especially in
current hostile network environments.
  In the present contribution we discuss the principles, potential benefits and
risks of virtualization in a deja vu perspective, related to previous
experiences with virtualization in the mainframe era.
"
1,A Survey of Unix Init Schemes,"  In most modern operating systems, init (as in ""initialization"") is the
program launched by the kernel at boot time. It runs as a daemon and typically
has PID 1. Init is responsible for spawning all other processes and scavenging
zombies. It is also responsible for reboot and shutdown operations. This
document describes existing solutions that implement the init process and/or
init scripts in Unix-like systems. These solutions range from the legacy and
still-in-use BSD and SystemV schemes, to recent and promising schemes from
Ubuntu, Apple, Sun and independent developers. Our goal is to highlight their
focus and compare their sets of features.
"
2,"Java Components Vulnerabilities - An Experimental Classification
  Targeted at the OSGi Platform","  The OSGi Platform finds a growing interest in two different applications
domains: embedded systems, and applications servers. However, the security
properties of this platform are hardly studied, which is likely to hinder its
use in production systems. This is all the more important that the dynamic
aspect of OSGi-based applications, that can be extended at runtime, make them
vulnerable to malicious code injection. We therefore perform a systematic audit
of the OSGi platform so as to build a vulnerability catalog that intends to
reference OSGi Vulnerabilities originating in the Core Specification, and in
behaviors related to the use of the Java language. Standard Services are not
considered. To support this audit, a Semi-formal Vulnerability Pattern is
defined, that enables to uniquely characterize fundamental properties for each
vulnerability, to include verbose description in the pattern, to reference
known security protections, and to track the implementation status of the
proof-of-concept OSGi Bundles that exploit the vulnerability. Based on the
analysis of the catalog, a robust OSGi Platform is built, and recommendations
are made to enhance the OSGi Specifications.
"
3,"Practical Multiwriter Lock-Free Queues for ""Hard Real-Time"" Systems
  without CAS","  FIFO queues with a single reader and writer can be insufficient for ""hard
real-time"" systems where interrupt handlers require wait-free guarantees when
writing to message queues. We present an algorithm which elegantly and
practically solves this problem on small processors that are often found in
embedded systems. The algorithm does not require special CPU instructions (such
as atomic CAS), and therefore is more robust than many existing methods that
suffer the ABA problem associated with swing pointers. The algorithm gives
""first-in, almost first-out"" guarantees under pathological interrupt
conditions, which manifests as arbitrary ""shoving"" among nearly-simultaneous
arrivals at the end of the queue.
"
4,OS Debugging Method Using a Lightweight Virtual Machine Monitor,"  Demands for implementing original OSs that can achieve high I/O performance
on PC/AT compatible hardware have recently been increasing, but conventional OS
debugging environments have not been able to simultaneously assure their
stability, be easily customized to new OSs and new I/O devices, and assure
efficient execution of I/O operations. We therefore developed a novel OS
debugging method using a lightweight virtual machine. We evaluated this
debugging method experimentally and confirmed that it can transfer data about
5.4 times as fast as the conventional virtual machine monitor.
"
5,"RTK-Spec TRON: A Simulation Model of an ITRON Based RTOS Kernel in
  SystemC","  This paper presents the methodology and the modeling constructs we have
developed to capture the real time aspects of RTOS simulation models in a
System Level Design Language (SLDL) like SystemC. We describe these constructs
and show how they are used to build a simulation model of an RTOS kernel
targeting the $\mu$-ITRON OS specification standard.
"
6,Power-Aware Real-Time Scheduling upon Identical Multiprocessor Platforms,"  In this paper, we address the power-aware scheduling of sporadic
constrained-deadline hard real-time tasks using dynamic voltage scaling upon
multiprocessor platforms. We propose two distinct algorithms. Our first
algorithm is an off-line speed determination mechanism which provides an
identical speed for each processor. That speed guarantees that all deadlines
are met if the jobs are scheduled using EDF. The second algorithm is an on-line
and adaptive speed adjustment mechanism which reduces the energy consumption
while the system is running.
"
7,"Exact Feasibility Tests for Real-Time Scheduling of Periodic Tasks upon
  Multiprocessor Platforms","  In this paper we study the global scheduling of periodic task systems upon
multiprocessor platforms. We first show two very general properties which are
well-known for uniprocessor platforms and which remain for multiprocessor
platforms: (i) under few and not so restrictive assumptions, we show that
feasible schedules of periodic task systems are periodic from some point with a
period equal to the least common multiple of task periods and (ii) for the
specific case of synchronous periodic task systems, we show that feasible
schedules repeat from the origin. We then present our main result: we
characterize, for task-level fixed-priority schedulers and for asynchronous
constrained or arbitrary deadline periodic task models, upper bounds of the
first time instant where the schedule repeats. We show that job-level
fixed-priority schedulers are predictable upon unrelated multiprocessor
platforms. For task-level fixed-priority schedulers, based on the upper bounds
and the predictability property, we provide for asynchronous constrained or
arbitrary deadline periodic task sets, exact feasibility tests. Finally, for
the job-level fixed-priority EDF scheduler, for which such an upper bound
remains unknown, we provide an exact feasibility test as well.
"
8,SAFIUS - A secure and accountable filesystem over untrusted storage,"  We describe SAFIUS, a secure accountable file system that resides over an
untrusted storage. SAFIUS provides strong security guarantees like
confidentiality, integrity, prevention from rollback attacks, and
accountability. SAFIUS also enables read/write sharing of data and provides the
standard UNIX-like interface for applications. To achieve accountability with
good performance, it uses asynchronous signatures; to reduce the space required
for storing these signatures, a novel signature pruning mechanism is used.
SAFIUS has been implemented on a GNU/Linux based system modifying OpenGFS.
Preliminary performance studies show that SAFIUS has a tolerable overhead for
providing secure storage: while it has an overhead of about 50% of OpenGFS in
data intensive workloads (due to the overhead of performing
encryption/decryption in software), it is comparable (or better in some cases)
to OpenGFS in metadata intensive workloads.
"
9,A Type System for Data-Flow Integrity on Windows Vista,"  The Windows Vista operating system implements an interesting model of
multi-level integrity. We observe that in this model, trusted code can be
blamed for any information-flow attack; thus, it is possible to eliminate such
attacks by static analysis of trusted code. We formalize this model by
designing a type system that can efficiently enforce data-flow integrity on
Windows Vista. Typechecking guarantees that objects whose contents are
statically trusted never contain untrusted values, regardless of what untrusted
code runs in the environment. Some of Windows Vista's runtime access checks are
necessary for soundness; others are redundant and can be optimized away.
"
10,Performance Evaluation of Multiple TCP connections in iSCSI,"  Scaling data storage is a significant concern in enterprise systems and
Storage Area Networks (SANs) are deployed as a means to scale enterprise
storage. SANs based on Fibre Channel have been used extensively in the last
decade while iSCSI is fast becoming a serious contender due to its reduced
costs and unified infrastructure. This work examines the performance of iSCSI
with multiple TCP connections. Multiple TCP connections are often used to
realize higher bandwidth but there may be no fairness in how bandwidth is
distributed. We propose a mechanism to share congestion information across
multiple flows in ``Fair-TCP'' for improved performance. Our results show that
Fair-TCP significantly improves the performance for I/O intensive workloads.
"
11,Void Traversal for Guaranteed Delivery in Geometric Routing,"  Geometric routing algorithms like GFG (GPSR) are lightweight, scalable
algorithms that can be used to route in resource-constrained ad hoc wireless
networks. However, such algorithms run on planar graphs only. To efficiently
construct a planar graph, they require a unit-disk graph. To make the topology
unit-disk, the maximum link length in the network has to be selected
conservatively. In practical setting this leads to the designs where the node
density is rather high. Moreover, the network diameter of a planar subgraph is
greater than the original graph, which leads to longer routes. To remedy this
problem, we propose a void traversal algorithm that works on arbitrary
geometric graphs. We describe how to use this algorithm for geometric routing
with guaranteed delivery and compare its performance with GFG.
"
12,Discrete Frequency Selection of Frame-Based Stochastic Real-Time Tasks,"  Energy-efficient real-time task scheduling has been actively explored in the
past decade. Different from the past work, this paper considers schedulability
conditions for stochastic real-time tasks. A schedulability condition is first
presented for frame-based stochastic real-time tasks, and several algorithms
are also examined to check the schedulability of a given strategy. An approach
is then proposed based on the schedulability condition to adapt a
continuous-speed-based method to a discrete-speed system. The approach is able
to stay as close as possible to the continuous-speed-based method, but still
guaranteeing the schedulability. It is shown by simulations that the energy
saving can be more than 20% for some system configurations
"
13,"(m,k)-firm constraints and DBP scheduling: impact of the initial
  k-sequence and exact schedulability test","  In this paper we study the scheduling of (m,k)-firm synchronous periodic task
systems using the Distance Based Priority (DBP) scheduler. We first show three
phenomena: (i) choosing, for each task, the initial k-sequence 1^k is not
optimal, (ii) we can even start the scheduling from a (fictive) error state (in
regard to the initial k-sequence) and (iii) the period of feasible
DBP-schedules is not necessarily the task hyper-period. We then show that any
feasible DBP-schedule is periodic and we upper-bound the length of that period.
Lastly, based on our periodicity result we provide an exact schedulability
test.
"
14,Integrating Job Parallelism in Real-Time Scheduling Theory,"  We investigate the global scheduling of sporadic, implicit deadline,
real-time task systems on multiprocessor platforms. We provide a task model
which integrates job parallelism. We prove that the time-complexity of the
feasibility problem of these systems is linear relatively to the number of
(sporadic) tasks for a fixed number of processors. We propose a scheduling
algorithm theoretically optimal (i.e., preemptions and migrations neglected).
Moreover, we provide an exact feasibility utilization bound. Lastly, we propose
a technique to limit the number of migrations and preemptions.
"
15,"Telex: Principled System Support for Write-Sharing in Collaborative
  Applications","  The Telex system is designed for sharing mutable data in a distributed
environment, particularly for collaborative applications. Users operate on
their local, persistent replica of shared documents; they can work disconnected
and suffer no network latency. The Telex approach to detect and correct
conflicts is application independent, based on an action-constraint graph (ACG)
that summarises the concurrency semantics of applications. The ACG is stored
efficiently in a multilog structure that eliminates contention and is optimised
for locality. Telex supports multiple applications and multi-document updates.
The Telex system clearly separates system logic (which includes replication,
views, undo, security, consistency, conflicts, and commitment) from application
logic. An example application is a shared calendar for managing multi-user
meetings; the system detects meeting conflicts and resolves them consistently.
"
16,Control-theoretic dynamic voltage scaling for embedded controllers,"  For microprocessors used in real-time embedded systems, minimizing power
consumption is difficult due to the timing constraints. Dynamic voltage scaling
(DVS) has been incorporated into modern microprocessors as a promising
technique for exploring the trade-off between energy consumption and system
performance. However, it remains a challenge to realize the potential of DVS in
unpredictable environments where the system workload cannot be accurately
known. Addressing system-level power-aware design for DVS-enabled embedded
controllers, this paper establishes an analytical model for the DVS system that
encompasses multiple real-time control tasks. From this model, a feedback
control based approach to power management is developed to reduce dynamic power
consumption while achieving good application performance. With this approach,
the unpredictability and variability of task execution times can be attacked.
Thanks to the use of feedback control theory, predictable performance of the
DVS system is achieved, which is favorable to real-time applications. Extensive
simulations are conducted to evaluate the performance of the proposed approach.
"
17,Feedback Scheduling: An Event-Driven Paradigm,"  Embedded computing systems today increasingly feature resource constraints
and workload variability, which lead to uncertainty in resource availability.
This raises great challenges to software design and programming in multitasking
environments. In this paper, the emerging methodology of feedback scheduling is
introduced to address these challenges. As a closed-loop approach to resource
management, feedback scheduling promises to enhance the flexibility and
resource efficiency of various software programs through dynamically
distributing available resources among concurrent tasks based on feedback
information about the actual usage of the resources. With emphasis on the
behavioral design of feedback schedulers, we describe a general framework of
feedback scheduling in the context of real-time control applications. A simple
yet illustrative feedback scheduling algorithm is given. From a programming
perspective, we describe how to modify the implementation of control tasks to
facilitate the application of feedback scheduling. An event-driven paradigm
that combines time-triggered and event-triggered approaches is proposed for
programming of the feedback scheduler. Simulation results argue that the
proposed event-driven paradigm yields better performance than time-triggered
paradigm in dynamic environments where the workload varies irregularly and
unpredictably.
"
18,Local Read-Write Operations in Sensor Networks,"  Designing protocols and formulating convenient programming units of
abstraction for sensor networks is challenging due to communication errors and
platform constraints. This paper investigates properties and implementation
reliability for a \emph{local read-write} abstraction. Local read-write is
inspired by the class of read-modify-write operations defined for shared-memory
multiprocessor architectures. The class of read-modify-write operations is
important in solving consensus and related synchronization problems for
concurrency control. Local read-write is shown to be an atomic abstraction for
synchronizing neighborhood states in sensor networks. The paper compares local
read-write to similar lightweight operations in wireless sensor networks, such
as read-all, write-all, and a transaction-based abstraction: for some
optimistic scenarios, local read-write is a more efficient neighborhood
operation. A partial implementation is described, which shows that three
outcomes characterize operation response: success, failure, and cancel. A
failure response indicates possible inconsistency for the operation result,
which is the result of a timeout event at the operation's initiator. The paper
presents experimental results on operation performance with different timeout
values and situations of no contention, with some tests also on various
neighborhood sizes.
"
19,Interface Matching and Combining Techniques for Services Integration,"  The development of many highly dynamic environments, like pervasive
environments, introduces the possibility to use geographically close-related
services. Dynamically integrating and unintegrating these services in running
applications is a key challenge for this use. In this article, we classify
service integration issues according to interfaces exported by services and
internal combining techniques. We also propose a contextual integration
service, IntegServ, and an interface, Integrable, for developing services.
"
20,"A Distributed and Deterministic TDMA Algorithm for
  Write-All-With-Collision Model","  Several self-stabilizing time division multiple access (TDMA) algorithms are
proposed for sensor networks. In addition to providing a collision-free
communication service, such algorithms enable the transformation of programs
written in abstract models considered in distributed computing literature into
a model consistent with sensor networks, i.e., write all with collision (WAC)
model. Existing TDMA slot assignment algorithms have one or more of the
following properties: (i) compute slots using a randomized algorithm, (ii)
assume that the topology is known upfront, and/or (iii) assign slots
sequentially. If these algorithms are used to transform abstract programs into
programs in WAC model then the transformed programs are probabilistically
correct, do not allow the addition of new nodes, and/or converge in a
sequential fashion. In this paper, we propose a self-stabilizing deterministic
TDMA algorithm where a sensor is aware of only its neighbors. We show that the
slots are assigned to the sensors in a concurrent fashion and starting from
arbitrary initial states, the algorithm converges to states where
collision-free communication among the sensors is restored. Moreover, this
algorithm facilitates the transformation of abstract programs into programs in
WAC model that are deterministically correct.
"
21,Managing Varying Worst Case Execution Times on DVS Platforms,"  Energy efficient real-time task scheduling attracted a lot of attention in
the past decade. Most of the time, deterministic execution lengths for tasks
were considered, but this model fits less and less with the reality, especially
with the increasing number of multimedia applications. It's why a lot of
research is starting to consider stochastic models, where execution times are
only known stochastically. However, authors consider that they have a pretty
much precise knowledge about the properties of the system, especially regarding
to the worst case execution time (or worst case execution cycles, WCEC).
  In this work, we try to relax this hypothesis, and assume that the WCEC can
vary. We propose miscellaneous methods to react to such a situation, and give
many simulation results attesting that with a small effort, we can provide very
good results, allowing to keep a low deadline miss rate as well as an energy
consumption similar to clairvoyant algorithms.
"
22,Multiprocessor Global Scheduling on Frame-Based DVFS Systems,"  In this ongoing work, we are interested in multiprocessor energy efficient
systems, where task durations are not known in advance, but are know
stochastically. More precisely, we consider global scheduling algorithms for
frame-based multiprocessor stochastic DVFS (Dynamic Voltage and Frequency
Scaling) systems. Moreover, we consider processors with a discrete set of
available frequencies.
"
23,"Mode Change Protocol for Multi-Mode Real-Time Systems upon Identical
  Multiprocessors","  In this paper, we propose a synchronous protocol without periodicity for
scheduling multi-mode real-time systems upon identical multiprocessor
platforms. Our proposal can be considered to be a multiprocessor extension of
the uniprocessor protocol called ""Minimal Single Offset protocol"".
"
24,"Optimizing Binary Code Produced by Valgrind (Project Report on Virtual
  Execution Environments Course - AVExe)","  Valgrind is a widely used framework for dynamic binary instrumentation and
its mostly known by its memcheck tool. Valgrind's code generation module is far
from producing optimal code. In addition it has many backends for different CPU
architectures, which difficults code optimization in an architecture
independent way. Our work focused on identifying sub-optimal code produced by
Valgrind and optimizing it.
"
25,The meaning of concurrent programs,"  The semantics of assignment and mutual exclusion in concurrent and
multi-core/multi-processor systems is presented with attention to low level
architectural features in an attempt to make the presentation realistic.
Recursive functions on event sequences are used to define state dependent
functions and variables in ordinary (non-formal-method) algebra.
"
26,Package upgrades in FOSS distributions: details and challenges,"  The upgrade problems faced by Free and Open Source Software distributions
have characteristics not easily found elsewhere. We describe the structure of
packages and their role in the upgrade process. We show that state of the art
package managers have shortcomings inhibiting their ability to cope with
frequent upgrade failures. We survey current countermeasures to such failures,
argue that they are not satisfactory, and sketch alternative solutions.
"
27,"CloudSim: A Novel Framework for Modeling and Simulation of Cloud
  Computing Infrastructures and Services","  Cloud computing focuses on delivery of reliable, secure, fault-tolerant,
sustainable, and scalable infrastructures for hosting Internet-based
application services. These applications have different composition,
configuration, and deployment requirements. Quantifying the performance of
scheduling and allocation policy on a Cloud infrastructure (hardware, software,
services) for different application and service models under varying load,
energy performance (power consumption, heat dissipation), and system size is an
extremely challenging problem to tackle. To simplify this process, in this
paper we propose CloudSim: a new generalized and extensible simulation
framework that enables seamless modelling, simulation, and experimentation of
emerging Cloud computing infrastructures and management services. The
simulation framework has the following novel features: (i) support for
modelling and instantiation of large scale Cloud computing infrastructure,
including data centers on a single physical computing node and java virtual
machine; (ii) a self-contained platform for modelling data centers, service
brokers, scheduling, and allocations policies; (iii) availability of
virtualization engine, which aids in creation and management of multiple,
independent, and co-hosted virtualized services on a data center node; and (iv)
flexibility to switch between space-shared and time-shared allocation of
processing cores to virtualized services.
"
28,"MORA: an Energy-Aware Slack Reclamation Scheme for Scheduling Sporadic
  Real-Time Tasks upon Multiprocessor Platforms","  In this paper, we address the global and preemptive energy-aware scheduling
problem of sporadic constrained-deadline tasks on DVFS-identical multiprocessor
platforms. We propose an online slack reclamation scheme which profits from the
discrepancy between the worst- and actual-case execution time of the tasks by
slowing down the speed of the processors in order to save energy. Our algorithm
called MORA takes into account the application-specific consumption profile of
the tasks. We demonstrate that MORA does not jeopardize the system
schedulability and we show by performing simulations that it can save up to 32%
of energy (in average) compared to execution without using any energy-aware
algorithm.
"
29,Aneka: A Software Platform for .NET-based Cloud Computing,"  Aneka is a platform for deploying Clouds developing applications on top of
it. It provides a runtime environment and a set of APIs that allow developers
to build .NET applications that leverage their computation on either public or
private clouds. One of the key features of Aneka is the ability of supporting
multiple programming models that are ways of expressing the execution logic of
applications by using specific abstractions. This is accomplished by creating a
customizable and extensible service oriented runtime environment represented by
a collection of software containers connected together. By leveraging on these
architecture advanced services including resource reservation, persistence,
storage management, security, and performance monitoring have been implemented.
On top of this infrastructure different programming models can be plugged to
provide support for different scenarios as demonstrated by the engineering,
life science, and industry applications.
"
30,"Predictability of Fixed-Job Priority Schedulers on Heterogeneous
  Multiprocessor Real-Time Systems","  The multiprocessor Fixed-Job Priority (FJP) scheduling of real-time systems
is studied. An important property for the schedulability analysis, the
predictability (regardless to the execution times), is studied for
heterogeneous multiprocessor platforms. Our main contribution is to show that
any FJP schedulers are predictable on unrelated platforms. A convenient
consequence is the fact that any FJP schedulers are predictable on uniform
multiprocessors.
"
31,Remembrance: The Unbearable Sentience of Being Digital,"  We introduce a world vision in which data is endowed with memory. In this
data-centric systems paradigm, data items can be enabled to retain all or some
of their previous values. We call this ability ""remembrance"" and posit that it
empowers significant leaps in the security, availability, and general
operational dimensions of systems. With the explosion in cheap, fast memories
and storage, large-scale remembrance will soon become practical. Here, we
introduce and explore the advantages of such a paradigm and the challenges in
making it a reality.
"
32,A Conceivable Origin of Machine Consciousness in the IDLE process,"  In this short paper, we would like to call professional community's attention
to a daring idea that is surely unhelpful, but is exciting for programmers and
anyway conflicts with the trend of energy consumption in computer systems.
"
33,Virtual-Threading: Advanced General Purpose Processors Architecture,"  The paper describes the new computers architecture, the main features of
which has been claimed in the Russian Federation patent 2312388 and in the US
patent application 11/991331. This architecture is intended to effective
support of the General Purpose Parallel Computing (GPPC), the essence of which
is extremely frequent switching of threads between states of activity and
states of viewed in the paper the algorithmic latency. To emphasize the same
impact of the architectural latency and the algorithmic latency upon GPPC, is
introduced the new notion of the generalized latency and is defined its
quantitative measure - the Generalized Latency Tolerance (GLT). It is shown
that a well suited for GPPC implementation architecture should have high level
of GLT and is described such architecture, which is called the Virtual-Threaded
Machine. This architecture originates a processor virtualization in the
direction of activities virtualization, which is orthogonal to the well-known
direction of memory virtualization. The key elements of the architecture are 1)
the distributed fine grain representation of the architectural register file,
which elements are hardware swapped through levels of a microarchitectural
memory, 2) the prioritized fine grain direct hardware multiprogramming, 3) the
access controlled virtual addressing and 4) the hardware driven semaphores. The
composition of these features lets to introduce new styles of operating system
(OS) programming, which is free of interruptions, and of applied programming
with a very rare using the OS services.
"
34,Temporal Debugging using URDB,"  A new style of temporal debugging is proposed. The new URDB debugger can
employ such techniques as temporal search for finding an underlying fault that
is causing a bug. This improves on the standard iterative debugging style,
which iteratively re-executes a program under debugger control in the search
for the underlying fault. URDB acts as a meta-debugger, with current support
for four widely used debuggers: gdb, MATLAB, python, and perl. Support for a
new debugger can be added in a few hours. Among its points of novelty are: (i)
the first reversible debuggers for MATLAB, python, and perl; (ii) support for
today's multi-core architectures; (iii) reversible debugging of multi-process
and distributed computations; and (iv) temporal search on changes in program
expressions. URDB gains its reversibility and temporal abilities through the
fast checkpoint-restart capability of DMTCP (Distributed MultiThreaded
CheckPointing). The recently enhanced DMTCP also adds ptrace support, enabling
one to freeze, migrate, and replicate debugging sessions.
"
35,On the stability of two-chunk file-sharing systems,"  We consider five different peer-to-peer file sharing systems with two chunks,
with the aim of finding chunk selection algorithms that have provably stable
performance with any input rate and assuming non-altruistic peers who leave the
system immediately after downloading the second chunk. We show that many
algorithms that first looked promising lead to unstable or oscillating
behavior. However, we end up with a system with desirable properties. Most of
our rigorous results concern the corresponding deterministic large system
limits, but in two simplest cases we provide proofs for the stochastic systems
also.
"
36,A New Scheduling Algorithms For Real Time Tasks,"  The main objective of this paper is to develop the two different ways in
which round robin architecture is modified and made suitable to be implemented
in real time and embedded systems. The scheduling algorithm plays a significant
role in the design of real time embedded systems. Simple round robin
architecture is not efficient to be implemented in embedded systems because of
higher context switch rate, larger waiting time and larger response time.
Missing of deadlines will degrade the system performance in soft real time
systems. The main objective of this paper is to develop the scheduling
algorithm which removes the drawbacks in simple round robin architecture. A
comparison with round robin architecture to the proposed architectures has been
made. It is observed that the proposed architectures solves the problems
encountered in round robin architecture in soft real time by decreasing the
number of context switches waiting time and response time thereby increasing
the system throughput.
"
37,"Deterministic Consistency: A Programming Model for Shared Memory
  Parallelism","  The difficulty of developing reliable parallel software is generating
interest in deterministic environments, where a given program and input can
yield only one possible result. Languages or type systems can enforce
determinism in new code, and runtime systems can impose synthetic schedules on
legacy parallel code. To parallelize existing serial code, however, we would
like a programming model that is naturally deterministic without language
restrictions or artificial scheduling. We propose ""deterministic consistency"",
a parallel programming model as easy to understand as the ""parallel assignment""
construct in sequential languages such as Perl and JavaScript, where concurrent
threads always read their inputs before writing shared outputs. DC supports
common data- and task-parallel synchronization abstractions such as fork/join
and barriers, as well as non-hierarchical structures such as producer/consumer
pipelines and futures. A preliminary prototype suggests that software-only
implementations of DC can run applications written for popular parallel
environments such as OpenMP with low (<10%) overhead for some applications.
"
38,Sharp utilization thresholds for some real-time scheduling problems,"  Scheduling policies for real-time systems exhibit threshold behavior that is
related to the utilization of the task set they schedule, and in some cases
this threshold is sharp. For the rate monotonic scheduling policy, we show that
periodic workload with utilization less than a threshold $U_{RM}^{*}$ can be
scheduled almost surely and that all workload with utilization greater than
$U_{RM}^{*}$ is almost surely not schedulable. We study such sharp threshold
behavior in the context of processor scheduling using static task priorities,
not only for periodic real-time tasks but for aperiodic real-time tasks as
well. The notion of a utilization threshold provides a simple schedulability
test for most real-time applications. These results improve our understanding
of scheduling policies and provide an interesting characterization of the
typical behavior of policies. The threshold is sharp (small deviations around
the threshold cause schedulability, as a property, to appear or disappear) for
most policies; this is a happy consequence that can be used to address the
limitations of existing utilization-based tests for schedulability. We
demonstrate the use of such an approach for balancing power consumption with
the need to meet deadlines in web servers.
"
39,Process Description of COM Object Life Cycle,"  The objective of this article is to provide for the reader a basic
description of all the steps involved in the COM object life-cycle process. COM
is a software technology and process performer. The first section briefly
introduces the Component Object Model (COM), considering the process of the COM
object life cycle as the baseline of all COM issues. The second part describes
in detail the basic steps of the process - client request, server location,
object creation, interaction, and disconnection. A brief description is given
for the components involved in each step. Finally, the third section provides a
brief conclusion summarizing all the process steps.
"
40,"A distributed file system for a wide-area high performance computing
  infrastructure","  We describe our work in implementing a wide-area distributed file system for
the NSF TeraGrid. The system, called XUFS, allows private distributed name
spaces to be created for transparent access to personal files across over 9000
computer nodes. XUFS builds on many principles from prior distributed file
systems research, but extends key design goals to support the workflow of
computational science researchers. Specifically, XUFS supports file access from
the desktop to the wide-area network seamlessly, survives transient
disconnected operations robustly, and demonstrates comparable or better
throughput than some current high performance file systems on the wide-area
network.
"
41,Fault Tolerance in Real Time Multiprocessors - Embedded Systems,"  All real time tasks which are termed as critical tasks by nature have to
complete its execution before its deadline, even in presence of faults. The
most popularly used real time task assignment algorithms are First Fit (FF),
Best Fit (BF), Bin Packing (BP).The common task scheduling algorithms are Rate
Monotonic (RM), Earliest Deadline First (EDF) etc.All the current approaches
deal with either fault tolerance or criticality in real time. In this paper we
have proposed an integrated approach with a new algorithm, called SASA (Sorting
And Sequential Assignment) which maps the real time task assignment with task
schedule and fault tolerance
"
42,"On the Design of an Optimal Multiprocessor Real-Time Scheduling
  Algorithm under Practical Considerations (Extended Version)","  This research addresses the multiprocessor scheduling problem of hard
real-time systems, and it especially focuses on optimal and global schedulers
when practical constraints are taken into account. First, we propose an
improvement of the optimal algorithm BF. We formally prove that our adaptation
is (i) optimal, i.e., it always generates a feasible schedule as long as such a
schedule exists, and (ii) valid, i.e., it complies with the all the
requirements. We also show that it outperforms BF by providing a computing
complexity of O(n), where n is the number of tasks to be scheduled. Next, we
propose a schedulability analysis which indicates a priori whether the
real-time application can be scheduled by our improvement of BF without missing
any deadline. This analysis is, to the best of our knowledge, the first such
test for multiprocessors that takes into account all the main overheads
generated by the Operating System.
"
43,"A Data Capsule Framework For Web Services: Providing Flexible Data
  Access Control To Users","  This paper introduces the notion of a secure data capsule, which refers to an
encapsulation of sensitive user information (such as a credit card number)
along with code that implements an interface suitable for the use of such
information (such as charging for purchases) by a service (such as an online
merchant). In our capsule framework, users provide their data in the form of
such capsules to web services rather than raw data. Capsules can be deployed in
a variety of ways, either on a trusted third party or the user's own computer
or at the service itself, through the use of a variety of hardware or software
modules, such as a virtual machine monitor or trusted platform module: the only
requirement is that the deployment mechanism must ensure that the user's data
is only accessed via the interface sanctioned by the user. The framework
further allows an user to specify policies regarding which services or machines
may host her capsule, what parties are allowed to access the interface, and
with what parameters. The combination of interface restrictions and policy
control lets us bound the impact of an attacker who compromises the service to
gain access to the user's capsule or a malicious insider at the service itself.
"
44,"A new model for virtual machine migration in virtualized cluster server
  based on Fuzzy Decision Making","  In this paper, we show that performance of the virtualized cluster servers
could be improved through intelligent decision over migration time of Virtual
Machines across heterogeneous physical nodes of a cluster server. The cluster
serves a variety range of services from Web Service to File Service. Some of
them are CPU-Intensive while others are RAM-Intensive and so on. Virtualization
has many advantages such as less hardware cost, cooling cost, more
manageability. One of the key benefits is better load balancing by using of VM
migration between hosts. To migrate, we must know which virtual machine needs
to be migrated and when this relocation has to be done and, moreover, which
host must be destined. To relocate VMs from overloaded servers to underloaded
ones, we need to sort nodes from the highest volume to the lowest. There are
some models to finding the most overloaded node, but they have some
shortcomings. The focus of this paper is to present a new method to migrate VMs
between cluster nodes using TOPSIS algorithm - one of the most efficient Multi
Criteria Decision Making techniques- to make more effective decision over whole
active servers of the Cluster and find the most loaded serversTo evaluate the
performance improvement resulted from this model, we used cluster Response time
and Unbalanced Factor.
"
45,FIFO anomaly is unbounded,"  Virtual memory of computers is usually implemented by demand paging. For some
page replacement algorithms the number of page faults may increase as the
number of page frames increases. Belady, Nelson and Shedler constructed
reference strings for which page replacement algorithm FIFO produces near twice
more page faults in a larger memory than in a smaller one. They formulated the
conjecture that 2 is a general bound. We prove that this ratio can be
arbitrarily large.
"
46,"Proficient Pair of Replacement Algorithms on L1 and L2 Cache for Merge
  Sort","  Memory hierarchy is used to compete the processors speed. Cache memory is the
fast memory which is used to conduit the speed difference of memory and
processor. The access patterns of Level 1 cache (L1) and Level 2 cache (L2) are
different, when CPU not gets the desired data in L1 then it accesses L2. Thus
the replacement algorithm which works efficiently on L1 may not be as efficient
on L2. Similarly various applications such as Matrix Multiplication, Web, Fast
Fourier Transform (FFT) etc will have varying access pattern. Thus same
replacement algorithm for all types of application may not be efficient. This
paper works for getting an efficient pair of replacement algorithm on L1 and L2
for the algorithm Merge Sort. With the memory reference string of Merge Sort,
we have analyzed the behavior of various existing replacement algorithms on L1.
The existing replacement algorithms which are taken into consideration are:
Least Recently Used (LRU), Least Frequently Used (LFU) and First In First Out
(FIFO). After Analyzing the memory reference pattern of Merge Sort, we have
proposed a Partition Based Replacement algorithm (PBR_L1)) on L1 Cache.
Furthermore we have analyzed various pairs of algorithms on L1 and L2
respectively, resulting in finding a suitable pair of replacement algorithms.
Simulation on L1 shows, among the considered existing replacement algorithms
FIFO is performing better than others. While the proposed replacement algorithm
PBR_L1 is working about 1.7% to 44 % better than FIFO for various cache sizes.
"
47,Determinating Timing Channels in Compute Clouds,"  Timing side-channels represent an insidious security challenge for cloud
computing, because: (a) massive parallelism in the cloud makes timing channels
pervasive and hard to control; (b) timing channels enable one customer to steal
information from another without leaving a trail or raising alarms; (c) only
the cloud provider can feasibly detect and report such attacks, but the
provider's incentives are not to; and (d) resource partitioning schemes for
timing channel control undermine statistical sharing efficiency, and, with it,
the cloud computing business model. We propose a new approach to timing channel
control, using provider-enforced deterministic execution instead of resource
partitioning to eliminate timing channels within a shared cloud domain.
Provider-enforced determinism prevents execution timing from affecting the
results of a compute task, however large or parallel, ensuring that a task's
outputs leak no timing information apart from explicit timing inputs and total
compute duration. Experiments with a prototype OS for deterministic cloud
computing suggest that such an approach may be practical and efficient. The OS
supports deterministic versions of familiar APIs such as processes, threads,
shared memory, and file systems, and runs coarse-grained parallel tasks as
efficiently and scalably as current timing channel-ridden systems.
"
48,Searching publications on operating systems,"  This note concerns a search for publications in which one can find statements
that explain the concept of an operating system, reasons for introducing
operating systems, a formalization of the concept of an operating system or
theory about operating systems based on such a formalization. It reports on the
way in which the search has been carried out and the outcome of the search. The
outcome includes not only what the search was meant for, but also some added
bonuses.
"
49,"Scheduling Multi-Mode Real-Time Systems upon Uniform Multiprocessor
  Platforms","  In this paper, we address the scheduling problem of multi-mode real-time
systems upon uniform multiprocessor platforms. We propose two transition
protocols, specified together with their schedulability test, and provide the
reader with two distinct upper bounds for the length of the transient phases
during mode transitions, respectively for the cases where jobs priorities are
known and unknown beforehand.
"
50,Multi-Criteria Evaluation of Partitioning Schemes for Real-Time Systems,"  In this paper we study the partitioning approach for multiprocessor real-time
scheduling. This approach seems to be the easiest since, once the partitioning
of the task set has been done, the problem reduces to well understood
uniprocessor issues. Meanwhile, there is no optimal and polynomial solution to
partition tasks on processors. In this paper we analyze partitioning algorithms
from several points of view such that for a given task set and specific
constraints (processor number, task set type, etc.) we should be able to
identify the best heuristic and the best schedulability test. We also analyze
the influence of the heuristics on the performance of the uniprocessor tests
and the impact of a specific task order on the schedulability. A study on
performance difference between Fixed Priority schedulers and EDF in the case of
partitioning scheduling is also considered.
"
51,Efficient System-Enforced Deterministic Parallelism,"  Deterministic execution offers many benefits for debugging, fault tolerance,
and security. Running parallel programs deterministically is usually difficult
and costly, however - especially if we desire system-enforced determinism,
ensuring precise repeatability of arbitrarily buggy or malicious software.
Determinator is a novel operating system that enforces determinism on both
multithreaded and multi-process computations. Determinator's kernel provides
only single-threaded, ""shared-nothing"" address spaces interacting via
deterministic synchronization. An untrusted user-level runtime uses distributed
computing techniques to emulate familiar abstractions such as Unix processes,
file systems, and shared memory multithreading. The system runs parallel
applications deterministically both on multicore PCs and across nodes in a
cluster. Coarse-grained parallel benchmarks perform and scale comparably to -
sometimes better than - conventional systems, though determinism is costly for
fine-grained parallel applications.
"
52,File Managing and Program Execution in Web Operating Systems,"  Web Operating Systems can be seen as an extension of traditional Operating
Systems where the addresses used to manage files and execute programs (via the
basic load/execution mechanism) are extended from local filesystem path-names
to URLs. A first consequence is that, similarly as in traditional web
technologies, executing a program at a given URL, can be done in two
modalities: either the execution is performed client-side at the invoking
machine (and relative URL addressing in the executed program set to refer to
the invoked URL) or it is performed server-side at the machine addressed by the
invoked URL (as, e.g., for a web service). Moreover in this context, user
identification for access to programs and files and workflow-based composition
of service programs is naturally based on token/session-like mechanisms. We
propose a middleware based on client-server protocols and on a set primitives,
for managing files/resources and executing programs (in the form of
client-side/server-side components/services) in Web Operating Systems. We
formally define the semantics of such middleware via a process algebraic
approach.
"
53,Simulation de traces r\'eelles d'E/S disque de PC,"  Under Windows operating system, existing I/O benchmarking tools does not
allow a developer to efficiently define a file access strategy according to the
applications' constraints. This is essentially due to the fact that the
existing tools do allow only a restricted set of I/O workloads that does not
generally correspond to the target applications. To cope with this problem, we
designed and implemented a precise I/O simulator allowing to simulate whatever
real I/O trace on a given defined architecture, and in which most of file and
disk cache strategies, their interactions and the detailed storage system
architecture are implemented. Simulation results on different workloads and
architectures show a very high degree of precision. In fact, the mean error
rate as compared to real measures is of about 6% with a maximum of 10% on
global throughput.
"
54,On the definition of a theoretical concept of an operating system,"  We dwell on how a definition of a theoretical concept of an operating system,
suitable to be incorporated in a mathematical theory of operating systems,
could look like. This is considered a valuable preparation for the development
of a mathematical theory of operating systems.
"
55,Perbandingan Shell Unix,"  Is it possible for an Information Technology [IT] product to be both mature
and state-of-theart at the same time? In the case of the UNIX system, the
answer is an unqualified ""Yes."" The UNIX system has continued to develop over
the past twenty-five years. In millions of installations running on nearly
every hardware platform made, the UNIX system has earned its reputation for
stability and scalability. Over the years, UNIX system suppliers have steadily
assimilated new technologies so that UNIX systems today provide more
functionality as any other operating system.
"
56,Gang FTP scheduling of periodic and parallel rigid real-time tasks,"  In this paper we consider the scheduling of periodic and parallel rigid
tasks. We provide (and prove correct) an exact schedulability test for Fixed
Task Priority (FTP) Gang scheduler sub-classes: Parallelism Monotonic, Idling,
Limited Gang, and Limited Slack Reclaiming. Additionally, we study the
predictability of our schedulers: we show that Gang FJP schedulers are not
predictable and we identify several sub-classes which are actually predictable.
Moreover, we extend the definition of rigid, moldable and malleable jobs to
recurrent tasks.
"
57,"Semi-Partitioned Hard Real-Time Scheduling with Restricted Migrations
  upon Identical Multiprocessor Platforms","  Algorithms based on semi-partitioned scheduling have been proposed as a
viable alternative between the two extreme ones based on global and partitioned
scheduling. In particular, allowing migration to occur only for few tasks which
cannot be assigned to any individual processor, while most tasks are assigned
to specific processors, considerably reduces the runtime overhead compared to
global scheduling on the one hand, and improve both the schedulability and the
system utilization factor compared to partitioned scheduling on the other hand.
In this paper, we address the preemptive scheduling problem of hard real-time
systems composed of sporadic constrained-deadline tasks upon identical
multiprocessor platforms. We propose a new algorithm and a scheduling paradigm
based on the concept of semi-partitioned scheduling with restricted migrations
in which jobs are not allowed to migrate, but two subsequent jobs of a task can
be assigned to different processors by following a periodic strategy.
"
58,Dynamic and Transparent Analysis of Commodity Production Systems,"  We propose a framework that provides a programming interface to perform
complex dynamic system-level analyses of deployed production systems. By
leveraging hardware support for virtualization available nowadays on all
commodity machines, our framework is completely transparent to the system under
analysis and it guarantees isolation of the analysis tools running on its top.
Thus, the internals of the kernel of the running system needs not to be
modified and the whole platform runs unaware of the framework. Moreover, errors
in the analysis tools do not affect the running system and the framework. This
is accomplished by installing a minimalistic virtual machine monitor and
migrating the system, as it runs, into a virtual machine. In order to
demonstrate the potentials of our framework we developed an interactive kernel
debugger, nicknamed HyperDbg. HyperDbg can be used to debug any critical kernel
component, and even to single step the execution of exception and interrupt
handlers.
"
59,Scaling Turbo Boost to a 1000 cores,"  The Intel Core i7 processor code named Nehalem provides a feature named Turbo
Boost which opportunistically varies the frequencies of the processor's cores.
The frequency of a core is determined by core temperature, the number of active
cores, the estimated power consumption, the estimated current consumption, and
operating system frequency scaling requests. For a chip multi-processor(CMP)
that has a small number of physical cores and a small set of performance
states, deciding the Turbo Boost frequency to use on a given core might not be
difficult. However, we do not know the complexity of this decision making
process in the context of a large number of cores, scaling to the 100s, as
predicted by researchers in the field.
"
60,"CloneCloud: Boosting Mobile Device Applications Through Cloud Clone
  Execution","  Mobile applications are becoming increasingly ubiquitous and provide ever
richer functionality on mobile devices. At the same time, such devices often
enjoy strong connectivity with more powerful machines ranging from laptops and
desktops to commercial clouds. This paper presents the design and
implementation of CloneCloud, a system that automatically transforms mobile
applications to benefit from the cloud. The system is a flexible application
partitioner and execution runtime that enables unmodified mobile applications
running in an application-level virtual machine to seamlessly off-load part of
their execution from mobile devices onto device clones operating in a
computational cloud. CloneCloud uses a combination of static analysis and
dynamic profiling to optimally and automatically partition an application so
that it migrates, executes in the cloud, and re-integrates computation in a
fine-grained manner that makes efficient use of resources. Our evaluation shows
that CloneCloud can achieve up to 21.2x speedup of smartphone applications we
tested and it allows different partitioning for different inputs and networks.
"
61,Revisiting deadlock prevention: a probabilistic approach,"  We revisit the deadlock-prevention problem by focusing on priority digraphs
instead of the traditional wait-for digraphs. This has allowed us to formulate
deadlock prevention in terms of prohibiting the occurrence of directed cycles
even in the most general of wait models (the so-called AND-OR model, in which
prohibiting wait-for directed cycles is generally overly restrictive). For a
particular case in which the priority digraphs are somewhat simplified, we
introduce a Las Vegas probabilistic mechanism for resource granting and analyze
its key aspects in detail.
"
62,An Introduction to Time-Constrained Automata,"  We present time-constrained automata (TCA), a model for hard real-time
computation in which agents behaviors are modeled by automata and constrained
by time intervals.
  TCA actions can have multiple start time and deadlines, can be aperiodic, and
are selected dynamically following a graph, the time-constrained automaton.
This allows expressing much more precise time constraints than classical
periodic or sporadic model, while preserving the ease of scheduling and
analysis.
  We provide some properties of this model as well as their scheduling
semantics. We show that TCA can be automatically derived from source-code, and
optimally scheduled on single processors using a variant of EDF. We explain how
time constraints can be used to guarantee communication determinism by
construction, and to study when possible agent interactions happen.
"
63,Use of Data Mining in Scheduler Optimization,"  The operating system's role in a computer system is to manage the various
resources. One of these resources is the Central Processing Unit. It is managed
by a component of the operating system called the CPU scheduler. Schedulers are
optimized for typical workloads expected to run on the platform. However, a
single scheduler may not be appropriate for all workloads. That is, a scheduler
may schedule a workload such that the completion time is minimized, but when
another type of workload is run on the platform, scheduling and therefore
completion time will not be optimal; a different scheduling algorithm, or a
different set of parameters, may work better. Several approaches to solving
this problem have been proposed. The objective of this survey is to summarize
the approaches based on data mining, which are available in the literature. In
addition to solutions that can be directly utilized for solving this problem,
we are interested in data mining research in related areas that have potential
for use in operating system scheduling. We also explain general technical
issues involved in scheduling in modern computers, including parallel
scheduling issues related to multi-core CPUs. We propose a taxonomy that
classifies the scheduling approaches we discuss into different categories.
"
64,"Leakage-Aware Reallocation for Periodic Real-Time Tasks on Multicore
  Processors","  It is an increasingly important issue to reduce the energy consumption of
computing systems. In this paper, we consider partition based energy-aware
scheduling of periodic real-time tasks on multicore processors. The scheduling
exploits dynamic voltage scaling (DVS) and core sleep scheduling to reduce both
dynamic and leakage energy consumption. If the overhead of core state switching
is non-negligible, however, the performance of this scheduling strategy in
terms of energy efficiency might degrade. To achieve further energy saving, we
extend the static task scheduling with run-time task reallocation. The basic
idea is to aggregate idle time among cores so that as many cores as possible
could be put into sleep in a way that the overall energy consumption is
reduced. Simulation results show that the proposed approach results in up to
20% energy saving over traditional leakage-aware DVS.
"
65,"Sesame: Self-Constructive System Energy Modeling for Battery-Powered
  Mobile Systems","  System energy models are important for energy optimization and management in
mobile systems. However, existing system energy models are built in lab with
the help from a second computer. Not only are they labor-intensive; but also
they will not adequately account for the great diversity in the hardware and
usage of mobile systems. Moreover, existing system energy models are intended
for energy estimation for time intervals of one second or longer; they do not
provide the required rate for fine-grain use such as per-application energy
accounting.
  In this work, we study a self-modeling paradigm in which a mobile system
automatically generates its energy model without any external assistance. Our
solution, Se-same, leverages the possibility of self power measurement through
the smart battery interface and employs a suite of novel techniques to achieve
accuracy and rate much higher than that of the smart battery interface.
  We report the implementation and evaluation of Se-same on a laptop and a
smartphone. The experiment results show that Sesame generates system energy
models of 95% accuracy at one estimation per second and 88% accuracy at one
estimation per 10ms, without any external assistance. A five-day field studies
with four laptop and four smartphones users further demonstrate the
effectiveness, efficiency, and noninvasiveness of Sesame.
"
66,Seamless Flow Migration on Smartphones without Network Support,"  This paper addresses the following question: Is it possible to migrate TCP/IP
flows between different networks on modern mobile devices, without
infrastructure support or protocol changes? To answer this question, we make
three research contributions. (i) We report a comprehensive characterization of
IP traffic on smartphones using traces collected from 27 iPhone 3GS users for
three months. (ii) Driven by the findings from the characterization, we devise
two novel system mechanisms for mobile devices to sup-port seamless flow
migration without network support, and extensively evaluate their effectiveness
using our field collected traces of real-life usage. Wait-n-Migrate leverages
the fact that most flows are short lived. It establishes new flows on newly
available networks but allows pre-existing flows on the old network to
terminate naturally, effectively decreasing, or even eliminating, connectivity
gaps during network switches. Resumption Agent takes advantage of the
functionality integrated into many modern protocols to securely resume flows
without application intervention. When combined, Wait-n-Migrate and Resumption
Agent provide an unprecedented opportunity to immediately deploy performance
and efficiency-enhancing policies that leverage multiple networks to improve
the performance, efficiency, and connectivity of mobile devices. (iii) Finally,
we report an iPhone 3GS based implementation of these two system mechanisms and
show that their overhead is negligible. Furthermore, we employ an example
network switching policy, called AutoSwitch, to demonstrate their performance.
AutoSwitch improves the Wi-Fi user experience by intelligently migrating TCP
flows between Wi-Fi and cellular networks. Through traces and field
measurements, we show that AutoSwitch reduces the number of user disruptions by
an order of magnitude.
"
67,Customer Appeasement Scheduling,"  Almost all of the current process scheduling algorithms which are used in
modern operating systems (OS) have their roots in the classical scheduling
paradigms which were developed during the 1970's. But modern computers have
different types of software loads and user demands. We think it is important to
run what the user wants at the current moment. A user can be a human, sitting
in front of a desktop machine, or it can be another machine sending a request
to a server through a network connection. We think that OS should become
intelligent to distinguish between different processes and allocate resources,
including CPU, to those processes which need them most. In this work, as a
first step to make the OS aware of the current state of the system, we consider
process dependencies and interprocess communications. We are developing a
model, which considers the need to satisfy interactive users and other possible
remote users or customers, by making scheduling decisions based on process
dependencies and interprocess communications. Our simple proof of concept
implementation and experiments show the effectiveness of this approach in the
real world applications. Our implementation does not require any change in the
software applications nor any special kind of configuration in the system,
Moreover, it does not require any additional information about CPU needs of
applications nor other resource requirements. Our experiments show significant
performance improvement for real world applications. For example, almost
constant average response time for Mysql data base server and constant frame
rate for mplayer under different simulated load values.
"
68,"Application of Global and One-Dimensional Local Optimization to
  Operating System Scheduler Tuning","  This paper describes a study of comparison of global and one-dimensional
local optimization methods to operating system scheduler tuning. The operating
system scheduler we use is the Linux 2.6.23 Completely Fair Scheduler (CFS)
running in simulator (LinSched). We have ported the Hackbench scheduler
benchmark to this simulator and use this as the workload. The global
optimization approach we use is Particle Swarm Optimization (PSO). We make use
of Response Surface Methodology (RSM) to specify optimal parameters for our PSO
implementation. The one-dimensional local optimization approach we use is the
Golden Section method. In order to use this approach, we convert the scheduler
tuning problem from one involving setting of three parameters to one involving
the manipulation of one parameter. Our results show that the global
optimization approach yields better response but the one- dimensional
optimization approach converges to a solution faster than the global
optimization approach.
"
69,"Dynamic Scheduling of Skippable Periodic Tasks with Energy Efficiency in
  Weakly Hard Real-Time System","  Energy consumption is a critical design issue in real-time systems,
especially in battery- operated systems. Maintaining high performance, while
extending the battery life between charges is an interesting challenge for
system designers. Dynamic Voltage Scaling (DVS) allows a processor to
dynamically change speed and voltage at run time, thereby saving energy by
spreading run cycles into idle time. Knowing when to use full power and when
not, requires the cooperation of the operating system scheduler. Usually,
higher processor voltage and frequency leads to higher system throughput while
energy reduction can be obtained using lower voltage and frequency. Instead of
lowering processor voltage and frequency as much as possible, energy efficient
real-time scheduling adjusts voltage and frequency according to some
optimization criteria, such as low energy consumption or high throughput, while
it meets the timing constraints of the real-time tasks. As the quantity and
functional complexity of battery powered portable devices continues to raise,
energy efficient design of such devices has become increasingly important. Many
real-time scheduling algorithms have been developed recently to reduce energy
consumption in the portable devices that use DVS capable processors. Three
algorithms namely Red Tasks Only (RTO), Blue When Possible (BWP) and Red as
Late as Possible (RLP) are proposed in the literature to schedule the real-time
tasks in Weakly-hard real-time systems. This paper proposes optimal slack
management algorithms to make the above existing weakly hard real-time
scheduling algorithms energy efficient using DVS and DPD techniques.
"
70,"Exact Schedulability Test for global-EDF Scheduling of Periodic Hard
  Real-Time Tasks on Identical Multiprocessors","  In this paper we consider the scheduling problem of hard real-time systems
composed of periodic constrained-deadline tasks upon identical multiprocessor
platforms. We assume that tasks are scheduled by using the global-EDF
scheduler. We establish an exact schedulability test for this scheduler by
exploiting on the one hand its predictability property and by providing on the
other hand a feasibility interval so that if it is possible to find a valid
schedule for all the jobs contained in this interval, then the whole system
will be stamped feasible. In addition, we show by means of a counterexample
that the feasibility interval, and thus the schedulability test, proposed by
Leung [Leung 1989] is incorrect and we show which arguments are actually
incorrect.
"
71,Comparison of Loss ratios of different scheduling algorithms,"  It is well known that in a firm real time system with a renewal arrival
process, exponential service times and independent and identically distributed
deadlines till the end of service of a job, the earliest deadline first (EDF)
scheduling policy has smaller loss ratio (expected fraction of jobs, not
completed) than any other service time independent scheduling policy, including
the first come first served (FCFS). Various modifications to the EDF and FCFS
policies have been proposed in the literature, with a view to improving
performance. In this article, we compare the loss ratios of these two policies
along with some of the said modifications, as well as their counterparts with
deterministic deadlines. The results include some formal inequalities and some
counter-examples to establish non-existence of an order. A few relations
involving loss ratios are posed as conjectures, and simulation results in
support of these are reported. These results lead to a complete picture of
dominance and non-dominance relations between pairs of scheduling policies, in
terms of loss ratios.
"
72,"Global Scheduling of Multi-Mode Real-Time Applications upon
  Multiprocessor Platforms","  Multi-mode real-time systems are those which support applications with
different modes of operation, where each mode is characterized by a specific
set of tasks. At run-time, such systems can, at any time, be requested to
switch from its current operating mode to another mode (called ""new mode"") by
replacing the current set of tasks with that of the new-mode. Thereby, ensuring
that all the timing requirements are met not only requires that a
schedulability test is performed on the tasks of each mode but also that (i) a
protocol for transitioning from one mode to another is specified and (ii) a
schedulability test for each transition is performed. We propose two distinct
protocols that manage the mode transitions upon uniform and identical
multiprocessor platforms at run-time, each specific to distinct task
requirements. For each protocol, we formally establish schedulability analyses
that indicate beforehand whether all the timing requirements will be met during
any mode transition of the system. This is performed assuming both
Fixed-Task-Priority and Fixed-Job-Priority schedulers.
"
73,Efficient and Playful Tools to Teach Unix to New Students,"  Teaching Unix to new students is a common tasks in many higher schools. This
paper presents an approach to such course where the students progress
autonomously with the help of the teacher. The traditional textbook is
complemented with a wiki, and the main thread of the course is a game, in the
form of a treasure hunt. The course finishes with a lab exam, where students
have to perform practical manipulations similar to the ones performed during
the treasure hunt. The exam is graded fully automatically. This paper discusses
the motivations and advantages of the approach, and gives an overall view of
the tools we developed. The tools are available from the web, and open-source,
hence re-usable outside the Ensimag.
"
74,"Building XenoBuntu Linux Distribution for Teaching and Prototyping
  Real-Time Operating Systems","  This paper describes the realization of a new Linux distribution based on
Ubuntu Linux and Xenomai Real-Time framework. This realization is motivated by
the eminent need of real-time systems in modern computer science courses. The
majority of the technical choices are made after qualitative comparison. The
main goal of this distribution is to offer standard Operating Systems (OS) that
include Xenomai infrastructure and the essential tools to begin hard real-time
application development inside a convivial desktop environment. The released
live/installable DVD can be adopted to emulate several classic RTOS Application
Program Interfaces (APIs), directly use and understand real-time Linux in
convivial desktop environment and prototyping real-time embedded applications.
"
75,Transparent Programming of Heterogeneous Smartphones for Sensing,"  Sensing on smartphones is known to be power-hungry. It has been shown that
this problem can be solved by adding an ultra low-power processor to execute
simple, frequent sensor data processing. While very effective in saving energy,
this resulting heterogeneous, distributed architecture poses a significant
challenge to application development.
  We present Reflex, a suite of runtime and compilation techniques to conceal
the heterogeneous, distributed nature from developers. The Reflex automatically
transforms the developer's code for distributed execution with the help of the
Reflex runtime. To create a unified system illusion, Reflex features a novel
software distributed shared memory (DSM) design that leverages the extreme
architectural asymmetry between the low-power processor and the powerful
central processor to achieve both energy efficiency and performance.
  We report a complete realization of Reflex for heterogeneous smartphones with
Maemo/Linux as the central kernel. Using a tri-processor hardware prototype and
sensing applications reported in recent literature, we evaluate the Reflex
realization for programming transparency, energy efficiency, and performance.
We show that Reflex supports a programming style that is very close to
contemporary smartphone programming. It allows existing sensing applications to
be ported with minor source code changes. Reflex reduces the system power in
sensing by up to 83%, and its runtime system only consumes 10% local memory on
a typical ultra-low power processor.
"
76,"A New Proposed Dynamic Quantum with Re-Adjusted Round Robin Scheduling
  Algorithm and Its Performance Analysis","  Scheduling is the central concept used frequently in Operating System. It
helps in choosing the processes for execution. Round Robin (RR) is one of the
most widely used CPU scheduling algorithm. But, its performance degrades with
respect to context switching, which is an overhead and it occurs during each
scheduling. Overall performance of the system depends on choice of an optimal
time quantum, so that context switching can be reduced. In this paper, we have
proposed a new variant of RR scheduling algorithm, known as Dynamic Quantum
with Readjusted Round Robin (DQRRR) algorithm. We have experimentally shown
that performance of DQRRR is better than RR by reducing number of context
switching, average waiting time and average turn around time.
"
77,"A New Dynamic Round Robin and SRTN Algorithm with Variable Original Time
  Slice and Intelligent Time Slice for Soft Real Time Systems","  The main objective of the paper is to improve the Round Robin (RR) algorithm
using dynamic ITS by coalescing it with Shortest Remaining Time Next (SRTN)
algorithm thus reducing the average waiting time, average turnaround time and
the number of context switches. The original time slice has been calculated for
each process based on its burst time.This is mostly suited for soft real time
systems where meeting of deadlines is desirable to increase its performance.
The advantage is that processes that are closer to their remaining completion
time will get more chances to execute and leave the ready queue. This will
reduce the number of processes in the ready queue by knocking out short jobs
relatively faster in a hope to reduce the average waiting time, turn around
time and number of context switches. This paper improves the algorithm [8] and
the experimental analysis shows that the proposed algorithm performs better
than algorithm [6] and [8] when the processes are having an increasing order,
decreasing order and random order of burst time.
"
78,Deterministic Real-time Thread Scheduling,"  Race condition is a timing sensitive problem. A significant source of timing
variation comes from nondeterministic hardware interactions such as cache
misses. While data race detectors and model checkers can check races, the
enormous state space of complex software makes it difficult to identify all of
the races and those residual implementation errors still remain a big
challenge. In this paper, we propose deterministic real-time scheduling methods
to address scheduling nondeterminism in uniprocessor systems. The main idea is
to use timing insensitive deterministic events, e.g, an instruction counter, in
conjunction with a real-time clock to schedule threads. By introducing the
concept of Worst Case Executable Instructions (WCEI), we guarantee both
determinism and real-time performance.
"
79,"An Optimal Real-Time Scheduling Approach: From Multiprocessor to
  Uniprocessor","  An optimal solution to the problem of scheduling real-time tasks on a set of
identical processors is derived. The described approach is based on solving an
equivalent uniprocessor real-time scheduling problem. Although there are other
scheduling algorithms that achieve optimality, they usually impose prohibitive
preemption costs. Unlike these algorithms, it is observed through simulation
that the proposed approach produces no more than three preemptions points per
job.
"
80,"Priority Based Dynamic Round Robin (PBDRR) Algorithm with Intelligent
  Time Slice for Soft Real Time Systems","  In this paper, a new variant of Round Robin (RR) algorithm is proposed which
is suitable for soft real time systems. RR algorithm performs optimally in
timeshared systems, but it is not suitable for soft real time systems. Because
it gives more number of context switches, larger waiting time and larger
response time. We have proposed a novel algorithm, known as Priority Based
Dynamic Round Robin Algorithm(PBDRR),which calculates intelligent time slice
for individual processes and changes after every round of execution. The
proposed scheduling algorithm is developed by taking dynamic time quantum
concept into account. Our experimental results show that our proposed algorithm
performs better than algorithm in [8] in terms of reducing the number of
context switches, average waiting time and average turnaround time.
"
81,User Mode Memory Page Allocation: A Silver Bullet For Memory Allocation?,"  This paper proposes a novel solution: the elimination of paged virtual memory
and partial outsourcing of memory page allocation and manipulation from the
operating system kernel into the individual process' user space - a user mode
page allocator - which allows an application to have direct, bare metal access
to the page mappings used by the hardware Memory Management Unit (MMU) for its
part of the overall address space. A user mode page allocator based emulation
of the mmap() abstraction layer of dlmalloc is then benchmarked against the
traditional kernel mode implemented mmap() in a series of synthetic Monte-Carlo
and real world application settings. Given the superb synthetic and positive
real world results from the profiling conducted, this paper proposes that with
proper operating system and API support one could gain a further order higher
performance again while keeping allocator performance invariant to the amount
of memory being allocated or freed i.e. a 100x performance improvement or more
in some common use cases. It is rare that through a simple and easy to
implement API and operating system structure change one can gain a Silver
Bullet with the potential for a second one.
"
82,"User Mode Memory Page Management: An old idea applied anew to the memory
  wall problem","  It is often said that one of the biggest limitations on computer performance
is memory bandwidth (i.e.""the memory wall problem""). In this position paper, I
argue that if historical trends in computing evolution (where growth in
available capacity is exponential and reduction in its access latencies is
linear) continue as they have, then this view is wrong - in fact we ought to be
concentrating on reducing whole system memory access latencies wherever
possible, and by ""whole system"" I mean that we ought to look at how software
can be unnecessarily wasteful with memory bandwidth due to legacy design
decisions. To this end I conduct a feasibility study to determine whether we
ought to virtualise the MMU for each application process such that it has
direct access to its own MMU page tables and the memory allocated to a process
is managed exclusively by the process and not the kernel. I find under typical
conditions that nearly scale invariant performance to memory allocation size is
possible such that hundreds of megabytes of memory can be allocated, relocated,
swapped and deallocated in almost the same time as kilobytes (e.g. allocating
8Mb is 10x quicker under this experimental allocator than a conventional
allocator, and resizing a 128Kb block to 256Kb block is 4.5x faster). I find
that first time page access latencies are improved tenfold; moreover, because
the kernel page fault handler is never called, the lack of cache pollution
improves whole application memory access latencies increasing performance by up
to 2x. Finally, I try binary patching existing applications to use the
experimental allocation technique, finding almost universal performance
improvements without having to recompile these applications to make better use
of the new facilities.
"
83,Unleashing the Power of Mobile Cloud Computing using ThinkAir,"  Smartphones have exploded in popularity in recent years, becoming ever more
sophisticated and capable. As a result, developers worldwide are building
increasingly complex applications that require ever increasing amounts of
computational power and energy. In this paper we propose ThinkAir, a framework
that makes it simple for developers to migrate their smartphone applications to
the cloud. ThinkAir exploits the concept of smartphone virtualization in the
cloud and provides method level computation offloading. Advancing on previous
works, it focuses on the elasticity and scalability of the server side and
enhances the power of mobile cloud computing by parallelizing method execution
using multiple Virtual Machine (VM) images. We evaluate the system using a
range of benchmarks starting from simple micro-benchmarks to more complex
applications. First, we show that the execution time and energy consumption
decrease two orders of magnitude for the N-queens puzzle and one order of
magnitude for a face detection and a virus scan application, using cloud
offloading. We then show that if a task is parallelizable, the user can request
more than one VM to execute it, and these VMs will be provided dynamically. In
fact, by exploiting parallelization, we achieve a greater reduction on the
execution time and energy consumption for the previous applications. Finally,
we use a memory-hungry image combiner tool to demonstrate that applications can
dynamically request VMs with more computational power in order to meet their
computational requirements.
"
84,A faster exact multiprocessor schedulability test for sporadic tasks,"  Baker and Cirinei introduced an exact but naive algorithm, based on solving a
state reachability problem in a finite automaton, to check whether sets of
sporadic hard real-time tasks are schedulable on identical multiprocessor
platforms. However, the algorithm suffered from poor performance due to the
exponential size of the automaton relative to the size of the task set. In this
paper, we successfully apply techniques developed by the formal verification
community, specifically antichain algorithms, by defining and proving the
correctness of a simulation relation on Baker and Cirinei's automaton. We show
our improved algorithm yields dramatically improved performance for the
schedulability test and opens for many further improvements.
"
85,Scheduling of Hard Real-Time Multi-Thread Periodic Tasks,"  In this paper we study the scheduling of parallel and real-time recurrent
tasks. Firstly, we propose a new parallel task model which allows recurrent
tasks to be composed of several threads, each thread requires a single
processor for execution and can be scheduled simultaneously. Secondly, we
define several kinds of real-time schedulers that can be applied to our
parallel task model. We distinguish between two scheduling classes:
hierarchical schedulers and global thread schedulers. We present and prove
correct an exact schedulability test for each class. Lastly, we also evaluate
the performance of our scheduling paradigm in comparison with Gang scheduling
by means of simulations.
"
86,Supporting Parallelism in Server-based Multiprocessor Systems,"  Developing an efficient server-based real-time scheduling solution that
supports dynamic task-level parallelism is now relevant to even the desktop and
embedded domains and no longer only to the high performance computing market
niche. This paper proposes a novel approach that combines the constant
bandwidth server abstraction with a work-stealing load balancing scheme which,
while ensuring isolation among tasks, enables a task to be executed on more
than one processor at a given time instant.
"
87,A Characterization of the SPARC T3-4 System,"  This technical report covers a set of experiments on the 64-core SPARC T3-4
system, comparing it to two similar AMD and Intel systems. Key characteristics
as maximum integer and floating point arithmetic throughput are measured as
well as memory throughput, showing the scalability of the SPARC T3-4 system.
The performance of POSIX threads primitives is characterized and compared in
detail, such as thread creation and mutex synchronization. Scalability tests
with a fine grained multithreaded runtime are performed, showing problems with
atomic CAS operations on such physically highly parallel systems.
"
88,Efficient Deterministic Replay Using Complete Race Detection,"  Data races can significantly affect the executions of multi-threaded
programs. Hence, one has to recur the results of data races to
deterministically replay a multi-threaded program. However, data races are
concealed in enormous number of memory operations in a program. Due to the
difficulty of accurately identifying data races, previous multi-threaded
deterministic record/replay schemes for commodity multi-processor system give
up to record data races directly. Consequently, they either record all shared
memory operations, which brings remarkable slowdown to the production run, or
record the synchronization only, which introduces significant efforts to
replay.
  Inspired by the advances in data race detection, we propose an efficient
software-only deterministic replay scheme for commodity multi-processor
systems, which is named RacX. The key insight of RacX is as follows: although
it is NP-hard to accurately identify the existence of data races between a pair
of memory operations, we can find out all potential data races in a
multi-threaded program, in which the false positives can be reduced to a small
amount with our automatic false positive reduction techniques. As a result,
RacX can efficiently monitor all potential data races to deterministically
replay a multi-threaded program.
  To evaluate RacX, we have carried out experiments over a number of well-known
multi-threaded programs from SPLASH-2 benchmark suite and large-scale
commercial programs. RacX can precisely recur production runs of these programs
with value determinism. Averagely, RacX causes only about 1.21%, 1.89%, 2.20%,
and 8.41% slowdown to the original run during recording (for 2-, 4-, 8- and
16-thread programs, respectively). The soundness, efficiency, scalability, and
portability of RacX well demonstrate its superiority.
"
89,"Towards Bridging IoT and Cloud Services: Proposing Smartphones as Mobile
  and Autonomic Service Gateways","  Computing is currently getting at the same time incredibly in the small with
sensors/actuators embedded in our every- day objects and also greatly in the
large with data and ser- vice clouds accessible anytime, anywhere. This
Internet of Things is physically closed to the user but suffers from weak
run-time execution environments. Cloud Environments provide powerful data
storage and computing power but can not be easily accessed and integrate the
final-user context- awareness. We consider smartphones are set to become the
universal interface between these two worlds. In this position paper, we
propose a middleware approach where smartphones provide service gateways to
bridge the gap between IoT services and Cloud services. Since smartphones are
mobile gateways, they should be able to (re)configure themself according to
their place, things discovered around, and their own resources such battery.
Several issues are discussed: collaborative event-based context management,
adaptive and opportunistic service deployment and invocation, multi-criteria
(user- and performance-oriented) optimization decision algorithm.
"
90,Light-weight Locks,"  In this paper, we propose a new approach to building synchronization
primitives, dubbed ""lwlocks"" (short for light-weight locks). The primitives are
optimized for small memory footprint while maintaining efficient performance in
low contention scenarios. A read-write lwlock occupies 4 bytes, a mutex
occupies 4 bytes (2 if deadlock detection is not required), and a condition
variable occupies 4 bytes. The corresponding primitives of the popular pthread
library occupy 56 bytes, 40 bytes and 48 bytes respectively on the x86-64
platform. The API for lwlocks is similar to that of the pthread library but
covering only the most common use cases. Lwlocks allow explicit control of
queuing and scheduling decisions in contention situations and support
""asynchronous"" or ""deferred blocking"" acquisition of locks. Asynchronous
locking helps in working around the constraints of lock-ordering which
otherwise limits concurrency. The small footprint of lwlocks enables the
construction of data structures with very fine-grained locking, which in turn
is crucial for lowering contention and supporting highly concurrent access to a
data structure. Currently, the Data Domain File System uses lwlocks for its
in-memory inode cache as well as in a generic doubly-linked concurrent list
which forms the building block for more sophisticated structures.
"
91,"Design and Performance Evaluation of A New Proposed Fittest Job First
  Dynamic Round Robin(FJFDRR) Scheduling Algorithm","  In this paper, we have proposed a new variant of Round Robin scheduling
algorithm by executing the processes according to the new calculated Fit Factor
f and using the concept of dynamic time quantum. We have compared the
performance of our proposed Fittest Job First Dynamic Round Robin(FJFDRR)
algorithm with the Priority Based Static Round Robin(PBSRR) algorithm.
Experimental results show that our proposed algorithm performs better than
PBSRR in terms of reducing the number of context switches, average waiting time
and average turnaround time.
"
92,"Comparative performance analysis of multi dynamic time quantum Round
  Robin(MDTQRR) algorithm with arrival time","  CPU being considered a primary computer resource, its scheduling is central
to operating-system design. A thorough performance evaluation of various
scheduling algorithms manifests that Round Robin Algorithm is considered as
optimal in time shared environment because the static time is equally shared
among the processes. We have proposed an efficient technique in the process
scheduling algorithm by using dynamic time quantum in Round Robin. Our approach
is based on the calculation of time quantum twice in single round robin cycle.
Taking into consideration the arrival time, we implement the algorithm.
Experimental analysis shows better performance of this improved algorithm over
the Round Robin algorithm and the Shortest Remaining Burst Round Robin
algorithm. It minimizes the overall number of context switches, average waiting
time and average turn-around time. Consequently the throughput and CPU
utilization is better.
"
93,Efficient Synchronization Primitives for GPUs,"  In this paper, we revisit the design of synchronization
primitives---specifically barriers, mutexes, and semaphores---and how they
apply to the GPU. Previous implementations are insufficient due to the
discrepancies in hardware and programming model of the GPU and CPU. We create
new implementations in CUDA and analyze the performance of spinning on the GPU,
as well as a method of sleeping on the GPU, by running a set of memory-system
benchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class
GPUs from NVIDIA. From our results we define higher-level principles that are
valid for generic many-core processors, the most important of which is to limit
the number of atomic accesses required for a synchronization operation because
atomic accesses are slower than regular memory accesses. We use the results of
the benchmarks to critique existing synchronization algorithms and guide our
new implementations, and then define an abstraction of GPUs to classify any GPU
based on the behavior of the memory system. We use this abstraction to create
suitable implementations of the primitives specifically targeting the GPU, and
analyze the performance of these algorithms on Tesla and Fermi. We then predict
performance on future GPUs based on characteristics of the abstraction. We also
examine the roles of spin waiting and sleep waiting in each primitive and how
their performance varies based on the machine abstraction, then give a set of
guidelines for when each strategy is useful based on the characteristics of the
GPU and expected contention.
"
94,"Sufficient FTP Schedulability Test for the Non-Cyclic Generalized
  Multiframe Task Model","  Our goal is to provide a sufficient schedulability test -ideally polynomial-
for the scheduling of Non-Cyclic Generalized Multiframe Task Model using
Fixed-Task-Priority schedulers. We report two first results: (i) we present and
prove correct the critical instant for the Non-Cyclic Generalized Multiframe
Task Model then (ii) we propose an algorithm which provides a sufficient (but
pseudo-polynomial) schedulability test.
"
95,The UWB Solution for Multimedia Traffic in Wireless Sensor Networks,"  Several researches are focused on the QoS (Quality of Service) and Energy
consumption in wireless Multimedia Sensor Networks. Those research projects
invest in theory and practice in order to extend the spectrum of use of norms,
standards and technologies which are emerged in wireless communications. The
performance of these technologies is strongly related to domains of use and
limitations of their characteristics. In this paper, we give a comparison of
ZigBee technology, most widely used in sensor networks, and UWB (Ultra Wide
Band) which presents itself as competitor that present in these work better
results for audiovisual applications with medium-range and high throughput.
"
96,Evolution of a Modular Software Network,"  ""Evolution behaves like a tinkerer"" (Francois Jacob, Science, 1977). Software
systems provide a unique opportunity to understand biological processes using
concepts from network theory. The Debian GNU/Linux operating system allows us
to explore the evolution of a complex network in a novel way. The modular
design detected during its growth is based on the reuse of existing code in
order to minimize costs during programming. The increase of modularity
experienced by the system over time has not counterbalanced the increase in
incompatibilities between software packages within modules. This negative
effect is far from being a failure of design. A random process of package
installation shows that the higher the modularity the larger the fraction of
packages working properly in a local computer. The decrease in the relative
number of conflicts between packages from different modules avoids a failure in
the functionality of one package spreading throughout the entire system. Some
potential analogies with the evolutionary and ecological processes determining
the structure of ecological networks of interacting species are discussed.
"
97,"A New Round Robin Based Scheduling Algorithm for Operating Systems:
  Dynamic Quantum Using the Mean Average","  Round Robin, considered as the most widely adopted CPU scheduling algorithm,
undergoes severe problems directly related to quantum size. If time quantum
chosen is too large, the response time of the processes is considered too high.
On the other hand, if this quantum is too small, it increases the overhead of
the CPU. In this paper, we propose a new algorithm, called AN, based on a new
approach called dynamic-time-quantum; the idea of this approach is to make the
operating systems adjusts the time quantum according to the burst time of the
set of waiting processes in the ready queue. Based on the simulations and
experiments, we show that the new proposed algorithm solves the fixed time
quantum problem and increases the performance of Round Robin.
"
98,Robustness Analysis for Battery Supported Cyber-Physical Systems,"  This paper establishes a novel analytical approach to quantify robustness of
scheduling and battery management for battery supported cyber-physical systems.
A dynamic schedulability test is introduced to determine whether tasks are
schedulable within a finite time window. The test is used to measure robustness
of a real-time scheduling algorithm by evaluating the strength of computing
time perturbations that break schedulability at runtime. Robustness of battery
management is quantified analytically by an adaptive threshold on the state of
charge. The adaptive threshold significantly reduces the false alarm rate for
battery management algorithms to decide when a battery needs to be replaced.
"
99,What is an OS?,"  While the engineering of operating systems is well understood, their formal
structure and properties are not. The latter needs a clear definition of the
purpose of an OS and an identification of the core. In this paper I offer
definitions of the OS, processes and files, and present a few useful
principles. The principles allow us to identify work like closure and
continuation algorithms, in programming languages that is useful for the OS
problem. The definitions and principles should yield a symbolic, albeit
semiquantitative, framework that encompasses practice. Towards that end I
specialise the definitions to describe conventional OSes and identify the core
operations for a single computer OS that can be used to express their
algorithms. The assumptions underlying the algorithms offer the design space
framework. The paging and segmentation algorithms for conventional OSes are
extracted from the framework as a check. Among the insights the emerge is that
an OS is a constructive proof of equivalence between models of computation.
Clear and useful definitions and principles are the first step towards a fully
quantitative structure of an OS.
"
100,Quest-V: A Virtualized Multikernel for High-Confidence Systems,"  This paper outlines the design of `Quest-V', which is implemented as a
collection of separate kernels operating together as a distributed system on a
chip. Quest-V uses virtualization techniques to isolate kernels and prevent
local faults from affecting remote kernels. This leads to a high-confidence
multikernel approach, where failures of system subcomponents do not render the
entire system inoperable. A virtual machine monitor for each kernel keeps track
of shadow page table mappings that control immutable memory access
capabilities. This ensures a level of security and fault tolerance in
situations where a service in one kernel fails, or is corrupted by a malicious
attack. Communication is supported between kernels using shared memory regions
for message passing. Similarly, device driver data structures are shareable
between kernels to avoid the need for complex I/O virtualization, or
communication with a dedicated kernel responsible for I/O. In Quest-V, device
interrupts are delivered directly to a kernel, rather than via a monitor that
determines the destination. Apart from bootstrapping each kernel, handling
faults and managing shadow page tables, the monitors are not needed. This
differs from conventional virtual machine systems in which a central monitor,
or hypervisor, is responsible for scheduling and management of host resources
amongst a set of guest kernels. In this paper we show how Quest-V can implement
novel fault isolation and recovery techniques that are not possible with
conventional systems. We also show how the costs of using virtualization for
isolation of system services does not add undue overheads to the overall system
performance.
"
101,AdSplit: Separating smartphone advertising from applications,"  A wide variety of smartphone applications today rely on third-party
advertising services, which provide libraries that are linked into the hosting
application. This situation is undesirable for both the application author and
the advertiser. Advertising libraries require additional permissions, resulting
in additional permission requests to users. Likewise, a malicious application
could simulate the behavior of the advertising library, forging the user's
interaction and effectively stealing money from the advertiser. This paper
describes AdSplit, where we extended Android to allow an application and its
advertising to run as separate processes, under separate user-ids, eliminating
the need for applications to request permissions on behalf of their advertising
libraries.
  We also leverage mechanisms from Quire to allow the remote server to validate
the authenticity of client-side behavior. In this paper, we quantify the degree
of permission bloat caused by advertising, with a study of thousands of
downloaded apps. AdSplit automatically recompiles apps to extract their ad
services, and we measure minimal runtime overhead. We also observe that most ad
libraries just embed an HTML widget within and describe how AdSplit can be
designed with this in mind to avoid any need for ads to have native code.
"
102,How to Bypass Verified Boot Security in Chromium OS,"  Verified boot is an interesting feature of Chromium OS that supposedly can
detect any modification in the root file system (rootfs) by a dedicated
adversary. However, by exploiting a design flaw in verified boot, we show that
an adversary can replace the original rootfs by a malicious rootfs containing
exploits such as a spyware or keylogger and still pass the verified boot
process. The exploit is based on the fact that a dedicated adversary can
replace the rootfs and the corresponding verification information in the
bootloader. We experimentally demonstrate an attack using both the base and
developer version of Chromium OS in which the adversary installs a spyware in
the target system to send cached user data to the attacker machine in plain
text which are otherwise encrypted, and thus inaccessible. We also demonstrate
techniques to mitigate this vulnerability.
"
103,Windows And Linux Operating Systems From A Security Perspective,"  Operating systems are vital system software that, without them, humans would
not be able to manage and use computer systems. In essence, an operating system
is a collection of software programs whose role is to manage computer resources
and provide an interface for client applications to interact with the different
computer hardware. Most of the commercial operating systems available today on
the market have buggy code and they exhibit security flaws and vulnerabilities.
In effect, building a trusted operating system that can mostly resist attacks
and provide a secure computing environment to protect the important assets of a
computer is the goal of every operating system manufacturer. This paper deeply
investigates the various security features of the two most widespread and
successful operating systems, Microsoft Windows and Linux. The different
security features, designs, and components of the two systems are to be covered
elaborately, pin-pointing the key similarities and differences between them. In
due course, a head-to-head comparison is to be drawn for each security aspect,
exposing the advantage of one system over the other.
"
104,"Schedulability Test for Soft Real-Time Systems under Multiprocessor
  Environment by using an Earliest Deadline First Scheduling Algorithm","  This paper deals with the study of Earliest Deadline First (EDF) which is an
optimal scheduling algorithm for uniprocessor real time systems use for
scheduling the periodic task in soft real-time multiprocessor systems. In hard
real-time systems, a significant disparity exists EDF-based schemes and RMA
scheduling (which is the only known way of optimally scheduling recurrent
real-time tasks on multiprocessors): on M processors, all known EDF variants
have utilization-based schedulability bounds of approximately M/2, while RMA
algorithms can fully utilize all processors. This is unfortunate because EDF
based algorithms entail lower scheduling and task migration overheads. In work
on hard real-time systems, it has been shown that this disparity in
Schedulability can be lessened by placing caps on per task utilizations. Our
main contribution is a new EDF based scheme that ensures bounded deadline
tardiness. In this scheme, per-task utilizations must be focused,but overall
utilization need not be stricted. Our scheme should enable a wide range of soft
real-time applications to be scheduled with no constraints on total
utilization. Also propose techniques and heuristics that can be used to reduce
tardiness as well as increase the efficiency of task.
"
105,Age Based User Interface in Mobile Operating System,"  This paper proposes the creation of different interfaces in the mobile
operating system for different age groups. The different age groups identified
are kids, elderly people and all others. The motive behind creating different
interfaces is to make the smartphones of today's world usable to all age
groups.
"
106,"Proposed Challenges And Areas of Concern in Operating System Research
  and Development","  Computers are a very important part of our lives and the major reason why
they have been such a success is because of the excellent graphical operating
systems that run on these powerful machines. As the computer hardware is
becoming more and more powerful, it is also vital to keep the software updated
in order to utilize the hardware of the system efficiently and make it faster
and smarter. This paper highlights some core issues that if dealt with in the
operating system level would make use of the full potential of the computer
hardware and provide an excellent user experience.
"
107,Energy-Aware Task Partitioning on Heterogeneous Multiprocessor Platforms,"  Efficient task partitioning plays a crucial role in achieving high
performance at multiprocessor plat forms. This paper addresses the problem of
energy-aware static partitioning of periodic real-time tasks on heterogeneous
multiprocessor platforms. A Particle Swarm Optimization variant based on
Min-min technique for task partitioning is proposed. The proposed approach aims
to minimize the overall energy consumption, meanwhile avoid deadline
violations. An energy-aware cost function is proposed to be considered in the
proposed approach. Extensive simulations and comparisons are conducted in order
to validate the effectiveness of the proposed technique. The achieved results
demonstrate that the proposed partitioning scheme significantly surpasses
previous approaches in terms of both number of iterations and energy savings.
"
108,"The Necessity for Hardware QoS Support for Server Consolidation and
  Cloud Computing","  Chip multiprocessors (CMPs) are ubiquitous in most of today's computing
fields. Although they provide noticeable benefits in terms of performance, cost
and power efficiency, they also introduce some new issues. In this paper we
analyze how the interference from Virtual Private Servers running in other
cores is a significant component of performance unpredictability and can
threaten the attainment of cloud computing. Even if virtualization is used, the
sharing of the on-chip section of the memory hierarchy by different cores makes
performance isolation strongly dependent on what is running elsewhere in the
system. We will show in three actual computing systems, based on Sun UltraSparc
T1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art
virtualization techniques are unable to guarantee performance isolation in a
representative workload such as SPECweb2005. In an especially conceived near
worst-case scenario, it is possible to reduce the performance achieved by a
Solaris Zones consolidated server for this suite of benchmarks in a Sun Fire
T1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by
a Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%. For
all systems under study, off-chip bandwidth is shown to be the most critical
resource.
"
109,A Secure Dynamic Job Scheduling on Smart Grid using RSA Algorithm,"  Grid computing is a computation methodology using group of clusters connected
over high-speed networks that involves coordinating and sharing computational
power, data storage and network resources. Integrating a set of clusters of
workstations into one large computing environment can improve the availability
of computing power. The goal of scheduling is to achieve highest possible
system throughput and to match the application need with the available
computing resources. A secure scheduling model is presented, that performs job
grouping activity at runtime. In a Grid environment, security is necessary
because grid is a dynamic environment and participates are independent bodies
with different policies, objectives and requirements. Authentication should be
verified for Grid resource owners as well as resource requesters before they
are allowed to join in scheduling activities. In order to achieve secure
resource and job scheduling including minimum processing time and maximum
resource utilization, A Secure Resource by using RSA algorithm on Networking
and Job Scheduling model with Job Grouping strategy(JGS) in Grid Computing has
been proposed. The result shows significant improvement in the processing time
of jobs and resource utilization as compared to dynamic job grouping (DJG)
based scheduling on smart grids (SG).
"
110,Performance Evaluation of Flash File Systems,"  Today, flash memory are strongly used in the embedded system domain. NAND
flash memories are the building block of main secondary storage systems. Such
memories present many benefits in terms of data density, I/O performance, shock
resistance and power consumption. Nevertheless, flash does not come without
constraints: the write / erase granularity asymmetry and the limited lifetime
bring the need for specific management. This can be done through the operating
system using dedicated Flash File Systems (FFSs). In this document, we present
general concepts about FFSs, and implementations example that are JFFS2, YAFFS2
and UBIFS, the most commonly used flash file systems. Then we give performance
evaluation results for these FFSs.
"
111,On Benchmarking Embedded Linux Flash File Systems,"  Due to its attractive characteristics in terms of performance, weight and
power consumption, NAND flash memory became the main non volatile memory (NVM)
in embedded systems. Those NVMs also present some specific
characteristics/constraints: good but asymmetric I/O performance, limited
lifetime, write/erase granularity asymmetry, etc. Those peculiarities are
either managed in hardware for flash disks (SSDs, SD cards, USB sticks, etc.)
or in software for raw embedded flash chips. When managed in software, flash
algorithms and structures are implemented in a specific flash file system
(FFS). In this paper, we present a performance study of the most widely used
FFSs in embedded Linux: JFFS2, UBIFS,and YAFFS. We show some very particular
behaviors and large performance disparities for tested FFS operations such as
mounting, copying, and searching file trees, compression, etc.
"
112,Building Resilient Cloud Over Unreliable Commodity Infrastructure,"  Cloud Computing has emerged as a successful computing paradigm for
efficiently utilizing managed compute infrastructure such as high speed
rack-mounted servers, connected with high speed networking, and reliable
storage. Usually such infrastructure is dedicated, physically secured and has
reliable power and networking infrastructure. However, much of our idle compute
capacity is present in unmanaged infrastructure like idle desktops, lab
machines, physically distant server machines, and laptops. We present a scheme
to utilize this idle compute capacity on a best-effort basis and provide high
availability even in face of failure of individual components or facilities.
  We run virtual machines on the commodity infrastructure and present a cloud
interface to our end users. The primary challenge is to maintain availability
in the presence of node failures, network failures, and power failures. We run
multiple copies of a Virtual Machine (VM) redundantly on geographically
dispersed physical machines to achieve availability. If one of the running
copies of a VM fails, we seamlessly switchover to another running copy. We use
Virtual Machine Record/Replay capability to implement this redundancy and
switchover. In current progress, we have implemented VM Record/Replay for
uniprocessor machines over Linux/KVM and are currently working on VM
Record/Replay on shared-memory multiprocessor machines. We report initial
experimental results based on our implementation.
"
113,"A Hardware Time Manager Implementation for the Xenomai Real-Time Kernel
  of Embedded Linux","  Nowadays, the use of embedded operating systems in different embedded
projects is subject to a tremendous growth. Embedded Linux is becoming one of
those most popular EOSs due to its modularity, efficiency, reliability, and
cost. One way to make it hard real-time is to include a real-time kernel like
Xenomai. One of the key characteristics of a Real-Time Operating System (RTOS)
is its ability to meet execution time deadlines deterministically. So, the more
precise and flexible the time management can be, the better it can handle
efficiently the determinism for different embedded applications. RTOS time
precision is characterized by a specific periodic interrupt service controlled
by a software time manager. The smaller the period of the interrupt, the better
the precision of the RTOS, the more it overloads the CPU, and though reduces
the overall efficiency of the RTOS. In this paper, we propose to drastically
reduce these overheads by migrating the time management service of Xenomai into
a configurable hardware component to relieve the CPU. The hardware component is
implemented in a Field Programmable Gate Array coupled to the CPU. This work
was achieved in a Master degree project where students could apprehend many
fields of embedded systems: RTOS programming, hardware design, performance
evaluation, etc.
"
114,Security Issues in the Android Cross-Layer Architecture,"  The security of Android has been recently challenged by the discovery of a
number of vulnerabilities involving different layers of the Android stack. We
argue that such vulnerabilities are largely related to the interplay among
layers composing the Android stack. Thus, we also argue that such interplay has
been underestimated from a security point-of-view and a systematic analysis of
the Android interplay has not been carried out yet. To this aim, in this paper
we provide a simple model of the Android cross-layer interactions based on the
concept of flow, as a basis for analyzing the Android interplay. In particular,
our model allows us to reason about the security implications associated with
the cross-layer interactions in Android, including a recently discovered
vulnerability that allows a malicious application to make Android devices
totally unresponsive. We used the proposed model to carry out an empirical
assessment of some flows within the Android cross-layered architecture. Our
experiments indicate that little control is exercised by the Android Security
Framework (ASF) over cross-layer interactions in Android. In particular, we
observed that the ASF lacks in discriminating the originator of a flow and
sensitive security issues arise between the Android stack and the Linux kernel,
thereby indicating that the attack surface of the Android platform is wider
than expected.
"
115,Classification Of Heterogeneous Operating System,"  Operating system is a bridge between system and user. An operating system
(OS) is a software program that manages the hardware and software resources of
a computer. The OS performs basic tasks, such as controlling and allocating
memory, prioritizing the processing of instructions, controlling input and
output devices, facilitating networking, and managing files. It is difficult to
present a complete as well as deep account of operating systems developed till
date. So, this paper tries to overview only a subset of the available operating
systems and its different categories. OS are being developed by a large number
of academic and commercial organizations for the last several decades. This
paper, therefore, concentrates on the different categories of OS with special
emphasis to those that had deep impact on the evolution process. The aim of
this paper is to provide a brief timely commentary on the different categories
important operating systems available today.
"
116,"JooFlux: Hijacking Java 7 InvokeDynamic To Support Live Code
  Modifications","  Changing functional and non-functional software implementation at runtime is
useful and even sometimes critical both in development and production
environments. JooFlux is a JVM agent that allows both the dynamic replacement
of method implementations and the application of aspect advices. It works by
doing bytecode transformation to take advantage of the new invokedynamic
instruction added in Java SE 7 to help implementing dynamic languages for the
JVM. JooFlux can be managed using a JMX agent so as to operate dynamic
modifications at runtime, without resorting to a dedicated domain-specific
language. We compared JooFlux with existing AOP platforms and dynamic
languages. Results demonstrate that JooFlux performances are close to the Java
ones --- with most of the time a marginal overhead, and sometimes a gain ---
where AOP platforms and dynamic languages present significant overheads. This
paves the way for interesting future evolutions and applications of JooFlux.
"
117,"Online Adaptive Fault Tolerant based Feedback Control Scheduling
  Algorithm for Multiprocessor Embedded Systems","  Since some years ago, use of Feedback Control Scheduling Algorithm (FCSA) in
the control scheduling co-design of multiprocessor embedded system has
increased. FCSA provides Quality of Service (QoS) in terms of overall system
performance and resource allocation in open and unpredictable environment. FCSA
uses quality control feedback loop to keep CPU utilization under desired
unitization bound by avoiding overloading and deadline miss ratio. Integrated
Fault tolerance (FT) based FCSA design methodology guarantees that the Safety
Critical (SC) tasks will meet their deadlines in the presence of faults.
However, current FCSA design model does not provide the optimal solution with
dynamic load fluctuation. This paper presented a novel methodology of designing
an online adaptive fault tolerant based feedback control algorithm for
multiprocessor embedded systems. This procedure is important for control
scheduling co-design for multiprocessor embedded systems.
"
118,Disk Scheduling: Selection of Algorithm,"  The objective of this paper is to take some aspects of disk scheduling and
scheduling algorithms. The disk scheduling is discussed with a sneak peak in
general and selection of algorithm in particular.
"
119,An Insight View of Kernel Visual Debugger in System Boot up,"  For many years, developers could not figure out the mystery of OS kernels.
The main source of this mystery is the interaction between operating systems
and hardware while system's boot up and kernel initialization. In addition,
many operating system kernels differ in their behavior toward many situations.
For instance, kernels act differently in racing conditions, kernel
initialization and process scheduling. For such operations, kernel debuggers
were designed to help in tracing kernel behavior and solving many kernel bugs.
The importance of kernel debuggers is not limited to kernel code tracing but
also, they can be used in verification and performance comparisons. However,
developers had to be aware of debugger commands thus introducing some
difficulties to non-expert programmers. Later, several visual kernel debuggers
were presented to make it easier for programmers to trace their kernel code and
analyze kernel behavior. Nowadays, several kernel debuggers exist for solving
this mystery but only very few support line-by-line debugging at run-time. In
this paper, a generic approach for operating system source code debugging in
graphical mode with line-by-line tracing support is proposed. In the context of
this approach, system boot up and evaluation of two operating system schedulers
from several points of views will be discussed.
"
120,"Multicore Dynamic Kernel Modules Attachment Technique for Kernel
  Performance Enhancement","  Traditional monolithic kernels dominated kernel structures for long time
along with small sized kernels,few hardware companies and limited kernel
functionalities. Monolithic kernel structure was not applicable when the number
of hardware companies increased and kernel services consumed by different users
for many purposes. One of the biggest disadvantages of the monolithic kernels
is the inflexibility due to the need to include all the available modules in
kernel compilation causing high time consuming. Lately, new kernel structure
was introduced through multicore operating systems. Unfortunately, many
multicore operating systems such as barrelfish and FOS are experimental. This
paper aims to simulate the performance of multicore hybrid kernels through
dynamic kernel module customized attachment/ deattachment for multicore
machines. In addition, this paper proposes a new technique for loading dynamic
kernel modules based on the user needs and machine capabilities.
"
121,Automatic Verification of Message-Based Device Drivers,"  We develop a practical solution to the problem of automatic verification of
the interface between device drivers and the OS. Our solution relies on a
combination of improved driver architecture and verification tools. It supports
drivers written in C and can be implemented in any existing OS, which sets it
apart from previous proposals for verification-friendly drivers. Our
Linux-based evaluation shows that this methodology amplifies the power of
existing verification tools in detecting driver bugs, making it possible to
verify properties beyond the reach of traditional techniques.
"
122,A Formal Model of a Virtual Filesystem Switch,"  This work presents a formal model that is part of our effort to construct a
verified file system for Flash memory. To modularize the verification we factor
out generic aspects into a common component that is inspired by the Linux
Virtual Filesystem Switch (VFS) and provides POSIX compatible operations. It
relies on an abstract specification of its internal interface to concrete file
system implementations (AFS). We proved that preconditions of AFS are respected
and that the state is kept consistent. The model can be made executable and
mounted into the Linux directory tree using FUSE.
"
123,"On the Use of Underspecified Data-Type Semantics for Type Safety in
  Low-Level Code","  In recent projects on operating-system verification, C and C++ data types are
often formalized using a semantics that does not fully specify the precise byte
encoding of objects. It is well-known that such an underspecified data-type
semantics can be used to detect certain kinds of type errors. In general,
however, underspecified data-type semantics are unsound: they assign
well-defined meaning to programs that have undefined behavior according to the
C and C++ language standards.
  A precise characterization of the type-correctness properties that can be
enforced with underspecified data-type semantics is still missing. In this
paper, we identify strengths and weaknesses of underspecified data-type
semantics for ensuring type safety of low-level systems code. We prove
sufficient conditions to detect certain classes of type errors and, finally,
identify a trade-off between the complexity of underspecified data-type
semantics and their type-checking capabilities.
"
124,"Chiefly Symmetric: Results on the Scalability of Probabilistic Model
  Checking for Operating-System Code","  Reliability in terms of functional properties from the safety-liveness
spectrum is an indispensable requirement of low-level operating-system (OS)
code. However, with evermore complex and thus less predictable hardware,
quantitative and probabilistic guarantees become more and more important.
Probabilistic model checking is one technique to automatically obtain these
guarantees. First experiences with the automated quantitative analysis of
low-level operating-system code confirm the expectation that the naive
probabilistic model checking approach rapidly reaches its limits when
increasing the numbers of processes. This paper reports on our work-in-progress
to tackle the state explosion problem for low-level OS-code caused by the
exponential blow-up of the model size when the number of processes grows. We
studied the symmetry reduction approach and carried out our experiments with a
simple test-and-test-and-set lock case study as a representative example for a
wide range of protocols with natural inter-process dependencies and long-run
properties. We quickly see a state-space explosion for scenarios where
inter-process dependencies are insignificant. However, once inter-process
dependencies dominate the picture models with hundred and more processes can be
constructed and analysed.
"
125,A Generic Checkpoint-Restart Mechanism for Virtual Machines,"  It is common today to deploy complex software inside a virtual machine (VM).
Snapshots provide rapid deployment, migration between hosts, dependability
(fault tolerance), and security (insulating a guest VM from the host). Yet, for
each virtual machine, the code for snapshots is laboriously developed on a
per-VM basis. This work demonstrates a generic checkpoint-restart mechanism for
virtual machines. The mechanism is based on a plugin on top of an unmodified
user-space checkpoint-restart package, DMTCP. Checkpoint-restart is
demonstrated for three virtual machines: Lguest, user-space QEMU, and KVM/QEMU.
The plugins for Lguest and KVM/QEMU require just 200 lines of code. The Lguest
kernel driver API is augmented by 40 lines of code. DMTCP checkpoints
user-space QEMU without any new code. KVM/QEMU, user-space QEMU, and DMTCP need
no modification. The design benefits from other DMTCP features and plugins.
Experiments demonstrate checkpoint and restart in 0.2 seconds using forked
checkpointing, mmap-based fast-restart, and incremental Btrfs-based snapshots.
"
126,"Feasibility Tests for Recurrent Real-Time Tasks in the Sporadic DAG
  Model","  A model has been proposed in [Baruah et al., in Proceedings of the IEEE
Real-Time Systems Symposium 2012] for representing recurrent
precedence-constrained tasks to be executed on multiprocessor platforms, where
each recurrent task is modeled by a directed acyclic graph (DAG), a period, and
a relative deadline. Each vertex of the DAG represents a sequential job, while
the edges of the DAG represent precedence constraints between these jobs. All
the jobs of the DAG are released simultaneously and have to be completed within
some specified relative deadline. The task may release jobs in this manner an
unbounded number of times, with successive releases occurring at least the
specified period apart. The feasibility problem is to determine whether such a
recurrent task can be scheduled to always meet all deadlines on a specified
number of dedicated processors.
  The case of a single task has been considered in [Baruah et al., 2012]. The
main contribution of this paper is to consider the case of multiple tasks. We
show that EDF has a speedup bound of 2-1/m, where m is the number of
processors. Moreover, we present polynomial and pseudopolynomial schedulability
tests, of differing effectiveness, for determining whether a set of sporadic
DAG tasks can be scheduled by EDF to meet all deadlines on a specified number
of processors.
"
127,Adaptive Scheduling in Real-Time Systems Through Period Adjustment,"  Real time system technology traditionally developed for safety critical
systems, has now been extended to support multimedia systems and virtual
reality. A large number of real-time application, related to multimedia and
adaptive control system, require more flexibility than classical real-time
theory usually permits. This paper proposes an efficient adaptive scheduling
framework in real-time systems based on period adjustment. Under this model
periodic task can change their execution rates based on their importance value
to keep the system underloaded. We propose Period_Adjust algorithm, which
consider the tasks whose periods are bounded as well as the tasks whose periods
are not bounded.
"
128,LNOS - Live Network Operating System,"  Operating Systems exists since existence of computers, and have been evolving
continuously from time to time. In this paper we have reviewed a relatively new
or unexplored topic of Live OS. From networking perspective, Live OS is used
for establishing Clusters, Firewalls and as Network security assessment tool
etc. Our proposed concept is that a Live OS can be established or configured
for an organizations specific network requirements with respect to their
servers. An important server failure due to hardware or software could take
time for remedy of the problem, so for that situation a preconfigured server in
the form of Live OS on CD/DVD/USB can be used as an immediate solution. In a
network of ten nodes, we stopped the server machine and with necessary
adjustments, Live OS replaced the server in less than five minutes. Live OS in
a network environment is a quick replacement of the services that are failed
due to server failure (hardware or software). It is a cost effective solution
for low budget networks. The life of Live OS starts when we boot it from
CD/DVD/USB and remains in action for that session. As soon as the machine is
rebooted, any work done for that session is gone, (in case we do not store any
information on permanent storage media). Live CD/DVD/USB is normally used on
systems where we do not have Operating Systems installed. A Live OS can also be
used on systems where we already have an installed OS. On the basis of
functionality a Live OS can be used for many purposes and has some typical
advantages that are not available on other operating systems. Vendors are
releasing different distributions of Live OS and is becoming their sole
identity in a particular domain like Networks, Security, Education or
Entertainment etc. There can be many aspects of Live OS, but Linux based Live
OS and their use in the field of networks is the main focus of this paper.
"
129,Dynamic Transparent General Purpose Process Migration For Linux,"  Process migration refers to the act of transferring a process in the middle
of its execution from one machine to another in a network. In this paper, we
proposed a process migration framework for Linux OS. It is a multilayer
architecture to confine every functionality independent section of the system
in separate layer. This architecture is capable of supporting diverse
applications due to generic user space interface and dynamic structure that can
be modified according to demands.
"
130,"Schedulability Analysis of Distributed Real-Time Applications under
  Dependence and Several Latency Constraints","  This paper focuses on the analysis of real-time non preemptive multiprocessor
scheduling with precedence and several latency constraints. It aims to specify
a schedulability condition which enables a designer to check a priori -without
executing or simulating- if its scheduling of tasks will hold the precedences
between tasks as well as several latency constraints imposed on determined
pairs of tasks. It is shown that the required analysis is closely linked to the
topological structure of the application graph. More precisely, it depends on
the configuration of tasks paths subject to latency constraints. As a result of
the study, a sufficient schedulability condition is introduced for precedences
and latency constraints in the hardest configuration in term of complexity with
an optimal number of processors in term of applications parallelism. In
addition, the proposed conditions provides a practical lower bounds for general
cases. Performances results and comparisons with an optimal approach
demonstrate the effectiveness of the proposed approach.
"
131,"RevDedup: A Reverse Deduplication Storage System Optimized for Reads to
  Latest Backups","  Scaling up the backup storage for an ever-increasing volume of virtual
machine (VM) images is a critical issue in virtualization environments. While
deduplication is known to effectively eliminate duplicates for VM image
storage, it also introduces fragmentation that will degrade read performance.
We propose RevDedup, a deduplication system that optimizes reads to latest VM
image backups using an idea called reverse deduplication. In contrast with
conventional deduplication that removes duplicates from new data, RevDedup
removes duplicates from old data, thereby shifting fragmentation to old data
while keeping the layout of new data as sequential as possible. We evaluate our
RevDedup prototype using microbenchmark and real-world workloads. For a 12-week
span of real-world VM images from 160 users, RevDedup achieves high
deduplication efficiency with around 97% of saving, and high backup and read
throughput on the order of 1GB/s. RevDedup also incurs small metadata overhead
in backup/read operations.
"
132,"Parametric Schedulability Analysis of Fixed Priority Real-Time
  Distributed Systems","  Parametric analysis is a powerful tool for designing modern embedded systems,
because it permits to explore the space of design parameters, and to check the
robustness of the system with respect to variations of some uncontrollable
variable. In this paper, we address the problem of parametric schedulability
analysis of distributed real-time systems scheduled by fixed priority. In
particular, we propose two different approaches to parametric analysis: the
first one is a novel technique based on classical schedulability analysis,
whereas the second approach is based on model checking of Parametric Timed
Automata (PTA).
  The proposed analytic method extends existing sensitivity analysis for single
processors to the case of a distributed system, supporting preemptive and
non-preemptive scheduling, jitters and unconstrained deadlines. Parametric
Timed Automata are used to model all possible behaviours of a distributed
system, and therefore it is a necessary and sufficient analysis. Both
techniques have been implemented in two software tools, and they have been
compared with classical holistic analysis on two meaningful test cases. The
results show that the analytic method provides results similar to classical
holistic analysis in a very efficient way, whereas the PTA approach is slower
but covers the entire space of solutions.
"
133,"Energy Minimization for Parallel Real-Time Systems with Malleable Jobs
  and Homogeneous Frequencies","  In this work, we investigate the potential utility of parallelization for
meeting real-time constraints and minimizing energy. We consider malleable Gang
scheduling of implicit-deadline sporadic tasks upon multiprocessors. We first
show the non-necessity of dynamic voltage/frequency regarding optimality of our
scheduling problem. We adapt the canonical schedule for DVFS multiprocessor
platforms and propose a polynomial-time optimal processor/frequency-selection
algorithm. We evaluate the performance of our algorithm via simulations using
parameters obtained from a hardware testbed implementation. Our algorithm has
up to a 60 watt decrease in power consumption over the optimal non-parallel
approach.
"
134,Capturing Information Flows inside Android and Qemu Environments,"  The smartphone market has grown so wide that it assumed a strategic
relevance. Today the most common smartphone OSs are Google's Android and
Apple's iOS. The former is particularly interesting due to its open source
nature, that allows everyone to deeply inspect every aspect of the OS. Android
source code is also bundled with an hardware emulator, based on the open source
software Qemu, that allows the user to run the Android OS without the need of a
physical device. We first present a procedure to extract information flows from
a generic system. We then focus on Android and Qemu architectures and their
logging infrastructures. Finally, we detail what happens inside an Android
device in a particular scenario: the system boot.
"
135,LFTL: A multi-threaded FTL for a Parallel IO Flash Card under Linux,"  New PCI-e flash cards and SSDs supporting over 100,000 IOPs are now
available, with several usecases in the design of a high performance storage
system. By using an array of flash chips, arranged in multiple banks, large
capacities are achieved. Such multi-banked architecture allow parallel read,
write and erase operations. In a raw PCI-e flash card, such parallelism is
directly available to the software layer. In addition, the devices have
restrictions such as, pages within a block can only be written sequentially.
The devices also have larger minimum write sizes (greater than 4KB). Current
flash translation layers (FTLs) in Linux are not well suited for such devices
due to the high device speeds, architectural restrictions as well as other
factors such as high lock contention. We present a FTL for Linux that takes
into account the hardware restrictions, that also exploits the parallelism to
achieve high speeds. We also consider leveraging the parallelism for garbage
collection by scheduling the garbage collection activities on idle banks. We
propose and evaluate an adaptive method to vary the amount of garbage
collection according to the current I/O load on the device.
"
136,"Towards Python-based Domain-specific Languages for Self-reconfigurable
  Modular Robotics Research","  This paper explores the role of operating system and high-level languages in
the development of software and domain-specific languages (DSLs) for
self-reconfigurable robotics. We review some of the current trends in
self-reconfigurable robotics and describe the development of a software system
for ATRON II which utilizes Linux and Python to significantly improve software
abstraction and portability while providing some basic features which could
prove useful when using Python, either stand-alone or via a DSL, on a
self-reconfigurable robot system. These features include transparent socket
communication, module identification, easy software transfer and reliable
module-to-module communication. The end result is a software platform for
modular robots that where appropriate builds on existing work in operating
systems, virtual machines, middleware and high-level languages.
"
137,Survey of Server Virtualization,"  Virtualization is a term that refers to the abstraction of computer
resources. The purpose of virtual computing environment is to improve resource
utilization by providing a unified integrated operating platform for users and
applications based on aggregation of heterogeneous and autonomous resources.
More recently, virtualization at all levels (system, storage, and network)
became important again as a way to improve system security, reliability and
availability, reduce costs, and provide greater flexibility. Virtualization has
rapidly become a go-to technology for increasing efficiency in the data center.
With virtualization technologies providing tremendous flexibility, even
disparate architectures may be deployed on a single machine without
interference This paper explains the basics of server virtualization and
addresses pros and cons of virtualization
"
138,Making I/O Virtualization Easy with Device Files,"  Personal computers have diverse and fast-evolving I/O devices, making their
I/O virtualization different from that of servers and data centers. In this
paper, we present our recent endeavors in simplifying I/O virtualization for
personal computers. Our key insight is that many operating systems, including
Unix-like ones, abstract I/O devices as device files. There is a small and
stable set of operations on device files, therefore, I/O virtualization at the
device file boundary requires a one-time effort to support various I/O devices.
  We present devirtualization, our design of I/O virtualization at the device
file boundary and its implementation for Linux/x86 systems. We are able to
virtualize various GPUs, input devices, cameras, and audio devices with fewer
than 4900 LoC, of which only about 300 are specific to I/O device classes. Our
measurements show that devirtualized devices achieve interactive performance
indistinguishable from native ones by human users, even when running 3D HD
games.
"
139,Paging with dynamic memory capacity,"  We study a generalization of the classic paging problem that allows the
amount of available memory to vary over time - capturing a fundamental property
of many modern computing realities, from cloud computing to multi-core and
energy-optimized processors. It turns out that good performance in the
""classic"" case provides no performance guarantees when memory capacity
fluctuates: roughly speaking, moving from static to dynamic capacity can mean
the difference between optimality within a factor 2 in space and time, and
suboptimality by an arbitrarily large factor. More precisely, adopting the
competitive analysis framework, we show that some online paging algorithms,
despite having an optimal (h,k)-competitive ratio when capacity remains
constant, are not (3,k)-competitive for any arbitrarily large k in the presence
of minimal capacity fluctuations. In this light it is surprising that several
classic paging algorithms perform remarkably well even if memory capacity
changes adversarially - even without taking those changes into explicit
account! In particular, we prove that LFD still achieves the minimum number of
faults, and that several classic online algorithms such as LRU have a ""dynamic""
(h,k)-competitive ratio that is the best one can achieve without knowledge of
future page requests, even if one had perfect knowledge of future capacity
fluctuations (an exact characterization of this ratio shows it is almost,
albeit not quite, equal to the ""classic"" ratio k/(k-h+1)). In other words, with
careful management, knowing/predicting future memory resources appears far less
crucial to performance than knowing/predicting future data accesses.
"
140,Invasive Computing - Common Terms and Granularity of Invasion,"  Future MPSoCs with 1000 or more processor cores on a chip require new means
for resource-aware programming in order to deal with increasing imperfections
such as process variation, fault rates, aging effects, and power as well as
thermal problems. On the other hand, predictable program executions are
threatened if not impossible if no proper means of resource isolation and
exclusive use may be established on demand. In view of these problems and
menaces, invasive computing enables an application programmer to claim for
processing resources and spread computations to claimed processors dynamically
at certain points of the program execution.
  Such decisions may be depending on the degree of application parallelism and
the state of the underlying resources such as utilization, load, and
temperature, but also with the goal to provide predictable program execution on
MPSoCs by claiming processing resources exclusively as the default and thus
eliminating interferences and creating the necessary isolation between multiple
concurrently running applications. For achieving this goal, invasive computing
introduces new programming constructs for resource-aware programming that
meanwhile, for testing purpose, have been embedded into the parallel computing
language X10 as developed by IBM using a library-based approach.
  This paper presents major ideas and common terms of invasive computing as
investigated by the DFG Transregional Collaborative Research Centre TR89.
Moreoever, a reflection is given on the granularity of resources that may be
requested by invasive programs.
"
141,Network Control Systems RTAI framework A Review,"  With the advancement in the automation industry, to perform complex remote
operations is required. Advancements in the networking technology has led to
the development of different architectures to implement control from a large
distance. In various control applications of the modern industry, the agents,
such as sensors, actuators, and controllers are basically geographically
distributed. For efficient working of a control application, all of the agents
have to exchange information through a communication media. At present, an
increasing number of distributed control systems are based on platforms made up
of conventional PCs running open-source real-time operating systems. Often,
these systems needed to have networked devices supporting synchronized
operations with respect to each node. A framework is studied that relies on
standard software and protocol as RTAI, EtherCAT, RTnet and IEEE 1588. RTAI and
its various protocols are studied in network control systems environment.
"
142,"EURETILE 2010-2012 summary: first three years of activity of the
  European Reference Tiled Experiment","  This is the summary of first three years of activity of the EURETILE FP7
project 247846. EURETILE investigates and implements brain-inspired and
fault-tolerant foundational innovations to the system architecture of massively
parallel tiled computer architectures and the corresponding programming
paradigm. The execution targets are a many-tile HW platform, and a many-tile
simulator. A set of SW process - HW tile mapping candidates is generated by the
holistic SW tool-chain using a combination of analytic and bio-inspired
methods. The Hardware dependent Software is then generated, providing OS
services with maximum efficiency/minimal overhead. The many-tile simulator
collects profiling data, closing the loop of the SW tool chain. Fine-grain
parallelism inside processes is exploited by optimized intra-tile compilation
techniques, but the project focus is above the level of the elementary tile.
The elementary HW tile is a multi-processor, which includes a fault tolerant
Distributed Network Processor (for inter-tile communication) and ASIP
accelerators. Furthermore, EURETILE investigates and implements the innovations
for equipping the elementary HW tile with high-bandwidth, low-latency
brain-like inter-tile communication emulating 3 levels of connection hierarchy,
namely neural columns, cortical areas and cortex, and develops a dedicated
cortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking
Neural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages
on the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES
Integrated Project (2006-2009).
"
143,"Practical Fine-grained Privilege Separation in Multithreaded
  Applications","  An inherent security limitation with the classic multithreaded programming
model is that all the threads share the same address space and, therefore, are
implicitly assumed to be mutually trusted. This assumption, however, does not
take into consideration of many modern multithreaded applications that involve
multiple principals which do not fully trust each other. It remains challenging
to retrofit the classic multithreaded programming model so that the security
and privilege separation in multi-principal applications can be resolved.
  This paper proposes ARBITER, a run-time system and a set of security
primitives, aimed at fine-grained and data-centric privilege separation in
multithreaded applications. While enforcing effective isolation among
principals, ARBITER still allows flexible sharing and communication between
threads so that the multithreaded programming paradigm can be preserved. To
realize controlled sharing in a fine-grained manner, we created a novel
abstraction named ARBITER Secure Memory Segment (ASMS) and corresponding OS
support. Programmers express security policies by labeling data and principals
via ARBITER's API following a unified model. We ported a widely-used, in-memory
database application (memcached) to ARBITER system, changing only around 100
LOC. Experiments indicate that only an average runtime overhead of 5.6% is
induced to this security enhanced version of application.
"
144,Augmenting Operating Systems With the GPU,"  The most popular heterogeneous many-core platform, the CPU+GPU combination,
has received relatively little attention in operating systems research. This
platform is already widely deployed: GPUs can be found, in some form, in most
desktop and laptop PCs. Used for more than just graphics processing, modern
GPUs have proved themselves versatile enough to be adapted to other
applications as well. Though GPUs have strengths that can be exploited in
systems software, this remains a largely untapped resource. We argue that
augmenting the OS kernel with GPU computing power opens the door to a number of
new opportunities. GPUs can be used to speed up some kernel functions, make
other scale better, and make it feasible to bring some computation-heavy
functionality into the kernel. We present our framework for using the GPU as a
co-processor from an OS kernel, and demonstrate a prototype in Linux.
"
145,"On the periodic behavior of real-time schedulers on identical
  multiprocessor platforms","  This paper is proposing a general periodicity result concerning any
deterministic and memoryless scheduling algorithm (including
non-work-conserving algorithms), for any context, on identical multiprocessor
platforms. By context we mean the hardware architecture (uniprocessor,
multicore), as well as task constraints like critical sections, precedence
constraints, self-suspension, etc. Since the result is based only on the
releases and deadlines, it is independent from any other parameter. Note that
we do not claim that the given interval is minimal, but it is an upper bound
for any cycle of any feasible schedule provided by any deterministic and
memoryless scheduler.
"
146,V-BOINC: The Virtualization of BOINC,"  The Berkeley Open Infrastructure for Network Computing (BOINC) is an open
source client-server middleware system created to allow projects with large
computational requirements, usually set in the scientific domain, to utilize a
technically unlimited number of volunteer machines distributed over large
physical distances. However various problems exist deploying applications over
these heterogeneous machines using BOINC: applications must be ported to each
machine architecture type, the project server must be trusted to supply
authentic applications, applications that do not regularly checkpoint may lose
execution progress upon volunteer machine termination and applications that
have dependencies may find it difficult to run under BOINC.
  To solve such problems we introduce virtual BOINC, or V-BOINC, where virtual
machines are used to run computations on volunteer machines. Application
developers can then compile their applications on a single architecture,
checkpointing issues are solved through virtualization API's and many security
concerns are addressed via the virtual machine's sandbox environment. In this
paper we focus on outlining a unique approach on how virtualization can be
introduced into BOINC and demonstrate that V-BOINC offers acceptable
computational performance when compared to regular BOINC. Finally we show that
applications with dependencies can easily run under V-BOINC in turn increasing
the computational potential volunteer computing offers to the general public
and project developers.
"
147,"Partitioned scheduling of multimode multiprocessor real-time systems
  with temporal isolation","  We consider the partitioned scheduling problem of multimode real-time systems
upon identical multiprocessor platforms. During the execution of a multimode
system, the system can change from one mode to another such that the current
task set is replaced with a new one. In this paper, we consider a synchronous
transition protocol in order to take into account mode-independent tasks, i.e.,
tasks of which the execution pattern must not be jeopardized by the mode
changes. We propose two methods for handling mode changes in partitioned
scheduling. The first method is offline/optimal and computes a static
allocation of tasks schedulable and respecting both tasks and transition
deadlines (if any). The second approach is subject to a sufficient condition in
order to ensure online First Fit based allocation to satisfy the timing
constraints.
"
148,A Comparative Study of CPU Scheduling Algorithms,"  Developing CPU scheduling algorithms and understanding their impact in
practice can be difficult and time consuming due to the need to modify and test
operating system kernel code and measure the resulting performance on a
consistent workload of real applications. As processor is the important
resource, CPU scheduling becomes very important in accomplishing the operating
system (OS) design goals. The intention should be allowed as many as possible
running processes at all time in order to make best use of CPU. This paper
presents a state diagram that depicts the comparative study of various
scheduling algorithms for a single CPU and shows which algorithm is best for
the particular situation. Using this representation, it becomes much easier to
understand what is going on inside the system and why a different set of
processes is a candidate for the allocation of the CPU at different time. The
objective of the study is to analyze the high efficient CPU scheduler on design
of the high quality scheduling algorithms which suits the scheduling goals. Key
Words:-Scheduler, State Diagrams, CPU-Scheduling, Performance
"
149,An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm,"  The main objective of this paper is to improve the Round Robin scheduling
algorithm using the dynamic time slice concept. CPU scheduling becomes very
important in accomplishing the operating system (OS) design goals. The
intention should be allowed as many as possible running processes at all time
in order to make best use of CPU. CPU scheduling has strong effect on resource
utilization as well as overall performance of the system. Round Robin algorithm
performs optimally in time-shared systems, but it is not suitable for soft real
time systems, because it gives more number of context switches, larger waiting
time and larger response time. In this paper, a new CPU scheduling algorithm
called An Optimum Multilevel Dynamic Round Robin Scheduling Algorithm is
proposed, which calculates intelligent time slice and changes after every round
of execution. The suggested algorithm was evaluated on some CPU scheduling
objectives and it was observed that this algorithm gave good performance as
compared to the other existing CPU scheduling algorithms.
"
150,An Improving Method for Loop Unrolling,"  In this paper we review main ideas mentioned in several other papers which
talk about optimization techniques used by compilers. Here we focus on loop
unrolling technique and its effect on power consumption, energy usage and also
its impact on program speed up by achieving ILP (Instruction-level
parallelism). Concentrating on superscalar processors, we discuss the idea of
generalized loop unrolling presented by J.C. Hang and T. Leng and then we
present a new method to traverse a linked list to get a better result of loop
unrolling in that case. After that we mention the results of some experiments
carried out on a Pentium 4 processor (as an instance of super scalar
architecture). Furthermore, the results of some other experiments on
supercomputer (the Alliat FX/2800 System) containing superscalar node
processors would be mentioned. These experiments show that loop unrolling has a
slight measurable effect on energy usage as well as power consumption. But it
could be an effective way for program speed up.
"
151,Intensional view of General Single Processor Operating Systems,"  Operating systems are currently viewed ostensively. As a result they mean
different things to different people. The ostensive character makes it is hard
to understand OSes formally. An intensional view can enable better formal work,
and also offer constructive support for some important problems, e.g. OS
architecture. This work argues for an intensional view of operating systems. It
proposes to overcome the current ostensive view by defining an OS based on
formal models of computation, and also introduces some principles. Together
these are used to develop a framework of algorithms of single processor OS
structure using an approach similar to function level programming. In this
abridged paper we illustrate the essential approach, discuss some advantages
and limitations and point out some future possibilities.
"
152,Opacity of Memory Management in Software Transactional Memory,"  Opacity of Transactional Memory is proposed to be established by incremental
validation. Quiescence in terms of epoch-based memory reclamation is applied to
deal with doomed transactions causing memory access violations. This method
unfortunately involves increased memory consumption and does not cover
reclamations outside of transactions. This paper introduces a different method
which combines incremental validation with elements of sandboxing to solve
these issues.
"
153,"Flashmon V2: Monitoring Raw NAND Flash Memory I/O Requests on Embedded
  Linux","  This paper presents Flashmon version 2, a tool for monitoring embedded Linux
NAND flash memory I/O requests. It is designed for embedded boards based
devices containing raw flash chips. Flashmon is a kernel module and stands for
""flash monitor"". It traces flash I/O by placing kernel probes at the NAND
driver level. It allows tracing at runtime the 3 main flash operations: page
reads / writes and block erasures. Flashmon is (1) generic as it was
successfully tested on the three most widely used flash file systems that are
JFFS2, UBIFS and YAFFS, and several NAND chip models. Moreover, it is (2) non
intrusive, (3) has a controllable memory footprint, and (4) exhibits a low
overhead (<6%) on the traced system. Finally, it is (5) simple to integrate and
used as a standalone module or as a built-in function / module in existing
kernel sources. Monitoring flash memory operations allows a better
understanding of existing flash management systems by studying and analyzing
their behavior. Moreover it is useful in development phase for prototyping and
validating new solutions.
"
154,"Simulation of an Optimum Multilevel Dynamic Round Robin Scheduling
  Algorithm","  CPU scheduling has valiant effect on resource utilization as well as overall
quality of the system. Round Robin algorithm performs optimally in time shared
systems, but it performs more number of context switches, larger waiting time
and larger response time. In order to simulate the behavior of various CPU
scheduling algorithms and to improve Round Robin scheduling algorithm using
dynamic time slice concept, in this paper we produce the implementation of new
CPU scheduling algorithm called An Optimum Multilevel Dynamic Round Robin
Scheduling (OMDRRS), which calculates intelligent time slice and warps after
every round of execution. The results display the robustness of this software,
especially for academic, research and experimental use, as well as proving the
desirability and efficiency of the probabilistic algorithm over the other
existing techniques and it is observed that this OMDRRS projects good
performance as compared to the other existing CPU scheduling algorithms.
"
155,Cudagrind: A Valgrind Extension for CUDA,"  Valgrind, and specifically the included tool Memcheck, offers an easy and
reliable way for checking the correctness of memory operations in programs.
This works in an unintrusive way where Valgrind translates the program into
intermediate code and executes it on an emulated CPU. The heavy weight tool
Memcheck uses this to keep a full shadow copy of the memory used by a program
and tracking accesses to it. This allows the detection of memory leaks and
checking the validity of accesses.
  Though suited for a wide variety of programs, this approach still fails when
accelerator based programming models are involved. The code running on these
devices is separate from the code running on the host. Access to memory on the
device and starting of kernels is being handled by an API provided by the
driver being used. Hence Valgrind is unable to understand and instrument
operations being run on the device.
  To circumvent this limitation a new set of wrapper functions have been
introduced. These wrap a subset of the CUDA Driver API function that is
responsible for (de-)allocation memory regions on the device and the respective
memory copy operations. This allows to check whether memory is fully allocated
during a transfer and, through the functionality provided by Valgrind, whether
the memory transfered to the device from the host is defined and addressable.
Through this technique it is possible to detect a number of common programming
mistakes, which are very difficult to debug by other means. The combination of
these wrappers together with the Valgrind tool Memcheck is being called
Cudagrind.
"
156,Impacting the bioscience progress by backporting software for Bio-Linux,"  In year 2006 Bio-Linux with the work of Tim Booth and team gives its rising
and provide an operating system that was and still specialized in providing a
bioinformatic specific software environment for the working needs in this
corner of bioscience. It is shown that Bio-Linux is affected by a 2 year
release cycle and with this the final releases of Bio-Linux will not have the
latest bioinformatic software on board. The paper shows how to get around this
huge time gap and bring new software for Bio-Linux on board through a process
that is called backporting. A summary of within the work to this paper just
backported bioinformatic tools is given. A describtion of a workflow for
continuously integration of the newest bioinformatic tools gives an outlook to
further concrete planned developments and the influence of speeding up
scientific progress.
"
157,C2MS: Dynamic Monitoring and Management of Cloud Infrastructures,"  Server clustering is a common design principle employed by many organisations
who require high availability, scalability and easier management of their
infrastructure. Servers are typically clustered according to the service they
provide whether it be the application(s) installed, the role of the server or
server accessibility for example. In order to optimize performance, manage load
and maintain availability, servers may migrate from one cluster group to
another making it difficult for server monitoring tools to continuously monitor
these dynamically changing groups. Server monitoring tools are usually
statically configured and with any change of group membership requires manual
reconfiguration; an unreasonable task to undertake on large-scale cloud
infrastructures.
  In this paper we present the Cloudlet Control and Management System (C2MS); a
system for monitoring and controlling dynamic groups of physical or virtual
servers within cloud infrastructures. The C2MS extends Ganglia - an open source
scalable system performance monitoring tool - by allowing system administrators
to define, monitor and modify server groups without the need for server
reconfiguration. In turn administrators can easily monitor group and individual
server metrics on large-scale dynamic cloud infrastructures where roles of
servers may change frequently. Furthermore, we complement group monitoring with
a control element allowing administrator-specified actions to be performed over
servers within service groups as well as introduce further customized
monitoring metrics. This paper outlines the design, implementation and
evaluation of the C2MS.
"
158,The Quest-V Separation Kernel for Mixed Criticality Systems,"  Multi- and many-core processors are becoming increasingly popular in embedded
systems. Many of these processors now feature hardware virtualization
capabilities, such as the ARM Cortex A15, and x86 processors with Intel VT-x or
AMD-V support. Hardware virtualization offers opportunities to partition
physical resources, including processor cores, memory and I/O devices amongst
guest virtual machines. Mixed criticality systems and services can then
co-exist on the same platform in separate virtual machines. However,
traditional virtual machine systems are too expensive because of the costs of
trapping into hypervisors to multiplex and manage machine physical resources on
behalf of separate guests. For example, hypervisors are needed to schedule
separate VMs on physical processor cores. In this paper, we discuss the design
of the Quest-V separation kernel, that partitions services of different
criticalities in separate virtual machines, or sandboxes. Each sandbox
encapsulates a subset of machine physical resources that it manages without
requiring intervention of a hypervisor. Moreover, a hypervisor is not needed
for normal operation, except to bootstrap the system and establish
communication channels between sandboxes.
"
159,Predictable Migration and Communication in the Quest-V Multikernel,"  Quest-V is a system we have been developing from the ground up, with
objectives focusing on safety, predictability and efficiency. It is designed to
work on emerging multicore processors with hardware virtualization support.
Quest-V is implemented as a ""distributed system on a chip"" and comprises
multiple sandbox kernels. Sandbox kernels are isolated from one another in
separate regions of physical memory, having access to a subset of processing
cores and I/O devices. This partitioning prevents system failures in one
sandbox affecting the operation of other sandboxes. Shared memory channels
managed by system monitors enable inter-sandbox communication.
  The distributed nature of Quest-V means each sandbox has a separate physical
clock, with all event timings being managed by per-core local timers. Each
sandbox is responsible for its own scheduling and I/O management, without
requiring intervention of a hypervisor.
  In this paper, we formulate bounds on inter-sandbox communication in the
absence of a global scheduler or global system clock. We also describe how
address space migration between sandboxes can be guaranteed without violating
service constraints. Experimental results on a working system show the
conditions under which Quest-V performs real-time communication and migration.
"
160,Quest-V: A Virtualized Multikernel for Safety-Critical Real-Time Systems,"  Modern processors are increasingly featuring multiple cores, as well as
support for hardware virtualization. While these processors are common in
desktop and server-class computing, they are less prevalent in embedded and
real-time systems. However, smartphones and tablet PCs are starting to feature
multicore processors with hardware virtualization. If the trend continues, it
is possible that future real-time systems will feature more sophisticated
processor architectures. Future automotive or avionics systems, for example,
could replace complex networks of uniprocessors with consolidated services on a
smaller number of multicore processors. Likewise, virtualization could be used
to isolate services and increase the availability of a system even when
failures occur.
  This paper investigates whether advances in modern processor technologies
offer new opportunities to rethink the design of real-time operating systems.
We describe some of the design principles behind Quest-V, which is being used
as an exploratory vehicle for real-time system design on multicore processors
with hardware virtualization capabilities. While not all embedded systems
should assume such features, a case can be made that more robust,
safety-critical systems can be built to use hardware virtualization without
incurring significant overheads.
"
161,"Efficient Runtime Monitoring with Metric Temporal Logic: A Case Study in
  the Android Operating System","  We present a design and an implementation of a security policy specification
language based on metric linear-time temporal logic (MTL). MTL features
temporal operators that are indexed by time intervals, allowing one to specify
timing-dependent security policies. The design of the language is driven by the
problem of runtime monitoring of applications in mobile devices. A main case
the study is the privilege escalation attack in the Android operating system,
where an app gains access to certain resource or functionalities that are not
explicitly granted to it by the user, through indirect control flow. To capture
these attacks, we extend MTL with recursive definitions, that are used to
express call chains betwen apps. We then show how the metric operators of MTL,
in combination with recursive definitions, can be used to specify policies to
detect privilege escalation, under various fine grained constraints. We present
a new algorithm, extending that of linear time temporal logic, for monitoring
safety policies written in our specification language. The monitor does not
need to store the entire history of events generated by the apps, something
that is crucial for practical implementations. We modified the Android OS
kernel to allow us to insert our generated monitors modularly. We have tested
the modified OS on an actual device, and show that it is effective in detecting
policy violations.
"
162,Impact of Limpware on HDFS: A Probabilistic Estimation,"  With the advent of cloud computing, thousands of machines are connected and
managed collectively. This era is confronted with a new challenge: performance
variability, primarily caused by large-scale management issues such as hardware
failures, software bugs, and configuration mistakes. In our previous work we
highlighted one overlooked cause: limpware - hardware whose performance
degrades significantly compared to its specification. We showed that limpware
can cause severe impact in current scale-out systems. In this report, we
quantify how often these scenarios happen in Hadoop Distributed File System.
"
163,Performance Evaluation of Java File Security System (JFSS),"  Security is a critical issue of the modern file and storage systems, it is
imperative to protect the stored data from unauthorized access. We have
developed a file security system named as Java File Security System (JFSS) [1]
that guarantee the security to files on the demand of all users. It has been
developed on Java platform. Java has been used as programming language in order
to provide portability, but it enforces some performance limitations. It is
developed in FUSE (File System in User space) [3]. Many efforts have been done
over the years for developing file systems in user space (FUSE). All have their
own merits and demerits. In this paper we have evaluated the performance of
Java File Security System (JFSS). Over and over again, the increased security
comes at the expense of user convenience, performance or compatibility with
other systems. JFSS system performance evaluations show that encryption
overheads are modest as compared to security.
"
164,File System - A Component of Operating System,"  The file system provides the mechanism for online storage and access to file
contents, including data and programs. This paper covers the high-level details
of file systems, as well as related topics such as the disk cache, the file
system interface to the kernel, and the user-level APIs that use the features
of the file system. It will give you a thorough understanding of how a file
system works in general. The main component of the operating system is the file
system. It is used to create, manipulate, store, and retrieve data. At the
highest level, a file system is a way to manage information on a secondary
storage medium. There are so many layers under and above the file system. All
the layers are to be fully described here. This paper will give the explanatory
knowledge of the file system designers and the researchers in the area. The
complete path from the user process to secondary storage device is to be
mentioned. File system is the area where the researchers are doing lot of job
and there is always a need to do more work. The work is going on for the
efficient, secure, energy saving techniques for the file systems. As we know
that the hardware is going to be fast in performance and low-priced day by day.
The software is not built to comeback with the hardware technology. So there is
a need to do research in this area to bridge the technology gap.
"
165,"Towards the Framework of the File Systems Performance Evaluation
  Techniques and the Taxonomy of Replay Traces","  This is the era of High Performance Computing (HPC). There is a great demand
of the best performance evaluation techniques for the file and storage systems.
The task of evaluation is both necessary and hard. It gives in depth analysis
of the target system and that becomes the decision points for the users. That
is also helpful for the inventors or developers to find out the bottleneck in
their systems. In this paper many performance evaluation techniques are
described for file and storage system evaluation and the main stress is given
on the important one that is replay traces. A survey has been done for the
performance evaluation techniques used by the researchers and on the replay
traces. And the taxonomy of the replay traces is described. The some of the
popular replay traces are just like, Tracefs [1], //Trace [2], Replayfs [3] and
VFS Interceptor [12]. At last we have concluded all the features that must be
considered when we are going to develop the new tool for the replay traces. The
complete work of this paper shows that the storage system developers must care
about all the techniques which can be used for the performance evaluation of
the file systems. So they can develop highly efficient future file and storage
systems.
"
166,Managing NymBoxes for Identity and Tracking Protection,"  Despite the attempts of well-designed anonymous communication tools to
protect users from tracking or identification, flaws in surrounding software
(such as web browsers) and mistakes in configuration may leak the user's
identity. We introduce Nymix, an anonymity-centric operating system
architecture designed ""top-to-bottom"" to strengthen identity- and
tracking-protection. Nymix's core contribution is OS support for nym-browsing:
independent, parallel, and ephemeral web sessions. Each web session, or
pseudonym, runs in a unique virtual machine (VM) instance evolving from a
common base state with support for long-lived sessions which can be anonymously
stored to the cloud, avoiding de-anonymization despite potential confiscation
or theft. Nymix allows a user to safely browse the Web using various different
transports simultaneously through a pluggable communication model that supports
Tor, Dissent, and a private browsing mode. In evaluations, Nymix consumes 600
MB per nymbox and loads within 15 to 25 seconds.
"
167,Transparent Checkpoint-Restart over InfiniBand,"  InfiniBand is widely used for low-latency, high-throughput cluster computing.
Saving the state of the InfiniBand network as part of distributed checkpointing
has been a long-standing challenge for researchers. Because of a lack of a
solution, typical MPI implementations have included custom checkpoint-restart
services that ""tear down"" the network, checkpoint each node as if the node were
a standalone computer, and then re-connect the network again. We present the
first example of transparent, system-initiated checkpoint-restart that directly
supports InfiniBand. The new approach is independent of any particular Linux
kernel, thus simplifying the current practice of using a kernel-based module,
such as BLCR. This direct approach results in checkpoints that are found to be
faster than with the use of a checkpoint-restart service. The generality of
this approach is shown not only by checkpointing an MPI computation, but also a
native UPC computation (Berkeley Unified Parallel C), which does not use MPI.
Scalability is shown by checkpointing 2,048 MPI processes across 128 nodes
(with 16 cores per node). In addition, a cost-effective debugging approach is
also enabled, in which a checkpoint image from an InfiniBand-based production
cluster is copied to a local Ethernet-based cluster, where it can be restarted
and an interactive debugger can be attached to it. This work is based on a
plugin that extends the DMTCP (Distributed MultiThreaded CheckPointing)
checkpoint-restart package.
"
168,"Cache-aware static scheduling for hard real-time multicore systems based
  on communication affinities","  The growing need for continuous processing capabilities has led to the
development of multicore systems with a complex cache hierarchy. Such multicore
systems are generally designed for improving the performance in average case,
while hard real-time systems must consider worst-case scenarios. An open
challenge is therefore to efficiently schedule hard real-time tasks on a
multicore architecture. In this work, we propose a mathematical formulation for
computing a static scheduling that minimize L1 data cache misses between hard
real-time tasks on a multicore architecture using communication affinities.
"
169,Rio: A System Solution for Sharing I/O between Mobile Systems,"  Mobile systems are equipped with a diverse collection of I/O devices,
including cameras, microphones, sensors, and modems. There exist many novel use
cases for allowing an application on one mobile system to utilize I/O devices
from another. This paper presents Rio, an I/O sharing solution that supports
unmodified applications and exposes all the functionality of an I/O device for
sharing. Rio's design is common to many classes of I/O devices, thus
significantly reducing the engineering effort to support new I/O devices. Our
implementation of Rio on Android consists of 6700 total lines of code and
supports four I/O classes with fewer than 450 class-specific lines of code. Rio
also supports I/O sharing between mobile systems of different form factors,
including smartphones and tablets. We show that Rio achieves performance close
to that of local I/O for audio, sensors, and modems, but suffers noticeable
performance degradation for camera due to network throughput limitations
between the two systems, which is likely to be alleviated by emerging wireless
standards.
"
170,Support for Error Tolerance in the Real-Time Transport Protocol,"  Streaming applications often tolerate bit errors in their received data well.
This is contrasted by the enforcement of correctness of the packet headers and
payload by network protocols. We investigate a solution for the Real-time
Transport Protocol (RTP) that is tolerant to errors by accepting erroneous
data. It passes potentially corrupted stream data payloads to the codecs. If
errors occur in the header, our solution recovers from these by leveraging the
known state and expected header values for each stream. The solution is fully
receiver-based and incrementally deployable, and as such requires neither
support from the sender nor changes to the RTP specification. Evaluations show
that our header error recovery scheme can recover from almost all errors, with
virtually no erroneous recoveries, up to bit error rates of about 10%.
"
171,Transparent Checkpoint-Restart for Hardware-Accelerated 3D Graphics,"  Providing fault-tolerance for long-running GPU-intensive jobs requires
application-specific solutions, and often involves saving the state of complex
data structures spread among many graphics libraries. This work describes a
mechanism for transparent GPU-independent checkpoint-restart of 3D graphics.
The approach is based on a record-prune-replay paradigm: all OpenGL calls
relevant to the graphics driver state are recorded; calls not relevant to the
internal driver state as of the last graphics frame prior to checkpoint are
discarded; and the remaining calls are replayed on restart. A previous approach
for OpenGL 1.5, based on a shadow device driver, required more than 78,000
lines of OpenGL-specific code. In contrast, the new approach, based on
record-prune-replay, is used to implement the same case in just 4,500 lines of
code. The speed of this approach varies between 80 per cent and nearly 100 per
cent of the speed of the native hardware acceleration for OpenGL 1.5, as
measured when running the ioquake3 game under Linux. This approach has also
been extended to demonstrate checkpointing of OpenGL 3.0 for the first time,
with a demonstration for PyMol, for molecular visualization.
"
172,"Performance Impact of Lock-Free Algorithms on Multicore Communication
  APIs","  Data race conditions in multi-tasking software applications are prevented by
serializing access to shared memory resources, ensuring data consistency and
deterministic behavior. Traditionally tasks acquire and release locks to
synchronize operations on shared memory. Unfortunately, lock management can add
significant processing overhead especially for multicore deployments where
tasks on different cores convoy in queues waiting to acquire a lock.
Implementing more than one lock introduces the risk of deadlock and using
spinlocks constrains which cores a task can run on. The better alternative is
to eliminate locks and validate that real-time properties are met, which is not
directly considered in many embedded applications. Removing the locks is
non-trivial and packaging lock-free algorithms for developers reduces the
possibility of concurrency defects. This paper details how a multicore
communication API implementation is enhanced to support lock-free messaging and
the impact this has on data exchange latency between tasks. Throughput and
latency are compared on Windows and Linux between lock-based and lock-free
implementations for data exchange of messages, packets, and scalars. A model of
the lock-free exchange predicts performance at the system architecture level
and provides a stop criterion for the refactoring. The results show that
migration from single to multicore hardware architectures degrades lock-based
performance, and increases lock-free performance.
"
173,Anception: Application Virtualization For Android,"  The problem of malware has become significant on Android devices. Library
operating systems and application virtualization are both possible solutions
for confining malware. Unfortunately, such solutions do not exist for Android.
Designing mechanisms for application virtualization is a significant chal-
lenge for several reasons: (1) graphics performance is important due to
popularity of games and (2) applications with the same UID can share state.
This paper presents Anception, the first flexible application virtualization
framework for Android. It is imple- mented as a modification to the Android
kernel and supports application virtualization that addresses the above
requirements. Anception is able to confine many types of malware while
supporting unmodified Android applications. Our Anception- based system
exhibits up to 3.9% overhead on various 2D/3D benchmarks, and 1.8% overhead on
the SunSpider benchmark.
"
174,"LWRP: Low Power Consumption Weighting Replacement Policy using Buffer
  Memory","  As the performance gap between memory and processors has increased, then it
leads to the poor performance. Efficient virtual memory can overcome this
problem. And the efficiency of virtual memory depends on the replacement policy
used for cache. In this paper, our algorithm not only based on the time to last
access and frequency index but, we also consider the power consumption. We show
that Low Power Consumption Weighting Replacement Policy (LWRP) has better
performance and low power consumption.
"
175,Formal Description of Components in Operating Systems,"  The contemporary development of hardware components is a prerequisite for
increasing the concentration of computing power. System software is developing
at a much slower pace. To use available resources efficiently modeling is
required. Formalization of elements, present in the material, provides the
basis for modeling. Examples are presented to demonstrate the efficiency of the
concept.
"
176,"Design and Performance Evaluation of an Optimized Disk Scheduling
  Algorithm (ODSA)","  Management of disk scheduling is a very important aspect of operating system.
Performance of the disk scheduling completely depends on how efficient is the
scheduling algorithm to allocate services to the request in a better manner.
Many algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.) are developed in the
recent years in order to optimize the system disk I/O performance. By reducing
the average seek time and transfer time, we can improve the performance of disk
I/O operation. In our proposed algorithm, Optimize Disk Scheduling Algorithm
(ODSA) is taking less average seek time and transfer time as compare to other
disk scheduling algorithms (FIFO, SSTF, SCAN, C-SCAN, LOOK, etc.), which
enhances the efficiency of the disk performance in a better manner.
"
177,"A Group based Time Quantum Round Robin Algorithm using Min-Max Spread
  Measure","  Round Robin (RR) Scheduling is the basis of time sharing environment. It is
the combination of First Come First Served (FCFS) scheduling algorithm and
preemption among processes. It is basically used in a time sharing operating
system. It switches from one process to another process in a time interval. The
time interval or Time Quantum (TQ) is fixed for all available processes. So,
the larger process suffers from Context Switches (CS). To increase efficiency,
we have to select different TQ for processes. The main objective of RR is to
reduce the CS, maximize the utilization of CPU and minimize the turn around and
the waiting time. In this paper, we have considered different TQ for a group of
processes. It reduces CS as well as enhancing the performance of RR algorithm.
TQ can be calculated using min-max dispersion measure. Our experimental
analysis shows that Group Based Time Quantum (GBTQ) RR algorithm performs
better than existing RR algorithm with respect to Average Turn Around Time
(ATAT), Average Waiting Time (AWT) and CS.
"
178,"A Taxonomy for Attack Patterns on Information Flows in Component-Based
  Operating Systems","  We present a taxonomy and an algebra for attack patterns on component-based
operating systems. In a multilevel security scenario, where isolation of
partitions containing data at different security classifications is the primary
security goal and security breaches are mainly defined as undesired disclosure
or modification of classified data, strict control of information flows is the
ultimate goal. In order to prevent undesired information flows, we provide a
classification of information flow types in a component-based operating system
and, by this, possible patterns to attack the system. The systematic
consideration of informations flows reveals a specific type of operating system
covert channel, the covert physical channel, which connects two former isolated
partitions by emitting physical signals into the computer's environment and
receiving them at another interface.
"
179,"Task & Resource Self-adaptive Embedded Real-time Operating System
  Microkernel for Wireless Sensor Nodes","  Wireless Sensor Networks (WSNs) are used in many application fields, such as
military, healthcare, environment surveillance, etc. The WSN OS based on
event-driven model doesn't support real-time and multi-task application types
and the OSs based on thread-driven model consume much energy because of
frequent context switch. Due to the high-dense and large-scale deployment of
sensor nodes, it is very difficult to collect sensor nodes to update their
software. Furthermore, the sensor nodes are vulnerable to security attacks
because of the characteristics of broadcast communication and unattended
application. This paper presents a task and resource self-adaptive embedded
real-time microkernel, which proposes hybrid programming model and offers a
two-level scheduling strategy to support real-time multi-task correspondingly.
A communication scheme, which takes the ""tuple"" space and ""IN/OUT"" primitives
from ""LINDA"", is proposed to support some collaborative and distributed tasks.
In addition, this kernel implements a run-time over-the-air updating mechanism
and provides a security policy to avoid the attacks and ensure the reliable
operation of nodes. The performance evaluation is proposed and the experiential
results show this kernel is task-oriented and resource-aware and can be used
for the applications of event-driven and real-time multi-task.
"
180,File System Design Approaches,"  In this article, the file system development design approaches are discussed.
The selection of the file system design approach is done according to the needs
of the developers what are the needed requirements and specifications for the
new design. It allowed us to identify where our proposal fitted in with
relation to current and past file system development. Our experience with file
system development is limited so the research served to identify the different
techniques that can be used. The variety of file systems encountered show what
an active area of research file system development is. The file systems may be
from one of the two fundamental categories. In one category, the file system is
developed in user space and runs as a user process. Another file system may be
developed in the kernel space and runs as a privileged process. Another one is
the mixed approach in which we can take the advantages of both aforesaid
approaches. Each development option has its own pros and cons. In this article,
these design approaches are discussed.
"
181,Toward Parametric Timed Interfaces for Real-Time Components,"  We propose here a framework to model real-time components consisting of
concurrent real-time tasks running on a single processor, using parametric
timed automata. Our framework is generic and modular, so as to be easily
adapted to different schedulers and more complex task models. We first perform
a parametric schedulability analysis of the components using the inverse
method. We show that the method unfortunately does not provide satisfactory
results when the task periods are consid- ered as parameters. After identifying
and explaining the problem, we present a solution adapting the model by making
use of the worst-case scenario in schedulability analysis. We show that the
analysis with the inverse method always converges on the modified model when
the system load is strictly less than 100%. Finally, we show how to use our
parametric analysis for the generation of timed interfaces in compositional
system design.
"
182,"An Enhanced Multi-Pager Environment Support for Second Generation
  Microkernels","  The main objective of this paper is to present a mechanism of enhanced paging
support for the second generation microkernels in the form of explicit support
of multi-pager environment for the tasks running in the system. Proposed
mechanism is based on the intra-kernel high granularity pagers assignments per
virtual address space, which allow efficient and simple dispatching of page
faults to the appropriate pagers. The paging is one of the major features of
the virtual memory, which is extensively used by advanced operating systems to
provide an illusion of elastic memory. Original and present second generation
microkernels provide only limited, inflexible and unnatural support for paging.
Furthermore, facilities provided by current solutions for multi-pager support
on the runtime level introduce an overhead in terms of mode switches and thread
context switches which can be significantly reduced. Limited paging support
limits the attractiveness of the second generation microkernel based systems
use in real-life applications, in which processes usually have concurrent
servicing of multiple paging servers. The purpose of this paper is to present a
facilities for the efficient and flexible support of multi-pager environments
for the second generation microkernels. A comparison of the proposed solution
to the present architecture L4 + L4Re has been made and overhead of the page
fault handling critical path has been evaluated. Proposed solution is simple
enough and provides a natural and flexible support of multi-pager environments
for second generation microkernels in efficient way. It introduces a third less
overhead in terms of the mode switches and thread context switches in
comparison to the present L4 + L4Re solution implemented in the Fiasco.OC.
"
183,An Effective Round Robin Algorithm using Min-Max Dispersion Measure,"  Round Robin (RR) scheduling algorithm is a preemptive scheduling algorithm.
It is designed especially for time sharing Operating System (OS). In RR
scheduling algorithm the CPU switches between the processes when the static
Time Quantum (TQ) expires. RR scheduling algorithm is considered as the most
widely used scheduling algorithm in research because the TQ is equally shared
among the processes. In this paper a newly proposed variant of RR algorithm
called Min-Max Round Robin (MMRR) scheduling algorithm is presented. The idea
of this MMRR is to make the TQ repeatedly adjusted using Min-Max dispersion
measure in accordance with remaining CPU burst time. Our experimental analysis
shows that MMRR performs much better than RR algorithm in terms of average
turnaround time, average waiting time and number of context switches.
"
184,"Enhancing CPU Performance using Subcontrary Mean Dynamic Round Robin
  (SMDRR) Scheduling Algorithm","  Round Robin (RR) Algorithm is considered as optimal in time shared
environment because the static time is equally shared among the processes. If
the time quantum taken is static then it undergoes degradation of the CPU
performance and leads to so many context switches. In this paper, we have
proposed a new effective dynamic RR algorithm SMDRR (Subcontrary Mean Dynamic
Round Robin) based on dynamic time quantum where we use the subcontrary mean or
harmonic mean to find the time quantum. The idea of this approach is to make
the time quantum repeatedly adjusted according to the burst time of the
currently running processes. Our experimental analysis shows that SMDRR
performs better than RR algorithm in terms of reducing the number of context
switches, average turnaround time and average waiting time.
"
185,"Proceedings of the First Workshop on Resource Awareness and Adaptivity
  in Multi-Core Computing (Racing 2014)","  This volume contains the papers accepted at the 1st Workshop on Resource
Awareness and Adaptivity in Multi-Core Computing (Racing 2014), held in
Paderborn, Germany, May 29-30, 2014. Racing 2014 was co-located with the IEEE
European Test Symposium (ETS).
"
186,"Heterogeneity-aware Fault Tolerance using a Self-Organizing Runtime
  System","  Due to the diversity and implicit redundancy in terms of processing units and
compute kernels, off-the-shelf heterogeneous systems offer the opportunity to
detect and tolerate faults during task execution in hardware as well as in
software. To automatically leverage this diversity, we introduce an extension
of an online-learning runtime system that combines the benefits of the existing
performance-oriented task mapping with task duplication, a diversity-oriented
mapping strategy and heterogeneity-aware majority voter. This extension uses a
new metric to dynamically rate the remaining benefit of unreliable processing
units and a memory management mechanism for automatic data transfers and
checkpointing in the host and device memories.
"
187,"Resource-Aware Replication on Heterogeneous Multicores: Challenges and
  Opportunities","  Decreasing hardware feature sizes and increasing heterogeneity in multicore
hardware require software that can adapt to these platforms' properties. We
implemented ROMAIN, an OS service providing redundant multithreading on top of
the FIASCO.OC microkernel to address the increasing unreliability of hardware.
In this paper we review challenges and opportunities for ROMAIN to adapt to
such multicore platforms in order to decrease execution overhead, resource
requirements, and vulnerability against faults.
"
188,Hello rootKitty: A lightweight invariance-enforcing framework,"  In monolithic operating systems, the kernel is the piece of code that
executes with the highest privileges and has control over all the software
running on a host. A successful attack against an operating system's kernel
means a total and complete compromise of the running system. These attacks
usually end with the installation of a rootkit, a stealthy piece of software
running with kernel privileges. When a rootkit is present, no guarantees can be
made about the correctness, privacy or isolation of the operating system.
  In this paper we present \emph{Hello rootKitty}, an invariance-enforcing
framework which takes advantage of current virtualization technology to protect
a guest operating system against rootkits. \emph{Hello rootKitty} uses the idea
of invariance to detect maliciously modified kernel data structures and restore
them to their original legitimate values. Our prototype has negligible
performance and memory overhead while effectively protecting commodity
operating systems from modern rootkits.
"
189,"Supporting Soft Real-Time Sporadic Task Systems on Heterogeneous
  Multiprocessors with No Utilization Loss","  Heterogeneous multicore architectures are becoming increasingly popular due
to their potential of achieving high performance and energy efficiency compared
to the homogeneous multicore architectures. In such systems, the real-time
scheduling problem becomes more challenging in that processors have different
speeds. A job executing on a processor with speed $x$ for $t$ time units
completes $(x \cdot t)$ units of execution. Prior research on heterogeneous
multiprocessor real-time scheduling has focused on hard real-time systems,
where, significant processing capacity may have to be sacrificed in the
worst-case to ensure that all deadlines are met. As meeting hard deadlines is
overkill for many soft real-time systems in practice, this paper shows that on
soft real-time heterogeneous multiprocessors, bounded response times can be
ensured for globally-scheduled sporadic task systems with no utilization loss.
A GEDF-based scheduling algorithm, namely GEDF-H, is presented and response
time bounds are established under both preemptive and non-preemptive GEDF-H
scheduling. Extensive experiments show that the magnitude of the derived
response time bound is reasonable, often smaller than three task periods. To
the best of our knowledge, this paper is the first to show that soft real-time
sporadic task systems can be supported on heterogeneous multiprocessors without
utilization loss, and with reasonable predicted response time.
"
190,Timing Analysis for DAG-based and GFP Scheduled Tasks,"  Modern embedded systems have made the transition from single-core to
multi-core architectures, providing performance improvement via parallelism
rather than higher clock frequencies. DAGs are considered among the most
generic task models in the real-time domain and are well suited to exploit this
parallelism. In this paper we provide a schedulability test using response-time
analysis exploiting exploring and bounding the self interference of a DAG task.
Additionally we bound the interference a high priority task has on lower
priority ones.
"
191,On the Reverse Engineering of the Citadel Botnet,"  Citadel is an advanced information-stealing malware which targets financial
information. This malware poses a real threat against the confidentiality and
integrity of personal and business data. A joint operation was recently
conducted by the FBI and the Microsoft Digital Crimes Unit in order to take
down Citadel command-and-control servers. The operation caused some disruption
in the botnet but has not stopped it completely. Due to the complex structure
and advanced anti-reverse engineering techniques, the Citadel malware analysis
process is both challenging and time-consuming. This allows cyber criminals to
carry on with their attacks while the analysis is still in progress. In this
paper, we present the results of the Citadel reverse engineering and provide
additional insight into the functionality, inner workings, and open source
components of the malware. In order to accelerate the reverse engineering
process, we propose a clone-based analysis methodology. Citadel is an offspring
of a previously analyzed malware called Zeus; thus, using the former as a
reference, we can measure and quantify the similarities and differences of the
new variant. Two types of code analysis techniques are provided in the
methodology, namely assembly to source code matching and binary clone
detection. The methodology can help reduce the number of functions requiring
manual analysis. The analysis results prove that the approach is promising in
Citadel malware analysis. Furthermore, the same approach is applicable to
similar malware analysis scenarios.
"
192,"Preemptive Thread Block Scheduling with Online Structural Runtime
  Prediction for Concurrent GPGPU Kernels","  Recent NVIDIA Graphics Processing Units (GPUs) can execute multiple kernels
concurrently. On these GPUs, the thread block scheduler (TBS) uses the FIFO
policy to schedule their thread blocks. We show that FIFO leaves performance to
chance, resulting in significant loss of performance and fairness. To improve
performance and fairness, we propose use of the preemptive Shortest Remaining
Time First (SRTF) policy instead. Although SRTF requires an estimate of runtime
of GPU kernels, we show that such an estimate of the runtime can be easily
obtained using online profiling and exploiting a simple observation on GPU
kernels' grid structure. Specifically, we propose a novel Structural Runtime
Predictor. Using a simple Staircase model of GPU kernel execution, we show that
the runtime of a kernel can be predicted by profiling only the first few thread
blocks. We evaluate an online predictor based on this model on benchmarks from
ERCBench, and find that it can estimate the actual runtime reasonably well
after the execution of only a single thread block. Next, we design a thread
block scheduler that is both concurrent kernel-aware and uses this predictor.
We implement the SRTF policy and evaluate it on two-program workloads from
ERCBench. SRTF improves STP by 1.18x and ANTT by 2.25x over FIFO. When compared
to MPMax, a state-of-the-art resource allocation policy for concurrent kernels,
SRTF improves STP by 1.16x and ANTT by 1.3x. To improve fairness, we also
propose SRTF/Adaptive which controls resource usage of concurrently executing
kernels to maximize fairness. SRTF/Adaptive improves STP by 1.12x, ANTT by
2.23x and Fairness by 2.95x compared to FIFO. Overall, our implementation of
SRTF achieves system throughput to within 12.64% of Shortest Job First (SJF, an
oracle optimal scheduling policy), bridging 49% of the gap between FIFO and
SJF.
"
193,"Effects of Hard Real-Time Constraints in Implementing the Myopic
  Scheduling Algorithm","  Myopic is a hard real-time process scheduling algorithm that selects a
suitable process based on a heuristic function from a subset (Window)of all
ready processes instead of choosing from all available processes, like original
heuristic scheduling algorithm. Performance of the algorithm significantly
depends on the chosen heuristic function that assigns weight to different
parameters like deadline, earliest starting time, processing time etc. and the
sizeof the Window since it considers only k processes from n processes (where,
k<= n). This research evaluates the performance of the Myopic algorithm for
different parameters to demonstrate the merits and constraints of the
algorithm. A comparative performance of the impact of window size in
implementing the Myopic algorithm is presented and discussed through a set of
experiments.
"
194,Security of OS-level virtualization technologies: Technical report,"  The need for flexible, low-overhead virtualization is evident on many fronts
ranging from high-density cloud servers to mobile devices. During the past
decade OS-level virtualization has emerged as a new, efficient approach for
virtualization, with implementations in multiple different Unix-based systems.
Despite its popularity, there has been no systematic study of OS-level
virtualization from the point of view of security. In this report, we conduct a
comparative study of several OS-level virtualization systems, discuss their
security and identify some gaps in current solutions.
"
195,Faults in Linux 2.6,"  In August 2011, Linux entered its third decade. Ten years before, Chou et al.
published a study of faults found by applying a static analyzer to Linux
versions 1.0 through 2.4.1. A major result of their work was that the drivers
directory contained up to 7 times more of certain kinds of faults than other
directories. This result inspired numerous efforts on improving the reliability
of driver code. Today, Linux is used in a wider range of environments, provides
a wider range of services, and has adopted a new development and release model.
What has been the impact of these changes on code quality? To answer this
question, we have transported Chou et al.'s experiments to all versions of
Linux 2.6; released between 2003 and 2011. We find that Linux has more than
doubled in size during this period, but the number of faults per line of code
has been decreasing. Moreover, the fault rate of drivers is now below that of
other directories, such as arch. These results can guide further development
and research efforts for the decade to come. To allow updating these results as
Linux evolves, we define our experimental protocol and make our checkers
available.
"
196,Assessment of Response Time for New Multi Level Feedback Queue Scheduler,"  Response time is one of the characteristics of scheduler, happens to be a
prominent attribute of any CPU scheduling algorithm. The proposed New Multi
Level Feedback Queue [NMLFQ] Scheduler is compared with dynamic, real time,
Dependent Activity Scheduling Algorithm (DASA) and Lockes Best Effort
Scheduling Algorithm (LBESA). We abbreviated beneficial result of NMLFQ
scheduler in comparison with dynamic best effort schedulers with respect to
response time.
"
197,"Making FPGAs Accessible to Scientists and Engineers as Domain Expert
  Software Programmers with LabVIEW","  In this paper we present a graphical programming framework, LabVIEW, and
associated language and libraries, as well as programming techniques and
patterns that we have found useful in making FPGAs accessible to scientists and
engineers as domain expert software programmers.
"
198,"Rank-Aware Dynamic Migrations and Adaptive Demotions for DRAM Power
  Management","  Modern DRAM architectures allow a number of low-power states on individual
memory ranks for advanced power management. Many previous studies have taken
advantage of demotions on low-power states for energy saving. However, most of
the demotion schemes are statically performed on a limited number of
pre-selected low-power states, and are suboptimal for different workloads and
memory architectures. Even worse, the idle periods are often too short for
effective power state transitions, especially for memory intensive
applications. Wrong decisions on power state transition incur significant
energy and delay penalties. In this paper, we propose a novel memory system
design named RAMZzz with rank-aware energy saving optimizations including
dynamic page migrations and adaptive demotions. Specifically, we group the
pages with similar access locality into the same rank with dynamic page
migrations. Ranks have their hotness: hot ranks are kept busy for high
utilization and cold ranks can have more lengthy idle periods for power state
transitions. We further develop adaptive state demotions by considering all
low-power states for each rank and a prediction model to estimate the
power-down timeout among states. We experimentally compare our algorithm with
other energy saving policies with cycle-accurate simulation. Experiments with
benchmark workloads show that RAMZzz achieves significant improvement on
energy-delay2 and energy consumption over other energy saving techniques.
"
199,"Proceedings 2014 International Workshop on Advanced Intrusion Detection
  and Prevention","  This volume contains the proceedings of the 2014 International Advanced
Intrusion Detection and Prevention (AIDP'14) Workshop, held in Marrakesh,
Morocco, on the 5th of June 2014, in conjunction with the 29th IFIP TC-11 SEC
2014 International Conference. It includes a revised version of the papers
selected for presentation at the work- shop.
"
200,"Mining Block I/O Traces for Cache Preloading with Sparse Temporal
  Non-parametric Mixture of Multivariate Poisson","  Existing caching strategies, in the storage domain, though well suited to
exploit short range spatio-temporal patterns, are unable to leverage long-range
motifs for improving hitrates. Motivated by this, we investigate novel Bayesian
non-parametric modeling(BNP) techniques for count vectors, to capture long
range correlations for cache preloading, by mining Block I/O traces. Such
traces comprise of a sequence of memory accesses that can be aggregated into
high-dimensional sparse correlated count vector sequences.
  While there are several state of the art BNP algorithms for clustering and
their temporal extensions for prediction, there has been no work on exploring
these for correlated count vectors. Our first contribution addresses this gap
by proposing a DP based mixture model of Multivariate Poisson (DP-MMVP) and its
temporal extension(HMM-DP-MMVP) that captures the full covariance structure of
multivariate count data. However, modeling full covariance structure for count
vectors is computationally expensive, particularly for high dimensional data.
Hence, we exploit sparsity in our count vectors, and as our main contribution,
introduce the Sparse DP mixture of multivariate Poisson(Sparse-DP-MMVP),
generalizing our DP-MMVP mixture model, also leading to more efficient
inference. We then discuss a temporal extension to our model for cache
preloading.
  We take the first step towards mining historical data, to capture long range
patterns in storage traces for cache preloading. Experimentally, we show a
dramatic improvement in hitrates on benchmark traces and lay the groundwork for
further research in storage domain to reduce latencies using data mining
techniques to capture long range motifs.
"
201,Sprobes: Enforcing Kernel Code Integrity on the TrustZone Architecture,"  Many smartphones now deploy conventional operating systems, so the rootkit
attacks so prevalent on desktop and server systems are now a threat to
smartphones. While researchers have advocated using virtualization to detect
and prevent attacks on operating systems (e.g., VM introspection and trusted
virtual domains), virtualization is not practical on smartphone systems due to
the lack of virtualization support and/or the expense of virtualization.
Current smartphone processors do have hardware support for running a protected
environment, such as the ARM TrustZone extensions, but such hardware does not
control the operating system operations sufficiently to enable VM
introspection. In particular, a conventional operating system running with
TrustZone still retains full control of memory management, which a rootkit can
use to prevent traps on sensitive instructions or memory accesses necessary for
effective introspection. In this paper, we present SPROBES, a novel primitive
that enables introspection of operating systems running on ARM TrustZone
hardware. Using SPROBES, an introspection mechanism protected by TrustZone can
instrument individual operating system instructions of its choice, receiving an
unforgeable trap whenever any SPROBE is executed. The key challenge in
designing SPROBES is preventing the rootkit from removing them, but we identify
a set of five invariants whose enforcement is sufficient to restrict rootkits
to execute only approved, SPROBE-injected kernel code. We implemented a
proof-of-concept version of SPROBES for the ARM Fast Models emulator,
demonstrating that in Linux kernel 2.6.38, only 12 SPROBES are sufficient to
enforce all five of these invariants. With SPROBES we show that it is possible
to leverage the limited TrustZone extensions to limit conventional kernel
execution to approved code comprehensively.
"
202,A First Look at Firefox OS Security,"  With Firefox OS, Mozilla is making a serious push for an HTML5-based mobile
platform. In order to assuage security concerns over providing hardware access
to web applications, Mozilla has introduced a number of mechanisms that make
the security landscape of Firefox OS distinct from both the desktop web and
other mobile operating systems. From an application security perspective, the
two most significant of these mechanisms are the the introduction of a default
Content Security Policy and code review in the market. This paper describes how
lightweight static analysis can augment these mechanisms to find
vulnerabilities which have otherwise been missed. We provide examples of
privileged applications in the market that contain vulnerabilities that can be
automatically detected.
  In addition to these findings, we show some of the challenges that occur when
desktop software is repurposed for a mobile operating system. In particular, we
argue that the caching of certificate overrides across applications--a known
problem in Firefox OS--generates a counter-intuitive user experience that
detracts from the security of the system.
"
203,Glider: A GPU Library Driver for Improved System Security,"  Legacy device drivers implement both device resource management and
isolation. This results in a large code base with a wide high-level interface
making the driver vulnerable to security attacks. This is particularly
problematic for increasingly popular accelerators like GPUs that have large,
complex drivers. We solve this problem with library drivers, a new driver
architecture. A library driver implements resource management as an untrusted
library in the application process address space, and implements isolation as a
kernel module that is smaller and has a narrower lower-level interface (i.e.,
closer to hardware) than a legacy driver. We articulate a set of device and
platform hardware properties that are required to retrofit a legacy driver into
a library driver. To demonstrate the feasibility and superiority of library
drivers, we present Glider, a library driver implementation for two GPUs of
popular brands, Radeon and Intel. Glider reduces the TCB size and attack
surface by about 35% and 84% respectively for a Radeon HD 6450 GPU and by about
38% and 90% respectively for an Intel Ivy Bridge GPU. Moreover, it incurs no
performance cost. Indeed, Glider outperforms a legacy driver for applications
requiring intensive interactions with the device driver, such as applications
using the OpenGL immediate mode API.
"
204,"A Case Study: Task Scheduling Methodologies for High Speed Computing
  Systems","  High Speed computing meets ever increasing real-time computational demands
through the leveraging of flexibility and parallelism. The flexibility is
achieved when computing platform designed with heterogeneous resources to
support multifarious tasks of an application where as task scheduling brings
parallel processing. The efficient task scheduling is critical to obtain
optimized performance in heterogeneous computing Systems (HCS). In this paper,
we brought a review of various application scheduling models which provide
parallelism for homogeneous and heterogeneous computing systems. In this paper,
we made a review of various scheduling methodologies targeted to high speed
computing systems and also prepared summary chart. The comparative study of
scheduling methodologies for high speed computing systems has been carried out
based on the attributes of platform & application as well. The attributes are
execution time, nature of task, task handling capability, type of host &
computing platform. Finally a summary chart has been prepared and it
demonstrates that the need of developing scheduling methodologies for
Heterogeneous Reconfigurable Computing Systems (HRCS) which is an emerging high
speed computing platform for real time applications.
"
205,"k2U: A General Framework from k-Point Effective Schedulability Analysis
  to Utilization-Based Tests","  To deal with a large variety of workloads in different application domains in
real-time embedded systems, a number of expressive task models have been
developed. For each individual task model, researchers tend to develop
different types of techniques for deriving schedulability tests with different
computation complexity and performance. In this paper, we present a general
schedulability analysis framework, namely the k2U framework, that can be
potentially applied to analyze a large set of real-time task models under any
fixed-priority scheduling algorithm, on both uniprocessor and multiprocessor
scheduling. The key to k2U is a k-point effective schedulability test, which
can be viewed as a ""blackbox"" interface. For any task model, if a corresponding
k-point effective schedulability test can be constructed, then a sufficient
utilization-based test can be automatically derived. We show the generality of
k2U by applying it to different task models, which results in new and improved
tests compared to the state-of-the-art.
  Analogously, a similar concept by testing only k points with a different
formulation has been studied by us in another framework, called k2Q, which
provides quadratic bounds or utilization bounds based on a different
formulation of schedulability test. With the quadratic and hyperbolic forms,
k2Q and k2U frameworks can be used to provide many quantitive features to be
measured, like the total utilization bounds, speed-up factors, etc., not only
for uniprocessor scheduling but also for multiprocessor scheduling. These
frameworks can be viewed as a ""blackbox"" interface for schedulability tests and
response-time analysis.
"
206,OS-level Failure Injection with SystemTap,"  Failure injection in distributed systems has been an important issue to
experiment with robust, resilient distributed systems. In order to reproduce
real-life conditions, parts of the application must be killed without letting
the operating system close the existing network communications in a ""clean""
way. When a process is simply killed, the OS closes them. SystemTap is a an
infrastructure that probes the Linux kernel's internal calls. If processes are
killed at kernel-level, they can be destroyed without letting the OS do
anything else. In this paper, we present a kernel-level failure injection
system based on SystemTap. We present how it can be used to implement
deterministic and probabilistic failure scenarios.
"
207,"Protecting Memory-Performance Critical Sections in Soft Real-Time
  Applications","  Soft real-time applications such as multimedia applications often show bursty
memory access patterns---regularly requiring a high memory bandwidth for a
short duration of time. Such a period is often critical for timely data
processing. Hence, we call it a memory-performance critical section.
Unfortunately, in multicore architecture, non-real-time applications on
different cores may also demand high memory bandwidth at the same time, which
can substantially increase the time spent on the memory performance critical
sections.
  In this paper, we present BWLOCK, user-level APIs and a memory bandwidth
control mechanism that can protect such memory performance critical sections of
soft real-time applications. BWLOCK provides simple lock like APIs to declare
memory-performance critical sections. If an application enters a
memory-performance critical section, the memory bandwidth control system then
dynamically limit other cores' memory access rates to protect memory
performance of the application until the critical section finishes.
  From case studies with real-world soft real-time applications, we found (1)
such memory-performance critical sections do exist and are often easy to
identify; and (2) applying BWLOCK for memory critical sections significantly
improve performance of the soft real-time applications at a small or no cost in
throughput of non real-time applications.
"
208,Garbage Collection Techniques for Flash-Resident Page-Mapping FTLs,"  Storage devices based on flash memory have replaced hard disk drives (HDDs)
due to their superior performance, increasing density, and lower power
consumption. Unfortunately, flash memory is subject to challenging
idiosyncrasies like erase-before-write and limited block lifetime. These
constraints are handled by a flash translation layer (FTL), which performs
out-of-place updates, wear-leveling and garbage-collection behind the scene,
while offering the application a virtualization of the physical address space.
  A class of relevant FTLs employ a flash-resident page-associative mapping
table from logical to physical addresses, with a smaller RAM-resident cache for
frequently mapped entries. In this paper, we address the problem of performing
garbage-collection under such FTLs. We observe two problems. Firstly,
maintaining the metadata needed to perform garbage-collection under these
schemes is problematic, because at write-time we do not necessarily know the
physical address of the before-image. Secondly, the size of this metadata must
remain small, because it makes RAM unavailable for caching frequently accessed
entries. We propose two complementary techniques, called Lazy Gecko and
Logarithmic Gecko, which address these issues. Lazy Gecko works well when RAM
is plentiful enough to store the GC metadata. Logarithmic Gecko works well when
RAM isn't plentiful and efficiently stores the GC metadata in flash. Thus,
these techniques are applicable to a wide range of flash devices with varying
amounts of embedded RAM.
"
209,Survey of Operating Systems for the IoT Environment,"  This paper is a comprehensive survey of the various operating systems
available for the Internet of Things environment. At first the paper introduces
the various aspects of the operating systems designed for the IoT environment
where resource constraint poses a huge problem for the operation of the general
OS designed for the various computing devices. The latter part of the paper
describes the various OS available for the resource constraint IoT environment
along with the various platforms each OS supports, the software development
kits available for the development of applications in the respective OS along
with the various protocols implemented in these OS for the purpose of
communication and networking.
"
210,"RIOT OS Paves the Way for Implementation of High-Performance MAC
  Protocols","  Implementing new, high-performance MAC protocols requires real-time features,
to be able to synchronize correctly between different unrelated devices. Such
features are highly desirable for operating wireless sensor networks (WSN) that
are designed to be part of the Internet of Things (IoT). Unfortunately, the
operating systems commonly used in this domain cannot provide such features. On
the other hand, ""bare-metal"" development sacrifices portability, as well as the
mul-titasking abilities needed to develop the rich applications that are useful
in the domain of the Internet of Things. We describe in this paper how we
helped solving these issues by contributing to the development of a port of
RIOT OS on the MSP430 microcontroller, an architecture widely used in
IoT-enabled motes. RIOT OS offers rich and advanced real-time features,
especially the simultaneous use of as many hardware timers as the underlying
platform (microcontroller) can offer. We then demonstrate the effectiveness of
these features by presenting a new implementation, on RIOT OS, of S-CoSenS, an
efficient MAC protocol that uses very low processing power and energy.
"
211,The Influence of Malloc Placement on TSX Hardware Transactional Memory,"  The hardware transactional memory (HTM) implementation in Intel's i7-4770
""Haswell"" processor tracks the transactional read-set in the L1 (level-1), L2
(level-2) and L3 (level-3) caches and the write-set in the L1 cache.
Displacement or eviction of read-set entries from the cache hierarchy or
write-set entries from the L1 results in abort. We show that the placement
policies of dynamic storage allocators -- such as those found in common
""malloc"" implementations -- can influence the L1 conflict miss rate in the L1.
Conflict misses -- sometimes called mapping misses -- arise because of less
than ideal associativity and represent imbalanced distribution of active memory
blocks over the set of available L1 indices. Under transactional execution
conflict misses may manifest as aborts, representing wasted or futile effort
instead of a simple stall as would occur in normal execution mode.
  Furthermore, when HTM is used for transactional lock elision (TLE),
persistent aborts arising from conflict misses can force the offending thread
through the so-called ""slow path"". The slow path is undesirable as the thread
must acquire the lock and run the critical section in normal execution mode,
precluding the concurrent execution of threads in the ""fast path"" that monitor
that same lock and run their critical sections in transactional mode. For a
given lock, multiple threads can concurrently use the transactional fast path,
but at most one thread can use the non-transactional slow path at any given
time. Threads in the slow path preclude safe concurrent fast path execution.
Aborts rising from placement policies and L1 index imbalance can thus result in
loss of concurrency and reduced aggregate throughput.
"
212,Evaluating Dynamic File Striping For Lustre,"  We define dynamic striping as the ability to assign different Lustre striping
characteristics to contiguous segments of a file as it grows. In this paper, we
evaluate the effects of dynamic striping using a watermark-based strategy where
the stripe count or width is increased once a file's size exceeds one of the
chosen watermarks. To measure the performance of this strategy we used a
modified version of the IOR benchmark, a netflow analysis workload, and the
blastn algorithm from NCBI BLAST. The results indicate that dynamic striping is
beneficial to tasks with unpredictable data file size and large sequential
reads, but are less conclusive for workloads with significant random read
phases.
"
213,Monitoring Extreme-scale Lustre Toolkit,"  We discuss the design and ongoing development of the Monitoring Extreme-scale
Lustre Toolkit (MELT), a unified Lustre performance monitoring and analysis
infrastructure that provides continuous, low-overhead summary information on
the health and performance of Lustre, as well as on-demand, in- depth problem
diagnosis and root-cause analysis. The MELT infrastructure leverages a
distributed overlay network to enable monitoring of center-wide Lustre
filesystems where clients are located across many network domains. We preview
interactive command-line utilities that help administrators and users to
observe Lustre performance at various levels of resolution, from individual
servers or clients to whole filesystems, including job-level reporting.
Finally, we discuss our future plans for automating the root-cause analysis of
common Lustre performance problems.
"
214,Deterministically Deterring Timing Attacks in Deterland,"  The massive parallelism and resource sharing embodying today's cloud business
model not only exacerbate the security challenge of timing channels, but also
undermine the viability of defenses based on resource partitioning. We propose
hypervisor-enforced timing mitigation to control timing channels in cloud
environments. This approach closes ""reference clocks"" internal to the cloud by
imposing a deterministic view of time on guest code, and uses timing mitigators
to pace I/O and rate-limit potential information leakage to external observers.
Our prototype hypervisor is the first system to mitigate timing-channel leakage
across full-scale existing operating systems such as Linux and applications in
arbitrary languages. Mitigation incurs a varying performance cost, depending on
workload and tunable leakage-limiting parameters, but this cost may be
justified for security-critical cloud applications and data.
"
215,Improving Block-level Efficiency with scsi-mq,"  Current generation solid-state storage devices are exposing a new bottlenecks
in the SCSI and block layers of the Linux kernel, where IO throughput is
limited by lock contention, inefficient interrupt handling, and poor memory
locality. To address these limitations, the Linux kernel block layer underwent
a major rewrite with the blk-mq project to move from a single request queue to
a multi-queue model. The Linux SCSI subsystem rework to make use of this new
model, known as scsi-mq, has been merged into the Linux kernel and work is
underway for dm-multipath support in the upcoming Linux 4.0 kernel. These
pieces were necessary to make use of the multi-queue block layer in a Lustre
parallel filesystem with high availability requirements. We undertook adding
support of the 3.18 kernel to Lustre with scsi-mq and dm-multipath patches to
evaluate the potential of these efficiency improvements. In this paper we
evaluate the block-level performance of scsi-mq with backing storage hardware
representative of a HPC-targerted Lustre filesystem. Our findings show that
SCSI write request latency is reduced by as much as 13.6%. Additionally, when
profiling the CPU usage of our prototype Lustre filesystem, we found that CPU
idle time increased by a factor of 7 with Linux 3.18 and blk-mq as compared to
a standard 2.6.32 Linux kernel. Our findings demonstrate increased efficiency
of the multi-queue block layer even with disk-based caching storage arrays used
in existing parallel filesystems.
"
216,Taking back control of HPC file systems with Robinhood Policy Engine,"  Today, the largest Lustre file systems store billions of entries. On such
systems, classic tools based on namespace scanning become unusable. Operations
such as managing file lifetime, scheduling data copies, and generating overall
filesystem statistics become painful as they require collecting, sorting and
aggregating information for billions of records. Robinhood Policy Engine is an
open source software developed to address these challenges. It makes it
possible to schedule automatic actions on huge numbers of filesystem entries.
It also gives a synthetic understanding of file systems contents by providing
overall statistics about data ownership, age and size profiles. Even if it can
be used with any POSIX filesystem, Robinhood supports Lustre specific features
like OSTs, pools, HSM, ChangeLogs, and DNE. It implements specific support for
these features, and takes advantage of them to manage Lustre file systems
efficiently.
"
217,Development of a Burst Buffer System for Data-Intensive Applications,"  Modern parallel filesystems such as Lustre are designed to provide high,
scalable I/O bandwidth in response to growing I/O requirements; however, the
bursty I/O characteristics of many data-intensive scientific applications make
it difficult for back-end parallel filesystems to efficiently handle I/O
requests. A burst buffer system, through which data can be temporarily buffered
via high-performance storage mediums, allows for gradual flushing of data to
back-end filesystems. In this paper, we explore issues surrounding the
development of a burst buffer system for data-intensive scientific
applications. Our initial results demonstrate that utilizing a burst buffer
system on top of the Lustre filesystem shows promise for dealing with the
intense I/O traffic generated by application checkpointing.
"
218,"Evaluate and Compare Two Utilization-Based Schedulability-Test
  Frameworks for Real-Time Systems","  This report summarizes two general frameworks, namely k2Q and k2U, that have
been recently developed by us. The purpose of this report is to provide
detailed evaluations and comparisons of these two frameworks. These two
frameworks share some similar characteristics, but they are useful for
different application cases. These two frameworks together provide
comprehensive means for the users to automatically convert the pseudo
polynomial-time tests (or even exponential-time tests) into polynomial-time
tests with closed mathematical forms. With the quadratic and hyperbolic forms,
k2Q and k2U frameworks can be used to provide many quantitive features to be
measured and evaluated, like the total utilization bounds, speed-up factors,
etc., not only for uniprocessor scheduling but also for multiprocessor
scheduling. These frameworks can be viewed as ""blackbox"" interfaces for
providing polynomial-time schedulability tests and response time analysis for
real-time applications. We have already presented their advantages for being
applied in some models in the previous papers. However, it was not possible to
present a more comprehensive comparison between these two frameworks. We hope
this report can help the readers and users clearly understand the difference of
these two frameworks, their unique characteristics, and their advantages. We
demonstrate their differences and properties by using the traditional sporadic
realtime task models in uniprocessor scheduling and multiprocessor global
scheduling.
"
219,A Survey Report on Operating Systems for Tiny Networked Sensors,"  Wireless sensor network (WSN) has attracted researchers worldwide to explore
the research opportunities, with application mainly in health monitoring,
industry automation, battlefields, home automation and environmental
monitoring. A WSN is highly resource constrained in terms of energy,
computation and memory. WSNs deployment ranges from the normal working
environment up to hostile and hazardous environment such as in volcano
monitoring and underground mines. These characteristics of WSNs hold additional
set of challenges in front of the operating system designer. The objective of
this survey is to highlight the features and weakness of the opearting system
available for WSNs, with the focus on the current application demands. The
paper also discusses the operating system design issues in terms of
architecture, programming model, scheduling and memory management and support
for real time applications.
"
220,Defending against malicious peripherals with Cinch,"  Malicious peripherals designed to attack their host computers are a growing
problem. Inexpensive and powerful peripherals that attach to plug-and-play
buses have made such attacks easy to mount. Making matters worse, commodity
operating systems lack coherent defenses, and users are often unaware of the
scope of the problem. We present Cinch, a pragmatic response to this threat.
Cinch uses virtualization to attach peripheral devices to a logically separate,
untrusted machine, and includes an interposition layer between the untrusted
machine and the protected one. This layer regulates interaction with devices
according to user-configured policies. Cinch integrates with existing OSes,
enforces policies that thwart real-world attacks, and has low overhead.
"
221,Reproducible and User-Controlled Software Environments in HPC with Guix,"  Support teams of high-performance computing (HPC) systems often find
themselves between a rock and a hard place: on one hand, they understandably
administrate these large systems in a conservative way, but on the other hand,
they try to satisfy their users by deploying up-to-date tool chains as well as
libraries and scientific software. HPC system users often have no guarantee
that they will be able to reproduce results at a later point in time, even on
the same system-software may have been upgraded, removed, or recompiled under
their feet, and they have little hope of being able to reproduce the same
software environment elsewhere. We present GNU Guix and the functional package
management paradigm and show how it can improve reproducibility and sharing
among researchers with representative use cases.
"
222,Optimize Unsynchronized Garbage Collection in an SSD Array,"  Solid state disks (SSDs) have advanced to outperform traditional hard drives
significantly in both random reads and writes. However, heavy random writes
trigger fre- quent garbage collection and decrease the performance of SSDs. In
an SSD array, garbage collection of individ- ual SSDs is not synchronized,
leading to underutilization of some of the SSDs.
  We propose a software solution to tackle the unsyn- chronized garbage
collection in an SSD array installed in a host bus adaptor (HBA), where
individual SSDs are exposed to an operating system. We maintain a long I/O
queue for each SSD and flush dirty pages intelligently to fill the long I/O
queues so that we hide the performance imbalance among SSDs even when there are
few parallel application writes. We further define a policy of select- ing
dirty pages to flush and a policy of taking out stale flush requests to reduce
the amount of data written to SSDs. We evaluate our solution in a real system.
Experi- ments show that our solution fully utilizes all SSDs in an array under
random write-heavy workloads. It improves I/O throughput by up to 62% under
random workloads of mixed reads and writes when SSDs are under active garbage
collection. It causes little extra data writeback and increases the cache hit
rate.
"
223,Cold Object Identification in the Java Virtual Machine,"  Many Java applications instantiate objects within the Java heap that are
persistent but seldom if ever referenced by the application. Examples include
strings, such as error messages, and collections of value objects that are
preloaded for fast access but they may include objects that are seldom
referenced. This paper describes a stack-based framework for detecting these
""cold"" objects at runtime, with a view to marshaling and sequestering them in
designated regions of the heap where they may be preferentially paged out to a
backing store, thereby freeing physical memory pages for occupation by more
active objects. Furthermore, we evaluate the correctness and efficiency of
stack-based approach with an Access Barrier. The experimental results from a
series of SPECjvm2008 benchmarks are presented.
"
224,"A Case Study on Covert Channel Establishment via Software Caches in
  High-Assurance Computing Systems","  Covert channels can be utilized to secretly deliver information from high
privileged processes to low privileged processes in the context of a
high-assurance computing system. In this case study, we investigate the
possibility of covert channel establishment via software caches in the context
of a framework for component-based operating systems. While component-based
operating systems offer security through the encapsulation of system service
processes, complete isolation of these processes is not reasonably feasible.
This limitation is practically demonstrated with our concept of a specific
covert timing channel based on file system caching. The stability of the covert
channel is evaluated and a methodology to disrupt the covert channel
transmission is presented. While these kinds of attacks are not limited to
high-assurance computing systems, our study practically demonstrates that even
security-focused computing systems with a minimal trusted computing base are
vulnerable for such kinds of attacks and careful design decisions are necessary
for secure operating system architectures.
"
225,"EOS: Automatic In-vivo Evolution of Kernel Policies for Better
  Performance","  Today's monolithic kernels often implement a small, fixed set of policies
such as disk I/O scheduling policies, while exposing many parameters to let
users select a policy or adjust the specific setting of the policy. Ideally,
the parameters exposed should be flexible enough for users to tune for good
performance, but in practice, users lack domain knowledge of the parameters and
are often stuck with bad, default parameter settings.
  We present EOS, a system that bridges the knowledge gap between kernel
developers and users by automatically evolving the policies and parameters in
vivo on users' real, production workloads. It provides a simple policy
specification API for kernel developers to programmatically describe how the
policies and parameters should be tuned, a policy cache to make in-vivo tuning
easy and fast by memorizing good parameter settings for past workloads, and a
hierarchical search engine to effectively search the parameter space.
Evaluation of EOS on four main Linux subsystems shows that it is easy to use
and effectively improves each subsystem's performance.
"
226,A Software-only Mechanism for Device Passthrough and Sharing,"  Network processing elements in virtual machines, also known as Network
Function Virtualization (NFV) often face CPU bottlenecks at the virtualization
interface. Even highly optimized paravirtual device interfaces fall short of
the throughput requirements of modern devices. Passthrough devices, together
with SR-IOV support for multiple device virtual functions (VF) and IOMMU
support, mitigate this problem somewhat, by allowing a VM to directly control a
device partition bypassing the virtualization stack. However, device
passthrough requires high-end (expensive and power-hungry) hardware, places
scalability limits on consolidation ratios, and does not support efficient
switching between multiple VMs on the same host.
  We present a paravirtual interface that securely exposes an I/O device
directly to the guest OS running inside the VM, and yet allows that device to
be securely shared among multiple VMs and the host. Compared to the best-known
paravirtualization interfaces, our paravirtual interface supports up to 2x
higher throughput, and is closer in performance to device passthrough. Unlike
device passthrough however, we do not require SR-IOV or IOMMU support, and
allow fine-grained dynamic resource allocation, significantly higher
consolidation ratios, and seamless VM migration. Our security mechanism is
based on a novel approach called dynamic binary opcode subtraction.
"
227,Virtualization Architecture for NoC-based Reconfigurable Systems,"  We propose a virtualization architecture for NoC-based reconfigurable
systems. The motivation of this work is to develop a service-oriented
architecture that includes Partial Reconfigurable Region as a Service (PRRaaS)
and Processing Element as a Service (PEaaS) for software applications.
According to the requirements of software applications, new PEs can be created
on-demand by (re)configuring the logic resource of the PRRs in the FPGA, while
the configured PEs can also be virtualized to support multiple application
tasks at the same time. As a result, such a two-level virtualization mechanism,
including the gate-level virtualization and the PE-level virtualization,
enables an SoC to be dynamically adapted to changing application requirements.
Therefore, more software applications can be performed, and system performance
can be further enhanced.
"
228,Folding a Tree into a Map,"  Analysis of the retrieval architecture of the highly influential UNIX file
system (\cite{Ritchie}\cite{multicsfs}) provides insight into design methods,
constraints, and possible alternatives. The basic architecture can be
understood in terms of function composition and recursion by anyone with some
mathematical maturity. Expertise in operating system coding or in any
specialized ""formal method"" is not required.
"
229,Multitasking Programming of OBDH Satellite Based On PC-104,"  On Board Data Handling (OBDH) has functions to monitor, control, acquire,
analyze, take a decision, and execute the command. OBDH should organize the
task between sub system. OBDH like a heart which has a vital function. Because
the function is seriously important therefore designing and implementing the
OBDH should be carefully, in order to have a good reliability. Many OBDHs have
been made to support the satellite mission using primitive programming. In
handling the data from various input, OBDH should always be available to all
sub systems, when the tasks are many, it is not easy to program using primitive
programming. Sometimes the data become corrupt because the data which come to
the OBDH is in the same time. Therefore it is required to have a way to handle
the data safely and also easy in programming perspective. In this research,
OBDH is programmed using multi tasking programming perspective has been
created. The Operating System (OS) has been implemented so that can run the
tasks simultaneously. The OS is prepared by configuring the Linux Kernel for
the specific processor, creating Root File System (RFS), installing the
BusyBox. In order to do the above method, preparing the environment in our
machine has been done, they are installing the Cross Tool Chain, U-Boot,
GNU-Linux Kernel Source etc. After that, programming using c code with
multitasking programming can be implemented. By using above method, it is found
that programming is easier and the corruption data because of reentrancy can be
minimized. Keywords- Operating System, PC-104, Kernel, C Programming
"
230,Energy-Efficient Scheduling for Homogeneous Multiprocessor Systems,"  We present a number of novel algorithms, based on mathematical optimization
formulations, in order to solve a homogeneous multiprocessor scheduling
problem, while minimizing the total energy consumption. In particular, for a
system with a discrete speed set, we propose solving a tractable linear
program. Our formulations are based on a fluid model and a global scheduling
scheme, i.e. tasks are allowed to migrate between processors. The new methods
are compared with three global energy/feasibility optimal workload allocation
formulations. Simulation results illustrate that our methods achieve both
feasibility and energy optimality and outperform existing methods for
constrained deadline tasksets. Specifically, the results provided by our
algorithm can achieve up to an 80% saving compared to an algorithm without a
frequency scaling scheme and up to 70% saving compared to a constant frequency
scaling scheme for some simulated tasksets. Another benefit is that our
algorithms can solve the scheduling problem in one step instead of using a
recursive scheme. Moreover, our formulations can solve a more general class of
scheduling problems, i.e. any periodic real-time taskset with arbitrary
deadline. Lastly, our algorithms can be applied to both online and offline
scheduling schemes.
"
231,"Characteristic specific prioritized dynamic average burst round robin
  scheduling for uniprocessor and multiprocessor environment","  CPU scheduling is one of the most crucial operations performed by operating
systems. Different conventional algorithms like FCFS, SJF, Priority, and RR
(Round Robin) are available for CPU Scheduling. The effectiveness of Priority
and Round Robin scheduling algorithm completely depends on selection of
priority features of processes and on the choice of time quantum. In this paper
a new CPU scheduling algorithm has been proposed, named as CSPDABRR
(Characteristic specific Prioritized Dynamic Average Burst Round Robin), that
uses seven priority features for calculating priority of processes and uses
dynamic time quantum instead of static time quantum used in RR. The performance
of the proposed algorithm is experimentally compared with traditional RR and
Priority scheduling algorithm in both uni-processor and multi-processor
environment. The results of our approach presented in this paper demonstrate
improved performance in terms of average waiting time, average turnaround time,
and optimal priority feature.
"
232,Proceedings Workshop on Models for Formal Analysis of Real Systems,"  This volume contains the proceedings of MARS 2015, the first workshop on
Models for Formal Analysis of Real Systems, held on November 23, 2015 in Suva,
Fiji, as an affiliated workshop of LPAR 2015, the 20th International Conference
on Logic for Programming, Artificial Intelligence and Reasoning.
  The workshop emphasises modelling over verification. It aims at discussing
the lessons learned from making formal methods for the verification and
analysis of realistic systems. Examples are:
  (1) Which formalism is chosen, and why?
  (2) Which abstractions have to be made and why?
  (3) How are important characteristics of the system modelled?
  (4) Were there any complications while modelling the system?
  (5) Which measures were taken to guarantee the accuracy of the model?
  We invited papers that present full models of real systems, which may lay the
basis for future comparison and analysis. An aim of the workshop is to present
different modelling approaches and discuss pros and cons for each of them.
Alternative formal descriptions of the systems presented at this workshop are
encouraged, which should foster the development of improved specification
formalisms.
"
233,Specifying a Realistic File System,"  We present the most interesting elements of the correctness specification of
BilbyFs, a performant Linux flash file system. The BilbyFs specification
supports asynchronous writes, a feature that has been overlooked by several
file system verification projects, and has been used to verify the correctness
of BilbyFs's fsync() C implementation. It makes use of nondeterminism to be
concise and is shallowly-embedded in higher-order logic.
"
234,"Controlled Owicki-Gries Concurrency: Reasoning about the Preemptible
  eChronos Embedded Operating System","  We introduce a controlled concurrency framework, derived from the
Owicki-Gries method, for describing a hardware interface in detail sufficient
to support the modelling and verification of small, embedded operating systems
(OS's) whose run-time responsiveness is paramount. Such real-time systems run
with interrupts mostly enabled, including during scheduling. That differs from
many other successfully modelled and verified OS's that typically reduce the
complexity of concurrency by running on uniprocessor platforms and by switching
interrupts off as much as possible. Our framework builds on the traditional
Owicki-Gries method, for its fine-grained concurrency is needed for
high-performance system code. We adapt it to support explicit concurrency
control, by providing a simple, faithful representation of the hardware
interface that allows software to control the degree of interleaving between
user code, OS code, interrupt handlers and a scheduler that controls context
switching. We then apply this framework to model the interleaving behavior of
the eChronos OS, a preemptible real-time OS for embedded micro-controllers. We
discuss the accuracy and usability of our approach when instantiated to model
the eChronos OS. Both our framework and the eChronos model are formalised in
the Isabelle/HOL theorem prover, taking advantage of the high level of
automation in modern reasoning tools.
"
235,TinyLFU: A Highly Efficient Cache Admission Policy,"  This paper proposes to use a frequency based cache admission policy in order
to boost the effectiveness of caches subject to skewed access distributions.
Given a newly accessed item and an eviction candidate from the cache, our
scheme decides, based on the recent access history, whether it is worth
admitting the new item into the cache at the expense of the eviction candidate.
  Realizing this concept is enabled through a novel approximate LFU structure
called TinyLFU, which maintains an approximate representation of the access
frequency of a large sample of recently accessed items. TinyLFU is very compact
and light-weight as it builds upon Bloom filter theory.
  We study the properties of TinyLFU through simulations of both synthetic
workloads as well as multiple real traces from several sources. These
simulations demonstrate the performance boost obtained by enhancing various
replacement policies with the TinyLFU eviction policy. Also, a new combined
replacement and eviction policy scheme nicknamed W-TinyLFU is presented.
W-TinyLFU is demonstrated to obtain equal or better hit-ratios than other state
of the art replacement policies on these traces. It is the only scheme to
obtain such good results on all traces.
"
236,Real-Time scheduling: from hard to soft real-time systems,"  Real-time systems are traditionally classified into hard real-time and soft
real-time: in the first category we have safety critical real-time systems
where missing a deadline can have catastrophic consequences, whereas in the
second class we find systems or which we need to optimise the Quality of
service provided to the user. However, the frontier between these two classes
is thinner than one may think, and many systems that were considered as hard
real-time in the past should now be reconsidered under a different light. In
this paper we shall first recall the fundamental notion of time-predictability
and criticality, in order to understand where the real-time deadlines that we
use in our theoretical models come from. We shall then introduce the model of a
soft real-time system and present one popular method for scheduling hard and
soft real-time tasks, the resource reservation framework. Finally, we shall
show how resource reservation techniques can be successfully applied to the
design of classical control systems, thus adding robustness to the system and
increasing resource utilisation and performance.
"
237,"Parallel and sequential reclaiming in multicore real-time global
  scheduling","  When integrating hard, soft and non-real-time tasks in general purpose
operating systems, it is necessary to provide temporal isolation so that the
timing properties of one task do not depend on the behaviour of the others.
However, strict budget enforcement can lead to inefficient use of the
computational resources in the presence of tasks with variable workload. Many
resource reclaiming algorithms have been proposed in the literature for single
processor scheduling, but not enough work exists for global scheduling in
multiprocessor systems. In this report, we propose two reclaiming algorithms
for multiprocessor global scheduling and we prove their correctness.
"
238,Research on Scalability of Operating Systems on Multicore Processors,"  Large number of cores and hardware resource sharing are two characteristics
on multicore processors, which bring new challenges for the design of operating
systems. How to locate and analyze the speedup restrictive factors in operating
systems, how to simulate and avoid the phenomenon that speedup decreases with
the number of cores because of lock contention (i.e., lock thrashing) and how
to avoid the contention of shared resources such as the last level cache are
key challenges for the operating system scalability research on multicore
systems.
"
239,Energy-aware Fixed-Priority Multi-core Scheduling for Real-time Systems,"  Multi-core processors are becoming more and more popular in embedded and
real-time systems. While fixed-priority scheduling with task-splitting in
real-time systems are widely applied, current approaches have not taken into
consideration energy-aware aspects such as dynamic voltage/frequency scheduling
(DVS). In this paper, we propose two strategies to apply dynamic voltage
scaling (DVS) to fixed-priority scheduling algorithms with task-splitting for
periodic real-time tasks on multi-core processors. The first strategy
determines voltage scales for each processor after scheduling (Static DVS),
which ensures all tasks meet the timing requirements on synchronization. The
second strategy adaptively determines the frequency of each task before
scheduling (Adaptive DVS) according to the total utilization of task-set and
number of cores available. The combination of frequency pre-allocation and
task-splitting makes it possible to maximize energy savings with DVS.
Simulation results show that it is possible to achieve significant energy
savings with DVS while preserving the schedulability requirements of real-time
schedulers for multi-core processors.
"
240,Mixed-Criticality Scheduling with I/O,"  This paper addresses the problem of scheduling tasks with different
criticality levels in the presence of I/O requests. In mixed-criticality
scheduling, higher criticality tasks are given precedence over those of lower
criticality when it is impossible to guarantee the schedulability of all tasks.
While mixed-criticality scheduling has gained attention in recent years, most
approaches typically assume a periodic task model. This assumption does not
always hold in practice, especially for real-time and embedded systems that
perform I/O. For example, many tasks block on I/O requests until devices signal
their completion via interrupts; both the arrival of interrupts and the waking
of blocked tasks can be aperiodic. In our prior work, we developed a scheduling
technique in the Quest real-time operating system, which integrates the
time-budgeted management of I/O operations with Sporadic Server scheduling of
tasks. This paper extends our previous scheduling approach with support for
mixed-criticality tasks and I/O requests on the same processing core. Results
show the effective schedulability of different task sets in the presence of I/O
requests is superior in our approach compared to traditional methods that
manage I/O using techniques such as Sporadic Servers.
"
241,Open Mobile API: Accessing the UICC on Android Devices,"  This report gives an overview of secure element integration into Android
devices. It focuses on the Open Mobile API as an open interface to access
secure elements from Android applications. The overall architecture of the Open
Mobile API is described and current Android devices are analyzed with regard to
the availability of this API. Moreover, this report summarizes our efforts of
reverse engineering the stock ROM of a Samsung Galaxy S3 in order to analyze
the integration of the Open Mobile API and the interface that is used to
perform APDU-based communication with the UICC (Universal Integrated Circuit
Card). It further provides a detailed explanation on how to integrate this
functionality into CyanogenMod (an after-market firmware for Android devices).
"
242,HyBIS: Windows Guest Protection through Advanced Memory Introspection,"  Effectively protecting the Windows OS is a challenging task, since most
implementation details are not publicly known. Windows has always been the main
target of malwares that have exploited numerous bugs and vulnerabilities.
Recent trusted boot and additional integrity checks have rendered the Windows
OS less vulnerable to kernel-level rootkits. Nevertheless, guest Windows
Virtual Machines are becoming an increasingly interesting attack target. In
this work we introduce and analyze a novel Hypervisor-Based Introspection
System (HyBIS) we developed for protecting Windows OSes from malware and
rootkits. The HyBIS architecture is motivated and detailed, while targeted
experimental results show its effectiveness. Comparison with related work
highlights main HyBIS advantages such as: effective semantic introspection,
support for 64-bit architectures and for latest Windows (8.x and 10), advanced
malware disabling capabilities. We believe the research effort reported here
will pave the way to further advances in the security of Windows OSes.
"
243,Powering the Internet of Things with RIOT: Why? How? What is RIOT?,"  The crucial importance of software platforms was highlighted by recent events
both at the political level (e.g. renewed calls for digital data and operating
system ""sovereignty"", following E. Snowden's revelations) and at the business
level (e.g. Android generated a new industry worth tens of billions of euros
yearly). In the Internet of Things, which is expected to generate business at
very large scale, but also to threaten even more individual privacy, such
aspects will be exacerbated. The need for an operating system like RIOT stems
from this context, and this short article outlines RIOT's main non-technical
aspects, as well as its key technical characteristics.
"
244,"An Implementation and Analysis of a Kernel Network Stack in Go with the
  CSP Style","  Modern operating system kernels are written in lower-level languages such as
C. Although the low-level functionalities of C are often useful within kernels,
they also give rise to several classes of bugs. Kernels written in higher level
languages avoid many of these potential problems, at the possible cost of
decreased performance. This research evaluates the advantages and disadvantages
of a kernel written in a higher level language. To do this, the network stack
subsystem of the kernel was implemented in Go with the Communicating Sequential
Processes (CSP) style. Go is a high-level programming language that supports
the CSP style, which recommends splitting large tasks into several smaller ones
running in independent ""threads"". Modules for the major networking protocols,
including Ethernet, ARP, IPv4, ICMP, UDP, and TCP, were implemented. In this
study, the implemented Go network stack, called GoNet, was compared to a
representative network stack written in C. The GoNet code is more readable and
generally performs better than that of its C stack counterparts. From this, it
can be concluded that Go with CSP style is a viable alternative to C for the
language of kernel implementations.
"
245,AuDroid: Preventing Attacks on Audio Channels in Mobile Devices,"  Voice control is a popular way to operate mobile devices, enabling users to
communicate requests to their devices. However, adversaries can leverage voice
control to trick mobile devices into executing commands to leak secrets or to
modify critical information. Contemporary mobile operating systems fail to
prevent such attacks because they do not control access to the speaker at all
and fail to control when untrusted apps may use the microphone, enabling
authorized apps to create exploitable communication channels. In this paper, we
propose a security mechanism that tracks the creation of audio communication
channels explicitly and controls the information flows over these channels to
prevent several types of attacks.We design and implement AuDroid, an extension
to the SELinux reference monitor integrated into the Android operating system
for enforcing lattice security policies over the dynamically changing use of
system audio resources. To enhance flexibility, when information flow errors
are detected, the device owner, system apps and services are given the
opportunity to resolve information flow errors using known methods, enabling
AuDroid to run many configurations safely. We evaluate our approach on 17
widely-used apps that make extensive use of the microphone and speaker, finding
that AuDroid prevents six types of attack scenarios on audio channels while
permitting all 17 apps to run effectively. AuDroid shows that it is possible to
prevent attacks using audio channels without compromising functionality or
introducing significant performance overhead.
"
246,"Isolate First, Then Share: a New OS Architecture for Datacenter
  Computing","  This paper presents the ""isolate first, then share"" OS model in which the
processor cores, memory, and devices are divided up between disparate OS
instances and a new abstraction, subOS, is proposed to encapsulate an OS
instance that can be created, destroyed, and resized on-the-fly. The intuition
is that this avoids shared kernel states between applications, which in turn
reduces performance loss caused by contention. We decompose the OS into the
supervisor and several subOSes running at the same privilege level: a subOS
directly manages physical resources, while the supervisor can create, destroy,
resize a subOS on-the-fly. The supervisor and subOSes have few state sharing,
but fast inter-subOS communication mechanisms are provided on demand.
  We present the first implementation, RainForest, which supports unmodified
Linux binaries. Our comprehensive evaluation shows RainForest outperforms Linux
with four different kernels, LXC, and Xen in terms of worst-case and average
performance most of time when running a large number of benchmarks. The source
code is available soon.
"
247,Aware: Controlling App Access to I/O Devices on Mobile Platforms,"  Smartphones' cameras, microphones, and device displays enable users to
capture and view memorable moments of their lives. However, adversaries can
trick users into authorizing malicious apps that exploit weaknesses in current
mobile platforms to misuse such on-board I/O devices to stealthily capture
photos, videos, and screen content without the users' consent. Contemporary
mobile operating systems fail to prevent such misuse of I/O devices by
authorized apps due to lack of binding between users' interactions and accesses
to I/O devices performed by these apps. In this paper, we propose Aware, a
security framework for authorizing app requests to perform operations using I/O
devices, which binds app requests with user intentions to make all uses of
certain I/O devices explicit. We evaluate our defense mechanisms through
laboratory-based experimentation and a user study, involving 74 human subjects,
whose ability to identify undesired operations targeting I/O devices increased
significantly. Without Aware, only 18% of the participants were able to
identify attacks from tested RAT apps. Aware systematically blocks all the
attacks in absence of user consent and supports users in identifying 82% of
social-engineering attacks tested to hijack approved requests, including some
more sophisticated forms of social engineering not yet present in available
RATs. Aware introduces only 4.79% maximum performance overhead over operations
targeting I/O devices. Aware shows that a combination of system defenses and
user interface can significantly strengthen defenses for controlling the use of
on-board I/O devices.
"
248,"Do the Hard Stuff First: Scheduling Dependent Computations in
  Data-Analytics Clusters","  We present a scheduler that improves cluster utilization and job completion
times by packing tasks having multi-resource requirements and
inter-dependencies. While the problem is algorithmically very hard, we achieve
near-optimality on the job DAGs that appear in production clusters at a large
enterprise and in benchmarks such as TPC-DS. A key insight is that carefully
handling the long-running tasks and those with tough-to-pack resource needs
will produce good-enough schedules. However, which subset of tasks to treat
carefully is not clear (and intractable to discover). Hence, we offer a search
procedure that evaluates various possibilities and outputs a preferred schedule
order over tasks. An online component enforces the schedule orders desired by
the various jobs running on the cluster. In addition, it packs tasks, overbooks
the fungible resources and guarantees bounded unfairness for a variety of
desirable fairness schemes. Relative to the state-of-the art schedulers, we
speed up 50% of the jobs by over 30% each.
"
249,"An optimized round robin cpu scheduling algorithm with dynamic time
  quantum","  CPU scheduling is one of the most crucial operations performed by operating
system. Different algorithms are available for CPU scheduling amongst them RR
(Round Robin) is considered as optimal in time shared environment. The
effectiveness of Round Robin completely depends on the choice of time quantum.
In this paper a new CPU scheduling algorithm has been proposed, named as DABRR
(Dynamic Average Burst Round Robin). That uses dynamic time quantum instead of
static time quantum used in RR. The performance of the proposed algorithm is
experimentally compared with traditional RR and some existing variants of RR.
The results of our approach presented in this paper demonstrate improved
performance in terms of average waiting time, average turnaround time, and
context switching.
"
250,"A Qualitative Comparison of MPSoC Mobile and Embedded Virtualization
  Techniques","  Virtualization is generally adopted in server and desktop environments to
provide for fault tolerance, resource management, and energy efficiency.
Virtualization enables parallel execution of multiple operating systems (OSs)
while sharing the hardware resources. Virtualization was previously not deemed
as feasible technology for mobile and embedded devices due to their limited
processing and memory resource. However, the enterprises are advocating Bring
Your Own Device (BYOD) applications that enable co-existence of heterogeneous
OSs on a single mobile device. Moreover, embedded device require virtualization
for logical isolation of secure and general purpose OSs on a single device. In
this paper, we investigate the processor architectures in the mobile and
embedded space while examining their formal visualizability. We also compare
the virtualization solutions enabling coexistence of multiple OSs in Multicore
Processor System-on-Chip (MPSoC) mobile and embedded systems. We advocate that
virtualization is necessary to manage resource in MPSoC designs and to enable
BYOD, security, and logical isolation use cases.
"
251,The Design of the NetBSD I/O Subsystems,"  This book describes the source code of the NetBSD Operating System Release
1.6 in SUN UltraSPARC 64-bit platform by annotating related excerpts from
references and user manuals on the NetBSD Operating System. The goal of this
book is to provide necessary information to understand the operation and the
implementation of I/O subsystems in the kernel as well as to design and
implement a new filesystem on the NetBSD platform.
"
252,It's Time: OS Mechanisms for Enforcing Asymmetric Temporal Integrity,"  Mixed-criticality systems combine real-time components of different levels of
criticality, i.e. severity of failure, on the same processor, in order to
obtain good resource utilisation. They must guarantee deadlines of
highly-critical tasks at the expense of lower-criticality ones in the case of
overload. Present operating systems provide inadequate support for this kind of
system, which is of growing importance in avionics and other verticals. We
present an approach that provides the required asymmetric integrity and its
implementation in the high-assurance seL4 microkernel.
"
253,"Feedback Scheduling for Energy-Efficient Real-Time Homogeneous
  Multiprocessor Systems","  Real-time scheduling algorithms proposed in the literature are often based on
worst-case estimates of task parameters. The performance of an open-loop scheme
can be degraded significantly if there are uncertainties in task parameters,
such as the execution times of the tasks. Therefore, to cope with such a
situation, a closed-loop scheme, where feedback is exploited to adjust the
system parameters, can be applied. We propose an optimal control framework that
takes advantage of feeding back information of finished tasks to solve a
real-time multiprocessor scheduling problem with uncertainty in task execution
times, with the objective of minimizing the total energy consumption.
Specifically, we propose a linear programming based algorithm to solve a
workload partitioning problem and adopt McNaughton's wrap around algorithm to
find the task execution order. The simulation results illustrate that our
feedback scheduling algorithm can save energy by as much as 40% compared to an
open-loop method for two processor models, i.e. a PowerPC 405LP and an XScale
processor.
"
254,A Note on the Period Enforcer Algorithm for Self-Suspending Tasks,"  The period enforcer algorithm for self-suspending real-time tasks is a
technique for suppressing the ""back-to-back"" scheduling penalty associated with
deferred execution. Originally proposed in 1991, the algorithm has attracted
renewed interest in recent years. This note revisits the algorithm in the light
of recent developments in the analysis of self-suspending tasks, carefully
re-examines and explains its underlying assumptions and limitations, and points
out three observations that have not been made in the literature to date: (i)
period enforcement is not strictly superior (compared to the base case without
enforcement) as it can cause deadline misses in self-suspending task sets that
are schedulable without enforcement; (ii) to match the assumptions underlying
the analysis of the period enforcer, a schedulability analysis of
self-suspending tasks subject to period enforcement requires a task set
transformation for which no solution is known in the general case, and which is
subject to exponential time complexity (with current techniques) in the limited
case of a single self-suspending task; and (iii) the period enforcer algorithm
is incompatible with all existing analyses of suspension-based locking
protocols, and can in fact cause ever-increasing suspension times until a
deadline is missed.
"
255,Scalability of VM Provisioning Systems,"  Virtual machines and virtualized hardware have been around for over half a
century. The commoditization of the x86 platform and its rapidly growing
hardware capabilities have led to recent exponential growth in the use of
virtualization both in the enterprise and high performance computing (HPC). The
startup time of a virtualized environment is a key performance metric for high
performance computing in which the runtime of any individual task is typically
much shorter than the lifetime of a virtualized service in an enterprise
context. In this paper, a methodology for accurately measuring the startup
performance on an HPC system is described. The startup performance overhead of
three of the most mature, widely deployed cloud management frameworks
(OpenStack, OpenNebula, and Eucalyptus) is measured to determine their
suitability for workloads typically seen in an HPC environment. A 10x
performance difference is observed between the fastest (Eucalyptus) and the
slowest (OpenNebula) framework. This time difference is primarily due to delays
in waiting on networking in the cloud-init portion of the startup. The
methodology and measurements presented should facilitate the optimization of
startup across a variety of virtualization environments.
"
256,"Energy-Efficient Real-Time Scheduling for Two-Type Heterogeneous
  Multiprocessors","  We propose three novel mathematical optimization formulations that solve the
same two-type heterogeneous multiprocessor scheduling problem for a real-time
taskset with hard constraints. Our formulations are based on a global
scheduling scheme and a fluid model. The first formulation is a mixed-integer
nonlinear program, since the scheduling problem is intuitively considered as an
assignment problem. However, by changing the scheduling problem to first
determine a task workload partition and then to find the execution order of all
tasks, the computation time can be significantly reduced. Specifically, the
workload partitioning problem can be formulated as a continuous nonlinear
program for a system with continuous operating frequency, and as a continuous
linear program for a practical system with a discrete speed level set. The task
ordering problem can be solved by an algorithm with a complexity that is linear
in the total number of tasks. The work is evaluated against existing global
energy/feasibility optimal workload allocation formulations. The results
illustrate that our algorithms are both feasibility optimal and energy optimal
for both implicit and constrained deadline tasksets. Specifically, our
algorithm can achieve up to 40% energy saving for some simulated tasksets with
constrained deadlines. The benefit of our formulation compared with existing
work is that our algorithms can solve a more general class of scheduling
problems due to incorporating a scheduling dynamic model in the formulations
and allowing for a time-varying speed profile. Moreover, our algorithms can be
applied to both online and offline scheduling schemes.
"
257,System-level Scalable Checkpoint-Restart for Petascale Computing,"  Fault tolerance for the upcoming exascale generation has long been an area of
active research. One of the components of a fault tolerance strategy is
checkpointing. Petascale-level checkpointing is demonstrated through a new
mechanism for virtualization of the InfiniBand UD (unreliable datagram) mode,
and for updating the remote address on each UD-based send, due to lack of a
fixed peer. Note that InfiniBand UD is required to support modern MPI
implementations. An extrapolation from the current results to future SSD-based
storage systems provides evidence that the current approach will remain
practical in the exascale generation. This transparent checkpointing approach
is evaluated using a framework of the DMTCP checkpointing package. Results are
shown for HPCG (linear algebra), NAMD (molecular dynamics), and the NAS NPB
benchmarks. In tests up to 32,752 MPI processes on 32,752 CPU cores,
checkpointing of a computation with a 38 TB memory footprint in 11 minutes is
demonstrated. Runtime overhead is reduced to less than 1%. The approach is also
evaluated across three widely used MPI implementations.
"
258,"TREES: A CPU/GPU Task-Parallel Runtime with Explicit Epoch
  Synchronization","  We have developed a task-parallel runtime system, called TREES, that is
designed for high performance on CPU/GPU platforms. On platforms with multiple
CPUs, Cilk's ""work-first"" principle underlies how task-parallel applications
can achieve performance, but work-first is a poor fit for GPUs. We build upon
work-first to create the ""work-together"" principle that addresses the specific
strengths and weaknesses of GPUs. The work-together principle extends
work-first by stating that (a) the overhead on the critical path should be paid
by the entire system at once and (b) work overheads should be paid
co-operatively. We have implemented the TREES runtime in OpenCL, and we
experimentally evaluate TREES applications on a CPU/GPU platform.
"
259,SandBlaster: Reversing the Apple Sandbox,"  In order to limit the damage of malware on Mac OS X and iOS, Apple uses
sandboxing, a kernel-level security layer that provides tight constraints for
system calls. Particularly used for Apple iOS, sandboxing prevents apps from
executing potentially dangerous actions, by defining rules in a sandbox
profile. Investigating Apple's built-in sandbox profiles is difficult as they
are compiled and stored in binary format. We present SandBlaster, a software
bundle that is able to reverse/decompile Apple binary sandbox profiles to their
original human readable SBPL (SandBox Profile Language) format. We use
SandBlaster to reverse all built-in Apple iOS binary sandbox profiles for iOS
7, 8 and 9. Our tool is, to the best of our knowledge, the first to provide a
full reversing of the Apple sandbox, shedding light into the inner workings of
Apple sandbox profiles and providing essential support for security researchers
and professionals interested in Apple security mechanisms.
"
260,POLYPATH: Supporting Multiple Tradeoffs for Interaction Latency,"  Modern mobile systems use a single input-to-display path to serve all
applications. In meeting the visual goals of all applications, the path has a
latency inadequate for many important interactions. To accommodate the
different latency requirements and visual constraints by different
interactions, we present POLYPATH, a system design in which application
developers (and users) can choose from multiple path designs for their
application at any time. Because a POLYPATH system asks for two or more path
designs, we present a novel fast path design, called Presto. Presto reduces
latency by judiciously allowing frame drops and tearing.
  We report an Android 5-based prototype of POLYPATH with two path designs:
Android legacy and Presto. Using this prototype, we quantify the effectiveness,
overhead, and user experience of POLYPATH, especially Presto, through both
objective measurements and subjective user assessment. We show that Presto
reduces the latency of legacy touchscreen drawing applications by almost half;
and more importantly, this reduction is orthogonal to that of other popular
approaches and is achieved without any user-noticeable negative visual effect.
When combined with touch prediction, Presto is able to reduce the touch latency
below 10 ms, a remarkable achievement without any hardware support.
"
261,Duplication of Windows Services,"  OS-level virtualization techniques virtualize system resources at the system
call interface, has the distinct advantage of smaller run-time resource
requirements as compared to HAL-level virtualization techniques, and thus forms
an important building block for virtualizing parallel and distributed
applications such as a HPC clusters. Because the Windows operating system puts
certain critical functionalities in privileged user-level system service
processes, a complete OS-level virtualization solution for the Windows platform
requires duplication of such Windows service as Remote Procedure Call Server
Service (RPCSS). As many implementation details of the Windows system services
are proprietary, duplicating Windows system services becomes the key technical
challenge for virtualizing the Windows platform at the OS level. Moreover, as a
core component of cloud computing, IIS web server-related services need to be
duplicated in containers (i.e., OS-level virtual machines), but so far there is
no such scheme. In this paper, we thoroughly identify all issues that affect
service duplication, and then propose the first known methodology to
systematically duplicate both system and ordinary Windows services. Our
experiments show that the methodology can duplicate a set of system and
ordinary services on different versions of Windows OS.
"
262,"Suspicious-Taint-Based Access Control for Protecting OS from Network
  Attacks","  Today, security threats to operating systems largely come from network.
Traditional discretionary access control mechanism alone can hardly defeat
them. Although traditional mandatory access control models can effectively
protect the security of OS, they have problems of being incompatible with
application software and complex in administration. In this paper, we propose a
new model, Suspicious-Taint-Based Access Control (STBAC) model, for defeating
network attacks while being compatible, simple and maintaining good system
performance. STBAC regards the processes using Non-Trustable-Communications as
the starting points of suspicious taint, traces the activities of the
suspiciously tainted processes by taint rules, and forbids the suspiciously
tainted processes to illegally access vital resources by protection rules. Even
in the cases when some privileged processes are subverted, STBAC can still
protect vital resources from being compromised by the intruder. We implemented
the model in the Linux kernel and evaluated it through experiments. The
evaluation showed that STBAC could protect vital resources effectively without
significant impact on compatibility and performance.
"
263,"Compatible and Usable Mandatory Access Control for Good-enough OS
  Security","  OS compromise is one of the most serious computer security problems today,
but still not being resolved. Although people proposed different kinds of
methods, they could not be accepted by most users who are non-expert due to the
lack of compatibility and usability. In this paper, we introduce a kind of new
mandatory access control model, named CUMAC, that aims to achieve good-enough
security, high compatibility and usability. It has two novel features. One is
access control based on tracing potential intrusion that can reduce false
negatives and facilitate security configuration, in order to improve both
compatibility and usability; the other is automatically figuring out all of the
compatibility exceptions that usually incurs incompatible problems. The
experiments performed on the prototype show that CUMAC can defense attacks from
network, mobile disk and local untrustable users while keeping good
compatibility and usability.
"
264,Practical Data Compression for Modern Memory Hierarchies,"  In this thesis, we describe a new, practical approach to integrating
hardware-based data compression within the memory hierarchy, including on-chip
caches, main memory, and both on-chip and off-chip interconnects. This new
approach is fast, simple, and effective in saving storage space. A key insight
in our approach is that access time (including decompression latency) is
critical in modern memory hierarchies. By combining inexpensive hardware
support with modest OS support, our holistic approach to compression achieves
substantial improvements in performance and energy efficiency across the memory
hierarchy. Using this new approach, we make several major contributions in this
thesis. First, we propose a new compression algorithm, Base-Delta-Immediate
Compression (BDI), that achieves high compression ratio with very low
compression/decompression latency. BDI exploits the existing low dynamic range
of values present in many cache lines to compress them to smaller sizes using
Base+Delta encoding. Second, we observe that the compressed size of a cache
block can be indicative of its reuse. We use this observation to develop a new
cache insertion policy for compressed caches, the Size-based Insertion Policy
(SIP), which uses the size of a compressed block as one of the metrics to
predict its potential future reuse. Third, we propose a new main memory
compression framework, Linearly Compressed Pages (LCP), that significantly
reduces the complexity and power cost of supporting main memory compression. We
demonstrate that any compression algorithm can be adapted to fit the
requirements of LCP, and that LCP can be efficiently integrated with the
existing cache compression designs, avoiding extra compression/decompression.
"
265,"Confining Windows Inter-Process Communications for OS-Level Virtual
  Machine","  As OS-level virtualization technology usually imposes little overhead on
virtual machine start-up and running, it provides an excellent choice for
building intrusion/fault tolerant applications that require redundancy and
frequent invocation. When developing Windows OS-level virtual machine, however,
people will inevitably face the challenge of confining Windows Inter-Process
Communications (IPC). As IPC on Windows platform is more complex than UNIX
style OS and most of the programs on Windows are not open-source, it is
difficult to discover all of the performed IPCs and confine them. In this
paper, we propose three general principles to confine IPC on Windows OS and a
novel IPC confinement mechanism based on the principles. With the mechanism,
for the first time from the literature, we successfully virtualized RPC System
Service (RPCSS) and Internet Information Server (IIS) on Feather-weight Virtual
Machine (FVM). Experimental results demonstrate that multiple IIS web server
instances can simultaneously run on single Windows OS with much less
performance overhead than other popular VM technology, offering a good basis
for constructing dependable system.
"
266,"Virtualizing System and Ordinary Services in Windows-based OS-Level
  Virtual Machines","  OS-level virtualization incurs smaller start-up and run-time overhead than
HAL-based virtualization and thus forms an important building block for
developing fault-tolerant and intrusion-tolerant applications. A complete
implementation of OS-level virtualization on the Windows platform requires
virtualization of Windows services, such as system services like the Remote
Procedure Call Server Service (RPCSS), because they are essentially extensions
of the kernel. As Windows system services work very differently from their
counterparts on UNIX-style OS, i.e., daemons, and many of their implementation
details are proprietary, virtualizing Windows system services turned out to be
the most challenging technical barrier for OS-level virtualization for the
Windows platform. In this paper, we describe a general technique to virtualize
Windows services, and demonstrate its effectiveness by applying it to
successfully virtualize a set of important Windows system services and ordinary
services on different versions of Windows OS, including RPCSS, DcomLaunch, IIS
service group, Tlntsvr, MySQL, Apache2.2, CiSvc, ImapiService, etc.
"
267,Implementing RBAC model in An Operating System Kernel,"  In this paper, the implementation of an operating system oriented RBAC model
is discussed. Firstly, on the basis of RBAC96 model, a new RBAC model named OSR
is presented. Secondly, the OSR model is enforced in RFSOS kernel by the way of
integrating GFAC method and Capability mechanism together. All parts of the OSR
implementation are described in detail.
"
268,An Evaluation of Coarse-Grained Locking for Multicore Microkernels,"  The trade-off between coarse- and fine-grained locking is a well understood
issue in operating systems. Coarse-grained locking provides lower overhead
under low contention, fine-grained locking provides higher scalability under
contention, though at the expense of implementation complexity and re- duced
best-case performance.
  We revisit this trade-off in the context of microkernels and tightly-coupled
cores with shared caches and low inter-core migration latencies. We evaluate
performance on two architectures: x86 and ARM MPCore, in the former case also
utilising transactional memory (Intel TSX). Our thesis is that on such
hardware, a well-designed microkernel, with short system calls, can take
advantage of coarse-grained locking on modern hardware, avoid the run-time and
complexity cost of multiple locks, enable formal verification, and still
achieve scalability comparable to fine-grained locking.
"
269,"Verification of the Tree-Based Hierarchical Read-Copy Update in the
  Linux Kernel","  Read-Copy Update (RCU) is a scalable, high-performance Linux-kernel
synchronization mechanism that runs low-overhead readers concurrently with
updaters. Production-quality RCU implementations for multi-core systems are
decidedly non-trivial. Giving the ubiquity of Linux, a rare ""million-year"" bug
can occur several times per day across the installed base. Stringent validation
of RCU's complex behaviors is thus critically important. Exhaustive testing is
infeasible due to the exponential number of possible executions, which suggests
use of formal verification.
  Previous verification efforts on RCU either focus on simple implementations
or use modeling languages, the latter requiring error-prone manual translation
that must be repeated frequently due to regular changes in the Linux kernel's
RCU implementation. In this paper, we first describe the implementation of Tree
RCU in the Linux kernel. We then discuss how to construct a model directly from
Tree RCU's source code in C, and use the CBMC model checker to verify its
safety and liveness properties. To our best knowledge, this is the first
verification of a significant part of RCU's source code, and is an important
step towards integration of formal verification into the Linux kernel's
regression test suite.
"
270,Memshare: a Dynamic Multi-tenant Memory Key-value Cache,"  Web application performance is heavily reliant on the hit rate of
memory-based caches. Current DRAM-based web caches statically partition their
memory across multiple applications sharing the cache. This causes under
utilization of memory which negatively impacts cache hit rates. We present
Memshare, a novel web memory cache that dynamically manages memory across
applications. Memshare provides a resource sharing model that guarantees
private memory to different applications while dynamically allocating the
remaining shared memory to optimize overall hit rate. Today's high cost of DRAM
storage and the availability of high performance CPU and memory bandwidth, make
web caches memory capacity bound. Memshare's log-structured design allows it to
provide significantly higher hit rates and dynamically partition memory among
applications at the expense of increased CPU and memory bandwidth consumption.
In addition, Memshare allows applications to use their own eviction policy for
their objects, independent of other applications. We implemented Memshare and
ran it on a week-long trace from a commercial memcached provider. We
demonstrate that Memshare increases the combined hit rate of the applications
in the trace by an 6.1% (from 84.7% hit rate to 90.8% hit rate) and reduces the
total number of misses by 39.7% without affecting system throughput or latency.
Even for single-tenant applications, Memshare increases the average hit rate of
the current state-of-the-art memory cache by an additional 2.7% on our
real-world trace.
"
271,Browsix: Bridging the Gap Between Unix and the Browser,"  Applications written to run on conventional operating systems typically
depend on OS abstractions like processes, pipes, signals, sockets, and a shared
file system. Porting these applications to the web currently requires extensive
rewriting or hosting significant portions of code server-side because browsers
present a nontraditional runtime environment that lacks OS functionality.
  This paper presents Browsix, a framework that bridges the considerable gap
between conventional operating systems and the browser, enabling unmodified
programs expecting a Unix-like environment to run directly in the browser.
Browsix comprises two core parts: (1) a JavaScript-only system that makes core
Unix features (including pipes, concurrent processes, signals, sockets, and a
shared file system) available to web applications; and (2) extended JavaScript
runtimes for C, C++, Go, and Node.js that support running programs written in
these languages as processes in the browser. Browsix supports running a POSIX
shell, making it straightforward to connect applications together via pipes.
  We illustrate Browsix's capabilities via case studies that demonstrate how it
eases porting legacy applications to the browser and enables new functionality.
We demonstrate a Browsix-enabled LaTeX editor that operates by executing
unmodified versions of pdfLaTeX and BibTeX. This browser-only LaTeX editor can
render documents in seconds, making it fast enough to be practical. We further
demonstrate how Browsix lets us port a client-server application to run
entirely in the browser for disconnected operation. Creating these applications
required less than 50 lines of glue code and no code modifications,
demonstrating how easily Browsix can be used to build sophisticated web
applications from existing parts without modification.
"
272,Near-Memory Address Translation,"  Memory and logic integration on the same chip is becoming increasingly cost
effective, creating the opportunity to offload data-intensive functionality to
processing units placed inside memory chips. The introduction of memory-side
processing units (MPUs) into conventional systems faces virtual memory as the
first big showstopper: without efficient hardware support for address
translation MPUs have highly limited applicability. Unfortunately, conventional
translation mechanisms fall short of providing fast translations as
contemporary memories exceed the reach of TLBs, making expensive page walks
common.
  In this paper, we are the first to show that the historically important
flexibility to map any virtual page to any page frame is unnecessary in today's
servers. We find that while limiting the associativity of the
virtual-to-physical mapping incurs no penalty, it can break the
translate-then-fetch serialization if combined with careful data placement in
the MPU's memory, allowing for translation and data fetch to proceed
independently and in parallel. We propose the Distributed Inverted Page Table
(DIPTA), a near-memory structure in which the smallest memory partition keeps
the translation information for its data share, ensuring that the translation
completes together with the data fetch. DIPTA completely eliminates the
performance overhead of translation, achieving speedups of up to 3.81x and
2.13x over conventional translation using 4KB and 1GB pages respectively.
"
273,"CannyFS: Opportunistically Maximizing I/O Throughput Exploiting the
  Transactional Nature of Batch-Mode Data Processing","  We introduce a user mode file system, CannyFS, that hides latency by assuming
all I/O operations will succeed. The user mode process will in turn report
errors, allowing proper cleanup and a repeated attempt to take place. We
demonstrate benefits for the model tasks of extracting archives and removing
directory trees in a real-life HPC environment, giving typical reductions in
time use of over 80%.
  This approach can be considered a view of HPC jobs and their I/O activity as
transactions. In general, file systems lack clearly defined transaction
semantics. Over time, the competing trends to add cache and maintain data
integrity have resulted in different practical tradeoffs.
  High-performance computing is a special case where overall throughput demands
are high. Latency can also be high, with non-local storage. In addition, a
theoretically possible I/O error (like permission denied, loss of connection,
exceeding disk quota) will frequently warrant the resubmission of a full job or
task, rather than traditional error reporting or handling. Therefore,
opportunistically treating each I/O operation as successful, and part of a
larger transaction, can speed up some applications that do not leverage
asynchronous I/O.
"
274,"Power and Execution Time Measurement Methodology for SDF Applications on
  FPGA-based MPSoCs","  Timing and power consumption play an important role in the design of embedded
systems. Furthermore, both properties are directly related to the safety
requirements of many embedded systems. With regard to availability
requirements, power considerations are of uttermost importance for battery
operated systems. Validation of timing and power requires observability of
these properties. In many cases this is difficult, because the observability is
either not possible or requires big extra effort in the system validation
process. In this paper, we present a measurement-based approach for the joint
timing and power analysis of Synchronous Dataflow (SDF) applications running on
a shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a
proof-of-concept, we implement an MPSoC system with configurable power and
timing measurement interfaces inside a Field Programmable Gate Array (FPGA).
Our experiments demonstrate the viability of our approach being able of
accurately analyzing different mappings of image processing applications (Sobel
filter and JPEG encoder) on an FPGA-based MPSoC implementation.
"
275,Flashield: a Key-value Cache that Minimizes Writes to Flash,"  As its price per bit drops, SSD is increasingly becoming the default storage
medium for cloud application databases. However, it has not become the
preferred storage medium for key-value caches, even though SSD offers more than
10x lower price per bit and sufficient performance compared to DRAM. This is
because key-value caches need to frequently insert, update and evict small
objects. This causes excessive writes and erasures on flash storage, since
flash only supports writes and erasures of large chunks of data. These
excessive writes and erasures significantly shorten the lifetime of flash,
rendering it impractical to use for key-value caches. We present Flashield, a
hybrid key-value cache that uses DRAM as a ""filter"" to minimize writes to SSD.
Flashield performs light-weight machine learning profiling to predict which
objects are likely to be read frequently before getting updated; these objects,
which are prime candidates to be stored on SSD, are written to SSD in large
chunks sequentially. In order to efficiently utilize the cache's available
memory, we design a novel in-memory index for the variable-sized objects stored
on flash that requires only 4 bytes per object in DRAM. We describe Flashield's
design and implementation and, we evaluate it on a real-world cache trace.
Compared to state-of-the-art systems that suffer a write amplification of 2.5x
or more, Flashield maintains a median write amplification of 0.5x without any
loss of hit rate or throughput.
"
276,Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation,"  Checkpoint-restart is now a mature technology. It allows a user to save and
later restore the state of a running process. The new plugin model for the
upcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is
described here. This plugin model allows a target application to disconnect
from the hardware emulator at checkpoint time and then re-connect to a possibly
different hardware emulator at the time of restart. The DMTCP plugin model is
important in allowing three distinct parties to seamlessly inter-operate. The
three parties are: the EDA designer, who is concerned with formal verification
of a circuit design; the DMTCP developers, who are concerned with providing
transparent checkpointing during the circuit emulation; and the hardware
emulator vendor, who provides a plugin library that responds to checkpoint,
restart, and other events.
  The new plugin model is an example of process-level virtualization:
virtualization of external abstractions from within a process. This capability
is motivated by scenarios for testing circuit models with the help of a
hardware emulator. The plugin model enables a three-way collaboration: allowing
a circuit designer and emulator vendor to each contribute separate proprietary
plugins while sharing an open source software framework from the DMTCP
developers. This provides a more flexible platform, where different fault
injection models based on plugins can be designed within the DMTCP
checkpointing framework. After initialization, one restarts from a checkpointed
state under the control of the desired plugin. This restart saves the time
spent in simulating the initialization phase, while enabling fault injection
exactly at the region of interest. Upon restart, one can inject faults or
otherwise modify the remainder of the simulation. The work concludes with a
brief survey of checkpointing and process-level virtualization.
"
277,Assessing Code Authorship: The Case of the Linux Kernel,"  Code authorship is a key information in large-scale open source systems.
Among others, it allows maintainers to assess division of work and identify key
collaborators. Interestingly, open-source communities lack guidelines on how to
manage authorship. This could be mitigated by setting to build an empirical
body of knowledge on how authorship-related measures evolve in successful
open-source communities. Towards that direction, we perform a case study on the
Linux kernel. Our results show that: (a) only a small portion of developers (26
%) makes significant contributions to the code base; (b) the distribution of
the number of files per author is highly skewed --- a small group of top
authors (3 %) is responsible for hundreds of files, while most authors (75 %)
are responsible for at most 11 files; (c) most authors (62 %) have a specialist
profile; (d) authors with a high number of co-authorship connections tend to
collaborate with others with less connections.
"
278,Formalizing Memory Accesses and Interrupts,"  The hardware/software boundary in modern heterogeneous multicore computers is
increasingly complex, and diverse across different platforms. A single memory
access by a core or DMA engine traverses multiple hardware translation and
caching steps, and the destination memory cell or register often appears at
different physical addresses for different cores. Interrupts pass through a
complex topology of interrupt controllers and remappers before delivery to one
or more cores, each with specific constraints on their configurations. System
software must not only correctly understand the specific hardware at hand, but
also configure it appropriately at runtime. We propose a formal model of
address spaces and resources in a system that allows us to express and verify
invariants of the system's runtime configuration, and illustrate (and motivate)
it with several real platforms we have encountered in the process of OS
implementation.
"
279,Memos: Revisiting Hybrid Memory Management in Modern Operating System,"  The emerging hybrid DRAM-NVM architecture is challenging the existing memory
management mechanism in operating system. In this paper, we introduce memos,
which can schedule memory resources over the entire memory hierarchy including
cache, channels, main memory comprising DRAM and NVM simultaneously. Powered by
our newly designed kernel-level monitoring module and page migration engine,
memos can dynamically optimize the data placement at the memory hierarchy in
terms of the on-line memory patterns, current resource utilization and feature
of memory medium. Our experimental results show that memos can achieve high
memory utilization, contributing to system throughput by 19.1% and QoS by 23.6%
on average. Moreover, memos can reduce the NVM side memory latency by 3~83.3%,
energy consumption by 25.1~99%, and benefit the NVM lifetime significantly (40X
improvement on average).
"
280,Virtualization technology for distributed time sensitive domains,"  This paper reports on the state of the art of virtualization technology for
both general purpose domains as well as real-time domains. There exits no
entirely instantaneous data transmission/transfer. There always exist a delay
while transmitting data, either in the processing or in the medium itself.
However most systems are designed to function appropriately with a delay
tolerance. This delay, inevitably, is affected when operating with an extra
layer, the virtualization. For real time systems it is crucial to know the
temporal limits in order not to surpass them. Introducing virtualization in the
real-time domain therefore requires deeper analysis by making use of techniques
that will offer results with deterministic execution times. The study of time
in systems and its behaviour under various possible circumstances is hence a
key for properly assessing this technology applied to both domains, especially
the real-time domain.
"
281,"A Backward Algorithm for the Multiprocessor Online Feasibility of
  Sporadic Tasks","  The online feasibility problem (for a set of sporadic tasks) asks whether
there is a scheduler that always prevents deadline misses (if any), whatever
the sequence of job releases, which is a priori} unknown to the scheduler. In
the multiprocessor setting, this problem is notoriously difficult. The only
exact test for this problem has been proposed by Bonifaci and
Marchetti-Spaccamela: it consists in modelling all the possible behaviours of
the scheduler and of the tasks as a graph; and to interpret this graph as a
game between the tasks and the scheduler, which are seen as antagonistic
players. Then, computing a correct scheduler is equivalent to finding a winning
strategy for the `scheduler player', whose objective in the game is to avoid
deadline misses. In practice, however this approach is limited by the
intractable size of the graph. In this work, we consider the classical
attractor algorithm to solve such games, and introduce antichain techniques to
optimise its performance in practice and overcome the huge size of the game
graph. These techniques are inspired from results from the formal methods
community, and exploit the specific structure of the feasibility problem. We
demonstrate empirically that our approach allows to dramatically improve the
performance of the game solving algorithm.
"
282,Tackling Diversity and Heterogeneity by Vertical Memory Management,"  Existing memory management mechanisms used in commodity computing machines
typically adopt hardware based address interleaving and OS directed random
memory allocation to service generic application requests. These conventional
memory management mechanisms are challenged by contention at multiple memory
levels, a daunting variety of workload behaviors, and an increasingly
complicated memory hierarchy. Our ISCA-41 paper proposes vertical partitioning
to eliminate shared resource contention at multiple levels in the memory
hierarchy. Combined with horizontal memory management policies, our framework
supports a flexible policy space for tackling diverse application needs in
production environment and is suitable for future heterogeneous memory systems.
"
283,"TrustShadow: Secure Execution of Unmodified Applications with ARM
  TrustZone","  The rapid evolution of Internet-of-Things (IoT) technologies has led to an
emerging need to make it smarter. A variety of applications now run
simultaneously on an ARM-based processor. For example, devices on the edge of
the Internet are provided with higher horsepower to be entrusted with storing,
processing and analyzing data collected from IoT devices. This significantly
improves efficiency and reduces the amount of data that needs to be transported
to the cloud for data processing, analysis and storage. However, commodity OSes
are prone to compromise. Once they are exploited, attackers can access the data
on these devices. Since the data stored and processed on the devices can be
sensitive, left untackled, this is particularly disconcerting.
  In this paper, we propose a new system, TrustShadow that shields legacy
applications from untrusted OSes. TrustShadow takes advantage of ARM TrustZone
technology and partitions resources into the secure and normal worlds. In the
secure world, TrustShadow constructs a trusted execution environment for
security-critical applications. This trusted environment is maintained by a
lightweight runtime system that coordinates the communication between
applications and the ordinary OS running in the normal world. The runtime
system does not provide system services itself. Rather, it forwards requests
for system services to the ordinary OS, and verifies the correctness of the
responses. To demonstrate the efficiency of this design, we prototyped
TrustShadow on a real chip board with ARM TrustZone support, and evaluated its
performance using both microbenchmarks and real-world applications. We showed
TrustShadow introduces only negligible overhead to real-world applications.
"
284,Mixed-criticality Scheduling with Dynamic Redistribution of Shared Cache,"  The design of mixed-criticality systems often involvespainful tradeoffs
between safety guarantees and performance.However, the use of more detailed
architectural modelsin the design and analysis of scheduling arrangements for
mixedcriticalitysystems can provide greater confidence in the analysis,but also
opportunities for better performance. Motivated by thisview, we propose an
extension of Vestal 19s model for mixedcriticalitymulticore systems that (i)
accounts for the per-taskpartitioning of the last-level cache and (ii) supports
the dynamicreassignment, for better schedulability, of cache portions
initiallyreserved for lower-criticality tasks to the higher-criticalitytasks,
when the system switches to high-criticality mode. Tothis model, we apply
partitioned EDF scheduling with Ekbergand Yi 19s deadline-scaling technique.
Our schedulability analysisand scalefactor calculation is cognisant of the
cache resourcesassigned to each task, by using WCET estimates that take
intoaccount these resources. It is hence able to leverage the
dynamicreconfiguration of the cache partitioning, at mode change, forbetter
performance, in terms of provable schedulability. We alsopropose heuristics for
partitioning the cache in low- and highcriticalitymode, that promote
schedulability. Our experimentswith synthetic task sets, indicate tangible
improvements inschedulability compared to a baseline cache-aware
arrangementwhere there is no redistribution of cache resources from low-
tohigh-criticality tasks in the event of a mode change.
"
285,"Contego: An Adaptive Framework for Integrating Security Tasks in
  Real-Time Systems","  Embedded real-time systems (RTS) are pervasive. Many modern RTS are exposed
to unknown security flaws, and threats to RTS are growing in both number and
sophistication. However, until recently, cyber-security considerations were an
afterthought in the design of such systems. Any security mechanisms integrated
into RTS must (a) co-exist with the real- time tasks in the system and (b)
operate without impacting the timing and safety constraints of the control
logic. We introduce Contego, an approach to integrating security tasks into RTS
without affecting temporal requirements. Contego is specifically designed for
legacy systems, viz., the real-time control systems in which major alterations
of the system parameters for constituent tasks is not always feasible. Contego
combines the concept of opportunistic execution with hierarchical scheduling to
maintain compatibility with legacy systems while still providing flexibility by
allowing security tasks to operate in different modes. We also define a metric
to measure the effectiveness of such integration. We evaluate Contego using
synthetic workloads as well as with an implementation on a realistic embedded
platform (an open- source ARM CPU running real-time Linux).
"
286,A Reconnaissance Attack Mechanism for Fixed-Priority Real-Time Systems,"  In real-time embedded systems (RTS), failures due to security breaches can
cause serious damage to the system, the environment and/or injury to humans.
Therefore, it is very important to understand the potential threats and attacks
against these systems. In this paper we present a novel reconnaissance attack
that extracts the exact schedule of real-time systems designed using fixed
priority scheduling algorithms. The attack is demonstrated on both a real
hardware platform and a simulator, with a high success rate. Our evaluation
results show that the algorithm is robust even in the presence of execution
time variation.
"
287,IOTune: A G-states Driver for Elastic Performance of Block Storage,"  Imagining a disk which provides baseline performance at a relatively low
price during low-load periods, but when workloads demand more resources, the
disk performance is automatically promoted in situ and in real time. In a
hardware era, this is hardly achievable. However, this imagined disk is
becoming reality due to the technical advances of software-defined storage,
which enable volume performance to be adjusted on the fly. We propose IOTune, a
resource management middleware which employs software-defined storage
primitives to implement G-states of virtual block devices. G-states enable
virtual block devices to serve at multiple performance gears, getting rid of
conflicts between immutable resource reservation and dynamic resource demands,
and always achieving resource right-provisioning for workloads. Accompanying
G-states, we also propose a new block storage pricing policy for cloud
providers. Our case study for applying G-states to cloud block storage verifies
the effectiveness of the IOTune framework. Trace-replay based evaluations
demonstrate that storage volumes with G-states adapt to workload fluctuations.
For tenants, G-states enable volumes to provide much better QoS with a same
cost of ownership, comparing with static IOPS provisioning and the I/O credit
mechanism. G-states also reduce I/O tail latencies by one to two orders of
magnitude. From the standpoint of cloud providers, G-states promote storage
utilization, creating values and benefiting competitiveness. G-states supported
by IOTune provide a new paradigm for storage resource management and pricing in
multi-tenant clouds.
"
288,"Improving the Performance and Endurance of Persistent Memory with
  Loose-Ordering Consistency","  Persistent memory provides high-performance data persistence at main memory.
Memory writes need to be performed in strict order to satisfy storage
consistency requirements and enable correct recovery from system crashes.
Unfortunately, adhering to such a strict order significantly degrades system
performance and persistent memory endurance. This paper introduces a new
mechanism, Loose-Ordering Consistency (LOC), that satisfies the ordering
requirements at significantly lower performance and endurance loss. LOC
consists of two key techniques. First, Eager Commit eliminates the need to
perform a persistent commit record write within a transaction. We do so by
ensuring that we can determine the status of all committed transactions during
recovery by storing necessary metadata information statically with blocks of
data written to memory. Second, Speculative Persistence relaxes the write
ordering between transactions by allowing writes to be speculatively written to
persistent memory. A speculative write is made visible to software only after
its associated transaction commits. To enable this, our mechanism supports the
tracking of committed transaction ID and multi-versioning in the CPU cache. Our
evaluations show that LOC reduces the average performance overhead of memory
persistence from 66.9% to 34.9% and the memory write traffic overhead from
17.1% to 3.4% on a variety of workloads.
"
289,"Comments on ""Gang EDF Schedulability Analysis""","  This short report raises a correctness issue in the schedulability test
presented in Kato et al., ""Gang EDF Scheduling of Parallel Task Systems"", 30th
IEEE Real-Time Systems Symposium, 2009, pp. 459-468.
"
290,"Look Mum, no VM Exits! (Almost)","  Multi-core CPUs are a standard component in many modern embedded systems.
Their virtualisation extensions enable the isolation of services, and gain
popularity to implement mixed-criticality or otherwise split systems. We
present Jailhouse, a Linux-based, OS-agnostic partitioning hypervisor that uses
novel architectural approaches to combine Linux, a powerful general-purpose
system, with strictly isolated special-purpose components. Our design goals
favour simplicity over features, establish a minimal code base, and minimise
hypervisor activity.
  Direct assignment of hardware to guests, together with a deferred
initialisation scheme, offloads any complex hardware handling and bootstrapping
issues from the hypervisor to the general purpose OS. The hypervisor
establishes isolated domains that directly access physical resources without
the need for emulation or paravirtualisation. This retains, with negligible
system overhead, Linux's feature-richness in uncritical parts, while frugal
safety and real-time critical workloads execute in isolated, safe domains.
"
291,GPU System Calls,"  GPUs are becoming first-class compute citizens and are being tasked to
perform increasingly complex work. Modern GPUs increasingly support
programmability- enhancing features such as shared virtual memory and hardware
cache coherence, enabling them to run a wider variety of programs. But a key
aspect of general-purpose programming where GPUs are still found lacking is the
ability to invoke system calls. We explore how to directly invoke generic
system calls in GPU programs. We examine how system calls should be meshed with
prevailing GPGPU programming models where thousands of threads are organized in
a hierarchy of execution groups: Should a system call be invoked at the
individual GPU task, or at different execution group levels? What are
reasonable ordering semantics for GPU system calls across these hierarchy of
execution groups? To study these questions, we implemented GENESYS -- a
mechanism to allow GPU pro- grams to invoke system calls in the Linux operating
system. Numerous subtle changes to Linux were necessary, as the existing kernel
assumes that only CPUs invoke system calls. We analyze the performance of
GENESYS using micro-benchmarks and three applications that exercise the
filesystem, networking, and memory allocation subsystems of the kernel. We
conclude by analyzing the suitability of all of Linux's system calls for the
GPU.
"
292,MITHRIL: Mining Sporadic Associations for Cache Prefetching,"  The growing pressure on cloud application scalability has accentuated storage
performance as a critical bottle- neck. Although cache replacement algorithms
have been extensively studied, cache prefetching - reducing latency by
retrieving items before they are actually requested remains an underexplored
area. Existing approaches to history-based prefetching, in particular, provide
too few benefits for real systems for the resources they cost. We propose
MITHRIL, a prefetching layer that efficiently exploits historical patterns in
cache request associations. MITHRIL is inspired by sporadic association rule
mining and only relies on the timestamps of requests. Through evaluation of 135
block-storage traces, we show that MITHRIL is effective, giving an average of a
55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain
over AMP at reasonable cost. We further show that MITHRIL can supplement any
cache replacement algorithm and be readily integrated into existing systems.
Furthermore, we demonstrate the improvement comes from MITHRIL being able to
capture mid-frequency blocks.
"
293,SMORE: A Cold Data Object Store for SMR Drives (Extended Version),"  Shingled magnetic recording (SMR) increases the capacity of magnetic hard
drives, but it requires that each zone of a disk be written sequentially and
erased in bulk. This makes SMR a good fit for workloads dominated by large data
objects with limited churn. To explore this possibility, we have developed
SMORE, an object storage system designed to reliably and efficiently store
large, seldom-changing data objects on an array of host-managed or host-aware
SMR disks.
  SMORE uses a log-structured approach to accommodate the constraint that all
writes to an SMR drive must be sequential within large shingled zones. It
stripes data across zones on separate disks, using erasure coding to protect
against drive failure. A separate garbage collection thread reclaims space by
migrating live data out of the emptiest zones so that they can be trimmed and
reused. An index stored on flash and backed up to the SMR drives maps object
identifiers to on-disk locations. SMORE interleaves log records with object
data within SMR zones to enable index recovery after a system crash (or failure
of the flash device) without any additional logging mechanism.
  SMORE achieves full disk bandwidth when ingesting data---with a variety of
object sizes---and when reading large objects. Read performance declines for
smaller object sizes where inter- object seek time dominates. With a worst-case
pattern of random deletions, SMORE has a write amplification (not counting RAID
parity) of less than 2.0 at 80% occupancy. By taking an index snapshot every
two hours, SMORE recovers from crashes in less than a minute. More frequent
snapshots allow faster recovery.
"
294,"Design and Implementation of Modified Fuzzy based CPU Scheduling
  Algorithm","  CPU Scheduling is the base of multiprogramming. Scheduling is a process which
decides order of task from a set of multiple tasks that are ready to execute.
There are number of CPU scheduling algorithms available, but it is very
difficult task to decide which one is better. This paper discusses the design
and implementation of modified fuzzy based CPU scheduling algorithm. This paper
present a new set of fuzzy rules. It demonstrates that scheduling done with new
priority improves average waiting time and average turnaround time.
"
295,Downgrade Attack on TrustZone,"  Security-critical tasks require proper isolation from untrusted software.
Chip manufacturers design and include trusted execution environments (TEEs) in
their processors to secure these tasks. The integrity and security of the
software in the trusted environment depend on the verification process of the
system.
  We find a form of attack that can be performed on the current implementations
of the widely deployed ARM TrustZone technology. The attack exploits the fact
that the trustlet (TA) or TrustZone OS loading verification procedure may use
the same verification key and may lack proper rollback prevention across
versions. If an exploit works on an out-of-date version, but the vulnerability
is patched on the latest version, an attacker can still use the same exploit to
compromise the latest system by downgrading the software to an older and
exploitable version.
  We did experiments on popular devices on the market including those from
Google, Samsung and Huawei, and found that all of them have the risk of being
attacked. Also, we show a real-world example to exploit Qualcomm's QSEE.
  In addition, in order to find out which device images share the same
verification key, pattern matching schemes for different vendors are analyzed
and summarized.
"
296,"Deterministic Memory Abstraction and Supporting Multicore System
  Architecture","  Poor time predictability of multicore processors has been a long-standing
challenge in the real-time systems community. In this paper, we make a case
that a fundamental problem that prevents efficient and predictable real-time
computing on multicore is the lack of a proper memory abstraction to express
memory criticality, which cuts across various layers of the system: the
application, OS, and hardware. We, therefore, propose a new holistic resource
management approach driven by a new memory abstraction, which we call
Deterministic Memory. The key characteristic of deterministic memory is that
the platform - the OS and hardware - guarantees small and tightly bounded
worst-case memory access timing. In contrast, we call the conventional memory
abstraction as best-effort memory in which only highly pessimistic worst-case
bounds can be achieved. We propose to utilize both abstractions to achieve high
time predictability but without significantly sacrificing performance. We
present deterministic memory-aware OS and architecture designs, including
OS-level page allocator, hardware-level cache, and DRAM controller designs. We
implement the proposed OS and architecture extensions on Linux and gem5
simulator. Our evaluation results, using a set of synthetic and real-world
benchmarks, demonstrate the feasibility and effectiveness of our approach.
"
297,Study and Analysis of MAC/IPAD Lab Configuration,"  This paper is about three virtualization modes: VMware, Parallels, and Boot
Camping. The trade off of their testing is the hardware requirements. The main
question is, among the three, which is the most suitable? The answer actually
varies from user to user. It depends on the user needs. Moreover, it is
necessary to consider its performance, graphics, efficiency and reliability,
and interoperability, and that is our major scope. In order to take the final
decision in choosing one of the modes it is important to run some tests, which
costs a lot in terms of money, complexity, and time consumption. Therefore, in
order to overcome this trade off, most of the research has been done through
online benchmarking and my own anticipation. The final solution was extracted
after comparing all previously mentioned above and after rigorous testing made
which will be introduced later in this document.
"
298,Optimizations of Management Algorithms for Multi-Level Memory Hierarchy,"  In the near future the SCM is predicted to modify the form of new programs,
the access form to storage, and the way that storage devices themselves are
built. Therefore, a combination between the SCM and a designated Memory
Allocation Manager (MAM) that will allow the programmer to manually control the
different memories in the memory hierarchy will be likely to achieve a new
level of performance for memory-aware data structures. Although the manual MAM
seems to be the optimal approach for multi-level memory hierarchy management,
this technique is still very far from being realistic, and the chances that it
would be implemented in current codes using High Performance Computing (HPC)
platforms is quite low. This premise means that the most reasonable way to
introduce the SCM into any usable and popular memory system would be by
implementing an automated version of the MAM using the fundamentals of paging
algorithms, as used for two-level memory hierarchy. Our hypothesis is that
achieving appropriate transferability between memory levels may be possible
using ideas of algorithms employed in current virtual memory systems, and that
the adaptation of those algorithms from a two-level memory hierarchy to an
N-level memory hierarchy is possible. In order to reach the conclusion that our
hypothesis is correct, we investigated various paging algorithms, and found the
ones that could be adapted successfully from two-level memory hierarchy to an
N-level memory hierarchy. We discovered that using an adaptation of the Aging
paging algorithm to an N-level memory hierarchy results in the best
performances in terms of Hit/Miss ratio. In order to verify our hypothesis we
build a simulator called ""DeMemory simulator"" for analyzing our algorithms as
well as for other algorithms that will be devised in the future.
"
299,FluidMem: Memory as a Service for the Datacenter,"  Disaggregating resources in data centers is an emerging trend. Recent work
has begun to explore memory disaggregation, but suffers limitations including
lack of consideration of the complexity of cloud-based deployment, including
heterogeneous hardware and APIs for cloud users and operators. In this paper,
we present FluidMem, a complete system to realize disaggregated memory in the
datacenter. Going beyond simply demonstrating remote memory is possible, we
create an entire Memory as a Service. We define the requirements of Memory as a
Service and build its implementation in Linux as FluidMem. We present a
performance analysis of FluidMem and demonstrate that it transparently supports
remote memory for standard applications such as MongoDB and genome sequencing
applications.
"
300,Analyzing IO Amplification in Linux File Systems,"  We present the first systematic analysis of read, write, and space
amplification in Linux file systems. While many researchers are tackling write
amplification in key-value stores, IO amplification in file systems has been
largely unexplored. We analyze data and metadata operations on five widely-used
Linux file systems: ext2, ext4, XFS, btrfs, and F2FS. We find that data
operations result in significant write amplification (2-32X) and that metadata
operations have a large IO cost. For example, a single rename requires 648 KB
write IO in btrfs. We also find that small random reads result in read
amplification of 2-13X. Based on these observations, we present the CReWS
conjecture about the relationship between IO amplification, consistency, and
storage space utilization. We hope this paper spurs people to design future
file systems with less IO amplification, especially for non-volatile memory
technologies.
"
301,Performance Measurements of Supercomputing and Cloud Storage Solutions,"  Increasing amounts of data from varied sources, particularly in the fields of
machine learning and graph analytics, are causing storage requirements to grow
rapidly. A variety of technologies exist for storing and sharing these data,
ranging from parallel file systems used by supercomputers to distributed block
storage systems found in clouds. Relatively few comparative measurements exist
to inform decisions about which storage systems are best suited for particular
tasks. This work provides these measurements for two of the most popular
storage technologies: Lustre and Amazon S3. Lustre is an open-source, high
performance, parallel file system used by many of the largest supercomputers in
the world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web
Services offering, and offers a scalable, distributed option to store and
retrieve data from anywhere on the Internet. Parallel processing is essential
for achieving high performance on modern storage systems. The performance tests
used span the gamut of parallel I/O scenarios, ranging from single-client,
single-node Amazon S3 and Lustre performance to a large-scale, multi-client
test designed to demonstrate the capabilities of a modern storage appliance
under heavy load. These results show that, when parallel I/O is used correctly
(i.e., many simultaneous read or write processes), full network bandwidth
performance is achievable and ranged from 10 gigabits/s over a 10 GigE S3
connection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These
results demonstrate that S3 is well-suited to sharing vast quantities of data
over the Internet, while Lustre is well-suited to processing large quantities
of data locally.
"
302,"Entirely protecting operating systems against transient errors in space
  environment","  In this article, we propose a mainly-software hardening technique to totally
protect unmodified running operating systems on COTS hardware against transient
errors in heavily radiation - flooded environment like high altitude space. The
technique is currently being implemented in a hypervisor and allows to control
the upper layers of the software stack (operating system and applications). The
rest of the system, the hypervisor, will be protected by other means, thus
resulting in a completely protected system against transient errors. The
induced overhead turns around 200% but this is expected to decrease with future
improvements.
"
303,"Bringing Fault-Tolerant GigaHertz-Computing to Space: A Multi-Stage
  Software-Side Fault-Tolerance Approach for Miniaturized Spacecraft","  Modern embedded technology is a driving factor in satellite miniaturization,
contributing to a massive boom in satellite launches and a rapidly evolving new
space industry. Miniaturized satellites, however, suffer from low reliability,
as traditional hardware-based fault-tolerance (FT) concepts are ineffective for
on-board computers (OBCs) utilizing modern systems-on-a-chip (SoC). Therefore,
larger satellites continue to rely on proven processors with large feature
sizes. Software-based concepts have largely been ignored by the space industry
as they were researched only in theory, and have not yet reached the level of
maturity necessary for implementation. We present the first integral,
real-world solution to enable fault-tolerant general-purpose computing with
modern multiprocessor-SoCs (MPSoCs) for spaceflight, thereby enabling their use
in future high-priority space missions. The presented multi-stage approach
consists of three FT stages, combining coarse-grained thread-level distributed
self-validation, FPGA reconfiguration, and mixed criticality to assure
long-term FT and excellent scalability for both resource constrained and
critical high-priority space missions. Early benchmark results indicate a
drastic performance increase over state-of-the-art radiation-hard OBC designs
and considerably lower software- and hardware development costs. This approach
was developed for a 4-year European Space Agency (ESA) project, and we are
implementing a tiled MPSoC prototype jointly with two industrial partners.
"
304,Tug-of-War: Observations on Unified Content Handling,"  Modern applications and Operating Systems vary greatly with respect to how
they register and identify different types of content. These discrepancies lead
to exploits and inconsistencies in user experience. In this paper, we highlight
the issues arising in the modern content handling ecosystem, and examine how
the operating system can be used to achieve unified and consistent content
identification.
"
305,FreeGuard: A Faster Secure Heap Allocator,"  In spite of years of improvements to software security, heap-related attacks
still remain a severe threat. One reason is that many existing memory
allocators fall short in a variety of aspects. For instance,
performance-oriented allocators are designed with very limited countermeasures
against attacks, but secure allocators generally suffer from significant
performance overhead, e.g., running up to 10x slower. This paper, therefore,
introduces FreeGuard, a secure memory allocator that prevents or reduces a wide
range of heap-related attacks, such as heap overflows, heap over-reads,
use-after-frees, as well as double and invalid frees. FreeGuard has similar
performance to the default Linux allocator, with less than 2% overhead on
average, but provides significant improvement to security guarantees. FreeGuard
also addresses multiple implementation issues of existing secure allocators,
such as the issue of scalability. Experimental results demonstrate that
FreeGuard is very effective in defending against a variety of heap-related
attacks.
"
306,"Performance Evaluation of Container-based Virtualization for High
  Performance Computing Environments","  Virtualization technologies have evolved along with the development of
computational environments since virtualization offered needed features at that
time such as isolation, accountability, resource allocation, resource fair
sharing and so on. Novel processor technologies bring to commodity computers
the possibility to emulate diverse environments where a wide range of
computational scenarios can be run. Along with processors evolution, system
developers have created different virtualization mechanisms where each new
development enhanced the performance of previous virtualized environments.
Recently, operating system-based virtualization technologies captured the
attention of communities abroad (from industry to academy and research) because
their important improvements on performance area.
  In this paper, the features of three container-based operating systems
virtualization tools (LXC, Docker and Singularity) are presented. LXC, Docker,
Singularity and bare metal are put under test through a customized single node
HPL-Benchmark and a MPI-based application for the multi node testbed. Also the
disk I/O performance, Memory (RAM) performance, Network bandwidth and GPU
performance are tested for the COS technologies vs bare metal. Preliminary
results and conclusions around them are presented and discussed.
"
307,The Case for a Single System Image for Personal Devices,"  Computing technology has gotten cheaper and more powerful, allowing users to
have a growing number of personal computing devices at their disposal. While
this trend is beneficial for the user, it also creates a growing management
burden for the user. Each device must be managed independently and users must
repeat the same management tasks on the each device, such as updating software,
changing configurations, backup, and replicating data for availability. To
prevent the management burden from increasing with the number of devices, we
propose that all devices run a single system image called a personal computing
image. Personal computing images export a device-specific user interface on
each device, but provide a consistent view of application and operating state
across all devices. As a result, management tasks can be performed once on any
device and will be automatically propagated to all other devices belonging to
the user. We discuss evolutionary steps that can be taken to achieve personal
computing images for devices and elaborate on challenges that we believe
building such systems will face.
"
308,Towards Linux Kernel Memory Safety,"  The security of billions of devices worldwide depends on the security and
robustness of the mainline Linux kernel. However, the increasing number of
kernel-specific vulnerabilities, especially memory safety vulnerabilities,
shows that the kernel is a popular and practically exploitable target. Two
major causes of memory safety vulnerabilities are reference counter overflows
(temporal memory errors) and lack of pointer bounds checking (spatial memory
errors).
  To succeed in practice, security mechanisms for critical systems like the
Linux kernel must also consider performance and deployability as critical
design objectives. We present and systematically analyze two such mechanisms
for improving memory safety in the Linux kernel: (a) an overflow-resistant
reference counter data structure designed to accommodate typical reference
counter usage in kernel source code, and (b) runtime pointer bounds checking
using Intel MPX in the kernel.
"
309,Tails & Tor and other tools for Safeguarding Online Activities,"  There are not many known ways to break Tor anonymity, and they require an
enormous amount of computational power. Controlling both entrance and exit
nodes allows an attacker to compromise client IP with enough pattern analysis.
If an .onion or public website does not use SSL, information will not be
encrypted once it reaches the exit node. Tor has been successfully broken by
Carnegie Mellon, however they will not answer questions nor confirm their
method. This research paper investigates Tails & Tor and other tools for
Safeguarding Online Activities.
"
310,Exploiting Commutativity For Practical Fast Replication,"  Traditional approaches to replication require client requests to be ordered
before making them durable by copying them to replicas. As a result, clients
must wait for two round-trip times (RTTs) before updates complete. In this
paper, we show that this entanglement of ordering and durability is unnecessary
for strong consistency. Consistent Unordered Replication Protocol (CURP) allows
clients to replicate requests that have not yet been ordered, as long as they
are commutative. This strategy allows most operations to complete in 1 RTT (the
same as an unreplicated system). We implemented CURP in the Redis and RAMCloud
storage systems. In RAMCloud, CURP improved write latency by ~2x (13.8 us ->
7.3 us) and write throughput by 4x. Compared to unreplicated RAMCloud, CURP's
latency overhead for 3-way replication is just 0.4 us (6.9 us vs 7.3 us). CURP
transformed a non-durable Redis cache into a consistent and durable storage
system with only a small performance overhead.
"
311,Barrier Enabled IO Stack for Flash Storage,"  This work is dedicated to eliminating the overhead of guaranteeing the
storage order in modern IO stack. The existing block device adopts
prohibitively expensive resort in ensuring the storage order among write
requests: interleaving successive write requests with transfer and flush.
Exploiting the cache barrier command for the Flash storage, we overhaul the IO
scheduler, the dispatch module and the filesystem so that these layers are
orchestrated to preserve the ordering condition imposed by the application can
be delivered to the storage. Key ingredients of Barrier Enabled IO stack are
Epoch based IO scheduling, Order Preserving Dispatch, and Dual Mode Journaling.
Barrier enabled IO stack successfully eliminates the root cause of excessive
overhead in enforcing the storage order. Dual Mode Journaling in BarrierFS
dedicates the separate threads to effectively decouple the control plane and
data plane of the journal commit. We implement Barrier Enabled IO Stack in
server as well as in mobile platform. SQLite performance increases by 270% and
75%, in server and in smartphone, respectively. Relaxing the durability of a
transaction, SQLite performance and MySQL performance increases as much as by
73X and by 43X, respectively, in server storage.
"
312,AppSwitch: Resolving the Application Identity Crisis,"  Networked applications traditionally derive their identity from the identity
of the host on which they run. The default application identity acquired from
the host results in subtle and substantial problems related to application
deployment, discovery and access, especially for modern distributed
applications. A number of mechanisms and workarounds, often quite elaborate,
are used to address those problems but they only address them indirectly and
incompletely.
  This paper presents AppSwitch, a novel transport layer network element that
decouples applications from underlying network at the system call layer and
enables them to be identified independently of the network. Without requiring
changes to existing applications or infrastructure, it removes the cost and
complexity associated with operating distributed applications while offering a
number of benefits including an efficient implementation of common network
functions such as application firewall and load balancer. Experiments with our
implementation show that AppSwitch model also effectively removes the
performance penalty associated with unnecessary data path processing that is
typical in those application environments.
"
313,Ocasta: Clustering Configuration Settings For Error Recovery,"  Effective machine-aided diagnosis and repair of configuration errors
continues to elude computer systems designers. Most of the literature targets
errors that can be attributed to a single erroneous configuration setting.
However, a recent study found that a significant amount of configuration errors
require fixing more than one setting together. To address this limitation,
Ocasta statistically clusters dependent configuration settings based on the
application's accesses to its configuration settings and utilizes the extracted
clustering of configuration settings to fix configuration errors involving more
than one configuration settings. Ocasta treats applications as black-boxes and
only relies on the ability to observe application accesses to their
configuration settings.
  We collected traces of real application usage from 24 Linux and 5 Windows
desktops computers and found that Ocasta is able to correctly identify clusters
with 88.6% accuracy. To demonstrate the effectiveness of Ocasta, we evaluated
it on 16 real-world configuration errors of 11 Linux and Windows applications.
Ocasta is able to successfully repair all evaluated configuration errors in 11
minutes on average and only requires the user to examine an average of 3
screenshots of the output of the application to confirm that the error is
repaired. A user study we conducted shows that Ocasta is easy to use by both
expert and non-expert users and is more efficient than manual configuration
error troubleshooting.
"
314,"A Design-Space Exploration for Allocating Security Tasks in Multicore
  Real-Time Systems","  The increased capabilities of modern real-time systems (RTS) expose them to
various security threats. Recently, frameworks that integrate security tasks
without perturbing the real-time tasks have been proposed, but they only target
single core systems. However, modern RTS are migrating towards multicore
platforms. This makes the problem of integrating security mechanisms more
complex, as designers now have multiple choices for where to allocate the
security tasks. In this paper we propose HYDRA, a design space exploration
algorithm that finds an allocation of security tasks for multicore RTS using
the concept of opportunistic execution. HYDRA allows security tasks to operate
with existing real-time tasks without perturbing system parameters or normal
execution patterns, while still meeting the desired monitoring frequency for
intrusion detection. Our evaluation uses a representative real-time control
system (along with synthetic task sets for a broader exploration) to illustrate
the efficacy of HYDRA.
"
315,Software Distribution Transparency and Auditability,"  A large user base relies on software updates provided through package
managers. This provides a unique lever for improving the security of the
software update process. We propose a transparency system for software updates
and implement it for a widely deployed Linux package manager, namely APT. Our
system is capable of detecting targeted backdoors without producing overhead
for maintainers. In addition, in our system, the availability of source code is
ensured, the binding between source and binary code is verified using
reproducible builds, and the maintainer responsible for distributing a specific
package can be identified. We describe a novel ""hidden version"" attack against
current software transparency systems and propose as well as integrate a
suitable defense. To address equivocation attacks by the transparency log
server, we introduce tree root cross logging, where the log's Merkle tree root
is submitted into a separately operated log server. This significantly relaxes
the inter-operator cooperation requirements compared to other systems. Our
implementation is evaluated by replaying over 3000 updates of the Debian
operating system over the course of two years, demonstrating its viability and
identifying numerous irregularities.
"
316,"Implementation of an Android Framework for USB storage access without
  root rights","  This bachelor thesis describes the implementation of an Android framework to
access mass storage devices over the USB interface of a smartphone. First the
basics of USB (i.e. interfaces, endpoints and USB On the go) and accessing USB
devices via the official Android API are discussed. Next the USB mass storage
class is explained, which was de- signed by the USB-IF to access mobile mass
storage like USB pen drives or external HDDs. For communication with mass
storage devices, most important are the bulk-only transfer and the SCSI
transparent command set. Furthermore file systems, for accessing directo- ries
and files, are described. This thesis focuses on the FAT32 file system from
Microsoft, because it is the most commonly used file system on such devices.
After the theory part it is time to look at the implementation of the
framework. In this section, the first concern is the purpose in general. Then
the architecture of the framework and the actual implementation are presented.
Important parts are discussed in detail. The thesis finishes with an overview
of the test results on various Android devices, a short conclusion and an
outlook to future developments. Moreover the current status of the developed
framework is visualized.
"
317,"Seamless Resources Sharing in Wearable Networks by Application Function
  Virtualization","  The prevalence of smart wearable devices is increasing exponentially and we
are witnessing a wide variety of fascinating new services that leverage the
capabilities of these wearables. Wearables are truly changing the way mobile
computing is deployed and mobile applications are being developed. It is
possible to leverage the capabilities such as connectivity, processing, and
sensing of wearable devices in an adaptive manner for efficient resource usage
and information accuracy within the personal area network. We show that
application developers are not yet taking advantage of these cross-device
capabilities, however, instead using wearables as passive sensors or simple end
displays to provide notifications to the user. We thus design AFV (Application
Function Virtualization), an architecture enabling automated dynamic function
virtualization and scheduling across devices in a personal area network,
simplifying the development of the apps that are adaptive to context changes.
AFV provides a simple set of APIs hiding complex architectural tasks from app
developers whilst continuously monitoring the user, device and network context,
to enable the adaptive invocation of functions across devices. We show the
feasibility of our design by implementing AFV on Android, and the benefits for
the user in terms of resource efficiency, especially in saving energy
consumption, and quality of experience with multiple use cases.
"
318,EmLog: Tamper-Resistant System Logging for Constrained Devices with TEEs,"  Remote mobile and embedded devices are used to deliver increasingly impactful
services, such as medical rehabilitation and assistive technologies. Secure
system logging is beneficial in these scenarios to aid audit and forensic
investigations particularly if devices bring harm to end-users. Logs should be
tamper-resistant in storage, during execution, and when retrieved by a trusted
remote verifier. In recent years, Trusted Execution Environments (TEEs) have
emerged as the go-to root of trust on constrained devices for isolated
execution of sensitive applications. Existing TEE-based logging systems,
however, focus largely on protecting server-side logs and offer little
protection to constrained source devices. In this paper, we introduce EmLog --
a tamper-resistant logging system for constrained devices using the
GlobalPlatform TEE. EmLog provides protection against complex software
adversaries and offers several additional security properties over past
schemes. The system is evaluated across three log datasets using an
off-the-shelf ARM development board running an open-source,
GlobalPlatform-compliant TEE. On average, EmLog runs with low run-time memory
overhead (1MB heap and stack), 430--625 logs/second throughput, and five-times
persistent storage overhead versus unprotected logs.
"
319,Reservation-Based Federated Scheduling for Parallel Real-Time Tasks,"  This paper considers the scheduling of parallel real-time tasks with
arbitrary-deadlines. Each job of a parallel task is described as a directed
acyclic graph (DAG). In contrast to prior work in this area, where
decomposition-based scheduling algorithms are proposed based on the
DAG-structure and inter-task interference is analyzed as self-suspending
behavior, this paper generalizes the federated scheduling approach. We propose
a reservation-based algorithm, called reservation-based federated scheduling,
that dominates federated scheduling. We provide general constraints for the
design of such systems and prove that reservation-based federated scheduling
has a constant speedup factor with respect to any optimal DAG task scheduler.
Furthermore, the presented algorithm can be used in conjunction with any
scheduler and scheduling analysis suitable for ordinary arbitrary-deadline
sporadic task sets, i.e., without parallelism.
"
320,"Migrate when necessary: toward partitioned reclaiming for soft real-time
  tasks","  This paper presents a new strategy for scheduling soft real-time tasks on
multiple identical cores. The proposed approach is based on partitioned CPU
reservations and it uses a reclaiming mechanism to reduce the number of missed
deadlines. We introduce the possibility for a task to temporarily migrate to
another, less charged, CPU when it has exhausted the reserved bandwidth on its
allocated CPU. In addition, we propose a simple load balancing method to
decrease the number of deadlines missed by the tasks. The proposed algorithm
has been evaluated through simulations, showing its effectiveness (compared to
other multi-core reclaiming approaches) and comparing the performance of
different partitioning heuristics (Best Fit, Worst Fit and First Fit).
"
321,POSIX-based Operating System in the environment of NVM/SCM memory,"  Modern Operating Systems are typically POSIX-compliant. The system calls are
the fundamental layer of interaction between user-space applications and the OS
kernel and its implementation of fundamental abstractions and primitives used
in modern computing. The next generation of NVM/SCM memory raises critical
questions about the efficiency of modern OS architecture. This paper
investigates how the POSIX API drives performance for a system with NVM/SCM
memory. We show that OS and metadata related system calls represent the most
important area of optimization. However, the synchronization related system
calls (poll(), futex(), wait4()) are the most time-consuming overhead that even
a RAMdisk platform fails to eliminate. Attempting to preserve the POSIX-based
approach will likely result in fundamental inefficiencies for any future
applications of NVM/SCM memory.
"
322,Protecting real-time GPU kernels on integrated CPU-GPU SoC platforms,"  Integrated CPU-GPU architecture provides excellent acceleration capabilities
for data parallel applications on embedded platforms while meeting the size,
weight and power (SWaP) requirements. However, sharing of main memory between
CPU applications and GPU kernels can severely affect the execution of GPU
kernels and diminish the performance gain provided by GPU. For example, in the
NVIDIA Tegra K1 platform which has the integrated CPU-GPU architecture, we
noticed that in the worst case scenario, the GPU kernels can suffer as much as
4X slowdown in the presence of co-running memory intensive CPU applications
compared to their solo execution. In this paper, we propose a software
mechanism, which we call BWLOCK++, to protect the performance of GPU kernels
from co-scheduled memory intensive CPU applications.
"
323,"Connecting the World of Embedded Mobiles: The RIOT Approach to
  Ubiquitous Networking for the Internet of Things","  The Internet of Things (IoT) is rapidly evolving based on low-power compliant
protocol standards that extend the Internet into the embedded world. Pioneering
implementations have proven it is feasible to inter-network very constrained
devices, but had to rely on peculiar cross-layered designs and offer a
minimalistic set of features. In the long run, however, professional use and
massive deployment of IoT devices require full-featured, cleanly composed, and
flexible network stacks.
  This paper introduces the networking architecture that turns RIOT into a
powerful IoT system, to enable low-power wireless scenarios. RIOT networking
offers (i) a modular architecture with generic interfaces for plugging in
drivers, protocols, or entire stacks, (ii) support for multiple heterogeneous
interfaces and stacks that can concurrently operate, and (iii) GNRC, its
cleanly layered, recursively composed default network stack. We contribute an
in-depth analysis of the communication performance and resource efficiency of
RIOT, both on a micro-benchmarking level as well as by comparing IoT
communication across different platforms. Our findings show that, though it is
based on significantly different design trade-offs, the networking subsystem of
RIOT achieves a performance equivalent to that of Contiki and TinyOS, the two
operating systems which pioneered IoT software platforms.
"
324,Shai: Enforcing Data-Specific Policies with Near-Zero Runtime Overhead,"  Data retrieval systems such as online search engines and online social
networks must comply with the privacy policies of personal and selectively
shared data items, regulatory policies regarding data retention and censorship,
and the provider's own policies regarding data use. Enforcing these policies is
difficult and error-prone. Systematic techniques to enforce policies are either
limited to type-based policies that apply uniformly to all data of the same
type, or incur significant runtime overhead.
  This paper presents Shai, the first system that systematically enforces
data-specific policies with near-zero overhead in the common case. Shai's key
idea is to push as many policy checks as possible to an offline, ahead-of-time
analysis phase, often relying on predicted values of runtime parameters such as
the state of access control lists or connected users' attributes. Runtime
interception is used sparingly, only to verify these predictions and to make
any remaining policy checks. Our prototype implementation relies on efficient,
modern OS primitives for sandboxing and isolation. We present the design of
Shai and quantify its overheads on an experimental data indexing and search
pipeline based on the popular search engine Apache Lucene.
"
325,Elevating commodity storage with the SALSA host translation layer,"  To satisfy increasing storage demands in both capacity and performance,
industry has turned to multiple storage technologies, including Flash SSDs and
SMR disks. These devices employ a translation layer that conceals the
idiosyncrasies of their mediums and enables random access. Device translation
layers are, however, inherently constrained: resources on the drive are scarce,
they cannot be adapted to application requirements, and lack visibility across
multiple devices. As a result, performance and durability of many storage
devices is severely degraded.
  In this paper, we present SALSA: a translation layer that executes on the
host and allows unmodified applications to better utilize commodity storage.
SALSA supports a wide range of single- and multi-device optimizations and,
because is implemented in software, can adapt to specific workloads. We
describe SALSA's design, and demonstrate its significant benefits using
microbenchmarks and case studies based on three applications: MySQL, the Swift
object store, and a video server.
"
326,vLibOS: Babysitting OS Evolution with a Virtualized Library OS,"  Many applications have service requirements that are not easily met by
existing operating systems. Real-time and security-critical tasks, for example,
often require custom OSes to meet their needs. However, development of special
purpose OSes is a time-consuming and difficult exercise. Drivers, libraries and
applications have to be written from scratch or ported from existing sources.
Many researchers have tackled this problem by developing ways to extend
existing systems with application-specific services. However, it is often
difficult to ensure an adequate degree of separation between legacy and new
services, especially when security and timing requirements are at stake.
Virtualization, for example, supports logical isolation of separate guest
services, but suffers from inadequate temporal isolation of time-critical code
required for real-time systems. This paper presents vLibOS, a master-slave
paradigm for new systems, whose services are built on legacy code that is
temporally and spatially isolated in separate VM domains. Existing OSes are
treated as sandboxed libraries, providing legacy services that are requested by
inter-VM calls, which execute with the time budget of the caller. We evaluate a
real-time implementation of vLibOS. Empirical results show that vLibOS achieves
as much as a 50\% reduction in performance slowdown for real-time threads, when
competing for a shared memory bus with a Linux VM.
"
327,"Mirrored and Hybrid Disk Arrays: Organization, Scheduling, Reliability,
  and Performance","  Basic mirroring (BM) classified as RAID level 1 replicates data on two disks,
thus doubling disk access bandwidth for read requests. RAID1/0 is an array of
BM pairs with balanced loads due to striping. When a disk fails the read load
on its pair is doubled, which results in halving the maximum attainable
bandwidth. We review RAID1 organizations which attain a balanced load upon disk
failure, but as shown by reliability analysis tend to be less reliable than
RAID1/0. Hybrid disk arrays which store XORed instead of replicated data tend
to have a higher reliability than mirrored disks, but incur a higher overhead
in updating data. Read request response time can be improved by processing them
at a higher priority than writes, since they have a direct effect on
application response time. Shortest seek distance and affinity based routing
both shorten seek time. Anticipatory arm placement places arms optimally to
minimize the seek distance. The analysis of RAID1 in normal, degraded, and
rebuild mode is provided to quantify RAID1/0 performance. We compare the
reliability of mirrored disk organizations against each other and hybrid disks
and erasure coded disk arrays.
"
328,Virtual Breakpoints for x86/64,"  Efficient, reliable trapping of execution in a program at the desired
location is a linchpin technique for dynamic malware analysis. The progression
of debuggers and malware is akin to a game of cat and mouse - each are
constantly in a state of trying to thwart one another. At the core of most
efficient debuggers today is a combination of virtual machines and traditional
binary modification breakpoints (int3). In this paper, we present a design for
Virtual Breakpoints. a modification to the x86 MMU which brings breakpoint
management into hardware alongside page tables. In this paper we demonstrate
the fundamental abstraction failures of current trapping methods, and design a
new mechanism from the hardware up. This design incorporates lessons learned
from 50 years of virtualization and debugger design to deliver fast, reliable
trapping without the pitfalls of traditional binary modification.
"
329,Representation Learning for Resource Usage Prediction,"  Creating a model of a computer system that can be used for tasks such as
predicting future resource usage and detecting anomalies is a challenging
problem. Most current systems rely on heuristics and overly simplistic
assumptions about the workloads and system statistics. These heuristics are
typically a one-size-fits-all solution so as to be applicable in a wide range
of applications and systems environments.
  With this paper, we present our ongoing work of integrating systems telemetry
ranging from standard resource usage statistics to kernel and library calls of
applications into a machine learning model. Intuitively, such a ML model
approximates, at any point in time, the state of a system and allows us to
solve tasks such as resource usage prediction and anomaly detection. To achieve
this goal, we leverage readily-available information that does not require any
changes to the applications run on the system. We train recurrent neural
networks to learn a model of the system under consideration. As a proof of
concept, we train models specifically to predict future resource usage of
running applications.
"
330,"Size-aware Sharding For Improving Tail Latencies in In-memory Key-value
  Stores","  This paper introduces the concept of size-aware sharding to improve tail
latencies for in-memory key-value stores, and describes its implementation in
the Minos key-value store. Tail latencies are crucial in distributed
applications with high fan-out ratios, because overall response time is
determined by the slowest response. Size-aware sharding distributes requests
for keys to cores according to the size of the item associated with the key. In
particular, requests for small and large items are sent to disjoint subsets of
cores. Size-aware sharding improves tail latencies by avoiding head-of-line
blocking, in which a request for a small item gets queued behind a request for
a large item. Alternative size-unaware approaches to sharding, such as
keyhash-based sharding, request dispatching and stealing do not avoid
head-of-line blocking, and therefore exhibit worse tail latencies. The
challenge in implementing size-aware sharding is to maintain high throughput by
avoiding the cost of software dispatching and by achieving load balancing
between different cores. Minos uses hardware dispatch for all requests for
small items, which form the very large majority of all requests. It achieves
load balancing by adapting the number of cores handling requests for small and
large items to their relative presence in the workload. We compare Minos to
three state-of-the-art designs of in-memory KV stores. Compared to its closest
competitor, Minos achieves a 99th percentile latency that is up to two orders
of magnitude lower. Put differently, for a given value for the 99th percentile
latency equal to 10 times the mean service time, Minos achieves a throughput
that is up to 7.4 times higher.
"
331,Realizing Uncertainty-Aware Timing Stack in Embedded Operating System,"  Time awareness is critical to a broad range of emerging applications -- in
Cyber-Physical Systems and Internet of Things -- running on commodity platforms
and operating systems. Traditionally, time is synchronized across devices
through a best-effort background service whose performance is neither
observable nor controllable, thus consuming system resources independently of
application needs while not allowing the applications and OS services to adapt
to changes in uncertainty in system time. We advocate for rethinking how time
is managed in a system stack. In this paper, we propose a new clock model that
characterizes various sources of timing uncertainties in true time. We then
present a Kalman filter based time synchronization protocol that adapts to the
uncertainties exposed by the clock model. Our realization of a
uncertainty-aware clock model and synchronization protocol is based on a
standard embedded Linux platform.
"
332,End-to-end Analysis and Design of a Drone Flight Controller,"  Timing guarantees are crucial to cyber-physical applications that must bound
the end-to-end delay between sensing, processing and actuation. For example, in
a flight controller for a multirotor drone, the data from a gyro or inertial
sensor must be gathered and processed to determine the attitude of the
aircraft. Sensor data fusion is followed by control decisions that adjust the
flight of a drone by altering motor speeds. If the processing pipeline between
sensor input and actuation is not bounded, the drone will lose control and
possibly fail to maintain flight.
  Motivated by the implementation of a multithreaded drone flight controller on
the Quest RTOS, we develop a composable pipe model based on the system's task,
scheduling and communication abstractions. This pipe model is used to analyze
two semantics of end-to-end time: reaction time and freshness time. We also
argue that end-to-end timing properties should be factored in at the early
stage of application design. Thus, we provide a mathematical framework to
derive feasible task periods that satisfy both a given set of end-to-end timing
constraints and the schedulability requirement. We demonstrate the
applicability of our design approach by using it to port the Cleanflight flight
controller firmware to Quest on the Intel Aero board. Experiments show that
Cleanflight ported to Quest is able to achieve end-to-end latencies within the
predicted time bounds derived by analysis.
"
333,"KASR: A Reliable and Practical Approach to Attack Surface Reduction of
  Commodity OS Kernels","  Commodity OS kernels have broad attack surfaces due to the large code base
and the numerous features such as device drivers. For a real-world use case
(e.g., an Apache Server), many kernel services are unused and only a small
amount of kernel code is used. Within the used code, a certain part is invoked
only at runtime while the rest are executed at startup and/or shutdown phases
in the kernel's lifetime run. In this paper, we propose a reliable and
practical system, named KASR, which transparently reduces attack surfaces of
commodity OS kernels at runtime without requiring their source code. The KASR
system, residing in a trusted hypervisor, achieves the attack surface reduction
through a two-step approach: (1) reliably depriving unused code of executable
permissions, and (2) transparently segmenting used code and selectively
activating them. We implement a prototype of KASR on Xen-4.8.2 hypervisor and
evaluate its security effectiveness on Linux kernel-4.4.0-87-generic. Our
evaluation shows that KASR reduces the kernel attack surface by 64% and trims
off 40% of CVE vulnerabilities. Besides, KASR successfully detects and blocks
all 6 real-world kernel rootkits. We measure its performance overhead with
three benchmark tools (i.e., SPECINT, httperf and bonnie++). The experimental
results indicate that KASR imposes less than 1% performance overhead (compared
to an unmodified Xen hypervisor) on all the benchmarks.
"
334,"Push Forward: Global Fixed-Priority Scheduling of Arbitrary-Deadline
  Sporadic Task Systems","  The sporadic task model is often used to analyze recurrent execution of
identical tasks in real-time systems. A sporadic task defines an infinite
sequence of task instances, also called jobs, that arrive under the minimum
inter-arrival time constraint. To ensure the system safety, timeliness has to
be guaranteed in addition to functional correctness, i.e., all jobs of all
tasks have to be finished before the job deadlines. We focus on analyzing
arbitrary-deadline task sets on a homogeneous (identical) multiprocessor system
under any given global fixed-priority scheduling approach and provide a series
of schedulability tests with different tradeoffs between their time complexity
and their accuracy. Under the arbitrary-deadline setting, the relative deadline
of a task can be longer than the minimum inter-arrival time of the jobs of the
task. We show that global deadline-monotonic (DM) scheduling has a speedup
bound of $3-1/M$ against any optimal scheduling algorithms, where $M$ is the
number of identical processors, and prove that this bound is asymptotically
tight.
"
335,The Secure Machine: Efficient Secure Execution On Untrusted Platforms,"  In this work we present the Secure Machine, SeM for short, a CPU architecture
extension for secure computing. SeM uses a small amount of in-chip additional
hardware that monitors key communication channels inside the CPU chip, and only
acts when required. SeM provides confidentiality and integrity for a secure
program without trusting the platform software or any off-chip hardware. SeM
supports existing binaries of single- and multi-threaded applications running
on single- or multi-core, multi-CPU. The performance reduction caused by it is
only few percent, most of which is due to the memory encryption layer that is
commonly used in many secure architectures.
  We also developed SeM-Prepare, a software tool that automatically instruments
existing applications (binaries) with additional instructions so they can be
securely executed on our architecture without requiring any programming efforts
or the availability of the desired program`s source code.
  To enable secure data sharing in shared memory environments, we developed
Secure Distributed Shared Memory (SDSM), an efficient (time and memory)
algorithm for allowing thousands of compute nodes to share data securely while
running on an untrusted computing environment. SDSM shows a negligible
reduction in performance, and it requires negligible and hardware resources. We
developed Distributed Memory Integrity Trees, a method for enhancing single
node integrity trees for preserving the integrity of a distributed application
running on an untrusted computing environment. We show that our method is
applicable to existing single node integrity trees such as Merkle Tree, Bonsai
Merkle Tree, and Intel`s SGX memory integrity engine. All these building blocks
may be used together to form a practical secure system, and some can be used in
conjunction with other secure systems.
"
336,"Reactive NaN Repair for Applying Approximate Memory to Numerical
  Applications","  Applications in the AI and HPC fields require much memory capacity, and the
amount of energy consumed by main memory of server machines is ever increasing.
Energy consumption of main memory can be greatly reduced by applying
approximate computing in exchange for increased bit error rates. AI and HPC
applications are to some extent robust to bit errors because small numerical
errors are amortized by their iterative nature. However, a single occurrence of
a NaN due to bit-flips corrupts the whole calculation result. The issue is that
fixing every bit-flip using ECC incurs too much overhead because the bit error
rate is much higher than in normal environments. We propose a low-overhead
method to fix NaNs when approximate computing is applied to main memory. The
main idea is to reactively repair NaNs while leaving other non-fatal numerical
errors as-is to reduce the overhead. We implemented a prototype by leveraging
floating-point exceptions of x86 CPUs, and the preliminary evaluations showed
that our method incurs negligible overhead.
"
337,"iReplayer: In-situ and Identical Record-and-Replay for Multithreaded
  Applications","  Reproducing executions of multithreaded programs is very challenging due to
many intrinsic and external non-deterministic factors. Existing RnR systems
achieve significant progress in terms of performance overhead, but none targets
the in-situ setting, in which replay occurs within the same process as the
recording process. Also, most existing work cannot achieve identical replay,
which may prevent the reproduction of some errors.
  This paper presents iReplayer, which aims to identically replay multithreaded
programs in the original process (under the ""in-situ"" setting). The novel
in-situ and identical replay of iReplayer makes it more likely to reproduce
errors, and allows it to directly employ debugging mechanisms (e.g.
watchpoints) to aid failure diagnosis. Currently, iReplayer only incurs 3%
performance overhead on average, which allows it to be always enabled in the
production environment. iReplayer enables a range of possibilities, and this
paper presents three examples: two automatic tools for detecting buffer
overflows and use-after-free bugs, and one interactive debugging tool that is
integrated with GDB.
"
338,"Mosaic: An Application-Transparent Hardware-Software Cooperative Memory
  Manager for GPUs","  Modern GPUs face a trade-off on how the page size used for memory management
affects address translation and demand paging. Support for multiple page sizes
can help relax the page size trade-off so that address translation and demand
paging optimizations work together synergistically. However, existing page
coalescing and splintering policies require costly base page migrations that
undermine the benefits multiple page sizes provide. In this paper, we observe
that GPGPU applications present an opportunity to support multiple page sizes
without costly data migration, as the applications perform most of their memory
allocation en masse (i.e., they allocate a large number of base pages at once).
We show that this en masse allocation allows us to create intelligent memory
allocation policies which ensure that base pages that are contiguous in virtual
memory are allocated to contiguous physical memory pages. As a result,
coalescing and splintering operations no longer need to migrate base pages.
  We introduce Mosaic, a GPU memory manager that provides
application-transparent support for multiple page sizes. Mosaic uses base pages
to transfer data over the system I/O bus, and allocates physical memory in a
way that (1) preserves base page contiguity and (2) ensures that a large page
frame contains pages from only a single memory protection domain. This
mechanism allows the TLB to use large pages, reducing address translation
overhead. During data transfer, this mechanism enables the GPU to transfer only
the base pages that are needed by the application over the system I/O bus,
keeping demand paging overhead low.
"
339,"An Operating System Level Data Migration Scheme in Hybrid DRAM-NVM
  Memory Architecture","  With the emergence of Non-Volatile Memories (NVMs) and their shortcomings
such as limited endurance and high power consumption in write requests, several
studies have suggested hybrid memory architecture employing both Dynamic Random
Access Memory (DRAM) and NVM in a memory system. By conducting a comprehensive
experiments, we have observed that such studies lack to consider very important
aspects of hybrid memories including the effect of: a) data migrations on
performance, b) data migrations on power, and c) the granularity of data
migration. This paper presents an efficient data migration scheme at the
Operating System level in a hybrid DRAMNVM memory architecture. In the proposed
scheme, two Least Recently Used (LRU) queues, one for DRAM section and one for
NVM section, are used for the sake of data migration. With careful
characterization of the workloads obtained from PARSEC benchmark suite, the
proposed scheme prevents unnecessary migrations and only allows migrations
which benefits the system in terms of power and performance. The experimental
results show that the proposed scheme can reduce the power consumption up to
79% compared to DRAM-only memory and up to 48% compared to the state-of-the art
techniques.
"
340,Datacenter RPCs can be General and Fast,"  It is commonly believed that datacenter networking software must sacrifice
generality to attain high performance. The popularity of specialized
distributed systems designed specifically for niche technologies such as RDMA,
lossless networks, FPGAs, and programmable switches testifies to this belief.
In this paper, we show that such specialization is not necessary. eRPC is a new
general-purpose remote procedure call (RPC) library that offers performance
comparable to specialized systems, while running on commodity CPUs in
traditional datacenter networks based on either lossy Ethernet or lossless
fabrics. eRPC performs well in three key metrics: message rate for small
messages; bandwidth for large messages; and scalability to a large number of
nodes and CPU cores. It handles packet loss, congestion, and background request
execution. In microbenchmarks, one CPU core can handle up to 10 million small
RPCs per second, or send large messages at 75 Gbps. We port a production-grade
implementation of Raft state machine replication to eRPC without modifying the
core Raft source code. We achieve 5.5 microseconds of replication latency on
lossy Ethernet, which is faster than or comparable to specialized replication
systems that use programmable switches, FPGAs, or RDMA.
"
341,Minimizing Event-Handling Latencies in Secure Virtual Machines,"  Virtualization, after having found widespread adoption in the server and
desktop arena, is poised to change the architecture of embedded systems as
well. The benefits afforded by virtualization - enhanced isolation,
manageability, flexibility, and security - could be instrumental for developers
of embedded systems as an answer to the rampant increase in complexity.
  While mature desktop and server solutions exist, they cannot be easily reused
on embedded systems because of markedly different requirements. Unfortunately,
optimizations aimed at throughput, important for servers, often compromise on
aspects like predictable real-time behavior, which are crucial to many embedded
systems. In a similar vein, the requirements for small trusted computing bases,
lightweight inter-VM communication, and small footprints are often not
accommodated. This observation suggests that virtual machines for embedded
systems should be constructed from scratch with particular attention paid to
the specific requirements.
  In this paper, we set out with a virtual machine designed for
security-conscious workloads and describe the steps necessary to achieve good
event-handling latencies. That evolution is possible because the underlying
microkernel is well suited to satisfy real-time requirements. As the guest
system we chose Linux with the PREEMPT_RT configuration, which itself was
developed in an effort to bring down event-handling latencies in a general
purpose system. Our results indicate that the increase of event-handling
latencies of a guest running in a virtual machine does not, compared to native
execution, exceed a factor of two.
"
342,"Blocking time under basic priority inheritance: Polynomial bound and
  exact computation","  The Priority Inheritance Protocol (PIP) is arguably the best-known protocol
for resource sharing under real-time constraints. Its importance in modern
applications is undisputed. Nevertheless, because jobs may be blocked under PIP
for a variety of reasons, determining a job's maximum blocking time could be
difficult, and thus far no exact method has been proposed that does it.
Existing analysis methods are inefficient, inaccurate, and of limited
applicability. This article proposes a new characterization of the problem,
thus allowing a polynomial method for bounding the blocking time, and an exact,
optimally efficient method for blocking time computation under priority
inheritance that have a general applicability.
"
343,"LazyFP: Leaking FPU Register State using Microarchitectural
  Side-Channels","  Modern processors utilize an increasingly large register set to facilitate
efficient floating point and SIMD computation. This large register set is a
burden for operating systems, as its content needs to be saved and restored
when the operating system context switches between tasks. As an optimization,
the operating system can defer the context switch of the FPU and SIMD register
set until the first instruction is executed that needs access to these
registers. Meanwhile, the old content is left in place with the hope that the
current task might not use these registers at all. This optimization is
commonly called lazy FPU context switching. To make it possible, a processor
offers the ability to toggle the availability of instructions utilizing
floating point and SIMD registers. If the instructions are turned off, any
attempt of executing them will generate a fault.
  In this paper, we present an attack that exploits lazy FPU context switching
and allows an adversary to recover the FPU and SIMD register set of arbitrary
processes or VMs. The attack works on processors that transiently execute FPU
or SIMD instructions that follow an instruction generating the fault indicating
the first use of FPU or SIMD instructions. On operating systems using lazy FPU
context switching, the FPU and SIMD register content of other processes or
virtual machines can then be reconstructed via cache side effects.
  With SIMD registers not only being used for cryptographic computation, but
also increasingly for simple operations, such as copying memory, we argue that
lazy FPU context switching is a dangerous optimization that needs to be turned
off in all operating systems, if there is a chance that they run on affected
processors.
"
344,Integrating Proactive Mode Changes in Mixed Criticality Systems,"  In this work, we propose to integrate prediction algorithms to the scheduling
of mode changes under the Earliest-Deadline-First and Fixed-priority scheduling
in mixed-criticality real-time systems. The method proactively schedules a mode
change in the system based on state variables such as laxity, to the percentage
difference in the temporal distance between the completion time of the instance
of a task and its respective deadline, by the deadline (D) stipulated for the
task, in order to minimize deadline misses. The simulation model was validated
against an analytical model prior to the logical integration of the
Kalman-based prediction algorithm. Two study cases were presented, one covering
earliest-deadline first and the other the fixed-priority scheduling approach.
The results showed the gains in the adoption of the prediction approach for
both scheduling paradigms by presenting a significant reduction of the number
of missed deadlines for low-criticality tasks.
"
345,"Parallel Architecture Hardware and General Purpose Operating System
  Co-design","  Because most optimisations to achieve higher computational performance
eventually are limited, parallelism that scales is required. Parallelised
hardware alone is not sufficient, but software that matches the architecture is
required to gain best performance. For decades now, hardware design has been
guided by the basic design of existing software, to avoid the higher cost to
redesign the latter. In doing so, however, quite a variety of superior concepts
is excluded a priori. Consequently, co-design of both hardware and software is
crucial where highest performance is the goal. For special purpose application,
this co-design is common practice. For general purpose application, however, a
precondition for usability of a computer system is an operating system which is
both comprehensive and dynamic. As no such operating system has ever been
designed, a sketch for a comprehensive dynamic operating system is presented,
based on a straightforward hardware architecture to demonstrate how design
decisions regarding software and hardware do coexist and harmonise.
"
346,"TabulaROSA: Tabular Operating System Architecture for Massively Parallel
  Heterogeneous Compute Engines","  The rise in computing hardware choices is driving a reevaluation of operating
systems. The traditional role of an operating system controlling the execution
of its own hardware is evolving toward a model whereby the controlling
processor is distinct from the compute engines that are performing most of the
computations. In this context, an operating system can be viewed as software
that brokers and tracks the resources of the compute engines and is akin to a
database management system. To explore the idea of using a database in an
operating system role, this work defines key operating system functions in
terms of rigorous mathematical semantics (associative array algebra) that are
directly translatable into database operations. These operations possess a
number of mathematical properties that are ideal for parallel operating systems
by guaranteeing correctness over a wide range of parallel operations. The
resulting operating system equations provide a mathematical specification for a
Tabular Operating System Architecture (TabulaROSA) that can be implemented on
any platform. Simulations of forking in TabularROSA are performed using an
associative array implementation and compared to Linux on a 32,000+ core
supercomputer. Using over 262,000 forkers managing over 68,000,000,000
processes, the simulations show that TabulaROSA has the potential to perform
operating system functions on a massively parallel scale. The TabulaROSA
simulations show 20x higher performance as compared to Linux while managing
2000x more processes in fully searchable tables.
"
347,"Fast & Flexible IO : A Compositional Approach to Storage Construction
  for High-Performance Devices","  Building storage systems has remained the domain of systems experts for many
years. They are complex and difficult to implement. Extreme care is needed to
ensure necessary guarantees of performance and operational correctness.
Furthermore, because of restrictions imposed by kernel-based designs, many
legacy implementations have traded software flexibility for performance. Their
implementation is restricted to compiled languages such as C and assembler, and
reuse tends to be difficult or constrained. Nevertheless, storage systems are
implicitly well-suited to software reuse and compositional software
construction. There are many logical functions, such as block allocation,
caching, partitioning, metadata management and so forth, that are common across
most variants of storage. In this paper, we present Comanche, an open-source
project that considers, as first-class concerns, both compositional design and
reuse, and the need for high-performance.
"
348,"New Analysis Techniques for Supporting Hard Real-Time Sporadic DAG Task
  Systems on Multiprocessors","  The scheduling and schedulability analysis of real-time directed acyclic
graph (DAG) task systems have received much recent attention. The DAG model can
accurately represent intra-task parallelim and precedence constraints existing
in many application domains. Existing techniques show that analyzing the DAG
model is fundamentally more challenging compared to the ordinary sporadic task
model, due to the complex intra-DAG precedence constraints which may cause
rather pessimistic schedulability loss. However,such increased loss is
counter-intuitive because the DAG structure shall better exploit the
parallelism provided by the multiprocessor platform. Our observation is that
the intra-DAG precedence constraints, if not carefully considered by the
scheduling algorithm, may cause very unpredictable execution behaviors of
subtasks in a DAG and further cause pessimistic analysis. In this paper, we
present a set of novel scheduling and analysis techniques for better supporting
hard real-time sporadic DAG tasks on multiprocessors, through smartly defining
and analyzing the execution order of subtasks in each DAG. Evaluation
demonstrates that our developed utilization-based schedulability test is highly
efficient, which dramatically improves schedulability of existing
utilization-based tests by over 60% on average. Interestingly, when each DAG in
the system is an ordinary sporadic task, our test becomes identical to the
classical density test designed for the sporadic task model.
"
349,"A Spin-based model checking for the simple concurrent program on a
  preemptive RTOS","  We adapt an existing preemptive scheduling model of RTOS kernel by eChronos
from machine-assisted proof to Spin-based model checker. The model we
constructed can be automatically verified rather than formulating proofs by
hand. Moreover, we look into the designs of a Linux-like real-time
kernel--Piko/RT and the specification of ARMv7-M architecture to reconstruct
the model, and use LTL to specify a simple concurrent
programs--consumer/producer problem during the development stage of the kernel.
We show that under the preemptive scheduling and the mechanism of ARMv7-M, the
program will not suffer from race condition, starvation, and deadlock.
"
350,StreamBox-TZ: Secure Stream Analytics at the Edge with TrustZone,"  While it is compelling to process large streams of IoT data on the cloud
edge, doing so exposes the data to a sophisticated, vulnerable software stack
on the edge and hence security threats. To this end, we advocate isolating the
data and its computations in a trusted execution environment (TEE) on the edge,
shielding them from the remaining edge software stack which we deem untrusted.
This approach faces two major challenges: (1) executing high-throughput,
low-delay stream analytics in a single TEE, which is constrained by a low
trusted computing base (TCB) and limited physical memory; (2) verifying
execution of stream analytics as the execution involves untrusted software
components on the edge. In response, we present StreamBox-TZ (SBT), a stream
analytics engine for an edge platform that offers strong data security,
verifiable results, and good performance. SBT contributes a data plane designed
and optimized for a TEE based on ARM TrustZone. It supports continuous remote
attestation for analytics correctness and result freshness while incurring low
overhead. SBT only adds 42.5 KB executable to the TCB (16% of the entire TCB).
On an octa core ARMv8 platform, it delivers the state-of-the-art performance by
processing input events up to 140 MB/sec (12M events/sec) with sub-second
delay. The overhead incurred by SBT's security mechanism is less than 25%.
"
351,Regulating Access to System Sensors in Cooperating Programs,"  Modern operating systems such as Android, iOS, Windows Phone, and Chrome OS
support a cooperating program abstraction. Instead of placing all functionality
into a single program, programs cooperate to complete tasks requested by users.
However, untrusted programs may exploit interactions with other programs to
obtain unauthorized access to system sensors either directly or through
privileged services. Researchers have proposed that programs should only be
authorized to access system sensors on a user-approved input event, but these
methods do not account for possible delegation done by the program receiving
the user input event. Furthermore, proposed delegation methods do not enable
users to control the use of their input events accurately. In this paper, we
propose ENTRUST, a system that enables users to authorize sensor operations
that follow their input events, even if the sensor operation is performed by a
program different from the program receiving the input event. ENTRUST tracks
user input as well as delegation events and restricts the execution of such
events to compute unambiguous delegation paths to enable accurate and reusable
authorization of sensor operations. To demonstrate this approach, we implement
the ENTRUST authorization system for Android. We find, via a laboratory user
study, that attacks can be prevented at a much higher rate (54-64%
improvement); and via a field user study, that ENTRUST requires no more than
three additional authorizations per program with respect to the first-use
approach, while incurring modest performance (<1%) and memory overheads (5.5 KB
per program).
"
352,Runtime Analysis of Whole-System Provenance,"  Identifying the root cause and impact of a system intrusion remains a
foundational challenge in computer security. Digital provenance provides a
detailed history of the flow of information within a computing system,
connecting suspicious events to their root causes. Although existing
provenance-based auditing techniques provide value in forensic analysis, they
assume that such analysis takes place only retrospectively. Such post-hoc
analysis is insufficient for realtime security applications, moreover, even for
forensic tasks, prior provenance collection systems exhibited poor performance
and scalability, jeopardizing the timeliness of query responses.
  We present CamQuery, which provides inline, realtime provenance analysis,
making it suitable for implementing security applications. CamQuery is a Linux
Security Module that offers support for both userspace and in-kernel execution
of analysis applications. We demonstrate the applicability of CamQuery to a
variety of runtime security applications including data loss prevention,
intrusion detection, and regulatory compliance. In evaluation, we demonstrate
that CamQuery reduces the latency of realtime query mechanisms, while imposing
minimal overheads on system execution. CamQuery thus enables the further
deployment of provenance-based technologies to address central challenges in
computer security.
"
353,"X-Lap: A Systems Approach for Cross-Layer Profiling and Latency Analysis
  for Cyber-Physical Networks","  Networked control applications for cyber-physical networks demand predictable
and reliable real-time communication. Applications of this domain have to
cooperate with network protocols, the operating system, and the hardware to
improve safety properties and increase resource efficiency. In consequence, a
cross-layer approach is necessary for the design and holistic optimisation of
cyber-physical systems and networks. This paper presents X-Lap, a cross-layer,
inter-host timing analysis tool tailored to the needs of real-time
communication. We use X-Lap to evaluate the timing behaviour of a reliable
real-time communication protocol. Our analysis identifies parts of the protocol
which are responsible for unwanted jitter. To system designers, X-Lap provides
useful support for the design and evaluation of networked real-time systems.
"
354,User Manual for the Apple CoreCapture Framework,"  CoreCapture is Apple's primary logging and tracing framework for IEEE 802.11
on iOS and macOS. It allows users and developers to create comprehensive debug
output for analysis by Apple. In this manual, we provide an overview into the
concepts, show in detail how CoreCapture logs can be created on iOS and macOS,
and introduce the first CoreCapture dissector for Wireshark.
"
355,"Comparative Study of Virtual Machines and Containers for DevOps
  Developers","  In this work, we plan to develop a system to compare virtual machines with
container technology. We would devise ways to measure the administrator effort
of containers vs. Virtual Machines (VMs). Metrics that will be tested against
include human efforts required, ease of migration, resource utilization and
ease of use using containers and virtual machines.
"
356,"Profiling and Improving the Duty-Cycling Performance of Linux-based IoT
  Devices","  Minimizing the energy consumption of Linux-based devices is an essential step
towards their wide deployment in various IoT scenarios. Energy saving methods
such as duty-cycling aim to address this constraint by limiting the amount of
time the device is powered on. In this work we study and improve the amount of
time a Linux-based IoT device is powered on to accomplish its tasks. We analyze
the processes of system boot up and shutdown on two platforms, the Raspberry Pi
3 and Raspberry Pi Zero Wireless, and enhance duty-cycling performance by
identifying and disabling time-consuming or unnecessary units initialized in
the userspace. We also study whether SD card speed and SD card capacity
utilization affect boot up duration and energy consumption. In addition, we
propose 'Pallex', a parallel execution framework built on top of the 'systemd
init' system to run a user application concurrently with userspace
initialization. We validate the performance impact of Pallex when applied to
various IoT application scenarios: (i) capturing an image, (ii) capturing and
encrypting an image, (iii) capturing and classifying an image using the the
k-nearest neighbor algorithm, and (iv) capturing images and sending them to a
cloud server. Our results show that system lifetime is increased by 18.3%,
16.8%, 13.9% and 30.2%, for these application scenarios, respectively.
"
357,"Real-time Linux communications: an evaluation of the Linux communication
  stack for real-time robotic applications","  As robotics systems become more distributed, the communications between
different robot modules play a key role for the reliability of the overall
robot control. In this paper, we present a study of the Linux communication
stack meant for real-time robotic applications. We evaluate the real-time
performance of UDP based communications in Linux on multi-core embedded devices
as test platforms. We prove that, under an appropriate configuration, the Linux
kernel greatly enhances the determinism of communications using the UDP
protocol. Furthermore, we demonstrate that concurrent traffic disrupts the
bounded latencies and propose a solution by separating the real-time
application and the corresponding interrupt in a CPU.
"
358,"A Review of Software-Defined WLANs: Architectures and Central Control
  Mechanisms","  The significant growth in the number of WiFi-enabled devices as well as the
increase in the traffic conveyed through wireless local area networks (WLANs)
necessitate the adoption of new network control mechanisms. Specifically, dense
deployment of access points, client mobility, and emerging QoS demands bring
about challenges that cannot be effectively addressed by distributed
mechanisms. Recent studies show that software-defined WLANs (SDWLANs) simplify
network control, improve QoS provisioning, and lower the deployment cost of new
network control mechanisms. In this paper, we present an overview of SDWLAN
architectures and provide a qualitative comparison in terms of features such as
programmability and virtualization. In addition, we classify and investigate
the two important classes of centralized network control mechanisms: (i)
association control (AsC) and (ii) channel assignment (ChA). We study the basic
ideas employed by these mechanisms, and in particular, we focus on the metrics
utilized and the problem formulation techniques proposed. We present a
comparison of these mechanisms and identify open research problems.
"
359,Dependency Graph Approach for Multiprocessor Real-Time Synchronization,"  Over the years, many multiprocessor locking protocols have been designed and
analyzed. However, the performance of these protocols highly depends on how the
tasks are partitioned and prioritized and how the resources are shared locally
and globally. This paper answers a few fundamental questions when real-time
tasks share resources in multiprocessor systems. We explore the fundamental
difficulty of the multiprocessor synchronization problem and show that a very
simplified version of this problem is ${\mathcal NP}$-hard in the strong sense
regardless of the number of processors and the underlying scheduling paradigm.
Therefore, the allowance of preemption or migration does not reduce the
computational complexity. For the positive side, we develop a dependency-graph
approach, that is specifically useful for frame-based real-time tasks, in which
all tasks have the same period and release their jobs always at the same time.
We present a series of algorithms with speedup factors between $2$ and $3$
under semi-partitioned scheduling. We further explore methodologies and
tradeoffs of preemptive against non-preemptive scheduling algorithms and
partitioned against semi-partitioned scheduling algorithms. The approach is
extended to periodic tasks under certain conditions.
"
360,"On the Fly Orchestration of Unikernels: Tuning and Performance
  Evaluation of Virtual Infrastructure Managers","  Network operators are facing significant challenges meeting the demand for
more bandwidth, agile infrastructures, innovative services, while keeping costs
low. Network Functions Virtualization (NFV) and Cloud Computing are emerging as
key trends of 5G network architectures, providing flexibility, fast
instantiation times, support of Commercial Off The Shelf hardware and
significant cost savings. NFV leverages Cloud Computing principles to move the
data-plane network functions from expensive, closed and proprietary hardware to
the so-called Virtual Network Functions (VNFs). In this paper we deal with the
management of virtual computing resources (Unikernels) for the execution of
VNFs. This functionality is performed by the Virtual Infrastructure Manager
(VIM) in the NFV MANagement and Orchestration (MANO) reference architecture. We
discuss the instantiation process of virtual resources and propose a generic
reference model, starting from the analysis of three open source VIMs, namely
OpenStack, Nomad and OpenVIM. We improve the aforementioned VIMs introducing
the support for special-purpose Unikernels and aiming at reducing the duration
of the instantiation process. We evaluate some performance aspects of the VIMs,
considering both stock and tuned versions. The VIM extensions and performance
evaluation tools are available under a liberal open source licence.
"
361,Platform-Agnostic Steal-Time Measurement in a Guest Operating System,"  Steal time is a key performance metric for applications executed in a
virtualized environment. Steal time measures the amount of time the processor
is preempted by code outside the virtualized environment. This, in turn, allows
to compute accurately the execution time of an application inside a virtual
machine (i.e. it eliminates the time the virtual machine is suspended).
Unfortunately, this metric is only available in particular scenarios in which
the host and the guest OS are tightly coupled. Typical examples are the Xen
hypervisor and Linux-based guest OSes. In contrast, in scenarios where the
steal time is not available inside the virtualized environment, performance
measurements are, most often, incorrect.
  In this paper, we introduce a novel and platform agnostic approach to
calculate this steal time within the virtualized environment and without the
cooperation of the host OS. The theoretical execution time of a deterministic
microbenchmark is compared to its execution time in a virtualized environment.
When factoring in the virtual machine load, this solution -as simple as it is-
can compute the steal time. The preliminary results show that we are able to
compute the load of the physical processor within the virtual machine with high
accuracy.
"
362,BRAVO -- Biased Locking for Reader-Writer Locks,"  Designers of modern reader-writer locks confront a difficult trade-off
related to reader scalability. Locks that have a compact memory representation
for active readers will typically suffer under high intensity read-dominated
workloads when the ""reader indicator""' state is updated frequently by a diverse
set of threads, causing cache invalidation and coherence traffic. Other
designs, such as cohort reader-writer locks, use distributed reader indicators,
one per NUMA node. This improves reader-reader scalability, but also increases
the size of each lock instance. We propose a simple transformation BRAVO, that
augments any existing reader-writer lock, adding just two integer fields to the
lock instance. Readers make their presence known to writers by hashing their
thread's identity with the lock address, forming an index into a visible
readers table. Readers attempt to install the lock address into that element in
the table, making their existence known to potential writers. All locks and
threads in an address space can share the visible readers table. Updates by
readers tend to be diffused over the table, resulting in a NUMA-friendly
design. Crucially, readers of the same lock tend to write to different
locations in the array, reducing coherence traffic. Specifically, BRAVO allows
a simple compact lock to be augmented so as to provide scalable concurrent
reading but with only a modest increase in footprint.
"
363,TWA -- Ticket Locks Augmented with a Waiting Array,"  The classic ticket lock consists of ticket and grant fields. Arriving threads
atomically fetch-and-increment ticket and then wait for grant to become equal
to the value returned by the fetch-and-increment primitive, at which point the
thread holds the lock. The corresponding unlock operation simply increments
grant. This simple design has short code paths and fast handover (transfer of
ownership) under light contention, but may suffer degraded scalability under
high contention when multiple threads busy wait on the grant field -- so-called
global spinning. We propose a variation on ticket locks where long-term waiting
threads wait on locations in a waiting array instead of busy waiting on the
grant field. The single waiting array is shared among all locks. Short-term
waiting is accomplished in the usual manner on the grant field. The resulting
algorithm, TWA, improves on ticket locks by limiting the number of threads
spinning on the grant field at any given time, reducing the number of remote
caches requiring invalidation from the store that releases the lock. In turn,
this accelerates handover, and since the lock is held throughout the handover
operation, scalability improves. Under light or no contention, TWA yields
performance comparable to the classic ticket lock, avoiding the complexity and
extra accesses incurred by MCS locks in the handover path, but providing
performance above or beyond that of MCS at high contention.
"
364,Finding Crash-Consistency Bugs with Bounded Black-Box Crash Testing,"  We present a new approach to testing file-system crash consistency: bounded
black-box crash testing (B3). B3 tests the file system in a black-box manner
using workloads of file-system operations. Since the space of possible
workloads is infinite, B3 bounds this space based on parameters such as the
number of file-system operations or which operations to include, and
exhaustively generates workloads within this bounded space. Each workload is
tested on the target file system by simulating power-loss crashes while the
workload is being executed, and checking if the file system recovers to a
correct state after each crash. B3 builds upon insights derived from our study
of crash-consistency bugs reported in Linux file systems in the last five
years. We observed that most reported bugs can be reproduced using small
workloads of three or fewer file-system operations on a newly-created file
system, and that all reported bugs result from crashes after fsync() related
system calls. We build two tools, CrashMonkey and ACE, to demonstrate the
effectiveness of this approach. Our tools are able to find 24 out of the 26
crash-consistency bugs reported in the last five years. Our tools also revealed
10 new crash-consistency bugs in widely-used, mature Linux file systems, seven
of which existed in the kernel since 2014. Our tools also found a
crash-consistency bug in a verified file system, FSCQ. The new bugs result in
severe consequences like broken rename atomicity and loss of persisted files.
"
365,"Formalising Filesystems in the ACL2 Theorem Prover: an Application to
  FAT32","  In this work, we present an approach towards constructing executable
specifications of existing filesystems and verifying their functional
properties in a theorem proving environment. We detail an application of this
approach to the FAT32 filesystem.
  We also detail the methodology used to build up this type of executable
specification through a series of models which incrementally add features of
the target filesystem. This methodology has the benefit of allowing the
verification effort to start from simple models which encapsulate features
common to many filesystems and which are thus suitable for reuse.
"
366,Revitalizing Copybacks in Modern SSDs: Why and How,"  For modern flash-based SSDs, the performance overhead of internal data
migrations is dominated by the data transfer time, not by the flash program
time as in old SSDs. In order to mitigate the performance impact of data
migrations, we propose rCopyback, a restricted version of copyback. Rcopyback
works like the original copyback except that only n consecutive copybacks are
allowed. By limiting the number of successive copybacks, it guarantees that no
data reliability problem occurs when data is internally migrated using
rCopyback. In order to take a full advantage of rCopyback, we developed a
rCopyback-aware FTL, rcFTL, which intelligently decides whether rCopyback
should be used or not by exploiting varying host workloads. Our evaluation
results show that rcFTL can improve the overall I/O throughput by 54% on
average over an existing FTL which does not use copybacks.
"
367,"T-Visor: A Hypervisor for Mixed Criticality Embedded Real-time System
  with Hardware Virtualization Support","  Recently, embedded systems have not only requirements for hard real-time
behavior and reliability, but also diversified functional demands, such as
network functions. To satisfy these requirements, virtualization using
hypervisors is promising for embedded systems. However, as most of existing
hypervisors are designed for general-purpose information processing systems,
they rely on large system stacks, so that they are not suitable for mixed
criticality embedded real-time systems. Even in hypervisors designed for
embedded systems, their schedulers do not consider the diversity of real-time
requirements and rapid change in scheduling theory.
  We present the design and implementation of T-Visor, a hypervisor specialized
for mixed criticality embedded real-time systems. T-Visor supports ARM
architecture and realizes full virtualization using ARM Virtualization
Extensions. To guarantee real-time behavior, T-Visor provides a flexible
scheduling framework so that developers can select the most suitable scheduling
algorithm for their systems. Our evaluation showed that it performed better
compared to Xen/ARM. From these results, we conclude that our design and
implementation are more suitable for embedded real-time systems than the
existing hypervisors.
"
368,Time Protection: the Missing OS Abstraction,"  Timing channels enable data leakage that threatens the security of computer
systems, from cloud platforms to smartphones and browsers executing untrusted
third-party code. Preventing unauthorised information flow is a core duty of
the operating system, however, present OSes are unable to prevent timing
channels. We argue that OSes must provide time protection in addition to the
established memory protection. We examine the requirements of time protection,
present a design and its implementation in the seL4 microkernel, and evaluate
its efficacy as well as performance overhead on Arm and x86 processors.
"
369,Compact NUMA-Aware Locks,"  Modern multi-socket architectures exhibit non-uniform memory access (NUMA)
behavior, where access by a core to data cached locally on a socket is much
faster than access to data cached on a remote socket. Prior work offers several
efficient NUMA-aware locks that exploit this behavior by keeping the lock
ownership on the same socket, thus reducing remote cache misses and
inter-socket communication. Virtually all those locks, however, are
hierarchical in their nature, thus requiring space proportional to the number
of sockets. The increased memory cost renders NUMA-aware locks unsuitable for
systems that are conscious to space requirements of their synchronization
constructs, with the Linux kernel being the chief example.
  In this work, we present a compact NUMA-aware lock that requires only one
word of memory, regardless of the number of sockets in the underlying machine.
The new lock is a variant of an efficient (NUMA-oblivious) MCS lock, and
inherits its performant features, such as local spinning and a single atomic
instruction in the acquisition path. Unlike MCS, the new lock organizes waiting
threads in two queues, one composed of threads running on the same socket as
the current lock holder, and another composed of threads running on a different
socket(s).
  We integrated the new lock in the Linux kernel's qspinlock, one of the major
synchronization constructs in the kernel. Our evaluation using both user-space
and kernel benchmarks shows that the new lock has a single-thread performance
of MCS, but significantly outperforms the latter under contention, achieving a
similar level of performance when compared to other, state-of-the-art
NUMA-aware locks that require substantially more space.
"
370,DurableFS: A File System for Persistent Memory,"  With the availability of hybrid DRAM-NVRAM memory on the memory bus of CPUs,
a number of file systems on NVRAM have been designed and implemented. In this
paper we present the design and implementation of a file system on NVRAM called
DurableFS, which provides atomicity and durability of file operations to
applications. Due to the byte level random accessibility of memory, it is
possible to provide these guarantees without much overhead. We use standard
techniques like copy on write for data, and a redo log for metadata changes to
build an efficient file system which provides durability and atomicity
guarantees at the time a file is closed. Benchmarks on the implementation shows
that there is only a 7 %degradation in performance due to providing these
guarantees.
"
371,Transkernel: Bridging Monolithic Kernels to Peripheral Cores,"  Smart devices see a large number of ephemeral tasks driven by background
activities. In order to execute such a task, the OS kernel wakes up the
platform beforehand and puts it back to sleep afterwards. In doing so, the
kernel operates various IO devices and orchestrates their power state
transitions. Such kernel executions are inefficient as they mismatch typical
CPU hardware. They are better off running on a low-power, microcontroller-like
core, i.e., peripheral core, relieving CPU from the inefficiency.
  We therefore present a new OS structure, in which a lightweight virtual
executor called transkernel offloads specific phases from a monolithic kernel.
The transkernel translates stateful kernel execution through cross-ISA, dynamic
binary translation (DBT); it emulates a small set of stateless kernel services
behind a narrow, stable binary interface; it specializes for hot paths; it
exploits ISA similarities for lowering DBT cost.
  Through an ARM-based prototype, we demonstrate transkernel's feasibility and
benefit. We show that while cross-ISA DBT is typically used under the
assumption of efficiency loss, it can enable efficiency gain, even on
off-the-shelf hardware.
"
372,MiniOS: an instructional platform for teaching operating systems labs,"  Delivering hands-on practice laboratories for introductory courses on
operating systems is a difficult task. One of the main sources of the
difficulty is the sheer size and complexity of the operating systems software.
Consequently, some of the solutions adopted in the literature to teach
operating systems laboratory consider smaller and simpler systems, generally
referred to as instructional operating systems. This work continues in the same
direction and is threefold. First, it considers a simpler hardware platform.
Second, it argues that a minimal operating system is a viable option for
delivering laboratories. Third, it presents a laboratory teaching platform,
whereby students build a minimal operating system for an embedded hardware
platform. The proposed platform is called MiniOS. An important aspect of MiniOS
is that it is sufficiently supported with additional technical and pedagogic
material. Finally, the effectiveness of the proposed approach to teach
operating systems laboratories is illustrated through the experience of using
it to deliver laboratory projects in the Operating Systems course at the
University of Northern British Columbia. Finally, we discuss experimental
research in computing education and considered the qualitative results of this
work as part of a larger research endeavour.
"
373,"Modeling Processor Idle Times in MPSoC Platforms to Enable Integrated
  DPM, DVFS, and Task Scheduling Subject to a Hard Deadline","  Energy efficiency is one of the most critical design criteria for modern
embedded systems such as multiprocessor system-on-chips (MPSoCs). Dynamic
voltage and frequency scaling (DVFS) and dynamic power management (DPM) are two
major techniques for reducing energy consumption in such embedded systems.
Furthermore, MPSoCs are becoming more popular for many real-time applications.
One of the challenges of integrating DPM with DVFS and task scheduling of
real-time applications on MPSoCs is the modeling of idle intervals on these
platforms. In this paper, we present a novel approach for modeling idle
intervals in MPSoC platforms which leads to a mixed integer linear programming
(MILP) formulation integrating DPM, DVFS, and task scheduling of periodic task
graphs subject to a hard deadline. We also present a heuristic approach for
solving the MILP and compare its results with those obtained from solving the
MILP.
"
374,MI6: Secure Enclaves in a Speculative Out-of-Order Processor,"  Recent attacks have broken process isolation by exploiting microarchitectural
side channels that allow indirect access to shared microarchitectural state.
Enclaves strengthen the process abstraction to restore isolation guarantees.
  We propose MI6, an aggressive, speculative out-of-order processor capable of
providing secure enclaves under a threat model that includes an untrusted OS
and an attacker capable of mounting any software attack currently considered
practical, including control flow speculation attacks. MI6 is inspired by
Sanctum [16] and extends its isolation guarantee to more realistic memory
hierarchies. It also introduces a purge instruction, which is used only when a
secure process is scheduled, and implements it for a complex processor
microarchitecture. We model the performance impact of enclaves in MI6 through
FPGA emulation on AWS F1 FPGAs by running SPEC CINT2006 benchmarks on top of an
untrusted Linux OS. Security comes at the cost of approximately 16.4% average
slowdown for protected programs.
"
375,Divide et Impera: MemoryRanger Runs Drivers in Isolated Kernel Spaces,"  One of the main issues in the OS security is to provide trusted code
execution in an untrusted environment. During executing, kernel-mode drivers
allocate and process memory data: OS internal structures, users private
information, and sensitive data of third-party drivers. All this data and the
drivers code can be tampered with by kernel-mode malware. Microsoft security
experts integrated new features to fill this gap, but they are not enough:
allocated data can be stolen and patched and the drivers code can be dumped
without any security reaction. The proposed hypervisor-based system
(MemoryRanger) tackles this issue by executing drivers in separate kernel
enclaves with specific memory attributes. MemoryRanger protects code and data
using Intel VT-x and EPT features with low performance degradation on Windows
10 x64.
"
376,XOS: An Application-Defined Operating System for Data Center Servers,"  Rapid growth of datacenter (DC) scale, urgency of cost control, increasing
workload diversity, and huge software investment protection place unprecedented
demands on the operating system (OS) efficiency, scalability, performance
isolation, and backward-compatibility. The traditional OSes are not built to
work with deep-hierarchy software stacks, large numbers of cores, tail latency
guarantee, and increasingly rich variety of applications seen in modern DCs,
and thus they struggle to meet the demands of such workloads.
  This paper presents XOS, an application-defined OS for modern DC servers. Our
design moves resource management out of the OS kernel, supports customizable
kernel subsystems in user space, and enables elastic partitioning of hardware
resources. Specifically, XOS leverages modern hardware support for
virtualization to move resource management functionality out of the
conventional kernel and into user space, which lets applications achieve near
bare-metal performance. We implement XOS on top of Linux to provide backward
compatibility. XOS speeds up a set of DC workloads by up to 1.6X over our
baseline Linux on a 24-core server, and outperforms the state-of-the-art Dune
by up to 3.3X in terms of virtual memory management. In addition, XOS
demonstrates good scalability and strong performance isolation.
"
377,"Efficient, Dynamic Multi-tenant Edge Computation in EdgeOS","  In the future, computing will be immersed in the world around us -- from
augmented reality to autonomous vehicles to the Internet of Things. Many of
these smart devices will offer services that respond in real time to their
physical surroundings, requiring complex processing with strict performance
guarantees. Edge clouds promise a pervasive computational infrastructure a
short network hop away from end devices, but today's operating systems are a
poor fit to meet the goals of scalable isolation, dense multi-tenancy, and
predictable performance required by these emerging applications. In this paper
we present EdgeOS, a micro-kernel based operating system that meets these goals
by blending recent advances in real-time systems and network function
virtualization. EdgeOS introduces a Featherweight Process model that offers
lightweight isolation and supports extreme scalability even under high churn.
Our architecture provides efficient communication mechanisms, and low-overhead
per-client isolation. To achieve high performance networking, EdgeOS employs
kernel bypass paired with the isolation properties of Featherweight Processes.
We have evaluated our EdgeOS prototype for running high scale network
middleboxes using the Click software router and endpoint applications using
memcached. EdgeOS reduces startup latency by 170X compared to Linux processes
and over five orders of magnitude compared to containers, while providing three
orders of magnitude latency improvement when running 300 to 1000 edge-cloud
memcached instances on one server.
"
378,File System in Data-Centric Computing,"  The moving computation on the edge or near to data is the new trend that can
break the bandwidth wall and to unleash the power of next generation NVM or SCM
memory. File system is the important OS subsystem that plays the role of
mediator between the user-space application and storage device. The key goal of
the file system is to represent the file abstraction and to build the files'
namespace. In the current paradigm the file system needs to copy the metadata
and user data in the DRAM of the host with the goal to access and to modify the
user data on the host side. The DAX approach doesn't change the concept but to
build the way to bypass the page cache via the direct access to file's content
in persistent memory. Generally speaking, for the case of data-centric
computing, the file system needs to solve the opposite task not to copy data
into page cache but to deliver the processing activity near data on the storage
device side.
"
379,"A C-DAG task model for scheduling complex real-time tasks on
  heterogeneous platforms: preemption matters","  Recent commercial hardware platforms for embedded real-time systems feature
heterogeneous processing units and computing accelerators on the same
System-on-Chip. When designing complex real-time application for such
architectures, the designer needs to make a number of difficult choices: on
which processor should a certain task be implemented? Should a component be
implemented in parallel or sequentially? These choices may have a great impact
on feasibility, as the difference in the processor internal architectures
impact on the tasks' execution time and preemption cost. To help the designer
explore the wide space of design choices and tune the scheduling parameters, in
this paper we propose a novel real-time application model, called C-DAG,
specifically conceived for heterogeneous platforms. A C-DAG allows to specify
alternative implementations of the same component of an application for
different processing engines to be selected off-line, as well as conditional
branches to model if-then-else statements to be selected at run-time. We also
propose a schedulability analysis for the C-DAG model and a heuristic
allocation algorithm so that all deadlines are respected. Our analysis takes
into account the cost of preempting a task, which can be non-negligible on
certain processors. We demonstrate the effectiveness of our approach on a large
set of synthetic experiments by comparing with state of the art algorithms in
the literature.
"
380,"Multiverse: Easy Conversion of Runtime Systems into OS Kernels via
  Automatic Hybridization","  The hybrid runtime (HRT) model offers a path towards high performance and
efficiency. By integrating the OS kernel, runtime, and application, an HRT
allows the runtime developer to leverage the full feature set of the hardware
and specialize OS services to the runtime's needs. However, conforming to the
HRT model currently requires a port of the runtime to the kernel level, for
example to the Nautilus kernel framework, and this requires knowledge of kernel
internals. In response, we developed Multiverse, a system that bridges the gap
between a built-from-scratch HRT and a legacy runtime system. Multiverse allows
unmodified applications and runtimes to be brought into the HRT model without
any porting effort whatsoever by splitting the execution of the application
between the domains of a legacy OS and an HRT environment. We describe the
design and implementation of Multiverse and illustrate its capabilities using
the massive, widely-used Racket runtime system.
"
381,"PINPOINT: Efficient and Effective Resource Isolation for Mobile Security
  and Privacy","  Virtualization is frequently used to isolate untrusted processes and control
their access to sensitive resources. However, isolation usually carries a price
in terms of less resource sharing and reduced inter-process communication. In
an open architecture such as Android, this price and its impact on performance,
usability, and transparency must be carefully considered. Although previous
efforts in developing general-purpose isolation solutions have shown that some
of these negative side effects can be mitigated, doing so involves overcoming
significant design challenges by incorporating numerous additional platform
complexities not directly related to improved security. Thus, the general
purpose solutions become inefficient and burdensome if the end-user has only
specific security goals. In this paper, we present PINPOINT, a resource
isolation strategy that forgoes general-purpose solutions in favor of a
""building block"" approach that addresses specific end-user security goals.
PINPOINT embodies the concept of Linux Namespace lightweight isolation, but
does so in the Android Framework by guiding the security designer towards
isolation points that are contextually close to the resource(s) that need to be
isolated. This strategy allows the rest of the Framework to function fully as
intended, transparently. We demonstrate our strategy with a case study on
Android System Services, and show four applications of PINPOINTed system
services functioning with unmodified market apps. Our evaluation results show
that practical security and privacy advantages can be gained using our
approach, without inducing the problematic side-effects that other
general-purpose designs must address.
"
382,Can We Prove Time Protection?,"  Timing channels are a significant and growing security threat in computer
systems, with no established solution. We have recently argued that the OS must
provide time protection, in analogy to the established memory protection, to
protect applications from information leakage through timing channels. Based on
a recently-proposed implementation of time protection in the seL4 microkernel,
we investigate how such an implementation could be formally proved to prevent
timing channels. We postulate that this should be possible by reasoning about a
highly abstracted representation of the shared hardware resources that cause
timing channels.
"
383,User Space Network Drivers,"  The rise of user space packet processing frameworks like DPDK and netmap
makes low-level code more accessible to developers and researchers. Previously,
driver code was hidden in the kernel and rarely modified, or even looked at, by
developers working at higher layers. These barriers are gone nowadays, yet
developers still treat user space drivers as black-boxes magically accelerating
applications. We want to change this: every researcher building high-speed
network applications should understand the intricacies of the underlying
drivers, especially if they impact performance. We present ixy, a user space
network driver designed for simplicity and educational purposes to show that
fast packet IO is not black magic but careful engineering. ixy focuses on the
bare essentials of user space packet processing: a packet forwarder including
the whole NIC driver uses less than 1,000 lines of C code.
  This paper is partially written in tutorial style on the case study of our
implementations of drivers for both the Intel 82599 family and for virtual
VirtIO NICs. The former allows us to reason about driver and framework
performance on a stripped-down implementation to assess individual
optimizations in isolation. VirtIO support ensures that everyone can run it in
a virtual machine.
  Our code is available as free and open source under the BSD license at
https://github.com/emmericp/ixy
"
384,Fine-Grain Checkpointing with In-Cache-Line Logging,"  Non-Volatile Memory offers the possibility of implementing high-performance,
durable data structures. However, achieving performance comparable to
well-designed data structures in non-persistent (transient) memory is
difficult, primarily because of the cost of ensuring the order in which memory
writes reach NVM. Often, this requires flushing data to NVM and waiting a full
memory round-trip time.
  In this paper, we introduce two new techniques: Fine-Grained Checkpointing,
which ensures a consistent, quickly recoverable data structure in NVM after a
system failure, and In-Cache-Line Logging, an undo-logging technique that
enables recovery of earlier state without requiring cache-line flushes in the
normal case. We implemented these techniques in the Masstree data structure,
making it persistent and demonstrating the ease of applying them to a highly
optimized system and their low (5.9-15.4\%) runtime overhead cost.
"
385,Cloud Programming Simplified: A Berkeley View on Serverless Computing,"  Serverless cloud computing handles virtually all the system administration
operations needed to make it easier for programmers to use the cloud. It
provides an interface that greatly simplifies cloud programming, and represents
an evolution that parallels the transition from assembly language to high-level
programming languages. This paper gives a quick history of cloud computing,
including an accounting of the predictions of the 2009 Berkeley View of Cloud
Computing paper, explains the motivation for serverless computing, describes
applications that stretch the current limits of serverless, and then lists
obstacles and research opportunities required for serverless computing to
fulfill its full potential. Just as the 2009 paper identified challenges for
the cloud and predicted they would be addressed and that cloud use would
accelerate, we predict these issues are solvable and that serverless computing
will grow to dominate the future of cloud computing.
"
386,Dynamic Fault Tolerance Through Resource Pooling,"  Miniaturized satellites are currently not considered suitable for critical,
high-priority, and complex multi-phased missions, due to their low reliability.
As hardware-side fault tolerance (FT) solutions designed for larger spacecraft
can not be adopted aboard very small satellites due to budget, energy, and size
constraints, we developed a hybrid FT-approach based upon only COTS components,
commodity processor cores, library IP, and standard software. This approach
facilitates fault detection, isolation, and recovery in software, and utilizes
fault-coverage techniques across the embedded stack within an multiprocessor
system-on-chip (MPSoC). This allows our FPGA-based proof-of-concept
implementation to deliver strong fault-coverage even for missions with a long
duration, but also to adapt to varying performance requirements during the
mission. The operator of a spacecraft utilizing this approach can define
performance profiles, which allow an on-board computer (OBC) to trade between
processing capacity, fault coverage, and energy consumption using simple
heuristics. The software-side FT approach developed also offers advantages if
deployed aboard larger spacecraft through spare resource pooling, enabling an
OBC to more efficiently handle permanent faults. This FT approach in part
mimics a critical biological systems's way of tolerating and adjusting to
failures, enabling graceful ageing of an MPSoC.
"
387,"Denial-of-Service Attacks on Shared Cache in Multicore: Analysis and
  Prevention","  In this paper we investigate the feasibility of denial-of-service (DoS)
attacks on shared caches in multicore platforms. With carefully engineered
attacker tasks, we are able to cause more than 300X execution time increases on
a victim task running on a dedicated core on a popular embedded multicore
platform, regardless of whether we partition its shared cache or not. Based on
careful experimentation on real and simulated multicore platforms, we identify
an internal hardware structure of a non-blocking cache, namely the cache
writeback buffer, as a potential target of shared cache DoS attacks. We propose
an OS-level solution to prevent such DoS attacks by extending a
state-of-the-art memory bandwidth regulation mechanism. We implement the
proposed mechanism in Linux on a real multicore platform and show its
effectiveness in protecting against cache DoS attacks.
"
388,Pyronia: Intra-Process Access Control for IoT Applications,"  Third-party code plays a critical role in IoT applications, which generate
and analyze highly privacy-sensitive data. Unlike traditional desktop and
server settings, IoT devices mostly run a dedicated, single application. As a
result, vulnerabilities in third-party libraries within a process pose a much
bigger threat than on traditional platforms.
  We present Pyronia, a fine-grained access control system for IoT applications
written in high-level languages. Pyronia exploits developers' coarse-grained
expectations about how imported third-party code operates to restrict access to
files, devices, and specific network destinations, at the granularity of
individual functions. To efficiently protect such sensitive OS resources,
Pyronia combines three techniques: system call interposition, stack inspection,
and memory domains. This design avoids the need for application refactoring, or
unintuitive data flow analysis, while enforcing the developer's access policy
at run time. Our Pyronia prototype for Python runs on a custom Linux kernel,
and incurs moderate performance overhead on unmodified Python applications.
"
389,The Lustre Storage Architecture,"  This lengthy document often referred to as the ""Lustre Book"", contains a
detailed outline of Lustre file system architecture, as it was created between
2001 and 2005, in accordance with the requirements from various users. Now, in
2019, most features have been implemented, but some only recently, and some
along different lines of thought.
"
390,"Processor in Non-Volatile Memory (PiNVSM): Towards to Data-centric
  Computing in Decentralized Environment","  The AI problem has no solution in the environment of existing hardware stack
and OS architecture. CPU-centric model of computation has a huge number of
drawbacks that originate from memory hierarchy and obsolete architecture of the
computing core. The concept of mixing memory and logic has been around since
1960s. However, the concept of Processor-In-Memory (PIM) is unable to resolve
the critical issues of the CPU-centric computing model because of inevitable
replication of von Neumann architecture's drawbacks. The next generation of
NVM/SCM memory is able to give the second birth to the data-centric computing
paradigm. This paper presents a concept of Processor in Non-Volatile Memory
(PiNVSM) architecture. The basis of PiNVSM architecture is the concept of DPU
that contains the NVM memory and dedicated PU. All necessary PU's registers can
be implemented in the space of NVM memory. NVM memory of DPU is the single
space for storing and transformation of data. In the basis of PiNVSM
architecture lies the DPU array is able to overcome the limitations as Turing
machine model as von Neumann architecture. The DPU array hasn't a centralized
computing core. Every data portion has dedicated computing core that excludes
the necessity to transfer data to the place of data processing. Every DPU
contains data portion that is associated with the set of keywords. Any complex
data structure can be split on elementary items that can be stored into
independent DPU with dedicated computing core(s). One DPU is able to apply the
elementary transformation on one item. But the DPU array is able to make the
transformation of complex structure by means of concurrent execution of
elementary transformations in different DPUs. The PiNVSM architecture suggests
a principally new architecture of the computing core that creates a new
opportunity for data self-organization, data and code synthesis.
"
391,Nature of System Calls in CPU-centric Computing Paradigm,"  Modern operating systems are typically POSIX-compliant with major system
calls specified decades ago. The next generation of non-volatile memory (NVM)
technologies raise concerns about the efficiency of the traditional POSIX-based
systems. As one step toward building high performance NVM systems, we explore
the potential dependencies between system call performance and major hardware
components (e.g., CPU, memory, storage) under typical user cases (e.g.,
software compilation, installation, web browser, office suite) in this paper.
We build histograms for the most frequent and time-consuming system calls with
the goal to understand the nature of distribution on different platforms. We
find that there is a strong dependency between the system call performance and
the CPU architecture. On the other hand, the type of persistent storage plays a
less important role in affecting the performance.
"
392,MultiK: A Framework for Orchestrating Multiple Specialized Kernels,"  We present, MultiK, a Linux-based framework 1 that reduces the attack surface
for operating system kernels by reducing code bloat. MultiK ""orchestrates""
multiple kernels that are specialized for individual applications in a
transparent manner. This framework is flexible to accommodate different kernel
code reduction techniques and, most importantly, run the specialized kernels
with near-zero additional runtime overheads. MultiK avoids the overheads of
virtualization and runs natively on the system. For instance, an Apache
instance is shown to run on a kernel that has (a) 93.68% of its code reduced,
(b) 19 of 23 known kernel vulnerabilities eliminated and (c) with negligible
performance overheads (0.19%). MultiK is a framework that can integrate with
existing code reduction and OS security techniques. We demonstrate this by
using D-KUT and S-KUT -- two methods to profile and eliminate unwanted kernel
code. The whole process is transparent to the user applications because MultiK
does not require a recompilation of the application.
"
393,"A WCET-aware cache coloring technique for reducing interference in
  real-time systems","  The predictability of a system is the condition to give saferbound on worst
case execution timeof real-time tasks which are running on it. Commercial
off-the-shelf(COTS) processors are in-creasingly used in embedded systems and
contain shared cache memory. This component hasa hard predictable behavior
because its state depends of theexecution history of the systems.To increase
predictability of COTS component we use cache coloring, a technique widely
usedto partition cache memory. Our main contribution is a WCET aware heuristic
which parti-tion task according to the needs of each task. Our experiments are
made with CPLEX an ILPsolver with random tasks set generated running on
preemptive system scheduled with earliestdeadline first(EDF).
"
394,"Understanding and taming SSD read performance variability: HDFS case
  study","  In this paper we analyze the influence that lower layers (file system, OS,
SSD) have on HDFS' ability to extract maximum performance from SSDs on the read
path. We uncover and analyze three surprising performance slowdowns induced by
lower layers that result in HDFS read throughput loss. First, intrinsic
slowdown affects reads from every new file system extent for a variable amount
of time. Second, temporal slowdown appears temporarily and periodically and is
workload-agnostic. Third, in permanent slowdown, some files can individually
and permanently become slower after a period of time. We analyze the impact of
these slowdowns on HDFS and show significant throughput loss. Individually,
each of the slowdowns can cause a read throughput loss of 10-15%. However,
their effect is cumulative. When all slowdowns happen concurrently, read
throughput drops by as much as 30%. We further analyze mitigation techniques
and show that two of the three slowdowns could be addressed via increased IO
request parallelism in the lower layers. Unfortunately, HDFS cannot
automatically adapt to use such additional parallelism. Our results point to a
need for adaptability in storage stacks. The reason is that an access pattern
that maximizes performance in the common case is not necessarily the same one
that can mask performance fluctuations.
"
395,KEY-SSD: Access-Control Drive to Protect Files from Ransomware Attacks,"  Traditional techniques to prevent damage from ransomware attacks are to
detect and block attacks by monitoring the known behaviors such as frequent
name changes, recurring access to cryptographic libraries and exchange keys
with remote servers. Unfortunately, intelligent ransomware can easily bypass
these techniques. Another prevention technique is to recover from the backup
copy when a file is infected with ransomware. However, the data backup
technique requires extra storage space and can be removed with ransomware. In
this paper, we propose to implement an access control mechanism on a disk
drive, called a KEY-SSD disk drive. KEY-SSD is the data store and the last
barrier to data protection. Unauthorized applications will not be able to read
file data even if they bypass the file system defense, thus denying the block
request without knowing the disk's registered block key and completely
eliminating the possibility of the file becoming hostage to ransomware. We have
prototyped KEY-SSD and validated the usefulness of KEY-SSD by demonstrating 1)
selective block access control, 2) unauthorized data access blocking and 3)
negligible performance overhead. Our comprehensive evaluation of KEY-SSD for
various workloads show the KEY-SSD performance is hardly degraded due to OS
lightweight key transmission and access control drive optimization. We also
confirmed that KEY-SSD successfully protects the files in the actual ransomware
sample.
"
396,The Android Platform Security Model,"  Android is the most widely deployed end-user focused operating system. With
its growing set of use cases encompassing communication, navigation, media
consumption, entertainment, finance, health, and access to sensors, actuators,
cameras, or microphones, its underlying security model needs to address a host
of practical threats in a wide variety of scenarios while being useful to
non-security experts. The model needs to strike a difficult balance between
security, privacy, and usability for end users, assurances for app developers,
and system performance under tight hardware constraints. While many of the
underlying design principles have implicitly informed the overall system
architecture, access control mechanisms, and mitigation techniques, the Android
security model has previously not been formally published. This paper aims to
both document the abstract model and discuss its implications. Based on a
definition of the threat model and Android ecosystem context in which it
operates, we analyze how the different security measures in past and current
Android implementations work together to mitigate these threats. There are some
special cases in applying the security model, and we discuss such deliberate
deviations from the abstract model.
"
397,IOArbiter: Dynamic Provisioning of Backend Block Storage in the Cloud,"  With the advent of virtualization technology, cloud computing realizes
on-demand computing. The capability of dynamic resource provisioning is a
fundamental driving factor for users to adopt the cloud technology. The aspect
is important for cloud service providers to optimize the expense for running
the infrastructure as well. Despite many technological advances in related
areas, however, it is still the case that the infrastructure providers must
decide hardware configuration before deploying a cloud infrastructure,
especially from the storage's perspective. This static nature of the storage
provisioning practice can cause many problems in meeting tenant requirements,
which often come later into the picture. In this paper, we propose a system
called IOArbiter that enables the dynamic creation of underlying storage
implementation in the cloud. IOArbiter defers storage provisioning to the time
at which a tenant actually requests a storage space. As a result, an underlying
storage implementation, e.g., RAID-5, 6 or Ceph storage pool with 6+3 erasure
coding, will be materialized at the volume creation time. Using our prototype
implementation with Openstack Cinder, we show that IOArbiter can simultaneously
satisfy a number of different tenant demands, which may not be possible with a
static configuration strategy. Additionally QoS mechanisms such as admission
control and dynamic throttling help the system mitigate a noisy neighbor
problem significantly.
"
398,A Survey on Tiering and Caching in High-Performance Storage Systems,"  Although every individual invented storage technology made a big step towards
perfection, none of them is spotless. Different data store essentials such as
performance, availability, and recovery requirements have not met together in a
single economically affordable medium, yet. One of the most influential factors
is price. So, there has always been a trade-off between having a desired set of
storage choices and the costs. To address this issue, a network of various
types of storing media is used to deliver the high performance of expensive
devices such as solid state drives and non-volatile memories, along with the
high capacity of inexpensive ones like hard disk drives. In software, caching
and tiering are long-established concepts for handling file operations and
moving data automatically within such a storage network and manage data backup
in low-cost media. Intelligently moving data around different devices based on
the needs is the key insight for this matter. In this survey, we discuss some
recent pieces of research that have been done to improve high-performance
storage systems with caching and tiering techniques.
"
399,MANA for MPI: MPI-Agnostic Network-Agnostic Transparent Checkpointing,"  Transparently checkpointing MPI for fault tolerance and load balancing is a
long-standing problem in HPC. The problem has been complicated by the need to
provide checkpoint-restart services for all combinations of an MPI
implementation over all network interconnects. This work presents MANA
(MPI-Agnostic Network-Agnostic transparent checkpointing), a single code base
which supports all MPI implementation and interconnect combinations. The
agnostic properties imply that one can checkpoint an MPI application under one
MPI implementation and perhaps over TCP, and then restart under a second MPI
implementation over InfiniBand on a cluster with a different number of CPU
cores per node. This technique is based on a novel ""split-process"" approach,
which enables two separate programs to co-exist within a single process with a
single address space. This work overcomes the limitations of the two most
widely adopted transparent checkpointing solutions, BLCR and DMTCP/InfiniBand,
which require separate modifications to each MPI implementation and/or
underlying network API. The runtime overhead is found to be insignificant both
for checkpoint-restart within a single host, and when comparing a local MPI
computation that was migrated to a remote cluster against an ordinary MPI
computation running natively on that same remote cluster.
"
400,Programming Unikernels in the Large via Functor Driven Development,"  Compiling applications as unikernels allows them to be tailored to diverse
execution environments. Dependency on a monolithic operating system is replaced
with linkage against libraries that provide specific services. Doing so in
practice has revealed a major barrier: managing the configuration matrix across
heterogenous execution targets. A realistic unikernel application depends on
hundreds of libraries, each of which may place different demands on the
different target execution platforms (e.g.,~cryptographic acceleration).
  We propose a modular approach to structuring large scale codebases that
cleanly separates configuration, application and operating system logic. Our
implementation is built on the \mirage unikernel framework, using the \ocaml
language's powerful abstraction and metaprogramming facilities. Leveraging
modules allows us to build many components independently, with only loose
coupling through a set of standardised signatures. Components can be
parameterized by other components and composed. Our approach accounts for
state, dependency ordering, and error management, and our usage over the years
has demonstrated significant efficiency benefits by leveraging compiler
features such as global link-time optimisation during the configuration
process. We describe our application architecture and experiences via some
practical applications of our approach, and discuss how library development in
\mirage can facilitate adoption in other unikernel frameworks and programming
languages.
"
401,"Neverland: Lightweight Hardware Extensions for Enforcing Operating
  System Integrity","  The security of applications hinges on the trustworthiness of the operating
system, as applications rely on the OS to protect code and data. As a result,
multiple protections for safeguarding the integrity of kernel code and data are
being continuously proposed and deployed. These existing protections, however,
are far from ideal as they either provide partial protection, or require
complex and high overhead hardware and software stacks.
  In this work, we present Neverland: a low-overhead, hardware-assisted, memory
protection scheme that safeguards the operating system from rootkits and
kernel-mode malware. Once the system is done booting, Neverland's hardware
takes away the operating system's ability to overwrite certain configuration
registers, as well as portions of its own physical address space that contain
kernel code and security-critical data. Furthermore, it prohibits the CPU from
fetching privileged code from any memory region lying outside the physical
addresses assigned to the OS kernel and drivers (regardless of virtual page
permissions). This combination of protections makes it extremely hard for an
attacker to tamper with the kernel or introduce new privileged code into the
system -- even in the presence of kernel vulnerabilities. Our evaluations show
that the extra hardware required to support these protections incurs minimal
silicon and energy overheads. Neverland enables operating systems to reduce
their attack surface without having to rely on complex integrity monitoring
software or hardware.
"
402,MemoryRanger Prevents Hijacking FILE_OBJECT Structures in Windows Kernel,"  Windows OS kernel memory is one of the main targets of cyber-attacks. By
launching such attacks, hackers are succeeding in process privilege escalation
and tampering with users data by accessing kernel mode memory. This paper
considers a new example of such an attack, which results in access to the files
opened in an exclusive mode. Windows built-in security features prevent such
legal access, but attackers can circumvent them by patching dynamically
allocated objects. The research shows that the Windows 10, version 1809 x64 is
vulnerable to this attack. The paper provides an example of using MemoryRanger,
a hypervisor-based solution to prevent such attack by running kernel-mode
drivers in isolated kernel memory enclaves.
"
403,Scan-and-Pay on Android is Dangerous,"  Mobile payments have increased significantly in the recent years and
one-to-one money transfers are offered by a wide variety of smartphone
applications. These applications usually support scan-and-pay -- a technique
that allows a payer to easily scan the destination address of the payment
directly from the payee's smartphone screen. This technique is pervasive
because it does not require any particular hardware, only the camera, which is
present on all modern smartphones. However, in this work we show that a
malicious application can exploit the overlay feature on Android to compromise
the integrity of transactions that make use of the scan-and-pay technique. We
implement Malview, a proof-of-concept malicious application that runs in the
background on the payee's smartphone and show that it succeeds in redirecting
payments to a malicious wallet. We analyze the weaknesses of the current
defense mechanisms and discuss possible countermeasures against the attack.
"
404,Avoiding Scalability Collapse by Restricting Concurrency,"  Saturated locks often degrade the performance of a multithreaded application,
leading to a so-called scalability collapse problem. This problem arises when a
growing number of threads circulating through a saturated lock causes the
overall application performance to fade or even drop abruptly. This problem is
particularly (but not solely) acute on oversubscribed systems (systems with
more threads than available hardware cores). In this paper, we introduce GCR
(generic concurrency restriction), a mechanism that aims to avoid the
scalability collapse. GCR, designed as a generic, lock-agnostic wrapper,
intercepts lock acquisition calls, and decides when threads would be allowed to
proceed with the acquisition of the underlying lock. Furthermore, we present
GCR-NUMA, a non-uniform memory access (NUMA)-aware extension of GCR, that
strives to ensure that threads allowed to acquire the lock are those that run
on the same socket. The extensive evaluation that includes more than two dozen
locks, three machines and three benchmarks shows that GCR brings substantial
speedup (in many cases, up to three orders of magnitude) in case of contention
and growing thread counts, while introducing nearly negligible slowdown when
the underlying lock is not contended. GCR-NUMA brings even larger performance
gains starting at even lighter lock contention.
"
405,"$\Delta$elta: Differential Energy-Efficiency, Latency, and Timing
  Analysis for Real-Time Networks","  The continuously increasing degree of automation in many areas (e.g.
manufacturing engineering, public infrastructure) lead to the construction of
cyber-physical systems and cyber-physical networks. To both, time and energy
are the most critical operating resources. Considering for instance the Tactile
Internet specification, end-to-end latencies in these systems must be below
1ms, which means that both communication and system latencies are in the same
order of magnitude and must be predictably low. As control loops are commonly
handled over different variants of network infrastructure (e.g. mobile and
fibre links) particular attention must be payed to the design of reliable, yet
fast and energy-efficient data-transmission channels that are robust towards
unexpected transmission failures. As design goals are often conflicting (e.g.
high performance vs. low energy), it is necessary to analyze and investigate
trade-offs with regards to design decisions during the construction of
cyber-physical networks. In this paper, we present $\Delta$elta, an approach
towards a tool-supported construction process for cyber-physical networks.
$\Delta$elta extends the previously presented X-Lap tool by new analysis
features, but keeps the original measurements facilities unchanged.
$\Delta$elta jointly analyzes and correlates the runtime behavior (i.e.
performance, latency) and energy demand of individual system components. It
provides an automated analysis with precise thread-local time interpolation,
control-flow extraction, and examination of latency criticality. We further
demonstrate the applicability of $\Delta$elta with an evaluation of a
prototypical implementation.
"
406,"ExplFrame: Exploiting Page Frame Cache for Fault Analysis of Block
  Ciphers","  Page Frame Cache (PFC) is a purely software cache, present in modern Linux
based operating systems (OS), which stores the page frames that are recently
being released by the processes running on a particular CPU. In this paper, we
show that the page frame cache can be maliciously exploited by an adversary to
steer the pages of a victim process to some pre-decided attacker-chosen
locations in the memory. We practically demonstrate an end-to-end attack,
ExplFrame, where an attacker having only user-level privilege is able to force
a victim process's memory pages to vulnerable locations in DRAM and
deterministically conduct Rowhammer to induce faults. We further show that
these faults can be exploited for extracting the secret key of table-based
block cipher implementations. As a case study, we perform a full-key recovery
on OpenSSL AES by Rowhammer-induced single bit faults in the T-tables. We
propose an improvised fault analysis technique which can exploit any
Rowhammer-induced bit-flips in the AES T-tables.
"
407,Cache Contention on Multicore Systems: An Ontology-based Approach,"  Multicore processors have proved to be the right choice for both desktop and
server systems because it can support high performance with an acceptable
budget expenditure. In this work, we have compared several works in cache
contention and found that such works have identified several techniques for
cache contention other than cache size including FSB, Memory Controller and
prefetching hardware. We found that Distributed Intensity Online (DIO) is a
very promising cache contention algorithm since it can achieve up to 2% from
the optimal technique. Moreover, we propose a new framework for cache
contention based on resource ontologies. In which ontologies instances will be
used for communication between diverse processes instead of grasping schedules
based on hardware.
"
408,Neural Heterogeneous Scheduler,"  Access to parallel and distributed computation has enabled researchers and
developers to improve algorithms and performance in many applications. Recent
research has focused on next generation special purpose systems with multiple
kinds of coprocessors, known as heterogeneous system-on-chips (SoC). In this
paper, we introduce a method to intelligently schedule--and learn to
schedule--a stream of tasks to available processing elements in such a system.
We use deep reinforcement learning enabling complex sequential decision making
and empirically show that our reinforcement learning system provides for a
viable, better alternative to conventional scheduling heuristics with respect
to minimizing execution time.
"
409,Slicing the IO execution with ReLayTracer,"  Analyzing IO performance anomalies is a crucial task in various computing
environments, ranging from large-scale cloud applications to desktop
applications. However, the IO stack of modern operating systems is complicated,
making it hard to understand the performance anomalies with existing tools.
Kernel IO executions are frequently interrupted by internal kernel activities,
requiring a sophisticated IO profile tool to deal with the noises. Furthermore,
complicated interactions of concurrent IO requests cause different sources of
tail latencies in kernel IO stack. As a consequence, developers want to know
fine-grained latency profile across IO layers, which may differ in each IO
requests. To meet the requirements, this paper suggests ReLayTracer, a
per-request, per-layer IO profiler. ReLayTracer enables a detailed analysis to
identify root causes of IO performance anomalies by providing per-layer latency
distributions of each IO request, hardware performance behavior, and time spent
by kernel activities such as an interrupt.
"
410,On The Performance of ARM TrustZone,"  The TrustZone technology, available in the vast majority of recent ARM
processors, allows the execution of code inside a so-called secure world. It
effectively provides hardware-isolated areas of the processor for sensitive
data and code, i.e., a trusted execution environment (TEE). The OP-TEE
framework provides a collection of toolchain, open-source libraries and secure
kernel specifically geared to develop applications for TrustZone. This paper
presents an in-depth performance- and energy-wise study of TrustZone using the
OP-TEE framework, including secure storage and the cost of switching between
secure and unsecure worlds, using emulated and hardware measurements.
"
411,"Container Density Improvements with Dynamic Memory Extension using NAND
  Flash","  While containers efficiently implement the idea of operating-system-level
application virtualization, they are often insufficient to increase the server
utilization to a desirable level. The reason is that in practice many
containerized applications experience a limited amount of load while there are
few containers with a high load. In such a scenario, the virtual memory
management system can become the limiting factor to container density even
though the working set of active containers would fit into main memory. In this
paper, we describe and evaluate a system for transparently moving memory pages
in and out of DRAM and to a NAND Flash medium which is attached through the
memory bus. This technique, called Diablo Memory Expansion (DMX), operates on a
prediction model and is able to relieve the pressure on the memory system. We
present a benchmark for container density and show that even under an overall
constant workload, adding additional containers adversely affects
performance-critical applications in Docker. When using the DMX technology of
the Memory1 system, however, the performance of the critical workload remains
stable.
"
412,"Lawn: an Unbound Low Latency Timer Data Structure for Large Scale, High
  Throughput Systems","  As demand for Real-Time applications rises among the general public, the
importance of enabling large-scale, unbound algorithms to solve conventional
problems with low to no latency is critical for product viability. Timer
algorithms are prevalent in the core mechanisms behind operating systems,
network protocol implementation, stream processing, and several database
capabilities. This paper presents a field-tested algorithm for low latency,
unbound range timer structure, based upon the well excepted Timing Wheel
algorithm. Using a set of queues hashed by TTL, the algorithm allows for a
simpler implementation, minimal overhead no overflow and no performance
degradation in comparison to the current state of the algorithms under typical
use cases.
"
413,HTS: A Hardware Task Scheduler for Heterogeneous Systems,"  As the Moore's scaling era comes to an end, application specific hardware
accelerators appear as an attractive way to improve the performance and power
efficiency of our computing systems. A massively heterogeneous system with a
large number of hardware accelerators along with multiple general purpose CPUs
is a promising direction, but pose several challenges in terms of the run-time
scheduling of tasks on the accelerators and design granularity of accelerators.
This paper addresses these challenges by developing an example heterogeneous
system to enable multiple applications to share the available accelerators. We
propose to design accelerators at a lower abstraction to enable applications to
be broken down into tasks that can be mapped on several accelerators. We
observe that several real-life workloads can be broken down into common
primitives that are shared across many workloads. Finally, we propose and
design a hardware task scheduler inspired by the hardware schedulers in
out-of-order superscalar processors to efficiently utilize the accelerators in
the system by scheduling tasks in out-of-order and even speculatively. We
evaluate the proposed system on both real-life and synthetic benchmarks based
on Digital Signal Processing~(DSP) applications. Compared to executing the
benchmark on a system with sequential scheduling, proposed scheduler achieves
up to 12x improvement in performance.
"
414,Accelerator-level Parallelism,"  Future applications demand more performance, but technology advances have
been faltering. A promising approach to further improve computer system
performance under energy constraints is to employ hardware accelerators.
Already today, mobile systems concurrently employ multiple accelerators in what
we call accelerator-level parallelism (ALP). To spread the benefits of ALP more
broadly, we charge computer scientists to develop the science needed to best
achieve the performance and cost goals of ALP hardware and software.
"
415,Reproducible Execution of POSIX Programs with DiOS,"  In this paper, we describe DiOS, a lightweight model operating system which
can be used to execute programs that make use of POSIX APIs. Such executions
are fully reproducible: running the same program with the same inputs twice
will result in two exactly identical instruction traces, even if the program
uses threads for parallelism.
  DiOS is implemented almost entirely in portable C and C++: although its
primary platform is DiVM, a verification-oriented virtual machine, it can be
configured to also run in KLEE, a symbolic executor. Finally, it can be
compiled into machine code to serve as a user-mode kernel.
  Additionally, DiOS is modular and extensible. Its various components can be
combined to match both the capabilities of the underlying platform and to
provide services required by a particular program. New components can be added
to cover additional system calls or APIs.
  The experimental evaluation has two parts. DiOS is first evaluated as a
component of a program verification platform based on DiVM. In the second part,
we consider its portability and modularity by combining it with the symbolic
executor KLEE.
"
416,Executable formal semantics for the POSIX shell,"  The POSIX shell is a widely deployed, powerful tool for managing computer
systems. The shell is the expert's control panel, a necessary tool for
configuring, compiling, installing, maintaining, and deploying systems. Even
though it is powerful, critical infrastructure, the POSIX shell is maligned and
misunderstood. Its power and its subtlety are a dangerous combination.
  We define a formal, mechanized, executable small-step semantics for the POSIX
shell, which we call Smoosh. We compared Smoosh against seven other shells that
aim for some measure of POSIX compliance (bash, dash, zsh, OSH, mksh, ksh93,
and yash). Using three test suites---the POSIX test suite, the Modernish test
suite and shell diagnosis, and a test suite of our own device---we found
Smoosh's semantics to be the most conformant to the POSIX standard. Modernish
judges Smoosh to have the fewest bugs (just one, from using dash's parser) and
no quirks. To show that our semantics is useful beyond yielding a conformant,
executable shell, we also implemented a symbolic stepper to illuminate the
subtle behavior of the shell.
  Smoosh will serve as a foundation for formal study of the POSIX shell,
supporting research on and development of new shells, new tooling for shells,
and new shell designs.
"
417,Keystone: An Open Framework for Architecting TEEs,"  Trusted execution environments (TEEs) are being used in all the devices from
embedded sensors to cloud servers and encompass a range of cost, power
constraints, and security threat model choices. On the other hand, each of the
current vendor-specific TEEs makes a fixed set of trade-offs with little room
for customization. We present Keystone -- the first open-source framework for
building customized TEEs. Keystone uses simple abstractions provided by the
hardware such as memory isolation and a programmable layer underneath untrusted
components (e.g., OS). We build reusable TEE core primitives from these
abstractions while allowing platform-specific modifications and application
features. We showcase how Keystone-based TEEs run on unmodified RISC-V hardware
and demonstrate the strengths of our design in terms of security, TCB size,
execution of a range of benchmarks, applications, kernels, and deployment
models.
"
418,SSDFS: Towards LFS Flash-Friendly File System without GC operation,"  Solid state drives have a number of interesting characteristics. However,
there are numerous file system and storage design issues for SSDs that impact
the performance and device endurance. Many flash-oriented and flash-friendly
file systems introduce significant write amplification issue and GC overhead
that results in shorter SSD lifetime and necessity to use the NAND flash
overprovisioning. SSDFS file system introduces several authentic concepts and
mechanisms: logical segment, logical extent, segment's PEBs pool,
Main/Diff/Journal areas in the PEB's log, Diff-On-Write approach, PEBs
migration scheme, hot/warm data self-migration, segment bitmap, hybrid b-tree,
shared dictionary b-tree, shared extents b-tree. Combination of all suggested
concepts are able: (1) manage write amplification in smart way, (2) decrease GC
overhead, (3) prolong SSD lifetime, and (4) provide predictable file system's
performance.
"
419,"The Preliminary Evaluation of a Hypervisor-based Virtualization
  Mechanism for Intel Optane DC Persistent Memory Module","  Non-volatile memory (NVM) technologies, being accessible in the same manner
as DRAM, are considered indispensable for expanding main memory capacities.
Intel Optane DCPMM is a long-awaited product that drastically increases main
memory capacities. However, a substantial performance gap exists between DRAM
and DCPMM. In our experiments, the read/write latencies of DCPMM were 400% and
407% higher than those of DRAM, respectively. The read/write bandwidths were
37% and 8% of those of DRAM. This performance gap in main memory presents a new
challenge to researchers; we need a new system software technology supporting
emerging hybrid memory architecture. In this paper, we present RAMinate, a
hypervisor-based virtualization mechanism for hybrid memory systems, and a key
technology to address the performance gap in main memory systems. It provides
great flexibility in memory management and maximizes the performance of virtual
machines (VMs) by dynamically optimizing memory mappings. Through experiments,
we confirmed that even though a VM has only 1% of DRAM in its RAM, the
performance degradation of the VM was drastically alleviated by memory mapping
optimization. The elapsed time to finish the build of Linux Kernel in the VM
was 557 seconds, which was only 13% increase from the 100% DRAM case (i.e., 495
seconds). When the optimization mechanism was disabled, the elapsed time
increased to 624 seconds (i.e. 26% increase from the 100% DRAM case).
"
420,"EnclaveDom: Privilege Separation for Large-TCB Applications in Trusted
  Execution Environments","  Trusted executions environments (TEEs) such as Intel(R) SGX provide
hardware-isolated execution areas in memory, called enclaves. By running only
the most trusted application components in the enclave, TEEs enable developers
to minimize the TCB of their applications thereby helping to protect sensitive
application data. However, porting existing applications to TEEs often requires
considerable refactoring efforts, as TEEs provide a restricted interface to
standard OS features. To ease development efforts, TEE application developers
often choose to run their unmodified application in a library OS container that
provides a full in-enclave OS interface. Yet, this large-TCB development
approach now leaves sensitive in-enclave data exposed to potential bugs or
vulnerabilities in third-party code imported into the application. Importantly,
because the TEE libOS and the application run in the same enclave address
space, even the libOS management data structures (e.g. file descriptor table)
may be vulnerable to attack, where in traditional OSes these data structures
may be protected via privilege isolation.
  We present EnclaveDom, a privilege separation system for large-TCB TEE
applications that partitions an enclave into tagged memory regions, and
enforces per-region access rules at the granularity of individual in-enclave
functions. EnclaveDom is implemented on Intel SGX using Memory Protection Keys
(MPK) for memory tagging. To evaluate the security and performance impact of
EnclaveDom, we integrated EnclaveDom with the Graphene-SGX library OS. While no
product or component can be absolutely secure, our prototype helps protect
internal libOS management data structures against tampering by
application-level code. At every libOS system call, EnclaveDom then only grants
access to those internal data structures which the syscall needs to perform its
task.
"
421,An Optimized Disk Scheduling Algorithm With Bad-Sector Management,"  In high performance computing, researchers try to optimize the CPU Scheduling
algorithms, for faster and efficient working of computers. But a process needs
both CPU bound and I/O bound for completion of its execution. With
modernization of computers the speed of processor, hard-disk, and I/O devices
increases gradually. Still the data access speed of hard-disk is much less than
the speed of the processor. So when processor receives a data from secondary
memory it executes immediately and again it have to wait for receiving another
data. So the slowness of the hard-disk becomes a bottleneck in the performance
of processor. Researchers try to develop and optimize the traditional disk
scheduling algorithms for faster data transfer to and from secondary data
storage devices. In this paper we try to evolve an optimized scheduling
algorithm by reducing the seek time, the rotational latency, and the data
transfer time in runtime. This algorithm has the feature to manage the
bad-sectors of the hard-disk. It also attempts to reduce power consumption and
heat reduction by minimizing bad sector reading time.
"
422,"Good Motive but Bad Design: Why ARM MPU Has Become an Outcast in
  Embedded Systems","  As more and more embedded devices are connected to the Internet, leading to
the emergence of Internet-of-Things (IoT), previously less tested (and
insecure) devices are exposed to miscreants. To prevent them from being
compromised, the memory protection unit (MPU), which is readily available on
many devices, has the potential to become a free lunch for the defenders. To
our surprise, the MPU is seldom used by real-world products. The reasons are
multi-fold. While there are non-technical reasons such as compatibility issues,
more importantly, we found that MPU brings virtually no security enhancement at
the expense of decreased performance and responsiveness. In this work, we
investigate the MPU adoption in major real-time operating systems (RTOSs), in
particular, the FreeRTOS, and try to pinpoint the fundamental reasons to
explain why MPU is not favored. We hope our findings can inspire new remedial
solutions to change the situation. We also review the latest MPU design and
provide technical suggestions to build more secure embedded systems.
"
423,PAStime: Progress-aware Scheduling for Time-critical Computing,"  Over-estimation of worst-case execution times (WCETs) of real-time tasks
leads to poor resource utilization. In a mixed-criticality system (MCS), the
over-provisioning of CPU time to accommodate the WCETs of highly critical tasks
can lead to degraded service for less critical tasks. In this paper, we present
PAStime, a novel approach to monitor and adapt the runtime progress of highly
time-critical applications, to allow for improved service to lower criticality
tasks. In PAStime, CPU time is allocated to time-critical tasks according to
the delays they experience as they progress through their control flow graphs.
This ensures that as much time as possible is made available to improve the
Quality-of-Service of less critical tasks, while high-criticality tasks are
compensated after their delays.
  In this paper, we integrate PAStime with Adaptive Mixed-criticality (AMC)
scheduling. The LO-mode budget of a high-criticality task is adjusted according
to the delay observed at execution checkpoints. Using LITMUS-RT to implement
both AMC and AMC-PAStime, we observe that AMC-PAStime significantly improves
the utilization of low-criticality tasks while guaranteeing service to
high-criticality tasks.
"
424,Boomerang: Real-Time I/O Meets Legacy Systems,"  This paper presents Boomerang, an I/O system that integrates a legacy
non-real-time OS with one that is customized for timing-sensitive tasks. A
relatively small RTOS benefits from the pre-existing libraries, drivers and
services of the legacy system. Additionally, timing-critical tasks are isolated
from less critical tasks by securely partitioning machine resources among the
separate OSes. Boomerang guarantees end-to-end processing delays on input data
that requires outputs to be generated within specific time bounds.
  We show how to construct composable task pipelines in Boomerang that combine
functionality spanning a custom RTOS and a legacy Linux system. By dedicating
time-critical I/O to the RTOS, we ensure that complementary services provided
by Linux are sufficiently predictable to meet end-to-end service guarantees.
While Boomerang benefits from spatial isolation, it also outperforms a
standalone Linux system using deadline-based CPU reservations for pipeline
tasks. We also show how Boomerang outperforms a virtualized system called ACRN,
designed for automotive systems.
"
425,MicroTEE: Designing TEE OS Based on the Microkernel Architecture,"  ARM TrustZone technology is widely used to provide Trusted Execution
Environments (TEE) for mobile devices. However, most TEE OSes are implemented
as monolithic kernels. In such designs, device drivers, kernel services and
kernel modules all run in the kernel, which results in large size of the
kernel. It is difficult to guarantee that all components of the kernel have no
security vulnerabilities in the monolithic kernel architecture, such as the
integer overflow vulnerability in Qualcomm QSEE TrustZone and the TZDriver
vulnerability in HUAWEI Hisilicon TEE architecture. This paper presents
MicroTEE, a TEE OS based on the microkernel architecture. In MicroTEE, the
microkernel provides strong isolation for TEE OS's basic services, such as
crypto service and platform key management service. The kernel is only
responsible for providing core services such as address space management,
thread management, and inter-process communication. Other fundamental services,
such as crypto service and platform key management service are implemented as
applications at the user layer. Crypto Services and Key Management are used to
provide Trusted Applications (TAs) with sensitive information encryption, data
signing, and platform attestation functions. Our design avoids the compromise
of the whole TEE OS if only one kernel service is vulnerable. A monitor has
also been added to perform the switch between the secure world and the normal
world. Finally, we implemented a MicroTEE prototype on the Freescale i.MX6Q
Sabre Lite development board and tested its performance. Evaluation results
show that the performance of cryptographic operations in MicroTEE is better
than it in Linux when the size of data is small.
"
426,A Least-Privilege Memory Protection Model for Modern Hardware,"  We present a new least-privilege-based model of addressing on which to base
memory management functionality in an OS for modern computers like phones or
server-based accelerators. Existing software assumptions do not account for
heterogeneous cores with different views of the address space, leading to the
related problems of numerous security bugs in memory management code (for
example programming IOMMUs), and an inability of mainstream OSes to securely
manage the complete set of hardware resources on, say, a phone System-on-Chip.
  Our new work is based on a recent formal model of address translation
hardware which views the machine as a configurable network of address spaces.
We refine this to capture existing address translation hardware from modern
SoCs and accelerators at a sufficiently fine granularity to model minimal
rights both to access memory and configure translation hardware. We then build
an executable specification in Haskell, which expresses the model and metadata
structures in terms of partitioned capabilities. Finally, we show a fully
functional implementation of the model in C created by extending the capability
system of the Barrelfish research OS.
  Our evaluation shows that our unoptimized implementation has comparable (and
in some cases) better performance than the Linux virtual memory system, despite
both capturing all the functionality of modern hardware addressing and enabling
least-privilege, decentralized authority to access physical memory and devices.
"
427,Tvarak: Software-managed hardware offload for DAX NVM storage redundancy,"  Tvarak efficiently implements system-level redundancy for direct-access (DAX)
NVM storage. Production storage systems complement device-level ECC (which
covers media errors) with system-checksums and cross-device parity. This
system-level redundancy enables detection of and recovery from data corruption
due to device firmware bugs (e.g., reading data from the wrong physical
location). Direct access to NVM penalizes software-only implementations of
system-level redundancy, forcing a choice between lack of data protection or
significant performance penalties. Offloading the update and verification of
system-level redundancy to Tvarak, a hardware controller co-located with the
last-level cache, enables efficient protection of data from such bugs in memory
controller and NVM DIMM firmware. Simulation-based evaluation with seven
data-intensive applications shows Tvarak's performance and energy efficiency.
For example, Tvarak reduces Redis set-only performance by only 3%, compared to
50% reduction for a state-of-the-art software-only approach.
"
428,"Kernel/User-level Collaborative Persistent Memory File System with
  Efficiency and Protection","  Emerging high performance non-volatile memories recall the importance of
efficient file system design. To avoid the virtual file system (VFS) and
syscall overhead as in these kernel-based file systems, recent works deploy
file systems directly in user level. Unfortunately, a userlevel file system can
easily be corrupted by a buggy program with misused pointers, and is hard to
scale on multi-core platforms which incorporates a centralized coordination
service. In this paper, we propose KucoFS, a Kernel and user-level
collaborative file system. It consists of two parts: a user-level library with
direct-access interfaces, and a kernel thread, which performs metadata updates
and enforces write protection by toggling the permission bits in the page
table. Hence, KucoFS achieves both direct-access of user-level designs and
fine-grained write protection of kernel-level ones. We further explore its
scalability to multicores: For metadata scalability, KucoFS rebalances the
pathname resolution overhead between the kernel and userspace, by adopting the
index offloading technique. For data access efficiency, it coordinates the data
allocation between kernel and userspace, and uses range-lock write and
lock-free read to improve concurrency. Experiments on Optane DC persistent
memory show that KucoFS significantly outperforms existing file systems and
shows better scalability.
"
429,SGX-LKL: Securing the Host OS Interface for Trusted Execution,"  Hardware support for trusted execution in modern CPUs enables tenants to
shield their data processing workloads in otherwise untrusted cloud
environments. Runtime systems for the trusted execution must rely on an
interface to the untrusted host OS to use external resources such as storage,
network, and other functions. Attackers may exploit this interface to leak data
or corrupt the computation.
  We describe SGX-LKL, a system for running Linux binaries inside of Intel SGX
enclaves that only exposes a minimal, protected and oblivious host interface:
the interface is (i) minimal because SGX-LKL uses a complete library OS inside
the enclave, including file system and network stacks, which requires a host
interface with only 7 calls; (ii) protected because SGX-LKL transparently
encrypts and integrity-protects all data passed via low-level I/O operations;
and (iii) oblivious because SGX-LKL performs host operations independently of
the application workload. For oblivious disk I/O, SGX-LKL uses an encrypted
ext4 file system with shuffled disk blocks. We show that SGX-LKL protects
TensorFlow training with a 21% overhead.
"
430,Porting of eChronos RTOS on RISC-V Architecture,"  eChronos is a formally verified Real Time Operating System(RTOS) designed for
embedded micro-controllers. eChronos was targeted for tightly constrained
devices without memory management units. Currently, eChronos is available on
proprietary designs like ARM, PowerPC and Intel architectures. eChronos is
adopted in safety critical systems like aircraft control system and medical
implant devices. eChronos is one of the very few system software not been
ported to RISC-V. RISC-V is an open-source Instruction Set Architecture (ISA)
that enables new era of processor development. Many standard Operating Systems,
software tool chain have migrated to the RISC-V architecture. According to the
latest trends, RISC-V is replacing many proprietary chips. As a secure RTOS, it
is attractive to port on an open-source ISA. SHAKTI and PicoRV32 are some of
the proven open-source RISC-V designs available. Now having a secure RTOS on an
open-source hardware design, designed based on an open-source ISA makes it more
interesting. In addition to this, the current architectures supported by
eChronos are all proprietary designs, and porting eChronos to the RISC-V
architecture increases the secure system development as a whole. This paper,
presents an idea of porting eChronos on a chip which is open-source and
effective, thus reducing the cost of embedded systems. Designing a open-source
system that is completely open-source reduces the overall cost, increased the
security and can be critically reviewed. This paper explores the design and
architecture aspect involved in porting eChronos to RISC-V. The authors have
successfully ported eChronos to RISC-V architecture and verified it on spike.
The port of RISC-V to eChronos is made available open-source by authors. Along
with that, the safe removal of architectural dependencies and subsequent
changes in eChronos are also analyzed.
"
431,"CrowdOS: A Ubiquitous Operating System for Crowdsourcing and Mobile
  Crowd Sensing","  With the rise of crowdsourcing and mobile crowdsensing techniques, a large
number of crowdsourcing applications or platforms (CAP) have appeared. In the
mean time, CAP-related models and frameworks based on different research
hypotheses are rapidly emerging, and they usually address specific issues from
a certain perspective. Due to different settings and conditions, different
models are not compatible with each other. However, CAP urgently needs to
combine these techniques to form a unified framework. In addition, these models
needs to be learned and updated online with the extension of crowdsourced data
and task types, thus requiring a unified architecture that integrates lifelong
learning concepts and breaks down the barriers between different modules. This
paper draws on the idea of ubiquitous operating systems and proposes a novel OS
(CrowdOS), which is an abstract software layer running between native OS and
application layer. In particular, based on an in-depth analysis of the complex
crowd environment and diverse characteristics of heterogeneous tasks, we
construct the OS kernel and three core frameworks including Task Resolution and
Assignment Framework (TRAF), Integrated Resource Management (IRM), and Task
Result quality Optimization (TRO). In addition, we validate the usability of
CrowdOS, module correctness and development efficiency. Our evaluation further
reveals TRO brings enormous improvement in efficiency and a reduction in energy
consumption.
"
432,Mapping Spiking Neural Networks to Neuromorphic Hardware,"  Neuromorphic hardware platforms implement biological neurons and synapses to
execute spiking neural networks (SNNs) in an energy-efficient manner. We
present SpiNeMap, a design methodology to map SNNs to crossbar-based
neuromorphic hardware, minimizing spike latency and energy consumption.
SpiNeMap operates in two steps: SpiNeCluster and SpiNePlacer. SpiNeCluster is a
heuristic-based clustering technique to partition SNNs into clusters of
synapses, where intracluster local synapses are mapped within crossbars of the
hardware and inter-cluster global synapses are mapped to the shared
interconnect. SpiNeCluster minimizes the number of spikes on global synapses,
which reduces spike congestion on the shared interconnect, improving
application performance. SpiNePlacer then finds the best placement of local and
global synapses on the hardware using a meta-heuristic-based approach to
minimize energy consumption and spike latency. We evaluate SpiNeMap using
synthetic and realistic SNNs on the DynapSE neuromorphic hardware. We show that
SpiNeMap reduces average energy consumption by 45% and average spike latency by
21%, compared to state-of-the-art techniques.
"
433,"The Study of Dynamic Caching via State Transition Field -- the Case of
  Time-Invariant Popularity","  This two-part paper investigates cache replacement schemes with the objective
of developing a general model to unify the analysis of various replacement
schemes and illustrate their features. To achieve this goal, we study the
dynamic process of caching in the vector space and introduce the concept of
state transition field (STF) to model and characterize replacement schemes. In
the first part of this work, we consider the case of time-invariant content
popularity based on the independent reference model (IRM). In such case, we
demonstrate that the resulting STFs are static, and each replacement scheme
leads to a unique STF. The STF determines the expected trace of the dynamic
change in the cache state distribution, as a result of content requests and
replacements, from any initial point. Moreover, given the replacement scheme,
the STF is only determined by the content popularity. Using four example
schemes including random replacement (RR) and least recently used (LRU), we
show that the STF can be used to analyze replacement schemes such as finding
their steady states, highlighting their differences, and revealing insights
regarding the impact of knowledge of content popularity. Based on the above
results, STF is shown to be useful for characterizing and illustrating
replacement schemes. Extensive numeric results are presented to demonstrate
analytical STFs and STFs from simulations for the considered example
replacement schemes.
"
434,"The Study of Dynamic Caching via State Transition Field -- the Case of
  Time-Varying Popularity","  In the second part of this two-part paper, we extend the study of dynamic
caching via state transition field (STF) to the case of time-varying content
popularity. The objective of this part is to investigate the impact of
time-varying content popularity on the STF and how such impact accumulates to
affect the performance of a replacement scheme. Unlike the case in the first
part, the STF is no longer static over time, and we introduce instantaneous STF
to model it. Moreover, we demonstrate that many metrics, such as instantaneous
state caching probability and average cache hit probability over an arbitrary
sequence of requests, can be found using the instantaneous STF. As a steady
state may not exist under time-varying content popularity, we characterize the
performance of replacement schemes based on how the instantaneous STF of a
replacement scheme after a content request impacts on its cache hit probability
at the next request. From this characterization, insights regarding the
relations between the pattern of change in the content popularity, the
knowledge of content popularity exploited by the replacement schemes, and the
effectiveness of these schemes under time-varying popularity are revealed. In
the simulations, different patterns of time-varying popularity, including the
shot noise model, are experimented. The effectiveness of example replacement
schemes under time-varying popularity is demonstrated, and the numerical
results support the observations from the analytic results.
"
435,Cache Where you Want! Reconciling Predictability and Coherent Caching,"  Real-time and cyber-physical systems need to interact with and respond to
their physical environment in a predictable time. While multicore platforms
provide incredible computational power and throughput, they also introduce new
sources of unpredictability. Large fluctuations in latency to access data
shared between multiple cores is an important contributor to the overall
execution-time variability. In addition to the temporal unpredictability
introduced by caching, parallel applications with data shared across multiple
cores also pay additional latency overheads due to data coherence. Analyzing
the impact of data coherence on the worst-case execution-time of real-time
applications is challenging because only scarce implementation details are
revealed by manufacturers. This paper presents application level control for
caching data at different levels of the cache hierarchy. The rationale is that
by caching data only in shared cache it is possible to bypass private caches.
The access latency to data present in caches becomes independent of its
coherence state. We discuss the existing architectural support as well as the
required hardware and OS modifications to support the proposed cacheability
control. We evaluate the system on an architectural simulator. We show that the
worst case execution time for a single memory write request is reduced by 52%.
"
436,Data Centers Job Scheduling with Deep Reinforcement Learning,"  Efficient job scheduling on data centers under heterogeneous complexity is
crucial but challenging since it involves the allocation of multi-dimensional
resources over time and space. To adapt the complex computing environment in
data centers, we proposed an innovative Advantage Actor-Critic (A2C) deep
reinforcement learning based approach called A2cScheduler for job scheduling.
A2cScheduler consists of two agents, one of which, dubbed the actor, is
responsible for learning the scheduling policy automatically and the other one,
the critic, reduces the estimation error. Unlike previous policy gradient
approaches, A2cScheduler is designed to reduce the gradient estimation variance
and to update parameters efficiently. We show that the A2cScheduler can achieve
competitive scheduling performance using both simulated workloads and real data
collected from an academic data center.
"
437,Making Code Re-randomization Practical with MARDU,"  Defense techniques such as Data Execution Prevention (DEP) and Address Space
Layout Randomization (ASLR) were the early role models preventing primitive
code injection and return-oriented programming (ROP) attacks. Notably, these
techniques did so in an elegant and utilitarian manner, keeping performance and
scalability in the forefront, making them one of the few widely-adopted defense
techniques. As code re-use has evolved in complexity from JIT-ROP, to BROP and
data-only attacks, defense techniques seem to have tunneled on defending at all
costs, losing-their-way in pragmatic defense design. Some fail to provide
comprehensive coverage, being too narrow in scope, while others provide
unrealistic overheads leaving users willing to take their chances to maintain
performance expectations.
  We present Mardu, an on-demand system-wide re-randomization technique that
improves re-randomization and refocuses efforts to simultaneously embrace key
characteristics of defense techniques: security, performance, and scalability.
Our code sharing with diversification is achieved by implementing reactive and
scalable, rather than continuous or one-time diversification while the use of
hardware supported eXecute-only Memory (XoM) and shadow stack prevent memory
disclosure; entwining and enabling code sharing further minimizes needed
tracking, patching costs, and memory overhead. Mardu's evaluation shows
performance and scalability to have low average overhead in both
compute-intensive (5.5% on SPEC) and real-world applications (4.4% on NGINX).
With this design, Mardu demonstrates that strong and scalable security
guarantees are possible to achieve at a practical cost to encourage deployment.
"
438,Multiprocessor Real-Time Locking Protocols: A Systematic Review,"  We systematically survey the literature on analytically sound multiprocessor
real-time locking protocols from 1988 until 2018, covering the following
topics: progress mechanisms that prevent the lock-holder preemption problem,
spin-lock protocols, binary semaphore protocols, independence-preserving (or
fully preemptive) locking protocols, reader-writer and k-exclusion
synchronization, support for nested critical sections, and implementation and
system-integration aspects. A special focus is placed on the
suspension-oblivious and suspension-aware analysis approaches for semaphore
protocols, their respective notions of priority inversion, optimality criteria,
lower bounds on maximum priority-inversion blocking, and matching
asymptotically optimal locking protocols.
"
439,"SplitFS: Reducing Software Overhead in File Systems for Persistent
  Memory","  We present SplitFS, a file system for persistent memory (PM) that reduces
software overhead significantly compared to state-of-the-art PM file systems.
SplitFS presents a novel split of responsibilities between a user-space library
file system and an existing kernel PM file system. The user-space library file
system handles data operations by intercepting POSIX calls, memory-mapping the
underlying file, and serving the read and overwrites using processor loads and
stores. Metadata operations are handled by the kernel PM file system (ext4
DAX). SplitFS introduces a new primitive termed relink to efficiently support
file appends and atomic data operations. SplitFS provides three consistency
modes, which different applications can choose from, without interfering with
each other. SplitFS reduces software overhead by up-to 4x compared to the NOVA
PM file system, and 17x compared to ext4-DAX. On a number of micro-benchmarks
and applications such as the LevelDB key-value store running the YCSB
benchmark, SplitFS increases application performance by up to 2x compared to
ext4 DAX and NOVA while providing similar consistency guarantees.
"
440,SIVSHM: Secure Inter-VM Shared Memory,"  With wide spread acceptance of virtualization, virtual machines (VMs) find
their presence in various applications such as Network Address Translation
(NAT) servers, firewall servers and MapReduce applications. Typically, in these
applications a data manager collects data from the external world and
distributes it to multiple workers for further processing. Currently, data
managers distribute data with workers either using inter-VM shared memory
(IVSHMEM) or network communication. IVSHMEM provides better data distribution
throughput sacrificing security as all untrusted workers have full access to
the shared memory region and network communication provides better security at
the cost of throughput. Secondly, IVSHMEM uses a central distributor to
exchange eventfd - a file descriptor to an event queue of length one, which is
used for inter-VM signaling. This central distributor becomes a bottleneck and
increases boot time of VMs. Secure Inter-VM Shared Memory (SIVSHM) provided
both security and better throughout by segmenting inter-VM shared memory, so
that each worker has access to segment that belong only to it, thereby enabling
security without sacrificing throughput. SIVSHM boots VMs in 30% less time
compared to IVSHMEM by eliminating central distributor from its architecture
and enabling direct exchange of eventfds amongst VMs.
"
441,An Improvement Over Threads Communications on Multi-Core Processors,"  Multicore is an integrated circuit chip that uses two or more computational
engines (cores) places in a single processor. This new approach is used to
split the computational work of a threaded application and spread it over
multiple execution cores, so that the computer system can benefits from a
better performance and better responsiveness of the system. A thread is a unit
of execution inside a process that is created and maintained to execute a set
of actions/ instructions. Threads can be implemented differently from an
operating system to another, but the operating system is in most cases
responsible to schedule the execution of different threads. Multi-threading
improving efficiency of processor performance with a cost-effective memory
system. In this paper, we explore one approach to improve communications for
multithreaded. Pre-send is a software Controlled data forwarding technique that
sends data to destination's cache before it is needed, eliminating cache misses
in the destination's cache as well as reducing the coherence traffic on the
bus. we show how we could improve the overall system performance by addition of
these architecture optimizations to multi-core processors.
"
442,SEUSS: Rapid serverless deployment using environment snapshots,"  Modern FaaS systems perform well in the case of repeat executions when
function working sets stay small. However, these platforms are less effective
when applied to more complex, large-scale and dynamic workloads. In this paper,
we introduce SEUSS (serverless execution via unikernel snapshot stacks), a new
system-level approach for rapidly deploying serverless functions. Through our
approach, we demonstrate orders of magnitude improvements in function start
times and cacheability, which improves common re-execution paths while also
unlocking previously-unsupported large-scale bursty workloads.
"
443,"APEX: Adaptive Ext4 File System for Enhanced Data Recoverability in Edge
  Devices","  Recently Edge Computing paradigm has gained significant popularity both in
industry and academia. With its increased usage in real-life scenarios,
security, privacy and integrity of data in such environments have become
critical. Malicious deletion of mission-critical data due to ransomware,
trojans and viruses has been a huge menace and recovering such lost data is an
active field of research. As most of Edge computing devices have compute and
storage limitations, difficult constraints arise in providing an optimal scheme
for data protection. These devices mostly use Linux/Unix based operating
systems. Hence, this work focuses on extending the Ext4 file system to APEX
(Adaptive Ext4): a file system based on novel on-the-fly learning model that
provides an Adaptive Recover-ability Aware file allocation platform for
efficient post-deletion data recovery and therefore maintaining data integrity.
Our recovery model and its lightweight implementation allow significant
improvement in recover-ability of lost data with lower compute, space, time,
and cost overheads compared to other methods. We demonstrate the effectiveness
of APEX through a case study of overwriting surveillance videos by CryPy
malware on Raspberry-Pi based Edge deployment and show 678% and 32% higher
recovery than Ext4 and current state-of-the-art File Systems. We also evaluate
the overhead characteristics and experimentally show that they are lower than
other related works.
"
444,"Enabling Failure-resilient Intermittent Systems Without Runtime
  Checkpointing","  Self-powered intermittent systems typically adopt runtime checkpointing as a
means to accumulate computation progress across power cycles and recover system
status from power failures. However, existing approaches based on the
checkpointing paradigm normally require system suspension and/or logging at
runtime. This paper presents a design which overcomes the drawbacks of
checkpointing-based approaches, to enable failure-resilient intermittent
systems. Our design allows accumulative execution and instant system recovery
under frequent power failures while enforcing the serializability of concurrent
task execution to improve computation progress and ensuring data consistency
without system suspension during runtime, by leveraging the characteristics of
data accessed in hybrid memory. We integrated the design into FreeRTOS running
on a Texas Instruments device. Experimental results show that our design can
still accumulate progress when the power source is too weak for
checkpointing-based approaches to make progress, and improves the computation
progress by up to 43% under a relatively strong power source, while reducing
the recovery time by at least 90%.
"
445,"Assise: Performance and Availability via NVM Colocation in a Distributed
  File System","  The adoption of very low latency persistent memory modules (PMMs) upends the
long-established model of disaggregated file system access. Instead, by
colocating computation and PMM storage, we can provide applications much higher
I/O performance, sub-second application failover, and strong consistency. To
demonstrate this, we built the Assise distributed file system, based on a
persistent, replicated coherence protocol for managing a set of
server-colocated PMMs as a fast, crash-recoverable cache between applications
and slower disaggregated storage, such as SSDs. Unlike disaggregated file
systems, Assise maximizes locality for all file IO by carrying out IO on
colocated PMM whenever possible and minimizes coherence overhead by maintaining
consistency at IO operation granularity, rather than at fixed block sizes.
  We compare Assise to Ceph/Bluestore, NFS, and Octopus on a cluster with Intel
Optane DC PMMs and SSDs for common cloud applications and benchmarks, such as
LevelDB, Postfix, and FileBench. We find that Assise improves write latency up
to 22x, throughput up to 56x, fail-over time up to 103x, and scales up to 6x
better than its counterparts, while providing stronger consistency semantics.
Assise promises to beat the MinuteSort world record by 1.5x.
"
446,"Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory
  Machines","  Multi-socket machines with 1-100 TBs of physical memory are becoming
prevalent. Applications running on multi-socket machines suffer non-uniform
bandwidth and latency when accessing physical memory. Decades of research have
focused on data allocation and placement policies in NUMA settings, but there
have been no studies on the question of how to place page-tables amongst
sockets. We make the case for explicit page-table allocation policies and show
that page-table placement is becoming crucial to overall performance. We
propose Mitosis to mitigate NUMA effects on page-table walks by transparently
replicating and migrating page-tables across sockets without application
changes. This reduces the frequency of accesses to remote NUMA nodes when
performing page-table walks. Mitosis uses two components: (i) a mechanism to
enable efficient page-table replication and migration; and (ii) policies for
processes to efficiently manage and control page-table replication and
migration. We implement Mitosis in Linux and evaluate its benefits on real
hardware. Mitosis improves performance for large-scale multi-socket workloads
by up to 1.34x by replicating page-tables across sockets. Moreover, it improves
performance by up to 3.24x in cases when the OS migrates a process across
sockets by enabling cross-socket page-table migration.
"
447,"PiBooster: A Light-Weight Approach to Performance Improvements in Page
  Table Management for Paravirtual Virtual-Machines","  In paravirtualization, the page table management components of the guest
operating systems are properly patched for the security guarantees of the
hypervisor. However, none of them pay enough attentions to the performance
improvements, which results in two noticeable performance issues. First, such
security patches exacerbate the problem that the execution paths of the guest
page table (de)allocations become extremely long, which would consequently
increase the latencies of process creations and exits. Second, the patches
introduce many additional IOTLB flushes, leading to extra IOTLB misses, and the
misses would have negative impacts on I/O performance of all peripheral
devices. In this paper, we propose PiBooster, a novel lightweight approach for
improving the performance in page table management. First, PiBooster shortens
the execution paths of the page table (de)allocations by the PiBooster cache,
which maintains dedicated buffers for serving page table (de)allocations.
Second, PiBooster eliminates the additional IOTLB misses with a fine-grained
validation scheme, which performs page table and DMA validations separately,
instead of doing both together. We implement a prototype on Xen with Linux as
the guest kernel. We do small modifications on Xen (166 SLoC) and Linux kernel
(350 SLoC). We evaluate the I/O performance in both micro and macro ways. The
micro experiment results indicate that PiBooster is able to completely
eliminate the additional IOTLB flushes in the workload-stable environments, and
effectively reduces (de)allocation time of the page table by 47% on average.
The macro benchmarks show that the latencies of the process creations and exits
are expectedly reduced by 16% on average. Moreover, the SPECINT,lmbench and
netperf results indicate that PiBooster has no negative performance impacts on
CPU computation, network I/O, and disk I/O.
"
448,Disaggregation and the Application,"  This paper examines disaggregated data center architectures from the
perspective of the applications that would run on these data centers, and
challenges the abstractions that have been proposed to date. In particular, we
argue that operating systems for disaggregated data centers should not abstract
disaggregated hardware resources, such as memory, compute, and storage away
from applications, but should instead give them information about, and control
over, these resources. To this end, we propose additional OS abstractions and
interfaces for disaggregation and show how they can improve data transfer in
data parallel frameworks and speed up failure recovery in replicated,
fault-tolerant applications. This paper studies the technical challenges in
providing applications with this additional functionality and advances several
preliminary proposals to overcome these challenges.
"
449,Debian Package usage profiler for Debian based Systems,"  The embedded devices of today due to their CPU, RAM capabilities can run
various Linux distributions but in most cases they are different from general
purpose distributions as they are usually lighter and specific to the needs of
that particular system. In this project, we share the problems associated in
adopting a fully heavy-weight Debian based system like Ubuntu in
embedded/automotive platforms and provide solutions to optimize them to
identify unused/redundant content in the system. This helps developer to reduce
the hefty general purpose distribution to an application specific distribution.
The solution involves collecting usage data in the system in a non-invasive
manner (to avoid any drop in performance) to suggest users the redundant,
unused parts of the system that can be safely removed without impacting the
system functionality.
"
450,Cichlid: Explicit physical memory management for large machines,"  In this paper, we rethink how an OS supports virtual memory. Classical VM is
an opaque abstraction of RAM, backed by demand paging. However, most systems
today (from phones to data-centers) do not page, and indeed may require the
performance benefits of non-paged physical memory, precise NUMA allocation,
etc. Moreover, MMU hardware is now useful for other purposes, such as detecting
page access or providing large page translation. Accordingly, the venerable VM
abstraction in OSes like Windows and Linux has acquired a plethora of extra
APIs to poke at the policy behind the illusion of a virtual address space.
  Instead, we present Cichlid, a memory system which inverts this model.
Applications explicitly manage their physical RAM of different types, and
directly (though safely) program the translation hardware. Cichlid is
implemented in Barrelfish, requires no virtualization support, and outperforms
VMM-based approaches for all but the smallest working sets. We show that
Cichlid enables use-cases for virtual memory not possible in Linux today, and
other use-cases are simple to program and significantly faster.
"
451,"CleanQ: a lightweight, uniform, formally specified interface for
  intra-machine data transfer","  We present CleanQ, a high-performance operating-system interface for
descriptor-based data transfer with rigorous formal semantics, based on a
simple, formally-verified notion of ownership transfer, with a fast reference
implementation. CleanQ aims to replace the current proliferation of similar,
but subtly diverse, and loosely specified, descriptor-based interfaces in OS
kernels and device drivers. CleanQ has strict semantics that not only clarify
both the implementation of the interface for different hardware devices and
software usecases, but also enable composition of modules as in more
heavyweight frameworks like Unix streams. We motivate CleanQ by showing that
loose specifications derived from implementation lead to security and
correctness bugs in production systems that a clean, formal, and
easilyunderstandable abstraction helps eliminate. We further demonstrate by
experiment that there is negligible performance cost for a clean design: we
show overheads in the tens of cycles for operations, and comparable end-to-end
performance to the highly-tuned Virtio and DPDK implementations on Linux.
"
452,Effectively Prefetching Remote Memory with Leap,"  Memory disaggregation over RDMA can improve the performance of
memory-constrained applications by replacing disk swapping with remote memory
accesses. However, state-of-the-art memory disaggregation solutions still use
data path components designed for slow disks. As a result, applications
experience remote memory access latency significantly higher than that of the
underlying low-latency network, which itself is too high for many applications.
  In this paper, we propose Leap, a prefetching solution for remote memory
accesses due to memory disaggregation. At its core, Leap employs an online,
majority-based prefetching algorithm, which increases the page cache hit rate.
We complement it with a lightweight and efficient data path in the kernel that
isolates each application's data path to the disaggregated memory and mitigates
latency bottlenecks arising from legacy throughput-optimizing operations.
Integration of Leap in the Linux kernel improves the median and tail remote
page access latencies of memory-bound applications by up to 104.04x and 22.62x,
respectively, over the default data path. This leads to up to 10.16x
performance improvements for applications using disaggregated memory in
comparison to the state-of-the-art solutions.
"
453,"Period Adaptation for Continuous Security Monitoring in Multicore
  Real-Time Systems","  We propose a design-time framework (named HYDRA-C) for integrating security
tasks into partitioned real-time systems (RTS) running on multicore platforms.
Our goal is to opportunistically execute security monitoring mechanisms in a
'continuous' manner -- i.e., as often as possible, across cores, to ensure that
security tasks run with as few interruptions as possible. Our framework will
allow designers to integrate security mechanisms without perturbing existing
real-time (RT) task properties or execution order. We demonstrate the framework
using a proof-of-concept implementation with intrusion detection mechanisms as
security tasks. We develop and use both, (a) a custom intrusion detection
system (IDS), as well as (b) Tripwire -- an open source data integrity checking
tool. These are implemented on a realistic rover platform designed using an ARM
multicore chip. We compare the performance of HYDRA-C with a state-of-the-art
RT security integration approach for multicore-based RTS and find that our
method can, on average, detect intrusions 19.05% faster without impacting the
performance of RT tasks.
"
454,"QoS-Aware Machine Learning-based Multiple Resources Scheduling for
  Microservices in Cloud Environment","  Microservices have been dominating in the modern cloud environment. To
improve cost efficiency, multiple microservices are normally co-located on a
server. Thus, the run-time resource scheduling becomes the pivot for QoS
control. However, the scheduling exploration space enlarges rapidly with the
increasing server resources - cores, cache, bandwidth, etc. - and the diversity
of microservices. Consequently, the existing schedulers might not meet the
rapid changes in service demands. Besides, we observe that there exist resource
cliffs in the scheduling space. It not only impacts the exploration efficiency,
making it difficult to converge to the optimal scheduling solution, but also
results in severe QoS fluctuation. To overcome these problems, we propose a
novel machine learning-based scheduling mechanism called OSML. It uses
resources and runtime states as the input and employs two MLP models and a
reinforcement learning model to perform scheduling space exploration. Thus,
OSML can reach an optimal solution much faster than traditional approaches.
More importantly, it can automatically detect the resource cliff and avoid them
during exploration. To verify the effectiveness of OSML and obtain a
well-generalized model, we collect a dataset containing over 2-billion samples
from 11 typical microservices running on real servers over 9 months. Under the
same QoS constraint, experimental results show that OSML outperforms the
state-of-the-art work, and achieves around 5 times scheduling speed.
"
455,Multi-version Indexing in Flash-based Key-Value Stores,"  Maintaining multiple versions of data is popular in key-value stores since it
increases concurrency and improves performance. However, designing a
multi-version key-value store entails several challenges, such as additional
capacity for storing extra versions and an indexing mechanism for mapping
versions of a key to their values. We present SkimpyFTL, a FTL-integrated
multi-version key-value store that exploits the remap-on-write property of
flash-based SSDs for multi-versioning and provides a tradeoff between memory
capacity and lookup latency for indexing.
"
456,"Exact Polynomial Time Algorithm for the Response Time Analysis of
  Harmonic Tasks with Constrained Release Jitter","  In some important application areas of hard real-time systems, preemptive
sporadic tasks with harmonic periods and constraint deadlines running upon a
uni-processor platform play an important role. We propose a new algorithm for
determining the exact worst-case response time for a task that has a lower
computational complexity (linear in the number of tasks) than the known
algorithm developed for the same system class. We also allow the task
executions to start delayed due to release jitter if they are within certain
value ranges. For checking if these constraints are met we define a constraint
programming problem that has a special structure and can be solved with
heuristic components in a time that is linear in the task number. If the check
determines the admissibility of the jitter values, the linear time algorithm
can be used to determine the worst-case response time also for jitter-aware
systems.
"
457,Dependability Assessment of the Android OS through Fault Injection,"  The reliability of mobile devices is a challenge for vendors, since the
mobile software stack has significantly grown in complexity. In this paper, we
study how to assess the impact of faults on the quality of user experience in
the Android mobile OS through fault injection. We first address the problem of
identifying a realistic fault model for the Android OS, by providing to
developers a set of lightweight and systematic guidelines for fault modeling.
Then, we present an extensible fault injection tool (AndroFIT) to apply such
fault model on actual, commercial Android devices. Finally, we present a large
fault injection experimentation on three Android products from major vendors,
and point out several reliability issues and opportunities for improving the
Android OS.
"
458,Nova -- A rainbow cloud over the Alps,"  A pooled and shared on-demand Infrastructure as a Service (IaaS), based on
the Openstack software suite, was rolled out on the Grenoble university campus
in 2018 and updated in 2019.We present the methods used to deploy and manage
the infrastructure: racadm and preseed for basic system installation, then
Kolla for Openstack deployment. This latter solution, based on containers for
each service, enables a centralised and logged configuration (GitLab) of
controllers and calculation nodes. The solution is the benchmark solution for a
reproducible deployment of Openstack. We have been able to expand our cloud
easily with new nodes. The change in version of the basic OS was also
successfully tested despite a few small hitches... As security is a key element
in the proper operation of this type of shared service, each project has been
made watertight and its data perfectly isolated from other projects, thanks to
the encryption of all network flows in VXLANs.This OpenStack infotainment
platform is operational. What is it all for? For example, our first users use
the Jupyter Notebook through the provision of Jupyterhub servers (web portal);
the Distributed Health Assessment IT System (SIDES project); the continuous
integration in connection with the GitLab platform; the test for the Kubernetes
container scheduler or the calculation and visualisation software, etc. Highly
varied uses that other platforms had difficulty offering.Nova, a new platform,
was born.
"
459,"Survivor: A Fine-Grained Intrusion Response and Recovery Approach for
  Commodity Operating Systems","  Despite the deployment of preventive security mechanisms to protect the
assets and computing platforms of users, intrusions eventually occur. We
propose a novel intrusion survivability approach to withstand ongoing
intrusions. Our approach relies on an orchestration of fine-grained recovery
and per-service responses (e.g., privileges removal). Such an approach may put
the system into a degraded mode. This degraded mode prevents attackers to
reinfect the system or to achieve their goals if they managed to reinfect it.
It maintains the availability of core functions while waiting for patches to be
deployed. We devised a cost-sensitive response selection process to ensure that
while the service is in a degraded mode, its core functions are still
operating. We built a Linux-based prototype and evaluated the effectiveness of
our approach against different types of intrusions. The results show that our
solution removes the effects of the intrusions, that it can select appropriate
responses, and that it allows services to survive when reinfected. In terms of
performance overhead, in most cases, we observed a small overhead, except in
the rare case of services that write many small files asynchronously in a
burst, where we observed a higher but acceptable overhead.
"
460,"Faster than Flash: An In-Depth Study of System Challenges for Emerging
  Ultra-Low Latency SSDs","  Emerging storage systems with new flash exhibit ultra-low latency (ULL) that
can address performance disparities between DRAM and conventional solid state
drives (SSDs) in the memory hierarchy. Considering the advanced low-latency
characteristics, different types of I/O completion methods (polling/hybrid) and
storage stack architecture (SPDK) are proposed. While these new techniques are
expected to take costly software interventions off the critical path in
ULL-applied systems, unfortunately no study exists to quantitatively analyze
system-level characteristics and challenges of combining such newly-introduced
techniques with real ULL SSDs. In this work, we comprehensively perform
empirical evaluations with 800GB ULL SSD prototypes and characterize ULL
behaviors by considering a wide range of I/O path parameters, such as different
queues and access patterns. We then analyze the efficiencies and challenges of
the polled-mode and hybrid polling I/O completion methods (added into Linux
kernels 4.4 and 4.10, respectively) and compare them with the efficiencies of a
conventional interrupt-based I/O path. In addition, we revisit the common
expectations of SPDK by examining all the system resources and parameters.
Finally, we demonstrate the challenges of ULL SSDs in a real SPDK-enabled
server-client system. Based on the performance behaviors that this study
uncovers, we also discuss several system implications, which are required to
take a full advantage of ULL SSD in the future.
"
461,Dispel: Byzantine SMR with Distributed Pipelining,"  Byzantine State Machine Replication (SMR) is a long studied topic that
received increasing attention recently with the advent of blockchains as
companies are trying to scale them to hundreds of nodes. Byzantine SMRs try to
increase throughput by either reducing the latency of consensus instances that
they run sequentially or by reducing the number of replicas that send messages
to others in order to reduce the network usage. Unfortunately, the former
approach makes use of resources in burst whereas the latter requires
CPU-intensive authentication mechanisms.
  In this paper, we propose a new Byzantine SMR called Dispel (Distributed
Pipeline) that allows any node to distributively start new consensus instances
whenever they detect sufficient resources locally. We evaluate the performance
of Dispel within a single datacenter and across up to 380 machines over 3
continents by comparing it against four other SMRs. On 128 nodes, Dispel speeds
up HotStuff, the Byzantine fault tolerant SMR being integrated within
Facebook's blockchain, by more than 12 times. In addition, we also test Dispel
under isolated and correlated failures and show that the Dispel distributed
design is more robust than HotStuff. Finally, we evaluate Dispel in a
cryptocurrency application with Bitcoin transactions and show that this SMR is
not the bottleneck.
"
462,"ARM Pointer Authentication based Forward-Edge and Backward-Edge Control
  Flow Integrity for Kernels","  Code reuse attacks are still big threats to software and system security.
Control flow integrity is a promising technique to defend against such attacks.
However, its effectiveness has been weakened due to the inaccurate control flow
graph and practical strategy to trade security for performance. In recent
years, CPU vendors have integrated hardware features as countermeasures. For
instance, ARM Pointer Authentication (PA in short) was introduced in ARMV8-A
architecture. It can efficiently generate an authentication code for an
address, which is encoded in the unused bits of the address. When the address
is de-referenced, the authentication code is checked to ensure its integrity.
Though there exist systems that adopt PA to harden user programs, how to
effectively use PA to protect OS kernels is still an open research question.
  In this paper, we shed lights on how to leverage PA to protect control flows,
including function pointers and return addresses, of Linux kernel.
Specifically, to protect function pointers, we embed authentication code into
them, track their propagation and verify their values when loading from memory
or branching to targets. To further defend against the pointer substitution
attack, we use the function pointer address as its context, and take a clean
design to propagate the address by piggybacking it into the pointer value. We
have implemented a prototype system with LLVM to identify function pointers,
add authentication code and verify function pointers by emitting new machine
instructions. We applied this system to Linux kernel, and solved numerous
practical issues, e.g., function pointer comparison and arithmetic operations.
The security analysis shows that our system can protect all function pointers
and return addresses in Linux kernel.
"
463,Virtual Gang based Scheduling of Real-Time Tasks on Multicore Platforms,"  We propose a virtual-gang based parallel real-time task scheduling approach
for multicore platforms. Our approach is based on the notion of a virtual-gang,
which is a group of parallel real-time tasks that are statically linked and
scheduled together by a gang scheduler. We present a light-weight intra-gang
synchronization framework, called RTG-Sync, and virtual gang formation
algorithms that provide strong temporal isolation and high real-time
schedulability in scheduling real-time tasks on multicore. We evaluate our
approach both analytically, with generated tasksets against state-of-the-art
approaches, and empirically with a case-study involving real-world workloads on
a real embedded multicore platform. The results show that our approach provides
simple but powerful compositional analysis framework, achieves better analytic
schedulability, especially when the effect of interference is considered, and
is a practical solution for COTS multicore platforms.
"
464,Runtime Verification of Linux Kernel Security Module,"  The Linux kernel is one of the most important Free/Libre Open Source Software
(FLOSS) projects. It is installed on billions of devices all over the world,
which process various sensitive, confidential or simply private data. It is
crucial to establish and prove its security properties. This work-in-progress
paper presents a method to verify the Linux kernel for conformance with an
abstract security policy model written in the Event-B specification language.
The method is based on system call tracing and aims at checking that the
results of system call execution do not lead to accesses that violate security
policy requirements. As a basis for it, we use an additional Event-B
specification of the Linux system call interface that is formally proved to
satisfy all the requirements of the security policy model. In order to perform
the conformance checks we use it to reproduce intercepted system calls and
verify accesses.
"
465,"Online Scheduling with Makespan Minimization: State of the Art Results,
  Research Challenges and Open Problems","  Online scheduling has been a well studied and challenging research problem
over the last five decades since the pioneering work of Graham with immense
practical significance in various applications such as interactive parallel
processing, routing in communication networks, distributed data management,
client-server communications, traffic management in transportation, industrial
manufacturing and production. In this problem, a sequence of jobs is received
one by one in order by the scheduler for scheduling over a number of machines.
On arrival of a job, the scheduler assigns the job irrevocably to a machine
before the availability of the next job with an objective to minimize the
completion time of the scheduled jobs. This paper highlights the state of the
art contributions for online scheduling of a sequence of independent jobs on
identical and uniform related machines with a special focus on preemptive and
non-preemptive processing formats by considering makespan minimization as the
optimality criterion. We present the fundamental aspects of online scheduling
from a beginner's perspective along with a background of general scheduling
framework. Important competitive analysis results obtained by well-known
deterministic and randomized online scheduling algorithms in the literature are
presented along with research challenges and open problems. Two of the emerging
recent trends such as resource augmentation and semi-online scheduling are
discussed as a motivation for future research work.
"
466,"On Schedulability Analysis of EDF Scheduling by Considering Suspension
  as Blocking","  During the execution of a job, it may suspend itself, i.e., its computation
ceases to process until certain activities are complete to be resumed. This
paper provides a counterexample of the schedulability analysis by Devi in
Euromicro Conference on Real-Time Systems (ECRTS) in 2003, which is the only
existing suspension-aware analysis specialized for uniprocessor systems when
preemptive earliest-deadline-first (EDF) is applied for scheduling dynamic
selfsuspending tasks.
"
467,"A New Fairness Model based on User's Objective for Multi-user
  Multi-processor Online Scheduling","  Resources of a multi-user system in multi-processor online scheduling are
shared by competing users in which fairness is a major performance criterion
for resource allocation. Fairness ensures equality in resource sharing among
the users. According to our knowledge, fairness based on the user's objective
has neither been comprehensively studied nor a formal fairness model has been
well defined in the literature. This motivates us to explore and define a new
model to ensure algorithmic fairness with quantitative performance measures
based on optimization of the user's objective. In this paper, we propose a new
model for fairness in Multi-user Multi-processor Online Scheduling
Problem(MUMPOSP). We introduce and formally define quantitative fairness
measures based on user's objective by optimizing makespan for individual user
in our proposed fairness model. We also define the unfairness of deprived users
and absolute fairness of an algorithm. We obtain lower bound results for the
absolute fairness for m identical machines with equal length jobs. We show that
our proposed fairness model can serve as a framework for measuring algorithmic
fairness by considering various optimality criteria such as flow time and sum
of completion times.
"
468,"SPARTA: A Divide and Conquer Approach to Address Translation for
  Accelerators","  Virtual memory (VM) is critical to the usability and programmability of
hardware accelerators. Unfortunately, implementing accelerator VM efficiently
is challenging because the area and power constraints make it difficult to
employ the large multi-level TLBs used in general-purpose CPUs. Recent research
proposals advocate a number of restrictions on virtual-to-physical address
mappings in order to reduce the TLB size or increase its reach. However, such
restrictions are unattractive because they forgo many of the original benefits
of traditional VM, such as demand paging and copy-on-write.
  We propose SPARTA, a divide and conquer approach to address translation.
SPARTA splits the address translation into accelerator-side and memory-side
parts. The accelerator-side translation hardware consists of a tiny TLB
covering only the accelerator's cache hierarchy (if any), while the translation
for main memory accesses is performed by shared memory-side TLBs. Performing
the translation for memory accesses on the memory side allows SPARTA to overlap
data fetch with translation, and avoids the replication of TLB entries for data
shared among accelerators. To further improve the performance and efficiency of
the memory-side translation, SPARTA logically partitions the memory space,
delegating translation to small and efficient per-partition translation
hardware. Our evaluation on index-traversal accelerators shows that SPARTA
virtually eliminates translation overhead, reducing it by over 30x on average
(up to 47x) and improving performance by 57%. At the same time, SPARTA requires
minimal accelerator-side translation hardware, reduces the total number of TLB
entries in the system, gracefully scales with memory size, and preserves all
key VM functionalities.
"
469,"Occlum: Secure and Efficient Multitasking Inside a Single Enclave of
  Intel SGX","  Intel Software Guard Extensions (SGX) enables user-level code to create
private memory regions called enclaves, whose code and data are protected by
the CPU from software and hardware attacks outside the enclaves. Recent work
introduces library operating systems (LibOSes) to SGX so that legacy
applications can run inside enclaves with few or even no modifications. As
virtually any non-trivial application demands multiple processes, it is
essential for LibOSes to support multitasking. However, none of the existing
SGX LibOSes support multitasking both securely and efficiently.
  This paper presents Occlum, a system that enables secure and efficient
multitasking on SGX. We implement the LibOS processes as SFI-Isolated Processes
(SIPs). SFI is a software instrumentation technique for sandboxing untrusted
modules (called domains). We design a novel SFI scheme named MPX-based,
Multi-Domain SFI (MMDSFI) and leverage MMDSFI to enforce the isolation of SIPs.
We also design an independent verifier to ensure the security guarantees of
MMDSFI. With SIPs safely sharing the single address space of an enclave, the
LibOS can implement multitasking efficiently. The Occlum LibOS outperforms the
state-of-the-art SGX LibOS on multitasking-heavy workloads by up to 6,600X on
micro-benchmarks and up to 500X on application benchmarks.
"
470,"AppStreamer: Reducing Storage Requirements of Mobile Games through
  Predictive Streaming","  Storage has become a constrained resource on smartphones. Gaming is a popular
activity on mobile devices and the explosive growth in the number of games
coupled with their growing size contributes to the storage crunch. Even where
storage is plentiful, it takes a long time to download and install a heavy app
before it can be launched. This paper presents AppStreamer, a novel technique
for reducing the storage requirements or startup delay of mobile games, and
heavy mobile apps in general. AppStreamer is based on the intuition that most
apps do not need the entirety of its files (images, audio and video clips,
etc.) at any one time. AppStreamer can, therefore, keep only a small part of
the files on the device, akin to a ""cache"", and download the remainder from a
cloud storage server or a nearby edge server when it predicts that the app will
need them in the near future. AppStreamer continuously predicts file blocks for
the near future as the user uses the app, and fetches them from the storage
server before the user sees a stall due to missing resources. We implement
AppStreamer at the Android file system layer. This ensures that the apps
require no source code or modification, and the approach generalizes across
apps. We evaluate AppStreamer using two popular games: Dead Effect 2, a 3D
first-person shooter, and Fire Emblem Heroes, a 2D turn-based strategy
role-playing game. Through a user study, 75% and 87% of the users respectively
find that AppStreamer provides the same quality of user experience as the
baseline where all files are stored on the device. AppStreamer cuts down the
storage requirement by 87% for Dead Effect 2 and 86% for Fire Emblem Heroes.
"
471,"Intel Page Modification Logging, a hardware virtualization feature:
  study and improvement for virtual machine working set estimation","  Intel Page Modification Logging (PML) is a novel hardware feature for
tracking virtual machine (VM) accessed memory pages. This task is essential in
today's data centers since it allows, among others, checkpointing, live
migration and working set size (WSS) estimation. Relying on the Xen hypervisor,
this paper studies PML from three angles: power consumption, efficiency, and
performance impact on user applications. Our findings are as follows. First,
PML does not incur any power consumption overhead. Second, PML reduces by up to
10.18% both VM live migration and checkpointing time. Third, PML slightly
reduces by up to 0.95% the performance degradation on applications incurred by
live migration and checkpointing. Fourth, PML however does not allow accurate
WSS estimation because read accesses are not tracked and hot pages cannot be
identified. A naive extension of PML for addressing these limitations could
lead to severe performance degradation (up to 34.8%) for the VM whose WSS is
computed.
  This paper presents Page Reference Logging (PRL), a smart extension of PML
for allowing both read and write accesses to be tracked. It does this without
impacting user VMs. The paper also presents a WSS estimation system which
leverages PRL and shows how this algorithm can be integrated into a data center
which implements memory overcommitment. We implement PRL and the WSS estimation
system under Gem5, a very popular hardware simulator. The evaluation results
validate the accuracy of PRL in the estimation of WSS. They also show that PRL
incurs no performance degradation for user VMs.
"
472,Privaros: A Framework for Privacy-Compliant Delivery Drones,"  We present Privaros, a framework to enforce privacy policies on drones.
Privaros is designed for commercial delivery drones, such as the ones that will
likely be used by Amazon Prime Air. Such drones visit a number of host
airspaces, each of which may have different privacy requirements. Privaros
provides an information flow control framework to enforce the policies of these
hosts on the guest delivery drones. The mechanisms in Privaros are built on top
of ROS, a middleware popular in many drone platforms. This paper presents the
design and implementation of these mechanisms, describes how policies are
specified, and shows that Privaros's policy specification can be integrated
with India's Digital Sky portal. Our evaluation shows that a drone running
Privaros can robustly enforce various privacy policies specified by hosts, and
that its core mechanisms only marginally increase communication latency and
power consumption.
"
473,Characterizing Synchronous Writes in Stable Memory Devices,"  Distributed algorithms that operate in the fail-recovery model rely on the
state stored in stable memory to guarantee the irreversibility of operations
even in the presence of failures. The performance of these algorithms lean
heavily on the performance of stable memory. Current storage technologies have
a defined performance profile: data is accessed in blocks of hundreds or
thousands of bytes, random access to these blocks is expensive and sequential
access is somewhat better. File system implementations hide some of the
performance limitations of the underlying storage devices using buffers and
caches. However, fail-recovery distributed algorithms bypass some of these
techniques and perform synchronous writes to be able to tolerate a failure
during the write itself. Assuming the distributed system designer is able to
buffer the algorithm's writes, we ask how buffer size and latency complement
each other. In this paper we start to answer this question by characterizing
the performance (throughput and latency) of typical stable memory devices using
a representative set of current file systems.
"
474,A Recurrent Neural Network Based Patch Recommender for Linux Kernel Bugs,"  Software bugs in a production environment have an undesirable impact on
quality of service, unplanned system downtime, and disruption in good customer
experience, resulting in loss of revenue and reputation. Existing approaches to
automated software bug repair focuses on known bug templates detected using
static code analysis tools and test suites, and in automatic generation of
patch code for these bugs. We describe the typical bug fixing process employed
in the Linux kernel, and motivate the need for a new automated tool flow to fix
bugs. We present an initial design of such an automated tool that uses
Recurrent Neural Network (RNN) based Natural Language Processing to generate
patch recommendations from user generated bug reports. At the 50th percentile
of the test bugs, the correct patch occurs within the top 11.5 patch
recommendations output by the model. Further, we present a Linux kernel
developer's assessment of the quality of patches recommended for new unresolved
kernel bugs.
"
475,LibrettOS: A Dynamically Adaptable Multiserver-Library OS,"  We present LibrettOS, an OS design that fuses two paradigms to simultaneously
address issues of isolation, performance, compatibility, failure
recoverability, and run-time upgrades. LibrettOS acts as a microkernel OS that
runs servers in an isolated manner. LibrettOS can also act as a library OS
when, for better performance, selected applications are granted exclusive
access to virtual hardware resources such as storage and networking.
Furthermore, applications can switch between the two OS modes with no
interruption at run-time. LibrettOS has a uniquely distinguishing advantage in
that, the two paradigms seamlessly coexist in the same OS, enabling users to
simultaneously exploit their respective strengths (i.e., greater isolation,
high performance). Systems code, such as device drivers, network stacks, and
file systems remain identical in the two modes, enabling dynamic mode switching
and reducing development and maintenance costs.
  To illustrate these design principles, we implemented a prototype of
LibrettOS using rump kernels, allowing us to reuse existent, hardened NetBSD
device drivers and a large ecosystem of POSIX/BSD-compatible applications. We
use hardware (VM) virtualization to strongly isolate different rump kernel
instances from each other. Because the original rumprun unikernel targeted a
much simpler model for uniprocessor systems, we redesigned it to support
multicore systems. Unlike kernel-bypass libraries such as DPDK, applications
need not be modified to benefit from direct hardware access. LibrettOS also
supports indirect access through a network server that we have developed.
Applications remain uninterrupted even when network components fail or need to
be upgraded. Finally, to efficiently use hardware resources, applications can
dynamically switch between the indirect and direct modes based on their I/O
load at run-time.
  [full abstract is in the paper]
"
476,"Safe and Efficient Remote Application Code Execution on Disaggregated
  NVM Storage with eBPF","  With rapid improvements in NVM storage devices, the performance bottleneck is
gradually shifting to the network, thus giving rise to the notion of ""data
movement wall"". To reduce the amount of data movement over the network,
researchers have proposed near-data computing by shipping operations and
compute-extensions closer to storage devices. However, running arbitrary,
user-provided extensions in a shared, disaggregated storage environment
presents multiple challenges regarding safety, isolation, and performance.
Instead of approaching this problem from scratch, in this work we make a case
for leveraging the Linux kernel eBPF framework to program disaggregated NVM
storage devices. eBPF offers a safe, verifiable, and high-performance way of
executing untrusted, user-defined code in a shared runtime. In this paper, we
describe our experiences building a first prototype that supports remote
operations on storage using eBPF, discuss the limitations of our approach, and
directions for addressing them.
"
477,"Bringing Inter-Thread Cache Benefits to Federated Scheduling -- Extended
  Results & Technical Report","  Multiprocessor scheduling of hard real-time tasks modeled by directed acyclic
graphs (DAGs) exploits the inherent parallelism presented by the model. For DAG
tasks, a node represents a request to execute an object on one of the available
processors. In one DAG task, there may be multiple execution requests for one
object, each represented by a distinct node. These distinct execution requests
offer an opportunity to reduce their combined cache overhead through
coordinated scheduling of objects as threads within a parallel task. The goal
of this work is to realize this opportunity by incorporating the cache-aware
BUNDLE-scheduling algorithm into federated scheduling of sporadic DAG task
sets.
  This is the first work to incorporate instruction cache sharing into
federated scheduling. The result is a modification of the DAG model named the
DAG with objects and threads (DAG-OT). Under the DAG-OT model, descriptions of
nodes explicitly include their underlying executable object and number of
threads. When possible, nodes assigned the same executable object are collapsed
into a single node; joining their threads when BUNDLE-scheduled. Compared to
the DAG model, the DAG-OT model with cache-aware scheduling reduces the number
of cores allocated to individual tasks by approximately 20 percent in the
synthetic evaluation and up to 50 percent on a novel parallel computing
platform implementation. By reducing the number of allocated cores, the DAG-OT
model is able to schedule a subset of previously infeasible task sets.
"
478,Reconfigurable Parallel Architecture of High Speed Round Robin Arbiter,"  With a view to managing the increasing traffic in computer networks, round
robin arbiter has been proposed to work with packet switching system to have
increased speed in providing access and scheduling. Round robin arbiter is a
doorway to a particular bus based on request along with equal priority and
gives turns to devices connected to it in a cyclic order. Considering the rapid
growth in computer networking and the emergence of computer automation which
will need much more access to the existing limited resources, this paper
emphasizes on designing a reconfigurable round robin arbiter over FPGA which
takes parallel requests and processes them with high efficiency and less delay
than existing designs. Proposed round robin arbiter encounters with 4 to 12
devices. Results show that with 200% increment in the number of connected
devices, only 2.69% increment has been found in the delay. With less delay,
proposed round robin arbiter exhibits high speed performance with higher
traffic, which is a new feature in comparison with the existing designs.
"
479,Fissile Locks,"  Classic test-and-test (TS) mutual exclusion locks are simple, and enjoy high
performance and low latency of ownership transfer under light or no contention.
However, they do not scale gracefully under high contention and do not provide
any admission order guarantees. Such concerns led to the development of
scalable queue-based locks, such as a recent Compact NUMA-aware (CNA) lock, a
variant of another popular queue-based MCS lock. CNA scales well under load and
provides certain admission guarantees, but has more complicated lock handover
operations than TS and incurs higher latencies at low contention. We propose
Fissile locks, which capture the most desirable properties of both TS and CNA.
A Fissile lock consists of two underlying locks: a TS lock, which serves as a
fast path, and a CNA lock, which serves as a slow path. The key feature of
Fissile locks is the ability of threads on the fast path to bypass threads
enqueued on the slow path, and acquire the lock with less overhead than CNA.
Bypass is bounded (by a tunable parameter) to avoid starvation and ensure
long-term fairness. The result is a highly scalable NUMA-aware lock with
progress guarantees that performs like TS at low contention and like CNA at
high contention.
"
480,"Efficient Schedulability Test for Dynamic-Priority Scheduling of
  Mixed-Criticality Real-Time Systems","  Systems in many safety-critical application domains are subject to
certification requirements. In such a system, there are typically different
applications providing functionalities that have varying degrees of
criticality. Consequently, the certification requirements for functionalities
at these different criticality levels are also varying, with very high levels
of assurance required for a highly critical functionality, whereas relatively
low levels of assurance required for a less critical functionality. Considering
the timing assurance given to various applications in the form of guaranteed
budgets within deadlines, a theory of real-time scheduling for such
multi-criticality systems has been under development in the recent past. In
particular, an algorithm called Earliest Deadline First with Virtual Deadlines
(EDF-VD) has shown a lot of promise for systems with two criticality levels,
especially in terms of practical performance demonstrated through experiment
results. In this paper we design a new schedulability test for EDF-VD that
extend these performance benefits to multi-criticality systems. We propose a
new test based on demand bound functions and also present a novel virtual
deadline assignment strategy. Through extensive experiments we show that the
proposed technique significantly outperforms existing strategies for a variety
of generic real-time systems.
"
481,"Multi-Rate Fluid Scheduling of Mixed-Criticality Systems on
  Multiprocessors","  In this paper we consider the problem of mixed-criticality (MC) scheduling of
implicit-deadline sporadic task systems on a homogenous multiprocessor
platform. Focusing on dual-criticality systems, algorithms based on the fluid
scheduling model have been proposed in the past. These algorithms use a
dual-rate execution model for each high-criticality task depending on the
system mode. Once the system switches to the high-criticality mode, the
execution rates of such tasks are increased to meet their increased demand.
Although these algorithms are speed-up optimal, they are unable to schedule
several feasible dual-criticality task systems. This is because a single fixed
execution rate for each high-criticality task after the mode switch is not
efficient to handle the high variability in demand during the transition period
immediately following the mode switch. This demand variability exists as long
as the carry-over jobs of high-criticality tasks, that is jobs released before
the mode switch, have not completed. Addressing this shortcoming, we propose a
multi-rate fluid execution model for dual-criticality task systems in this
paper. Under this model, high-criticality tasks are allocated varying execution
rates in the transition period after the mode switch to efficiently handle the
demand variability. We derive a sufficient schedulability test for the proposed
model and show its dominance over the dual-rate fluid execution model. Further,
we also present a speed-up optimal rate assignment strategy for the multi-rate
model, and experimentally show that the proposed model outperforms all the
existing MC scheduling algorithms with known speed-up bounds.
"
482,"Combining Task-level and System-level Scheduling Modes for Mixed
  Criticality Systems","  Different scheduling algorithms for mixed criticality systems have been
recently proposed. The common denominator of these algorithms is to discard low
critical tasks whenever high critical tasks are in lack of computation
resources. This is achieved upon a switch of the scheduling mode from Normal to
Critical. We distinguish two main categories of the algorithms: system-level
mode switch and task-level mode switch. System-level mode algorithms allow low
criticality (LC) tasks to execute only in normal mode. Task-level mode switch
algorithms enable to switch the mode of an individual high criticality task
(HC), from low (LO) to high (HI), to obtain priority over all LC tasks. This
paper investigates an online scheduling algorithm for mixed-criticality systems
that supports dynamic mode switches for both task level and system level. When
a HC task job overruns its LC budget, then only that particular job is switched
to HI mode. If the job cannot be accommodated, then the system switches to
Critical mode. To accommodate for resource availability of the HC jobs, the LC
tasks are degraded by stretching their periods until the Critical mode
exhibiting job complete its execution. The stretching will be carried out until
the resource availability is met. We have mechanized and implemented the
proposed algorithm using Uppaal. To study the efficiency of our scheduling
algorithm, we examine a case study and compare our results to the state of the
art algorithms.
"
483,"Demand-based Scheduling of Mixed-Criticality Sporadic Tasks on One
  Processor","  Strategies that artificially tighten high-criticality task deadlines in
low-criticality behaviors have been successfully employed for scheduling
mixed-criticality systems. Although efficient scheduling algorithms have been
developed for implicit deadline task systems, the same is not true for more
general sporadic tasks. In this paper we develop a new demand-based
schedulability test for such general mixed-criticality task systems, in which
we collectively bound the low- and high-criticality demand of tasks. We show
that the new test strictly dominates the only other known demand-based test for
such systems. We also propose a new deadline tightening strategy based on this
test, and show through simulations that the strategy significantly outperforms
all known scheduling algorithms for a variety of sporadic task systems.
"
484,"Utilization Difference Based Partitioned Scheduling of Mixed-Criticality
  Systems","  Mixed-Criticality (MC) systems consolidate multiple functionalities with
different criticalities onto a single hardware platform. Such systems improve
the overall resource utilization while guaranteeing resources to critical
tasks. In this paper, we focus on the problem of partitioned multiprocessor MC
scheduling, in particular the problem of designing efficient partitioning
strategies. We develop two new partitioning strategies based on the principle
of evenly distributing the difference between total high-critical utilization
and total low-critical utilization for the critical tasks among all processors.
By balancing this difference, we are able to reduce the pessimism in
uniprocessor MC schedulability tests that are applied on each processor, thus
improving overall schedulability. To evaluate the schedulability performance of
the proposed strategies, we compare them against existing partitioned
algorithms using extensive experiments. We show that the proposed strategies
are effective with both dynamic-priority Earliest Deadline First with Virtual
Deadlines (EDF-VD) and fixed-priority Adaptive Mixed-Criticality (AMC)
algorithms. Specifically, our results show that the proposed strategies improve
schedulability by as much as 28.1% and 36.2% for implicit and
constrained-deadline task systems respectively.
"
485,"Co-Optimizing Performance and Memory FootprintVia Integrated CPU/GPU
  Memory Management, anImplementation on Autonomous Driving Platform","  Cutting-edge embedded system applications, such as self-driving cars and
unmanned drone software, are reliant on integrated CPU/GPU platforms for their
DNNs-driven workload, such as perception and other highly parallel components.
In this work, we set out to explore the hidden performance implication of GPU
memory management methods of integrated CPU/GPU architecture. Through a series
of experiments on micro-benchmarks and real-world workloads, we find that the
performance under different memory management methods may vary according to
application characteristics. Based on this observation, we develop a
performance model that can predict system overhead for each memory management
method based on application characteristics. Guided by the performance model,
we further propose a runtime scheduler. By conducting per-task memory
management policy switching and kernel overlapping, the scheduler can
significantly relieve the system memory pressure and reduce the multitasking
co-run response time. We have implemented and extensively evaluated our system
prototype on the NVIDIA Jetson TX2, Drive PX2, and Xavier AGX platforms, using
both Rodinia benchmark suite and two real-world case studies of drone software
and autonomous driving software.
"
486,"Dynamic Budget Management with Service Guarantees for Mixed-Criticality
  Systems","  Many existing studies on mixed-criticality (MC) scheduling assume that
low-criticality budgets for high-criticality applications are known apriori.
These budgets are primarily used as guidance to determine when the scheduler
should switch the system mode from low to high. Based on this key observation,
in this paper we propose a dynamic MC scheduling model under which
low-criticality budgets for individual high-criticality applications are
determined at runtime as opposed to being fixed offline. To ensure sufficient
budget for high-criticality applications at all times, we use offline
schedulability analysis to determine a system-wide total low-criticality budget
allocation for all the high-criticality applications combined. This total
budget is used as guidance in our model to determine the need for a
mode-switch. The runtime strategy then distributes this total budget among the
various applications depending on their execution requirement and with the
objective of postponing mode-switch as much as possible. We show that this
runtime strategy is able to postpone mode-switches for a longer time than any
strategy that uses a fixed low-criticality budget allocation for each
application. Finally, since we are able to control the total budget allocation
for high-criticality applications before mode-switch, we also propose
techniques to determine these budgets considering system-wide objectives such
as schedulability and service guarantee for low-criticality applications.
"
487,FLIC: A Distributed Fog Cache for City-Scale Applications,"  We present FLIC, a distributed software data caching framework for fogs that
reduces network traffic and latency. FLICis targeted toward city-scale
deployments of cooperative IoT devices in which each node gathers and shares
data with surrounding devices. As machine learning and other data processing
techniques that require large volumes of training data are ported to low-cost
and low-power IoT systems, we expect that data analysis will be moved away from
the cloud. Separation from the cloud will reduce reliance on power-hungry
centralized cloud-based infrastructure. However, city-scale deployments of
cooperative IoT devices often connect to the Internet with cellular service, in
which service charges are proportional to network usage. IoT system architects
must be clever in order to keep costs down in these scenarios. To reduce the
network bandwidth required to operate city-scale deployments of cooperative IoT
systems, FLIC implements a distributed cache on the IoT nodes in the fog. FLIC
allows the IoT network to share its data without repetitively interacting with
a simple cloud storage service reducing calls out to a backing store. Our
results displayed a less than 2% miss rate on reads. Thus, allowing for only 5%
of requests needing the backing store. We were also able to achieve more than
50% reduction in bytes transmitted per second.
"
488,A File System For Write-Once Media,"  A file system standard for use with write-once media such as digital compact
disks is proposed. The file system is designed to work with any operating
system and a variety of physical media. Although the implementation is simple,
it provides a a full-featured and high-performance alternative to conventional
file systems on traditional, multiple-write media such as magnetic disks.
"
489,Resource Efficient Isolation Mechanisms in Mixed-Criticality Scheduling,"  Mixed-criticality real-time scheduling has been developed to improve resource
utilization while guaranteeing safe execution of critical applications. These
studies use optimistic resource reservation for all the applications to improve
utilization, but prioritize critical applications when the reservations become
insufficient at runtime. Many of them however share an impractical assumption
that all the critical applications will simultaneously demand additional
resources. As a consequence, they under-utilize resources by penalizing all the
low-criticality applications. In this paper we overcome this shortcoming using
a novel mechanism that comprises a parameter to model the expected number of
critical applications simultaneously demanding more resources, and an execution
strategy based on the parameter to improve resource utilization. Since most
mixed-criticality systems in practice are component-based, we design our
mechanism such that the component boundaries provide the isolation necessary to
support the execution of low-criticality applications, and at the same time
protect the critical ones. We also develop schedulability tests for the
proposed mechanism under both a flat as well as a hierarchical scheduling
framework. Finally, through simulations, we compare the performance of the
proposed approach with existing studies in terms of schedulability and the
capability to support low-criticality applications.
"
490,Optimal Virtual Cluster-based Multiprocessor Scheduling,"  Scheduling of constrained deadline sporadic task systems on multiprocessor
platforms is an area which has received much attention in the recent past. It
is widely believed that finding an optimal scheduler is hard, and therefore
most studies have focused on developing algorithms with good processor
utilization bounds. These algorithms can be broadly classified into two
categories: partitioned scheduling in which tasks are statically assigned to
individual processors, and global scheduling in which each task is allowed to
execute on any processor in the platform. In this paper we consider a third,
more general, approach called cluster-based scheduling. In this approach each
task is statically assigned to a processor cluster, tasks in each cluster are
globally scheduled among themselves, and clusters in turn are scheduled on the
multiprocessor platform. We develop techniques to support such cluster-based
scheduling algorithms, and also consider properties that minimize total
processor utilization of individual clusters. In the last part of this paper,
we develop new virtual cluster-based scheduling algorithms. For implicit
deadline sporadic task systems, we develop an optimal scheduling algorithm that
is neither Pfair nor ERfair. We also show that the processor utilization bound
of US-EDF{m/(2m-1)} can be improved by using virtual clustering. Since neither
partitioned nor global strategies dominate over the other, cluster-based
scheduling is a natural direction for research towards achieving improved
processor utilization bounds.
"
491,"SoftWear: Software-Only In-Memory Wear-Leveling for Non-Volatile Main
  Memory","  Several emerging technologies for byte-addressable non-volatile memory (NVM)
have been considered to replace DRAM as the main memory in computer systems
during the last years. The disadvantage of a lower write endurance, compared to
DRAM, of NVM technologies like Phase-Change Memory (PCM) or Ferroelectric RAM
(FeRAM) has been addressed in the literature. As a solution, in-memory
wear-leveling techniques have been proposed, which aim to balance the
wear-level over all memory cells to achieve an increased memory lifetime.
Generally, to apply such advanced aging-aware wear-leveling techniques proposed
in the literature, additional special hardware is introduced into the memory
system to provide the necessary information about the cell age and thus enable
aging-aware wear-leveling decisions.
  This paper proposes software-only aging-aware wear-leveling based on common
CPU features and does not rely on any additional hardware support from the
memory subsystem. Specifically, we exploit the memory management unit (MMU),
performance counters, and interrupts to approximate the memory write counts as
an aging indicator. Although the software-only approach may lead to slightly
worse wear-leveling, it is applicable on commonly available hardware. We
achieve page-level coarse-grained wear-leveling by approximating the current
cell age through statistical sampling and performing physical memory remapping
through the MMU. This method results in non-uniform memory usage patterns
within a memory page. Hence, we further propose a fine-grained wear-leveling in
the stack region of C / C++ compiled software.
  By applying both wear-leveling techniques, we achieve up to $78.43\%$ of the
ideal memory lifetime, which is a lifetime improvement of more than a factor of
$900$ compared to the lifetime without any wear-leveling.
"
492,Efficient Kernel Object Management for Tiered Memory Systems with KLOC,"  Software-controlled heterogeneous memory systems have the potential to
improve performance, efficiency, and cost tradeoffs in emerging systems.
Delivering on this promise requires an efficient operating system (OS)
mechanisms and policies for data management. Unfortunately, modern OSes do not
support efficient tiering of data between heterogeneous memories. While this
problem is known (and is being studied) for application-level data pages, the
question of how best to tier OS kernel objects has largely been ignored. We
show that careful kernel object management is vital to the performance of
software-controlled tiered memory systems. We find that the state-of-the-art OS
page management research leaves considerable performance on the table by
overlooking how best to tier, migrate, and manage kernel objects like inodes,
dentry caches, journal blocks, network socket buffers, etc., associated with
the filesystem and networking stack. In response, we characterize hotness,
reuse, and liveness properties of kernel objects to develop appropriate
tiering/migration mechanisms and policies. We evaluate our proposal using a
real-system emulation framework on large-scale workloads like RocksDB, Redis,
Cassandra, and Spark and achieve 1.4X to 4X higher throughput compared to the
prior art.
"
493,"$\mu$Tiles: Efficient Intra-Process Privilege Enforcement of Memory
  Regions","  With the alarming rate of security advisories and privacy concerns on
connected devices, there is an urgent need for strong isolation guarantees in
resource-constrained devices that demand very lightweight solutions. However,
the status quo is that Unix-like operating systems do not offer privilege
separation inside a process. Lack of practical fine-grained
compartmentalization inside a shared address space leads to private data
leakage through applications' untrusted dependencies and compromised threads.
To this end, we propose $\mu$Tiles, a lightweight kernel abstraction and set of
security primitives based on mutual distrust for intra-process privilege
separation, memory protection, and secure multithreading. $\mu$Tiles takes
advantage of hardware support for virtual memory tagging (e.g., ARM memory
domains) to achieve significant performance gain while eliminating various
hardware limitations. Our results (based on OpenSSL, the Apache HTTP server,
and LevelDB) show that $\mu$Tiles is extremely lightweight (adds $\approx 10KB$
to kernel image) for IoT use cases. It adds negligible runtime overhead
($\approx 0.5\%-3.5\%$) and is easy to integrate with existing applications for
providing strong privilege separation.
"
494,Hardware Memory Management for Future Mobile Hybrid Memory Systems,"  The current mobile applications have rapidly growing memory footprints,
posing a great challenge for memory system design. Insufficient DRAM main
memory will incur frequent data swaps between memory and storage, a process
that hurts performance, consumes energy and deteriorates the write endurance of
typical flash storage devices. Alternately, a larger DRAM has higher leakage
power and drains the battery faster. Further, DRAM scaling trends make further
growth of DRAMin the mobile space prohibitive due to cost. Emerging
non-volatile memory (NVM) has the potential to alleviate these issues due to
its higher capacity per cost than DRAM and mini-mal static power. Recently, a
wide spectrum of NVM technologies, including phase-change memories (PCM),
memristor, and 3D XPoint have emerged. Despite the mentioned advantages, NVM
has longer access latency compared to DRAMand NVM writes can incur higher
latencies and wear costs. Therefore integration of these new memory
technologies in the memory hierarchy requires a fundamental rearchitect-ing of
traditional system designs. In this work, we propose a hardware-accelerated
memory manager (HMMU) that addresses both types of memory in a flat space
address space. We design a set of data placement and data migration policies
within this memory manager, such that we may exploit the advantages of each
memory technology. By augmenting the system with this HMMU, we reduce the
overall memory latency while also reducing writes to the NVM. Experimental
results show that our design achieves a 39% reduction in energy consumption
with only a 12% performance degradation versus an all-DRAM baseline that is
likely untenable in the future.
"
495,Accelerating Filesystem Checking and Repair with pFSCK,"  File system checking and recovery (C/R) tools play a pivotal role in
increasing the reliability of storage software, identifying and correcting file
system inconsistencies. However, with increasing disk capacity and data
content, file system C/R tools notoriously suffer from long runtimes. We posit
that current file system checkers fail to exploit CPU parallelism and high
throughput offered by modern storage devices. To overcome these challenges, we
propose pFSCK, a tool that redesigns C/R to enable fine-grained parallelism at
the granularity of inodes without impacting the correctness of C/R's
functionality. To accelerate C/R, pFSCK first employs data parallelism by
identifying functional operations in each stage of the checker and isolating
dependent operation and their shared data structures. However, fully isolating
shared structures is infeasible, consequently requiring serialization that
limits scalability. To reduce the impact of synchronization bottlenecks and
exploit CPU parallelism, pFSCK designs pipeline parallelism allowing multiple
stages of C/R to run simultaneously without impacting correctness. To realize
efficient pipeline parallelism for different file system data configurations,
pFSCK provides techniques for ordering updates to global data structures,
efficient per-thread I/O cache management, and dynamic thread placement across
different passes of a C/R. Finally, pFSCK designs a resource-aware scheduler
aimed towards reducing the impact of C/R on other applications sharing CPUs and
the file system. Evaluation of pFSCK shows more than 2.6x gains of e2fsck and
more than 1.8x over XFS's checker that provides coarse-grained parallelism.
"
496,A Linux Kernel Scheduler Extension for Multi-core Systems,"  The Linux kernel is mostly designed for multi-programed environments, but
high-performance applications have other requirements. Such applications are
run standalone, and usually rely on runtime systems to distribute the
application's workload on worker threads, one per core. However, due to current
OSes limitations, it is not feasible to track whether workers are actually
running or blocked due to, for instance, a requested resource. For I/O
intensive applications, this leads to a significant performance degradation
given that the core of a blocked thread becomes idle until it is able to run
again. In this paper, we present the proof-of-concept of a Linux kernel
extension denoted User-Monitored Threads (UMT) which tackles this problem. Our
extension allows a user-space process to be notified of when the selected
threads become blocked or unblocked, making it possible for a runtime to
schedule additional work on the idle core. We implemented the extension on the
Linux Kernel 5.1 and adapted the Nanos6 runtime of the OmpSs-2 programming
model to take advantage of it. The whole prototype was tested on two
applications which, on the tested hardware and the appropriate conditions,
reported speedups of almost 2x.
"
497,MemShield: GPU-assisted software memory encryption,"  Cryptographic algorithm implementations are vulnerable to Cold Boot attacks,
which consist in exploiting the persistence of RAM cells across reboots or
power down cycles to read the memory contents and recover precious sensitive
data. The principal defensive weapon against Cold Boot attacks is memory
encryption. In this work we propose MemShield, a memory encryption framework
for user space applications that exploits a GPU to safely store the master key
and perform the encryption/decryption operations. We developed a prototype that
is completely transparent to existing applications and does not require changes
to the OS kernel. We discuss the design, the related works, the implementation,
the security analysis, and the performances of MemShield.
"
498,Vilamb: Low Overhead Asynchronous Redundancy for Direct Access NVM,"  Vilamb provides efficient asynchronous systemredundancy for direct access
(DAX) non-volatile memory (NVM) storage. Production storage deployments often
use system-redundancy in form of page checksums and cross-page parity.
State-of-the-art solutions for maintaining system-redundancy for DAX NVM either
incur a high performance overhead or require specialized hardware. The Vilamb
user-space library maintains system-redundancy with low overhead by delaying
and amortizing the system-redundancy updates over multiple data writes. As a
result, Vilamb provides 3--5x the throughput of the state-of-the-art software
solution at high operation rates. For applications that need system-redundancy
with high performance, and can tolerate some delaying of data redundancy,
Vilamb provides a tunable knob between performance and quicker redundancy. Even
with the delayed coverage, Vilamb increases the mean time to data loss due to
firmware-induced corruptions by up to two orders of magnitude in comparison to
maintaining no system-redundancy.
"
499,Designing Robust API Monitoring Solutions,"  Tracing the sequence of library and system calls made by a program is very
helpful in the characterization of its interactions with the environment and
ultimately of its semantics. Due to entanglements of real-world software
stacks, this task can become challenging as we take accuracy, reliability, and
transparency aspects into the equation. In this paper we report on our
experience in designing and implementing API tracing solutions for software
security research. We discuss two implementation variants based on
hardware-assisted virtualization and on dynamic binary translation to realize
API call interposition robustly.
"
500,Dim Silicon and the Case for Improved DVFS Policies,"  Due to thermal and power supply limits, modern Intel CPUs reduce their
frequency when AVX2 and AVX-512 instructions are executed. As the CPUs wait for
670{\mu}s before increasing the frequency again, the performance of some
heterogeneous workloads is reduced. In this paper, we describe parallels
between this situation and dynamic power management as well as between the
policy implemented by these CPUs and fixed-timeout device shutdown policies. We
show that the policy implemented by Intel CPUs is not optimal and describe
potential better policies. In particular, we present a mechanism to classify
applications based on their likeliness to cause frequency reduction. Our
approach takes either the resulting classification information or information
provided by the application and generates hints for the DVFS policy. We show
that faster frequency changes based on these hints are able to improve
performance for a web server using the OpenSSL library.
"
501,On Failure Diagnosis of the Storage Stack,"  Diagnosing storage system failures is challenging even for professionals. One
example is the ""When Solid State Drives Are Not That Solid"" incident occurred
at Algolia data center, where Samsung SSDs were mistakenly blamed for failures
caused by a Linux kernel bug. With the system complexity keeps increasing, such
obscure failures will likely occur more often. As one step to address the
challenge, we present our on-going efforts called X-Ray. Different from
traditional methods that focus on either the software or the hardware, X-Ray
leverages virtualization to collects events across layers, and correlates them
to generate a correlation tree. Moreover, by applying simple rules, X-Ray can
highlight critical nodes automatically. Preliminary results based on 5 failure
cases shows that X-Ray can effectively narrow down the search space for
failures.
"
502,"Exploiting Inter- and Intra-Memory Asymmetries for Data Mapping in
  Hybrid Tiered-Memories","  Modern computing systems are embracing hybrid memory comprising of DRAM and
non-volatile memory (NVM) to combine the best properties of both memory
technologies, achieving low latency, high reliability, and high density. A
prominent characteristic of DRAM-NVM hybrid memory is that it has NVM access
latency much higher than DRAM access latency. We call this inter-memory
asymmetry. We observe that parasitic components on a long bitline are a major
source of high latency in both DRAM and NVM, and a significant factor
contributing to high-voltage operations in NVM, which impact their reliability.
We propose an architectural change, where each long bitline in DRAM and NVM is
split into two segments by an isolation transistor. One segment can be accessed
with lower latency and operating voltage than the other. By introducing tiers,
we enable non-uniform accesses within each memory type (which we call
intra-memory asymmetry), leading to performance and reliability trade-offs in
DRAM-NVM hybrid memory. We extend existing NVM-DRAM OS in three ways. First, we
exploit both inter- and intra-memory asymmetries to allocate and migrate memory
pages between the tiers in DRAM and NVM. Second, we improve the OS's page
allocation decisions by predicting the access intensity of a newly-referenced
memory page in a program and placing it to a matching tier during its initial
allocation. This minimizes page migrations during program execution, lowering
the performance overhead. Third, we propose a solution to migrate pages between
the tiers of the same memory without transferring data over the memory channel,
minimizing channel occupancy and improving performance. Our overall approach,
which we call MNEME, to enable and exploit asymmetries in DRAM-NVM hybrid
tiered memory improves both performance and reliability for both single-core
and multi-programmed workloads.
"
503,Improving Phase Change Memory Performance with Data Content Aware Access,"  A prominent characteristic of write operation in Phase-Change Memory (PCM) is
that its latency and energy are sensitive to the data to be written as well as
the content that is overwritten. We observe that overwriting unknown memory
content can incur significantly higher latency and energy compared to
overwriting known all-zeros or all-ones content. This is because all-zeros or
all-ones content is overwritten by programming the PCM cells only in one
direction, i.e., using either SET or RESET operations, not both. In this paper,
we propose data content aware PCM writes (DATACON), a new mechanism that
reduces the latency and energy of PCM writes by redirecting these requests to
overwrite memory locations containing all-zeros or all-ones. DATACON operates
in three steps. First, it estimates how much a PCM write access would benefit
from overwriting known content (e.g., all-zeros, or all-ones) by
comprehensively considering the number of set bits in the data to be written,
and the energy-latency trade-offs for SET and RESET operations in PCM. Second,
it translates the write address to a physical address within memory that
contains the best type of content to overwrite, and records this translation in
a table for future accesses. We exploit data access locality in workloads to
minimize the address translation overhead. Third, it re-initializes unused
memory locations with known all-zeros or all-ones content in a manner that does
not interfere with regular read and write accesses. DATACON overwrites unknown
content only when it is absolutely necessary to do so. We evaluate DATACON with
workloads from state-of-the-art machine learning applications, SPEC CPU2017,
and NAS Parallel Benchmarks. Results demonstrate that DATACON significantly
improves system performance and memory system energy consumption compared to
the best of performance-oriented state-of-the-art techniques.
"
504,High Velocity Kernel File Systems with Bento,"  High development velocity is critical for modern systems. This is especially
true for Linux file systems which are seeing increased pressure from new
storage devices and new demands on storage systems. However, high velocity
Linux kernel development is challenging due to the ease of introducing bugs,
the difficulty of testing and debugging, and the lack of support for
redeployment without service disruption. Existing approaches to high-velocity
development of file systems for Linux have major downsides, such as the high
performance penalty for FUSE file systems, slowing the deployment cycle for new
file system functionality.
  We propose Bento, a framework for high velocity development of Linux kernel
file systems. It enables file systems written in safe Rust to be installed in
the Linux kernel, with errors largely sandboxed to the file system. Bento file
systems can be replaced with no disruption to running applications, allowing
daily or weekly upgrades in a cloud server setting. Bento also supports
userspace debugging. We implement a simple file system using Bento and show
that it performs similarly to VFS-native ext4 on a variety of benchmarks and
outperforms a FUSE version by 10x-60x on Filebench. We also show that we can
dynamically add file provenance tracking to a running kernel file system with
only 10ms of service interruption.
"
505,"A Way Around UMIP and Descriptor-Table Exiting via TSX-based
  Side-Channel Attack","  Nowadays, in operating systems, numerous protection mechanisms prevent or
limit the user-mode applications to access the kernel's internal information.
This is regularly carried out by software-based defenses such as Address Space
Layout Randomization (ASLR) and Kernel ASLR (KASLR). They play pronounced roles
when the security of sandboxed applications such as Web-browser are considered.
Armed with arbitrary write access in the kernel memory, if these protections
are bypassed, an attacker could find a suitable Where to Write in order to get
an elevation of privilege or maliciously execute codes in ring 0. In this
paper, we introduce a reliable method based on Transactional Synchronization
Extensions (TSX) side-channel attacks to reveal the address of the Global
Descriptor Table (GDT) and Interrupt Descriptor Table (IDT). We indicate that
by detecting these addresses, an attack could be executed to sidestep the
Intel's User-Mode Instruction Prevention (UMIP) and the Hypervisor-based
mitigation and, consequently, neutralized them. The introduced attack is
successfully performed after the most recent patches for Meltdown and Spectre.
Moreover, the implementation of the proposed attack on different platforms,
including the latest releases of Microsoft Windows, Linux, and, Mac OSX with
the latest $9^{th}$ generation of Intel processors, shows that the attack is
independent of the Operating System implementation. We demonstrate that a
combination of this method with call-gate mechanism (available in modern
processors) in a chain of attacks will eventually lead to a full system
compromise despite the limitations of a super-secure sandboxed environment in
the presence of Windows's proprietary Virtualization Based Security (VBS).
Finally, we suggest the software-based mitigation to avoid these attacks with
an acceptable cost.
"
506,"Autonomous Task Dropping Mechanism to Achieve Robustness in
  Heterogeneous Computing Systems","  Robustness of a distributed computing system is defined as the ability to
maintain its performance in the presence of uncertain parameters. Uncertainty
is a key problem in heterogeneous (and even homogeneous) distributed computing
systems that perturbs system robustness. Notably, the performance of these
systems is perturbed by uncertainty in both task execution time and arrival.
Accordingly, our goal is to make the system robust against these uncertainties.
Considering task execution time as a random variable, we use probabilistic
analysis to develop an autonomous proactive task dropping mechanism to attain
our robustness goal. Specifically, we provide a mathematical model that
identifies the optimality of a task dropping decision, so that the system
robustness is maximized. Then, we leverage the mathematical model to develop a
task dropping heuristic that achieves the system robustness within a feasible
time complexity. Although the proposed model is generic and can be applied to
any distributed system, we concentrate on heterogeneous computing (HC) systems
that have a higher degree of exposure to uncertainty than homogeneous systems.
Experimental results demonstrate that the autonomous proactive dropping
mechanism can improve the system robustness by up to 20%.
"
507,Study of Firecracker MicroVM,"  Firecracker is a virtualization technology that makes use of Kernel Virtual
Machine (KVM). Firecracker belongs to a new virtualization class named the
micro-virtual machines (MicroVMs). Using Firecracker, we can launch lightweight
MicroVMs in non-virtualized environments in a fraction of a second, at the same
time offering the security and workload isolation provided by traditional VMs
and also the resource efficiency that comes along with containers \cite{b1}.
Firecracker aims to provide a slimmed-down MicroVM, comprised of approximately
50K lines of code in Rust and with a reduced attack surface for guest VMs. This
report will examine the internals of Firecracker and understand why Firecracker
is the next big thing going forward in virtualization and cloud computing.
"
508,"Memory virtualization in virtualized systems: segmentation is better
  than paging","  The utilization of paging for virtual machine (VM) memory management is the
root cause of memory virtualization overhead. This paper shows that paging is
not necessary in the hypervisor. In fact, memory fragmentation, which explains
paging utilization, is not an issue in virtualized datacenters thanks to VM
memory demand patterns. Our solution Compromis, a novel Memory Management Unit,
uses direct segment for VM memory management combined with paging for VM's
processes. The paper presents a systematic methodology for implementing
Compromis in the hardware, the hypervisor and the datacenter scheduler.
Evaluation results show that Compromis outperforms the two popular memory
virtualization solutions: shadow paging and Extended Page Table by up to 30%
and 370% respectively.
"
509,Flex: Closing the Gaps between Usage and Allocation,"  Data centers are giant factories of Internet data and services. Worldwide
data centers consume energy and emit emissions more than airline industry.
Unfortunately, most of data centers are significantly underutilized. One of the
major reasons is the big gaps between the real usage and the provisioned
resources because users tend to over-estimate their demand and data center
operators often rely on users' requests for resource allocation. In this paper,
we first conduct an in-depth analysis of a Google cluster trace to unveil the
root causes for low utilization and highlight the great potential to improve
it. We then developed an online resource manager Flex to maximize the cluster
utilization while satisfying the Quality of Service (QoS). Large-scale
evaluations based on real-world traces show that Flex admits up to 1.74x more
requests and 1.6x higher utilization compared to tradition schedulers while
maintaining the QoS.
"
510,"The Art of CPU-Pinning: Evaluating and Improving the Performance of
  Virtualization and Containerization Platforms","  Cloud providers offer a variety of execution platforms in form of bare-metal,
VM, and containers. However, due to the pros and cons of each execution
platform, choosing the appropriate platform for a specific cloud-based
application has become a challenge for solution architects. The possibility to
combine these platforms (e.g. deploying containers within VMs) offers new
capacities that makes the challenge even further complicated. However, there is
a little study in the literature on the pros and cons of deploying different
application types on various execution platforms. In particular, evaluation of
diverse hardware configurations and different CPU provisioning methods, such as
CPU pinning, have not been sufficiently studied in the literature. In this
work, the performance overhead of container, VM, and bare-metal execution
platforms are measured and analyzed for four categories of real-world
applications, namely video processing, parallel processing (MPI), web
processing, and No-SQL, respectively representing CPU intensive, parallel
processing, and two IO intensive processes. Our analyses reveal a set of
interesting and sometimes counterintuitive findings that can be used as best
practices by the solution architects to efficiently deploy cloud-based
applications. Here are some notable mentions: (A) Under specific circumstances,
containers can impose a higher overhead than VMs; (B) Containers on top of VMs
can mitigate the overhead of VMs for certain applications; (C) Containers with
a large number of cores impose a lower overhead than those with a few cores.
"
511,An Adaptive Approach to Recoverable Mutual Exlcusion,"  Mutual exclusion (ME) is one of the most commonly used techniques to handle
conflicts in concurrent systems. Traditionally, mutual exclusion algorithms
have been designed under the assumption that a process does not fail while
acquiring/releasing a lock or while executing its critical section. However,
failures do occur in real life, potentially leaving the lock in an inconsistent
state. This gives rise to the problem of \emph{recoverable mutual exclusion
(RME)} that involves designing a mutual exclusion algorithm that can tolerate
failures, while maintaining safety and liveness properties.
  One of the important measures of performance of any ME algorithm, including
an RME algorithm, is the number of \emph{remote memory references (RMRs)} made
by a process (for acquiring and releasing a lock as well as recovering the lock
structure after a failure). The best known RME algorithm solves the problem for
$n$ processes in sub-logarithmic number of RMRs, given by
$\mathcal{O}(\frac{\log n}{\log \log n})$, irrespective of the number of
failures in the system.
  In this work, we present a new algorithm for solving the RME problem whose
RMR complexity gradually \emph{adapts} to the number of failures that have
occurred in the system ""recently"". In the absence of failures, our algorithm
generates only $\mathcal{O}(1)$ RMRs. Furthermore, its RMR complexity is given
by $\mathcal{O}(\min\{ \sqrt{F}, \frac{\log n}{\log \log n} \})$ where $F$ is
the total number of failures in the ""recent"" past. In addition to read and
write instructions, our algorithm uses compare-and-swap (\CAS{}) and
fetch-and-store (\FAS{}) hardware instructions, both of which are commonly
available in most modern processors.
"
512,Nefele: Process Orchestration for the Cloud,"  Virtualization, either at OS- or hardware level, plays an important role in
cloud computing. It enables easier automation and faster deployment in
distributed environments. While virtualized infrastructures provide a level of
management flexibility, they lack practical abstraction of the distributed
resources. A developer in such an environment still needs to deal with all the
complications of building a distributed software system. Different
orchestration systems are built to provide that abstraction; however, they do
not solve the inherent challenges of distributed systems, such as
synchronization issues or resilience to failures. This paper introduces Nefele,
a decentralized process orchestration system that automatically deploys and
manages individual processes, rather than containers/VMs, within a cluster.
Nefele is inspired by the Single System Image (SSI) vision of mitigating the
intricacies of remote execution, yet it maintains the flexibility and
performance of virtualized infrastructures. Nefele offers a set of APIs for
building cloud-native applications that lets the developer easily build,
deploy, and scale applications in a cloud environment. We have implemented and
deployed Nefele on a cluster in our datacenter and evaluated its performance.
Our evaluations show that Nefele can effectively deploy, scale, and monitor
processes across a distributed environment, while it incorporates essential
primitives to build a distributed software system.
"
513,FastDrain: Removing Page Victimization Overheads in NVMe Storage Stack,"  Host-side page victimizations can easily overflow the SSD internal buffer,
which interferes I/O services of diverse user applications thereby degrading
user-level experiences. To address this, we propose FastDrain, a co-design of
OS kernel and flash firmware to avoid the buffer overflow, caused by page
victimizations. Specifically, FastDrain can detect a triggering point where a
near-future page victimization introduces an overflow of the SSD internal
buffer. Our new flash firmware then speculatively scrubs the buffer space to
accommodate the requests caused by the page victimization. In parallel, our new
OS kernel design controls the traffic of page victimizations by considering the
target device buffer status, which can further reduce the risk of buffer
overflow. To secure more buffer spaces, we also design a latency-aware FTL,
which dumps the dirty data only to the fast flash pages. Our evaluation results
reveal that FastDrain reduces the 99th response time of user applications by
84%, compared to a conventional system.
"
514,"Optimizing Placement of Heap Memory Objects in Energy-Constrained Hybrid
  Memory Systems","  Main memory (DRAM) significantly impacts the power and energy utilization of
the overall server system. Non-Volatile Memory (NVM) devices, such as Phase
Change Memory and Spin-Transfer Torque RAM, are suitable candidates for main
memory to reduce energy consumption. But unlike DRAM, NVMs access latencies are
higher than DRAM and NVM writes are more energy sensitive than DRAM write
operations. Thus, Hybrid Main Memory Systems (HMMS) employing DRAM and NVM have
been proposed to reduce the overall energy depletion of main memory while
optimizing the performance of NVM. This paper proposes eMap, an optimal heap
memory object placement planner in HMMS. eMap considers the object-level access
patterns and energy consumption at the application level and provides an ideal
placement strategy for each object to augment performance and energy
utilization. eMap is equipped with two modules, eMPlan and eMDyn. Specifically,
eMPlan is a static placement planner which provides one time placement policies
for memory object to meet the energy budget while eMDyn is a runtime placement
planner to consider the change in energy limiting constraint during the runtime
and shuffles the memory objects by taking into account the access patterns as
well as the migration cost in terms of energy and performance. The evaluation
shows that our proposed solution satisfies both the energy limiting constraint
and the performance. We compare our methodology with the state-of-the-art
memory object classification and allocation (MOCA) framework. Our extensive
evaluation shows that our proposed solution, eMPlan meets the energy constraint
with 4.17 times less costly and reducing the energy consumption up to 14% with
the same performance. eMDyn also satisfies the performance and energy
requirement while considering the migration cost in terms of time and energy.
"
515,Scalable Range Locks for Scalable Address Spaces and Beyond,"  Range locks are a synchronization construct designed to provide concurrent
access to multiple threads (or processes) to disjoint parts of a shared
resource. Originally conceived in the file system context, range locks are
gaining increasing interest in the Linux kernel community seeking to alleviate
bottlenecks in the virtual memory management subsystem. The existing
implementation of range locks in the kernel, however, uses an internal spin
lock to protect the underlying tree structure that keeps track of acquired and
requested ranges. This spin lock becomes a point of contention on its own when
the range lock is frequently acquired. Furthermore, where and exactly how
specific (refined) ranges can be locked remains an open question.
  In this paper, we make two independent, but related contributions. First, we
propose an alternative approach for building range locks based on linked lists.
The lists are easy to maintain in a lock-less fashion, and in fact, our range
locks do not use any internal locks in the common case. Second, we show how the
range of the lock can be refined in the mprotect operation through a
speculative mechanism. This refinement, in turn, allows concurrent execution of
mprotect operations on non-overlapping memory regions. We implement our new
algorithms and demonstrate their effectiveness in user-space and kernel-space,
achieving up to 9$\times$ speedup compared to the stock version of the Linux
kernel. Beyond the virtual memory management subsystem, we discuss other
applications of range locks in parallel software. As a concrete example, we
show how range locks can be used to facilitate the design of scalable
concurrent data structures, such as skip lists.
"
516,DPCP-p: A Distributed Locking Protocol for Parallel Real-Time Tasks,"  Real-time scheduling and locking protocols are fundamental facilities to
construct time-critical systems. For parallel real-time tasks, predictable
locking protocols are required when concurrent sub-jobs mutually exclusive
access to shared resources. This paper for the first time studies the
distributed synchronization framework of parallel real-time tasks, where both
tasks and global resources are partitioned to designated processors, and
requests to each global resource are conducted on the processor on which the
resource is partitioned. We extend the Distributed Priority Ceiling Protocol
(DPCP) for parallel tasks under federated scheduling, with which we proved that
a request can be blocked by at most one lower-priority request. We develop task
and resource partitioning heuristics and propose analysis techniques to safely
bound the task response times. Numerical evaluation (with heavy tasks on 8-,
16-, and 32-core processors) indicates that the proposed methods improve the
schedulability significantly compared to the state-of-the-art locking protocols
under federated scheduling.
"
517,"IOCA: High-Speed I/O-Aware LLC Management for Network-Centric
  Multi-Tenant Platform","  In modern server CPUs, last-level cache (LLC) is a critical hardware resource
that exerts significant influence on the performance of the workloads, and how
to manage LLC is a key to the performance isolation and QoS in the cloud with
multi-tenancy. In this paper, we argue that besides CPU cores, high-speed
network I/O is also important for LLC management. This is because of an Intel
architectural innovation -- Data Direct I/O (DDIO) -- that directly injects the
inbound I/O traffic to (part of) the LLC instead of the main memory. We
summarize two problems caused by DDIO and show that (1) the default DDIO
configuration may not always achieve optimal performance, (2) DDIO can decrease
the performance of non-I/O workloads which share LLC with it by as high as 32%.
  We then present IOCA, the first LLC management mechanism for network-centric
platforms that treats the I/O as the first-class citizen. IOCA monitors and
analyzes the performance of the cores, LLC, and DDIO using CPU's hardware
performance counters, and adaptively adjusts the number of LLC ways for DDIO or
the tenants that demand more LLC capacity. In addition, IOCA dynamically
chooses the tenants that share its LLC resource with DDIO, to minimize the
performance interference by both the tenants and the I/O. Our experiments with
multiple microbenchmarks and real-world applications in two major end-host
network models demonstrate that IOCA can effectively reduce the performance
degradation caused by DDIO, with minimal overhead.
"
518,"LINTS^RT: A Learning-driven Testbed for Intelligent Scheduling in
  Embedded Systems","  Due to the increasing complexity seen in both workloads and hardware
resources in state-of-the-art embedded systems, developing efficient real-time
schedulers and the corresponding schedulability tests becomes rather
challenging. Although close to optimal schedulability performance can be
achieved for supporting simple system models in practice, adding any small
complexity element into the problem context such as non-preemption or resource
heterogeneity would cause significant pessimism, which may not be eliminated by
any existing scheduling technique. In this paper, we present LINTS^RT, a
learning-based testbed for intelligent real-time scheduling, which has the
potential to handle various complexities seen in practice. The design of
LINTS^RT is fundamentally motivated by AlphaGo Zero for playing the board game
Go, and specifically addresses several critical challenges due to the real-time
scheduling context. We first present a clean design of LINTS^RT for supporting
the basic case: scheduling sporadic workloads on a homogeneous multiprocessor,
and then demonstrate how to easily extend the framework to handle further
complexities such as non-preemption and resource heterogeneity. Both
application and OS-level implementation and evaluation demonstrate that
LINTS^RT is able to achieve significantly higher runtime schedulability under
different settings compared to perhaps the most commonly applied schedulers,
global EDF, and RM. To our knowledge, this work is the first attempt to design
and implement an extensible learning-based testbed for autonomously making
real-time scheduling decisions.
"
519,Analyzing and Mitigating Data Stalls in DNN Training,"  Training Deep Neural Networks (DNNs) is resource-intensive and
time-consuming. While prior research has explored many different ways of
reducing DNN training time spanning different layers of the system stack, the
impact of input data pipeline, i.e., fetching raw data items from storage and
performing data pre-processing in memory, has been relatively unexplored. This
paper makes the following contributions: (1) We present the first comprehensive
analysis of how the input data pipeline affects the training time of
widely-used Deep Neural Networks (DNNs). We analyze nine different models
across three tasks and four datasets while varying factors such as the amount
of memory, number of CPU threads, storage device, GPU generation etc on servers
that are a part of a large production cluster at Microsoft. We find that in
many cases, DNN training time is dominated by data stall time: time spent
waiting for data to be fetched and pre-processed. (2) We build a tool,
DS-Analyzer to precisely measure data stalls using a differential technique,
and perform predictive what-if analysis on data stalls. (3) Finally, based on
the insights from our analysis, we design and implement three simple but
effective techniques in a data-loading library, CoorDL, to mitigate data
stalls. Our experiments on a range of DNN tasks, models, datasets, and hardware
configurations show that when PyTorch uses CoorDL instead of the
state-of-the-art DALI data loading library, DNN training time is reduced
significantly (by as much as 5x on a single server).
"
520,"Scheduling of Real-Time Tasks with Multiple Critical Sections in
  Multiprocessor Systems","  The performance of multiprocessor synchronization and locking protocols is a
key factor to utilize the computation power of multiprocessor systems under
real-time constraints. While multiple protocols have been developed in the past
decades, their performance highly depends on the task partition and
prioritization. The recently proposed Dependency Graph Approach showed its
advantages and attracted a lot of interest. It is, however, restricted to task
sets where each task has at most one critical section. In this paper, we remove
this restriction and demonstrate how to utilize algorithms for the classical
job shop scheduling problem to construct a dependency graph for tasks with
multiple critical sections. To show the applicability, we discuss the
implementation in Litmus^{RT} and report the overheads. Moreover, we provide
extensive numerical evaluations under different configurations, which in many
situations show significant improvement compared to the state-of-the-art.
"
521,DBOS: A Proposal for a Data-Centric Operating System,"  Current operating systems are complex systems that were designed before
today's computing environments. This makes it difficult for them to meet the
scalability, heterogeneity, availability, and security challenges in current
cloud and parallel computing environments. To address these problems, we
propose a radically new OS design based on data-centric architecture: all
operating system state should be represented uniformly as database tables, and
operations on this state should be made via queries from otherwise stateless
tasks. This design makes it easy to scale and evolve the OS without
whole-system refactoring, inspect and debug system state, upgrade components
without downtime, manage decisions using machine learning, and implement
sophisticated security features. We discuss how a database OS (DBOS) can
improve the programmability and performance of many of today's most important
applications and propose a plan for the development of a DBOS proof of concept.
"
522,HeRTA: Heaviside Real-Time Analysis,"  We investigate the mathematical properties of event bound functions as they
are used in the worst-case response time analysis and utilization tests. We
figure out the differences and similarities between the two approaches. Based
on this analysis, we derive a more general form do describe events and event
bounds. This new unified approach gives clear new insights in the investigation
of real-time systems, simplifies the models and will support algebraic proofs
in future work. In the end, we present a unified analysis which allows the
algebraic definition of any scheduler. Introducing such functions to the
real-time scheduling theory will lead two a more systematic way to integrate
new concepts and applications to the theory. Last but not least, we show how
the response time analysis in dynamic scheduling can be improved.
"
523,Interprocess Communication in FreeBSD 11: Performance Analysis,"  Interprocess communication, IPC, is one of the most fundamental functions of
a modern operating system, playing an essential role in the fabric of
contemporary applications. This report conducts an investigation in FreeBSD of
the real world performance considerations behind two of the most common IPC
mechanisms; pipes and sockets. A simple benchmark provides a fair sense of
effective bandwidth for each, and analysis using DTrace, hardware performance
counters and the operating system's source code is presented. We note that
pipes outperform sockets by 63% on average across all configurations, and
further that the size of userspace transmission buffers has a profound effect
on performance - larger buffers are beneficial up to a point (~32-64 KiB) after
which performance collapses as a result of devastating cache exhaustion. A deep
scrutiny of the probe effects at play is also presented, justifying the
validity of conclusions drawn from these experiments.
"
524,"eXpOS: A Simple Pedagogical Operating System for Undergraduate
  Instruction","  An operating system project suitable for undergraduate computing/electrical
sciences students is presented. The project can be used as a course project in
a one semester course, or as a self-study project for motivated students. The
course is organized such that a student with a basic background in programming
and computer organization can follow the implementation road map available
online, and build the OS from scratch on her personal machine/laptop, with
minimal instructional supervision. The student is provided with a simulated
abstract machine, an application interface specification, specification and
design of the OS, and a step by step project implementation road map. The
functionalities of the OS include multitasking, virtual memory, semaphores,
shared memory, an elementary file system, interrupt driven disk and console
I/O, and a limited multi-user support. The final stage of the project involves
porting the OS to a two-core machine. An independent one semester compiler
design project, where the student builds a compiler for a tiny object oriented
programming language that generates target code that can be loaded and executed
by the OS is also briefly discussed.
"
525,"Consideration for effectively handling parallel workloads on public
  cloud system","  We retrieved and analyzed parallel storage workloads of the FUJITSU K5 cloud
service to clarify how to build cost-effective hybrid storage systems. A hybrid
storage system consists of fast but low-capacity tier (first tier) and slow but
high-capacity tier (second tier). And, it typically consists of either SSDs and
HDDs or NVMs and SSDs. As a result, we found that 1) regions for first tier
should be assigned only if a workload includes large number of IO accesses for
a whole day, 2) the regions that include a large number of IO accesses should
be dynamically chosen and moved from second tier to first tier for a short
interval, and 3) if a cache hit ratio is regularly low, use of the cache for
the workload should be cancelled, and the whole workload region should be
assigned to the region for first tier. These workloads already have been
released from the SNIA web site.
"
526,"Making Distributed Mobile Applications SAFE: Enforcing User Privacy
  Policies on Untrusted Applications with Secure Application Flow Enforcement","  Today's mobile devices sense, collect, and store huge amounts of personal
information, which users share with family and friends through a wide range of
applications. Once users give applications access to their data, they must
implicitly trust that the apps correctly maintain data privacy. As we know from
both experience and all-too-frequent press articles, that trust is often
misplaced. While users do not trust applications, they do trust their mobile
devices and operating systems. Unfortunately, sharing applications are not
limited to mobile clients but must also run on cloud services to share data
between users. In this paper, we leverage the trust that users have in their
mobile OSes to vet cloud services. To do so, we define a new Secure Application
Flow Enforcement (SAFE) framework, which requires cloud services to attest to a
system stack that will enforce policies provided by the mobile OS for user
data. We implement a mobile OS that enforces SAFE policies on unmodified mobile
apps and two systems for enforcing policies on untrusted cloud services. Using
these prototypes, we demonstrate that it is possible to enforce existing user
privacy policies on unmodified applications.
"
527,BumbleBee: Application-aware adaptation for container orchestration,"  Application-aware adaptation is the key to maintaining acceptable quality
when resources become scarce. Application-oblivious responses to resource
scarcity, such as TCP congestion control, may fairly reallocate a diminishing
resource pool, but only the application knows how to adjust its fidelity under
resource scarcity. Unfortunately, modern container-orchestration platforms like
Kubernetes do not offer good support for application-aware adaptation. Thus,
this paper presents a set of orchestration extensions to support
application-aware adaption called BumbleBee. BumbleBee provides a clean
abstraction for making decisions about network data using application
semantics. Experiments with a BumbleBee prototype show that it can help a
video-analytics application utilize cloud resources when available and operate
without interruption when disconnected, and it can help the Fugu video server
eliminate all stalling while sacrificing only 6-24% mean resolution.
"
528,"Analysis of Interference between RDMA and Local Access on Hybrid Memory
  System","  We can use a hybrid memory system consisting of DRAM and Intel Optane DC
Persistent Memory (We call it DCPM in this paper) as DCPM is now commercially
available since April 2019. Even if the latency for DCPM is several times
higher than that for DRAM, the capacity for DCPM is several times higher than
that for DRAM and the cost of DCPM is also several times lower than that for
DRAM. In addition, DCPM is non-volatile. A Server with this hybrid memory
system could improve the performance for in-memory database systems and virtual
machine (VM) systems because these systems often consume a large amount of
memory. Moreover, a high-speed shared storage system can be implemented by
accessing DCPM via remote direct memory access (RDMA). I assume that some of
the DCPM is often assigned as a shared area among other remote servers because
applications executed on a server with a hybrid memory system often cannot use
the entire capacity of DCPM. This paper evaluates the interference between
local memory access and RDMA from a remote server. As a result, I indicate that
the interference on this hybrid memory system is significantly different from
that on a conventional DRAM-only memory system. I also believe that some kind
of throttling implementation is needed when this interference occures.
"
529,"toki: A Build- and Test-Platform for Prototyping and Evaluating
  Operating System Concepts in Real-Time Environments","  Typically, even low-level operating system concepts, such as resource sharing
strategies and predictability measures, are evaluated with Linux on PC
hardware. This leaves a large gap to real industrial applications. Hence, the
direct transfer of the results might be difficult. As a solution, we present
toki, a prototyping and evaluation platform based on FreeRTOS and several
open-source libraries. toki comes with a unified build- and test-environment
based on Yocto and Qemu, which makes it well suited for rapid prototyping. With
its architecture chosen similar to production industrial systems, toki provides
the ground work to implement early prototypes of real-time systems research
results, up to technology readiness level 7, with little effort.
"
530,"Quantifying the Latency and Possible Throughput of External Interrupts
  on Cyber-Physical Systems","  An important characteristic of cyber-physical systems is their capability to
respond, in-time, to events from their physical environment. However, to the
best of our knowledge there exists no benchmark for assessing and comparing the
interrupt handling performance of different software stacks. Hence, we present
a flexible evaluation method for measuring the interrupt latency and throughput
on ARMv8-A based platforms. We define and validate seven test-cases that stress
individual parts of the overall process and combine them to three benchmark
functions that provoke the minimal and maximal interrupt latency, and maximal
interrupt throughput.
"
531,"Sirius: Enabling System-Wide Isolation for Trusted Execution
  Environments","  Hardware-assisted trusted execution environments (TEEs) are critical building
blocks of many modern applications. However, the one-way isolation model
introduces a semantic gap between TEE and its outside world, including
conventional OSs and applications. This causes the most practical and
ever-increasing set of attacks on TEE-enabled applications by exploiting
various insecure interactions with the host OS and applications. Complex
applications rely on many mechanisms on the host OS and TEE system; their
complex interactions open a large attack surface that threatens both the
trusted and normal worlds. To address this fundamental issue, we introduce
Sirius, the first OS and TEE system to achieve system-wide isolation in TEEs.
It enables fine-grained compartmentalization, strong isolation, and secure
interactions between enclaves and kernel objects (e.g., threads, address
spaces, IPC, files, and sockets). Sirius replaces ad-hoc and inefficient forms
of interactions in current TEE systems with a principled approach that adds
strong inter- and intra-process isolation and efficiently eliminates a wide
range of attacks. We evaluate Sirius on ARM platforms, and find that it is
lightweight ($\approx 15K$ LoC) and only adds $\approx 10.8\%$ overhead to
enable TEE support on applications such as httpd, and improves the performance
of existing TEE-enabled applications such as the Darknet ML framework and ARM's
LibDDSSec by $0.05\%-5.6\%$.
"
532,Secure Memory Management on Modern Hardware,"  Almost all modern hardware, from phone SoCs to high-end servers with
accelerators, contain memory translation and protection hardware like IOMMUs,
firewalls, and lookup tables which make it impossible to reason about, and
enforce protection and isolation based solely on the processor's MMUs. This has
led to numerous bugs and security vulnerabilities in today's system software.
  In this paper we regain the ability to reason about and enforce access
control using the proven concept of a reference monitor mediating accesses to
memory resources. We present a fine-grained, realistic memory protection model
that makes this traditional concept applicable today, and bring system software
in line with the complexity of modern, heterogeneous hardware.
  Our design is applicable to any operating system, regardless of architecture.
We show that it not only enforces the integrity properties of a system, but
does so with no inherent performance overhead and it is even amenable to
automation through code generation from trusted hardware specifications.
"
533,"MigrOS: Transparent Operating Systems Live Migration Support for
  Containerised RDMA-applications","  Major data centre providers are introducing RDMA-based networks for their
tenants, as well as for operating the underlying infrastructure. In comparison
to traditional socket-based network stacks, RDMA-based networks offer higher
throughput, lower latency and reduced CPU overhead. However, transparent
checkpoint and migration operations become much more difficult. The key reason
is that the OS is removed from the critical path of communication. As a result,
some of the communication state itself resides in the NIC hardware and is no
more under the direct control of the OS. This control includes especially the
support for virtualisation of communication which is needed for live migration
of communication partners. In this paper, we propose the basic principles
required to implement a migration-capable RDMA-based network. We recommend some
changes at the software level and small changes at the hardware level. As a
proof of concept, we integrate the proposed changes into SoftRoCE, an
open-source kernel-level implementation of the RoCE protocol. We claim that
these changes introduce no runtime overhead when migration does not happen.
Finally, we develop a proof-of-concept implementation for migrating
containerised applications that use RDMA-based networks.
"
534,Akita: A CPU scheduler for virtualized Clouds,"  Clouds inherit CPU scheduling policies of operating systems. These policies
enforce fairness while leveraging best-effort mechanisms to enhance
responsiveness of all schedulable entities, irrespective of their service level
objectives (SLOs). This leads to unpredictable performance that forces cloud
providers to enforce strict reservation and isolation policies to prevent
high-criticality services (e.g., Memcached) from being impacted by
low-criticality ones (e.g., logging), which results in low utilization.
  In this paper, we present Akita, a hypervisor CPU scheduler that delivers
predictable performance at high utilization. Akita allows virtual machines
(VMs) to be categorized into high- and low-criticality VMs. Akita provides
strong guarantees on the ability of cloud providers to meet SLOs of
high-criticality VMs, by temporarily slowing down low-criticality VMs if
necessary. Akita, therefore, allows the co-existence of high and
low-criticality VMs on the same physical machine, leading to higher
utilization. The effectiveness of Akita is demonstrated by a prototype
implementation in the Xen hypervisor. We present experimental results that show
the many advantages of adopting Akita as the hypervisor CPU scheduler. In
particular, we show that high-criticality Memcached VMs are able to deliver
predictable performance despite being co-located with low-criticality CPU-bound
VMs.
"
535,DEAP Cache: Deep Eviction Admission and Prefetching for Cache,"  Recent approaches for learning policies to improve caching, target just one
out of the prefetching, admission and eviction processes. In contrast, we
propose an end to end pipeline to learn all three policies using machine
learning. We also take inspiration from the success of pretraining on large
corpora to learn specialized embeddings for the task. We model prefetching as a
sequence prediction task based on past misses. Following previous works
suggesting that frequency and recency are the two orthogonal fundamental
attributes for caching, we use an online reinforcement learning technique to
learn the optimal policy distribution between two orthogonal eviction
strategies based on them. While previous approaches used the past as an
indicator of the future, we instead explicitly model the future frequency and
recency in a multi-task fashion with prefetching, leveraging the abilities of
deep networks to capture futuristic trends and use them for learning eviction
and admission. We also model the distribution of the data in an online fashion
using Kernel Density Estimation in our approach, to deal with the problem of
caching non-stationary data. We present our approach as a ""proof of concept"" of
learning all three components of cache strategies using machine learning and
leave improving practical deployment for future work.
"
536,A FaaS File System for Serverless Computing,"  Serverless computing with cloud functions is quickly gaining adoption, but
constrains programmers with its limited support for state management. We
introduce a shared file system for cloud functions. It offers familiar POSIX
semantics while taking advantage of distinctive aspects of cloud functions to
achieve scalability and performance beyond what traditional shared file systems
can offer. We take advantage of the function-grained fault tolerance model of
cloud functions to proceed optimistically using local state, safe in the
knowledge that we can restart if cache reads or lock activity cannot be
reconciled upon commit. The boundaries of cloud functions provide implicit
commit and rollback points, giving us the flexibility to use transaction
processing techniques without changing the programming model or API. This
allows a variety of stateful sever-based applications to benefit from the
simplicity and scalability of serverless computing, often with little or no
modification.
"
537,"PIMOD: A Tool for Configuring Single-Board Computer Operating System
  Images","  Computer systems used in the field of humanitarian technology are often based
on general-purpose single-board computers, such as Raspberry Pis. While these
systems offer great flexibility for developers and users, configuration and
deployment either introduces overhead by executing scripts on multiple devices
or requires deeper technical understanding when building operating system
images for such small computers from scratch. In this paper, we present PIMOD,
a software tool for configuring operating system images for single-board
computer systems. We propose a simple yet comprehensive configuration language.
In a configuration profile, called Pifile, a small set of commands is used to
describe the configuration of an operating system image. Virtualization
techniques are used during the execution of the profile in order to be
distribution and platform independent. Commands can be issued in the guest
operating system, providing access to the distribution specific tools, e.g., to
configure hardware parameters. The implementation of PIMOD is made public under
a free and open source license. PIMOD is evaluated in terms of user benefits,
performance compared to on-system configuration, and applicability across
different hardware platforms and operating systems.
"
538,Stage Lookup: Accelerating Path Lookup using Directory Shortcuts,"  The lookup procedure in Linux costs a significant portion of file accessing
time as the virtual file system (VFS) traverses the file path components one
after another. The lookup procedure becomes more time consuming when
applications frequently access files, especially those with small sizes. We
propose Stage Lookup, which dynamically caches popular directories to speed up
lookup procedures and further reduce file accessing latency. The core of Stage
Lookup is to cache popular dentries as shortcuts, so that path walks do not
bother to traverse directory trees from the root. Furthermore, Stage Lookup
enriches backward path walks as it treats the directory tree in a VFS as an
undirected map. We implement a Stage Lookup prototype and integrate it into
Linux Kernel v3.14. Our extensive performance evaluation studies show that
Stage Lookup offers up to 46.9% performance gain compared to ordinary path
lookup schemes. Furthermore, Stage Lookup shows smaller performance overheads
in rename and chmod operations compared to the original method of the kernel.
"
539,"Towards Efficiently Establishing Mutual Distrust Between Host
  Application and Enclave for SGX","  Since its debut, SGX has been used in many applications, e.g., secure data
processing. However, previous systems usually assume a trusted enclave and
ignore the security issues caused by an untrusted enclave. For instance, a
vulnerable (or even malicious) third-party enclave can be exploited to attack
the host application and the rest of the system. In this paper, we propose an
efficient mechanism to confine an untrusted enclave's behaviors. The threats of
an untrusted enclave come from the enclave-host asymmetries. They can be abused
to access arbitrary memory regions of its host application, jump to any code
location after leaving the enclave and forge the stack register to manipulate
the saved context. Our solution breaks such asymmetries and establishes mutual
distrust between the host application and the enclave. It leverages Intel MPK
for efficient memory isolation and the x86 single-step debugging mechanism to
capture the event when an enclave is existing. It then performs the integrity
check for the jump target and the stack pointer. We have solved two practical
challenges and implemented a prototype system. The evaluation with multiple
micro-benchmarks and representative real-world applications demonstrated the
efficiency of our system, with less than 4% performance overhead.
"
540,Disaggregated Accelerator Management System for Cloud Data Centers,"  A conventional data center that consists of monolithic-servers is confronted
with limitations including lack of operational flexibility, low resource
utilization, low maintainability, etc. Resource disaggregation is a promising
solution to address the above issues. We propose a concept of disaggregated
cloud data center architecture called Flow-in-Cloud (FiC) that enables an
existing cluster computer system to expand an accelerator pool through a
high-speed network. FlowOS-RM manages the entire pool resources, and deploys a
user job on a dynamically constructed slice according to a user request. This
slice consists of compute nodes and accelerators where each accelerator is
attached to the corresponding compute node. This paper demonstrates the
feasibility of FiC in a proof of concept experiment running a distributed deep
learning application on the prototype system. The result successfully warrants
the applicability of the proposed system.
"
541,"Experimental Analysis of Communication Relaying Delay in Low-Energy
  Ad-hoc Networks","  In recent years, more and more applications use ad-hoc networks for local M2M
communications, but in some cases such as when using WSNs, the software
processing delay induced by packets relaying may not be negligible. In this
paper, we planned and carried out a delay measurement experiment using
Raspberry Pi Zero W. The results demonstrated that, in low-energy ad-hoc
networks, processing delay of the application is always too large to ignore; it
is at least ten times greater than the kernel routing and corresponds to 30% of
the transmission delay. Furthermore, if the task is CPU-intensive, such as
packet encryption, the processing delay can be greater than the transmission
delay and its behavior is represented by a simple linear model. Our findings
indicate that the key factor for achieving QoS in ad-hoc networks is an
appropriate node-to-node load balancing that takes into account the CPU
performance and the amount of traffic passing through each node.
"
542,Flexible File Address Space Management,"  Many applications store their data using structured files. In order to insert
or remove a record in the middle of a structured file, the application needs to
shift the positions of existing data. To this end, the existing data after the
insertion or removal point must be rewritten to admit the change in place,
which can be unaffordable for applications that make frequent updates.
Alternatively, the out-of-place update approach can admit changes with reduced
rewrites. However, it leads to increased access costs and excessive complexity.
  This paper presents a novel mechanism for managing file address space, named
FlexFile, that enables fast insertion and removal of arbitrary-sized data in a
file. Based on FlexFile, applications can perform in-place updates to a file
without rewriting existing data, and efficiently manage data on a linear file
layout with minimal complexity. Evaluation results show that a simple key-value
store built on top of FlexFile can achieve high performance for both reads and
writes.
"
543,Hints and Principles for Computer System Design,"  This new short version of my 1983 paper suggests the goals you might have for
your system -- Simple, Timely, Efficient, Adaptable, Dependable, Yummy (STEADY)
-- and techniques for achieving them -- Approximate, Incremental, Divide &
Conquer (AID). It also gives some principles for system design that are more
than just hints, and many examples of how to apply the ideas.
"
544,"Phoebe: Reuse-Aware Online Caching with Reinforcement Learning for
  Emerging Storage Models","  With data durability, high access speed, low power efficiency and byte
addressability, NVMe and SSD, which are acknowledged representatives of
emerging storage technologies, have been applied broadly in many areas.
However, one key issue with high-performance adoption of these technologies is
how to properly define intelligent cache layers such that the performance gap
between emerging technologies and main memory can be well bridged. To this end,
we propose Phoebe, a reuse-aware reinforcement learning framework for the
optimal online caching that is applicable for a wide range of emerging storage
models. By continuous interacting with the cache environment and the data
stream, Phoebe is capable to extract critical temporal data dependency and
relative positional information from a single trace, becoming ever smarter over
time. To reduce training overhead during online learning, we utilize periodical
training to amortize costs. Phoebe is evaluated on a set of Microsoft cloud
storage workloads. Experiment results show that Phoebe is able to close the gap
of cache miss rate from LRU and a state-of-the-art online learning based cache
policy to the Belady's optimal policy by 70.3% and 52.6%, respectively.
"
545,"A network file system over HTTP: remote access and modification of files
  and ""files""","  The goal of the present HTTPFS project is to enable access to remote files,
directories, and other containers through an HTTP pipe. HTTPFS system permits
retrieval, creation and modification of these resources as if they were regular
files and directories on a local filesystem. The remote host can be any UNIX or
Win9x/WinNT box that is capable of running a Perl CGI script and accessible
either directly or via a web proxy or a gateway. HTTPFS runs entirely in user
space.
  The current implementation fully supports reading as well as creating,
writing, appending, and truncating of files on a remote HTTP host. HTTPFS
provides an isolation level for concurrent file access stronger than the one
mandated by POSIX file system semantics, closer to that of AFS. Both an API
with familiar open(), read(), write(), close(), etc. calls, and an interactive
interface, via the popular Midnight Commander file browser, are provided.
"
546,"Solaris System Resource Manager: All I Ever Wanted Was My Unfair
  Advantage (And Why You Can't Have It!)","  Traditional UNIX time-share schedulers attempt to be fair to all users by
employing a round-robin style algorithm for allocating CPU time. Unfortunately,
a loophole exists whereby the scheduler can be biased in favor of a greedy user
running many short CPU-time processes. This loophole is not a defect but an
intrinsic property of the round-robin scheduler that ensures responsiveness to
the short CPU demands associated with multiple interactive users. A new
generation of UNIX system resource management software constrains the scheduler
to be equitable to all users regardless of the number of processes each may be
running. This ""fair-share"" scheduling draws on the concept of pro rating
resource ""shares"" across users and groups and then dynamically adjusting CPU
usage to meet those share proportions. The simple notion of statically
allocating these shares, however, belies the potential consequences for
performance as measured by user response time and service level targets. We
demonstrate this point by modeling several simple share allocation scenarios
and analyzing the corresponding performance effects. A brief comparison of
commercial system resource management implementations from HP, IBM, and SUN is
also given.
"
547,UNIX Resource Managers: Capacity Planning and Resource Issues,"  The latest implementations of commercial UNIX to offer mainframe style
capacity management on enterprise servers include: AIX Workload Manager (WLM),
HP-UX Process Resource Manager (PRM), Solaris Resource Manager (SRM), as well
as SGI and Compaq. The ability to manage server capacity is achieved by making
significant modifications to the standard UNIX operating system so that
processes are inherently tied to specific users. Those users, in turn, are
granted only a certain fraction of system resources. Resource usage is
monitored and compared with each users grant to ensure that the assigned
entitlement constraints are met. In this paper, we begin by clearing up some of
the confusion that has surrounded the motivation and the terminology behind the
new technology. The common theme across each of the commercial implementations
is the introduction of the fair-share scheduler. After reviewing some potential
performance pitfalls, we present capacity planning guidelines for migrating to
automated UNIX resource management.
"
548,"System Support for Bandwidth Management and Content Adaptation in
  Internet Applications","  This paper describes the implementation and evaluation of an operating system
module, the Congestion Manager (CM), which provides integrated network flow
management and exports a convenient programming interface that allows
applications to be notified of, and adapt to, changing network conditions. We
describe the API by which applications interface with the CM, and the
architectural considerations that factored into the design. To evaluate the
architecture and API, we describe our implementations of TCP; a streaming
layered audio/video application; and an interactive audio application using the
CM, and show that they achieve adaptive behavior without incurring much
end-system overhead. All flows including TCP benefit from the sharing of
congestion information, and applications are able to incorporate new
functionality such as congestion control and adaptive behavior.
"
549,Open Source Real Time Operating Systems Overview,"  Modern control systems applications are often built on top of a real time
operating system (RTOS) which provides the necessary hardware abstraction as
well as scheduling, networking and other services. Several open source RTOS
solutions are publicly available, which is very attractive, both from an
economic (no licensing fees) as well as from a technical (control over the
source code) point of view. This contribution gives an overview of the RTLinux
and RTEMS systems (architecture, development environment, API etc.). Both
systems feature most popular CPUs, several APIs (including Posix), networking,
portability and optional commercial support. Some performance figures are
presented, focusing on interrupt latency and context switching delay.
"
550,The Weaves Reconfigurable Programming Framework,"  This research proposes a language independent intra-process framework for
object based composition of unmodified code modules. Intuitively, the two major
programming models, threads and processes, can be considered as extremes along
a sharing axis. Multiple threads through a process share all global state,
whereas instances of a process (or independent processes) share no global
state. Weaves provide the generalized framework that allows arbitrary
(selective) sharing of state between multiple control flows through a process.
The Weaves framework supports multiple independent components in a single
process, with flexible state sharing and scheduling, all of which is achieved
without requiring any modification to existing code bases. Furthermore, the
framework allows dynamic instantiation of code modules and control flows
through them. In effect, weaves create intra-process modules (similar to
objects in OOP) from code written in any language. The Weaves paradigm allows
objects to be arbitrarily shared, it is a true superset of both processes as
well as threads, with code sharing and fast context switching time similar to
threads. Weaves does not require any special support from either the language
or application code, practically any code can be weaved. Weaves also include
support for fast automatic checkpointing and recovery with no application
support. This paper presents the elements of the Weaves framework and results
from our implementation that works by reverse-analyzing source-code independent
ELF object files. The current implementation has been validated over Sweep3D, a
benchmark for 3D discrete ordinates neutron transport [Koch et al., 1992], and
a user-level port of the Linux 2.4 family kernel TCP/IP protocol stack.
"
551,"Experimental Software Schedulability Estimation For Varied Processor
  Frequencies","  This paper describes a new approach to experimentally estimate the
application schedulability for various processor frequencies. We use additional
workload generated by an artificial high priority routine to simulate the
frequency decrease of a processor. Then we estimate the schedulability of
applications at different frequencies. The results of such estimation can be
used to determine the frequencies and control algorithms of dynamic voltage
scaling/dynamic frequency scaling (DVS/DFS) implementations. The paper presents
a general problem description, the proposed schedulability estimation method,
its analysis and evaluation.
"
552,The combinatorics of resource sharing,"  We discuss general models of resource-sharing computations, with emphasis on
the combinatorial structures and concepts that underlie the various deadlock
models that have been proposed, the design of algorithms and deadlock-handling
policies, and concurrency issues. These structures are mostly graph-theoretic
in nature, or partially ordered sets for the establishment of priorities among
processes and acquisition orders on resources. We also discuss graph-coloring
concepts as they relate to resource sharing.
"
553,End-User Effects of Microreboots in Three-Tiered Internet Systems,"  Microreboots restart fine-grained components of software systems ""with a
clean slate,"" and only take a fraction of the time needed for full system
reboot. Microreboots provide an application-generic recovery technique for
Internet services, which can be supported entirely in middleware and requires
no changes to the applications or any a priori knowledge of application
semantics.
  This paper investigates the effect of microreboots on end-users of an
eBay-like online auction application; we find that microreboots are nearly as
effective as full reboots, but are significantly less disruptive in terms of
downtime and lost work. In our experiments, microreboots reduced the number of
failed user requests by 65% and the perceived downtime by 78% compared to a
server process restart. We also show how to replace user-visible transient
failures with transparent call-retry, at the cost of a slight increase in
end-user-visible latency during recovery. Due to their low cost, microreboots
can be used aggressively, even when their necessity is less than certain, hence
adding to the reduced recovery time a reduction in the fault detection time,
which further improves availability.
"
554,Predictable Software -- A Shortcut to Dependable Computing ?,"  Many dependability techniques expect certain behaviors from the underlying
subsystems and fail in chaotic ways if these expectations are not met. Under
expected circumstances, however, software tends to work quite well. This paper
suggests that, instead of fixing elusive bugs or rewriting software, we improve
the predictability of conditions faced by our programs. This approach might be
a cheaper and faster way to improve dependability of software. After
identifying some of the common triggers of unpredictability, the paper
describes three engineering principles that hold promise in combating
unpredictability, suggests a way to benchmark predictability, and outlines a
brief research agenda.
"
555,Microreboot -- A Technique for Cheap Recovery,"  A significant fraction of software failures in large-scale Internet systems
are cured by rebooting, even when the exact failure causes are unknown.
However, rebooting can be expensive, causing nontrivial service disruption or
downtime even when clusters and failover are employed. In this work we separate
process recovery from data recovery to enable microrebooting -- a fine-grain
technique for surgically recovering faulty application components, without
disturbing the rest of the application.
  We evaluate microrebooting in an Internet auction system running on an
application server. Microreboots recover most of the same failures as full
reboots, but do so an order of magnitude faster and result in an order of
magnitude savings in lost work. This cheap form of recovery engenders a new
approach to high availability: microreboots can be employed at the slightest
hint of failure, prior to node failover in multi-node clusters, even when
mistakes in failure detection are likely; failure and recovery can be masked
from end users through transparent call-level retries; and systems can be
rejuvenated by parts, without ever being shut down.
"
556,Securing Data in Storage: A Review of Current Research,"  Protecting data from malicious computer users continues to grow in
importance. Whether preventing unauthorized access to personal photographs,
ensuring compliance with federal regulations, or ensuring the integrity of
corporate secrets, all applications require increased security to protect data
from talented intruders. Specifically, as more and more files are preserved on
disk the requirement to provide secure storage has increased in importance.
This paper presents a survey of techniques for securely storing data, including
theoretical approaches, prototype systems, and existing systems currently
available. Due to the wide variety of potential solutions available and the
variety of techniques to arrive at a particular solution, it is important to
review the entire field prior to selecting an implementation that satisfies
particular requirements. This paper provides an overview of the prominent
characteristics of several systems to provide a foundation for making an
informed decision. Initially, the paper establishes a set of criteria for
evaluating a storage solution based on confidentiality, integrity,
availability, and performance. Then, using these criteria, the paper explains
the relevant characteristics of select storage systems and provides a
comparison of the major differences.
"
557,"A Shared Write-protected Root Filesystem for a Group of Networked
  Clients","  A method to boot a cluster of diskless network clients from a single
write-protected NFS root file system is shown. The problems encountered when
first implementing the setup and their solution are discussed. Finally, the
setup is briefly compared to using a kernel-embedded root file system.
"
558,"Modeling the input history of programs for improved instruction-memory
  performance","  When a program is loaded into memory for execution, the relative position of
its basic blocks is crucial, since loading basic blocks that are unlikely to be
executed first places them high in the instruction-memory hierarchy only to be
dislodged as the execution goes on. In this paper we study the use of Bayesian
networks as models of the input history of a program. The main point is the
creation of a probabilistic model that persists as the program is run on
different inputs and at each new input refines its own parameters in order to
reflect the program's input history more accurately. As the model is thus
tuned, it causes basic blocks to be reordered so that, upon arrival of the next
input for execution, loading the basic blocks into memory automatically takes
into account the input history of the program. We report on extensive
experiments, whose results demonstrate the efficacy of the overall approach in
progressively lowering the execution times of a program on identical inputs
placed randomly in a sequence of varied inputs. We provide results on selected
SPEC CINT2000 programs and also evaluate our approach as compared to the gcc
level-3 optimization and to Pettis-Hansen reordering.
"
559,"Tycoon: an Implementation of a Distributed, Market-based Resource
  Allocation System","  Distributed clusters like the Grid and PlanetLab enable the same statistical
multiplexing efficiency gains for computing as the Internet provides for
networking. One major challenge is allocating resources in an economically
efficient and low-latency way. A common solution is proportional share, where
users each get resources in proportion to their pre-defined weight. However,
this does not allow users to differentiate the value of their jobs. This leads
to economic inefficiency. In contrast, systems that require reservations impose
a high latency (typically minutes to hours) to acquire resources.
  We present Tycoon, a market based distributed resource allocation system
based on proportional share. The key advantages of Tycoon are that it allows
users to differentiate the value of their jobs, its resource acquisition
latency is limited only by communication delays, and it imposes no manual
bidding overhead on users. We present experimental results using a prototype
implementation of our design.
"
560,"Threats of Human Error in a High-Performance Storage System: Problem
  Statement and Case Study","  System administration is a difficult, often tedious, job requiring many
skilled laborers. The data that is protected by system administrators is often
valued at or above the value of the institution maintaining that data. A number
of ethnographic studies have confirmed the skill of these operators, and the
difficulty of providing adequate tools. In an effort to minimize the
maintenance costs, an increasing portion of system administration is subject to
automation - particularly simple, routine tasks such as data backup. While such
tools reduce the risk of errors from carelessness, the same tools may result in
reduced skill and system familiarity in experienced workers. Care should be
taken to ensure that operators maintain system awareness without placing the
operator in a passive, monitoring role.
"
561,Sequential File Programming Patterns and Performance with .NET,"  Programming patterns for sequential file access in the .NET Framework are
described and the performance is measured. The default behavior provides
excellent performance on a single disk - 50 MBps both reading and writing.
Using large request sizes and doing file pre-allocation when possible have
quantifiable benefits. When one considers disk arrays, .NET unbuffered IO
delivers 800 MBps on a 16-disk array, but buffered IO delivers about 12% of
that performance. Consequently, high-performance file and database utilities
are still forced to use unbuffered IO for maximum sequential performance. The
report is accompanied by downloadable source code that demonstrates the
concepts and code that was used to obtain these measurements.
"
562,"Markets are Dead, Long Live Markets","  Researchers have long proposed using economic approaches to resource
allocation in computer systems. However, few of these proposals became
operational, let alone commercial. Questions persist about the economic
approach regarding its assumptions, value, applicability, and relevance to
system design. The goal of this paper is to answer these questions. We find
that market-based resource allocation is useful, and more importantly, that
mechanism design and system design should be integrated to produce systems that
are both economically and computationally efficient.
"
563,UNICORE - From Project Results to Production Grids,"  The UNICORE Grid-technology provides a seamless, secure and intuitive access
to distributed Grid resources. In this paper we present the recent evolution
from project results to production Grids. At the beginning UNICORE was
developed as a prototype software in two projects funded by the German research
ministry (BMBF). Over the following years, in various European-funded projects,
UNICORE evolved to a full-grown and well-tested Grid middleware system, which
today is used in daily production at many supercomputing centers worldwide.
Beyond this production usage, the UNICORE technology serves as a solid basis in
many European and International research projects, which use existing UNICORE
components to implement advanced features, high level services, and support for
applications from a growing range of domains. In order to foster these ongoing
developments, UNICORE is available as open source under BSD licence at
SourceForge, where new releases are published on a regular basis. This paper is
a review of the UNICORE achievements so far and gives a glimpse on the UNICORE
roadmap.
"
564,A File System Abstraction for Sense and Respond Systems,"  The heterogeneity and resource constraints of sense-and-respond systems pose
significant challenges to system and application development. In this paper, we
present a flexible, intuitive file system abstraction for organizing and
managing sense-and-respond systems based on the Plan 9 design principles. A key
feature of this abstraction is the ability to support multiple views of the
system via filesystem namespaces. Constructed logical views present an
application-specific representation of the network, thus enabling high-level
programming of the network. Concurrently, structural views of the network
enable resource-efficient planning and execution of tasks. We present and
motivate the design using several examples, outline research challenges and our
research plan to address them, and describe the current state of
implementation.
"
565,A Scalable Stream-Oriented Framework for Cluster Applications,"  This paper presents a stream-oriented architecture for structuring cluster
applications. Clusters that run applications based on this architecture can
scale to tenths of thousands of nodes with significantly less performance loss
or reliability problems. Our architecture exploits the stream nature of the
data flow and reduces congestion through load balancing, hides latency behind
data pushes and transparently handles node failures. In our ongoing work, we
are developing an implementation for this architecture and we are able to run
simple data mining applications on a cluster simulator.
"
566,Software Performance Analysis,"  The key to speeding up applications is often understanding where the elapsed
time is spent, and why. This document reviews in depth the full array of
performance analysis tools and techniques available on Linux for this task,
from the traditional tools like gcov and gprof, to the more advanced tools
still under development like oprofile and the Linux Trace Toolkit. The focus is
more on the underlying data collection and processing algorithms, and their
overhead and precision, than on the cosmetic details of the graphical user
interface frontends.
"
567,"Disks, Partitions, Volumes and RAID Performance with the Linux Operating
  System","  Block devices in computer operating systems typically correspond to disks or
disk partitions, and are used to store files in a filesystem. Disks are not the
only real or virtual device which adhere to the block accessible stream of
bytes block device model. Files, remote devices, or even RAM may be used as a
virtual disks. This article examines several common combinations of block
device layers used as virtual disks in the Linux operating system: disk
partitions, loopback files, software RAID, Logical Volume Manager, and Network
Block Devices. It measures their relative performance using different
filesystems: Ext2, Ext3, ReiserFS, JFS, XFS,NFS.
"
568,A Fresh Look at the Reliability of Long-term Digital Storage,"  Many emerging Web services, such as email, photo sharing, and web site
archives, need to preserve large amounts of quickly-accessible data
indefinitely into the future. In this paper, we make the case that these
applications' demands on large scale storage systems over long time horizons
require us to re-evaluate traditional storage system designs. We examine
threats to long-lived data from an end-to-end perspective, taking into account
not just hardware and software faults but also faults due to humans and
organizations. We present a simple model of long-term storage failures that
helps us reason about the various strategies for addressing these threats in a
cost-effective manner. Using this model we show that the most important
strategies for increasing the reliability of long-term storage are detecting
latent faults quickly, automating fault repair to make it faster and cheaper,
and increasing the independence of data replicas.
"
569,"A Survey of Virtualization Techniques Focusing on Secure On-Demand
  Cluster Computing","  Virtualization, a technique once used to multiplex the resources of
high-priced mainframe hardware, is seeing a resurgence in applicability with
the increasing computing power of commodity computers. By inserting a layer of
software between the machine and traditional operating systems, this technology
allows access to a shared computing medium in a manner that is secure,
resource-controlled, and efficient. These properties are attractive in the
field of on-demand computing, where the fine-grained subdivision of resources
provided by virtualized systems allows potentially higher utilization of
computing resources.
  It this work, we survey a number of virtual machine systems with the goal of
finding an appropriate candidate to serve as the basis for the On-Demand Secure
Cluster Computing project at the National Center for Supercomputing
Applications. Contenders are reviewed on a number of desirable properties
including portability and security. We conclude with a comparison and
justification of our choice.
"
570,Checkbochs: Use Hardware to Check Software,"  In this paper, we present a system called Checkbochs, a machine simulator
that checks rules about its guest operating system and applications at the
hardware level. The properties to be checked can be implemented as `plugins' in
the Checkbochs simulator. Some of the properties that were checked using
Checkbochs include null-pointer checks, format-string vulnerabilities,
user/kernel pointer checks, and race-conditions. On implementing these checks,
we were able to uncover previously-unknown bugs in widely used Linux
distributions. We also tested our tools on undergraduate coursework, and found
numerous bugs.
"
571,Language Support for Optional Functionality,"  We recommend a programming construct - availability check - for programs that
need to automatically adjust to presence or absence of segments of code. The
idea is to check the existence of a valid definition before a function call is
invoked. The syntax is that of a simple 'if' statement. The vision is to enable
customization of application functionality through addition or removal of
optional components, but without requiring complete re-building. Focus is on
C-like compiled procedural languages and UNIX-based systems. Essentially, our
approach attempts to combine the flexibility of dynamic libraries with the
usability of utility (dependency) libraries. We outline the benefits over
prevalent strategies mainly in terms of development complexity, crudely
measured as lesser lines of code. We also allude to performance and flexibility
facets. A Preliminary implementation and figures from early experimental
evaluation are presented.
"
572,Unmanaged Internet Protocol: Taming the Edge Network Management Crisis,"  Though appropriate for core Internet infrastructure, the Internet Protocol is
unsuited to routing within and between emerging ad-hoc edge networks due to its
dependence on hierarchical, administratively assigned addresses. Existing
ad-hoc routing protocols address the management problem but do not scale to
Internet-wide networks. The promise of ubiquitous network computing cannot be
fulfilled until we develop an Unmanaged Internet Protocol (UIP), a scalable
routing protocol that manages itself automatically. UIP must route within and
between constantly changing edge networks potentially containing millions or
billions of nodes, and must still function within edge networks disconnected
from the main Internet, all without imposing the administrative burden of
hierarchical address assignment. Such a protocol appears challenging but
feasible. We propose an architecture based on self-certifying, cryptographic
node identities and a routing algorithm adapted from distributed hash tables.
"
573,User-Relative Names for Globally Connected Personal Devices,"  Nontechnical users who own increasingly ubiquitous network-enabled personal
devices such as laptops, digital cameras, and smart phones need a simple,
intuitive, and secure way to share information and services between their
devices. User Information Architecture, or UIA, is a novel naming and
peer-to-peer connectivity architecture addressing this need. Users assign UIA
names by ""introducing"" devices to each other on a common local-area network,
but these names remain securely bound to their target as devices migrate.
Multiple devices owned by the same user, once introduced, automatically merge
their namespaces to form a distributed ""personal cluster"" that the owner can
access or modify from any of his devices. Instead of requiring users to
allocate globally unique names from a central authority, UIA enables users to
assign their own ""user-relative"" names both to their own devices and to other
users. With UIA, for example, Alice can always access her iPod from any of her
own personal devices at any location via the name ""ipod"", and her friend Bob
can access her iPod via a relative name like ""ipod.Alice"".
"
574,Secure Component Deployment in the OSGi(tm) Release 4 Platform,"  Last years have seen a dramatic increase in the use of component platforms,
not only in classical application servers, but also more and more in the domain
of Embedded Systems. The OSGi(tm) platform is one of these platforms dedicated
to lightweight execution environments, and one of the most prominent. However,
new platforms also imply new security flaws, and a lack of both knowledge and
tools for protecting the exposed systems. This technical report aims at
fostering the understanding of security mechanisms in component deployment. It
focuses on securing the deployment of components. It presents the cryptographic
mechanisms necessary for signing OSGi(tm) bundles, as well as the detailed
process of bundle signature and validation. We also present the SFelix
platform, which is a secure extension to Felix OSGi(tm) framework
implementation. It includes our implementation of the bundle signature process,
as specified by OSGi(tm) Release 4 Security Layer. Moreover, a tool for signing
and publishing bundles, SFelix JarSigner, has been developed to conveniently
integrate bundle signature in the bundle deployment process.
"
575,"A Low-Footprint Class Loading Mechanism for Embedded Java Virtual
  Machines","  This paper shows that it is possible to dramatically reduce the memory
consumption of classes loaded in an embedded Java virtual machine without
reducing its functionalities. We describe how to pack the constant pool by
deleting entries which are only used during the class loading process. We
present some benchmarks which demonstrate the efficiency of this mechanism. We
finally suggest some additional optimizations which can be applied if some
restrictions to the functionalities of the virtual machine can be tolerated.
"
576,Discovering Network Topology in the Presence of Byzantine Faults,"  We study the problem of Byzantine-robust topology discovery in an arbitrary
asynchronous network. We formally state the weak and strong versions of the
problem. The weak version requires that either each node discovers the topology
of the network or at least one node detects the presence of a faulty node. The
strong version requires that each node discovers the topology regardless of
faults. We focus on non-cryptographic solutions to these problems. We explore
their bounds. We prove that the weak topology discovery problem is solvable
only if the connectivity of the network exceeds the number of faults in the
system. Similarly, we show that the strong version of the problem is solvable
only if the network connectivity is more than twice the number of faults. We
present solutions to both versions of the problem. The presented algorithms
match the established graph connectivity bounds. The algorithms do not require
the individual nodes to know either the diameter or the size of the network.
The message complexity of both programs is low polynomial with respect to the
network size. We describe how our solutions can be extended to add the property
of termination, handle topology changes and perform neighborhood discovery.
"
577,2FACE: Bi-Directional Face Traversal for Efficient Geometric Routing,"  We propose bi-directional face traversal algorithm $2FACE$ to shorten the
path the message takes to reach the destination in geometric routing. Our
algorithm combines the practicality of the best single-direction traversal
algorithms with the worst case message complexity of $O(|E|)$, where $E$ is the
number of network edges. We apply $2FACE$ to a variety of geometric routing
algorithms. Our simulation results indicate that bi-directional face traversal
decreases the latency of message delivery two to three times compared to single
direction face traversal. The thus selected path approaches the shortest
possible route. This gain in speed comes with a similar message overhead
increase. We describe an algorithm which compensates for this message overhead
by recording the preferable face traversal direction. Thus, if a source has
several messages to send to the destination, the subsequent messages follow the
shortest route. Our simulation results show that with most geometric routing
algorithms the message overhead of finding the short route by bi-directional
face traversal is compensated within two to four repeat messages.
"
578,Executing the same binary on several operating systems,"  We notice a way to execute a binary file on Windows and ELF-based systems. It
can be used to create software installers and other applications not exceeding
64 kilo bytes.
"
579,The Unix KISS: A Case Study,"  In this paper we show that the initial philosophy used in designing and
developing UNIX in early times has been forgotten due to ""fast practices"". We
question the leitmotif that microkernels, though being by design adherent to
the KISS principle, have a number of context switches higher than their
monolithic counterparts, running a test suite and verify the results with
standard statistical validation tests. We advocate a wiser distribution of
shared libraries by statistically analyzing the weight of each shared object in
a typical UNIX system, showing that the majority of shared libraries exist in a
common space for no real evidence of need. Finally we examine the UNIX heritage
with an historical point of view, noticing how habits swiftly replaced the
intents of the original authors, moving the focus from the earliest purpose of
is avoiding complications, keeping a system simple to use and maintain.
"
580,"DMTCP: Transparent Checkpointing for Cluster Computations and the
  Desktop","  DMTCP (Distributed MultiThreaded CheckPointing) is a transparent user-level
checkpointing package for distributed applications. Checkpointing and restart
is demonstrated for a wide range of over 20 well known applications, including
MATLAB, Python, TightVNC, MPICH2, OpenMPI, and runCMS. RunCMS runs as a 680 MB
image in memory that includes 540 dynamic libraries, and is used for the CMS
experiment of the Large Hadron Collider at CERN. DMTCP transparently
checkpoints general cluster computations consisting of many nodes, processes,
and threads; as well as typical desktop applications. On 128 distributed cores
(32 nodes), checkpoint and restart times are typically 2 seconds, with
negligible run-time overhead. Typical checkpoint times are reduced to 0.2
seconds when using forked checkpointing. Experimental results show that
checkpoint time remains nearly constant as the number of nodes increases on a
medium-size cluster.
  DMTCP automatically accounts for fork, exec, ssh, mutexes/semaphores, TCP/IP
sockets, UNIX domain sockets, pipes, ptys (pseudo-terminals), terminal modes,
ownership of controlling terminals, signal handlers, open file descriptors,
shared open file descriptors, I/O (including the readline library), shared
memory (via mmap), parent-child process relationships, pid virtualization, and
other operating system artifacts. By emphasizing an unprivileged, user-space
approach, compatibility is maintained across Linux kernels from 2.6.9 through
the current 2.6.28. Since DMTCP is unprivileged and does not require special
kernel modules or kernel patches, DMTCP can be incorporated and distributed as
a checkpoint-restart module within some larger package.
"
581,"The Design and Architecture of the Microsoft Cluster Service -- A
  Practical Approach to High-Availability and Scalability","  Microsoft Cluster Service (MSCS) extends the Win-dows NT operating system to
support high-availability services. The goal is to offer an execution
environment where off-the-shelf server applications can continue to operate,
even in the presence of node failures. Later ver-sions of MSCS will provide
scalability via a node and application management system that allows
applications to scale to hundreds of nodes. This paper provides a de-tailed
description of the MSCS architecture and the de-sign decisions that have driven
the implementation of the service. The paper also describes how some major
appli-cations use the MSCS features, and describes features added to make it
easier to implement and manage fault-tolerant applications on MSCS.
"
582,A nested transaction mechanism for LOCUS,"  A working implementation of nested transactions has been produced for LOCUS,
an integrated distributed operating system which provides a high degree of
network transparency. Several aspects of our mechanism are novel. First, the
mechanism allows a transaction to access objects directly without regard to the
location of the object. Second, processes running on behalf of a single
transaction may be located at many sites. Thus there is no need to invoke a new
transaction to perform processing or access objects at a remote site. Third,
unlike other environments, LOCUS allows replication of data objects at more
than one site in the network, and this capability is incorporated into the
transaction mechanism. If the copy of an object that is currently being
accessed becomes unavailable, it is possible to continue work by using another
one of the replicated copies. Finally, an efficient orphan removal algorithm is
presented, and the problem of providing continued operation during network
partitions is addressed in detail.
"
583,A Flit Level Simulator for Wormhole Routing,"  Wormhole routing, the latest switching technique to be utilized by massively
parallel computers, enjoys the distinct advantage of a low latency when
compared to other switching techniques. This low latency is due to the nearly
distance insensitive routing traits in the absence of channel contention. The
low latency of wormhole routing brings about a liability of this switching
technique, a chance of deadlock. Deadlock is a concern in wormhole routed
networks due to the fact a message does not release its allocated resources
until all flits of a message have completely traversed the router in which
these resources are associated. The deadlock condition is addressed in the
routing algorithm. Simulation tools are currently needed that will aid in the
size and number of resources necessary to obtain the optimum utilization of
network resources for an algorithm. Some of these resources include the
topology of the network along with the number of nodes for the topology, the
size of the message, and the number and size of buffers at each router.
"
584,"Perpetual Adaptation of Software to Hardware: An Extensible Architecture
  for Providing Code Optimization as a Central System Service","  We present an open architecture for just-in-time code generation and dynamic
code optimization that is flexible, customizable, and extensible. While
previous research has primarily investigated functional aspects of such a
system, architectural aspects have so far remained unexplored. In this paper,
we argue that these properties are important to generate optimal code for a
variety of hardware architectures and different processor generations within
processor families. These properties are also important to make system-level
code generation useful in practice.
"
585,"ODP channel objects that provide services transparently for distributing
  processing systems","  This paper describes an architecture for a distributing processing system
that would allow remote procedure calls to invoke other services as messages
are passed between clients and servers. It proposes that an additional class of
data processing objects be located in the software communications channel. The
objects in this channel would then be used to enforce protocols on
client-server applications without any additional effort by the application
programmers. For example, services such as key-management, time-stamping,
sequencing and encryption can be implemented at different levels of the
software communications stack to provide a complete authentication service. A
distributing processing environment could be used to control broadband network
data delivery. Architectures and invocation semantics are discussed, Example
classes and interfaces for channel objects are given in the Java programming
language.
"
586,DRAFT : Task System and Item Architecture (TSIA),"  During its execution, a task is independent of all other tasks. For an
application which executes in terms of tasks, the application definition can be
free of the details of the execution. Many projects have demonstrated that a
task system (TS) can provide such an application with a parallel, distributed,
heterogeneous, adaptive, dynamic, real-time, interactive, reliable, secure or
other execution. A task consists of items and thus the application is defined
in terms of items. An item architecture (IA) can support arrays, routines and
other structures of items, thus allowing for a structured application
definition. Taking properties from many projects, the support can extend
through to currying, application defined types, conditional items, streams and
other definition elements. A task system and item architecture (TSIA) thus
promises unprecedented levels of support for application execution and
definition.
"
587,"After Compilers and Operating Systems : The Third Advance in Application
  Support","  After compilers and operating systems, TSIAs are the third advance in
application support. A compiler supports a high level application definition in
a programming language. An operating system supports a high level interface to
the resources used by an application execution. A Task System and Item
Architecture (TSIA) provides an application with a transparent reliable,
distributed, heterogeneous, adaptive, dynamic, real-time, interactive,
parallel, secure or other execution. In addition to supporting the application
execution, a TSIA also supports the application definition. This run-time
support for the definition is complementary to the compile-time support of a
compiler. For example, this allows a language similar to Fortran or C to
deliver features promised by functional computing. While many TSIAs exist, they
previously have not been recognized as such and have served only a particular
type of application. Existing TSIAs and other projects demonstrate that TSIAs
are feasible for most applications. As the next paradigm for application
support, the TSIA simplifies and unifies existing computing practice and
research. By solving many outstanding problems, the TSIA opens many, many new
opportunities for computing.
"
