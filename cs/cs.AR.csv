,title,abstract
0,"Cross-Layer Optimization of MIMO-Based Mesh Networks with Gaussian
  Vector Broadcast Channels","  MIMO technology is one of the most significant advances in the past decade to
increase channel capacity and has a great potential to improve network capacity
for mesh networks. In a MIMO-based mesh network, the links outgoing from each
node sharing the common communication spectrum can be modeled as a Gaussian
vector broadcast channel. Recently, researchers showed that ``dirty paper
coding'' (DPC) is the optimal transmission strategy for Gaussian vector
broadcast channels. So far, there has been little study on how this fundamental
result will impact the cross-layer design for MIMO-based mesh networks. To fill
this gap, we consider the problem of jointly optimizing DPC power allocation in
the link layer at each node and multihop/multipath routing in a MIMO-based mesh
networks. It turns out that this optimization problem is a very challenging
non-convex problem. To address this difficulty, we transform the original
problem to an equivalent problem by exploiting the channel duality. For the
transformed problem, we develop an efficient solution procedure that integrates
Lagrangian dual decomposition method, conjugate gradient projection method
based on matrix differential calculus, cutting-plane method, and subgradient
method. In our numerical example, it is shown that we can achieve a network
performance gain of 34.4% by using DPC.
"
1,"Nature-Inspired Interconnects for Self-Assembled Large-Scale
  Network-on-Chip Designs","  Future nano-scale electronics built up from an Avogadro number of components
needs efficient, highly scalable, and robust means of communication in order to
be competitive with traditional silicon approaches. In recent years, the
Networks-on-Chip (NoC) paradigm emerged as a promising solution to interconnect
challenges in silicon-based electronics. Current NoC architectures are either
highly regular or fully customized, both of which represent implausible
assumptions for emerging bottom-up self-assembled molecular electronics that
are generally assumed to have a high degree of irregularity and imperfection.
Here, we pragmatically and experimentally investigate important design
trade-offs and properties of an irregular, abstract, yet physically plausible
3D small-world interconnect fabric that is inspired by modern network-on-chip
paradigms. We vary the framework's key parameters, such as the connectivity,
the number of switch nodes, the distribution of long- versus short-range
connections, and measure the network's relevant communication characteristics.
We further explore the robustness against link failures and the ability and
efficiency to solve a simple toy problem, the synchronization task. The results
confirm that (1) computation in irregular assemblies is a promising and
disruptive computing paradigm for self-assembled nano-scale electronics and (2)
that 3D small-world interconnect fabrics with a power-law decaying distribution
of shortcut lengths are physically plausible and have major advantages over
local 2D and 3D regular topologies.
"
2,"Simulating spin systems on IANUS, an FPGA-based computer","  We describe the hardwired implementation of algorithms for Monte Carlo
simulations of a large class of spin models. We have implemented these
algorithms as VHDL codes and we have mapped them onto a dedicated processor
based on a large FPGA device. The measured performance on one such processor is
comparable to O(100) carefully programmed high-end PCs: it turns out to be even
better for some selected spin models. We describe here codes that we are
currently executing on the IANUS massively parallel FPGA-based system.
"
3,"A Communication Model for Adaptive Service Provisioning in Hybrid
  Wireless Networks","  Mobile entities with wireless links are able to form a mobile ad-hoc network.
Such an infrastructureless network does not have to be administrated. However,
self-organizing principles have to be applied to deal with upcoming problems,
e.g. information dissemination. These kinds of problems are not easy to tackle,
requiring complex algorithms. Moreover, the usefulness of pure ad-hoc networks
is arguably limited. Hence, enthusiasm for mobile ad-hoc networks, which could
eliminate the need for any fixed infrastructure, has been damped. The goal is
to overcome the limitations of pure ad-hoc networks by augmenting them with
instant Internet access, e.g. via integration of UMTS respectively GSM links.
However, this raises multiple questions at the technical as well as the
organizational level. Motivated by characteristics of small-world networks that
describe an efficient network even without central or organized design, this
paper proposes to combine mobile ad-hoc networks and infrastructured networks
to form hybrid wireless networks. One main objective is to investigate how this
approach can reduce the costs of a permanent backbone link and providing in the
same way the benefits of useful information from Internet connectivity or
service providers. For the purpose of bridging between the different types of
networks, an adequate middleware service is the focus of our investigation.
This paper shows our first steps forward to this middleware by introducing the
Injection Communication paradigm as principal concept.
"
4,"A Methodology for Efficient Space-Time Adapter Design Space Exploration:
  A Case Study of an Ultra Wide Band Interleaver","  This paper presents a solution to efficiently explore the design space of
communication adapters. In most digital signal processing (DSP) applications,
the overall architecture of the system is significantly affected by
communication architecture, so the designers need specifically optimized
adapters. By explicitly modeling these communications within an effective
graph-theoretic model and analysis framework, we automatically generate an
optimized architecture, named Space-Time AdapteR (STAR). Our design flow inputs
a C description of Input/Output data scheduling, and user requirements
(throughput, latency, parallelism...), and formalizes communication constraints
through a Resource Constraints Graph (RCG). The RCG properties enable an
efficient architecture space exploration in order to synthesize a STAR
component. The proposed approach has been tested to design an industrial data
mixing block example: an Ultra-Wideband interleaver.
"
5,A Design Methodology for Space-Time Adapter,"  This paper presents a solution to efficiently explore the design space of
communication adapters. In most digital signal processing (DSP) applications,
the overall architecture of the system is significantly affected by
communication architecture, so the designers need specifically optimized
adapters. By explicitly modeling these communications within an effective
graph-theoretic model and analysis framework, we automatically generate an
optimized architecture, named Space-Time AdapteR (STAR). Our design flow inputs
a C description of Input/Output data scheduling, and user requirements
(throughput, latency, parallelism...), and formalizes communication constraints
through a Resource Constraints Graph (RCG). The RCG properties enable an
efficient architecture space exploration in order to synthesize a STAR
component. The proposed approach has been tested to design an industrial data
mixing block example: an Ultra-Wideband interleaver.
"
6,"M\'ethodologie de mod\'elisation et d'impl\'ementation d'adaptateurs
  spatio-temporels","  The re-use of pre-designed blocks is a well-known concept of the software
development. This technique has been applied to System-on-Chip (SoC) design
whose complexity and heterogeneity are growing. The re-use is made thanks to
high level components, called virtual components (IP), available in more or
less flexible forms. These components are dedicated blocks: digital signal
processing (DCT, FFT), telecommunications (Viterbi, TurboCodes),... These
blocks rest on a model of fixed architecture with very few degrees of
personalization. This rigidity is particularly true for the communication
interface whose orders of acquisition and production of data, the temporal
behavior and protocols of exchanges are fixed. The successful integration of
such an IP requires that the designer (1) synchronizes the components (2)
converts the protocols between ""incompatible"" blocks (3) temporizes the data to
guarantee the temporal constraints and the order of the data. This phase
remains however very manual and source of errors. Our approach proposes a
formal modeling, based on an original Ressource Compatibility Graph. The
synthesis flow is based on a set of transformations of the initial graph to
lead to an interface architecture allowing the space-time adaptation of the
data exchanges between several components.
"
7,"Application of a design space exploration tool to enhance interleaver
  generation","  This paper presents a methodology to efficiently explore the design space of
communication adapters. In most digital signal processing (DSP) applications,
the overall performance of the system is significantly affected by
communication architectures, as a consequence the designers need specifically
optimized adapters. By explicitly modeling these communications within an
effective graph-theoretic model and analysis framework, we automatically
generate an optimized architecture, named Space-Time AdapteR (STAR). Our design
flow inputs a C description of Input/Output data scheduling, and user
requirements (throughput, latency, parallelism...), and formalizes
communication constraints through a Resource Constraints Graph (RCG). Design
space exploration is then performed through associated tools, to synthesize a
STAR component under time-to-market constraints. The proposed approach has been
tested to design an industrial data mixing block example: an Ultra-Wideband
interleaver.
"
8,"Logic, Design & Organization of PTVD-SHAM; A Parallel Time Varying &
  Data Super-helical Access Memory","  This paper encompasses a super helical memory system's design, 'Boolean logic
& image-logic' as a theoretical concept of an invention-model to 'store
time-data' in terms of anticipating the best memory location ever for
data/time. A waterfall effect is deemed to assist the process of
potential-difference output-switch into diverse logic states in quantum dot
computational methods via utilizing coiled carbon nanotubes (CCNTs) and carbon
nanotube field effect transistors (CNFETs). A 'quantum confinement' is thus
derived for a flow of particles in a categorized quantum well substrate with a
normalized capacitance rectifying high B-field flux into electromagnetic
induction. Multi-access of coherent sequences of 'qubit addressing' is gained
in any magnitude as pre-defined for the orientation of array displacement.
Briefly, Gaussian curvature of k<0 is debated in aim of specifying the 2D
electron gas characteristics in scenarios where data is stored in short
intervals versus long ones e.g. when k'>(k<0) for greater CCNT diameters,
space-time continuum is folded by chance for the particle. This benefits from
Maxwell-Lorentz theory in Minkowski's space-time viewpoint alike to crystal
oscillators for precise data timing purposes and radar systems e.g., time
varying self-clocking devices in diverse geographic locations. This application
could also be optional for data depository versus extraction, in the best
supercomputer system's locations, autonomously. For best performance in
minimizing current limiting mechanisms including electromigration, a multilevel
metallization and implant process forming elevated sources/drains for the
circuit's staircase pyramidal construction, is discussed accordingly.
"
9,A Light-Based Device for Solving the Hamiltonian Path Problem,"  In this paper we suggest the use of light for performing useful computations.
Namely, we propose a special device which uses light rays for solving the
Hamiltonian path problem on a directed graph. The device has a graph-like
representation and the light is traversing it following the routes given by the
connections between nodes. In each node the rays are uniquely marked so that
they can be easily identified. At the destination node we will search only for
particular rays that have passed only once through each node. We show that the
proposed device can solve small and medium instances of the problem in
reasonable time.
"
10,Solving the Hamiltonian path problem with a light-based computer,"  In this paper we propose a special computational device which uses light rays
for solving the Hamiltonian path problem on a directed graph. The device has a
graph-like representation and the light is traversing it by following the
routes given by the connections between nodes. In each node the rays are
uniquely marked so that they can be easily identified. At the destination node
we will search only for particular rays that have passed only once through each
node. We show that the proposed device can solve small and medium instances of
the problem in reasonable time.
"
11,Exact Cover with light,"  We suggest a new optical solution for solving the YES/NO version of the Exact
Cover problem by using the massive parallelism of light. The idea is to build
an optical device which can generate all possible solutions of the problem and
then to pick the correct one. In our case the device has a graph-like
representation and the light is traversing it by following the routes given by
the connections between nodes. The nodes are connected by arcs in a special way
which lets us to generate all possible covers (exact or not) of the given set.
For selecting the correct solution we assign to each item, from the set to be
covered, a special integer number. These numbers will actually represent delays
induced to light when it passes through arcs. The solution is represented as a
subray arriving at a certain moment in the destination node. This will tell us
if an exact cover does exist or not.
"
12,Solving the subset-sum problem with a light-based device,"  We propose a special computational device which uses light rays for solving
the subset-sum problem. The device has a graph-like representation and the
light is traversing it by following the routes given by the connections between
nodes. The nodes are connected by arcs in a special way which lets us to
generate all possible subsets of the given set. To each arc we assign either a
number from the given set or a predefined constant. When the light is passing
through an arc it is delayed by the amount of time indicated by the number
placed in that arc. At the destination node we will check if there is a ray
whose total delay is equal to the target value of the subset sum problem (plus
some constants).
"
13,Theoretical Engineering and Satellite Comlink of a PTVD-SHAM System,"  This paper focuses on super helical memory system's design, 'Engineering,
Architectural and Satellite Communications' as a theoretical approach of an
invention-model to 'store time-data'. The current release entails three
concepts: 1- an in-depth theoretical physics engineering of the chip including
its, 2- architectural concept based on VLSI methods, and 3- the time-data
versus data-time algorithm. The 'Parallel Time Varying & Data Super-helical
Access Memory' (PTVD-SHAM), possesses a waterfall effect in its architecture
dealing with the process of voltage output-switch into diverse logic and
quantum states described as 'Boolean logic & image-logic', respectively.
Quantum dot computational methods are explained by utilizing coiled carbon
nanotubes (CCNTs) and CNT field effect transistors (CNFETs) in the chip's
architecture. Quantum confinement, categorized quantum well substrate, and
B-field flux involvements are discussed in theory. Multi-access of coherent
sequences of 'qubit addressing' in any magnitude, gained as pre-defined, here
e.g., the 'big O notation' asymptotically confined into singularity while
possessing a magnitude of 'infinity' for the orientation of array displacement.
Gaussian curvature of k<0 versus k'>(k<0) is debated in aim of specifying the
2D electron gas characteristics, data storage system for defining short and
long time cycles for different CCNT diameters where space-time continuum is
folded by chance for the particle. Precise pre/post data timing for, e.g.,
seismic waves before earthquake mantle-reach event occurrence, including time
varying self-clocking devices in diverse geographic locations for radar systems
is illustrated in the Subsections of the paper. The theoretical fabrication
process, electromigration between chip's components is discussed as well.
"
14,"DPA on quasi delay insensitive asynchronous circuits: formalization and
  improvement","  The purpose of this paper is to formally specify a flow devoted to the design
of Differential Power Analysis (DPA) resistant QDI asynchronous circuits. The
paper first proposes a formal modeling of the electrical signature of QDI
asynchronous circuits. The DPA is then applied to the formal model in order to
identify the source of leakage of this type of circuits. Finally, a complete
design flow is specified to minimize the information leakage. The relevancy and
efficiency of the approach is demonstrated using the design of an AES
crypto-processor.
"
15,JANUS: an FPGA-based System for High Performance Scientific Computing,"  This paper describes JANUS, a modular massively parallel and reconfigurable
FPGA-based computing system. Each JANUS module has a computational core and a
host. The computational core is a 4x4 array of FPGA-based processing elements
with nearest-neighbor data links. Processors are also directly connected to an
I/O node attached to the JANUS host, a conventional PC. JANUS is tailored for,
but not limited to, the requirements of a class of hard scientific applications
characterized by regular code structure, unconventional data manipulation
instructions and not too large data-base size. We discuss the architecture of
this configurable machine, and focus on its use on Monte Carlo simulations of
statistical mechanics. On this class of application JANUS achieves impressive
performances: in some cases one JANUS processing element outperfoms high-end
PCs by a factor ~ 1000. We also discuss the role of JANUS on other classes of
scientific applications.
"
16,"Frequency Analysis of Decoupling Capacitors for Three Voltage Supplies
  in SoC","  Reduction in power consumption has become a major criterion of design in
modern ICs. One such scheme to reduce power consumption by an IC is the use of
multiple power supplies for critical and non-critical paths. To maintain the
impedance of a power distribution system below a specified level, multiple
decoupling capacitors are placed at different levels of power grid hierarchy.
This paper describes about three-voltage supply power distribution systems. The
noise at one power supply can propagate to the other power supply, causing
power and signal integrity problems in the overall system. Effects such as
anti-resonance and remedies for these effects are studied. Impedance of the
three-voltage supply power distribution system is calculated in terms of
RLC-model of decoupling capacitors. Further the obtained impedance depends on
the frequency; hence brief frequency analysis of impedance is done.
"
17,"CAFFEINE: Template-Free Symbolic Model Generation of Analog Circuits via
  Canonical Form Functions and Genetic Programming","  This paper presents a method to automatically generate compact symbolic
performance models of analog circuits with no prior specification of an
equation template. The approach takes SPICE simulation data as input, which
enables modeling of any nonlinear circuits and circuit characteristics. Genetic
programming is applied as a means of traversing the space of possible symbolic
expressions. A grammar is specially designed to constrain the search to a
canonical form for functions. Novel evolutionary search operators are designed
to exploit the structure of the grammar. The approach generates a set of
symbolic models which collectively provide a tradeoff between error and model
complexity. Experimental results show that the symbolic models generated are
compact and easy to understand, making this an effective method for aiding
understanding in analog design. The models also demonstrate better prediction
quality than posynomials.
"
18,"Hardware Support for Arbitrarily Complex Loop Structures in Embedded
  Applications","  In this paper, the program control unit of an embedded RISC processor is
enhanced with a novel zero-overhead loop controller (ZOLC) supporting arbitrary
loop structures with multiple-entry/exit nodes. The ZOLC has been incorporated
to an open RISC processor core to evaluate the performance of the proposed unit
for alternative configurations of the selected processor. It is proven that
speed improvements of 8.4% to 48.2% are feasible for the used benchmarks.
"
19,"A Probabilistic Collocation Method Based Statistical Gate Delay Model
  Considering Process Variations and Multiple Input Switching","  Since the advent of new nanotechnologies, the variability of gate delay due
to process variations has become a major concern. This paper proposes a new
gate delay model that includes impact from both process variations and multiple
input switching. The proposed model uses orthogonal polynomial based
probabilistic collocation method to construct a delay analytical equation from
circuit timing performance. From the experimental results, our approach has
less that 0.2% error on the mean delay of gates and less than 3% error on the
standard deviation.
"
20,Why Systems-on-Chip Needs More UML like a Hole in the Head,"  Let's be clear from the outset: SoC can most certainly make use of UML; SoC
just doesn't need more UML, or even all of it. The advent of model mappings,
coupled with marks that indicate which mapping rule to apply, enable a major
simplification of the use of UML in SoC.
"
21,"Buffer Insertion for Bridges and Optimal Buffer Sizing for Communication
  Sub-System of Systems-on-Chip","  We have presented an optimal buffer sizing and buffer insertion methodology
which uses stochastic models of the architecture and Continuous Time Markov
Decision Processes CTMDPs. Such a methodology is useful in managing the scarce
buffer resources available on chip as compared to network based data
communication which can have large buffer space. The modeling of this problem
in terms of a CT-MDP framework lead to a nonlinear formulation due to usage of
bridges in the bus architecture. We present a methodology to split the problem
into several smaller though linear systems and we then solve these subsystems.
"
22,"Modeling the Non-Linear Behavior of Library Cells for an Accurate Static
  Noise Analysis","  In signal integrity analysis, the joint effect of propagated noise through
library cells, and of the noise injected on a quiet net by neighboring
switching nets through coupling capacitances, must be considered in order to
accurately estimate the overall noise impact on design functionality and
performances. In this work the impact of the cell non-linearity on the noise
glitch waveform is analyzed in detail, and a new macromodel that allows to
accurately and efficiently modeling the non-linear effects of the victim driver
in noise analysis is presented. Experimental results demonstrate the
effectiveness of our method, and confirm that existing noise analysis
approaches based on linear superposition of the propagated and
crosstalk-injected noise can be highly inaccurate, thus impairing the sign-off
functional verification phase.
"
23,"Generic Pipelined Processor Modeling and High Performance Cycle-Accurate
  Simulator Generation","  Detailed modeling of processors and high performance cycle-accurate
simulators are essential for today's hardware and software design. These
problems are challenging enough by themselves and have seen many previous
research efforts. Addressing both simultaneously is even more challenging, with
many existing approaches focusing on one over another. In this paper, we
propose the Reduced Colored Petri Net (RCPN) model that has two advantages:
first, it offers a very simple and intuitive way of modeling pipelined
processors; second, it can generate high performance cycle-accurate simulators.
RCPN benefits from all the useful features of Colored Petri Nets without
suffering from their exponential growth in complexity. RCPN processor models
are very intuitive since they are a mirror image of the processor pipeline
block diagram. Furthermore, in our experiments on the generated cycle-accurate
simulators for XScale and StrongArm processor models, we achieved an order of
magnitude (~15 times) speedup over the popular SimpleScalar ARM simulator.
"
24,"Cycle Accurate Binary Translation for Simulation Acceleration in Rapid
  Prototyping of SoCs","  In this paper, the application of a cycle accurate binary translator for
rapid prototyping of SoCs will be presented. This translator generates code to
run on a rapid prototyping system consisting of a VLIW processor and FPGAs. The
generated code is annotated with information that triggers cycle generation for
the hardware in parallel to the execution of the translated program. The VLIW
processor executes the translated program whereas the FPGAs contain the
hardware for the parallel cycle generation and the bus interface that adapts
the bus of the VLIW processor to the SoC bus of the emulated processor core.
"
25,At-Speed Logic BIST for IP Cores,"  This paper describes a flexible logic BIST scheme that features high fault
coverage achieved by fault-simulation guided test point insertion, real
at-speed test capability for multi-clock designs without clock frequency
manipulation, and easy physical implementation due to the use of a low-speed SE
signal. Application results of this scheme to two widely used IP cores are also
reported.
"
26,"Fast Dynamic Memory Integration in Co-Simulation Frameworks for
  Multiprocessor System on-Chip","  In this paper is proposed a technique to integrate and simulate a dynamic
memory in a multiprocessor framework based on C/C++/SystemC. Using host
machine's memory management capabilities, dynamic data processing is supported
without compromising speed and accuracy of the simulation. A first prototype in
a shared memory context is presented.
"
27,Stochastic Power Grid Analysis Considering Process Variations,"  In this paper, we investigate the impact of interconnect and device process
variations on voltage fluctuations in power grids. We consider random
variations in the power grid's electrical parameters as spatial stochastic
processes and propose a new and efficient method to compute the stochastic
voltage response of the power grid. Our approach provides an explicit
analytical representation of the stochastic voltage response using orthogonal
polynomials in a Hilbert space. The approach has been implemented in a
prototype software called OPERA (Orthogonal Polynomial Expansions for Response
Analysis). Use of OPERA on industrial power grids demonstrated speed-ups of up
to two orders of magnitude. The results also show a significant variation of
about $\pm$ 35% in the nominal voltage drops at various nodes of the power
grids and demonstrate the need for variation-aware power grid analysis.
"
28,Locality-Aware Process Scheduling for Embedded MPSoCs,"  Utilizing on-chip caches in embedded multiprocessor-system-on-a-chip (MPSoC)
based systems is critical from both performance and power perspectives. While
most of the prior work that targets at optimizing cache behavior are performed
at hardware and compilation levels, operating system (OS) can also play major
role as it sees the global access pattern information across applications. This
paper proposes a cache-conscious OS process scheduling strategy based on data
reuse. The proposed scheduler implements two complementary approaches. First,
the processes that do not share any data between them are scheduled at
different cores if it is possible to do so. Second, the processes that could
not be executed at the same time (due to dependences) but share data among each
other are mapped to the same processor core so that they share the cache
contents. Our experimental results using this new data locality aware OS
scheduling strategy are promising, and show significant improvements in task
completion times.
"
29,Simultaneous Reduction of Dynamic and Static Power in Scan Structures,"  Power dissipation during test is a major challenge in testing integrated
circuits. Dynamic power has been the dominant part of power dissipation in CMOS
circuits, however, in future technologies the static portion of power
dissipation will outreach the dynamic portion. This paper proposes an efficient
technique to reduce both dynamic and static power dissipation in scan
structures. Scan cell outputs which are not on the critical path(s) are
multiplexed to fixed values during scan mode. These constant values and primary
inputs are selected such that the transitions occurred on non-multiplexed scan
cells are suppressed and the leakage current during scan mode is decreased. A
method for finding these vectors is also proposed. Effectiveness of this
technique is proved by experiments performed on ISCAS89 benchmark circuits.
"
30,"Modeling Interconnect Variability Using Efficient Parametric Model Order
  Reduction","  Assessing IC manufacturing process fluctuations and their impacts on IC
interconnect performance has become unavoidable for modern DSM designs.
However, the construction of parametric interconnect models is often hampered
by the rapid increase in computational cost and model complexity. In this paper
we present an efficient yet accurate parametric model order reduction algorithm
for addressing the variability of IC interconnect performance. The efficiency
of the approach lies in a novel combination of low-rank matrix approximation
and multi-parameter moment matching. The complexity of the proposed parametric
model order reduction is as low as that of a standard Krylov subspace method
when applied to a nominal system. Under the projection-based framework, our
algorithm also preserves the passivity of the resulting parametric models.
"
31,A Fast Diagnosis Scheme for Distributed Small Embedded SRAMs,"  This paper proposes a diagnosis scheme aimed at reducing diagnosis time of
distributed small embedded SRAMs (e-SRAMs). This scheme improves the one
proposed in [A parallel built-in self-diagnostic method for embedded memory
buffers, A parallel built-in self-diagnostic method for embedded memory
arrays]. The improvements are mainly two-fold. On one hand, the diagnosis of
time-consuming Data Retention Faults (DRFs), which is neglected by the
diagnosis architecture in [A parallel built-in self-diagnostic method for
embedded memory buffers, A parallel built-in self-diagnostic method for
embedded memory arrays], is now considered and performed via a DFT technique
referred to as the ""No Write Recovery Test Mode (NWRTM)"". On the other hand, a
pair comprising a Serial to Parallel Converter (SPC) and a Parallel to Serial
Converter (PSC) is utilized to replace the bi-directional serial interface, to
avoid the problems of serial fault masking and defect rate dependent diagnosis.
Results from our evaluations show that the proposed diagnosis scheme achieves
an increased diagnosis coverage and reduces diagnosis time compared to those
obtained in [A parallel built-in self-diagnostic method for embedded memory
buffers, A parallel built-in self-diagnostic method for embedded memory
arrays], with neglectable extra area cost.
"
32,"A Memory Hierarchical Layer Assigning and Prefetching Technique to
  Overcome the Memory Performance/Energy Bottleneck","  The memory subsystem has always been a bottleneck in performance as well as
significant power contributor in memory intensive applications. Many
researchers have presented multi-layered memory hierarchies as a means to
design energy and performance efficient systems. However, most of the previous
work do not explore trade-offs systematically. We fill this gap by proposing a
formalized technique that takes into consideration data reuse, limited lifetime
of the arrays of an application and application specific prefetching
opportunities, and performs a thorough trade-off exploration for different
memory layer sizes. This technique has been implemented on a prototype tool,
which was tested successfully using nine real-life applications of industrial
relevance. Following this approach we have able to reduce execution time up to
60%, and energy consumption up to 70%.
"
33,New Schemes for Self-Testing RAM,"  This paper gives an overview of a new technique, named pseudo-ring testing
(PRT). PRT can be applied for testing wide type of random access memories
(RAM): bit- or word-oriented and single- or dual-port RAM's. An essential
particularity of the proposed methodology is the emulation of a linear
automaton over Galois field by memory own components.
"
34,Compositional Memory Systems for Multimedia Communicating Tasks,"  Conventional cache models are not suited for real-time parallel processing
because tasks may flush each other's data out of the cache in an unpredictable
manner. In this way the system is not compositional so the overall performance
is difficult to predict and the integration of new tasks expensive. This paper
proposes a new method that imposes compositionality to the system?s performance
and makes different memory hierarchy optimizations possible for multimedia
communicating tasks when running on embedded multiprocessor architectures. The
method is based on a cache allocation strategy that assigns sets of the unified
cache exclusively to tasks and to the communication buffers. We also
analytically formulate the problem and describe a method to compute the cache
partitioning ratio for optimizing the throughput and the consumed power. When
applied to a multiprocessor with memory hierarchy our technique delivers also
performance gain. Compared to the shared cache case, for an application
consisting of two jpeg decoders and one edge detection algorithm 5 times less
misses are experienced and for an mpeg2 decoder 6.5 times less misses are
experienced.
"
35,Synchronization Processor Synthesis for Latency Insensitive Systems,"  In this paper we present our contribution in terms of synchronization
processor for a SoC design methodology based on the theory of the latency
insensitive systems (LIS) of Carloni et al. Our contribution consists in IP
encapsulation into a new wrapper model which speed and area are optimized and
synthetizability guarantied. The main benefit of our approach is to preserve
the local IP performances when encapsulating them and reduce SoC silicon area.
"
36,Thermal-Aware Task Allocation and Scheduling for Embedded Systems,"  Temperature affects not only the reliability but also the performance, power,
and cost of the embedded system. This paper proposes a thermal-aware task
allocation and scheduling algorithm for embedded systems. The algorithm is used
as a sub-routine for hardware/software co-synthesis to reduce the peak
temperature and achieve a thermally even distribution while meeting real time
constraints. The paper investigates both power-aware and thermal-aware
approaches to task allocation and scheduling. The experimental results show
that the thermal-aware approach outperforms the power-aware schemes in terms of
maximal and average temperature reductions. To the best of our knowledge, this
is the first task allocation and scheduling algorithm that takes temperature
into consideration.
"
37,Bright-Field AAPSM Conflict Detection and Correction,"  As feature sizes shrink, it will be necessary to use AAPSM
(Alternating-Aperture Phase Shift Masking) to image critical features,
especially on the polysilicon layer. This imposes additional constraints on the
layouts beyond traditional design rules. Of particular note is the requirement
that all critical features be flanked by opposite-phase shifters, while the
shifters obey minimum width and spacing requirements. A layout is called
phase-assignable if it satisfies this requirement. If a layout is not
phase-assignable, the phase conflicts have to removed to enable the use of
AAPSM for the layout. Previous work has sought to detect a suitable set of
phase Conflicts to be removed, as well as correct them. The contribution of
this paper are the following: (1) a new approach to detect a minimal set of
phase conflicts (also referred to as AAPSM conflicts), which when corrected
will produce a phase-assignable layout; (2) a novel layout modification scheme
for correcting these AAPSM conflicts. The proposed approach for conflict
detection shows significant improvements in the quality of results and runtime
for real industrial circuits, when compared to previous methods. To the best of
our knowledge, this is the first time layout modification results are presented
for bright-field AAPSM. Our experiments show that the percentage area increase
for making a layout phase-assignable ranges from 0.7-11.8%.
"
38,"Statistical Modeling of Pipeline Delay and Design of Pipeline under
  Process Variation to Enhance Yield in sub-100nm Technologies","  Operating frequency of a pipelined circuit is determined by the delay of the
slowest pipeline stage. However, under statistical delay variation in sub-100nm
technology regime, the slowest stage is not readily identifiable and the
estimation of the pipeline yield with respect to a target delay is a
challenging problem. We have proposed analytical models to estimate yield for a
pipelined design based on delay distributions of individual pipe stages. Using
the proposed models, we have shown that change in logic depth and imbalance
between the stage delays can improve the yield of a pipeline. A statistical
methodology has been developed to optimally design a pipeline circuit for
enhancing yield. Optimization results show that, proper imbalance among the
stage delays in a pipeline improves design yield by 9% for the same area and
performance (and area reduction by about 8.4% under a yield constraint) over a
balanced design.
"
39,"New Perspectives and Opportunities From the Wild West of Microelectronic
  Biochips","  Application of Microelectronic to bioanalysis is an emerging field which
holds great promise. From the standpoint of electronic and system design,
biochips imply a radical change of perspective, since new, completely different
constraints emerge while other usual constraints can be relaxed. While
electronic parts of the system can rely on the usual established design-flow,
fluidic and packaging design, calls for a new approach which relies
significantly on experiments. We hereby make some general considerations based
on our experience in the development of biochips for cell analysis.
"
40,"Integration, Verification and Layout of a Complex Multimedia SOC","  We present our experience of designing a single-chip controller for advanced
digital still camera from specification all the way to mass production. The
process involves collaboration with camera system designer, IP vendors, EDA
vendors, silicon wafer foundry, package and testing houses, and camera maker.
We also co-work with academic research groups to develop a JPEG codec IP and
memory BIST and SOC testing methodology. In this presentation, we cover the
problems encountered, our solutions, and lessons learned.
"
41,SOC Testing Methodology and Practice,"  On a commercial digital still camera (DSC) controller chip we practice a
novel SOC test integration platform, solving real problems in test scheduling,
test IO reduction, timing of functional test, scan IO sharing, embedded memory
built-in self-test (BIST), etc. The chip has been fabricated and tested
successfully by our approach. Test results justify that short test integration
cost, short test time, and small area overhead can be achieved. To support SOC
testing, a memory BIST compiler and an SOC testing integration system have been
developed.
"
42,Evolutionary Optimization in Code-Based Test Compression,"  We provide a general formulation for the code-based test compression problem
with fixed-length input blocks and propose a solution approach based on
Evolutionary Algorithms. In contrast to existing code-based methods, we allow
unspecified values in matching vectors, which allows encoding of arbitrary test
sets using a relatively small number of code-words. Experimental results for
both stuck-at and path delay fault test sets for ISCAS circuits demonstrate an
improvement compared to existing techniques.
"
43,An Application-Specific Design Methodology for STbus Crossbar Generation,"  As the communication requirements of current and future Multiprocessor
Systems on Chips (MPSoCs) continue to increase, scalable communication
architectures are needed to support the heavy communication demands of the
system. This is reflected in the recent trend that many of the standard bus
products such as STbus, have now introduced the capability of designing a
crossbar with multiple buses operating in parallel. The crossbar configuration
should be designed to closely match the application traffic characteristics and
performance requirements. In this work we address this issue of
application-specific design of optimal crossbar (using STbus crossbar
architecture), satisfying the performance requirements of the application and
optimal binding of cores onto the crossbar resources. We present a simulation
based design approach that is based on analysis of actual traffic trace of the
application, considering local variations in traffic rates, temporal overlap
among traffic streams and criticality of traffic streams. Our methodology is
applied to several MPSoC designs and the resulting crossbar platforms are
validated for performance by cycle-accurate SystemC simulation of the designs.
The experimental case studies show large reduction in packet latencies (up to
7x) and large crossbar component savings (up to 3.5x) compared to traditional
design approaches.
"
44,"Yield Enhancement of Digital Microfluidics-Based Biochips Using Space
  Redundancy and Local Reconfiguration","  As microfluidics-based biochips become more complex, manufacturing yield will
have significant influence on production volume and product cost. We propose an
interstitial redundancy approach to enhance the yield of biochips that are
based on droplet-based microfluidics. In this design method, spare cells are
placed in the interstitial sites within the microfluidic array, and they
replace neighboring faulty cells via local reconfiguration. The proposed design
method is evaluated using a set of concurrent real-life bioassays.
"
45,"Design of Fault-Tolerant and Dynamically-Reconfigurable Microfluidic
  Biochips","  Microfluidics-based biochips are soon expected to revolutionize clinical
diagnosis, DNA sequencing, and other laboratory procedures involving molecular
biology. Most microfluidic biochips are based on the principle of continuous
fluid flow and they rely on permanently-etched microchannels, micropumps, and
microvalves. We focus here on the automated design of ""digital"" droplet-based
microfluidic biochips. In contrast to continuous-flow systems, digital
microfluidics offers dynamic reconfigurability; groups of cells in a
microfluidics array can be reconfigured to change their functionality during
the concurrent execution of a set of bioassays. We present a simulated
annealing-based technique for module placement in such biochips. The placement
procedure not only addresses chip area, but it also considers fault tolerance,
which allows a microfluidic module to be relocated elsewhere in the system when
a single cell is detected to be faulty. Simulation results are presented for a
case study involving the polymerase chain reaction.
"
46,CMOS-Based Biosensor Arrays,"  CMOS-based sensor array chips provide new and attractive features as compared
to today's standard tools for medical, diagnostic, and biotechnical
applications. Examples for molecule- and cell-based approaches and related
circuit design issues are discussed.
"
47,DVS for On-Chip Bus Designs Based on Timing Error Correction,"  On-chip buses are typically designed to meet performance constraints at
worst-case conditions, including process corner, temperature, IR-drop, and
neighboring net switching pattern. This can result in significant performance
slack at more typical operating conditions. In this paper, we propose a dynamic
voltage scaling (DVS) technique for buses, based on a double sampling latch
which can detect and correct for delay errors without the need for
retransmission. The proposed approach recovers the available slack at
non-worst-case operating points through more aggressive voltage scaling and
tracks changing conditions by monitoring the error recovery rate. Voltage
margins needed in traditional designs to accommodate worst-case performance
conditions are therefore eliminated, resulting in a significant improvement in
energy efficiency. The approach was implemented for a 6mm memory read bus
operating at 1.5GHz (0.13 $\mu$m technology node) and was simulated for a
number of benchmark programs. Even at the worst-case process and environment
conditions, energy gains of up to 17% are achieved, with error recovery rates
under 2.3%. At more typical process and environment conditions, energy gains
range from 35% to 45%, with a performance degradation under 2%. An analysis of
optimum interconnect architectures for maximizing energy gains with this
approach shows that the proposed approach performs well with technology
scaling.
"
48,"A Quality-of-Service Mechanism for Interconnection Networks in
  System-on-Chips","  As Moore's Law continues to fuel the ability to build ever increasingly
complex system-on-chips (SoCs), achieving performance goals is rising as a
critical challenge to completing designs. In particular, the system
interconnect must efficiently service a diverse set of data flows with widely
ranging quality-of-service (QoS) requirements. However, the known solutions for
off-chip interconnects such as large-scale networks are not necessarily
applicable to the on-chip environment. Latency and memory constraints for
on-chip interconnects are quite different from larger-scale interconnects. This
paper introduces a novel on-chip interconnect arbitration scheme. We show how
this scheme can be distributed across a chip for high-speed implementation. We
compare the performance of the arbitration scheme with other known interconnect
arbitration schemes. Existing schemes typically focus heavily on either low
latency of service for some initiators, or alternatively on guaranteed
bandwidth delivery for other initiators. Our scheme allows service latency on
some initiators to be traded off smoothly against jitter bounds on other
initiators, while still delivering bandwidth guarantees. This scheme is a
subset of the QoS controls that are available in the SonicsMX? (SMX) product.
"
49,Reliability-Centric High-Level Synthesis,"  Importance of addressing soft errors in both safety critical applications and
commercial consumer products is increasing, mainly due to ever shrinking
geometries, higher-density circuits, and employment of power-saving techniques
such as voltage scaling and component shut-down. As a result, it is becoming
necessary to treat reliability as a first-class citizen in system design. In
particular, reliability decisions taken early in system design can have
significant benefits in terms of design quality. Motivated by this observation,
this paper presents a reliability-centric high-level synthesis approach that
addresses the soft error problem. The proposed approach tries to maximize
reliability of the design while observing the bounds on area and performance,
and makes use of our reliability characterization of hardware components such
as adders and multipliers. We implemented the proposed approach, performed
experiments with several designs, and compared the results with those obtained
by a prior proposal.
"
50,Reliable System Specification for Self-Checking Data-Paths,"  The design of reliable circuits has received a lot of attention in the past,
leading to the definition of several design techniques introducing fault
detection and fault tolerance properties in systems for critical
applications/environments. Such design methodologies tackled the problem at
different abstraction levels, from switch-level to logic, RT level, and more
recently to system level. Aim of this paper is to introduce a novel
system-level technique based on the redefinition of the operators functionality
in the system specification. This technique provides reliability properties to
the system data path, transparently with respect to the designer. Feasibility,
fault coverage, performance degradation and overheads are investigated on a FIR
circuit.
"
51,Test Planning for Mixed-Signal SOCs with Wrapped Analog Cores,"  Many SOCs today contain both digital and analog embedded cores. Even though
the test cost for such mixed-signal SOCs is significantly higher than that for
digital SOCs, most prior research in this area has focused exclusively on
digital cores. We propose a low-cost test development methodology for
mixed-signal SOCs that allows the analog and digital cores to be tested in a
unified manner, thereby minimizing the overall test cost. The analog cores in
the SOC are wrapped such that they can be accessed using a digital test access
mechanism (TAM). We evaluate the impact of the use of analog test wrappers on
area overhead and test time. To reduce area overhead, we present an analog test
wrapper optimization technique, which is then combined with TAM optimization in
a cost-oriented heuristic approach for test scheduling. We also demonstrate the
feasibility of using analog wrappers by presenting transistor-level simulations
for an analog wrapper and a representative core. We present experimental
results on test scheduling for an ITC'02 benchmark SOC that has been augmented
with five analog cores.
"
52,"On-Chip Test Infrastructure Design for Optimal Multi-Site Testing of
  System Chips","  Multi-site testing is a popular and effective way to increase test throughput
and reduce test costs. We present a test throughput model, in which we focus on
wafer testing, and consider parameters like test time, index time,
abort-on-fail, and contact yield. Conventional multi-site testing requires
sufficient ATE resources, such as ATE channels, to allow to test multiple SOCs
in parallel. In this paper, we design and optimize on-chip DfT, in order to
maximize the test throughput for a given SOC and ATE. The on-chip DfT consists
of an E-RPCT wrapper, and, for modular SOCs, module wrappers and TAMs. We
present experimental results for a Philips SOC and several ITC'02 SOC Test
Benchmarks.
"
53,"On the Optimal Design of Triple Modular Redundancy Logic for SRAM-based
  FPGAs","  Triple Modular Redundancy (TMR) is a suitable fault tolerant technique for
SRAM-based FPGA. However, one of the main challenges in achieving 100%
robustness in designs protected by TMR running on programmable platforms is to
prevent upsets in the routing from provoking undesirable connections between
signals from distinct redundant logic parts, which can generate an error in the
output. This paper investigates the optimal design of the TMR logic (e.g., by
cleverly inserting voters) to ensure robustness. Four different versions of a
TMR digital filter were analyzed by fault injection. Faults were randomly
inserted straight into the bitstream of the FPGA. The experimental results
presented in this paper demonstrate that the number and placement of voters in
the TMR design can directly affect the fault tolerance, ranging from 4.03% to
0.98% the number of upsets in the routing able to cause an error in the TMR
circuit.
"
54,"An O(bn^2) Time Algorithm for Optimal Buffer Insertion with b Buffer
  Types","  Buffer insertion is a popular technique to reduce the interconnect delay. The
classic buffer insertion algorithm of van Ginneken has time complexity O(n^2),
where n is the number of buffer positions. Lillis, Cheng and Lin extended van
Ginneken's algorithm to allow b buffer types in time O (b^2 n^2). For modern
design libraries that contain hundreds of buffers, it is a serious challenge to
balance the speed and performance of the buffer insertion algorithm. In this
paper, we present a new algorithm that computes the optimal buffer insertion in
O (bn^2) time. The reduction is achieved by the observation that the (Q, C)
pairs of the candidates that generate the new candidates must form a convex
hull. On industrial test cases, the new algorithm is faster than the previous
best buffer insertion algorithms by orders of magnitude.
"
55,Cantilever-Based Biosensors in CMOS Technology,"  Single-chip CMOS-based biosensors that feature microcantilevers as transducer
elements are presented. The cantilevers are functionalized for the capturing of
specific analytes, e.g., proteins or DNA. The binding of the analyte changes
the mechanical properties of the cantilevers such as surface stress and
resonant frequency, which can be detected by an integrated Wheatstone bridge.
The monolithic integrated readout allows for a high signal-to-noise ratio,
lowers the sensitivity to external interference and enables autonomous device
operation.
"
56,"Memory Testing Under Different Stress Conditions: An Industrial
  Evaluation","  This paper presents the effectiveness of various stress conditions (mainly
voltage and frequency) on detecting the resistive shorts and open defects in
deep sub-micron embedded memories in an industrial environment. Simulation
studies on very-low voltage, high voltage and at-speed testing show the need of
the stress conditions for high quality products; i.e., low defect-per-million
(DPM) level, which is driving the semiconductor market today. The above test
conditions have been validated to screen out bad devices on real silicon (a
test-chip) built on CMOS 0.18 um technology. IFA (inductive fault analysis)
based simulation technique leads to an efficient fault coverage and DPM
estimator, which helps the customers upfront to make decisions on test
algorithm implementations under different stress conditions in order to reduce
the number of test escapes.
"
57,Statistical Timing Based Optimization using Gate Sizing,"  The increased dominance of intra-die process variations has motivated the
field of Statistical Static Timing Analysis (SSTA) and has raised the need for
SSTA-based circuit optimization. In this paper, we propose a new sensitivity
based, statistical gate sizing method. Since brute-force computation of the
change in circuit delay distribution to gate size change is computationally
expensive, we propose an efficient and exact pruning algorithm. The pruning
algorithm is based on a novel theory of perturbation bounds which are shown to
decrease as they propagate through the circuit. This allows pruning of gate
sensitivities without complete propagation of their perturbations. We apply our
proposed optimization algorithm to ISCAS benchmark circuits and demonstrate the
accuracy and efficiency of the proposed method. Our results show an improvement
of up to 10.5% in the 99-percentile circuit delay for the same circuit area,
using the proposed statistical optimizer and a run time improvement of up to
56x compared to the brute-force approach.
"
58,"A Way Memoization Technique for Reducing Power Consumption of Caches in
  Application Specific Integrated Processors","  This paper presents a technique for eliminating redundant cache-tag and
cache-way accesses to reduce power consumption. The basic idea is to keep a
small number of Most Recently Used (MRU) addresses in a Memory Address Buffer
(MAB) and to omit redundant tag and way accesses when there is a MAB-hit. Since
the approach keeps only tag and set-index values in the MAB, the energy and
area overheads are relatively small even for a MAB with a large number of
entries. Furthermore, the approach does not sacrifice the performance. In other
words, neither the cycle time nor the number of executed cycles increases. The
proposed technique has been applied to Fujitsu VLIW processor (FR-V) and its
power saving has been estimated using NanoSim. Experiments for 32kB 2-way set
associative caches show the power consumption of I-cache and D-cache can be
reduced by 40% and 50%, respectively.
"
59,"Resource Sharing and Pipelining in Coarse-Grained Reconfigurable
  Architecture for Domain-Specific Optimization","  Coarse-grained reconfigurable architectures aim to achieve both goals of high
performance and flexibility. However, existing reconfigurable array
architectures require many resources without considering the specific
application domain. Functional resources that take long latency and/or large
area can be pipelined and/or shared among the processing elements. Therefore
the hardware cost and the delay can be effectively reduced without any
performance degradation for some application domains. We suggest such
reconfigurable array architecture template and design space exploration flow
for domain-specific optimization. Experimental results show that our approach
is much more efficient both in performance and area compared to existing
reconfigurable architectures.
"
60,"A Study of the Speedups and Competitiveness of FPGA Soft Processor Cores
  using Dynamic Hardware/Software Partitioning","  Field programmable gate arrays (FPGAs) provide designers with the ability to
quickly create hardware circuits. Increases in FPGA configurable logic capacity
and decreasing FPGA costs have enabled designers to more readily incorporate
FPGAs in their designs. FPGA vendors have begun providing configurable soft
processor cores that can be synthesized onto their FPGA products. While FPGAs
with soft processor cores provide designers with increased flexibility, such
processors typically have degraded performance and energy consumption compared
to hard-core processors. Previously, we proposed warp processing, a technique
capable of optimizing a software application by dynamically and transparently
re-implementing critical software kernels as custom circuits in on-chip
configurable logic. In this paper, we study the potential of a MicroBlaze
soft-core based warp processing system to eliminate the performance and energy
overhead of a soft-core processor compared to a hard-core processor. We
demonstrate that the soft-core based warp processor achieves average speedups
of 5.8 and energy reductions of 57% compared to the soft core alone. Our data
shows that a soft-core based warp processor yields performance and energy
consumption competitive with existing hard-core processors, thus expanding the
usefulness of soft processor cores on FPGAs to a broader range of applications.
"
61,"An Infrastructure to Functionally Test Designs Generated by Compilers
  Targeting FPGAs","  This paper presents an infrastructure to test the functionality of the
specific architectures output by a high-level compiler targeting dynamically
reconfigurable hardware. It results in a suitable scheme to verify the
architectures generated by the compiler, each time new optimization techniques
are included or changes in the compiler are performed. We believe this kind of
infrastructure is important to verify, by functional simulation, further
research techniques, as far as compilation to Field-Programmable Gate Array
(FPGA) platforms is concerned.
"
62,"Energy- and Performance-Driven NoC Communication Architecture Synthesis
  Using a Decomposition Approach","  In this paper, we present a methodology for customized communication
architecture synthesis that matches the communication requirements of the
target application. This is an important problem, particularly for
network-based implementations of complex applications. Our approach is based on
using frequently encountered generic communication primitives as an alphabet
capable of characterizing any given communication pattern. The proposed
algorithm searches through the entire design space for a solution that
minimizes the system total energy consumption, while satisfying the other
design constraints. Compared to the standard mesh architecture, the customized
architecture generated by the newly proposed approach shows about 36%
throughput increase and 51% reduction in the energy required to encrypt 128
bits of data with a standard encryption algorithm.
"
63,Analog and Digital Circuit Design in 65 nm CMOS: End of the Road?,"  This special session adresses the problems that designers face when
implementing analog and digital circuits in nanometer technologies. An
introductory embedded tutorial will give an overview of the design problems at
hand : the leakage power and process variability and their implications for
digital circuits and memories, and the reducing supply voltages, the design
productivity and signal integrity problems for embedded analog blocks. Next, a
panel of experts from both industrial semiconductor houses and design
companies, EDA vendors and research institutes will present and discuss with
the audience their opinions on whether the design road ends at marker ""65nm"" or
not.
"
64,FPGA Architecture for Multi-Style Asynchronous Logic,"  This paper presents a novel FPGA architecture for implementing various styles
of asynchronous logic. The main objective is to break the dependency between
the FPGA architecture dedicated to asynchronous logic and the logic style. The
innovative aspects of the architecture are described. Moreover the structure is
well suited to be rebuilt and adapted to fit with further asynchronous logic
evolutions thanks to the architecture genericity. A full-adder was implemented
in different styles of logic to show the architecture flexibility.
"
65,An Accurate SER Estimation Method Based on Propagation Probability,"  In this paper, we present an accurate but very fast soft error rate (SER)
estimation technique for digital circuits based on error propagation
probability (EPP) computation. Experiments results and comparison of the
results with the random simulation technique show that our proposed method is
on average within 6% of the random simulation method and four to five orders of
magnitude faster.
"
66,"Improving the Process-Variation Tolerance of Digital Circuits Using Gate
  Sizing and Statistical Techniques","  A new approach for enhancing the process-variation tolerance of digital
circuits is described. We extend recent advances in statistical timing analysis
into an optimization framework. Our objective is to reduce the performance
variance of a technology-mapped circuit where delays across elements are
represented by random variables which capture the manufacturing variations. We
introduce the notion of statistical critical paths, which account for both
means and variances of performance variation. An optimization engine is used to
size gates with a goal of reducing the timing variance along the statistical
critical paths. We apply a pair of nested statistical analysis methods
deploying a slower more accurate approach for tracking statistical critical
paths and a fast engine for evaluation of gate size assignments. We derive a
new approximation for the max operation on random variables which is deployed
for the faster inner engine. Circuit optimization is carried out using a
gain-based algorithm that terminates when constraints are satisfied or no
further improvements can be made. We show optimization results that demonstrate
an average of 72% reduction in performance variation at the expense of average
20% increase in design area.
"
67,"Assertion-Based Design Exploration of DVS in Network Processor
  Architectures","  With the scaling of technology and higher requirements on performance and
functionality, power dissipation is becoming one of the major design
considerations in the development of network processors. In this paper, we use
an assertion-based methodology for system-level power/performance analysis to
study two dynamic voltage scaling (DVS) techniques, traffic-based DVS and
execution-based DVS, in a network processor model. Using the automatically
generated distribution analyzers, we analyze the power and performance
distributions and study their trade-offs for the two DVS policies with
different parameter settings such as threshold values and window sizes. We
discuss the optimal configurations of the two DVS policies under different
design requirements. By a set of experiments, we show that the assertion-based
trace analysis methodology is an efficient tool that can help a designer easily
compare and study optimal architectural configurations in a large design space.
"
68,"Circuit-Level Modeling for Concurrent Testing of Operational Defects due
  to Gate Oxide Breakdown","  As device sizes shrink and current densities increase, the probability of
device failures due to gate oxide breakdown (OBD) also increases. To provide
designs that are tolerant to such failures, we must investigate and understand
the manifestations of this physical phenomenon at the circuit and system level.
In this paper, we develop a model for operational OBD defects, and we explore
how to test for faults due to OBD. For a NAND gate, we derive the necessary
input conditions that excite and detect errors due to OBD defects at the gate
level. We show that traditional pattern generators fail to exercise all of
these defects. Finally, we show that these test patterns can be propagated and
justified for a combinational circuit in a manner similar to traditional ATPG.
"
69,Optimized Generation of Data-Path from C Codes for FPGAs,"  FPGAs, as computing devices, offer significant speedup over microprocessors.
Furthermore, their configurability offers an advantage over traditional ASICs.
However, they do not yet enjoy high-level language programmability, as
microprocessors do. This has become the main obstacle for their wider
acceptance by application designers. ROCCC is a compiler designed to generate
circuits from C source code to execute on FPGAs, more specifically on CSoCs. It
generates RTL level HDLs from frequently executing kernels in an application.
In this paper, we describe ROCCC's system overview and focus on its data path
generation. We compare the performance of ROCCC-generated VHDL code with that
of Xilinx IPs. The synthesis result shows that ROCCC-generated circuit takes
around 2x ~ 3x area and runs at comparable clock rate.
"
70,"Multi-Placement Structures for Fast and Optimized Placement in Analog
  Circuit Synthesis","  This paper presents the novel idea of multi-placement structures, for a fast
and optimized placement instantiation in analog circuit synthesis. These
structures need to be generated only once for a specific circuit topology. When
used in synthesis, these pre-generated structures instantiate various layout
floorplans for various sizes and parameters of a circuit. Unlike procedural
layout generators, they enable fast placement of circuits while keeping the
quality of the placements at a high level during a synthesis process. The fast
placement is a result of high speed instantiation resulting from the efficiency
of the multi-placement structure. The good quality of placements derive from
the extensive and intelligent search process that is used to build the
multi-placement structure. The target benchmarks of these structures are analog
circuits in the vicinity of 25 modules. An algorithm for the generation of such
multi-placement structures is presented. Experimental results show placement
execution times with an average of a few milliseconds making them usable during
layout-aware synthesis for optimized placements.
"
71,Specification Test Compaction for Analog Circuits and MEMS,"  Testing a non-digital integrated system against all of its specifications can
be quite expensive due to the elaborate test application and measurement setup
required. We propose to eliminate redundant tests by employing e-SVM based
statistical learning. Application of the proposed methodology to an operational
amplifier and a MEMS accelerometer reveal that redundant tests can be
statistically identified from a complete set of specification-based tests with
negligible error. Specifically, after eliminating five of eleven
specification-based tests for an operational amplifier, the defect escape and
yield loss is small at 0.6% and 0.9%, respectively. For the accelerometer,
defect escape of 0.2% and yield loss of 0.1% occurs when the hot and colt tests
are eliminated. For the accelerometer, this level of Compaction would reduce
test cost by more than half.
"
72,Soft-Error Tolerance Analysis and Optimization of Nanometer Circuits,"  Nanometer circuits are becoming increasingly susceptible to soft-errors due
to alpha-particle and atmospheric neutron strikes as device scaling reduces
node capacitances and supply/threshold voltage scaling reduces noise margins.
It is becoming crucial to add soft-error tolerance estimation and optimization
to the design flow to handle the increasing susceptibility. The first part of
this paper presents a tool for accurate soft-error tolerance analysis of
nanometer circuits (ASERTA) that can be used to estimate the soft-error
tolerance of nanometer circuits consisting of millions of gates. The tolerance
estimates generated by the tool match SPICE generated estimates closely while
taking orders of magnitude less computation time. The second part of the paper
presents a tool for soft-error tolerance optimization of nanometer circuits
(SERTOPT) using the tolerance estimates generated by ASERTA. The tool finds
optimal sizes, channel lengths, supply voltages and threshold voltages to be
assigned to gates in a combinational circuit such that the soft-error tolerance
is increased while meeting the timing constraint. Experiments on ISCAS'85
benchmark circuits showed that soft-error rate of the optimized circuit
decreased by as much as 47% with marginal increase in circuit delay.
"
73,IEEE 1149.4 Compatible ABMs for Basic RF Measurements,"  An analogue testing standard IEEE 1149.4 is mainly targeted for low-frequency
testing. The problem studied in this paper is extending the standard also for
radio frequency testing. IEEE 1149.4 compatible measurement structures (ABMs)
developed in this study extract the information one is measuring from the radio
frequency signal and represent the result as a DC voltage level. The ABMs
presented in this paper are targeted for power and frequency measurements
operating in frequencies from 1 GHz to 2 GHz. The power measurement error
caused by temperature, supply voltage and process variations is roughly 2 dB
and the frequency measurement error is 0.1 GHz, respectively.
"
74,"Designer-Driven Topology Optimization for Pipelined Analog to Digital
  Converters","  This paper suggests a practical ""hybrid"" synthesis methodology which
integrates designer-derived analytical models for system-level description with
simulation-based models at the circuit level. We show how to optimize
stage-resolution to minimize the power in a pipelined ADC. Exploration (via
detailed synthesis) of several ADC configurations is used to show that a
4-3-2... resolution distribution uses the least power for a 13-bit 40 MSPS
converter in a 0.25 $\mu$m CMOS process.
"
75,Systematic Figure of Merit Computation for the Design of Pipeline ADC,"  The emerging concept of SoC-AMS leads to research new top-down methodologies
to aid systems designers in sizing analog and mixed devices. This work applies
this idea to the high-level optimization of pipeline ADC. Considering a given
technology, it consists in comparing different configurations according to
their imperfections and their architectures without FFT computation or
time-consuming simulations. The final selection is based on a figure of merit.
"
76,"Top-Down Design of a Low-Power Multi-Channel 2.5-Gbit/s/Channel Gated
  Oscillator Clock-Recovery Circuit","  We present a complete top-down design of a low-power multi-channel clock
recovery circuit based on gated current-controlled oscillators. The flow
includes several tools and methods used to specify block constraints, to design
and verify the topology down to the transistor level, as well as to achieve a
power consumption as low as 5mW/Gbit/s. Statistical simulation is used to
estimate the achievable bit error rate in presence of phase and frequency
errors and to prove the feasibility of the concept. VHDL modeling provides
extensive verification of the topology. Thermal noise modeling based on
well-known concepts delivers design parameters for the device sizing and
biasing. We present two practical examples of possible design improvements
analyzed and implemented with this methodology.
"
77,Energy-Aware Routing for E-Textile Applications,"  As the scale of electronic devices shrinks, ""electronic textiles""
(e-textiles) will make possible a wide variety of novel applications which are
currently unfeasible. Due to the wearability concerns, low-power techniques are
critical for e-textile applications. In this paper, we address the issue of the
energy-aware routing for e-textile platforms and propose an efficient algorithm
to solve it. The platform we consider consists of dedicated components for
e-textiles, including computational modules, dedicated transmission lines and
thin-film batteries on fiber substrates. Furthermore, we derive an analytical
upper bound for the achievable number of jobs completed over all possible
routing strategies. From a practical standpoint, for the Advanced Encryption
Standard (AES) cipher, the routing technique we propose achieves about fifty
percent of this analytical upper bound. Moreover, compared to the
non-energy-aware counterpart, our routing technique increases the number of
encryption jobs completed by one order of magnitude.
"
78,"Modeling and Analysis of Loading Effect in Leakage of Nano-Scaled
  Bulk-CMOS Logic Circuits","  In nanometer scaled CMOS devices significant increase in the subthreshold,
the gate and the reverse biased junction band-to-band-tunneling (BTBT) leakage,
results in the large increase of total leakage power in a logic circuit.
Leakage components interact with each other in device level (through device
geometry, doping profile) and also in the circuit level (through node
voltages). Due to the circuit level interaction of the different leakage
components, the leakage of a logic gate strongly depends on the circuit
topology i.e. number and nature of the other logic gates connected to its input
and output. In this paper, for the first time, we have analyzed loading effect
on leakage and proposed a method to accurately estimate the total leakage in a
logic circuit, from its logic level description considering the impact of
loading and transistor stacking.
"
79,Leakage-Aware Interconnect for On-Chip Network,"  On-chip networks have been proposed as the interconnect fabric for future
systems-on-chip and multi-processors on chip. Power is one of the main
constraints of these systems and interconnect consumes a significant portion of
the power budget. In this paper, we propose four leakage-aware interconnect
schemes. Our schemes achieve 10.13%~63.57% active leakage savings and
12.35%~95.96% standby leakage savings across schemes while the delay penalty
ranges from 0% to 4.69%.
"
80,Smart Temperature Sensor for Thermal Testing of Cell-Based ICs,"  In this paper we present a simple and efficient built-in temperature sensor
for thermal monitoring of standard-cell based VLSI circuits. The proposed smart
temperature sensor uses a ring-oscillator composed of complex gates instead of
inverters to optimize their linearity. Simulation results from a 0.18$\mu$m
CMOS technology show that the non-linearity error of the sensor can be reduced
when an adequate set of standard logic gates is selected.
"
81,Worst-Case and Average-Case Analysis of n-Detection Test Sets,"  Test sets that detect each target fault n times (n-detection test sets) are
typically generated for restricted values of n due to the increase in test set
size with n. We perform both a worst-case analysis and an average-case analysis
to check the effect of restricting n on the unmodeled fault coverage of an
(arbitrary) n-detection test set. Our analysis is independent of any particular
test set or test generation approach. It is based on a specific set of target
faults and a specific set of untargeted faults. It shows that, depending on the
circuit, very large values of n may be needed to guarantee the detection of all
the untargeted faults. We discuss the implications of these results.
"
82,A New Embedded Measurement Structure for eDRAM Capacitor,"  The embedded DRAM (eDRAM) is more and more used in System On Chip (SOC). The
integration of the DRAM capacitor process into a logic process is challenging
to get satisfactory yields. The specific process of DRAM capacitor and the low
capacitance value (~30F) of this device induce problems of process monitoring
and failure analysis. We propose a new test structure to measure the
capacitance value of each DRAM cell capacitor in a DRAM array. This concept has
been validated by simulation on a 0.18$\mu$m eDRAM technology.
"
83,Exploring NoC Mapping Strategies: An Energy and Timing Aware Technique,"  Complex applications implemented as Systems on Chip (SoCs) demand extensive
use of system level modeling and validation. Their implementation gathers a
large number of complex IP cores and advanced interconnection schemes, such as
hierarchical bus architectures or networks on chip (NoCs). Modeling
applications involves capturing its computation and communication
characteristics. Previously proposed communication weighted models (CWM)
consider only the application communication aspects. This work proposes a
communication dependence and computation model (CDCM) that can simultaneously
consider both aspects of an application. It presents a solution to the problem
of mapping applications on regular NoCs while considering execution time and
energy consumption. The use of CDCM is shown to provide estimated average
reductions of 40% in execution time, and 20% in energy consumption, for current
technologies.
"
84,Hardware Accelerated Power Estimation,"  In this paper, we present power emulation, a novel design paradigm that
utilizes hardware acceleration for the purpose of fast power estimation. Power
emulation is based on the observation that the functions necessary for power
estimation (power model evaluation, aggregation, etc.) can be implemented as
hardware circuits. Therefore, we can enhance any given design with ""power
estimation hardware"", map it to a prototyping platform, and exercise it with
any given test stimuli to obtain power consumption estimates. Our empirical
studies with industrial designs reveal that power emulation can achieve
significant speedups (10X to 500X) over state-of-the-art commercial
register-transfer level (RTL) power estimation tools.
"
85,An Efficient Transparent Test Scheme for Embedded Word-Oriented Memories,"  Memory cores are usually the densest portion with the smallest feature size
in system-on-chip (SOC) designs. The reliability of memory cores thus has heavy
impact on the reliability of SOCs. Transparent test is one of useful technique
for improving the reliability of memories during life time. This paper presents
a systematic algorithm used for transforming a bit-oriented march test into a
transparent word-oriented march test. The transformed transparent march test
has shorter test complexity compared with that proposed in the previous works
[Theory of transparent BIST for RAMs, A transparent online memory test for
simultaneous detection of functional faults and soft errors in memories]. For
example, if a memory with 32-bit words is tested with March C-, time complexity
of the transparent word-oriented test transformed by the proposed scheme is
only about 56% or 19% time complexity of the transparent word-oriented test
converted by the scheme reported in [Theory of transparent BIST for RAMs] or [A
transparent online memory test for simultaneous detection of functional faults
and soft errors in memories], respectively.
"
86,Systematic Transaction Level Modeling of Embedded Systems with SystemC,"  This paper gives an overview of a transaction level modeling (TLM) design
flow for straightforward embedded system design with SystemC. The goal is to
systematically develop both application-specific HW and SW components of an
embedded system using the TLM approach, thus allowing for fast communication
architecture exploration, rapid prototyping and early embedded SW development.
To this end, we specify the lightweight transaction-based communication
protocol SHIP and present a methodology for automatic mapping of the
communication part of a system to a given architecture, including HW/SW
interfaces.
"
87,"Influence of Memory Hierarchies on Predictability for Time Constrained
  Embedded Software","  Safety-critical embedded systems having to meet real-time constraints are
expected to be highly predictable in order to guarantee at design time that
certain timing deadlines will always be met. This requirement usually prevents
designers from utilizing caches due to their highly dynamic, thus hardly
predictable behavior. The integration of scratchpad memories represents an
alternative approach which allows the system to benefit from a performance gain
comparable to that of caches while at the same time maintaining predictability.
In this work, we compare the impact of scratchpad memories and caches on worst
case execution time (WCET) analysis results. We show that caches, despite
requiring complex techniques, can have a negative impact on the predicted WCET,
while the estimated WCET for scratchpad memories scales with the achieved
Performance gain at no extra analysis cost.
"
88,Design of a Virtual Component Neutral Network-on-Chip Transaction Layer,"  Research studies have demonstrated the feasibility and advantages of
Network-on-Chip (NoC) over traditional bus-based architectures but have not
focused on compatibility communication standards. This paper describes a number
of issues faced when designing a VC-neutral NoC, i.e. compatible with standards
such as AHB 2.0, AXI, VCI, OCP, and various other proprietary protocols, and
how a layered approach to communication helps solve these issues.
"
89,"Techniques for Fast Transient Fault Grading Based on Autonomous
  Emulation","  Very deep submicron and nanometer technologies have increased notably
integrated circuit (IC) sensitiveness to radiation. Soft errors are currently
appearing into ICs working at earth surface. Hardened circuits are currently
required in many applications where Fault Tolerance (FT) was not a requirement
in the very near past. The use of platform FPGAs for the emulation of
single-event upset effects (SEU) is gaining attention in order to speed up the
FT evaluation. In this work, a new emulation system for FT evaluation with
respect to SEU effects is proposed, providing shorter evaluation times by
performing all the evaluation process in the FPGA and avoiding emulator-host
communication bottlenecks.
"
90,A Fast Concurrent Power-Thermal Model for Sub-100nm Digital ICs,"  As technology scales down, the static power is expected to become a
significant fraction of the total power. The exponential dependence of static
power with the operating temperature makes the thermal profile estimation of
high-performance ICs a key issue to compute the total power dissipated in
next-generations. In this paper we present accurate and compact analytical
models to estimate the static power dissipation and the temperature of
operation of CMOS gates. The models are the fundamentals of a performance
estimation tool in which numerical procedures are avoided for any computation
to set a faster estimation and optimization. The models developed are compared
to measurements and SPICE simulations for a 0.12mm technology showing excellent
results.
"
91,Low Power Oriented CMOS Circuit Optimization Protocol,"  Low power oriented circuit optimization consists in selecting the best
alternative between gate sizing, buffer insertion and logic structure
transformation, for satisfying a delay constraint at minimum area cost. In this
paper we used a closed form model of delay in CMOS structures to define metrics
for a deterministic selection of the optimization alternative. The target is
delay constraint satisfaction with minimum area cost. We validate the design
space exploration method, defining maximum and minimum delay bounds on logical
paths. Then we adapt this method to a ""constant sensitivity method"" allowing to
size a circuit at minimum area under a delay constraint. An optimisation
protocol is finally defined to manage the trade-off performance constraint -
circuit structure. These methods are implemented in an optimization tool (POPS)
and validated by comparing on a 0.25$\mu$m process, the optimization efficiency
obtained on various benchmarks (ISCAS?85) to that resulting from an industrial
tool.
"
92,Low-Cost Multi-Gigahertz Test Systems Using CMOS FPGAs and PECL,"  This paper describes two research projects that develop new low-cost
techniques for testing devices with multiple high-speed (2 to 5 Gbps) signals.
Each project uses commercially available components to keep costs low, yet
achieves performance characteristics comparable to (and in some ways exceeding)
more expensive ATE. A common CMOS FPGA-based logic core provides flexibility,
adaptability, and communication with controlling computers while customized
positive emitter-coupled logic (PECL) achieves multi-gigahertz data rates with
about $\pm$25ps timing accuracy.
"
93,"Area-Efficient Selective Multi-Threshold CMOS Design Methodology for
  Standby Leakage Power Reduction","  This paper presents a design flow for an improved selective
multi-threshold(Selective-MT) circuit. The Selective-MT circuit is improved so
that plural MT-cells can share one switch transistor. We propose the design
methodology from RTL(Register Transfer Level) to final layout with optimizing
switch transistor structure.
"
94,"Logic Design for On-Chip Test Clock Generation - Implementation Details
  and Impact on Delay Test Quality","  This paper addresses delay test for SOC devices with high frequency clock
domains. A logic design for on-chip high-speed clock generation, implemented to
avoid expensive test equipment, is described in detail. Techniques for on-chip
clock generation, meant to reduce test vector count and to increase test
quality, are discussed. ATPG results for the proposed techniques are given.
"
95,Hotspot Prevention Through Runtime Reconfiguration in Network-On-Chip,"  Many existing thermal management techniques focus on reducing the overall
power consumption of the chip, and do not address location-specific temperature
problems referred to as hotspots. We propose the use of dynamic runtime
reconfiguration to shift the hotspot-inducing computation periodically and make
the thermal profile more uniform. Our analysis shows that dynamic
reconfiguration is an effective technique in reducing hotspots for NoCs.
"
96,"Power-Performance Trade-Offs in Nanometer-Scale Multi-Level Caches
  Considering Total Leakage","  In this paper, we investigate the impact of T_{ox} and Vth on power
performance trade-offs for on-chip caches. We start by examining the
optimization of the various components of a single level cache and then extend
this to two level cache systems. In addition to leakage, our studies also
account for the dynamic power expanded as a result of cache misses. Our results
show that one can often reduce overall power by increasing the size of the L2
cache if we only allow one pair of Vth/T_{ox} in L2. However, if we allow the
memory cells and the peripherals to have their own Vth's and T_{ox}'s, we show
that a two-level cache system with smaller L2's will yield less total leakage.
We further show that two Vth's and two T_{ox}'s are sufficient to get close to
an optimal solution, and that Vth is generally a better design knob than T_{ox}
for leakage optimization, thus it is better to restrict the number of T_{ox}'s
rather than Vth's if cost is a concern.
"
97,"Test Time Reduction Reusing Multiple Processors in a Network-on-Chip
  Based Architecture","  The increasing complexity and the short life cycles of embedded systems are
pushing the current system-on-chip designs towards a rapid increasing on the
number of programmable processing units, while decreasing the gate count for
custom logic. Considering this trend, this work proposes a test planning method
capable of reusing available processors as test sources and sinks, and the
on-chip network as the test access mechanism. Experimental results are based on
ITC'02 benchmarks and on two open core processors compliant with MIPS and SPARC
instruction set. The results show that the cooperative use of both the on-chip
network and the embedded processors can increase the test parallelism and
reduce the test time without additional cost in area and pins.
"
98,"A Hybrid Prefetch Scheduling Heuristic to Minimize at Run-Time the
  Reconfiguration Overhead of Dynamically Reconfigurable Hardware","  Due to the emergence of highly dynamic multimedia applications there is a
need for flexible platforms and run-time scheduling support for embedded
systems. Dynamic Reconfigurable Hardware (DRHW) is a promising candidate to
provide this flexibility but, currently, not sufficient run-time scheduling
support to deal with the run-time reconfigurations exists. Moreover, executing
at run-time a complex scheduling heuristic to provide this support may generate
an excessive run-time penalty. Hence, we have developed a hybrid
design/run-time prefetch heuristic that schedules the reconfigurations at
run-time, but carries out the scheduling computations at design-time by
carefully identifying a set of near-optimal schedules that can be selected at
run-time. This approach provides run-time flexibility with a negligible
penalty.
"
99,"Behavioural Transformation to Improve Circuit Performance in High-Level
  Synthesis","  Early scheduling algorithms usually adjusted the clock cycle duration to the
execution time of the slowest operation. This resulted in large slack times
wasted in those cycles executing faster operations. To reduce the wasted times
multi-cycle and chaining techniques have been employed. While these techniques
have produced successful designs, its effectiveness is often limited due to the
area increment that may derive from chaining, and the extra latencies that may
derive from multicycling. In this paper we present an optimization method that
solves the time-constrained scheduling problem by transforming behavioural
specifications into new ones whose subsequent synthesis substantially improves
circuit performance. Our proposal breaks up some of the specification
operations, allowing their execution during several possibly unconsecutive
cycles, and also the calculation of several data-dependent operation fragments
in the same cycle. To do so, it takes into account the circuit latency and the
execution time of every specification operation. The experimental results
carried out show that circuits obtained from the optimized specification are on
average 60% faster than those synthesized from the original specification, with
only slight increments in the circuit area.
"
100,"Modeling of a Reconfigurable OFDM IP Block Family For an RF System
  Simulator","  The idea of design domain specific Mother Model of IP block family as a base
of modeling of system integration is presented here. A common reconfigurable
Mother Model for ten different standardized digital OFDM transmitters has been
developed. By means of a set of parameters, the mother model can be
reconfigured to any of the ten selected standards. So far the applicability of
the proposed reconfiguration and analog-digital co-modeling methods have been
proved by modeling the function of the digital parts of three, 802.11a, ADSL
and DRM, transmitters in an RF system simulator. The model is intended to be
used as signal source template in RF system simulations. The concept is not
restricted to signal sources, it can be applied to any IP block development.
The idea of the Mother Model will be applied in other design domains to prove
that in certain application areas, OFDM transceivers in this case, the design
process can progress simultaneously in different design domains - mixed signal,
system and RTL-architectural - without the need of high-level synthesis. Only
the Mother Models of three design domains are needed to be formally proved to
function as specified.
"
101,A VLSI Design Flow for Secure Side-Channel Attack Resistant ICs,"  This paper presents a digital VLSI design flow to create secure, side-channel
attack (SCA) resistant integrated circuits. The design flow starts from a
normal design in a hardware description language such as VHDL or Verilog and
provides a direct path to a SCA resistant layout. Instead of a full custom
layout or an iterative design process with extensive simulations, a few key
modifications are incorporated in a regular synchronous CMOS standard cell
design flow. We discuss the basis for side-channel attack resistance and adjust
the library databases and constraints files of the synthesis and place & route
procedures accordingly. Experimental results show that a DPA attack on a
regular single ended CMOS standard cell implementation of a module of the DES
algorithm discloses the secret key after 200 measurements. The same attack on a
secure version still does not disclose the secret key after more than 2000
measurements.
"
102,"Fast and Accurate Transaction Level Modeling of an Extended AMBA2.0 Bus
  Architecture","  Transaction Level Modeling (TLM) approach is used to meet the simulation
speed as well as cycle accuracy for large scale SoC performance analysis. We
implemented a transaction-level model of a proprietary bus called AHB+ which
supports an extended AMBA2.0 protocol. The AHB+ transaction-level model shows
353 times faster than pin-accurate RTL model while maintaining 97% of accuracy
on average. We also present the development procedure of TLM of a bus
architecture.
"
103,C Based Hardware Design for Wireless Applications,"  The algorithms used in wireless applications are increasingly more
sophisticated and consequently more challenging to implement in hardware.
Traditional design flows require developing the micro architecture, coding the
RTL, and verifying the generated RTL against the original functional C or
MATLAB specification. This paper describes a C-based design flow that is well
suited for the hardware implementation of DSP algorithms commonly found in
wireless applications. The C design flow relies on guided synthesis to generate
the RTL directly from the untimed C algorithm. The specifics of the C-based
design flow are described using a simple DSP filtering algorithm consisting of
a forward adaptive equalizer, a 64-QAM slicer and an adaptive decision feedback
equalizer. The example illustrates some of the capabilities and advantages
offered by this flow.
"
104,"Area and Throughput Trade-Offs in the Design of Pipelined Discrete
  Wavelet Transform Architectures","  The JPEG2000 standard defines the discrete wavelet transform (DWT) as a
linear space-to-frequency transform of the image domain in an irreversible
compression. This irreversible discrete wavelet transform is implemented by FIR
filter using 9/7 Daubechies coefficients or a lifting scheme of factorizated
coefficients from 9/7 Daubechies coefficients. This work investigates the
tradeoffs between area, power and data throughput (or operating frequency) of
several implementations of the Discrete Wavelet Transform using the lifting
scheme in various pipeline designs. This paper shows the results of five
different architectures synthesized and simulated in FPGAs. It concludes that
the descriptions with pipelined operators provide the best area-power-operating
frequency trade-off over non-pipelined operators descriptions. Those
descriptions require around 40% more hardware to increase the maximum operating
frequency up to 100% and reduce power consumption to less than 50%. Starting
from behavioral HDL descriptions provide the best area-power-operating
frequency trade-off, improving hardware cost and maximum operating frequency
around 30% in comparison to structural descriptions for the same power
requirement.
"
105,Queue Management in Network Processors,"  One of the main bottlenecks when designing a network processing system is
very often its memory subsystem. This is mainly due to the state-of-the-art
network links operating at very high speeds and to the fact that in order to
support advanced Quality of Service (QoS), a large number of independent queues
is desirable. In this paper we analyze the performance bottlenecks of various
data memory managers integrated in typical Network Processing Units (NPUs). We
expose the performance limitations of software implementations utilizing the
RISC processing cores typically found in most NPU architectures and we identify
the requirements for hardware assisted memory management in order to achieve
wire-speed operation at gigabit per second rates. Furthermore, we describe the
architecture and performance of a hardware memory manager that fulfills those
requirements. This memory manager, although it is implemented in a
reconfigurable technology, it can provide up to 6.2Gbps of aggregate
throughput, while handling 32K independent queues.
"
106,picoArray Technology: The Tool's Story,"  This paper briefly describes the picoArray? architecture, and in particular
the deterministic internal communication fabric. The methods that have been
developed for debugging and verifying systems using devices from the picoArray
family are explained. In order to maximize the computational ability of these
devices, hardware debugging support has been kept to a minimum and the methods
and tools developed to take this into account.
"
107,"ISEGEN: Generation of High-Quality Instruction Set Extensions by
  Iterative Improvement","  Customization of processor architectures through Instruction Set Extensions
(ISEs) is an effective way to meet the growing performance demands of embedded
applications. A high-quality ISE generation approach needs to obtain results
close to those achieved by experienced designers, particularly for complex
applications that exhibit regularity: expert designers are able to exploit
manually such regularity in the data flow graphs to generate high-quality ISEs.
In this paper, we present ISEGEN, an approach that identifies high-quality ISEs
by iterative improvement following the basic principles of the well-known
Kernighan-Lin (K-L) min-cut heuristic. Experimental results on a number of
MediaBench, EEMBC and cryptographic applications show that our approach matches
the quality of the optimal solution obtained by exhaustive search. We also show
that our ISEGEN technique is on average 20x faster than a genetic formulation
that generates equivalent solutions. Furthermore, the ISEs identified by our
technique exhibit 35% more speedup than the genetic solution on a large
cryptographic application (AES) by effectively exploiting its regular
structure.
"
108,FPGA based Agile Algorithm-On-Demand Co-Processor,"  With growing computational needs of many real-world applications, frequently
changing specifications of standards, and the high design and NRE costs of
ASICs, an algorithm-agile FPGA based co-processor has become a viable
alternative. In this article, we report about the general design of an
algorith-agile co-processor and the proof-of-concept implementation.
"
109,Meeting the Embedded Design Needs of Automotive Applications,"  The importance of embedded systems in driving innovation in automotive
applications continues to grow. Understanding the specific needs of developers
targeting this market is also helping to drive innovation in RISC core design.
This paper describes how a RISC instruction set architecture has evolved to
better meet those needs, and the key implementation features in two very
different RISC cores are used to demonstrate the challenges of designing for
real-time automotive systems.
"
110,"The Integration of On-Line Monitoring and Reconfiguration Functions
  using EDAA - European design and Automation Association1149.4 Into a Safety
  Critical Automotive Electronic Control Unit","  This paper presents an innovative application of EDAA - European design and
Automation Association 1149.4 and the Integrated Diagnostic Reconfiguration
(IDR) as tools for the implementation of an embedded test solution for an
Automotive Electronic Control Unit implemented as a fully integrated mixed
signal system. The paper described how the test architecture can be used for
fault avoidance with results from a hardware prototype presented. The paper
concludes that fault avoidance can be integrated into mixed signal electronic
systems to handle key failure modes.
"
111,"Debug Support, Calibration and Emulation for Multiple Processor and
  Powertrain Control SoCs","  The introduction of complex SoCs with multiple processor cores presents new
development challenges, such that development support is now a decisive factor
when choosing a System-on-Chip (SoC). The presented developments support
strategy addresses the challenges using both architecture and technology
approaches. The Multi-Core Debug Support (MCDS) architecture provides flexible
triggering using cross triggers and a multiple core break and suspend switch.
Temporal trace ordering is guaranteed down to cycle level by on-chip time
stamping. The Package Sized-ICE (PSI) approach is a novel method of including
trace buffers, overlay memories, processing resources and communication
interfaces without changing device behavior. PSI requires no external emulation
box, as the debug host interfaces directly with the SoC using a standard
interface.
"
112,SystemC Analysis of a New Dynamic Power Management Architecture,"  This paper presents a new dynamic power management architecture of a System
on Chip. The Power State Machine describing the status of the core follows the
recommendations of the ACPI standard. The algorithm controls the power states
of each block on the basis of battery status, chip temperature and a user
defined task priority.
"
113,"Exploiting Real-Time FPGA Based Adaptive Systems Technology for
  Real-Time Sensor Fusion in Next Generation Automotive Safety Systems","  We present a system for the boresighting of sensors using inertial
measurement devices as the basis for developing a range of dynamic real-time
sensor fusion applications. The proof of concept utilizes a COTS FPGA platform
for sensor fusion and real-time correction of a misaligned video sensor. We
exploit a custom-designed 32-bit soft processor core and C-based design &
synthesis for rapid, platform-neutral development. Kalman filter and sensor
fusion techniques established in advanced aviation systems are applied to
automotive vehicles with results exceeding typical industry requirements for
sensor alignment. Results of the static and the dynamic tests demonstrate that
using inexpensive accelerometers mounted on (or during assembly of) a sensor
and an Inertial Measurement Unit (IMU) fixed to a vehicle can be used to
compute the misalignment of the sensor to the IMU and thus vehicle. In some
cases the model predications and test results exceeded the requirements by an
order of magnitude with a 3-sigma or 99% confidence.
"
114,Platform Based Design for Automotive Sensor Conditioning,"  In this paper a general architecture suitable to interface several kinds of
sensors for automotive applications is presented. A platform based design
approach is pursued to improve system performance while minimizing
time-to-market.. The platform is composed by an analog front-end and a digital
section. The latter is based on a microcontroller core (8051 IP by Oregano)
plus a set of dedicated hardware dedicated to the complex signal processing
required for sensor conditioning. The microcontroller handles also the
communication with external devices (as a PC) for data output and fast
prototyping. A case study is presented concerning the conditioning of a Gyro
yaw rate sensor for automotive applications. Measured performance results
outperform current state-of-the-art commercial devices.
"
115,"A 6bit, 1.2GSps Low-Power Flash-ADC in 0.13$\mu$m Digital CMOS","  A 6bit flash-ADC with 1.2GSps, wide analog bandwidth and low power, realized
in a standard digital 0.13 $\mu$m CMOS copper technology is presented.
Employing capacitive interpolation gives various advantages when designing for
low power: no need for a reference resistor ladder, implicit sample-and-hold
operation, no edge effects in the interpolation network (as compared to
resistive interpolation), and a very low input capacitance of only 400fF, which
leads to an easily drivable analog converter interface. Operating at 1.2GSps
the ADC achieves an effective resolution bandwidth (ERBW) of 700MHz, while
consuming 160mW of power. At 600MSps we achieve an ERBW of 600MHz with only
90mW power consumption, both from a 1.5V supply. This corresponds to
outstanding Figure-of-Merit numbers (FoM) of 2.2 and 1.5pJ/convstep,
respectively. The module area is 0.12mm^2.
"
116,A 97mW 110MS/s 12b Pipeline ADC Implemented in 0.18$\mu$m Digital CMOS,"  A 12 bit Pipeline ADC fabricated in a 0.18 $\mu$m pure digital CMOS
technology is presented. Its nominal conversion rate is 110MS/s and the nominal
supply voltage is 1.8V. The effective number of bits is 10.4 when a 10MHz input
signal with 2V_{P-P} signal swing is applied. The occupied silicon area is
0.86mm^2 and the power consumption equals 97mW. A switched capacitor bias
current circuit scale the bias current automatically with the conversion rate,
which gives scaleable power consumption and full performance of the ADC from 20
to 140MS/s.
"
117,"Testing Logic Cores using a BIST P1500 Compliant Approach: A Case of
  Study","  In this paper we describe how we applied a BIST-based approach to the test of
a logic core to be included in System-on-a-chip (SoC) environments. The
approach advantages are the ability to protect the core IP, the simple test
interface (thanks also to the adoption of the P1500 standard), the possibility
to run the test at-speed, the reduced test time, and the good diagnostic
capabilities. The paper reports figures about the achieved fault coverage, the
required area overhead, and the performance slowdown, and compares the figures
with those for alternative approaches, such as those based on full scan and
sequential ATPG.
"
118,"Using Mobilize Power Management IP for Dynamic & Static Power Reduction
  in SoC at 130 nm","  At 130 nm and 90 nm, power consumption (both dynamic and static) has become a
barrier in the roadmap for SoC designs targeting battery powered, mobile
applications. This paper presents the results of dynamic and static power
reduction achieved implementing Tensilica's 32-bit Xtensa microprocessor core,
using Virtual Silicon's Power Management IP. Independent voltage islands are
created using Virtual Silicon's VIP PowerSaver standard cells by using voltage
level shifting cells and voltage isolation cells to implement power islands.
The VIP PowerSaver standard cells are characterized at 1.2V, 1.0V and 0.8V, to
accommodate voltage scaling. Power islands can also be turned off completely.
Designers can significantly lower both the dynamic power and the quiescent or
leakage power of their SoC designs, with very little impact on speed or area
using Virtual Silicon's VIP Gate Bias standard cells.
"
119,MultiNoC: A Multiprocessing System Enabled by a Network on Chip,"  The MultiNoC system implements a programmable on-chip multiprocessing
platform built on top of an efficient, low area overhead intra-chip
interconnection scheme. The employed interconnection structure is a Network on
Chip, or NoC. NoCs are emerging as a viable alternative to increasing demands
on interconnection architectures, due to the following characteristics: (i)
energy efficiency and reliability; (ii) scalability of bandwidth, when compared
to traditional bus architectures; (iii) reusability; (iv) distributed routing
decisions. An external host computer feeds MultiNoC with application
instructions and data. After this initialization procedure, MultiNoC executes
some algorithm. After finishing execution of the algorithm, output data can be
read back by the host. Sequential or parallel algorithms conveniently adapted
to the MultiNoC structure can be executed. The main motivation to propose this
design is to enable the investigation of current trends to increase the number
of embedded processors in SoCs, leading to the concept of ""sea of processors""
systems.
"
120,"A Partitioning Methodology for Accelerating Applications in Hybrid
  Reconfigurable Platforms","  In this paper, we propose a methodology for partitioning and mapping
computational intensive applications in reconfigurable hardware blocks of
different granularity. A generic hybrid reconfigurable architecture is
considered so as the methodology can be applicable to a large number of
heterogeneous reconfigurable platforms. The methodology mainly consists of two
stages, the analysis and the mapping of the application onto fine and
coarse-grain hardware resources. A prototype framework consisting of analysis,
partitioning and mapping tools has been also developed. For the coarse-grain
reconfigurable hardware, we use our previous-developed high-performance
coarse-grain data-path. In this work, the methodology is validated using two
real-world applications, an OFDM transmitter and a JPEG encoder. In the case of
the OFDM transmitter, a maximum clock cycles decrease of 82% relative to the
ones in an all fine-grain mapping solution is achieved. The corresponding
performance improvement for the JPEG is 43%.
"
121,Evaluation of SystemC Modelling of Reconfigurable Embedded Systems,"  This paper evaluates the use of pin and cycle accurate SystemC models for
embedded system design exploration and early software development. The target
system is MicroBlaze VanillaNet Platform running MicroBlaze uClinux operating
system. The paper compares Register Transfer Level (RTL) Hardware Description
Language (HDL) simulation speed to the simulation speed of several different
SystemC models. It is shown that simulation speed of pin and cycle accurate
models can go up to 150 kHz, compared to 100 Hz range of HDL simulation.
Furthermore, utilising techniques that temporarily compromise cycle accuracy,
effective simulation speed of up to 500 kHz can be obtained.
"
122,"Hardware Support for QoS-based Function Allocation in Reconfigurable
  Systems","  This contribution presents a new approach for allocating suitable
function-implementation variants depending on given quality-of-service
function-requirements for run-time reconfigurable multi-device systems. Our
approach adapts methodologies from the domain of knowledge-based systems which
can be used for doing run-time hardware/software resource usage optimizations.
"
123,On the operating unit size of load/store architectures,"  We introduce a strict version of the concept of a load/store instruction set
architecture in the setting of Maurer machines. We take the view that
transformations on the states of a Maurer machine are achieved by applying
threads as considered in thread algebra to the Maurer machine. We study how the
transformations on the states of the main memory of a strict load/store
instruction set architecture that can be achieved by applying threads depend on
the operating unit size, the cardinality of the instruction set, and the
maximal number of states of the threads.
"
124,Decoding the Golden Code: a VLSI design,"  The recently proposed Golden code is an optimal space-time block code for 2 X
2 multiple-input multiple-output (MIMO) systems. The aim of this work is the
design of a VLSI decoder for a MIMO system coded with the Golden code. The
architecture is based on a rearrangement of the sphere decoding algorithm that
achieves maximum-likelihood (ML) decoding performance. Compared to other
approaces, the proposed solution exhibits an inherent flexibility in terms of
modulation schemes QAM modulation size and this makes our architecture
particularly suitable for adaptive modulation schemes.
"
125,"Combined Integer and Variable Precision (CIVP) Floating Point
  Multiplication Architecture for FPGAs","  In this paper, we propose an architecture/methodology for making FPGAs
suitable for integer as well as variable precision floating point
multiplication. The proposed work will of great importance in applications
which requires variable precision floating point multiplication such as
multi-media processing applications. In the proposed architecture/methodology,
we propose the replacement of existing 18x18 bit and 25x18 bit dedicated
multipliers in FPGAs with dedicated 24x24 bit and 24x9 bit multipliers,
respectively. We have proved that our approach of providing the dedicated 24x24
bit and 24x9 bit multipliers in FPGAs will make them efficient for performing
integer as well as single precision, double precision, and Quadruple precision
floating point multiplications.
"
126,Partial Reversible Gates(PRG) for Reversible BCD Arithmetic,"  IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and
a major enhancement to the standard is the addition of decimal format.
Furthermore, in the recent years reversible logic has emerged as a promising
computing paradigm having its applications in low power CMOS, quantum
computing, nanotechnology, and optical computing. The major goal in reversible
logic is to minimize the number of reversible gates and garbage outputs. Thus,
this paper proposes the novel concept of partial reversible gates that will
satisfy the reversibility criteria for specific cases in BCD arithmetic. The
partial reversible gate is proposed to minimize the number of reversible gates
and garbage outputs, while designing the reversible BCD arithmetic circuits.
"
127,"Transactional WaveCache: Towards Speculative and Out-of-Order DataFlow
  Execution of Memory Operations","  The WaveScalar is the first DataFlow Architecture that can efficiently
provide the sequential memory semantics required by imperative languages. This
work presents an alternative memory ordering mechanism for this architecture,
the Transaction WaveCache. Our mechanism maintains the execution order of
memory operations within blocks of code, called Waves, but adds the ability to
speculatively execute, out-of-order, operations from different waves. This
ordering mechanism is inspired by progress in supporting Transactional
Memories. Waves are considered as atomic regions and executed as nested
transactions. If a wave has finished the execution of all its memory
operations, as soon as the previous waves are committed, it can be committed.
If a hazard is detected in a speculative Wave, all the following Waves
(children) are aborted and re-executed. We evaluate the WaveCache on a set
artificial benchmarks. If the benchmark does not access memory often, we could
achieve speedups of around 90%. Speedups of 33.1% and 24% were observed on more
memory intensive applications, and slowdowns up to 16% arise if memory
bandwidth is a bottleneck. For an application full of WAW, WAR and RAW hazards,
a speedup of 139.7% was verified.
"
128,Optimal Memoryless Encoding for Low Power Off-Chip Data Buses,"  Off-chip buses account for a significant portion of the total system power
consumed in embedded systems. Bus encoding schemes have been proposed to
minimize power dissipation, but none has been demonstrated to be optimal with
respect to any measure. In this paper, we give the first provably optimal and
explicit (polynomial-time constructible) families of memoryless codes for
minimizing bit transitions in off-chip buses. Our results imply that having
access to a clock does not make a memoryless encoding scheme that minimizes bit
transitions more powerful.
"
129,Policies of System Level Pipeline Modeling,"  Pipelining is a well understood and often used implementation technique for
increasing the performance of a hardware system. We develop several SystemC/C++
modeling techniques that allow us to quickly model, simulate, and evaluate
pipelines. We employ a small domain specific language (DSL) based on resource
usage patterns that automates the drudgery of boilerplate code needed to
configure connectivity in simulation models. The DSL is embedded directly in
the host modeling language SystemC/C++. Additionally we develop several
techniques for parameterizing a pipeline's behavior based on policies of
function, communication, and timing (performance modeling).
"
130,"Efficient implementation of GALS systems over commercial synchronous
  FPGAs: a new approach","  The new vision presented is aimed to overcome the logic overhead issues that
previous works exhibit when applying GALS techniques to programmable logic
devices. The proposed new view relies in a 2-phase, bundled data parity based
protocol for data transfer and clock generation tasks. The ability of the
introduced methodology for smart real-time delay selection allows the
implementation of a variety of new methodologies for electromagnetic
interference mitigation and device environment changes adaptation.
"
131,Assessing Random Dynamical Network Architectures for Nanoelectronics,"  Independent of the technology, it is generally expected that future nanoscale
devices will be built from vast numbers of densely arranged devices that
exhibit high failure rates. Other than that, there is little consensus on what
type of technology and computing architecture holds most promises to go far
beyond today's top-down engineered silicon devices. Cellular automata (CA) have
been proposed in the past as a possible class of architectures to the von
Neumann computing architecture, which is not generally well suited for future
parallel and fine-grained nanoscale electronics. While the top-down engineered
semi-conducting technology favors regular and locally interconnected
structures, future bottom-up self-assembled devices tend to have irregular
structures because of the current lack precise control over these processes. In
this paper, we will assess random dynamical networks, namely Random Boolean
Networks (RBNs) and Random Threshold Networks (RTNs), as alternative computing
architectures and models for future information processing devices. We will
illustrate that--from a theoretical perspective--they offer superior properties
over classical CA-based architectures, such as inherent robustness as the
system scales up, more efficient information processing capabilities, and
manufacturing benefits for bottom-up designed devices, which motivates this
investigation. We will present recent results on the dynamic behavior and
robustness of such random dynamical networks while also including manufacturing
issues in the assessment.
"
132,"Archer: A Community Distributed Computing Infrastructure for Computer
  Architecture Research and Education","  This paper introduces Archer, a community-based computing resource for
computer architecture research and education. The Archer infrastructure
integrates virtualization and batch scheduling middleware to deliver
high-throughput computing resources aggregated from resources distributed
across wide-area networks and owned by different participating entities in a
seamless manner. The paper discusses the motivations leading to the design of
Archer, describes its core middleware components, and presents an analysis of
the functionality and performance of a prototype wide-area deployment running a
representative computer architecture simulation workload.
"
133,"An adaptive embedded architecture for real-time Particle Image
  Velocimetry algorithms","  Particle Image Velocimetry (PIV) is a method of im-aging and analysing fields
of flows. The PIV tech-niques compute and display all the motion vectors of the
field in a resulting image. Speeds more than thou-sand vectors per second can
be required, each speed being environment-dependent. Essence of this work is to
propose an adaptive FPGA-based system for real-time PIV algorithms. The
proposed structure is ge-neric so that this unique structure can be re-used for
any PIV applications that uses the cross-correlation technique. The major
structure remains unchanged, adaptations only concern the number of processing
operations. The required speed (corresponding to the number of vector per
second) is obtained thanks to a parallel processing strategy. The image
processing designer duplicates the processing modules to distrib-ute the
operations. The result is a FPGA-based archi-tecture, which is easily adapted
to algorithm specifica-tions without any hardware requirement. The design flow
is fast and reliable.
"
134,On Transformations of Load-Store Maurer Instruction Set Architecture,"  In this paper, we study how certain conditions can affect the transformations
on the states of the memory of a strict load-store Maurer ISA, when half of the
data memory serves as the part of the operating unit.
"
135,Easily testable logical networks based on a 'widened long flip-flop',"  The article describes an attempt to solve at once three basic problems
arising at testing a complex digital equipment for defects: 1) the problem of
an exponential increasing of the complexity of testing the equipment with the
complexity of the equipment; 2) the problem of testing of the tester; 3) the
problem of a mutual masking of defects. The proposed solution is nothing more
than using certain limitations for connections between usual logical gates.
Arbitrary multiple stuck-at-faults are supposed as defects.
"
136,"On the Effect of Quantum Interaction Distance on Quantum Addition
  Circuits","  We investigate the theoretical limits of the effect of the quantum
interaction distance on the speed of exact quantum addition circuits. For this
study, we exploit graph embedding for quantum circuit analysis. We study a
logical mapping of qubits and gates of any $\Omega(\log n)$-depth quantum adder
circuit for two $n$-qubit registers onto a practical architecture, which limits
interaction distance to the nearest neighbors only and supports only one- and
two-qubit logical gates. Unfortunately, on the chosen $k$-dimensional practical
architecture, we prove that the depth lower bound of any exact quantum addition
circuits is no longer $\Omega(\log {n})$, but $\Omega(\sqrt[k]{n})$. This
result, the first application of graph embedding to quantum circuits and
devices, provides a new tool for compiler development, emphasizes the impact of
quantum computer architecture on performance, and acts as a cautionary note
when evaluating the time performance of quantum algorithms.
"
137,Interval Semantics for Standard Floating-Point Arithmetic,"  If the non-zero finite floating-point numbers are interpreted as point
intervals, then the effect of rounding can be interpreted as computing one of
the bounds of the result according to interval arithmetic. We give an interval
interpretation for the signed zeros and infinities, so that the undefined
operations 0*inf, inf - inf, inf/inf, and 0/0 become defined.
  In this way no operation remains that gives rise to an error condition.
Mathematically questionable features of the floating-point standard become
well-defined sets of reals. Interval semantics provides a basis for the
verification of numerical algorithms. We derive the results of the newly
defined operations and consider the implications for hardware implementation.
"
138,"NB-FEB: An Easy-to-Use and Scalable Universal Synchronization Primitive
  for Parallel Programming","  This paper addresses the problem of universal synchronization primitives that
can support scalable thread synchronization for large-scale many-core
architectures. The universal synchronization primitives that have been deployed
widely in conventional architectures like CAS and LL/SC are expected to reach
their scalability limits in the evolution to many-core architectures with
thousands of cores. We introduce a non-blocking full/empty bit primitive, or
NB-FEB for short, as a promising synchronization primitive for parallel
programming on may-core architectures. We show that the NB-FEB primitive is
universal, scalable, feasible and convenient to use. NB-FEB, together with
registers, can solve the consensus problem for an arbitrary number of processes
(universality). NB-FEB is combinable, namely its memory requests to the same
memory location can be combined into only one memory request, which
consequently mitigates performance degradation due to synchronization ""hot
spots"" (scalability). Since NB-FEB is a variant of the original full/empty bit
that always returns a value instead of waiting for a conditional flag, it is as
feasible as the original full/empty bit, which has been implemented in many
computer systems (feasibility). The original full/empty bit is well-known as a
special-purpose primitive for fast producer-consumer synchronization and has
been used extensively in the specific domain of applications. In this paper, we
show that NB-FEB can be deployed easily as a general-purpose primitive. Using
NB-FEB, we construct a non-blocking software transactional memory system called
NBFEB-STM, which can be used to handle concurrent threads conveniently.
NBFEB-STM is space efficient: the space complexity of each object updated by
$N$ concurrent threads/transactions is $\Theta(N)$, the optimal.
"
139,Decting Errors in Reversible Circuits With Invariant Relationships,"  Reversible logic is experience renewed interest as we are approach the limits
of CMOS technologies. While physical implementations of reversible gates have
yet to materialize, it is safe to assume that they will rely on faulty
individual components. In this work we present a present a method to provide
fault tolerance to a reversible circuit based on invariant relationships.
"
140,A High Dynamic Range 3-Moduli-Set with Efficient Reverse Converter,"  -Residue Number System (RNS) is a valuable tool for fast and parallel
arithmetic. It has a wide application in digital signal processing, fault
tolerant systems, etc. In this work, we introduce the 3-moduli set {2^n,
2^{2n}-1, 2^{2n}+1} and propose its residue to binary converter using the
Chinese Remainder Theorem. We present its simple hardware implementation that
mainly includes one Carry Save Adder (CSA) and a Modular Adder (MA). We compare
the performance and area utilization of our reverse converter to the reverse
converters of the moduli sets {2^n-1, 2^n, 2^n+1, 2^{2n}+1} and {2^n-1, 2^n,
2^n+1, 2^n-2^{(n+1)/2}+1, 2^n+2^{(n+1)/2}+1} that have the same dynamic range
and we demonstrate that our architecture is better in terms of performance and
area utilization. Also, we show that our reverse converter is faster than the
reverse converter of {2^n-1, 2^n, 2^n+1} for dynamic ranges like 8-bit, 16-bit,
32-bit and 64-bit however it requires more area.
"
141,Adaptive FPGA NoC-based Architecture for Multispectral Image Correlation,"  An adaptive FPGA architecture based on the NoC (Network-on-Chip) approach is
used for the multispectral image correlation. This architecture must contain
several distance algorithms depending on the characteristics of spectral images
and the precision of the authentication. The analysis of distance algorithms is
required which bases on the algorithmic complexity, result precision, execution
time and the adaptability of the implementation. This paper presents the
comparison of these distance computation algorithms on one spectral database.
The result of a RGB algorithm implementation was discussed.
"
142,Limit on the Addressability of Fault-Tolerant Nanowire Decoders,"  Although prone to fabrication error, the nanowire crossbar is a promising
candidate component for next generation nanometer-scale circuits. In the
nanowire crossbar architecture, nanowires are addressed by controlling voltages
on the mesowires. For area efficiency, we are interested in the maximum number
of nanowires $N(m,e)$ that can be addressed by $m$ mesowires, in the face of up
to $e$ fabrication errors. Asymptotically tight bounds on $N(m,e)$ are
established in this paper. In particular, it is shown that $N(m,e) = \Theta(2^m
/ m^{e+1/2})$. Interesting observations are made on the equivalence between
this problem and the problem of constructing optimal EC/AUED codes,
superimposed distance codes, pooling designs, and diffbounded set systems.
Results in this paper also improve upon those in the EC/AUEC codes literature.
"
143,Optimal cache-aware suffix selection,"  Given string $S[1..N]$ and integer $k$, the {\em suffix selection} problem is
to determine the $k$th lexicographically smallest amongst the suffixes $S[i...
N]$, $1 \leq i \leq N$. We study the suffix selection problem in the
cache-aware model that captures two-level memory inherent in computing systems,
for a \emph{cache} of limited size $M$ and block size $B$. The complexity of
interest is the number of block transfers. We present an optimal suffix
selection algorithm in the cache-aware model, requiring $\Thetah{N/B}$ block
transfers, for any string $S$ over an unbounded alphabet (where characters can
only be compared), under the common tall-cache assumption (i.e.
$M=\Omegah{B^{1+\epsilon}}$, where $\epsilon<1$). Our algorithm beats the
bottleneck bound for permuting an input array to the desired output array,
which holds for nearly any nontrivial problem in hierarchical memory models.
"
144,Circuit Design for A Measurement-Based Quantum Carry-Lookahead Adder,"  We present the design and evaluation of a quantum carry-lookahead adder
(QCLA) using measurement-based quantum computation (MBQC), called MBQCLA. QCLA
was originally designed for an abstract, concurrent architecture supporting
long-distance communication, but most realistic architectures heavily constrain
communication distances. The quantum carry-lookahead adder is faster than a
quantum ripple-carry adder; QCLA has logarithmic depth while ripple adders have
linear depth. MBQCLA utilizes MBQC's ability to transfer quantum states in unit
time to accelerate addition. MBQCLA breaks the latency limit of addition
circuits in nearest neighbor-only architectures : compared to the $\Theta(n)$
limit on circuit depth for linear nearest-neighbor architectures, it can reach
$\Theta(log n)$ depth. MBQCLA is an order of magnitude faster than a
ripple-carry adder when adding registers longer than 100 qubits, but requires a
cluster state that is an order of magnitude larger. The cluster state resources
can be classified as computation and communication; for the unoptimized form,
$\approx$ 88 % of the resources are used for communication. Hand optimization
of horizontal communication costs results in a $\approx$ 12% reduction in
spatial resources for the in-place MBQCLA circuit. For comparison, a graph
state quantum carry-lookahead adder (GSQCLA) uses only $\approx$ 9 % of the
spatial resources of the MBQCLA.
"
145,CRT-Based High Speed Parallel Architecture for Long BCH Encoding,"  BCH (Bose-Chaudhuri-Hocquenghen) error correcting codes ([1]-[2]) are now
widely used in communication systems and digital technology. Direct LFSR(linear
feedback shifted register)-based encoding of a long BCH code suffers from
serial-in and serial-out limitation and large fanout effect of some XOR gates.
This makes the LFSR-based encoders of long BCH codes cannot keep up with the
data transmission speed in some applications. Several parallel long parallel
encoders for long cyclic codes have been proposed in [3]-[8]. The technique for
eliminating the large fanout effect by J-unfolding method and some algebraic
manipulation was presented in [7] and [8] . In this paper we propose a
CRT(Chinese Remainder Theorem)-based parallel architecture for long BCH
encoding. Our novel technique can be used to eliminate the fanout bottleneck.
The only restriction on the speed of long BCH encoding of our CRT-based
architecture is $log_2N$, where $N$ is the length of the BCH code.
"
146,Feasibility Conditions for Interference Alignment,"  The degrees of freedom of MIMO interference networks with constant channel
coefficients are not known in general. Determining the feasibility of a linear
interference alignment solution is a key step toward solving this open problem.
Our approach in this paper is to view the alignment problem as a system of
bilinear equations and determine its solvability by comparing the number of
equations and the number of variables. To this end, we divide interference
alignment problems into two classes - proper and improper. An interference
alignment problem is called proper if the number of equations does not exceed
the number of variables. Otherwise, it is called improper. Examples are
presented to support the intuition that for generic channel matrices, proper
systems are almost surely feasible and improper systems are almost surely
infeasible.
"
147,Introducing a Performance Model for Bandwidth-Limited Loop Kernels,"  We present a performance model for bandwidth limited loop kernels which is
founded on the analysis of modern cache based microarchitectures. This model
allows an accurate performance prediction and evaluation for existing
instruction codes. It provides an in-depth understanding of how performance for
different memory hierarchy levels is made up. The performance of raw memory
load, store and copy operations and a stream vector triad are analyzed and
benchmarked on three modern x86-type quad-core architectures in order to
demonstrate the capabilities of the model.
"
148,Hardware Trojan by Hot Carrier Injection,"  This paper discusses how hot carrier injection (HCI) can be exploited to
create a trojan that will cause hardware failures. The trojan is produced not
via additional logic circuitry but by controlled scenarios that maximize and
accelerate the HCI effect in transistors. These scenarios range from
manipulating the manufacturing process to varying the internal voltage
distribution. This new type of trojan is difficult to test due to its gradual
hardware degradation mechanism. This paper describes the HCI effect, detection
techniques and discusses the possibility for maliciously induced HCI trojans.
"
149,Exploiting Semiconductor Properties for Hardware Trojans,"  This paper discusses the possible introduction of hidden reliability defects
during CMOS foundry fabrication processes that may lead to accelerated wearout
of the devices. These hidden defects or hardware Trojans can be created by
deviation from foundry design rules and processing parameters. The Trojans are
produced by exploiting time-based wearing mechanisms (HCI, NBTI, TDDB and EM)
and/or condition-based triggers (ESD, Latchup and Softerror). This class of
latent damage is difficult to test due to its gradual degradation nature. The
paper describes life-time expectancy results for various Trojan induced
scenarios. Semiconductor properties, processing and design parameters critical
for device reliability and Trojan creation are discussed.
"
150,"Function Interface Models for Hardware Compilation: Types, Signatures,
  Protocols","  The problem of synthesis of gate-level descriptions of digital circuits from
behavioural specifications written in higher-level programming languages
(hardware compilation) has been studied for a long time yet a definitive
solution has not been forthcoming. The argument of this essay is mainly
methodological, bringing a perspective that is informed by recent developments
in programming-language theory. We argue that one of the major obstacles in the
way of hardware compilation becoming a useful and mature technology is the lack
of a well defined function interface model, i.e. a canonical way in which
functions communicate with arguments. We discuss the consequences of this
problem and propose a solution based on new developments in programming
language theory. We conclude by presenting a prototype implementation and some
examples illustrating our principles.
"
151,FPGA-based Controller for a Mobile Robot,"  With application in the robotics and automation, more and more it becomes
necessary the development of applications based on methodologies that
facilitate future modifications, updates and enhancements in the original
projected system. This project presents a conception of mobile robots using
rapid prototyping, distributing the several control actions in growing levels
of complexity and computing proposal oriented to embed systems implementation.
This kind of controller can be tested on different platform representing the
mobile robots using reprogrammable logic components (FPGA). This mobile robot
will detect obstacle and also be able to control the speed. Different modules
will be Actuators, Sensors, wireless transmission. All this modules will be
interfaced using FPGA controller. I would like to construct a mechanically
simple robot model, which can measure the distance from obstacle with the aid
of sensor and accordingly should able to control the speed of motor. I would
like to construct a mechanically simple robot model, which can measure the
distance from obstacle with the aid of sensor and accordingly should able to
control the speed of motor.
"
152,"Hardware Virtualization Support In INTEL, AMD And IBM Power Processors","  At present, the mostly used and developed mechanism is hardware
virtualization which provides a common platform to run multiple operating
systems and applications in independent partitions. More precisely, it is all
about resource virtualization as the term hardware virtualization is
emphasized. In this paper, the aim is to find out the advantages and
limitations of current virtualization techniques, analyze their cost and
performance and also depict which forthcoming hardware virtualization
techniques will able to provide efficient solutions for multiprocessor
operating systems. This is done by making a methodical literature survey and
statistical analysis of the benchmark reports provided by SPEC (Standard
Performance Evaluation Corporation) and TPC (Transaction processing Performance
Council). Finally, this paper presents the current aspects of hardware
virtualization which will help the IT managers of the large organizations to
take effective decision while choosing server with virtualization support.
Again, the future works described in section 4 of this paper focuses on some
real world challenges such as abstraction of multiple servers, language level
virtualization, pre-virtualization etc. which may be point of great interest
for the researchers.
"
153,Boosting XML Filtering with a Scalable FPGA-based Architecture,"  The growing amount of XML encoded data exchanged over the Internet increases
the importance of XML based publish-subscribe (pub-sub) and content based
routing systems. The input in such systems typically consists of a stream of
XML documents and a set of user subscriptions expressed as XML queries. The
pub-sub system then filters the published documents and passes them to the
subscribers. Pub-sub systems are characterized by very high input ratios,
therefore the processing time is critical. In this paper we propose a ""pure
hardware"" based solution, which utilizes XPath query blocks on FPGA to solve
the filtering problem. By utilizing the high throughput that an FPGA provides
for parallel processing, our approach achieves drastically better throughput
than the existing software or mixed (hardware/software) architectures. The
XPath queries (subscriptions) are translated to regular expressions which are
then mapped to FPGA devices. By introducing stacks within the FPGA we are able
to express and process a wide range of path queries very efficiently, on a
scalable environment. Moreover, the fact that the parser and the filter
processing are performed on the same FPGA chip, eliminates expensive
communication costs (that a multi-core system would need) thus enabling very
fast and efficient pipelining. Our experimental evaluation reveals more than
one order of magnitude improvement compared to traditional pub/sub systems.
"
154,"Turbo NOC: a framework for the design of Network On Chip based turbo
  decoder architectures","  This work proposes a general framework for the design and simulation of
network on chip based turbo decoder architectures. Several parameters in the
design space are investigated, namely the network topology, the parallelism
degree, the rate at which messages are sent by processing nodes over the
network and the routing strategy. The main results of this analysis are: i) the
most suited topologies to achieve high throughput with a limited complexity
overhead are generalized de-Bruijn and generalized Kautz topologies; ii)
depending on the throughput requirements different parallelism degrees, message
injection rates and routing algorithms can be used to minimize the network area
overhead.
"
155,"Hard Data on Soft Errors: A Large-Scale Assessment of Real-World Error
  Rates in GPGPU","  Graphics processing units (GPUs) are gaining widespread use in computational
chemistry and other scientific simulation contexts because of their huge
performance advantages relative to conventional CPUs. However, the reliability
of GPUs in error-intolerant applications is largely unproven. In particular, a
lack of error checking and correcting (ECC) capability in the memory subsystems
of graphics cards has been cited as a hindrance to the acceptance of GPUs as
high-performance coprocessors, but the impact of this design has not been
previously quantified.
  In this article we present MemtestG80, our software for assessing memory
error rates on NVIDIA G80 and GT200-architecture-based graphics cards.
Furthermore, we present the results of a large-scale assessment of GPU error
rate, conducted by running MemtestG80 on over 20,000 hosts on the Folding@home
distributed computing network. Our control experiments on consumer-grade and
dedicated-GPGPU hardware in a controlled environment found no errors. However,
our survey over cards on Folding@home finds that, in their installed
environments, two-thirds of tested GPUs exhibit a detectable, pattern-sensitive
rate of memory soft errors. We demonstrate that these errors persist after
controlling for overclocking and environmental proxies for temperature, but
depend strongly on board architecture.
"
156,"A Scalable VLSI Architecture for Soft-Input Soft-Output Depth-First
  Sphere Decoding","  Multiple-input multiple-output (MIMO) wireless transmission imposes huge
challenges on the design of efficient hardware architectures for iterative
receivers. A major challenge is soft-input soft-output (SISO) MIMO demapping,
often approached by sphere decoding (SD). In this paper, we introduce the - to
our best knowledge - first VLSI architecture for SISO SD applying a single
tree-search approach. Compared with a soft-output-only base architecture
similar to the one proposed by Studer et al. in IEEE J-SAC 2008, the
architectural modifications for soft input still allow a one-node-per-cycle
execution. For a 4x4 16-QAM system, the area increases by 57% and the operating
frequency degrades by 34% only.
"
157,"A Fault-tolerant Structure for Reliable Multi-core Systems Based on
  Hardware-Software Co-design","  To cope with the soft errors and make full use of the multi-core system, this
paper gives an efficient fault-tolerant hardware and software co-designed
architecture for multi-core systems. And with a not large number of test
patterns, it will use less than 33% hardware resources compared with the
traditional hardware redundancy (TMR) and it will take less than 50% time
compared with the traditional software redundancy (time redundant).Therefore,
it will be a good choice for the fault-tolerant architecture for the future
high-reliable multi-core systems.
"
158,Virtual-Threading: Advanced General Purpose Processors Architecture,"  The paper describes the new computers architecture, the main features of
which has been claimed in the Russian Federation patent 2312388 and in the US
patent application 11/991331. This architecture is intended to effective
support of the General Purpose Parallel Computing (GPPC), the essence of which
is extremely frequent switching of threads between states of activity and
states of viewed in the paper the algorithmic latency. To emphasize the same
impact of the architectural latency and the algorithmic latency upon GPPC, is
introduced the new notion of the generalized latency and is defined its
quantitative measure - the Generalized Latency Tolerance (GLT). It is shown
that a well suited for GPPC implementation architecture should have high level
of GLT and is described such architecture, which is called the Virtual-Threaded
Machine. This architecture originates a processor virtualization in the
direction of activities virtualization, which is orthogonal to the well-known
direction of memory virtualization. The key elements of the architecture are 1)
the distributed fine grain representation of the architectural register file,
which elements are hardware swapped through levels of a microarchitectural
memory, 2) the prioritized fine grain direct hardware multiprogramming, 3) the
access controlled virtual addressing and 4) the hardware driven semaphores. The
composition of these features lets to introduce new styles of operating system
(OS) programming, which is free of interruptions, and of applied programming
with a very rare using the OS services.
"
159,"Multi-core architectures: Complexities of performance prediction and the
  impact of cache topology","  The balance metric is a simple approach to estimate the performance of
bandwidth-limited loop kernels. However, applying the method to in-cache
situations and modern multi-core architectures yields unsatisfactory results.
This paper analyzes the in uence of cache hierarchy design on performance
predictions for bandwidth-limited loop kernels on current mainstream
processors. We present a diagnostic model with improved predictive power,
correcting the limitations of the simple balance metric. The importance of code
execution overhead even in bandwidth-bound situations is emphasized. Finally we
analyze the impact of synchronization overhead on multi-threaded performance
with a special emphasis on the in uence of cache topology.
"
160,QPACE -- a QCD parallel computer based on Cell processors,"  QPACE is a novel parallel computer which has been developed to be primarily
used for lattice QCD simulations. The compute power is provided by the IBM
PowerXCell 8i processor, an enhanced version of the Cell processor that is used
in the Playstation 3. The QPACE nodes are interconnected by a custom,
application optimized 3-dimensional torus network implemented on an FPGA. To
achieve the very high packaging density of 26 TFlops per rack a new water
cooling concept has been developed and successfully realized. In this paper we
give an overview of the architecture and highlight some important technical
details of the system. Furthermore, we provide initial performance results and
report on the installation of 8 QPACE racks providing an aggregate peak
performance of 200 TFlops.
"
161,Classifying Application Phases in Asymmetric Chip Multiprocessors,"  In present study, in order to improve the performance and reduce the amount
of power which is dissipated in heterogeneous multicore processors, the ability
of detecting the program execution phases is investigated. The programs
execution intervals have been classified in different phases based on their
throughput and the utilization of the cores. The results of implementing the
phase detection technique are investigated on a single core processor and also
on a multicore processor. To minimize the profiling overhead, an algorithm for
the dynamic adjustment of the profiling intervals is presented. It is based on
the behavior of the program and reduces the profiling overhead more than three
fold. The results are obtained from executing multiprocessor benchmarks on a
given processor. In order to show the program phases clearly, throughput and
utilization of execution intervals are presented on a scatter plot. The results
are presented for both fixed and variable intervals.
"
162,"A Multicore Processor based Real-Time System for Automobile management
  application","  In this paper we propose an Intelligent Management System which is capable of
managing the automobile functions using the rigorous real-time principles and a
multicore processor in order to realize higher efficiency and safety for the
vehicle. It depicts how various automobile functionalities can be fine grained
and treated to fit in real time concepts. It also shows how the modern
multicore processors can be of good use in organizing vast amounts of
correlated functions to be executed in real-time with excellent time
commitments. The modeling of the automobile tasks with real time commitments,
organizing appropriate scheduling for various real time tasks and the usage of
a multicore processor enables the system to realize higher efficiency and offer
better safety levels to the vehicle. The industry available real time operating
system is used for scheduling various tasks and jobs on the multicore
processor.
"
163,"An Architectural Approach for Decoding and Distributing Functions in
  FPUs in a Functional Processor System","  The main goal of this research is to develop the concepts of a revolutionary
processor system called Functional Processor System. The fairly novel work
carried out in this proposal concentrates on decoding of function pipelines and
distributing it in FPUs as a part of scheduling approach. As the functional
programs are super-level programs that entails requirements only at functional
level, decoding of functions and distribution of functions in the heterogeneous
functional processor units are a challenge. We explored the possibilities of
segregation of the functions from the application program and distributing the
functions on the relevant FPUs by using address mapping techniques. Here we
pursue the perception of feeding the functions into the processor farm rather
than the processor fetching the instructions or functions and executing it.
This work is carried out at theoretical levels and it requires a long way to go
in the realization of this work in hardware perhaps with a large industrial
team with a pragmatic time frame.
"
164,Maintaining Virtual Areas on FPGAs using Strip Packing with Delays,"  Every year, the computing resources available on dynamically partially
reconfigurable devices increase enormously. In the near future, we expect many
applications to run on a single reconfigurable device. In this paper, we
present a concept for multitasking on dynamically partially reconfigurable
systems called virtual area management. We explain its advantages, show its
challenges, and discuss possible solutions. Furthermore, we investigate one
problem in more detail: Packing modules with time-varying resource requests.
This problem from the reconfigurable computing field results in a completely
new optimization problem not tackled before. ILP-based and heuristic approaches
are compared in an experimental study and the drawbacks and benefits discussed.
"
165,VLSI Architectures for WIMAX Channel Decoders,"  This chapter describes the main architectures proposed in the literature to
implement the channel decoders required by the WiMax standard, namely
convolutional codes, turbo codes (both block and convolutional) and LDPC. Then
it shows a complete design of a convolutional turbo code encoder/decoder system
for WiMax.
"
166,"Virtual Machine Support for Many-Core Architectures: Decoupling Abstract
  from Concrete Concurrency Models","  The upcoming many-core architectures require software developers to exploit
concurrency to utilize available computational power. Today's high-level
language virtual machines (VMs), which are a cornerstone of software
development, do not provide sufficient abstraction for concurrency concepts. We
analyze concrete and abstract concurrency models and identify the challenges
they impose for VMs. To provide sufficient concurrency support in VMs, we
propose to integrate concurrency operations into VM instruction sets.
  Since there will always be VMs optimized for special purposes, our goal is to
develop a methodology to design instruction sets with concurrency support.
Therefore, we also propose a list of trade-offs that have to be investigated to
advise the design of such instruction sets.
  As a first experiment, we implemented one instruction set extension for
shared memory and one for non-shared memory concurrency. From our experimental
results, we derived a list of requirements for a full-grown experimental
environment for further research.
"
167,"Evaluation and Design Space Exploration of a Time-Division Multiplexed
  NoC on FPGA for Image Analysis Applications","  The aim of this paper is to present an adaptable Fat Tree NoC architecture
for Field Programmable Gate Array (FPGA) designed for image analysis
applications. Traditional NoCs (Network on Chip) are not optimal for dataflow
applications with large amount of data. On the opposite, point to point
communications are designed from the algorithm requirements but they are
expensives in terms of resource and wire. We propose a dedicated communication
architecture for image analysis algorithms. This communication mechanism is a
generic NoC infrastructure dedicated to dataflow image processing applications,
mixing circuit-switching and packet-switching communications. The complete
architecture integrates two dedicated communication architectures and reusable
IP blocks. Communications are based on the NoC concept to support the high
bandwidth required for a large number and type of data.
"
168,Ahb Compatible DDR Sdram Controller Ip Core for Arm Based Soc,"  DDR SDRAM is similar in function to the regular SDRAM but doubles the
bandwidth of the memory by transferring data on both edges of the clock cycles.
DDR SDRAM most commonly used in various embedded application like networking,
image or video processing, Laptops ete. Now a days many applications needs more
and more cheap and fast memory. Especially in the field of signal processing,
requires significant amount of memory. The most used type of dynamic memory for
that purpose is DDR SDRAM. For FPGA design the IC manufacturers are providing
commercial memory controller IP cores working only on their products. Main
disadvantage is the lack of memory access optimization for random memory access
patterns. The data path part of those controllers can be used free of charge.
This work propose an architecture of a DDR SDRAM controller, which takes
advantage of those available and well tested data paths and can be used for any
FPGA device or ASIC design.(5). In most of the SOC design, DDR SDRAM is
commonly used. ARM processor is widely used in SOCs; so that we focused to
implement AHB compatible DDR SDRAM controller suitable for ARM based SOC
design.
"
169,"Static Address Generation Easing: a Design Methodology for Parallel
  Interleaver Architectures","  For high throughput applications, turbo-like iterative decoders are
implemented with parallel architectures. However, to be efficient parallel
architectures require to avoid collision accesses i.e. concurrent read/write
accesses should not target the same memory block. This consideration applies to
the two main classes of turbo-like codes which are Low Density Parity Check
(LDPC) and Turbo-Codes. In this paper we propose a methodology which finds a
collision-free mapping of the variables in the memory banks and which optimizes
the resulting interleaving architecture. Finally, we show through a pedagogical
example the interest of our approach compared to state-of-the-art techniques.
"
170,"On Complexity, Energy- and Implementation-Efficiency of Channel Decoders","  Future wireless communication systems require efficient and flexible baseband
receivers. Meaningful efficiency metrics are key for design space exploration
to quantify the algorithmic and the implementation complexity of a receiver.
Most of the current established efficiency metrics are based on counting
operations, thus neglecting important issues like data and storage complexity.
In this paper we introduce suitable energy and area efficiency metrics which
resolve the afore-mentioned disadvantages. These are decoded information bit
per energy and throughput per area unit. Efficiency metrics are assessed by
various implementations of turbo decoders, LDPC decoders and convolutional
decoders. New exploration methodologies are presented, which permit an
appropriate benchmarking of implementation efficiency, communications
performance, and flexibility trade-offs. These exploration methodologies are
based on efficiency trajectories rather than a single snapshot metric as done
in state-of-the-art approaches.
"
171,Low Power Shift and Add Multiplier Design,"  Today every circuit has to face the power consumption issue for both portable
device aiming at large battery life and high end circuits avoiding cooling
packages and reliability issues that are too complex. It is generally accepted
that during logic synthesis power tracks well with area. This means that a
larger design will generally consume more power. The multiplier is an important
kernel of digital signal processors. Because of the circuit complexity, the
power consumption and area are the two important design considerations of the
multiplier. In this paper a low power low area architecture for the shift and
add multiplier is proposed. For getting the low power low area architecture,
the modifications made to the conventional architecture consist of the
reduction in switching activities of the major blocks of the multiplier, which
includes the reduction in switching activity of the adder and counter. This
architecture avoids the shifting of the multiplier register. The simulation
result for 8 bit multipliers shows that the proposed low power architecture
lowers the total power consumption by 35.25% and area by 52.72 % when compared
to the conventional architecture. Also the reduction in power consumption
increases with the increase in bit width.
"
172,"FPGA Implementation of a Reconfigurable Viterbi Decoder for WiMAX
  Receiver","  Field Programmable Gate Array technology (FPGA) is a highly configurable
option for implementing many sophisticated signal processing tasks in Software
Defined Radios (SDRs). Those types of radios are realized using highly
configurable hardware platforms. Convolutional codes are used in every robust
digital communication system and Viterbi algorithm is employed in wireless
communications to decode the convolutional codes. Such decoders are complex and
dissipate large amount of power. In this paper, a low power-reconfigurable
Viterbi decoder for WiMAX receiver is described using a VHDL code for FPGA
implementation. The proposed design is implemented on Xilinx Virtex-II Pro,
XC2vpx30 FPGA using the FPGA Advantage Pro package provided by Mentor Graphics
and ISE 10.1 by Xilinx.
"
173,Associative control processor with a rigid structure,"  The approach of applying associative processor for decision making problem
was proposed. It focuses on hardware implementations of fuzzy processing
systems, associativity as effective management basis of fuzzy processor. The
structural approach is being developed resulting in a quite simple and compact
parallel associative memory unit (PAMU). The memory cost and speed comparison
of processors with rigid and soft-variable structure is given. Also the example
PAMU flashing is considered.
"
174,Asynchronous logic circuits and sheaf obstructions,"  This article exhibits a particular encoding of logic circuits into a sheaf
formalism. The central result of this article is that there exists strictly
more information available to a circuit designer in this setting than exists in
static truth tables, but less than exists in event-level simulation. This
information is related to the timing behavior of the logic circuits, and
thereby provides a ``bridge'' between static logic analysis and detailed
simulation.
"
175,Reversible Logic Synthesis of Fault Tolerant Carry Skip BCD Adder,"  Reversible logic is emerging as an important research area having its
application in diverse fields such as low power CMOS design, digital signal
processing, cryptography, quantum computing and optical information processing.
This paper presents a new 4*4 parity preserving reversible logic gate, IG. The
proposed parity preserving reversible gate can be used to synthesize any
arbitrary Boolean function. It allows any fault that affects no more than a
single signal readily detectable at the circuit's primary outputs. It is shown
that a fault tolerant reversible full adder circuit can be realized using only
two IGs. The proposed fault tolerant full adder (FTFA) is used to design other
arithmetic logic circuits for which it is used as the fundamental building
block. It has also been demonstrated that the proposed design offers less
hardware complexity and is efficient in terms of gate count, garbage outputs
and constant inputs than the existing counterparts.
"
176,"Fault tolerant reversible logic synthesis: Carry look-ahead and
  carry-skip adders","  Irreversible logic circuits dissipate heat for every bit of information that
is lost. Information is lost when the input vector cannot be recovered from its
corresponding output vector. Reversible logic circuit naturally takes care of
heating because it implements only the functions that have one-to-one mapping
between its input and output vectors. Therefore reversible logic design becomes
one of the promising research directions in low power dissipating circuit
design in the past few years and has found its application in low power CMOS
design, digital signal processing and nanotechnology. This paper presents the
efficient approaches for designing reversible fast adders that implement carry
look-ahead and carry-skip logic. The proposed 16-bit high speed reversible
adder will include IG gates for the realization of its basic building block.
The IG gate is universal in the sense that it can be used to synthesize any
arbitrary Boolean-functions. The IG gate is parity preserving, that is, the
parity of the inputs matches the parity of the outputs. It allows any fault
that affects no more than a single signal readily detectable at the circuit's
primary outputs. Therefore, the proposed high speed adders will have the
inherent opportunity of detecting errors in its output side. It has also been
demonstrated that the proposed design offers less hardware complexity and is
efficient in terms of gate count, garbage outputs and constant inputs than the
existing counterparts.
"
177,Synthesis of Fault Tolerant Reversible Logic Circuits,"  Reversible logic is emerging as an important research area having its
application in diverse fields such as low power CMOS design, digital signal
processing, cryptography, quantum computing and optical information processing.
This paper presents a new 4*4 universal reversible logic gate, IG. It is a
parity preserving reversible logic gate, that is, the parity of the inputs
matches the parity of the outputs. The proposed parity preserving reversible
gate can be used to synthesize any arbitrary Boolean function. It allows any
fault that affects no more than a single signal readily detectable at the
circuit's primary outputs. Finally, it is shown how a fault tolerant reversible
full adder circuit can be realized using only two IGs. It has also been
demonstrated that the proposed design offers less hardware complexity and is
efficient in terms of gate count, garbage outputs and constant inputs than the
existing counterparts.
"
178,"Efficient Approaches for Designing Fault Tolerant Reversible Carry
  Look-Ahead and Carry-Skip Adders","  Combinational or Classical logic circuits dissipate heat for every bit of
information that is lost. Information is lost when the input vector cannot be
recovered from its corresponding output vector. Reversible logic circuit
implements only the functions having one-to-one mapping between its input and
output vectors and therefore naturally takes care of heating. Reversible logic
design becomes one of the promising research directions in low power
dissipating circuit design in the past few years and has found its application
in low power CMOS design, digital signal processing and nanotechnology. This
paper presents the efficient approaches for designing fault tolerant reversible
fast adders that implement carry look-ahead and carry-skip logic. The proposed
high speed reversible adders include MIG gates for the realization of its basic
building block. The MIG gate is universal and parity preserving. It allows any
fault that affects no more than a single signal readily detectable at the
circuit's primary outputs. It has also been demonstrated that the proposed
design offers less hardware complexity and is efficient in terms of gate count,
garbage outputs and constant inputs than the existing counterparts.
"
179,Variable Block Carry Skip Logic using Reversible Gates,"  Reversible circuits have applications in digital signal processing, computer
graphics, quantum computation and cryptography. In this paper, a generalized
k*k reversible gate family is proposed and a 3*3 gate of the family is
discussed. Inverter, AND, OR, NAND, NOR, and EXOR gates can be realized by this
gate. Implementation of a full-adder circuit using two such 3*3 gates is given.
This full-adder circuit contains only two reversible gates and produces no
extra garbage outputs. The proposed full-adder circuit is efficient in terms of
gate count, garbage outputs and quantum cost. A 4-bit carry skip adder is
designed using this full-adder circuit and a variable block carry skip adder is
discussed. Necessary equations required to evaluate these adder are presented.
"
180,"Building Toffoli Network for Reversible Logic Synthesis Based on
  Swapping Bit Strings","  In this paper, we have implemented and designed a sorting network for
reversible logic circuits synthesis in terms of n*n Toffoli gates. The
algorithm presented in this paper constructs a Toffoli Network based on
swapping bit strings. Reduction rules are then applied by simple template
matching and removing useless gates from the network. Random selection of bit
strings and reduction of control inputs are used to minimize both the number of
gates and gate width. The method produces near optimal results for up to
3-input 3-output circuits.
"
181,Memristor-based Circuits for Performing Basic Arithmetic Operations,"  In almost all of the currently working circuits, especially in analog
circuits implementing signal processing applications, basic arithmetic
operations such as multiplication, addition, subtraction and division are
performed on values which are represented by voltages or currents. However, in
this paper, we propose a new and simple method for performing analog arithmetic
operations which in this scheme, signals are represented and stored through a
memristance of the newly found circuit element, i.e. memristor, instead of
voltage or current. Some of these operators such as divider and multiplier are
much simpler and faster than their equivalent voltage-based circuits and they
require less chip area. In addition, a new circuit is designed for programming
the memristance of the memristor with predetermined analog value. Presented
simulation results demonstrate the effectiveness and the accuracy of the
proposed circuits.
"
182,"A Novel Quantum Cost Efficient Reversible Full Adder Gate in
  Nanotechnology","  Reversible logic has become one of the promising research directions in low
power dissipating circuit design in the past few years and has found its
applications in low power CMOS design, cryptography, optical information
processing and nanotechnology. This paper presents a novel and quantum cost
efficient reversible full adder gate in nanotechnology. This gate can work
singly as a reversible full adder unit and requires only one clock cycle. The
proposed gate is a universal gate in the sense that it can be used to
synthesize any arbitrary Boolean functions. It has been demonstrated that the
hardware complexity offered by the proposed gate is less than the existing
counterparts. The proposed reversible full adder gate also adheres to the
theoretical minimum established by the researchers.
"
183,Sorting Network for Reversible Logic Synthesis,"  In this paper, we have introduced an algorithm to implement a sorting network
for reversible logic synthesis based on swapping bit strings. The algorithm
first constructs a network in terms of n*n Toffoli gates read from left to
right. The number of gates in the circuit produced by our algorithm is then
reduced by template matching and removing useless gates from the network. We
have also compared the efficiency of the proposed method with the existing
ones.
"
184,"Fourier Domain Decoding Algorithm of Non-Binary LDPC codes for Parallel
  Implementation","  For decoding non-binary low-density parity check (LDPC) codes,
logarithm-domain sum-product (Log-SP) algorithms were proposed for reducing
quantization effects of SP algorithm in conjunction with FFT. Since FFT is not
applicable in the logarithm domain, the computations required at check nodes in
the Log-SP algorithms are computationally intensive. What is worth, check nodes
usually have higher degree than variable nodes. As a result, most of the time
for decoding is used for check node computations, which leads to a bottleneck
effect. In this paper, we propose a Log-SP algorithm in the Fourier domain.
With this algorithm, the role of variable nodes and check nodes are switched.
The intensive computations are spread over lower-degree variable nodes, which
can be efficiently calculated in parallel. Furthermore, we develop a fast
calculation method for the estimated bits and syndromes in the Fourier domain.
"
185,"BSSSN: Bit String Swapping Sorting Network for Reversible Logic
  Synthesis","  In this paper, we have introduced the notion of UselessGate and
ReverseOperation. We have also given an algorithm to implement a sorting
network for reversible logic synthesis based on swapping bit strings. The
network is constructed in terms of n*n Toffoli Gates read from left to right
and it has shown that there will be no more gates than the number of swappings
the algorithm requires. The gate complexity of the network is O(n2). The number
of gates in the network can be further reduced by template reduction technique
and removing UselessGate from the network.
"
186,"An $\Theta(\sqrt{n})$-depth Quantum Adder on a 2D NTC Quantum Computer
  Architecture","  In this work, we propose an adder for the 2D NTC architecture, designed to
match the architectural constraints of many quantum computing technologies. The
chosen architecture allows the layout of logical qubits in two dimensions and
the concurrent execution of one- and two-qubit gates with nearest-neighbor
interaction only. The proposed adder works in three phases. In the first phase,
the first column generates the summation output and the other columns do the
carry-lookahead operations. In the second phase, these intermediate values are
propagated from column to column, preparing for computation of the final carry
for each register position. In the last phase, each column, except the first
one, generates the summation output using this column-level carry. The depth
and the number of qubits of the proposed adder are $\Theta(\sqrt{n})$ and O(n),
respectively. The proposed adder executes faster than the adders designed for
the 1D NTC architecture when the length of the input registers $n$ is larger
than 58.
"
187,Memristor Crossbar-based Hardware Implementation of IDS Method,"  Ink Drop Spread (IDS) is the engine of Active Learning Method (ALM), which is
the methodology of soft computing. IDS, as a pattern-based processing unit,
extracts useful information from a system subjected to modeling. In spite of
its excellent potential in solving problems such as classification and modeling
compared to other soft computing tools, finding its simple and fast hardware
implementation is still a challenge. This paper describes a new hardware
implementation of IDS method based on the memristor crossbar structure. In
addition of simplicity, being completely real-time, having low latency and the
ability to continue working after the occurrence of power breakdown are some of
the advantages of our proposed circuit.
"
188,"Memristor Crossbar-based Hardware Implementation of Fuzzy Membership
  Functions","  In May 1, 2008, researchers at Hewlett Packard (HP) announced the first
physical realization of a fundamental circuit element called memristor that
attracted so much interest worldwide. This newly found element can easily be
combined with crossbar interconnect technology which this new structure has
opened a new field in designing configurable or programmable electronic
systems. These systems in return can have applications in signal processing and
artificial intelligence. In this paper, based on the simple memristor crossbar
structure, we propose new and simple circuits for hardware implementation of
fuzzy membership functions. In our proposed circuits, these fuzzy membership
functions can have any shapes and resolutions. In addition, these circuits can
be used as a basis in the construction of evolutionary systems.
"
189,Wideband Spectrum Sensing at Sub-Nyquist Rates,"  We present a mixed analog-digital spectrum sensing method that is especially
suited to the typical wideband setting of cognitive radio (CR). The advantages
of our system with respect to current architectures are threefold. First, our
analog front-end is fixed and does not involve scanning hardware. Second, both
the analog-to-digital conversion (ADC) and the digital signal processing (DSP)
rates are substantially below Nyquist. Finally, the sensing resources are
shared with the reception path of the CR, so that the lowrate streaming samples
can be used for communication purposes of the device, besides the sensing
functionality they provide. Combining these advantages leads to a real time map
of the spectrum with minimal use of mobile resources. Our approach is based on
the modulated wideband converter (MWC) system, which samples sparse wideband
inputs at sub-Nyquist rates. We report on results of hardware experiments,
conducted on an MWC prototype circuit, which affirm fast and accurate spectrum
sensing in parallel to CR communication.
"
190,Power optimized programmable embedded controller,"  Now a days, power has become a primary consideration in hardware design, and
is critical in computer systems especially for portable devices with high
performance and more functionality. Clock-gating is the most common technique
used for reducing processor's power. In this work clock gating technique is
applied to optimize the power of fully programmable Embedded Controller (PEC)
employing RISC architecture. The CPU designed supports i) smart instruction
set, ii) I/O port, UART iii) on-chip clocking to provide a range of frequencies
, iv) RISC as well as controller concepts. The whole design is captured using
VHDL and is implemented on FPGA chip using Xilinx .The architecture and clock
gating technique together is found to reduce the power consumption by 33.33% of
total power consumed by this chip.
"
191,On the Design and Analysis of Quaternary Serial and Parallel Adders,"  Optimization techniques for decreasing the time and area of adder circuits
have been extensively studied for years mostly in binary logic system. In this
paper, we provide the necessary equations required to design a full adder in
quaternary logic system. We develop the equations for single-stage parallel
adder which works as a carry look-ahead adder. We also provide the design of a
logarithmic stage parallel adder which can compute the carries within log2(n)
time delay for n qudits. At last, we compare the designs and finally propose a
hybrid adder which combines the advantages of serial and parallel adder.
"
192,"Fault Tolerant Variable Block Carry Skip Logic (VBCSL) using Parity
  Preserving Reversible Gates","  Reversible logic design has become one of the promising research directions
in low power dissipating circuit design in the past few years and has found its
application in low power CMOS design, digital signal processing and
nanotechnology. This paper presents the efficient design approaches of fault
tolerant carry skip adders (FTCSAs) and compares those designs with the
existing ones. Variable block carry skip logic (VBCSL) using the fault tolerant
full adders (FTFAs) has also been developed. The designs are minimized in terms
of hardware complexity, gate count, constant inputs and garbage outputs.
Besides of it, technology independent evaluation of the proposed designs
clearly demonstrates its superiority with the existing counterparts.
"
193,A Unique 10 Segment Display for Bengali Numerals,"  Segmented display is widely used for efficient display of alphanumeric
characters. English numerals are displayed by 7 segment and 16 segment display.
The segment size is uniform in this two display architecture. Display
architecture using 8, 10, 11, 18 segments have been proposed for Bengali
numerals 0...9 yet no display architecture is designed using segments of
uniform size and uniform power consumption. In this paper we have proposed a
uniform 10 segment architecture for Bengali numerals. This segment architecture
uses segments of uniform size and no bent segment is used.
"
194,Universal Numeric Segmented Display,"  Segmentation display plays a vital role to display numerals. But in today's
world matrix display is also used in displaying numerals. Because numerals has
lots of curve edges which is better supported by matrix display. But as matrix
display is costly and complex to implement and also needs more memory, segment
display is generally used to display numerals. But as there is yet no proposed
compact display architecture to display multiple language numerals at a time,
this paper proposes uniform display architecture to display multiple language
digits and general mathematical expressions with higher accuracy and simplicity
by using a 18-segment display, which is an improvement over the 16 segment
display.
"
195,"Multi-standard programmable baseband modulator for next generation
  wireless communication","  Considerable research has taken place in recent times in the area of
parameterization of software defined radio (SDR) architecture. Parameterization
decreases the size of the software to be downloaded and also limits the
hardware reconfiguration time. The present paper is based on the design and
development of a programmable baseband modulator that perform the QPSK
modulation schemes and as well as its other three commonly used variants to
satisfy the requirement of several established 2G and 3G wireless communication
standards. The proposed design has been shown to be capable of operating at a
maximum data rate of 77 Mbps on Xilinx Virtex 2-Pro University field
programmable gate array (FPGA) board. The pulse shaping root raised cosine
(RRC) filter has been implemented using distributed arithmetic (DA) technique
in the present work in order to reduce the computational complexity, and to
achieve appropriate power reduction and enhanced throughput. The designed
multiplier-less programmable 32-tap FIR-based RRC filter has been found to
withstand a peak inter-symbol interference (ISI) distortion of -41 dBs
"
196,"Multiplierless Modules for Forward and Backward Integer Wavelet
  Transform","  This article is about the architecture of a lossless wavelet filter bank with
reprogrammable logic. It is based on second generation of wavelets with a
reduced of number of operations. A new basic structure for parallel
architecture and modules to forward and backward integer discrete wavelet
transform is proposed.
"
197,"Model-Based Development of Distributed Embedded Systems by the Example
  of the Scicos/SynDEx Framework","  The embedded systems engineering industry faces increasing demands for more
functionality, rapidly evolving components, and shrinking schedules. Abilities
to quickly adapt to changes, develop products with safe design, minimize
project costs, and deliver timely are needed. Model-based development (MBD)
follows a separation of concerns by abstracting systems with an appropriate
intensity. MBD promises higher comprehension by modeling on several
abstraction-levels, formal verification, and automated code generation. This
thesis demonstrates MBD with the Scicos/SynDEx framework on a distributed
embedded system. Scicos is a modeling and simulation environment for hybrid
systems. SynDEx is a rapid prototyping integrated development environment for
distributed systems. Performed examples implement well-known control algorithms
on a target system containing several networked microcontrollers, sensors, and
actuators. The addressed research question tackles the feasibility of MBD for
medium-sized embedded systems. In the case of single-processor applications
experiments show that the comforts of tool-provided simulation, verification,
and code-generation have to be weighed against an additional memory consumption
in dynamic and static memory compared to a hand-written approach. Establishing
a near-seamless modeling-framework with Scicos/SynDEx is expensive. An
increased development effort indicates a high price for developing single
applications, but might pay off for product families. A further drawback was
that the distributed code generated with SynDEx could not be adapted to
microcontrollers without a significant alteration of the scheduling tables. The
Scicos/SynDEx framework forms a valuable tool set that, however, still needs
many improvements. Therefore, its usage is only recommended for experimental
purposes.
"
198,"Hardware architectures for Successive Cancellation Decoding of Polar
  Codes","  The recently-discovered polar codes are widely seen as a major breakthrough
in coding theory. These codes achieve the capacity of many important channels
under successive cancellation decoding. Motivated by the rapid progress in the
theory of polar codes, we propose a family of architectures for efficient
hardware implementation of successive cancellation decoders. We show that such
decoders can be implemented with O(n) processing elements and O(n) memory
elements, while providing constant throughput. We also propose a technique for
overlapping the decoding of several consecutive codewords, thereby achieving a
significant speed-up factor. We furthermore show that successive cancellation
decoding can be implemented in the logarithmic domain, thereby eliminating the
multiplication and division operations and greatly reducing the complexity of
each processing element.
"
199,Multi-core: Adding a New Dimension to Computing,"  Invention of Transistors in 1948 started a new era in technology, called
Solid State Electronics. Since then, sustaining development and advancement in
electronics and fabrication techniques has caused the devices to shrink in size
and become smaller, paving the quest for increasing density and clock speed.
That quest has suddenly come to a halt due to fundamental bounds applied by
physical laws. But, demand for more and more computational power is still
prevalent in the computing world. As a result, the microprocessor industry has
started exploring the technology along a different dimension. Speed of a single
work unit (CPU) is no longer the concern, rather increasing the number of
independent processor cores packed in a single package has become the new
concern. Such processors are commonly known as multi-core processors. Scaling
the performance by using multiple cores has gained so much attention from the
academia and the industry, that not only desktops, but also laptops, PDAs, cell
phones and even embedded devices today contain these processors. In this paper,
we explore state of the art technologies for multi-core processors and existing
software tools to support parallelism. We also discuss present and future trend
of research in this field. From our survey, we conclude that next few decades
are going to be marked by the success of this ""Ubiquitous parallel processing"".
"
200,Design and simulation of a sigma delta ADC,"  In this report we describe the design and simulation of a Sigma Delta ADC in
Matlan/Simulink
"
201,"A full-custom ASIC design of a 8-bit, 25 MHz, Pipeline ADC using 0.35 um
  CMOS technology","  The purpose of this project was to design and implement a pipeline
Analog-to-Digital Converter using 0.35um CMOS technology. Initial requirements
of a 25-MHz conversion rate and 8-bits of resolution where the only given ones.
Although additional secondary goals such as low power consumption and small
area were stated. The architecture is based on a 1.5 bit per stage structure
utilizing digital correction for each stage [12]. A differential switched
capacitor circuit consisting of a cascade gm-C op-amp with 200MHz ft is used
for sampling and amplification in each stage [12]. Differential dynamic
comparators are used to implement the decision levels required for the 1.5-b
per stage structure. Correction of the pipeline is accomplished by using
digital correction circuit consist of D-latches and full-adders. Area and Power
consumption of whole design was 0.24mm2 and 35mW respectively. The maximum
sample rate at which the converter gave an adequate output was 33MHz.
"
202,Systolic Arrays for Lattice-Reduction-Aided MIMO Detection,"  Multiple-input, multiple-output (MIMO) technology provides high data rate and
enhanced QoS for wireless com- munications. Since the benefits from MIMO result
in a heavy computational load in detectors, the design of low-complexity
sub-optimum receivers is currently an active area of research.
Lattice-reduction-aided detection (LRAD) has been shown to be an effective
low-complexity method with near-ML performance. In this paper we advocate the
use of systolic array architectures for MIMO receivers, and in particular we
exhibit one of them based on LRAD. The ""LLL lattice reduction algorithm"" and
the ensuing linear detections or successive spatial-interference cancellations
can be located in the same array, which is con- siderably hardware-efficient.
Since the conventional form of the LLL algorithm is not immediately suitable
for parallel processing, two modified LLL algorithms are considered here for
the systolic array. LLL algorithm with full-size reduction (FSR-LLL) is one of
the versions more suitable for parallel processing. Another variant is the
all-swap lattice-reduction (ASLR) algorithm for complex-valued lattices, which
processes all lattice basis vectors simultaneously within one iteration. Our
novel systolic array can operate both algorithms with different external logic
controls. In order to simplify the systolic array design, we replace the
Lov\'asz condition in the definition of LLL-reduced lattice with the looser
Siegel condition. Simulation results show that for LR- aided linear detections,
the bit-error-rate performance is still maintained with this relaxation.
Comparisons between the two algorithms in terms of bit-error-rate performance,
and average FPGA processing time in the systolic array are made, which shows
that ASLR is a better choice for a systolic architecture, especially for
systems with a large number of antennas.
"
203,"Reversible Logic Based Concurrent Error Detection Methodology For
  Emerging Nanocircuits","  Reversible logic has promising applications in emerging nanotechnologies,
such as quantum computing, quantum dot cellular automata and optical computing,
etc. Faults in reversible logic circuits that result in multi-bit error at the
outputs are very tough to detect, and thus in literature, researchers have only
addressed the problem of online testing of faults that result single-bit error
at the outputs based on parity preserving logic. In this work, we propose a
methodology for the concurrent error detection in reversible logic circuits to
detect faults that can result in multi-bit error at the outputs. The
methodology is based on the inverse property of reversible logic and is termed
as 'inverse and compare' method. By using the inverse property of reversible
logic, all the inputs can be regenerated at the outputs. Thus, by comparing the
original inputs with the regenerated inputs, the faults in reversible circuits
can be detected. Minimizing the garbage outputs is one of the main goals in
reversible logic design and synthesis. We show that the proposed methodology
results in 'garbageless' reversible circuits. A design of reversible full adder
that can be concurrently tested for multi-bit error at the outputs is
illustrated as the application of the proposed scheme. Finally, we showed the
application of the proposed scheme of concurrent error detection towards fault
detection in quantum dot cellular automata (QCA) emerging nanotechnology.
"
204,RISC and CISC,"  Comparison of RISC & CISC in details, encompassing the addressing modes,
evolution, definitions and characteristics. Pre - RISC design is also
elaborated. Both the architectures are explained with the help of example.
Analysis is made based on performance.
"
205,"A Simulation Experiment on a Built-In Self Test Equipped with
  Pseudorandom Test Pattern Generator and Multi-Input Shift Register (MISR)","  This paper investigates the impact of the changes of the characteristic
polynomials and initial loadings, on behaviour of aliasing errors of parallel
signature analyzer (Multi-Input Shift Register), used in an LFSR based digital
circuit testing technique. The investigation is carried-out through an
extensive simulation study of the effectiveness of the LFSR based digital
circuit testing technique. The results of the study show that when the
identical characteristic polynomials of order n are used in both pseudo-random
test-pattern generator, as well as in Multi-Input Shift Register (MISR)
signature analyzer (parallel type) then the probability of aliasing errors
remains unchanged due to the changes in the initial loadings of the
pseudo-random test-pattern generator.
"
206,"APEnet+: high bandwidth 3D torus direct network for petaflops scale
  commodity clusters","  We describe herein the APElink+ board, a PCIe interconnect adapter featuring
the latest advances in wire speed and interface technology plus hardware
support for a RDMA programming model and experimental acceleration of GPU
networking; this design allows us to build a low latency, high bandwidth PC
cluster, the APEnet+ network, the new generation of our cost-effective,
tens-of-thousands-scalable cluster network architecture. Some test results and
characterization of data transmission of a complete testbench, based on a
commercial development card mounting an Altera FPGA, are provided.
"
207,"A Secure Asynchronous FPGA Architecture, Experimental Results and Some
  Debug Feedback","  This article presents an asynchronous FPGA architecture for implementing
cryptographic algorithms secured against physical cryptanalysis. We discuss the
suitability of asynchronous reconfigurable architectures for such applications
before proceeding to model the side channel and defining our objectives. The
logic block architecture is presented in detail. We discuss several solutions
for the interconnect architecture, and how these solutions can be ported to
other flavours of interconnect (i.e. single driver). Next We discuss in detail
a high speed asynchronous configuration chain architecture used to configure
our asynchronous FPGA with simulation results, and we present a 3 X 3 prototype
FPGA fabricated in 65 nm CMOS. Lastly we present experiments to test the high
speed asynchronous configuration chain and evaluate how far our objectives have
been achieved with proposed solutions, and we conclude with emphasis on
complementary FPGA CAD algorithms, and the effect of CMOS variation on
Side-Channel Vulnerability.
"
208,"High Speed Multiple Valued Logic Full Adder Using Carbon Nano Tube Field
  Effect Transistor","  High speed Full-Adder (FA) module is a critical element in designing high
performance arithmetic circuits. In this paper, we propose a new high speed
multiple-valued logic FA module. The proposed FA is constructed by 14
transistors and 3 capacitors, using carbon nano-tube field effect transistor
(CNFET) technology. Furthermore, our proposed technique has been examined in
different voltages (i.e., 0.65v and 0.9v). The observed results reveal power
consumption and power delay product (PDP) improvements compared to existing FA
counterparts
"
209,ReveR: Software Simulator of Reversible Processor with Stack,"  A software model of a reversible processor ReveR with the stack is discussed
in this paper. An architecture, the minimal set of elementary reversible
operations together with an implementation of the basic control flow structures
and procedures calls using simple assembler language are described.
"
210,"Scalability of spin FPGA: A Reconfigurable Architecture based on spin
  MOSFET","  Scalability of Field Programmable Gate Array (FPGA) using spin MOSFET (spin
FPGA) with magnetocurrent (MC) ratio in the range of 100% to 1000% is discussed
for the first time. Area and speed of million-gate spin FPGA are numerically
benchmarked with CMOS FPGA for 22nm, 32nm and 45nm technologies including 20%
transistor size variation. We show that area is reduced and speed is increased
in spin FPGA owing to the nonvolatile memory function of spin MOSFET.
"
211,"Computer Arithmetic Preserving Hamming Distance of Operands in Operation
  Result","  The traditional approach to fault tolerant computing involves replicating
computation units and applying a majority vote operation on individual result
bits. This approach, however, has several limitations; the most severe is the
resource requirement. This paper presents a new method for fault tolerant
computing where for a given error rate, the hamming distance between correct
inputs and faulty inputs as well as the hamming distance between a correct
result and a faulty result is preserved throughout processing thereby enabling
correction of up to transient faults per computation cycle. The new method is
compared and contrasted with current protection methods and its cost /
performance is analyzed.
"
212,Improving Network-on-Chip-based turbo decoder architectures,"  In this work novel results concerning Network-on-Chip-based turbo decoder
architectures are presented. Stemming from previous publications, this work
concentrates first on improving the throughput by exploiting adaptive-bandwidth
reduction techniques. This technique shows in the best case an improvement of
more than 60 Mb/s. Moreover, it is known that double-binary turbo decoders
require higher area than binary ones. This characteristic has the negative
effect of increasing the data width of the network nodes. Thus, the second
contribution of this work is to reduce the network complexity to support
doublebinary codes, by exploiting bit-level and pseudo-floating-point
representation of the extrinsic information. These two techniques allow for an
area reduction of up to more than the 40% with a performance degradation of
about 0.2 dB.
"
213,Algebra-Logical Repair Method for FPGA Logic Blocks,"  An algebra-logical repair method for FPGA functional logic blocks on the
basis of solving the coverage problem is proposed. It is focused on
implementation into Infrastructure IP for system-on-a chip and
system-in-package. A method is designed for providing the operability of FPGA
blocks and digital system as a whole. It enables to obtain exact and optimal
solution associated with the minimum number of spares needed to repair the FPGA
logic components with multiple faults.
"
214,Brain-like infrastructure for embedded SoC diagnosis,"  This article describes high-speed multiprocessor architecture for the
concurrent analyzing information represented in analytic, graph- and table
forms of associative relations to search, recognize and make a decision in
n-dimensional vector discrete space. Vector-logical process models of actual
applications,for which the quality of solution is estimated by the proposed
integral non-arithmetical metric of the interaction between Boolean vectors,
are described.
"
215,"A Flexible LDPC code decoder with a Network on Chip as underlying
  interconnect architecture","  LDPC (Low Density Parity Check) codes are among the most powerful and widely
adopted modern error correcting codes. The iterative decoding algorithms
required for these codes involve high computational complexity and high
processing throughput is achieved by allocating a sufficient number of
processing elements (PEs). Supporting multiple heterogeneous LDPC codes on a
parallel decoder poses serious problems in the design of the interconnect
structure for such PEs. The aim of this work is to explore the feasibility of
NoC (Network on Chip) based decoders, where full flexibility in terms of
supported LDPC codes is obtained resorting to an NoC to connect PEs. NoC based
LDPC decoders have been previously considered unfeasible because of the cost
overhead associated to packet management and routing. On the contrary, the
designed NoC adopts a low complexity routing, which introduces a very limited
cost overhead with respect to architectures dedicated to specific classes of
codes. Moreover the paper proposes an efficient configuration technique, which
allows for fast on--the--fly switching among different codes. The decoder
architecture is scalable and VLSI synthesis results are presented for several
cases of study, including the whole set of WiMAX LDPC codes, WiFi codes and
DVB-S2 standard.
"
216,"Multi-Amdahl: Optimal Resource Sharing with Multiple Program Execution
  Segments","  This paper presents Multi-Amdahl, a resource allocation analytical tool for
heterogeneous systems. Our model includes multiple program execution segments,
where each one is accelerated by a specific hardware unit. The acceleration
speedup of the specific hardware unit is a function of a limited resource, such
as the unit area, power, or energy. Using the Lagrange theorem we discover the
optimal resource distribution between all specific units. We then illustrate
this general Multi-Amdahl technique using several examples of area and power
allocation among several cores and accelerators.
"
217,"Fault-tolerant Algorithms for Tick-Generation in Asynchronous Logic:
  Robust Pulse Generation","  Today's hardware technology presents a new challenge in designing robust
systems. Deep submicron VLSI technology introduced transient and permanent
faults that were never considered in low-level system designs in the past.
Still, robustness of that part of the system is crucial and needs to be
guaranteed for any successful product. Distributed systems, on the other hand,
have been dealing with similar issues for decades. However, neither the basic
abstractions nor the complexity of contemporary fault-tolerant distributed
algorithms match the peculiarities of hardware implementations. This paper is
intended to be part of an attempt striving to overcome this gap between theory
and practice for the clock synchronization problem. Solving this task
sufficiently well will allow to build a very robust high-precision clocking
system for hardware designs like systems-on-chips in critical applications. As
our first building block, we describe and prove correct a novel Byzantine
fault-tolerant self-stabilizing pulse synchronization protocol, which can be
implemented using standard asynchronous digital logic. Despite the strict
limitations introduced by hardware designs, it offers optimal resilience and
smaller complexity than all existing protocols.
"
218,"HMTT: A Hybrid Hardware/Software Tracing System for Bridging Memory
  Trace's Semantic Gap","  Memory trace analysis is an important technology for architecture research,
system software (i.e., OS, compiler) optimization, and application performance
improvements. Hardware-snooping is an effective and efficient approach to
monitor and collect memory traces. Compared with software-based approaches,
memory traces collected by hardware-based approaches are usually lack of
semantic information, such as process/function/loop identifiers, virtual
address and I/O access. In this paper we propose a hybrid hardware/software
mechanism which is able to collect memory reference trace as well as semantic
information. Based on this mechanism, we designed and implemented a prototype
system called HMTT (Hybrid Memory Trace Tool) which adopts a DIMMsnooping
mechanism to snoop on memory bus and a software-controlled tracing mechanism to
inject semantic information into normal memory trace. To the best of our
knowledge, the HMTT system is the first hardware tracing system capable of
correlating memory trace with high-level events. Comprehensive validations and
evaluations show that the HMTT system has both hardware's (e.g., no distortion
or pollution) and software's advantages (e.g., flexibility and more
information).
"
219,A Simple Multi-Processor Computer Based on Subleq,"  Subleq (Subtract and Branch on result Less than or Equal to zero) is both an
instruction set and a programming language for One Instruction Set Computer
(OISC). We describe a hardware implementation of an array of 28 one-instruction
Subleq processors on a low-cost FPGA board. Our test results demonstrate that
computational power of our Subleq OISC multi-processor is comparable to that of
CPU of a modern personal computer. Additionally, we provide implementation
details of our complier from a C-style language to Subleq.
"
220,"Pseudo-Ring Testing Schemes and Algorithms of RAM Built-In and Embedded
  Self-Testing","  Scan and ring schemes of the pseudo-ring memory selftesting are investigated.
Both schemes are based on emulation of the linear or nonlinear feedback shift
register by memory itself. Peculiarities of the pseudo-ring schemes
implementation for multi-port and embedded memories, and for register file are
described. It is shown that only small additional logic is required and allows
microcontrollers at-speed testing. Also, in this article,are given the a
posteriori values of some type of memories faults coverage when pseudo-ring
testing schemes are applied.
"
221,SoC Software Components Diagnosis Technology,"  A novel approach to evaluation of hardware and software testability,
represented in the form of register transfer graph, is proposed. Instances of
making of software graph models for their subsequent testing and diagnosis are
shown.
"
222,Reversible arithmetic logic unit,"  Quantum computer requires quantum arithmetic. The sophisticated design of a
reversible arithmetic logic unit (reversible ALU) for quantum arithmetic has
been investigated in this letter. We provide explicit construction of
reversible ALU effecting basic arithmetic operations. By provided the
corresponding control unit, the proposed reversible ALU can combine the
classical arithmetic and logic operation in a reversible integrated system.
This letter provides actual evidence to prove the possibility of the
realization of reversible Programmable Logic Device (RPLD) using reversible
ALU.
"
223,AWRP: Adaptive Weight Ranking Policy for Improving Cache Performance,"  Due to the huge difference in performance between the computer memory and
processor, the virtual memory management plays a vital role in system
performance. A Cache memory is the fast memory which is used to compensate the
speed difference between the memory and processor. This paper gives an adaptive
replacement policy over the traditional policy which has low overhead, better
performance and is easy to implement. Simulations show that our algorithm
performs better than Least-Recently-Used (LRU), First-In-First-Out (FIFO) and
Clock with Adaptive Replacement (CAR).
"
224,"A Design Methodology for Folded, Pipelined Architectures in VLSI
  Applications using Projective Space Lattices","  Semi-parallel, or folded, VLSI architectures are used whenever hardware
resources need to be saved at design time. Most recent applications that are
based on Projective Geometry (PG) based balanced bipartite graph also fall in
this category. In this paper, we provide a high-level, top-down design
methodology to design optimal semi-parallel architectures for applications,
whose Data Flow Graph (DFG) is based on PG bipartite graph. Such applications
have been found e.g. in error-control coding and matrix computations. Unlike
many other folding schemes, the topology of connections between physical
elements does not change in this methodology. Another advantage is the ease of
implementation. To lessen the throughput loss due to folding, we also
incorporate a multi-tier pipelining strategy in the design methodology. The
design methodology has been verified by implementing a synthesis tool in C++,
which has been verified as well. The tool is publicly available. Further, a
complete decoder was manually protototyped before the synthesis tool design, to
verify all the algorithms evolved in this paper, towards various steps of
refinement. Another specific high-performance design of an LDPC decoder based
on this methodology was worked out in past, and has been patented as well.
"
225,Facile Algebraic Representation of a Novel Quaternary Logic,"  In this work, a novel quaternary algebra has been proposed that can be used
to implement an arbitrary quaternary logic function in more than one systematic
ways. The proposed logic has evolved from and is closely related to the Boolean
algebra for binary domain; yet it does not lack the benefits of a higher-radix
system. It offers seamless integration of the binary logic functions and
expressions through a set of transforms and allows any binary logic
simplification technique to be applied in quaternary domain. Since physical
realization of the operators defined in this logic has recently been reported,
it has become very important to have a well-defined algebra that will
facilitate the algebraic manipulation of the novel quaternary logic and aid in
designing various complex logic circuits. Therefore, based on our earlier
works, here we describe the complete algebraic representation of this logic for
the first time. The efficacy of the logic has been shown by designing and
comparing several common logic circuits with existing designs in both binary
and quaternary domain.
"
226,"A Novel Methodology for Thermal Analysis & 3-Dimensional Memory
  Integration","  The semiconductor industry is reaching a fascinating confluence in several
evolutionary trends that will likely lead to a number of revolutionary changes
in the design, implementation, scaling, and the use of computer systems.
However, recently Moore's law has come to a stand-still since device scaling
beyond 65 nm is not practical. 2D integration has problems like memory latency,
power dissipation, and large foot-print. 3D technology comes as a solution to
the problems posed by 2D integration. The utilization of 3D is limited by the
problem of temperature crisis. It is important to develop an accurate power
profile extraction methodology to design 3D structure. In this paper, design of
3D integration of memory is considered and hence the static power dissipation
of the memory cell is analysed in transistor level and is used to accurately
model the inter-layer thermal effects for 3D memory stack. Subsequently,
packaging of the chip is considered and modelled using an architecture level
simulator. This modelling is intended to analyse the thermal effects of 3D
memory, its reliability and lifetime of the chip, with greater accuracy.
"
227,An improved distributed routing algorithm for Benes based optical NoC,"  Integrated optical interconnect is believed to be one of the main
technologies to replace electrical wires. Optical Network-on-Chip (ONoC) has
attracted more attentions nowadays. Benes topology is a good choice for ONoC
for its rearrangeable non-blocking character, multistage feature and easy
scalability. Routing algorithm plays an important role in determining the
performance of ONoC. But traditional routing algorithms for Benes network are
not suitable for ONoC communication, we developed a new distributed routing
algorithm for Benes ONoC in this paper. Our algorithm selected the routing path
dynamically according to network condition and enables more path choices for
the message traveling in the network. We used OPNET to evaluate the performance
of our routing algorithm and also compared it with a well-known bit-controlled
routing algorithm. ETE delay and throughput were showed under different packet
length and network sizes. Simulation results show that our routing algorithm
can provide better performance for ONoC.
"
228,Intelligent Bees for QoS Routing in Networks-on-Chip,"  Networks-on-Chip (NoCs) for future many-core processor platforms integrate
more and more heterogeneous components of different types and many real-time
and latency-sensitive applications can run on a single chip concurrently. The
reconfigurable FPGA and reconfigurable NoCs have emerged for the purpose of
reusability. Those types' traffics within NoCs exhibit diverse, burst, and
unpredictable communication patterns. QoS guaranteed mechanisms are necessary
to provide guaranteed throughput (GT) or guaranteed bandwidth (GB) performance
for NoCs. In this paper, we propose a QoS routing algorithm inspired by bees'
foraging behaviors to provide guaranteed bandwidth performance. Virtual
circuits and Spatial Division Multiplexing are employed to maintain available
paths for different type's traffics.
"
229,Designing a CPU model: from a pseudo-formal document to fast code,"  For validating low level embedded software, engineers use simulators that
take the real binary as input. Like the real hardware, these full-system
simulators are organized as a set of components. The main component is the CPU
simulator (ISS), because it is the usual bottleneck for the simulation speed,
and its development is a long and repetitive task. Previous work showed that an
ISS can be generated from an Architecture Description Language (ADL). In the
work reported in this paper, we generate a CPU simulator directly from the
pseudo-formal descriptions of the reference manual. For each instruction, we
extract the information describing its behavior, its binary encoding, and its
assembly syntax. Next, after automatically applying many optimizations on the
extracted information, we generate a SystemC/TLM ISS. We also generate tests
for the decoder and a formal specification in Coq. Experiments show that the
generated ISS is as fast and stable as our previous hand-written ISS.
"
230,Memristive fuzzy edge detector,"  Fuzzy inference systems always suffer from the lack of efficient structures
or platforms for their hardware implementation. In this paper, we tried to
overcome this problem by proposing new method for the implementation of those
fuzzy inference systems which use fuzzy rule base to make inference. To achieve
this goal, we have designed a multi-layer neuro-fuzzy computing system based on
the memristor crossbar structure by introducing some new concepts like fuzzy
minterms. Although many applications can be realized through the use of our
proposed system, in this study we show how the fuzzy XOR function can be
constructed and how it can be used to extract edges from grayscale images. Our
memristive fuzzy edge detector (implemented in analog form) compared with other
common edge detectors has this advantage that it can extract edges of any given
image all at once in real-time.
"
231,"High-Precision Tuning of State for Memristive Devices by Adaptable
  Variation-Tolerant Algorithm","  Using memristive properties common for the titanium dioxide thin film
devices, we designed a simple write algorithm to tune device conductance at a
specific bias point to 1% relative accuracy (which is roughly equivalent to
7-bit precision) within its dynamic range even in the presence of large
variations in switching behavior. The high precision state is nonvolatile and
the results are likely to be sustained for nanoscale memristive devices because
of the inherent filamentary nature of the resistive switching. The proposed
functionality of memristive devices is especially attractive for analog
computing with low precision data. As one representative example we demonstrate
hybrid circuitry consisting of CMOS summing amplifier and two memristive
devices to perform analog multiply and accumulate computation, which is a
typical bottleneck operation in information processing.
"
232,Power comparison of CMOS and adiabatic full adder circuit,"  Full adders are important components in applications such as digital signal
processors (DSP) architectures and microprocessors. Apart from the basic
addition adders also used in performing useful operations such as subtraction,
multiplication, division, address calculation, etc. In most of these systems
the adder lies in the critical path that determines the overall performance of
the system. In this paper conventional complementary metal oxide semiconductor
(CMOS) and adiabatic adder circuits are analyzed in terms of power and
transistor count using 0.18UM technology.
"
233,Faster Energy Efficient Dadda Based Baugh-Wooley Multipliers,"  In this work faster Baugh-Wooley multiplication has been achieved by using a
combination of two design techniques: partition of the partial products into
two parts for independent parallel column compression and acceleration of the
final addition using a hybrid adder proposed in this work. Based on the
proposed techniques 8, 16, 32 and 64-bit Dadda based Baugh-Wooley multipliers
has been developed and compared with the regular Baugh-Wooley multiplier. The
performance of the proposed multiplier is analyzed by evaluating the delay,
area and power, with 180 nm process technologies on interconnect and layout
using industry standard design and layout tools. The result analysis shows that
the 64-bit proposed multiplier is as much as 26.9% faster than the regular
Baugh-Wooley multiplier and requires only 2.21% more power. Also the
power-delay product of the proposed design is significantly lower than that of
the regular Baugh-Wooley multiplier.
"
234,Faster and Low Power Twin Precision Multiplier,"  In this work faster unsigned multiplication has been achieved by using a
combination of High Performance Multiplication [HPM] column reduction technique
and implementing a N-bit multiplier using 4 N/2-bit multipliers (recursive
multiplication) and acceleration of the final addition using a hybrid adder.
Low power has been achieved by using clock gating technique. Based on the
proposed technique 16 and 32-bit multipliers are developed. The performance of
the proposed multiplier is analyzed by evaluating the delay, area and power,
with TCBNPHP 90 nm process technology on interconnect and layout using Cadence
NC launch, RTL compiler and ENCOUNTER tools. The results show that the 32-bit
proposed multiplier is as much as 22% faster, occupies only 3% more area and
consumes 30% lesser power with respect to the recently reported twin precision
multiplier.
"
235,Multi-core processors - An overview,"  Microprocessors have revolutionized the world we live in and continuous
efforts are being made to manufacture not only faster chips but also smarter
ones. A number of techniques such as data level parallelism, instruction level
parallelism and hyper threading (Intel's HT) already exists which have
dramatically improved the performance of microprocessor cores. This paper
briefs on evolution of multi-core processors followed by introducing the
technology and its advantages in today's world. The paper concludes by
detailing on the challenges currently faced by multi-core processors and how
the industry is trying to address these issues.
"
236,Optimal Final Carry Propagate Adder Design for Parallel Multipliers,"  Based on the ASIC layout level simulation of 7 types of adder structures each
of four different sizes, i.e. a total of 28 adders, we propose expressions for
the width of each of the three regions of the final Carry Propagate Adder (CPA)
to be used in parallel multipliers. We also propose the types of adders to be
used in each region that would lead to the optimal performance of the hybrid
final adders in parallel multipliers. This work evaluates the complete
performance of the analyzed designs in terms of delay, area, power through
custom design and layout in 0.18 um CMOS process technology.
"
237,"Accelerating Algorithms using a Dataflow Graph in a Reconfigurable
  System","  In this paper, the acceleration of algorithms using a design of a field
programmable gate array (FPGA) as a prototype of a static dataflow architecture
is discussed. The static dataflow architecture using operators interconnected
by parallel buses was implemented. Accelerating algorithms using a dataflow
graph in a reconfigurable system shows the potential for high computation
rates. The results of benchmarks implemented using the static dataflow
architecture are reported at the end of this paper.
"
238,"Formal Verification of an Iterative Low-Power x86 Floating-Point
  Multiplier with Redundant Feedback","  We present the formal verification of a low-power x86 floating-point
multiplier. The multiplier operates iteratively and feeds back intermediate
results in redundant representation. It supports x87 and SSE instructions in
various precisions and can block the issuing of new instructions. The design
has been optimized for low-power operation and has not been constrained by the
formal verification effort. Additional improvements for the implementation were
identified through formal verification. The formal verification of the design
also incorporates the implementation of clock-gating and control logic. The
core of the verification effort was based on ACL2 theorem proving.
Additionally, model checking has been used to verify some properties of the
floating-point scheduler that are relevant for the correct operation of the
unit.
"
239,"FPGA implementation of short critical path CORDIC-based approximation of
  the eight-point DCT","  This paper presents an efficient approach for multiplierless implementation
for eight-point DCT approximation, which based on coordinate rotation digital
computer (CORDIC) algorithm. The main design objective is to make critical path
of corresponding circuits shorter and reduce the combinational delay of
proposed scheme.
"
240,Efficient Network for Non-Binary QC-LDPC Decoder,"  This paper presents approaches to develop efficient network for non-binary
quasi-cyclic LDPC (QC-LDPC) decoders. By exploiting the intrinsic shifting and
symmetry properties of the check matrices, significant reduction of memory size
and routing complexity can be achieved. Two different efficient network
architectures for Class-I and Class-II non-binary QC-LDPC decoders have been
proposed, respectively. Comparison results have shown that for the code of the
64-ary (1260, 630) rate-0.5 Class-I code, the proposed scheme can save more
than 70.6% hardware required by shuffle network than the state-of-the-art
designs. The proposed decoder example for the 32-ary (992, 496) rate-0.5
Class-II code can achieve a 93.8% shuffle network reduction compared with the
conventional ones. Meanwhile, based on the similarity of Class-I and Class-II
codes, similar shuffle network is further developed to incorporate both classes
of codes at a very low cost.
"
241,Reduced-Latency SC Polar Decoder Architectures,"  Polar codes have become one of the most favorable capacity achieving error
correction codes (ECC) along with their simple encoding method. However, among
the very few prior successive cancellation (SC) polar decoder designs, the
required long code length makes the decoding latency high. In this paper,
conventional decoding algorithm is transformed with look-ahead techniques. This
reduces the decoding latency by 50%. With pipelining and parallel processing
schemes, a parallel SC polar decoder is proposed. Sub-structure sharing
approach is employed to design the merged processing element (PE). Moreover,
inspired by the real FFT architecture, this paper presents a novel input
generating circuit (ICG) block that can generate additional input signals for
merged PEs on-the-fly. Gate-level analysis has demonstrated that the proposed
design shows advantages of 50% decoding latency and twice throughput over the
conventional one with similar hardware cost.
"
242,Low-Latency SC Decoder Architectures for Polar Codes,"  Nowadays polar codes are becoming one of the most favorable capacity
achieving error correction codes for their low encoding and decoding
complexity. However, due to the large code length required by practical
applications, the few existing successive cancellation (SC) decoder
implementations still suffer from not only the high hardware cost but also the
long decoding latency. This paper presents novel several approaches to design
low-latency decoders for polar codes based on look-ahead techniques. Look-ahead
techniques can be employed to reschedule the decoding process of polar decoder
in numerous approaches. However, among those approaches, only well-arranged
ones can achieve good performance in terms of both latency and hardware
complexity. By revealing the recurrence property of SC decoding chart, the
authors succeed in reducing the decoding latency by 50% with look-ahead
techniques. With the help of VLSI-DSP design techniques such as pipelining,
folding, unfolding, and parallel processing, methodologies for four different
polar decoder architectures have been proposed to meet various application
demands. Sub-structure sharing scheme has been adopted to design the merged
processing element (PE) for further hardware reduction. In addition, systematic
methods for construction refined pipelining decoder (2nd design) and the input
generating circuits (ICG) block have been given. Detailed gate-level analysis
has demonstrated that the proposed designs show latency advantages over
conventional ones with similar hardware cost.
"
243,"Design and Simulation of an 8-bit Dedicated Processor for calculating
  the Sine and Cosine of an Angle using the CORDIC Algorithm","  This paper describes the design and simulation of an 8-bit dedicated
processor for calculating the Sine and Cosine of an Angle using CORDIC
Algorithm (COordinate Rotation DIgital Computer), a simple and efficient
algorithm to calculate hyperbolic and trigonometric functions. We have proposed
a dedicated processor system, modeled by writing appropriate programs in VHDL,
for calculating the Sine and Cosine of an angle. System simulation was carried
out using ModelSim 6.3f and Xilinx ISE Design Suite 12.3. A maximum frequency
of 81.353 MHz was reached with a minimum period of 12.292 ns. 126 (3%) slices
were used. This paper attempts to survey the existing CORDIC algorithm with an
eye towards implementation in Field Programmable Gate Arrays (FPGAs). A brief
description of the theory behind the algorithm and the derivation of the Sine
and Cosine of an angle using the CORDIC algorithm has been presented. The
system can be implemented using Spartan3 XC3S400 with Xilinx ISE 12.3 and VHDL.
"
244,Performance of Cache Memory Subsystems for Multicore Architectures,"  Advancements in multi-core have created interest among many research groups
in finding out ways to harness the true power of processor cores. Recent
research suggests that on-board component such as cache memory plays a crucial
role in deciding the performance of multi-core systems. In this paper,
performance of cache memory is evaluated through the parameters such as cache
access time, miss rate and miss penalty. The influence of cache parameters over
execution time is also discussed. Results obtained from simulated studies of
multi-core environments with different instruction set architectures (ISA) like
ALPHA and X86 are produced.
"
245,"Elastic Fidelity: Trading-off Computational Accuracy for Energy
  Reduction","  Power dissipation and energy consumption have become one of the most
important problems in the design of processors today. This is especially true
in power-constrained environments, such as embedded and mobile computing. While
lowering the operational voltage can reduce power consumption, there are limits
imposed at design time, beyond which hardware components experience faulty
operation. Moreover, the decrease in feature size has led to higher
susceptibility to process variations, leading to reliability issues and
lowering yield. However, not all computations and all data in a workload need
to maintain 100% fidelity. In this paper, we explore the idea of employing
functional or storage units that let go the conservative guardbands imposed on
the design to guarantee reliable execution. Rather, these units exhibit Elastic
Fidelity, by judiciously lowering the voltage to trade-off reliable execution
for power consumption based on the error guarantees required by the executing
code. By estimating the accuracy required by each computational segment of a
workload, and steering each computation to different functional and storage
units, Elastic Fidelity Computing obtains power and energy savings while
reaching the reliability targets required by each computational segment. Our
preliminary results indicate that even with conservative estimates, Elastic
Fidelity can reduce the power and energy consumption of a processor by 11-13%
when executing applications involving human perception that are typically
included in modern mobile platforms, such as audio, image, and video decoding.
"
246,Parametric Estimation of the Ultimate Size of Hypercomputers,"  The performance of the emerging petaflops-scale supercomputers of the nearest
future (hypercomputers) will be governed not only by the clock frequency of the
processing nodes or by the width of the system bus, but also by such factors as
the overall power consumption and the geometric size. In this paper, we study
the influence of such parameters on one of the most important characteristics
of a general purpose computer - on the degree of multithreading that must be
present in an application to make the use of the hypercomputer justifiable. Our
major finding is that for the class of applications with purely random memory
access patterns ""super-fast computing"" and ""high-performance computing"" are
essentially synonyms for ""massively-parallel computing.""
"
247,"Hardware Implementation of Successive Cancellation Decoders for Polar
  Codes","  The recently-discovered polar codes are seen as a major breakthrough in
coding theory; they provably achieve the theoretical capacity of discrete
memoryless channels using the low complexity successive cancellation (SC)
decoding algorithm. Motivated by recent developments in polar coding theory, we
propose a family of efficient hardware implementations for SC polar decoders.
We show that such decoders can be implemented with O(n) processing elements,
O(n) memory elements, and can provide a constant throughput for a given target
clock frequency. Furthermore, we show that SC decoding can be implemented in
the logarithm domain, thereby eliminating costly multiplication and division
operations and reducing the complexity of each processing element greatly. We
also present a detailed architecture for an SC decoder and provide logic
synthesis results confirming the linear growth in complexity of the decoder as
the code length increases.
"
248,A New Design for Array Multiplier with Trade off in Power and Area,"  In this paper a low power and low area array multiplier with carry save adder
is proposed. The proposed adder eliminates the final addition stage of the
multiplier than the conventional parallel array multiplier. The conventional
and proposed multiplier both are synthesized with 16-T full adder. Among
Transmission Gate, Transmission Function Adder, 14-T, 16-T full adder shows
energy efficiency. In the proposed 4x4 multiplier to add carry bits with out
using Ripple Carry Adder (RCA) in the final stage, the carries given to the
input of the next left column input. Due to this the proposed multiplier shows
56 less transistor count, then cause trade off in power and area. The proposed
multiplier has shown 13.91% less power, 34.09% more speed and 59.91% less
energy consumption for TSMC 0.18nm technology at a supply voltage 2.0V than the
conventional multiplier.
"
249,"Quantum Cost Efficient Reversible BCD Adder for Nanotechnology Based
  Systems","  Reversible logic allows low power dissipating circuit design and founds its
application in cryptography, digital signal processing, quantum and optical
information processing. This paper presents a novel quantum cost efficient
reversible BCD adder for nanotechnology based systems using PFAG gate. It has
been demonstrated that the proposed design offers less hardware complexity and
requires minimum number of garbage outputs than the existing counterparts. The
remarkable property of the proposed designs is that its quantum realization is
given in NMR technology.
"
250,"Multiplexed multiple-{\tau} auto- and cross- correlators on a single
  FPGA","  Fluorescence correlation and cross-correlation spectroscopy (FCS, FCCS) are
widely used techniques to study the diffusion properties and interactions of
fluorescent molecules. Autocorrelation (ACFs) and cross-correlation functions
(CCFs) are typically acquired with fast hardware correlators. Here we introduce
a new multiple-{\tau} hardware correlator design for computing ACFs and CCFs in
real time. A scheduling algorithm minimizes the use of hardware resources by
calculating the different segments of the correlation function on a single
correlator block. The program was written in LabVIEW, enabling computation of
two multiple-{\tau} ACFs and two CCFs on a National Instruments FPGA card (NI
7833R) in real time with a minimal sampling time of 400 ns. Raw data are also
stored with a time resolution of 50 ns for later analysis. The design can be
adapted to other FPGA cards with only minor changes and extended to evaluate
more inputs and correlation functions.
"
251,"Umgebungserfassungssystem fuer mobile Roboter (environment logging
  system for mobile autonomous robots)","  This diploma thesis describes the theoretical bases, the conception of the
module and the final result of the development process in application. for the
environment logging with a small mobile robot for interiors should be sketched
an economical alternative to the expensive laser scanners. the structure, color
or the material of the objects in the radius of action, as well as the
environment brightness and illuminating are to have thereby no influence on the
results of measurement.
"
252,Information Analysis Infrastructure for Diagnosis,"  A high-speed multiprocessor architecture for brain-like analyzing information
represented in analytic, graph- and table forms of associative relations to
search, recognize and make a decision in n-dimensional vector discrete space is
offered. Vector-logical process models of actual applications, where the
quality of solution is estimated by the proposed integral non-arithmetical
metric of the interaction between binary vectors, are described. The
theoretical proof of the metric for a vector logical space and the quality
criteria for estimating solutions is created.
"
253,"Theoretical Modeling and Simulation of Phase-Locked Loop (PLL) for Clock
  Data Recovery (CDR)","  Modern communication and computer systems require rapid (Gbps), efficient and
large bandwidth data transfers. Agressive scaling of digital integrated systems
allow buses and communication controller circuits to be integrated with the
microprocessor on the same chip. The Peripheral Component Interconnect Express
(PCIe) protocol handles all communcation between the central processing unit
(CPU) and hardware devices. PCIe buses require efficient clock data recovery
circuits (CDR) to recover clock signals embedded in data during transmission.
This paper describes the theoretical modeling and simulation of a phase-locked
loop (PLL) used in a CDR circuit. A simple PLL architecture for a 5 GHz CDR
circuit is proposed and elaborated in this work. Simulations were carried out
using a Hardware Description Language, Verilog- AMS. The effect of jitter on
the proposed design is also simulated and evaluated in this work. It was found
that the proposed design is robust against both input and VCO jitter.
"
254,Design and ASIC implementation of DUC/DDC for communication systems,"  Communication systems use the concept of transmitting information using the
electrical distribution network as a communication channel. To enable the
transmission data signal modulated on a carrier signal is superimposed on the
electrical wires. Typical power lines are designed to handle 50/60 Hz of AC
power signal; however they can carry the signals up to 500 KHz frequency. This
work aims to aid transmission/reception of an audio signal in the spectrum from
300 Hz to 4000 Hz using PLCC on a tunable carrier frequency in the spectrum
from 200 KHz to 500 KHz. For digital amplitude modulation the sampling rate of
the carrier and the audio signal has to be matched. Tunable carrier generation
can be achieved with Direct Digital Synthesizers at a desired sampling rate.
DSP Sample rate conversion techniques are very useful to make the sampling
circuits to work on their own sampling rates which are fine for the
data/modulated-carrier signal's bandwidth. This also simplifies the complexity
of the sampling circuits. Digital Up Conversion (DUC) and Digital Down
Conversion (DDC) are DSP sample rate conversion techniques which refer to
increasing and decreasing the sampling rate of a signal respectively.
"
255,"An efficient FPGA implementation of MRI image filtering and tumor
  characterization using Xilinx system generator","  This paper presents an efficient architecture for various image filtering
algorithms and tumor characterization using Xilinx System Generator (XSG). This
architecture offers an alternative through a graphical user interface that
combines MATLAB, Simulink and XSG and explores important aspects concerned to
hardware implementation. Performance of this architecture implemented in
SPARTAN-3E Starter kit (XC3S500E-FG320) exceeds those of similar or greater
resources architectures. The proposed architecture reduces the resources
available on target device by 50%.
"
256,"A Novel Methodology for Thermal Aware Silicon Area Estimation for 2D &
  3D MPSoCs","  In a multiprocessor system on chip (MPSoC) IC the processor is one of the
highest heat dissipating devices. The temperature generated in an IC may vary
with floor plan of the chip. This paper proposes an integration and thermal
analysis methodology to extract the peak temperature and temperature
distribution of 2-dimensional and 3-dimensional multiprocessor system-on-chip.
As we know the peak temperature of chip increases in 3-dimensional structures
compared to 2-dimensional ones due to the reduced space in intra-layer and
inter-layer components. In sub-nanometre scale technologies, it is inevitable
to analysis the heat developed in individual chip to extract the temperature
distribution of the entire chip. With the technology scaling in new generation
ICs more and more components are integrated to a smaller area. Along with the
other parameters threshold voltage is also scaled down which results in
exponential increase in leakage current. This has resulted in rise in hotspot
temperature value due to increase in leakage power. In this paper, we have
analysed the temperature developed in an IC with four identical processors at
2.4 GHz in different floorplans. The analysis has been done for both 2D and 3D
arrangements. In the 3D arrangement, a three layered structure has been
considered with two Silicon layers and a thermal interface material (TIM) in
between them. Based on experimental results the paper proposes a methodology to
reduce the peak temperature developed in 2D and 3D integrated circuits .
"
257,"A Resolution for Shared Memory Conflict in Multiprocessor
  System-on-a-Chip","  Now days, manufacturers are focusing on increasing the concurrency in
multiprocessor system-on-a-chip (MPSoC) architecture instead of increasing
clock speed, for embedded systems. Traditionally lock-based synchronization is
provided to support concurrency; as managing locks can be very difficult and
error prone. Transactional memories and lock based systems have been
extensively used to provide synchronization between multiple processors [1] in
general-purpose systems. It has been shown that locks have numerous
shortcomings over transactional memory in terms of power consumption, ease of
programming and performance. In this paper, we propose a new semaphore scheme
for synchronization in shared cache memory in an MPSoC. Moreover, we have
evaluated and compared our scheme with locks and transactions in terms of
energy consumption and cache miss rate using SimpleScalar functional simulator.
"
258,"Cross-point architecture for spin transfer torque magnetic random access
  memory","  Spin transfer torque magnetic random access memory (STT-MRAM) is considered
as one of the most promising candidates to build up a true universal memory
thanks to its fast write/read speed, infinite endurance and non-volatility.
However the conventional access architecture based on 1 transistor + 1 memory
cell limits its storage density as the selection transistor should be large
enough to ensure the write current higher than the critical current for the STT
operation. This paper describes a design of cross-point architecture for
STT-MRAM. The mean area per word corresponds to only two transistors, which are
shared by a number of bits (e.g. 64). This leads to significant improvement of
data density (e.g. 1.75 F2/bit). Special techniques are also presented to
address the sneak currents and low speed issues of conventional cross-point
architecture, which are difficult to surmount and few efficient design
solutions have been reported in the literature. By using a STT-MRAM SPICE model
including precise experimental parameters and STMicroelectronics 65 nm
technology, some chip characteristic results such as cell area, data access
speed and power have been calculated or simulated to demonstrate the expected
performances of this new memory architecture.
"
259,"FATAL+: A Self-Stabilizing Byzantine Fault-tolerant Clocking Scheme for
  SoCs","  We present concept and implementation of a self-stabilizing Byzantine
fault-tolerant distributed clock generation scheme for multi-synchronous GALS
architectures in critical applications. It combines a variant of a recently
introduced self-stabilizing algorithm for generating low-frequency,
low-accuracy synchronized pulses with a simple non-stabilizing high-frequency,
high-accuracy clock synchronization algorithm. We provide thorough correctness
proofs and a performance analysis, which use methods from fault-tolerant
distributed computing research but also addresses hardware-related issues like
metastability. The algorithm, which consists of several concurrent
communicating asynchronous state machines, has been implemented in VHDL using
Petrify in conjunction with some extensions, and synthetisized for an Altera
Cyclone FPGA. An experimental validation of this prototype has been carried out
to confirm the skew and clock frequency bounds predicted by the theoretical
analysis, as well as the very short stabilization times (required for
recovering after excessively many transient failures) achievable in practice.
"
260,"A handy systematic method for data hazards detection in an instruction
  set of a pipelined microprocessor","  It is intended in this document to introduce a handy systematic method for
enumerating all possible data dependency cases that could occur between any two
instructions that might happen to be processed at the same time at different
stages of the pipeline. Given instructions of the instruction set, specific
information about operands of each instruction and when an instruction reads or
writes data, the method could be used to enumerate all possible data hazard
cases and to determine whether forwarding or stalling is suitable for resolving
each case.
"
261,"The Distributed Network Processor: a novel off-chip and on-chip
  interconnection network architecture","  One of the most demanding challenges for the designers of parallel computing
architectures is to deliver an efficient network infrastructure providing low
latency, high bandwidth communications while preserving scalability. Besides
off-chip communications between processors, recent multi-tile (i.e. multi-core)
architectures face the challenge for an efficient on-chip interconnection
network between processor's tiles. In this paper, we present a configurable and
scalable architecture, based on our Distributed Network Processor (DNP) IP
Library, targeting systems ranging from single MPSoCs to massive HPC platforms.
The DNP provides inter-tile services for both on-chip and off-chip
communications with a uniform RDMA style API, over a multi-dimensional direct
network with a (possibly) hybrid topology.
"
262,"Designing a WISHBONE Protocol Network Adapter for an Asynchronous
  Network-on-Chip","  The Scaling of microchip technologies, from micron to submicron and now to
deep sub-micron (DSM) range, has enabled large scale systems-on-chip (SoC). In
future deep submicron (DSM) designs, the interconnect effect will definitely
dominate performance. Network-on-Chip (NoC) has become a promising solution to
bus-based communication infrastructure limitations. NoC designs usually targets
Application Specific Integrated Circuits (ASICs), however, the fabrication
process costs a lot. Implementing a NoC on an FPGA does not only reduce the
cost but also decreases programming and verification cycles. In this paper, an
Asynchronous NoC has been implemented on a SPARTAN-3E\textregistered device.
The NoC supports basic transactions of both widely used on-chip interconnection
standards, the Open Core Protocol (OCP) and the WISHBONE Protocol. Although,
FPGA devices are synchronous in nature, it has been shown that they can be used
to prototype a Global Asynchronous Local Synchronous (GALS) systems, comprising
an Asynchronous NoC connecting IP cores operating in different clock domains.
"
263,LOCKE Detailed Specification Tables,"  This document shows the detailed specification of LOCKE coherence protocol
for each cache controller, using a table-based technique. This representation
provides clear, concise visual information yet includes sufficient detail
(e.g., transient states) arguably lacking in the traditional, graphical form of
state diagrams.
"
264,"C-slow Technique vs Multiprocessor in designing Low Area Customized
  Instruction set Processor for Embedded Applications","  The demand for high performance embedded processors, for consumer
electronics, is rapidly increasing for the past few years. Many of these
embedded processors depend upon custom built Instruction Ser Architecture (ISA)
such as game processor (GPU), multimedia processors, DSP processors etc.
Primary requirement for consumer electronic industry is low cost with high
performance and low power consumption. A lot of research has been evolved to
enhance the performance of embedded processors through parallel computing. But
some of them focus superscalar processors i.e. single processors with more
resources like Instruction Level Parallelism (ILP) which includes Very Long
Instruction Word (VLIW) architecture, custom instruction set extensible
processor architecture and others require more number of processing units on a
single chip like Thread Level Parallelism (TLP) that includes Simultaneous
Multithreading (SMT), Chip Multithreading (CMT) and Chip Multiprocessing (CMP).
In this paper, we present a new technique, named C-slow, to enhance performance
for embedded processors for consumer electronics by exploiting multithreading
technique in single core processors. Without resulting into the complexity of
micro controlling with Real Time Operating system (RTOS), C-slowed processor
can execute multiple threads in parallel using single datapath of Instruction
Set processing element. This technique takes low area & approach complexity of
general purpose processor running RTOS.
"
265,"Effect of Thread Level Parallelism on the Performance of Optimum
  Architecture for Embedded Applications","  According to the increasing complexity of network application and internet
traffic, network processor as a subset of embedded processors have to process
more computation intensive tasks. By scaling down the feature size and emersion
of chip multiprocessors (CMP) that are usually multi-thread processors, the
performance requirements are somehow guaranteed. As multithread processors are
the heir of uni-thread processors and there isn't any general design flow to
design a multithread embedded processor, in this paper we perform a
comprehensive design space exploration for an optimum uni-thread embedded
processor based on the limited area and power budgets. Finally we run multiple
threads on this architecture to find out the maximum thread level parallelism
(TLP) based on performance per power and area optimum uni-thread architecture.
"
266,Performance-Optimum Superscalar Architecture for Embedded Applications,"  Embedded applications are widely used in portable devices such as wireless
phones, personal digital assistants, laptops, etc. High throughput and real
time requirements are especially important in such data-intensive tasks.
Therefore, architectures that provide the required performance are the most
desirable. On the other hand, processor performance is severely related to the
average memory access delay, number of processor registers and also size of the
instruction window and superscalar parameters. Therefore, cache, register file
and superscalar parameters are the major architectural concerns in designing a
superscalar architecture for embedded processors. Although increasing cache and
register file size leads to performance improvements in high performance
embedded processors, the increased area, power consumption and memory delay are
the overheads of these techniques. This paper explores the effect of cache,
register file and superscalar parameters on the processor performance to
specify the optimum size of these parameters for embedded applications.
Experimental results show that although having bigger size of these parameters
is one of the performance improvement approaches in embedded processors,
however, by increasing the size of some parameters over a threshold value,
performance improvement is saturated and especially in cache size, increments
over this threshold value decrease the performance.
"
267,"Reconfigurable computing for Monte Carlo simulations: results and
  prospects of the Janus project","  We describe Janus, a massively parallel FPGA-based computer optimized for the
simulation of spin glasses, theoretical models for the behavior of glassy
materials. FPGAs (as compared to GPUs or many-core processors) provide a
complementary approach to massively parallel computing. In particular, our
model problem is formulated in terms of binary variables, and floating-point
operations can be (almost) completely avoided. The FPGA architecture allows us
to run many independent threads with almost no latencies in memory access, thus
updating up to 1024 spins per cycle. We describe Janus in detail and we
summarize the physics results obtained in four years of operation of this
machine; we discuss two types of physics applications: long simulations on very
large systems (which try to mimic and provide understanding about the
experimental non-equilibrium dynamics), and low-temperature equilibrium
simulations using an artificial parallel tempering dynamics. The time scale of
our non-equilibrium simulations spans eleven orders of magnitude (from
picoseconds to a tenth of a second). On the other hand, our equilibrium
simulations are unprecedented both because of the low temperatures reached and
for the large systems that we have brought to equilibrium. A finite-time
scaling ansatz emerges from the detailed comparison of the two sets of
simulations. Janus has made it possible to perform spin-glass simulations that
would take several decades on more conventional architectures. The paper ends
with an assessment of the potential of possible future versions of the Janus
architecture, based on state-of-the-art technology.
"
268,"Reversible Programmable Logic Array (RPLA) using Feynman & MUX Gates for
  Low Power Industrial Applications","  This paper present the research work directed towards the design of
reversible programmable logic array using very high speed integrated circuit
hardware description language (VHDL). Reversible logic circuits have
significant importance in bioinformatics, optical information processing, CMOS
design etc. In this paper the authors propose the design of new RPLA using
Feynman & MUX gate.VHDL based codes of reversible gates with simulating results
are shown .This proposed RPLA may be further used to design any reversible
logic function or Boolean function (Adder, subtractor etc.) which dissipate
very low or ideally no heat.
"
269,Mppsocgen: A framework for automatic generation of mppsoc architecture,"  Automatic code generation is a standard method in software engineering since
it improves the code consistency and reduces the overall development time. In
this context, this paper presents a design flow for automatic VHDL code
generation of mppSoC (massively parallel processing System-on-Chip)
configuration. Indeed, depending on the application requirements, a framework
of Netbeans Platform Software Tool named MppSoCGEN was developed in order to
accelerate the design process of complex mppSoC. Starting from an architecture
parameters design, VHDL code will be automatically generated using parsing
method. Configuration rules are proposed to have a correct and valid VHDL
syntax configuration. Finally, an automatic generation of Processor Elements
and network topologies models of mppSoC architecture will be done for Stratix
II device family. Our framework improves its flexibility on Netbeans 5.5
version and centrino duo Core 2GHz with 22 Kbytes and 3 seconds average
runtime. Experimental results for reduction algorithm validate our MppSoCGEN
design flow and demonstrate the efficiency of generated architectures.
"
270,"A simple 1-byte 1-clock RC4 design and its efficient implementation in
  FPGA coprocessor for secured ethernet communication","  In the field of cryptography till date the 1-byte in 1-clock is the best
known RC4 hardware design [1], while the 1-byte in 3clocks is the best known
implementation [2,3]. The design algorithm in [1] considers two consecutive
bytes together and processes them in 2 clocks. The design of 1-byte in 3-clocks
is too much modular and clock hungry. In this paper considering the RC4
algorithm, as it is, a simpler RC4 hardware design providing higher throughput
is proposed in which 1-byte is processed in 1-clock. In the design two
sequential tasks are executed as two independent events during rising and
falling edges of the same clock and the swapping is directly executed using a
MUX-DEMUX combination. The power consumed in behavioral and structural designs
of RC4 are estimated and a power optimization technique is proposed. The NIST
statistical test suite is run on RC4 key streams in order to know its
randomness property. The encryption and decryption designs are respectively
embedded on two FPGA boards with RC4 in a custom coprocessor followed by
Ethernet communication.
"
271,Wishbone bus Architecture - A Survey and Comparison,"  The performance of an on-chip interconnection architecture used for
communication between IP cores depends on the efficiency of its bus
architecture. Any bus architecture having advantages of faster bus clock speed,
extra data transfer cycle, improved bus width and throughput is highly
desirable for a low cost, reduced time-to-market and efficient System-on-Chip
(SoC). This paper presents a survey of WISHBONE bus architecture and its
comparison with three other on-chip bus architectures viz. Advanced Micro
controller Bus Architecture (AMBA) by ARM, CoreConnect by IBM and Avalon by
Altera. The WISHBONE Bus Architecture by Silicore Corporation appears to be
gaining an upper edge over the other three bus architecture types because of
its special performance parameters like the use of flexible arbitration scheme
and additional data transfer cycle (Read-Modify-Write cycle). Moreover, its IP
Cores are available free for use requiring neither any registration nor any
agreement or license.
"
272,Microcontroller Based Testing of Digital IP-Core,"  Testing core based System on Chip is a challenge for the test engineers. To
test the complete SOC at one time with maximum fault coverage, test engineers
prefer to test each IP-core separately. At speed testing using external testers
is more expensive because of gigahertz processor. The purpose of this paper is
to develop cost efficient and flexible test methodology for testing digital
IP-cores . The prominent feature of the approach is to use microcontroller to
test IP-core. The novel feature is that there is no need of test pattern
generator and output response analyzer as microcontroller performs the function
of both. This approach has various advantages such as at speed testing, low
cost, less area overhead and greater flexibility since most of the testing
process is based on software.
"
273,"Design Space Exploration to Find the Optimum Cache and Register File
  Size for Embedded Applications","  In the future, embedded processors must process more computation-intensive
network applications and internet traffic and packet-processing tasks become
heavier and sophisticated. Since the processor performance is severely related
to the average memory access delay and also the number of processor registers
affects the performance, cache and register file are two major parts in
designing embedded processor architecture. Although increasing cache and
register file size leads to performance improvement in embedded applications
and packet-processing tasks in high traffic networks with too much packets, the
increased area, power consumption and memory hierarchy delay are the overheads
of these techniques. Therefore, implementing these components in the optimum
size is of significant interest in the design of embedded processors. This
paper explores the effect of cache and register file size on the processor
performance to calculate the optimum size of these components for embedded
applications. Experimental results show that although having bigger cache and
register file is one of the performance improvement approaches in embedded
processors, however, by increasing the size of these parameters over a
threshold level, performance improvement is saturated and then, decreased.
"
274,"Design and implementation of real time AES-128 on real time operating
  system for multiple FPGA communication","  Security is the most important part in data communication system, where more
randomization in secret keys increases the security as well as complexity of
the cryptography algorithms. As a result in recent dates these algorithms are
compensating with enormous memory spaces and large execution time on hardware
platform. Field programmable gate arrays (FPGAs), provide one of the major
alternative in hardware platform scenario due to its reconfiguration nature,
low price and marketing speed. In FPGA based embedded system we can use
embedded processor to execute particular algorithm with the inclusion of a real
time operating System (RTOS), where threads may reduce resource utilization and
time consumption. A process in the runtime is separated in different smaller
tasks which are executed by the scheduler to meet the real time dead line using
RTOS. In this paper we demonstrate the design and implementation of a 128-bit
Advanced Encryption Standard (AES) both symmetric key encryption and decryption
algorithm by developing suitable hardware and software design on Xilinx
Spartan- 3E (XC3S500E-FG320) device using an Xilkernel RTOS, the implementation
has been tested successfully The system is optimized in terms of execution
speed and hardware utilization.
"
275,Relaxed Half-Stochastic Belief Propagation,"  Low-density parity-check codes are attractive for high throughput
applications because of their low decoding complexity per bit, but also because
all the codeword bits can be decoded in parallel. However, achieving this in a
circuit implementation is complicated by the number of wires required to
exchange messages between processing nodes. Decoding algorithms that exchange
binary messages are interesting for fully-parallel implementations because they
can reduce the number and the length of the wires, and increase logic density.
This paper introduces the Relaxed Half-Stochastic (RHS) decoding algorithm, a
binary message belief propagation (BP) algorithm that achieves a coding gain
comparable to the best known BP algorithms that use real-valued messages. We
derive the RHS algorithm by starting from the well-known Sum-Product algorithm,
and then derive a low-complexity version suitable for circuit implementation.
We present extensive simulation results on two standardized codes having
different rates and constructions, including low bit error rate results. These
simulations show that RHS can be an advantageous replacement for the existing
state-of-the-art decoding algorithms when targeting fully-parallel
implementations.
"
276,Investigating Warp Size Impact in GPUs,"  There are a number of design decisions that impact a GPU's performance. Among
such decisions deciding the right warp size can deeply influence the rest of
the design. Small warps reduce the performance penalty associated with branch
divergence at the expense of a reduction in memory coalescing. Large warps
enhance memory coalescing significantly but also increase branch divergence.
This leaves designers with two choices: use a small warps and invest in finding
new solutions to enhance coalescing or use large warps and address branch
divergence employing effective control-flow solutions. In this work our goal is
to investigate the answer to this question. We analyze warp size impact on
memory coalescing and branch divergence. We use our findings to study two
machines: a GPU using small warps but equipped with excellent memory coalescing
(SW+) and a GPU using large warps but employing an MIMD engine immune from
control-flow costs (LW+). Our evaluations show that building
coalescing-enhanced small warp GPUs is a better approach compared to pursuing a
control-flow enhanced large warp GPU.
"
277,"Architecture for real time continuous sorting on large width data volume
  for fpga based applications","  In engineering applications sorting is an important and widely studied
problem where execution speed and resources used for computation are of extreme
importance, especially if we think about real time data processing. Most of the
traditional sorting techniques compute the process after receiving all of the
data and hence the process needs large amount of resources for data storage.
So, suitable design strategy needs to be adopted if we wish to sort a large
amount of data in real time, which essential means higher speed of process
execution and utilization of fewer resources in most of the cases. This paper
proposes a single chip scalable architecture based on Field Programmable Gate
Array(FPGA), for a modified counting sort algorithm where data acquisition and
sorting is being done in real time scenario. Our design promises to work
efficiently, where data can be accepted in the run time scenario without any
need of prior storage of data and also the execution speed of our algorithm is
invariant to the length of the data stream. The proposed design is implemented
and verified on Spartan 3E(XC3S500E-FG320) FPGA system. The results prove that
our design is better in terms of some of the design parameters compared to the
existing research works.
"
278,RepTFD: Replay Based Transient Fault Detection,"  The advances in IC process make future chip multiprocessors (CMPs) more and
more vulnerable to transient faults. To detect transient faults, previous
core-level schemes provide redundancy for each core separately. As a result,
they may leave transient faults in the uncore parts, which consume over 50%
area of a modern CMP, escaped from detection. This paper proposes RepTFD, the
first core-level transient fault detection scheme with 100% coverage. Instead
of providing redundancy for each core separately, RepTFD provides redundancy
for a group of cores as a whole. To be specific, it replays the execution of
the checked group of cores on a redundant group of cores. Through comparing the
execution results between the two groups of cores, all malignant transient
faults can be caught. Moreover, RepTFD adopts a novel pending period based
record-replay approach, which can greatly reduce the number of execution orders
that need to be enforced in the replay-run. Hence, RepTFD brings only 4.76%
performance overhead in comparison to the normal execution without
fault-tolerance according to our experiments on the RTL design of an industrial
CMP named Godson-3. In addition, RepTFD only consumes about 0.83% area of
Godson-3, while needing only trivial modifications to existing components of
Godson-3.
"
279,DLS: Directoryless Shared Last-level Cache,"  Directory-based protocols have been the de facto solution for maintaining
cache coherence in shared-memory parallel systems comprising multi/many cores,
where each store instruction is eagerly made globally visible by invalidating
the private cache (PC) backups of other cores. Consequently, the directory not
only consumes large chip area, but also incurs considerable energy consumption
and performance degradation, due to the large number of Invalidation/Ack
messages transferred in the interconnection network and resulting network
congestion. In this paper, we reveal the interesting fact that the directory is
actually an unnecessary luxury for practical parallel systems. Because of
widely deployed software/hardware techniques involving instruction reordering,
most (if not all) parallel systems work under the weak consistency model, where
a remote store instruction is allowed to be invisible to a core before the next
synchronization of the core, instead of being made visible eagerly by
invalidating PC backups of other cores. Based on this key observation, we
propose a lightweight novel scheme called {\em DLS (DirectoryLess Shared
last-level cache)}, which completely removes the directory and Invalidation/Ack
messages, and efficiently maintains cache coherence using a novel {\em
self-suspicion + speculative execution} mechanism. Experimental results over
SPLASH-2 benchmarks show that on a 16-core processor, DLS not only completely
removes the chip area cost of the directory, but also improves processor
performance by 11.08%, reduces overall network traffic by 28.83%, and reduces
energy consumption of the network by 15.65% on average (compared with
traditional MESI protocol with full directory). Moreover, DLS does not involve
any modification to programming languages and compilers, and hence is
seamlessly compatible with legacy codes.
"
280,"The Necessity for Hardware QoS Support for Server Consolidation and
  Cloud Computing","  Chip multiprocessors (CMPs) are ubiquitous in most of today's computing
fields. Although they provide noticeable benefits in terms of performance, cost
and power efficiency, they also introduce some new issues. In this paper we
analyze how the interference from Virtual Private Servers running in other
cores is a significant component of performance unpredictability and can
threaten the attainment of cloud computing. Even if virtualization is used, the
sharing of the on-chip section of the memory hierarchy by different cores makes
performance isolation strongly dependent on what is running elsewhere in the
system. We will show in three actual computing systems, based on Sun UltraSparc
T1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art
virtualization techniques are unable to guarantee performance isolation in a
representative workload such as SPECweb2005. In an especially conceived near
worst-case scenario, it is possible to reduce the performance achieved by a
Solaris Zones consolidated server for this suite of benchmarks in a Sun Fire
T1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by
a Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%. For
all systems under study, off-chip bandwidth is shown to be the most critical
resource.
"
281,"Dynamic Priority Queue: An SDRAM Arbiter With Bounded Access Latencies
  for Tight WCET Calculation","  This report introduces a shared resource arbitration scheme ""DPQ - Dynamic
Priority Queue"" which provides bandwidth guarantees and low worst case latency
to each master in an MPSoC. Being a non-trivial candidate for timing analysis,
SDRAM has been chosen as a showcase, but the approach is valid for any shared
resource arbitration.
  Due to its significant cost, data rate and physical size advantages, SDRAM is
a potential candidate for cost sensitive, safety critical and space conserving
systems. The variable access latency is a major drawback of SDRAM that induces
largely over estimated Worst Case Execution Time (WCET) bounds of applications.
In this report we present the DPQ together with an algorithm to predict the
shared SDRAM's worst case latencies. We use the approach to calculate WCET
bounds of six hardware tasks executing on an Altera Cyclone III FPGA with
shared DDR2 memory. The results show that the DPQ is a fair arbitration scheme
and produces low WCET bounds.
"
282,Design and Development of Low Cost Multi-Channel USB Data,"  This paper describes the design and development of low cost USB Data
Acquisition System (DAS) for the measurement of physical parameters. Physical
parameters such as temperature, humidity, light intensity etc., which are
generally slowly varying signals are sensed by respective sensors or integrated
sensors and converted into voltages. The DAS is designed using PIC18F4550
microcontroller, communicating with Personal Computer (PC) through USB
(Universal Serial Bus). The designed DAS has been tested with the application
program developed in Visual Basic, which allows online monitoring in graphical
as well as numerical display.
"
283,"Design of PIC12F675 Microcontroller Based Data Acquisition System for
  Slowly Varying Signals","  The present paper describes the design of a cost effective, better resolution
data acquisition system (DAS) which is compatible to most of the PC and
laptops. A low cost DAS has been designed using PIC12F675 having 4-channel
analog input with 10-bit resolution for the monitoring of slowly varying
signals. The DAS so designed is interfaced to the serial port of the PC.
Firmware is written in Basic using Oshonsoft PIC IDE and burn to the
microcontroller by using PICkit2 programmer. An application program is also
developed using Visual Basic 6 which allows to display the waveform of the
signal(s) and simultaneously the data also can be saved into the hard disk of
the computer for future use and analysis.
"
284,"Low Cost PC Based Real Time Data Logging System Using PCs Parallel Port
  For Slowly Varying Signals","  A low cost PC based real time data logging system can be used in the
laboratories for the measurement, monitoring and storage of the data for slowly
varying signals in science and engineering stream. This can be designed and
interfaced to the PCs Parallel Port, which is common to all desktop computers
or Personal Computers (PCs). By the use of this data logging system one can
monitor, measure and store data for slowly varying signals, which is hard to
visualise the signal waveforms by ordinary CRO (Cathode Ray Oscilloscope) and
DSO (Digital Storage Oscilloscope). The data so stored can be used for further
study and analysis. It can be used for a wide range of applications to monitor
and store data of temperature, humidity, light intensity, ECG signals etc. with
proper signal conditioning circuitry.
"
285,"Design and Performance Analysis of hybrid adders for high speed
  arithmetic circuit","  Adder cells using Gate Diffusion Technique (GDI) & PTL-GDI technique are
described in this paper. GDI technique allows reducing power consumption,
propagation delay and low PDP (power delay product) whereas Pass Transistor
Logic (PTL) reduces the count of transistors used to make different logic
gates, by eliminating redundant transistors. Performance comparison with
various Hybrid Adder is been presented. In this paper, we propose two new
designs based on GDI & PTL techniques, which is found to be much more power
efficient in comparison with existing design technique. Only 10 transistors are
used to implement the SUM & CARRY function for both the designs. The SUM and
CARRY cell are implemented in a cascaded way i.e. firstly the XOR cell is
implemented and then using XOR as input SUM as well as CARRY cell is
implemented. For Proposed GDI adder the SUM as well as CARRY cell is designed
using GDI technique. On the other hand in Proposed PTL-GDI adder the SUM cell
is constructed using PTL technique and the CARRY cell is designed using GDI
technique. The advantages of both the designs are discussed. The significance
of these designs is substantiated by the simulation results obtained from
Cadence Virtuoso 180nm environment.
"
286,Ethernet Packet Processor for SoC Application,"  As the demand for Internet expands significantly in numbers of users,
servers, IP addresses, switches and routers, the IP based network architecture
must evolve and change. The design of domain specific processors that require
high performance, low power and high degree of programmability is the
bottleneck in many processor based applications. This paper describes the
design of ethernet packet processor for system-on-chip (SoC) which performs all
core packet processing functions, including segmentation and reassembly,
packetization classification, route and queue management which will speedup
switching/routing performance. Our design has been configured for use with
multiple projects ttargeted to a commercial configurable logic device the
system is designed to support 10/100/1000 links with a speed advantage. VHDL
has been used to implement and simulated the required functions in FPGA.
"
287,"Design and implementation of a digital clock showing digits in Bangla
  font using microcontroller AT89C4051","  In this paper, a digital clock is designed where the microcontroller is used
for timing controller and the font of the Bangla digits are designed, and
programmed within the microcontroller. The design is cost effective, simple and
easy for maintenance.
"
288,Dynamic Warp Resizing in High-Performance SIMT,"  Modern GPUs synchronize threads grouped in a warp at every instruction. These
results in improving SIMD efficiency and makes sharing fetch and decode
resources possible. The number of threads included in each warp (or warp size)
affects divergence, synchronization overhead and the efficiency of memory
access coalescing. Small warps reduce the performance penalty associated with
branch and memory divergence at the expense of a reduction in memory
coalescing. Large warps enhance memory coalescing significantly but also
increase branch and memory divergence. Dynamic workload behavior, including
branch/memory divergence and coalescing, is an important factor in determining
the warp size returning best performance. Optimal warp size can vary from one
workload to another or from one program phase to the next. Based on this
observation, we propose Dynamic Warp Resizing (DWR). DWR takes innovative
microarchitectural steps to adjust warp size during runtime and according to
program characteristics. DWR outperforms static warp size decisions, up to 1.7X
to 2.28X, while imposing less than 1% area overhead. We investigate various
alternative configurations and show that DWR performs better for narrower SIMD
and larger caches.
"
289,"A Hardware Time Manager Implementation for the Xenomai Real-Time Kernel
  of Embedded Linux","  Nowadays, the use of embedded operating systems in different embedded
projects is subject to a tremendous growth. Embedded Linux is becoming one of
those most popular EOSs due to its modularity, efficiency, reliability, and
cost. One way to make it hard real-time is to include a real-time kernel like
Xenomai. One of the key characteristics of a Real-Time Operating System (RTOS)
is its ability to meet execution time deadlines deterministically. So, the more
precise and flexible the time management can be, the better it can handle
efficiently the determinism for different embedded applications. RTOS time
precision is characterized by a specific periodic interrupt service controlled
by a software time manager. The smaller the period of the interrupt, the better
the precision of the RTOS, the more it overloads the CPU, and though reduces
the overall efficiency of the RTOS. In this paper, we propose to drastically
reduce these overheads by migrating the time management service of Xenomai into
a configurable hardware component to relieve the CPU. The hardware component is
implemented in a Field Programmable Gate Array coupled to the CPU. This work
was achieved in a Master degree project where students could apprehend many
fields of embedded systems: RTOS programming, hardware design, performance
evaluation, etc.
"
290,"A Cache Management Strategy to Replace Wear Leveling Techniques for
  Embedded Flash Memory","  Prices of NAND flash memories are falling drastically due to market growth
and fabrication process mastering while research efforts from a technological
point of view in terms of endurance and density are very active. NAND flash
memories are becoming the most important storage media in mobile computing and
tend to be less confined to this area. The major constraint of such a
technology is the limited number of possible erase operations per block which
tend to quickly provoke memory wear out. To cope with this issue,
state-of-the-art solutions implement wear leveling policies to level the wear
out of the memory and so increase its lifetime. These policies are integrated
into the Flash Translation Layer (FTL) and greatly contribute in decreasing the
write performance. In this paper, we propose to reduce the flash memory wear
out problem and improve its performance by absorbing the erase operations
throughout a dual cache system replacing FTL wear leveling and garbage
collection services. We justify this idea by proposing a first performance
evaluation of an exclusively cache based system for embedded flash memories.
Unlike wear leveling schemes, the proposed cache solution reduces the total
number of erase operations reported on the media by absorbing them in the cache
for workloads expressing a minimal global sequential rate.
"
291,Deadlock Recovery Technique in Bus Enhanced NoC Architecture,"  Increase in the speed of processors has led to crucial role of communication
in the performance of systems. As a result, routing is taken into consideration
as one of the most important subjects of the Network on Chip architecture.
Routing algorithms to deadlock avoidance prevent packets route completely based
on network traffic condition by means of restricting the route of packets. This
action leads to less performance especially in non-uniform traffic patterns. On
the other hand True Fully Adoptive Routing algorithm provides routing of
packets completely based on traffic condition. However, deadlock detection and
recovery mechanisms are needed to handle deadlocks. Use of global bus beside
NoC as a parallel supportive environment, provide platform to offer advantages
of both features of bus and NoC. This bus is useful for broadcast and multicast
operations, sending delay sensitive signals, system management and other
services. In this research, we use this bus as an escaping path for deadlock
recovery technique. According to simulation results, this bus is suitable
platform for deadlock recovery technique.
"
292,Recursive Descriptions of Polar Codes,"  Polar codes are recursive general concatenated codes. This property motivates
a recursive formalization of the known decoding algorithms: Successive
Cancellation, Successive Cancellation with Lists and Belief Propagation. Using
such description allows an easy development of these algorithms for arbitrary
polarizing kernels. Hardware architectures for these decoding algorithms are
also described in a recursive way, both for Arikan's standard polar codes and
for arbitrary polarizing kernels.
"
293,Emulating a large memory with a collection of small ones,"  Sequential computation is well understood but does not scale well with
current technology. Within the next decade, systems will contain large numbers
of processors with potentially thousands of processors per chip. Despite this,
many computational problems exhibit little or no parallelism and many existing
formulations are sequential. It is therefore essential that highly-parallel
architectures can support sequential computation by emulating large memories
with collections of smaller ones, thus supporting efficient execution of
sequential programs or sequential components of parallel programs.
  This paper demonstrates that a realistic parallel architecture with scalable
low-latency communications can execute large-memory sequential programs with a
factor of only 2 to 3 slowdown, when compared to a conventional sequential
architecture. This overhead seems an acceptable price to pay to be able to
switch between executing highly-parallel programs and sequential programs with
large memory requirements. Efficient emulation of large memories could
therefore facilitate a transition from sequential machines by allowing existing
programs to be compiled directly to a highly-parallel architecture and then for
their performance to be improved by exploiting parallelism in memory accesses
and computation.
"
294,"A Low-Power 9-bit Pipelined CMOS ADC with Amplifier and Comparator
  Sharing Technique","  This paper describes a pipelined analog-to-digital converter (ADC) employing
a power and area efficient architecture. The adjacent stages of a pipeline
share operational amplifiers. In order to keep accuracy of the amplifiers in
the first stages, they use a partially sharing technique. The feature of the
proposed scheme is that it also shares the comparators. The capacitors of the
first stages of a pipeline are scaled down along a pipeline for a further
reducing the chip area and its power consumption. A 9-bit 20-MSamples/s ADC,
intended for use in multi-channel mixed-signal chips, has been fabricated via
Europractice in a 180-nm CMOS process from UMC. The prototype ADC shows a
spurious-free dynamic range of 58.5 dB at a sample rate of 20 MSamples/s, when
a 400 kHz input signal with a swing of 1 dB below full scale is applied. The
effective number of bits is 8.0 at the same conditions. ADC occupies an active
area of 0.4 mm2 and dissipates 8.6 mW at a 1.8 V supply.
"
295,Design & Simulation of 128x Interpolator Filter,"  This paper presents the design consideration and simulation of interpolator
of OSR 128. The proposed structure uses the half band filers & Comb/Sinc
filter. Experimental result shows that proposed interpolator achieves the
design specification, and also has good noise rejection capabilities. The
interpolator accepts the input at 44.1 kHz for applications like CD & DVD
audio. The interpolation filter can be applied to the delta sigma DAC. The
related work is done with the MATLAB & XILINX ISE simulators. The maximum
operating frequency is achieved as 34.584 MHz.
"
296,"A Ternary Digital to Analog Converter with High Power Output and 170-dB
  Dynamic Range","  A prototype of a very high dynamic range 32-bits Digital to Analog Converter
(DAC) was designed and built for the purpose of direct auditory stimulus
generation. It provides signals from less than 100 nV up to 50 Watts peak power
output, driving a 32-Ohms earphone or speaker. The use of ternary cells makes
possible a 170 dB dynamic range that is basically limited by thermal noise
only.
"
297,"Design Of A Reconfigurable DSP Processor With Bit Efficient Residue
  Number System","  Residue Number System (RNS), which originates from the Chinese Remainder
Theorem, offers a promising future in VLSI because of its carry-free operations
in addition, subtraction and multiplication. This property of RNS is very
helpful to reduce the complexity of calculation in many applications. A residue
number system represents a large integer using a set of smaller integers,
called residues. But the area overhead, cost and speed not only depend on this
word length, but also the selection of moduli, which is a very crucial step for
residue system. This parameter determines bit efficiency, area, frequency etc.
In this paper a new moduli set selection technique is proposed to improve bit
efficiency which can be used to construct a residue system for digital signal
processing environment. Subsequently, it is theoretically proved and
illustrated using examples, that the proposed solution gives better results
than the schemes reported in the literature. The novelty of the architecture is
shown by comparison the different schemes reported in the literature. Using the
novel moduli set, a guideline for a Reconfigurable Processor is presented here
that can process some predefined functions. As RNS minimizes the carry
propagation, the scheme can be implemented in Real Time Signal Processing &
other fields where high speed computations are required.
"
298,Static Analysis of Lockless Microcontroller C Programs,"  Concurrently accessing shared data without locking is usually a subject to
race conditions resulting in inconsistent or corrupted data. However, there are
programs operating correctly without locking by exploiting the atomicity of
certain operations on a specific hardware. In this paper, we describe how to
precisely analyze lockless microcontroller C programs with interrupts by taking
the hardware architecture into account. We evaluate this technique in an
octagon-based value range analysis using access-based localization to increase
efficiency.
"
299,"Design and Implementation of Multistage Interconnection Networks for SoC
  Networks","  In this paper the focus is on a family of Interconnection Networks (INs)
known as Multistage Interconnection Networks (MINs). When it is exploited in
Network-on-Chip (NoC) architecture designs, smaller circuit area, lower power
consumption, less junctions and broader bandwidth can be achieved. Each MIN can
be considered as an alternative for an NoC architecture design for its simple
topology and easy scalability with low degree. This paper includes two major
contributions. First, it compares the performance of seven prominent MINs (i.e.
Omega, Butterfly, Flattened Butterfly, Flattened Baseline, Generalized Cube,
Bene\v{s} and Clos networks) based on 45nm-CMOS technology and under different
types of Synthetic and Trace-driven workloads. Second, a network called
Meta-Flattened Network (MFN), was introduced that can decrease the blocking
probability by means of reduction the number of hops and increase the
intermediate paths between stages. This is also led into significant decrease
in power consumption.
"
300,"Diametrical Mesh Of Tree (D2D-MoT) Architecture: A Novel Routing
  Solution For NoC","  Network-on-chip (NoC) is a new aspect for designing of future System-On-Chips
(SoC) where a vast number of IP cores are connected through interconnection
network. The communication between the nodes occurred by routing packets rather
than wires. It supports high degree of scalability, reusability and parallelism
in communication. In this paper, we present a Mesh routing architecture, which
is called Diametrical 2D Mesh of Tree, based on Mesh-of-Tree (MoT) routing and
Diametrical 2D Mesh. It has the advantage of having small diameter as well as
large bisection width and small node degree clubbed with being the fastest
network in terms of speed. The routing algorithm ensures that the packets will
always reach from source to sink through shortest path and is deadlock free.
"
301,"A brief experience on journey through hardware developments for image
  processing and its applications on Cryptography","  The importance of embedded applications on image and video
processing,communication and cryptography domain has been taking a larger space
in current research era. Improvement of pictorial information for betterment of
human perception like deblurring, de-noising in several fields such as
satellite imaging, medical imaging etc are renewed research thrust.
Specifically we would like to elaborate our experience on the significance of
computer vision as one of the domains where hardware implemented algorithms
perform far better than those implemented through software. So far embedded
design engineers have successfully implemented their designs by means of
Application Specific Integrated Circuits (ASICs) and/or Digital Signal
Processors (DSP), however with the advancement of VLSI technology a very
powerful hardware device namely the Field Programmable Gate Array (FPGA)
combining the key advantages of ASICs and DSPs was developed which have the
possibility of reprogramming making them a very attractive device for rapid
prototyping.Communication of image and video data in multiple FPGA is no longer
far away from the thrust of secured transmission among them, and then the
relevance of cryptography is indeed unavoidable. This paper shows how the
Xilinx hardware development platform as well Mathworks Matlab can be used to
develop hardware based computer vision algorithms and its corresponding crypto
transmission channel between multiple FPGA platform from a system level
approach, making it favourable for developing a hardware-software co-design
environment.
"
302,MIMS: Towards a Message Interface based Memory System,"  Memory system is often the main bottleneck in chipmultiprocessor (CMP)
systems in terms of latency, bandwidth and efficiency, and recently
additionally facing capacity and power problems in an era of big data. A lot of
research works have been done to address part of these problems, such as
photonics technology for bandwidth, 3D stacking for capacity, and NVM for power
as well as many micro-architecture level innovations. Many of them need a
modification of current memory architecture, since the decades-old synchronous
memory architecture (SDRAM) has become an obstacle to adopt those advances.
However, to the best of our knowledge, none of them is able to provide a
universal memory interface that is scalable enough to cover all these problems.
  In this paper, we argue that a message-based interface should be adopted to
replace the traditional bus-based interface in memory system. A novel message
interface based memory system (MIMS) is proposed. The key innovation of MIMS is
that processor and memory system communicate through a universal and flexible
message interface. Each message packet could contain multiple memory requests
or commands along with various semantic information. The memory system is more
intelligent and active by equipping with a local buffer scheduler, which is
responsible to process packet, schedule memory requests, and execute specific
commands with the help of semantic information. The experimental results by
simulator show that, with accurate granularity message, the MIMS would improve
performance by 53.21%, while reducing energy delay product (EDP) by 55.90%, the
effective bandwidth utilization is improving by 62.42%. Furthermore, combining
multiple requests in a packet would reduce link overhead and provide
opportunity for address compression.
"
303,A joint communication and application simulator for NoC-based SoCs,"  NoCs have become a widespread paradigm in the system-on-chip design world,
not only for multi-purpose SoCs, but also for application-specific ICs. The
common approach in the NoC design world is to separate the design of the
interconnection from the design of the processing elements: this is well suited
for a large number of developments, but the need for joint application and NoC
design is not uncommon, especially in the application specific case. The
correlation between processing and communication tasks can be strong, and
separate or trace-based simulations fall often short of the desired precision.
In this work, the OMNET++ based JANoCS simulator is presented: concurrent
simulation of processing and communication allow cycle-accurate evaluation of
the system. Two cases of study are presented, showing both the need for joint
simulations and the effectiveness of JANoCS.
"
304,"Reconfiguration Strategies for Online Hardware Multitasking in Embedded
  Systems","  An intensive use of reconfigurable hardware is expected in future embedded
systems. This means that the system has to decide which tasks are more suitable
for hardware execution. In order to make an efficient use of the FPGA it is
convenient to choose one that allows hardware multitasking, which is
implemented by using partial dynamic reconfiguration. One of the challenges for
hardware multitasking in embedded systems is the online management of the only
reconfiguration port of present FPGA devices. This paper presents different
online reconfiguration scheduling strategies which assign the reconfiguration
interface resource using different criteria: workload distribution or task
deadline. The online scheduling strategies presented take efficient and fast
decisions based on the information available at each moment. Experiments have
been made in order to analyze the performance and convenience of these
reconfiguration strategies.
"
305,"Performance Evaluation of Sparse Matrix Multiplication Kernels on Intel
  Xeon Phi","  Intel Xeon Phi is a recently released high-performance coprocessor which
features 61 cores each supporting 4 hardware threads with 512-bit wide SIMD
registers achieving a peak theoretical performance of 1Tflop/s in double
precision. Many scientific applications involve operations on large sparse
matrices such as linear solvers, eigensolver, and graph mining algorithms. The
core of most of these applications involves the multiplication of a large,
sparse matrix with a dense vector (SpMV). In this paper, we investigate the
performance of the Xeon Phi coprocessor for SpMV. We first provide a
comprehensive introduction to this new architecture and analyze its peak
performance with a number of micro benchmarks. Although the design of a Xeon
Phi core is not much different than those of the cores in modern processors,
its large number of cores and hyperthreading capability allow many application
to saturate the available memory bandwidth, which is not the case for many
cutting-edge processors. Yet, our performance studies show that it is the
memory latency not the bandwidth which creates a bottleneck for SpMV on this
architecture. Finally, our experiments show that Xeon Phi's sparse kernel
performance is very promising and even better than that of cutting-edge general
purpose processors and GPUs.
"
306,MGSim - Simulation tools for multi-core processor architectures,"  MGSim is an open source discrete event simulator for on-chip hardware
components, developed at the University of Amsterdam. It is intended to be a
research and teaching vehicle to study the fine-grained hardware/software
interactions on many-core and hardware multithreaded processors. It includes
support for core models with different instruction sets, a configurable
multi-core interconnect, multiple configurable cache and memory models, a
dedicated I/O subsystem, and comprehensive monitoring and interaction
facilities. The default model configuration shipped with MGSim implements
Microgrids, a many-core architecture with hardware concurrency management.
MGSim is furthermore written mostly in C++ and uses object classes to represent
chip components. It is optimized for architecture models that can be described
as process networks.
"
307,"Reduction in Packet Delay Through the use of Common Buffer over
  Distributed Buffer in the Routing Node of NOC Architecture","  Performance evaluation of the routing node in terms of latency is the
characteristics of an efficient design of Buffer in input module. It is
intended to study and quantify the behavior of the single packet array design
in relation to the multiple packet array design. The utilization efficiency of
the packet buffer array improves when a common buffer is used instead of
individual buffers in each input port. First Poissons Queuing model was
prepared to manifest the differences in packet delays. The queuing model can be
classified as (M/M/1), (32/FIFO). Arrival rate has been assumed to be Poisson
distributed with a mean arrival rate of 10 x 1000000. The service rate is
assumed to be exponentially distributed with a mean service rate of 10.05 x
1000000. It has been observed that latency in Common Buffer improved by 46
percent over its distributed buffer. A Simulink model later simulated on MATLAB
to calculate the improvement in packet delay. It has been observed that the
delay improved by approximately 40 percent through the use of a common buffer.
A verilog RTL for both common and shared buffer has been prepared and later
synthesized using Design Compiler of SYNOPSYS. In distributed buffer, arrival
of data packet could be delayed by 2 or 4 clock cycles which lead to latency
improvement either by 17 percent or 34 percent in a common buffer
"
308,"A Low-Power Content-Addressable-Memory Based on
  Clustered-Sparse-Networks","  A low-power Content-Addressable-Memory (CAM) is introduced employing a new
mechanism for associativity between the input tags and the corresponding
address of the output data. The proposed architecture is based on a recently
developed clustered-sparse-network using binary-weighted connections that
on-average will eliminate most of the parallel comparisons performed during a
search. Therefore, the dynamic energy consumption of the proposed design is
significantly lower compared to that of a conventional low-power CAM design.
Given an input tag, the proposed architecture computes a few possibilities for
the location of the matched tag and performs the comparisons on them to locate
a single valid match. A 0.13 um CMOS technology was used for simulation
purposes. The energy consumption and the search delay of the proposed design
are 9.5%, and 30.4% of that of the conventional NAND architecture respectively
with a 3.4% higher number of transistors.
"
309,Dynamic Power Reduction in a Novel CMOS 5T-SRAM for Low-Power SoC,"  This paper addresses a novel five-transistor (5T) CMOS SRAM design with high
performance and reliability in 65nm CMOS, and illustrates how it reduces the
dynamic power consumption in comparison with the conventional and low-power 6T
SRAM counterparts. This design can be used as cache memory in processors and
low-power portable devices. The proposed SRAM cell features ~13% area reduction
compared to a conventional 6T cell, and features a unique bit-line and negative
supply voltage biasing methodology and ground control architecture to enhance
performance, and suppress standby leakage power.
"
310,Hybrid Crossbar Architecture for a Memristor Based Memory,"  This paper describes a new memristor crossbar architecture that is proposed
for use in a high density cache design. This design has less than 10% of the
write energy consumption than a simple memristor crossbar. Also, it has up to 4
times the bit density of an STT-MRAM system and up to 11 times the bit density
of an SRAM architecture. The proposed architecture is analyzed using a detailed
SPICE analysis that accounts for the resistance of the wires in the memristor
structure. Additionally, the memristor model used in this work has been matched
to specific device characterization data to provide accurate results in terms
of energy, area, and timing.
"
311,Using Virtual Addresses with Communication Channels,"  While for single processor and SMP machines, memory is the allocatable
quantity, for machines made up of large amounts of parallel computing units,
each with its own local memory, the allocatable quantity is a single computing
unit. Where virtual address management is used to keep memory coherent and
allow allocation of more than physical memory is actually available, virtual
communication channel references can be used to make computing units stay
connected across allocation and swapping.
"
312,An efficient cntfet-based 7-input minority gate,"  Complementary metal oxide semiconductor technology (CMOS) has been faced
critical challenges in nano-scale regime. CNTFET (Carbon Nanotube Field effect
transistor) technology is a promising alternative for CMOS technology. In this
paper, we proposed a novel 7-input minority gate in CNTFET technology that has
only 9 CNTFETs. Minority function is utilized in the voting systems for
decision making and also it is used in data mining. This proposed 7-input
minority gate is utilized less fewer transistors than the conventional CMOS
method which utilizes many transistors for implementing sum of products. By
means of this proposed 7-input minority gate, a 4-input NAND gate can be
implemented, which gets better the conventional design in terms of delay and
energy efficiency and has much more deriving power at its output.
"
313,"On whether and how D-RISC and Microgrids can be kept relevant
  (self-assessment report)","  This report lays flat my personal views on D-RISC and Microgrids as of March
2013. It reflects the opinions and insights that I have gained from working on
this project during the period 2008-2013. This report is structed in two parts:
deconstruction and reconstruction. In the deconstruction phase, I review what I
believe are the fundamental motivation and goals of the D-RISC/Microgrids
enterprise, and identify what I judge are shortcomings: that the project did
not deliver on its expectations, that fundamental questions are left
unanswered, and that its original motivation may not even be relevant in
scientific research any more in this day and age. In the reconstruction phase,
I start by identifying the merits of the current D-RISC/Microgrids technology
and know-how taken at face value, re-motivate its existence from a different
angle, and suggest new, relevant research questions that could justify
continued scientific investment.
"
314,FreeIMU: An Open Hardware Framework for Orientation and Motion Sensing,"  Orientation and Motion Sensing are widely implemented on various consumer
products, such as mobile phones, tablets and cameras as they enable immediate
interaction with virtual information. The prototyping phase of any orientation
and motion sensing capable device is however a quite difficult process as it
may involve complex hardware designing, math algorithms and programming.
  In this paper, we present FreeIMU, an Open Hardware Framework for prototyping
orientation and motion sensing capable devices. The framework consists in a
small circuit board containing various sensors and a software library, built on
top of the Arduino platform. Both the hardware and library are released under
open licences and supported by an active community allowing to be implemented
into research and commercial projects.
"
315,Object-oriented approach to Rapid Custom Instruction design,"  Due to continuous evolution of Systems-on-Chip (SoC), the complexity of their
design and development has augmented exponentially. To deal with the
ever-growing complexity of such embedded systems, we introduce, in this paper,
an object-oriented approach to rapid SoC design using auto-generation of
hardware custom instructions to simplify and accelerate the SoC design process.
In our approach, a Data Flow Graph (DFG) is adopted as a representation of the
arithmetic operation to convert it to a custom instruction. Then VHDL code will
be automatically generated. The input C code is automatically updated for
calling the new hardware components. To prove the effectiveness of the proposed
approach, a Java source code framework named Automatic Custom Architecture
generator (ACAgen) is developed. Experimental results on 3D sample application
validate our approach and demonstrate how the proposed framework facilitates
and accelerates the SoC design process at low costs.
"
316,A Fast Improved Fat Tree Encoder for Wave Union TDC in an FPGA,"  Up to the present, the wave union method can achieve the best timing
performance in FPGA based TDC designs. However, it should be guaranteed in such
a structure that the non-thermometer code to binary code (NTH2B) encoding
process should be finished within just one system clock cycle. So the
implementation of the NTH2B encoder is quite challenging considering the high
speed requirement. Besides, the high resolution wave union TDC also demands the
encoder to convert an ultra-wide input code to a binary code. We present a fast
improved fat tree encoder (IFTE) to fulfill such requirements, in which bubble
error suppression is also integrated. With this encoder scheme, a wave union
TDC with 7.7 ps RMS and 3.8 ps effective bin size was implemented in an FPGA
from Xilinx Virtex 5 family. An encoding time of 8.33 ns was achieved for a
276-bit non-thermometer code to a 9-bit binary code conversion. We conducted a
series of tests on the oscillating period of the wave union launcher, as well
as the overall performance of the TDC; test results indicate that the IFTE
works well. In fact, in the implementation of this encoder, no manual routing
or special constrains were required; therefore, this IFTE structure could also
be further applied in other delay chain based FPGA TDCs.
"
317,Hardware Architecture for List SC Decoding of Polar Codes,"  We present a hardware architecture and algorithmic improvements for list SC
decoding of polar codes. More specifically, we show how to completely avoid
copying of the likelihoods, which is algorithmically the most cumbersome part
of list SC decoding. The hardware architecture was synthesized for a
blocklength of N = 1024 bits and list sizes L = 2, 4 using a UMC 90nm VLSI
technology. The resulting decoder can achieve a coded throughput of 181 Mbps at
a frequency of 459 MHz.
"
318,Improved Analytical Delay Models for RC-Coupled Interconnects,"  As the process technologies scale into deep submicron region, crosstalk delay
is becoming increasingly severe, especially for global on-chip buses. To cope
with this problem, accurate delay models of coupled interconnects are needed.
In particular, delay models based on analytical approaches are desirable,
because they not only are largely transparent to technology, but also
explicitly establish the connections between delays of coupled interconnects
and transition patterns, thereby enabling crosstalk alleviating techniques such
as crosstalk avoidance codes (CACs). Unfortunately, existing analytical delay
models, such as the widely cited model in [1], have limited accuracy and do not
account for loading capacitance. In this paper, we propose analytical delay
models for coupled interconnects that address these disadvantages. By
accounting for more wires and eschewing the Elmore delay, our delay models
achieve better accuracy than the model in [1].
"
319,An Improved GEF Fast Addition Algorithm,"  In this paper, an improved GEF fast addition algorithm is proposed. The
proposed algorithm reduces time and memory space. In this algorithm, carry is
calculated on the basis of arrival timing of the operand's bits without
overhead of sorting. Intermediate terms are generated from the most significant
bit and the carry is generated from the least significant bit using the
functions of efficient operators. This algorithm shows better performance for
use in the fastest computational devices of the near future.
"
320,Open Tiled Manycore System-on-Chip,"  Manycore System-on-Chip include an increasing amount of processing elements
and have become an important research topic for improvements of both hardware
and software. While research can be conducted using system simulators,
prototyping requires a variety of components and is very time consuming. With
the Open Tiled Manycore System-on-Chip (OpTiMSoC) we aim at building such an
environment for use in our and other research projects as prototyping platform.
  This paper describes the project goals and aspects of OpTiMSoC and summarizes
the current status and ideas.
"
321,Hardware Implementation of Algorithm for Cryptanalysis,"  Cryptanalysis of block ciphers involves massive computations which are
independent of each other and can be instantiated simultaneously so that the
solution space is explored at a faster rate. With the advent of low cost Field
Programmable Gate Arrays, building special purpose hardware for computationally
intensive applications has now become possible. For this the Data Encryption
Standard is used as a proof of concept. This paper presents the design for
Hardware implementation of DES cryptanalysis on FPGA using exhaustive key
search. Two architectures viz. Rolled and Unrolled DES architecture are
compared and based on experimental result the Rolled architecture is
implemented on FPGA. The aim of this work is to make cryptanalysis faster and
better.
"
322,Abstract Stobjs and Their Application to ISA Modeling,"  We introduce a new ACL2 feature, the abstract stobj, and show how to apply it
to modeling the instruction set architecture of a microprocessor. Benefits of
abstract stobjs over traditional (""concrete"") stobjs can include faster
execution, support for symbolic simulation, more efficient reasoning, and
resilience of proof developments under modeling optimization.
"
323,A formalisation of XMAS,"  Communication fabrics play a key role in the correctness and performance of
modern multi-core processors and systems-on-chip. To enable formal
verification, a recent trend is to use high-level micro-architectural models to
capture designers' intent about the communication and processing of messages.
Intel proposed the xMAS language to support the formal definition of executable
specifications of micro-architectures. We formalise the semantics of xMAS in
ACL2. Our formalisation represents the computation of the values of all wires
of a design. Our main function computes a set of possible routing targets for
each message and whether a message can make progress according to the current
network state. We prove several properties on the semantics, including
termination, non-emptiness of routing, and correctness of progress conditions.
Our current effort focuses on a basic subset of the entire xMAS language, which
includes queues, functions, and switches.
"
324,A 2.0 Gb/s Throughput Decoder for QC-LDPC Convolutional Codes,"  This paper propose a decoder architecture for low-density parity-check
convolutional code (LDPCCC). Specifically, the LDPCCC is derived from a
quasi-cyclic (QC) LDPC block code. By making use of the quasi-cyclic structure,
the proposed LDPCCC decoder adopts a dynamic message storage in the memory and
uses a simple address controller. The decoder efficiently combines the memories
in the pipelining processors into a large memory block so as to take advantage
of the data-width of the embedded memory in a modern field-programmable gate
array (FPGA). A rate-5/6 QC-LDPCCC has been implemented on an Altera Stratix
FPGA. It achieves up to 2.0 Gb/s throughput with a clock frequency of 100 MHz.
Moreover, the decoder displays an excellent error performance of lower than
$10^{-13}$ at a bit-energy-to-noise-power-spectral-density ratio ($E_b/N_0$) of
3.55 dB.
"
325,"EURETILE 2010-2012 summary: first three years of activity of the
  European Reference Tiled Experiment","  This is the summary of first three years of activity of the EURETILE FP7
project 247846. EURETILE investigates and implements brain-inspired and
fault-tolerant foundational innovations to the system architecture of massively
parallel tiled computer architectures and the corresponding programming
paradigm. The execution targets are a many-tile HW platform, and a many-tile
simulator. A set of SW process - HW tile mapping candidates is generated by the
holistic SW tool-chain using a combination of analytic and bio-inspired
methods. The Hardware dependent Software is then generated, providing OS
services with maximum efficiency/minimal overhead. The many-tile simulator
collects profiling data, closing the loop of the SW tool chain. Fine-grain
parallelism inside processes is exploited by optimized intra-tile compilation
techniques, but the project focus is above the level of the elementary tile.
The elementary HW tile is a multi-processor, which includes a fault tolerant
Distributed Network Processor (for inter-tile communication) and ASIP
accelerators. Furthermore, EURETILE investigates and implements the innovations
for equipping the elementary HW tile with high-bandwidth, low-latency
brain-like inter-tile communication emulating 3 levels of connection hierarchy,
namely neural columns, cortical areas and cortex, and develops a dedicated
cortical simulation benchmark: DPSNN-STDP (Distributed Polychronous Spiking
Neural Net with synaptic Spiking Time Dependent Plasticity). EURETILE leverages
on the multi-tile HW paradigm and SW tool-chain developed by the FET-ACA SHAPES
Integrated Project (2006-2009).
"
326,Phase-Priority based Directory Coherence for Multicore Processor,"  As the number of cores in a single chip increases, a typical implementation
of coherence protocol adds significant hardware and complexity overhead.
Besides, the performance of CMP system depends on the data access latency,
which is highly affected by coherence protocol and on-chip interconnect. In
this paper, we propose PPB (Phase-Priority Based) cache coherence protocol, an
optimization of modern directory coherence protocol. We take advantage of the
observation that transient states occur in directory coherence protocol,
resulting in some unnecessary transient states and stalling. PPB cache
coherence protocol decouples a coherence transaction and introduces the idea of
phase message. This phase is considered as the priority of the message.
Additionally, we also add new priority-based arbitrators in on-chip network to
support PPB cache coherence protocol. This mechanism in on-chip network can
support effective cache access, which makes the on-chip network more efficient.
Our analysis on an execution-driven full system simulator using SPLASH-2
benchmark shows that PPB cache coherence outperforms a MESI based directory,
and the number of unnecessary transient states and stalling reduces up to 24%.
Also it reported the speedup of 7.4%. Other advantages of this strategy are
reduced delay of flits and significantly less energy consumption in on-chip
network.
"
327,"A Novel Reconfigurable Architecture of a DSP Processor for Efficient
  Mapping of DSP Functions using Field Programmable DSP Arrays","  Development of modern integrated circuit technologies makes it feasible to
develop cheaper, faster and smaller special purpose signal processing function
circuits. Digital Signal processing functions are generally implemented either
on ASICs with inflexibility, or on FPGAs with bottlenecks of relatively smaller
utilization factor or lower speed compared to ASIC. Field Programmable DSP
Array (FPDA) is the proposed DSP dedicated device, redolent to FPGA, but with
basic fixed common modules (CMs) (like adders, subtractors, multipliers,
scaling units, shifters) instead of CLBs. This paper introduces the development
of reconfigurable system architecture with a focus on FPDA that integrates
different DSP functions like DFT, FFT, DCT, FIR, IIR, and DWT etc. The
switching between DSP functions is occurred by reconfiguring the
interconnection between CMs. Validation of the proposed architecture has been
achieved on Virtex5 FPGA. The architecture provides sufficient amount of
flexibility, parallelism and scalability.
"
328,An Improved Structure Of Reversible Adder And Subtractor,"  In today's world everyday a new technology which is faster, smaller and more
complex than its predecessor is being developed. The increased number of
transistors packed onto a chip of a conventional system results in increased
power consumption that is why Reversible logic has drawn attention of
Researchers due to its less heat dissipating characteristics. Reversible logic
can be imposed over applications such as quantum computing, optical computing,
quantum dot cellular automata, low power VLSI circuits, DNA computing. This
paper presents the reversible combinational circuit of adder, subtractor and
parity preserving subtractor. The suggested circuit in this paper are designed
using Feynman, Double Feynman and MUX gates which are better than the existing
one in literature in terms of Quantum cost, Garbage output and Total logical
calculations.
"
329,"Performance Evaluation of Low Power MIPS Crypto Processor based on
  Cryptography Algorithms","  This paper presents the design and implementation of low power 32-bit
encrypted and decrypted MIPS processor for Data Encryption Standard (DES),
Triple DES, Advanced Encryption Standard (AES) based on MIPS pipeline
architecture. The organization of pipeline stages has been done in such a way
that pipeline can be clocked at high frequency. Encryption and Decryption
blocks of three standard cryptography algorithms on MIPS processor and
dependency among themselves are explained in detail with the help of a block
diagram. Clock gating technique is used to reduce the power consumption in MIPS
crypto processor. This approach results in processor that meets power
consumption and performance specification for security applications. Proposed
Implementation approach concludes higher system performance while reducing
operating power consumption. Testing results shows that the MIPS crypto
processor operates successfully at a working frequency of 218MHz and a
bandwidth of 664Mbits/s.
"
330,"Computer Architecture with Associative Processor Replacing Last Level
  Cache and SIMD Accelerator","  This study presents a novel computer architecture where a last level cache
and a SIMD accelerator are replaced by an Associative Processor. Associative
Processor combines data storage and data processing and provides parallel
computational capabilities and data memory at the same time. An analytic
performance model of the new computer architecture is introduced. Comparative
analysis supported by simulation shows that this novel architecture may
outperform a conventional architecture comprising a SIMD coprocessor and a
shared last level cache while consuming less power.
"
331,"The Effect of Communication and Synchronization on Amdahl Law in
  Multicore Systems","  This work analyses the effects of sequential-to-parallel synchronization and
inter-core communication on multicore performance, speedup and scaling. A
modification of Amdahl law is formulated, to reflect the finding that parallel
speedup is lower than originally predicted, due to these effects. In
applications with high inter-core communication requirements, the workload
should be executed on a small number of cores, and applications of high
sequential-to-parallel synchronization requirements may better be executed by
the sequential core, even when f, the Amdahl fraction of parallelization, is
very close to 1. To improve the scalability and performance speedup of a
multicore, it is as important to address the synchronization and connectivity
intensities of parallel algorithms as their parallelization factor.
"
332,A Wrapper of PCI Express with FIFO Interfaces based on FPGA,"  This paper proposes a PCI Express (PCIE) Wrapper core named PWrapper with
FIFO interfaces. Compared with other PCIE solutions, PWrapper has several
advantages such as flexibility, isolation of clock domain, etc. PWrapper is
implemented and verified on Vertex -5-FX70T which is a development board
provided by Xilinx Inc. Architecture of PWrapper and design of two key modules
are illustrated, which timing optimization methods have been adopted. Then we
explained the advantages and challenges of on-chip interfaces technology based
on FIFOs. The verification results show that PWrapper can achieve the speed of
1.8Gbps (Giga bits per second).
"
333,Dynamic Computing Random Access Memory,"  The present von Neumann computing paradigm involves a significant amount of
information transfer between a central processing unit (CPU) and memory, with
concomitant limitations in the actual execution speed. However, it has been
recently argued that a different form of computation, dubbed memcomputing
[Nature Physics, 9, 200-202 (2013)] and inspired by the operation of our brain,
can resolve the intrinsic limitations of present day architectures by allowing
for computing and storing of information on the same physical platform. Here we
show a simple and practical realization of memcomputing that utilizes
easy-to-build memcapacitive systems. We name this architecture Dynamic
Computing Random Access Memory (DCRAM). We show that DCRAM provides
massively-parallel and polymorphic digital logic, namely it allows for
different logic operations with the same architecture, by varying only the
control signals. In addition, by taking into account realistic parameters, its
energy expenditures can be as low as a few fJ per operation. DCRAM is fully
compatible with CMOS technology, can be realized with current fabrication
facilities, and therefore can really serve as an alternative to the present
computing technology.
"
334,"Marrying Many-core Accelerators and InfiniBand for a New Commodity
  Processor","  During the last 15 years, the supercomputing industry has been using
mass-produced, off-the-shelf components to build cluster computers. Such
components are not perfect for HPC purposes, but are cheap due to effect of
scale in their production. The coming exa-scale era changes the landscape:
exa-scale computers will contain components in quantities large enough to
justify their custom development and production.
  We propose a new heterogeneous processor, equipped with a network controller
and designed specifically for HPC. We then show how it can be used for
enterprise computing market, guaranteeing its widespread adoption and therefore
low production costs.
"
335,Power efficient carry propagate adder,"  Here we describe the design details and performance of proposed Carry
Propagate Adder based on GDI technique. GDI technique is power efficient
technique for designing digital circuit that consumes less power as compare to
most commonly used CMOS technique. GDI also has an advantage of minimum
propagation delay, minimum area required and less complexity for designing any
digital circuit. We designed Carry Propagate Adder using GDI technique and
compared its performance with CMOS technique in terms of area, delay and power
dissipation. Circuit designed using CADENCE EDA tool and simulated using
SPECTRE VIRTUOSO tool at 0.18m technology. Comparative performance result shows
that Carry Propagate Adder using GDI technique dissipated 55.6% less power as
compare to Carry Propagate Adder using CMOS technique.
"
336,"Design of Parity Preserving Logic Based Fault Tolerant Reversible
  Arithmetic Logic Unit","  Reversible Logic is gaining significant consideration as the potential logic
design style for implementation in modern nanotechnology and quantum computing
with minimal impact on physical entropy .Fault Tolerant reversible logic is one
class of reversible logic that maintain the parity of the input and the
outputs. Significant contributions have been made in the literature towards the
design of fault tolerant reversible logic gate structures and arithmetic units,
however, there are not many efforts directed towards the design of fault
tolerant reversible ALUs. Arithmetic Logic Unit (ALU) is the prime performing
unit in any computing device and it has to be made fault tolerant. In this
paper we aim to design one such fault tolerant reversible ALU that is
constructed using parity preserving reversible logic gates. The designed ALU
can generate up to seven Arithmetic operations and four logical operations.
"
337,Thermal analysis of 3D associative processor,"  Thermal density and hot spots limit three-dimensional (3D) implementation of
massively-parallel SIMD processors and prohibit stacking DRAM dies above them.
This study proposes replacing SIMD by an Associative Processor (AP). AP
exhibits close to uniform thermal distribution with reduced hot spots.
Additionally, AP may outperform SIMD processor when the data set size is
sufficiently large, while dissipating less power. Comparative performance and
thermal analysis supported by simulation confirm that AP might be preferable
over SIMD for 3D implementation of large scale massively parallel processing
engines combined with 3D DRAM integration.
"
338,"Relative Performance of a Multi-level Cache with Last-Level Cache
  Replacement: An Analytic Review","  Current day processors employ multi-level cache hierarchy with one or two
levels of private caches and a shared last-level cache (LLC). An efficient
cache replacement policy at LLC is essential for reducing the off-chip memory
transfer as well as conflict for memory bandwidth. Cache replacement techniques
for inclusive LLCs may not be efficient for multilevel cache as it can be
shared by enormous applications with varying access behavior, running
simultaneously. One application may dominate another by flooding of cache
requests and evicting the useful data of the other application. From the
performance point of view, an exclusive LLC make the replacement policies more
demanding, as compared to an inclusive LLC. This paper analyzes some of the
existing replacement techniques on the LLC with their performance assessment.
"
339,Fast Polar Decoders: Algorithm and Implementation,"  Polar codes provably achieve the symmetric capacity of a memoryless channel
while having an explicit construction. This work aims to increase the
throughput of polar decoder hardware by an order of magnitude relative to the
state of the art successive-cancellation decoder. We present an algorithm,
architecture, and FPGA implementation of a gigabit-per-second polar decoder.
"
340,"Allocating the chains of consecutive additions for optimal fixed-point
  data path synthesis","  Minimization of computational errors in the fixed-point data path is often
difficult task. Many signal processing algorithms use chains of consecutive
additions. The analyzing technique that can be applied to fixed-point data path
synthesis has been proposed. This technique takes advantage of allocating the
chains of consecutive additions in order to predict growing width of the data
path and minimize the design complexity and computational errors.
"
341,FpSynt: a fixed-point datapath synthesis tool for embedded systems,"  Digital mobile systems must function with low power, small size and weight,
and low cost. High-performance desktop microprocessors, with built-in floating
point hardware, are not suitable in these cases. For embedded systems, it can
be advantageous to implement these calculations with fixed point arithmetic
instead. We present an automated fixed-point data path synthesis tool FpSynt
for designing embedded applications in fixed-point domain with sufficient
accuracy for most applications. FpSynt is available under the GNU General
Public License from the following GitHub repository:
http://github.com/izhbannikov/FPSYNT
"
342,Resistive Threshold Logic,"  We report a resistance based threshold logic family useful for mimicking
brain like large variable logic functions in VLSI. A universal Boolean logic
cell based on an analog resistive divider and threshold logic circuit is
presented. The resistive divider is implemented using memristors and provides
output voltage as a summation of weighted product of input voltages. The output
of resistive divider is converted into a binary value by a threshold operation
implemented by CMOS inverter and/or Opamp. An universal cell structure is
presented to decrease the overall implementation complexity and number of
components. When the number of input variables become very high, the proposed
cell offers advantages of smaller area and design simplicity in comparison with
CMOS based logic circuits.
"
343,Designing Parity Preserving Reversible Circuits,"  Making a reversible circuit fault-tolerant is much more difficult than
classical circuit and there have been only a few works in the area of
parity-preserving reversible logic design. Moreover, all of these designs are
ad hoc, based on some pre-defined parity preserving reversible gates as
building blocks. In this paper, we for the first time propose a novel and
systematic approach towards parity preserving reversible circuits design. We
provide some related theoretical results and give two algorithms, one from
reversible specification to parity preserving reversible specification and
another from irreversible specification to parity preserving reversible
specification. We also evaluate the effectiveness of our approach by extensive
experimental results.
"
344,Improving the GPU space of computation under triangular domain problems,"  There is a stage in the GPU computing pipeline where a grid of thread-blocks
is mapped to the problem domain. Normally, this grid is a k-dimensional
bounding box that covers a k-dimensional problem no matter its shape. Threads
that fall inside the problem domain perform computations, otherwise they are
discarded at runtime. For problems with non-square geometry, this is not always
the best idea because part of the space of computation is executed without any
practical use. Two- dimensional triangular domain problems, alias td-problems,
are a particular case of interest. Problems such as the Euclidean distance map,
LU decomposition, collision detection and simula- tions over triangular tiled
domains are all td-problems and they appear frequently in many areas of
science. In this work, we propose an improved GPU mapping function g(lambda),
that maps any lambda block to a unique location (i, j) in the triangular
domain. The mapping is based on the properties of the lower triangular matrix
and it works at a block level, thus not compromising thread organization within
a block. The theoretical improvement from using g(lambda) is upper bounded as I
< 2 and the number of wasted blocks is reduced from O(n^2) to O(n). We compare
our strategy with other proposed methods; the upper-triangular mapping (UTM),
the rectangular box (RB) and the recursive partition (REC). Our experimental
results on Nvidias Kepler GPU architecture show that g(lambda) is between 12%
and 15% faster than the bounding box (BB) strategy. When compared to the other
strategies, our mapping runs significantly faster than UTM and it is as fast as
RB in practical use, with the advantage that thread organization is not
compromised, as in RB. This work also contributes at presenting, for the first
time, a fair comparison of all existing strategies running the same experiments
under the same hardware.
"
345,First experiences with the Intel MIC architecture at LRZ,"  With the rapidly growing demand for computing power new accelerator based
architectures have entered the world of high performance computing since around
5 years. In particular GPGPUs have recently become very popular, however
programming GPGPUs using programming languages like CUDA or OpenCL is
cumbersome and error-prone. Trying to overcome these difficulties, Intel
developed their own Many Integrated Core (MIC) architecture which can be
programmed using standard parallel programming techniques like OpenMP and MPI.
In the beginning of 2013, the first production-level cards named Intel Xeon Phi
came on the market. LRZ has been considered by Intel as a leading research
centre for evaluating coprocessors based on the MIC architecture since 2010
under strict NDA. Since the Intel Xeon Phi is now generally available, we can
share our experience on programming Intel's new MIC architecture.
"
346,"Ultra-low Energy, High Performance and Programmable Magnetic Threshold
  Logic","  We propose magnetic threshold-logic (MTL) design based on non-volatile
spin-torque switches. A threshold logic gate (TLG) performs summation of
multiple inputs multiplied by a fixed set of weights and compares the sum with
a threshold. MTL employs resistive states of magnetic tunnel junctions as
programmable input weights, while, a low-voltage domain-wall shift based
spin-torque switch is used for thresholding operation. The resulting MTL gate
acts as a low-power, configurable logic unit and can be used to build fully
pipelined, high-performance programmable computing blocks. Multiple stages in
such a MTL design can be connected using energy-efficient ultralow swing
programmable interconnect networks based on resistive switches. Owing to
memory-based compact logic and interconnect design and low-voltage, high-speed
spintorque based threshold operation, MTL can achieve more than two orders of
magnitude improvement in energy-delay product as compared to look-up table
based CMOS FPGA.
"
347,"Ultra-low Energy, High-Performance Dynamic Resistive Threshold Logic","  We propose dynamic resistive threshold-logic (DRTL) design based on
non-volatile resistive memory. A threshold logic gate (TLG) performs summation
of multiple inputs multiplied by a fixed set of weights and compares the sum
with a threshold. DRTL employs resistive memory elements to implement the
weights and the thresholds, while a compact dynamic CMOS latch is used for the
comparison operation. The resulting DRTL gate acts as a low-power, configurable
dynamic logic unit and can be used to build fully pipelined, high-performance
programmable computing blocks. Multiple stages in such a DRTL design can be
connected using energy-efficient low swing programmable interconnect networks
based on resistive switches. Owing to memory-based compact logic and
interconnect design and highspeed dynamic-pipelined operation, DRTL can achieve
more than two orders of magnitude improvement in energy-delay product as
compared to look-up table based CMOS FPGA.
"
348,"Selective Decoding in Associative Memories Based on Sparse-Clustered
  Networks","  Associative memories are structures that can retrieve previously stored
information given a partial input pattern instead of an explicit address as in
indexed memories. A few hardware approaches have recently been introduced for a
new family of associative memories based on Sparse-Clustered Networks (SCN)
that show attractive features. These architectures are suitable for
implementations with low retrieval latency, but are limited to small networks
that store a few hundred data entries. In this paper, a new hardware
architecture of SCNs is proposed that features a new data-storage technique as
well as a method we refer to as Selective Decoding (SD-SCN). The SD-SCN has
been implemented using a similar FPGA used in the previous efforts and achieves
two orders of magnitude higher capacity, with no error-performance penalty but
with the cost of few extra clock cycles per data access.
"
349,Low power-area designs of 1bit full adder in cadence virtuoso platform,"  Power consumption has emerged as a primary design constraint for integrated
circuits (ICs). In the Nano meter technology regime, leakage power has become a
major component of total power. Full adder is the basic functional unit of an
ALU. The power consumption of a processor is lowered by lowering the power
consumption of an ALU, and the power consumption of an ALU can be lowered by
lowering the power consumption of Full adder. So the full adder designs with
low power characteristics are becoming more popular these days. This proposed
work illustrates the design of the low-power less transistor full adder designs
using cadence tool and virtuoso platform, the entire simulations have been done
on 180nm single n-well CMOS bulk technology, in virtuoso platform of cadence
tool with the supply voltage 1.8V and frequency of 100MHz. These circuits
consume less power with maximum (6T design)of 93.1% power saving compare to
conventional 28T design and 80.2% power saving compare to SERF design without
much delay degradation. The proposed circuit exploits the advantage of GDI
technique and pass transistor logic
"
350,"Evaluation of the Performance/Energy Overhead in DSP Video Decoding and
  its Implications","  Video decoding is considered as one of the most compute and energy intensive
application in energy constrained mobile devices. Some specific processing
units, such as DSPs, are added to those devices in order to optimize the
performance and the energy consumption. However, in DSP video decoding, the
inter-processor communication overhead may have a considerable impact on the
performance and the energy consumption. In this paper, we propose to evaluate
this overhead and analyse its impact on the performance and the energy
consumption as compared to the GPP decoding. Our work revealed that the GPP can
be the best choice in many cases due to the a significant overhead in DSP
decoding which may represents 30% of the total decoding energy.
"
351,"On the Performance Potential of Speculative Execution based on Branch
  and Value Prediction","  Fluid Stochastic Petri Nets are used to capture the dynamic behavior of an
ILP processor, and discrete-event simulation is applied to assess the
performance potential of predictions and speculative execution in boosting the
performance of ILP processors that fetch, issue, execute and commit a large
number of instructions per cycle.
"
352,Energy Saving Techniques for Phase Change Memory (PCM),"  In recent years, the energy consumption of computing systems has increased
and a large fraction of this energy is consumed in main memory. Towards this,
researchers have proposed use of non-volatile memory, such as phase change
memory (PCM), which has low read latency and power; and nearly zero leakage
power. However, the write latency and power of PCM are very high and this,
along with limited write endurance of PCM present significant challenges in
enabling wide-spread adoption of PCM. To address this, several
architecture-level techniques have been proposed. In this report, we review
several techniques to manage power consumption of PCM. We also classify these
techniques based on their characteristics to provide insights into them. The
aim of this work is encourage researchers to propose even better techniques for
improving energy efficiency of PCM based main memory.
"
353,Advances in computer architecture,"  In the past, efforts were taken to improve the performance of a processor via
frequency scaling. However, industry has reached the limits of increasing the
frequency and therefore concurrent execution of instructions on multiple cores
seems the only possible option. It is not enough to provide concurrent
execution by the hardware, software also have to introduce concurrency in order
to exploit the parallelism.
"
354,Microgrid - The microthreaded many-core architecture,"  Traditional processors use the von Neumann execution model, some other
processors in the past have used the dataflow execution model. A combination of
von Neuman model and dataflow model is also tried in the past and the resultant
model is referred as hybrid dataflow execution model. We describe a hybrid
dataflow model known as the microthreading. It provides constructs for
creation, synchronization and communication between threads in an intermediate
language. The microthreading model is an abstract programming and machine model
for many-core architecture. A particular instance of this model is named as the
microthreaded architecture or the Microgrid. This architecture implements all
the concurrency constructs of the microthreading model in the hardware with the
management of these constructs in the hardware.
"
355,Design space exploration in the microthreaded many-core architecture,"  Design space exploration is commonly performed in embedded system, where the
architecture is a complicated piece of engineering. With the current trend of
many-core systems, design space exploration in general-purpose computers can no
longer be avoided. Microgrid is a complicated architecture, and therefor we
need to perform design space exploration. Generally, simulators are used for
the design space exploration of an architecture. Different simulators with
different levels of complexity, simulation time and accuracy are used.
Simulators with little complexity, low simulation time and reasonable accuracy
are desirable for the design space exploration of an architecture. These
simulators are referred as high-level simulators and are commonly used in the
design of embedded systems. However, the use of high-level simulation for
design space exploration in general-purpose computers is a relatively new area
of research.
"
356,"A Cache-Coloring Based Technique for Saving Leakage Energy In
  Multitasking Systems","  There has been a significant increase in leakage energy dissipation of CMOS
circuits with each technology generation. Further, due to their large size,
last level caches (LLCs) spend a large fraction of their energy in the form of
leakage energy and hence, addressing this has become extremely important to
meet the challenges of chip power budget. For addressing this, several
techniques have been proposed. However, most of these techniques require
offline profiling and hence cannot be used for real-life systems which usually
run multitasking programs, with possible pre-emptions. In this paper, we
propose a dynamic profiling based technique for saving cache leakage energy in
multitasking systems. Our technique uses a small coloring-based profiling
cache, to estimate performance and energy consumption of multiple cache
configurations and then selects the best (least-energy) configuration among
them. Our technique uses non-intrusive profiling and saves energy despite
intra-task and inter-task variations; thus, it is suitable for multitasking
systems. Simulations performed using workloads from SPEC2006 suite show the
superiority of our technique over an existing cache energy saving technique.
With a 2MB baseline cache, the average saving in memory sub-system energy is
22.8%.
"
357,"A Cache Reconfiguration Approach for Saving Leakage and Refresh Energy
  in Embedded DRAM Caches","  In recent years, the size and leakage energy consumption of large last level
caches (LLCs) has increased. To address this, embedded DRAM (eDRAM) caches have
been considered which have lower leakage energy consumption; however eDRAM
caches consume a significant amount of energy in the form of refresh energy. In
this paper, we present a technique for saving both leakage and refresh energy
in eDRAM caches. We use dynamic cache reconfiguration approach to intelligently
turn-off part of the cache to save leakage energy and refresh only valid data
of the active (i.e. not turned-off) cache to save refresh energy. We evaluate
our technique using an x86-64 simulator and SPEC2006 benchmarks and compare it
with a recently proposed technique for saving refresh energy, named Refrint.
The experiments have shown that our technique provides better performance and
energy efficiency than Refrint. Using our technique, for a 2MB LLC and 40
micro-seconds eDRAM refresh period, the average saving in energy over eDRAM
baseline (which periodically refreshes all cache lines) is 22.8%.
"
358,"A Low-Voltage, Low-Power 4-bit BCD Adder, designed using the Clock Gated
  Power Gating, and the DVT Scheme","  This paper proposes a Low-Power, Energy Efficient 4-bit Binary Coded Decimal
(BCD) adder design where the conventional 4-bit BCD adder has been modified
with the Clock Gated Power Gating Technique. Moreover, the concept of DVT
(Dual-vth) scheme has been introduced while designing the full adder blocks to
reduce the Leakage Power, as well as, to maintain the overall performance of
the entire circuit. The reported architecture of 4-bit BCD adder is designed
using 45 nm technology and it consumes 1.384 {\mu}Watt of Average Power while
operating with a frequency of 200 MHz, and a Supply Voltage (Vdd) of 1 Volt.
The results obtained from different simulation runs on SPICE, indicate the
superiority of the proposed design compared to the conventional 4-bit BCD
adder. Considering the product of Average Power and Delay, for the operating
frequency of 200 MHz, a fair 47.41 % reduction compared to the conventional
design has been achieved with this proposed scheme.
"
359,"Recycled Error Bits: Energy-Efficient Architectural Support for Higher
  Precision Floating Point","  In this work, we provide energy-efficient architectural support for floating
point accuracy. Our goal is to provide accuracy that is far greater than that
provided by the processor's hardware floating point unit (FPU). Specifically,
for each floating point addition performed, we ""recycle"" that operation's
error: the difference between the finite-precision result produced by the
hardware and the result that would have been produced by an infinite-precision
FPU. We make this error architecturally visible such that it can be used, if
desired, by software. Experimental results on physical hardware show that
software that exploits architecturally recycled error bits can achieve accuracy
comparable to a 2B-bit FPU with performance and energy that are comparable to a
B-bit FPU.
"
360,"Partial Sums Generation Architecture for Successive Cancellation
  Decoding of Polar Codes","  Polar codes are a new family of error correction codes for which efficient
hardware architectures have to be defined for the encoder and the decoder.
Polar codes are decoded using the successive cancellation decoding algorithm
that includes partial sums computations. We take advantage of the recursive
structure of polar codes to introduce an efficient partial sums computation
unit that can also implements the encoder. The proposed architecture is
synthesized for several codelengths in 65nm ASIC technology. The area of the
resulting design is reduced up to 26% and the maximum working frequency is
improved by ~25%.
"
361,"Technical report: Functional Constraint Extraction From Register
  Transfer Level for ATPG","  We proposed in ""Functional Constraint Extraction From Register Transfer Level
for ATPG"" that is currently submitted to TVLSI, an automatic functional
constraint extractor that can be applied on the RT level. These functional
constraints are used to generate pseudo functional test patterns with ATPG
tools. The patterns are then used to improve the verification process. This
technical report complements the work proposed as it contains the
implementation details of the proposed methodology and shows the detailed
intermediate and final results of the application of this methodology on a
concrete example.
"
362,"Janus II: a new generation application-driven computer for spin-system
  simulations","  This paper describes the architecture, the development and the implementation
of Janus II, a new generation application-driven number cruncher optimized for
Monte Carlo simulations of spin systems (mainly spin glasses). This domain of
computational physics is a recognized grand challenge of high-performance
computing: the resources necessary to study in detail theoretical models that
can make contact with experimental data are by far beyond those available using
commodity computer systems. On the other hand, several specific features of the
associated algorithms suggest that unconventional computer architectures, which
can be implemented with available electronics technologies, may lead to order
of magnitude increases in performance, reducing to acceptable values on human
scales the time needed to carry out simulation campaigns that would take
centuries on commercially available machines. Janus II is one such machine,
recently developed and commissioned, that builds upon and improves on the
successful JANUS machine, which has been used for physics since 2008 and is
still in operation today. This paper describes in detail the motivations behind
the project, the computational requirements, the architecture and the
implementation of this new machine and compares its expected performances with
those of currently available commercial systems.
"
363,Partial Sums Computation In Polar Codes Decoding,"  Polar codes are the first error-correcting codes to provably achieve the
channel capacity but with infinite codelengths. For finite codelengths the
existing decoder architectures are limited in working frequency by the partial
sums computation unit. We explain in this paper how the partial sums
computation can be seen as a matrix multiplication. Then, an efficient hardware
implementation of this product is investigated. It has reduced logic resources
and interconnections. Formalized architectures, to compute partial sums and to
generate the bits of the generator matrix k^n, are presented. The proposed
architecture allows removing the multiplexing resources used to assigned to
each processing elements the required partial sums.
"
364,"A Novel Reconfigurable Computing Architecture for Image Signal
  Processing Using Circuit-Switched NoC and Synchronous Dataflow Model","  In this paper, a novel reconfigurable architecture is proposed for
multifunctional image signal processing systems. A circuit-switched NoC is used
to provide interconnection because the non-TMD links ensure fixed throughput,
which is a desirable behavior for computational intensive image processing
algorithms compared with packet-switched NoC. Image processing algorithms are
modeled as synchronous dataflow graphs which provide a unified model for
general computing procedure. An image processing system is considered as
several temporally mutually exclusive algorithms. Thus, their dataflow graph
representations could be considered as a group and a merging algorithm could be
applied to generate a union graph while eliminating spatial redundancy for area
consumption optimization. After the union graph have been mapped and routed on
the NoC, the reconfigurable system could be configured to any of its target
image processing algorithms by properly setting the NoC topology. Experiments
show the demo reconfigurable system with two image processing applications cost
26.4% less hardware resource, compared with the non-reconfigurable
implementations.
"
365,"Dynamic cache reconfiguration based techniques for improving cache
  energy efficiency","  Modern multicore processors are employing large last-level caches, for
example Intel's E7-8800 processor uses 24MB L3 cache. Further, with each CMOS
technology generation, leakage energy has been dramatically increasing and
hence, leakage energy is expected to become a major source of energy
dissipation, especially in last-level caches (LLCs). The conventional schemes
of cache energy saving either aim at saving dynamic energy or are based on
properties specific to first-level caches, and thus these schemes have limited
utility for last-level caches. Further, several other techniques require
offline profiling or per-application tuning and hence are not suitable for
product systems. In this research, we propose novel cache leakage energy saving
schemes for single-core and multicore systems; desktop, QoS, real-time and
server systems. We propose software-controlled, hardware-assisted techniques
which use dynamic cache reconfiguration to configure the cache to the most
energy efficient configuration while keeping the performance loss bounded. To
profile and test a large number of potential configurations, we utilize
low-overhead, micro-architecture components, which can be easily integrated
into modern processor chips. We adopt a system-wide approach to save energy to
ensure that cache reconfiguration does not increase energy consumption of other
components of the processor. We have compared our techniques with the
state-of-art techniques and have found that our techniques outperform them in
their energy efficiency. This research has important applications in improving
energy-efficiency of higher-end embedded, desktop, server processors and
multitasking systems. We have also proposed performance estimation approach for
efficient design space exploration and have implemented time-sampling based
simulation acceleration approach for full-system architectural simulators.
"
366,"An Improved Majority-Logic Decoder Offering Massively Parallel Decoding
  for Real-Time Control in Embedded Systems","  We propose an easy-to-implement hard-decision majority-logic decoding
algorithm for Reed-Muller codes RM(r,m) with m >= 3, m/2 >= r >= 1. The
presented algorithm outperforms the best known majority-logic decoding
algorithms and offers highly parallel decoding. The result is of special
importance for safety- and time-critical applications in embedded systems. A
simple combinational circuit can perform the proposed decoding. In particular,
we show how our decoder for the three-error-correcting code RM(2,5) of
dimension 16 and length 32 can be realized on hardware level.
"
367,"Evaluating Cache Coherent Shared Virtual Memory for Heterogeneous
  Multicore Chips","  The trend in industry is towards heterogeneous multicore processors (HMCs),
including chips with CPUs and massively-threaded throughput-oriented processors
(MTTOPs) such as GPUs. Although current homogeneous chips tightly couple the
cores with cache-coherent shared virtual memory (CCSVM), this is not the
communication paradigm used by any current HMC. In this paper, we present a
CCSVM design for a CPU/MTTOP chip, as well as an extension of the pthreads
programming model, called xthreads, for programming this HMC. Our goal is to
evaluate the potential performance benefits of tightly coupling heterogeneous
cores with CCSVM.
"
368,"Using Cache-coloring to Mitigate Inter-set Write Variation in
  Non-volatile Caches","  In recent years, researchers have explored use of non-volatile devices such
as STT-RAM (spin torque transfer RAM) for designing on-chip caches, since they
provide high density and consume low leakage power. A common limitation of all
non-volatile devices is their limited write endurance. Further, since existing
cache management policies are write-variation unaware, excessive writes to a
few blocks may lead to a quick failure of the whole cache. We propose an
architectural technique for wear-leveling of non-volatile last level caches
(LLCs). Our technique uses cache-coloring approach which adds a
software-controlled mapping layer between groups of physical pages and cache
sets. Periodically the mapping is altered to ensure that write-traffic can be
spread uniformly to different sets of the cache to achieve wear-leveling.
Simulations performed with an x86-64 simulator and SPEC2006 benchmarks show
that our technique reduces the worst-case writes to cache blocks and thus
improves the cache lifetime by 4.07X.
"
369,"A Technique for Write-endurance aware Management of Resistive RAM Last
  Level Caches","  Due to increasing cache sizes and large leakage consumption of SRAM device,
conventional SRAM caches contribute significantly to the processor power
consumption. Recently researchers have used non-volatile memory devices to
design caches, since they provide high density, comparable read latency and low
leakage power dissipation. However, their high write latency may increase the
execution time and hence, leakage energy consumption. Also, since their write
endurance is small, a conventional energy saving technique may further
aggravate the problem of write-variations, thus reducing their lifetime. In
this paper, we present a cache energy saving technique for non-volatile caches,
which also attempts to improve their lifetime by making writes equally
distributed to the cache. Our technique uses dynamic cache reconfiguration to
adjust the cache size to meet program requirement and turns off the remaining
cache to save energy. Microarchitectural simulations performed using an x86-64
simulator, SPEC2006 benchmarks and a resistive-RAM LLC (last level cache) show
that over an 8MB baseline cache, our technique saves 17.55% memory subsystem
(last level cache + main memory) energy and improves the lifetime by 1.33X.
Over the same resistive-RAM baseline, an SRAM of similar area with no cache
reconfiguration leads to an energy loss of 186.13%.
"
370,A Technique for Efficiently Managing SRAM-NVM Hybrid Cache,"  In this paper, we present a SRAM-PCM hybrid cache design, along with a cache
replacement policy, named dead fast block (DFB) to manage the hybrid cache.
This design aims to leverage the best features of both SRAM and PCM devices.
Compared to a PCM-only cache, the hybrid cache with DFB policy provides
superior results on all relevant evaluation metrics, viz. cache lifetime,
performance and energy efficiency. Also, use of DFB policy for managing the
hybrid cache provides better results compared to LRU replacement policy on all
the evaluation metrics.
"
371,"Input-Output Logic based Fault-Tolerant Design Technique for SRAM-based
  FPGAs","  Effects of radiation on electronic circuits used in extra-terrestrial
applications and radiation prone environments need to be corrected. Since FPGAs
offer flexibility, the effects of radiation on them need to be studied and
robust methods of fault tolerance need to be devised. In this paper a new
fault-tolerant design strategy has been presented. This strategy exploits the
relation between changes in inputs and the expected change in output.
Essentially, it predicts whether or not a change in the output is expected and
thereby calculates the error. As a result this strategy reduces hardware and
time redundancy required by existing strategies like Duplication with
Comparison (DWC) and Triple Modular Redundancy (TMR). The design arising from
this strategy has been simulated and its robustness to fault-injection has been
verified. Simulations for a 16 bit multiplier show that the new design strategy
performs better than the state-of-the-art on critical factors such as hardware
redundancy, time redundancy and power consumption.
"
372,3D Cache Hierarchy Optimization,"  3D integration has the potential to improve the scalability and performance
of Chip Multiprocessors (CMP). A closed form analytical solution for optimizing
3D CMP cache hierarchy is developed. It allows optimal partitioning of the
cache hierarchy levels into 3D silicon layers and optimal allocation of area
among cache hierarchy levels under constrained area and power budgets. The
optimization framework is extended by incorporating the impact of multithreaded
data sharing on the private cache miss rate. An analytical model for cache
access time as a function of cache size and a number of 3D partitions is
proposed and verified using CACTI simulation.
"
373,"Architectural improvements and 28 nm FPGA implementation of the APEnet+
  3D Torus network for hybrid HPC systems","  Modern Graphics Processing Units (GPUs) are now considered accelerators for
general purpose computation. A tight interaction between the GPU and the
interconnection network is the strategy to express the full potential on
capability computing of a multi-GPU system on large HPC clusters; that is the
reason why an efficient and scalable interconnect is a key technology to
finally deliver GPUs for scientific HPC. In this paper we show the latest
architectural and performance improvement of the APEnet+ network fabric, a
FPGA-based PCIe board with 6 fully bidirectional off-board links with 34 Gbps
of raw bandwidth per direction, and X8 Gen2 bandwidth towards the host PC. The
board implements a Remote Direct Memory Access (RDMA) protocol that leverages
upon peer-to-peer (P2P) capabilities of Fermi- and Kepler-class NVIDIA GPUs to
obtain real zero-copy, low-latency GPU-to-GPU transfers. Finally, we report on
the development activities for 2013 focusing on the adoption of the latest
generation 28 nm FPGAs and the preliminary tests performed on this new
platform.
"
374,"Row-Based Dual Vdd Assignment, for a Level Converter Free CSA Design and
  Its Near-Threshold Operation","  Subthreshold circuit designs are very much popular for some of the ultra low
power applications, where the minimum energy consumption is the primary
concern. But, due to the weak driving current, these circuits generally suffer
from huge performance degradation. Therefore, in this paper, we primarily
targeted to analyze the performance of a Near-Threshold Circuit (NTC), which
retains the excellent energy efficiency of the subthreshold design, while
improving the performance to a certain extent. A modified row-based dual Vdd
4-operand CSA (Carry Save Adder) design has been reported in the present work
using 45 nm technology. Moreover, to find out the effectiveness of the
near-threshold operation of the 4-operand CSA design; it has been compared with
the other design styles. From the simulation results, obtained for the
frequency of 20 MHz, we found that the proposed scheme of CSA design consumes
3.009*10-7 Watt of Average Power (Pavg), which is almost 90.9 % lesser than
that of the conventional CSA design. Whereas, looking at the perspective of
maximum delay at output, the proposed scheme of CSA design provides a fair
44.37 % improvement, compared to that of the subthreshold CSA design.
"
375,A Cache Energy Optimization Technique for STT-RAM Last Level Cache,"  Last level caches (LLCs) occupy a large chip-area and there size is expected
to grow further to offset the limitations of memory bandwidth and speed. Due to
high leakage consumption of SRAM device, caches designed with SRAM consume
large amount of energy. To address this, use of emerging technologies such as
spin torque transfer RAM (STT-RAM) has been investigated which have lower
leakage power dissipation. However, the high write latency and power of it may
lead to large energy consumption which present challenges in its use. In this
report, we propose a cache reconfiguration based technique for improving the
energy efficiency of STT-RAM based LLCs. Our technique dynamically adjusts the
active cache size to reduce the cache leakage energy consumption with minimum
performance loss. We choose a suitable value of STT-RAM retention time for
avoiding refresh overhead and gaining performance. Single-core simulations have
been performed using SPEC2006 benchmarks and Sniper x86-64 simulator. The
results show that while, compared to an STT-RAM LLC of similar area, an SRAM
LLC incurs nearly 100% loss in energy and 7.3% loss in performance; our
technique using STT-RAM cache saves 21.8% energy and incurs only 1.7% loss in
performance.
"
376,"Dominant block guided optimal cache size estimation to maximize IPC of
  embedded software","  Embedded system software is highly constrained from performance, memory
footprint, energy consumption and implementing cost view point. It is always
desirable to obtain better Instructions per Cycle. Instruction cache has major
contribution in improving IPC. Cache memories are realized on the same chip
where the processor is running. This considerably increases the system cost as
well. Hence, it is required to maintain a trade off between cache sizes and
performance improvement offered. Determining the number of cache lines and size
of cache line are important parameters for cache designing. The design space
for cache is quite large. It is time taking to execute the given application
with different cache sizes on an instruction set simulator to figure out the
optimal cache size. In this paper, a technique is proposed to identify a number
of cache lines and cache line size for the L1 instruction cache that will offer
best or nearly best IPC. Cache size is derived, at a higher abstraction level,
from basic block analysis in the Low Level Virtual Machine environment. The
cache size estimated is cross validated by simulating the set of benchmark
applications with different cache sizes in simple scalar simulator. The
proposed method seems to be superior in terms of estimation accuracy and
estimation time as compared to the existing methods for estimation of optimal
cache size parameters like cache line size, number of cache lines.
"
377,A Survey of Network-On-Chip Tools,"  Nowadays System-On-Chips (SoCs) have evolved considerably in term of
performances, reliability and integration capacity. The last advantage has
induced the growth of the number of cores or Intellectual Properties (IPs) in a
same chip. Unfortunately, this important number of IPs has caused a new issue
which is the intra-communication between the elements of a same chip. To
resolve this problem, a new paradigm has been introduced which is the
Network-On-Chip (NoC). Since the introduction of the NoC paradigm in the last
decade, new methodologies and approaches have been presented by research
community and many of them have been adopted by industrials. The literature
contains many relevant studies and surveys discussing NoC proposals and
contributions. However, few of them have discussed or proposed a comparative
study of NoC tools. The objective of this work is to establish a reliable
survey about available design, simulation or implementation NoC tools. We
collected an important amount of information and characteristics about NoC
dedicated tools that we will present throughout this survey. This study is
built around a respectable amount of references and we hope it will help
scientists.
"
378,"FFTPL: An Analytic Placement Algorithm Using Fast Fourier Transform for
  Density Equalization","  We propose a flat nonlinear placement algorithm FFTPL using fast Fourier
transform for density equalization. The placement instance is modeled as an
electrostatic system with the analogy of density cost to the potential energy.
A well-defined Poisson's equation is proposed for gradient and cost
computation. Our placer outperforms state-of-the-art placers with better
solution quality and efficiency.
"
379,Design of Reversible Random Access Memory,"  Reversible logic has become immensely popular research area and its
applications have spread in various technologies for their low power
consumption. In this paper we proposed an efficient design of random access
memory using reversible logic. In the way of designing the reversible random
access memory we proposed a reversible decoder and a write enable reversible
master slave D flip-flop. All the reversible designs are superior in terms of
quantum cost, delay and garbage outputs compared to the designs existing in
literature.
"
380,A Novel Approach for Designing Online Testable Reversible Circuits,"  Reversible logic is gaining interest of many researchers due to its low power
dissipating characteristic. In this paper we proposed a new approach for
designing online testable reversible circuits. The resultant testable
reversible circuit can detect any single bit error whiles it is operating.
Appropriate theorems and lemmas are presented to clarify the proposed design.
The experimental results show that our design approach is superior in terms of
number of number of gates, garbage outputs and quantum cost.
"
381,"A Survey of Techniques For Improving Energy Efficiency in Embedded
  Computing Systems","  Recent technological advances have greatly improved the performance and
features of embedded systems. With the number of just mobile devices now
reaching nearly equal to the population of earth, embedded systems have truly
become ubiquitous. These trends, however, have also made the task of managing
their power consumption extremely challenging. In recent years, several
techniques have been proposed to address this issue. In this paper, we survey
the techniques for managing power consumption of embedded systems. We discuss
the need of power management and provide a classification of the techniques on
several important parameters to highlight their similarities and differences.
This paper is intended to help the researchers and application-developers in
gaining insights into the working of power management techniques and designing
even more efficient high-performance embedded systems of tomorrow.
"
382,On the likelihood of multiple bit upsets in logic circuits,"  Soft errors have a significant impact on the circuit reliability at nanoscale
technologies. At the architectural level, soft errors are commonly modeled by a
probabilistic bit-flip model. In developing such abstract fault models, an
important issue to consider is the likelihood of multiple bit errors caused by
particle strikes. This likelihood has been studied to a great extent in
memories, but has not been understood to the same extent in logic circuits. In
this paper, we attempt to quantify the likelihood that a single transient event
can cause multiple bit errors in logic circuits consisting of combinational
gates and flip-flops. In particular, we calculate the conditional probability
of multiple bit-flips given that a single bit flips as a result of the
transient. To calculate this conditional probability, we use a Monte Carlo
technique in which samples are generated using detailed post-layout circuit
simulations. Our experiments on the ISCAS'85 benchmarks and a few other
circuits indicate that, this conditional probability is quite significant and
can be as high as 0.31. Thus we conclude that multiple bit-flips must
necessarily be considered in order to obtain a realistic architectural fault
model for soft errors.
"
383,Hardware Implementation of four byte per clock RC4 algorithm,"  In the field of cryptography till date the 2-byte in 1-clock is the best
known RC4 hardware design [1], while 1-byte in 1-clock [2], and the 1-byte in 3
clocks [3][4] are the best known implementation. The design algorithm in[2]
considers two consecutive bytes together and processes them in 2 clocks. The
design [1] is a pipelining architecture of [2]. The design of 1-byte in
3-clocks is too much modular and clock hungry. In this paper considering the
RC4 algorithm, as it is, a simpler RC4 hardware design providing higher
throughput is proposed in which 6 different architecture has been proposed. In
design 1, 1-byte is processed in 1-clock, design 2 is a dynamic KSA-PRGA
architecture of Design 1. Design 3 can process 2 byte in a single clock, where
as Design 4 is Dynamic KSA-PRGA architecture of Design 3. Design 5 and Design 6
are parallelization architecture design 2 and design 4 which can compute 4 byte
in a single clock. The maturity in terms of throughput, power consumption and
resource usage, has been achieved from design 1 to design 6. The RC4 encryption
and decryption designs are respectively embedded on two FPGA boards as
co-processor hardware, the communication between the two boards performed using
Ethernet.
"
384,"Fault Detection for RC4 Algorithm and its Implementation on FPGA
  Platform","  In hardware implementation of a cryptographic algorithm, one may achieve
leakage of secret information by creating scopes to introduce controlled faulty
bit(s) even though the algorithm is mathematically a secured one. The technique
is very effective in respect of crypto processors embedded in smart cards. In
this paper few fault detecting architectures for RC4 algorithm are designed and
implemented on Virtex5(ML505, LX110t) FPGA board. The results indicate that the
proposed architectures can handle most of the faults without loss of throughput
consuming marginally additional hardware and power.
"
385,"Design of novel architectures and field programmable gate arrays
  implementation of two dimensional gaussian surround function","  A new design and novel architecture suitable for FPGA/ASIC implementation of
a 2D Gaussian surround function for image processing application is presented
in this paper. The proposed scheme results in enormous savings of memory
normally required for 2D Gaussian function implementation. In the present work,
the Gaussian symmetric characteristics which quickly falls off toward
plus/minus infinity has been used in order to save the memory. The 2D Gaussian
function implementation is presented for use in applications such as image
enhancement, smoothing, edge detection and filtering etc. The FPGA
implementation of the proposed 2D Gaussian function is capable of processing
(blurring, smoothing, and convolution) high resolution color pictures of size
up to $1600\times1200$ pixels at the real time video rate of 30 frames/sec. The
Gaussian design exploited here has been used in the core part of retinex based
color image enhancement. Therefore, the design presented produces Gaussian
output with three different scales, namely, 16, 64 and 128. The design was
coded in Verilog, a popular hardware design language used in industries,
conforming to RTL coding guidelines and fits onto a single chip with a gate
count utilization of 89,213 gates. Experimental results presented confirms that
the proposed method offers a new approach for development of large sized
Gaussian pyramid while reducing the on-chip memory utilization.
"
386,"Performance Evaluation of ECC in Single and Multi Processor
  Architectures on FPGA Based Embedded System","  Cryptographic algorithms are computationally costly and the challenge is more
if we need to execute them in resource constrained embedded systems. Field
Programmable Gate Arrays (FPGAs) having programmable logic de- vices and
processing cores, have proven to be highly feasible implementation platforms
for embedded systems providing lesser design time and reconfig- urability.
Design parameters like throughput, resource utilization and power requirements
are the key issues. The popular Elliptic Curve Cryptography (ECC), which is
superior over other public-key crypto-systems like RSA in many ways, such as
providing greater security for a smaller key size, is cho- sen in this work and
the possibilities of its implementation in FPGA based embedded systems for both
single and dual processor core architectures in- volving task parallelization
have been explored. This exploration, which is first of its kind considering
the other existing works, is a needed activity for evaluating the best possible
architectural environment for ECC implementa- tion on FPGA (Virtex4 XC4VFX12,
FF668, -10) based embedded platform.
"
387,"HERMES: A Hierarchical Broadcast-Based Silicon Photonic Interconnect for
  Scalable Many-Core Systems","  Optical interconnection networks, as enabled by recent advances in silicon
photonic device and fabrication technology, have the potential to address
on-chip and off-chip communication bottlenecks in many-core systems. Although
several designs have shown superior power efficiency and performance compared
to electrical alternatives, these networks will not scale to the thousands of
cores required in the future.
  In this paper, we introduce Hermes, a hybrid network composed of an optimized
broadcast for power-efficient low-latency global-scale coordination and
circuit-switch sub-networks for high-throughput data delivery. This network
will scale for use in thousand core chip systems. At the physical level,
SoI-based adiabatic coupler has been designed to provide low-loss and compact
optical power splitting. Based on the adiabatic coupler, a topology based on
2-ary folded butterfly is designed to provide linear power division in a
thousand core layout with minimal cross-overs. To address the network agility
and provide for efficient use of optical bandwidth, a flow control and routing
mechanism is introduced to dynamically allocate bandwidth and provide fairness
usage of network resources. At the system level, bloom filter-based filtering
for localization of communication are designed for reducing global traffic. In
addition, a novel greedy-based data and workload migration are leveraged to
increase the locality of communication in a NUCA (non-uniform cache access)
architecture. First order analytic evaluation results have indicated that
Hermes is scalable to at least 1024 cores and offers significant performance
improvement and power savings over prior silicon photonic designs.
"
388,"The Design of a Network-On-Chip Architecture Based On An Avionic
  Protocol","  When the Network-On-Chip (NoC) paradigm was introduced, many researchers have
proposed many novelistic NoC architectures, tools and design strategies. In
this paper we introduce a new approach in the field of designing
Network-On-Chip (NoC). Our inspiration came from an avionic protocol which is
the AFDX protocol. The proposed NoC architecture is a switch centric
architecture, with exclusive shortcuts between hosts and utilizes the
flexibility, the reliability and the performances offered by AFDX.
"
389,"Design of a High Speed XAUI Based on Dynamic Reconfigurable Transceiver
  IP Core","  By using the dynamic reconfigurable transceiver in high speed interface
design, designer can solve critical technology problems such as ensuring signal
integrity conveniently, with lower error binary rate. In this paper, we
designed a high speed XAUI (10Gbps Ethernet Attachment Unit Interface) to
transparently extend the physical reach of the XGMII. The following points are
focused: (1) IP (Intellectual Property) core usage. Altera Co. offers two
transceiver IP cores in Quartus II MegaWizard Plug-In Manager for XAUI design
which is featured of dynamic reconfiguration performance, that is,
ALTGX_RECO?FIG instance and ALTGX instance, we can get various groups by
changing settings of the devices without power off. These two blocks can
accomplish function of PCS (Physical Coding Sub-layer) and PMA (Physical Medium
Attachment), however, with higher efficiency and reliability. (2) 1+1
protection. In our design, two ALTGX IP cores are used to work in parallel,
which named XAUI0 and XAUI1. The former works as the main channel while the
latter redundant channel. When XAUI0 is out of service for some reasons, XAUI1
will start to work to keep the business. (3) RTL (Register Transfer Level)
coding with Verilog HDL and simulation. Create the ALTGX_RECO?FIG instance and
ALTGX instance, enable dynamic reconfiguration in the ALTGXB Megafunction, then
connect the ALTGX_RECO?FIG with the ALTGX instances. After RTL coding, the
design was simulated on VCS simulator. The validated result indicates that the
packets are transferred efficiently. FPGA makes high-speed optical
communication system design simplified.
"
390,"Design of an Encryption-Decryption Module Oriented for Internet
  Information Security SOC Design","  In order to protect the security of network data, a high speed chip module
for encrypting and decrypting of network data packet is designed. The chip
module is oriented for internet information security SOC (System on Chip)
design. During the design process, AES (Advanced Encryption Standard) and 3DES
(Data Encryption Standard) encryption algorithm are adopted to protect the
security of network data. The following points are focused: (1) The SOC (System
on Chip) design methodology based on IP (Intellectual Property) core is used.
AES (Advanced Encryption Standard) and 3DES (Data Encryption Standard) IP
(Intellectual Property) cores are embedded in the chip module, peripheral
control sub-modules are designed to control the encryption-decryption module,
which is capable of shortening the design period of the chip module. (2) The
implementation of encryption-decryption with hardware was presented, which
improves the safety of data through the encryption-decryption chip and reduce
the load of CPU. (3) In our hardware solution, two AES (Advanced Encryption
Standard) cores are used to work in parallel, which improves the speed of the
encryption module. Moreover, the key length of AES (Advanced Encryption
Standard) encryption algorithm is designed with three optional configurations
at 128 bits, 256 bits and 192 bits respectively and six optional encryption
algorithm modes: CBC (Cipher Block Chaining) mode, ECB (Electronic Code Book)
mode, GCM (Galois/Counter Mode) mode, XTS(cipherteXT Stealing) mode, CTR
(CounTeR) mode and 3DES respectively, which adds the flexibility to its
applications.
"
391,Reversible Squaring Circuit For Low Power Digital Signal Processing,"  With the high demand of low power digital systems, energy dissipation in the
digital system is one of the limiting factors. Reversible logic is one of the
alternate to reduce heat/energy dissipation in the digital circuits and have a
very significant importance in bioinformatics, optical information processing,
CMOS design etc. In this paper the authors propose the design of new 2- bit
binary Squaring circuit used in most of the digital signal processing hardware
using Feynman & MUX gate. The proposed squaring circuit having less garbage
outputs, constant inputs, Quantum cost and Total logical calculation i.e. less
delay as compared to the traditional method of squaring operation by reversible
multiplier. The simulating results and quantized results are also shown in the
paper which shows the greatest improvement in the design against the previous
methodology.
"
392,L-Shape based Layout Fracturing for E-Beam Lithography,"  Layout fracturing is a fundamental step in mask data preparation and e-beam
lithography (EBL) writing. To increase EBL throughput, recently a new L-shape
writing strategy is proposed, which calls for new L-shape fracturing, versus
the conventional rectangular fracturing. Meanwhile, during layout fracturing,
one must minimize very small/narrow features, also called slivers, due to
manufacturability concern. This paper addresses this new research problem of
how to perform L-shaped fracturing with sliver minimization. We propose two
novel algorithms. The first one, rectangular merging (RM), starts from a set of
rectangular fractures and merges them optimally to form L-shape fracturing. The
second algorithm, direct L-shape fracturing (DLF), directly and effectively
fractures the input layouts into L-shapes with sliver minimization. The
experimental results show that our algorithms are very effective.
"
393,"Triple Patterning Lithography (TPL) Layout Decomposition using
  End-Cutting","  Triple patterning lithography (TPL) is one of the most promising techniques
in the 14nm logic node and beyond. However, traditional LELELE type TPL
technology suffers from native conflict and overlapping problems. Recently
LELEEC process was proposed to overcome the limitations, where the third mask
is used to generate the end-cuts. In this paper we propose the first study for
LELEEC layout decomposition. Conflict graphs and end-cut graphs are constructed
to extract all the geometrical relationships of input layout and end-cut
candidates. Based on these graphs, integer linear programming (ILP) is
formulated to minimize the conflict number and the stitch number.
"
394,"E-BLOW: E-Beam Lithography Overlapping aware Stencil Planning for MCC
  System","  Electron beam lithography (EBL) is a promising maskless solution for the
technology beyond 14nm logic node. To overcome its throughput limitation,
recently the traditional EBL system is extended into MCC system. %to further
improve the throughput. In this paper, we present E-BLOW, a tool to solve the
overlapping aware stencil planning (OSP) problems in MCC system. E-BLOW is
integrated with several novel speedup techniques, i.e., successive relaxation,
dynamic programming and KD-Tree based clustering, to achieve a good performance
in terms of runtime and solution quality. Experimental results show that,
compared with previous works, E-BLOW demonstrates better performance for both
conventional EBL system and MCC system.
"
395,"Self-Aligned Double Patterning Friendly Configuration for Standard Cell
  Library Considering Placement","  Self-aligned double patterning (SADP) has become a promising technique to
push pattern resolution limit to sub-22nm technology node. Although SADP
provides good overlay controllability, it encounters many challenges in
physical design stages to obtain conflict-free layout decomposition. In this
paper, we study the impact on placement by different standard cell layout
decomposition strategies. We propose a SADP friendly standard cell
configuration which provides pre-coloring results for standard cells. These
configurations are brought into the placement stage to help ensure layout
decomposability and save the extra effort for solving conflicts in later
stages.
"
396,Layout decomposition for triple patterning lithography,"  As minimum feature size and pitch spacing further decrease, triple patterning
lithography (TPL) is a possible 193nm extension along the paradigm of double
patterning lithography (DPL). However, there is very little study on TPL layout
decomposition. In this paper, we show that TPL layout decomposition is a more
difficult problem than that for DPL. We then propose a general integer linear
programming formulation for TPL layout decomposition which can simultaneously
minimize conflict and stitch numbers. Since ILP has very poor scalability, we
propose three acceleration techniques without sacrificing solution quality:
independent component computation, layout graph simplification, and bridge
computation. For very dense layouts, even with these speedup techniques, ILP
formulation may still be too slow. Therefore, we propose a novel vector
programming formulation for TPL decomposition, and solve it through effective
semidefinite programming (SDP) approximation. Experimental results show that
the ILP with acceleration techniques can reduce 82% runtime compared to the
baseline ILP. Using SDP based algorithm, the runtime can be further reduced by
42% with some tradeoff in the stitch number (reduced by 7%) and the conflict
(9% more). However, for very dense layouts, SDP based algorithm can achieve
140x speed-up even compared with accelerated ILP.
"
397,"Network flow-based simultaneous retiming and slack budgeting for low
  power design","  Low power design has become one of the most significant requirements when
CMOS technology entered the nanometer era. Therefore, timing budget is often
performed to slow down as many components as possible so that timing slacks can
be applied to reduce the power consumption while maintaining the performance of
the whole design. Retiming is a procedure that involves the relocation of
flip-flops (FFs) across logic gates to achieve faster clocking speed. In this
paper we show that the retiming and slack budgeting problem can be formulated
to a convex cost dual network flow problem. Both the theoretical analysis and
experimental results show the efficiency of our approach which can not only
reduce power consumption by 8.9%, but also speedup previous work by 500 times.
"
398,"Floorplanning and Topology Generation for Application-Specific
  Network-on-Chip","  Network-on-chip (NoC) architectures have been proposed as a promising
alternative to classical bus-based communication architectures. In this paper,
we propose a two phases framework to solve application-specific NoCs topology
generation problem. At floorplanning phase, we carry out partition driven
floorplanning. At post-floorplanning phase, a heuristic method and a min-cost
max-flow algorithm is used to insert switches and network interfaces. Finally,
we allocate paths to minimize power consumption. The experimental results show
our algorithm is effective for power saving.
"
399,Design and Implementation of Bit Transition Counter,"  In today VLSI system design, power consumption is gaining more attention as
compared to performance and area. This is due to battery life in portable
devices and operating frequency of the design. Power consumption mainly
consists of static power, dynamic power, leakage power and short circuit power.
Dynamic power is dominant among all which depends on many factors viz. power
supply, load capacitance and frequency. Switching activity also affects dynamic
power consumption of bus which is determined by calculating the number of bit
transitions on bus. The purpose of this paper is to design a bit transition
counter which can be used to calculate the switching activity of the circuit
nodes. The novel feature is that it can be inserted at any node of the circuit,
thus helpful for calculating power consumption of bus.
"
400,"Methodology for standard cell compliance and detailed placement for
  triple patterning lithography","  As the feature size of semiconductor process further scales to sub-16nm
technology node, triple patterning lithography (TPL) has been regarded one of
the most promising lithography candidates. M1 and contact layers, which are
usually deployed within standard cells, are most critical and complex parts for
modern digital designs. Traditional design flow that ignores TPL in early
stages may limit the potential to resolve all the TPL conflicts. In this paper,
we propose a coherent framework, including standard cell compliance and
detailed placement to enable TPL friendly design. Considering TPL constraints
during early design stages, such as standard cell compliance, improves the
layout decomposability. With the pre-coloring solutions of standard cells, we
present a TPL aware detailed placement, where the layout decomposition and
placement can be resolved simultaneously. Our experimental results show that,
with negligible impact on critical path delay, our framework can resolve the
conflicts much more easily, compared with the traditional physical design flow
and followed layout decomposition.
"
401,"A High-Performance Triple Patterning Layout Decomposer with Balanced
  Density","  Triple patterning lithography (TPL) has received more and more attentions
from industry as one of the leading candidate for 14nm/11nm nodes. In this
paper, we propose a high performance layout decomposer for TPL. Density
balancing is seamlessly integrated into all key steps in our TPL layout
decomposition, including density-balanced semi-definite programming (SDP),
density-based mapping, and density-balanced graph simplification. Our new TPL
decomposer can obtain high performance even compared to previous
state-of-the-art layout decomposers which are not balanced-density aware, e.g.,
by Yu et al. (ICCAD'11), Fang et al. (DAC'12), and Kuang et al. (DAC'13).
Furthermore, the balanced-density version of our decomposer can provide more
balanced density which leads to less edge placement error (EPE), while the
conflict and stitch numbers are still very comparable to our
non-balanced-density baseline.
"
402,Multi-Voltage and Level-Shifter Assignment Driven Floorplanning,"  As technology scales, low power design has become a significant requirement
for SOC designers. Among the existing techniques, Multiple-Supply Voltage (MSV)
is a popular and effective method to reduce both dynamic and static power.
Besides, level shifters consume area and delay, and should be considered during
floorplanning. In this paper, we present a new floorplanning system, called
MVLSAF, to solve multi-voltage and level shifter assignment problem. We use a
convex cost network flow algorithm to assign arbitrary number of legal working
voltages and a minimum cost flow algorithm to handle level-shifter assignment.
The experimental results show MVLSAF is effective.
"
403,"GLOW: A global router for low-power thermal-reliable interconnect
  synthesis using photonic wavelength multiplexing","  In this paper, we examine the integration potential and explore the design
space of low power thermal reliable on-chip interconnect synthesis featuring
nanophotonics Wavelength Division Multiplexing (WDM). With the recent
advancements, it is foreseen that nanophotonics holds the promise to be
employed for future on-chip data signalling due to its unique power efficiency,
signal delay and huge multiplexing potential. However, there are major
challenges to address before feasible on-chip integration could be reached. In
this paper, we present GLOW, a hybrid global router to provide low power
opto-electronic interconnect synthesis under the considerations of thermal
reliability and various physical design constraints such as optical power,
delay and signal quality. GLOW is evaluated with testing cases derived from
ISPD07-08 global routing benchmarks. Compared with a greedy approach, GLOW
demonstrates around 23%-50% of total optical power reduction, revealing great
potential of on-chip WDM interconnect synthesis.
"
404,"EPIC: Efficient prediction of IC manufacturing hotspots with a unified
  meta-classification formulation","  In this paper we present EPIC, an efficient and effective predictor for IC
manufacturing hotspots in deep sub-wavelength lithography. EPIC proposes a
unified framework to combine different hotspot detection methods together, such
as machine learning and pattern matching, using mathematical
programming/optimization. EPIC algorithm has been tested on a number of
industry benchmarks under advanced manufacturing conditions. It demonstrates so
far the best capability in selectively combining the desirable features of
various hotspot detection methods (3.5-8.2% accuracy improvement) as well as
significant suppression of the detection noise (e.g., 80% false-alarm
reduction). These characteristics make EPIC very suitable for conducting high
performance physical verification and guiding efficient manufacturability
friendly physical design.
"
405,TRIAD: a triple patterning lithography aware detailed router,"  TPL-friendly detailed routers require a systematic approach to detect TPL
conflicts. However, the complexity of conflict graph (CG) impedes directly
detecting TPL conflicts in CG. This work proposes a token graph-embedded
conflict graph (TECG) to facilitate the TPL conflict detection while
maintaining high coloring-flexibility. We then develop a TPL aware detailed
router (TRIAD) by applying TECG to a gridless router with the TPL stitch
generation. Compared to a greedy coloring approach, experimental results
indicate that TRIAD generates no conflicts and few stitches with shorter
wirelength at the cost of 2.41x of runtime.
"
406,Voltage and Level-Shifter Assignment Driven Floorplanning,"  Low Power Design has become a significant requirement when the CMOS
technology entered the nanometer era. Multiple-Supply Voltage (MSV) is a
popular and effective method for both dynamic and static power reduction while
maintaining performance. Level shifters may cause area and Interconnect Length
Overhead (ILO), and should be considered at both floorplanning and
post-floorplanning stages. In this paper, we propose a two phases algorithm
framework, called VLSAF, to solve voltage and level shifter assignment problem.
At floorplanning phase, we use a convex cost network flow algorithm to assign
voltage and a minimum cost flow algorithm to handle level-shifter assignment.
At post-floorplanning phase, a heuristic method is adopted to redistribute
white spaces and calculate the positions and shapes of level shifters. The
experimental results show VLSAF is effective.
"
407,Lithography Hotspot Detection and Mitigation in Nanometer VLSI,"  With continued feature size scaling, even state of the art semiconductor
manufacturing processes will often run into layouts with poor printability and
yield. Identifying lithography hotspots is important at both physical
verification and early physical design stages. While detailed lithography
simulations can be very accurate, they may be too computationally expensive for
full-chip scale and physical design inner loops. Meanwhile, pattern matching
and machine learning based hotspot detection methods can provide acceptable
quality and yet fast turn-around-time for full-chip scale physical verification
and design. In this paper, we discuss some key issues and recent results on
lithography hotspot detection and mitigation in nanometer VLSI.
"
408,"The Short-term Memory (D.C. Response) of the Memristor Demonstrates the
  Causes of the Memristor Frequency Effect","  A memristor is often identified by showing its distinctive pinched hysteresis
curve and testing for the effect of frequency. The hysteresis size should
relate to frequency and shrink to zero as the frequency approaches infinity.
Although mathematically understood, the material causes for this are not well
known. The d.c. response of the memristor is a decaying curve with its own
timescale. We show via mathematical reasoning that this decaying curve when
transformed to a.c. leads to the frequency effect by considering a descretized
curve. We then demonstrate the validity of this approach with experimental data
from two different types of memristors.
"
409,Is Spiking Logic the Route to Memristor-Based Computers?,"  Memristors have been suggested as a novel route to neuromorphic computing
based on the similarity between neurons (synapses and ion pumps) and
memristors. The D.C. action of the memristor is a current spike, which we think
will be fruitful for building memristor computers. In this paper, we introduce
4 different logical assignations to implement sequential logic in the memristor
and introduce the physical rules, summation, `bounce-back', directionality and
`diminishing returns', elucidated from our investigations. We then demonstrate
how memristor sequential logic works by instantiating a NOT gate, an AND gate
and a Full Adder with a single memristor. The Full Adder makes use of the
memristor's memory to add three binary values together and outputs the value,
the carry digit and even the order they were input in.
"
410,"Boolean Logic Gates From A Single Memristor Via Low-Level Sequential
  Logic","  By using the memristor's memory to both store a bit and perform an operation
with a second input bit, simple Boolean logic gates have been built with a
single memristor. The operation makes use of the interaction of current spikes
(occasionally called current transients) found in both memristors and other
devices. The sequential time-based logic methodology allows two logical input
bits to be used on a one-port by sending the bits separated in time. The
resulting logic gate is faster than one relying on memristor's state switching,
low power and requires only one memristor. We experimentally demonstrate
working OR and XOR gates made with a single flexible Titanium dioxide sol-gel
memristor.
"
411,"Building fast Bayesian computing machines out of intentionally
  stochastic, digital parts","  The brain interprets ambiguous sensory information faster and more reliably
than modern computers, using neurons that are slower and less reliable than
logic gates. But Bayesian inference, which underpins many computational models
of perception and cognition, appears computationally challenging even given
modern transistor speeds and energy budgets. The computational principles and
structures needed to narrow this gap are unknown. Here we show how to build
fast Bayesian computing machines using intentionally stochastic, digital parts,
narrowing this efficiency gap by multiple orders of magnitude. We find that by
connecting stochastic digital components according to simple mathematical
rules, one can build massively parallel, low precision circuits that solve
Bayesian inference problems and are compatible with the Poisson firing
statistics of cortical neurons. We evaluate circuits for depth and motion
perception, perceptual learning and causal reasoning, each performing inference
over 10,000+ latent variables in real time - a 1,000x speed advantage over
commodity microprocessors. These results suggest a new role for randomness in
the engineering and reverse-engineering of intelligent computation.
"
412,Open Cores for Digital Signal Processing,"  This paper presents the design and implementation of three System on Chip
(SoC) cores, which implement the Digital Signal Processing (DSP) functions:
Finite Impulse Response (FIR) filter, Infinite Impulse Response (IIR) filter
and Fast Fourier Transform (FFT). The FIR filter core is based on the
symmetrical realization form, the IIR filter core is based on the Second Order
Sections (SOS) architecture and the FFT core is based on the Radix $2^2$ Single
Delay Feedback (R$2^2$SDF) architecture. The three cores are compatible with
the Wishbone SoC bus and they were described using generic and structural VHDL.
In system hardware verification was performed by using an OpenRisc-based SoC
synthesized on an Altera FPGA, the tests showed that the designed DSP cores are
suitable for building SoC based on the OpenRisc processor and the Wishbone bus.
"
413,"Five Modular Redundancy with Mitigation Technique to Recover the Error
  Module","  Hazard radiation can lead the system fault therefore Fault Tolerance is
required. Fault Tolerant is a system, which is designed to keep operations
running, despite the degradation in the specific module is happening. Many
fault tolerances have been developed to handle the problem, to find the most
robust and efficient in the possible technology. This paper will present the
Five Modular Redundancy (FMR) with Mitigation Technique to Recover the Error
Module. With Dynamic Partial Reconfiguration technology that have already
available today, such fault tolerance technique can be implemented
successfully. The project showed the robustness of the system is increased and
module which is error can be recovered immediately.
"
414,Development of SyReC based expandable reversible logic circuits,"  Reversible computing is gaining high interest from researchers due to its
various promises. One of the prominent advantages perceived from reversible
logic is that of reduced power dissipation with many reversible gates at hand,
designing a reversible circuit (combinational) has received due attention and
achievement. A proposed language for description of reversible circuit, namely
SyReC, is also in place. What remain are the software tools which would help in
reversible circuit synthesis through simulation. Beginning with the smallest
reversible circuit realizations the SyReC statements and expressions, we employ
a hierarchal approach to develop a complete reversible circuit, entirely from
its SyReC code. We implement this as a software tool. The tool allows a user to
expand a reversible circuit of choice in terms of bit width of its inputs. The
background approach of expansion of a reversible circuit has also been proposed
as a part of this dissertation. Also, a user can use the tool to observe the
effect of expansion on incurred costs, in terms of increase in number of lines,
number of gates and quantum cost. The importance of observing the change in
costs with respect to scale of expansion is important not only from analysis
point of view, but also because the cost depends on the approach used for
expansion. This dissertation also proposes a reversible circuit design for
elevator controller (combinational) and the related costs. The aim is to
emphasize use of the proposed approach is designing customized circuits.
"
415,State Dependent Statistical Timing Model for Voltage Scaled Circuits,"  This paper presents a novel statistical state-dependent timing model for
voltage over scaled (VoS) logic circuits that accurately and rapidly finds the
timing distribution of output bits. Using this model erroneous VoS circuits can
be represented as error-free circuits combined with an error-injector. A case
study of a two point DFT unit employing the proposed model is presented and
compared to HSPICE circuit simulation. Results show an accurate match, with
significant speedup gains.
"
416,"Parallel Interleaver Design for a High Throughput HSPA+/LTE
  Multi-Standard Turbo Decoder","  To meet the evolving data rate requirements of emerging wireless
communication technologies, many parallel architectures have been proposed to
implement high throughput turbo decoders. However, concurrent memory
reading/writing in parallel turbo decoding architectures leads to severe memory
conflict problem, which has become a major bottleneck for high throughput turbo
decoders. In this paper, we propose a flexible and efficient VLSI architecture
to solve the memory conflict problem for highly parallel turbo decoders
targeting multi-standard 3G/4G wireless communication systems. To demonstrate
the effectiveness of the proposed parallel interleaver architecture, we
implemented an HSPA+/LTE/LTE-Advanced multi-standard turbo decoder with a 45nm
CMOS technology. The implemented turbo decoder consists of 16 Radix-4 MAP
decoder cores, and the chip core area is 2.43 mm^2. When clocked at 600 MHz,
this turbo decoder can achieve a maximum decoding throughput of 826 Mbps in the
HSPA+ mode and 1.67 Gbps in the LTE/LTE-Advanced mode, exceeding the peak data
rate requirements for both standards.
"
417,"A Flexible Design for Optimization of Hardware Architecture in
  Distributed Arithmetic based FIR Filters","  FIR filters are used in many performance/power critical applications such as
mobile communication devices, analogue to digital converters and digital signal
processing applications. Design of appropriate FIR filters usually causes the
order of filter to be increased. Synthesis and tape-out of high-order FIR
filters with reasonable delay, area and power has become an important challenge
for hardware designers. In many cases the complexity of high-order filters
causes the constraints of the total design could not be satisfied. In this
paper, efficient hardware architecture is proposed for distributed arithmetic
(DA) based FIR filters. The architecture is based on optimized combination of
Look-up Tables (LUTs) and compressors. The optimized system level solution is
obtained from a set of dynamic programming optimization algorithms. The
experiments show the proposed design educed the delay cost between 16%-62.5% in
comparison of previous optimized structures for DA-based architectures.
"
418,"Design space exploration tools for the ByoRISC configurable processor
  family","  In this paper, the ByoRISC (Build your own RISC) configurable
application-specific instruction-set processor (ASIP) family is presented.
ByoRISCs, as vendor-independent cores, provide extensive architectural
parameters over a baseline processor, which can be customized by
application-specific hardware extensions (ASHEs). Such extensions realize
multi-input multi-output (MIMO) custom instructions with local state and
load/store accesses to the data memory. ByoRISCs incorporate a true multi-port
register file, zero-overhead custom instruction decoding, and scalable data
forwarding mechanisms. Given these design decisions, ByoRISCs provide a unique
combination of features that allow their use as architectural testbeds and the
seamless and rapid development of new high-performance ASIPs.
  The performance characteristics of ByoRISCs, implemented as
vendor-independent cores, have been evaluated for both ASIC and FPGA
implementations, and it is proved that they provide a viable solution in
FPGA-based system-on-a-chip design. A case study of an image processing
pipeline is also presented to highlight the process of utilizing a ByoRISC
custom processor. A peak performance speedup of up to 8.5$\times$ can be
observed, whereas an average performance speedup of 4.4$\times$ on Xilinx
Virtex-4 targets is achieved. In addition, ByoRISC outperforms an experimental
VLIW architecture named VEX even in its 16-wide configuration for a number of
data-intensive application kernels.
"
419,"Instruction-set Selection for Multi-application based ASIP Design: An
  Instruction-level Study","  Efficiency in embedded systems is paramount to achieve high performance while
consuming less area and power. Processors in embedded systems have to be
designed carefully to achieve such design constraints. Application Specific
Instruction set Processors (ASIPs) exploit the nature of applications to design
an optimal instruction set. Despite being not general to execute any
application, ASIPs are highly preferred in the embedded systems industry where
the devices are produced to satisfy a certain type of application domain/s
(either intra-domain or inter-domain). Typically, ASIPs are designed from a
base-processor and functionalities are added for applications. This paper
studies the multi-application ASIPs and their instruction sets, extensively
analysing the instructions for inter-domain and intra-domain designs. Metrics
analysed are the reusable instructions and the extra cost to add a certain
application. A wide range of applications from various application benchmarks
(MiBench, MediaBench and SPEC2006) and domains are analysed for two different
architectures (ARM-Thumb and PISA). Our study shows that the intra-domain
applications contain larger number of common instructions, whereas the
inter-domain applications have very less common instructions, regardless of the
architecture (and therefore the ISA).
"
420,Heterogeneous processor pipeline for a product cipher application,"  Processing data received as a stream is a task commonly performed by modern
embedded devices, in a wide range of applications such as multimedia
(encoding/decoding/ playing media), networking (switching and routing), digital
security, scientific data processing, etc. Such processing normally tends to be
calculation intensive and therefore requiring significant processing power.
Therefore, hardware acceleration methods to increase the performance of such
applications constitute an important area of study. In this paper, we present
an evaluation of one such method to process streaming data, namely
multi-processor pipeline architecture. The hardware is based on a
Multiple-Processor System on Chip (MPSoC), using a data encryption algorithm as
a case study. The algorithm is partitioned on a coarse grained level and mapped
on to an MPSoC with five processor cores in a pipeline, using specifically
configured Xtensa LX3 cores. The system is then selectively optimized by
strengthening and pruning the resources of each processor core. The optimized
system is evaluated and compared against an optimal single-processor System on
Chip (SoC) for the same application. The multiple-processor pipeline system for
data encryption algorithms used was observed to provide significant speed ups,
up to 4.45 times that of the single-processor system, which is close to the
ideal speed up from a five-stage pipeline.
"
421,Generating and evaluating application-specific hardware extensions,"  Modern platform-based design involves the application-specific extension of
embedded processors to fit customer requirements. To accomplish this task, the
possibilities offered by recent custom/extensible processors for tuning their
instruction set and microarchitecture to the applications of interest have to
be exploited. A significant factor often determining the success of this
process is the utomation available in application analysis and custom
instruction generation.
  In this paper we present YARDstick, a design automation tool for custom
processor development flows that focuses on generating and evaluating
application-specific hardware extensions. YARDstick is a building block for
ASIP development, integrating application analysis, custom instruction
generation and selection with user-defined compiler intermediate
representations. In a YARDstick-enabled environment, practical issues in
traditional ASIP design are confronted efficiently; the exploration
infrastructure is liberated from compiler and simulator idiosyncrasies, since
the ASIP designer is empowered with the freedom of specifying the target
architectures of choice and adding new implementations of analyses and custom
instruction generation/selection methods. To illustrate the capabilities of the
YARDstick approach, we present interesting exploration scenarios: quantifying
the effect of machine-dependent compiler optimizations and the selection of the
target architecture in terms of operation set and memory model on custom
instruction generation/selection under different input/output constraints.
"
422,Metal-Gated Junctionless Nanowire Transistors,"  Junctionless Nanowire Field-Effect Transistors (JNFETs), where the channel
region is uniformly doped without the need for source-channel and drain-channel
junctions or lateral doping abruptness, are considered an attractive
alternative to conventional CMOS FETs. Previous theoretical and experimental
works [1][2] on JNFETs have considered polysilicon gates and silicon-dioxide
dielectric. However, with further scaling, JNFETs will suffer from deleterious
effects of doped polysilicon such as high resistance, additional capacitance
due to gate-oxide interface depletion, and incompatibility with high-k
dielectrics[3][4]. In this paper, novel metal- gated high-k JNFETs are
investigated through detailed process and device simulations. These MJNFETs are
also ideally suited for new types of nano-architectures such as N3ASICs [5]
which utilize regular nanowire arrays with limited customization. In such nano-
systems, the simplified device geometry in conjunction with a single-type FET
circuit style [6] would imply that logic arrays could be patterned out of
pre-doped SOI wafers without the need for any additional ion implantation.
"
423,Skybridge: 3-D Integrated Circuit Technology Alternative to CMOS,"  Continuous scaling of CMOS has been the major catalyst in miniaturization of
integrated circuits (ICs) and crucial for global socio-economic progress.
However, scaling to sub-20nm technologies is proving to be challenging as
MOSFETs are reaching their fundamental limits and interconnection bottleneck is
dominating IC operational power and performance. Migrating to 3-D, as a way to
advance scaling, has eluded us due to inherent customization and manufacturing
requirements in CMOS that are incompatible with 3-D organization. Partial
attempts with die-die and layer-layer stacking have their own limitations. We
propose a 3-D IC fabric technology, Skybridge[TM], which offers paradigm shift
in technology scaling as well as design. We co-architect Skybridge's core
aspects, from device to circuit style, connectivity, thermal management, and
manufacturing pathway in a 3-D fabric-centric manner, building on a uniform 3-D
template. Our extensive bottom-up simulations, accounting for detailed material
system structures, manufacturing process, device, and circuit parasitics,
carried through for several designs including a designed microprocessor, reveal
a 30-60x density, 3.5x performance per watt benefits, and 10X reduction in
interconnect lengths vs. scaled 16-nm CMOS. Fabric-level heat extraction
features are shown to successfully manage IC thermal profiles in 3-D. Skybridge
can provide continuous scaling of integrated circuits beyond CMOS in the 21st
century.
"
424,"Comments on ""IEEE 1588 Clock Synchronization using Dual Slave Clocks in
  a Slave""","  In the above letter, Chin and Chen proposed an IEEE 1588 clock
synchronization method based on dual slave clocks, where they claim that
multiple unknown parameters --- i.e., clock offset, clock skew, and
master-to-slave delay --- can be estimated with only one-way time transfers
using more equations than usual. This comment investigates Chin and Chen's dual
clock scheme with detailed models for a master and dual slave clocks and shows
that the formulation of multi-parameter estimation is invalid, which affirms
that it is impossible to distinguish the effect of delay from that of clock
offset at a slave even with dual slave clocks.
"
425,A high-level model of embedded flash energy consumption,"  The alignment of code in the flash memory of deeply embedded SoCs can have a
large impact on the total energy consumption of a computation. We investigate
the effect of code alignment in six SoCs and find that a large proportion of
this energy (up to 15% of total SoC energy consumption) can be saved by changes
to the alignment.
  A flexible model is created to predict the read-access energy consumption of
flash memory on deeply embedded SoCs, where code is executed in place. This
model uses the instruction level memory accesses performed by the processor to
calculate the flash energy consumption of a sequence of instructions. We derive
the model parameters for five SoCs and validate them. The error is as low as
5%, with a 11% average normalized RMS deviation overall.
  The scope for using this model to optimize code alignment is explored across
a range of benchmarks and SoCs. Analysis shows that over 30% of loops can be
better aligned. This can significantly reduce energy while increasing code size
by less than 4%. We conclude that this effect has potential as an effective
optimization, saving significant energy in deeply embedded SoCs.
"
426,A Signal Processor for Gaussian Message Passing,"  In this paper, we present a novel signal processing unit built upon the
theory of factor graphs, which is able to address a wide range of signal
processing algorithms. More specifically, the demonstrated factor graph
processor (FGP) is tailored to Gaussian message passing algorithms. We show how
to use a highly configurable systolic array to solve the message update
equations of nodes in a factor graph efficiently. A proper instruction set and
compilation procedure is presented. In a recursive least squares channel
estimation example we show that the FGP can compute a message update faster
than a state-ofthe- art DSP. The results demonstrate the usabilty of the FGP
architecture as a flexible HW accelerator for signal-processing and
communication systems.
"
427,"Modeling the Temperature Bias of Power Consumption for Nanometer-Scale
  CPUs in Application Processors","  We introduce and experimentally validate a new macro-level model of the CPU
temperature/power relationship within nanometer-scale application processors or
system-on-chips. By adopting a holistic view, this model is able to take into
account many of the physical effects that occur within such systems. Together
with two algorithms described in the paper, our results can be used, for
instance by engineers designing power or thermal management units, to cancel
the temperature-induced bias on power measurements. This will help them gather
temperature-neutral power data while running multiple instance of their
benchmarks. Also power requirements and system failure rates can be decreased
by controlling the CPU's thermal behavior.
  Even though it is usually assumed that the temperature/power relationship is
exponentially related, there is however a lack of publicly available physical
temperature/power measurements to back up this assumption, something our paper
corrects. Via measurements on two pertinent platforms sporting nanometer-scale
application processors, we show that the power/temperature relationship is
indeed very likely exponential over a 20{\deg}C to 85{\deg}C temperature range.
Our data suggest that, for application processors operating between 20{\deg}C
and 50{\deg}C, a quadratic model is still accurate and a linear approximation
is acceptable.
"
428,"Design space exploration for image processing architectures on FPGA
  targets","  Due to the emergence of embedded applications in image and video processing,
communication and cryptography, improvement of pictorial information for better
human perception like deblurring, denoising in several fields such as satellite
imaging, medical imaging, mobile applications etc. are gaining importance for
renewed research. Behind such developments, the primary responsibility lies
with the advancement of semiconductor technology leading to FPGA based
programmable logic devices, which combines the advantages of both custom
hardware and dedicated DSP resources. In addition, FPGA provides powerful
reconfiguration feature and hence is an ideal target for rapid prototyping. We
have endeavoured to exploit exceptional features of FPGA technology in respect
to hardware parallelism leading to higher computational density and throughput,
and have observed better performances than those one can get just merely
porting the image processing software algorithms to hardware. In this paper, we
intend to present an elaborate review, based on our expertise and experiences,
on undertaking necessary transformation to an image processing software
algorithm including the optimization techniques that makes its operation in
hardware comparatively faster.
"
429,A Survey of Methods For Analyzing and Improving GPU Energy Efficiency,"  Recent years have witnessed a phenomenal growth in the computational
capabilities and applications of GPUs. However, this trend has also led to
dramatic increase in their power consumption. This paper surveys research works
on analyzing and improving energy efficiency of GPUs. It also provides a
classification of these techniques on the basis of their main research idea.
Further, it attempts to synthesize research works which compare energy
efficiency of GPUs with other computing systems, e.g. FPGAs and CPUs. The aim
of this survey is to provide researchers with knowledge of state-of-the-art in
GPU power management and motivate them to architect highly energy-efficient
GPUs of tomorrow.
"
430,"Hardware Efficient WiMAX Deinterleaver Capable of Address Generation for
  Random Interleaving Depths","  The variation in the prescribed modulation schemes and code rates for WiMAX
interleaver design, as defined by IEEE 802.16 standard, demands a plethora of
hardware if all the modulation schemes and code rates have to be unified into a
single electronic device. Add to this the complexities involved with the
algorithms and permutations of the WiMAX standard, invariably dependent on
floor function which is extremely hardware inefficient. This paper is an
attempt towards removing the complexities and excess hardware involvement in
the implementation of the permutations involved in Deinterleaver designs as
defined by IEEE 802.16
"
431,FPGA design of a cdma2000 turbo decoder,"  This paper presents the FPGA hardware design of a turbo decoder for the
cdma2000 standard. The work includes a study and mathematical analysis of the
turbo decoding process, based on the MAX-Log-MAP algorithm. Results of decoding
for a packet size of two hundred fifty bits are presented, as well as an
analysis of area versus performance, and the key variables for hardware design
in turbo decoding.
"
432,"Multiplierless Approximate 4-point DCT VLSI Architectures for Transform
  Block Coding","  Two multiplierless algorithms are proposed for 4x4 approximate-DCT for
transform coding in digital video. Computational architectures for 1-D/2-D
realisations are implemented using Xilinx FPGA devices. CMOS synthesis at the
45 nm node indicate real-time operation at 1 GHz yielding 4x4 block rates of
125 MHz at less than 120 mW of dynamic power consumption.
"
433,Massively Parallel Processor Architectures for Resource-aware Computing,"  We present a class of massively parallel processor architectures called
invasive tightly coupled processor arrays (TCPAs). The presented processor
class is a highly parameterizable template, which can be tailored before
runtime to fulfill costumers' requirements such as performance, area cost, and
energy efficiency. These programmable accelerators are well suited for
domain-specific computing from the areas of signal, image, and video processing
as well as other streaming processing applications. To overcome future scaling
issues (e.g., power consumption, reliability, resource management, as well as
application parallelization and mapping), TCPAs are inherently designed in a
way to support self-adaptivity and resource awareness at hardware level. Here,
we follow a recently introduced resource-aware parallel computing paradigm
called invasive computing where an application can dynamically claim, execute,
and release resources. Furthermore, we show how invasive computing can be used
as an enabler for power management. Finally, we will introduce ideas on how to
realize fault-tolerant loop execution on such massively parallel architectures
through employing on-demand spatial redundancies at the processor array level.
"
434,"Emulated ASIC Power and Temperature Monitor System for FPGA Prototyping
  of an Invasive MPSoC Computing Architecture","  In this contribution the emulation of an ASIC temperature and power
monitoring system (TPMon) for FPGA prototyping is presented and tested to
control processor temperatures under different control targets and operating
strategies. The approach for emulating the power monitor is based on an
instruction-level energy model. For emulating the temperature monitor, a
thermal RC model is used. The monitoring system supplies an invasive MPSoC
computing architecture with hardware status information (power and temperature
data of the processors within the system). These data are required for
resource-aware load distribution. As a proof of concept different operating
strategies and control targets were evaluated for a 2-tile invasive MPSoC
computing system.
"
435,Architectural Design of a RAM Arbiter,"  Standard memory modules to store (and access) data are designed for use with
a single system accessing it. More complicated memory modules would be accessed
through a memory controller, which are also designed for one system. For
multiple systems to access a single memory module there must be some
facilitation that allows them to access the memory without overriding or
corrupting the access from the others. This was done with the use of a memory
arbiter, which controls the flow of traffic into the memory controller. The
arbiter has a set of rules to abide to in order to choose which system gets
through to the memory controller. In this project, a regular RAM module is
designed for use with one system. Furthermore, a memory arbiter is also
designed in Verilog that allows for more than one system to use a single RAM
module in a controlled and synchronized manner. The arbiter uses a fixed
priority scheme to avoid starvation of the system. In addition one of the major
problems associated with such systems i.e. The Address Clash Problem has been
nicely tackled and solved. The design is verified in simulation and validated
on a Xilinx ML605 evaluation board with a Virtex 6 FPGA.
"
436,"Network Function Virtualization based on FPGAs:A Framework for
  all-Programmable network devices","  Network Function Virtualization (NFV) refers to the use of commodity hardware
resources as the basic platform to perform specialized network functions as
opposed to specialized hardware devices. Currently, NFV is mainly implemented
based on general purpose processors, or general purpose network processors. In
this paper we propose the use of FPGAs as an ideal platform for NFV that can be
used to provide both the flexibility of virtualizations and the high
performance of the specialized hardware. We present the early attempts of using
FPGAs dynamic reconfiguration in network processing applications to provide
flexible network functions and we present the opportunities for an FPGA-based
NFV platform.
"
437,Modeling Algorithms in SystemC and ACL2,"  We describe the formal language MASC, based on a subset of SystemC and
intended for modeling algorithms to be implemented in hardware. By means of a
special-purpose parser, an algorithm coded in SystemC is converted to a MASC
model for the purpose of documentation, which in turn is translated to ACL2 for
formal verification. The parser also generates a SystemC variant that is
suitable as input to a high-level synthesis tool. As an illustration of this
methodology, we describe a proof of correctness of a simple 32-bit radix-4
multiplier.
"
438,The Z1: Architecture and Algorithms of Konrad Zuse's First Computer,"  This paper provides the first comprehensive description of the Z1, the
mechanical computer built by the German inventor Konrad Zuse in Berlin from
1936 to 1938. The paper describes the main structural elements of the machine,
the high-level architecture, and the dataflow between components. The computer
could perform the four basic arithmetic operations using floating-point
numbers. Instructions were read from punched tape. A program consisted of a
sequence of arithmetical operations, intermixed with memory store and load
instructions, interrupted possibly by input and output operations. Numbers were
stored in a mechanical memory. The machine did not include conditional
branching in the instruction set. While the architecture of the Z1 is similar
to the relay computer Zuse finished in 1941 (the Z3) there are some significant
differences. The Z1 implements operations as sequences of microinstructions, as
in the Z3, but does not use rotary switches as micro-steppers. The Z1 uses a
digital incrementer and a set of conditions which are translated into
microinstructions for the exponent and mantissa units, as well as for the
memory blocks. Microinstructions select one out of 12 layers in a machine with
a 3D mechanical structure of binary mechanical elements. The exception circuits
for mantissa zero, necessary for normalized floating-point, were lacking; they
were first implemented in the Z3. The information for this article was
extracted from careful study of the blueprints drawn by Zuse for the
reconstruction of the Z1 for the German Technology Museum in Berlin, from some
letters, and from sketches in notebooks. Although the machine has been in
exhibition since 1989 (non-operational), no detailed high-level description of
the machine's architecture had been available. This paper fills that gap.
"
439,"NaNet: a Low-Latency, Real-Time, Multi-Standard Network Interface Card
  with GPUDirect Features","  While the GPGPU paradigm is widely recognized as an effective approach to
high performance computing, its adoption in low-latency, real-time systems is
still in its early stages.
  Although GPUs typically show deterministic behaviour in terms of latency in
executing computational kernels as soon as data is available in their internal
memories, assessment of real-time features of a standard GPGPU system needs
careful characterization of all subsystems along data stream path.
  The networking subsystem results in being the most critical one in terms of
absolute value and fluctuations of its response latency.
  Our envisioned solution to this issue is NaNet, a FPGA-based PCIe Network
Interface Card (NIC) design featuring a configurable and extensible set of
network channels with direct access through GPUDirect to NVIDIA Fermi/Kepler
GPU memories.
  NaNet design currently supports both standard - GbE (1000BASE-T) and 10GbE
(10Base-R) - and custom - 34~Gbps APElink and 2.5~Gbps deterministic latency
KM3link - channels, but its modularity allows for a straightforward inclusion
of other link technologies.
  To avoid host OS intervention on data stream and remove a possible source of
jitter, the design includes a network/transport layer offload module with
cycle-accurate, upper-bound latency, supporting UDP, KM3link Time Division
Multiplexing and APElink protocols.
  After NaNet architecture description and its latency/bandwidth
characterization for all supported links, two real world use cases will be
presented: the GPU-based low level trigger for the RICH detector in the NA62
experiment at CERN and the on-/off-shore data link for KM3 underwater neutrino
telescope.
"
440,An Efficient Synchronous Static Memory design for Embedded System,"  Custom memory organization are challenging task in the area of VLSI design.
This study aims to design high speed and low power consumption memory for
embedded system. Synchronous SRAM has been proposed and analyzed using various
simulators. Xilinx simulator simulates the Synchronous SRAM memories which can
perform efficient read/write capability for embedded systems. Xinix tool also
provide the access time that required selecting a word and reading it.
Synchronous Static RAM which has easily read /writes capability and performs
scheduled read /writes operation in efficient manner.
"
441,"Application Specific Cache Simulation Analysis for Application Specific
  Instruction set Processor","  An Efficient Simulation of application specific instruction-set processors
(ASIP) is a challenging onus in the area of VLSI design. This paper
reconnoiters the possibility of use of ASIP simulators for ASIP Simulation.
This proposed study allow as the simulation of the cache memory design with
various ASIP simulators like Simple scalar and VEX. In this paper we have
implemented the memory configuration according to desire application. These
simulators performs the cache related results such as cache name, sets, cache
associativity, cache block size, cache replacement policy according to specific
application.
"
442,"Preemptive Thread Block Scheduling with Online Structural Runtime
  Prediction for Concurrent GPGPU Kernels","  Recent NVIDIA Graphics Processing Units (GPUs) can execute multiple kernels
concurrently. On these GPUs, the thread block scheduler (TBS) uses the FIFO
policy to schedule their thread blocks. We show that FIFO leaves performance to
chance, resulting in significant loss of performance and fairness. To improve
performance and fairness, we propose use of the preemptive Shortest Remaining
Time First (SRTF) policy instead. Although SRTF requires an estimate of runtime
of GPU kernels, we show that such an estimate of the runtime can be easily
obtained using online profiling and exploiting a simple observation on GPU
kernels' grid structure. Specifically, we propose a novel Structural Runtime
Predictor. Using a simple Staircase model of GPU kernel execution, we show that
the runtime of a kernel can be predicted by profiling only the first few thread
blocks. We evaluate an online predictor based on this model on benchmarks from
ERCBench, and find that it can estimate the actual runtime reasonably well
after the execution of only a single thread block. Next, we design a thread
block scheduler that is both concurrent kernel-aware and uses this predictor.
We implement the SRTF policy and evaluate it on two-program workloads from
ERCBench. SRTF improves STP by 1.18x and ANTT by 2.25x over FIFO. When compared
to MPMax, a state-of-the-art resource allocation policy for concurrent kernels,
SRTF improves STP by 1.16x and ANTT by 1.3x. To improve fairness, we also
propose SRTF/Adaptive which controls resource usage of concurrently executing
kernels to maximize fairness. SRTF/Adaptive improves STP by 1.12x, ANTT by
2.23x and Fairness by 2.95x compared to FIFO. Overall, our implementation of
SRTF achieves system throughput to within 12.64% of Shortest Job First (SJF, an
oracle optimal scheduling policy), bridging 49% of the gap between FIFO and
SJF.
"
443,Selective Match-Line Energizer Content Addressable Memory(SMLE -CAM),"  A Content Addressable Memory (CAM) is a memory primarily designed for high
speed search operation. Parallel search scheme forms the basis of CAM, thus
power reduction is the challenge associated with a large amount of parallel
active circuits. We are presenting a novel algorithm and architecture described
as Selective Match-Line Energizer Content Addressable Memory (SMLE-CAM) which
energizes only those MLs (Match-Line) whose first three bits are conditionally
matched with corresponding first three search bit using special architecture
which comprises of novel XNOR-CAM cell and novel XOR-CAM cell. The rest of the
CAM chain is followed by NOR-CAM cell. The 256 X 144 bit SMLE-CAM is
implemented in TSMC 90 nm technology and its robustness across PVT variation is
verified. The post-layout simulation result shows, it has energy metric of
0.115 fJ/bit/search with search time 361.6 ps, the best reported so far. The
maximum operating frequency is 1GHz.
"
444,"Application Specific Hardware Design Simulation for High Performance
  Embedded System","  Application specific simulation is challenging task in various real time high
performance embedded devices. In this study specific application is implemented
with the help of Xilinx. Xilinx provides SDK and XPS tools, XPS tools used for
develop complete hardware platform and SDK provides software platform for
application creation and verification. Xilinx XUP-5 board have been used and
implemented various specific Applications with hardware platform. In this study
the base instruction set with customized instructions, supported with specific
hardware resources are analyzed.
"
445,"FPGA Based Efficient Multiplier for Image Processing Applications Using
  Recursive Error Free Mitchell Log Multiplier and KOM Architecture","  The Digital Image processing applications like medical imaging, satellite
imaging, Biometric trait images etc., rely on multipliers to improve the
quality of image. However, existing multiplication techniques introduce errors
in the output with consumption of more time, hence error free high speed
multipliers has to be designed. In this paper we propose FPGA based Recursive
Error Free Mitchell Log Multiplier (REFMLM) for image Filters. The 2x2 error
free Mitchell log multiplier is designed with zero error by introducing error
correction term is used in higher order Karastuba-Ofman Multiplier (KOM)
Architectures. The higher order KOM multipliers is decomposed into number of
lower order multipliers using radix 2 till basic multiplier block of order 2x2
which is designed by error free Mitchell log multiplier. The 8x8 REFMLM is
tested for Gaussian filter to remove noise in fingerprint image. The Multiplier
is synthesized using Spartan 3 FPGA family device XC3S1500-5fg320. It is
observed that the performance parameters such as area utilization, speed, error
and PSNR are better in the case of proposed architecture compared to existing
architectures
"
446,"An ECG-SoC with 535nW/channel lossless data compression for wearable
  sensors","  This paper presents a low power ECG recording Sys-tem-on-Chip (SoC) with
on-chip low complexity lossless ECG compression for data reduction in
wireless/ambulatory ECG sensor devices. The proposed algorithm uses a linear
slope predictor to estimate the ECG samples, and uses a novel low complexity
dynamic coding-packaging scheme to frame the resulting estimation error into
fixed-length 16-bit format. The proposed technique achieves an average
compression ratio of 2.25x on MIT/BIH ECG database. Implemented in 0.35 {\mu}m
process, the compressor uses 0.565 K gates/channel occupying 0.4 mm2 for
4-channel, and consumes 535 nW/channel at 2.4V for ECG sampled at 512 Hz. Small
size and ultra-low power consumption makes the proposed technique suitable for
wearable ECG sensor application.
"
447,RTL2RTL Formal Equivalence: Boosting the Design Confidence,"  Increasing design complexity driven by feature and performance requirements
and the Time to Market (TTM) constraints force a faster design and validation
closure. This in turn enforces novel ways of identifying and debugging
behavioral inconsistencies early in the design cycle. Addition of incremental
features and timing fixes may alter the legacy design behavior and would
inadvertently result in undesirable bugs. The most common method of verifying
the correctness of the changed design is to run a dynamic regression test suite
before and after the intended changes and compare the results, a method which
is not exhaustive. Modern Formal Verification (FV) techniques involving new
methods of proving Sequential Hardware Equivalence enabled a new set of
solutions for the given problem, with complete coverage guarantee. Formal
Equivalence can be applied for proving functional integrity after design
changes resulting from a wide variety of reasons, ranging from simple pipeline
optimizations to complex logic redistributions. We present here our experience
of successfully applying the RTL to RTL (RTL2RTL) Formal Verification across a
wide spectrum of problems on a Graphics design. The RTL2RTL FV enabled checking
the design sanity in a very short time, thus enabling faster and safer design
churn. The techniques presented in this paper are applicable to any complex
hardware design.
"
448,"New Trends in Parallel and Distributed Simulation: from Many-Cores to
  Cloud Computing","  Recent advances in computing architectures and networking are bringing
parallel computing systems to the masses so increasing the number of potential
users of these kinds of systems. In particular, two important technological
evolutions are happening at the ends of the computing spectrum: at the ""small""
scale, processors now include an increasing number of independent execution
units (cores), at the point that a mere CPU can be considered a parallel
shared-memory computer; at the ""large"" scale, the Cloud Computing paradigm
allows applications to scale by offering resources from a large pool on a
pay-as-you-go model. Multi-core processors and Clouds both require applications
to be suitably modified to take advantage of the features they provide. In this
paper, we analyze the state of the art of parallel and distributed simulation
techniques, and assess their applicability to multi-core architectures or
Clouds. It turns out that most of the current approaches exhibit limitations in
terms of usability and adaptivity which may hinder their application to these
new computing architectures. We propose an adaptive simulation mechanism, based
on the multi-agent system paradigm, to partially address some of those
limitations. While it is unlikely that a single approach will work well on both
settings above, we argue that the proposed adaptive mechanism has useful
features which make it attractive both in a multi-core processor and in a Cloud
system. These features include the ability to reduce communication costs by
migrating simulation components, and the support for adding (or removing) nodes
to the execution architecture at runtime. We will also show that, with the help
of an additional support layer, parallel and distributed simulations can be
executed on top of unreliable resources.
"
449,Modeling and simulation of multiprocessor systems MPSoC by SystemC/TLM2,"  The current manufacturing technology allows the integration of a complex
multiprocessor system on one piece of silicon (MPSoC for Multiprocessor
System-on- Chip). One way to manage the growing complexity of these systems is
to increase the level of abstraction and to address the system-level design. In
this paper, we focus on the implementation in SystemC language with TLM
(Transaction Level Model) to model an MPSOC platform. Our main contribution is
to define a comprehensive, fast and accurate method for designing and
evaluating performance for MPSoC systems. The studied MPSoC is composed of
MicroBlaze microprocessors, memory, a timer, a VGA and an interrupt handler
with two examples of software. This paper has two novel contributions: the
first is to develop this MPSOC at CABA and TLM for ISS (Instruction Set
Simulator), Native simulations and timed Programmer s View (PV+T); the second
is to show that with PV+T simulations we can achieve timing fidelity with
higher speeds than CABA simulations and have almost the same precision.
"
450,"Proceedings of the First International Workshop on FPGAs for Software
  Programmers (FSP 2014)","  This volume contains the papers accepted at the First International Workshop
on FPGAs for Software Programmers (FSP 2014), held in Munich, Germany,
September 1st, 2014. FSP 2014 was co-located with the International Conference
on Field Programmable Logic and Applications (FPL).
"
451,A Many-Core Overlay for High-Performance Embedded Computing on FPGAs,"  In this work, we propose a configurable many-core overlay for
high-performance embedded computing. The size of internal memory, supported
operations and number of ports can be configured independently for each core of
the overlay. The overlay was evaluated with matrix multiplication, LU
decomposition and Fast-Fourier Transform (FFT) on a ZYNQ-7020 FPGA platform.
The results show that using a system-level many-core overlay avoids complex
hardware design and still provides good performance results.
"
452,"On Delay Faults Affecting I/O Blocks of an SRAM-Based FPGA Due to
  Ionizing Radiations","  Experimental means to characterize delay faults induced by bit flips and SEUs
in I/O blocks of SRAM-based FPGAs are proposed. A delay fault up to 6.2ns
sensitized by an events chain is reported.
"
453,"Design of Novel Algorithm and Architecture for Gaussian Based Color
  Image Enhancement System for Real Time Applications","  This paper presents the development of a new algorithm for Gaussian based
color image enhancement system. The algorithm has been designed into
architecture suitable for FPGA/ASIC implementation. The color image enhancement
is achieved by first convolving an original image with a Gaussian kernel since
Gaussian distribution is a point spread function which smoothen the image.
Further, logarithm-domain processing and gain/offset corrections are employed
in order to enhance and translate pixels into the display range of 0 to 255.
The proposed algorithm not only provides better dynamic range compression and
color rendition effect but also achieves color constancy in an image. The
design exploits high degrees of pipelining and parallel processing to achieve
real time performance. The design has been realized by RTL compliant Verilog
coding and fits into a single FPGA with a gate count utilization of 321,804.
The proposed method is implemented using Xilinx Virtex-II Pro XC2VP40-7FF1148
FPGA device and is capable of processing high resolution color motion pictures
of sizes of up to 1600x1200 pixels at the real time video rate of 116 frames
per second. This shows that the proposed design would work for not only still
images but also for high resolution video sequences.
"
454,An Efficient List Decoder Architecture for Polar Codes,"  Long polar codes can achieve the symmetric capacity of arbitrary binary-input
discrete memoryless channels under a low complexity successive cancelation (SC)
decoding algorithm. However, for polar codes with short and moderate code
length, the decoding performance of the SC algorithm is inferior. The cyclic
redundancy check (CRC) aided successive cancelation list (SCL) decoding
algorithm has better error performance than the SC algorithm for short or
moderate polar codes. In this paper, we propose an efficient list decoder
architecture for the CRC aided SCL algorithm, based on both algorithmic
reformulations and architectural techniques. In particular, an area efficient
message memory architecture is proposed to reduce the area of the proposed
decoder architecture. An efficient path pruning unit suitable for large list
size is also proposed. For a polar code of length 1024 and rate $\frac{1}{2}$,
when list size $L=2$ and 4, the proposed list decoder architecture is
implemented under a TSMC 90nm CMOS technology. Compared with the list decoders
in the literature, our decoder achieves 1.33 to 1.96 times hardware efficiency.
"
455,"Rank-Aware Dynamic Migrations and Adaptive Demotions for DRAM Power
  Management","  Modern DRAM architectures allow a number of low-power states on individual
memory ranks for advanced power management. Many previous studies have taken
advantage of demotions on low-power states for energy saving. However, most of
the demotion schemes are statically performed on a limited number of
pre-selected low-power states, and are suboptimal for different workloads and
memory architectures. Even worse, the idle periods are often too short for
effective power state transitions, especially for memory intensive
applications. Wrong decisions on power state transition incur significant
energy and delay penalties. In this paper, we propose a novel memory system
design named RAMZzz with rank-aware energy saving optimizations including
dynamic page migrations and adaptive demotions. Specifically, we group the
pages with similar access locality into the same rank with dynamic page
migrations. Ranks have their hotness: hot ranks are kept busy for high
utilization and cold ranks can have more lengthy idle periods for power state
transitions. We further develop adaptive state demotions by considering all
low-power states for each rank and a prediction model to estimate the
power-down timeout among states. We experimentally compare our algorithm with
other energy saving policies with cycle-accurate simulation. Experiments with
benchmark workloads show that RAMZzz achieves significant improvement on
energy-delay2 and energy consumption over other energy saving techniques.
"
456,"An ECG-on-Chip with 535-nW/Channel Integrated Lossless Data Compressor
  for Wireless Sensors","  This paper presents a low-power ECG recording system-on-chip (SoC) with
on-chip low-complexity lossless ECG compression for data reduction in
wireless/ambulatory ECG sensor devices. The chip uses a linear slope predictor
for data compression, and incorporates a novel low-complexity dynamic
coding-packaging scheme to frame the prediction error into fixed-length 16-bit
format. The proposed technique achieves an average compression ratio of 2.25x
on MIT/BIH ECG database. Implemented in a standard 0.35 um process, the
compressor uses 0.565K gates/channel occupying 0.4 mm2 for four channels, and
consumes 535 nW/channel at 2.4 V for ECG sampled at 512 Hz. Small size and
ultra-low power consumption makes the proposed technique suitable for wearable
ECG sensor applications.
"
457,An ECG-on-Chip for Wearable Cardiac Monitoring Devices,"  This paper describes a highly integrated, low power chip solution for ECG
signal processing in wearable devices. The chip contains an instrumentation
amplifier with programmable gain, a band-pass filter, a 12-bit SAR ADC, a novel
QRS detector, 8K on-chip SRAM, and relevant control circuitry and CPU
interfaces. The analog front end circuits accurately senses and digitizes the
raw ECG signal, which is then filtered to extract the QRS. The sampling
frequency used is 256 Hz. ECG samples are buffered locally on an asynchronous
FIFO and is read out using a faster clock, as and when it is required by the
host CPU via an SPI interface. The chip was designed and implemented in 0.35um
standard CMOS process. The analog core operates at 1V while the digital
circuits and SRAM operate at 3.3V. The chip total core area is 5.74 mm^2 and
consumes 9.6uW. Small size and low power consumption make this design suitable
for usage in wearable heart monitoring devices.
"
458,"Memristive Threshold Logic Circuit Design of Fast Moving Object
  Detection","  Real-time detection of moving objects involves memorisation of features in
the template image and their comparison with those in the test image. At high
sampling rates, such techniques face the problems of high algorithmic
complexity and component delays. We present a new resistive switching based
threshold logic cell which encodes the pixels of a template image. The cell
comprises a voltage divider circuit that programs the resistances of the
memristors arranged in a single node threshold logic network and the output is
encoded as a binary value using a CMOS inverter gate. When a test image is
applied to the template-programmed cell, a mismatch in the respective pixels is
seen as a change in the output voltage of the cell. The proposed cell when
compared with CMOS equivalent implementation shows improved performance in
area, leakage power, power dissipation and delay.
"
459,"On Metric Sorting for Successive Cancellation List Decoding of Polar
  Codes","  We focus on the metric sorter unit of successive cancellation list decoders
for polar codes, which lies on the critical path in all current hardware
implementations of the decoder. We review existing metric sorter architectures
and we propose two new architectures that exploit the structure of the path
metrics in a log-likelihood ratio based formulation of successive cancellation
list decoding. Our synthesis results show that, for the list size of $L=32$,
our first proposed sorter is $14\%$ faster and $45\%$ smaller than existing
sorters, while for smaller list sizes, our second sorter has a higher delay in
return for up to $36\%$ reduction in the area.
"
460,"Multi Core SSL/TLS Security Processor Architecture Prototype Design with
  automated Preferential Algorithm in FPGA","  In this paper a pipelined architecture of a high speed network security
processor (NSP) for SSL,TLS protocol is implemented on a system on chip (SOC)
where hardware information of all encryption, hashing and key exchange
algorithms are stored in flash memory in terms of bit files, in contrary to
related works where all are actually implemented in hardware. The NSP finds
applications in e-commerce, virtual private network (VPN) and in other fields
that require data confidentiality. The motivation of the present work is to
dynamically execute applications with stipulated throughput within budgeted
hardware resource and power. A preferential algorithm choosing an appropriate
cipher suite is proposed, which is based on Efficient System Index (ESI) budget
comprising of power, throughput and resource given by the user. The bit files
of the chosen security algorithms are downloaded from the flash memory to the
partial region of field programmable gate array (FPGA). The proposed SOC
controls data communication between an application running in a system through
a PCI and the Ethernet interface of a network. Partial configuration feature is
used in ISE14.4 suite with ZYNQ 7z020-clg484 FPGA platform. The performances
"
461,Programming the Adapteva Epiphany 64-core Network-on-chip Coprocessor,"  In the construction of exascale computing systems energy efficiency and power
consumption are two of the major challenges. Low-power high performance
embedded systems are of increasing interest as building blocks for large scale
high- performance systems. However, extracting maximum performance out of such
systems presents many challenges. Various aspects from the hardware
architecture to the programming models used need to be explored. The Epiphany
architecture integrates low-power RISC cores on a 2D mesh network and promises
up to 70 GFLOPS/Watt of processing efficiency. However, with just 32 KB of
memory per eCore for storing both data and code, and only low level inter-core
communication support, programming the Epiphany system presents several
challenges. In this paper we evaluate the performance of the Epiphany system
for a variety of basic compute and communication operations. Guided by this
data we explore strategies for implementing scientific applications on memory
constrained low-powered devices such as the Epiphany. With future systems
expected to house thousands of cores in a single chip, the merits of such
architectures as a path to exascale is compared to other competing systems.
"
462,Inner Loop Optimizations in Mapping Single Threaded Programs to Hardware,"  In the context of mapping high-level algorithms to hardware, we consider the
basic problem of generating an efficient hardware implementation of a single
threaded program, in particular, that of an inner loop. We describe a
control-flow mechanism which provides dynamic loop-pipelining capability in
hardware, so that multiple iterations of an arbitrary inner loop can be made
simultaneously active in the generated hardware, We study the impact of this
loop-pipelining scheme in conjunction with source-level loop-unrolling. In
particular, we apply this technique to some common loop kernels: regular
kernels such as the fast-fourier transform and matrix multiplication, as well
as an example of an inner loop whose body has branching. The resulting
resulting hardware descriptions are synthesized to an FPGA target, and then
characterized for performance and resource utilization. We observe that the use
of dynamic loop-pipelining mechanism alone typically results in a significant
improvements in the performance of the hardware. If the loop is statically
unrolled and if loop-pipelining is applied to the unrolled program, then the
performance improvement is still substantial. When dynamic loop pipelining is
used in conjunction with static loop unrolling, the improvement in performance
ranges from 6X to 20X (in terms of number of clock cycles needed for the
computation) across the loop kernels that we have studied. These optimizations
do have a hardware overhead, but, in spite of this, we observe that the joint
use of these loop optimizations not only improves performance, but also the
performance/cost ratio of the resulting hardware.
"
463,"Energy Efficient Full Adder Cell Design With Using Carbon Nanotube Field
  Effect Transistors In 32 Nanometer Technology","  Full Adder is one of the critical parts of logical and arithmetic units. So,
presenting a low power full adder cell reduces the power consumption of the
entire circuit. Also, using Nano-scale transistors, because of their unique
characteristics will save energy consumption and decrease the chip area. In
this paper we presented a low power full adder cell by using carbon nanotube
field effect transistors (CNTFETs). Simulation results were carried out using
HSPICE based on the CNTFET model in 32 nanometer technology in Different values
of temperature and VDD.
"
464,"Designing high-speed, low-power full adder cells based on carbon
  nanotube technology","  This article presents novel high speed and low power full adder cells based
on carbon nanotube field effect transistor (CNFET). Four full adder cells are
proposed in this article. First one (named CN9P4G) and second one (CN9P8GBUFF)
utilizes 13 and 17 CNFETs respectively. Third design that we named CN10PFS uses
only 10 transistors and is full swing. Finally, CN8P10G uses 18 transistors and
divided into two modules, causing Sum and Cout signals are produced in a
parallel manner. All inputs have been used straight, without inverting. These
designs also used the special feature of CNFET that is controlling the
threshold voltage by adjusting the diameters of CNFETs to achieve the best
performance and right voltage levels. All simulation performed using Synopsys
HSPICE software and the proposed designs are compared to other classical and
modern CMOS and CNFET-based full adder cells in terms of delay, power
consumption and power delay product.
"
465,Fast Prefix Adders for Non-Uniform Input Arrival Times,"  We consider the problem of constructing fast and small parallel prefix adders
for non-uniform input arrival times. This problem arises whenever the adder is
embedded into a more complex circuit, e. g. a multiplier.
  Most previous results are based on representing binary carry-propagate adders
as so-called parallel prefix graphs, in which pairs of generate and propagate
signals are combined using complex gates known as prefix gates. Adders
constructed in this model usually minimize the delay in terms of these prefix
gates. However, the delay in terms of logic gates can be worse by a factor of
two.
  In contrast, we aim to minimize the delay of the underlying logic circuit
directly. We prove a lower bound on the delay of a carry bit computation
achievable by any prefix carry bit circuit and develop an algorithm that
computes a prefix carry bit circuit with optimum delay up to a small additive
constant. Furthermore, we use this algorithm to construct a small parallel
prefix adder.
  Compared to existing algorithms we simultaneously improve the delay and size
guarantee, as well as the running time for constructing prefix carry bit and
adder circuits.
"
466,Evaluation of silicon consumption for a connectionless Network-on-Chip,"  We present the design and evaluation of a predictable Network-on-Chip (NoC)
to interconnect processing units running multimedia applications with
variable-bit-rate. The design is based on a connectionless strategy in which
flits from different communication flows are interleaved in the same
communication channel between routers. Each flit carries routing information
used by routers to perform arbitration and scheduling of the corresponding
output communication channel. Analytic comparisons show that our approach keeps
average latency lower than a network based on resource reservation, when both
networks are working over 80% of offered load. We also evaluate the proposed
NoC on FPGA and ASIC technologies to understand the trade-off due to our
approach, in terms of silicon consumption.
"
467,Analog Signal Processing Solution for Image Alignment,"  Imaging and Image sensors is a field that is continuously evolving. There are
new products coming into the market every day. Some of these have very severe
Size, Weight and Power constraints whereas other devices have to handle very
high computational loads. Some require both these conditions to be met
simultaneously. Current imaging architectures and digital image processing
solutions will not be able to meet these ever increasing demands. There is a
need to develop novel imaging architectures and image processing solutions to
address these requirements. In this work we propose analog signal processing as
a solution to this problem. The analog processor is not suggested as a
replacement to a digital processor but it will be used as an augmentation
device which works in parallel with the digital processor, making the system
faster and more efficient. In order to show the merits of analog processing the
highly computational Normalized Cross Correlation algorithm is implemented. We
propose two novel modifications to the algorithm and a new imaging architecture
which, significantly reduces the computation time.
"
468,"Threshold Logic Computing: Memristive-CMOS Circuits for Fast Fourier
  Transform and Vedic Multiplication","  Brain inspired circuits can provide an alternative solution to implement
computing architectures taking advantage of fault tolerance and generalisation
ability of logic gates. In this brief, we advance over the memristive threshold
circuit configuration consisting of memristive averaging circuit in combination
with operational amplifier and/or CMOS inverters in application to realizing
complex computing circuits. The developed memristive threshold logic gates are
used for designing FFT and multiplication circuits useful for modern
microprocessors. Overall, the proposed threshold logic outperforms previous
memristive-CMOS logic cells on every aspect, however, indicate a lower chip
area, lower THD, and controllable leakage power, but a higher power dissipation
with respect to CMOS logic.
"
469,"Correction to the 2005 paper: ""Digit Selection for SRT Division and
  Square Root""","  It has been pointed out by counterexamples in a 2013 paper in the IEEE
Transactions on Computers [1], that there is an error in the previously ibid.\
in 2005 published paper [2] on the construction of valid digit selection tables
for SRT type division and square root algorithms. The error has been corrected,
and new results found on selection constants for maximally redundant digit
sets.
"
470,Sphynx: A Shared Instruction Cache Exporatory Study,"  The Sphynx project was an exploratory study to discover what might be done to
improve the heavy replication of in- structions in independent instruction
caches for a massively parallel machine where a single program is executing
across all of the cores. While a machine with only many cores (fewer than 50)
might not have any issues replicating the instructions for each core, as we
approach the era where thousands of cores can be placed on one chip, the
overhead of instruction replication may become unacceptably large. We believe
that a large amount of sharing should be possible when the ma- chine is
configured for all of the threads to issue from the same set of instructions.
We propose a technique that allows sharing an instruction cache among a number
of independent processor cores to allow for inter-thread sharing and reuse of
instruction memory. While we do not have test cases to demonstrate the
potential magnitude of performance gains that could be achieved, the potential
for sharing reduces the die area required for instruction storage on chip.
"
471,"Performance Enhancement of Routers in Networks-on-Chip Using Dynamic
  Virtual Channels Allocation","  This study proposes a new router architecture to improve the performance of
dynamic allocation of virtual channels. The proposed router is designed to
reduce the hardware complexity and to improve power and area consumption,
simultaneously. In the new structure of the proposed router, all of the
controlling components have been implemented sequentially inside the allocator
router modules. This optimizes communications between the controlling
components and eliminates the most of hardware overloads of modular
communications. Eliminating additional communications also reduces the hardware
complexity. In order to show the validity of the proposed design in real
hardware resources, the proposed router has been implemented onto a
Field-Programmable Gate Array (FPGA). Since the implementation of a
Network-on-Chip (NoC) requires certain amount of area on the chip, the
suggested approach is also able to reduce the demand of hardware resources. In
this method, the internal memory of the FPGA is used for implementing control
units. This memory is faster and can be used with specific patterns. The use of
the FPGA memory saves the hardware resources and allows the implementation of
NoC based FPGA.
"
472,"Prophet: A Speculative Multi-threading Execution Model with
  Architectural Support Based on CMP","  Speculative multi-threading (SpMT) has been proposed as a perspective method
to exploit Chip Multiprocessors (CMP) hardware potential. It is a thread level
speculation (TLS) model mainly depending on software and hardware co-design.
This paper researches speculative thread-level parallelism of general purpose
programs and a speculative multi-threading execution model called Prophet is
presented. The architectural support for Prophet execution model is designed
based on CMP. In Prophet the inter-thread data dependency are predicted by
pre-computation slice (p-slice) to reduce RAW violation. Prophet
multi-versioning Cache system along with thread state control mechanism in
architectural support are utilized for buffering the speculative data, and a
snooping bus based cache coherence protocol is used to detect data dependence
violation. The simulation-based evaluation shows that the Prophet system could
achieve significant speedup for general-purpose programs.
"
473,"A High-Throughput Energy-Efficient Implementation of
  Successive-Cancellation Decoder for Polar Codes Using Combinational Logic","  This paper proposes a high-throughput energy-efficient Successive
Cancellation (SC) decoder architecture for polar codes based on combinational
logic. The proposed combinational architecture operates at relatively low clock
frequencies compared to sequential circuits, but takes advantage of the high
degree of parallelism inherent in such architectures to provide a favorable
tradeoff between throughput and energy efficiency at short to medium block
lengths. At longer block lengths, the paper proposes a hybrid-logic SC decoder
that combines the advantageous aspects of the combinational decoder with the
low-complexity nature of sequential-logic decoders. Performance characteristics
on ASIC and FPGA are presented with a detailed power consumption analysis for
combinational decoders. Finally, the paper presents an analysis of the
complexity and delay of combinational decoders, and of the throughput gains
obtained by hybrid-logic decoders with respect to purely synchronous
architectures.
"
474,"Kickstarting High-performance Energy-efficient Manycore Architectures
  with Epiphany","  In this paper we introduce Epiphany as a high-performance energy-efficient
manycore architecture suitable for real-time embedded systems. This scalable
architecture supports floating point operations in hardware and achieves 50
GFLOPS/W in 28 nm technology, making it suitable for high performance streaming
applications like radio base stations and radar signal processing. Through an
efficient 2D mesh Network-on-Chip and a distributed shared memory model, the
architecture is scalable to thousands of cores on a single chip. An
Epiphany-based open source computer named Parallella was launched in 2012
through Kickstarter crowd funding and has now shipped to thousands of customers
around the world.
"
475,A 237 Gbps Unrolled Hardware Polar Decoder,"  In this letter we present a new architecture for a polar decoder using a
reduced complexity successive cancellation decoding algorithm. This novel
fully-unrolled, deeply-pipelined architecture is capable of achieving a coded
throughput of over 237 Gbps for a (1024,512) polar code implemented using an
FPGA. This decoder is two orders of magnitude faster than state-of-the-art
polar decoders.
"
476,"Very Low Cost Entropy Source Based on Chaotic Dynamics Retrofittable on
  Networked Devices to Prevent RNG Attacks","  Good quality entropy sources are indispensable in most modern cryptographic
protocols. Unfortunately, many currently deployed networked devices do not
include them and may be vulnerable to Random Number Generator (RNG) attacks.
Since most of these systems allow firmware upgrades and have serial
communication facilities, the potential for retrofitting them with secure
hardware-based entropy sources exists. To this aim, very low-cost, robust, easy
to deploy solutions are required. Here, a retrofittable, sub 10$ entropy source
based on chaotic dynamics is illustrated, capable of a 32 kbit/s rate or more
and offering multiple serial communication options including USB, I2C, SPI or
USART. Operation is based on a loop built around the Analog to Digital
Converter (ADC) hosted on a standard microcontroller.
"
477,"A Feasibility Study on Programmer Specific Instruction Set Processors
  (PSISPs)","  ASIPs are designed in order to execute instructions of a particular domain of
applications. The designing of ASIPs addresses the major challenges faced by a
system on chip such as size, cost, performance and energy consumption. The
higher the number of similar instructions within the domain to be mapped the
lesser the energy consumption, the smaller the size and the higher the
performance of the ASIP. Thus, designing processors for domains with more
similar programs would overcome these issues. This paper describes the
investigation of whether the domains of programmer specific programs have any
significance like application specific program domains and thus, whether the
approach of designing processors known as Programmer Specific Instruction Set
Processors is worthwhile. We performed the evaluation at the instruction level
by using four different measures to obtain the similarity of programs: (1) by
the existence of each instruction, (2) by the frequency of each instruction,
(3) by two consecutive instruction patterns and (4) by three consecutive
instruction patterns of application specific and programmer specific programs.
We found that although programmer specific instructions show some impact on the
similarity measures, they are much smaller and therefore insignificant compared
to the impact from application specific programs.
"
478,"A Model Study of an All-Digital, Discrete-Time and Embedded Linear
  Regulator","  With an increasing number of power-states, finer- grained power management
and larger dynamic ranges of digital circuits, the integration of compact,
scalable linear-regulators embedded deep within logic blocks has become
important. While analog linear-regulators have traditionally been used in
digital ICs, the need for digitally implementable designs that can be
synthesized and embedded in digital functional units for ultra fine- grained
power management has emerged. This paper presents the circuit design and
control models of an all-digital, discrete-time linear regulator and explores
the parametric design space for transient response time and loop stability.
"
479,"Design of a Transport Triggered Architecture Processor for Flexible
  Iterative Turbo Decoder","  In order to meet the requirement of high data rates for the next generation
wireless systems, the efficient implementation of receiver algorithms is
essential. On the other hand, the rapid development of technology motivates the
investigation of programmable implementations. This paper summarizes the design
of a programmable turbo decoder as an applicationspecific instruction-set
processor (ASIP) using Transport Triggered Architecture (TTA). The processor
architecture is designed in such manner that it can be programmed to support
other receiver algorithms, for example, decoding based on the Viterbi
algorithm. Different suboptimal maximum a posteriori (MAP) algorithms are used
and compared to one another for the softinput soft-output (SISO) component
decoders in a single TTA processor. The max-log-MAP algorithm outperforms the
other suboptimal algorithms in terms of latency. The design enables the
designer to change the suboptimal algorithms according to the bit error rate
(BER) performance requirement. Unlike many other programmable turbo decoder
implementations, quadratic polynomial permutation (QPP) interleaver is used in
this work for contention-free memory access and to make the processor 3GPP LTE
compliant. Several optimization techniques to enable real time processing on
programmable platforms are introduced. Using our method, with a single
iteration 31.32 Mbps throughput is achieved for the max-log-MAP algorithm for a
clock frequency of 200 MHz.
"
480,Tejas Simulator : Validation against Hardware,"  In this report we show results that validate the Tejas architectural
simulator against native hardware. We report mean error rates of 11.45% and
18.77% for the SPEC2006 and Splash2 benchmark suites respectively. These error
rates are competitive and in most cases better than the numbers reported by
other contemporary simulators.
"
481,"Running Identical Threads in C-Slow Retiming based Designs for
  Functional Failure Detection","  This paper shows the usage of C-Slow Retiming (CSR) in safety critical and
low power applications. CSR generates C copies of a design by reusing the given
logic resources in a time sliced fashion. When all C design copies are
stimulated with the same input values, then all C design copies should behave
the same way and will therefore create a redundant system. The paper shows that
this special method of using CSR offers great benefits when used in safety
critical and low power applications. Additional optimization techniques towards
reducing register count are shown and an on-the-fly recovery mechanism is
discussed.
"
482,"A High-Performance Solid-State Disk with Double-Data-Rate NAND Flash
  Memory","  We propose a novel solid-state disk (SSD) architecture that utilizes a
double-data-rate synchronous NAND flash interface for improving read and write
performance. Unlike the conventional design, the data transfer rate in the
proposed design is doubled in harmony with synchronous signaling. The new
architecture does not require any extra pins with respect to the conventional
architecture, thereby guaranteeing backward compatibility. For performance
evaluation, we simulated various SSD designs that adopt the proposed
architecture and measured their performance in terms of read/write bandwidths
and energy consumption. Both NAND flash cell types, namely single-level cells
(SLCs) and multi-level cells (MLCs), were considered. In the experiments using
SLC-type NAND flash chips, the read and write speeds of the proposed
architecture were 1.65-2.76 times and 1.09-2.45 times faster than those of the
conventional architecture, respectively. Similar improvements were observed for
the MLC-based architectures tested. It was particularly effective to combine
the proposed architecture with the way-interleaving technique that multiplexes
the data channel between the controller and each flash chip. For a reasonably
high degree of way interleaving, the read/write performance and the energy
consumption of our approach were notably better than those of the conventional
design.
"
483,"Circuit Level Modeling of Extra Combinational Delays in SRAM FPGAs Due
  to Transient Ionizing Radiation","  This paper presents a novel circuit level model that explains and confirms
the extra combinational delays in a SRAM-FPGA (Virtex-5) due to radiation,
which matches the experimental results by proton irradiation at TRIUMF.
"
484,"A Row-parallel 8$\times$8 2-D DCT Architecture Using Algebraic Integer
  Based Exact Computation","  An algebraic integer (AI) based time-multiplexed row-parallel architecture
and two final-reconstruction step (FRS) algorithms are proposed for the
implementation of bivariate AI-encoded 2-D discrete cosine transform (DCT). The
architecture directly realizes an error-free 2-D DCT without using FRSs between
row-column transforms, leading to an 8$\times$8 2-D DCT which is entirely free
of quantization errors in AI basis. As a result, the user-selectable accuracy
for each of the coefficients in the FRS facilitates each of the 64 coefficients
to have its precision set independently of others, avoiding the leakage of
quantization noise between channels as is the case for published DCT designs.
The proposed FRS uses two approaches based on (i) optimized Dempster-Macleod
multipliers and (ii) expansion factor scaling. This architecture enables
low-noise high-dynamic range applications in digital video processing that
requires full control of the finite-precision computation of the 2-D DCT. The
proposed architectures and FRS techniques are experimentally verified and
validated using hardware implementations that are physically realized and
verified on FPGA chip. Six designs, for 4- and 8-bit input word sizes, using
the two proposed FRS schemes, have been designed, simulated, physically
implemented and measured. The maximum clock rate and block-rate achieved among
8-bit input designs are 307.787 MHz and 38.47 MHz, respectively, implying a
pixel rate of 8$\times$307.787$\approx$2.462 GHz if eventually embedded in a
real-time video-processing system. The equivalent frame rate is about 1187.35
Hz for the image size of 1920$\times$1080. All implementations are functional
on a Xilinx Virtex-6 XC6VLX240T FPGA device.
"
485,"A Novel Architecture of Area Efficient FFT Algorithm for FPGA
  Implementation","  Fast Fourier transform (FFT) of large number of samples requires huge
hardware resources of field programmable gate arrays (FPGA), which needs more
area and power. In this paper, we present an area efficient architecture of FFT
processor that reuses the butterfly elements several times. The FFT processor
is simulated using VHDL and the results are validated on a Virtex-6 FPGA. The
proposed architecture outperforms the conventional architecture of a $N$-point
FFT processor in terms of area which is reduced by a factor of $log_N 2$ with
negligible increase in processing time.
"
486,"Proceedings of the DATE Friday Workshop on Heterogeneous Architectures
  and Design Methods for Embedded Image Systems (HIS 2015)","  This volume contains the papers accepted at the DATE Friday Workshop on
Heterogeneous Architectures and Design Methods for Embedded Image Systems (HIS
2015), held in Grenoble, France, March 13, 2015. HIS 2015 was co-located with
the Conference on Design, Automation and Test in Europe (DATE).
"
487,Concept for a CMOS Image Sensor Suited for Analog Image Pre-Processing,"  A concept for a novel CMOS image sensor suited for analog image
pre-processing is presented in this paper. As an example, an image restoration
algorithm for reducing image noise is applied as image pre-processing in the
analog domain. To supply low-latency data input for analog image preprocessing,
the proposed concept for a CMOS image sensor offers a new sensor signal
acquisition method in 2D. In comparison to image pre-processing in the digital
domain, the proposed analog image pre-processing promises an improved image
quality. Furthermore, the image noise at the stage of analog sensor signal
acquisition can be used to select the most effective restoration algorithm
applied to the analog circuit due to image processing prior to the A/D
converter.
"
488,"Generation and Validation of Custom Multiplication IP Blocks from the
  Web","  Every CPU carries one or more arithmetical and logical units. One popular
operation that is performed by these units is multiplication. Automatic
generation of custom VHDL models for performing this operation, allows the
designer to achieve a time efficient design space exploration. Although these
units are heavily utilized in modern digital circuits and DSP, there is no
tool, accessible from the web, to generate the HDL description of such designs
for arbitrary and different input bitwidths. In this paper, we present our web
accessible tool to construct completely custom optimized multiplication units
together with random generated test vectors for their verification. Our novel
tool is one of the firsts web based EDA tools to automate the design of such
units and simultaneously provide custom testbenches to verify their
correctness. Our synthesized circuits on Xilinx Virtex 6 FPGA, operate up to
589 Mhz.
"
489,FPGA Implementation of the CAR Model of the Cochlea,"  The front end of the human auditory system, the cochlea, converts sound
signals from the outside world into neural impulses transmitted along the
auditory pathway for further processing. The cochlea senses and separates sound
in a nonlinear active fashion, exhibiting remarkable sensitivity and frequency
discrimination. Although several electronic models of the cochlea have been
proposed and implemented, none of these are able to reproduce all the
characteristics of the cochlea, including large dynamic range, large gain and
sharp tuning at low sound levels, and low gain and broad tuning at intense
sound levels. Here, we implement the Cascade of Asymmetric Resonators (CAR)
model of the cochlea on an FPGA. CAR represents the basilar membrane filter in
the Cascade of Asymmetric Resonators with Fast-Acting Compression (CAR-FAC)
cochlear model. CAR-FAC is a neuromorphic model of hearing based on a pole-zero
filter cascade model of auditory filtering. It uses simple nonlinear extensions
of conventional digital filter stages that are well suited to FPGA
implementations, so that we are able to implement up to 1224 cochlear sections
on Virtex-6 FPGA to process sound data in real time. The FPGA implementation of
the electronic cochlea described here may be used as a front-end sound analyser
for various machine-hearing applications.
"
490,"Disaggregated and optically interconnected memory: when will it be cost
  effective?","  The ""Disaggregated Server"" concept has been proposed for datacenters where
the same type server resources are aggregated in their respective pools, for
example a compute pool, memory pool, network pool, and a storage pool. Each
server is constructed dynamically by allocating the right amount of resources
from these pools according to the workload's requirements. Modularity, higher
packaging and cooling efficiencies, and higher resource utilization are among
the suggested benefits. With the emergence of very large datacenters, ""clouds""
containing tens of thousands of servers, datacenter efficiency has become an
important topic. Few computer chip and systems vendors are working on and
making frequent announcements on silicon photonics and disaggregated memory
systems.
  In this paper we study the trade-off between cost and performance of building
a disaggregated memory system where DRAM modules in the datacenter are pooled,
for example in memory-only chassis and racks. The compute pool and the memory
pool are interconnected by an optical interconnect to overcome the distance and
bandwidth issues of electrical fabrics. We construct a simple cost model that
includes the cost of latency, cost of bandwidth and the savings expected from a
disaggregated memory system. We then identify the level at which a
disaggregated memory system becomes cost competitive with a traditional direct
attached memory system.
  Our analysis shows that a rack-scale disaggregated memory system will have a
non-trivial performance penalty, and at the datacenter scale the penalty is
impractically high, and the optical interconnect costs are at least a factor of
10 more expensive than where they should be when compared to the traditional
direct attached memory systems.
"
491,Efficient Hardware Design and Implementation of Encrypted MIPS Processor,"  The paper describes the design and hardware implementation of 32-bit
encrypted MIPS processor based on MIPS pipeline architecture. The organization
of pipeline stages in such a way that pipeline can be clocked at high
frequency. Encryption and Decryption blocks of data encryption standard (DES)
cryptosystem and dependency among themselves are explained in detail with the
help of block diagram. In order to increase the processor functionality and
performance, especially for security applications we include three new
instructions 32-bit LKLW, LKUW and CRYPT. The design has been synthesized at
40nm process technology targeting using Xilinx Virtex-6 device. The encrypted
MIPS pipeline processor can work at 218MHz at synthesis level and 744MHz at
simulation level.
"
492,"A General Scheme for Noise-Tolerant Logic Design Based on Probabilistic
  and DCVS Approaches","  In this paper, a general circuit scheme for noise-tolerant logic design based
on Markov Random Field theory and differential Cascade Voltage Switch technique
has been proposed, which is an extension of the work in [1-3], [4]. A block
with only four transistors has been successfully inserted to the original
circuit scheme from [3] and extensive simulation results show that our proposed
design can operate correctly with the input signal of 1 dB signal-noise-ratio.
When using the evaluation parameter from [5], the output value of our design
decreases by 76.5% on average than [3] which means that superior noise-immunity
could be obtained through our work.
"
493,Strategies for High-Throughput FPGA-based QC-LDPC Decoder Architecture,"  We propose without loss of generality strategies to achieve a high-throughput
FPGA-based architecture for a QC-LDPC code based on a circulant-1 identity
matrix construction. We present a novel representation of the parity-check
matrix (PCM) providing a multi-fold throughput gain. Splitting of the node
processing algorithm enables us to achieve pipelining of blocks and hence
layers. By partitioning the PCM into not only layers but superlayers we derive
an upper bound on the pipelining depth for the compact representation. To
validate the architecture, a decoder for the IEEE 802.11n (2012) QC-LDPC is
implemented on the Xilinx Kintex-7 FPGA with the help of the FPGA IP compiler
[2] available in the NI LabVIEW Communication System Design Suite (CSDS) which
offers an automated and systematic compilation flow where an optimized hardware
implementation from the LDPC algorithm was generated in approximately 3
minutes, achieving an overall throughput of 608Mb/s (at 260MHz). As per our
knowledge this is the fastest implementation of the IEEE 802.11n QC-LDPC
decoder using an algorithmic compiler.
"
494,"Design of High Performance MIPS Cryptography Processor Based on T-DES
  Algorithm","  The paper describes the design of high performance MIPS Cryptography
processor based on triple data encryption standard. The organization of
pipeline stages in such a way that pipeline can be clocked at high frequency.
Encryption and Decryption blocks of triple data encryption standard (T-DES)
crypto system and dependency among themselves are explained in detail with the
help of block diagram. In order to increase the processor functionality and
performance, especially for security applications we include three new 32-bit
instructions LKLW, LKUW and CRYPT. The design has been synthesized at 40nm
process technology targeting using Xilinx Virtex-6 device. The overall MIPS
Crypto processor works at 209MHz.
"
495,"Dynamic Partitioning of Physical Memory Among Virtual Machines,
  ASMI:Architectural Support for Memory Isolation","  Cloud computing relies on secure and efficient virtualization. Software level
security solutions compromise the performance of virtual machines (VMs), as a
large amount of computational power would be utilized for running the security
modules. Moreover, software solutions are only as secure as the level that they
work on. For example a security module on a hypervisor cannot provide security
in the presence of an infected hypervisor. It is a challenge for virtualization
technology architects to enhance the security of VMs without degrading their
performance. Currently available server machines are not fully equipped to
support a secure VM environment without compromising on performance. A few
hardware modifications have been introduced by manufactures like Intel and AMD
to provide a secure VM environment with low performance degradation. In this
paper we propose a novel memory architecture model named \textit{ Architectural
Support for Memory Isolation(ASMI)}, that can achieve a true isolated physical
memory region to each VM without degrading performance. Along with true memory
isolation, ASMI is designed to provide lower memory access times, better
utilization of available memory, support for DMA isolation and support for
platform independence for users of VMs.
"
496,"Modeling and Energy Optimization of LDPC Decoder Circuits with Timing
  Violations","  This paper proposes a ""quasi-synchronous"" design approach for signal
processing circuits, in which timing violations are permitted, but without the
need for a hardware compensation mechanism. The case of a low-density
parity-check (LDPC) decoder is studied, and a method for accurately modeling
the effect of timing violations at a high level of abstraction is presented.
The error-correction performance of code ensembles is then evaluated using
density evolution while taking into account the effect of timing faults.
Following this, several quasi-synchronous LDPC decoder circuits based on the
offset min-sum algorithm are optimized, providing a 23%-40% reduction in energy
consumption or energy-delay product, while achieving the same performance and
occupying the same area as conventional synchronous circuits.
"
497,Logic BIST: State-of-the-Art and Open Problems,"  Many believe that in-field hardware faults are too rare in practice to
justify the need for Logic Built-In Self-Test (LBIST) in a design. Until now,
LBIST was primarily used in safety-critical applications. However, this may
change soon. First, even if costly methods like burn-in are applied, it is no
longer possible to get rid of all latent defects in devices at leading-edge
technology. Second, demands for high reliability spread to consumer electronics
as smartphones replace our wallets and IDs. However, today many ASIC vendors
are reluctant to use LBIST. In this paper, we describe the needs for successful
deployment of LBIST in the industrial practice and discuss how these needs can
be addressed. Our work is hoped to attract a wider attention to this important
research topic.
"
498,Improving GPU Performance Through Resource Sharing,"  Graphics Processing Units (GPUs) consisting of Streaming Multiprocessors
(SMs) achieve high throughput by running a large number of threads and context
switching among them to hide execution latencies. The number of thread blocks,
and hence the number of threads that can be launched on an SM, depends on the
resource usage--e.g. number of registers, amount of shared memory--of the
thread blocks. Since the allocation of threads to an SM is at the thread block
granularity, some of the resources may not be used up completely and hence will
be wasted.
  We propose an approach that shares the resources of SM to utilize the wasted
resources by launching more thread blocks. We show the effectiveness of our
approach for two resources: register sharing, and scratchpad (shared memory)
sharing. We further propose optimizations to hide long execution latencies,
thus reducing the number of stall cycles. We implemented our approach in
GPGPU-Sim simulator and experimentally validated it on several applications
from 4 different benchmark suites: GPGPU-Sim, Rodinia, CUDA-SDK, and Parboil.
We observed that with register sharing, applications show maximum improvement
of 24%, and average improvement of 11%. With scratchpad sharing, we observed a
maximum improvement of 30% and an average improvement of 12.5%.
"
499,Evaluating Asymmetric Multicore Systems-on-Chip using Iso-Metrics,"  The end of Dennard scaling has pushed power consumption into a first order
concern for current systems, on par with performance. As a result,
near-threshold voltage computing (NTVC) has been proposed as a potential means
to tackle the limited cooling capacity of CMOS technology. Hardware operating
in NTV consumes significantly less power, at the cost of lower frequency, and
thus reduced performance, as well as increased error rates. In this paper, we
investigate if a low-power systems-on-chip, consisting of ARM's asymmetric
big.LITTLE technology, can be an alternative to conventional high performance
multicore processors in terms of power/energy in an unreliable scenario. For
our study, we use the Conjugate Gradient solver, an algorithm representative of
the computations performed by a large range of scientific and engineering
codes.
"
500,"Binary Adder Circuits of Asymptotically Minimum Depth, Linear Size, and
  Fan-Out Two","  We consider the problem of constructing fast and small binary adder circuits.
Among widely-used adders, the Kogge-Stone adder is often considered the
fastest, because it computes the carry bits for two $n$-bit numbers (where $n$
is a power of two) with a depth of $2\log_2 n$ logic gates, size $4 n\log_2 n$,
and all fan-outs bounded by two. Fan-outs of more than two are avoided, because
they lead to the insertion of repeaters for repowering the signal and
additional depth in the physical implementation. However, the depth bound of
the Kogge-Stone adder is off by a factor of two from the lower bound of $\log_2
n$. This bound is achieved asymptotically in two separate constructions by
Brent and Krapchenko. Brent's construction gives neither a bound on the fan-out
nor the size, while Krapchenko's adder has linear size, but can have up to
linear fan-out. With a fan-out bound of two, neither construction achieves a
depth of less than $2 \log_2 n$. In a further approach, Brent and Kung proposed
an adder with linear size and fan-out two, but twice the depth of the
Kogge-Stone adder. These results are 33-43 years old and no substantial
theoretical improvement for has been made since then.
  In this paper we integrate the individual advantages of all previous adder
circuits into a new family of full adders, the first to improve on the depth
bound of $2\log_2 n$ while maintaining a fan-out bound of two. Our adders
achieve an asymptotically optimum logic gate depth of $\log_2 n + o(\log_2 n)$
and linear size $\mathcal {O}(n)$.
"
501,"FPGA based High Speed Data Acquisition System for High Energy Physics
  Application","  In high energy physics experiments (HEP), high speed and fault resilient data
communication is needed between detectors/sensors and the host PC. Transient
faults can occur in the communication hardware due to various external effects
like presence of charged particles, noise in the environment or radiation
effects in HEP experiments and that leads to single/multiple bit error. In
order to keep the communication system functional in such a radiation
environment where direct intervention of human is not possible, a high speed
data acquisition (DAQ) architecture is necessary which supports error recovery.
This design presents an efficient implementation of field programmable gate
array (FPGA) based high speed DAQ system with optical communication link
supported by multi-bit error correcting model. The design has been implemented
on Xilinx Kintex-7 board and is tested for board to board communication as well
as for PC communication using PCI (Peripheral Component Interconnect express).
Data communication speed up to 4.8 Gbps has been achieved in board to board and
board to PC communication and estimation of resource utilization and critical
path delay are also measured.
"
502,Recent Development in Analog Computation - A Brief Overview,"  The recent development in analog computation is reviewed in this paper.
Analog computation was used in many applications where power and energy
efficiency is of paramount importance. It is shown that by using innovative
architecture and circuit design, analog computation systems can achieve much
higher energy efficiency than their digital counterparts, as they are able to
exploit the computational power inherent to the devices and physics. However,
these systems do suffer from some disadvantages, such as lower accuracy and
speed, and designers have come up with novel approaches to overcome them. The
paper provides an overview of analog computation systems, from basic components
such as memory and arithmetic elements, to architecture and system design.
"
503,"Modular Acquisition and Stimulation System for Timestamp-Driven
  Neuroscience Experiments","  Dedicated systems are fundamental for neuroscience experimental protocols
that require timing determinism and synchronous stimuli generation. We
developed a data acquisition and stimuli generator system for neuroscience
research, optimized for recording timestamps from up to 6 spiking neurons and
entirely specified in a high-level Hardware Description Language (HDL). Despite
the logic complexity penalty of synthesizing from such a language, it was
possible to implement our design in a low-cost small reconfigurable device.
Under a modular framework, we explored two different memory arbitration schemes
for our system, evaluating both their logic element usage and resilience to
input activity bursts. One of them was designed with a decoupled and latency
insensitive approach, allowing for easier code reuse, while the other adopted a
centralized scheme, constructed specifically for our application. The usage of
a high-level HDL allowed straightforward and stepwise code modifications to
transform one architecture into the other. The achieved modularity is very
useful for rapidly prototyping novel electronic instrumentation systems
tailored to scientific research.
"
504,Low-latency List Decoding Of Polar Codes With Double Thresholding,"  For polar codes with short-to-medium code length, list successive
cancellation decoding is used to achieve a good error-correcting performance.
However, list pruning in the current list decoding is based on the sorting
strategy and its timing complexity is high. This results in a long decoding
latency for large list size. In this work, aiming at a low-latency list
decoding implementation, a double thresholding algorithm is proposed for a fast
list pruning. As a result, with a negligible performance degradation, the list
pruning delay is greatly reduced. Based on the double thresholding, a
low-latency list decoding architecture is proposed and implemented using a UMC
90nm CMOS technology. Synthesis results show that, even for a large list size
of 16, the proposed low-latency architecture achieves a decoding throughput of
220 Mbps at a frequency of 641 MHz.
"
505,MigrantStore: Leveraging Virtual Memory in DRAM-PCM Memory Architecture,"  With the imminent slowing down of DRAM scaling, Phase Change Memory (PCM) is
emerging as a lead alternative for main memory technology. While PCM achieves
low energy due to various technology-specific advantages, PCM is significantly
slower than DRAM (especially for writes) and can endure far fewer writes before
wearing out. Previous work has proposed to use a large, DRAM-based hardware
cache to absorb writes and provide faster access. However, due to ineffectual
caching where blocks are evicted before sufficient number of accesses, hardware
caches incur significant overheads in energy and bandwidth, two key but scarce
resources in modern multicores. Because using hardware for detecting and
removing such ineffectual caching would incur additional hardware cost and
complexity, we leverage the OS virtual memory support for this purpose. We
propose a DRAM-PCM hybrid memory architecture where the OS migrates pages on
demand from the PCM to DRAM. We call the DRAM part of our memory as
MigrantStore which includes two ideas. First, to reduce the energy, bandwidth,
and wear overhead of ineffectual migrations, we propose migration hysteresis.
Second, to reduce the software overhead of good replacement policies, we
propose recently- accessed-page-id (RAPid) buffer, a hardware buffer to track
the addresses of recently-accessed MigrantStore pages.
"
506,"A Reconfigurable Vector Instruction Processor for Accelerating a
  Convection Parametrization Model on FPGAs","  High Performance Computing (HPC) platforms allow scientists to model
computationally intensive algorithms. HPC clusters increasingly use
General-Purpose Graphics Processing Units (GPGPUs) as accelerators; FPGAs
provide an attractive alternative to GPGPUs for use as co-processors, but they
are still far from being mainstream due to a number of challenges faced when
using FPGA-based platforms. Our research aims to make FPGA-based high
performance computing more accessible to the scientific community. In this work
we present the results of investigating the acceleration of a particular
atmospheric model, Flexpart, on FPGAs. We focus on accelerating the most
computationally intensive kernel from this model. The key contribution of our
work is the architectural exploration we undertook to arrive at a solution that
best exploits the parallelism available in the legacy code, and is also
convenient to program, so that eventually the compilation of high-level legacy
code to our architecture can be fully automated. We present the three different
types of architecture, comparing their resource utilization and performance,
and propose that an architecture where there are a number of computational
cores, each built along the lines of a vector instruction processor, works best
in this particular scenario, and is a promising candidate for a generic
FPGA-based platform for scientific computation. We also present the results of
experiments done with various configuration parameters of the proposed
architecture, to show its utility in adapting to a range of scientific
applications.
"
507,"Overview of Swallow --- A Scalable 480-core System for Investigating the
  Performance and Energy Efficiency of Many-core Applications and Operating
  Systems","  We present Swallow, a scalable many-core architecture, with a current
configuration of 480 x 32-bit processors.
  Swallow is an open-source architecture, designed from the ground up to
deliver scalable increases in usable computational power to allow
experimentation with many-core applications and the operating systems that
support them.
  Scalability is enabled by the creation of a tile-able system with a
low-latency interconnect, featuring an attractive communication-to-computation
ratio and the use of a distributed memory configuration.
  We analyse the energy and computational and communication performances of
Swallow. The system provides 240GIPS with each core consuming 71--193mW,
dependent on workload. Power consumption per instruction is lower than almost
all systems of comparable scale.
  We also show how the use of a distributed operating system (nOS) allows the
easy creation of scalable software to exploit Swallow's potential. Finally, we
show two use case studies: modelling neurons and the overlay of shared memory
on a distributed memory system.
"
508,An event-based architecture for solving constraint satisfaction problems,"  Constraint satisfaction problems (CSPs) are typically solved using
conventional von Neumann computing architectures. However, these architectures
do not reflect the distributed nature of many of these problems and are thus
ill-suited to solving them. In this paper we present a hybrid analog/digital
hardware architecture specifically designed to solve such problems. We cast
CSPs as networks of stereotyped multi-stable oscillatory elements that
communicate using digital pulses, or events. The oscillatory elements are
implemented using analog non-stochastic circuits. The non-repeating phase
relations among the oscillatory elements drive the exploration of the solution
space. We show that this hardware architecture can yield state-of-the-art
performance on a number of CSPs under reasonable assumptions on the
implementation. We present measurements from a prototype electronic chip to
demonstrate that a physical implementation of the proposed architecture is
robust to practical non-idealities and to validate the theory proposed.
"
509,Multi-mode Unrolled Architectures for Polar Decoders,"  In this work, we present a family of architectures for polar decoders using a
reduced-complexity successive-cancellation decoding algorithm that employs
unrolling to achieve extremely high throughput values while retaining moderate
implementation complexity. The resulting fully-unrolled, deeply-pipelined
architecture is capable of achieving a coded throughput in excess of 1 Tbps on
a 65 nm ASIC at 500 MHz---three orders of magnitude greater than current
state-of-the-art polar decoders. However, unrolled decoders are built for a
specific, fixed code. Therefore we also present a new method to enable the use
of multiple code lengths and rates in a fully-unrolled polar decoder
architecture. This method leads to a length- and rate-flexible decoder while
retaining the very high speed typical to unrolled decoders. The resulting
decoders can decode a master polar code of a given rate and length, and several
shorter codes of different rates and lengths. We present results for two
versions of a multi-mode decoder supporting eight and ten different polar
codes, respectively. Both are capable of a peak throughput of 25.6 Gbps. For
each decoder, the energy efficiency for the longest supported polar code is
shown to be of 14.8 pJ/bit at 250 MHz and of 8.8 pJ/bit at 500 MHz.
"
510,"TPAD: Hardware Trojan Prevention and Detection for Trusted Integrated
  Circuits","  There are increasing concerns about possible malicious modifications of
integrated circuits (ICs) used in critical applications. Such attacks are often
referred to as hardware Trojans. While many techniques focus on hardware Trojan
detection during IC testing, it is still possible for attacks to go undetected.
Using a combination of new design techniques and new memory technologies, we
present a new approach that detects a wide variety of hardware Trojans during
IC testing and also during system operation in the field. Our approach can also
prevent a wide variety of attacks during synthesis, place-and-route, and
fabrication of ICs. It can be applied to any digital system, and can be tuned
for both traditional and split-manufacturing methods. We demonstrate its
applicability for both ASICs and FPGAs. Using fabricated test chips with Trojan
emulation capabilities and also using simulations, we demonstrate: 1. The area
and power costs of our approach can range between 7.4-165% and 0.07-60%,
respectively, depending on the design and the attacks targeted; 2. The speed
impact can be minimal (close to 0%); 3. Our approach can detect 99.998% of
Trojans (emulated using test chips) that do not require detailed knowledge of
the design being attacked; 4. Our approach can prevent 99.98% of specific
attacks (simulated) that utilize detailed knowledge of the design being
attacked (e.g., through reverse-engineering). 5. Our approach never produces
any false positives, i.e., it does not report attacks when the IC operates
correctly.
"
511,"Twin-Load: Building a Scalable Memory System over the Non-Scalable
  Interface","  Commodity memory interfaces have difficulty in scaling memory capacity to
meet the needs of modern multicore and big data systems. DRAM device density
and maximum device count are constrained by technology, package, and signal in-
tegrity issues that limit total memory capacity. Synchronous DRAM protocols
require data to be returned within a fixed latency, and thus memory extension
methods over commodity DDRx interfaces fail to support scalable topologies.
Current extension approaches either use slow PCIe interfaces, or require
expensive changes to the memory interface, which limits commercial
adoptability. Here we propose twin-load, a lightweight asynchronous memory
access mechanism over the synchronous DDRx interface. Twin-load uses two
special loads to accomplish one access request to extended memory, the first
serves as a prefetch command to the DRAM system, and the second asynchronously
gets the required data. Twin-load requires no hardware changes on the processor
side and only slight soft- ware modifications. We emulate this system on a
prototype to demonstrate the feasibility of our approach. Twin-load has
comparable performance to NUMA extended memory and outperforms a page-swapping
PCIe-based system by several orders of magnitude. Twin-load thus enables
instant capacity increases on commodity platforms, but more importantly, our
architecture opens opportunities for the design of novel, efficient, scalable,
cost-effective memory subsystems.
"
512,An Approach to Data Prefetching Using 2-Dimensional Selection Criteria,"  We propose an approach to data memory prefetching which augments the standard
prefetch buffer with selection criteria based on performance and usage pattern
of a given instruction. This approach is built on top of a pattern matching
based prefetcher, specifically one which can choose between a stream, a stride,
or a stream followed by a stride. We track the most recently called
instructions to make a decision on the quantity of data to prefetch next. The
decision is based on the frequency with which these instructions are called and
the hit/miss rate of the prefetcher. In our approach, we separate the amount of
data to prefetch into three categories: a high degree, a standard degree and a
low degree. We ran tests on different values for the high prefetch degree,
standard prefetch degree and low prefetch degree to determine that the most
optimal combination was 1, 4, 8 lines respectively. The 2 dimensional selection
criteria improved the performance of the prefetcher by up to 9.5% over the
first data prefetching championship winner. Unfortunately performance also fell
by as much as 14%, but remained similar on average across all of the benchmarks
we tested.
"
513,A 2.48Gb/s QC-LDPC Decoder Implementation on the NI USRP-2953R,"  The increasing data rates expected to be of the order of Gb/s for future
wireless systems directly impact the throughput requirements of the modulation
and coding subsystems of the physical layer. In an effort to design a suitable
channel coding solution for 5G wireless systems, in this brief we present a
massively-parallel 2.48Gb/s Quasi-Cyclic Low-Density Parity-Check (QC-LDPC)
decoder implementation operating at 200MHz on the NI USRP-2953R, on a single
FPGA. The high-level description of the entire massively-parallel decoder was
translated to a Hardware Description Language (HDL), namely VHDL, using the
algorithmic compiler in the National Instruments LabVIEW Communication System
Design Suite (CSDS) in approximately 2 minutes. This implementation not only
demonstrates the scalability of our decoder architecture but also, the rapid
prototyping capability of the LabVIEW CSDS tools. As per our knowledge, at the
time of writing this paper, this is the fastest implementation of a standard
compliant QC-LDPC decoder on a USRP using an algorithmic compiler.
"
514,"High speed fault tolerant secure communication for muon chamber using
  fpga based gbt emulator","  The Compressed Baryonic Matter (CBM) experiment is a part of the Facility for
Antiproton and Ion Research (FAIR) in Darmstadt at the GSI. The CBM experiment
will investigate the highly compressed nuclear matter using nucleus-nucleus
collisions. This experiment will examine heavy-ion collisions in fixed target
geometry and will be able to measure hadrons, electrons and muons. CBM requires
precise time synchronization, compact hardware, radiation tolerance,
self-triggered front-end electronics, efficient data aggregation schemes and
capability to handle high data rate (up to several TB/s). As a part of the
implementation of read out chain of MUCH in India, we have tried to implement
FPGA based emulator of GBTx in India. GBTx is a radiation tolerant ASIC that
can be used to implement multipurpose high speed bidirectional optical links
for high-energy physics (HEP) experiments and is developed by CERN. GBTx will
be used in highly irradiated area and more prone to be affected by multi bit
error. To mitigate this effect instead of single bit error correcting RS code
we have used two bit error correcting (15, 7) BCH code. It will increase the
redundancy which in turn increases the reliability of the coded data. So the
coded data will be less prone to be affected by noise due to radiation. Data
will go from detector to PC through multiple nodes through the communication
channel. In order to make the data communication secure, advanced encryption
standard (AES - a symmetric key cryptography) and RSA (asymmetric key
cryptography) are used after the channel coding.
"
515,"SQUASH: Simple QoS-Aware High-Performance Memory Scheduler for
  Heterogeneous Systems with Hardware Accelerators","  Modern SoCs integrate multiple CPU cores and Hardware Accelerators (HWAs)
that share the same main memory system, causing interference among memory
requests from different agents. The result of this interference, if not
controlled well, is missed deadlines for HWAs and low CPU performance.
State-of-the-art mechanisms designed for CPU-GPU systems strive to meet a
target frame rate for GPUs by prioritizing the GPU close to the time when it
has to complete a frame. We observe two major problems when such an approach is
adapted to a heterogeneous CPU-HWA system. First, HWAs miss deadlines because
they are prioritized only close to their deadlines. Second, such an approach
does not consider the diverse memory access characteristics of different
applications running on CPUs and HWAs, leading to low performance for
latency-sensitive CPU applications and deadline misses for some HWAs, including
GPUs.
  In this paper, we propose a Simple Quality of service Aware memory Scheduler
for Heterogeneous systems (SQUASH), that overcomes these problems using three
key ideas, with the goal of meeting deadlines of HWAs while providing high CPU
performance. First, SQUASH prioritizes a HWA when it is not on track to meet
its deadline any time during a deadline period. Second, SQUASH prioritizes HWAs
over memory-intensive CPU applications based on the observation that the
performance of memory-intensive applications is not sensitive to memory
latency. Third, SQUASH treats short-deadline HWAs differently as they are more
likely to miss their deadlines and schedules their requests based on worst-case
memory access time estimates.
  Extensive evaluations across a wide variety of different workloads and
systems show that SQUASH achieves significantly better CPU performance than the
best previous scheduler while always meeting the deadlines for all HWAs,
including GPUs, thereby largely improving frame rates.
"
516,"Simultaneous Multi Layer Access: A High Bandwidth and Low Cost
  3D-Stacked Memory Interface","  Limited memory bandwidth is a critical bottleneck in modern systems.
3D-stacked DRAM enables higher bandwidth by leveraging wider
Through-Silicon-Via (TSV) channels, but today's systems cannot fully exploit
them due to the limited internal bandwidth of DRAM. DRAM reads a whole row
simultaneously from the cell array to a row buffer, but can transfer only a
fraction of the data from the row buffer to peripheral IO circuit, through a
limited and expensive set of wires referred to as global bitlines. In presence
of wider memory channels, the major bottleneck becomes the limited data
transfer capacity through these global bitlines. Our goal in this work is to
enable higher bandwidth in 3D-stacked DRAM without the increased cost of adding
more global bitlines. We instead exploit otherwise-idle resources, such as
global bitlines, already existing within the multiple DRAM layers by accessing
the layers simultaneously. Our architecture, Simultaneous Multi Layer Access
(SMLA), provides higher bandwidth by aggregating the internal bandwidth of
multiple layers and transferring the available data at a higher IO frequency.
  To implement SMLA, simultaneous data transfer from multiple layers through
the same IO TSVs requires coordination between layers to avoid channel
conflict. We first study coordination by static partitioning, which we call
Dedicated-IO, that assigns groups of TSVs to each layer. We then provide a
simple, yet sophisticated mechanism, called Cascaded-IO, which enables
simultaneous access to each layer by time-multiplexing the IOs. By operating at
a frequency proportional to the number of layers, SMLA provides a higher
bandwidth (4X for a four-layer stacked DRAM). Our evaluations show that SMLA
provides significant performance improvement and energy reduction (55%/18% on
average for multi-programmed workloads, respectively) over a baseline
3D-stacked DRAM with very low area overhead.
"
517,"DEW: A Fast Level 1 Cache Simulation Approach for Embedded Processors
  with FIFO Replacement Policy","  Increasing the speed of cache simulation to obtain hit/miss rates en- ables
performance estimation, cache exploration for embedded sys- tems and energy
estimation. Previously, such simulations, particu- larly exact approaches, have
been exclusively for caches which uti- lize the least recently used (LRU)
replacement policy. In this paper, we propose a new, fast and exact cache
simulation method for the First In First Out(FIFO) replacement policy. This
method, called DEW, is able to simulate multiple level 1 cache configurations
(dif- ferent set sizes, associativities, and block sizes) with FIFO replace-
ment policy. DEW utilizes a binomial tree based representation of cache
configurations and a novel searching method to speed up sim- ulation over
single cache simulators like Dinero IV. Depending on different cache block
sizes and benchmark applications, DEW oper- ates around 8 to 40 times faster
than Dinero IV. Dinero IV compares 2.17 to 19.42 times more cache ways than DEW
to determine accu- rate miss rates.
"
518,"TRISHUL: A Single-pass Optimal Two-level Inclusive Data Cache Hierarchy
  Selection Process for Real-time MPSoCs","  Hitherto discovered approaches analyze the execution time of a real time
application on all the possible cache hierarchy setups to find the application
specific optimal two level inclusive data cache hierarchy to reduce cost, space
and energy consumption while satisfying the time deadline in real time
Multiprocessor Systems on Chip. These brute force like approaches can take
years to complete. Alternatively, memory access trace driven crude estimation
methods can find a cache hierarchy quickly by compromising the accuracy of
results. In this article, for the first time, we propose a fast and accurate
trace driven approach to find the optimal real time application specific two
level inclusive data cache hierarchy. Our proposed approach TRISHUL predicts
the optimal cache hierarchy performance first and then utilizes that
information to find the optimal cache hierarchy quickly. TRISHUL can suggest a
cache hierarchy, which has up to 128 times smaller size, up to 7 times faster
compared to the suggestion of the state of the art crude trace driven two level
inclusive cache hierarchy selection approach for the application traces
analyzed.
"
519,"CIPARSim: Cache Intersection Property Assisted Rapid Single-pass FIFO
  Cache Simulation Technique","  In this paper, for the first time, we introduce a cache property called the
Intersection Property that helps to reduce singlepass simulation time in a
manner similar to inclusion property. An intersection property defines
conditions that if met, prove a particular element exists in larger caches,
thus avoiding further search time. We have discussed three such intersection
properties for caches using the FIFO replacement policy in this paper. A rapid
singlepass FIFO cache simulator CIPARSim has also been proposed. CIPARSim is
the first singlepass simulator dependent on the FIFO cache properties to reduce
simulation time significantly. CIPARSim simulation time was up to 5 times
faster compared to the state of the art singlepass FIFO cache simulator for the
cache configurations tested. CIPARSim produces the cache hit and miss rates of
an application accurately on various cache configurations. During simulation,
CIPARSim intersection properties alone predict up to 90% of the total hits,
reducing simulationtime immensely
"
520,"Accelerating Non-volatile/Hybrid Processor Cache Design Space
  Exploration for Application Specific Embedded Systems","  In this article, we propose a technique to accelerate nonvolatile or hybrid
of volatile and nonvolatile processor cache design space exploration for
application specific embedded systems. Utilizing a novel cache behavior
modeling equation and a new accurate cache miss prediction mechanism, our
proposed technique can accelerate NVM or hybrid FIFO processor cache design
space exploration for SPEC CPU 2000 applications up to 249 times compared to
the conventional approach.
"
521,FPGA based Novel High Speed DAQ System Design with Error Correction,"  Present state of the art applications in the area of high energy physics
experiments (HEP), radar communication, satellite communication and bio medical
instrumentation require fault resilient data acquisition (DAQ) system with the
data rate in the order of Gbps. In order to keep the high speed DAQ system
functional in such radiation environment where direct intervention of human is
not possible, a robust and error free communication system is necessary. In
this work we present an efficient DAQ design and its implementation on field
programmable gate array (FPGA). The proposed DAQ system supports high speed
data communication (~4.8 Gbps) and achieves multi-bit error correction
capabilities. BCH code (named after Raj Bose and D. K. RayChaudhuri) has been
used for multi-bit error correction. The design has been implemented on Xilinx
Kintex-7 board and is tested for board to board communication as well as for
board to PC using PCIe (Peripheral Component Interconnect express) interface.
To the best of our knowledge, the proposed FPGA based high speed DAQ system
utilizing optical link and multi-bit error resiliency can be considered first
of its kind. Performance estimation of the implemented DAQ system is done based
on resource utilization, critical path delay, efficiency and bit error rate
(BER).
"
522,"Managing Hybrid Main Memories with a Page-Utility Driven Performance
  Model","  Hybrid memory systems comprised of dynamic random access memory (DRAM) and
non-volatile memory (NVM) have been proposed to exploit both the capacity
advantage of NVM and the latency and dynamic energy advantages of DRAM. An
important problem for such systems is how to place data between DRAM and NVM to
improve system performance.
  In this paper, we devise the first mechanism, called UBM (page Utility Based
hybrid Memory management), that systematically estimates the system performance
benefit of placing a page in DRAM versus NVM and uses this estimate to guide
data placement. UBM's estimation method consists of two major components.
First, it estimates how much an application's stall time can be reduced if the
accessed page is placed in DRAM. To do this, UBM comprehensively considers
access frequency, row buffer locality, and memory level parallelism (MLP) to
estimate the application's stall time reduction. Second, UBM estimates how much
each application's stall time reduction contributes to overall system
performance. Based on this estimation method, UBM can determine and place the
most critical data in DRAM to directly optimize system performance.
Experimental results show that UBM improves system performance by 14% on
average (and up to 39%) compared to the best of three state-of-the-art
mechanisms for a large number of data-intensive workloads from the SPEC CPU2006
and Yahoo Cloud Serving Benchmark (YCSB) suites.
"
523,How Data Volume Affects Spark Based Data Analytics on a Scale-up Server,"  Sheer increase in volume of data over the last decade has triggered research
in cluster computing frameworks that enable web enterprises to extract big
insights from big data. While Apache Spark is gaining popularity for exhibiting
superior scale-out performance on the commodity machines, the impact of data
volume on the performance of Spark based data analytics in scale-up
configuration is not well understood. We present a deep-dive analysis of Spark
based applications on a large scale-up server machine. Our analysis reveals
that Spark based data analytics are DRAM bound and do not benefit by using more
than 12 cores for an executor. By enlarging input data size, application
performance degrades significantly due to substantial increase in wait time
during I/O operations and garbage collection, despite 10\% better instruction
retirement rate (due to lower L1 cache misses and higher core utilization). We
match memory behaviour with the garbage collector to improve performance of
applications between 1.6x to 3x.
"
524,"A Novel Reconfigurable Hardware Design for Speech Enhancement Based on
  Multi-Band Spectral Subtraction Involving Magnitude and Phase Components","  This paper proposes an efficient reconfigurable hardware design for speech
enhancement based on multi band spectral subtraction algorithm and involving
both magnitude and phase components. Our proposed design is novel as it
estimates environmental noise from speech adaptively utilizing both magnitude
and phase components of the speech spectrum. We performed multi-band spectrum
subtraction by dividing the noisy speech spectrum into different non-uniform
frequency bands having varying signal to noise ratio (SNR) and subtracting the
estimated noise from each of these frequency bands. This results to the
elimination of noise from both high SNR and low SNR signal components for all
the frequency bands. We have coined our proposed speech enhancement technique
as Multi Band Magnitude Phase Spectral Subtraction (MBMPSS). The magnitude and
phase operations are executed concurrently exploiting the parallel logic blocks
of Field Programmable Gate Array (FPGA), thus increasing the throughput of the
system to a great extent. We have implemented our design on Spartan6 Lx45 FPGA
and presented the implementation result in terms of resource utilization and
delay information for the different blocks of our design. To the best of our
best knowledge, this is a new type of hardware design for speech enhancement
application and also a first of its kind implementation on reconfigurable
hardware. We have used benchmark audio data for the evaluation of the proposed
hardware and the experimental results show that our hardware shows a better SNR
value compared to the existing state of the art research works.
"
525,"Proceedings of the Second International Workshop on FPGAs for Software
  Programmers (FSP 2015)","  This volume contains the papers accepted at the Second International Workshop
on FPGAs for Software Programmers (FSP 2015), held in London, United Kingdom,
September 1st, 2015. FSP 2015 was co-located with the International Conference
on Field Programmable Logic and Applications (FPL).
"
526,Allowing Software Developers to Debug HLS Hardware,"  High-Level Synthesis (HLS) is emerging as a mainstream design methodology,
allowing software designers to enjoy the benefits of a hardware implementation.
Significant work has led to effective compilers that produce high-quality
hardware designs from software specifications. However, in order to fully
benefit from the promise of HLS, a complete ecosystem that provides the ability
to analyze, debug, and optimize designs is essential. This ecosystem has to be
accessible to software designers. This is challenging, since software
developers view their designs very differently than how they are physically
implemented on-chip. Rather than individual sequential lines of code, the
implementation consists of gates operating in parallel across multiple clock
cycles. In this paper, we report on our efforts to create an ecosystem that
allows software designers to debug HLS-generated circuits in a familiar manner.
We have implemented our ideas in a debug framework that will be included in the
next release of the popular LegUp high-level synthesis tool.
"
527,"Model-based Hardware Design for FPGAs using Folding Transformations
  based on Subcircuits","  We present a tool flow and results for a model-based hardware design for
FPGAs from Simulink descriptions which nicely integrates into existing
environments. While current commercial tools do not exploit some high-level
optimizations, we investigate the promising approach of using reusable
subcircuits for folding transformations to control embedded multiplier usage
and to optimize logic block usage. We show that resource improvements of up to
70% compared to the original model are possible, but it is also shown that
subcircuit selection is a critical task. While our tool flow provides good
results already, the investigation and optimization of subcircuit selection is
clearly identified as an additional keypoint to extend high-level control on
low-level FPGA mapping properties.
"
528,"ThreadPoolComposer - An Open-Source FPGA Toolchain for Software
  Developers","  This extended abstract presents ThreadPoolComposer, a high-level
synthesis-based development framework and meta-toolchain that provides a
uniform programming interface for FPGAs portable across multiple platforms.
"
529,"Designing Hardware/Software Systems for Embedded High-Performance
  Computing","  In this work, we propose an architecture and methodology to design
hardware/software systems for high-performance embedded computing on FPGA. The
hardware side is based on a many-core architecture whose design is generated
automatically given a set of architectural parameters. Both the architecture
and the methodology were evaluated running dense matrix multiplication and
sparse matrix-vector multiplication on a ZYNQ-7020 FPGA platform. The results
show that using a system-level design of the system avoids complex hardware
design and still provides good performance results.
"
530,Proposal of ROS-compliant FPGA Component for Low-Power Robotic Systems,"  In recent years, robots are required to be autonomous and their robotic
software are sophisticated. Robots have a problem of insufficient performance,
since it cannot equip with a high-performance microprocessor due to
battery-power operation. On the other hand, FPGA devices can accelerate
specific functions in a robot system without increasing power consumption by
implementing customized circuits. But it is difficult to introduce FPGA devices
into a robot due to large development cost of an FPGA circuit compared to
software. Therefore, in this study, we propose an FPGA component technology for
an easy integration of an FPGA into robots, which is compliant with ROS (Robot
Operating System). As a case study, we designed ROS-compliant FPGA component of
image labeling using Xilinx Zynq platform. The developed ROS-component FPGA
component performs 1.7 times faster compared to the ordinary ROS software
component.
"
531,Performance monitoring for multicore embedded computing systems on FPGAs,"  When designing modern embedded computing systems, most software programmers
choose to use multicore processors, possibly in combination with
general-purpose graphics processing units (GPGPUs) and/or hardware
accelerators. They also often use an embedded Linux O/S and run
multi-application workloads that may even be multi-threaded. Modern FPGAs are
large enough to combine multicore hard/soft processors with multiple hardware
accelerators as custom compute units, enabling entire embedded compute systems
to be implemented on a single FPGA. Furthermore, the large FPGA vendors also
support embedded Linux kernels for both their soft and embedded processors.
When combined with high-level synthesis to generate hardware accelerators using
a C-to-gates flows, the necessary primitives for a framework that can enable
software designers to use FPGAs as their custom compute platform now exist.
However, in order to ensure that computing resources are integrated and shared
effectively, software developers need to be able to monitor and debug the
runtime performance of the applications in their workload. This paper describes
ABACUS, a performance-monitoring framework that can be used to debug the
execution behaviours and interactions of multi-application workloads on
multicore systems. We also discuss how this framework is extensible for use
with hardware accelerators in heterogeneous systems.
"
532,Virtualization Architecture for NoC-based Reconfigurable Systems,"  We propose a virtualization architecture for NoC-based reconfigurable
systems. The motivation of this work is to develop a service-oriented
architecture that includes Partial Reconfigurable Region as a Service (PRRaaS)
and Processing Element as a Service (PEaaS) for software applications.
According to the requirements of software applications, new PEs can be created
on-demand by (re)configuring the logic resource of the PRRs in the FPGA, while
the configured PEs can also be virtualized to support multiple application
tasks at the same time. As a result, such a two-level virtualization mechanism,
including the gate-level virtualization and the PE-level virtualization,
enables an SoC to be dynamically adapted to changing application requirements.
Therefore, more software applications can be performed, and system performance
can be further enhanced.
"
533,"Using System Hyper Pipelining (SHP) to Improve the Performance of a
  Coarse-Grained Reconfigurable Architecture (CGRA) Mapped on an FPGA","  The well known method C-Slow Retiming (CSR) can be used to automatically
convert a given CPU into a multithreaded CPU with independent threads. These
CPUs are then called streaming or barrel processors. System Hyper Pipelining
(SHP) adds a new flexibility on top of CSR by allowing a dynamic number of
threads to be executed and by enabling the threads to be stalled, bypassed and
reordered. SHP is now applied on the programming elements (PE) of a
coarse-grained reconfigurable architecture (CGRA). By using SHP, more
performance can be achieved per PE. Fork-Join operations can be implemented on
a PE using the flexibility provided by SHP to dynamically adjust the number of
threads per PE. Multiple threads can share the same data locally, which greatly
reduces the data traffic load on the CGRA's routing structure. The paper shows
the results of a CGRA using SHP-ed RISC-V cores as PEs implemented on a FPGA.
"
534,"DSL-based Design Space Exploration for Temporal and Spatial Parallelism
  of Custom Stream Computing","  Stream computation is one of the approaches suitable for FPGA-based custom
computing due to its high throughput capability brought by pipelining with
regular memory access. To increase performance of iterative stream computation,
we can exploit both temporal and spatial parallelism by deepening and
duplicating pipelines, respectively. However, the performance is constrained by
several factors including available hardware resources on FPGA, an external
memory bandwidth, and utilization of pipeline stages, and therefore we need to
find the best mix of the different parallelism to achieve the highest
performance per power. In this paper, we present a domain-specific language
(DSL) based design space exploration for temporally and/or spatially parallel
stream computation with FPGA. We define a DSL where we can easily design a
hierarchical structure of parallel stream computation with abstract description
of computation. For iterative stream computation of fluid dynamics simulation,
we design hardware structures with a different mix of the temporal and spatial
parallelism. By measuring the performance and the power consumption, we find
the best among them.
"
535,Automatic Nested Loop Acceleration on FPGAs Using Soft CGRA Overlay,"  Offloading compute intensive nested loops to execute on FPGA accelerators
have been demonstrated by numerous researchers as an effective performance
enhancement technique across numerous application domains. To construct such
accelerators with high design productivity, researchers have increasingly
turned to the use of overlay architectures as an intermediate generation target
built on top of off-the-shelf FPGAs. However, achieving the desired
performance-overhead trade-off remains a major productivity challenge as
complex application-specific customizations over a large design space covering
multiple architectural parameters are needed.
  In this work, an automatic nested loop acceleration framework utilizing a
regular soft coarse-grained reconfigurable array (SCGRA) overlay is presented.
Given high-level resource constraints, the framework automatically customizes
the overlay architectural design parameters, high-level compilation options as
well as communication between the accelerator and the host processor for
optimized performance specifically to the given application. In our
experiments, at a cost of 10 to 20 minutes additional tools run time, the
proposed customization process resulted in up to 5 times additional speedup
over a baseline accelerator generated by the same framework without
customization. Overall, when compared to the equivalent software running on the
host ARM processor alone on the Zedboard, the resulting accelerators achieved
up to 10 times speedup.
"
536,Dissecting GPU Memory Hierarchy through Microbenchmarking,"  Memory access efficiency is a key factor in fully utilizing the computational
power of graphics processing units (GPUs). However, many details of the GPU
memory hierarchy are not released by GPU vendors. In this paper, we propose a
novel fine-grained microbenchmarking approach and apply it to three generations
of NVIDIA GPUs, namely Fermi, Kepler and Maxwell, to expose the previously
unknown characteristics of their memory hierarchies. Specifically, we
investigate the structures of different GPU cache systems, such as the data
cache, the texture cache and the translation look-aside buffer (TLB). We also
investigate the throughput and access latency of GPU global memory and shared
memory. Our microbenchmark results offer a better understanding of the
mysterious GPU memory hierarchy, which will facilitate the software
optimization and modelling of GPU architectures. To the best of our knowledge,
this is the first study to reveal the cache properties of Kepler and Maxwell
GPUs, and the superiority of Maxwell in shared memory performance under bank
conflict.
"
537,"FPGA Implementation of High Speed Baugh-Wooley Multiplier using
  Decomposition Logic","  The Baugh-Wooley algorithm is a well-known iterative algorithm for performing
multiplication in digital signal processing applications. Decomposition logic
is used with Baugh-Wooley algorithm to enhance the speed and to reduce the
critical path delay. In this paper a high speed multiplier is designed and
implemented using decomposition logic and Baugh-Wooley algorithm. The result is
compared with booth multiplier. FPGA based architecture is presented and design
has been implemented using Xilinx 12.3 device.
"
538,"DReAM: Dynamic Re-arrangement of Address Mapping to Improve the
  Performance of DRAMs","  The initial location of data in DRAMs is determined and controlled by the
'address-mapping' and even modern memory controllers use a fixed and
run-time-agnostic address mapping. On the other hand, the memory access pattern
seen at the memory interface level will dynamically change at run-time. This
dynamic nature of memory access pattern and the fixed behavior of address
mapping process in DRAM controllers, implied by using a fixed address mapping
scheme, means that DRAM performance cannot be exploited efficiently. DReAM is a
novel hardware technique that can detect a workload-specific address mapping at
run-time based on the application access pattern which improves the performance
of DRAMs. The experimental results show that DReAM outperforms the best
evaluated address mapping on average by 9%, for mapping-sensitive workloads, by
2% for mapping-insensitive workloads, and up to 28% across all the workloads.
DReAM can be seen as an insurance policy capable of detecting which scenarios
are not well served by the predefined address mapping.
"
539,HAPPY: Hybrid Address-based Page Policy in DRAMs,"  Memory controllers have used static page closure policies to decide whether a
row should be left open, open-page policy, or closed immediately, close-page
policy, after the row has been accessed. The appropriate choice for a
particular access can reduce the average memory latency. However, since
application access patterns change at run time, static page policies cannot
guarantee to deliver optimum execution time. Hybrid page policies have been
investigated as a means of covering these dynamic scenarios and are now
implemented in state-of-the-art processors. Hybrid page policies switch between
open-page and close-page policies while the application is running, by
monitoring the access pattern of row hits/conflicts and predicting future
behavior. Unfortunately, as the size of DRAM memory increases, fine-grain
tracking and analysis of memory access patterns does not remain practical. We
propose a compact memory address-based encoding technique which can improve or
maintain the performance of DRAMs page closure predictors while reducing the
hardware overhead in comparison with state-of-the-art techniques. As a case
study, we integrate our technique, HAPPY, with a state-of-the-art monitor, the
Intel-adaptive open-page policy predictor employed by the Intel Xeon X5650, and
a traditional Hybrid page policy. We evaluate them across 70 memory intensive
workload mixes consisting of single-thread and multi-thread applications. The
experimental results show that using the HAPPY encoding applied to the
Intel-adaptive page closure policy can reduce the hardware overhead by 5X for
the evaluated 64 GB memory (up to 40X for a 512 GB memory) while maintaining
the prediction accuracy.
"
540,"Feasible methodology for optimization of a novel reversible binary
  compressor","  Now a day reversible logic is an attractive research area due to its low
power consumption in the area of VLSI circuit design. The reversible logic gate
is utilized to optimize power consumption by a feature of retrieving input
logic from an output logic because of bijective mapping between input and
output. In this manuscript, we design 4 2 and 5 2 reversible compressor
circuits using a new type of reversible gate. In addition, we propose new gate,
named as inventive0 gate for optimizing a compressor circuit. The utility of
the inventive0 gate is that it can be used as full adder and full subtraction
with low value of garbage outputs and quantum cost. An algorithm is shown for
designing a compressor structure. The comparative study shows that the proposed
compressor structure outperforms the existing ones in terms of garbage outputs,
number of gates and quantum cost. The compressor can reduce the effect of carry
(Produce from full adder) of the arithmetic frame design. In addition, we
implement a basic reversible gate of MOS transistor with less number of MOS
transistor count.
"
541,High Speed VLSI Architecture for 3-D Discrete Wavelet Transform,"  This paper presents a memory efficient, high throughput parallel lifting
based running three dimensional discrete wavelet transform (3-D DWT)
architecture. 3-D DWT is constructed by combining the two spatial and four
temporal processors. Spatial processor (SP) apply the two dimensional DWT on a
frame, using lifting based 9/7 filter bank through the row rocessor (RP) in row
direction and then apply in the colum direction through column processor (CP).
To reduce the temporal memory and the latency, the temporal processor (TP) has
been designed with lifting based 1-D Haar wavelet filter. The proposed
architecture replaced the multiplications by pipeline shift-add operations to
reduce the CPD. Two spatial processors works simultaneously on two adjacent
frames and provide 2-D DWT coefficients as inputs to the temporal processors.
TPs apply the one dimensional DWT in temporal direction and provide eight 3-D
DWT coefficients per clock (throughput). Higher throughput reduces the
computing cycles per frame and enable the lower power consumption.
Implementation results shows that the proposed architecture has the advantage
in reduced memory, low power consumption, low latency, and high throughput over
the existing designs. The RTL of the proposed architecture is described using
verilog and synthesized using 90-nm technology CMOS standard cell library and
results show that it consumes 43.42 mW power and occupies an area equivalent to
231.45 K equivalent gate at frequency of 200 MHz. The proposed architecture has
also been synthesised for the Xilinx zynq 7020 series field programmable gate
array (FPGA).
"
542,"Cost Efficient Design of Reversible Adder Circuits for Low Power
  Applications","  A large amount of research is currently going on in the field of reversible
logic, which have low heat dissipation, low power consumption, which is the
main factor to apply reversible in digital VLSI circuit design. This paper
introduces reversible gate named as Inventive0 gate. The novel gate is
synthesis the efficient adder modules with minimum garbage output and gate
count. The Inventive0 gate capable of implementing a 4-bit ripple carry adder
and carry skip adders.It is presented that Inventive0 gate is much more
efficient and optimized approach as compared to their existing design, in terms
of gate count, garbage outputs and constant inputs. In addition, some popular
available reversible gates are implemented in the MOS transistor design the
implementation kept in mind for minimum MOS transistor count and are completely
reversible in behavior more precise forward and backward computation. Lesser
architectural complexity show that the novel designs are compact, fast as well
as low power.
"
543,"A Novel Method for Soft Error Mitigation in FPGA using Adaptive Cross
  Parity Code","  Field Programmable Gate Arrays (FPGAs) are more prone to be affected by
transient faults in presence of radiation and other environmental hazards
compared to Application Specific Integrated Circuits (ASICs). Hence, error
mitigation and recovery techniques are absolutely necessary to protect the FPGA
hardware from soft errors arising due to such transient faults. In this paper,
a new efficient multi-bit error correcting method for FPGAs is proposed using
adaptive cross parity check (ACPC) code. ACPC is easy to implement and the
needed decoding circuit is also simple. In the proposed scheme total
configuration memory is partitioned into two parts. One part will contain ACPC
hardware, which is static and assumed to be unaffected by any kind of errors.
Other portion will store the binary file for logic, which is to be protected
from transient error and is assumed to be dynamically reconfigurable (Partial
reconfigurable area). Binary file from the secondary memory passes through ACPC
hardware and the bits for forward error correction (FEC) field are calculated
before entering into the reconfigurable portion. In the runtime scenario, the
data from the dynamically reconfigurable portion of the configuration memory
will be read back and passed through the ACPC hardware. The ACPC hardware will
correct the errors before the data enters into the dynamic configuration
memory. We propose a first of its kind methodology for novel transient fault
correction using ACPC code for FPGAs. To validate the design we have tested the
proposed methodology with Kintex FPGA. We have also measured different
parameters like critical path, power consumption, overhead resource and error
correction efficiency to estimate the performance of our proposed method.
"
544,"Automatic latency balancing in VHDL-implemented complex pipelined
  systems","  Balancing (equalization) of latency in parallel paths in the pipelined data
processing system is an important problem. Without that the data from different
paths arrive at the processing blocks in different clock cycles, and incorrect
results are produced. Manual correction of latencies is a tedious and
error-prone work. This paper presents an automatic method of latency
equalization in systems described in VHDL. The method is based on simulation
and is portable between different simulation and synthesis tools. The method
does not increase the complexity of the synthesized design comparing to the
solution based on manual latency adjustment. The example implementation of the
proposed methodology together with a simple design demonstrating its use is
available as an open source project under BSD license.
"
545,"VLSI Implementation of Deep Neural Network Using Integral Stochastic
  Computing","  The hardware implementation of deep neural networks (DNNs) has recently
received tremendous attention: many applications in fact require high-speed
operations that suit a hardware implementation. However, numerous elements and
complex interconnections are usually required, leading to a large area
occupation and copious power consumption. Stochastic computing has shown
promising results for low-power area-efficient hardware implementations, even
though existing stochastic algorithms require long streams that cause long
latencies. In this paper, we propose an integer form of stochastic computation
and introduce some elementary circuits. We then propose an efficient
implementation of a DNN based on integral stochastic computing. The proposed
architecture has been implemented on a Virtex7 FPGA, resulting in 45% and 62%
average reductions in area and latency compared to the best reported
architecture in literature. We also synthesize the circuits in a 65 nm CMOS
technology and we show that the proposed integral stochastic architecture
results in up to 21% reduction in energy consumption compared to the binary
radix implementation at the same misclassification rate. Due to fault-tolerant
nature of stochastic architectures, we also consider a quasi-synchronous
implementation which yields 33% reduction in energy consumption w.r.t. the
binary radix implementation without any compromise on performance.
"
546,In-Field Logic Repair of Deep Sub-Micron CMOS Processors,"  Ultra Deep-Sub-Micron CMOS chips have to function correctly and reliably, not
only during their early post-fabrication life, but also for their entire life
span. In this paper, we present an architectural-level in-field repair
technique. The key idea is to trade area for reliability by adding repair
features to the system while keeping the power and the performance overheads as
low as possible. In the case of permanent faults, spare blocks will replace the
faulty blocks on the fly. Meanwhile by shutting down the main logic blocks,
partial threshold voltage recovery can be achieved which will alleviate the
ageing-related delays and timing issues. The technique can avoid fatal
shut-downs in the system and will decrease the down-time, hence the
availability of such a system will be preserved. We have implemented the
proposed idea on a pipelined processor core using a conventional ASIC design
flow. The simulation results show that by tolerating about 70% area overhead
and less than 18% power overhead we can dramatically increase the reliability
and decrease the downtime of the processor.
"
547,A High Throughput List Decoder Architecture for Polar Codes,"  While long polar codes can achieve the capacity of arbitrary binary-input
discrete memoryless channels when decoded by a low complexity successive
cancelation (SC) algorithm, the error performance of the SC algorithm is
inferior for polar codes with finite block lengths. The cyclic redundancy check
(CRC) aided successive cancelation list (SCL) decoding algorithm has better
error performance than the SC algorithm. However, current CRC aided SCL
(CA-SCL) decoders still suffer from long decoding latency and limited
throughput. In this paper, a reduced latency list decoding (RLLD) algorithm for
polar codes is proposed. Our RLLD algorithm performs the list decoding on a
binary tree, whose leaves correspond to the bits of a polar code. In existing
SCL decoding algorithms, all the nodes in the tree are traversed and all
possibilities of the information bits are considered. Instead, our RLLD
algorithm visits much fewer nodes in the tree and considers fewer possibilities
of the information bits. When configured properly, our RLLD algorithm
significantly reduces the decoding latency and hence improves throughput, while
introducing little performance degradation. Based on our RLLD algorithm, we
also propose a high throughput list decoder architecture, which is suitable for
larger block lengths due to its scalable partial sum computation unit. Our
decoder architecture has been implemented for different block lengths and list
sizes using the TSMC 90nm CMOS technology. The implementation results
demonstrate that our decoders achieve significant latency reduction and area
efficiency improvement compared with other list polar decoders in the
literature.
"
548,A Clock Synchronizer for Repeaterless Low Swing On-Chip Links,"  A clock synchronizing circuit for repeaterless low swing interconnects is
presented in this paper. The circuit uses a delay locked loop (DLL) to generate
multiple phases of the clock, of which the one closest to the center of the eye
is picked by a phase detector loop. The picked phase is then further fine tuned
by an analog voltage controlled delay to position the sampling clock at the
center of the eye. A clock domain transfer circuit then transfers the sampled
data to the receiver clock domain with a maximum latency of three clock cycles.
The proposed synchronizer has been designed and fabricated in 130 nm UMC MM
CMOS technology. The circuit consumes 1.4 mW from a 1.2 V supply at a data rate
of 1.3 Gbps. Further, the proposed synchronizer has been designed and simulated
in TSMC 65 nm CMOS technology. Post layout simulations show that the
synchronizer consumes 1.5 mW from a 1 V supply, at a data rate of 4 Gbps in
this technology.
"
549,"Network-on-Chip with load balancing based on interleave of flits
  technique","  This paper presents the evaluation of a Network-on-Chip (NoC) that offers
load balancing for Systems-on-Chip (SoCs) dedicated for multimedia applications
that require high traffic of variable bitrate communication. The NoC is based
on a technique that allows the interleaving of flits from diferente flows in
the same communication channel, and keep the load balancing without a
centralized control in the network. For this purpose, all flits in the network
received extra bits, such that every flit carries routing information. The
routers use this extra information to perform arbitration and schedule the
flits to the corresponding output ports. Analytic comparisons and experimental
data show that the approach adopted in the network keeps average latency lower
for variable bitrate flows than a network based on resource reservation when
both networks are working over 80% of offered load.
"
550,SecureD: A Secure Dual Core Embedded Processor,"  Security of embedded computing systems is becoming of paramount concern as
these devices become more ubiquitous, contain personal information and are
increasingly used for financial transactions. Security attacks targeting
embedded systems illegally gain access to the information in these devices or
destroy information. The two most common types of attacks embedded systems
encounter are code-injection and power analysis attacks. In the past, a number
of countermeasures, both hardware- and software-based, were proposed
individually against these two types of attacks. However, no single system
exists to counter both of these two prominent attacks in a processor based
embedded system. Therefore, this paper, for the first time, proposes a
hardware/software based countermeasure against both code-injection attacks and
power analysis based side-channel attacks in a dual core embedded system. The
proposed processor, named SecureD, has an area overhead of just 3.80% and an
average runtime increase of 20.0% when compared to a standard dual processing
system. The overhead were measured using a set of industry standard application
benchmarks, with two encryption and five other programs.
"
551,"Analysis of Intel's Haswell Microarchitecture Using The ECM Model and
  Microbenchmarks","  This paper presents an in-depth analysis of Intel's Haswell microarchitecture
for streaming loop kernels. Among the new features examined is the dual-ring
Uncore design, Cluster-on-Die mode, Uncore Frequency Scaling, core improvements
as new and improved execution units, as well as improvements throughout the
memory hierarchy. The Execution-Cache-Memory diagnostic performance model is
used together with a generic set of microbenchmarks to quantify the efficiency
of the microarchitecture. The set of microbenchmarks is chosen such that it can
serve as a blueprint for other streaming loop kernels.
"
552,Testable Design of Repeaterless Low Swing On-Chip Interconnect,"  Repeaterless low swing interconnects use mixed signal circuits to achieve
high performance at low power. When these interconnects are used in large scale
and high volume digital systems their testability becomes very important. This
paper discusses the testability of low swing repeaterless on-chip interconnects
with equalization and clock synchronization. A capacitively coupled transmitter
with a weak driver is used as the transmitter. The receiver samples the low
swing input data at the center of the data eye and converts it to rail to rail
levels and also synchronizes the data to the receiver's clock domain. The
system is a mixed signal circuit and the digital components are all scan
testable. For the analog section, just a DC test has a fault coverage of 50% of
the structural faults. Simple techniques allow integration of the analog
components into the digital scan chain increasing the coverage to 74%. Finally,
a BIST with low overhead enhances the coverage to 95% of the structural faults.
The design and simulations have been done in UMC 130 nm CMOS technology.
"
553,"Tardis 2.0: Optimized Time Traveling Coherence for Relaxed Consistency
  Models","  Cache coherence scalability is a big challenge in shared memory systems.
Traditional protocols do not scale due to the storage and traffic overhead of
cache invalidation. Tardis, a recently proposed coherence protocol, removes
cache invalidation using logical timestamps and achieves excellent scalability.
The original Tardis protocol, however, only supports the Sequential Consistency
(SC) memory model, limiting its applicability. Tardis also incurs extra network
traffic on some benchmarks due to renew messages, and has suboptimal
performance when the program uses spinning to communicate between threads.
  In this paper, we address these downsides of Tardis protocol and make it
significantly more practical. Specifically, we discuss the architectural,
memory system and protocol changes required in order to implement the TSO
consistency model on Tardis, and prove that the modified protocol satisfies
TSO. We also describe modifications for Partial Store Order (PSO) and Release
Consistency (RC). Finally, we propose optimizations for better leasing policies
and to handle program spinning. On a set of benchmarks, optimized Tardis
improves on a full-map directory protocol in the metrics of performance,
storage and network traffic, while being simpler to implement.
"
554,"Digital LDO with Time-Interleaved Comparators for Fast Response and Low
  Ripple","  On-chip voltage regulation using distributed Digital Low Drop Out (LDO)
voltage regulators has been identified as a promising technique for efficient
power-management for emerging multi-core processors. Digital LDOs (DLDO) can
offer low voltage operation, faster transient response, and higher current
efficiency. Response time as well as output voltage ripple can be reduced by
increasing the speed of the dynamic comparators. However, the comparator offset
steeply increases for high clock frequencies, thereby leading to enhanced
variations in output voltage. In this work we explore the design of digital
LDOs with multiple dynamic comparators that can overcome this bottleneck. In
the proposed topology, we apply time-interleaved comparators with the same
voltage threshold and uniform current step in order to accomplish the
aforementioned features. Simulation based analysis shows that the DLDO with
time-interleaved comparators can achieve better overall performance in terms of
current efficiency, ripple and settling time. For a load step of 50mA, a DLDO
with 8 time-interleaved comparators could achieve an output ripple of less than
5mV, while achieving a settling time of less than 0.5us. Load current dependant
dynamic adjustment of clock frequency is proposed to maintain high current
efficiency of ~97%.
"
555,"Energy Efficient and High Performance Current-Mode Neural Network
  Circuit using Memristors and Digitally Assisted Analog CMOS Neurons","  Emerging nano-scale programmable Resistive-RAM (RRAM) has been identified as
a promising technology for implementing brain-inspired computing hardware.
Several neural network architectures, that essentially involve computation of
scalar products between input data vectors and stored network weights can be
efficiently implemented using high density cross-bar arrays of RRAM integrated
with CMOS. In such a design, the CMOS interface may be responsible for
providing input excitations and for processing the RRAM output. In order to
achieve high energy efficiency along with high integration density in RRAM
based neuromorphic hardware, the design of RRAM-CMOS interface can therefore
play a major role. In this work we propose design of high performance, current
mode CMOS interface for RRAM based neural network design. The use of current
mode excitation for input interface and design of digitally assisted
current-mode CMOS neuron circuit for the output interface is presented. The
proposed technique achieve 10x energy as well as performance improvement over
conventional approaches employed in literature. Network level simulations show
that the proposed scheme can achieve 2 orders of magnitude lower energy
dissipation as compared to a digital ASIC implementation of a feed-forward
neural network.
"
556,Efficient Edge Detection on Low-Cost FPGAs,"  Improving the efficiency of edge detection in embedded applications, such as
UAV control, is critical for reducing system cost and power dissipation. Field
programmable gate arrays (FPGA) are a good platform for making improvements
because of their specialised internal structure. However, current FPGA edge
detectors do not exploit this structure well. A new edge detection architecture
is proposed that is better optimised for FPGAs. The basis of the architecture
is the Sobel edge kernels that are shown to be the most suitable because of
their separability and absence of multiplications. Edge intensities are
calculated with a new 4:2 compressor that consists of two custom-designed 3:2
compressors. Addition speed is increased by breaking carry propagation chains
with look-ahead logic. Testing of the design showed it gives a 28% increase in
speed and 4.4% reduction in area over previous equivalent designs, which
demonstrated that it will lower the cost of edge detection systems, dissipate
less power and still maintain high-speed control.
"
557,Threshold Voltage-Defined Switches for Programmable Gates,"  Semiconductor supply chain is increasingly getting exposed to variety of
security attacks such as Trojan insertion, cloning, counterfeiting, reverse
engineering (RE), piracy of Intellectual Property (IP) or Integrated Circuit
(IC) and side-channel analysis due to involvement of untrusted parties. In this
paper, we propose transistor threshold voltage-defined switches to camouflage
the logic gate both logically and physically to resist against RE and IP
piracy. The proposed gate can function as NAND, AND, NOR, OR, XOR, XNOR, INV
and BUF robustly using threshold-defined switches. The camouflaged design
operates at nominal voltage and obeys conventional reliability limits. The
proposed gate can also be used to personalize the design during manufacturing.
"
558,Partitioned Successive-Cancellation List Decoding of Polar Codes,"  Successive-cancellation list (SCL) decoding is an algorithm that provides
very good error-correction performance for polar codes. However, its hardware
implementation requires a large amount of memory, mainly to store intermediate
results. In this paper, a partitioned SCL algorithm is proposed to reduce the
large memory requirements of the conventional SCL algorithm. The decoder tree
is broken into partitions that are decoded separately. We show that with
careful selection of list sizes and number of partitions, the proposed
algorithm can outperform conventional SCL while requiring less memory.
"
559,Configurable memory systems for embedded many-core processors,"  The memory system of a modern embedded processor consumes a large fraction of
total system energy. We explore a range of different configuration options and
show that a reconfigurable design can make better use of the resources
available to it than any fixed implementation, and provide large improvements
in both performance and energy consumption. Reconfigurability becomes
increasingly useful as resources become more constrained, so is particularly
relevant in the embedded space.
  For an optimised architectural configuration, we show that a configurable
cache system performs an average of 20% (maximum 70%) better than the best
fixed implementation when two programs are competing for the same resources,
and reduces cache miss rate by an average of 70% (maximum 90%). We then present
a case study of AES encryption and decryption, and find that a custom memory
configuration can almost double performance, with further benefits being
achieved by specialising the task of each core when parallelising the program.
"
560,Design of a Low-Power 1.65 Gbps Data Channel for HDMI Transmitter,"  This paper presents a design of low power data channel for application in
High Definition Multimedia Interface (HDMI) Transmitter circuit. The input is
10 bit parallel data and output is serial data at 1.65 Gbps. This circuit uses
only a single frequency of serial clock input. All other timing signals are
derived within the circuit from the serial clock. This design has dedicated
lines to disable and enable all its channels within two pixel-clock periods
only. A pair of disable and enable functions performed immediately after
power-on of the circuit serves as the reset function. The presented design is
immune to data-dependent switching spikes in supply current and pushes them in
the range of serial frequency and its multiples. Thus filtering requirements
are relaxed. The output stage uses a bias voltage of 2.8 volts for a receiver
pull-up voltage of 3.3 volts. The reported data channel is designed using UMC
180 nm CMOS Technology. The design is modifiable for other inter-board serial
interfaces like USB and LAN with different number of bits at the parallel
input.
"
561,Profiling-Assisted Decoupled Access-Execute,"  As energy efficiency became a critical factor in the embedded systems domain,
dynamic voltage and frequency scaling (DVFS) techniques have emerged as means
to control the system's power and energy efficiency. Additionally, due to the
compact design, thermal issues become prominent. State of the art work promotes
software decoupled access-execution (DAE) that statically generates code
amenable to DVFS techniques. The compiler builds memory-bound access phases,
designed to prefetch data in the cache at low frequency, and compute-bound
phases, that consume the data and perform computations at high frequency. This
work investigates techniques to find the optimal balance between lightweight
and efficient access phases. A profiling step guides the selection of loads to
be prefetched in the access phase. For applications whose behavior vary
significantly with respect to the input data, the profiling can be performed
online, accompanied by just-in-time compilation. We evaluated the benefits in
energy efficiency and performance for both static and dynamic code generation
and showed that precise prefetching of critical loads can result in 20% energy
improvements, on average. DAE is particularly beneficial for embedded systems
as by alternating access phases (executed at low frequency) and execute phases
(at high frequency) DAE proactively reduces the temperature and therefore
prevents thermal emergencies.
"
562,"Reducing Performance Impact of DRAM Refresh by Parallelizing Refreshes
  with Accesses","  Modern DRAM cells are periodically refreshed to prevent data loss due to
leakage. Commodity DDR DRAM refreshes cells at the rank level. This degrades
performance significantly because it prevents an entire rank from serving
memory requests while being refreshed. DRAM designed for mobile platforms,
LPDDR DRAM, supports an enhanced mode, called per-bank refresh, that refreshes
cells at the bank level. This enables a bank to be accessed while another in
the same rank is being refreshed, alleviating part of the negative performance
impact of refreshes. However, there are two shortcomings of per-bank refresh.
First, the per-bank refresh scheduling scheme does not exploit the full
potential of overlapping refreshes with accesses across banks because it
restricts the banks to be refreshed in a sequential round-robin order. Second,
accesses to a bank that is being refreshed have to wait.
  To mitigate the negative performance impact of DRAM refresh, we propose two
complementary mechanisms, DARP (Dynamic Access Refresh Parallelization) and
SARP (Subarray Access Refresh Parallelization). The goal is to address the
drawbacks of per-bank refresh by building more efficient techniques to
parallelize refreshes and accesses within DRAM. First, instead of issuing
per-bank refreshes in a round-robin order, DARP issues per-bank refreshes to
idle banks in an out-of-order manner. Furthermore, DARP schedules refreshes
during intervals when a batch of writes are draining to DRAM. Second, SARP
exploits the existence of mostly-independent subarrays within a bank. With
minor modifications to DRAM organization, it allows a bank to serve memory
accesses to an idle subarray while another subarray is being refreshed.
Extensive evaluations show that our mechanisms improve system performance and
energy efficiency compared to state-of-the-art refresh policies and the benefit
increases as DRAM density increases.
"
563,Tiered-Latency DRAM (TL-DRAM),"  This paper summarizes the idea of Tiered-Latency DRAM, which was published in
HPCA 2013. The key goal of TL-DRAM is to provide low DRAM latency at low cost,
a critical problem in modern memory systems. To this end, TL-DRAM introduces
heterogeneity into the design of a DRAM subarray by segmenting the bitlines,
thereby creating a low-latency, low-energy, low-capacity portion in the
subarray (called the near segment), which is close to the sense amplifiers, and
a high-latency, high-energy, high-capacity portion, which is farther away from
the sense amplifiers. Thus, DRAM becomes heterogeneous with a small portion
having lower latency and a large portion having higher latency. Various
techniques can be employed to take advantage of the low-latency near segment
and this new heterogeneous DRAM substrate, including hardware-based caching and
software based caching and memory allocation of frequently used data in the
near segment. Evaluations with simple such techniques show significant
performance and energy-efficiency benefits.
"
564,"Enabling Efficient Dynamic Resizing of Large DRAM Caches via A Hardware
  Consistent Hashing Mechanism","  Die-stacked DRAM has been proposed for use as a large, high-bandwidth,
last-level cache with hundreds or thousands of megabytes of capacity. Not all
workloads (or phases) can productively utilize this much cache space, however.
Unfortunately, the unused (or under-used) cache continues to consume power due
to leakage in the peripheral circuitry and periodic DRAM refresh. Dynamically
adjusting the available DRAM cache capacity could largely eliminate this energy
overhead. However, the current proposed DRAM cache organization introduces new
challenges for dynamic cache resizing. The organization differs from a
conventional SRAM cache organization because it places entire cache sets and
their tags within a single bank to reduce on-chip area and power overhead.
Hence, resizing a DRAM cache requires remapping sets from the powered-down
banks to active banks.
  In this paper, we propose CRUNCH (Cache Resizing Using Native Consistent
Hashing), a hardware data remapping scheme inspired by consistent hashing, an
algorithm originally proposed to uniformly and dynamically distribute Internet
traffic across a changing population of web servers. CRUNCH provides a
load-balanced remapping of data from the powered-down banks alone to the active
banks, without requiring sets from all banks to be remapped, unlike naive
schemes to achieve load balancing. CRUNCH remaps only sets from the
powered-down banks, so it achieves this load balancing with low bank
power-up/down transition latencies. CRUNCH's combination of good load balancing
and low transition latencies provides a substrate to enable efficient DRAM
cache resizing.
"
565,Effect of Data Sharing on Private Cache Design in Chip Multiprocessors,"  In multithreaded applications with high degree of data sharing, the miss rate
of private cache is shown to exhibit a compulsory miss component. It manifests
because at least some of the shared data originates from other cores and can
only be accessed in a shared cache. The compulsory component does not change
with the private cache size, causing its miss rate to diminish slower as the
cache size grows. As a result, the peak performance of a Chip Multiprocessor
(CMP) for workloads with high degree of data sharing is achieved with a smaller
private cache, compared to workloads with no data sharing. The CMP performance
can be improved by reassigning some of the constrained area or power resource
from private cache to core. Alternatively, the area or power budget of a CMP
can be reduced without a performance hit.
"
566,"A Framework for Accelerating Bottlenecks in GPU Execution with Assist
  Warps","  Modern Graphics Processing Units (GPUs) are well provisioned to support the
concurrent execution of thousands of threads. Unfortunately, different
bottlenecks during execution and heterogeneous application requirements create
imbalances in utilization of resources in the cores. For example, when a GPU is
bottlenecked by the available off-chip memory bandwidth, its computational
resources are often overwhelmingly idle, waiting for data from memory to
arrive.
  This work describes the Core-Assisted Bottleneck Acceleration (CABA)
framework that employs idle on-chip resources to alleviate different
bottlenecks in GPU execution. CABA provides flexible mechanisms to
automatically generate ""assist warps"" that execute on GPU cores to perform
specific tasks that can improve GPU performance and efficiency.
  CABA enables the use of idle computational units and pipelines to alleviate
the memory bandwidth bottleneck, e.g., by using assist warps to perform data
compression to transfer less data from memory. Conversely, the same framework
can be employed to handle cases where the GPU is bottlenecked by the available
computational units, in which case the memory pipelines are idle and can be
used by CABA to speed up computation, e.g., by performing memoization using
assist warps.
  We provide a comprehensive design and evaluation of CABA to perform effective
and flexible data compression in the GPU memory hierarchy to alleviate the
memory bandwidth bottleneck. Our extensive evaluations show that CABA, when
used to implement data compression, provides an average performance improvement
of 41.7% (as high as 2.6X) across a variety of memory-bandwidth-sensitive GPGPU
applications.
"
567,EIE: Efficient Inference Engine on Compressed Deep Neural Network,"  State-of-the-art deep neural networks (DNNs) have hundreds of millions of
connections and are both computationally and memory intensive, making them
difficult to deploy on embedded systems with limited hardware resources and
power budgets. While custom hardware helps the computation, fetching weights
from DRAM is two orders of magnitude more expensive than ALU operations, and
dominates the required power.
  Previously proposed 'Deep Compression' makes it possible to fit large DNNs
(AlexNet and VGGNet) fully in on-chip SRAM. This compression is achieved by
pruning the redundant connections and having multiple connections share the
same weight. We propose an energy efficient inference engine (EIE) that
performs inference on this compressed network model and accelerates the
resulting sparse matrix-vector multiplication with weight sharing. Going from
DRAM to SRAM gives EIE 120x energy saving; Exploiting sparsity saves 10x;
Weight sharing gives 8x; Skipping zero activations from ReLU saves another 3x.
Evaluated on nine DNN benchmarks, EIE is 189x and 13x faster when compared to
CPU and GPU implementations of the same DNN without compression. EIE has a
processing power of 102GOPS/s working directly on a compressed network,
corresponding to 3TOPS/s on an uncompressed network, and processes FC layers of
AlexNet at 1.88x10^4 frames/sec with a power dissipation of only 600mW. It is
24,000x and 3,400x more energy efficient than a CPU and GPU respectively.
Compared with DaDianNao, EIE has 2.9x, 19x and 3x better throughput, energy
efficiency and area efficiency.
"
568,"FPGA Based Implementation of Deep Neural Networks Using On-chip Memory
  Only","  Deep neural networks (DNNs) demand a very large amount of computation and
weight storage, and thus efficient implementation using special purpose
hardware is highly desired. In this work, we have developed an FPGA based
fixed-point DNN system using only on-chip memory not to access external DRAM.
The execution time and energy consumption of the developed system is compared
with a GPU based implementation. Since the capacity of memory in FPGA is
limited, only 3-bit weights are used for this implementation, and training
based fixed-point weight optimization is employed. The implementation using
Xilinx XC7Z045 is tested for the MNIST handwritten digit recognition benchmark
and a phoneme recognition task on TIMIT corpus. The obtained speed is about one
quarter of a GPU based implementation and much better than that of a PC based
one. The power consumption is less than 5 Watt at the full speed operation
resulting in much higher efficiency compared to GPU based systems.
"
569,Energy Efficient Video Fusion with Heterogeneous CPU-FPGA Devices,"  This paper presents a complete video fusion system with hardware acceleration
and investigates the energy trade-offs between computing in the CPU or the FPGA
device. The video fusion application is based on the Dual-Tree Complex Wavelet
Transforms (DT-CWT). In this work the transforms are mapped to a hardware
accelerator using high-level synthesis tools for the FPGA and also vectorized
code for the single instruction multiple data (SIMD) engine available in the
CPU. The accelerated system reduces computation time and energy by a factor of
2. Moreover, the results show a key finding that the FPGA is not always the
best choice for acceleration, and the SIMD engine should be selected when the
wavelet decomposition reduces the frame size below a certain threshold. This
dependency on workload size means that an adaptive system that intelligently
selects between the SIMD engine and the FPGA achieves the most energy and
performance efficiency point.
"
570,"FPGA Hardware Acceleration of Monte Carlo Simulations for the Ising
  Model","  A two-dimensional Ising model with nearest-neighbors ferromagnetic
interactions is implemented in a Field Programmable Gate Array (FPGA)
board.Extensive Monte Carlo simulations were carried out using an efficient
hardware representation of individual spins and a combined global-local LFSR
random number generator. Consistent results regarding the descriptive
properties of magnetic systems, like energy, magnetization and susceptibility
are obtained while a speed-up factor of approximately 6 times is achieved in
comparison to previous FPGA-based published works and almost $10^4$ times in
comparison to a standard CPU simulation. A detailed description of the logic
design used is given together with a careful analysis of the quality of the
random number generator used. The obtained results confirm the potential of
FPGAs for analyzing the statistical mechanics of magnetic systems.
"
571,OpenRISC System-on-Chip Design Emulation,"  Recently the hardware emulation technique has emerged as a promising approach
to accelerating hardware verification/debugging process. To fully evaluate the
powerfulness of the emulation approach and demonstrate its potential impact, we
propose to emulate a system-on-chip (SoC) design using Mentor Graphics Veloce
emulation platform. This article presents our project setup and the results we
have achieved. The results are encouraging. ORPSoC emulation with Veloce has
more than ten times faster than hardware simulation. Our experimental results
demonstrate that Mentor Graphics Veloce has major advantages in emulation,
verification, and debugging of complicated real hardware designs, especially in
the context of SoC complexity. Through our three major tasks, we will
demonstrate that (1) Veloce can successfully emulate large-scale SoC designs;
(2) it has much better performance comparing to the state-of-the-art simulation
tools; (3) it can significantly accelerate the process of hardware verification
and debugging while maintaining full signal visibility.
"
572,"Dark Memory and Accelerator-Rich System Optimization in the Dark Silicon
  Era","  The key challenge to improving performance in the age of Dark Silicon is how
to leverage transistors when they cannot all be used at the same time. In
modern SOCs, these transistors are often used to create specialized
accelerators which improve energy efficiency for some applications by 10-1000X.
While this might seem like the magic bullet we need, for most CPU applications
more energy is dissipated in the memory system than in the processor: these
large gains in efficiency are only possible if the DRAM and memory hierarchy
are mostly idle. We refer to this desirable state as Dark Memory, and it only
occurs for applications with an extreme form of locality.
  To show our findings, we introduce Pareto curves in the energy/op and
mm$^2$/(ops/s) metric space for compute units, accelerators, and on-chip
memory/interconnect. These Pareto curves allow us to solve the power,
performance, area constrained optimization problem to determine which
accelerators should be used, and how to set their design parameters to optimize
the system. This analysis shows that memory accesses create a floor to the
achievable energy-per-op. Thus high performance requires Dark Memory, which in
turn requires co-design of the algorithm for parallelism and locality, with the
hardware.
"
573,Temperature-aware Dynamic Optimization of Embedded Systems,"  Due to embedded systems` stringent design constraints, much prior work
focused on optimizing energy consumption and/or performance. Since embedded
systems typically have fewer cooling options, rising temperature, and thus
temperature optimization, is an emergent concern. Most embedded systems only
dissipate heat by passive convection, due to the absence of dedicated thermal
management hardware mechanisms. The embedded system`s temperature not only
affects the system`s reliability, but could also affect the performance, power,
and cost. Thus, embedded systems require efficient thermal management
techniques. However, thermal management can conflict with other optimization
objectives, such as execution time and energy consumption. In this paper, we
focus on managing the temperature using a synergy of cache optimization and
dynamic frequency scaling, while also optimizing the execution time and energy
consumption. This paper provides new insights on the impact of cache parameters
on efficient temperature-aware cache tuning heuristics. In addition, we present
temperature-aware phase-based tuning, TaPT, which determines Pareto optimal
clock frequency and cache configurations for fine-grained execution time,
energy, and temperature tradeoffs. TaPT enables autonomous system optimization
and also allows designers to specify temperature constraints and optimization
priorities. Experiments show that TaPT can effectively reduce execution time,
energy, and temperature, while imposing minimal hardware overhead.
"
574,"Phase distance mapping: a phase-based cache tuning methodology for
  embedded systems","  Networked embedded systems typically leverage a collection of low-power
embedded systems (nodes) to collaboratively execute applications spanning
diverse application domains (e.g., video, image processing, communication,
etc.) with diverse application requirements. The individual networked nodes
must operate under stringent constraints (e.g., energy, memory, etc.) and
should be specialized to meet varying application requirements in order to
adhere to these constraints. Phase-based tuning specializes system tunable
parameters to the varying runtime requirements of different execution phases to
meet optimization goals. Since the design space for tunable systems can be very
large, one of the major challenges in phase-based tuning is determining the
best configuration for each phase without incurring significant tuning overhead
(e.g., energy and/or performance) during design space exploration. In this
paper, we propose phase distance mapping, which directly determines the best
configuration for a phase, thereby eliminating design space exploration. Phase
distance mapping applies the correlation between the characteristics and best
configuration of a known phase to determine the best configuration of a new
phase. Experimental results verify that our phase distance mapping approach,
when applied to cache tuning, determines cache configurations within 1 % of the
optimal configurations on average and yields an energy delay product savings of
27 % on average.
"
575,"Automatic Generation of High-Coverage Tests for RTL Designs using
  Software Techniques and Tools","  Register Transfer Level (RTL) design validation is a crucial stage in the
hardware design process. We present a new approach to enhancing RTL design
validation using available software techniques and tools. Our approach converts
the source code of a RTL design into a C++ software program. Then a powerful
symbolic execution engine is employed to execute the converted C++ program
symbolically to generate test cases. To better generate efficient test cases,
we limit the number of cycles to guide symbolic execution. Moreover, we add
bit-level symbolic variable support into the symbolic execution engine.
Generated test cases are further evaluated by simulating the RTL design to get
accurate coverage. We have evaluated the approach on a floating point unit
(FPU) design. The preliminary results show that our approach can deliver
high-quality tests to achieve high coverage.
"
576,"A Dynamic Overlay Supporting Just-In-Time Assembly to Construct
  Customized Hardware Accelerators","  Barriers that prevent programmers from using FPGAs include the need to work
within vendor specific CAD tools, knowledge of hardware programming models, and
the requirement to pass each design through synthesis, place and route. In this
work, a dynamic overlay is designed to support Just- In-Time assembly by
composing hardware operators to construct full accelerators. The hardware
operators are pre-synthesized bit- streams and can be downloaded to Partially
Reconfigurable(PR) regions at runtime.
"
577,On the limitations of analysing worst-case dynamic energy of processing,"  This paper examines dynamic energy consumption caused by data during software
execution on deeply embedded microprocessors, which can be significant on some
devices. In worst-case energy consumption analysis, energy models are used to
find the most costly execution path. Taking each instruction's worst case
energy produces a safe but overly pessimistic upper bound. Algorithms for safe
and tight bounds would be desirable. We show that finding exact worst-case
energy is NP-hard, and that tight bounds cannot be approximated with guaranteed
safety. We conclude that any energy model targeting tightness must either
sacrifice safety or accept overapproximation proportional to data-dependent
energy.
"
578,Design and Implementation of an Improved Carry Increment Adder,"  A complex digital circuit comprises of adder as a basic unit. The performance
of the circuit depends on the design of this basic adder unit. The speed of
operation of a circuit is one of the important performance criteria of many
digital circuits which ultimately depends on the delay of the basic adder unit.
Many research works have been devoted in improving the delay of the adder
circuit. In this paper we have proposed an improved carry increment adder (CIA)
that improves the delay performance of the circuit. The improvement is achieved
by incorporating carry look adder (CLA) in the design of CIA contrary to the
previous design of CIA that employs ripple carry adder (RCA). A simulation
study is carried out for comparative analysis. The coding is done in Verilog
hardware description language (HDL) and the simulation is carried out in Xilinx
ISE 13.1 environment.
"
579,"Modified Micropipline Architecture for Synthesizable Asynchronous FIR
  Filter Design","  The use of asynchronous design approaches to construct digital signal
processing (DSP) systems is a rapidly growing research area driven by a wide
range of emerging energy constrained applications such as wireless sensor
network, portable medical devices and brain implants. The asynchronous design
techniques allow the construction of systems which are samples driven, which
means they only dissipate dynamic energy when there processing data and idle
otherwise. This inherent advantage of asynchronous design over conventional
synchronous circuits allows them to be energy efficient. However the
implementation flow of asynchronous systems is still difficult due to its lack
of compatibility with industry-standard synchronous design tools and modelling
languages. This paper devises a novel asynchronous design for a finite impulse
response (FIR) filter, an essential building block of DSP systems, which is
synthesizable and suitable for implementation using conventional synchronous
systems design flow and tools. The proposed design is based on a modified
version of the micropipline architecture and it is constructed using four phase
bundled data protocol. A hardware prototype of the proposed filter has been
developed on an FPGA, and systematically verified. The results prove correct
functionality of the novel design and a superior performance compared to a
synchronous FIR implementation. The findings of this work will allow a wider
adoption of asynchronous circuits by DSP designers to harness their energy and
performance benefits.
"
580,"2D Discrete Fourier Transform with Simultaneous Edge Artifact Removal
  for Real-Time Applications","  Two-Dimensional (2D) Discrete Fourier Transform (DFT) is a basic and
computationally intensive algorithm, with a vast variety of applications. 2D
images are, in general, non-periodic, but are assumed to be periodic while
calculating their DFTs. This leads to cross-shaped artifacts in the frequency
domain due to spectral leakage. These artifacts can have critical consequences
if the DFTs are being used for further processing. In this paper we present a
novel FPGA-based design to calculate high-throughput 2D DFTs with simultaneous
edge artifact removal. Standard approaches for removing these artifacts using
apodization functions or mirroring, either involve removing critical
frequencies or a surge in computation by increasing image size. We use a
periodic-plus-smooth decomposition based artifact removal algorithm optimized
for FPGA implementation, while still achieving real-time ($\ge$23 frames per
second) performance for a 512$\times$512 size image stream. Our optimization
approach leads to a significant decrease in external memory utilization thereby
avoiding memory conflicts and simplifies the design. We have tested our design
on a PXIe based Xilinx Kintex 7 FPGA system communicating with a host PC which
gives us the advantage to further expand the design for industrial
applications.
"
581,Fast Low-Complexity Decoders for Low-Rate Polar Codes,"  Polar codes are capacity-achieving error-correcting codes with an explicit
construction that can be decoded with low-complexity algorithms. In this work,
we show how the state-of-the-art low-complexity decoding algorithm can be
improved to better accommodate low-rate codes. More constituent codes are
recognized in the updated algorithm and dedicated hardware is added to
efficiently decode these new constituent codes. We also alter the polar code
construction to further decrease the latency and increase the throughput with
little to no noticeable effect on error-correction performance. Rate-flexible
decoders for polar codes of length 1024 and 2048 are implemented on FPGA. Over
the previous work, they are shown to have from 22% to 28% lower latency and 26%
to 34% greater throughput when decoding low-rate codes. On 65 nm ASIC CMOS
technology, the proposed decoder for a (1024, 512) polar code is shown to
compare favorably against the state-of-the-art ASIC decoders. With a clock
frequency of 400 MHz and a supply voltage of 0.8 V, it has a latency of 0.41
$\mu$s and an area efficiency of 1.8 Gbps/mm$^2$ for an energy efficiency of 77
pJ/info. bit. At 600 MHz with a supply of 1 V, the latency is reduced to 0.27
$\mu$s and the area efficiency increased to 2.7 Gbps/mm$^2$ at 115 pJ/info.
bit.
"
582,"LLR-based Successive-Cancellation List Decoder for Polar Codes with
  Multi-bit Decision","  Due to their capacity-achieving property, polar codes have become one of the
most attractive channel codes. To date, the successive cancellation list (SCL)
decoding algorithm is the primary approach that can guarantee outstanding
error-correcting performance of polar codes. However, the hardware designs of
the original SCL decoder have large silicon area and long decoding latency.
Although some recent efforts can reduce either the area or latency of SCL
decoders, these two metrics still cannot be optimized at the same time. This
paper, for the first time, proposes a general log-likelihood-ratio (LLR)-based
SCL decoding algorithm with multi-bit decision. This new algorithm, referred as
LLR-2Kb-SCL, can determine 2K bits simultaneously for arbitrary K with the use
of LLR messages. In addition, a reduced-data-width scheme is presented to
reduce the critical path of the sorting block. Then, based on the proposed
algorithm, a VLSI architecture of the new SCL decoder is developed. Synthesis
results show that for an example (1024, 512) polar code with list size 4, the
proposed LLR-2Kb-SCL decoders achieve significant reduction in both area and
latency as compared to prior works. As a result, the hardware efficiency of the
proposed designs with K=2 and 3 are 2.33 times and 3.32 times of that of the
state-of-the-art works, respectively.
"
583,"A Reconfigurable Low Power High Throughput Architecture for Deep Network
  Training","  General purpose computing systems are used for a large variety of
applications. Extensive supports for flexibility in these systems limit their
energy efficiencies. Neural networks, including deep networks, are widely used
for signal processing and pattern recognition applications. In this paper we
propose a multicore architecture for deep neural network based processing.
Memristor crossbars are utilized to provide low power high throughput execution
of neural networks. The system has both training and recognition (evaluation of
new input) capabilities. The proposed system could be used for classification,
dimensionality reduction, feature extraction, and anomaly detection
applications. The system level area and power benefits of the specialized
architecture is compared with the NVIDIA Telsa K20 GPGPU. Our experimental
evaluations show that the proposed architecture can provide up to five orders
of magnitude more energy efficiency over GPGPUs for deep neural network
processing.
"
584,"ASIC-based Implementation of Synchronous Section-Carry Based Carry
  Lookahead Adders","  The section-carry based carry lookahead adder (SCBCLA) topology was proposed
as an improved high-speed alternative to the conventional carry lookahead adder
(CCLA) topology in previous works. Self-timed and FPGA-based implementations of
SCBCLAs and CCLAs were considered earlier, and it was found that SCBCLAs could
help in delay reduction i.e. pave the way for improved speed compared to CCLAs
at the expense of some increase in area and/or power parameters. In this work,
we consider semi-custom ASIC-based implementations of different variants of
SCBCLAs and CCLAs to perform 32-bit dual-operand addition. Based on the
simulation results for 32-bit dual-operand addition obtained by targeting a
high-end 32/28nm CMOS process, it is found that an optimized SCBCLA
architecture reports a 9.8% improvement in figure-of-merit (FOM) compared to an
optimized CCLA architecture, where the FOM is defined as the inverse of the
product of power, delay, and area. It is generally inferred from the
simulations that the SCBCLA architecture could be more beneficial compared to
the CCLA architecture in terms of the design metrics whilst benefitting a
variety of computer arithmetic operations involving dual-operand and/or
multi-operand additions. Also, it is observed that heterogeneous CLA
architectures tend to fare well compared to homogeneous CLA architectures, as
substantiated by the simulation results.
"
585,"Global versus Local Weak-Indication Self-Timed Function Blocks - A
  Comparative Analysis","  This paper analyzes the merits and demerits of global weak-indication
self-timed function blocks versus local weak-indication self-timed function
blocks, implemented using a delay-insensitive data code and adhering to 4-phase
return-to-zero handshaking. A self-timed ripple carry adder is considered as an
example function block for the analysis. The analysis shows that while global
weak-indication could help in optimizing the power, latency and area
parameters, local weak-indication facilitates the optimum performance in terms
of realizing the data-dependent cycle time that is characteristic of a
weak-indication self-timed design.
"
586,"Power, Delay and Area Comparisons of Majority Voters relevant to TMR
  Architectures","  N-modular redundancy (NMR) is commonly used to enhance the fault tolerance of
a circuit/system, when subject to a fault-inducing environment such as in space
or military systems, where upsets due to radiation phenomena, temperature
and/or other environmental conditions are anticipated. Triple Modular
Redundancy (TMR), which is a 3-tuple version of NMR, is widely preferred for
mission-control space, military, and aerospace, and safety-critical nuclear,
power, medical, and industrial control and automation systems. The TMR scheme
involves the two-times duplication of a simplex system hardware, with a
majority voter ensuring correctness provided at least two out of three copies
of the hardware remain operational. Thus the majority voter plays a pivotal
role in ensuring the correct operation of the TMR scheme. In this paper, a
number of standard-cell based majority voter designs relevant to TMR
architectures are presented, and their power, delay and area parameters are
estimated based on physical realization using a 32/28nm CMOS process.
"
587,Adaptive-Latency DRAM (AL-DRAM),"  This paper summarizes the idea of Adaptive-Latency DRAM (AL-DRAM), which was
published in HPCA 2015. The key goal of AL-DRAM is to exploit the extra margin
that is built into the DRAM timing parameters to reduce DRAM latency. The key
observation is that the timing parameters are dictated by the worst-case
temperatures and worst-case DRAM cells, both of which lead to small amount of
charge storage and hence high access latency. One can therefore reduce latency
by adapting the timing parameters to the current operating temperature and the
current DIMM that is being accessed. Using an FPGA-based testing platform, our
work first characterizes the extra margin for 115 DRAM modules from three major
manufacturers. The experimental results demonstrate that it is possible to
reduce four of the most critical timing parameters by a minimum/maximum of
17.3%/54.8% at 55C while maintaining reliable operation. AL-DRAM adaptively
selects between multiple different timing parameters for each DRAM module based
on its current operating condition. AL-DRAM does not require any changes to the
DRAM chip or its interface; it only requires multiple different timing
parameters to be specified and supported by the memory controller. Real system
evaluations show that AL-DRAM improves the performance of memory-intensive
workloads by an average of 14% without introducing any errors.
"
588,"FPGA Impementation of Erasure-Only Reed Solomon Decoders for Hybrid-ARQ
  Systems","  This paper presents the usage of the Reed Solomon Codes as the Forward Error
Correction (FEC) unit of the Hybrid Automatic Repeat Request (ARQ) methods.
Parametric and flexible FPGA implementation details of such Erasure-Only RS
decoders with high symbol lengths (e.g. GF(2^32)) have been presented. The
design is based on the GF(2m) multiplier logic core operating at a single clock
cycle, where the resource utilization and throughput are both directly
proportional to the number of these cores. For a fixed implementation, the
throughput inversely decreases with the number of erasures to be corrected.
Implementation in Zynq7020 SoC device of an example GF(2^32)-RS Decoder capable
of correcting 64-erasures with a single multiplier resulted in 1641-LUTs and
188-FFs achieving 15Mbps, whereas the design with 8 multipliers resulted in
6128-LUTs and 628-FFs achieving 100Mbps.
"
589,"GateKeeper: A New Hardware Architecture for Accelerating Pre-Alignment
  in DNA Short Read Mapping","  Motivation: High throughput DNA sequencing (HTS) technologies generate an
excessive number of small DNA segments -- called short reads -- that cause
significant computational burden. To analyze the entire genome, each of the
billions of short reads must be mapped to a reference genome based on the
similarity between a read and ""candidate"" locations in that reference genome.
The similarity measurement, called alignment, formulated as an approximate
string matching problem, is the computational bottleneck because: (1) it is
implemented using quadratic-time dynamic programming algorithms, and (2) the
majority of candidate locations in the reference genome do not align with a
given read due to high dissimilarity. Calculating the alignment of such
incorrect candidate locations consumes an overwhelming majority of a modern
read mapper's execution time. Therefore, it is crucial to develop a fast and
effective filter that can detect incorrect candidate locations and eliminate
them before invoking computationally costly alignment operations. Results: We
propose GateKeeper, a new hardware accelerator that functions as a
pre-alignment step that quickly filters out most incorrect candidate locations.
GateKeeper is the first design to accelerate pre-alignment using
Field-Programmable Gate Arrays (FPGAs), which can perform pre-alignment much
faster than software. GateKeeper can be integrated with any mapper that
performs sequence alignment for verification. When implemented on a single FPGA
chip, GateKeeper maintains high accuracy (on average >96%) while providing up
to 90-fold and 130-fold speedup over the state-of-the-art software
pre-alignment techniques, Adjacency Filter and Shifted Hamming Distance (SHD),
respectively. The addition of GateKeeper as a pre-alignment step can reduce the
verification time of the mrFAST mapper by a factor of 10. Availability:
https://github.com/BilkentCompGen/GateKeeper
"
590,"CLEAR: Cross-Layer Exploration for Architecting Resilience - Combining
  Hardware and Software Techniques to Tolerate Soft Errors in Processor Cores","  We present a first of its kind framework which overcomes a major challenge in
the design of digital systems that are resilient to reliability failures:
achieve desired resilience targets at minimal costs (energy, power, execution
time, area) by combining resilience techniques across various layers of the
system stack (circuit, logic, architecture, software, algorithm). This is also
referred to as cross-layer resilience. In this paper, we focus on
radiation-induced soft errors in processor cores. We address both single-event
upsets (SEUs) and single-event multiple upsets (SEMUs) in terrestrial
environments. Our framework automatically and systematically explores the large
space of comprehensive resilience techniques and their combinations across
various layers of the system stack (586 cross-layer combinations in this
paper), derives cost-effective solutions that achieve resilience targets at
minimal costs, and provides guidelines for the design of new resilience
techniques. We demonstrate the practicality and effectiveness of our framework
using two diverse designs: a simple, in-order processor core and a complex,
out-of-order processor core. Our results demonstrate that a carefully optimized
combination of circuit-level hardening, logic-level parity checking, and
micro-architectural recovery provides a highly cost-effective soft error
resilience solution for general-purpose processor cores. For example, a 50x
improvement in silent data corruption rate is achieved at only 2.1% energy cost
for an out-of-order core (6.1% for an in-order core) with no speed impact.
However, selective circuit-level hardening alone, guided by a thorough analysis
of the effects of soft errors on application benchmarks, provides a
cost-effective soft error resilience solution as well (with ~1% additional
energy cost for a 50x improvement in silent data corruption rate).
"
591,"Area/latency optimized early output asynchronous full adders and
  relative-timed ripple carry adders","  This article presents two area/latency optimized gate level asynchronous full
adder designs which correspond to early output logic. The proposed full adders
are constructed using the delay-insensitive dual-rail code and adhere to the
four-phase return-to-zero handshaking. For an asynchronous ripple carry adder
(RCA) constructed using the proposed early output full adders, the
relative-timing assumption becomes necessary and the inherent advantages of the
relative-timed RCA are: (1) computation with valid inputs, i.e., forward
latency is data-dependent, and (2) computation with spacer inputs involves a
bare minimum constant reverse latency of just one full adder delay, thus
resulting in the optimal cycle time. With respect to different 32-bit RCA
implementations, and in comparison with the optimized strong-indication,
weak-indication, and early output full adder designs, one of the proposed early
output full adders achieves respective reductions in latency by 67.8, 12.3 and
6.1 %, while the other proposed early output full adder achieves corresponding
reductions in area by 32.6, 24.6 and 6.9 %, with practically no power penalty.
Further, the proposed early output full adders based asynchronous RCAs enable
minimum reductions in cycle time by 83.4, 15, and 8.8 % when considering
carry-propagation over the entire RCA width of 32-bits, and maximum reductions
in cycle time by 97.5, 27.4, and 22.4 % for the consideration of a typical
carry chain length of 4 full adder stages, when compared to the least of the
cycle time estimates of various strong-indication, weak-indication, and early
output asynchronous RCAs of similar size. All the asynchronous full adders and
RCAs were realized using standard cells in a semi-custom design fashion based
on a 32/28 nm CMOS process technology.
"
592,CLAASIC: a Cortex-Inspired Hardware Accelerator,"  This work explores the feasibility of specialized hardware implementing the
Cortical Learning Algorithm (CLA) in order to fully exploit its inherent
advantages. This algorithm, which is inspired in the current understanding of
the mammalian neo-cortex, is the basis of the Hierarchical Temporal Memory
(HTM). In contrast to other machine learning (ML) approaches, the structure is
not application dependent and relies on fully unsupervised continuous learning.
We hypothesize that a hardware implementation will be able not only to extend
the already practical uses of these ideas to broader scenarios but also to
exploit the hardware-friendly CLA characteristics. The architecture proposed
will enable an unfeasible scalability for software solutions and will fully
capitalize on one of the many CLA advantages: low computational requirements
and reduced storage utilization. Compared to a state-of-the-art CLA software
implementation it could be possible to improve by 4 orders of magnitude in
performance and up to 8 orders of magnitude in energy efficiency. We propose to
use a packet-switched network to tackle this. The paper addresses the
fundamental issues of such an approach, proposing solutions to achieve scalable
solutions. We will analyze cost and performance when using well-known
architecture techniques and tools. The results obtained suggest that even with
CMOS technology, under constrained cost, it might be possible to implement a
large-scale system. We found that the proposed solutions enable a saving of 90%
of the original communication costs running either synthetic or realistic
workloads.
"
593,Reducing DRAM Latency at Low Cost by Exploiting Heterogeneity,"  In modern systems, DRAM-based main memory is significantly slower than the
processor. Consequently, processors spend a long time waiting to access data
from main memory, making the long main memory access latency one of the most
critical bottlenecks to achieving high system performance. Unfortunately, the
latency of DRAM has remained almost constant in the past decade. This is mainly
because DRAM has been optimized for cost-per-bit, rather than access latency.
As a result, DRAM latency is not reducing with technology scaling, and
continues to be an important performance bottleneck in modern and future
systems.
  This dissertation seeks to achieve low latency DRAM-based memory systems at
low cost in three major directions. First, based on the observation that long
bitlines in DRAM are one of the dominant sources of DRAM latency, we propose a
new DRAM architecture, Tiered-Latency DRAM (TL-DRAM), which divides the long
bitline into two shorter segments using an isolation transistor, allowing one
segment to be accessed with reduced latency. Second, we propose a fine-grained
DRAM latency reduction mechanism, Adaptive-Latency DRAM, which optimizes DRAM
latency for the common operating conditions for individual DRAM module. Third,
we propose a new technique, Architectural-Variation-Aware DRAM (AVA-DRAM),
which reduces DRAM latency at low cost, by profiling and identifying only the
inherently slower regions in DRAM to dynamically determine the lowest latency
DRAM can operate at without causing failures.
  This dissertation provides a detailed analysis of DRAM latency by using both
circuit-level simulation with a detailed DRAM model and FPGA-based profiling of
real DRAM modules. Our latency analysis shows that our low latency DRAM
mechanisms enable significant latency reductions, leading to large improvement
in both system performance and energy efficiency.
"
594,"Architectural Impact on Performance of In-memory Data Analytics: Apache
  Spark Case Study","  While cluster computing frameworks are continuously evolving to provide
real-time data analysis capabilities, Apache Spark has managed to be at the
forefront of big data analytics for being a unified framework for both, batch
and stream data processing. However, recent studies on micro-architectural
characterization of in-memory data analytics are limited to only batch
processing workloads. We compare micro-architectural performance of batch
processing and stream processing workloads in Apache Spark using hardware
performance counters on a dual socket server. In our evaluation experiments, we
have found that batch processing are stream processing workloads have similar
micro-architectural characteristics and are bounded by the latency of frequent
data access to DRAM. For data accesses we have found that simultaneous
multi-threading is effective in hiding the data latencies. We have also
observed that (i) data locality on NUMA nodes can improve the performance by
10% on average and(ii) disabling next-line L1-D prefetchers can reduce the
execution time by up-to 14\% and (iii) multiple small executors can provide
up-to 36\% speedup over single large executor.
"
595,"A Linearization Technique for Self-Interference Cancellation in
  Full-Duplex Radios","  The fundamental problem in the design of a full-duplex radio is the
cancellation of the self-interference (SI) signal generated by the
transmitter.Current techniques for suppressing SI rely on generating a copy of
the SI signal and subtracting it partly in the RF (radio frequency) and digital
domains. A critical step in replicating the self-interference is the estimation
of the multi-path channel through which the transmitted signal propagates to
the antenna. Since there is no prior model on the number of multipath
reflections, current techniques assume a tap delay line filter (in the RF and
digital domain) with a large number of taps, and estimate the taps in the
analog and the digital domain. Assuming such a model leads to a large
form-factor for the analog and RF circuits and increased complexity in the
digital domain.
  In this paper, using a linearization technique, we show that the
self-interference channel in an indoor environment can be effectively modelled
as $H(f)=C_0 + C_1f$ in the frequency domain. Thus, the effective
self-interference channel can be represented by two parameters $C_0$ and $C_1$,
irrespective of the multipath environment. We also provide experimental
evidence to verify the above channel model and propose novel low-complexity
designs for self-interference cancellation. Linearization not only aids in the
practicality of analog cancellation by reducing the form factor, but also
results in a simpler SI filter model in the digital domain due to
dimensionality reduction of the channel parameters. Therefore this method can
enable the widespread adoption of full-duplex techniques to portable devices in
addition to infrastructure base-stations.
"
596,"CORDIC-based Architecture for Powering Computation in Fixed-Point
  Arithmetic","  We present a fixed point architecture (source VHDL code is provided) for
powering computation. The fully customized architecture, based on the expanded
hyperbolic CORDIC algorithm, allows for design space exploration to establish
trade-offs among design parameters (numerical format, number of iterations),
execution time, resource usage and accuracy. We also generate Pareto-optimal
realizations in the resource-accuracy space: this approach can produce optimal
hardware realizations that simultaneously satisfy resource and accuracy
requirements.
"
597,"An Asynchronous Early Output Full Adder and a Relative-Timed Ripple
  Carry Adder","  This article presents the design of a new asynchronous early output full
adder which when cascaded leads to a relative-timed ripple carry adder (RCA).
The relative-timed RCA requires imposing a very small relative-timing
assumption to overcome the problem of gate orphans associated with internal
carry propagation. The relative-timing assumption is however independent of the
RCA size. The primary benefits of the relative-timed RCA are processing of
valid data incurs data-dependent forward latency, while the processing of
spacer involves a very fast constant time reverse latency of just 1 full adder
delay which represents the ultimate in the design of an asynchronous RCA with
the fastest reset. The secondary benefits of the relative-timed RCA are it
achieves good optimization of power and area metrics simultaneously. A 32-bit
relative-timed RCA constructed using the proposed early output full adder
achieves respective reductions in forward latency by 67%, 10% and 3.5% compared
to the optimized strong-indication, weak-indication, and early output 32-bit
asynchronous RCAs existing in the literature. Based on a similar comparison,
the proposed 32-bit relative-timed RCA achieves corresponding reductions in
cycle time by 83%, 12.7% and 6.4%. In terms of area, the proposed 32-bit
relative-timed RCA occupies 27% less Silicon than its optimized
strong-indication counterpart and 17% less Silicon than its optimized
weak-indication counterpart, and features increased area occupancy by a meager
1% compared to the optimized early output 32-bit asynchronous RCA. The average
power dissipation of all the asynchronous 32-bit RCAs are found to be
comparable since they all satisfy the monotonic cover constraint. The
simulation results obtained correspond to a 32/28nm CMOS process.
"
598,A Fault Tolerance Improved Majority Voter for TMR System Architectures,"  For digital system designs, triple modular redundancy (TMR), which is a
3-tuple version of N-modular redundancy is widely preferred for many
mission-control and safety-critical applications. The TMR scheme involves
two-times duplication of the simplex system hardware, with a majority voter
ensuring correctness provided at least two out of three copies of the system
remain operational. Thus the majority voter plays a pivotal role in ensuring
the correct operation of the system. The fundamental assumption implicit in the
TMR scheme is that the majority voter does not become faulty, which may not
hold well for implementations based on latest technology nodes with dimensions
of the order of just tens of nanometers. To overcome the drawbacks of the
classical majority voter some new voter designs were put forward in the
literature with the aim of enhancing the fault tolerance. However, these voter
designs generally ensure the correct system operation in the presence of either
a faulty function module or the faulty voter, considered only in isolation.
Since multiple faults may no longer be excluded in the nanoelectronics regime,
simultaneous fault occurrences on both the function module and the voter should
be considered, and the fault tolerance of the voters have to be analyzed under
such a scenario. In this context, this article proposes a new fault-tolerant
majority voter which is found to be more robust to faults than the existing
voters in the presence of faults occurring internally and/or externally to the
voter. Moreover, the proposed voter features less power dissipation, delay, and
area metrics based on the simulation results obtained by using a 32/28nm CMOS
process.
"
599,"A Foray into Efficient Mapping of Algorithms to Hardware Platforms on
  Heterogeneous Systems","  Heterogeneous computing can potentially offer significant performance and
performance per watt improvements over homogeneous computing, but the question
""what is the ideal mapping of algorithms to architectures?"" remains an open
one. In the past couple of years new types of computing devices such as FPGAs
have come into general computing use. In this work we attempt to add to the
body of scientific knowledge by comparing Kernel performance and performance
per watt of seven key algorithms according to Berkley's dwarf taxonomy. We do
so using the Rodinia benchmark suite on three different high-end hardware
architecture representatives from the CPU, GPU and FPGA families. We find
results that support some distinct mappings between the architecture and
performance per watt. Perhaps the most interesting finding is that, for our
specific hardware representatives, FPGAs should be considered as alternatives
to GPUs and CPUs in several key algorithms: N-body simulations, dense linear
algebra and structured grid.
"
600,"Simple DRAM and Virtual Memory Abstractions to Enable Highly Efficient
  Memory Systems","  In most modern systems, the memory subsystem is managed and accessed at
multiple different granularities at various resources. We observe that such
multi-granularity management results in significant inefficiency in the memory
subsystem. Specifically, we observe that 1) page-granularity virtual memory
unnecessarily triggers large memory operations, and 2) existing cache-line
granularity memory interface is inefficient for performing bulk data operations
and operations that exhibit poor spatial locality. To address these problems,
we present a series of techniques in this thesis.
  First, we propose page overlays, a framework augments the existing virtual
memory framework with the ability to track a new version of a subset of cache
lines within each virtual page. We show that this extension is powerful by
demonstrating its benefits on a number of applications.
  Second, we show that DRAM can be used to perform more complex operations than
just store data. We propose RowClone, a mechanism to perform bulk data copy and
initialization completely inside DRAM, and Buddy RAM, a mechanism to perform
bulk bitwise operations using DRAM. Both these techniques achieve an
order-of-magnitude improvement in the efficiency of the respective operations.
  Third, we propose Gather-Scatter DRAM, a technique that exploits DRAM
organization to effectively gather/scatter values with a power-of-2 strided
access patterns. For these access patterns, GS-DRAM achieves near-ideal
bandwidth and cache utilization, without increasing the latency of fetching
data from memory.
  Finally, we propose the Dirty-Block Index, a new way of tracking dirty
blocks. In addition to improving the efficiency of bulk data coherence, DBI has
several applications including high-performance memory scheduling, efficient
cache lookup bypassing, and enabling heterogeneous ECC.
"
601,"Proceedings of the 2nd International Workshop on Overlay Architectures
  for FPGAs (OLAF 2016)","  The 2nd International Workshop on Overlay Architectures for FPGAs (OLAF 2016)
was held on 21 Mar, 2016 as a co-located workshop at the 24th ACM/SIGDA
International Symposium on Field-Programmable Gate Arrays (FPGA 2016). This
year, the program committee selected 6 papers and 3 extended abstracts to be
presented at the workshop, which are subsequently collected in this online
volume.
"
602,Profile-Driven Automated Mixed Precision,"  We present a scheme to automatically set the precision of floating point
variables in an application. We design a framework that profiles applications
to measure undesirable numerical behavior at the floating point operation
level. We use this framework to perform mixed precision analysis to
heuristically set the precision of all variables in an application based on
their numerical profiles. We experimentally evaluate the mixed precision
analysis to show that it can generate a range of results with different
accuracy and performance characteristics.
"
603,GRVI Phalanx: A Massively Parallel RISC-V FPGA Accelerator Accelerator,"  GRVI is an FPGA-efficient RISC-V RV32I soft processor. Phalanx is a parallel
processor and accelerator array framework. Groups of processors and
accelerators form shared memory clusters. Clusters are interconnected with each
other and with extreme bandwidth I/O and memory devices by a 300- bit-wide
Hoplite NOC. An example Kintex UltraScale KU040 system has 400 RISC-V cores,
peak throughput of 100,000 MIPS, peak shared memory bandwidth of 600 GB/s, NOC
bisection bandwidth of 700 Gbps, and uses 13 W.
"
604,CG-OoO: Energy-Efficient Coarse-Grain Out-of-Order Execution,"  We introduce the Coarse-Grain Out-of-Order (CG- OoO) general purpose
processor designed to achieve close to In-Order processor energy while
maintaining Out-of-Order (OoO) performance. CG-OoO is an energy-performance
proportional general purpose architecture that scales according to the program
load. Block-level code processing is at the heart of the this architecture;
CG-OoO speculates, fetches, schedules, and commits code at block-level
granularity. It eliminates unnecessary accesses to energy consuming tables, and
turns large tables into smaller and distributed tables that are cheaper to
access. CG-OoO leverages compiler-level code optimizations to deliver efficient
static code, and exploits dynamic instruction-level parallelism and block-level
parallelism. CG-OoO introduces Skipahead issue, a complexity effective, limited
out-of-order instruction scheduling model. Through the energy efficiency
techniques applied to the compiler and processor pipeline stages, CG-OoO closes
64% of the average energy gap between the In-Order and Out-of-Order baseline
processors at the performance of the OoO baseline. This makes CG-OoO 1.9x more
efficient than the OoO on the energy-delay product inverse metric.
"
605,Open-source Hardware: Opportunities and Challenges,"  Innovation in hardware is slowing due to rising costs of chip design and
diminishing benefits from Moore's law and Dennard scaling. Software innovation,
on the other hand, is flourishing, helped in good measure by a thriving
open-source ecosystem. We believe that open source can similarly help hardware
innovation, but has not yet due to several reasons. We identify these reasons
and how the industry, academia, and the hardware community at large can come
together to address them.
"
606,"MAC: a novel systematically multilevel cache replacement policy for PCM
  memory","  The rapid development of multi-core system and increase of data-intensive
application in recent years call for larger main memory. Traditional DRAM
memory can increase its capacity by reducing the feature size of storage cell.
Now further scaling of DRAM faces great challenge, and the frequent refresh
operations of DRAM can bring a lot of energy consumption. As an emerging
technology, Phase Change Memory (PCM) is promising to be used as main memory.
It draws wide attention due to the advantages of low power consumption, high
density and nonvolatility, while it incurs finite endurance and relatively long
write latency. To handle the problem of write, optimizing the cache replacement
policy to protect dirty cache block is an efficient way. In this paper, we
construct a systematically multilevel structure, and based on it propose a
novel cache replacement policy called MAC. MAC can effectively reduce write
traffic to PCM memory with low hardware overhead. We conduct simulation
experiments on GEM5 to evaluate the performances of MAC and other related
works. The results show that MAC performs best in reducing the amount of writes
(averagely 25.12%) without increasing the program execution time.
"
607,Automated Space/Time Scaling of Streaming Task Graph,"  In this paper, we describe a high-level synthesis (HLS) tool that
automatically allows area/throughput trade-offs for implementing streaming task
graphs (STG). Our tool targets a massively parallel processor array (MPPA)
architecture, very similar to the Ambric MPPA chip architecture, which is to be
implemented as an FPGA overlay. Similar to Ambric tools, our HLS tool accepts a
STG as input written in a subset of Java and a structural language in the style
of a Kahn Processing Network (KPN). Unlike the Ambric tools, our HLS tool
analyzes the parallelism internal to each Java ""node"" and evaluates the
throughput and area of several possible implementations. It then analyzes the
full graph for bottlenecks or excess compute capacity, selects an
implementation for each node, and even considers replicating or splitting nodes
while either minimizing area (for a fixed throughput target), or maximizing
throughput (for a fixed area target). In addition to traditional node selection
and replication methods used in prior work, we have uniquely implemented node
combining and splitting to find a better area/throughput trade-off. We present
two optimization approaches, a formal ILP formulation and a heuristic solution.
Results show that the heuristic is more flexible and can find design points not
available to the ILP, thereby achieving superior results.
"
608,Application-Driven Near-Data Processing for Similarity Search,"  Similarity search is a key to a variety of applications including
content-based search for images and video, recommendation systems, data
deduplication, natural language processing, computer vision, databases,
computational biology, and computer graphics. At its core, similarity search
manifests as k-nearest neighbors (kNN), a computationally simple primitive
consisting of highly parallel distance calculations and a global top-k sort.
However, kNN is poorly supported by today's architectures because of its high
memory bandwidth requirements.
  This paper proposes an application-driven near-data processing accelerator
for similarity search: the Similarity Search Associative Memory (SSAM). By
instantiating compute units close to memory, SSAM benefits from the higher
memory bandwidth and density exposed by emerging memory technologies. We
evaluate the SSAM design down to layout on top of the Micron hybrid memory cube
(HMC), and show that SSAM can achieve up to two orders of magnitude
area-normalized throughput and energy efficiency improvement over multicore
CPUs; we also show SSAM is faster and more energy efficient than competing GPUs
and FPGAs. Finally, we show that SSAM is also useful for other data intensive
tasks like kNN index construction, and can be generalized to semantically
function as a high capacity content addressable memory.
"
609,ENTRA: Whole-Systems Energy Transparency,"  Promoting energy efficiency to a first class system design goal is an
important research challenge. Although more energy-efficient hardware can be
designed, it is software that controls the hardware; for a given system the
potential for energy savings is likely to be much greater at the higher levels
of abstraction in the system stack. Thus the greatest savings are expected from
energy-aware software development, which is the vision of the EU ENTRA project.
This article presents the concept of energy transparency as a foundation for
energy-aware software development. We show how energy modelling of hardware is
combined with static analysis to allow the programmer to understand the energy
consumption of a program without executing it, thus enabling exploration of the
design space taking energy into consideration. The paper concludes by
summarising the current and future challenges identified in the ENTRA project.
"
610,"High Throughput Neural Network based Embedded Streaming Multicore
  Processors","  With power consumption becoming a critical processor design issue,
specialized architectures for low power processing are becoming popular.
Several studies have shown that neural networks can be used for signal
processing and pattern recognition applications. This study examines the design
of memristor based multicore neural processors that would be used primarily to
process data directly from sensors. Additionally, we have examined the design
of SRAM based neural processors for the same task. Full system evaluation of
the multicore processors based on these specialized cores were performed taking
I/O and routing circuits into consideration. The area and power benefits were
compared with traditional multicore RISC processors. Our results show that the
memristor based architectures can provide an energy efficiency between three
and five orders of magnitude greater than that of RISC processors for the
benchmarks examined.
"
611,"A 0.3-2.6 TOPS/W Precision-Scalable Processor for Real-Time Large-Scale
  ConvNets","  A low-power precision-scalable processor for ConvNets or convolutional neural
networks (CNN) is implemented in a 40nm technology. Its 256 parallel processing
units achieve a peak 102GOPS running at 204MHz. To minimize energy consumption
while maintaining throughput, this works is the first to both exploit the
sparsity of convolutions and to implement dynamic precision-scalability
enabling supply- and energy scaling. The processor is fully C-programmable,
consumes 25-288mW at 204 MHz and scales efficiency from 0.3-2.6 real TOPS/W.
This system hereby outperforms the state-of-the-art up to 3.9x in energy
efficiency.
"
612,Taming Weak Memory Models,"  Speculative techniques in microarchitectures relax various dependencies in
programs, which contributes to the complexity of (weak) memory models. We show
using WMM, a new weak memory model, that the model becomes simpler if it
includes load-value speculation and thus, does not enforce any dependency!
However, in the absence of good value-prediction techniques, a programmer may
end up paying a price for the extra fences. Thus, we also present WMM-D, which
enforces the dependencies captured by the current microarchitectures. WMM-D is
still much simpler than other existing models. We also show that non-atomic
multi-copy stores arise as a result of sharing write-through caches. We think
restricting microarchitectures to write-back caches (and thus simpler weak
memory models) will not incur any performance penalty. Nevertheless, we present
WMM-S, another extension to WMM, which could model the effects of non-atomic
multi-copy stores. WMM, WMM-D, and WMM-S are all defined using Instantaneous
Instruction Execution (I^2E), a new way of describing memory models without
explicit reordering or speculative execution.
"
613,"YodaNN: An Architecture for Ultra-Low Power Binary-Weight CNN
  Acceleration","  Convolutional neural networks (CNNs) have revolutionized the world of
computer vision over the last few years, pushing image classification beyond
human accuracy. The computational effort of today's CNNs requires power-hungry
parallel processors or GP-GPUs. Recent developments in CNN accelerators for
system-on-chip integration have reduced energy consumption significantly.
Unfortunately, even these highly optimized devices are above the power envelope
imposed by mobile and deeply embedded applications and face hard limitations
caused by CNN weight I/O and storage. This prevents the adoption of CNNs in
future ultra-low power Internet of Things end-nodes for near-sensor analytics.
Recent algorithmic and theoretical advancements enable competitive
classification accuracy even when limiting CNNs to binary (+1/-1) weights
during training. These new findings bring major optimization opportunities in
the arithmetic core by removing the need for expensive multiplications, as well
as reducing I/O bandwidth and storage. In this work, we present an accelerator
optimized for binary-weight CNNs that achieves 1510 GOp/s at 1.2 V on a core
area of only 1.33 MGE (Million Gate Equivalent) or 0.19 mm$^2$ and with a power
dissipation of 895 {\mu}W in UMC 65 nm technology at 0.6 V. Our accelerator
significantly outperforms the state-of-the-art in terms of energy and area
efficiency achieving 61.2 TOp/s/W@0.6 V and 1135 GOp/s/MGE@1.2 V, respectively.
"
614,An Orthogonal 16-point Approximate DCT for Image and Video Compression,"  A low-complexity orthogonal multiplierless approximation for the 16-point
discrete cosine transform (DCT) was introduced. The proposed method was
designed to possess a very low computational cost. A fast algorithm based on
matrix factorization was proposed requiring only 60~additions. The proposed
architecture outperforms classical and state-of-the-art algorithms when
assessed as a tool for image and video compression. Digital VLSI hardware
implementations were also proposed being physically realized in FPGA technology
and implemented in 45 nm up to synthesis and place-route levels. Additionally,
the proposed method was embedded into a high efficiency video coding (HEVC)
reference software for actual proof-of-concept. Obtained results show
negligible video degradation when compared to Chen DCT algorithm in HEVC.
"
615,"Design of Synchronous Section-Carry Based Carry Lookahead Adders with
  Improved Figure of Merit","  The section-carry based carry lookahead adder (SCBCLA) architecture was
proposed as an efficient alternative to the conventional carry lookahead adder
(CCLA) architecture for the physical implementation of computer arithmetic. In
previous related works, self-timed SCBCLA architectures and synchronous SCBCLA
architectures were realized using standard cells and FPGAs. In this work, we
deal with improved realizations of synchronous SCBCLA architectures designed in
a semi-custom fashion using standard cells. The improvement is quantified in
terms of a figure of merit (FOM), where the FOM is defined as the inverse
product of power, delay and area. Since power, delay and area of digital
designs are desirable to be minimized, the FOM is desirable to be maximized.
Starting from an efficient conventional carry lookahead generator, we show how
an optimized section-carry based carry lookahead generator is realized. In
comparison with our recent work dealing with standard cells based
implementation of SCBCLAs to perform 32-bit addition of two binary operands, we
show in this work that with improved section-carry based carry lookahead
generators, the resulting SCBCLAs exhibit significant improvements in FOM.
Compared to the earlier optimized hybrid SCBCLA, the proposed optimized hybrid
SCBCLA improves the FOM by 88.3%. Even the optimized hybrid CCLA features
improvement in FOM by 77.3% over the earlier optimized hybrid CCLA. However,
the proposed optimized hybrid SCBCLA is still the winner and has a better FOM
than the currently optimized hybrid CCLA by 15.3%. All the CCLAs and SCBCLAs
are implemented to realize 32-bit dual-operand binary addition using a 32/28nm
CMOS process.
"
616,Criticality Aware Multiprocessors,"  Typically, a memory request from a processor may need to go through many
intermediate interconnect routers, directory node, owner node, etc before it is
finally serviced. Current multiprocessors do not give preference to any
particular memory request. But certain memory requests are more critical to
multiprocessor's performance than other requests. Example: memory requests from
critical sections, load request feeding into multiple dependent instructions,
etc. This knowledge can be used to improve the performance of current
multiprocessors by letting the ordering point and the interconnect routers
prioritize critical requests over non-critical ones. In this paper, we evaluate
using SIMICS/GEMS infrastructure. For lock-intensive microbenchmarks,
criticality-aware multiprocessors showed 5-15% performance improvement over
baseline multiprocessor. Criticality aware multiprocessor provides a new
direction for tapping performance in a shared memory multiprocessor and can
provide substantial speedup in lock intensive benchmarks.
"
617,High Level Synthesis with a Dataflow Architectural Template,"  In this work, we present a new approach to high level synthesis (HLS), where
high level functions are first mapped to an architectural template, before
hardware synthesis is performed. As FPGA platforms are especially suitable for
implementing streaming processing pipelines, we perform transformations on
conventional high level programs where they are turned into multi-stage
dataflow engines [1]. This target template naturally overlaps slow memory data
accesses with computations and therefore has much better tolerance towards
memory subsystem latency. Using a state-of-the-art HLS tool for the actual
circuit generation, we observe up to 9x improvement in overall performance when
the dataflow architectural template is used as an intermediate compilation
target.
"
618,"Reliability-Aware Overlay Architectures for FPGAs: Features and Design
  Challenges","  The FPGA overlay architectures have been mainly proposed to improve design
productivity, circuit portability and system debugging. In this paper, we
address the use of overlay architectures for building fault tolerant SRAM-based
FPGA systems and discuss the main features and design challenges of a
reliability-aware overlay architecture.
"
619,Soft GPGPUs for Embedded FPGAs: An Architectural Evaluation,"  We present a customizable soft architecture which allows for the execution of
GPGPU code on an FPGA without the need to recompile the design. Issues related
to scaling the overlay architecture to multiple GPGPU multiprocessors are
considered along with application-class architectural optimizations. The
overlay architecture is optimized for FPGA implementation to support efficient
use of embedded block memories and DSP blocks. This architecture supports
direct CUDA compilation of integer computations to a binary which is executable
on the FPGA-based GPGPU. The benefits of our architecture are evaluated for a
collection of five standard CUDA benchmarks which are compiled using standard
GPGPU compilation tools. Speedups of 44x, on average, versus a MicroBlaze
microprocessor are achieved. We show dynamic energy savings versus a soft-core
processor of 80% on average. Application-customized versions of the soft GPGPU
can be used to further reduce dynamic energy consumption by an average of 14%.
"
620,"Enabling Effective FPGA Debug using Overlays: Opportunities and
  Challenges","  FPGAs are going mainstream. Major companies that were not traditionally
FPGA-focused are now seeking ways to exploit the benefits of reconfigurable
technology and provide it to their customers. In order to do so, a debug
ecosystem that provides for effective visibility into a working design and
quick debug turn-around times is essential. Overlays have the opportunity to
play a key role in this ecosystem. In this overview paper, we discuss how an
overlay fabric that allows the user to rapidly add debug instrumentation to a
design can be created and exploited. We discuss the requirements of such an
overlay and some of the research challenges and opportunities that need to be
addressed. To make our exposition concrete, we use two previously-published
examples of overlays that have been developed to implement debug
instrumentation.
"
621,"An Area-Efficient FPGA Overlay using DSP Block based Time-multiplexed
  Functional Units","  Coarse grained overlay architectures improve FPGA design productivity by
providing fast compilation and software-like programmability. Throughput
oriented spatially configurable overlays typically suffer from area overheads
due to the requirement of one functional unit for each compute kernel
operation. Hence, these overlays have often been of limited size, supporting
only relatively small compute kernels while consuming considerable FPGA
resources. This paper examines the possibility of sharing the functional units
among kernel operations for reducing area overheads. We propose a linear
interconnected array of time-multiplexed FUs as an overlay architecture with
reduced instruction storage and interconnect resource requirements, which uses
a fully-pipelined, architecture-aware FU design supporting a fast context
switching time. The results presented show a reduction of up to 85% in FPGA
resource requirements compared to existing throughput oriented overlay
architectures, with an operating frequency which approaches the theoretical
limit for the FPGA device.
"
622,A Soft Processor Overlay with Tightly-coupled FPGA Accelerator,"  FPGA overlays are commonly implemented as coarse-grained reconfigurable
architectures with a goal to improve designers' productivity through balancing
flexibility and ease of configuration of the underlying fabric. To truly
facilitate full application acceleration, it is often necessary to also include
a highly efficient processor that integrates and collaborates with the
accelerators while maintaining the benefits of being implemented within the
same overlay framework. This paper presents an open-source soft processor that
is designed to tightly-couple with FPGA accelerators as part of an overlay
framework. RISC-V is chosen as the instruction set for its openness and
portability, and the soft processor is designed as a 4-stage pipeline to
balance resource consumption and performance when implemented on FPGAs. The
processor is generically implemented so as to promote design portability and
compatibility across different FPGA platforms. Experimental results show that
integrated software-hardware applications using the proposed tightly-coupled
architecture achieve comparable performance as hardware-only accelerators while
the proposed architecture provides additional run-time flexibility. The
processor has been synthesized to both low-end and high-performance FPGA
families from different vendors, achieving the highest frequency of 268.67MHz
and resource consumption comparable to existing RISC-V designs.
"
623,"FPMax: a 106GFLOPS/W at 217GFLOPS/mm2 Single-Precision FPU, and a
  43.7GFLOPS/W at 74.6GFLOPS/mm2 Double-Precision FPU, in 28nm UTBB FDSOI","  FPMax implements four FPUs optimized for latency or throughput workloads in
two precisions, fabricated in 28nm UTBB FDSOI. Each unit's parameters, e.g
pipeline stages, booth encoding etc., were optimized to yield 1.42ns latency at
110GLOPS/W (SP) and 1.39ns latency at 36GFLOPS/W (DP). At 100% activity,
body-bias control improves the energy efficiency by about 20%; at 10% activity
this saving is almost 2x.
  Keywords: FPU, energy efficiency, hardware generator, SOI
"
624,"A Benes Based NoC Switching Architecture for Mixed Criticality Embedded
  Systems","  Multi-core, Mixed Criticality Embedded (MCE) real-time systems require high
timing precision and predictability to guarantee there will be no interference
between tasks. These guarantees are necessary in application areas such as
avionics and automotive, where task interference or missed deadlines could be
catastrophic, and safety requirements are strict. In modern multi-core systems,
the interconnect becomes a potential point of uncertainty, introducing major
challenges in proving behaviour is always within specified constraints,
limiting the means of growing system performance to add more tasks, or provide
more computational resources to existing tasks.
  We present MCENoC, a Network-on-Chip (NoC) switching architecture that
provides innovations to overcome this with predictable, formally verifiable
timing behaviour that is consistent across the whole NoC. We show how the
fundamental properties of Benes networks benefit MCE applications and meet our
architecture requirements. Using SystemVerilog Assertions (SVA), formal
properties are defined that aid the refinement of the specification of the
design as well as enabling the implementation to be exhaustively formally
verified. We demonstrate the performance of the design in terms of size,
throughput and predictability, and discuss the application level considerations
needed to exploit this architecture.
"
625,Maximizing CNN Accelerator Efficiency Through Resource Partitioning,"  Convolutional neural networks (CNNs) are revolutionizing machine learning,
but they present significant computational challenges. Recently, many
FPGA-based accelerators have been proposed to improve the performance and
efficiency of CNNs. Current approaches construct a single processor that
computes the CNN layers one at a time; the processor is optimized to maximize
the throughput at which the collection of layers is computed. However, this
approach leads to inefficient designs because the same processor structure is
used to compute CNN layers of radically varying dimensions.
  We present a new CNN accelerator paradigm and an accompanying automated
design methodology that partitions the available FPGA resources into multiple
processors, each of which is tailored for a different subset of the CNN
convolutional layers. Using the same FPGA resources as a single large
processor, multiple smaller specialized processors increase computational
efficiency and lead to a higher overall throughput. Our design methodology
achieves 3.8x higher throughput than the state-of-the-art approach on
evaluating the popular AlexNet CNN on a Xilinx Virtex-7 FPGA. For the more
recent SqueezeNet and GoogLeNet, the speedups are 2.2x and 2.0x.
"
626,"Reducing the Energy Cost of Inference via In-sensor Information
  Processing","  There is much interest in incorporating inference capabilities into
sensor-rich embedded platforms such as autonomous vehicles, wearables, and
others. A central problem in the design of such systems is the need to extract
information locally from sensed data on a severely limited energy budget. This
necessitates the design of energy-efficient sensory embedded system. A typical
sensory embedded system enforces a physical separation between sensing and
computational subsystems - a separation mandated by the differing requirements
of the sensing and computational functions. As a consequence, the energy
consumption in such systems tends to be dominated by the energy consumed in
transferring data over the sensor-processor interface (communication energy)
and the energy consumed in processing the data in digital processor
(computational energy). In this article, we propose an in-sensor computing
architecture which (mostly) eliminates the sensor-processor interface by
embedding inference computations in the noisy sensor fabric in analog and
retraining the hyperparameters in order to compensate for non-ideal
computations. The resulting architecture referred to as the Compute Sensor - a
sensor that computes in addition to sensing - represents a radical departure
from the conventional. We show that a Compute Sensor for image data can be
designed by embedding both feature extraction and classification functions in
the analog domain in close proximity to the CMOS active pixel sensor (APS)
array. Significant gains in energy-efficiency are demonstrated using behavioral
and energy models in a commercial semiconductor process technology. In the
process, the Compute Sensor creates a unique opportunity to develop machine
learning algorithms for information extraction from data on a noisy underlying
computational fabric.
"
627,"A configurable accelerator for manycores: the Explicitly Many-Processor
  Approach","  A new approach to designing processor accelerators is presented. A new
computing model and a special kind of accelerator with dynamic (end-user
programmable) architecture is suggested. The new model considers a processor,
in which a newly introduced supervisor layer coordinates the job of the cores.
The cores have the ability (based on the parallelization information provided
by the compiler, and using the help of the supervisor) to outsource part of the
job they received to some neighbouring core. The introduced changes essentially
and advantageously modify the architecture and operation of the computing
systems. The computing throughput drastically increases, the efficiency of the
technological implementation (computing performance per logic gates) increases,
the non-payload activity for using operating system services decreases, the
real-time behavior changes advantageously, and connecting accelerators to the
processor greatly simplifies. Here only some details of the architecture and
operation of the processor are discussed, the rest is described elsewhere.
"
628,"The Renewed Case for the Reduced Instruction Set Computer: Avoiding ISA
  Bloat with Macro-Op Fusion for RISC-V","  This report makes the case that a well-designed Reduced Instruction Set
Computer (RISC) can match, and even exceed, the performance and code density of
existing commercial Complex Instruction Set Computers (CISC) while maintaining
the simplicity and cost-effectiveness that underpins the original RISC goals.
  We begin by comparing the dynamic instruction counts and dynamic instruction
bytes fetched for the popular proprietary ARMv7, ARMv8, IA-32, and x86-64
Instruction Set Architectures (ISAs) against the free and open RISC-V RV64G and
RV64GC ISAs when running the SPEC CINT2006 benchmark suite. RISC-V was designed
as a very small ISA to support a wide range of implementations, and has a less
mature compiler toolchain. However, we observe that on SPEC CINT2006 RV64G
executes on average 16% more instructions than x86-64, 3% more instructions
than IA-32, 9% more instructions than ARMv8, but 4% fewer instructions than
ARMv7.
  CISC x86 implementations break up complex instructions into smaller internal
RISC-like micro-ops, and the RV64G instruction count is within 2% of the x86-64
retired micro-op count. RV64GC, the compressed variant of RV64G, is the densest
ISA studied, fetching 8% fewer dynamic instruction bytes than x86-64. We
observed that much of the increased RISC-V instruction count is due to a small
set of common multi-instruction idioms.
  Exploiting this fact, the RV64G and RV64GC effective instruction count can be
reduced by 5.4% on average by leveraging macro-op fusion. Combining the
compressed RISC-V ISA extension with macro-op fusion provides both the densest
ISA and the fewest dynamic operations retired per program, reducing the
motivation to add more instructions to the ISA. This approach retains a single
simple ISA suitable for both low-end and high-end implementations, where
high-end implementations can boost performance through microarchitectural
techniques.
"
629,Scratchpad Sharing in GPUs,"  GPGPU applications exploit on-chip scratchpad memory available in the
Graphics Processing Units (GPUs) to improve performance. The amount of thread
level parallelism present in the GPU is limited by the number of resident
threads, which in turn depends on the availability of scratchpad memory in its
streaming multiprocessor (SM). Since the scratchpad memory is allocated at
thread block granularity, part of the memory may remain unutilized. In this
paper, we propose architectural and compiler optimizations to improve the
scratchpad utilization. Our approach, Scratchpad Sharing, addresses scratchpad
under-utilization by launching additional thread blocks in each SM. These
thread blocks use unutilized scratchpad and also share scratchpad with other
resident blocks. To improve the performance of scratchpad sharing, we propose
Owner Warp First (OWF) scheduling that schedules warps from the additional
thread blocks effectively. The performance of this approach, however, is
limited by the availability of the shared part of scratchpad.
  We propose compiler optimizations to improve the availability of shared
scratchpad. We describe a scratchpad allocation scheme that helps in allocating
scratchpad variables such that shared scratchpad is accessed for short
duration. We introduce a new instruction, relssp, that when executed, releases
the shared scratchpad. Finally, we describe an analysis for optimal placement
of relssp instructions such that shared scratchpad is released as early as
possible.
  We implemented the hardware changes using the GPGPU-Sim simulator and
implemented the compiler optimizations in Ocelot framework. We evaluated the
effectiveness of our approach on 19 kernels from 3 benchmarks suites: CUDA-SDK,
GPGPU-Sim, and Rodinia. The kernels that underutilize scratchpad memory show an
average improvement of 19% and maximum improvement of 92.17% compared to the
baseline approach.
"
630,DiaSys: Improving SoC Insight Through On-Chip Diagnosis,"  To find the cause of a functional or non-functional defect (bug) in software
running on a multi-processor System-on-Chip (MPSoC), developers need insight
into the chip. Tracing systems provide this insight non-intrusively, at the
cost of high off-chip bandwidth requirements. This I/O bottleneck limits the
observability, a problem becoming more severe as more functionality is
integrated on-chip. In this paper, we present DiaSys, an MPSoC diagnosis system
with the potential to replace today's tracing systems. Its main idea is to
partially execute the analysis of observation data on the chip; in consequence,
more information and less data is sent to the attached host PC. With DiaSys,
the data analysis is performed by the diagnosis application. Its input are
events, which are generated by observation hardware at interesting points in
the program execution (like a function call). Its outputs are events with
higher information density. The event transformation is modeled as dataflow
application. For execution, it is mapped in part to dedicated and distributed
on-chip components, and in part to the host PC; the off-chip boundary is
transparent to the developer of the diagnosis application. We implement DiaSys
as extension to an existing SoC with four tiles and a mesh network running on
an FPGA platform. Two usage examples confirm that DiaSys is flexible enough to
replace a tracing system, while significantly lowering the off-chip bandwidth
requirements. In our examples, the debugging of a race-condition bug, and the
creation of a lock contention profile, we see a reduction of trace bandwidth of
more than three orders of magnitude, compared to a full trace created by a
common tracing system.
"
631,"Novel Graph Processor Architecture, Prototype System, and Results","  Graph algorithms are increasingly used in applications that exploit large
databases. However, conventional processor architectures are inadequate for
handling the throughput and memory requirements of graph computation. Lincoln
Laboratory's graph-processor architecture represents a rethinking of parallel
architectures for graph problems. Our processor utilizes innovations that
include a sparse matrix-based graph instruction set, a cacheless memory system,
accelerator-based architecture, a systolic sorter, high-bandwidth
multi-dimensional toroidal communication network, and randomized
communications. A field-programmable gate array (FPGA) prototype of the new
graph processor has been developed with significant performance enhancement
over conventional processors in graph computational throughput.
"
632,Uber: Utilizing Buffers to Simplify NoCs for Hundreds-Cores,"  Approaching ideal wire latency using a network-on-chip (NoC) is an important
practical problem for many-core systems, particularly hundreds-cores. Although
other researchers have focused on optimizing large meshes, bypassing or
speculating router pipelines, or creating more intricate logarithmic
topologies, this paper proposes a balanced combination that trades queue
buffers for simplicity. Preliminary analysis of nine benchmarks from PARSEC and
SPLASH using execution-driven simulation shows that utilization rises from 2%
when connecting a single core per mesh port to at least 50%, as slack for delay
in concentrator and router queues is around 6x higher compared to the ideal
latency of just 20 cycles. That is, a 16-port mesh suffices because queueing is
the uncommon case for system performance. In this way, the mesh hop count is
bounded to three, as load becomes uniform via extended concentration, and ideal
latency is approached using conventional four-stage pipelines for the mesh
routers together with minor logarithmic edges. A realistic Uber is also
detailed, featuring the same performance as a 64-port mesh that employs
optimized router pipelines, improving the baseline by 12%. Ongoing work
develops techniques to better balance load by tuning the placement of cache
blocks, and compares Uber with bufferless routing.
"
633,"Read-Tuned STT-RAM and eDRAM Cache Hierarchies for Throughput and Energy
  Enhancement","  As capacity and complexity of on-chip cache memory hierarchy increases, the
service cost to the critical loads from Last Level Cache (LLC), which are
frequently repeated, has become a major concern. The processor may stall for a
considerable interval while waiting to access the data stored in the cache
blocks in LLC, if there are no independent instructions to execute. To provide
accelerated service to the critical loads requests from LLC, this work
concentrates on leveraging the additional capacity offered by replacing
SRAM-based L2 with Spin-Transfer Torque Random Access Memory (STT-RAM) to
accommodate frequently accessed cache blocks in exclusive read mode in favor of
reducing the overall read service time. Our proposed technique partitions L2
cache into two STT-RAM arrangements with different write performance and data
retention time. The retention-relaxed STT-RAM arrays are utilized to
effectively deal with the regular L2 cache requests while the high retention
STT-RAM arrays in L2 are selected for maintaining repeatedly read accessed
cache blocks from LLC by incurring negligible energy consumption for data
retention. Our experimental results show that the proposed technique can reduce
the mean L2 read miss ratio by 51.4% and increase the IPC by 11.7% on average
across PARSEC benchmark suite while significantly decreasing the total L2
energy consumption compared to conventional SRAM-based L2 design.
"
634,The Study of Transient Faults Propagation in Multithread Applications,"  Whereas contemporary Error Correcting Codes (ECC) designs occupy a
significant fraction of total die area in chip-multiprocessors (CMPs),
approaches to deal with the vulnerability increase of CMP architecture against
Single Event Upsets (SEUs) and Multi-Bit Upsets (MBUs) are sought. In this
paper, we focus on reliability assessment of multithreaded applications running
on CMPs to propose an adaptive application-relevant architecture design to
accommodate the impact of both SEUs and MBUs in the entire CMP architecture.
This work concentrates on leveraging the intrinsic soft-error-immunity feature
of Spin-Transfer Torque RAM (STT-RAM) as an alternative for SRAM-based storage
and operation components. We target a specific portion of working set for
reallocation to improve the reliability level of the CMP architecture design. A
selected portion of instructions in multithreaded program which experience high
rate of referencing with the lowest memory modification are ideal candidate to
be stored and executed in STT-RAM based components. We argue about why we
cannot use STT-RAM for the global storage and operation counterparts and
describe the obtained resiliency compared to the baseline setup. In addition, a
detail study of the impact of SEUs and MBUs on multithreaded programs will be
presented in the Appendix.
"
635,"A 58.6mW Real-Time Programmable Object Detector with Multi-Scale
  Multi-Object Support Using Deformable Parts Model on 1920x1080 Video at 30fps","  This paper presents a programmable, energy-efficient and real-time object
detection accelerator using deformable parts models (DPM), with 2x higher
accuracy than traditional rigid body models. With 8 deformable parts detection,
three methods are used to address the high computational complexity:
classification pruning for 33x fewer parts classification, vector quantization
for 15x memory size reduction, and feature basis projection for 2x reduction of
the cost of each classification. The chip is implemented in 65nm CMOS
technology, and can process HD (1920x1080) images at 30fps without any off-chip
storage while consuming only 58.6mW (0.94nJ/pixel, 1168 GOPS/W). The chip has
two classification engines to simultaneously detect two different classes of
objects. With a tested high throughput of 60fps, the classification engines can
be time multiplexed to detect even more than two object classes. It is energy
scalable by changing the pruning factor or disabling the parts classification.
"
636,"Early Output Hybrid Input Encoded Asynchronous Full Adder and
  Relative-Timed Ripple Carry Adder","  This paper presents a new early output hybrid input encoded asynchronous full
adder designed using dual-rail and 1-of-4 delay-insensitive data codes. The
proposed full adder when cascaded to form a ripple carry adder (RCA)
necessitates the use of a small relative-timing assumption with respect to the
internal carries, which is independent of the RCA size. The forward latency of
the proposed hybrid input encoded full adder based RCA is data-dependent while
its reverse latency is the least equaling the propagation delay of just one
full adder. Compared to the best of the existing hybrid input encoded full
adders based 32-bit RCAs, the proposed early output hybrid input encoded full
adder based 32-bit RCA enables respective reductions in forward latency and
area by 7.9% and 5.6% whilst dissipating the same average power; in terms of
the theoretically computed cycle time, the latter reports a 10.9% reduction
compared to the former.
"
637,"FPGA Design for Pseudorandom Number Generator Based on Chaotic Iteration
  used in Information Hiding Application","  Lots of researches indicate that the inefficient generation of random numbers
is a significant bottleneck for information communication applications.
Therefore, Field Programmable Gate Array (FPGA) is developed to process a
scalable fixed-point method for random streams generation. In our previous
researches, we have proposed a technique by applying some well-defined discrete
chaotic iterations that satisfy the reputed Devaney's definition of chaos,
namely chaotic iterations (CI). We have formerly proven that the generator with
CI can provide qualified chaotic random numbers. In this paper, this generator
based on chaotic iterations is optimally redesigned for FPGA device. By doing
so, the generation rate can be largely improved. Analyses show that these
hardware generators can also provide good statistical chaotic random bits and
can be cryptographically secure too. An application in the information hiding
security field is finally given as an illustrative example.
"
638,"System Reliability, Fault Tolerance and Design Metrics Tradeoffs in the
  Distributed Minority and Majority Voting Based Redundancy Scheme","  The distributed minority and majority voting based redundancy (DMMR) scheme
was recently proposed as an efficient alternative to the conventional N-modular
redundancy (NMR) scheme for the physical design of mission/safety-critical
circuits and systems. The DMMR scheme enables significant improvements in fault
tolerance and design metrics compared to the NMR scheme albeit at the expense
of a slight decrease in the system reliability. In this context, this paper
studies the system reliability, fault tolerance and design metrics tradeoffs in
the DMMR scheme compared to the NMR scheme when the majority logic group of the
DMMR scheme is increased in size relative to the minority logic group. Some
example DMMR and NMR systems were realized using a 32/28nm CMOS process and
compared. The results show that 5-of-M DMMR systems have a similar or better
fault tolerance whilst requiring similar or fewer function modules than their
counterpart NMR systems and simultaneously achieve optimizations in design
metrics. Nevertheless, 3-of-M DMMR systems have the upper hand with respect to
fault tolerance and design metrics optimizations than the comparable NMR and
5-of-M DMMR systems. With regard to system reliability, NMR systems are closely
followed by 5-of-M DMMR systems which are closely followed by 3-of-M DMMR
systems. The verdict is 3-of-M DMMR systems are preferable to implement higher
levels of redundancy from a combined system reliability, fault tolerance and
design metrics perspective to realize mission/safety-critical circuits and
systems.
"
639,"When to use 3D Die-Stacked Memory for Bandwidth-Constrained Big Data
  Workloads","  Response time requirements for big data processing systems are shrinking. To
meet this strict response time requirement, many big data systems store all or
most of their data in main memory to reduce the access latency. Main memory
capacities have grown, and systems with 2 TB of main memory capacity available
today. However, the rate at which processors can access this data--the memory
bandwidth--has not grown at the same rate. In fact, some of these big-memory
systems can access less than 10% of their main memory capacity in one second
(billions of processor cycles).
  3D die-stacking is one promising solution to this bandwidth problem, and
industry is investing significantly in 3D die-stacking. We use a simple
back-of-the-envelope-style model to characterize if and when the 3D die-stacked
architecture is more cost-effective than current architectures for in-memory
big data workloads. We find that die-stacking has much higher performance than
current systems (up to 256x lower response times), and it does not require
expensive memory over provisioning to meet real-time (10 ms) response time
service-level agreements. However, the power requirements of the die-stacked
systems are significantly higher (up to 50x) than current systems, and its
memory capacity is lower in many cases. Even in this limited case study, we
find 3D die-stacking is not a panacea. Today, die-stacking is the most
cost-effective solution for strict SLAs and by reducing the power of the
compute chip and increasing memory densities die-stacking can be cost-effective
under other constraints in the future.
"
640,"TriCheck: Memory Model Verification at the Trisection of Software,
  Hardware, and ISA","  Memory consistency models (MCMs) which govern inter-module interactions in a
shared memory system, are a significant, yet often under-appreciated, aspect of
system design. MCMs are defined at the various layers of the hardware-software
stack, requiring thoroughly verified specifications, compilers, and
implementations at the interfaces between layers. Current verification
techniques evaluate segments of the system stack in isolation, such as proving
compiler mappings from a high-level language (HLL) to an ISA or proving
validity of a microarchitectural implementation of an ISA.
  This paper makes a case for full-stack MCM verification and provides a
toolflow, TriCheck, capable of verifying that the HLL, compiler, ISA, and
implementation collectively uphold MCM requirements. The work showcases
TriCheck's ability to evaluate a proposed ISA MCM in order to ensure that each
layer and each mapping is correct and complete. Specifically, we apply TriCheck
to the open source RISC-V ISA, seeking to verify accurate, efficient, and legal
compilations from C11. We uncover under-specifications and potential
inefficiencies in the current RISC-V ISA documentation and identify possible
solutions for each. As an example, we find that a RISC-V-compliant
microarchitecture allows 144 outcomes forbidden by C11 to be observed out of
1,701 litmus tests examined. Overall, this paper demonstrates the necessity of
full-stack verification for detecting MCM-related bugs in the hardware-software
stack.
"
641,"A near-threshold RISC-V core with DSP extensions for scalable IoT
  Endpoint Devices","  Endpoint devices for Internet-of-Things not only need to work under extremely
tight power envelope of a few milliwatts, but also need to be flexible in their
computing capabilities, from a few kOPS to GOPS. Near-threshold(NT) operation
can achieve higher energy efficiency, and the performance scalability can be
gained through parallelism. In this paper we describe the design of an
open-source RISC-V processor core specifically designed for NT operation in
tightly coupled multi-core clusters. We introduce instruction-extensions and
microarchitectural optimizations to increase the computational density and to
minimize the pressure towards the shared memory hierarchy. For typical
data-intensive sensor processing workloads the proposed core is on average 3.5x
faster and 3.2x more energy-efficient, thanks to a smart L0 buffer to reduce
cache access contentions and support for compressed instructions. SIMD
extensions, such as dot-products, and a built-in L0 storage further reduce the
shared memory accesses by 8x reducing contentions by 3.2x. With four
NT-optimized cores, the cluster is operational from 0.6V to 1.2V achieving a
peak efficiency of 67MOPS/mW in a low-cost 65nm bulk CMOS technology. In a low
power 28nm FDSOI process a peak efficiency of 193MOPS/mW(40MHz, 1mW) can be
achieved.
"
642,On-Chip Mechanisms to Reduce Effective Memory Access Latency,"  This dissertation develops hardware that automatically reduces the effective
latency of accessing memory in both single-core and multi-core systems. To
accomplish this, the dissertation shows that all last level cache misses can be
separated into two categories: dependent cache misses and independent cache
misses. Independent cache misses have all of the source data that is required
to generate the address of the memory access available on-chip, while dependent
cache misses depend on data that is located off-chip. This dissertation
proposes that dependent cache misses are accelerated by migrating the
dependence chain that generates the address of the memory access to the memory
controller for execution. Independent cache misses are accelerated using a new
mode for runahead execution that only executes filtered dependence chains. With
these mechanisms, this dissertation demonstrates a 62% increase in performance
and a 19% decrease in effective memory access latency for a quad-core processor
on a set of high memory intensity workloads.
"
643,"A Hardware-Efficient Approach to Computing the Rotation Matrix from a
  Quaternion","  In this paper, we have proposed a novel VLSI-oriented approach to computing
the rotation matrix entries from the quaternion coefficients. The advantage of
this approach is the complete elimination of multiplications and replacing them
by less costly squarings. Our approach uses Logan's identity, which proposes to
replace the calculation of the product of two numbers on summing the squares
via the Binomial Theorem. Replacing multiplications by squarings implies
reducing power consumption as well as decreases hardware circuit complexity.
"
644,Practical Data Compression for Modern Memory Hierarchies,"  In this thesis, we describe a new, practical approach to integrating
hardware-based data compression within the memory hierarchy, including on-chip
caches, main memory, and both on-chip and off-chip interconnects. This new
approach is fast, simple, and effective in saving storage space. A key insight
in our approach is that access time (including decompression latency) is
critical in modern memory hierarchies. By combining inexpensive hardware
support with modest OS support, our holistic approach to compression achieves
substantial improvements in performance and energy efficiency across the memory
hierarchy. Using this new approach, we make several major contributions in this
thesis. First, we propose a new compression algorithm, Base-Delta-Immediate
Compression (BDI), that achieves high compression ratio with very low
compression/decompression latency. BDI exploits the existing low dynamic range
of values present in many cache lines to compress them to smaller sizes using
Base+Delta encoding. Second, we observe that the compressed size of a cache
block can be indicative of its reuse. We use this observation to develop a new
cache insertion policy for compressed caches, the Size-based Insertion Policy
(SIP), which uses the size of a compressed block as one of the metrics to
predict its potential future reuse. Third, we propose a new main memory
compression framework, Linearly Compressed Pages (LCP), that significantly
reduces the complexity and power cost of supporting main memory compression. We
demonstrate that any compression algorithm can be adapted to fit the
requirements of LCP, and that LCP can be efficiently integrated with the
existing cache compression designs, avoiding extra compression/decompression.
"
645,"Design of a Ternary Edge-Triggered D Flip-Flap-Flop for Multiple-Valued
  Sequential Logic","  Development of large computerized systems requires both combinational and
sequential circuits. Registers and counters are two important examples of
sequential circuits, which are widely used in practical applications like CPUs.
The basic element of sequential logic is Flip-Flop, which stores an input value
and returns two outputs (Q and Q_bar). This paper presents an innovative
ternary D Flip-Flap-Flop, which offers circuit designers to customize their
design by eliminating one of the outputs if it is not required. This unique
feature of the new design leads to considerable power reduction in comparison
with the previously presented structures. The proposed design is simulated and
tested by HSPICE and 45 nm CMOS technology.
"
646,FPGA Implementation of a Novel Image Steganography for Hiding Images,"  As the complexity of current data flow systems and according infrastructure
networks increases, the security of data transition through such platforms
becomes more important. Thus, different areas of steganography turn to one of
the most challengeable topics of current researches. In this paper a novel
method is presented to hide an image into the host image and Hardware/Software
design is proposed to implement our stagenography system on FPGA- DE2 70 Altera
board. The size of the secret image is quadrant of the host image. Host image
works as a cipher key to completely distort and encrypt the secret image using
XOR operand. Each pixel of the secret image is composed of 8 bits (4 bit-pair)
in which each bit-pair is distorted by XORing it with two LSB bits of the host
image and putting the results in the location of two LSB bits of host image.
The experimental results show the effectiveness of the proposed method compared
to the most recently proposed algorithms by considering that the obtained
information entropy for encrypt image is approximately equal to 8.
"
647,"Design of an Optoelectronic State Machine with integrated BDD based
  Optical logic","  In this paper I demonstrate a novel design for an optoelectronic State
Machine which replaces input/output forming logic found in conventional state
machines with BDD based optical logic while still using solid state memory in
the form of flip-flops in order to store states. This type of logic makes use
of waveguides and ring resonators to create binary switches. These switches in
turn can be used to create combinational logic which can be used as
input/output forming logic for a state machine. Replacing conventional
combinational logic with BDD based optical logic allows for a faster range of
state machines that can certainly outperform conventional state machines as
propagation delays within the logic described are in the order of picoseconds
as opposed to nanoseconds in digital logic.
"
648,"Reducing DRAM Access Latency by Exploiting DRAM Leakage Characteristics
  and Common Access Patterns","  DRAM-based memory is a critical factor that creates a bottleneck on the
system performance since the processor speed largely outperforms the DRAM
latency. In this thesis, we develop a low-cost mechanism, called ChargeCache,
which enables faster access to recently-accessed rows in DRAM, with no
modifications to DRAM chips. Our mechanism is based on the key observation that
a recently-accessed row has more charge and thus the following access to the
same row can be performed faster. To exploit this observation, we propose to
track the addresses of recently-accessed rows in a table in the memory
controller. If a later DRAM request hits in that table, the memory controller
uses lower timing parameters, leading to reduced DRAM latency. Row addresses
are removed from the table after a specified duration to ensure rows that have
leaked too much charge are not accessed with lower latency. We evaluate
ChargeCache on a wide variety of workloads and show that it provides
significant performance and energy benefits for both single-core and multi-core
systems.
"
649,"FPGA Implementation of High Speed Reconfigurable Filter Bank for
  Multi-standard Wireless Communication Receivers","  In next generation wireless communication system, wireless transceivers
should be able to handle wideband input signals compromising of multiple
communication standards.Such multi-standard wireless communication receivers
(MWCRs) need filter bank to extract the desired signal of interest from
wideband input spectrum and bring it to the baseband for further signal
processing tasks such as spectrum sensing, modulation
classification,demodulation etc.In MWCRs,rather any wireless receivers,
modulated filter banks, such as Discrete Fourier Transform Filter Banks
(DFTFB), are preferred due to their advantages such as lower area, delay and
power requirements. To support multi-standard operation, reconfigurable DFTFB
(RDFTFB) was proposed by integrating DFTFB with the coefficient decimation
method. In this paper, an efficient high speed implementation of RDFTFB on
Virtex-7 field programmable gate arrays (FPGA) has been proposed.The proposed
approach minimizes the critical path delay between clocked registers thereby
leading to significant improvement in the maximum operating frequency of the
RDFTFB. Numerically, the proposed implementation leads to 89.7% improvement in
the maximum frequency at which RDFTFB can be clocked.Furthermore,proposed
implementation leads to 18.5% reduction in the dynamic power consumption.
"
650,Multi-Valued Routing Tracks for FPGAs in 28nm FDSOI Technology,"  In this paper we present quaternary and ternary routing tracks for FPGAs, and
their implementation in 28nm FDSOI technology. We discuss the transistor level
design of multi-valued repeaters, multiplexers and translators, and specific
features of FDSOI technology which make it possible. Next we compare the
multi-valued routing architectures with equivalent single driver two-valued
routing architectures. We show that for long tracks, it is possible to achieve
upto 3x reduction in dynamic switching energy, upto 2x reduction in routing
wire area and 10% reduction in area dedicated to routing resources. The
multi-valued tracks are slightly more susceptible to process variation. We
present a layout method for multivalued standard cells and determine the layout
overhead.We conclude with various usage scenarios of these tracks.
"
651,An overview about Networks-on-Chip with multicast suppor,"  Modern System-on-Chip (SoC) platforms typically consist of multiple
processors and a communication interconnect between them. Network-on-Chip (NoC)
arises as a solution to interconnect these systems, which provides a scalable,
reusable, and an efficient interconnect. For these SoC platforms, multicast
communication is significantly used for parallel applications. Cache coherency
in distributed sharedmemory,clock synchronization, replication, or barrier
synchronization are examples of these requests. This paper presents an overview
of research on NoC with support for multicast communication and delineates the
major issues addressed so far by the scientific community in this investigation
area.
"
652,Epiphany-V: A 1024 processor 64-bit RISC System-On-Chip,"  This paper describes the design of a 1024-core processor chip in 16nm FinFet
technology. The chip (""Epiphany-V"") contains an array of 1024 64-bit RISC
processors, 64MB of on-chip SRAM, three 136-bit wide mesh Networks-On-Chip, and
1024 programmable IO pins. The chip has taped out and is being manufactured by
TSMC.
  This research was developed with funding from the Defense Advanced Research
Projects Agency (DARPA). The views, opinions and/or findings expressed are
those of the author and should not be interpreted as representing the official
views or policies of the Department of Defense or the U.S. Government.
"
653,Validating Simplified Processor Models in Architectural Studies,"  Cycle-accurate software simulation of multicores with complex
microarchitectures is often excruciatingly slow. People use simplified core
models to gain simulation speed. However, a persistent question is to what
extent the results derived from a simplified core model can be used to
characterize the behavior of a real machine.
  We propose a new methodology of validating simplified simulation models,
which focuses on the trends of metric values across benchmarks and
architectures, instead of errors of absolute metric values. To illustrate this
methodology, we conduct a case study using an FPGA-accelerated cycle-accurate
full system simulator. We evaluated three cache replacement polices on a
10-stage in-order core model, and then re-conducted all the experiments by
substituting a 1-IPC core model for the 10-stage core model. We found that the
1-IPC core model generally produces qualitatively the same results as the
accurate core model except for a few mismatches. We argue that most observed
mismatches were either indistinguishable from experimental noise or
corresponded to the cases where the policy differences even in the accurate
model showed inconclusive results. We think it is fair to use simplified core
models to study a feature once the influence of the simplification is
understood. Additional studies on branch predictors and scaling properties of
multithread benchmarks reinforce our argument. However, the validation of a
simplified model requires a detailed cycle-accurate model!
"
654,Near-Data Processing for Differentiable Machine Learning Models,"  Near-data processing (NDP) refers to augmenting memory or storage with
processing power. Despite its potential for acceleration computing and reducing
power requirements, only limited progress has been made in popularizing NDP for
various reasons. Recently, two major changes have occurred that have ignited
renewed interest and caused a resurgence of NDP. The first is the success of
machine learning (ML), which often demands a great deal of computation for
training, requiring frequent transfers of big data. The second is the
popularity of NAND flash-based solid-state drives (SSDs) containing multicore
processors that can accommodate extra computation for data processing. In this
paper, we evaluate the potential of NDP for ML using a new SSD platform that
allows us to simulate instorage processing (ISP) of ML workloads. Our platform
(named ISP-ML) is a full-fledged simulator of a realistic multi-channel SSD
that can execute various ML algorithms using data stored in the SSD. To conduct
a thorough performance analysis and an in-depth comparison with alternative
techniques, we focus on a specific algorithm: stochastic gradient descent
(SGD), which is the de facto standard for training differentiable models such
as logistic regression and neural networks. We implement and compare three SGD
variants (synchronous, Downpour, and elastic averaging) using ISP-ML,
exploiting the multiple NAND channels to parallelize SGD. In addition, we
compare the performance of ISP and that of conventional in-host processing,
revealing the advantages of ISP. Based on the advantages and limitations
identified through our experiments, we further discuss directions for future
research on ISP for accelerating ML.
"
655,Implementing High-Order FIR Filters in FPGAs,"  Contemporary field-programmable gate arrays (FPGAs) are predestined for the
application of finite impulse response (FIR) filters. Their embedded digital
signal processing (DSP) blocks for multiply-accumulate operations enable
efficient fixed-point computations, in cases where the filter structure is
accurately mapped to the dedicated hardware architecture. This brief presents a
generic systolic structure for high-order FIR filters, efficiently exploiting
the hardware resources of an FPGA in terms of routability and timing. Although
this seems to be an easily implementable task, the synthesizing tools require
an adaptation of the straightforward digital filter implementation for an
optimal mapping. Using the example of a symmetric FIR filter with 90 taps, we
demonstrate the performance of the proposed structure with FPGAs from Xilinx
and Altera. The implementation utilizes less than 1% of slice logic and runs at
clock frequencies up to 526 MHz. Moreover, an enhancement of the structure
ultimately provides an extended dynamic range for the quantized coefficients
without the costs of additional slice logic.
"
656,"High-performance K-means Implementation based on a Simplified Map-Reduce
  Architecture","  The k-means algorithm is one of the most common clustering algorithms and
widely used in data mining and pattern recognition. The increasing
computational requirement of big data applications makes hardware acceleration
for the k-means algorithm necessary. In this paper, a simplified Map-Reduce
architecture is proposed to implement the k-means algorithm on an FPGA.
Algorithmic segmentation, data path elaboration and automatic control are
applied to optimize the architecture for high performance. In addition, high
level synthesis technique is utilized to reduce development cycles and
complexity. For a single iteration in the k-means algorithm, a throughput of
28.74 Gbps is achieved. The performance shows at least 3.93x speedup compared
with four representative existing FPGA-based implementations and can satisfy
the demand of big data applications.
"
657,"A 9.52 dB NCG FEC scheme and 164 bits/cycle low-complexity product
  decoder architecture","  Powerful Forward Error Correction (FEC) schemes are used in optical
communications to achieve bit-error rates below $10^{-15}$. These FECs follow
one of two approaches: concatenation of simpler hard-decision codes or usage of
inherently powerful soft-decision codes. The first approach yields lower Net
Coding Gains (NCGs), but can usually work at higher code rates and have lower
complexity decoders. In this work, we propose a novel FEC scheme based on a
product code and a post-processing technique. It can achieve an NCG of 9.52~dB
at a BER of $10^{-15}$ and 9.96~dB at a BER of $10^{-18}$, an error-correction
performance that sits between that of current hard-decision and soft-decision
FECs. A decoder architecture is designed, tested on FPGA and synthesized in 65
nm CMOS technology: its 164 bits/cycle worst-case information throughput can
reach 100 Gb/s at the achieved frequency of 609~MHz. Its complexity is shown to
be lower than that of hard-decision decoders in literature, and an order of
magnitude lower than the estimated complexity of soft-decision decoders.
"
658,Design of a Compact Reversible Read-Only-Memory with MOS Transistors,"  Energy conservative devices are the need of the modern technology which leads
to the development of reversible logic. The synthesis of reversible logic has
become an intensely studied area as it overcomes the problem of power
dissipation associated with irreversibility. Storage device such as
Read-Only-Memory (ROM) can be realized in a reversible way with low power
dissipation. The reversibility of ROM has not been yet realized in literature
and hence, this paper presents a novel reversible ROM with its Complementary
Metal Oxide Semiconductor (CMOS) realization. On the way to present the
architecture of reversible ROM, we propose a new reversible gate named as
Nowrin Papiya (NP) gate. All the proposed circuits and gates are realized with
CMOS based pass transistor logic. Finally, an algorithm as well as several
theorems on the numbers of gates, transistors and garbage outputs have been
presented to show the optimality of the reversible ROM. Simulations using
Microwind DSCH software has been shown to verify the correctness of the
proposed design. The comparative results prove that the proposed designs are
efficient and optimized in terms of numbers of gates, transistors, garbage
outputs, quantum cost and delay.
"
659,"Accelerating BLAS on Custom Architecture through Algorithm-Architecture
  Co-design","  Basic Linear Algebra Subprograms (BLAS) play key role in high performance and
scientific computing applications. Experimentally, yesteryear multicore and
General Purpose Graphics Processing Units (GPGPUs) are capable of achieving up
to 15 to 57% of the theoretical peak performance at 65W to 240W respectively
for compute bound operations like Double/Single Precision General Matrix
Multiplication (XGEMM). For bandwidth bound operations like Single/Double
precision Matrix-vector Multiplication (XGEMV) the performance is merely 5 to
7% of the theoretical peak performance in multicores and GPGPUs respectively.
Achieving performance in BLAS requires moving away from conventional wisdom and
evolving towards customized accelerator tailored for BLAS through
algorithm-architecture co-design. In this paper, we present acceleration of
Level-1 (vector operations), Level-2 (matrix-vector operations), and Level-3
(matrix-matrix operations) BLAS through algorithm architecture co-design on a
Coarse-grained Reconfigurable Architecture (CGRA). We choose REDEFINE CGRA as a
platform for our experiments since REDEFINE can be adapted to support domain of
interest through tailor-made Custom Function Units (CFUs). For efficient
sequential realization of BLAS, we present design of a Processing Element (PE)
and perform micro-architectural enhancements in the PE to achieve up-to 74% of
the theoretical peak performance of PE in DGEMM, 40% in DGEMV and 20% in double
precision inner product (DDOT). We attach this PE to REDEFINE CGRA as a CFU and
show the scalability of our solution. Finally, we show performance improvement
of 3-140x in PE over commercially available Intel micro-architectures,
ClearSpeed CSX700, FPGA, and Nvidia GPGPUs.
"
660,Bit-pragmatic Deep Neural Network Computing,"  We quantify a source of ineffectual computations when processing the
multiplications of the convolutional layers in Deep Neural Networks (DNNs) and
propose Pragmatic (PRA), an architecture that exploits it improving performance
and energy efficiency. The source of these ineffectual computations is best
understood in the context of conventional multipliers which generate internally
multiple terms, that is, products of the multiplicand and powers of two, which
added together produce the final product [1]. At runtime, many of these terms
are zero as they are generated when the multiplicand is combined with the
zero-bits of the multiplicator. While conventional bit-parallel multipliers
calculate all terms in parallel to reduce individual product latency, PRA
calculates only the non-zero terms using a) on-the-fly conversion of the
multiplicator representation into an explicit list of powers of two, and b)
hybrid bit-parallel multplicand/bit-serial multiplicator processing units. PRA
exploits two sources of ineffectual computations: 1) the aforementioned zero
product terms which are the result of the lack of explicitness in the
multiplicator representation, and 2) the excess in the representation precision
used for both multiplicants and multiplicators, e.g., [2]. Measurements
demonstrate that for the convolutional layers, a straightforward variant of PRA
improves performance by 2.6x over the DaDiaNao (DaDN) accelerator [3] and by
1.4x over STR [4]. Similarly, PRA improves energy efficiency by 28% and 10% on
average compared to DaDN and STR. An improved cross lane synchronication scheme
boosts performance improvements to 3.1x over DaDN. Finally, Pragmatic benefits
persist even with an 8-bit quantized representation [5].
"
661,"A 481pJ/decision 3.4M decision/s Multifunctional Deep In-memory
  Inference Processor using Standard 6T SRAM Array","  This paper describes a multi-functional deep in-memory processor for
inference applications. Deep in-memory processing is achieved by embedding
pitch-matched low-SNR analog processing into a standard 6T 16KB SRAM array in
65 nm CMOS. Four applications are demonstrated. The prototype achieves up to
5.6X (9.7X estimated for multi-bank scenario) energy savings with negligible
(<1%) accuracy degradation in all four applications as compared to the
conventional architecture.
"
662,"Accelerating BLAS and LAPACK via Efficient Floating Point Architecture
  Design","  Basic Linear Algebra Subprograms (BLAS) and Linear Algebra Package (LAPACK)
form basic building blocks for several High Performance Computing (HPC)
applications and hence dictate performance of the HPC applications. Performance
in such tuned packages is attained through tuning of several algorithmic and
architectural parameters such as number of parallel operations in the Directed
Acyclic Graph of the BLAS/LAPACK routines, sizes of the memories in the memory
hierarchy of the underlying platform, bandwidth of the memory, and structure of
the compute resources in the underlying platform. In this paper, we closely
investigate the impact of the Floating Point Unit (FPU) micro-architecture for
performance tuning of BLAS and LAPACK. We present theoretical analysis for
pipeline depth of different floating point operations like multiplier, adder,
square root, and divider followed by characterization of BLAS and LAPACK to
determine several parameters required in the theoretical framework for deciding
optimum pipeline depth of the floating operations. A simple design of a
Processing Element (PE) is presented and shown that the PE outperforms the most
recent custom realizations of BLAS and LAPACK by 1.1X to 1.5X in Gflops/W, and
1.9X to 2.1X in Gflops/mm^2.
"
663,"The Processing Using Memory Paradigm:In-DRAM Bulk Copy, Initialization,
  Bitwise AND and OR","  In existing systems, the off-chip memory interface allows the memory
controller to perform only read or write operations. Therefore, to perform any
operation, the processor must first read the source data and then write the
result back to memory after performing the operation. This approach consumes
high latency, bandwidth, and energy for operations that work on a large amount
of data. Several works have proposed techniques to process data near memory by
adding a small amount of compute logic closer to the main memory chips. In this
article, we describe two techniques proposed by recent works that take this
approach of processing in memory further by exploiting the underlying operation
of the main memory technology to perform more complex tasks. First, we describe
RowClone, a mechanism that exploits DRAM technology to perform bulk copy and
initialization operations completely inside main memory. We then describe a
complementary work that uses DRAM to perform bulk bitwise AND and OR operations
inside main memory. These two techniques significantly improve the performance
and energy efficiency of the respective operations.
"
664,"Understanding and Exploiting Design-Induced Latency Variation in Modern
  DRAM Chips","  Variation has been shown to exist across the cells within a modern DRAM chip.
We empirically demonstrate a new form of variation that exists within a real
DRAM chip, induced by the design and placement of different components in the
DRAM chip. Our goals are to understand design-induced variation that exists in
real, state-of-the-art DRAM chips, exploit it to develop low-cost mechanisms
that can dynamically find and use the lowest latency at which to operate a DRAM
chip reliably, and, thus, improve overall system performance while ensuring
reliable system operation.
  To this end, we first experimentally demonstrate and analyze designed-induced
variation in modern DRAM devices by testing and characterizing 96 DIMMs (768
DRAM chips). Our characterization identifies DRAM regions that are vulnerable
to errors, if operated at lower latency, and finds consistency in their
locations across a given DRAM chip generation, due to design-induced variation.
Based on our extensive experimental analysis, we develop two mechanisms that
reliably reduce DRAM latency. First, DIVA Profiling uses runtime profiling to
dynamically identify the lowest DRAM latency that does not introduce failures.
DIVA Profiling exploits design-induced variation and periodically profiles only
the vulnerable regions to determine the lowest DRAM latency at low cost. Our
second mechanism, DIVA Shuffling, shuffles data such that values stored in
vulnerable regions are mapped to multiple error-correcting code (ECC)
codewords. Combined together, our two mechanisms reduce read/write latency by
40.0%/60.5%, which translates to an overall system performance improvement of
14.7%/13.7%/13.8% (in 2-/4-/8-core systems) across a variety of workloads,
while ensuring reliable operation.
"
665,"ARAPrototyper: Enabling Rapid Prototyping and Evaluation for
  Accelerator-Rich Architectures","  Compared to conventional general-purpose processors, accelerator-rich
architectures (ARAs) can provide orders-of-magnitude performance and energy
gains and are emerging as one of the most promising solutions in the age of
dark silicon. However, many design issues related to the complex interaction
between general-purpose cores, accelerators, customized on-chip interconnects,
and memory systems remain unclear and difficult to evaluate.
  In this paper we design and implement the ARAPrototyper to enable rapid
design space explorations for ARAs in real silicons and reduce the tedious
prototyping efforts far down to manageable efforts. First, ARAPrototyper
provides a reusable baseline prototype with a highly customizable memory
system, including interconnect between accelerators and buffers, interconnect
between buffers and last-level cache (LLC) or DRAM, coherency choice at LLC or
DRAM, and address translation support. Second, ARAPrototyper provides a clean
interface to quickly integrate users' own accelerators written in high-level
synthesis (HLS) code. The whole design flow is highly automated to generate a
prototype of ARA on an FPGA system-on-chip (SoC). Third, to quickly develop
applications that run seamlessly on the ARA prototype, ARAPrototyper provides a
system software stack, abstracts the accelerators as software libraries, and
provides APIs for software developers. Our experimental results demonstrate
that ARAPrototyper enables a wide range of design space explorations for ARAs
at manageable prototyping efforts, which has 4,000X to 10,000X faster
evaluation time than full-system simulations. We believe that ARAPrototyper can
be an attractive alternative for ARA design and evaluation.
"
666,"Flat ORAM: A Simplified Write-Only Oblivious RAM Construction for Secure
  Processors","  Oblivious RAM (ORAM) is a cryptographic primitive which obfuscates the access
patterns to a storage thereby preventing privacy leakage. So far in the current
literature, only `fully functional' ORAMs are widely studied which can protect,
at a cost of considerable performance penalty, against the strong adversaries
who can monitor all read and write operations. However, recent research has
shown that information can still be leaked even if only the write access
pattern (not reads) is visible to the adversary. For such weaker adversaries, a
fully functional ORAM turns out to be an overkill causing unnecessary
overheads. Instead, a simple `write-only' ORAM is sufficient, and, more
interestingly, is preferred as it can offer far more performance and energy
efficiency than a fully functional ORAM.
  In this work, we present Flat ORAM: an efficient write-only ORAM scheme which
outperforms the closest existing write-only ORAM called HIVE. HIVE suffers from
performance bottlenecks while managing the memory occupancy information vital
for correctness of the protocol. Flat ORAM resolves these bottlenecks by
introducing a simple idea of Occupancy Map (OccMap) which efficiently manages
the memory occupancy information resulting in far better performance. Our
simulation results show that, on average, Flat ORAM only incurs a moderate
slowdown of $3\times$ over the insecure DRAM for memory intensive benchmarks
among Splash2 and $1.6\times$ for SPEC06. Compared to HIVE, Flat ORAM offers
$50\%$ performance gain on average and up to $80\%$ energy savings.
"
667,"PipeCNN: An OpenCL-Based FPGA Accelerator for Large-Scale Convolution
  Neuron Networks","  Convolutional neural networks (CNNs) have been widely employed in many
applications such as image classification, video analysis and speech
recognition. Being compute-intensive, CNN computations are mainly accelerated
by GPUs with high power dissipations. Recently, studies were carried out
exploiting FPGA as CNN accelerator because of its reconfigurability and energy
efficiency advantage over GPU, especially when OpenCL-based high-level
synthesis tools are now available providing fast verification and
implementation flows. Previous OpenCL-based design only focused on creating a
generic framework to identify performance-related hardware parameters, without
utilizing FPGA's special capability of pipelining kernel functions to minimize
memory bandwidth requirement. In this work, we propose an FPGA accelerator with
a new architecture of deeply pipelined OpenCL kernels. Data reuse and task
mapping techniques are also presented to improve design efficiency. The
proposed schemes are verified by implementing two representative large-scale
CNNs, AlexNet and VGG on Altera Stratix-V A7 FPGA. We have achieved a similar
peak performance of 33.9 GOPS with a 34% resource reduction on DSP blocks
compared to previous work. Our design is openly accessible and thus can be
reused to explore new architectures for neural network accelerators.
"
668,Non-volatile Hierarchical Temporal Memory: Hardware for Spatial Pooling,"  Hierarchical Temporal Memory (HTM) is a biomimetic machine learning algorithm
imbibing the structural and algorithmic properties of the neocortex. Two main
functional components of HTM that enable spatio-temporal processing are the
spatial pooler and temporal memory. In this research, we explore a scalable
hardware realization of the spatial pooler closely coupled with the
mathematical formulation of spatial pooler. This class of neuromorphic
algorithms are advantageous in solving a subset of the future engineering
problems by extracting nonintuitive patterns in complex data. The proposed
architecture, Non-volatile HTM (NVHTM), leverages large-scale solid state flash
memory to realize a optimal memory organization, area and power envelope. A
behavioral model of NVHTM is evaluated against the MNIST dataset, yielding
91.98% classification accuracy. A full custom layout is developed to validate
the design in a TSMC 180nm process. The area and power profile of the spatial
pooler are 30.538mm2 and 64.394mW, respectively. This design is a
proof-of-concept that storage processing is a viable platform for large scale
HTM network models.
"
669,Power Gating Structure for Reversible Programmable Logic Array,"  Throughout the world, the numbers of researchers or hardware designer
struggle for the reducing of power dissipation in low power VLSI systems. This
paper presented an idea of using the power gating structure for reducing the
sub threshold leakage in the reversible system. This concept presented in the
paper is entirely new and presented in the literature of reversible logics. By
using the reversible logics for the digital systems, the energy can be saved up
to the gate level implementation. But at the physical level designing of the
reversible logics by the modern CMOS technology the heat or energy is
dissipated due the sub-threshold leakage at the time of inactivity or standby
mode. The Reversible Programming logic array (RPLA) is one of the important
parts of the low power industrial applications and in this paper the physical
design of the RPLA is presented by using the sleep transistor and the results
is shown with the help of TINA- PRO software. The results for the proposed
design is also compare with the CMOS design and shown that of 40.8% of energy
saving. The Transient response is also produces in the paper for the switching
activity and showing that the proposed design is much better that the modern
CMOS design of the RPLA.
"
670,A Brief Survey of Non-Residue Based Computational Error Correction,"  The idea of computational error correction has been around for over half a
century. The motivation has largely been to mitigate unreliable devices,
manufacturing defects or harsh environments, primarily as a mandatory measure
to preserve reliability, or more recently, as a means to lower energy by
allowing soft errors to occasionally creep. While residue codes have shown
great promise for this purpose, there have been several orthogonal non-residue
based techniques. In this article, we provide a high level outline of some of
these non-residual approaches.
"
671,"Energy-efficient Machine Learning in Silicon: A Communications-inspired
  Approach","  This position paper advocates a communications-inspired approach to the
design of machine learning systems on energy-constrained embedded `always-on'
platforms. The communications-inspired approach has two versions - 1) a
deterministic version where existing low-power communication IC design methods
are repurposed, and 2) a stochastic version referred to as Shannon-inspired
statistical information processing employing information-based metrics,
statistical error compensation (SEC), and retraining-based methods to implement
ML systems on stochastic circuit/device fabrics operating at the limits of
energy-efficiency. The communications-inspired approach has the potential to
fully leverage the opportunities afforded by ML algorithms and applications in
order to address the challenges inherent in their deployment on
energy-constrained platforms.
"
672,In-Storage Embedded Accelerator for Sparse Pattern Processing,"  We present a novel architecture for sparse pattern processing, using flash
storage with embedded accelerators. Sparse pattern processing on large data
sets is the essence of applications such as document search, natural language
processing, bioinformatics, subgraph matching, machine learning, and graph
processing. One slice of our prototype accelerator is capable of handling up to
1TB of data, and experiments show that it can outperform C/C++ software
solutions on a 16-core system at a fraction of the power and cost; an optimized
version of the accelerator can match the performance of a 48-core server.
"
673,"Revisiting FPGA Acceleration of Molecular Dynamics Simulation with
  Dynamic Data Flow Behavior in High-Level Synthesis","  Molecular dynamics (MD) simulation is one of the past decade's most important
tools for enabling biology scientists and researchers to explore human health
and diseases. However, due to the computation complexity of the MD algorithm,
it takes weeks or even months to simulate a comparatively simple biology entity
on conventional multicore processors. The critical path in molecular dynamics
simulations is the force calculation between particles inside the simulated
environment, which has abundant parallelism. Among various acceleration
platforms, FPGA is an attractive alternative because of its low power and high
energy efficiency. However, due to its high programming cost using RTL, none of
the mainstream MD software packages has yet adopted FPGA for acceleration.
  In this paper we revisit the FPGA acceleration of MD in high-level synthesis
(HLS) so as to provide affordable programming cost. Our experience with the MD
acceleration demonstrates that HLS optimizations such as loop pipelining,
module duplication and memory partitioning are essential to improve the
performance, achieving a speedup of 9.5X compared to a 12-core CPU. More
importantly, we observe that even the fully optimized HLS design can still be
2X slower than the reference RTL architecture due to the common dynamic
(conditional) data flow behavior that is not yet supported by current HLS
tools. To support such behavior, we further customize an array of processing
elements together with a data-driven streaming network through a common RTL
template, and fully automate the design flow. Our final experimental results
demonstrate a 19.4X performance speedup and 39X energy efficiency for the
widely used ApoA1 MD benchmark on the Convey HC1ex FPGA compared to a 12-core
Intel Xeon server.
"
674,"Multipliers: comparison of Fourier transformation based method and
  Synopsys design technique for up to 32 bits inputs in regular and saturation
  arithmetics","  The technique for hardware multiplication based upon Fourier transformation
has been introduced. The technique has the highest efficiency on multiplication
units with up to 8 bit range. Each multiplication unit is realized on base of
the minimized Boolean functions. Experimental data showed that this technique
the multiplication process speed up to 20% higher for 2-8 bit range of input
operands and up to 3% higher for 8-32 bit range of input operands than
analogues designed by Synopsys technique.
"
675,"An Efficient Framework for Floor-plan Prediction of Dynamic Runtime
  Reconfigurable Systems","  Several embedded application domains for reconfigurable systems tend to
combine frequent changes with high performance demands of their workloads such
as image processing, wearable computing and network processors. Time
multiplexing of reconfigurable hardware resources raises a number of new
issues, ranging from run-time systems to complex programming models that
usually form a Reconfigurable hardware Operating System (ROS). The Operating
System performs online task scheduling and handles resource management. There
are many challenges in adaptive computing and dynamic reconfigurable systems.
One of the major understudied challenges is estimating the required resources
in terms of soft cores, Programmable Reconfigurable Regions (PRRs), the
appropriate communication infrastructure, and to predict a near optimal layout
and floorplan of the reconfigurable logic fabric. Some of these issues are
specific to the application being designed, while others are more general and
relate to the underlying run-time environment. Static resource allocation for
Run- Time Reconfiguration (RTR) often leads to inferior and unacceptable
results. In this paper, we present a novel adaptive and dynamic methodology,
based on a Machine Learning approach, for predicting and estimating the
necessary resources for an application based on past historical information. An
important feature of the proposed methodology is that the system is able to
learn and generalize and, therefore, is expected to improve its accuracy over
time. The goal of the entire process is to extract useful hidden knowledge from
the data. This knowledge is the prediction and estimation of the necessary
resources for an unknown or not previously seen application.
"
676,"Fast and reconfigurable packet classification engine in FPGA-based
  firewall","  In data communication via internet, security is becoming one of the most
influential aspects. One way to support it is by classifying and filtering
ethernet packets within network devices. Packet classification is a fundamental
task for network devices such as routers, firewalls, and intrusion detection
systems. In this paper we present architecture of fast and reconfigurable
Packet Classification Engine (PCE). This engine is used in FPGA-based firewall.
Our PCE inspects multi-dimensional field of packet header sequentially based on
tree-based algorithm. This algorithm simplifies overall system to a lower scale
and leads to a more secure system. The PCE works with an adaptation of single
cycle processor architecture in the system. Ethernet packet is examined with
PCE based on Source IP Address, Destination IP Address, Source Port,
Destination Port, and Protocol fields of the packet header. These are basic
fields to know whether it is a dangerous or normal packet before inspecting the
content. Using implementation of tree-based algorithm in the architecture,
firewall rules are rebuilt into 24-bit sub-rules which are read as processor
instruction in the inspection process. The inspection process is comparing one
sub-rule with input field of header every clock cycle. The proposed PCE shows
91 MHz clock frequency in Cyclone II EP2C70F896C6 with 13 clocks throughput
average from input to output generation. The use of tree-based algorithm
simplifies the multidimensional packet inspection and gives us reconfigurable
as well as scalable system. The architecture is fast, reliable, and adaptable
and also can maximize the advantages of the algorithm very well. Although the
PCE has high frequency and little amount of clock, filtering speed of a
firewall also depends on the other components, such as packet FIFO buffer. Fast
and reliable FIFO buffer is needed to support the PCE. This PCE also is not
completed with rule update mechanism yet. This proposed PCE is tested as a
component of FPGA-based firewall to filter Ethernet packet with FPGA DE2 Board
using NIOS II platform.
"
677,Can Broken Multicore Hardware be Mended?,"  A suggestion is made for mending multicore hardware, which has been diagnosed
as broken.
"
678,"FPGA Based Implementation of Distributed Minority and Majority Voting
  Based Redundancy for Mission and Safety-Critical Applications","  Electronic circuits and systems used in mission and safety-critical
applications usually employ redundancy in the design to overcome arbitrary
fault(s) or failure(s) and guarantee the correct operation. In this context,
the distributed minority and majority voting based redundancy (DMMR) scheme
forms an efficient alternative to the conventional N-modular redundancy (NMR)
scheme for implementing mission and safety-critical circuits and systems by
significantly minimizing their weight and design cost and also their design
metrics whilst providing a similar degree of fault tolerance. This article
presents the first FPGAs based implementation of example DMMR circuits and
compares it with counterpart NMR circuits on the basis of area occupancy and
critical path delay viz. area-delay product (ADP). The example DMMR circuits
and counterpart NMR circuits are able to accommodate the faulty or failure
states of 2, 3 and 4 function modules. For physical synthesis, two commercial
Xilinx FPGAs viz. Spartan 3E and Virtex 5 corresponding to 90nm and 65nm CMOS
processes, and two radiation-tolerant and military grade Xilinx FPGAs viz. QPro
Virtex 2 and QPro Virtex E corresponding to 150nm and 180nm CMOS processes were
considered for the NMR and DMMR circuit realizations which employ the 4-by-4
array multiplier as a representative function module. To achieve a fault
tolerance of 2 function modules, both the DMMR and the NMR schemes provide near
similar mean ADPs across all the four FPGAs. But while achieving a fault
tolerance of 3 function modules the DMMR features reduced ADP by 44.5% on
average compared to the NMR, and in achieving a fault tolerance of 4 function
modules the DMMR reports reduced ADP by 56.5% on average compared to the NMR
with respect to all the four FPGAs considered.
"
679,"An Efficient Partial Sums Generator for Constituent Code based
  Successive Cancellation Decoding of Polar Codes","  This paper proposes the architecture of partial sum generator for constituent
codes based polar code decoder. Constituent codes based polar code decoder has
the advantage of low latency. However, no purposefully designed partial sum
generator design exists that can yield desired timing for the decoder. We first
derive the mathematical presentation with the partial sums set $\bm{\beta^c}$
which is corresponding to each constituent codes. From this, we concoct a
shift-register based partial sum generator. Next, the overall architecture and
design details are described, and the overhead compared with conventional
partial sum generator is evaluated. Finally, the implementation results with
both ASIC and FPGA technology and relevant discussions are presented.
"
680,"Buddy-RAM: Improving the Performance and Efficiency of Bulk Bitwise
  Operations Using DRAM","  Bitwise operations are an important component of modern day programming. Many
widely-used data structures (e.g., bitmap indices in databases) rely on fast
bitwise operations on large bit vectors to achieve high performance.
Unfortunately, in existing systems, regardless of the underlying architecture
(e.g., CPU, GPU, FPGA), the throughput of such bulk bitwise operations is
limited by the available memory bandwidth.
  We propose Buddy, a new mechanism that exploits the analog operation of DRAM
to perform bulk bitwise operations completely inside the DRAM chip. Buddy
consists of two components. First, simultaneous activation of three DRAM rows
that are connected to the same set of sense amplifiers enables us to perform
bitwise AND and OR operations. Second, the inverters present in each sense
amplifier enables us to perform bitwise NOT operations, with modest changes to
the DRAM array. These two components make Buddy functionally complete. Our
implementation of Buddy largely exploits the existing DRAM structure and
interface, and incurs low overhead (1% of DRAM chip area).
  Our evaluations based on SPICE simulations show that, across seven
commonly-used bitwise operations, Buddy provides between 10.9X---25.6X
improvement in raw throughput and 25.1X---59.5X reduction in energy
consumption. We evaluate three real-world data-intensive applications that
exploit bitwise operations: 1) bitmap indices, 2) BitWeaving, and 3)
bitvector-based implementation of sets. Our evaluations show that Buddy
significantly outperforms the state-of-the-art.
"
681,Memory Controller Design Under Cloud Workloads,"  This work studies the behavior of state-of-the-art memory controller designs
when executing scale-out workloads. It considers memory scheduling techniques,
memory page management policies, the number of memory channels, and the address
mapping scheme used. Experimental measurements demonstrate: 1)~Several recently
proposed memory scheduling policies are not a good match for these scale-out
workloads. 2)~The relatively simple First-Ready-First-Come-First-Served
(FR-FCFS) policy performs consistently better, and 3)~for most of the studied
workloads, the even simpler First-Come-First-Served scheduling policy is within
1\% of FR-FCFS. 4)~Increasing the number of memory channels offers negligible
performance benefits, e.g., performance improves by 1.7\% on average for
4-channels vs. 1-channel. 5)~77\%-90\% of DRAM rows activations are accessed
only once before closure. These observation can guide future development and
optimization of memory controllers for scale-out workloads.
"
682,Near-Memory Address Translation,"  Memory and logic integration on the same chip is becoming increasingly cost
effective, creating the opportunity to offload data-intensive functionality to
processing units placed inside memory chips. The introduction of memory-side
processing units (MPUs) into conventional systems faces virtual memory as the
first big showstopper: without efficient hardware support for address
translation MPUs have highly limited applicability. Unfortunately, conventional
translation mechanisms fall short of providing fast translations as
contemporary memories exceed the reach of TLBs, making expensive page walks
common.
  In this paper, we are the first to show that the historically important
flexibility to map any virtual page to any page frame is unnecessary in today's
servers. We find that while limiting the associativity of the
virtual-to-physical mapping incurs no penalty, it can break the
translate-then-fetch serialization if combined with careful data placement in
the MPU's memory, allowing for translation and data fetch to proceed
independently and in parallel. We propose the Distributed Inverted Page Table
(DIPTA), a near-memory structure in which the smallest memory partition keeps
the translation information for its data share, ensuring that the translation
completes together with the data fetch. DIPTA completely eliminates the
performance overhead of translation, achieving speedups of up to 3.81x and
2.13x over conventional translation using 4KB and 1GB pages respectively.
"
683,Field-Programmable Crossbar Array (FPCA) for Reconfigurable Computing,"  For decades, advances in electronics were directly driven by the scaling of
CMOS transistors according to Moore's law. However, both the CMOS scaling and
the classical computer architecture are approaching fundamental and practical
limits, and new computing architectures based on emerging devices, such as
resistive random-access memory (RRAM) devices, are expected to sustain the
exponential growth of computing capability. Here we propose a novel
memory-centric, reconfigurable, general purpose computing platform that is
capable of handling the explosive amount of data in a fast and energy-efficient
manner. The proposed computing architecture is based on a uniform, physical,
resistive, memory-centric fabric that can be optimally reconfigured and
utilized to perform different computing and data storage tasks in a massively
parallel approach. The system can be tailored to achieve maximal energy
efficiency based on the data flow by dynamically allocating the basic computing
fabric for storage, arithmetic, and analog computing including neuromorphic
computing tasks.
"
684,"Arch2030: A Vision of Computer Architecture Research over the Next 15
  Years","  Application trends, device technologies and the architecture of systems drive
progress in information technologies. However, the former engines of such
progress - Moore's Law and Dennard Scaling - are rapidly reaching the point of
diminishing returns. The time has come for the computing community to boldly
confront a new challenge: how to secure a foundational future for information
technology's continued progress. The computer architecture community engaged in
several visioning exercises over the years. Five years ago, we released a white
paper, 21st Century Computer Architecture, which influenced funding programs in
both academia and industry. More recently, the IEEE Rebooting Computing
Initiative explored the future of computing systems in the architecture,
device, and circuit domains. This report stems from an effort to continue this
dialogue, reach out to the applications and devices/circuits communities, and
understand their trends and vision. We aim to identify opportunities where
architecture research can bridge the gap between the application and device
domains.
"
685,"An Artificial Neural Networks based Temperature Prediction Framework for
  Network-on-Chip based Multicore Platform","  Continuous improvement in silicon process technologies has made possible the
integration of hundreds of cores on a single chip. However, power and heat have
become dominant constraints in designing these massive multicore chips causing
issues with reliability, timing variations and reduced lifetime of the chips.
Dynamic Thermal Management (DTM) is a solution to avoid high temperatures on
the die. Typical DTM schemes only address core level thermal issues. However,
the Network-on-chip (NoC) paradigm, which has emerged as an enabling
methodology for integrating hundreds to thousands of cores on the same die can
contribute significantly to the thermal issues. Moreover, the typical DTM is
triggered reactively based on temperature measurements from on-chip thermal
sensor requiring long reaction times whereas predictive DTM method estimates
future temperature in advance, eliminating the chance of temperature overshoot.
Artificial Neural Networks (ANNs) have been used in various domains for
modeling and prediction with high accuracy due to its ability to learn and
adapt. This thesis concentrates on designing an ANN prediction engine to
predict the thermal profile of the cores and Network-on-Chip elements of the
chip. This thermal profile of the chip is then used by the predictive DTM that
combines both core level and network level DTM techniques. On-chip wireless
interconnect which is recently envisioned to enable energy-efficient data
exchange between cores in a multicore environment, will be used to provide a
broadcast-capable medium to efficiently distribute thermal control messages to
trigger and manage the DTM schemes.
"
686,Copycat: A High Precision Real Time NAND Simulator,"  In this paper, we describe the design and implementation of a high precision
real time NAND simulator called Copycat that runs on a commodity multi-core
desktop environment. This NAND simulator facilitates the development of
embedded flash memory management software such as the flash translation layer
(FTL). The simulator also allows a comprehensive fault injection for testing
the reliability of the FTL. Compared against a real FPGA implementation, the
simulator's response time deviation is under 0.28% on average, with a maximum
of 10.12%.
"
687,"A 700uW 1GS/s 4-bit Folding-Flash ADC in 65nm CMOS for Wideband Wireless
  Communications","  We present the design of a low-power 4-bit 1GS/s folding-flash ADC with a
folding factor of two. The design of a new unbalanced double-tail dynamic
comparator affords an ultra-low power operation and a high dynamic range.
Unlike the conventional approaches, this design uses a fully matched input
stage, an unbalanced latch stage, and a two-clock operation scheme. A
combination of these features yields significant reduction of the kick-back
noise, while allowing the design flexibility for adjusting the trip points of
the comparators. As a result, the ADC achieves SNDR of 22.3 dB at 100MHz and
21.8 dB at 500MHz (i.e. the Nyquist frequency). The maximum INL and DNL are
about 0.2 LSB. The converter consumes about 700uW from a 1-V supply yielding a
figure of merit of 65fJ/conversion step. These attributes make the proposed
folding-flash ADC attractive for the next-generation wireless applications.
"
688,"HADES: Microprocessor Hazard Analysis via Formal Verification of
  Parameterized Systems","  HADES is a fully automated verification tool for pipeline-based
microprocessors that aims at flaws caused by improperly handled data hazards.
It focuses on single-pipeline microprocessors designed at the register transfer
level (RTL) and deals with read-after-write, write-after-write, and
write-after-read hazards. HADES combines several techniques, including
data-flow analysis, error pattern matching, SMT solving, and abstract regular
model checking. It has been successfully tested on several microprocessors for
embedded applications.
"
689,"A Novel RTL ATPG Model Based on Gate Inherent Faults (GIF-PO) of Complex
  Gates","  This paper starts with a comprehensive survey on RTL ATPG. It then proposes a
novel RTL ATPG model based on ""Gate Inherent Faults"" (GIF). These GIF are
extracted from each complex gate (adder, case-statement, etc.) of the RTL
source code individually. They are related to the internal logic paths of a
complex gate. They are not related to any net/signal in the RTL design. It is
observed, that when all GIF on RTL are covered (100%) and the same stimulus is
applied, then all gate level stuck-at faults of the netlist are covered (100%)
as well. The proposed RTL ATPG model is therefore synthesis independent. This
is shown on ITC'99 testcases. The applied semi-automatic test pattern
generation process is based on functional simulation.
"
690,"Prototyping RISC Based, Reconfigurable Networking Applications in Open
  Source","  In the last decade we have witnessed a rapid growth in data center systems,
requiring new and highly complex networking devices. The need to refresh
networking infrastructure whenever new protocols or functions are introduced,
and the increasing costs that this entails, are of a concern to all data center
providers. New generations of Systems on Chip (SoC), integrating
microprocessors and higher bandwidth interfaces, are an emerging solution to
this problem. These devices permit entirely new systems and architectures that
can obviate the replacement of existing networking devices while enabling
seamless functionality change. In this work, we explore open source, RISC
based, SoC architectures with high performance networking capabilities. The
prototype architectures are implemented on the NetFPGA-SUME platform. Beyond
details of the architecture, we also describe the hardware implementation and
the porting of operating systems to the platform. The platform can be exploited
for the development of practical networking appliances, and we provide use case
examples.
"
691,"An IoT Endpoint System-on-Chip for Secure and Energy-Efficient
  Near-Sensor Analytics","  Near-sensor data analytics is a promising direction for IoT endpoints, as it
minimizes energy spent on communication and reduces network load - but it also
poses security concerns, as valuable data is stored or sent over the network at
various stages of the analytics pipeline. Using encryption to protect sensitive
data at the boundary of the on-chip analytics engine is a way to address data
security issues. To cope with the combined workload of analytics and encryption
in a tight power envelope, we propose Fulmine, a System-on-Chip based on a
tightly-coupled multi-core cluster augmented with specialized blocks for
compute-intensive data processing and encryption functions, supporting software
programmability for regular computing tasks. The Fulmine SoC, fabricated in
65nm technology, consumes less than 20mW on average at 0.8V achieving an
efficiency of up to 70pJ/B in encryption, 50pJ/px in convolution, or up to
25MIPS/mW in software. As a strong argument for real-life flexible application
of our platform, we show experimental results for three secure analytics use
cases: secure autonomous aerial surveillance with a state-of-the-art deep CNN
consuming 3.16pJ per equivalent RISC op; local CNN-based face detection with
secured remote recognition in 5.74pJ/op; and seizure detection with encrypted
data collection from EEG within 12.7pJ/op.
"
692,NOP - A Simple Experimental Processor for Parallel Deployment,"  The design of a parallel computing system using several thousands or even up
to a million processors asks for processing units that are simple and thus
small in space, to make as many processing units as possible fit on a single
die.
  The design presented herewith is far from being optimised, it is not meant to
compete with industry performance devices. Its main purpose is to allow for a
prototypical implementation of a dynamic software system as a proof of concept.
"
693,"FINN: A Framework for Fast, Scalable Binarized Neural Network Inference","  Research has shown that convolutional neural networks contain significant
redundancy, and high classification accuracy can be obtained even when weights
and activations are reduced from floating point to binary values. In this
paper, we present FINN, a framework for building fast and flexible FPGA
accelerators using a flexible heterogeneous streaming architecture. By
utilizing a novel set of optimizations that enable efficient mapping of
binarized neural networks to hardware, we implement fully connected,
convolutional and pooling layers, with per-layer compute resources being
tailored to user-provided throughput requirements. On a ZC706 embedded FPGA
platform drawing less than 25 W total system power, we demonstrate up to 12.3
million image classifications per second with 0.31 {\mu}s latency on the MNIST
dataset with 95.8% accuracy, and 21906 image classifications per second with
283 {\mu}s latency on the CIFAR-10 and SVHN datasets with respectively 80.1%
and 94.9% accuracy. To the best of our knowledge, ours are the fastest
classification rates reported to date on these benchmarks.
"
694,"Application-aware Retiming of Accelerators: A High-level Data-driven
  Approach","  Flexibility at hardware level is the main driving force behind adaptive
systems whose aim is to realise microarhitecture deconfiguration 'online'. This
feature allows the software/hardware stack to tolerate drastic changes of the
workload in data centres. With emerge of FPGA reconfigurablity this technology
is becoming a mainstream computing paradigm. Adaptivity is usually accompanied
by the high-level tools to facilitate multi-dimensional space exploration. An
essential aspect in this space is memory orchestration where on-chip and
off-chip memory distribution significantly influences the architecture in
coping with the critical spatial and timing constraints, e.g. Place and Route.
This paper proposes a memory smart technique for a particular class of adaptive
systems: Elastic Circuits which enjoy slack elasticity at fine level of
granularity. We explore retiming of a set of popular benchmarks via
investigating the memory distribution within and among accelerators. The area,
performance and power patterns are adopted by our high-level synthesis
framework, with respect to the behaviour of the input descriptions, to improve
the quality of the synthesised elastic circuits.
"
695,"Neutron induced strike: On the likelihood of multiple bit-flips in logic
  circuits","  High energy particles from cosmic rays or packaging materials can generate a
glitch or a current transient (single event transient or SET) in a logic
circuit. This SET can eventually get captured in a register resulting in a flip
of the register content, which is known as soft error or single-event upset
(SEU). A soft error is typically modeled as a probabilistic single bit-flip
model. In developing such abstract fault models, an important issue to consider
is the likelihood of multiple bit errors caused by particle strikes. The fact
that an SET causes multiple flips is noted in the literature. We perform a
characterization study of the impact of an SET on a logic circuit to quantify
the extent to which an SET can cause multiple bit flips. We use post-layout
circuit simulations and Monte Carlo sampling scheme to get accurate bit-flip
statistics. We perform our simulations on ISCAS'85, ISCAS'89 and ITC'99
benchmarks in 180nm and 65nm technologies. We find that a substantial fraction
of SEU outcomes had multiple register flips. We futher analyse the individual
contributions of the strike on a register and the strike on a logic gate, to
multiple flips. We find that, amongst the erroneous outcomes, the probability
of multiple bit-flips for 'gate-strike' cases was substantial and went up to
50%, where as those for 'register-strike' cases was just about 2%. This implies
that, in principle, we can eliminate the flips due to register strikes using
hardened flip-flop designs. However, in such designs, out of the remaining
flips which will be due to gate strikes, a large fraction is likely to be
multiple flips.
"
696,"Memory Efficient Multi-Scale Line Detector Architecture for Retinal
  Blood Vessel Segmentation","  This paper presents a memory efficient architecture that implements the
Multi-Scale Line Detector (MSLD) algorithm for real-time retinal blood vessel
detection in fundus images on a Zynq FPGA. This implementation benefits from
the FPGA parallelism to drastically reduce the memory requirements of the MSLD
from two images to a few values. The architecture is optimized in terms of
resource utilization by reusing the computations and optimizing the bit-width.
The throughput is increased by designing fully pipelined functional units. The
architecture is capable of achieving a comparable accuracy to its software
implementation but 70x faster for low resolution images. For high resolution
images, it achieves an acceleration by a factor of 323x.
"
697,Reducing Competitive Cache Misses in Modern Processor Architectures,"  The increasing number of threads inside the cores of a multicore processor,
and competitive access to the shared cache memory, become the main reasons for
an increased number of competitive cache misses and performance decline.
Inevitably, the development of modern processor architectures leads to an
increased number of cache misses. In this paper, we make an attempt to
implement a technique for decreasing the number of competitive cache misses in
the first level of cache memory. This technique enables competitive access to
the entire cache memory when there is a hit - but, if there are cache misses,
memory data (by using replacement techniques) is put in a virtual part given to
threads, so that competitive cache misses are avoided. By using a simulator
tool, the results show a decrease in the number of cache misses and performance
increase for up to 15%. The conclusion that comes out of this research is that
cache misses are a real challenge for future processor designers, in order to
hide memory latency.
"
698,VESPA: VIPT Enhancements for Superpage Accesses,"  L1 caches are critical to the performance of modern computer systems. Their
design involves a delicate balance between fast lookups, high hit rates, low
access energy, and simplicity of implementation. Unfortunately, constraints
imposed by virtual memory make it difficult to satisfy all these attributes
today. Specifically, the modern staple of supporting virtual-indexing and
physical-tagging (VIPT) for parallel TLB-L1 lookups means that L1 caches are
usually grown with greater associativity rather than sets. This compromises
performance -- by degrading access times without significantly boosting hit
rates -- and increases access energy. We propose VIPT Enhancements for
SuperPage Accesses or VESPA in response. VESPA side-steps the traditional
problems of VIPT by leveraging the increasing ubiquity of superpages; since
superpages have more page offset bits, they can accommodate L1 cache
organizations with more sets than baseline pages can. VESPA dynamically adapts
to any OS distribution of page sizes to operate L1 caches with good access
times, hit rates, and energy, for both single- and multi-threaded workloads.
Since the hardware changes are modest, and there are no OS or application
changes, VESPA is readily-implementable.
  By superpages (also called huge or large pages) we refer to any page sizes
supported by the architecture bigger than baseline page size.
"
699,An OpenCL(TM) Deep Learning Accelerator on Arria 10,"  Convolutional neural nets (CNNs) have become a practical means to perform
vision tasks, particularly in the area of image classification. FPGAs are well
known to be able to perform convolutions efficiently, however, most recent
efforts to run CNNs on FPGAs have shown limited advantages over other devices
such as GPUs. Previous approaches on FPGAs have often been memory bound due to
the limited external memory bandwidth on the FPGA device. We show a novel
architecture written in OpenCL(TM), which we refer to as a Deep Learning
Accelerator (DLA), that maximizes data reuse and minimizes external memory
bandwidth. Furthermore, we show how we can use the Winograd transform to
significantly boost the performance of the FPGA. As a result, when running our
DLA on Intel's Arria 10 device we can achieve a performance of 1020 img/s, or
23 img/s/W when running the AlexNet CNN benchmark. This comes to 1382 GFLOPs
and is 10x faster with 8.4x more GFLOPS and 5.8x better efficiency than the
state-of-the-art on FPGAs. Additionally, 23 img/s/W is competitive against the
best publicly known implementation of AlexNet on nVidia's TitanX GPU.
"
700,"Power and Execution Time Measurement Methodology for SDF Applications on
  FPGA-based MPSoCs","  Timing and power consumption play an important role in the design of embedded
systems. Furthermore, both properties are directly related to the safety
requirements of many embedded systems. With regard to availability
requirements, power considerations are of uttermost importance for battery
operated systems. Validation of timing and power requires observability of
these properties. In many cases this is difficult, because the observability is
either not possible or requires big extra effort in the system validation
process. In this paper, we present a measurement-based approach for the joint
timing and power analysis of Synchronous Dataflow (SDF) applications running on
a shared memory multiprocessor systems-on-chip (MPSoC) architecture. As a
proof-of-concept, we implement an MPSoC system with configurable power and
timing measurement interfaces inside a Field Programmable Gate Array (FPGA).
Our experiments demonstrate the viability of our approach being able of
accurately analyzing different mappings of image processing applications (Sobel
filter and JPEG encoder) on an FPGA-based MPSoC implementation.
"
701,"Formal Analysis of SEU Mitigation for Early Dependability and
  Performability Analysis of FPGA-based Space Applications","  SRAM-based FPGAs are increasingly popular in the aerospace industry due to
their field programmability and low cost. However, they suffer from cosmic
radiation induced Single Event Upsets (SEUs). In safety-critical applications,
the dependability of the design is a prime concern since failures may have
catastrophic consequences. An early analysis of the relationship between
dependability metrics, performability-area trade-off, and different mitigation
techniques for such applications can reduce the design effort while increasing
the design confidence. This paper introduces a novel methodology based on
probabilistic model checking, for the analysis of the reliability,
availability, safety and performance-area tradeoffs of safety-critical systems
for early design decisions. Starting from the high-level description of a
system, a Markov reward model is constructed from the Control Data Flow Graph
(CDFG) and a component characterization library targeting FPGAs. The proposed
model and exhaustive analysis capture all the failure states (based on the
fault detection coverage) and repairs possible in the system. We present
quantitative results based on an FIR filter circuit to illustrate the
applicability of the proposed approach and to demonstrate that a wide range of
useful dependability and performability properties can be analyzed using the
proposed methodology. The modeling results show the relationship between
different mitigation techniques and fault detection coverage, exposing their
direct impact on the design for early decisions.
"
702,HoLiSwap: Reducing Wire Energy in L1 Caches,"  This paper describes HoLiSwap a method to reduce L1 cache wire energy, a
significant fraction of total cache energy, by swapping hot lines to the cache
way nearest to the processor. We observe that (i) a small fraction (<3%) of
cache lines (hot lines) serve over 60% of the L1 cache accesses and (ii) the
difference in wire energy between the nearest and farthest cache subarray can
be over 6$\times$. Our method exploits this difference in wire energy to
dynamically identify hot lines and swap them to the nearest physical way in a
set-associative L1 cache. This provides up to 44% improvement in the wire
energy (1.82% saving in overall system energy) with no impact on the cache miss
rate and 0.13% performance drop. We also show that HoLiSwap can simplify
way-prediction.
"
703,Design of an Audio Interface for Patmos,"  This paper describes the design and implementation of an audio interface for
the Patmos processor, which runs on an Altera DE2-115 FPGA board. This board
has an audio codec included, the WM8731. The interface described in this work
allows to receive and send audio from and to the WM8731, and to synthesize,
store or manipulate audio signals writing C programs for Patmos. The audio
interface described in this paper is intended to be used with the Patmos
processor. Patmos is an open source RISC ISAs with a load-store architecture,
that is optimized for Real-Time Systems. Patmos is part of a project founded by
the European Union called T-CREST (Time-predictable Multi-Core Architecture for
Embedded Systems).[5] The structure of this project is integrated with the
Patmos project: new hardware modules have been added as IOs, which allow the
communication between the processor and the audio codec. These modules include
a clock generator for the audio chip, ADC and DAC modules for the audio
conversion from analog to digital and vice versa, and an I2C module which
allows setting configuration parameters on the audio codec. Moreover, a top
module has been created, which connects all the modules previously mentioned
between them, to Patmos and to the WM8731, using the external pins of the FPGA.
"
704,"Neurostream: Scalable and Energy Efficient Deep Learning with Smart
  Memory Cubes","  High-performance computing systems are moving towards 2.5D and 3D memory
hierarchies, based on High Bandwidth Memory (HBM) and Hybrid Memory Cube (HMC)
to mitigate the main memory bottlenecks. This trend is also creating new
opportunities to revisit near-memory computation. In this paper, we propose a
flexible processor-in-memory (PIM) solution for scalable and energy-efficient
execution of deep convolutional networks (ConvNets), one of the fastest-growing
workloads for servers and high-end embedded systems. Our codesign approach
consists of a network of Smart Memory Cubes (modular extensions to the standard
HMC) each augmented with a many-core PIM platform called NeuroCluster.
NeuroClusters have a modular design based on NeuroStream coprocessors (for
Convolution-intensive computations) and general-purpose RISCV cores. In
addition, a DRAM-friendly tiling mechanism and a scalable computation paradigm
are presented to efficiently harness this computational capability with a very
low programming effort. NeuroCluster occupies only 8% of the total logic-base
(LoB) die area in a standard HMC and achieves an average performance of 240
GFLOPS for complete execution of full-featured state-of-the-art (SoA) ConvNets
within a power budget of 2.5W. Overall 11 W is consumed in a single SMC device,
with 22.5 GFLOPS/W energy-efficiency which is 3.5X better than the best GPU
implementations in similar technologies. The minor increase in system-level
power and the negligible area increase make our PIM system a cost-effective and
energy efficient solution, easily scalable to 955 GFLOPS with a small network
of just four SMCs.
"
705,"Variability-Aware Design for Energy Efficient Computational Artificial
  Intelligence Platform","  Portable computing devices, which include tablets, smart phones and various
types of wearable sensors, experienced a rapid development in recent years. One
of the most critical limitations for these devices is the power consumption as
they use batteries as the power supply. However, the bottleneck of the power
saving schemes in both hardware design and software algorithm is the huge
variability in power consumption. The variability is caused by a myriad of
factors, including the manufacturing process, the ambient environment
(temperature, humidity), the aging effects and etc. As the technology node
scaled down to 28nm and even lower, the variability becomes more severe. As a
result, a platform for variability characterization seems to be very necessary
and helpful.
"
706,Hardware Translation Coherence for Virtualized Systems,"  To improve system performance, modern operating systems (OSes) often
undertake activities that require modification of virtual-to-physical page
translation mappings. For example, the OS may migrate data between physical
frames to defragment memory and enable superpages. The OS may migrate pages of
data between heterogeneous memory devices. We refer to all such activities as
page remappings. Unfortunately, page remappings are expensive. We show that
translation coherence is a major culprit and that systems employing
virtualization are especially badly affected by their overheads. In response,
we propose hardware translation invalidation and coherence or HATRIC, a readily
implementable hardware mechanism to piggyback translation coherence atop
existing cache coherence protocols. We perform detailed studies using KVM-based
virtualization, showing that HATRIC achieves up to 30% performance and 10%
energy benefits, for per-CPU area overheads of 2%. We also quantify HATRIC's
benefits on systems running Xen and find up to 33% performance improvements.
"
707,"Accurate Measurement of Power Consumption Overhead During FPGA Dynamic
  Partial Reconfiguration","  In the context of embedded systems design, two important challenges are still
under investigation. First, improve real-time data processing,
reconfigurability, scalability, and self-adjusting capabilities of hardware
components. Second, reduce power consumption through low-power design
techniques as clock gating, logic gating, and dynamic partial reconfiguration
(DPR) capabilities. Today, several application, e.g., cryptography,
Software-defined radio or aerospace missions exploit the benefits of DPR of
programmable logic devices. The DPR allows well defined reconfigurable FPGA
region to be modified during runtime. However, it introduces an overhead in
term of power consumption and time during the reconfiguration phase. In this
paper, we present an investigation of power consumption overhead of the DPR
process using a high-speed digital oscilloscope and the shunt resistor method.
Results in terms of reconfiguration time and power consumption overhead for
Virtex 5 FPGAs are shown.
"
708,"1.5 bit-per-stage 8-bit Pipelined CMOS A/D Converter for Neuromophic
  Vision Processor","  Neuromorphic vision processor is an electronic implementation of vision
algorithm processor on semiconductor. To image the world, a low-power CMOS
image sensor array is required in the vision processor. The image sensor array
is typically formed through photo diodes and analog to digital converter (ADC).
To achieve low power acquisition, a low-power mid-resolution ADC is necessary.
In this paper, a 1.8V, 8-bit, 166MS/s pipelined ADC was proposed in a 0.18 um
CMOS technology. The ADC used operational amplifier sharing architecture to
reduce power consumption and achieved maximum DNL of 0.24 LSB, maximum INL of
0.35 LSB, at a power consumption of 38.9mW. When input frequency is 10.4MHz, it
achieved an SNDR 45.9dB, SFDR 50dB, and an ENOB of 7.33 bit.
"
709,Machines and Algorithms,"  I discuss the evolution of computer architectures with a focus on QCD and
with reference to the interplay between architecture, engineering, data motion
and algorithms. New architectures are discussed and recent performance results
are displayed. I also review recent progress in multilevel solver and
integation algorithms.
"
710,"FPGA-based real-time 105-channel data acquisition platform for imaging
  system","  In this paper, a real-time 105-channel data acquisition platform based on
FPGA for imaging will be implemented for mm-wave imaging systems. PC platform
is also realized for imaging results monitoring purpose. Mm-wave imaging
expands our vision by letting us see things under poor visibility conditions.
With this extended vision ability, a wide range of military imaging missions
would benefit, such as surveillance, precision targeting, navigation, and
rescue. Based on the previously designed imager modules, this project would go
on finishing the PCB design (both schematic and layout) of the following signal
processing systems consisting of Programmable Gain Amplifier(PGA) (4 PGA for
each ADC) and 16-channel Analog to Digital Converter (ADC) (7 ADC in total).
Then the system verification would be performed on the Artix-7 35T Arty FPGA
with the developing of proper controlling code to configure the ADC and realize
the communication between the FPGA and the PC (through both UART and Ethernet).
For the verification part, a simple test on a breadboard with a simple analog
input (generated from a resistor divider) would first be performed. After the
PCB design is finished, the whole system would be tested again with a precise
reference and analog input.
"
711,A Multi-Gbps Unrolled Hardware List Decoder for a Systematic Polar Code,"  Polar codes are a new class of block codes with an explicit construction that
provably achieve the capacity of various communications channels, even with the
low-complexity successive-cancellation (SC) decoding algorithm. Yet, the more
complex successive-cancellation list (SCL) decoding algorithm is gathering more
attention lately as it significantly improves the error-correction performance
of short- to moderate-length polar codes, especially when they are concatenated
with a cyclic redundancy check code. However, as SCL decoding explores several
decoding paths, existing hardware implementations tend to be significantly
slower than SC-based decoders. In this paper, we show how the unrolling
technique, which has already been used in the context of SC decoding, can be
adapted to SCL decoding yielding a multi-Gbps SCL-based polar decoder with an
error-correction performance that is competitive when compared to an LDPC code
of similar length and rate. Post-place-and-route ASIC results for 28 nm CMOS
are provided showing that this decoder can sustain a throughput greater than 10
Gbps at 468 MHz with an energy efficiency of 7.25 pJ/bit.
"
712,"Sense Amplifier Comparator with Offset Correction for Decision Feedback
  Equalization based Receivers","  A decision feedback circuit with integrated offset compensation is presented
in this paper. The circuit is built around the sense amplifier comparator. The
feedback loop is closed around the first stage of the comparator resulting in
minimum loop latency. The feedback loop is implemented using a switched
capacitor network that picks from one of pre-computed voltages to be fed back.
The comparator's offset that is to be compensated for, is added in the same
path. Hence, an extra offset correction input is not required. The circuit is
used as a receiver for a 10 mm low swing interconnect implemented in UMC 130 nm
CMOS technology. The circuit is tested at a frequency of 1 GHz and it consumes
145 $\mu$A from a 1.2V supply at this frequency.
"
713,Embedded Systems Architecture for SLAM Applications,"  In recent years, we have observed a clear trend in the rapid rise of
autonomous vehicles, robotics, virtual reality, and augmented reality. The core
technology enabling these applications, Simultaneous Localization And Mapping
(SLAM), imposes two main challenges: first, these workloads are computationally
intensive and they often have real-time requirements; second, these workloads
run on battery-powered mobile devices with limited energy budget. In short, the
essence of these challenges is that performance should be improved while
simultaneously reducing energy consumption, two rather contradicting goals by
conventional wisdom. In this paper, we take a close look at state-of-the-art
Simultaneous Localization And Mapping (SLAM) workloads, especially how these
workloads behave on mobile devices. Based on the results, we propose a mobile
architecture to improve SLAM performance on mobile devices.
"
714,"A Digital Hardware Fast Algorithm and FPGA-based Prototype for a Novel
  16-point Approximate DCT for Image Compression Applications","  The discrete cosine transform (DCT) is the key step in many image and video
coding standards. The 8-point DCT is an important special case, possessing
several low-complexity approximations widely investigated. However, 16-point
DCT transform has energy compaction advantages. In this sense, this paper
presents a new 16-point DCT approximation with null multiplicative complexity.
The proposed transform matrix is orthogonal and contains only zeros and ones.
The proposed transform outperforms the well-know Walsh-Hadamard transform and
the current state-of-the-art 16-point approximation. A fast algorithm for the
proposed transform is also introduced. This fast algorithm is experimentally
validated using hardware implementations that are physically realized and
verified on a 40 nm CMOS Xilinx Virtex-6 XC6VLX240T FPGA chip for a maximum
clock rate of 342 MHz. Rapid prototypes on FPGA for 8-bit input word size shows
significant improvement in compressed image quality by up to 1-2 dB at the cost
of only eight adders compared to the state-of-art 16-point DCT approximation
algorithm in the literature [S. Bouguezel, M. O. Ahmad, and M. N. S. Swamy. A
novel transform for image compression. In {\em Proceedings of the 53rd IEEE
International Midwest Symposium on Circuits and Systems (MWSCAS)}, 2010].
"
715,CAAD: Computer Architecture for Autonomous Driving,"  We describe the computing tasks involved in autonomous driving, examine
existing autonomous driving computing platform implementations. To enable
autonomous driving, the computing stack needs to simultaneously provide high
performance, low power consumption, and low thermal dissipation, at low cost.
We discuss possible approaches to design computing platforms that will meet
these needs.
"
716,FASHION: Fault-Aware Self-Healing Intelligent On-chip Network,"  To avoid packet loss and deadlock scenarios that arise due to faults or power
gating in multicore and many-core systems, the network-on-chip needs to possess
resilient communication and load-balancing properties. In this work, we
introduce the Fashion router, a self-monitoring and self-reconfiguring design
that allows for the on-chip network to dynamically adapt to component failures.
First, we introduce a distributed intelligence unit, called Self-Awareness
Module (SAM), which allows the router to detect permanent component failures
and build a network connectivity map. Using local information, SAM adapts to
faults, guarantees connectivity and deadlock-free routing inside the maximal
connected subgraph and keeps routing tables up-to-date. Next, to reconfigure
network links or virtual channels around faulty/power-gated components, we add
bidirectional link and unified virtual channel structure features to the
Fashion router. This version of the router, named Ex-Fashion, further mitigates
the negative system performance impacts, leads to larger maximal connected
subgraph and sustains a relatively high degree of fault-tolerance. To support
the router, we develop a fault diagnosis and recovery algorithm executed by the
Built-In Self-Test, self-monitoring, and self-reconfiguration units at runtime
to provide fault-tolerant system functionalities. The Fashion router places no
restriction on topology, position or number of faults. It drops 54.3-55.4%
fewer nodes for same number of faults (between 30 and 60 faults) in an 8x8
2D-mesh over other state-of-the-art solutions. It is scalable and efficient.
The area overheads are 2.311% and 2.659% when implemented in 8x8 and 16x16
2D-meshes using the TSMC 65nm library at 1.38GHz clock frequency.
"
717,1-bit Massive MU-MIMO Precoding in VLSI,"  Massive multiuser (MU) multiple-input multiple-output (MIMO) will be a core
technology in fifth-generation (5G) wireless systems as it offers significant
improvements in spectral efficiency compared to existing multi-antenna
technologies. The presence of hundreds of antenna elements at the base station
(BS), however, results in excessively high hardware costs and power
consumption, and requires high interconnect throughput between the
baseband-processing unit and the radio unit. Massive MU-MIMO that uses
low-resolution analog-to-digital and digital-to-analog converters (DACs) has
the potential to address all these issues. In this paper, we focus on downlink
precoding for massive MU-MIMO systems with 1-bit DACs at the BS. The objective
is to design precoders that simultaneously mitigate multi-user interference
(MUI) and quantization artifacts. We propose two nonlinear 1-bit precoding
algorithms and corresponding very-large scale integration (VLSI) designs. Our
algorithms rely on biconvex relaxation, which enables the design of efficient
1-bit precoding algorithms that achieve superior error-rate performance
compared to that of linear precoding algorithms followed by quantization. To
showcase the efficacy of our algorithms, we design VLSI architectures that
enable efficient 1-bit precoding for massive MU-MIMO systems in which hundreds
of antennas serve tens of user equipments. We present corresponding
field-programmable gate array (FPGA) implementations to demonstrate that 1-bit
precoding enables reliable and high-rate downlink data transmission in
practical systems.
"
718,"A GPU-Outperforming FPGA Accelerator Architecture for Binary
  Convolutional Neural Networks","  FPGA-based hardware accelerators for convolutional neural networks (CNNs)
have obtained great attentions due to their higher energy efficiency than GPUs.
However, it is challenging for FPGA-based solutions to achieve a higher
throughput than GPU counterparts. In this paper, we demonstrate that FPGA
acceleration can be a superior solution in terms of both throughput and energy
efficiency when a CNN is trained with binary constraints on weights and
activations. Specifically, we propose an optimized FPGA accelerator
architecture tailored for bitwise convolution and normalization that features
massive spatial parallelism with deep pipelines stages. A key advantage of the
FPGA accelerator is that its performance is insensitive to data batch size,
while the performance of GPU acceleration varies largely depending on the batch
size of the data. Experiment results show that the proposed accelerator
architecture for binary CNNs running on a Virtex-7 FPGA is 8.3x faster and 75x
more energy-efficient than a Titan X GPU for processing online individual
requests in small batch sizes. For processing static data in large batch sizes,
the proposed solution is on a par with a Titan X GPU in terms of throughput
while delivering 9.5x higher energy efficiency.
"
719,"Physically unclonable function using initial waveform of ring
  oscillators on 65 nm CMOS technology","  A silicon physically unclonable function (PUF) using ring oscillators (ROs)
has the advantage of easy application in both an application specific
integrated circuit (ASIC) and a field-programmable gate array (FPGA). Here, we
provide a RO-PUF using the initial waveform of the ROs based on 65 nm CMOS
technology. Compared with the conventional RO-PUF, the number of ROs is greatly
reduced and the time needed to generate an ID is within a couple of system
clocks.
"
720,Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation,"  Checkpoint-restart is now a mature technology. It allows a user to save and
later restore the state of a running process. The new plugin model for the
upcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is
described here. This plugin model allows a target application to disconnect
from the hardware emulator at checkpoint time and then re-connect to a possibly
different hardware emulator at the time of restart. The DMTCP plugin model is
important in allowing three distinct parties to seamlessly inter-operate. The
three parties are: the EDA designer, who is concerned with formal verification
of a circuit design; the DMTCP developers, who are concerned with providing
transparent checkpointing during the circuit emulation; and the hardware
emulator vendor, who provides a plugin library that responds to checkpoint,
restart, and other events.
  The new plugin model is an example of process-level virtualization:
virtualization of external abstractions from within a process. This capability
is motivated by scenarios for testing circuit models with the help of a
hardware emulator. The plugin model enables a three-way collaboration: allowing
a circuit designer and emulator vendor to each contribute separate proprietary
plugins while sharing an open source software framework from the DMTCP
developers. This provides a more flexible platform, where different fault
injection models based on plugins can be designed within the DMTCP
checkpointing framework. After initialization, one restarts from a checkpointed
state under the control of the desired plugin. This restart saves the time
spent in simulating the initialization phase, while enabling fault injection
exactly at the region of interest. Upon restart, one can inject faults or
otherwise modify the remainder of the simulation. The work concludes with a
brief survey of checkpointing and process-level virtualization.
"
721,"Chain-NN: An Energy-Efficient 1D Chain Architecture for Accelerating
  Deep Convolutional Neural Networks","  Deep convolutional neural networks (CNN) have shown their good performances
in many computer vision tasks. However, the high computational complexity of
CNN involves a huge amount of data movements between the computational
processor core and memory hierarchy which occupies the major of the power
consumption. This paper presents Chain-NN, a novel energy-efficient 1D chain
architecture for accelerating deep CNNs. Chain-NN consists of the dedicated
dual-channel process engines (PE). In Chain-NN, convolutions are done by the 1D
systolic primitives composed of a group of adjacent PEs. These systolic
primitives, together with the proposed column-wise scan input pattern, can
fully reuse input operand to reduce the memory bandwidth requirement for energy
saving. Moreover, the 1D chain architecture allows the systolic primitives to
be easily reconfigured according to specific CNN parameters with fewer design
complexity. The synthesis and layout of Chain-NN is under TSMC 28nm process. It
costs 3751k logic gates and 352KB on-chip memory. The results show a 576-PE
Chain-NN can be scaled up to 700MHz. This achieves a peak throughput of
806.4GOPS with 567.5mW and is able to accelerate the five convolutional layers
in AlexNet at a frame rate of 326.2fps. 1421.0GOPS/W power efficiency is at
least 2.5 to 4.1x times better than the state-of-the-art works.
"
722,A 588 Gbps LDPC Decoder Based on Finite-Alphabet Message Passing,"  An ultra-high throughput low-density parity check (LDPC) decoder with an
unrolled full-parallel architecture is proposed, which achieves the highest
decoding throughput compared to previously reported LDPC decoders in the
literature. The decoder benefits from a serial message-transfer approach
between the decoding stages to alleviate the well-known routing congestion
problem in parallel LDPC decoders. Furthermore, a finite-alphabet message
passing algorithm is employed to replace the variable node update rule of the
standard min-sum decoder with look-up tables, which are designed in a way that
maximizes the mutual information between decoding messages. The proposed
algorithm results in an architecture with reduced bit-width messages, leading
to a significantly higher decoding throughput and to a lower area as compared
to a min-sum decoder when serial message-transfer is used. The architecture is
placed and routed for the standard min-sum reference decoder and for the
proposed finite-alphabet decoder using a custom pseudo-hierarchical backend
design strategy to further alleviate routing congestions and to handle the
large design. Post-layout results show that the finite-alphabet decoder with
the serial message-transfer architecture achieves a throughput as large as 588
Gbps with an area of 16.2 mm$^2$ and dissipates an average power of 22.7 pJ per
decoded bit in a 28 nm FD-SOI library. Compared to the reference min-sum
decoder, this corresponds to 3.1 times smaller area and 2 times better energy
efficiency.
"
723,"Hardware-Efficient Schemes of Quaternion Multiplying Units for 2D
  Discrete Quaternion Fourier Transform Processors","  In this paper, we offer and discuss three efficient structural solutions for
the hardware-oriented implementation of discrete quaternion Fourier transform
basic operations with reduced implementation complexities. The first solution:
a scheme for calculating sq product, the second solution: a scheme for
calculating qt product, and the third solution: a scheme for calculating sqt
product, where s is a so-called i-quaternion, t is an j-quaternion, and q is an
usual quaternion. The direct multiplication of two usual quaternions requires
16 real multiplications (or two-operand multipliers in the case of fully
parallel hardware implementation) and 12 real additions (or binary adders). At
the same time, our solutions allow to design the computation units, which
consume only 6 multipliers plus 6 two input adders for implementation of sq or
qt basic operations and 9 binary multipliers plus 6 two-input adders and 4
four-input adders for implementation of sqt basic operation.
"
724,Formalizing Memory Accesses and Interrupts,"  The hardware/software boundary in modern heterogeneous multicore computers is
increasingly complex, and diverse across different platforms. A single memory
access by a core or DMA engine traverses multiple hardware translation and
caching steps, and the destination memory cell or register often appears at
different physical addresses for different cores. Interrupts pass through a
complex topology of interrupt controllers and remappers before delivery to one
or more cores, each with specific constraints on their configurations. System
software must not only correctly understand the specific hardware at hand, but
also configure it appropriately at runtime. We propose a formal model of
address spaces and resources in a system that allows us to express and verify
invariants of the system's runtime configuration, and illustrate (and motivate)
it with several real platforms we have encountered in the process of OS
implementation.
"
725,"CNN-MERP: An FPGA-Based Memory-Efficient Reconfigurable Processor for
  Forward and Backward Propagation of Convolutional Neural Networks","  Large-scale deep convolutional neural networks (CNNs) are widely used in
machine learning applications. While CNNs involve huge complexity, VLSI (ASIC
and FPGA) chips that deliver high-density integration of computational
resources are regarded as a promising platform for CNN's implementation. At
massive parallelism of computational units, however, the external memory
bandwidth, which is constrained by the pin count of the VLSI chip, becomes the
system bottleneck. Moreover, VLSI solutions are usually regarded as a lack of
the flexibility to be reconfigured for the various parameters of CNNs. This
paper presents CNN-MERP to address these issues. CNN-MERP incorporates an
efficient memory hierarchy that significantly reduces the bandwidth
requirements from multiple optimizations including on/off-chip data allocation,
data flow optimization and data reuse. The proposed 2-level reconfigurability
is utilized to enable fast and efficient reconfiguration, which is based on the
control logic and the multiboot feature of FPGA. As a result, an external
memory bandwidth requirement of 1.94MB/GFlop is achieved, which is 55% lower
than prior arts. Under limited DRAM bandwidth, a system throughput of
1244GFlop/s is achieved at the Vertex UltraScale platform, which is 5.48 times
higher than the state-of-the-art FPGA implementations.
"
726,"Ozone: Efficient Execution with Zero Timing Leakage for Modern
  Microarchitectures","  Time variation during program execution can leak sensitive information. Time
variations due to program control flow and hardware resource contention have
been used to steal encryption keys in cipher implementations such as AES and
RSA. A number of approaches to mitigate timing-based side-channel attacks have
been proposed including cache partitioning, control-flow obfuscation and
injecting timing noise into the outputs of code. While these techniques make
timing-based side-channel attacks more difficult, they do not eliminate the
risks. Prior techniques are either too specific or too expensive, and all leave
remnants of the original timing side channel for later attackers to attempt to
exploit.
  In this work, we show that the state-of-the-art techniques in timing
side-channel protection, which limit timing leakage but do not eliminate it,
still have significant vulnerabilities to timing-based side-channel attacks. To
provide a means for total protection from timing-based side-channel attacks, we
develop Ozone, the first zero timing leakage execution resource for a modern
microarchitecture. Code in Ozone execute under a special hardware thread that
gains exclusive access to a single core's resources for a fixed (and limited)
number of cycles during which it cannot be interrupted. Memory access under
Ozone thread execution is limited to a fixed size uncached scratchpad memory,
and all Ozone threads begin execution with a known fixed microarchitectural
state. We evaluate Ozone using a number of security sensitive kernels that have
previously been targets of timing side-channel attacks, and show that Ozone
eliminates timing leakage with minimal performance overhead.
"
727,Memos: Revisiting Hybrid Memory Management in Modern Operating System,"  The emerging hybrid DRAM-NVM architecture is challenging the existing memory
management mechanism in operating system. In this paper, we introduce memos,
which can schedule memory resources over the entire memory hierarchy including
cache, channels, main memory comprising DRAM and NVM simultaneously. Powered by
our newly designed kernel-level monitoring module and page migration engine,
memos can dynamically optimize the data placement at the memory hierarchy in
terms of the on-line memory patterns, current resource utilization and feature
of memory medium. Our experimental results show that memos can achieve high
memory utilization, contributing to system throughput by 19.1% and QoS by 23.6%
on average. Moreover, memos can reduce the NVM side memory latency by 3~83.3%,
energy consumption by 25.1~99%, and benefit the NVM lifetime significantly (40X
improvement on average).
"
728,UNBIAS PUF: A Physical Implementation Bias Agnostic Strong PUF,"  The Physical Unclonable Function (PUF) is a promising hardware security
primitive because of its inherent uniqueness and low cost. To extract the
device-specific variation from delay-based strong PUFs, complex routing
constraints are imposed to achieve symmetric path delays; and systematic
variations can severely compromise the uniqueness of the PUF. In addition, the
metastability of the arbiter circuit of an Arbiter PUF can also degrade the
quality of the PUF due to the induced instability. In this paper we propose a
novel strong UNBIAS PUF that can be implemented purely by Register Transfer
Language (RTL), such as verilog, without imposing any physical design
constraints or delay characterization effort to solve the aforementioned
issues. Efficient inspection bit prediction models for unbiased response
extraction are proposed and validated. Our experimental results of the strong
UNBIAS PUF show 5.9% intra-Fractional Hamming Distance (FHD) and 45.1%
inter-FHD on 7 Field Programmable Gate Array (FPGA) boards without applying any
physical layout constraints or additional XOR gates. The UNBIAS PUF is also
scalable because no characterization cost is required for each challenge to
compensate the implementation bias. The averaged intra-FHD measured at worst
temperature and voltage variation conditions is 12%, which is still below the
margin of practical Error Correction Code (ECC) with error reduction techniques
for PUFs.
"
729,"Banshee: Bandwidth-Efficient DRAM Caching Via Software/Hardware
  Cooperation","  Putting the DRAM on the same package with a processor enables several times
higher memory bandwidth than conventional off-package DRAM. Yet, the latency of
in-package DRAM is not appreciably lower than that of off-package DRAM. A
promising use of in-package DRAM is as a large cache. Unfortunately, most
previous DRAM cache designs mainly optimize for hit latency and do not consider
off-chip bandwidth efficiency as a first-class design constraint. Hence, as we
show in this paper, these designs are suboptimal for use with in-package DRAM.
  We propose a new DRAM cache design, Banshee, that optimizes for both in- and
off-package DRAM bandwidth efficiency without degrading access latency. The key
ideas are to eliminate the in-package DRAM bandwidth overheads due to costly
tag accesses through virtual memory mechanism and to incorporate a
bandwidth-aware frequency-based replacement policy that is biased to reduce
unnecessary traffic to off-package DRAM. Our extensive evaluation shows that
Banshee provides significant performance improvement and traffic reduction over
state-of-the-art latency-optimized DRAM cache designs.
"
730,"FMMU: A Hardware-Automated Flash Map Management Unit for Scalable
  Performance of NAND Flash-Based SSDs","  NAND flash-based Solid State Drives (SSDs), which are widely used from
embedded systems to enterprise servers, are enhancing performance by exploiting
the parallelism of NAND flash memories. To cope with the performance
improvement of SSDs, storage systems have rapidly adopted the host interface
for SSDs from Serial-ATA, which is used for existing hard disk drives, to
high-speed PCI express. Since NAND flash memory does not allow in-place
updates, it requires special software called Flash Translation Layer (FTL), and
SSDs are equipped with embedded processors to run FTL. Existing SSDs increase
the clock frequency of embedded processors or increase the number of embedded
processors in order to prevent FTL from acting as bottleneck of SSD
performance, but these approaches are not scalable. This paper proposes a
hardware-automated Flash Map Management Unit, called FMMU, that handles the
address translation process dominating the execution time of the FTL by
hardware automation. FMMU provides methods for exploiting the parallelism of
flash memory by processing outstanding requests in a non-blocking manner while
reducing the number of flash operations. The experimental results show that the
FMMU reduces the FTL execution time in the map cache hit case and the miss case
by 44% and 37%, respectively, compared with the existing software-based
approach operating in 4-core. FMMU also prevents FTL from acting as a
performance bottleneck for up to 32-channel, 8-way SSD using PCIe 3.0 x32 host
interface.
"
731,Architectural Techniques to Enable Reliable and Scalable Memory Systems,"  High capacity and scalable memory systems play a vital role in enabling our
desktops, smartphones, and pervasive technologies like Internet of Things
(IoT). Unfortunately, memory systems are becoming increasingly prone to faults.
This is because we rely on technology scaling to improve memory density, and at
small feature sizes, memory cells tend to break easily. Today, memory
reliability is seen as the key impediment towards using high-density devices,
adopting new technologies, and even building the next Exascale supercomputer.
To ensure even a bare-minimum level of reliability, present-day solutions tend
to have high performance, power and area overheads. Ideally, we would like
memory systems to remain robust, scalable, and implementable while keeping the
overheads to a minimum. This dissertation describes how simple cross-layer
architectural techniques can provide orders of magnitude higher reliability and
enable seamless scalability for memory systems while incurring negligible
overheads.
"
732,In-Datacenter Performance Analysis of a Tensor Processing Unit,"  Many architects believe that major improvements in cost-energy-performance
must now come from domain-specific hardware. This paper evaluates a custom
ASIC---called a Tensor Processing Unit (TPU)---deployed in datacenters since
2015 that accelerates the inference phase of neural networks (NN). The heart of
the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak
throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed
on-chip memory. The TPU's deterministic execution model is a better match to
the 99th-percentile response-time requirement of our NN applications than are
the time-varying optimizations of CPUs and GPUs (caches, out-of-order
execution, multithreading, multiprocessing, prefetching, ...) that help average
throughput more than guaranteed latency. The lack of such features helps
explain why, despite having myriad MACs and a big memory, the TPU is relatively
small and low power. We compare the TPU to a server-class Intel Haswell CPU and
an Nvidia K80 GPU, which are contemporaries deployed in the same datacenters.
Our workload, written in the high-level TensorFlow framework, uses production
NN applications (MLPs, CNNs, and LSTMs) that represent 95% of our datacenters'
NN inference demand. Despite low utilization for some applications, the TPU is
on average about 15X - 30X faster than its contemporary GPU or CPU, with
TOPS/Watt about 30X - 80X higher. Moreover, using the GPU's GDDR5 memory in the
TPU would triple achieved TOPS and raise TOPS/Watt to nearly 70X the GPU and
200X the CPU.
"
733,"A Study on Performance and Power Efficiency of Dense Non-Volatile Caches
  in Multi-Core Systems","  In this paper, we present a novel cache design based on Multi-Level Cell
Spin-Transfer Torque RAM (MLC STTRAM) that can dynamically adapt the set
capacity and associativity to use efficiently the full potential of MLC STTRAM.
We exploit the asymmetric nature of the MLC storage scheme to build cache lines
featuring heterogeneous performances, that is, half of the cache lines are
read-friendly, while the other is write-friendly. Furthermore, we propose to
opportunistically deactivate ways in underutilized sets to convert MLC to
Single-Level Cell (SLC) mode, which features overall better performance and
lifetime. Our ultimate goal is to build a cache architecture that combines the
capacity advantages of MLC and performance/energy advantages of SLC. Our
experiments show an improvement of 43% in total numbers of conflict misses, 27%
in memory access latency, 12% in system performance, and 26% in LLC access
energy, with a slight degradation in cache lifetime (about 7%) compared to an
SLC cache.
"
734,"Exploiting Data Longevity for Enhancing the Lifetime of Flash-based
  Storage Class Memory","  Storage-class memory (SCM) combines the benefits of a solid-state memory,
such as high-performance and robustness, with the archival capabilities and low
cost of conventional hard-disk magnetic storage. Among candidate solid-state
nonvolatile memory technologies that could potentially be used to construct
SCM, flash memory is a well-established technology and have been widely used in
commercially available SCM incarnations. Flash-based SCM enables much better
tradeoffs between performance, space and power than disk-based systems.
However, write endurance is a significant challenge for a flash-based SCM (each
act of writing a bit may slightly damage a cell, so one flash cell can be
written 10^4--10^5 times, depending on the flash technology, before it becomes
unusable). This is a well-documented problem and has received a lot of
attention by manufactures that are using some combination of write reduction
and wear-leveling techniques for achieving longer lifetime. In an effort to
improve flash lifetime, first, by quantifying data longevity in an SCM, we show
that a majority of the data stored in a solid-state SCM do not require long
retention times provided by flash memory (i.e., up to 10 years in modern
devices); second, by exploiting retention time relaxation, we propose a novel
mechanism, called Dense-SLC (D-SLC), which enables us perform multiple writes
into a cell during each erase cycle for lifetime extension; and finally, we
discuss the required changes in the flash management software (FTL) in order to
use this characteristic for extending the lifetime of the solid-state part of
an SCM. Using an extensive simulation-based analysis of a flash-based SCM, we
demonstrate that D-SLC is able to significantly improve device lifetime
(between 5.1X and 8.6X) with no performance overhead and also very small
changes at the FTL software.
"
735,"Asynchronous Early Output Dual-Bit Full Adders Based on Homogeneous and
  Heterogeneous Delay-Insensitive Data Encoding","  This paper presents the designs of asynchronous early output dual-bit full
adders without and with redundant logic (implicit) corresponding to homogeneous
and heterogeneous delay-insensitive data encoding. For homogeneous
delay-insensitive data encoding only dual-rail i.e. 1-of-2 code is used, and
for heterogeneous delay-insensitive data encoding 1-of-2 and 1-of-4 codes are
used. The 4-phase return-to-zero protocol is used for handshaking. To
demonstrate the merits of the proposed dual-bit full adder designs, 32-bit
ripple carry adders (RCAs) are constructed comprising dual-bit full adders. The
proposed dual-bit full adders based 32-bit RCAs incorporating redundant logic
feature reduced latency and area compared to their non-redundant counterparts
with no accompanying power penalty. In comparison with the weakly indicating
32-bit RCA constructed using homogeneously encoded dual-bit full adders
containing redundant logic, the early output 32-bit RCA comprising the proposed
homogeneously encoded dual-bit full adders with redundant logic reports
corresponding reductions in latency and area by 22.2% and 15.1% with no
associated power penalty. On the other hand, the early output 32-bit RCA
constructed using the proposed heterogeneously encoded dual-bit full adder
which incorporates redundant logic reports respective decreases in latency and
area than the weakly indicating 32-bit RCA that consists of heterogeneously
encoded dual-bit full adders with redundant logic by 21.5% and 21.3% with nil
power overhead. The simulation results obtained are based on a 32/28nm CMOS
process technology.
"
736,"An Efficient Reconfigurable FIR Digital Filter Using Modified Distribute
  Arithmetic Technique","  This paper provides modified Distributed Arithmetic based technique to
compute sum of products saving appreciable number of Multiply And accumulation
blocks and this consecutively reduces circuit size. In this technique
multiplexer based structure is used to reuse the blocks so as to reduce the
required memory locations. In this technique a Carry Look Ahead based adder
tree is used to have better area-delay product. Designing of FIR filter is done
using VHDL and synthesized using Xilinx 12.2 synthesis tool and ISIM simulator.
The power analysis is done using Xilinx Xpower analyzer. The proposed structure
requires nearly 42% less cells, 40% less LUT flip-flop pairs used, and also 2%
less power compared with existing structure.
"
737,"Proceedings of the 3rd International Workshop on Overlay Architectures
  for FPGAs (OLAF 2017)","  The 3rd International Workshop on Overlay Architectures for FPGAs (OLAF 2017)
was held on 22 Feb, 2017 as a co-located workshop at the 25th ACM/SIGDA
International Symposium on Field-Programmable Gate Arrays (FPGA 2017). This
year, the program committee selected 3 papers and 3 extended abstracts to be
presented at the workshop, which are subsequently collected in this online
volume.
"
738,"A floating point division unit based on Taylor-Series expansion
  algorithm and Iterative Logarithmic Multiplier","  Floating point division, even though being an infrequent operation in the
traditional sense, is indis- pensable when it comes to a range of
non-traditional applications such as K-Means Clustering and QR Decomposition
just to name a few. In such applications, hardware support for floating point
division would boost the performance of the entire system. In this paper, we
present a novel architecture for a floating point division unit based on the
Taylor-series expansion algorithm. We show that the Iterative Logarithmic
Multiplier is very well suited to be used as a part of this architecture. We
propose an implementation of the powering unit that can calculate an odd power
and an even power of a number simultaneously, meanwhile having little hardware
overhead when compared to the Iterative Logarithmic Multiplier.
"
739,"Compressing DMA Engine: Leveraging Activation Sparsity for Training Deep
  Neural Networks","  Popular deep learning frameworks require users to fine-tune their memory
usage so that the training data of a deep neural network (DNN) fits within the
GPU physical memory. Prior work tries to address this restriction by
virtualizing the memory usage of DNNs, enabling both CPU and GPU memory to be
utilized for memory allocations. Despite its merits, virtualizing memory can
incur significant performance overheads when the time needed to copy data back
and forth from CPU memory is higher than the latency to perform the
computations required for DNN forward and backward propagation. We introduce a
high-performance virtualization strategy based on a ""compressing DMA engine""
(cDMA) that drastically reduces the size of the data structures that are
targeted for CPU-side allocations. The cDMA engine offers an average 2.6x
(maximum 13.8x) compression ratio by exploiting the sparsity inherent in
offloaded data, improving the performance of virtualized DNNs by an average 32%
(maximum 61%).
"
740,"Pixie: A heterogeneous Virtual Coarse-Grained Reconfigurable Array for
  high performance image processing applications","  Coarse-Grained Reconfigurable Arrays (CGRAs) enable ease of programmability
and result in low development costs. They enable the ease of use specifically
in reconfigurable computing applications. The smaller cost of compilation and
reduced reconfiguration overhead enables them to become attractive platforms
for accelerating high-performance computing applications such as image
processing. The CGRAs are ASICs and therefore, expensive to produce. However,
Field Programmable Gate Arrays (FPGAs) are relatively cheaper for low volume
products but they are not so easily programmable. We combine best of both
worlds by implementing a Virtual Coarse-Grained Reconfigurable Array (VCGRA) on
FPGA. VCGRAs are a trade off between FPGA with large routing overheads and
ASICs. In this perspective we present a novel heterogeneous Virtual
Coarse-Grained Reconfigurable Array (VCGRA) called ""Pixie"" which is suitable
for implementing high performance image processing applications. The proposed
VCGRA contains generic processing elements and virtual channels that are
described using the Hardware Description Language VHDL. Both elements have been
optimized by using the parameterized configuration tool flow and result in a
resource reduction of 24% for each processing elements and 82% for each virtual
channels respectively.
"
741,Static Timing Model Extraction for Combinational Circuits,"  For large circuits, static timing analysis (STA) needs to be performed in a
hierarchical manner to achieve higher performance in arrival time propagation.
In hierarchical STA, efficient and accurate timing models of sub-modules need
to be created. We propose a timing model extraction method that significantly
reduces the size of timing models without losing any accuracy by removing
redundant timing information. Circuit components which do not contribute to the
delay of any input to output pair are removed. The proposed method is
deterministic. Compared to the original models, the numbers of edges and
vertices of the resulting timing models are reduced by 84% and 85% on average,
respectively, which are significantly more than the results achieved by other
methods.
"
742,"Resource-Aware Just-in-Time OpenCL Compiler for Coarse-Grained FPGA
  Overlays","  FPGA vendors have recently started focusing on OpenCL for FPGAs because of
its ability to leverage the parallelism inherent to heterogeneous computing
platforms. OpenCL allows programs running on a host computer to launch
accelerator kernels which can be compiled at run-time for a specific
architecture, thus enabling portability. However, the prohibitive compilation
times (specifically the FPGA place and route times) are a major stumbling block
when using OpenCL tools from FPGA vendors. The long compilation times mean that
the tools cannot effectively use just-in-time (JIT) compilation or runtime
performance scaling. Coarse-grained overlays represent a possible solution by
virtue of their coarse granularity and fast compilation. In this paper, we
present a methodology for run-time compilation of OpenCL kernels to a DSP block
based coarse-grained overlay, rather than directly to the fine-grained FPGA
fabric. The proposed methodology allows JIT compilation and on-demand
resource-aware kernel replication to better utilize available overlay
resources, raising the abstraction level while reducing compile times
significantly. We further demonstrate that this approach can even be used for
run-time compilation of OpenCL kernels on the ARM processor of the embedded
heterogeneous Zynq device.
"
743,"A Scalable, Low-Overhead Finite-State Machine Overlay for Rapid FPGA
  Application Development","  Productivity issues such as lengthy compilation and limited code reuse have
restricted usage of field-programmable gate arrays (FPGAs), despite significant
technical advantages. Recent work into overlays -- virtual coarse-grained
architectures implemented atop FPGAs -- has aimed to address these concerns
through abstraction, but have mostly focused on pipelined applications with
minimal control requirements. Although research has introduced overlays for
finite-state machines, those architectures suffer from limited scalability and
flexibility, which we address with a new overlay architecture using memory
decomposition on transitional logic. Although our overlay provides modest
average improvements of 15% to 29% fewer lookup tables for individual
finite-state machines, for the more common usage of an overlay supporting
different finite-state machines, our overlay achieves a 77% to 99% reduction in
lookup tables. In addition, our overlay reduces compilation time to tenths of a
second to enable rapid iterative-development methodologies.
"
744,Out-of-Order Dataflow Scheduling for FPGA Overlays,"  We exploit floating-point DSPs in the Arria10 FPGA and multi-pumping feature
of the M20K RAMs to build a dataflow-driven soft processor fabric for large
graph workloads. In this paper, we introduce the idea of out-of-order node
scheduling across a large number of local nodes (thousands) per processor by
combining an efficient node tagging scheme along with leading-one detector
circuits. We use a static one-time node labeling algorithm to sort nodes based
on criticality to organize local memory inside each soft processor. This
translates to a small ~6% memory overhead. When compared to a memory-expensive
FIFO-based first-come-first-serve approach used in previous studies, we deliver
up to 50% performance improvement while eliminating the cost of the FIFOs. On
the Arria10 10AX115S board, we can create an overlay design of up to 300
processors connected by high bandwidth Hoplite NoC at frequencies up to 250MHz.
"
745,"Improving the Performance and Endurance of Persistent Memory with
  Loose-Ordering Consistency","  Persistent memory provides high-performance data persistence at main memory.
Memory writes need to be performed in strict order to satisfy storage
consistency requirements and enable correct recovery from system crashes.
Unfortunately, adhering to such a strict order significantly degrades system
performance and persistent memory endurance. This paper introduces a new
mechanism, Loose-Ordering Consistency (LOC), that satisfies the ordering
requirements at significantly lower performance and endurance loss. LOC
consists of two key techniques. First, Eager Commit eliminates the need to
perform a persistent commit record write within a transaction. We do so by
ensuring that we can determine the status of all committed transactions during
recovery by storing necessary metadata information statically with blocks of
data written to memory. Second, Speculative Persistence relaxes the write
ordering between transactions by allowing writes to be speculatively written to
persistent memory. A speculative write is made visible to software only after
its associated transaction commits. To enable this, our mechanism supports the
tracking of committed transaction ID and multi-versioning in the CPU cache. Our
evaluations show that LOC reduces the average performance overhead of memory
persistence from 66.9% to 34.9% and the memory write traffic overhead from
17.1% to 3.4% on a variety of workloads.
"
746,"Sprinkler: Maximizing Resource Utilization in Many-Chip Solid State
  Disks","  Resource utilization is one of the emerging problems in many-chip SSDs. In
this paper, we propose Sprinkler, a novel device-level SSD controller, which
targets maximizing resource utilization and achieving high performance without
additional NAND flash chips. Specifically, Sprinkler relaxes parallelism
dependency by scheduling I/O requests based on internal resource layout rather
than the order imposed by the device-level queue. In addition, Sprinkler
improves flash-level parallelism and reduces the number of transactions (i.e.,
improves transactional-locality) by over-committing flash memory requests to
specific resources. Our extensive experimental evaluation using a
cycle-accurate large-scale SSD simulation framework shows that a many-chip SSD
equipped with our Sprinkler provides at least 56.6% shorter latency and 1.8 ~
2.2 times better throughput than the state-of-the-art SSD controllers. Further,
it improves overall resource utilization by 68.8% under different I/O request
patterns and provides, on average, 80.2% more flash-level parallelism by
reducing half of the flash memory requests at runtime.
"
747,On Hierarchical Statistical Static Timing Analysis,"  Statistical static timing analysis deals with the increasing variations in
manufacturing processes to reduce the pessimism in the worst case timing
analysis. Because of the correlation between delays of circuit components,
timing model generation and hierarchical timing analysis face more challenges
than in static timing analysis. In this paper, a novel method to generate
timing models for combinational circuits considering variations is proposed.
The resulting timing models have accurate input-output delays and are about 80%
smaller than the original circuits. Additionally, an accurate hierarchical
timing analysis method at design level using pre-characterized timing models is
proposed. This method incorporates the correlation between modules by replacing
independent random variables to improve timing accuracy. Experimental results
show that the correlation between modules strongly affects the delay
distribution of the hierarchical design and the proposed method has good
accuracy compared with Monte Carlo simulation, but is faster by three orders of
magnitude.
"
748,"Timing Model Extraction for Sequential Circuits Considering Process
  Variations","  As semiconductor devices continue to scale down, process vari- ations become
more relevant for circuit design. Facing such variations, statistical static
timing analysis is introduced to model variations more accurately so that the
pessimism in tra- ditional worst case timing analysis is reduced. Because all
de- lays are modeled using correlated random variables, most statis- tical
timing methods are much slower than corner based timing analysis. To speed up
statistical timing analysis, we propose a method to extract timing models for
flip-flop and latch based sequential circuits respectively. When such a circuit
is used as a module in a hierarchical design, the timing model instead of the
original circuit is used for timing analysis. The extracted timing models are
much smaller than the original circuits. Ex- periments show that using
extracted timing models accelerates timing verification by orders of magnitude
compared to previ- ous approaches using flat netlists directly. Accuracy is
main- tained, however, with the mean and standard deviation of the clock period
both showing usually less than 1% error compared to Monte Carlo simulation on a
number of benchmark circuits.
"
749,"Fast Statistical Timing Analysis for Circuits with Post-Silicon Tunable
  Clock Buffers","  Post-Silicon Tunable (PST) clock buffers are widely used in high performance
designs to counter process variations. By allowing delay compensation between
consecutive register stages, PST buffers can effectively improve the yield of
digital circuits. To date, the evaluation of manufacturing yield in the
presence of PST buffers is only possible using Monte Carlo simulation. In this
paper, we propose an alternative method based on graph transformations, which
is much faster, more than 1000 times, and computes a parametric minimum clock
period. It also identifies the gates which are most critical to the circuit
performance, therefore enabling a fast analysis-optimization flow.
"
750,On Timing Model Extraction and Hierarchical Statistical Timing Analysis,"  In this paper, we investigate the challenges to apply Statistical Static
Timing Analysis (SSTA) in hierarchical design flow, where modules supplied by
IP vendors are used to hide design details for IP protection and to reduce the
complexity of design and verification. For the three basic circuit types,
combinational, flip-flop-based and latch-controlled, we propose methods to
extract timing models which contain interfacing as well as compressed internal
constraints. Using these compact timing models the runtime of full-chip timing
analysis can be reduced, while circuit details from IP vendors are not exposed.
We also propose a method to reconstruct the correlation between modules during
full-chip timing analysis. This correlation can not be incorporated into timing
models because it depends on the layout of the corresponding modules in the
chip. In addition, we investigate how to apply the extracted timing models with
the reconstructed correlation to evaluate the performance of the complete
design. Experiments demonstrate that using the extracted timing models and
reconstructed correlation full-chip timing analysis can be several times faster
than applying the flattened circuit directly, while the accuracy of statistical
timing analysis is still well maintained.
"
751,"Post-Route Refinement for High-Frequency PCBs Considering Meander
  Segment Alleviation","  In this paper, we propose a post-processing framework which iteratively
refines the routing results from an existing PCB router by removing dense
meander segments. By swapping and detouring dense meander segments the proposed
method can effectively alleviate accumulating crosstalk noise, while respecting
pre-defined area constraints. Experimental results show more than 85% reduction
of the meander segments and hence the noise cost.
"
752,"Post-Route Alleviation of Dense Meander Segments in High-Performance
  Printed Circuit Boards","  Length-matching is an important technique to balance delays of bus signals in
high-performance PCB routing. Existing routers, however, may generate dense
meander segments with small distance. Signals propagating across these meander
segments exhibit a speedup effect due to crosstalks between the segments of the
same wire, thus leading to mismatch of arrival times even with the same
physical wire length. In this paper, we propose a post-processing method to
enlarge the width and the distance of meander segments and distribute them more
evenly on the board so that the crosstalks can be reduced. In the proposed
framework, we model the sharing combinations of available routing areas after
removing dense meander segments from the initial routing, as well as the
generation of relaxed meander segments and their groups in subareas.
Thereafter, this model is transformed into an ILP problem and solved
efficiently. Experimental results show that the proposed method can extend the
width and the distance of meander segments about two times even under very
tight area constraints, so that the crosstalks and thus the speedup effect can
be alleviated effectively in high-performance PCB designs.
"
753,"ILP-based Alleviation of Dense Meander Segments with Prioritized
  Shifting and Progressive Fixing in PCB Routing","  Length-matching is an important technique to bal- ance delays of bus signals
in high-performance PCB routing. Existing routers, however, may generate very
dense meander segments. Signals propagating along these meander segments
exhibit a speedup effect due to crosstalk between the segments of the same
wire, thus leading to mismatch of arrival times even under the same physical
wire length. In this paper, we present a post-processing method to enlarge the
width and the distance of meander segments and hence distribute them more
evenly on the board so that crosstalk can be reduced. In the proposed
framework, we model the sharing of available routing areas after removing dense
meander segments from the initial routing, as well as the generation of relaxed
meander segments and their groups for wire length compensation. This model is
transformed into an ILP problem and solved for a balanced distribution of wire
patterns. In addition, we adjust the locations of long wire segments according
to wire priorities to swap free spaces toward critical wires that need much
length compensation. To reduce the problem space of the ILP model, we also
introduce a progressive fixing technique so that wire patterns are grown
gradually from the edge of the routing toward the center area. Experimental
results show that the proposed method can expand meander segments significantly
even under very tight area constraints, so that the speedup effect can be
alleviated effectively in high- performance PCB designs.
"
754,"Statistical Timing Analysis and Criticality Computation for Circuits
  with Post-Silicon Clock Tuning Elements","  Post-silicon clock tuning elements are widely used in high-performance
designs to mitigate the effects of process variations and aging. Located on
clock paths to flip-flops, these tuning elements can be configured through the
scan chain so that clock skews to these flip-flops can be adjusted after man-
ufacturing. Owing to the delay compensation across consecutive register stages
enabled by the clock tuning elements, higher yield and enhanced robustness can
be achieved. These benefits are, nonetheless, attained by increasing die area
due to the inserted clock tuning elements. For balancing performance
improvement and area cost, an efficient timing analysis algorithm is needed to
evaluate the performance of such a circuit. So far this evaluation is only
possible by Monte Carlo simulation which is very timing- consuming. In this
paper, we propose an alternative method using graph transformation, which
computes a parametric minimum clock period and is more than 10 4 times faster
than Monte Carlo simulation while maintaining a good accuracy. This method also
identifies the gates that are critical to circuit performance, so that a fast
analysis-optimization flow becomes possible.
"
755,"Sampling-based Buffer Insertion for Post-Silicon Yield Improvement under
  Process Variability","  At submicron manufacturing technology nodes process variations affect circuit
performance significantly. This trend leads to a large timing margin and thus
overdesign to maintain yield. To combat this pessimism, post-silicon clock
tuning buffers can be inserted into circuits to balance timing budgets of
critical paths with their neighbors. After manufacturing, these clock buffers
can be configured for each chip individually so that chips with timing failures
may be rescued to improve yield. In this paper, we propose a sampling-based
method to determine the proper locations of these buffers. The goal of this
buffer insertion is to reduce the number of buffers and their ranges, while
still maintaining a good yield improvement. Experimental results demonstrate
that our algorithm can achieve a significant yield improvement (up to 35%) with
only a small number of buffers.
"
756,"EffiTest: Efficient Delay Test and Statistical Prediction for
  Configuring Post-silicon Tunable Buffers","  At nanometer manufacturing technology nodes, process variations significantly
affect circuit performance. To combat them, post- silicon clock tuning buffers
can be deployed to balance timing bud- gets of critical paths for each
individual chip after manufacturing. The challenge of this method is that path
delays should be mea- sured for each chip to configure the tuning buffers
properly. Current methods for this delay measurement rely on path-wise
frequency stepping. This strategy, however, requires too much time from ex-
pensive testers. In this paper, we propose an efficient delay test framework
(EffiTest) to solve the post-silicon testing problem by aligning path delays
using the already-existing tuning buffers in the circuit. In addition, we only
test representative paths and the delays of other paths are estimated by
statistical delay prediction. Exper- imental results demonstrate that the
proposed method can reduce the number of frequency stepping iterations by more
than 94% with only a slight yield loss.
"
757,"PieceTimer: A Holistic Timing Analysis Framework Considering Setup/Hold
  Time Interdependency Using A Piecewise Model","  In static timing analysis, clock-to-q delays of flip-flops are considered as
constants. Setup times and hold times are characterized separately and also
used as constants. The characterized delays, setup times and hold times, are
ap- plied in timing analysis independently to verify the perfor- mance of
circuits. In reality, however, clock-to-q delays of flip-flops depend on both
setup and hold times. Instead of being constants, these delays change with
respect to different setup/hold time combinations. Consequently, the simple ab-
straction of setup/hold times and constant clock-to-q delays introduces
inaccuracy in timing analysis. In this paper, we propose a holistic method to
consider the relation between clock-to-q delays and setup/hold time
combinations with a piecewise linear model. The result is more accurate than
that of traditional timing analysis, and the incorporation of the
interdependency between clock-to-q delays, setup times and hold times may also
improve circuit performance.
"
758,"Design-Phase Buffer Allocation for Post-Silicon Clock Binning by
  Iterative Learning","  At submicron manufacturing technology nodes, pro- cess variations affect
circuit performance significantly. To counter these variations, engineers are
reserving more timing margin to maintain yield, leading to an unaffordable
overdesign. Most of these margins, however, are wasted after manufacturing,
because process variations cause only some chips to be really slow, while other
chips can easily meet given timing specifications. To reduce this pessimism, we
can reserve less timing margin and tune failed chips after manufacturing with
clock buffers to make them meet timing specifications. With this post-silicon
clock tuning, critical paths can be balanced with neighboring paths in each
chip specifically to counter the effect of process variations. Consequently,
chips with timing failures can be rescued and the yield can thus be improved.
This is specially useful in high- performance designs, e.g., high-end CPUs,
where clock binning makes chips with higher performance much more profitable.
In this paper, we propose a method to determine where to insert post-silicon
tuning buffers during the design phase to improve the overall profit with clock
binning. This method learns the buffer locations with a Sobol sequence
iteratively and reduces the buffer ranges afterwards with tuning concentration
and buffer grouping. Experimental results demonstrate that the proposed method
can achieve a profit improvement of about 14% on average and up to 26%, with
only a small number of tuning buffers inserted into the circuit.
"
759,SimpleSSD: Modeling Solid State Drives for Holistic System Simulation,"  Existing solid state drive (SSD) simulators unfortunately lack hardware
and/or software architecture models. Consequently, they are far from capturing
the critical features of contemporary SSD devices. More importantly, while the
performance of modern systems that adopt SSDs can vary based on their numerous
internal design parameters and storage-level configurations, a full system
simulation with traditional SSD models often requires unreasonably long
runtimes and excessive computational resources. In this work, we propose
SimpleSSD, a highfidelity simulator that models all detailed characteristics of
hardware and software, while simplifying the nondescript features of storage
internals. In contrast to existing SSD simulators, SimpleSSD can easily be
integrated into publicly-available full system simulators. In addition, it can
accommodate a complete storage stack and evaluate the performance of SSDs along
with diverse memory technologies and microarchitectures. Thus, it facilitates
simulations that explore the full design space at different levels of system
abstraction.
"
760,MultiAmdahl: Optimal Resource Allocation in Heterogeneous Architectures,"  Future multiprocessor chips will integrate many different units, each
tailored to a specific computation. When designing such a system, the chip
architect must decide how to distribute limited system resources such as area,
power, and energy among the computational units. We extend MultiAmdahl, an
analytical optimization technique for resource allocation in heterogeneous
architectures, for energy optimality under a variety of constant system power
scenarios. We conclude that reduction in constant system power should be met by
reallocating resources from general-purpose computing to heterogeneous
accelerator-dominated computing, to keep the overall energy consumption at a
minimum. We extend this conclusion to offer an intuition regarding
energy-optimal resource allocation in data center computing.
"
761,The Effect of Temperature on Amdahl Law in 3D Multicore Era,"  This work studies the influence of temperature on performance and scalability
of 3D Chip Multiprocessors (CMP) from Amdahl law perspective. We find that 3D
CMP may reach its thermal limit before reaching its maximum power. We show that
a high level of parallelism may lead to high peak temperatures even in small
scale 3D CMPs, thus limiting 3D CMP scalability and calling for different,
in-memory computing architectures.
"
762,Cache Hierarchy Optimization,"  Power consumption, off-chip memory bandwidth, chip area and Network on Chip
(NoC) capacity are among main chip resources limiting the scalability of Chip
Multiprocessors (CMP). A closed form analytical solution for optimizing the CMP
cache hierarchy and optimally allocating area among hierarchy levels under such
constrained resources is developed. The optimization framework is extended by
incorporating the impact of data sharing on cache miss rate. An analytical
model for cache access time as a function of cache size is proposed and
verified using CACTI simulation.
"
763,"Some Schemes for Implementation of Arithmetic Operations with Complex
  Numbers Using Squaring Units","  In this paper, new schemes for a squarer, multiplier and divider of complex
numbers are proposed. Traditional structural solutions for each of these
operations require the presence some number of general-purpose binary
multipliers. The advantage of our solutions is a removing of multiplications
through replacing them by less costly squarers. We use Logan's trick and
quarter square technique, which propose to replace the calculation of the
product of two real numbers by summing the squares. Replacing usual multipliers
on digital squares implies reducing power consumption as well as decreases
hardware circuit complexity. The squarer requiring less area and power as
compared to general-purpose multiplier, it is interesting to assess the use of
squarers to implementation of complex arithmetic.
"
764,"A Low-Power Accelerator for Deep Neural Networks with Enlarged Near-Zero
  Sparsity","  It remains a challenge to run Deep Learning in devices with stringent power
budget in the Internet-of-Things. This paper presents a low-power accelerator
for processing Deep Neural Networks in the embedded devices. The power
reduction is realized by avoiding multiplications of near-zero valued data. The
near-zero approximation and a dedicated Near-Zero Approximation Unit (NZAU) are
proposed to predict and skip the near-zero multiplications under certain
thresholds. Compared with skipping zero-valued computations, our design
achieves 1.92X and 1.51X further reduction of the total multiplications in
LeNet-5 and Alexnet respectively, with negligible lose of accuracy. In the
proposed accelerator, 256 multipliers are grouped into 16 independent
Processing Lanes (PL) to support up to 16 neuron activations simultaneously.
With the help of data pre-processing and buffering in each PL, multipliers can
be clock-gated in most of the time even the data is excessively streaming in.
Designed and simulated in UMC 65 nm process, the accelerator operating at 500
MHz is $>$ 4X faster than the mobile GPU Tegra K1 in processing the
fully-connected layer FC8 of Alexnet, while consuming 717X less energy.
"
765,Sparse Matrix Multiplication on CAM Based Accelerator,"  Sparse matrix multiplication is an important component of linear algebra
computations. In this paper, an architecture based on Content Addressable
Memory (CAM) and Resistive Content Addressable Memory (ReCAM) is proposed for
accelerating sparse matrix by sparse vector and matrix multiplication in CSR
format. Using functional simulation, we show that the proposed ReCAM-based
accelerator exhibits two orders of magnitude higher power efficiency as
compared to existing sparse matrix-vector multiplication implementations.
"
766,"Understanding Reduced-Voltage Operation in Modern DRAM Chips:
  Characterization, Analysis, and Mechanisms","  The energy consumption of DRAM is a critical concern in modern computing
systems. Improvements in manufacturing process technology have allowed DRAM
vendors to lower the DRAM supply voltage conservatively, which reduces some of
the DRAM energy consumption. We would like to reduce the DRAM supply voltage
more aggressively, to further reduce energy. Aggressive supply voltage
reduction requires a thorough understanding of the effect voltage scaling has
on DRAM access latency and DRAM reliability.
  In this paper, we take a comprehensive approach to understanding and
exploiting the latency and reliability characteristics of modern DRAM when the
supply voltage is lowered below the nominal voltage level specified by DRAM
standards. Using an FPGA-based testing platform, we perform an experimental
study of 124 real DDR3L (low-voltage) DRAM chips manufactured recently by three
major DRAM vendors. We find that reducing the supply voltage below a certain
point introduces bit errors in the data, and we comprehensively characterize
the behavior of these errors. We discover that these errors can be avoided by
increasing the latency of three major DRAM operations (activation, restoration,
and precharge). We perform detailed DRAM circuit simulations to validate and
explain our experimental findings. We also characterize the various
relationships between reduced supply voltage and error locations, stored data
patterns, DRAM temperature, and data retention.
  Based on our observations, we propose a new DRAM energy reduction mechanism,
called Voltron. The key idea of Voltron is to use a performance model to
determine by how much we can reduce the supply voltage without introducing
errors and without exceeding a user-specified threshold for performance loss.
Voltron reduces the average system energy by 7.3% while limiting the average
system performance loss to only 1.8%, for a variety of workloads.
"
767,"Energy-Efficient Hybrid Stochastic-Binary Neural Networks for
  Near-Sensor Computing","  Recent advances in neural networks (NNs) exhibit unprecedented success at
transforming large, unstructured data streams into compact higher-level
semantic information for tasks such as handwriting recognition, image
classification, and speech recognition. Ideally, systems would employ
near-sensor computation to execute these tasks at sensor endpoints to maximize
data reduction and minimize data movement. However, near- sensor computing
presents its own set of challenges such as operating power constraints, energy
budgets, and communication bandwidth capacities. In this paper, we propose a
stochastic- binary hybrid design which splits the computation between the
stochastic and binary domains for near-sensor NN applications. In addition, our
design uses a new stochastic adder and multiplier that are significantly more
accurate than existing adders and multipliers. We also show that retraining the
binary portion of the NN computation can compensate for precision losses
introduced by shorter stochastic bit-streams, allowing faster run times at
minimal accuracy losses. Our evaluation shows that our hybrid stochastic-binary
design can achieve 9.8x energy efficiency savings, and application-level
accuracies within 0.05% compared to conventional all-binary designs.
"
768,"Demystifying the Characteristics of 3D-Stacked Memories: A Case Study
  for Hybrid Memory Cube","  Three-dimensional (3D)-stacking technology, which enables the integration of
DRAM and logic dies, offers high bandwidth and low energy consumption. This
technology also empowers new memory designs for executing tasks not
traditionally associated with memories. A practical 3D-stacked memory is Hybrid
Memory Cube (HMC), which provides significant access bandwidth and low power
consumption in a small area. Although several studies have taken advantage of
the novel architecture of HMC, its characteristics in terms of latency and
bandwidth or their correlation with temperature and power consumption have not
been fully explored. This paper is the first, to the best of our knowledge, to
characterize the thermal behavior of HMC in a real environment using the AC-510
accelerator and to identify temperature as a new limitation for this
state-of-the-art design space. Moreover, besides bandwidth studies, we
deconstruct factors that contribute to latency and reveal their sources for
high- and low-load accesses. The results of this paper demonstrates essential
behaviors and performance bottlenecks for future explorations of
packet-switched and 3D-stacked memories.
"
769,"LazyPIM: Efficient Support for Cache Coherence in Processing-in-Memory
  Architectures","  Processing-in-memory (PIM) architectures have seen an increase in popularity
recently, as the high internal bandwidth available within 3D-stacked memory
provides greater incentive to move some computation into the logic layer of the
memory. To maintain program correctness, the portions of a program that are
executed in memory must remain coherent with the portions of the program that
continue to execute within the processor. Unfortunately, PIM architectures
cannot use traditional approaches to cache coherence due to the high off-chip
traffic consumed by coherence messages, which, as we illustrate in this work,
can undo the benefits of PIM execution for many data-intensive applications. We
propose LazyPIM, a new hardware cache coherence mechanism designed specifically
for PIM. Prior approaches for coherence in PIM are ill-suited to applications
that share a large amount of data between the processor and the PIM logic.
LazyPIM uses a combination of speculative cache coherence and compressed
coherence signatures to greatly reduce the overhead of keeping PIM coherent
with the processor, even when a large amount of sharing exists.We find that
LazyPIM improves average performance across a range of data-intensive PIM
applications by 19.6%, reduces off-chip traffic by 30.9%, and reduces energy
consumption by 18.0%, over the best prior approaches to PIM coherence.
"
770,Proposal for a High Precision Tensor Processing Unit,"  This whitepaper proposes the design and adoption of a new generation of
Tensor Processing Unit which has the performance of Google's TPU, yet performs
operations on wide precision data. The new generation TPU is made possible by
implementing arithmetic circuits which compute using a new general purpose,
fractional arithmetic based on the residue number system.
"
771,Exploring Computation-Communication Tradeoffs in Camera Systems,"  Cameras are the defacto sensor. The growing demand for real-time and
low-power computer vision, coupled with trends towards high-efficiency
heterogeneous systems, has given rise to a wide range of image processing
acceleration techniques at the camera node and in the cloud. In this paper, we
characterize two novel camera systems that use acceleration techniques to push
the extremes of energy and performance scaling, and explore the
computation-communication tradeoffs in their design. The first case study
targets a camera system designed to detect and authenticate individual faces,
running solely on energy harvested from RFID readers. We design a
multi-accelerator SoC design operating in the sub-mW range, and evaluate it
with real-world workloads to show performance and energy efficiency
improvements over a general purpose microprocessor. The second camera system
supports a 16-camera rig processing over 32 Gb/s of data to produce real-time
3D-360 degree virtual reality video. We design a multi-FPGA processing pipeline
that outperforms CPU and GPU configurations by up to 10x in computation time,
producing panoramic stereo video directly from the camera rig at 30 frames per
second. We find that an early data reduction step, either before complex
processing or offloading, is the most critical optimization for in-camera
systems.
"
772,"Latency Optimized Asynchronous Early Output Ripple Carry Adder based on
  Delay-Insensitive Dual-Rail Data Encoding","  Asynchronous circuits employing delay-insensitive codes for data
representation i.e. encoding and following a 4-phase return-to-zero protocol
for handshaking are generally robust. Depending upon whether a single
delay-insensitive code or multiple delay-insensitive code(s) are used for data
encoding, the encoding scheme is called homogeneous or heterogeneous
delay-insensitive data encoding. This article proposes a new latency optimized
early output asynchronous ripple carry adder (RCA) that utilizes single-bit
asynchronous full adders (SAFAs) and dual-bit asynchronous full adders (DAFAs)
which incorporate redundant logic and are based on the delay-insensitive
dual-rail code i.e. homogeneous data encoding, and follow a 4-phase
return-to-zero handshaking. Amongst various RCA, carry lookahead adder (CLA),
and carry select adder (CSLA) designs, which are based on homogeneous or
heterogeneous delay-insensitive data encodings which correspond to the
weak-indication or the early output timing model, the proposed early output
asynchronous RCA that incorporates SAFAs and DAFAs with redundant logic is
found to result in reduced latency for a dual-operand addition operation. In
particular, for a 32-bit asynchronous RCA, utilizing 15 stages of DAFAs and 2
stages of SAFAs leads to reduced latency. The theoretical worst-case latencies
of the different asynchronous adders were calculated by taking into account the
typical gate delays of a 32/28nm CMOS digital cell library, and a comparison is
made with their practical worst-case latencies estimated. The theoretical and
practical worst-case latencies show a close correlation....
"
773,"HourGlass: Predictable Time-based Cache Coherence Protocol for
  Dual-Critical Multi-Core Systems","  We present a hardware mechanism called HourGlass to predictably share data in
a multi-core system where cores are explicitly designated as critical or
non-critical. HourGlass is a time-based cache coherence protocol for
dual-critical multi-core systems that ensures worst-case latency (WCL) bounds
for memory requests originating from critical cores. Although HourGlass does
not provide either WCL or bandwidth guarantees for memory requests from
non-critical cores, it promotes the use of timers to improve its bandwidth
utilization while still maintaining WCL bounds for critical cores. This
encourages a trade-off between the WCL bounds for critical cores, and the
improved memory bandwidth for non-critical cores via timer configurations. We
evaluate HourGlass using gem5, and with multithreaded benchmark suites
including SPLASH-2, and synthetic workloads. Our results show that the WCL for
critical cores with HourGlass is always within the analytical WCL bounds, and
provides a tighter WCL bound on critical cores compared to the state-of-the-art
real-time cache coherence protocol. Further, we show that HourGlass enables a
trade-off between provable WCL bounds for critical cores, and improved
bandwidth utilization for non-critical cores. The average-case performance of
HourGlass is comparable to the state-of-the-art real-time cache coherence
protocol, and suffers a slowdown of 1.43x and 1.46x compared to the
conventional MSI and MESI protocols.
"
774,"Loom: Exploiting Weight and Activation Precisions to Accelerate
  Convolutional Neural Networks","  Loom (LM), a hardware inference accelerator for Convolutional Neural Networks
(CNNs) is presented. In LM every bit of data precision that can be saved
translates to proportional performance gains. Specifically, for convolutional
layers LM's execution time scales inversely proportionally with the precisions
of both weights and activations. For fully-connected layers LM's performance
scales inversely proportionally with the precision of the weights. LM targets
area- and bandwidth-constrained System-on-a-Chip designs such as those found on
mobile devices that cannot afford the multi-megabyte buffers that would be
needed to store each layer on-chip. Accordingly, given a data bandwidth budget,
LM boosts energy efficiency and performance over an equivalent bit-parallel
accelerator. For both weights and activations LM can exploit profile-derived
perlayer precisions. However, at runtime LM further trims activation precisions
at a much smaller than a layer granularity. Moreover, it can naturally exploit
weight precision variability at a smaller granularity than a layer. On average,
across several image classification CNNs and for a configuration that can
perform the equivalent of 128 16b x 16b multiply-accumulate operations per
cycle LM outperforms a state-of-the-art bit-parallel accelerator [1] by 4.38x
without any loss in accuracy while being 3.54x more energy efficient. LM can
trade-off accuracy for additional improvements in execution performance and
energy efficiency and compares favorably to an accelerator that targeted only
activation precisions. We also study 2- and 4-bit LM variants and find the the
2-bit per cycle variant is the most energy efficient.
"
775,"Error Characterization, Mitigation, and Recovery in Flash Memory Based
  Solid-State Drives","  NAND flash memory is ubiquitous in everyday life today because its capacity
has continuously increased and cost has continuously decreased over decades.
This positive growth is a result of two key trends: (1) effective process
technology scaling, and (2) multi-level (e.g., MLC, TLC) cell data coding.
Unfortunately, the reliability of raw data stored in flash memory has also
continued to become more difficult to ensure, because these two trends lead to
(1) fewer electrons in the flash memory cell (floating gate) to represent the
data and (2) larger cell-to-cell interference and disturbance effects. Without
mitigation, worsening reliability can reduce the lifetime of NAND flash memory.
As a result, flash memory controllers in solid-state drives (SSDs) have become
much more sophisticated: they incorporate many effective techniques to ensure
the correct interpretation of noisy data stored in flash memory cells.
  In this article, we review recent advances in SSD error characterization,
mitigation, and data recovery techniques for reliability and lifetime
improvement. We provide rigorous experimental data from state-of-the-art MLC
and TLC NAND flash devices on various types of flash memory errors, to motivate
the need for such techniques. Based on the understanding developed by the
experimental characterization, we describe several mitigation and recovery
techniques, including (1) cell-to-cell interference mitigation, (2) optimal
multi-level cell sensing, (3) error correction using state-of-the-art
algorithms and methods, and (4) data recovery when error correction fails. We
quantify the reliability improvement provided by each of these techniques.
Looking forward, we briefly discuss how flash memory and these techniques could
evolve into the future.
"
776,Using ECC DRAM to Adaptively Increase Memory Capacity,"  Modern DRAM modules are often equipped with hardware error correction
capabilities, especially for DRAM deployed in large-scale data centers, as
process technology scaling has increased the susceptibility of these devices to
errors. To provide fast error detection and correction, error-correcting codes
(ECC) are placed on an additional DRAM chip in a DRAM module. This additional
chip expands the raw capacity of a DRAM module by 12.5%, but the applications
are unable to use any of this extra capacity, as it is used exclusively to
provide reliability for all data. In reality, there are a number of
applications that do not need such strong reliability for all their data
regions (e.g., some user batch jobs executing on a public cloud), and can
instead benefit from using additional DRAM capacity to store extra data. Our
goal in this work is to provide the additional capacity within an ECC DRAM
module to applications when they do not need the high reliability of error
correction.
  In this paper, we propose Capacity- and Reliability-Adaptive Memory (CREAM),
a hardware mechanism that adapts error correcting DRAM modules to offer
multiple levels of error protection, and provides the capacity saved from using
weaker protection to applications. For regions of memory that do not require
strong error correction, we either provide no ECC protection or provide error
detection using multibit parity. We evaluate several layouts for arranging the
data within ECC DRAM in these reduced-protection modes, taking into account the
various trade-offs exposed from exploiting the extra chip. Our experiments show
that the increased capacity provided by CREAM improves performance by 23.0% for
a memory caching workload, and by 37.3% for a commercial web search workload
executing production query traces. In addition, CREAM can increase bank-level
parallelism within DRAM, offering further performance improvements.
"
777,"Fast Processing of Large Graph Applications Using Asynchronous
  Architecture","  Graph algorithms and techniques are increasingly being used in scientific and
commercial applications to express relations and explore large data sets.
Although conventional or commodity computer architectures, like CPU or GPU, can
compute fairly well dense graph algorithms, they are often inadequate in
processing large sparse graph applications. Memory access patterns, memory
bandwidth requirements and on-chip network communications in these applications
do not fit in the conventional program execution flow. In this work, we propose
and design a new architecture for fast processing of large graph applications.
To leverage the lack of the spatial and temporal localities in these
applications and to support scalable computational models, we design the
architecture around two key concepts. (1) The architecture is a multicore
processor of independently clocked processing elements. These elements
communicate in a self-timed manner and use handshaking to perform
synchronization, communication, and sequencing of operations. By being
asynchronous, the operating speed at each processing element is determined by
actual local latencies rather than global worst-case latencies. We create a
specialized ISA to support these operations. (2) The application compilation
and mapping process uses a graph clustering algorithm to optimize parallel
computing of graph operations and load balancing. Through the clustering
process, we make scalability an inherent property of the architecture where
task-to-element mapping can be done at the graph node level or at node cluster
level. A prototyped version of the architecture outperforms a comparable CPU by
10~20x across all benchmarks and provides 2~5x better power efficiency when
compared to a GPU.
"
778,Pipelined Parallel FFT Architecture,"  In this paper, an optimized efficient VLSI architecture of a pipeline Fast
Fourier transform (FFT) processor capable of producing the reverse output order
sequence is presented. Paper presents Radix-2 multipath delay architecture for
FFT calculation. The implementation of FFT in hardware is very critical because
for calculation of FFT number of butterfly operations i.e. number of
multipliers requires due to which hardware gets increased means indirectly cost
of hardware is automatically gets increased. Also multiplier operations are
slow that's why it limits the speed of operation of architecture. The optimized
VLSI implementation of FFT algorithm is presented in this paper. Here
architecture is pipelined to optimize it and to increase the speed of
operation. Also to increase the speed of operation 2 levels parallel processing
is used.
"
779,"A Reconfigurable Streaming Deep Convolutional Neural Network Accelerator
  for Internet of Things","  Convolutional neural network (CNN) offers significant accuracy in image
detection. To implement image detection using CNN in the internet of things
(IoT) devices, a streaming hardware accelerator is proposed. The proposed
accelerator optimizes the energy efficiency by avoiding unnecessary data
movement. With unique filter decomposition technique, the accelerator can
support arbitrary convolution window size. In addition, max pooling function
can be computed in parallel with convolution by using separate pooling unit,
thus achieving throughput improvement. A prototype accelerator was implemented
in TSMC 65nm technology with a core size of 5mm2. The accelerator can support
major CNNs and achieve 152GOPS peak throughput and 434GOPS/W energy efficiency
at 350mW, making it a promising hardware accelerator for intelligent IoT
devices.
"
780,Variable Instruction Fetch Rate to Reduce Control Dependent Penalties,"  In order to overcome the branch execution penalties of hard-to-predict
instruction branches, two new instruction fetch micro-architectural methods are
proposed in this paper. In addition, to compare performance of the two proposed
methods, different instruction fetch policy schemes of existing multi-branch
path architectures are evaluated. An improvement in Instructions Per Cycle
(IPC) of 29.4% on average over single-thread execution with gshare branch
predictor on SPEC 2000/2006 benchmark is shown. In this paper, wide pipeline
machines are simulated for evaluation purposes. The methods discussed in this
paper can be extended to High Performance Scientific Computing needs, if the
demands of IPC improvement are far more critical than $cost.
"
781,"The Normalized Singular Value Decomposition of Non-Symmetric Matrices
  Using Givens fast Rotations","  In this paper we introduce the algorithm and the fixed point hardware to
calculate the normalized singular value decomposition of a non-symmetric
matrices using Givens fast (approximate) rotations. This algorithm only uses
the basic combinational logic modules such as adders, multiplexers, encoders,
Barrel shifters (B-shifters), and comparators and does not use any lookup
table. This method in fact combines the iterative properties of singular value
decomposition method and CORDIC method in one single iteration. The introduced
architecture is a systolic architecture that uses two different types of
processors, diagonal and non-diagonal processors. The diagonal processor
calculates, transmits and applies the horizontal and vertical rotations, while
the non-diagonal processor uses a fully combinational architecture to receive,
and apply the rotations. The diagonal processor uses priority encoders, Barrel
shifters, and comparators to calculate the rotation angles. Both processors use
a series of adders to apply the rotation angles. The design presented in this
work provides $2.83\sim649$ times better energy per matrix performance compared
to the state of the art designs. This performance achieved without the
employment of pipelining; a better performance advantage is expected to be
achieved employing pipelining.
"
782,"Deterministic Memory Abstraction and Supporting Multicore System
  Architecture","  Poor time predictability of multicore processors has been a long-standing
challenge in the real-time systems community. In this paper, we make a case
that a fundamental problem that prevents efficient and predictable real-time
computing on multicore is the lack of a proper memory abstraction to express
memory criticality, which cuts across various layers of the system: the
application, OS, and hardware. We, therefore, propose a new holistic resource
management approach driven by a new memory abstraction, which we call
Deterministic Memory. The key characteristic of deterministic memory is that
the platform - the OS and hardware - guarantees small and tightly bounded
worst-case memory access timing. In contrast, we call the conventional memory
abstraction as best-effort memory in which only highly pessimistic worst-case
bounds can be achieved. We propose to utilize both abstractions to achieve high
time predictability but without significantly sacrificing performance. We
present deterministic memory-aware OS and architecture designs, including
OS-level page allocator, hardware-level cache, and DRAM controller designs. We
implement the proposed OS and architecture extensions on Linux and gem5
simulator. Our evaluation results, using a set of synthetic and real-world
benchmarks, demonstrate the feasibility and effectiveness of our approach.
"
783,"Performance Implications of NoCs on 3D-Stacked Memories: Insights from
  the Hybrid Memory Cube","  Memories that exploit three-dimensional (3D)-stacking technology, which
integrate memory and logic dies in a single stack, are becoming popular. These
memories, such as Hybrid Memory Cube (HMC), utilize a network-on-chip (NoC)
design for connecting their internal structural organizations. This novel usage
of NoC, in addition to aiding processing-in-memory capabilities, enables
numerous benefits such as high bandwidth and memory-level parallelism. However,
the implications of NoCs on the characteristics of 3D-stacked memories in terms
of memory access latency and bandwidth have not been fully explored. This paper
addresses this knowledge gap by (i) characterizing an HMC prototype on the
AC-510 accelerator board and revealing its access latency behaviors, and (ii)
by investigating the implications of such behaviors on system and software
designs.
"
784,"Real-Time Impulse Noise Removal from MR Images for Radiosurgery
  Applications","  In the recent years image processing techniques are used as a tool to improve
detection and diagnostic capabilities in the medical applications. Medical
applications have been so much affected by these techniques which some of them
are embedded in medical instruments such as MRI, CT and other medical devices.
Among these techniques, medical image enhancement algorithms play an essential
role in removal of the noise which can be produced by medical instruments and
during image transfer. It has been proved that impulse noise is a major type of
noise, which is produced during medical operations, such as MRI, CT, and
angiography, by their image capturing devices. An embeddable hardware module
which is able to denoise medical images before and during surgical operations
could be very helpful. In this paper an accurate algorithm is proposed for
real-time removal of impulse noise in medical images. All image blocks are
divided into three categories of edge, smooth, and disordered areas. A
different reconstruction method is applied to each category of blocks for the
purpose of noise removal. The proposed method is tested on MR images.
Simulation results show acceptable denoising accuracy for various levels of
noise. Also an FPAG implementation of our denoising algorithm shows acceptable
hardware resource utilization. Hence, the algorithm is suitable for embedding
in medical hardware instruments such as radiosurgery devices.
"
785,"Redundant Logic Insertion and Fault Tolerance Improvement in
  Combinational Circuits","  This paper presents a novel method to identify and insert redundant logic
into a combinational circuit to improve its fault tolerance without having to
replicate the entire circuit as is the case with conventional redundancy
techniques. In this context, it is discussed how to estimate the fault masking
capability of a combinational circuit using the truth-cum-fault enumeration
table, and then it is shown how to identify the logic that can introduced to
add redundancy into the original circuit without affecting its native
functionality and with the aim of improving its fault tolerance though this
would involve some trade-off in the design metrics. However, care should be
taken while introducing redundant logic since redundant logic insertion may
give rise to new internal nodes and faults on those may impact the fault
tolerance of the resulting circuit. The combinational circuit that is
considered and its redundant counterparts are all implemented in semi-custom
design style using a 32/28nm CMOS digital cell library and their respective
design metrics and fault tolerances are compared.
"
786,"Mathematical Estimation of Logical Masking Capability of
  Majority/Minority Gates Used in Nanoelectronic Circuits","  In nanoelectronic circuit synthesis, the majority gate and the inverter form
the basic combinational logic primitives. This paper deduces the mathematical
formulae to estimate the logical masking capability of majority gates, which
are used extensively in nanoelectronic digital circuit synthesis. The
mathematical formulae derived to evaluate the logical masking capability of
majority gates holds well for minority gates, and a comparison with the logical
masking capability of conventional gates such as NOT, AND/NAND, OR/NOR, and
XOR/XNOR is provided. It is inferred from this research work that the logical
masking capability of majority/minority gates is similar to that of XOR/XNOR
gates, and with an increase of fan-in the logical masking capability of
majority/minority gates also increases.
"
787,"Optimizing Scrubbing by Netlist Analysis for FPGA Configuration Bit
  Classification and Floorplanning","  Existing scrubbing techniques for SEU mitigation on FPGAs do not guarantee an
error-free operation after SEU recovering if the affected configuration bits do
belong to feedback loops of the implemented circuits. In this paper, we a)
provide a netlist-based circuit analysis technique to distinguish so-called
critical configuration bits from essential bits in order to identify
configuration bits which will need also state-restoring actions after a
recovered SEU and which not. Furthermore, b) an alternative classification
approach using fault injection is developed in order to compare both
classification techniques. Moreover, c) we will propose a floorplanning
approach for reducing the effective number of scrubbed frames and d),
experimental results will give evidence that our optimization methodology not
only allows to detect errors earlier but also to minimize the
Mean-Time-To-Repair (MTTR) of a circuit considerably. In particular, we show
that by using our approach, the MTTR for datapath-intensive circuits can be
reduced by up to 48.5% in comparison to standard approaches.
"
788,Address Translation Design Tradeoffs for Heterogeneous Systems,"  This paper presents a broad, pathfinding design space exploration of memory
management units (MMUs) for heterogeneous systems. We consider a variety of
designs, ranging from accelerators tightly coupled with CPUs (and using their
MMUs) to fully independent accelerators that have their own MMUs. We find that
regardless of the CPU-accelerator communication, accelerators should not rely
on the CPU MMU for any aspect of address translation, and instead must have its
own, local, fully-fledged MMU. That MMU, however, can and should be as
application-specific as the accelerator itself, as our data indicates that even
a 100% hit rate in a small, standard L1 Translation Lookaside Buffer (TLB)
presents a substantial accelerator performance overhead. Furthermore, we
isolate the benefits of individual MMU components (e.g., TLBs versus page table
walkers) and discover that their relative performance, area, and energy are
workload dependent, with their interplay resulting in different area-optimal
and energy-optimal configurations.
"
789,"Multiscale Co-Design Analysis of Energy, Latency, Area, and Accuracy of
  a ReRAM Analog Neural Training Accelerator","  Neural networks are an increasingly attractive algorithm for natural language
processing and pattern recognition. Deep networks with >50M parameters are made
possible by modern GPU clusters operating at <50 pJ per op and more recently,
production accelerators capable of <5pJ per operation at the board level.
However, with the slowing of CMOS scaling, new paradigms will be required to
achieve the next several orders of magnitude in performance per watt gains.
Using an analog resistive memory (ReRAM) crossbar to perform key matrix
operations in an accelerator is an attractive option. This work presents a
detailed design using a state of the art 14/16 nm PDK for of an analog crossbar
circuit block designed to process three key kernels required in training and
inference of neural networks. A detailed circuit and device-level analysis of
energy, latency, area, and accuracy are given and compared to relevant designs
using standard digital ReRAM and SRAM operations. It is shown that the analog
accelerator has a 270x energy and 540x latency advantage over a similar block
utilizing only digital ReRAM and takes only 11 fJ per multiply and accumulate
(MAC). Compared to an SRAM based accelerator, the energy is 430X better and
latency is 34X better. Although training accuracy is degraded in the analog
accelerator, several options to improve this are presented. The possible gains
over a similar digital-only version of this accelerator block suggest that
continued optimization of analog resistive memories is valuable. This detailed
circuit and device analysis of a training accelerator may serve as a foundation
for further architecture-level studies.
"
790,"Streaming Architecture for Large-Scale Quantized Neural Networks on an
  FPGA-Based Dataflow Platform","  Deep neural networks (DNNs) are used by different applications that are
executed on a range of computer architectures, from IoT devices to
supercomputers. The footprint of these networks is huge as well as their
computational and communication needs. In order to ease the pressure on
resources, research indicates that in many cases a low precision representation
(1-2 bit per parameter) of weights and other parameters can achieve similar
accuracy while requiring less resources. Using quantized values enables the use
of FPGAs to run NNs, since FPGAs are well fitted to these primitives; e.g.,
FPGAs provide efficient support for bitwise operations and can work with
arbitrary-precision representation of numbers.
  This paper presents a new streaming architecture for running QNNs on FPGAs.
The proposed architecture scales out better than alternatives, allowing us to
take advantage of systems with multiple FPGAs. We also included support for
skip connections, that are used in state-of-the art NNs, and shown that our
architecture allows to add those connections almost for free. All this allowed
us to implement an 18-layer ResNet for 224x224 images classification, achieving
57.5% top-1 accuracy.
  In addition, we implemented a full-sized quantized AlexNet. In contrast to
previous works, we use 2-bit activations instead of 1-bit ones, which improves
AlexNet's top-1 accuracy from 41.8% to 51.03% for the ImageNet classification.
Both AlexNet and ResNet can handle 1000-class real-time classification on an
FPGA.
  Our implementation of ResNet-18 consumes 5x less power and is 4x slower for
ImageNet, when compared to the same NN on the latest Nvidia GPUs. Smaller NNs,
that fit a single FPGA, are running faster then on GPUs on small (32x32)
inputs, while consuming up to 20x less energy and power.
"
791,"Snowflake: A Model Agnostic Accelerator for Deep Convolutional Neural
  Networks","  Deep convolutional neural networks (CNNs) are the deep learning model of
choice for performing object detection, classification, semantic segmentation
and natural language processing tasks. CNNs require billions of operations to
process a frame. This computational complexity, combined with the inherent
parallelism of the convolution operation make CNNs an excellent target for
custom accelerators. However, when optimizing for different CNN hierarchies and
data access patterns, it is difficult for custom accelerators to achieve close
to 100% computational efficiency. In this work, we present Snowflake, a
scalable and efficient accelerator that is agnostic to CNN workloads, and was
designed to always perform at near-peak hardware utilization. Snowflake is able
to achieve a computational efficiency of over 91% on modern CNN models.
Snowflake, implemented on a Xilinx Zynq XC7Z045 SoC is capable of achieving a
peak throughput of 128G-ops/s and a measured throughput of 100 frames per
second and 120 G-ops/s on the AlexNet CNN model, 36 frames per second and 116G-
ops/s on the GoogLeNet CNN model and 17 frames per second and 122 G-ops/s on
the ResNet-50 CNN model. To the best of our knowledge, Snowflake is the only
implemented system capable of achieving over 91% efficiency on modern CNNs and
the only implemented system with GoogLeNet and ResNet as part of the benchmark
suite.
"
792,Sensitivity Analysis of Core Specialization Techniques,"  The instruction footprint of OS-intensive workloads such as web servers,
database servers, and file servers typically exceeds the size of the
instruction cache (32 KB). Consequently, such workloads incur a lot of i-cache
misses, which reduces their performance drastically. Several papers have
proposed to improve the performance of such workloads using core
specialization. In this scheme, tasks with different instruction footprints are
executed on different cores. In this report, we study the performance of five
state of the art core specialization techniques: SelectiveOffload [6], FlexSC
[8], DisAggregateOS [5], SLICC [2], and SchedTask [3] for different system
parameters. Our studies show that for a suite of 8 popular OS-intensive
workloads, SchedTask performs best for all evaluated configurations.
"
793,"A scalable multi-core architecture with heterogeneous memory structures
  for Dynamic Neuromorphic Asynchronous Processors (DYNAPs)","  Neuromorphic computing systems comprise networks of neurons that use
asynchronous events for both computation and communication. This type of
representation offers several advantages in terms of bandwidth and power
consumption in neuromorphic electronic systems. However, managing the traffic
of asynchronous events in large scale systems is a daunting task, both in terms
of circuit complexity and memory requirements. Here we present a novel routing
methodology that employs both hierarchical and mesh routing strategies and
combines heterogeneous memory structures for minimizing both memory
requirements and latency, while maximizing programming flexibility to support a
wide range of event-based neural network architectures, through parameter
configuration. We validated the proposed scheme in a prototype multi-core
neuromorphic processor chip that employs hybrid analog/digital circuits for
emulating synapse and neuron dynamics together with asynchronous digital
circuits for managing the address-event traffic. We present a theoretical
analysis of the proposed connectivity scheme, describe the methods and circuits
used to implement such scheme, and characterize the prototype chip. Finally, we
demonstrate the use of the neuromorphic processor with a convolutional neural
network for the real-time classification of visual symbols being flashed to a
dynamic vision sensor (DVS) at high speed.
"
794,SCNN: An Accelerator for Compressed-sparse Convolutional Neural Networks,"  Convolutional Neural Networks (CNNs) have emerged as a fundamental technology
for machine learning. High performance and extreme energy efficiency are
critical for deployments of CNNs in a wide range of situations, especially
mobile platforms such as autonomous vehicles, cameras, and electronic personal
assistants. This paper introduces the Sparse CNN (SCNN) accelerator
architecture, which improves performance and energy efficiency by exploiting
the zero-valued weights that stem from network pruning during training and
zero-valued activations that arise from the common ReLU operator applied during
inference. Specifically, SCNN employs a novel dataflow that enables maintaining
the sparse weights and activations in a compressed encoding, which eliminates
unnecessary data transfers and reduces storage requirements. Furthermore, the
SCNN dataflow facilitates efficient delivery of those weights and activations
to the multiplier array, where they are extensively reused. In addition, the
accumulation of multiplication products are performed in a novel accumulator
array. Our results show that on contemporary neural networks, SCNN can improve
both performance and energy by a factor of 2.7x and 2.3x, respectively, over a
comparably provisioned dense CNN accelerator.
"
795,"Improving Multi-Application Concurrency Support Within the GPU Memory
  System","  GPUs exploit a high degree of thread-level parallelism to hide long-latency
stalls. Due to the heterogeneous compute requirements of different
applications, there is a growing need to share the GPU across multiple
applications in large-scale computing environments. However, while CPUs offer
relatively seamless multi-application concurrency, and are an excellent fit for
multitasking and for virtualized environments, GPUs currently offer only
primitive support for multi-application concurrency. Much of the problem in a
contemporary GPU lies within the memory system, where multi-application
execution requires virtual memory support to manage the address spaces of each
application and to provide memory protection. In this work, we perform a
detailed analysis of the major problems in state-of-the-art GPU virtual memory
management that hinders multi-application execution. Existing GPUs are designed
to share memory between the CPU and GPU, but do not handle multi-application
support within the GPU well. We find that when multiple applications spatially
share the GPU, there is a significant amount of inter-core thrashing on the
shared TLB within the GPU. The TLB contention is high enough to prevent the GPU
from successfully hiding stall latencies, thus becoming a first-order
performance concern. We introduce MASK, a memory hierarchy design that provides
low-overhead virtual memory support for the concurrent execution of multiple
applications. MASK extends the GPU memory hierarchy to efficiently support
address translation through the use of multi-level TLBs, and uses
translation-aware memory and cache management to maximize throughput in the
presence of inter-application contention.
"
796,GraphR: Accelerating Graph Processing Using ReRAM,"  This paper presents GRAPHR, the first ReRAM-based graph processing
accelerator. GRAPHR follows the principle of near-data processing and explores
the opportunity of performing massive parallel analog operations with low
hardware and energy cost. The analog computation is suit- able for graph
processing because: 1) The algorithms are iterative and could inherently
tolerate the imprecision; 2) Both probability calculation (e.g., PageRank and
Collaborative Filtering) and typical graph algorithms involving integers (e.g.,
BFS/SSSP) are resilient to errors. The key insight of GRAPHR is that if a
vertex program of a graph algorithm can be expressed in sparse matrix vector
multiplication (SpMV), it can be efficiently performed by ReRAM crossbar. We
show that this assumption is generally true for a large set of graph
algorithms. GRAPHR is a novel accelerator architecture consisting of two
components: memory ReRAM and graph engine (GE). The core graph computations are
performed in sparse matrix format in GEs (ReRAM crossbars). The
vector/matrix-based graph computation is not new, but ReRAM offers the unique
opportunity to realize the massive parallelism with unprecedented energy
efficiency and low hardware cost. With small subgraphs processed by GEs, the
gain of performing parallel operations overshadows the wastes due to sparsity.
The experiment results show that GRAPHR achieves a 16.01x (up to 132.67x)
speedup and a 33.82x energy saving on geometric mean compared to a CPU baseline
system. Com- pared to GPU, GRAPHR achieves 1.69x to 2.19x speedup and consumes
4.77x to 8.91x less energy. GRAPHR gains a speedup of 1.16x to 4.12x, and is
3.67x to 10.96x more energy efficiency compared to PIM-based architecture.
"
797,Design of Adiabatic MTJ-CMOS Hybrid Circuits,"  Low-power designs are a necessity with the increasing demand of portable
devices which are battery operated. In many of such devices the operational
speed is not as important as battery life. Logic-in-memory structures using
nano-devices and adiabatic designs are two methods to reduce the static and
dynamic power consumption respectively. Magnetic tunnel junction (MTJ) is an
emerging technology which has many advantages when used in logic-in-memory
structures in conjunction with CMOS. In this paper, we introduce a novel
adiabatic hybrid MTJ/CMOS structure which is used to design AND/NAND, XOR/XNOR
and 1-bit full adder circuits. We simulate the designs using HSPICE with 32nm
CMOS technology and compared it with a non-adiabatic hybrid MTJ/CMOS circuits.
The proposed adiabatic MTJ/CMOS full adder design has more than 7 times lower
power consumtion compared to the previous MTJ/CMOS full adder.
"
798,"An Experimental Microarchitecture for a Superconducting Quantum
  Processor","  Quantum computers promise to solve certain problems that are intractable for
classical computers, such as factoring large numbers and simulating quantum
systems. To date, research in quantum computer engineering has focused
primarily at opposite ends of the required system stack: devising high-level
programming languages and compilers to describe and optimize quantum
algorithms, and building reliable low-level quantum hardware. Relatively little
attention has been given to using the compiler output to fully control the
operations on experimental quantum processors. Bridging this gap, we propose
and build a prototype of a flexible control microarchitecture supporting
quantum-classical mixed code for a superconducting quantum processor. The
microarchitecture is based on three core elements: (i) a codeword-based event
control scheme, (ii) queue-based precise event timing control, and (iii) a
flexible multilevel instruction decoding mechanism for control. We design a set
of quantum microinstructions that allows flexible control of quantum operations
with precise timing. We demonstrate the microarchitecture and microinstruction
set by performing a standard gate-characterization experiment on a transmon
qubit.
"
799,Advanced Datapath Synthesis using Graph Isomorphism,"  This paper presents an advanced DAG-based algorithm for datapath synthesis
that targets area minimization using logic-level resource sharing. The problem
of identifying common specification logic is formulated using unweighted graph
isomorphism problem, in contrast to a weighted graph isomorphism using AIGs. In
the context of gate-level datapath circuits, our algorithm solves the un-
weighted graph isomorphism problem in linear time. The experiments are
conducted within an industrial synthesis flow that includes the complete
high-level synthesis, logic synthesis and placement and route procedures.
Experimental results show a significant runtime improvements compared to the
existing datapath synthesis algorithms.
"
800,PolarBear: A 28-nm FD-SOI ASIC for Decoding of Polar Codes,"  Polar codes are a recently proposed class of block codes that provably
achieve the capacity of various communication channels. They received a lot of
attention as they can do so with low-complexity encoding and decoding
algorithms, and they have an explicit construction. Their recent inclusion in a
5G communication standard will only spur more research. However, only a couple
of ASICs featuring decoders for polar codes were fabricated, and none of them
implements a list-based decoding algorithm. In this paper, we present ASIC
measurement results for a fabricated 28 nm CMOS chip that implements two
different decoders: the first decoder is tailored toward error-correction
performance and flexibility. It supports any code rate as well as three
different decoding algorithms: successive cancellation (SC), SC flip and SC
list (SCL). The flexible decoder can also decode both non-systematic and
systematic polar codes. The second decoder targets speed and energy efficiency.
We present measurement results for the first silicon-proven SCL decoder, where
its coded throughput is shown to be of 306.8 Mbps with a latency of 3.34 us and
an energy per bit of 418.3 pJ/bit at a clock frequency of 721 MHz for a supply
of 1.3 V. The energy per bit drops down to 178.1 pJ/bit with a more modest
clock frequency of 308 MHz, lower throughput of 130.9 Mbps and a reduced supply
voltage of 0.9 V. For the other two operating modes, the energy per bit is
shown to be of approximately 95 pJ/bit. The less flexible high-throughput
unrolled decoder can achieve a coded throughput of 9.2 Gbps and a latency of
628 ns for a measured energy per bit of 1.15 pJ/bit at 451 MHz.
"
801,Cost Modeling and Projection for Stacked Nanowire Fabric,"  To continue scaling beyond 2-D CMOS with 3-D integration, any new 3-D IC
technology has to be comparable or better than 2-D CMOS in terms of
scalability, enhanced functionality, density, power, performance, cost, and
reliability. Transistor-level 3-D integration carries the most potential in
this regard. Recently, we proposed a stacked horizontal nanowire based
transistor-level 3-D integration approach, called SN3D [1][2] that solves
scaling challenges and achieves tremendous benefits with respect to 2-D CMOS
while keeping manageable thermal profile. In this paper, we present the cost
analysis of SN3D and show comparison with 2-D CMOS (2D), conventional TSV based
3-D (T3D) and Monolithic 3-D integrations (M3D). In our cost model, we capture
the implications of manufacturing, circuit density, interconnects, bonding and
heat in determining die cost, and evaluate how cost scales as transistor count
increases. Since SN3D is a new 3-D IC fabric, based on our proposed
manufacturing pathway[1] we assumed complexity of fabrication steps as
proportionality constants in our cost estimation model. Our analysis revealed
86%, 72% and 74% reduction in area; 55%, 43% and 43% reduction in interconnects
distribution and total interconnect length for SN3D, which largely contributed
to 70%, 67% and 68% reduction in cost in comparison to 2D, T3D and M3D
respectively.
"
802,Read Mapping Near Non-Volatile Memory,"  DNA sequencing is the physical/biochemical process of identifying the
location of the four bases (Adenine, Guanine, Cytosine, Thymine) in a DNA
strand. As semiconductor technology revolutionized computing, modern DNA
sequencing technology (termed Next Generation Sequencing, NGS)revolutionized
genomic research. As a result, modern NGS platforms can sequence hundreds of
millions of short DNA fragments in parallel. The sequenced DNA fragments,
representing the output of NGS platforms, are termed reads. Besides genomic
variations, NGS imperfections induce noise in reads. Mapping each read to (the
most similar portion of) a reference genome of the same species, i.e., read
mapping, is a common critical first step in a diverse set of emerging
bioinformatics applications. Mapping represents a search-heavy memory-intensive
similarity matching problem, therefore, can greatly benefit from near-memory
processing. Intuition suggests using fast associative search enabled by Ternary
Content Addressable Memory (TCAM) by construction. However, the excessive
energy consumption and lack of support for similarity matching (under NGS and
genomic variation induced noise) renders direct application of TCAM infeasible,
irrespective of volatility, where only non-volatile TCAM can accommodate the
large memory footprint in an area-efficient way. This paper introduces GeNVoM,
a scalable, energy-efficient and high-throughput solution. Instead of
optimizing an algorithm developed for general-purpose computers or GPUs, GeNVoM
rethinks the algorithm and non-volatile TCAM-based accelerator design together
from the ground up. Thereby GeNVoM can improve the throughput by up to 113.5
times (3.6); the energy consumption, by up to 210.9 times (1.36), when compared
to a GPU (accelerator) baseline, which represents one of the highest-throughput
implementations known.
"
803,Charge-based computing with analogue reconfigurable gates,"  As the world enters the age of ubiquitous computing, the need for
reconfigurable hardware operating close to the fundamental limits of energy
consumption becomes increasingly pressing. Simultaneously, scaling-driven
performance improvements within the framework of traditional analogue and
digital design become progressively more restricted by fundamental physical
constraints. Thus, a true paradigm shift in electronics design is required for
fuelling the next big burst in technology. Here we lay the foundations of a new
design paradigm that fuses analogue and digital thinking by combining digital
electronics with memristive devices for achieving charge-based computation;
information processing where every dissipated charge counts. This is realised
by introducing memristive devices into standard logic gates, thus rendering
them reconfigurable and able to perform analogue computation at a power cost
close to digital. The power of this concept is then showcased by experimentally
demonstrating a hardware data clusterer and a fuzzy NAND gate using this
principle.
"
804,GREENER: A Tool for Improving Energy Efficiency of Register Files,"  Graphics Processing Units (GPUs) maintain a large register file to increase
the thread level parallelism (TLP). To increase the TLP further, recent GPUs
have increased the number of on-chip registers in every generation. However,
with the increase in the register file size, the leakage power increases. Also,
with the technology advances, the leakage power component has increased and has
become an important consideration for the manufacturing process. The leakage
power of a register file can be reduced by turning infrequently used registers
into low power (drowsy or off) state after accessing them. A major challenge in
doing so is the lack of runtime register access information.
  This paper proposes GREENER (GPU REgister file ENErgy Reducer): a system to
minimize leakage energy of the register file of GPUs. GREENER employs a
compile-time analysis to estimate the run-time register access information. The
result of the analysis is used to determine the power state of the registers
(ON, SLEEP, or OFF) after each instruction. We propose a power optimized
assembly instruction set that allows GREENER to encode the power state of the
registers in the executable itself. The modified assembly, along with a
run-time optimization to update the power state of a register during execution,
results in significant power reduction.
  We implemented GREENER in GPGPU-Sim simulator, and used GPUWattch framework
to measure the register file's leakage power. Evaluation of GREENER on 21
kernels from CUDASDK, GPGPU-SIM, Parboil, and Rodinia benchmarks suites shows
an average reduction of register leakage energy by 69.04% and maximum reduction
of 87.95% with a negligible number of simulation cycles overhead (0.53% on
average).
"
805,"TraceTracker: Hardware/Software Co-Evaluation for Large-Scale I/O
  Workload Reconstruction","  Block traces are widely used for system studies, model verifications, and
design analyses in both industry and academia. While such traces include
detailed block access patterns, existing trace-driven research unfortunately
often fails to find true-north due to a lack of runtime contexts such as user
idle periods and system delays, which are fundamentally linked to the
characteristics of target storage hardware. In this work, we propose
TraceTracker, a novel hardware/software co-evaluation method that allows users
to reuse a broad range of the existing block traces by keeping most their
execution contexts and user scenarios while adjusting them with new system
information. Specifically, our TraceTracker's software evaluation model can
infer CPU burst times and user idle periods from old storage traces, whereas
its hardware evaluation method remasters the storage traces by interoperating
the inferred time information, and updates all inter-arrival times by making
them aware of the target storage system. We apply the proposed co-evaluation
model to 577 traces, which were collected by servers from different
institutions and locations a decade ago, and revive the traces on a
high-performance flash-based storage array. The evaluation results reveal that
the accuracy of the execution contexts reconstructed by TraceTracker is on
average 99% and 96% with regard to the frequency of idle operations and the
total idle periods, respectively.
"
806,"A Streaming Accelerator for Deep Convolutional Neural Networks with
  Image and Feature Decomposition for Resource-limited System Applications","  Deep convolutional neural networks (CNN) are widely used in modern artificial
intelligence (AI) and smart vision systems but also limited by computation
latency, throughput, and energy efficiency on a resource-limited scenario, such
as mobile devices, internet of things (IoT), unmanned aerial vehicles (UAV),
and so on. A hardware streaming architecture is proposed to accelerate
convolution and pooling computations for state-of-the-art deep CNNs. It is
optimized for energy efficiency by maximizing local data reuse to reduce
off-chip DRAM data access. In addition, image and feature decomposition
techniques are introduced to optimize memory access pattern for an arbitrary
size of image and number of features within limited on-chip SRAM capacity. A
prototype accelerator was implemented in TSMC 65 nm CMOS technology with 2.3 mm
x 0.8 mm core area, which achieves 144 GOPS peak throughput and 0.8 TOPS/W peak
energy efficiency.
"
807,"Understanding System Characteristics of Online Erasure Coding on
  Scalable, Distributed and Large-Scale SSD Array Systems","  Large-scale systems with arrays of solid state disks (SSDs) have become
increasingly common in many computing segments. To make such systems resilient,
we can adopt erasure coding such as Reed-Solomon (RS) code as an alternative to
replication because erasure coding can offer a significantly lower storage cost
than replication. To understand the impact of using erasure coding on system
performance and other system aspects such as CPU utilization and network
traffic, we build a storage cluster consisting of approximately one hundred
processor cores with more than fifty high-performance SSDs, and evaluate the
cluster with a popular open-source distributed parallel file system, Ceph. Then
we analyze behaviors of systems adopting erasure coding from the following five
viewpoints, compared with those of systems using replication: (1) storage
system I/O performance; (2) computing and software overheads; (3) I/O
amplification; (4) network traffic among storage nodes; (5) the impact of
physical data layout on performance of RS-coded SSD arrays. For all these
analyses, we examine two representative RS configurations, which are used by
Google and Facebook file systems, and compare them with triple replication that
a typical parallel file system employs as a default fault tolerance mechanism.
Lastly, we collect 54 block-level traces from the cluster and make them
available for other researchers.
"
808,"An Analog Neural Network Computing Engine using CMOS-Compatible
  Charge-Trap-Transistor (CTT)","  An analog neural network computing engine based on CMOS-compatible
charge-trap transistor (CTT) is proposed in this paper. CTT devices are used as
analog multipliers. Compared to digital multipliers, CTT-based analog
multiplier shows significant area and power reduction. The proposed computing
engine is composed of a scalable CTT multiplier array and energy efficient
analog-digital interfaces. Through implementing the sequential analog fabric
(SAF), the engine mixed-signal interfaces are simplified and hardware overhead
remains constant regardless of the size of the array. A proof-of-concept 784 by
784 CTT computing engine is implemented using TSMC 28nm CMOS technology and
occupied 0.68mm2. The simulated performance achieves 76.8 TOPS (8-bit) with 500
MHz clock frequency and consumes 14.8 mW. As an example, we utilize this
computing engine to address a classic pattern recognition problem --
classifying handwritten digits on MNIST database and obtained a performance
comparable to state-of-the-art fully connected neural networks using 8-bit
fixed-point resolution.
"
809,"Satisfiability Modulo Theory based Methodology for Floorplanning in VLSI
  Circuits","  This paper proposes a Satisfiability Modulo Theory based formulation for
floorplanning in VLSI circuits. The proposed approach allows a number of fixed
blocks to be placed within a layout region without overlapping and at the same
time minimizing the area of the layout region. The proposed approach is
extended to allow a number of fixed blocks with ability to rotate and flexible
blocks (with variable width and height) to be placed within a layout without
overlap. Our target in all cases is reduction in area occupied on a chip which
is of vital importance in obtaining a good circuit design. Satisfiability
Modulo Theory combines the problem of Boolean satisfiability with domains such
as convex optimization. Satisfiability Modulo Theory provides a richer modeling
language than is possible with pure Boolean SAT formulas. We have conducted our
experiments on MCNC and GSRC benchmark circuits to calculate the total area
occupied, amount of deadspace and the total CPU time consumed while placing the
blocks without overlapping. The results obtained shows clearly that the amount
of dead space or wasted space is reduced if rotation is applied to the blocks.
"
810,"Energy-Efficient Wireless Interconnection Framework for Multichip
  Systems with In-package Memory Stacks","  Multichip systems with memory stacks and various processing chips are at the
heart of platform based designs such as servers and embedded systems. Full
utilization of the benefits of these integrated multichip systems need a
seamless, and scalable in-package interconnection framework. However,
state-of-the-art inter-chip communication requires long wireline channels which
increases energy consumption and latency while decreasing data bandwidth. Here,
we propose the design of an energy-efficient, seamless wireless interconnection
network for multichip systems. We demonstrate with cycle-accurate simulations
that such a design reduces the energy consumption and latency while increasing
the bandwidth in comparison to modern multichip integration systems.
"
811,Flexible Support for Fast Parallel Commutative Updates,"  Privatizing data is a useful strategy for increasing parallelism in a shared
memory multithreaded program. Independent cores can compute independently on
duplicates of shared data, combining their results at the end of their
computations. Conventional approaches to privatization, however, rely on
explicit static or dynamic memory allocation for duplicated state, increasing
memory footprint and contention for cache resources, especially in shared
caches. In this work, we describe CCache, a system for on-demand privatization
of data manipulated by commutative operations. CCache garners the benefits of
privatization, without the increase in memory footprint or cache occupancy.
Each core in CCache dynamically privatizes commutatively manipulated data,
operating on a copy. Periodically or at the end of its computation, the core
merges its value with the value resident in memory, and when all cores have
merged, the in-memory copy contains the up-to-date value. We describe a
low-complexity architectural implementation of CCache that extends a
conventional multicore to support on-demand privatization without using
additional memory for private copies. We evaluate CCache on several high-value
applications, including random access key-value store, clustering, breadth
first search and graph ranking, showing speedups upto 3.2X.
"
812,"Tolerating Soft Errors in Processor Cores Using CLEAR (Cross-Layer
  Exploration for Architecting Resilience)","  We present CLEAR (Cross-Layer Exploration for Architecting Resilience), a
first of its kind framework which overcomes a major challenge in the design of
digital systems that are resilient to reliability failures: achieve desired
resilience targets at minimal costs (energy, power, execution time, area) by
combining resilience techniques across various layers of the system stack
(circuit, logic, architecture, software, algorithm). This is also referred to
as cross-layer resilience. In this paper, we focus on radiation-induced soft
errors in processor cores. We address both single-event upsets (SEUs) and
single-event multiple upsets (SEMUs) in terrestrial environments. Our framework
automatically and systematically explores the large space of comprehensive
resilience techniques and their combinations across various layers of the
system stack (586 cross-layer combinations in this paper), derives
cost-effective solutions that achieve resilience targets at minimal costs, and
provides guidelines for the design of new resilience techniques. Our results
demonstrate that a carefully optimized combination of circuit-level hardening,
logic-level parity checking, and micro-architectural recovery provides a highly
cost-effective soft error resilience solution for general-purpose processor
cores. For example, a 50x improvement in silent data corruption rate is
achieved at only 2.1% energy cost for an out-of-order core (6.1% for an
in-order core) with no speed impact. However, (application-aware) selective
circuit-level hardening alone, guided by a thorough analysis of the effects of
soft errors on application benchmarks, provides a cost-effective soft error
resilience solution as well (with ~1% additional energy cost for a 50x
improvement in silent data corruption rate).
"
813,Ascertaining Uncertainty for Efficient Exact Cache Analysis,"  Static cache analysis characterizes a program's cache behavior by determining
in a sound but approximate manner which memory accesses result in cache hits
and which result in cache misses. Such information is valuable in optimizing
compilers, worst-case execution time analysis, and side-channel attack
quantification and mitigation.Cache analysis is usually performed as a
combination of `must' and `may' abstract interpretations, classifying
instructions as either `always hit', `always miss', or `unknown'. Instructions
classified as `unknown' might result in a hit or a miss depending on program
inputs or the initial cache state. It is equally possible that they do in fact
always hit or always miss, but the cache analysis is too coarse to see it.Our
approach to eliminate this uncertainty consists in (i) a novel abstract
interpretation able to ascertain that a particular instruction may definitely
cause a hit and a miss on different paths, and (ii) an exact analysis, removing
all remaining uncertainty, based on model checking, using
abstract-interpretation results to prune down the model for scalability.We
evaluated our approach on a variety of examples; it notably improves precision
upon classical abstract interpretation at reasonable cost.
"
814,"Analysis and Design of Cost-Effective, High-Throughput LDPC Decoders","  This paper introduces a new approach to cost-effective, high-throughput
hardware designs for Low Density Parity Check (LDPC) decoders. The proposed
approach, called Non-Surjective Finite Alphabet Iterative Decoders (NS-FAIDs),
exploits the robustness of message-passing LDPC decoders to inaccuracies in the
calculation of exchanged messages, and it is shown to provide a unified
framework for several designs previously proposed in the literature. NS-FAIDs
are optimized by density evolution for regular and irregular LDPC codes, and
are shown to provide different trade-offs between hardware complexity and
decoding performance. Two hardware architectures targeting high-throughput
applications are also proposed, integrating both Min-Sum (MS) and NS-FAID
decoding kernels. ASIC post synthesis implementation results on 65nm CMOS
technology show that NS-FAIDs yield significant improvements in the throughput
to area ratio, by up to 58.75% with respect to the MS decoder, with even better
or only slightly degraded error correction performance.
"
815,NeuroTrainer: An Intelligent Memory Module for Deep Learning Training,"  This paper presents, NeuroTrainer, an intelligent memory module with
in-memory accelerators that forms the building block of a scalable architecture
for energy efficient training for deep neural networks. The proposed
architecture is based on integration of a homogeneous computing substrate
composed of multiple processing engines in the logic layer of a 3D memory
module. NeuroTrainer utilizes a programmable data flow based execution model to
optimize memory mapping and data re-use during different phases of training
operation. A programming model and supporting architecture utilizes the
flexible data flow to efficiently accelerate training of various types of DNNs.
The cycle level simulation and synthesized design in 15nm FinFET showspower
efficiency of 500 GFLOPS/W, and almost similar throughput for a wide range of
DNNs including convolutional, recurrent, multi-layer-perceptron, and mixed
(CNN+RNN) networks
"
816,Real time ridge orientation estimation for fingerprint images,"  Fingerprint verification is an important bio-metric technique for personal
identification. Most of the automatic verification systems are based on
matching of fingerprint minutiae. Extraction of minutiae is an essential
process which requires estimation of orientation of the lines in an image. Most
of the existing methods involve intense mathematical computations and hence are
performed through software means. In this paper a hardware scheme to perform
real time orientation estimation is presented which is based on pipelined
architecture. Synthesized circuits proved the functionality and accuracy of the
suggested method.
"
817,High Throughput 2D Spatial Image Filters on FPGAs,"  FPGAs are well established in the signal processing domain, where their
fine-grained programmable nature allows the inherent parallelism in these
applications to be exploited for enhanced performance. As architectures have
evolved, FPGA vendors have added more heterogeneous resources to allow
often-used functions to be implemented with higher performance, at lower power
and using less area. DSP blocks, for example, have evolved from basic
multipliers to support the multiply-accumulate operations that are the core of
many signal processing tasks. While more features were added to DSP blocks,
their structure and connectivity has been optimised primarily for
one-dimensional signal processing. Basic operations in image processing are
similar, but performed in a two-dimensional structure, and hence, many of the
optimisations in newer DSP blocks are not exploited when mapping image
processing algorithms to them. We present a detailed study of two-dimensional
spatial filter implementation on FPGAs, showing how to maximise performance
through exploitation of DSP block capabilities, while also presenting a lean
border pixel management policy.
"
818,"Asynchronous Early Output Section-Carry Based Carry Lookahead Adder with
  Alias Carry Logic","  A new asynchronous early output section-carry based carry lookahead adder
(SCBCLA) with alias carry output logic is presented in this paper. To evaluate
the proposed SCBCLA with alias carry logic and to make a comparison with other
CLAs, a 32-bit addition operation is considered. Compared to the
weak-indication SCBCLA with alias logic, the proposed early output SCBCLA with
alias logic reports a 13% reduction in area without any increases in latency
and power dissipation. On the other hand, in comparison with the early output
recursive CLA (RCLA), the proposed early output SCBCLA with alias logic reports
a 16% reduction in latency while occupying almost the same area and dissipating
almost the same average power. All the asynchronous CLAs are
quasi-delay-insensitive designs which incorporate the delay-insensitive
dual-rail data encoding and adhere to the 4-phase return-to-zero handshaking.
The adders were realized and the simulations were performed based on a 32/28nm
CMOS process.
"
819,"Approximate Ripple Carry and Carry Lookahead Adders - A Comparative
  Analysis","  Approximate ripple carry adders (RCAs) and carry lookahead adders (CLAs) are
presented which are compared with accurate RCAs and CLAs for performing a
32-bit addition. The accurate and approximate RCAs and CLAs are implemented
using a 32/28nm CMOS process. Approximations ranging from 4- to 20-bits are
considered for the less significant adder bit positions. The simulation results
show that approximate RCAs report reductions in the power-delay product (PDP)
ranging from 19.5% to 82% than the accurate RCA for approximation sizes varying
from 4- to 20-bits. Also, approximate CLAs report reductions in PDP ranging
from 16.7% to 74.2% than the accurate CLA for approximation sizes varying from
4- to 20-bits. On average, for the approximation sizes considered, it is
observed that approximate CLAs achieve a 46.5% reduction in PDP compared to the
approximate RCAs. Hence, approximate CLAs are preferable over approximate RCAs
for the low power implementation of approximate computer arithmetic.
"
820,Hardware design for binarization and thinning of fingerprint images,"  Two critical steps in fingerprint recognition are binarization and thinning
of the image. The need for real time processing motivates us to select local
adaptive thresholding approach for the binarization step. We introduce a new
hardware for this purpose based on pipeline architecture. We propose a formula
for selecting an optimal block size for the thresholding purpose. To decrease
minutiae false detection, the binarized image is dilated. We also present in
this paper a new pipeline structure for implementing the thinning algorithm
"
821,FPGA-based ORB Feature Extraction for Real-Time Visual SLAM,"  Simultaneous Localization And Mapping (SLAM) is the problem of constructing
or updating a map of an unknown environment while simultaneously keeping track
of an agent's location within it. How to enable SLAM robustly and durably on
mobile, or even IoT grade devices, is the main challenge faced by the industry
today. The main problems we need to address are: 1.) how to accelerate the SLAM
pipeline to meet real-time requirements; and 2.) how to reduce SLAM energy
consumption to extend battery life. After delving into the problem, we found
out that feature extraction is indeed the bottleneck of performance and energy
consumption. Hence, in this paper, we design, implement, and evaluate a
hardware ORB feature extractor and prove that our design is a great balance
between performance and energy consumption compared with ARM Krait and Intel
Core i5.
"
822,"Amorphous Dynamic Partial Reconfiguration with Flexible Boundaries to
  Remove Fragmentation","  Dynamic partial reconfiguration (DPR) allows one region of an
field-programmable gate array (FPGA) fabric to be reconfigured without
affecting the operations on the rest of the fabric. To use an FPGA as a
dynamically shared compute resource, one could partition and manage an FPGA
fabric as multiple DPR partitions that can be independently reconfigured at
runtime with different application function units (AFUs). Unfortunately,
dividing a fabric into DPR partitions with fixed boundaries causes the
available fabric resources to become fragmented. An AFU of a given size cannot
be loaded unless a sufficiently large DPR partition was floorplanned at build
time. To overcome this inefficiency, we devised an ""amorphous"" DPR technique
that is compatible with current device and tool support but does not require
the DPR partition boundaries to be a priori fixed. A collection of AFU
bitstreams can be simultaneously loaded on the fabric if their footprints (the
actual area used by an AFU) in the fabric do not overlap. We verified the
feasibility of amorphous DPR on Xilinx Zynq System-on-Chip (SoC) FPGAs using
Vivado. We evaluated the benefits of amorphous DPR in the context of a
dynamically reconfigurable vision processing pipeline framework.
"
823,A Survey on Hardware Implementations of Elliptic Curve Cryptosystems,"  In the past two decades, Elliptic Curve Cryptography (ECC) have become
increasingly advanced. ECC, with much smaller key sizes, offers equivalent
security when compared to other asymmetric cryptosystems. In this survey, an
comprehensive overview of hardware implementations of ECC is provided. We first
discuss different elliptic curves, point multiplication algorithms and
underling finite field operations over binary fields F2m and prime fields Fp
which are used in the literature for hardware implementation. Then methods,
steps and considerations of ECC implementation are presented. The
implementations of the ECC are categorized in two main groups based on
implementation technologies consist of field programmable gate array (FPGA)
based implementations and application specific integrated circuit (ASIC)
implementations. Therefore, in these categories to have a better presentation
and comparison, the implementations are presented and distinguished based on
type of finite fields. The best and newest structures in the literature are
described in more details for overall presentation of architectures and
approaches in each group of implementations. High-speed implementation is an
important factor in the ECC applications such as network servers. Also in smart
cards, Wireless Sensor Networks (WSN) and Radio Frequency Identification (RFID)
tags require to low-cost and lightweight implementations. Therefore,
implementation methods related to these applications are explored. In addition,
a classification of the previous works in terms of scalability, flexibility,
performance and cost effectiveness is provided. Finally, some words and
techniques about future works that should be considered are provided.
"
824,"An Energy-Efficient Mixed-Signal Neuron for Inherently Error-Resilient
  Neuromorphic Systems","  This work presents the design and analysis of a mixed-signal neuron (MS-N)
for convolutional neural networks (CNN) and compares its performance with a
digital neuron (Dig-N) in terms of operating frequency, power and noise. The
circuit-level implementation of the MS-N in 65 nm CMOS technology exhibits 2-3
orders of magnitude better energy-efficiency over Dig-N for neuromorphic
computing applications - especially at low frequencies due to the high leakage
currents from many transistors in Dig-N. The inherent error-resiliency of CNN
is exploited to handle the thermal and flicker noise of MS-N. A system-level
analysis using a cohesive circuit-algorithmic framework on MNIST and CIFAR-10
datasets demonstrate an increase of 3% in worst-case classification error for
MNIST when the integrated noise power in the bandwidth is ~ 1 {\mu}V2.
"
825,"A software framework for pipelined arithmetic algorithms in field
  programmable gate arrays","  Pipelined algorithms implemented in field programmable gate arrays are being
extensively used for hardware triggers in the modern experimental high energy
physics field and the complexity of such algorithms are increases rapidly. For
development of such hardware triggers, algorithms are developed in
$\texttt{C++}$, ported to hardware description language for synthesizing
firmware, and then ported back to $\texttt{C++}$ for simulating the firmware
response down to the single bit level. We present a $\texttt{C++}$ software
framework which automatically simulates and generates hardware description
language code for pipelined arithmetic algorithms.
"
826,"CODA: Enabling Co-location of Computation and Data for Near-Data
  Processing","  Recent studies have demonstrated that near-data processing (NDP) is an
effective technique for improving performance and energy efficiency of
data-intensive workloads. However, leveraging NDP in realistic systems with
multiple memory modules introduces a new challenge. In today's systems, where
no computation occurs in memory modules, the physical address space is
interleaved at a fine granularity among all memory modules to help improve the
utilization of processor-memory interfaces by distributing the memory traffic.
However, this is at odds with efficient use of NDP, which requires careful
placement of data in memory modules such that near-data computations and their
exclusively used data can be localized in individual memory modules, while
distributing shared data among memory modules to reduce hotspots. In order to
address this new challenge, we propose a set of techniques that (1) enable
collections of OS pages to either be fine-grain interleaved among memory
modules (as is done today) or to be placed contiguously on individual memory
modules (as is desirable for NDP private data), and (2) decide whether to
localize or distribute each memory object based on its anticipated access
pattern and steer computations to the memory where the data they access is
located. Our evaluations across a wide range of workloads show that the
proposed mechanism improves performance by 31% and reduces 38% remote data
accesses over a baseline system that cannot exploit computate-data affinity
characteristics.
"
827,"A Single-Channel Architecture for Algebraic Integer Based 8$\times$8 2-D
  DCT Computation","  An area efficient row-parallel architecture is proposed for the real-time
implementation of bivariate algebraic integer (AI) encoded 2-D discrete cosine
transform (DCT) for image and video processing. The proposed architecture
computes 8$\times$8 2-D DCT transform based on the Arai DCT algorithm. An
improved fast algorithm for AI based 1-D DCT computation is proposed along with
a single channel 2-D DCT architecture. The design improves on the 4-channel AI
DCT architecture that was published recently by reducing the number of integer
channels to one and the number of 8-point 1-D DCT cores from 5 down to 2. The
architecture offers exact computation of 8$\times$8 blocks of the 2-D DCT
coefficients up to the FRS, which converts the coefficients from the AI
representation to fixed-point format using the method of expansion factors.
Prototype circuits corresponding to FRS blocks based on two expansion factors
are realized, tested, and verified on FPGA-chip, using a Xilinx Virtex-6
XC6VLX240T device. Post place-and-route results show a 20% reduction in terms
of area compared to the 2-D DCT architecture requiring five 1-D AI cores. The
area-time and area-time${}^2$ complexity metrics are also reduced by 23% and
22% respectively for designs with 8-bit input word length. The digital
realizations are simulated up to place and route for ASICs using 45 nm CMOS
standard cells. The maximum estimated clock rate is 951 MHz for the CMOS
realizations indicating 7.608$\cdot$10$^9$ pixels/seconds and a 8$\times$8
block rate of 118.875 MHz.
"
828,Using Vivado-HLS for Structural Design: a NoC Case Study,"  There have been ample successful examples of applying Xilinx Vivado's
""function-to-module"" high-level synthesis (HLS) where the subject is
algorithmic in nature. In this work, we carried out a design study to assess
the effectiveness of applying Vivado-HLS in structural design. We employed
Vivado-HLS to synthesize C functions corresponding to standalone
network-on-chip (NoC) routers as well as complete multi-endpoint NoCs.
Interestingly, we find that describing a complete NoC comprising router
submodules faces fundamental difficulties not present in describing the routers
as standalone modules. Ultimately, we succeeded in using Vivado-HLS to produce
router and NoC modules that are exact cycle- and bit-accurate replacements of
our reference RTL-based router and NoC modules. Furthermore, the routers and
NoCs resulting from HLS and RTL are comparable in resource utilization and
critical path delay. Our experience subjectively suggests that HLS is able to
simplify the design effort even though much of the structural details had to be
provided in the HLS description through a combination of coding discipline and
explicit pragmas. The C++ source code can be found at
https://github.com/zhipengzhaocmu/HLS_NoC.
"
829,"The implementation of a Deep Recurrent Neural Network Language Model on
  a Xilinx FPGA","  Recently, FPGA has been increasingly applied to problems such as speech
recognition, machine learning, and cloud computation such as the Bing search
engine used by Microsoft. This is due to FPGAs great parallel computation
capacity as well as low power consumption compared to general purpose
processors. However, these applications mainly focus on large scale FPGA
clusters which have an extreme processing power for executing massive matrix or
convolution operations but are unsuitable for portable or mobile applications.
This paper describes research on single-FPGA platform to explore the
applications of FPGAs in these fields. In this project, we design a Deep
Recurrent Neural Network (DRNN) Language Model (LM) and implement a hardware
accelerator with AXI Stream interface on a PYNQ board which is equipped with a
XILINX ZYNQ SOC XC7Z020 1CLG400C. The PYNQ has not only abundant programmable
logic resources but also a flexible embedded operation system, which makes it
suitable to be applied in the natural language processing field. We design the
DRNN language model with Python and Theano, train the model on a CPU platform,
and deploy the model on a PYNQ board to validate the model with Jupyter
notebook. Meanwhile, we design the hardware accelerator with Overlay, which is
a kind of hardware library on PYNQ, and verify the acceleration effect on the
PYNQ board. Finally, we have found that the DRNN language model can be deployed
on the embedded system smoothly and the Overlay accelerator with AXI Stream
interface performs at 20 GOPS processing throughput, which constitutes a 70.5X
and 2.75X speed up compared to the work in Ref.30 and Ref.31 respectively.
"
830,Louvre: Lightweight Ordering Using Versioning for Release Consistency,"  Fence instructions are fundamental primitives that ensure consistency in a
weakly consistent shared memory multi-core processor. The execution cost of
these instructions is significant and adds a non-trivial overhead to parallel
programs. In a naive architecture implementation, we track the ordering
constraints imposed by a fence by its entry in the reorder buffer and its
execution overhead entails stalling the processor's pipeline until the store
buffer is drained and also conservatively invalidating speculative loads. These
actions create a cascading effect of increased overhead on the execution of the
following instructions in the program. We find these actions to be overly
restrictive and that they can be further relaxed thereby allowing aggressive
optimizations.
  The current work proposes a lightweight mechanism in which we assign ordering
tags, called versions, to load and store instructions when they reside in the
load/store queues and the write buffer. The version assigned to a memory access
allows us to fully exploit the relaxation allowed by the weak consistency model
and restricts its execution in such a way that the ordering constraints by the
model are satisfied. We utilize the information captured through the assigned
versions to reduce stalls caused by waiting for the store buffer to drain and
to avoid unnecessary squashing of speculative loads, thereby minimizing the
re-execution penalty. This method is particularly effective for the release
consistency model that employs uni-directional fence instructions. We show that
this mechanism reduces the ordering instruction latency by 39.6% and improves
program performance by 11% on average over the baseline implementation.
"
831,VLSI Computational Architectures for the Arithmetic Cosine Transform,"  The discrete cosine transform (DCT) is a widely-used and important signal
processing tool employed in a plethora of applications. Typical fast algorithms
for nearly-exact computation of DCT require floating point arithmetic, are
multiplier intensive, and accumulate round-off errors. Recently proposed fast
algorithm arithmetic cosine transform (ACT) calculates the DCT exactly using
only additions and integer constant multiplications, with very low area
complexity, for null mean input sequences. The ACT can also be computed
non-exactly for any input sequence, with low area complexity and low power
consumption, utilizing the novel architecture described. However, as a
trade-off, the ACT algorithm requires 10 non-uniformly sampled data points to
calculate the 8-point DCT. This requirement can easily be satisfied for
applications dealing with spatial signals such as image sensors and biomedical
sensor arrays, by placing sensor elements in a non-uniform grid. In this work,
a hardware architecture for the computation of the null mean ACT is proposed,
followed by a novel architectures that extend the ACT for non-null mean
signals. All circuits are physically implemented and tested using the Xilinx
XC6VLX240T FPGA device and synthesized for 45 nm TSMC standard-cell library for
performance assessment.
"
832,Minimum Energy Quantized Neural Networks,"  This work targets the automated minimum-energy optimization of Quantized
Neural Networks (QNNs) - networks using low precision weights and activations.
These networks are trained from scratch at an arbitrary fixed point precision.
At iso-accuracy, QNNs using fewer bits require deeper and wider network
architectures than networks using higher precision operators, while they
require less complex arithmetic and less bits per weights. This fundamental
trade-off is analyzed and quantified to find the minimum energy QNN for any
benchmark and hence optimize energy-efficiency. To this end, the energy
consumption of inference is modeled for a generic hardware platform. This
allows drawing several conclusions across different benchmarks. First, energy
consumption varies orders of magnitude at iso-accuracy depending on the number
of bits used in the QNN. Second, in a typical system, BinaryNets or int4
implementations lead to the minimum energy solution, outperforming int8
networks up to 2-10x at iso-accuracy. All code used for QNN training is
available from https://github.com/BertMoons.
"
833,Non Uniform On Chip Power Delivery Network Synthesis Methodology,"  In this paper, we proposed a non-uniform power delivery network (PDN)
synthesis methodology. It first constructs initial PDN using uniform approach.
Then preliminary power integrity analysis is performed to derive IR-safe
candidate window. Congestion map is obtained based global route congestion
estimation. A self-adaptive non-uniform PDN synthesis is then performed to
globally and locally optimize PDN over selected regions. The PDN synthesis is
congestion-driven and IR- guarded. Experimental results show significant timing
important in trade-off small PDN length reduction with no EM/IR impact. We
further explored potential power savings using our non-uniform PDN synthesis
methodology.
"
834,"Dynamic FPGA Detection and Protection of Hardware Trojan: A Comparative
  Analysis","  Hardware Trojan detection and protection is becoming more crucial as more
untrusted third parties manufacture many parts of critical systems nowadays.
The most common way to detect hardware Trojans is comparing the untrusted
design with a golden (trusted) one. However, third-party intellectual
properties (IPs) are black boxes with no golden IPs to trust. So, previous
attempts to detect hardware Trojans will not work with third-party IPs. In this
work, we present novel methods for Trojan protection and detection on field
programmable gate arrays (FPGAs) without the need for golden chips. Presented
methods work at runtime instead of test time. We provide a wide spectrum of
Trojan detection and protection methods. While the simplest methods have low
overhead and provide limited protection mechanisms, more sophisticated and
costly techniques are introduced that can detect hardware Trojans and even
clean up the system from infected IPs. Moreover, we study the cost of using the
FPGA partial reconfiguration feature to get rid of infected IPs. In addition,
we discuss the possibility to construct IP core certificate authority that
maintains a centralized database of unsafe vendors and IPs. We show the
practicality of the introduced schemes by implementing the different
methodologies on FPGAs. Results show that simple methods present negligible
overheads and as we try to increase security the delay and power overheads
increase.
"
835,"Spintronics based Stochastic Computing for Efficient Bayesian Inference
  System","  Bayesian inference is an effective approach for solving statistical learning
problems especially with uncertainty and incompleteness. However, inference
efficiencies are physically limited by the bottlenecks of conventional
computing platforms. In this paper, an emerging Bayesian inference system is
proposed by exploiting spintronics based stochastic computing. A stochastic
bitstream generator is realized as the kernel components by leveraging the
inherent randomness of spintronics devices. The proposed system is evaluated by
typical applications of data fusion and Bayesian belief networks. Simulation
results indicate that the proposed approach could achieve significant
improvement on inference efficiencies in terms of power consumption and
inference speed.
"
836,"SparseNN: An Energy-Efficient Neural Network Accelerator Exploiting
  Input and Output Sparsity","  Contemporary Deep Neural Network (DNN) contains millions of synaptic
connections with tens to hundreds of layers. The large computation and memory
requirements pose a challenge to the hardware design. In this work, we leverage
the intrinsic activation sparsity of DNN to substantially reduce the execution
cycles and the energy consumption. An end-to-end training algorithm is proposed
to develop a lightweight run-time predictor for the output activation sparsity
on the fly. From our experimental results, the computation overhead of the
prediction phase can be reduced to less than 5% of the original feedforward
phase with negligible accuracy loss. Furthermore, an energy-efficient hardware
architecture, SparseNN, is proposed to exploit both the input and output
sparsity. SparseNN is a scalable architecture with distributed memories and
processing elements connected through a dedicated on-chip network. Compared
with the state-of-the-art accelerators which only exploit the input sparsity,
SparseNN can achieve a 10%-70% improvement in throughput and a power reduction
of around 50%.
"
837,Timing Aware Dummy Metal Fill Methodology,"  In this paper, we analyzed parasitic coupling capacitance coming from dummy
metal fill and its impact on timing. Based on the modeling, we proposed two
approaches to minimize the timing impact from dummy metal fill. The first
approach applies more spacing between critical nets and metal fill, while the
second approach leverages the shielding effects of reference nets. Experimental
results show consistent improvement compared to traditional metal fill method.
"
838,"Critique of ""Asynchronous Logic Implementation Based on Factorized DIMS""","  This paper comments on ""Asynchronous Logic Implementation Based on Factorized
DIMS"" [Journal of Circuits, Systems, and Computers, vol. 26, no. 5, 1750087:
1-9, May 2017] with respect to two main problematic issues: i) the gate orphan
problem implicit in the factorized DIMS approach discussed in the referenced
article which affects its strong-indication, and ii) how the enumeration of
product terms to represent the synthesis cost is skewed in the referenced
article because the logic expression contains sum of products and also product
of sums. It is observed that the referenced article has not provided a general
logic synthesis algorithm excepting only an example illustration involving a
3-input AND logic function. The absence of a general logic synthesis algorithm
would make it difficult to reproduce the research described in the referenced
article. Moreover, the example illustration in the referenced article describes
an unsafe logic decomposition which is not suitable for the multi-level
synthesis of strong-indication asynchronous circuits. Further, a logic
synthesis method which safely decomposes the DIMS solution to synthesize
multi-level strong-indication asynchronous circuits is available in the
existing literature, which was neither cited nor taken up for comparison in the
referenced article, which is another drawback. Subsequently, it is concluded
that the referenced article has not advanced existing knowledge in the field
but on the contrary, has caused confusions. Hence, in the interest of readers,
this paper additionally highlights some important and relevant literature which
provide valuable information about robust asynchronous circuit synthesis
techniques which employ delay-insensitive codes for data representation and
processing and the 4-phase return-to-zero handshake protocol for data
communication.
"
839,A Dwarf-based Scalable Big Data Benchmarking Methodology,"  Different from the traditional benchmarking methodology that creates a new
benchmark or proxy for every possible workload, this paper presents a scalable
big data benchmarking methodology. Among a wide variety of big data analytics
workloads, we identify eight big data dwarfs, each of which captures the common
requirements of each class of unit of computation while being reasonably
divorced from individual implementations. We implement the eight dwarfs on
different software stacks, e.g., OpenMP, MPI, Hadoop as the dwarf components.
For the purpose of architecture simulation, we construct and tune big data
proxy benchmarks using the directed acyclic graph (DAG)-like combinations of
the dwarf components with different weights to mimic the benchmarks in
BigDataBench. Our proxy benchmarks preserve the micro-architecture, memory, and
I/O characteristics, and they shorten the simulation time by 100s times while
maintain the average micro-architectural data accuracy above 90 percentage on
both X86 64 and ARMv8 processors. We will open-source the big data dwarf
components and proxy benchmarks soon.
"
840,"Hydra: An Accelerator for Real-Time Edge-Aware Permeability Filtering in
  65nm CMOS","  Many modern video processing pipelines rely on edge-aware (EA) filtering
methods. However, recent high-quality methods are challenging to run in
real-time on embedded hardware due to their computational load. To this end, we
propose an area-efficient and real-time capable hardware implementation of a
high quality EA method. In particular, we focus on the recently proposed
permeability filter (PF) that delivers promising quality and performance in the
domains of HDR tone mapping, disparity and optical flow estimation. We present
an efficient hardware accelerator that implements a tiled variant of the PF
with low on-chip memory requirements and a significantly reduced external
memory bandwidth (6.4x w.r.t. the non-tiled PF). The design has been taped out
in 65 nm CMOS technology, is able to filter 720p grayscale video at 24.8 Hz and
achieves a high compute density of 6.7 GFLOPS/mm2 (12x higher than embedded
GPUs when scaled to the same technology node). The low area and bandwidth
requirements make the accelerator highly suitable for integration into SoCs
where silicon area budget is constrained and external memory is typically a
heavily contended resource.
"
841,Depth First Always On Routing Trace Algorithm,"  In this paper, we discussed current limitation in the
electronic-design-automotation (EDA) tool on tracing the always on routing. We
developed an algorithm to efficiently track the secondary power routing and
accurately estimate the routing quality using approximate voltage drop as the
criteria. The fast check can identify potential hotspot issues without going
through sign-off checks. It helps designers to capture issues at early stages
and fix the issues with less design effort. We also discussed some limitations
to our algorithm.
"
842,A General Neural Network Hardware Architecture on FPGA,"  Field Programmable Gate Arrays (FPGAs) plays an increasingly important role
in data sampling and processing industries due to its highly parallel
architecture, low power consumption, and flexibility in custom algorithms.
Especially, in the artificial intelligence field, for training and implement
the neural networks and machine learning algorithms, high energy efficiency
hardware implement and massively parallel computing capacity are heavily
demanded. Therefore, many global companies have applied FPGAs into AI and
Machine learning fields such as autonomous driving and Automatic Spoken
Language Recognition (Baidu) [1] [2] and Bing search (Microsoft) [3].
Considering the FPGAs great potential in these fields, we tend to implement a
general neural network hardware architecture on XILINX ZU9CG System On Chip
(SOC) platform [4], which contains abundant hardware resource and powerful
processing capacity. The general neural network architecture on the FPGA SOC
platform can perform forward and backward algorithms in deep neural networks
(DNN) with high performance and easily be adjusted according to the type and
scale of the neural networks.
"
843,"SparCE: Sparsity aware General Purpose Core Extensions to Accelerate
  Deep Neural Networks","  Deep Neural Networks (DNNs) have emerged as the method of choice for solving
a wide range of machine learning tasks. The enormous computational demands
posed by DNNs have most commonly been addressed through the design of custom
accelerators. However, these accelerators are prohibitive in many design
scenarios (e.g., wearable devices and IoT sensors), due to stringent area/cost
constraints. Accelerating DNNs on these low-power systems, comprising of mainly
the general-purpose processor (GPP) cores, requires new approaches. We improve
the performance of DNNs on GPPs by exploiting a key attribute of DNNs, i.e.,
sparsity. We propose Sparsity aware Core Extensions (SparCE)- a set of
micro-architectural and ISA extensions that leverage sparsity and are minimally
intrusive and low-overhead. We dynamically detect zero operands and skip a set
of future instructions that use it. Our design ensures that the instructions to
be skipped are prevented from even being fetched, as squashing instructions
comes with a penalty. SparCE consists of 2 key micro-architectural
enhancements- a Sparsity Register File (SpRF) that tracks zero registers and a
Sparsity aware Skip Address (SASA) table that indicates instructions to be
skipped. When an instruction is fetched, SparCE dynamically pre-identifies
whether the following instruction(s) can be skipped and appropriately modifies
the program counter, thereby skipping the redundant instructions and improving
performance. We model SparCE using the gem5 architectural simulator, and
evaluate our approach on 6 image-recognition DNNs in the context of both
training and inference using the Caffe framework. On a scalar microprocessor,
SparCE achieves 19%-31% reduction in application-level. We also evaluate SparCE
on a 4-way SIMD ARMv8 processor using the OpenBLAS library, and demonstrate
that SparCE achieves 8%-15% reduction in the application-level execution time.
"
844,"P4-compatible High-level Synthesis of Low Latency 100 Gb/s Streaming
  Packet Parsers in FPGAs","  Packet parsing is a key step in SDN-aware devices. Packet parsers in SDN
networks need to be both reconfigurable and fast, to support the evolving
network protocols and the increasing multi-gigabit data rates. The combination
of packet processing languages with FPGAs seems to be the perfect match for
these requirements. In this work, we develop an open-source FPGA-based
configurable architecture for arbitrary packet parsing to be used in SDN
networks. We generate low latency and high-speed streaming packet parsers
directly from a packet processing program. Our architecture is pipelined and
entirely modeled using templated C++ classes. The pipeline layout is derived
from a parser graph that corresponds a P4 code after a series of graph
transformation rounds. The RTL code is generated from the C++ description using
Xilinx Vivado HLS and synthesized with Xilinx Vivado. Our architecture achieves
100 Gb/s data rate in a Xilinx Virtex-7 FPGA while reducing the latency by 45%
and the LUT usage by 40% compared to the state-of-the-art.
"
845,"Decanting the Contribution of Instruction Types and Loop Structures in
  the Reuse of Traces","  Reuse has been proposed as a microarchitecture-level mechanism to reduce the
amount of executed instructions, collapsing dependencies and freeing resources
for other instructions. Previous works have used reuse domains such as memory
accesses, integer or not floating point, based on the reusability rate.
However, these works have not studied the specific contribution of reusing
different subsets of instructions for performance. In this work, we analysed
the sensitivity of trace reuse to instruction subsets, comparing their
efficiency to their complementary subsets. We also studied the amount of reuse
that can be extracted from loops. Our experiments show that disabling trace
reuse outside loops does not harm performance but reduces in 12% the number of
accesses to the reuse table. Our experiments with reuse subsets show that most
of the speedup can be retained even when not reusing all types of instructions
previously found in the reuse domain.
"
846,"Mitigating Read-disturbance Errors in STT-RAM Caches by Using Data
  Compression","  Due to its high density and close-to-SRAM read latency, spin transfer torque
RAM (STT-RAM) is considered one of the most-promising emerging memory
technologies for designing large last level caches (LLCs). However, in deep
sub-micron region, STT-RAM shows read-disturbance error (RDE) whereby a read
operation may modify the stored data value and this presents a severe threat to
performance and reliability of STT-RAM caches. In this paper, we present a
technique, named SHIELD, to mitigate RDE in STT-RAM LLCs. SHIELD uses data
compression to reduce number of read operations from STT-RAM blocks to avoid
RDE and also to reduce the number of bits written to cache during both write
and restore operations. Experimental results have shown that SHIELD provides
significant improvement in performance and energy efficiency. SHIELD consumes
smaller energy than two previous RDE-mitigation techniques, namely high-current
restore required read (HCRR, also called restore-after-read) and low-current
long latency read (LCLL) and even an ideal RDE-free STT-RAM cache.
"
847,E-PUR: An Energy-Efficient Processing Unit for Recurrent Neural Networks,"  Recurrent Neural Networks (RNNs) are a key technology for emerging
applications such as automatic speech recognition, machine translation or image
description. Long Short Term Memory (LSTM) networks are the most successful RNN
implementation, as they can learn long term dependencies to achieve high
accuracy. Unfortunately, the recurrent nature of LSTM networks significantly
constrains the amount of parallelism and, hence, multicore CPUs and many-core
GPUs exhibit poor efficiency for RNN inference. In this paper, we present
E-PUR, an energy-efficient processing unit tailored to the requirements of LSTM
computation. The main goal of E-PUR is to support large recurrent neural
networks for low-power mobile devices. E-PUR provides an efficient hardware
implementation of LSTM networks that is flexible to support diverse
applications. One of its main novelties is a technique that we call Maximizing
Weight Locality (MWL), which improves the temporal locality of the memory
accesses for fetching the synaptic weights, reducing the memory requirements by
a large extent. Our experimental results show that E-PUR achieves real-time
performance for different LSTM networks, while reducing energy consumption by
orders of magnitude with respect to general-purpose processors and GPUs, and it
requires a very small chip area. Compared to a modern mobile SoC, an NVIDIA
Tegra X1, E-PUR provides an average energy reduction of 92x.
"
848,"BILBO-friendly Hybrid BIST Architecture with Asymmetric Polynomial
  Reseeding","  By advances in technology, integrated circuits have come to include more
functionality and more complexity in a single chip. Although methods of testing
have improved, but the increase in complexity of circuits, keeps testing a
challenging problem. Two important challenges in testing of digital circuits
are test time and accessing the circuit under test (CUT) for testing. These
challenges become even more important in complex system on chip (SoC) zone.
This paper presents a multistage test strategy to be implemented on a BIST
architecture for reducing test time of a simple core as solution for more
global application of SoC testing strategy. This strategy implements its test
pattern generation and output response analyzer in a BILBO architecture. The
proposed method benefits from an irregular polynomial BILBO (IP-BILBO)
structure to improve its test results. Experimental results on ISCAS-89
benchmark circuits show an average of 35% improvement in test time in
proportion to pervious work.
"
849,"Enabling Fine-Grain Restricted Coset Coding Through Word-Level
  Compression for PCM","  Phase change memory (PCM) has recently emerged as a promising technology to
meet the fast growing demand for large capacity memory in computer systems,
replacing DRAM that is impeded by physical limitations. Multi-level cell (MLC)
PCM offers high density with low per-byte fabrication cost. However, despite
many advantages, such as scalability and low leakage, the energy for
programming intermediate states is considerably larger than programing
single-level cell PCM. In this paper, we study encoding techniques to reduce
write energy for MLC PCM when the encoding granularity is lowered below the
typical cache line size. We observe that encoding data blocks at small
granularity to reduce write energy actually increases the write energy because
of the auxiliary encoding bits. We mitigate this adverse effect by 1) designing
suitable codeword mappings that use fewer auxiliary bits and 2) proposing a new
Word-Level Compression (WLC) which compresses more than 91% of the memory lines
and provides enough room to store the auxiliary data using a novel restricted
coset encoding applied at small data block granularities.
  Experimental results show that the proposed encoding at 16-bit data
granularity reduces the write energy by 39%, on average, versus the leading
encoding approach for write energy reduction. Furthermore, it improves
endurance by 20% and is more reliable than the leading approach. Hardware
synthesis evaluation shows that the proposed encoding can be implemented
on-chip with only a nominal area overhead.
"
850,"fpgaConvNet: A Toolflow for Mapping Diverse Convolutional Neural
  Networks on Embedded FPGAs","  In recent years, Convolutional Neural Networks (ConvNets) have become an
enabling technology for a wide range of novel embedded Artificial Intelligence
systems. Across the range of applications, the performance needs vary
significantly, from high-throughput video surveillance to the very low-latency
requirements of autonomous cars. In this context, FPGAs can provide a potential
platform that can be optimally configured based on the different performance
needs. However, the complexity of ConvNet models keeps increasing making their
mapping to an FPGA device a challenging task. This work presents fpgaConvNet,
an end-to-end framework for mapping ConvNets on FPGAs. The proposed framework
employs an automated design methodology based on the Synchronous Dataflow (SDF)
paradigm and defines a set of SDF transformations in order to efficiently
explore the architectural design space. By selectively optimising for
throughput, latency or multiobjective criteria, the presented tool is able to
efficiently explore the design space and generate hardware designs from
high-level ConvNet specifications, explicitly optimised for the performance
metric of interest. Overall, our framework yields designs that improve the
performance by up to 6.65x over highly optimised embedded GPU designs for the
same power constraints in embedded environments.
"
851,A Transprecision Floating-Point Platform for Ultra-Low Power Computing,"  In modern low-power embedded platforms, floating-point (FP) operations emerge
as a major contributor to the energy consumption of compute-intensive
applications with large dynamic range. Experimental evidence shows that 50% of
the energy consumed by a core and its data memory is related to FP
computations. The adoption of FP formats requiring a lower number of bits is an
interesting opportunity to reduce energy consumption, since it allows to
simplify the arithmetic circuitry and to reduce the memory bandwidth between
memory and registers by enabling vectorization. From a theoretical point of
view, the adoption of multiple FP types perfectly fits with the principle of
transprecision computing, allowing fine-grained control of approximation while
meeting specified constraints on the precision of final results. In this paper
we propose an extended FP type system with complete hardware support to enable
transprecision computing on low-power embedded processors, including two
standard formats (binary32 and binary16) and two new formats (binary8 and
binary16alt). First, we introduce a software library that enables exploration
of FP types by tuning both precision and dynamic range of program variables.
Then, we present a methodology to integrate our library with an external tool
for precision tuning, and experimental results that highlight the clear
benefits of introducing the new formats. Finally, we present the design of a
transprecision FP unit capable of handling 8-bit and 16-bit operations in
addition to standard 32-bit operations. Experimental results on FP-intensive
benchmarks show that up to 90% of FP operations can be safely scaled down to
8-bit or 16-bit formats. Thanks to precision tuning and vectorization,
execution time is decreased by 12% and memory accesses are reduced by 27% on
average, leading to a reduction of energy consumption up to 30%.
"
852,LP-Based Power Grid Enhancement Methodology,"  In this paper, we explored the opportunity to enhance power grid robustness
after routing stage, and propose a linear programming based algorithm that
maximizes the improvement of power grid strengthening with given available
routing resource. We further discussed some techniques to leverage tradeoffs
between runtime and optimality of the solutions. Experimental results show
substantial power integrity improvement with ""zero cost"".
"
853,"Energy-Efficient Time-Domain Vector-by-Matrix Multiplier for
  Neurocomputing and Beyond","  We propose an extremely energy-efficient mixed-signal approach for performing
vector-by-matrix multiplication in a time domain. In such implementation,
multi-bit values of the input and output vector elements are represented with
time-encoded digital signals, while multi-bit matrix weights are realized with
current sources, e.g. transistors biased in subthreshold regime. With our
approach, multipliers can be chained together to implement large-scale circuits
completely in a time domain. Multiplier operation does not rely on
energy-taxing static currents, which are typical for peripheral and
input/output conversion circuits of the conventional mixed-signal
implementations. As a case study, we have designed a multilayer perceptron,
based on two layers of 10x10 four-quadrant vector-by-matrix multipliers, in
55-nm process with embedded NOR flash memory technology, which allows for
compact implementation of adjustable current sources. Our analysis, based on
memory cell measurements, shows that at high computing speed the drain-induced
barrier lowering is a major factor limiting multiplier precision to ~6 bit.
Post-layout estimates for a conservative 6-bit digital input/output NxN
multiplier designed in 55 nm process, including I/O circuitry for converting
between digital and time domain representations, show ~7 fJ/Op for N>200, which
can be further lowered well below 1 fJ/Op for more optimal and aggressive
design.
"
854,"Errors in Flash-Memory-Based Solid-State Drives: Analysis, Mitigation,
  and Recovery","  NAND flash memory is ubiquitous in everyday life today because its capacity
has continuously increased and cost has continuously decreased over decades.
This positive growth is a result of two key trends: (1) effective process
technology scaling; and (2) multi-level (e.g., MLC, TLC) cell data coding.
Unfortunately, the reliability of raw data stored in flash memory has also
continued to become more difficult to ensure, because these two trends lead to
(1) fewer electrons in the flash memory cell floating gate to represent the
data; and (2) larger cell-to-cell interference and disturbance effects. Without
mitigation, worsening reliability can reduce the lifetime of NAND flash memory.
As a result, flash memory controllers in solid-state drives (SSDs) have become
much more sophisticated: they incorporate many effective techniques to ensure
the correct interpretation of noisy data stored in flash memory cells.
  In this chapter, we review recent advances in SSD error characterization,
mitigation, and data recovery techniques for reliability and lifetime
improvement. We provide rigorous experimental data from state-of-the-art MLC
and TLC NAND flash devices on various types of flash memory errors, to motivate
the need for such techniques. Based on the understanding developed by the
experimental characterization, we describe several mitigation and recovery
techniques, including (1) cell-tocell interference mitigation; (2) optimal
multi-level cell sensing; (3) error correction using state-of-the-art
algorithms and methods; and (4) data recovery when error correction fails. We
quantify the reliability improvement provided by each of these techniques.
Looking forward, we briefly discuss how flash memory and these techniques could
evolve into the future.
"
855,Machine Learning and Manycore Systems Design: A Serendipitous Symbiosis,"  Tight collaboration between experts of machine learning and manycore system
design is necessary to create a data-driven manycore design framework that
integrates both learning and expert knowledge. Such a framework will be
necessary to address the rising complexity of designing large-scale manycore
systems and machine learning techniques.
"
856,Data Cache Prefetching with Perceptron Learning,"  Cache prefetcher greatly eliminates compulsory cache misses, by fetching data
from slower memory to faster cache before it is actually required by
processors. Sophisticated prefetchers predict next use cache line by repeating
program's historical spatial and temporal memory access pattern. However, they
are error prone and the mis-predictions lead to cache pollution and exert extra
pressure on memory subsystem. In this paper, a novel scheme of data cache
prefetching with perceptron learning is proposed. The key idea is a two-level
prefetching mechanism. A primary decision is made by utilizing previous
table-based prefetching mechanism, e.g. stride prefetching or Markov
prefetching, and then, a neural network, perceptron is taken to detect and
trace program memory access patterns, to help reject those unnecessary
prefetching decisions. The perceptron can learn from both local and global
history in time and space, and can be easily implemented by hardware. This
mechanism boost execution performance by ideally mitigating cache pollution and
eliminating redundant memory request issued by prefetcher. Detailed evaluation
and analysis were conducted based on SPEC CPU 2006 benchmarks. The simulation
results show that generally the proposed scheme yields a geometric mean of
60.64%-83.84% decrease in prefetching memory requests without loss in
instruction per cycle(IPC)(floating between -2.22% and 2.55%) and cache hit
rate(floating between -1.67% and 2.46%). Though it is possible that perceptron
may refuse useful blocks and thus cause minor raise in cache miss rate, lower
memory request count can decrease average memory access latency, which
compensate for the loss, and in the meantime, enhance overall performance in
multi-programmed workloads.
"
857,"NEURAghe: Exploiting CPU-FPGA Synergies for Efficient and Flexible CNN
  Inference Acceleration on Zynq SoCs","  Deep convolutional neural networks (CNNs) obtain outstanding results in tasks
that require human-level understanding of data, like image or speech
recognition. However, their computational load is significant, motivating the
development of CNN-specialized accelerators. This work presents NEURAghe, a
flexible and efficient hardware/software solution for the acceleration of CNNs
on Zynq SoCs. NEURAghe leverages the synergistic usage of Zynq ARM cores and of
a powerful and flexible Convolution-Specific Processor deployed on the
reconfigurable logic. The Convolution-Specific Processor embeds both a
convolution engine and a programmable soft core, releasing the ARM processors
from most of the supervision duties and allowing the accelerator to be
controlled by software at an ultra-fine granularity. This methodology opens the
way for cooperative heterogeneous computing: while the accelerator takes care
of the bulk of the CNN workload, the ARM cores can seamlessly execute
hard-to-accelerate parts of the computational graph, taking advantage of the
NEON vector engines to further speed up computation. Through the companion
NeuDNN SW stack, NEURAghe supports end-to-end CNN-based classification with a
peak performance of 169 Gops/s, and an energy efficiency of 17 Gops/W. Thanks
to our heterogeneous computing model, our platform improves upon the
state-of-the-art, achieving a frame rate of 5.5 fps on the end-to-end execution
of VGG-16, and 6.6 fps on ResNet-18.
"
858,"An 826 MOPS, 210 uW/MHz Unum ALU in 65 nm","  To overcome the limitations of conventional floating-point number formats, an
interval arithmetic and variable-width storage format called universal number
(unum) has been recently introduced. This paper presents the first (to the best
of our knowledge) silicon implementation measurements of an
application-specific integrated circuit (ASIC) for unum floating-point
arithmetic. The designed chip includes a 128-bit wide unum arithmetic unit to
execute additions and subtractions, while also supporting lossless (for
intermediate results) and lossy (for external data movements) compression units
to exploit the memory usage reduction potential of the unum format. Our chip,
fabricated in a 65 nm CMOS process, achieves a maximum clock frequency of 413
MHz at 1.2 V with an average measured power of 210 uW/MHz.
"
859,"Bit Fusion: Bit-Level Dynamically Composable Architecture for
  Accelerating Deep Neural Networks","  Fully realizing the potential of acceleration for Deep Neural Networks (DNNs)
requires understanding and leveraging algorithmic properties. This paper builds
upon the algorithmic insight that bitwidth of operations in DNNs can be reduced
without compromising their classification accuracy. However, to prevent
accuracy loss, the bitwidth varies significantly across DNNs and it may even be
adjusted for each layer. Thus, a fixed-bitwidth accelerator would either offer
limited benefits to accommodate the worst-case bitwidth requirements, or lead
to a degradation in final accuracy. To alleviate these deficiencies, this work
introduces dynamic bit-level fusion/decomposition as a new dimension in the
design of DNN accelerators. We explore this dimension by designing Bit Fusion,
a bit-flexible accelerator, that constitutes an array of bit-level processing
elements that dynamically fuse to match the bitwidth of individual DNN layers.
This flexibility in the architecture enables minimizing the computation and the
communication at the finest granularity possible with no loss in accuracy. We
evaluate the benefits of BitFusion using eight real-world feed-forward and
recurrent DNNs. The proposed microarchitecture is implemented in Verilog and
synthesized in 45 nm technology. Using the synthesis results and cycle accurate
simulation, we compare the benefits of Bit Fusion to two state-of-the-art DNN
accelerators, Eyeriss and Stripes. In the same area, frequency, and process
technology, BitFusion offers 3.9x speedup and 5.1x energy savings over Eyeriss.
Compared to Stripes, BitFusion provides 2.6x speedup and 3.9x energy reduction
at 45 nm node when BitFusion area and frequency are set to those of Stripes.
Scaling to GPU technology node of 16 nm, BitFusion almost matches the
performance of a 250-Watt Titan Xp, which uses 8-bit vector instructions, while
BitFusion merely consumes 895 milliwatts of power.
"
860,"Design Automation for Binarized Neural Networks: A Quantum Leap
  Opportunity?","  Design automation in general, and in particular logic synthesis, can play a
key role in enabling the design of application-specific Binarized Neural
Networks (BNN). This paper presents the hardware design and synthesis of a
purely combinational BNN for ultra-low power near-sensor processing. We
leverage the major opportunities raised by BNN models, which consist mostly of
logical bit-wise operations and integer counting and comparisons, for pushing
ultra-low power deep learning circuits close to the sensor and coupling it with
binarized mixed-signal image sensor data. We analyze area, power and energy
metrics of BNNs synthesized as combinational networks. Our synthesis results in
GlobalFoundries 22nm SOI technology shows a silicon area of 2.61mm2 for
implementing a combinational BNN with 32x32 binary input sensor receptive field
and weight parameters fixed at design time. This is 2.2x smaller than a
synthesized network with re-configurable parameters. With respect to other
comparable techniques for deep learning near-sensor processing, our approach
features a 10x higher energy efficiency.
"
861,On Path Memory in List Successive Cancellation Decoder of Polar Codes,"  Polar code is a breakthrough in coding theory. Using list successive
cancellation decoding with large list size L, polar codes can achieve excellent
error correction performance. The L partial decoded vectors are stored in the
path memory and updated according to the results of list management. In the
state-of-the-art designs, the memories are implemented with registers and a
large crossbar is used for copying the partial decoded vectors from one block
of memory to another during the update. The architectures are quite area-costly
when the code length and list size are large. To solve this problem, we propose
two optimization schemes for the path memory in this work. First, a folded path
memory architecture is presented to reduce the area cost. Second, we show a
scheme that the path memory can be totally removed from the architecture.
Experimental results show that these schemes effectively reduce the area of
path memory.
"
862,"FPGA with Improved Routability and Robustness in 130nm CMOS with
  Open-Source CAD Targetability","  This paper outlines an FPGA VLSI design methodology that was used to realize
a fully functioning FPGA chip in 130nm CMOS with improved routability and
memory robustness. The architectural design space exploration and synthesis
capability were enabled by the Verilog-to-Routing CAD tool. The capabilities of
this tool were extended to enable bitstream generation and deployment. To
validate the architecture and bitstream implementation, a Chisel (Constructing
Hardware in the Embedded Scala Language) model of the FPGA was created to
rapidly verify the microarchitectural details of the device prior to schematic
design. A custom carrier board and configuration tool were used to verify
correct operational characteristics of the FPGA over various resource
utilizations and clock frequencies.
"
863,A Flexible High-Bandwidth Low-Latency Multi-Port Memory Controller,"  Multi-port memory controllers (MPMCs) have become increasingly important in
many modern applications due to the tremendous growth in bandwidth requirement.
Many approaches so far have focused on improving either the memory access
latency or the bandwidth utilization for specific applications. Moreover, the
application systems are likely to require certain adjustments to connect with
an MPMC, since the MPMC interface is limited to a single-clock and single
data-width domain. In this paper, we propose efficient techniques to improve
the flexibility, latency, and bandwidth of an MPMC. Firstly, MPMC interfaces
employ a pair of dual-clock dual-port FIFOs at each port, so any multi-clock
multi-data-width application system can connect to an MPMC without requiring
extra resources. Secondly, memory access latency is significantly reduced
because parallel FIFOs temporarily keep the data transfer between the
application system and memory. Lastly, a proposed arbitration scheme, namely
window-based first-come-first-serve, considerably enhances the bandwidth
utilization. Depending on the applications, MPMC can be properly configured by
updating several internal configuration registers. The experimental results in
an Altera Cyclone FPGA prove that MPMC is fully operational at 150 MHz and
supports up to 32 concurrent connections at various clocks and data widths.
More significantly, achieved bandwidth utilization is approximately 93.2% of
the theoretical bandwidth, and the access latency is minimized as compared to
previous designs.
"
864,"A Scalable High-Performance Priority Encoder Using 1D-Array to 2D-Array
  Conversion","  In our prior study of an L-bit priority encoder (PE), a so-called
one-directional-array to two-directional-array conversion method is deployed to
turn an L-bit input data into an MxN-bit matrix. Following this, an N-bit PE
and an M-bit PE are employed to obtain a row index and column index. From
those, the highest priority bit of L-bit input data is achieved. This brief
extends our previous work to construct a scalable architecture of
high-performance large-sized PEs. An optimum pair of (M, N) and look-ahead
signal are proposed to improve the overall PE performance significantly. The
evaluation is achieved by implementing a variety of PEs whose L varies from
4-bit to 4096-bit in 180-nm CMOS technology. According to post-place-and-route
simulation results, at PE size of 64 bits, 256 bits, and 2048 bits the
operating frequencies reach 649 MHz, 520 MHz, and 370 MHz, which are 1.2 times,
1.5 times, and 1.4 times, as high as state-of-the-art ones.
"
865,"Cross-Layer Optimization for Power-Efficient and Robust Digital Circuits
  and Systems","  With the increasing digital services demand, performance and power-efficiency
become vital requirements for digital circuits and systems. However, the
enabling CMOS technology scaling has been facing significant challenges of
device uncertainties, such as process, voltage, and temperature variations. To
ensure system reliability, worst-case corner assumptions are usually made in
each design level. However, the over-pessimistic worst-case margin leads to
unnecessary power waste and performance loss as high as 2.2x. Since
optimizations are traditionally confined to each specific level, those safe
margins can hardly be properly exploited.
  To tackle the challenge, it is therefore advised in this Ph.D. thesis to
perform a cross-layer optimization for digital signal processing circuits and
systems, to achieve a global balance of power consumption and output quality.
  To conclude, the traditional over-pessimistic worst-case approach leads to
huge power waste. In contrast, the adaptive voltage scaling approach saves
power (25% for the CORDIC application) by providing a just-needed supply
voltage. The power saving is maximized (46% for CORDIC) when a more aggressive
voltage over-scaling scheme is applied. These sparsely occurred circuit errors
produced by aggressive voltage over-scaling are mitigated by higher level error
resilient designs. For functions like FFT and CORDIC, smart error mitigation
schemes were proposed to enhance reliability (soft-errors and timing-errors,
respectively). Applications like Massive MIMO systems are robust against lower
level errors, thanks to the intrinsically redundant antennas. This property
makes it applicable to embrace digital hardware that trades quality for power
savings.
"
866,Multi-Mode Inference Engine for Convolutional Neural Networks,"  During the past few years, interest in convolutional neural networks (CNNs)
has risen constantly, thanks to their excellent performance on a wide range of
recognition and classification tasks. However, they suffer from the high level
of complexity imposed by the high-dimensional convolutions in convolutional
layers. Within scenarios with limited hardware resources and tight power and
latency constraints, the high computational complexity of CNNs makes them
difficult to be exploited. Hardware solutions have striven to reduce the power
consumption using low-power techniques, and to limit the processing time by
increasing the number of processing elements (PEs). While most of ASIC designs
claim a peak performance of a few hundred giga operations per seconds, their
average performance is substantially lower when applied to state-of-the-art
CNNs such as AlexNet, VGGNet and ResNet, leading to low resource utilization.
Their performance efficiency is limited to less than 55% on average, which
leads to unnecessarily high processing latency and silicon area. In this paper,
we propose a dataflow which enables to perform both the fully-connected and
convolutional computations for any filter/layer size using the same PEs. We
then introduce a multi-mode inference engine (MMIE) based on the proposed
dataflow. Finally, we show that the proposed MMIE achieves a performance
efficiency of more than 84% when performing the computations of the three
renown CNNs (i.e., AlexNet, VGGNet and ResNet), outperforming the best
architecture in the state-of-the-art in terms of energy consumption, processing
latency and silicon area.
"
867,Tactics to Directly Map CNN graphs on Embedded FPGAs,"  Deep Convolutional Neural Networks (CNNs) are the state-of-the-art in image
classification. Since CNN feed forward propagation involves highly regular
parallel computation, it benefits from a significant speed-up when running on
fine grain parallel programmable logic devices. As a consequence, several
studies have proposed FPGA-based accelerators for CNNs. However, because of the
large computationalpower required by CNNs, none of the previous studies has
proposed a direct mapping of the CNN onto the physical resources of an FPGA,
allocating each processing actor to its own hardware instance.In this paper, we
demonstrate the feasibility of the so called direct hardware mapping (DHM) and
discuss several tactics we explore to make DHM usable in practice. As a proof
of concept, we introduce the HADDOC2 open source tool, that automatically
transforms a CNN description into a synthesizable hardware description with
platform-independent direct hardware mapping.
"
868,Applying the Residue Number System to Network Inference,"  This work explores the lesser studied objective of optimizing the
multiply-and-accumulates executed during evaluation of the network. In
particular, we propose using the Residue Number System (RNS) as the internal
number representation across all layer evaluations, allowing us to explore
usage of the more power-efficient RNS multipliers and adders. Using results
from simulation of our RNS arithmetic block implementations, we show
theoretical power advantages of using RNS for an end-to-end evaluator.
"
869,"Reconfigurable Hardware Accelerators: Opportunities, Trends, and
  Challenges","  With the emerging big data applications of Machine Learning, Speech
Recognition, Artificial Intelligence, and DNA Sequencing in recent years,
computer architecture research communities are facing the explosive scale of
various data explosion. To achieve high efficiency of data-intensive computing,
studies of heterogeneous accelerators which focus on latest applications, have
become a hot issue in computer architecture domain. At present, the
implementation of heterogeneous accelerators mainly relies on heterogeneous
computing units such as Application-specific Integrated Circuit (ASIC),
Graphics Processing Unit (GPU), and Field Programmable Gate Array (FPGA). Among
the typical heterogeneous architectures above, FPGA-based reconfigurable
accelerators have two merits as follows: First, FPGA architecture contains a
large number of reconfigurable circuits, which satisfy requirements of high
performance and low power consumption when specific applications are running.
Second, the reconfigurable architectures of employing FPGA performs prototype
systems rapidly and features excellent customizability and reconfigurability.
Nowadays, in top-tier conferences of computer architecture, emerging a batch of
accelerating works based on FPGA or other reconfigurable architectures. To
better review the related work of reconfigurable computing accelerators
recently, this survey reserves latest high-level research products of
reconfigurable accelerator architectures and algorithm applications as the
basis. In this survey, we compare hot research issues and concern domains,
furthermore, analyze and illuminate advantages, disadvantages, and challenges
of reconfigurable accelerators. In the end, we prospect the development
tendency of accelerator architectures in the future, hoping to provide a
reference for computer architecture researchers.
"
870,Accelerator Codesign as Non-Linear Optimization,"  We propose an optimization approach for determining both hardware and
software parameters for the efficient implementation of a (family of)
applications called dense stencil computations on programmable GPGPUs. We first
introduce a simple, analytical model for the silicon area usage of accelerator
architectures and a workload characterization of stencil computations. We
combine this characterization with a parametric execution time model and
formulate a mathematical optimization problem. That problem seeks to maximize a
common objective function of 'all the hardware and software parameters'. The
solution to this problem, therefore ""solves"" the codesign problem:
simultaneously choosing software-hardware parameters to optimize total
performance.
  We validate this approach by proposing architectural variants of the NVIDIA
Maxwell GTX-980 (respectively, Titan X) specifically tuned to a predetermined
workload of four common 2D stencils (Heat, Jacobi, Laplacian, and Gradient) and
two 3D ones (Heat and Laplacian). Our model predicts that performance would
potentially improve by 28% (respectively, 33%) with simple tweaks to the
hardware parameters such as adapting coarse and fine-grained parallelism by
changing the number of streaming multiprocessors and the number of compute
cores each contains. We propose a set of Pareto-optimal design points to
exploit the trade-off between performance and silicon area and show that by
additionally eliminating GPU caches, we can get a further 2-fold improvement.
"
871,"The microarchitecture of a multi-threaded RISC-V compliant processing
  core family for IoT end-nodes","  Internet-of-Things end-nodes demand low power processing platforms
characterized by heterogeneous dedicated units, controlled by a processor core
running concurrent control threads. Such architecture scheme fits one of the
main target application domain of the RISC-V instruction set. We present an
open-source processing core compliant with RISC-V on the software side and with
the popular Pulpino processor platform on the hardware side, while supporting
interleaved multi-threading for IoT applications. The latter feature is a novel
contribution in this application domain. We report details about the
microarchitecture design along with performance data.
"
872,"Automated flow for compressing convolution neural networks for efficient
  edge-computation with FPGA","  Deep convolutional neural networks (CNN) based solutions are the current
state- of-the-art for computer vision tasks. Due to the large size of these
models, they are typically run on clusters of CPUs or GPUs. However, power
requirements and cost budgets can be a major hindrance in adoption of CNN for
IoT applications. Recent research highlights that CNN contain significant
redundancy in their structure and can be quantized to lower bit-width
parameters and activations, while maintaining acceptable accuracy. Low
bit-width and especially single bit-width (binary) CNN are particularly
suitable for mobile applications based on FPGA implementation, due to the
bitwise logic operations involved in binarized CNN. Moreover, the transition to
lower bit-widths opens new avenues for performance optimizations and model
improvement. In this paper, we present an automatic flow from trained
TensorFlow models to FPGA system on chip implementation of binarized CNN. This
flow involves quantization of model parameters and activations, generation of
network and model in embedded-C, followed by automatic generation of the FPGA
accelerator for binary convolutions. The automated flow is demonstrated through
implementation of binarized ""YOLOV2"" on the low cost, low power Cyclone- V FPGA
device. Experiments on object detection using binarized YOLOV2 demonstrate
significant performance benefit in terms of model size and inference speed on
FPGA as compared to CPU and mobile CPU platforms. Furthermore, the entire
automated flow from trained models to FPGA synthesis can be completed within
one hour.
"
873,"HERO: Heterogeneous Embedded Research Platform for Exploring RISC-V
  Manycore Accelerators on FPGA","  Heterogeneous embedded systems on chip (HESoCs) co-integrate a standard host
processor with programmable manycore accelerators (PMCAs) to combine
general-purpose computing with domain-specific, efficient processing
capabilities. While leading companies successfully advance their HESoC
products, research lags behind due to the challenges of building a prototyping
platform that unites an industry-standard host processor with an open research
PMCA architecture. In this work we introduce HERO, an FPGA-based research
platform that combines a PMCA composed of clusters of RISC-V cores, implemented
as soft cores on an FPGA fabric, with a hard ARM Cortex-A multicore host
processor. The PMCA architecture mapped on the FPGA is silicon-proven,
scalable, configurable, and fully modifiable. HERO includes a complete software
stack that consists of a heterogeneous cross-compilation toolchain with support
for OpenMP accelerator programming, a Linux driver, and runtime libraries for
both host and PMCA. HERO is designed to facilitate rapid exploration on all
software and hardware layers: run-time behavior can be accurately analyzed by
tracing events, and modifications can be validated through fully automated hard
ware and software builds and executed tests. We demonstrate the usefulness of
HERO by means of case studies from our research.
"
874,Improving DRAM Performance by Parallelizing Refreshes with Accesses,"  Modern DRAM cells are periodically refreshed to prevent data loss due to
leakage. Commodity DDR DRAM refreshes cells at the rank level. This degrades
performance significantly because it prevents an entire rank from serving
memory requests while being refreshed. DRAM designed for mobile platforms,
LPDDR DRAM, supports an enhanced mode, called per-bank refresh, that refreshes
cells at the bank level. This enables a bank to be accessed while another in
the same rank is being refreshed, alleviating part of the negative performance
impact of refreshes. However, there are two shortcomings of per-bank refresh.
First, the per-bank refresh scheduling scheme does not exploit the full
potential of overlapping refreshes with accesses across banks because it
restricts the banks to be refreshed in a sequential round-robin order. Second,
accesses to a bank that is being refreshed have to wait.
  To mitigate the negative performance impact of DRAM refresh, we propose two
complementary mechanisms, DARP (Dynamic Access Refresh Parallelization) and
SARP (Subarray Access Refresh Parallelization). The goal is to address the
drawbacks of per-bank refresh by building more efficient techniques to
parallelize refreshes and accesses within DRAM. First, instead of issuing
per-bank refreshes in a round-robin order, DARP issues per-bank refreshes to
idle banks in an out-of-order manner. Furthermore, DARP schedules refreshes
during intervals when a batch of writes are draining to DRAM. Second, SARP
exploits the existence of mostly-independent subarrays within a bank. With
minor modifications to DRAM organization, it allows a bank to serve memory
accesses to an idle subarray while another subarray is being refreshed.
Extensive evaluations show that our mechanisms improve system performance and
energy efficiency compared to state-of-the-art refresh policies and the benefit
increases as DRAM density increases.
"
875,"T-count and Qubit Optimized Quantum Circuit Design of the Non-Restoring
  Square Root Algorithm","  Quantum circuits for basic mathematical functions such as the square root are
required to implement scientific computing algorithms on quantum computers.
Quantum circuits that are based on Clifford+T gates can easily be made fault
tolerant but the T gate is very costly to implement. As a result, reducing
T-count has become an important optimization goal. Further, quantum circuits
with many qubits are difficult to realize, making designs that save qubits and
produce no garbage outputs desirable. In this work, we present a T-count
optimized quantum square root circuit with only $2 \cdot n +1$ qubits and no
garbage output. To make a fair comparison against existing work, the Bennett's
garbage removal scheme is used to remove garbage output from existing works. We
determined that our proposed design achieves an average T-count savings of
$43.44 \%$, $98.95 \%$, $41.06 \%$ and $20.28 \%$ as well as qubit savings of
$85.46 \%$, $95.16 \%$, $90.59 \%$ and $86.77 \%$ compared to existing works.
"
876,Understanding and Improving the Latency of DRAM-Based Memory Systems,"  Over the past two decades, the storage capacity and access bandwidth of main
memory have improved tremendously, by 128x and 20x, respectively. These
improvements are mainly due to the continuous technology scaling of DRAM
(dynamic random-access memory), which has been used as the physical substrate
for main memory. In stark contrast with capacity and bandwidth, DRAM latency
has remained almost constant, reducing by only 1.3x in the same time frame.
Therefore, long DRAM latency continues to be a critical performance bottleneck
in modern systems. Increasing core counts, and the emergence of increasingly
more data-intensive and latency-critical applications further stress the
importance of providing low-latency memory access.
  In this dissertation, we identify three main problems that contribute
significantly to long latency of DRAM accesses. To address these problems, we
present a series of new techniques. Our new techniques significantly improve
both system performance and energy efficiency. We also examine the critical
relationship between supply voltage and latency in modern DRAM chips and
develop new mechanisms that exploit this voltage-latency trade-off to improve
energy efficiency.
  The key conclusion of this dissertation is that augmenting DRAM architecture
with simple and low-cost features, and developing a better understanding of
manufactured DRAM chips together lead to significant memory latency reduction
as well as energy efficiency improvement. We hope and believe that the proposed
architectural techniques and the detailed experimental data and observations on
real commodity DRAM chips presented in this dissertation will enable
development of other new mechanisms to improve the performance, energy
efficiency, or reliability of future memory systems.
"
877,A Survey of FPGA-Based Neural Network Accelerator,"  Recent researches on neural network have shown significant advantage in
machine learning over traditional algorithms based on handcrafted features and
models. Neural network is now widely adopted in regions like image, speech and
video recognition. But the high computation and storage complexity of neural
network inference poses great difficulty on its application. CPU platforms are
hard to offer enough computation capacity. GPU platforms are the first choice
for neural network process because of its high computation capacity and easy to
use development frameworks.
  On the other hand, FPGA-based neural network inference accelerator is
becoming a research topic. With specifically designed hardware, FPGA is the
next possible solution to surpass GPU in speed and energy efficiency. Various
FPGA-based accelerator designs have been proposed with software and hardware
optimization techniques to achieve high speed and energy efficiency. In this
paper, we give an overview of previous work on neural network inference
accelerators based on FPGA and summarize the main techniques used. An
investigation from software to hardware, from circuit level to system level is
carried out to complete analysis of FPGA-based neural network inference
accelerator design and serves as a guide to future work.
"
878,"Automated Formal Equivalence Verification of Pipelined Nested Loops in
  Datapath Designs","  In this paper, we present an efficient formal approach to check the
equivalence of synthesized RTL against the high-level specification in the
presence of pipelining transformations. To increase the scalability of our
proposed method, we dynamically divide the designs into several smaller parts
called segments by introducing cut-points. Then we employ Modular Horner
Expansion Diagram (M-HED) to check whether the specification and implementation
are equivalent or not. In an iterative manner, the equivalence checking for
each segment is performed. At each step, the equivalent nodes and those nodes
which have an impact on them are removed until the whole design is covered. Our
proposed method enables us to deal with the equivalence checking problem for
behaviorally synthesized designs even in the presence of pipelines for nested
loops. The empirical results demonstrate the efficiency and scalability of our
proposed method in terms of run-time and memory usage for several large designs
synthesized by a commercial behavioral synthesis tool. Average improvements in
terms of the memory usage and run time in comparison with SMT- and SAT-based
equivalence checking are 16.7x and 111.9x, respectively.
"
879,Analytical Inverter Delay Modeling Using Matlab's Curve Fitting Toolbox,"  This paper presents a new analytical propagation delay model for deep
submicron CMOS inverters. The model is inspired by the key observation that the
inverter delay is a complicated function of several process parameters as well
as load capacitance. These relationships are considered by fitting functions
for each parameter derived from the Curve Fitting Toolbox in Matlab. Compared
to SPICE simulations based on the BSIM4 transistor model, the analytical delay
model shows very good accuracy with an average error less than 2% over a wide
range of process parameters and output loads. Hence, the proposed model can be
efficiently used for different technology nodes as well as statistical gate
delay characterisation.
"
880,Auto-Generation of Pipelined Hardware Designs for Polar Encoder,"  This paper presents a general framework for auto-generation of pipelined
polar encoder architectures. The proposed framework could be well represented
by a general formula. Given arbitrary code length $N$ and the level of
parallelism $M$, the formula could specify the corresponding hardware
architecture. We have written a compiler which could read the formula and then
automatically generate its register-transfer level (RTL) description suitable
for FPGA or ASIC implementation. With this hardware generation system, one
could explore the design space and make a trade-off between cost and
performance. Our experimental results have demonstrated the efficiency of this
auto-generator for polar encoder architectures.
"
881,"Instruction-Level Abstraction (ILA): A Uniform Specification for
  System-on-Chip (SoC) Verification","  Modern Systems-on-Chip (SoC) designs are increasingly heterogeneous and
contain specialized semi-programmable accelerators in addition to programmable
processors. In contrast to the pre-accelerator era, when the ISA played an
important role in verification by enabling a clean separation of concerns
between software and hardware, verification of these ""accelerator-rich"" SoCs
presents new challenges. From the perspective of hardware designers, there is a
lack of a common framework for the formal functional specification of
accelerator behavior. From the perspective of software developers, there exists
no unified framework for reasoning about software/hardware interactions of
programs that interact with accelerators. This paper addresses these challenges
by providing a formal specification and high-level abstraction for accelerator
functional behavior. It formalizes the concept of an Instruction Level
Abstraction (ILA), developed informally in our previous work, and shows its
application in modeling and verification of accelerators. This formal ILA
extends the familiar notion of instructions to accelerators and provides a
uniform, modular, and hierarchical abstraction for modeling software-visible
behavior of both accelerators and programmable processors. We demonstrate the
applicability of the ILA through several case studies of accelerators (for
image processing, machine learning, and cryptography), and a general-purpose
processor (RISC-V). We show how the ILA model facilitates equivalence checking
between two ILAs, and between an ILA and its hardware finite-state machine
(FSM) implementation. Further, this equivalence checking supports accelerator
upgrades using the notion of ILA compatibility, similar to processor upgrades
using ISA compatibility.
"
882,Approximate FPGA-based LSTMs under Computation Time Constraints,"  Recurrent Neural Networks and in particular Long Short-Term Memory (LSTM)
networks have demonstrated state-of-the-art accuracy in several emerging
Artificial Intelligence tasks. However, the models are becoming increasingly
demanding in terms of computational and memory load. Emerging latency-sensitive
applications including mobile robots and autonomous vehicles often operate
under stringent computation time constraints. In this paper, we address the
challenge of deploying computationally demanding LSTMs at a constrained time
budget by introducing an approximate computing scheme that combines iterative
low-rank compression and pruning, along with a novel FPGA-based LSTM
architecture. Combined in an end-to-end framework, the approximation method's
parameters are optimised and the architecture is configured to address the
problem of high-performance LSTM execution in time-constrained applications.
Quantitative evaluation on a real-life image captioning application indicates
that the proposed methods required up to 6.5x less time to achieve the same
application-level accuracy compared to a baseline method, while achieving an
average of 25x higher accuracy under the same computation time constraints.
"
883,Spiking memristor logic gates are a type of time-variant perceptron,"  Memristors are low-power memory-holding resistors thought to be useful for
neuromophic computing, which can compute via spike-interactions mediated
through the device's short-term memory. Using interacting spikes, it is
possible to build an AND gate that computes OR at the same time, similarly a
full adder can be built that computes the arithmetical sum of its inputs. Here
we show how these gates can be understood by modelling the memristors as a
novel type of perceptron: one which is sensitive to input order. The
memristor's memory can change the input weights for later inputs, and thus the
memristor gates cannot be accurately described by a single perceptron,
requiring either a network of time-invarient perceptrons or a complex
time-varying self-reprogrammable perceptron. This work demonstrates the high
functionality of memristor logic gates, and also that the addition of
theasholding could enable the creation of a standard perceptron in hardware,
which may have use in building neural net chips.
"
884,Mechanical Computing Systems Using Only Links and Rotary Joints,"  A new model for mechanical computing is demonstrated that requires only two
basic parts: links and rotary joints. These basic parts are combined into two
main higher level structures: locks and balances, which suffice to create all
necessary combinatorial and sequential logic required for a Turing-complete
computational system. While working systems have yet to be implemented using
this new approach, the mechanical simplicity of the systems described may lend
themselves better to, e.g., microfabrication, than previous mechanical
computing designs. Additionally, simulations indicate that if molecular-scale
implementations could be realized, they would be far more energy-efficient than
conventional electronic computers.
"
885,"A Software-defined SoC Memory Bus Bridge Architecture for Disaggregated
  Computing","  Disaggregation and rack-scale systems have the potential of drastically
decreasing TCO and increasing utilization of cloud datacenters, while
maintaining performance. While the concept of organising resources in separate
pools and interconnecting them together on demand is straightforward, its
materialisation can be radically different in terms of performance and scale
potential.
  In this paper, we present a memory bus bridge architecture which enables
communication between 100s of masters and slaves in todays complex
multiprocessor SoCs, that are physically intregrated in different chips and
even different mainboards. The bridge tightly couples serial transceivers and a
circuit network for chip-to-chip transfers. A key property of the proposed
bridge architecture is that it is software-defined and thus can be configured
at runtime, via a software control plane, to prepare and steer memory access
transactions to remote slaves. This is particularly important because it
enables datacenter orchestration tools to manage the disaggregated resource
allocation. Moreover, we evaluate a bridge prototype we have build for ARM AXI4
memory bus interconnect and we discuss application-level observed performance.
"
886,"Dependability modeling and optimization of triple modular redundancy
  partitioning for SRAM-based FPGAs","  SRAM-based FPGAs are popular in the aerospace industry for their field
programmability and low cost. However, they suffer from cosmic
radiation-induced Single Event Upsets (SEUs). Triple Modular Redundancy (TMR)
is a well-known technique to mitigate SEUs in FPGAs that is often used with
another SEU mitigation technique known as configuration scrubbing. Traditional
TMR provides protection against a single fault at a time, while partitioned TMR
provides improved reliability and availability. In this paper, we present a
methodology to analyze TMR partitioning at early design stage using
probabilistic model checking. The proposed formal model can capture both single
and multiple-cell upset scenarios, regardless of any assumption of equal
partition sizes. Starting with a high-level description of a design, a Markov
model is constructed from the Data Flow Graph (DFG) using a specified number of
partitions, a component characterization library and a user defined scrub rate.
Such a model and exhaustive analysis captures all the considered failures and
repairs possible in the system within the radiation environment. Various
reliability and availability properties are then verified automatically using
the PRISM model checker exploring the relationship between the scrub frequency
and the number of TMR partitions required to meet the design requirements.
Also, the reported results show that based on a known voter failure rate, it is
possible to find an optimal number of partitions at early design stages using
our proposed method.
"
887,"Inter-thread Communication in Multithreaded, Reconfigurable Coarse-grain
  Arrays","  Traditional von Neumann GPGPUs only allow threads to communicate through
memory on a group-to-group basis. In this model, a group of producer threads
writes intermediate values to memory, which are read by a group of consumer
threads after a barrier synchronization. To alleviate the memory bandwidth
imposed by this method of communication, GPGPUs provide a small scratchpad
memory that prevents intermediate values from overloading DRAM bandwidth. In
this paper we introduce direct inter-thread communications for massively
multithreaded CGRAs, where intermediate values are communicated directly
through the compute fabric on a point-to-point basis. This method avoids the
need to write values to memory, eliminates the need for a dedicated scratchpad,
and avoids workgroup-global barriers. The paper introduces the programming
model (CUDA) and execution model extensions, as well as the hardware primitives
that facilitate the communication. Our simulations of Rodinia benchmarks
running on the new system show that direct inter-thread communication provides
an average speedup of 4.5x (13.5x max) and reduces system power by an average
of 7x (33x max), when compared to an equivalent Nvidia GPGPU.
"
888,Trends in Processor Architecture,"  This paper presents an overview of the main trends in processor architecture.
It starts with an analysis of the past evolution of processors and the main
driving forces behind it, and then it focuses on a description of the main
architectural features of current processors. Finally, it presents a discussion
on some promising directions for future evolution of processor architectures.
"
889,In-network Neural Networks,"  We present N2Net, a system that implements binary neural networks using
commodity switching chips deployed in network switches and routers. Our system
shows that these devices can run simple neural network models, whose input is
encoded in the network packets' header, at packet processing speeds (billions
of packets per second). Furthermore, our experience highlights that switching
chips could support even more complex models, provided that some minor and
cheap modifications to the chip's design are applied. We believe N2Net provides
an interesting building block for future end-to-end networked systems.
"
890,"An Energy-Efficient FPGA-based Deconvolutional Neural Networks
  Accelerator for Single Image Super-Resolution","  Convolutional neural networks (CNNs) demonstrate excellent performance in
various computer vision applications. In recent years, FPGA-based CNN
accelerators have been proposed for optimizing performance and power
efficiency. Most accelerators are designed for object detection and recognition
algorithms that are performed on low-resolution (LR) images. However, real-time
image super-resolution (SR) cannot be implemented on a typical accelerator
because of the long execution cycles required to generate high-resolution (HR)
images, such as those used in ultra-high-definition (UHD) systems. In this
paper, we propose a novel CNN accelerator with efficient parallelization
methods for SR applications. First, we propose a new methodology for optimizing
the deconvolutional neural networks (DCNNs) used for increasing feature maps.
Secondly, we propose a novel method to optimize CNN dataflow so that the SR
algorithm can be driven at low power in display applications. Finally, we
quantize and compress a DCNN-based SR algorithm into an optimal model for
efficient inference using on-chip memory. We present an energy-efficient
architecture for SR and validate our architecture on a mobile panel with
quad-high-definition (QHD) resolution. Our experimental results show that, with
the same hardware resources, the proposed DCNN accelerator achieves a
throughput up to 108 times greater than that of a conventional DCNN
accelerator. In addition, our SR system achieves an energy efficiency of 144.9
GOPS/W, 293.0 GOPS/W, and 500.2 GOPS/W at SR scale factors of 2, 3, and 4,
respectively. Furthermore, we demonstrate that our system can restore HR images
to a high quality while greatly reducing the data bit-width and the number of
parameters compared to conventional SR algorithms.
"
891,In-RDBMS Hardware Acceleration of Advanced Analytics,"  The data revolution is fueled by advances in machine learning, databases, and
hardware design. Programmable accelerators are making their way into each of
these areas independently. As such, there is a void of solutions that enables
hardware acceleration at the intersection of these disjoint fields. This paper
sets out to be the initial step towards a unifying solution for in-Database
Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such
as FPGAs, for in-database analytics currently requires hand-designing the
hardware and manually routing the data. Instead, DAnA automatically maps a
high-level specification of advanced analytics queries to an FPGA accelerator.
The accelerator implementation is generated for a User Defined Function (UDF),
expressed as a part of an SQL query using a Python-embedded Domain-Specific
Language (DSL). To realize an efficient in-database integration, DAnA
accelerators contain a novel hardware structure, Striders, that directly
interface with the buffer pool of the database. Striders extract, cleanse, and
process the training data tuples that are consumed by a multi-threaded FPGA
engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL
to generate hardware accelerators for a range of real-world and synthetic
datasets running diverse ML algorithms. Results show that DAnA-enhanced
PostgreSQL provides, on average, 8.3x end-to-end speedup for real datasets,
with a maximum of 28.2x. Moreover, DAnA-enhanced PostgreSQL is, on average,
4.0x faster than the multi-threaded Apache MADLib running on Greenplum. DAnA
provides these benefits while hiding the complexity of hardware design from
data scientists and allowing them to express the algorithm in =30-60 lines of
Python.
"
892,"Approximate Early Output Asynchronous Adders Based on Dual-Rail Data
  Encoding and 4-Phase Return-to-Zero and Return-to-One Handshaking","  Approximate computing is emerging as an alternative to accurate computing due
to its potential for realizing digital circuits and systems with low power
dissipation, less critical path delay, and less area occupancy for an
acceptable trade-off in the accuracy of results. In the domain of computer
arithmetic, several approximate adders and multipliers have been designed and
their potential have been showcased versus accurate adders and multipliers for
practical digital signal processing applications. Nevertheless, in the existing
literature, almost all the approximate adders and multipliers reported
correspond to the synchronous design method. In this work, we consider robust
asynchronous i.e. quasi-delay-insensitive realizations of approximate adders by
employing delay-insensitive codes for data representation and processing, and
the 4-phase handshake protocols for data communication. The 4-phase handshake
protocols used are the return-to-zero and the return-to-one protocols.
Specifically, we consider the implementations of 32-bit approximate adders
based on the return-to-zero and return-to-one handshake protocols by adopting
the delay-insensitive dual-rail code for data encoding. We consider a range of
approximations varying from 4-bits to 20-bits for the least significant
positions of the accurate 32-bit asynchronous adder. The asynchronous adders
correspond to early output (i.e. early reset) type, which are based on the
well-known ripple carry adder architecture. The experimental results show that
approximate asynchronous adders achieve reductions in the design metrics such
as latency, cycle time, average power dissipation, and silicon area compared to
the accurate asynchronous adders. Further, the reductions in the design metrics
are greater for the return-to-one protocol compared to the return-to-zero
protocol. The design metrics were estimated using a 32/28nm CMOS technology.
"
893,"Mobile Machine Learning Hardware at ARM: A Systems-on-Chip (SoC)
  Perspective","  Machine learning is playing an increasingly significant role in emerging
mobile application domains such as AR/VR, ADAS, etc. Accordingly, hardware
architects have designed customized hardware for machine learning algorithms,
especially neural networks, to improve compute efficiency. However, machine
learning is typically just one processing stage in complex end-to-end
applications, involving multiple components in a mobile Systems-on-a-chip
(SoC). Focusing only on ML accelerators loses bigger optimization opportunity
at the system (SoC) level. This paper argues that hardware architects should
expand the optimization scope to the entire SoC. We demonstrate one particular
case-study in the domain of continuous computer vision where camera sensor,
image signal processor (ISP), memory, and NN accelerator are synergistically
co-designed to achieve optimal system-level efficiency.
"
894,Design Guidelines for High-Performance SCM Hierarchies,"  With emerging storage-class memory (SCM) nearing commercialization, there is
evidence that it will deliver the much-anticipated high density and access
latencies within only a few factors of DRAM. Nevertheless, the
latency-sensitive nature of memory-resident services makes seamless integration
of SCM in servers questionable. In this paper, we ask the question of how best
to introduce SCM for such servers to improve overall performance/cost over
existing DRAM-only architectures. We first show that even with the most
optimistic latency projections for SCM, the higher memory access latency
results in prohibitive performance degradation. However, we find that
deployment of a modestly sized high-bandwidth 3D stacked DRAM cache makes the
performance of an SCM-mostly memory system competitive. The high degree of
spatial locality that memory-resident services exhibit not only simplifies the
DRAM cache's design as page-based, but also enables the amortization of
increased SCM access latencies and the mitigation of SCM's read/write latency
disparity.
  We identify the set of memory hierarchy design parameters that plays a key
role in the performance and cost of a memory system combining an SCM technology
and a 3D stacked DRAM cache. We then introduce a methodology to drive
provisioning for each of these design parameters under a target
performance/cost goal. Finally, we use our methodology to derive concrete
results for specific SCM technologies. With PCM as a case study, we show that a
two bits/cell technology hits the performance/cost sweet spot, reducing the
memory subsystem cost by 40% while keeping performance within 3% of the best
performing DRAM-only system, whereas single-level and triple-level cell
organizations are impractical for use as memory replacements.
"
895,HCIC: Hardware-assisted Control-flow Integrity Checking,"  Recently, code reuse attacks (CRAs), such as return-oriented programming
(ROP) and jump-oriented programming (JOP), have emerged as a new class of
ingenious security threatens. Attackers can utilize CRAs to hijack the control
flow of programs to perform malicious actions without injecting any codes. Many
defenses, classed into software-based and hardware-based, have been proposed.
However, software-based methods are difficult to be deployed in practical
systems due to high performance overhead. Hardware-based methods can reduce
performance overhead but may require extending instruction set architectures
(ISAs) and modifying compiler or suffer the vulnerability of key leakage. To
tackle these issues, this paper proposes a new hardware-based control flow
checking method to resist CRAs with negligible performance overhead without
extending ISAs, modifying compiler and leaking the encryption/decryption key.
The key technique involves two control flow checking mechanisms. The first one
is the encrypted Hamming distances (EHDs) matching between the physical
unclonable function (PUF) response and the return addresses, which prevents
attackers from returning between gadgets so long as the PUF response is secret,
thus resisting ROP attacks. The second one is the liner encryption/decryption
operation (XOR) between PUF response and the instructions at target addresses
of call and jmp instructions to defeat JOP attacks. Advanced return-based
full-function reuse attacks will be prevented with the dynamic key-updating
method. Experimental evaluations on benchmarks demonstrate that the proposed
method introduces negligible 0.95% run-time overhead and 0.78% binary size
overhead on average.
"
896,Pointer-Chase Prefetcher for Linked Data Structures,"  Caches only exploit spatial and temporal locality in a set of address
referenced in a program. Due to dynamic construction of linked data-structures,
they are difficult to cache as the spatial locality between the nodes is highly
dependent on the data layout. Prefetching can play an important role in
improving the performance of linked data-structures. In this project, a pointer
chase mechanism along with compiler hints is adopted to design a prefetcher for
linked data-structures. The design is evaluated against the baseline of
processor with cache in terms of performance, area and energy
"
897,"Low Complexity Multiply-Accumulate Units for Convolutional Neural
  Networks with Weight-Sharing","  Convolutional neural networks (CNNs) are one of the most successful machine
learning techniques for image, voice and video processing. CNNs require large
amounts of processing capacity and memory bandwidth. Hardware accelerators have
been proposed for CNNs which typically contain large numbers of
multiply-accumulate (MAC) units, the multipliers of which are large in an
integrated circuit (IC) gate count and power consumption. ""Weight sharing""
accelerators have been proposed where the full range of weight values in a
trained CNN are compressed and put into bins and the bin index used to access
the weight-shared value. We reduce power and area of the CNN by implementing
parallel accumulate shared MAC (PASM) in a weight shared CNN. PASM
re-architects the MAC to instead count the frequency of each weight and place
it in a bin. The accumulated value is computed in a subsequent multiply phase,
significantly reducing gate count and power consumption of the CNN. In this
paper, we implement PASM in a weight-shared CNN convolution hardware
accelerator and analyze its effectiveness. Experiments show that for a clock
speed 1GHz implemented on a 45nm ASIC process our approach results in fewer
gates, smaller logic, and reduced power with only a slight increase in latency.
We also show that the same weight-shared-with-PASM CNN accelerator can be
implemented in resource-constrained FPGAs, where the FPGA has limited numbers
of digital signal processor (DSP) units to accelerate the MAC operations.
"
898,"Enabling the Adoption of Processing-in-Memory: Challenges, Mechanisms,
  Future Research Directions","  Poor DRAM technology scaling over the course of many years has caused
DRAM-based main memory to increasingly become a larger system bottleneck. A
major reason for the bottleneck is that data stored within DRAM must be moved
across a pin-limited memory channel to the CPU before any computation can take
place. This requires a high latency and energy overhead, and the data often
cannot benefit from caching in the CPU, making it difficult to amortize the
overhead.
  Modern 3D-stacked DRAM architectures include a logic layer, where compute
logic can be integrated underneath multiple layers of DRAM cell arrays within
the same chip. Architects can take advantage of the logic layer to perform
processing-in-memory (PIM), or near-data processing. In a PIM architecture, the
logic layer within DRAM has access to the high internal bandwidth available
within 3D-stacked DRAM (which is much greater than the bandwidth available
between DRAM and the CPU). Thus, PIM architectures can effectively free up
valuable memory channel bandwidth while reducing system energy consumption.
  A number of important issues arise when we add compute logic to DRAM. In
particular, the logic does not have low-latency access to common CPU structures
that are essential for modern application execution, such as the virtual memory
and cache coherence mechanisms. To ease the widespread adoption of PIM, we
ideally would like to maintain traditional virtual memory abstractions and the
shared memory programming model. This requires efficient mechanisms that can
provide logic in DRAM with access to CPU structures without having to
communicate frequently with the CPU. To this end, we propose and evaluate two
general-purpose solutions that minimize unnecessary off-chip communication for
PIM architectures. We show that both mechanisms improve the performance and
energy consumption of many important memory-intensive applications.
"
899,"Combined Spatial and Temporal Blocking for High-Performance Stencil
  Computation on FPGAs Using OpenCL","  Recent developments in High Level Synthesis tools have attracted software
programmers to accelerate their high-performance computing applications on
FPGAs. Even though it has been shown that FPGAs can compete with GPUs in terms
of performance for stencil computation, most previous work achieve this by
avoiding spatial blocking and restricting input dimensions relative to FPGA
on-chip memory. In this work we create a stencil accelerator using Intel FPGA
SDK for OpenCL that achieves high performance without having such restrictions.
We combine spatial and temporal blocking to avoid input size restrictions, and
employ multiple FPGA-specific optimizations to tackle issues arisen from the
added design complexity. Accelerator parameter tuning is guided by our
performance model, which we also use to project performance for the upcoming
Intel Stratix 10 devices. On an Arria 10 GX 1150 device, our accelerator can
reach up to 760 and 375 GFLOP/s of compute performance, for 2D and 3D stencils,
respectively, which rivals the performance of a highly-optimized GPU
implementation. Furthermore, we estimate that the upcoming Stratix 10 devices
can achieve a performance of up to 3.5 TFLOP/s and 1.6 TFLOP/s for 2D and 3D
stencil computation, respectively.
"
900,A Multi-Kernel Multi-Code Polar Decoder Architecture,"  Polar codes have received increasing attention in the past decade, and have
been selected for the next generation of wireless communication standard. Most
research on polar codes has focused on codes constructed from a $2\times2$
polarization matrix, called binary kernel: codes constructed from binary
kernels have code lengths that are bound to powers of $2$. A few recent works
have proposed construction methods based on multiple kernels of different
dimensions, not only binary ones, allowing code lengths different from powers
of $2$. In this work, we design and implement the first multi-kernel successive
cancellation polar code decoder in literature. It can decode any code
constructed with binary and ternary kernels: the architecture, sized for a
maximum code length $N_{max}$, is fully flexible in terms of code length, code
rate and kernel sequence. The decoder can achieve frequency of more than $1$
GHz in $65$ nm CMOS technology, and a throughput of $615$ Mb/s. The area
occupation ranges between $0.11$ mm$^2$ for $N_{max}=256$ and $2.01$ mm$^2$ for
$N_{max}=4096$. Implementation results show an unprecedented degree of
flexibility: with $N_{max}=4096$, up to $55$ code lengths can be decoded with
the same hardware, along with any kernel sequence and code rate.
"
901,VIBNN: Hardware Acceleration of Bayesian Neural Networks,"  Bayesian Neural Networks (BNNs) have been proposed to address the problem of
model uncertainty in training and inference. By introducing weights associated
with conditioned probability distributions, BNNs are capable of resolving the
overfitting issue commonly seen in conventional neural networks and allow for
small-data training, through the variational inference process. Frequent usage
of Gaussian random variables in this process requires a properly optimized
Gaussian Random Number Generator (GRNG). The high hardware cost of conventional
GRNG makes the hardware implementation of BNNs challenging.
  In this paper, we propose VIBNN, an FPGA-based hardware accelerator design
for variational inference on BNNs. We explore the design space for massive
amount of Gaussian variable sampling tasks in BNNs. Specifically, we introduce
two high performance Gaussian (pseudo) random number generators: the RAM-based
Linear Feedback Gaussian Random Number Generator (RLF-GRNG), which is inspired
by the properties of binomial distribution and linear feedback logics; and the
Bayesian Neural Network-oriented Wallace Gaussian Random Number Generator. To
achieve high scalability and efficient memory access, we propose a deep
pipelined accelerator architecture with fast execution and good hardware
utilization. Experimental results demonstrate that the proposed VIBNN
implementations on an FPGA can achieve throughput of 321,543.4 Images/s and
energy efficiency upto 52,694.8 Images/J while maintaining similar accuracy as
its software counterpart.
"
902,"Musical Chair: Efficient Real-Time Recognition Using Collaborative IoT
  Devices","  The prevalence of Internet of things (IoT) devices and abundance of sensor
data has created an increase in real-time data processing such as recognition
of speech, image, and video. While currently such processes are offloaded to
the computationally powerful cloud system, a localized and distributed approach
is desirable because (i) it preserves the privacy of users and (ii) it omits
the dependency on cloud services. However, IoT networks are usually composed of
resource-constrained devices, and a single device is not powerful enough to
process real-time data. To overcome this challenge, we examine data and model
parallelism for such devices in the context of deep neural networks. We propose
Musical Chair to enable efficient, localized, and dynamic real-time recognition
by harvesting the aggregated computational power from the resource-constrained
devices in the same IoT network as input sensors. Musical chair adapts to the
availability of computing devices at runtime and adjusts to the inherit
dynamics of IoT networks. To demonstrate Musical Chair, on a network of
Raspberry PIs (up to 12) each connected to a camera, we implement a
state-of-the-art action recognition model for videos and two recognition models
for images. Compared to the Tegra TX2, an embedded low-power platform with a
six-core CPU and a GPU, our distributed action recognition system achieves not
only similar energy consumption but also twice the performance of the TX2.
Furthermore, in image recognition, Musical Chair achieves similar performance
and saves dynamic energy.
"
903,"Zorua: Enhancing Programming Ease, Portability, and Performance in GPUs
  by Decoupling Programming Models from Resource Management","  The application resource specification--a static specification of several
parameters such as the number of threads and the scratchpad memory usage per
thread block--forms a critical component of the existing GPU programming
models. This specification determines the performance of the application during
execution because the corresponding on-chip hardware resources are allocated
and managed purely based on this specification. This tight coupling between the
software-provided resource specification and resource management in hardware
leads to significant challenges in programming ease, portability, and
performance, as we demonstrate in this work.
  Our goal in this work is to reduce the dependence of performance on the
software-provided resource specification to simultaneously alleviate the above
challenges. To this end, we introduce Zorua, a new resource virtualization
framework, that decouples the programmer-specified resource usage of a GPU
application from the actual allocation in the on-chip hardware resources. Zorua
enables this decoupling by virtualizing each resource transparently to the
programmer.
  We demonstrate that by providing the illusion of more resources than
physically available, Zorua offers several important benefits: (i) Programming
Ease: Zorua eases the burden on the programmer to provide code that is tuned to
efficiently utilize the physically available on-chip resources. (ii)
Portability: Zorua alleviates the necessity of re-tuning an application's
resource usage when porting the application across GPU generations. (iii)
Performance: By dynamically allocating resources and carefully oversubscribing
them when necessary, Zorua improves or retains the performance of applications
that are already highly tuned to best utilize the resources. The holistic
virtualization provided by Zorua has many other potential uses which we
describe in this paper.
"
904,FPGA Implementation of ECG feature extraction using Time domain analysis,"  An electrocardiogram (ECG) feature extraction system has been developed and
evaluated using Virtex-6 FPGA kit which belongs to Xilinx Ltd. In time domain,
Pan-Tompkins algorithm is used for QRS detection and it is followed by a
feature extractor block to extract ECG features. This whole system can be used
to detect cardiac arrhythmia. The completed algorithm was implemented on
Virtex-6(XC6VLX240-T) device and tested using hardware co-simulation in
Modelsim and simulink environment. The software generated ECG signals are
obtained from MIT-BIH arrhythmia Database [1]. The memory and time complexities
of the implemented design were recorded and feature extraction has been done.
We have achieved satisfactory results which is mainly due to parallel
implementation. Therefore accurate arrhythmia detection using hardware
implementation a viable approach.
"
905,"Achieving Efficient Realization of Kalman Filter on CGRA through
  Algorithm-Architecture Co-design","  In this paper, we present efficient realization of Kalman Filter (KF) that
can achieve up to 65% of the theoretical peak performance of underlying
architecture platform. KF is realized using Modified Faddeeva Algorithm (MFA)
as a basic building block due to its versatility and REDEFINE Coarse Grained
Reconfigurable Architecture (CGRA) is used as a platform for experiments since
REDEFINE is capable of supporting realization of a set algorithmic compute
structures at run-time on a Reconfigurable Data-path (RDP). We perform several
hardware and software based optimizations in the realization of KF to achieve
116% improvement in terms of Gflops over the first realization of KF. Overall,
with the presented approach for KF, 4-105x performance improvement in terms of
Gflops/watt over several academically and commercially available realizations
of KF is attained. In REDEFINE, we show that our implementation is scalable and
the performance attained is commensurate with the underlying hardware resources
"
906,"MeltdownPrime and SpectrePrime: Automatically-Synthesized Attacks
  Exploiting Invalidation-Based Coherence Protocols","  The recent Meltdown and Spectre attacks highlight the importance of automated
verification techniques for identifying hardware security vulnerabilities. We
have developed a tool for synthesizing microarchitecture-specific programs
capable of producing any user-specified hardware execution pattern of interest.
Our tool takes two inputs: a formal description of (i) a microarchitecture in a
domain-specific language, and (ii) a microarchitectural execution pattern of
interest, e.g. a threat pattern. All programs synthesized by our tool are
capable of producing the specified execution pattern on the supplied
microarchitecture.
  We used our tool to specify a hardware execution pattern common to
Flush+Reload attacks and automatically synthesized security litmus tests
representative of those that have been publicly disclosed for conducting
Meltdown and Spectre attacks. We also formulated a Prime+Probe threat pattern,
enabling our tool to synthesize a new variant of each---MeltdownPrime and
SpectrePrime. Both of these new exploits use Prime+Probe approaches to conduct
the timing attack. They are both also novel in that they are 2-core attacks
which leverage the cache line invalidation mechanism in modern cache coherence
protocols. These are the first proposed Prime+Probe variants of Meltdown and
Spectre. But more importantly, both Prime attacks exploit invalidation-based
coherence protocols to achieve the same level of precision as a Flush+Reload
attack. While mitigation techniques in software (e.g., barriers that prevent
speculation) will likely be the same for our Prime variants as for original
Spectre and Meltdown, we believe that hardware protection against them will be
distinct. As a proof of concept, we implemented SpectrePrime as a C program and
ran it on an Intel x86 processor, averaging about the same accuracy as Spectre
over 100 runs---97.9% for Spectre and 99.95% for SpectrePrime.
"
907,"ThUnderVolt: Enabling Aggressive Voltage Underscaling and Timing Error
  Resilience for Energy Efficient Deep Neural Network Accelerators","  Hardware accelerators are being increasingly deployed to boost the
performance and energy efficiency of deep neural network (DNN) inference. In
this paper we propose Thundervolt, a new framework that enables aggressive
voltage underscaling of high-performance DNN accelerators without compromising
classification accuracy even in the presence of high timing error rates. Using
post-synthesis timing simulations of a DNN accelerator modeled on the Google
TPU, we show that Thundervolt enables between 34%-57% energy savings on
state-of-the-art speech and image recognition benchmarks with less than 1% loss
in classification accuracy and no performance loss. Further, we show that
Thundervolt is synergistic with and can further increase the energy efficiency
of commonly used run-time DNN pruning techniques like Zero-Skip.
"
908,ClosNets: a Priori Sparse Topologies for Faster DNN Training,"  Fully-connected layers in deep neural networks (DNN) are often the throughput
and power bottleneck during training. This is due to their large size and low
data reuse. Pruning dense layers can significantly reduce the size of these
networks, but this approach can only be applied after training. In this work we
propose a novel fully-connected layer that reduces the memory requirements of
DNNs without sacrificing accuracy. We replace a dense matrix with products of
sparse matrices whose topologies we pick in advance. This allows us to: (1)
train significantly smaller networks without a loss in accuracy, and (2) store
the network weights without having to store connection indices. We therefore
achieve significant training speedups due to the smaller network size, and a
reduced amount of computation per epoch. We tested several sparse layer
topologies and found that Clos networks perform well due to their high path
diversity, shallowness, and high model accuracy. With the ClosNets, we are able
to reduce dense layer sizes by as much as an order of magnitude without hurting
model accuracy.
"
909,"Sphinx: A Secure Architecture Based on Binary Code Diversification and
  Execution Obfuscation","  Sphinx, a hardware-software co-design architecture for binary code and
runtime obfuscation. The Sphinx architecture uses binary code diversification
and self-reconfigurable processing elements to maintain application
functionality while obfuscating the binary code and architecture states to
attackers. This approach dramatically reduces an attacker's ability to exploit
information gained from one deployment to attack another deployment. Our
results show that the Sphinx is able to decouple the program's execution time,
power and memory and I/O activities from its functionality. It is also
practical in the sense that the system (both software and hardware) overheads
are minimal.
"
910,"Polar-Coded Forward Error Correction for MLC NAND Flash Memory Polar FEC
  for NAND Flash Memory","  With the ever-growing storage density, high-speed, and low-cost data access,
flash memory has inevitably become popular. Multi-level cell (MLC) NAND flash
memory, which can well balance the data density and memory stability, has
occupied the largest market share of flash memory. With the aggressive memory
scaling, however, the reliability decays sharply owing to multiple
interferences. Therefore, the control system should be embedded with a suitable
error correction code (ECC) to guarantee the data integrity and accuracy. We
proposed the pre-check scheme which is a multi-strategy polar code scheme to
strike a balance between reasonable frame error rate (FER) and decoding
latency. Three decoders namely binary-input, quantized-soft, and pure-soft
decoders are embedded in this scheme. Since the calculation of soft
log-likelihood ratio (LLR) inputs needs multiple sensing operations and
optional quantization boundaries, a 2-bit quantized hard-decision decoder is
proposed to outperform the hard-decoded LDPC bit-flipping decoder with fewer
sensing operations. We notice that polar codes have much lower computational
complexity compared to LDPC codes. The stepwise maximum mutual information
(SMMI) scheme is also proposed to obtain overlapped boundaries without
exhausting search. The mapping scheme using Gray code is employed and proved to
achieve better raw error performance compared to other alternatives. Hardware
architectures are also given in this paper.
"
911,"Analyzing and Mitigating the Impact of Permanent Faults on a Systolic
  Array Based Neural Network Accelerator","  Due to their growing popularity and computational cost, deep neural networks
(DNNs) are being targeted for hardware acceleration. A popular architecture for
DNN acceleration, adopted by the Google Tensor Processing Unit (TPU), utilizes
a systolic array based matrix multiplication unit at its core. This paper deals
with the design of fault-tolerant, systolic array based DNN accelerators for
high defect rate technologies. To this end, we empirically show that the
classification accuracy of a baseline TPU drops significantly even at extremely
low fault rates (as low as $0.006\%$). We then propose two novel strategies,
fault-aware pruning (FAP) and fault-aware pruning+retraining (FAP+T), that
enable the TPU to operate at fault rates of up to $50\%$, with negligible drop
in classification accuracy (as low as $0.1\%$) and no run-time performance
overhead. The FAP+T does introduce a one-time retraining penalty per TPU chip
before it is deployed, but we propose optimizations that reduce this one-time
penalty to under 12 minutes. The penalty is then amortized over the entire
lifetime of the TPU's operation.
"
912,SAPA: Self-Aware Polymorphic Architecture,"  In this work, we introduce a Self-Aware Polymorphic Architecture (SAPA)
design approach to support emerging context-aware applications and mitigate the
programming challenges caused by the ever-increasing complexity and
heterogeneity of high performance computing systems. Through the SAPA design,
we examined the salient software-hardware features of adaptive computing
systems that allow for (1) the dynamic allocation of computing resources
depending on program needs (e.g., the amount of parallelism in the program) and
(2) automatic approximation to meet program and system goals (e.g., execution
time budget, power constraints and computation resiliency) without the
programming complexity of current multicore and many-core systems. The proposed
adaptive computer architecture framework applies machine learning algorithms
and control theory techniques to the application execution based on information
collected about the system runtime performance trade-offs. It has heterogeneous
reconfigurable cores with fast hardware-level migration capability,
self-organizing memory structures and hierarchies, an adaptive
application-aware network-on-chip, and a built-in hardware layer for dynamic,
autonomous resource management. Our prototyped architecture performs extremely
well on a large pool of applications.
"
913,"Residual-Based Detections and Unified Architecture for Massive MIMO
  Uplink","  Massive multiple-input multiple-output (M-MIMO) technique brings better
energy efficiency and coverage but higher computational complexity than
small-scale MIMO. For linear detections such as minimum mean square error
(MMSE), prohibitive complexity lies in solving large-scale linear equations.
For a better trade-off between bit-error-rate (BER) performance and
computational complexity, iterative linear algorithms like conjugate gradient
(CG) have been applied and have shown their feasibility in recent years. In
this paper, residual-based detection (RBD) algorithms are proposed for M-MIMO
detection, including minimal residual (MINRES) algorithm, generalized minimal
residual (GMRES) algorithm, and conjugate residual (CR) algorithm. RBD
algorithms focus on the minimization of residual norm per iteration, whereas
most existing algorithms focus on the approximation of exact signal. Numerical
results have shown that, for $64$-QAM $128\times 8$ MIMO, RBD algorithms are
only $0.13$ dB away from the exact matrix inversion method when BER$=10^{-4}$.
Stability of RBD algorithms has also been verified in various correlation
conditions. Complexity comparison has shown that, CR algorithm require $87\%$
less complexity than the traditional method for $128\times 60$ MIMO. The
unified hardware architecture is proposed with flexibility, which guarantees a
low-complexity implementation for a family of RBD M-MIMO detectors.
"
914,High Speed SRT Divider for Intelligent Embedded System,"  Increasing development in embedded systems, VLSI and processor design have
given rise to increased demands from the system in terms of power, speed, area,
throughput etc. Most of the sophisticated embedded system applications consist
of processors, which now need an arithmetic unit with the ability to execute
complex division operations with maximum efficiency. Hence the speed of the
arithmetic unit is critically dependent on division operation. Most of the
dividers use the SRT division algorithm for division. In IoT and other embedded
applications, typically radix 2 and radix 4 division algorithms are used. The
proposed algorithm lies on parallel execution of various steps so as to reduce
time critical path, use fuzzy logic to solve the overlap problem in quotient
selection, hence reducing maximum delay and increasing the accuracy. Every
logical circuit has a maximum delay on which the timing of the circuit is
dependent and the path, causing the maximum delay is known as the critical
path. Our approach uses the previous SRT algorithm methods to make a highly
parallel pipelined design and use Mamdani model to determine a solution to the
overlapping problem to reduce the overall execution time of radix 4 SRT
division on 64 bits double precision floating point numbers to 281ns. The
design is made using Bluespec System Verilog, synthesized and simulated using
Vivado v.2016.1 and implemented on Xilinx Virtex UltraScale FPGA board.
"
915,Privacy Leakages in Approximate Adders,"  Approximate computing has recently emerged as a promising method to meet the
low power requirements of digital designs. The erroneous outputs produced in
approximate computing can be partially a function of each chip's process
variation. We show that, in such schemes, the erroneous outputs produced on
each chip instance can reveal the identity of the chip that performed the
computation, possibly jeopardizing user privacy. In this work, we perform
simulation experiments on 32-bit Ripple Carry Adders, Carry Lookahead Adders,
and Han-Carlson Adders running at over-scaled operating points. Our results
show that identification is possible, we contrast the identifiability of each
type of adder, and we quantify how success of identification varies with the
extent of over-scaling and noise. Our results are the first to show that
approximate digital computations may compromise privacy. Designers of future
approximate computing systems should be aware of the possible privacy leakages
and decide whether mitigation is warranted in their application.
"
916,Memory Tagging and how it improves C/C++ memory safety,"  Memory safety in C and C++ remains largely unresolved. A technique usually
called ""memory tagging"" may dramatically improve the situation if implemented
in hardware with reasonable overhead. This paper describes two existing
implementations of memory tagging: one is the full hardware implementation in
SPARC; the other is a partially hardware-assisted compiler-based tool for
AArch64. We describe the basic idea, evaluate the two implementations, and
explain how they improve memory safety. This paper is intended to initiate a
wider discussion of memory tagging and to motivate the CPU and OS vendors to
add support for it in the near future.
"
917,"On the Low-Complexity, Hardware-Friendly Tridiagonal Matrix Inversion
  for Correlated Massive MIMO Systems","  In massive MIMO (M-MIMO) systems, one of the key challenges in the
implementation is the large-scale matrix inversion operation, as widely used in
channel estimation, equalization, detection, and decoding procedures.
Traditionally, to handle this complexity issue, several low-complexity matrix
inversion approximation methods have been proposed, including the classic
Cholesky decomposition and the Neumann series expansion (NSE). However, the
conventional approaches failed to exploit neither the special structure of
channel matrices nor the critical issues in the hardware implementation, which
results in poorer throughput performance and longer processing delay. In this
paper, by targeting at the correlated M-MIMO systems, we propose a modified NSE
based on tridiagonal matrix inversion approximation (TMA) to accommodate the
complexity as well as the performance issue in the conventional hardware
implementation, and analyze the corresponding approximation errors. Meanwhile,
we investigate the VLSI implementation for the proposed detection algorithm
based on a Xilinx Virtex-7 XC7VX690T FPGA platform. It is shown that for
correlated massive MIMO systems, it can achieve near-MMSE performance and $630$
Mb/s throughput. Compared with other benchmark systems, the proposed pipelined
TMA detector can get high throughput-to-hardware ratio. Finally, we also
propose a fast iteration structure for further research.
"
918,45-year CPU evolution: one law and two equations,"  Moore's law and two equations allow to explain the main trends of CPU
evolution since MOS technologies have been used to implement microprocessors.
"
919,Adaptive 3D-IC TSV Fault Tolerance Structure Generation,"  In three dimensional integrated circuits (3D-ICs), through silicon via (TSV)
is a critical technique in providing vertical connections. However, the yield
and reliability is one of the key obstacles to adopt the TSV based 3D-ICs
technology in industry. Various fault-tolerance structures using spare TSVs to
repair faulty functional TSVs have been proposed in literature for yield and
reliability enhancement, but a valid structure cannot always be found due to
the lack of effective generation methods for fault-tolerance structures. In
this paper, we focus on the problem of adaptive fault-tolerance structure
generation. Given the relations between functional TSVs and spare TSVs, we
first calculate the maximum number of tolerant faults in each TSV group. Then
we propose an integer linear programming (ILP) based model to construct
adaptive fault-tolerance struc- ture with minimal multiplexer delay overhead
and hardware cost. We further develop a speed-up technique through efficient
min-cost-max-flow (MCMF) model. All the proposed method- ologies are embedded
in a top-down TSV planning framework to form functional TSV groups and generate
adaptive fault- tolerance structures. Experimental results show that, compared
with state-of-the-art, the number of spare TSVs used for fault tolerance can be
effectively reduced.
"
920,ASAP: Accelerated Short-Read Alignment on Programmable Hardware,"  The proliferation of high-throughput sequencing machines ensures rapid
generation of up to billions of short nucleotide fragments in a short period of
time. This massive amount of sequence data can quickly overwhelm today's
storage and compute infrastructure. This paper explores the use of hardware
acceleration to significantly improve the runtime of short-read alignment, a
crucial step in preprocessing sequenced genomes. We focus on the Levenshtein
distance (edit-distance) computation kernel and propose the ASAP accelerator,
which utilizes the intrinsic delay of circuits for edit-distance computation
elements as a proxy for computation. Our design is implemented on an Xilinx
Virtex 7 FPGA in an IBM POWER8 system that uses the CAPI interface for cache
coherence across the CPU and FPGA. Our design is $200\times$ faster than the
equivalent C implementation of the kernel running on the host processor and
$2.2\times$ faster for an end-to-end alignment tool for 120-150 base-pair
short-read sequences. Further the design represents a $3760\times$ improvement
over the CPU in performance/Watt terms.
"
921,"Synthesizing Power and Area Efficient Image Processing Pipelines on
  FPGAs using Customized Bit-widths","  High-level synthesis (HLS) has received significant attention in recent
years, improving programmability for FPGAs. PolyMage is a domain-specific
language (DSL) for image processing pipelines that also has a HLS backend to
translate the input DSL into an equivalent circuit that can be synthesized on
FPGAs, while leveraging an HLS suite. The data at each stage of a pipeline is
stored using a fixed-point data type (alpha,beta) where alpha and beta denote
the number of integral and fractional bits. The power and area savings while
performing arithmetic operations on fixed-point data type is known to be
significant over using floating point. In this paper, we first propose an
interval-arithmetic based range analysis (alpha-analysis) algorithm to estimate
the number of bits required to store the integral part of the data at each
stage of an image processing pipeline. The analysis algorithm uses the
homogeneity of pixel signals at each stage to cluster them and perform a
combined range analysis. Secondly, we propose a software architecture for
easily deploying any kind of interval/affine arithmetic based range analyses in
the DSL compiler. Thirdly, we propose a new range analysis technique using
Satisfiability Modulo Theory (SMT) solvers, and show that the range estimates
obtained through it are very close to the lower bounds obtained through
profile-driven analysis.We evaluated our bitwidth analysis algorithms on four
image processing benchmarks listed in the order of increasing complexity:
Unsharp Mask, Down-Up Sampling, Harris Corner Detection and Horn-Schunck
Optical Flow. For example, on Optical Flow, the interval analysis based
approach showed an 1.4x and 1.14x improvement on area and power metrics over
floating-point representation respectively; whereas the SMT solver based
approach showed 2.49x and 1.58x improvement on area and power metrics when
compared to interval analysis.
"
922,"Efficient reconfigurable regions management method for adaptive and
  dynamic FPGA based systems","  Adaptive systems based on field programmable gate array (FPGA) architectures
can greatly benefi t fro m th e high degree of flexibility offered by dynamic
partial reconfiguration (DPR). By using this technique, hardware tasks can be
loaded and reloaded on demand depending on the system requirements. In this
paper, we propose to use the DPR for dynamic and adaptive implementation of a
video cut detection application based on the MPEG-7 color structure descriptor
(CSD). In the proposed implementation, different scenarios have been tested.
Depending on the application and the system requirements, the CSD module can be
loaded at any time with variable module size (corresponding to different
version of the CSD) and allocated in different possible reconfigurable regions.
Such implementation entails many problems related to communication, relocation
and reconfigurable region management. We will demonstrate how we have made this
implementation successful through the use of an appropriate design method. This
method was proposed to support the management of variable-size hardware tasks
on DPR FPGAs based adaptive systems. It permits to efficiently handle the
reconfigurable area and to relocate the reconfigurable modules in different
possible regions. The implementation results for the considered application
show an important optimization in terms of configuration time (until 66 %) and
memory storage (until 87 %) and an efficient hardware resources utilization
rate (until 90%).
"
923,"Integrated Optimization of Partitioning, Scheduling and Floorplanning
  for Partially Dynamically Reconfigurable Systems","  Confronted with the challenge of high performance for applications and the
restriction of hardware resources for field-programmable gate arrays (FPGAs),
partial dynamic reconfiguration (PDR) technology is anticipated to accelerate
the reconfiguration process and alleviate the device shortage. In this paper,
we propose an integrated optimization framework for task partitioning,
scheduling and floorplanning on partially dynamically reconfigurable FPGAs. The
partitions, schedule, and floorplan of the tasks are represented by the
partitioned sequence triple P-ST (PS,QS,RS), where (PS,QS) is a hybrid nested
sequence pair (HNSP) for representing the spatial and temporal partitions, as
well as the floorplan, and RS is the partitioned dynamic configuration order of
the tasks. The floorplanning and scheduling of task modules can be computed
from the partitioned sequence triple P-ST in O(n^2) time. To integrate the
exploration of the scheduling and floorplanning design space, we use a
simulated annealing-based search engine and elaborate a perturbation method,
where a randomly chosen task module is removed from the partition sequence
triple and then inserted back into a proper position selected from all the
(n+1)^3 possible combinations of partitions, schedule and floorplan. The
experimental results demonstrate the efficiency and effectiveness of the
proposed framework.
"
924,"Towards a Multi-array Architecture for Accelerating Large-scale Matrix
  Multiplication on FPGAs","  Large-scale floating-point matrix multiplication is a fundamental kernel in
many scientific and engineering applications. Most existing work only focus on
accelerating matrix multiplication on FPGA by adopting a linear systolic array.
This paper towards the extension of this architecture by proposing a scalable
and highly configurable multi-array architecture. In addition, we propose a
work-stealing scheme to ensure the equality in the workload partition among
multiple linear arrays. Furthermore, an analytical model is developed to
determine the optimal design parameters. Experiments on a real-life
convolutional neural network (CNN) show that we can obtain the optimal
extension of the linear array architecture.
"
925,The Secure Machine: Efficient Secure Execution On Untrusted Platforms,"  In this work we present the Secure Machine, SeM for short, a CPU architecture
extension for secure computing. SeM uses a small amount of in-chip additional
hardware that monitors key communication channels inside the CPU chip, and only
acts when required. SeM provides confidentiality and integrity for a secure
program without trusting the platform software or any off-chip hardware. SeM
supports existing binaries of single- and multi-threaded applications running
on single- or multi-core, multi-CPU. The performance reduction caused by it is
only few percent, most of which is due to the memory encryption layer that is
commonly used in many secure architectures.
  We also developed SeM-Prepare, a software tool that automatically instruments
existing applications (binaries) with additional instructions so they can be
securely executed on our architecture without requiring any programming efforts
or the availability of the desired program`s source code.
  To enable secure data sharing in shared memory environments, we developed
Secure Distributed Shared Memory (SDSM), an efficient (time and memory)
algorithm for allowing thousands of compute nodes to share data securely while
running on an untrusted computing environment. SDSM shows a negligible
reduction in performance, and it requires negligible and hardware resources. We
developed Distributed Memory Integrity Trees, a method for enhancing single
node integrity trees for preserving the integrity of a distributed application
running on an untrusted computing environment. We show that our method is
applicable to existing single node integrity trees such as Merkle Tree, Bonsai
Merkle Tree, and Intel`s SGX memory integrity engine. All these building blocks
may be used together to form a practical secure system, and some can be used in
conjunction with other secure systems.
"
926,"A Scalable Near-Memory Architecture for Training Deep Neural Networks on
  Large In-Memory Datasets","  Most investigations into near-memory hardware accelerators for deep neural
networks have primarily focused on inference, while the potential of
accelerating training has received relatively little attention so far. Based on
an in-depth analysis of the key computational patterns in state-of-the-art
gradient-based training methods, we propose an efficient near-memory
acceleration engine called NTX that can be used to train state-of-the-art deep
convolutional neural networks at scale. Our main contributions are: (i) a loose
coupling of RISC-V cores and NTX co-processors reducing offloading overhead by
7x over previously published results; (ii) an optimized IEEE754 compliant data
path for fast high-precision convolutions and gradient propagation; (iii)
evaluation of near-memory computing with NTX embedded into residual area on the
Logic Base die of a Hybrid Memory Cube; and (iv) a scaling analysis to meshes
of HMCs in a data center scenario. We demonstrate a 2.7x energy efficiency
improvement of NTX over contemporary GPUs at 4.4x less silicon area, and a
compute performance of 1.2 Tflop/s for training large state-of-the-art networks
with full floating-point precision. At the data center scale, a mesh of NTX
achieves above 95% parallel and energy efficiency, while providing 2.1x energy
savings or 3.1x performance improvement over a GPU-based system.
"
927,"A Design Space Exploration Methodology for Parameter Optimization in
  Multicore Processors","  The need for application-specific design of multicore/manycore processing
platforms is evident with computing systems finding use in diverse application
domains. In order to tailor multicore/manycore processors for application
specific requirements, a multitude of processor design parameters have to be
tuned accordingly which involves rigorous and extensive design space
exploration over large search spaces. In this paper, we propose an efficient
methodology for design space exploration. We evaluate our methodology over two
search spaces - small and large, using a cycle-accurate simulator (ESESC) and a
standard set of PARSEC and SPLASH-2 benchmarks. For the smaller design space,
we compare results obtained from our design space exploration methodology with
results obtained from fully exhaustive search. The results show that solution
quality obtained from our methodology are within 1.35% - 3.69% of the results
obtained from fully exhaustive search while only exploring 2.74% - 3% of the
design space. For larger design space, we compare solution quality of different
results obtained by varying the number of tunable processor design parameters
included in the exhaustive search phase of our methodology. The results show
that including more number of tunable parameters in the exhaustive search phase
of our methodology greatly improves solution quality.
"
928,Correlation Manipulating Circuits for Stochastic Computing,"  Stochastic computing (SC) is an emerging computing technique that promises
high density, low power, and error tolerant solutions. In SC, values are
encoded as unary bitstreams and SC arithmetic circuits operate on one or more
bitstreams. In many cases, the input bitstreams must be correlated or
uncorrelated for SC arithmetic to produce accurate results. As a result, a key
challenge for designing SC accelerators is manipulating the impact of
correlation across SC operations. This paper presents and evaluates a set of
novel correlation manipulating circuits to manage correlation in SC
computation: a synchronizer, desynchronizer, and decorrelator. We then use
these circuits to propose improved SC maximum, minimum, and saturating adder
designs. Compared to existing correlation manipulation techniques, our circuits
are more accurate and up to 3x more energy efficient. In the context of an
image processing pipeline, these circuits can reduce the total energy
consumption by up to 24%.
"
929,"Feature extraction without learning in an analog Spatial Pooler
  memristive-CMOS circuit design of Hierarchical Temporal Memory","  Hierarchical Temporal Memory (HTM) is a neuromorphic algorithm that emulates
sparsity, hierarchy and modularity resembling the working principles of
neocortex. Feature encoding is an important step to create sparse binary
patterns. This sparsity is introduced by the binary weights and random weight
assignment in the initialization stage of the HTM. We propose the alternative
deterministic method for the HTM initialization stage, which connects the HTM
weights to the input data and preserves natural sparsity of the input
information. Further, we introduce the hardware implementation of the
deterministic approach and compare it to the traditional HTM and existing
hardware implementation. We test the proposed approach on the face recognition
problem and show that it outperforms the conventional HTM approach.
"
930,Neuron inspired data encoding memristive multi-level memory cell,"  Mapping neuro-inspired algorithms to sensor backplanes of on-chip hardware
require shifting the signal processing from digital to the analog domain,
demanding memory technologies beyond conventional CMOS binary storage units.
Using memristors for building analog data storage is one of the promising
approaches amongst emerging non-volatile memory technologies. Recently, a
memristive multi-level memory (MLM) cell for storing discrete analog values has
been developed in which memory system is implemented combining memristors in
voltage divider configuration. In given example, the memory cell of 3 sub-cells
with a memristor in each was programmed to store ternary bits which overall
achieved 10 and 27 discrete voltage levels. However, for further use of
proposed memory cell in analog signal processing circuits data encoder is
required to generate control voltages for programming memristors to store
discrete analog values. In this paper, we present the design and performance
analysis of data encoder that generates write pattern signals for 10 level
memristive memory.
"
931,"Efficient Realization of Givens Rotation through Algorithm-Architecture
  Co-design for Acceleration of QR Factorization","  We present efficient realization of Generalized Givens Rotation (GGR) based
QR factorization that achieves 3-100x better performance in terms of
Gflops/watt over state-of-the-art realizations on multicore, and General
Purpose Graphics Processing Units (GPGPUs). GGR is an improvement over
classical Givens Rotation (GR) operation that can annihilate multiple elements
of rows and columns of an input matrix simultaneously. GGR takes 33% lesser
multiplications compared to GR. For custom implementation of GGR, we identify
macro operations in GGR and realize them on a Reconfigurable Data-path (RDP)
tightly coupled to pipeline of a Processing Element (PE). In PE, GGR attains
speed-up of 1.1x over Modified Householder Transform (MHT) presented in the
literature. For parallel realization of GGR, we use REDEFINE, a scalable
massively parallel Coarse-grained Reconfigurable Architecture, and show that
the speed-up attained is commensurate with the hardware resources in REDEFINE.
GGR also outperforms General Matrix Multiplication (gemm) by 10% in-terms of
Gflops/watt which is counter-intuitive.
"
932,"XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional
  Neural Networks","  Deploying state-of-the-art CNNs requires power-hungry processors and off-chip
memory. This precludes the implementation of CNNs in low-power embedded
systems. Recent research shows CNNs sustain extreme quantization, binarizing
their weights and intermediate feature maps, thereby saving 8-32\x memory and
collapsing energy-intensive sum-of-products into XNOR-and-popcount operations.
  We present XNORBIN, an accelerator for binary CNNs with computation tightly
coupled to memory for aggressive data reuse. Implemented in UMC 65nm technology
XNORBIN achieves an energy efficiency of 95 TOp/s/W and an area efficiency of
2.0 TOp/s/MGE at 0.8 V.
"
933,"Toolflows for Mapping Convolutional Neural Networks on FPGAs: A Survey
  and Future Directions","  In the past decade, Convolutional Neural Networks (CNNs) have demonstrated
state-of-the-art performance in various Artificial Intelligence tasks. To
accelerate the experimentation and development of CNNs, several software
frameworks have been released, primarily targeting power-hungry CPUs and GPUs.
In this context, reconfigurable hardware in the form of FPGAs constitutes a
potential alternative platform that can be integrated in the existing deep
learning ecosystem to provide a tunable balance between performance, power
consumption and programmability. In this paper, a survey of the existing
CNN-to-FPGA toolflows is presented, comprising a comparative study of their key
characteristics which include the supported applications, architectural
choices, design space exploration methods and achieved performance. Moreover,
major challenges and objectives introduced by the latest trends in CNN
algorithmic research are identified and presented. Finally, a uniform
evaluation methodology is proposed, aiming at the comprehensive, complete and
in-depth evaluation of CNN-to-FPGA toolflows.
"
934,"Memory Slices: A Modular Building Block for Scalable, Intelligent Memory
  Systems","  While reduction in feature size makes computation cheaper in terms of
latency, area, and power consumption, performance of emerging data-intensive
applications is determined by data movement. These trends have introduced the
concept of scalability as reaching a desirable performance per unit cost by
using as few number of units as possible. Many proposals have moved compute
closer to the memory. However, these efforts ignored maintaining a balance
between bandwidth and compute rate of an architecture, with those of
applications, which is a key principle in designing scalable large systems.
This paper proposes the use of memory slices, a modular building block for
scalable memory systems integrated with compute, in which performance scales
with memory size (and volume of data). The slice architecture utilizes a
programmable memory interface feeding a systolic compute engine with high reuse
rate. The modularity feature of slice-based systems is exploited with a
partitioning and data mapping strategy across allocated memory slices where
training performance scales with the data size. These features enable shifting
the most pressure to cheap compute units rather than expensive memory accesses
or transfers via interconnection network. An application of the memory slices
to a scale-out memory system is accelerating the training of recurrent,
convolutional, and hybrid neural networks (RNNs and RNNs+CNN) that are forming
cloud workloads. The results of our cycle-level simulations show that memory
slices exhibits a superlinear speedup when the number of slices increases.
Furthermore, memory slices improve power efficiency to 747 GFLOPs/J for
training LSTMs. While our current evaluation uses memory slices with 3D
packaging, a major value is that slices can also be constructed with a variety
of packaging options, for example with DDR-based memory units.
"
935,The ARM Scalable Vector Extension,"  This article describes the ARM Scalable Vector Extension (SVE). Several goals
guided the design of the architecture. First was the need to extend the vector
processing capability associated with the ARM AArch64 execution state to better
address the computational requirements in domains such as high-performance
computing, data analytics, computer vision, and machine learning. Second was
the desire to introduce an extension that can scale across multiple
implementations, both now and into the future, allowing CPU designers to choose
the vector length most suitable for their power, performance, and area targets.
Finally, the architecture should avoid imposing a software development cost as
the vector length changes and where possible reduce it by improving the reach
of compiler auto-vectorization technologies. SVE achieves these goals. It
allows implementations to choose a vector register length between 128 and 2,048
bits. It supports a vector-length agnostic programming model that lets code run
and scale automatically across all vector lengths without recompilation.
Finally, it introduces several innovative features that begin to overcome some
of the traditional barriers to autovectorization.
"
936,"C-LSTM: Enabling Efficient LSTM using Structured Compression Techniques
  on FPGAs","  Recently, significant accuracy improvement has been achieved for acoustic
recognition systems by increasing the model size of Long Short-Term Memory
(LSTM) networks. Unfortunately, the ever-increasing size of LSTM model leads to
inefficient designs on FPGAs due to the limited on-chip resources. The previous
work proposes to use a pruning based compression technique to reduce the model
size and thus speedups the inference on FPGAs. However, the random nature of
the pruning technique transforms the dense matrices of the model to highly
unstructured sparse ones, which leads to unbalanced computation and irregular
memory accesses and thus hurts the overall performance and energy efficiency.
  In contrast, we propose to use a structured compression technique which could
not only reduce the LSTM model size but also eliminate the irregularities of
computation and memory accesses. This approach employs block-circulant instead
of sparse matrices to compress weight matrices and reduces the storage
requirement from $\mathcal{O}(k^2)$ to $\mathcal{O}(k)$. Fast Fourier Transform
algorithm is utilized to further accelerate the inference by reducing the
computational complexity from $\mathcal{O}(k^2)$ to
$\mathcal{O}(k\text{log}k)$. The datapath and activation functions are
quantized as 16-bit to improve the resource utilization. More importantly, we
propose a comprehensive framework called C-LSTM to automatically optimize and
implement a wide range of LSTM variants on FPGAs. According to the experimental
results, C-LSTM achieves up to 18.8X and 33.5X gains for performance and energy
efficiency compared with the state-of-the-art LSTM implementation under the
same experimental setup, and the accuracy degradation is very small.
"
937,"Towards an Area-Efficient Implementation of a High ILP EDGE Soft
  Processor","  In-order scalar RISC architectures have been the dominant paradigm in FPGA
soft processor design for twenty years. Prior out-of-order superscalar
implementations have not exhibited competitive area or absolute performance.
This paper describes a new way to build fast and area-efficient out-of-order
superscalar soft processors by utilizing an Explicit Data Graph Execution
(EDGE) instruction set architecture. By carefully mapping the EDGE
microarchitecture, and in particular, its dataflow instruction scheduler, we
demonstrate the feasibility of an out-of-order FPGA architecture. Two scheduler
design alternatives are compared.
"
938,Newton: Gravitating Towards the Physical Limits of Crossbar Acceleration,"  Many recent works have designed accelerators for Convolutional Neural
Networks (CNNs). While digital accelerators have relied on near data
processing, analog accelerators have further reduced data movement by
performing in-situ computation. Recent works take advantage of highly parallel
analog in-situ computation in memristor crossbars to accelerate the many
vector-matrix multiplication operations in CNNs. However, these in-situ
accelerators have two significant short-comings that we address in this work.
First, the ADCs account for a large fraction of chip power and area. Second,
these accelerators adopt a homogeneous design where every resource is
provisioned for the worst case. By addressing both problems, the new
architecture, Newton, moves closer to achieving optimal energy-per-neuron for
crossbar accelerators.
  We introduce multiple new techniques that apply at different levels of the
tile hierarchy. Two of the techniques leverage heterogeneity: one adapts ADC
precision based on the requirements of every sub-computation (with zero impact
on accuracy), and the other designs tiles customized for convolutions or
classifiers. Two other techniques rely on divide-and-conquer numeric algorithms
to reduce computations and ADC pressure. Finally, we place constraints on how a
workload is mapped to tiles, thus helping reduce resource provisioning in
tiles. For a wide range of CNN dataflows and structures, Newton achieves a 77%
decrease in power, 51% improvement in energy efficiency, and 2.2x higher
throughput/area, relative to the state-of-the-art ISAAC accelerator.
"
939,AISC: Approximate Instruction Set Computer,"  This paper makes the case for a single-ISA heterogeneous computing platform,
AISC, where each compute engine (be it a core or an accelerator) supports a
different subset of the very same ISA. An ISA subset may not be functionally
complete, but the union of the (per compute engine) subsets renders a
functionally complete, platform-wide single ISA. Tailoring the
microarchitecture of each compute engine to the subset of the ISA that it
supports can easily reduce hardware complexity. At the same time, the energy
efficiency of computing can improve by exploiting algorithmic noise tolerance:
by mapping code sequences that can tolerate (any potential inaccuracy induced
by) the incomplete ISA-subsets to the corresponding compute engines.
"
940,"Techniques for Shared Resource Management in Systems with Throughput
  Processors","  The continued growth of the computational capability of throughput processors
has made throughput processors the platform of choice for a wide variety of
high performance computing applications. Graphics Processing Units (GPUs) are a
prime example of throughput processors that can deliver high performance for
applications ranging from typical graphics applications to general-purpose data
parallel (GPGPU) applications. However, this success has been accompanied by
new performance bottlenecks throughout the memory hierarchy of GPU-based
systems. We identify and eliminate performance bottlenecks caused by major
sources of interference throughout the memory hierarchy.
  We introduce changes to the memory hierarchy for systems with GPUs that allow
the memory hierarchy to be aware of both CPU and GPU applications'
characteristics. We introduce mechanisms to dynamically analyze different
applications' characteristics and propose four major changes throughout the
memory hierarchy. We propose changes to the cache management and memory
scheduling mechanisms to mitigate intra-application interference in GPGPU
applications. We propose changes to the memory controller design and its
scheduling policy to mitigate inter-application interference in heterogeneous
CPU-GPU systems. We redesign the MMU and the memory hierarchy in GPUs to be
aware of ddress-translation data in order to mitigate the inter-address-space
interference. We introduce a hardware-software cooperative technique that
modifies the memory allocation policy to enable large page support in order to
further reduce the inter-address-space interference at the shared Translation
Lookaside Buffer (TLB). Our evaluations show that the GPU-aware cache and
memory management techniques proposed in this dissertation are effective at
mitigating the interference caused by GPUs on current and future GPU-based
systems.
"
941,Integrating DRAM Power-Down Modes in gem5 and Quantifying their Impact,"  Across applications, DRAM is a significant contributor to the overall system
power, with the DRAM access energy per bit up to three orders of magnitude
higher compared to on-chip memory accesses. To improve the power efficiency,
DRAM technology incorporates multiple power-down modes, each with different
trade-offs between achievable power savings and performance impact due to entry
and exit delay requirements. Accurate modeling of these low power modes and
entry and exit control is crucial to analyze the trade-offs across controller
configurations and workloads with varied memory access characteristics. To
address this, we integrate the power-down modes into the DRAM controller model
in the open-source simulator gem5. This is the first publicly available
full-system simulator with DRAM power-down modes, providing the research
community a tool for DRAM power analysis for a breadth of use cases. We
validate the power-down functionality with sweep tests, which trigger defined
memory access characteristics. We further evaluate the model with real HPC
workloads, illustrating the value of integrating low power functionality into a
full system simulator.
"
942,"Crossing the Architectural Barrier: Evaluating Representative Regions of
  Parallel HPC Applications","  Exascale computing will get mankind closer to solving important social,
scientific and engineering problems. Due to high prototyping costs, High
Performance Computing (HPC) system architects make use of simulation models for
design space exploration and hardware-software co-design. However, as HPC
systems reach exascale proportions, the cost of simulation increases, since
simulators themselves are largely single-threaded. Tools for selecting
representative parts of parallel applications to reduce running costs are
widespread, e.g., BarrierPoint achieves this by analysing, in simulation,
abstract characteristics such as basic blocks and reuse distances. However,
architectures new to HPC have a limited set of tools available.
  In this work, we provide an independent cross-architectural evaluation on
real hardware - across Intel and ARM - of the BarrierPoint methodology, when
applied to parallel HPC proxy applications. We present both cases: when the
methodology can be applied and when it cannot. In the former case, results show
that we can predict the performance of full application execution by running
shorter representative sections. In the latter case, we dive into the
underlying issues and suggest improvements. We demonstrate a total simulation
time reduction of up to 178x, whilst keeping the error below 2.3% for both
cycles and instructions.
"
943,Modeling a Cache Coherence Protocol with the Guarded Action Language,"  We present a formal model built for verification of the hardware Tera-Scale
ARchitecture (TSAR), focusing on its Distributed Hybrid Cache Coherence
Protocol (DHCCP). This protocol is by nature asynchronous, concurrent and
distributed, which makes classical validation of the design (e.g. through
testing) difficult. We therefore applied formal methods to prove essential
properties of the protocol, such as absence of deadlocks, eventual consensus,
and fairness.
"
944,"An FPGA-Based Hardware Accelerator for Energy-Efficient Bitmap Index
  Creation","  Bitmap index is recognized as a promising candidate for online analytics
processing systems, because it effectively supports not only parallel
processing but also complex and multi-dimensional queries. However, bitmap
index creation is a time-consuming task. In this study, by taking full
advantage of massive parallel computing of field-programmable gate array
(FPGA), two hardware accelerators of bitmap index creation, namely BIC64K8 and
BIC32K16, are originally proposed. Each of the accelerator contains two primary
components, namely an enhanced content-addressable memory and a query logic
array module, which allow BIC64K8 and BIC32K16 to index 65,536 8-bit words and
32,768 16-bit words in parallel, at every clock cycle. The experimental results
on an Intel Arria V 5ASTFD5 FPGA prove that at 100 MHz, BIC64K8 and BIC32K16
achieve the approximate indexing throughput of 1.43 GB/s and 1.46 GB/s,
respectively. The throughputs are also proven to be stable, regardless the size
of the data sets. More significantly, BIC32K16 only consumes as low as 6.76%
and 3.28% of energy compared to the central-processing-unit- and
graphic-processing-unit-based designs, respectively.
"
945,"ScaleSimulator: A Fast and Cycle-Accurate Parallel Simulator for
  Architectural Exploration","  Design of next generation computer systems should be supported by simulation
infrastructure that must achieve a few contradictory goals such as fast
execution time, high accuracy, and enough flexibility to allow comparison
between large numbers of possible design points. Most existing architecture
level simulators are designed to be flexible and to execute the code in
parallel for greater efficiency, but at the cost of scarified accuracy. This
paper presents the ScaleSimulator simulation environment, which is based on a
new design methodology whose goal is to achieve near cycle accuracy while still
being flexible enough to simulate many different future system architectures
and efficient enough to run meaningful workloads. We achieve these goals by
making the parallelism a first-class citizen in our methodology. Thus, this
paper focuses mainly on the ScaleSimulator design points that enable better
parallel execution while maintaining the scalability and cycle accuracy of a
simulated architecture. The paper indicates that the new proposed
ScaleSimulator tool can (1) efficiently parallelize the execution of a
cycle-accurate architecture simulator, (2) efficiently simulate complex
architectures (e.g., out-of-order CPU pipeline, cache coherency protocol, and
network) and massive parallel systems, and (3) use meaningful workloads, such
as full simulation of OLTP benchmarks, to examine future architectural choices.
"
946,"Efficient Sparse Code Multiple Access Decoder Based on Deterministic
  Message Passing Algorithm","  Being an effective non-orthogonal multiple access (NOMA) technique, sparse
code multiple access (SCMA) is promising for future wireless communication.
Compared with orthogonal techniques, SCMA enjoys higher overloading tolerance
and lower complexity because of its sparsity. In this paper, based on
deterministic message passing algorithm (DMPA), algorithmic simplifications
such as domain changing and probability approximation are applied for SCMA
decoding. Early termination, adaptive decoding, and initial noise reduction are
also employed for faster convergence and better performance. Numerical results
show that the proposed optimizations benefit both decoding complexity and
speed. Furthermore, efficient hardware architectures based on folding and
retiming are proposed. VLSI implementation is also given in this paper.
Comparison with the state-of-the-art have shown the proposed decoder's
advantages in both latency and throughput (multi-Gbps).
"
947,A Survey of Techniques for Dynamic Branch Prediction,"  Branch predictor (BP) is an essential component in modern processors since
high BP accuracy can improve performance and reduce energy by decreasing the
number of instructions executed on wrong-path. However, reducing latency and
storage overhead of BP while maintaining high accuracy presents significant
challenges. In this paper, we present a survey of dynamic branch prediction
techniques. We classify the works based on key features to underscore their
differences and similarities. We believe this paper will spark further research
in this area and will be useful for computer architects, processor designers
and researchers.
"
948,"Hyperdrive: A Multi-Chip Systolically Scalable Binary-Weight CNN
  Inference Engine","  Deep neural networks have achieved impressive results in computer vision and
machine learning. Unfortunately, state-of-the-art networks are extremely
compute and memory intensive which makes them unsuitable for mW-devices such as
IoT end-nodes. Aggressive quantization of these networks dramatically reduces
the computation and memory footprint. Binary-weight neural networks (BWNs)
follow this trend, pushing weight quantization to the limit. Hardware
accelerators for BWNs presented up to now have focused on core efficiency,
disregarding I/O bandwidth and system-level efficiency that are crucial for
deployment of accelerators in ultra-low power devices. We present Hyperdrive: a
BWN accelerator dramatically reducing the I/O bandwidth exploiting a novel
binary-weight streaming approach, which can be used for arbitrarily sized
convolutional neural network architecture and input resolution by exploiting
the natural scalability of the compute units both at chip-level and
system-level by arranging Hyperdrive chips systolically in a 2D mesh while
processing the entire feature map together in parallel. Hyperdrive achieves 4.3
TOp/s/W system-level efficiency (i.e., including I/Os)---3.1x higher than
state-of-the-art BWN accelerators, even if its core uses resource-intensive
FP16 arithmetic for increased robustness.
"
949,"Synergy: A HW/SW Framework for High Throughput CNNs on Embedded
  Heterogeneous SoC","  Convolutional Neural Networks (CNN) have been widely deployed in diverse
application domains. There has been significant progress in accelerating both
their training and inference using high-performance GPUs, FPGAs, and custom
ASICs for datacenter-scale environments. The recent proliferation of mobile and
IoT devices have necessitated real-time, energy-efficient deep neural network
inference on embedded-class, resource-constrained platforms. In this context,
we present {\em Synergy}, an automated, hardware-software co-designed,
pipelined, high-throughput CNN inference framework on embedded heterogeneous
system-on-chip (SoC) architectures (Xilinx Zynq). {\em Synergy} leverages,
through multi-threading, all the available on-chip resources, which includes
the dual-core ARM processor along with the FPGA and the NEON SIMD engines as
accelerators. Moreover, {\em Synergy} provides a unified abstraction of the
heterogeneous accelerators (FPGA and NEON) and can adapt to different network
configurations at runtime without changing the underlying hardware accelerator
architecture by balancing workload across accelerators through work-stealing.
{\em Synergy} achieves 7.3X speedup, averaged across seven CNN models, over a
well-optimized software-only solution. {\em Synergy} demonstrates substantially
better throughput and energy-efficiency compared to the contemporary CNN
implementations on the same SoC architecture.
"
950,SARA: Self-Aware Resource Allocation for Heterogeneous MPSoCs,"  In modern heterogeneous MPSoCs, the management of shared memory resources is
crucial in delivering end-to-end QoS. Previous frameworks have either focused
on singular QoS targets or the allocation of partitionable resources among CPU
applications at relatively slow timescales. However, heterogeneous MPSoCs
typically require instant response from the memory system where most resources
cannot be partitioned. Moreover, the health of different cores in a
heterogeneous MPSoC is often measured by diverse performance objectives. In
this work, we propose a Self-Aware Resource Allocation (SARA) framework for
heterogeneous MPSoCs. Priority-based adaptation allows cores to use different
target performance and self-monitor their own intrinsic health. In response,
the system allocates non-partitionable resources based on priorities. The
proposed framework meets a diverse range of QoS demands from heterogeneous
cores.
"
951,"Probabilistic Value-Deviation-Bounded Integer Codes for Approximate
  Communication","  When computing systems can tolerate the effects of errors or erasures in
their communicated data values, they can trade this tolerance for improved
resource efficiency. One method for enabling this tradeoff in the I/O
subsystems of computing systems, is to use channel codes that reduce the power
needed to send bits on a channel in exchange for bounded errors and erasures on
numeric program values---value-deviation-bounded (VDB) codes. Unlike rate
distortion codes, which guarantee a bound on the expected value of channel
distortion, the probabilistic VDB codes we present guarantee any desired tail
distribution on integer distances of words transmitted over a channel. We
extend prior work to present tighter upper bounds on the efficiency for VDB
codes. We present a new probabilistic VDB encoder that lowers power dissipation
in exchange for bounded channel integer distortions. The code we present takes
the peculiar approach of changing the channel bit error rate across the ordinal
bit positions in a word to reduce power dissipation. We implement the code
table generator in a software tool built on the dReal SMT solver and we
validate the generated codes using Monte Carlo simulation. We present one
realization of hardware to implement the technique, requiring 2 mm$^2$ of
circuit board area and dissipating less than 0.5 $\mu$W.
"
952,"An Efficient I/O Architecture for RAM-based Content-Addressable Memory
  on FPGA","  Despite the impressive search rate of one key per clock cycle, the update
stage of a random-access-memory-based content-addressable-memory (RAM-based
CAM) always suffers high latency. Two primary causes of such latency include:
(1) the compulsory erasing stage along with the writing stage and (2) the major
difference in data width between the RAM-based CAM (e.g., 8-bit width) and the
modern systems (e.g., 256-bit width). This brief, therefore, aims for an
efficient input/output (I/O) architecture of RAM-based binary CAM (RCAM) for
low-latency update. To achieve this goal, three techniques, namely centralized
erase RAM, bit-sliced, and hierarchical-partitioning, are proposed to eliminate
the latency of erasing stage, as well as to allow RCAM to exploit the bandwidth
of modern systems effectively. Several RCAMs, whose data width ranges from 8
bits to 64 bits, were integrated into a 256-bit system for the evaluation. The
experimental results in an Intel Arria V 5ASTFD5 FPGA prove that at 100 MHz,
the proposed designs achieve at least 9.6 times higher I/O efficiency as
compared to the traditional RCAM.
"
953,"Large Scale Low Power Computing System - Status of Network Design in
  ExaNeSt and EuroExa Projects","  The deployment of the next generation computing platform at ExaFlops scale
requires to solve new technological challenges mainly related to the impressive
number (up to 10^6) of compute elements required. This impacts on system power
consumption, in terms of feasibility and costs, and on system scalability and
computing efficiency. In this perspective analysis, exploration and evaluation
of technologies characterized by low power, high efficiency and high degree of
customization is strongly needed. Among the various European initiative
targeting the design of ExaFlops system, ExaNeSt and EuroExa are EU-H2020
funded initiatives leveraging on high end MPSoC FPGAs. Last generation MPSoC
FPGAs can be seen as non-mainstream but powerful HPC Exascale enabling
components thanks to the integration of embedded multi-core, ARM-based low
power CPUs and a huge number of hardware resources usable to co-design
application oriented accelerators and to develop a low latency high bandwidth
network architecture. In this paper we introduce ExaNet the FPGA-based,
scalable, direct network architecture of ExaNeSt system. ExaNet allow us to
explore different interconnection topologies, to evaluate advanced routing
functions for congestion control and fault tolerance and to design specific
hardware components for acceleration of collective operations. After a brief
introduction of the motivations and goals of ExaNeSt and EuroExa projects, we
will report on the status of network architecture design and its
hardware/software testbed adding preliminary bandwidth and latency
achievements.
"
954,"A Hardware Platform for Efficient Multi-Modal Sensing with Adaptive
  Approximation","  We present Warp, a hardware platform to support research in approximate
computing, sensor energy optimization, and energy-scavenged systems. Warp
incorporates 11 state-of-the-art sensor integrated circuits, computation, and
an energy-scavenged power supply, all within a miniature system that is just
3.6 cm x 3.3 cm x 0.5 cm. Warp's sensor integrated circuits together contain a
total of 21 sensors with a range of precisions and accuracies for measuring
eight sensing modalities of acceleration, angular rate, magnetic flux density
(compass heading), humidity, atmospheric pressure (elevation), infrared
radiation, ambient temperature, and color. Warp uses a combination of analog
circuits and digital control to facilitate further tradeoffs between sensor and
communication accuracy, energy efficiency, and performance. This article
presents the design of Warp and presents an evaluation of our hardware
implementation. The results show how Warp's design enables performance and
energy efficiency versus ac- curacy tradeoffs.
"
955,"Optimal Scheduling for Exposed Datapath Architectures with Buffered
  Processing Units by ASP","  Conventional processor architectures are restricted in exploiting instruction
level parallelism (ILP) due to the relatively low number of programmer-visible
registers. Therefore, more recent processor architectures expose their
datapaths so that the compiler (1) can schedule parallel instructions to
different processing units and (2) can make effective use of local storage of
the processing units. Among these architectures, the Synchronous Control
Asynchronous Dataflow (SCAD) architecture is a new exposed datapath
architecture whose processing units are equipped with first-in first-out (FIFO)
buffers at their input and output ports.
  In contrast to register-based machines, the optimal code generation for SCAD
is still a matter of research. In particular, SAT and SMT solvers were used to
generate optimal resource constrained and optimal time constrained schedules
for SCAD, respectively. As Answer Set Programming (ASP) offers better
flexibility in handling such scheduling problems, we focus in this paper on
using an answer set solver for both resource and time constrained optimal SCAD
code generation. As a major benefit of using ASP, we are able to generate
\emph{all} optimal schedules for a given program which allows one to study
their properties. Furthermore, the experimental results of this paper
demonstrate that the answer set solver can compete with SAT solvers and
outperforms SMT solvers. \emph{This paper is under consideration for acceptance
in TPLP.}
"
956,"Holistic Management of the GPGPU Memory Hierarchy to Manage Warp-level
  Latency Tolerance","  In a modern GPU architecture, all threads within a warp execute the same
instruction in lockstep. For a memory instruction, this can lead to memory
divergence: the memory requests for some threads are serviced early, while the
remaining requests incur long latencies. This divergence stalls the warp, as it
cannot execute the next instruction until all requests from the current
instruction complete. In this work, we make three new observations. First,
GPGPU warps exhibit heterogeneous memory divergence behavior at the shared
cache: some warps have most of their requests hit in the cache, while other
warps see most of their request miss. Second, a warp retains the same
divergence behavior for long periods of execution. Third, requests going to the
shared cache can incur queuing delays as large as hundreds of cycles,
exacerbating the effects of memory divergence. We propose a set of techniques,
collectively called Memory Divergence Correction (MeDiC), that reduce the
negative performance impact of memory divergence and cache queuing. MeDiC
delivers an average speedup of 21.8%, and 20.1% higher energy efficiency, over
a state-of-the-art GPU cache management mechanism across 15 different GPGPU
applications.
"
957,"A Memory Controller with Row Buffer Locality Awareness for Hybrid Memory
  Systems","  Non-volatile memory (NVM) is a class of promising scalable memory
technologies that can potentially offer higher capacity than DRAM at the same
cost point. Unfortunately, the access latency and energy of NVM is often higher
than those of DRAM, while the endurance of NVM is lower. Many DRAM-NVM hybrid
memory systems use DRAM as a cache to NVM, to achieve the low access latency,
low energy, and high endurance of DRAM, while taking advantage of the large
capacity of NVM. A key question for a hybrid memory system is what data to
cache in DRAM to best exploit the advantages of each technology while avoiding
the disadvantages of each technology as much as possible.
  We propose a new memory controller design that improves hybrid memory
performance and energy efficiency. We observe that both DRAM and NVM banks
employ row buffers that act as a cache for the most recently accessed memory
row. Accesses that are row buffer hits incur similar latencies (and energy
consumption) in both DRAM and NVM, whereas accesses that are row buffer misses
incur longer latencies (and higher energy consumption) in NVM than in DRAM. To
exploit this, we devise a policy that caches heavily-reused data that
frequently misses in the NVM row buffers into DRAM. Our policy tracks the row
buffer miss counts of recently-used rows in NVM, and caches in DRAM the rows
that are predicted to incur frequent row buffer misses. Our proposed policy
also takes into account the high write latencies of NVM, in addition to row
buffer locality and more likely places the write-intensive pages in DRAM
instead of NVM.
"
958,"High-Performance and Energy-Effcient Memory Scheduler Design for
  Heterogeneous Systems","  When multiple processor cores (CPUs) and a GPU integrated together on the
same chip share the off-chip DRAM, requests from the GPU can heavily interfere
with requests from the CPUs, leading to low system performance and starvation
of cores. Unfortunately, state-of-the-art memory scheduling algorithms are
ineffective at solving this problem due to the very large amount of GPU memory
traffic, unless a very large and costly request buffer is employed to provide
these algorithms with enough visibility across the global request stream.
  Previously-proposed memory controller (MC) designs use a single monolithic
structure to perform three main tasks. First, the MC attempts to schedule
together requests to the same DRAM row to increase row buffer hit rates.
Second, the MC arbitrates among the requesters (CPUs and GPU) to optimize for
overall system throughput, average response time, fairness and quality of
service. Third, the MC manages the low-level DRAM command scheduling to
complete requests while ensuring compliance with all DRAM timing and power
constraints. This paper proposes a fundamentally new approach, called the
Staged Memory Scheduler (SMS), which decouples the three primary MC tasks into
three significantly simpler structures that together improve system performance
and fairness. Our evaluation shows that SMS provides 41.2% performance
improvement and fairness improvement compared to the best previous
state-of-the-art technique, while enabling a design that is significantly less
complex and more power-efficient to implement.
"
959,"Structured Weight Matrices-Based Hardware Accelerators in Deep Neural
  Networks: FPGAs and ASICs","  Both industry and academia have extensively investigated hardware
accelerations. In this work, to address the increasing demands in computational
capability and memory requirement, we propose structured weight matrices
(SWM)-based compression techniques for both \emph{field programmable gate
array} (FPGA) and \emph{application-specific integrated circuit} (ASIC)
implementations. In algorithm part, SWM-based framework adopts block-circulant
matrices to achieve a fine-grained tradeoff between accuracy and compression
ratio. The SWM-based technique can reduce computational complexity from
O($n^2$) to O($n\log n$) and storage complexity from O($n^2$) to O($n$) for
each layer and both training and inference phases. For FPGA implementations on
deep convolutional neural networks (DCNNs), we achieve at least 152X and 72X
improvement in performance and energy efficiency, respectively using the
SWM-based framework, compared with the baseline of IBM TrueNorth processor
under same accuracy constraints using the data set of MNIST, SVHN, and
CIFAR-10. For FPGA implementations on long short term memory (LSTM) networks,
the proposed SWM-based LSTM can achieve up to 21X enhancement in performance
and 33.5X gains in energy efficiency compared with the baseline accelerator.
For ASIC implementations, the SWM-based ASIC design exhibits impressive
advantages in terms of power, throughput, and energy efficiency. Experimental
results indicate that this method is greatly suitable for applying DNNs onto
both FPGAs and mobile/IoT devices.
"
960,"Mosaic: An Application-Transparent Hardware-Software Cooperative Memory
  Manager for GPUs","  Modern GPUs face a trade-off on how the page size used for memory management
affects address translation and demand paging. Support for multiple page sizes
can help relax the page size trade-off so that address translation and demand
paging optimizations work together synergistically. However, existing page
coalescing and splintering policies require costly base page migrations that
undermine the benefits multiple page sizes provide. In this paper, we observe
that GPGPU applications present an opportunity to support multiple page sizes
without costly data migration, as the applications perform most of their memory
allocation en masse (i.e., they allocate a large number of base pages at once).
We show that this en masse allocation allows us to create intelligent memory
allocation policies which ensure that base pages that are contiguous in virtual
memory are allocated to contiguous physical memory pages. As a result,
coalescing and splintering operations no longer need to migrate base pages.
  We introduce Mosaic, a GPU memory manager that provides
application-transparent support for multiple page sizes. Mosaic uses base pages
to transfer data over the system I/O bus, and allocates physical memory in a
way that (1) preserves base page contiguity and (2) ensures that a large page
frame contains pages from only a single memory protection domain. This
mechanism allows the TLB to use large pages, reducing address translation
overhead. During data transfer, this mechanism enables the GPU to transfer only
the base pages that are needed by the application over the system I/O bus,
keeping demand paging overhead low.
"
961,"Hardware Implementation of A Non-RLL Soft-decoding Beacon-based Visible
  Light Communication Receiver","  Visible light communication (VLC)-based beacon systems, which usually
transmit identification (ID) information in small-size data frames are applied
widely in indoor localization applications. There is one fact that flicker of
LED light should be avoid in any VLC systems. Current flicker mitigation
solutions based on run-length limited (RLL) codes suffer from reduced code
rates, or are limited to hard-decoding forward error correction (FEC) decoders.
Recently, soft-decoding techniques of RLL-codes are proposed to support
soft-decoding FEC algorithms, but they contain potentials of high-complexity
and time-consuming computations. Fortunately, non-RLL direct current
(DC)-balance solutions can overcome the drawbacks of RLL-based algorithms,
however, they meet some difficulties in system latency or inferior
error-correction performances. Recently, non-RLL flicker mitigation solution
based on Polar code has proved to be an optimal approach due to its natural
equal probabilities of short runs of 1's and 0's with high error-correction
performance. However, we found that this solution can only maintain the DC
balance only when the data frame length is sufficiently long. Accordingly,
short beacon-based data frames might still be a big challenge for flicker
mitigation in such non-RLL cases. In this paper, we introduce a flicker
mitigation solution designed for VLC-based beacon systems that combines a
simple pre-scrambler with a Polar encoder which has a codeword smaller than the
previous work 8 times. We also propose a hardware architecture for the proposed
compact non-RLL VLC receiver for the first time. Also, a 3-bit soft-decision
filter is introduce to enable soft-decoding of Polar decoder to improve the
performance of the receiver.
"
962,Dynamically Improving Branch Prediction Accuracy Between Contexts,"  Branch prediction is a standard feature in most processors, significantly
improving the run time of programs by allowing a processor to predict the
direction of a branch before it has been evaluated. Current branch prediction
methods can achieve excellent prediction accuracy through global tables,
various hashing methods, and even machine learning techniques such as SVMs or
neural networks. Such designs, however, may lose effectiveness when attempting
to predict across context switches in the operating system. Such a scenario may
lead to destructive interference between contexts, therefore reducing overall
predictor accuracy. To solve this problem, we propose a novel scheme for
deciding whether a context switch produces destructive or constructive
interference. First, we present evidence that shows that destructive
interference can have a significant negative impact on prediction accuracy.
Second, we present an extensible framework that keeps track of context switches
and prediction accuracy to improve overall accuracy. Experimental results show
that this framework effectively reduces the effect of destructive interference
on branch prediction.
"
963,"ECI-Cache: A High-Endurance and Cost-Efficient I/O Caching Scheme for
  Virtualized Platforms","  In recent years, high interest in using Virtual Machines (VMs) in data
centers and Cloud computing has significantly increased the demand for
high-performance data storage systems. Recent studies suggest using SSDs as a
caching layer for HDD-based storage subsystems in virtualization platforms.
Such studies neglect to address the endurance and cost of SSDs, which can
significantly affect the efficiency of I/O caching. Moreover, previous studies
only configure the cache size to provide the required performance level for
each VM, while neglecting other important parameters such as cache write policy
and request type, which can adversely affect both performance-per-cost and
endurance.
  In this paper, we present a new high-Endurance and Cost-efficient I/O Caching
(ECI-Cache) scheme for virtualized platforms, which can significantly improve
both the performance-per-cost and endurance of storage subsystems as opposed to
previously proposed I/O caching schemes. Unlike traditional I/O caching schemes
which allocate cache size only based on reuse distance of accesses, we propose
a new metric, Useful Reuse Distance (URD), which considers the request type in
reuse distance calculation, resulting in improved performance-per-cost and
endurance for the SSD cache. Via online characterization of workloads and using
URD, ECI-Cache partitions the SSD cache across VMs and is able to dynamically
adjust the cache size and write policy for each VM. To evaluate the proposed
scheme, we have implemented ECI-Cache in an open source hypervisor, QEMU
(version 2.8.0), on a server running the CentOS 7 operating system (kernel
version 3.10.0-327). Experimental results show that our proposed scheme
improves the performance, performance-per-cost, and endurance of the SSD cache
by 17%, 30% and 65%, respectively, compared to the state-of-the-art dynamic
cache partitioning scheme.
"
964,Reducing DRAM Refresh Overheads with Refresh-Access Parallelism,"  This article summarizes the idea of ""refresh-access parallelism,"" which was
published in HPCA 2014, and examines the work's significance and future
potential. The overarching objective of our HPCA 2014 paper is to reduce the
significant negative performance impact of DRAM refresh with intelligent memory
controller mechanisms.
  To mitigate the negative performance impact of DRAM refresh, our HPCA 2014
paper proposes two complementary mechanisms, DARP (Dynamic Access Refresh
Parallelization) and SARP (Subarray Access Refresh Parallelization). The goal
is to address the drawbacks of state-of-the-art per-bank refresh mechanism by
building more efficient techniques to parallelize refreshes and accesses within
DRAM. First, instead of issuing per-bank refreshes in a round-robin order, as
it is done today, DARP issues per-bank refreshes to idle banks in an
out-of-order manner. Furthermore, DARP proactively schedules refreshes during
intervals when a batch of writes are draining to DRAM. Second, SARP exploits
the existence of mostly-independent subarrays within a bank. With minor
modifications to DRAM organization, it allows a bank to serve memory accesses
to an idle subarray while another subarray is being refreshed. Our extensive
evaluations on a wide variety of workloads and systems show that our mechanisms
improve system performance (and energy efficiency) compared to three
state-of-the-art refresh policies, and their performance bene ts increase as
DRAM density increases.
"
965,"Exploiting the DRAM Microarchitecture to Increase Memory-Level
  Parallelism","  This paper summarizes the idea of Subarray-Level Parallelism (SALP) in DRAM,
which was published in ISCA 2012, and examines the work's significance and
future potential. Modern DRAMs have multiple banks to serve multiple memory
requests in parallel. However, when two requests go to the same bank, they have
to be served serially, exacerbating the high latency of on-chip memory. Adding
more banks to the system to mitigate this problem incurs high system cost. Our
goal in this work is to achieve the benefits of increasing the number of banks
with a low-cost approach. To this end, we propose three new mechanisms, SALP-1,
SALP-2, and MASA (Multitude of Activated Subarrays), to reduce the
serialization of different requests that go to the same bank. The key
observation exploited by our mechanisms is that a modern DRAM bank is
implemented as a collection of subarrays that operate largely independently
while sharing few global peripheral structures.
  Our three proposed mechanisms mitigate the negative impact of bank
serialization by overlapping different components of the bank access latencies
of multiple requests that go to different subarrays within the same bank.
SALP-1 requires no changes to the existing DRAM structure, and needs to only
reinterpret some of the existing DRAM timing parameters. SALP-2 and MASA
require only modest changes (< 0.15% area overhead) to the DRAM peripheral
structures, which are much less design constrained than the DRAM core. Our
evaluations show that SALP-1, SALP-2 and MASA significantly improve performance
for both single-core systems (7%/13%/17%) and multi-core systems (15%/16%/20%),
averaged across a wide range of workloads. We also demonstrate that our
mechanisms can be combined with application-aware memory request scheduling in
multicore systems to further improve performance and fairness.
"
966,"FlashAbacus: A Self-Governing Flash-Based Accelerator for Low-Power
  Systems","  Energy efficiency and computing flexibility are some of the primary design
constraints of heterogeneous computing. In this paper, we present FlashAbacus,
a data-processing accelerator that self-governs heterogeneous kernel executions
and data storage accesses by integrating many flash modules in lightweight
multiprocessors. The proposed accelerator can simultaneously process data from
different applications with diverse types of operational functions, and it
allows multiple kernels to directly access flash without the assistance of a
host-level file system or an I/O runtime library. We prototype FlashAbacus on a
multicore-based PCIe platform that connects to FPGA-based flash controllers
with a 20 nm node process. The evaluation results show that FlashAbacus can
improve the bandwidth of data processing by 127%, while reducing energy
consumption by 78.4%, as compared to a conventional method of heterogeneous
computing. \blfootnote{This paper is accepted by and will be published at 2018
EuroSys. This document is presented to ensure timely dissemination of scholarly
and technical work.
"
967,"Experimental Characterization, Optimization, and Recovery of Data
  Retention Errors in MLC NAND Flash Memory","  This paper summarizes our work on experimentally characterizing, mitigating,
and recovering data retention errors in multi-level cell (MLC) NAND flash
memory, which was published in HPCA 2015, and examines the work's significance
and future potential. Retention errors, caused by charge leakage over time, are
the dominant source of flash memory errors. Understanding, characterizing, and
reducing retention errors can significantly improve NAND flash memory
reliability and endurance. In this work, we first characterize, with real 2Y-nm
MLC NAND flash chips, how the threshold voltage distribution of flash memory
changes with different retention ages -- the length of time since a flash cell
was programmed. We observe from our characterization results that 1) the
optimal read reference voltage of a flash cell, using which the data can be
read with the lowest raw bit error rate (RBER), systematically changes with its
retention age, and 2) different regions of flash memory can have different
retention ages, and hence different optimal read reference voltages.
  Based on our findings, we propose two new techniques. First, Retention
Optimized Reading (ROR) adaptively learns and applies the optimal read
reference voltage for each flash memory block online. The key idea of ROR is to
periodically learn a tight upper bound of the optimal read reference voltage,
and from there approach the optimal read reference voltage. Our evaluations
show that ROR can extend flash memory lifetime by 64% and reduce average error
correction latency by 10.1%. Second, Retention Failure Recovery (RFR) recovers
data with uncorrectable errors offline by identifying and probabilistically
correcting flash cells with retention errors. Our evaluation shows that RFR
essentially doubles the error correction capability.
"
968,"A High-Throughput Architecture of List Successive Cancellation Polar
  Codes Decoder with Large List Size","  As the first kind of forward error correction (FEC) codes that achieve
channel capacity, polar codes have attracted much research interest recently.
Compared with other popular FEC codes, polar codes decoded by list successive
cancellation decoding (LSCD) with a large list size have better error
correction performance. However, due to the serial decoding nature of LSCD and
the high complexity of list management (LM), the decoding latency is high,
which limits the usage of polar codes in practical applications that require
low latency and high throughput. In this work, we study the high-throughput
implementation of LSCD with a large list size. Specifically, at the algorithmic
level, to achieve a low decoding latency with moderate hardware complexity, two
decoding schemes, a multi-bit double thresholding scheme and a partial G-node
look-ahead scheme, are proposed. Then, a high-throughput VLSI architecture
implementing the proposed algorithms is developed with optimizations on
different computation modules. From the implementation results on UMC 90 nm
CMOS technology, the proposed architecture achieves decoding throughputs of
1.103 Gbps, 977 Mbps and 827 Mbps when the list sizes are 8, 16 and 32,
respectively.
"
969,Hierarchical Temporal Memory using Memristor Networks: A Survey,"  This paper presents a survey of the currently available hardware designs for
implementation of the human cortex inspired algorithm, Hierarchical Temporal
Memory (HTM). In this review, we focus on the state of the art advances of
memristive HTM implementation and related HTM applications. With the advent of
edge computing, HTM can be a potential algorithm to implement on-chip near
sensor data processing. The comparison of analog memristive circuit
implementations with the digital and mixed-signal solutions are provided. The
advantages of memristive HTM over digital implementations against performance
metrics such as processing speed, reduced on-chip area and power dissipation
are discussed. The limitations and open problems concerning the memristive HTM,
such as the design scalability, sneak currents, leakage, parasitic effects,
lack of the analog learning circuits implementations and unreliability of the
memristive devices integrated with CMOS circuits are also discussed.
"
970,"Adaptive-Latency DRAM: Reducing DRAM Latency by Exploiting Timing
  Margins","  This paper summarizes the idea of Adaptive-Latency DRAM (AL-DRAM), which was
published in HPCA 2015, and examines the work's significance and future
potential. AL-DRAM is a mechanism that optimizes DRAM latency based on the DRAM
module and the operating temperature, by exploiting the extra margin that is
built into the DRAM timing parameters. DRAM manufacturers provide a large
margin for the timing parameters as a provision against two worst-case
scenarios. First, due to process variation, some outlier DRAM chips are much
slower than others. Second, chips become slower at higher temperatures. The
timing parameter margin ensures that the slow outlier chips operate reliably at
the worst-case temperature, and hence leads to a high access latency.
  Using an FPGA-based DRAM testing platform, our work first characterizes the
extra margin for 115 DRAM modules from three major manufacturers. The
experimental results demonstrate that it is possible to reduce four of the most
critical timing parameters by a minimum/maximum of 17.3%/54.8% at 55C while
maintaining reliable operation. AL-DRAM uses these observations to adaptively
select reliable DRAM timing parameters for each DRAM module based on the
module's current operating conditions. AL-DRAM does not require any changes to
the DRAM chip or its interface; it only requires multiple different timing
parameters to be specified and supported by the memory controller. Our real
system evaluations show that AL-DRAM improves the performance of
memory-intensive workloads by an average of 14% without introducing any errors.
Our characterization and proposed techniques have inspired several other works
on analyzing and/or exploiting different sources of latency and performance
variation within DRAM chips.
"
971,Tiered-Latency DRAM: Enabling Low-Latency Main Memory at Low Cost,"  This paper summarizes the idea of Tiered-Latency DRAM (TL-DRAM), which was
published in HPCA 2013, and examines the work's significance and future
potential. The capacity and cost-per-bit of DRAM have historically scaled to
satisfy the needs of increasingly large and complex computer systems. However,
DRAM latency has remained almost constant, making memory latency the
performance bottleneck in today's systems. We observe that the high access
latency is not intrinsic to DRAM, but a trade-off is made to decrease the cost
per bit. To mitigate the high area overhead of DRAM sensing structures,
commodity DRAMs connect many DRAM cells to each sense amplifier through a wire
called a bitline. These bit-lines have a high parasitic capacitance due to
their long length, and this bitline capacitance is the dominant source of DRAM
latency. Specialized low-latency DRAMs use shorter bitlines with fewer cells,
but have a higher cost-per-bit due to greater sense amplifier area overhead. To
achieve both low latency and low cost per bit, we introduce Tiered-Latency DRAM
(TL-DRAM). In TL-DRAM, each long bitline is split into two shorter segments by
an isolation transistor, allowing one of the two segments to be accessed with
the latency of a short-bitline DRAM without incurring a high cost per bit. We
propose mechanisms that use the low-latency segment as a hardware-managed or
software-managed cache. Our evaluations show that our proposed mechanisms
improve both performance and energy efficiency for both single-core and
multiprogrammed workloads. Tiered-Latency DRAM has inspired several other works
on reducing DRAM latency with little to no architectural modification.
"
972,"Flexible-Latency DRAM: Understanding and Exploiting Latency Variation in
  Modern DRAM Chips","  This article summarizes key results of our work on experimental
characterization and analysis of latency variation and latency-reliability
trade-offs in modern DRAM chips, which was published in SIGMETRICS 2016, and
examines the work's significance and future potential.
  The goal of this work is to (i) experimentally characterize and understand
the latency variation across cells within a DRAM chip for these three
fundamental DRAM operations, and (ii) develop new mechanisms that exploit our
understanding of the latency variation to reliably improve performance. To this
end, we comprehensively characterize 240 DRAM chips from three major vendors,
and make six major new observations about latency variation within DRAM.
Notably, we find that (i) there is large latency variation across the cells for
each of the three operations; (ii) variation characteristics exhibit
significant spatial locality: slower cells are clustered in certain regions of
a DRAM chip; and (iii) the three fundamental operations exhibit different
reliability characteristics when the latency of each operation is reduced.
  Based on our observations, we propose Flexible-LatencY DRAM (FLY-DRAM), a
mechanism that exploits latency variation across DRAM cells within a DRAM chip
to improve system performance. The key idea of FLY-DRAM is to exploit the
spatial locality of slower cells within DRAM, and access the faster DRAM
regions with reduced latencies for the fundamental operations. Our evaluations
show that FLY-DRAM improves the performance of a wide range of applications by
13.3%, 17.6%, and 19.5%, on average, for each of the three different vendors'
real DRAM chips, in a simulated 8-core system.
"
973,"Voltron: Understanding and Exploiting the Voltage-Latency-Reliability
  Trade-Offs in Modern DRAM Chips to Improve Energy Efficiency","  This paper summarizes our work on experimental characterization and analysis
of reduced-voltage operation in modern DRAM chips, which was published in
SIGMETRICS 2017, and examines the work's significance and future potential.
  We take a comprehensive approach to understanding and exploiting the latency
and reliability characteristics of modern DRAM when the DRAM supply voltage is
lowered below the nominal voltage level specified by DRAM standards. We perform
an experimental study of 124 real DDR3L (low-voltage) DRAM chips manufactured
recently by three major DRAM vendors. We find that reducing the supply voltage
below a certain point introduces bit errors in the data, and we comprehensively
characterize the behavior of these errors. We discover that these errors can be
avoided by increasing the latency of three major DRAM operations (activation,
restoration, and precharge). We perform detailed DRAM circuit simulations to
validate and explain our experimental findings. We also characterize the
various relationships between reduced supply voltage and error locations,
stored data patterns, DRAM temperature, and data retention.
  Based on our observations, we propose a new DRAM energy reduction mechanism,
called Voltron. The key idea of Voltron is to use a performance model to
determine by how much we can reduce the supply voltage without introducing
errors and without exceeding a user-specified threshold for performance loss.
Our evaluations show that Voltron reduces the average DRAM and system energy
consumption by 10.5% and 7.3%, respectively, while limiting the average system
performance loss to only 1.8%, for a variety of memory-intensive quad-core
workloads. We also show that Voltron significantly outperforms prior dynamic
voltage and frequency scaling mechanisms for DRAM.
"
974,"LISA: Increasing Internal Connectivity in DRAM for Fast Data Movement
  and Low Latency","  This paper summarizes the idea of Low-Cost Interlinked Subarrays (LISA),
which was published in HPCA 2016, and examines the work's significance and
future potential. Contemporary systems perform bulk data movement movement
inefficiently, by transferring data from DRAM to the processor, and then back
to DRAM, across a narrow off-chip channel. The use of this narrow channel
results in high latency and energy consumption. Prior work proposes to avoid
these high costs by exploiting the existing wide internal DRAM bandwidth for
bulk data movement, but the limited connectivity of wires within DRAM allows
fast data movement within only a single DRAM subarray. Each subarray is only a
few megabytes in size, greatly restricting the range over which fast bulk data
movement can happen within DRAM.
  Our HPCA 2016 paper proposes a new DRAM substrate, Low-Cost Inter-Linked
Subarrays (LISA), whose goal is to enable fast and efficient data movement
across a large range of memory at low cost. LISA adds low-cost connections
between adjacent subarrays. By using these connections to interconnect the
existing internal wires (bitlines) of adjacent subarrays, LISA enables
wide-bandwidth data transfer across multiple subarrays with little (only 0.8%)
DRAM area overhead. As a DRAM substrate, LISA is versatile, enabling a variety
of new applications. We describe and evaluate three such applications in
detail: (1) fast inter-subarray bulk data copy, (2) in-DRAM caching using a
DRAM architecture whose rows have heterogeneous access latencies, and (3)
accelerated bitline precharging by linking multiple precharge units together.
Our extensive evaluations show that each of LISA's three applications
significantly improves performance and memory energy efficiency on a variety of
workloads and system configurations.
"
975,"SoftMC: Practical DRAM Characterization Using an FPGA-Based
  Infrastructure","  This paper summarizes the SoftMC DRAM characterization infrastructure, which
was published in HPCA 2017, and examines the work's significance and future
potential.
  SoftMC (Soft Memory Controller) is the first publicly-available DRAM testing
infrastructure that can flexibly and efficiently test DRAM chips in a manner
accessible to both software and hardware developers. SoftMC is an FPGA-based
testing platform that can control and test memory modules designed for the
commonly-used DDR (Double Data Rate) interface. SoftMC has two key properties:
(i) it provides flexibility to thoroughly control memory behavior or to
implement a wide range of mechanisms using DDR commands; and (ii) it is easy to
use as it provides a simple and intuitive high-level programming interface for
users, completely hiding the low-level details of the FPGA.
  We demonstrate the capability, flexibility, and programming ease of SoftMC
with two example use cases. First, we implement a test that characterizes the
retention time of DRAM cells. Second, we show that the expected latency
reduction of two recently-proposed mechanisms, which rely on accessing
recently-refreshed or recently-accessed DRAM cells faster than other DRAM
cells, is not observable in existing DRAM chips.
  Various versions of the SoftMC platform have enabled many of our other DRAM
characterization studies. We discuss several other use cases of SoftMC,
including the ability to characterize emerging non-volatile memory modules that
obey the DDR standard. We hope that our open-source release of SoftMC fills a
gap in the space of publicly-available experimental memory testing
infrastructures and inspires new studies, ideas, and methodologies in memory
system design.
"
976,Read Disturb Errors in MLC NAND Flash Memory,"  This paper summarizes our work on experimentally characterizing, mitigating,
and recovering read disturb errors in multi-level cell (MLC) NAND flash memory,
which was published in DSN 2015, and examines the work's significance and
future potential. NAND flash memory reliability continues to degrade as the
memory is scaled down and more bits are programmed per cell. A key contributor
to this reduced reliability is read disturb, where a read to one row of cells
impacts the threshold voltages of unread flash cells in different rows of the
same block.
  For the first time in open literature, this work experimentally characterizes
read disturb errors on state-of-the-art 2Y-nm (i.e., 20-24 nm) MLC NAND flash
memory chips. Our findings (1) correlate the magnitude of threshold voltage
shifts with read operation counts, (2) demonstrate how program/erase cycle
count and retention age affect the read-disturb-induced error rate, and (3)
identify that lowering pass-through voltage levels reduces the impact of read
disturb and extend flash lifetime. Particularly, we find that the probability
of read disturb errors increases with both higher wear-out and higher
pass-through voltage levels.
  We leverage these findings to develop two new techniques. The first technique
mitigates read disturb errors by dynamically tuning the pass-through voltage on
a per-block basis. Using real workload traces, our evaluations show that this
technique increases flash memory endurance by an average of 21%. The second
technique recovers from previously-uncorrectable flash errors by identifying
and probabilistically correcting cells susceptible to read disturb errors. Our
evaluations show that this recovery technique reduces the raw bit error rate by
36%.
"
977,"Characterizing, Exploiting, and Mitigating Vulnerabilities in MLC NAND
  Flash Memory Programming","  This paper summarizes our work on experimentally analyzing, exploiting, and
addressing vulnerabilities in multi-level cell NAND flash memory programming,
which was published in the industrial session of HPCA 2017, and examines the
work's significance and future potential. Modern NAND flash memory chips use
multi-level cells (MLC), which store two bits of data in each cell, to improve
chip density. As MLC NAND flash memory scaled down to smaller manufacturing
process technologies, manufacturers adopted a two-step programming method to
improve reliability. In two-step programming, the two bits of a multi-level
cell are programmed using two separate steps, in order to minimize the amount
of cell-to-cell program interference induced on neighboring flash cells.
  In this work, we demonstrate that two-step programming exposes new
reliability and security vulnerabilities in state-of-the-art MLC NAND flash
memory. We experimentally characterize contemporary 1X-nm (i.e., 15--19nm)
flash memory chips, and find that a partially-programmed flash cell (i.e., a
cell where the second programming step has not yet been performed) is much more
vulnerable to cell-to-cell interference and read disturb than a
fully-programmed cell. We show that it is possible to exploit these
vulnerabilities on solid-state drives (SSDs) to alter the partially-programmed
data, causing (potentially malicious) data corruption. Based on our
observations, we propose several new mechanisms that eliminate or mitigate
these vulnerabilities in partially-programmed cells, and at the same time
increase flash memory lifetime by 16%.
"
978,RowClone: Accelerating Data Movement and Initialization Using DRAM,"  In existing systems, to perform any bulk data movement operation (copy or
initialization), the data has to first be read into the on-chip processor, all
the way into the L1 cache, and the result of the operation must be written back
to main memory. This is despite the fact that these operations do not involve
any actual computation. RowClone exploits the organization and operation of
commodity DRAM to perform these operations completely inside DRAM using two
mechanisms. The first mechanism, Fast Parallel Mode, copies data between two
rows inside the same DRAM subarray by issuing back-to-back activate commands to
the source and the destination row. The second mechanism, Pipelined Serial
Mode, transfers cache lines between two banks using the shared internal bus.
RowClone significantly reduces the raw latency and energy consumption of bulk
data copy and initialization. This reduction directly translates to improvement
in performance and energy efficiency of systems running copy or
initialization-intensive workloads
"
979,Parallel Programming for FPGAs,"  This book focuses on the use of algorithmic high-level synthesis (HLS) to
build application-specific FPGA systems. Our goal is to give the reader an
appreciation of the process of creating an optimized hardware design using HLS.
Although the details are, of necessity, different from parallel programming for
multicore processors or GPUs, many of the fundamental concepts are similar. For
example, designers must understand memory hierarchy and bandwidth, spatial and
temporal locality of reference, parallelism, and tradeoffs between computation
and storage. This book is a practical guide for anyone interested in building
FPGA systems. In a university environment, it is appropriate for advanced
undergraduate and graduate courses. At the same time, it is also useful for
practicing system designers and embedded programmers. The book assumes the
reader has a working knowledge of C/C++ and includes a significant amount of
sample code. In addition, we assume familiarity with basic computer
architecture concepts (pipelining, speedup, Amdahl's Law, etc.). A knowledge of
the RTL-based FPGA design flow is helpful, although not required.
"
980,Neural Cache: Bit-Serial In-Cache Acceleration of Deep Neural Networks,"  This paper presents the Neural Cache architecture, which re-purposes cache
structures to transform them into massively parallel compute units capable of
running inferences for Deep Neural Networks. Techniques to do in-situ
arithmetic in SRAM arrays, create efficient data mapping and reducing data
movement are proposed. The Neural Cache architecture is capable of fully
executing convolutional, fully connected, and pooling layers in-cache. The
proposed architecture also supports quantization in-cache. Our experimental
results show that the proposed architecture can improve inference latency by
18.3x over state-of-art multi-core CPU (Xeon E5), 7.7x over server class GPU
(Titan Xp), for Inception v3 model. Neural Cache improves inference throughput
by 12.4x over CPU (2.2x over GPU), while reducing power consumption by 50% over
CPU (53% over GPU).
"
981,"Exploiting Row-Level Temporal Locality in DRAM to Reduce the Memory
  Access Latency","  This paper summarizes the idea of ChargeCache, which was published in HPCA
2016 [51], and examines the work's significance and future potential. DRAM
latency continues to be a critical bottleneck for system performance. In this
work, we develop a low-cost mechanism, called ChargeCache, that enables faster
access to recently-accessed rows in DRAM, with no modifications to DRAM chips.
Our mechanism is based on the key observation that a recently-accessed row has
more charge and thus the following access to the same row can be performed
faster. To exploit this observation, we propose to track the addresses of
recently-accessed rows in a table in the memory controller. If a later DRAM
request hits in that table, the memory controller uses lower timing parameters,
leading to reduced DRAM latency. Row addresses are removed from the table after
a specified duration to ensure rows that have leaked too much charge are not
accessed with lower latency. We evaluate ChargeCache on a wide variety of
workloads and show that it provides significant performance and energy benefits
for both single-core and multi-core systems.
"
982,Hybrid CMOS-CNFET based NP dynamic Carry Look Ahead Adder,"  Advanced electronic device technologies require a faster operation and
smaller average power consumption, which are the most important parameters in
very large scale integrated circuit design. The conventional Complementary
Metal-Oxide Semiconductor (CMOS) technology is limited by the threshold voltage
and subthreshold leakage problems in scaling of devices. This leads to failure
in adapting it to sub-micron and nanotechnologies. The carbon nanotube (CNT)
technology overcomes the threshold voltage and subthreshold leakage problems
despite reduction in size. The CNT based technology develops the most promising
devices among emerging technologies because it has most of the desired
features. Carbon Nanotube Field Effect Transistors (CNFETs) are the novel
devices that are expected to sustain the transistor scalability while
increasing its performance. Recently, there have been tremendous advances in
CNT technology for nanoelectronics applications. CNFETs avoid most of the
fundamental limitations and offer several advantages compared to silicon-based
technology. Though CNT evolves as a better option to overcome some of the bulk
CMOS problems, the CNT itself still immersed with setbacks. The fabrication of
carbon nanotube at very large digital circuits on a single substrate is
difficult to achieve. Therefore, a hybrid NP dynamic Carry Look Ahead Adder
(CLA) is designed using p-CNFET and n-MOS transistors. Here, the performance of
CLA is evaluated in 8-bit, 16-bit, 32-bit and 64-bit stages with the following
four different implementations: silicon MOSFET (Si-MOSFET) domino logic,
Si-MOSFET NP dynamic CMOS, carbon nanotube MOSFET (CN-MOSFET) domino logic, and
CN-MOSFET NP dynamic CMOS. Finally, a Hybrid CMOS-CNFET based 64-bit NP dynamic
CLA is evaluated based on HSPICE simulation in 32nm technology, which
effectively suppresses power dissipation without an increase in propagation
delay.
"
983,Laconic Deep Learning Computing,"  We motivate a method for transparently identifying ineffectual computations
in unmodified Deep Learning models and without affecting accuracy.
Specifically, we show that if we decompose multiplications down to the bit
level the amount of work performed during inference for image classification
models can be consistently reduced by two orders of magnitude. In the best case
studied of a sparse variant of AlexNet, this approach can ideally reduce
computation work by more than 500x. We present Laconic a hardware accelerator
that implements this approach to improve execution time, and energy efficiency
for inference with Deep Learning Networks. Laconic judiciously gives up some of
the work reduction potential to yield a low-cost, simple, and energy efficient
design that outperforms other state-of-the-art accelerators. For example, a
Laconic configuration that uses a weight memory interface with just 128 wires
outperforms a conventional accelerator with a 2K-wire weight memory interface
by 2.3x on average while being 2.13x more energy efficient on average. A
Laconic configuration that uses a 1K-wire weight memory interface, outperforms
the 2K-wire conventional accelerator by 15.4x and is 1.95x more energy
efficient. Laconic does not require but rewards advances in model design such
as a reduction in precision, the use of alternate numeric representations that
reduce the number of bits that are ""1"", or an increase in weight or activation
sparsity.
"
984,"Predictable Performance and Fairness Through Accurate Slowdown
  Estimation in Shared Main Memory Systems","  This paper summarizes the ideas and key concepts in MISE (Memory
Interference-induced Slowdown Estimation), which was published in HPCA 2013
[97], and examines the work's significance and future potential. Applications
running concurrently on a multicore system interfere with each other at the
main memory. This interference can slow down different applications
differently. Accurately estimating the slowdown of each application in such a
system can enable mechanisms that can enforce quality-of-service. While much
prior work has focused on mitigating the performance degradation due to
inter-application interference, there is little work on accurately estimating
slowdown of individual applications in a multi-programmed environment. Our goal
is to accurately estimate application slowdowns, towards providing predictable
performance.
  To this end, we first build a simple Memory Interference-induced Slowdown
Estimation (MISE) model, which accurately estimates slowdowns caused by memory
interference. We then leverage our MISE model to develop two new memory
scheduling schemes: 1) one that provides soft quality-of-service guarantees,
and 2) another that explicitly attempts to minimize maximum slowdown (i.e.,
unfairness) in the system. Evaluations show that our techniques perform
significantly better than state-of-the-art memory scheduling approaches to
address the same problems.
  Our proposed model and techniques have enabled significant research in the
development of accurate performance models [35, 59, 98, 110] and interference
management mechanisms [66, 99, 100, 108, 119, 120].
"
985,BLASYS: Approximate Logic Synthesis Using Boolean Matrix Factorization,"  Approximate computing is an emerging paradigm where design accuracy can be
traded off for benefits in design metrics such as design area, power
consumption or circuit complexity. In this work, we present a novel paradigm to
synthesize approximate circuits using Boolean matrix factorization (BMF). In
our methodology the truth table of a sub-circuit of the design is approximated
using BMF to a controllable approximation degree, and the results of the
factorization are used to synthesize a less complex subcircuit. To scale our
technique to large circuits, we devise a circuit decomposition method and a
subcircuit design-space exploration technique to identify the best order for
subcircuit approximations. Our method leads to a smooth trade-off between
accuracy and full circuit complexity as measured by design area and power
consumption. Using an industrial strength design flow, we extensively evaluate
our methodology on a number of testcases, where we demonstrate that the
proposed methodology can achieve up to 63% in power savings, while introducing
an average relative error of 5%. We also compare our work to previous works in
Boolean circuit synthesis and demonstrate significant improvements in design
metrics for same accuracy targets.
"
986,"Recent Advances in Overcoming Bottlenecks in Memory Systems and Managing
  Memory Resources in GPU Systems","  This article features extended summaries and retrospectives of some of the
recent research done by our research group, SAFARI, on (1) various critical
problems in memory systems and (2) how memory system bottlenecks affect
graphics processing unit (GPU) systems. As more applications share a single
system, operations from each application can contend with each other at various
shared components. Such contention can slow down each application or thread of
execution. The compound effect of contention, high memory latency and access
overheads, as well as inefficient management of resources, greatly degrades
performance, quality-of-service, and energy efficiency. The ten works featured
in this issue study several aspects of (1) inter-application interference in
multicore systems, heterogeneous systems, and GPUs; (2) the growing overheads
and expenses associated with growing memory densities and latencies; and (3)
performance, programmability, and portability issues in modern GPUs, especially
those related to memory system resources.
"
987,"ReCA: an Efficient Reconfigurable Cache Architecture for Storage Systems
  with Online Workload Characterization","  In recent years, SSDs have gained tremendous attention in computing and
storage systems due to significant performance improvement over HDDs. The cost
per capacity of SSDs, however, prevents them from entirely replacing HDDs in
such systems. One approach to effectively take advantage of SSDs is to use them
as a caching layer to store performance critical data blocks to reduce the
number of accesses to disk subsystem. Due to characteristics of Flash-based
SSDs such as limited write endurance and long latency on write operations,
employing caching algorithms at the Operating System (OS) level necessitates to
take such characteristics into consideration. Previous caching techniques are
optimized towards only one type of application, which affects both generality
and applicability. In addition, they are not adaptive when the workload pattern
changes over time. This paper presents an efficient Reconfigurable Cache
Architecture (ReCA) for storage systems using a comprehensive workload
characterization to find an optimal cache configuration for I/O intensive
applications. For this purpose, we first investigate various types of I/O
workloads and classify them into five major classes. Based on this
characterization, an optimal cache configuration is presented for each class of
workloads. Then, using the main features of each class, we continuously monitor
the characteristics of an application during system runtime and the cache
organization is reconfigured if the application changes from one class to
another class of workloads. The cache reconfiguration is done online and
workload classes can be extended to emerging I/O workloads in order to maintain
its efficiency with the characteristics of I/O requests. Experimental results
obtained by implementing ReCA in a server running Linux show that the proposed
architecture improves performance and lifetime up to 24\% and 33\%,
respectively.
"
988,"LECTOR Based Clock Gating for Low Power Multi-Stage Flip Flop
  Applications","  Power dissipation in integrated circuits is one of the major concerns to the
research community, at the verge when more number of transistors are integrated
on a single chip. The substantial source of power dissipation in sequential
elements of the integrated circuit is due to the fast switching of high
frequency clock signals. These signals do not carry any information and are
mainly intended to synchronize the operation of sequential components. This
unnecessary switching of Clock, during the HOLD phase of either logic 1 or
logic 0, may be eliminated using a technique, called Clock Gating. In this
paper, we have incorporated a recent clock gating style called LECTOR based
clock gating LB CG to drive multi stage architecture and simulated its
performance using 90nm CMOS Predictive Technology Model PTM with a power supply
of 1.1V at 18GHz clock frequency. A substantial savings in terms of average
power in comparison to its non gated correspondent have been observed.
"
989,"CIAO: Cache Interference-Aware Throughput-Oriented Architecture and
  Scheduling for GPUs","  A modern GPU aims to simultaneously execute more warps for higher
Thread-Level Parallelism (TLP) and performance. When generating many memory
requests, however, warps contend for limited cache space and thrash cache,
which in turn severely degrades performance. To reduce such cache thrashing, we
may adopt cache locality-aware warp scheduling which gives higher execution
priority to warps with higher potential of data locality. However, we observe
that warps with high potential of data locality often incurs far more cache
thrashing or interference than warps with low potential of data locality.
Consequently, cache locality-aware warp scheduling may undesirably increase
cache interference and/or unnecessarily decrease TLP. In this paper, we propose
Cache Interference-Aware throughput-Oriented (CIAO) on-chip memory architecture
and warp scheduling which exploit unused shared memory space and take insight
opposite to cache locality-aware warp scheduling. Specifically, CIAO on-chip
memory architecture can adaptively redirect memory requests of severely
interfering warps to unused shared memory space to isolate memory requests of
these interfering warps from those of interfered warps. If these interfering
warps still incur severe cache interference, CIAO warp scheduling then begins
to selectively throttle execution of these interfering warps. Our experiment
shows that CIAO can offer 54% higher performance than prior cache
locality-aware scheduling at a small chip cost.
"
990,Constructing a Weak Memory Model,"  Weak memory models are a consequence of the desire on part of architects to
preserve all the uniprocessor optimizations while building a shared memory
multiprocessor. The efforts to formalize weak memory models of ARM and POWER
over the last decades are mostly empirical -- they try to capture empirically
observed behaviors -- and end up providing no insight into the inherent nature
of weak memory models. This paper takes a constructive approach to find a
common base for weak memory models: we explore what a weak memory would look
like if we constructed it with the explicit goal of preserving all the
uniprocessor optimizations. We will disallow some optimizations which break a
programmer's intuition in highly unexpected ways. The constructed model, which
we call General Atomic Memory Model (GAM), allows all four load/store
reorderings. We give the construction procedure of GAM, and provide insights
which are used to define its operational and axiomatic semantics. Though no
attempt is made to match GAM to any existing weak memory model, we show by
simulation that GAM has comparable performance with other models. No deep
knowledge of memory models is needed to read this paper.
"
991,"SqueezeJet: High-level Synthesis Accelerator Design for Deep
  Convolutional Neural Networks","  Deep convolutional neural networks have dominated the pattern recognition
scene by providing much more accurate solutions in computer vision problems
such as object recognition and object detection. Most of these solutions come
at a huge computational cost, requiring billions of multiply-accumulate
operations and, thus, making their use quite challenging in real-time
applications that run on embedded mobile (resource-power constrained) hardware.
This work presents the architecture, the high-level synthesis design, and the
implementation of SqueezeJet, an FPGA accelerator for the inference phase of
the SqueezeNet DCNN architecture, which is designed specifically for use in
embedded systems. Results show that SqueezeJet can achieve 15.16 times speed-up
compared to the software implementation of SqueezeNet running on an embedded
mobile processor with less than 1% drop in top-5 accuracy.
"
992,Recent Advances in DRAM and Flash Memory Architectures,"  This article features extended summaries and retrospectives of some of the
recent research done by our group, SAFARI, on (1) understanding,
characterizing, and modeling various critical properties of modern DRAM and
NAND flash memory, the dominant memory and storage technologies, respectively;
and (2) several new mechanisms we have proposed based on our observations from
these analyses, characterization, and modeling, to tackle various key
challenges in memory and storage scaling. In order to understand the sources of
various bottlenecks of the dominant memory and storage technologies, these
works perform rigorous studies of device-level and application-level behavior,
using a combination of detailed simulation and experimental characterization of
real memory and storage devices.
"
993,PRINS: Resistive CAM Processing in Storage,"  Near-data in-storage processing research has been gaining momentum in recent
years. Typical processing-in-storage architecture places a single or several
processing cores inside the storage and allows data processing without
transferring it to the host CPU. Since this approach replicates von Neumann
architecture inside storage, it is exposed to the problems faced by von Neumann
architecture, especially the bandwidth wall. We present PRINS, a novel in-data
processing-in-storage architecture based on Resistive Content Addressable
Memory (RCAM). PRINS functions simultaneously as a storage and a massively
parallel associative processor. PRINS alleviates the bandwidth wall faced by
conventional processing-in-storage architectures by keeping the computing
inside the storage arrays, thus implementing in-data, rather than near-data,
processing. We show that PRINS may outperform a reference computer architecture
with a bandwidth-limited external storage. The performance of PRINS Euclidean
distance, dot product and histogram implementation exceeds the attainable
performance of a reference architecture by up to four orders of magnitude,
depending on the dataset size. The performance of PRINS SpMV may exceed the
attainable performance of such reference architecture by more than two orders
of magnitude.
"
994,"Architectures for High Performance Computing and Data Systems using
  Byte-Addressable Persistent Memory","  Non-volatile, byte addressable, memory technology with performance close to
main memory promises to revolutionise computing systems in the near future.
Such memory technology provides the potential for extremely large memory
regions (i.e. > 3TB per server), very high performance I/O, and new ways of
storing and sharing data for applications and workflows. This paper outlines an
architecture that has been designed to exploit such memory for High Performance
Computing and High Performance Data Analytics systems, along with descriptions
of how applications could benefit from such hardware.
"
995,"f-CNN$^{\text{x}}$: A Toolflow for Mapping Multiple Convolutional Neural
  Networks on FPGAs","  The predictive power of Convolutional Neural Networks (CNNs) has been an
integral factor for emerging latency-sensitive applications, such as autonomous
drones and vehicles. Such systems employ multiple CNNs, each one trained for a
particular task. The efficient mapping of multiple CNNs on a single FPGA device
is a challenging task as the allocation of compute resources and external
memory bandwidth needs to be optimised at design time. This paper proposes
f-CNN$^{\text{x}}$, an automated toolflow for the optimised mapping of multiple
CNNs on FPGAs, comprising a novel multi-CNN hardware architecture together with
an automated design space exploration method that considers the user-specified
performance requirements for each model to allocate compute resources and
generate a synthesisable accelerator. Moreover, f-CNN$^{\text{x}}$ employs a
novel scheduling algorithm that alleviates the limitations of the memory
bandwidth contention between CNNs and sustains the high utilisation of the
architecture. Experimental evaluation shows that f-CNN$^{\text{x}}$'s designs
outperform contention-unaware FPGA mappings by up to 50% and deliver up to 6.8x
higher performance-per-Watt over highly optimised GPU designs for multi-CNN
systems.
"
996,"Time-Shared Execution of Realtime Computer Vision Pipelines by Dynamic
  Partial Reconfiguration","  This paper presents an FPGA runtime framework that demonstrates the
feasibility of using dynamic partial reconfiguration (DPR) for time-sharing an
FPGA by multiple realtime computer vision pipelines. The presented time-sharing
runtime framework manages an FPGA fabric that can be round-robin time-shared by
different pipelines at the time scale of individual frames. In this new
use-case, the challenge is to achieve useful performance despite high
reconfiguration time. The paper describes the basic runtime support as well as
four optimizations necessary to achieve realtime performance given the
limitations of DPR on today's FPGAs. The paper provides a characterization of a
working runtime framework prototype on a Xilinx ZC706 development board. The
paper also reports the performance of realtime computer vision pipelines when
time-shared.
"
997,"LaKe: An Energy Efficient, Low Latency, Accelerated Key-Value Store","  Key-value store is a popular type of cloud computing applications. The
performance of key-value store applications have been shown to be very
sensitive to load within the data center, and in particular to latency. As load
within data center increases, it is becoming hard to maintain key-value store
applications' performance, without exceeding both the processing capacity of
hosts and the power budgets of racks. In this paper, we present LaKe: a low
latency, power efficient key-value store design for cloud applications. LaKe is
a modular design, combining multiple cores and cache layering, both in hardware
and software. LaKe achieves full line rate throughput, while maintaining a
latency of 1.1us and better power efficiency than existing hardware based
memcached designs. Using the modularity of our design, we study trade-offs in
the use of on-chip memory, SRAM and DRAM in accelerated designs and provide
insights for future architectures.
"
998,A programmable clock generator for automatic Quality Assurance of LOCx2,"  The upgrade of ATLAS Liquid Argon Calorimeter (LAr) Phase-1 trigger requires
high-speed, low-latency data transmission to read out the Lar Trigger Digitizer
Board (LTDB). A dual-channel transmitter ASIC LOCx2 have been designed and
produced. In order to ensure all the LOCx2 chips behave properly, a Quality
Assurance needs to be conducted before assembly. The problem I was trying to
solve in this project is to yield a clock signal with continuously adjustable
frequency and phase offset to generate and control an eye diagram for the QA.
By configuring the registers of an any-frequency generator IC, Si5338, the
clock signal whose frequency range from 5MHz to 200 MHz have been properly
produced. For the purpose of further development, a C-language based DLL which
packs up the function of adjusting frequency and setting phase offset was
designed and built, and several evaluation was performed to ensure the
robustness of DLL.
"
999,An Efficient Graph Accelerator with Parallel Data Conflict Management,"  Graph-specific computing with the support of dedicated accelerator has
greatly boosted the graph processing in both efficiency and energy.
Nevertheless, their data conflict management is still sequential in essential
when some vertex needs a large number of conflicting updates at the same time,
leading to prohibitive performance degradation. This is particularly true for
processing natural graphs.
  In this paper, we have the insight that the atomic operations for the vertex
updating of many graph algorithms (e.g., BFS, PageRank and WCC) are typically
incremental and simplex. This hence allows us to parallelize the conflicting
vertex updates in an accumulative manner. We architect a novel graphspecific
accelerator that can simultaneously process atomic vertex updates for massive
parallelism on the conflicting data access while ensuring the correctness. A
parallel accumulator is designed to remove the serialization in atomic
protection for conflicting vertex updates through merging their results in
parallel. Our implementation on Xilinx Virtex UltraScale+ XCVU9P with a wide
variety of typical graph algorithms shows that our accelerator achieves an
average throughput by 2.36 GTEPS as well as up to 3.14x performance speedup in
comparison with state-of-the-art ForeGraph (with single-chip version).
"
1000,"Supporting Superpages and Lightweight Page Migration in Hybrid Memory
  Systems","  Superpages have long been used to mitigate address translation overhead in
big memory systems. However, superpages often preclude lightweight page
migration, which is crucial for performance and energy efficiency in hybrid
memory systems composed of DRAM and non-volatile memory (NVM). In this paper,
we propose a novel memory management mechanism called \textit{Rainbow} to
bridge this fundamental conflict between superpages and lightweight page
migration. \textit{Rainbow} manages NVM at the superpage granularity, and uses
DRAM to cache frequently-accessed (hot) small pages in each superpage.
Correspondingly, \textit{Rainbow} utilizes split TLBs to support different page
sizes. By introducing an efficient hot page identification mechanism and a
novel NVM-to-DRAM address remapping mechanism, \textit{Rainbow} supports
lightweight page migration while without splintering superpages. Experimental
results show that Rainbow can significantly reduce applications' TLB misses by
99.8\%, and improve application performance (IPC) by up to 2.9X (43.0\% on
average) when compared to a state-of-the-art memory migration policy without
superpage support.
"
1001,Gemini: Reducing DRAM Cache Hit Latency by Hybrid Mappings,"  Die-stacked DRAM caches are increasingly advocated to bridge the performance
gap between on-chip Cache and main memory. It is essential to improve DRAM
cache hit rate and lower cache hit latency simultaneously. Prior DRAM cache
designs fall into two categories according to the data mapping polices:
set-associative and direct-mapped, achieving either one. In this paper, we
propose a partial direct-mapped die-stacked DRAM cache to achieve the both
objectives simultaneously, called Gemini, which is motivated by the following
observations: applying unified mapping policy to different blocks cannot
achieve high cache hit rate and low hit latency in terms of mapping structure.
Gemini cache classifies data into leading blocks and following blocks, and
places them with static mapping and dynamic mapping respectively in a unified
set-associative structure. Gemini also designs a replacement policy to balance
the different blocks miss penalty and the recency, and provides strategies to
mitigate cache thrashing due to block type transitions. Experimental results
demonstrate that Gemini cache can narrow the hit latency gap with direct-mapped
cache significantly, from 1.75X to 1.22X on average, and can achieve comparable
hit rate with set-associative cache. Compared with the state-of-the-art
baselines, i.e., enhanced Loh-Hill cache, Gemini improves the IPC by up to 20%
respectively.
"
1002,"GANAX: A Unified MIMD-SIMD Acceleration for Generative Adversarial
  Networks","  Generative Adversarial Networks (GANs) are one of the most recent deep
learning models that generate synthetic data from limited genuine datasets.
GANs are on the frontier as further extension of deep learning into many
domains (e.g., medicine, robotics, content synthesis) requires massive sets of
labeled data that is generally either unavailable or prohibitively costly to
collect. Although GANs are gaining prominence in various fields, there are no
accelerators for these new models. In fact, GANs leverage a new operator,
called transposed convolution, that exposes unique challenges for hardware
acceleration. This operator first inserts zeros within the multidimensional
input, then convolves a kernel over this expanded array to add information to
the embedded zeros. Even though there is a convolution stage in this operator,
the inserted zeros lead to underutilization of the compute resources when a
conventional convolution accelerator is employed. We propose the GANAX
architecture to alleviate the sources of inefficiency associated with the
acceleration of GANs using conventional convolution accelerators, making the
first GAN accelerator design possible. We propose a reorganization of the
output computations to allocate compute rows with similar patterns of zeros to
adjacent processing engines, which also avoids inconsequential multiply-adds on
the zeros. This compulsory adjacency reclaims data reuse across these
neighboring processing engines, which had otherwise diminished due to the
inserted zeros. The reordering breaks the full SIMD execution model, which is
prominent in convolution accelerators. Therefore, we propose a unified
MIMD-SIMD design for GANAX that leverages repeated patterns in the computation
to create distinct microprograms that execute concurrently in SIMD mode.
"
1003,Hardware Transactional Persistent Memory,"  Emerging Persistent Memory technologies (also PM, Non-Volatile DIMMs, Storage
Class Memory or SCM) hold tremendous promise for accelerating popular
data-management applications like in-memory databases. However, programmers now
need to deal with ensuring the atomicity of transactions on Persistent Memory
resident data and maintaining consistency between the order in which processors
perform stores and that in which the updated values become durable.
  The problem is specially challenging when high-performance isolation
mechanisms like Hardware Transactional Memory (HTM) are used for concurrency
control. This work shows how HTM transactions can be ordered correctly and
atomically into PM by the use of a novel software protocol combined with a
Persistent Memory Controller, without requiring changes to processor cache
hardware or HTM protocols. In contrast, previous approaches require significant
changes to existing processor microarchitectures. Our approach, evaluated using
both micro-benchmarks and the STAMP suite compares well with standard
(volatile) HTM transactions. It also yields significant gains in throughput and
latency in comparison with persistent transactional locking.
"
1004,Accelerating CNN inference on FPGAs: A Survey,"  Convolutional Neural Networks (CNNs) are currently adopted to solve an ever
greater number of problems, ranging from speech recognition to image
classification and segmentation. The large amount of processing required by
CNNs calls for dedicated and tailored hardware support methods. Moreover, CNN
workloads have a streaming nature, well suited to reconfigurable hardware
architectures such as FPGAs. The amount and diversity of research on the
subject of CNN FPGA acceleration within the last 3 years demonstrates the
tremendous industrial and academic interest. This paper presents a
state-of-the-art of CNN inference accelerators over FPGAs. The computational
workloads, their parallelism and the involved memory accesses are analyzed. At
the level of neurons, optimizations of the convolutional and fully connected
layers are explained and the performances of the different methods compared. At
the network level, approximate computing and datapath optimization methods are
covered and state-of-the-art approaches compared. The methods and tools
investigated in this survey represent the recent trends in FPGA CNN inference
accelerators and will fuel the future advances on efficient hardware deep
learning.
"
1005,Set-based Obfuscation for Strong PUFs against Machine Learning Attacks,"  Strong physical unclonable function (PUF) is a promising solution for device
authentication in resourceconstrained applications but vulnerable to machine
learning attacks. In order to resist such attack, many defenses have been
proposed in recent years. However, these defenses incur high hardware overhead,
degenerate reliability and are inefficient against advanced machine learning
attacks such as approximation attacks. In order to address these issues, we
propose a Random Set-based Obfuscation (RSO) for Strong PUFs to resist machine
learning attacks. The basic idea is that several stable responses are derived
from the PUF itself and pre-stored as the set for obfuscation in the testing
phase, and then a true random number generator is used to select any two keys
to obfuscate challenges and responses with XOR operations. When the number of
challenge-response pairs (CRPs) collected by the attacker exceeds the given
threshold, the set will be updated immediately. In this way, machine learning
attacks can be prevented with extremely low hardware overhead. Experimental
results show that for a 64x64 Arbiter PUF, when the size of set is 32 and even
if 1 million CRPs are collected by attackers, the prediction accuracies of
Logistic regression, support vector machines, artificial neural network,
convolutional neural network and covariance matrix adaptive evolutionary
strategy are about 50% which is equivalent to the random guessing.
"
1006,Data-Dependent Clock Gating approach for Low Power Sequential System,"  Power dissipation in the sequential systems of modern CPU integrated chips
(CPU-IC viz., Silicon Chip) is in discussion since the last decade. Researchers
have been cultivating many low power design methods to choose the best
potential candidate for reducing both static and dynamic power of a chip.
Though, clock gating (CG) has been an accepted technique to control dynamic
power dissipation, question still loiters on its credibility to handle the
static power of the system. Therefore in this paper, we have revisited the
popular CG schemes and found out some scope of improvisation to support the
simultaneous reduction of static and dynamic power dissipation. Our proposed CG
is simulated for 90nm CMOS using Cadence Virtuoso and has been tested on a
conventional Master-Slave Flip-flop at 5GHz clock with a power supply of
1.1Volt. This assignment clearly depicts its supremacy in terms of power and
timing metrics in comparison to the implementation of existing CG schemes.
"
1007,Mitigating Wordline Crosstalk using Adaptive Trees of Counters,"  High access frequency of certain rows in the DRAM may cause data loss in
cells of physically adjacent rows due to crosstalk. The malicious exploit of
this crosstalk by repeatedly accessing a row to induce this effect is known as
row hammering. Additionally, inadvertent row hammering may also occur due to
the natural weighted nature of applications' access patterns.
  In this paper, we analyze the efficiency of existing approaches for
mitigating wordline crosstalk and demonstrate that they have been
conservatively designed. Given the unbalanced nature of DRAM accesses, a small
group of dynamically allocated counters in banks can deterministically detect
hot rows and mitigate crosstalk. Based on our findings, we propose a
Counter-based Adaptive Tree (CAT) approach to mitigate wordline crosstalk using
adaptive trees of counters to guide appropriate refreshing of vulnerable rows.
The key idea is to tune the distribution of the counters to the rows in a bank
based on the memory reference patterns. In contrast to deterministic solutions,
CAT utilizes fewer counters, making it practically feasible to be implemented
on-chip. Compared to existing probabilistic approaches, CAT more precisely
refreshes rows vulnerable to crosstalk based on their access frequency.
  Experimental results on workloads from four benchmark suites show that CAT
reduces the Crosstalk Mitigation Refresh Power Overhead in quad-core systems to
7%, which is an improvement over the 21% and 18% incurred in the leading
deterministic and probabilistic approaches, respectively. Moreover, CAT incurs
very low performance overhead (0.5%). Hardware synthesis evaluation shows that
CAT can be implemented on-chip with only a nominal area overhead.
"
1008,Static Quantized Radix-2 FFT/IFFT Processor for Constraints Analysis,"  This research work focuses on the design of a high-resolution fast Fourier
transform (FFT) /inverse fast Fourier transform (IFFT) processors for
constraints analysis purpose. Amongst the major setbacks associated with such
high resolution, FFT processors are the high power consumption resulting from
the structural complexity and computational inefficiency of floating-point
calculations. As such, a parallel pipelined architecture was proposed to
statically scale the resolution of the processor to suite adequate trade-off
constraints. The quantization was applied to provide an approximation to
address the finite word-length constraints of digital signal processing (DSP).
An optimum operating mode was proposed, based on the
signal-to-quantization-noise ratio (SQNR) as well as the statistical theory of
quantization, to minimize the tradeoff issues associated with selecting the
most application-efficient floating-point processing capability in contrast to
their resolution quality.
"
1009,VLSI Design Of Advanced Digital Filters,"  The Cascaded Integrator Comb filters (CIC) find many applications in recent
electronic devices such as frequency selection functions in a digital radio or
modem and any filter structure that is required to efficiently process large
sample rate factor. These filters are normally located after the sigma-delta
modulator and have a regular structure. These types of filters do not require
multipliers and the coefficient storage unlike in the normal digital FIR and
IIR filters because of all filter coefficients are unity. Hence, it can be
efficiently implemented to operate at high speed. Hence, this book describes
the Very Large Scale Integration (VLSI) implementation of the CIC filters that
are suitable for high-performance audio applications.
"
1010,Development of FEB Configuration Test Board for ATLAS NSW Upgrade,"  The FEB(front end board) configuration test board is developed aiming at
meeting the requirement of testing the new generation ASIC(application-specific
integrated circuit) chips and its configuration system for ATLAS NSW(New Small
Wheel) upgrade, In this paper, some functions are developed in terms of the
configurations of the key chips on the FEB, VMM3 and TDS2 using GBT-SCA.
Additionally, a flexible communication protocol is designed, verifying the
whole data link. It provides technical reference for prototype FEB key chip
configuration and data readout, as well as the final system configuration.
"
1011,"FPGA Implementation of pipeline Digit-Slicing Multiplier-Less Radix 2
  power of 2 DIF SDF Butterfly for Fourier Transform Structure","  The need for wireless communication has driven the communication systems to
high performance. However, the main bottleneck that affects the communication
capability is the Fast Fourier Transform (FFT), which is the core of most
modulators. This paper presents FPGA implementation of pipeline digit-slicing
multiplier-less radix 22 DIF (Decimation In Frequency) SDF (single path delay
feedback) butterfly for FFT structure. The approach is taken, in order to
reduce computation complexity in butterfly multiplier, the digit-slicing
multiplier-less technique was utilized in the critical path of pipeline
Radix-22 DIF SDF FFT structure. The proposed design focused on the trade-off
between the speed and active silicon area for the chip implementation. The
multiplier input data was sliced into four blocks each one with four bits to
process at the same time in parallel. The new architecture was investigated and
simulated with MATLAB software. The Verilog HDL code in Xilinx ISE environment
was derived to describe the FFT Butterfly functionality and was downloaded to
Virtex II FPGA board. Consequently, the Virtex-II FG456 Proto board was used to
implement and test the design on the real hardware. As a result, from the
findings, the synthesis report indicates the maximum clock frequency of 555.75
MHz with the total equivalent gate count of 32,146 is a marked and significant
improvement over Radix 22 DIF SDF FFT butterfly. In comparison with the
conventional butterfly architecture design which can only run at a maximum
clock frequency of 200.102 MHz and the conventional multiplier can only run at
a maximum clock frequency of 221.140 MHz, the proposed system exhibits better
results.
"
1012,"Characteristic Analysis of 1024-Point Quantized Radix-2 FFT/IFFT
  Processor","  The precise analysis and accurate measurement of harmonic provides a reliable
scientific industrial application. However, the high-performance DSP processor
is the important method of electrical harmonic analysis. Hence, in this
research work, the effort was taken to design a novel high-resolution single
1024-point fast Fourier transform (FFT) and inverse fast Fourier transform
(IFFT) processors for improvement of the harmonic measurement techniques.
Meanwhile, the project is started with design and simulation to demonstrate the
benefit that is achieved by the proposed 1024-point FFT/IFFT processor. The
pipelined structure is incorporated in order to enhance the system efficiency.
As such, a pipelined architecture was proposed to statically scale the
resolution of the processor to suite adequate trade-off constraints. The
proposed FFT makes use of programmable fixed-point/floating-point to realize
higher precision FFT.
"
1013,"Novel Architecture of Pipeline Radix 2 power of 2 SDF FFT Based on
  Digit-Slicing Technique","  The prevalent need for very high-speed digital signals processing in wireless
communications has driven the communications system to high-performance levels.
The objective of this paper is to propose a novel structure for efficient
implementation for the Fast Fourier Transform (FFT) processor to meet the
requirement for high-speed wireless communication system standards. Based on
the algorithm, architecture analysis, the design of pipeline Radix 2power of 2
SDF FFT processor based on digit-slicing Multiplier-Less is proposed.
Furthermore, this paper proposed an optimal constant multiplication arithmetic
design to multiply a fixed point input selectively by one of the several
present twiddle factor constants. The proposed architecture was simulated using
MATLAB software and the Field Programmable Gate Array (FPGA) Virtex 4 was
targeted to synthesis the proposed architecture. The design was tested in real
hardware of TLA5201 logic analyzer and the ISE synthesis report results the
high speed of 669.277 MHz with the total equivalent gate count of 14,854.
Meanwhile, It can be found as significant improvement over Radix 22 DIF SDF FFT
processor and can be concluded that the proposed pipeline Radix 22 DIF SDF FFT
processor based on digit-slicing multiplier-less is an enable in solving
problems that affect the most high-speed wireless communication systems
capability in FFT and possesses huge potentials for future related works and
research areas.
"
1014,"SafeSpec: Banishing the Spectre of a Meltdown with Leakage-Free
  Speculation","  Speculative execution which is used pervasively in modern CPUs can leave side
effects in the processor caches and other structures even when the speculated
instructions do not commit and their direct effect is not visible. The recent
Meltdown and Spectre attacks have shown that this behavior can be exploited to
expose privileged information to an unprivileged attacker. In particular, the
attack forces the speculative execution of a code gadget that will carry out
the illegal read, which eventually gets squashed, but which leaves a
side-channel trail that can be used by the attacker to infer the value. Several
attack variations are possible, allowing arbitrary exposure of the full kernel
memory to an unprivileged attacker. In this paper, we introduce a new model
(SafeSpec) for supporting speculation in a way that is immune to side-channel
leakage necessary for attacks such as Meltdown and Spectre. In particular,
SafeSpec stores side effects of speculation in a way that is not visible to the
attacker while the instructions are speculative. The speculative state is then
either committed to the main CPU structures if the branch commits, or squashed
if it does not, making all direct side effects of speculative code invisible.
The solution must also address the possibility of a covert channel from
speculative instructions to committed instructions before these instructions
are committed. We show that SafeSpec prevents all three variants of Spectre and
Meltdown, as well as new variants that we introduce. We also develop a cycle
accurate model of modified design of an x86-64 processor and show that the
performance impact is negligible. We build prototypes of the hardware support
in a hardware description language to show that the additional overhead is
small. We believe that SafeSpec completely closes this class of attacks, and
that it is practical to implement.
"
1015,RAPIDNN: In-Memory Deep Neural Network Acceleration Framework,"  Deep neural networks (DNN) have demonstrated effectiveness for various
applications such as image processing, video segmentation, and speech
recognition. Running state-of-the-art DNNs on current systems mostly relies on
either generalpurpose processors, ASIC designs, or FPGA accelerators, all of
which suffer from data movements due to the limited onchip memory and data
transfer bandwidth. In this work, we propose a novel framework, called RAPIDNN,
which processes all DNN operations within the memory to minimize the cost of
data movement. To enable in-memory processing, RAPIDNN reinterprets a DNN model
and maps it into a specialized accelerator, which is designed using
non-volatile memory blocks that model four fundamental DNN operations, i.e.,
multiplication, addition, activation functions, and pooling. The framework
extracts representative operands of a DNN model, e.g., weights and input
values, using clustering methods to optimize the model for in-memory
processing. Then, it maps the extracted operands and their precomputed results
into the accelerator memory blocks. At runtime, the accelerator identifies
computation results based on efficient in-memory search capability which also
provides tunability of approximation to further improve computation efficiency.
Our evaluation shows that RAPIDNN achieves 68.4x, 49.5x energy efficiency
improvement and 48.1x, 10.9x speedup as compared to ISAAC and PipeLayer, the
state-of-the-art DNN accelerators, while ensuring less than 0.3% of quality
loss.
"
1016,"A 1.2-V 162.9-pJ/cycle Bitmap Index Creation Core with 0.31-pW/bit
  Standby Power on 65-nm SOTB","  The ability to maximize the performance during peak workload hours and
minimize the power consumption during off-peak time plays a significant role in
the energy-efficient systems. Our previous work has proposed a high-performance
multi-core bitmap index creator (BIC) in a field-programmable gate array that
could deliver higher indexing throughput than central processing units and
graphics processing units. This brief extends the previous study by focusing on
the application-specific integrated circuit implementation of the proposed BIC
in a 65-nm silicon-on-thin-buried-oxide (SOTB) CMOS process. The BIC chip can
operate with different supply voltage from 0.4 V to 1.2 V. In the active mode
with the supply voltage of 1.2 V, the BIC chip is fully operational at 41 MHz
and consumes 162.9 pJ/cycle. In the standby mode with the supply voltage of 0.4
V and clock-gating technique, the power consumption was reduced to 10.6 uW. The
standby power is also dramatically reduced to 2.64 nW due to the utilization of
reverse back-gate biasing technique. This achievement is considerable
importance to the energy-efficient systems.
"
1017,"LazyFP: Leaking FPU Register State using Microarchitectural
  Side-Channels","  Modern processors utilize an increasingly large register set to facilitate
efficient floating point and SIMD computation. This large register set is a
burden for operating systems, as its content needs to be saved and restored
when the operating system context switches between tasks. As an optimization,
the operating system can defer the context switch of the FPU and SIMD register
set until the first instruction is executed that needs access to these
registers. Meanwhile, the old content is left in place with the hope that the
current task might not use these registers at all. This optimization is
commonly called lazy FPU context switching. To make it possible, a processor
offers the ability to toggle the availability of instructions utilizing
floating point and SIMD registers. If the instructions are turned off, any
attempt of executing them will generate a fault.
  In this paper, we present an attack that exploits lazy FPU context switching
and allows an adversary to recover the FPU and SIMD register set of arbitrary
processes or VMs. The attack works on processors that transiently execute FPU
or SIMD instructions that follow an instruction generating the fault indicating
the first use of FPU or SIMD instructions. On operating systems using lazy FPU
context switching, the FPU and SIMD register content of other processes or
virtual machines can then be reconstructed via cache side effects.
  With SIMD registers not only being used for cryptographic computation, but
also increasingly for simple operations, such as copying memory, we argue that
lazy FPU context switching is a dangerous optimization that needs to be turned
off in all operating systems, if there is a chance that they run on affected
processors.
"
1018,"Generic and Universal Parallel Matrix Summation with a Flexible
  Compression Goal for Xilinx FPGAs","  Bit matrix compression is a highly relevant operation in computer arithmetic.
Essentially being a multi-operand addition, it is the key operation behind fast
multiplication and many higher-level operations such as multiply-accumulate,
the computation of the dot product or the implementation of FIR filters.
Compressor implementations have been constantly evolving for greater efficiency
both in general and in the context of concrete applications or specific
implementation technologies. This paper is building on this history and
describes a generic implementation of a bit matrix compressor for Xilinx FPGAs,
which does not require a generator tool. It contributes FPGA-oriented metrics
for the evaluation of elementary parallel bit counters, a systematic analysis
and partial decomposition of previously proposed counters and a fully
implemented construction heuristic with a flexible compression target matching
the device capabilities. The generic implementation is agnostic of the aspect
ratio of the input matrix and can be used for multiplication the same way as it
can be for single-column population count operations.
"
1019,"BISMO: A Scalable Bit-Serial Matrix Multiplication Overlay for
  Reconfigurable Computing","  Matrix-matrix multiplication is a key computational kernel for numerous
applications in science and engineering, with ample parallelism and data
locality that lends itself well to high-performance implementations. Many
matrix multiplication-dependent applications can use reduced-precision integer
or fixed-point representations to increase their performance and energy
efficiency while still offering adequate quality of results. However, precision
requirements may vary between different application phases or depend on input
data, rendering constant-precision solutions ineffective. We present BISMO, a
vectorized bit-serial matrix multiplication overlay for reconfigurable
computing. BISMO utilizes the excellent binary-operation performance of FPGAs
to offer a matrix multiplication performance that scales with required
precision and parallelism. We characterize the resource usage and performance
of BISMO across a range of parameters to build a hardware cost model, and
demonstrate a peak performance of 6.5 TOPS on the Xilinx PYNQ-Z1 board.
"
1020,"On the Resilience of RTL NN Accelerators: Fault Characterization and
  Mitigation","  Machine Learning (ML) is making a strong resurgence in tune with the massive
generation of unstructured data which in turn requires massive computational
resources. Due to the inherently compute- and power-intensive structure of
Neural Networks (NNs), hardware accelerators emerge as a promising solution.
However, with technology node scaling below 10nm, hardware accelerators become
more susceptible to faults, which in turn can impact the NN accuracy. In this
paper, we study the resilience aspects of Register-Transfer Level (RTL) model
of NN accelerators, in particular, fault characterization and mitigation. By
following a High-Level Synthesis (HLS) approach, first, we characterize the
vulnerability of various components of RTL NN. We observed that the severity of
faults depends on both i) application-level specifications, i.e., NN data
(inputs, weights, or intermediate), NN layers, and NN activation functions, and
ii) architectural-level specifications, i.e., data representation model and the
parallelism degree of the underlying accelerator. Second, motivated by
characterization results, we present a low-overhead fault mitigation technique
that can efficiently correct bit flips, by 47.3% better than state-of-the-art
methods.
"
1021,"A Low-Latency List Successive-Cancellation Decoding Implementation for
  Polar Codes","  Due to their provably capacity-achieving performance, polar codes have
attracted a lot of research interest recently. For a good error-correcting
performance, list successive-cancellation decoding (LSCD) with large list size
is used to decode polar codes. However, as the complexity and delay of the list
management operation rapidly increase with the list size, the overall latency
of LSCD becomes large and limits the applicability of polar codes in
high-throughput and latency-sensitive applications. Therefore, in this work,
the low-latency implementation for LSCD with large list size is studied.
Specifically, at the system level, a selective expansion method is proposed
such that some of the reliable bits are not expanded to reduce the computation
and latency. At the algorithmic level, a double thresholding scheme is proposed
as a fast approximate-sorting method for the list management operation to
reduce the LSCD latency for large list size. A VLSI architecture of the LSCD
implementing the selective expansion and double thresholding scheme is then
developed, and implemented using a UMC 90 nm CMOS technology. Experimental
results show that, even for a large list size of 16, the proposed LSCD achieves
a decoding throughput of 460 Mbps at a clock frequency of 658 MHz.
"
1022,"Exploration of Low Numeric Precision Deep Learning Inference Using Intel
  FPGAs","  CNNs have been shown to maintain reasonable classification accuracy when
quantized to lower precisions. Quantizing to sub 8-bit activations and weights
can result in accuracy falling below an acceptable threshold. Techniques exist
for closing the accuracy gap of limited numeric precision typically by
increasing computation. This results in a trade-off between throughput and
accuracy and can be tailored for different networks through various
combinations of activation and weight data widths. Hardware architectures like
FPGAs provide the opportunity for data width specific computation through
unique logic configurations leading to highly optimized processing that is
unattainable by full precision networks. Ternary and binary weighted networks
offer an efficient method of inference for 2-bit and 1-bit data respectively.
Most hardware architectures can take advantage of the memory storage and
bandwidth savings that come along with smaller datapaths, but very few
architectures can take advantage of limited numeric precision at the
computation level. In this paper, we present a hardware design for FPGAs that
takes advantage of bandwidth, memory, power, and computation savings of limited
numerical precision data. We provide insights into the trade-offs between
throughput and accuracy for various networks and how they map to our framework.
Further, we show how limited numeric precision computation can be efficiently
mapped onto FPGAs for both ternary and binary cases. Starting with Arria 10, we
show a 2-bit activation and ternary weighted AlexNet running in hardware that
achieves 3,700 images per second on the ImageNet dataset with a top-1 accuracy
of 0.49. Using a hardware modeler designed for our low numeric precision
framework we project performance most notably for a 55.5 TOPS Stratix 10 device
running a modified ResNet-34 with only 3.7% accuracy degradation compared with
single precision.
"
1023,High-Performance Parallel Implementation of Genetic Algorithm on FPGA,"  Genetic Algorithms (GAs) are used to solve search and optimization problems
in which an optimal solution can be found using an iterative process with
probabilistic and non-deterministic transitions. However, depending on the
problem's nature, the time required to find a solution can be high in
sequential machines due to the computational complexity of genetic algorithms.
This work proposes a parallel implementation of a genetic algorithm on
field-programmable gate array (FPGA). Optimization of the system's processing
time is the main goal of this project. Results associated with the processing
time and area occupancy (on FPGA) for various population sizes are analyzed.
Studies concerning the accuracy of the GA response for the optimization of two
variables functions were also evaluated for the hardware implementation.
However, the high-performance implementation proposes in this paper is able to
work with more variable from some adjustments on hardware architecture.
"
1024,"The Challenge of Multi-Operand Adders in CNNs on FPGAs: How not to solve
  it!","  Convolutional Neural Networks (CNNs) are computationally intensive algorithms
that currently require dedicated hardware to be executed. In the case of
FPGA-Based accelerators, we point-out in this work the challenge of
Multi-Operand Adders (MOAs) and their high resource utilization in an FPGA
implementation of a CNN. To address this challenge, two optimization
strategies, that rely on time-multiplexing and approximate computing, are
investigated. At first glance, the two strategies looked promising to reduce
the footprint of a given architectural mapping, but when synthesized on the
device, none of them gave the expected results. Experimental sections analyze
the reasons of these unexpected results.
"
1025,"FATE: Fast and Accurate Timing Error Prediction Framework for Low Power
  DNN Accelerator Design","  Deep neural networks (DNN) are increasingly being accelerated on
application-specific hardware such as the Google TPU designed especially for
deep learning. Timing speculation is a promising approach to further increase
the energy efficiency of DNN accelerators. Architectural exploration for timing
speculation requires detailed gate-level timing simulations that can be
time-consuming for large DNNs that execute millions of multiply-and-accumulate
(MAC) operations. In this paper we propose FATE, a new methodology for fast and
accurate timing simulations of DNN accelerators like the Google TPU. FATE
proposes two novel ideas: (i) DelayNet, a DNN based timing model for MAC units;
and (ii) a statistical sampling methodology that reduces the number of MAC
operations for which timing simulations are performed. We show that FATE
results in between 8 times-58 times speed-up in timing simulations, while
introducing less than 2% error in classification accuracy estimates. We
demonstrate the use of FATE by comparing to conventional DNN accelerator that
uses 2's complement (2C) arithmetic with an alternative implementation that
uses signed magnitude representations (SMR). We show that that the SMR
implementation provides 18% more energy savings for the same classification
accuracy than 2C, a result that might be of independent interest.
"
1026,Neuro-memristive Circuits for Edge Computing: A review,"  The volume, veracity, variability, and velocity of data produced from the
ever-increasing network of sensors connected to Internet pose challenges for
power management, scalability, and sustainability of cloud computing
infrastructure. Increasing the data processing capability of edge computing
devices at lower power requirements can reduce several overheads for cloud
computing solutions. This paper provides the review of neuromorphic
CMOS-memristive architectures that can be integrated into edge computing
devices. We discuss why the neuromorphic architectures are useful for edge
devices and show the advantages, drawbacks and open problems in the field of
neuro-memristive circuits for edge computing.
"
1027,Best-Effort FPGA Programming: A Few Steps Can Go a Long Way,"  FPGA-based heterogeneous architectures provide programmers with the ability
to customize their hardware accelerators for flexible acceleration of many
workloads. Nonetheless, such advantages come at the cost of sacrificing
programmability. FPGA vendors and researchers attempt to improve the
programmability through high-level synthesis (HLS) technologies that can
directly generate hardware circuits from high-level language descriptions.
However, reading through recent publications on FPGA designs using HLS, one
often gets the impression that FPGA programming is still hard in that it leaves
programmers to explore a very large design space with many possible
combinations of HLS optimization strategies.
  In this paper we make two important observations and contributions. First, we
demonstrate a rather surprising result: FPGA programming can be made easy by
following a simple best-effort guideline of five refinement steps using HLS. We
show that for a broad class of accelerator benchmarks from MachSuite, the
proposed best-effort guideline improves the FPGA accelerator performance by
42-29,030x. Compared to the baseline CPU performance, the FPGA accelerator
performance is improved from an average 292.5x slowdown to an average 34.4x
speedup. Moreover, we show that the refinement steps in the best-effort
guideline, consisting of explicit data caching, customized pipelining,
processing element duplication, computation/communication overlapping and
scratchpad reorganization, correspond well to the best practice guidelines for
multicore CPU programming. Although our best-effort guideline may not always
lead to the optimal solution, it substantially simplifies the FPGA programming
effort, and will greatly support the wide adoption of FPGA-based acceleration
by the software programming community.
"
1028,"Crosstalk based Fine-Grained Reconfiguration Techniques for Polymorphic
  Circuits","  Truly polymorphic circuits, whose functionality/circuit behavior can be
altered using a control variable, can provide tremendous benefits in
multi-functional system design and resource sharing. For secure and fault
tolerant hardware designs these can be crucial as well. Polymorphic circuits
work in literature so far either rely on environmental parameters such as
temperature, variation etc. or on special devices such as ambipolar FET,
configurable magnetic devices, etc., that often result in inefficiencies in
performance and/or realization. In this paper, we introduce a novel polymorphic
circuit design approach where deterministic interference between nano-metal
lines is leveraged for logic computing and configuration. For computing, the
proposed approach relies on nano-metal lines, their interference and commonly
used FETs, and for polymorphism, it requires only an extra metal line that
carries the control signal. In this paper, we show a wide range of crosstalk
polymorphic (CT-P) logic gates and their evaluation results. We also show an
example of a large circuit that performs both the functionalities of multiplier
and sorter depending on the configuration signal. Our benchmarking results are
presented in this paper. For CT-P, the transistor count was found to be
significantly less compared to other existing approaches, ranging from 25% to
83%. For example, CT-P AOI21-OA21 cell show 83%, 85% and 50% transistor count
reduction, and MultiplierSorter circuit show 40%, 36% and 28% transistor count
reduction with respect to CMOS, genetically evolved, and ambipolar transistor
based polymorphic circuits respectively.
"
1029,A New Paradigm for Fault-Tolerant Computing with Interconnect Crosstalks,"  The CMOS integrated chips at advanced technology nodes are becoming more
vulnerable to various sources of faults like manufacturing imprecisions,
variations, aging, etc. Additionally, the intentional fault attacks (e.g., high
power microwave, cybersecurity threats, etc.) and environmental effects (i.e.,
radiation) also pose reliability threats to integrated circuits. Though the
traditional hardware redundancy-based techniques like Triple Modular Redundancy
(TMR), Quadded (QL) Logic etc. mitigate the risk to some extent, they add huge
hardware overhead and are not very effective. Truly polymorphic circuits that
are inherently capable of achieving multiple functionalities in a limited
footprint could enhance the faultresilience/recovery of the circuits with
limited overhead. We demonstrate a novel crosstalk logic based polymorphic
circuit approach to achieve compact and efficient fault resilient circuits. We
show a range of polymorphic primitive gates and their usage in a functional
unit. The functional unit is a single arithmetic circuit that is capable of
delivering Multiplication/Sorting/Addition output depending on the control
inputs. Using such polymorphic computing units in an ALU would imply that a
correct path for functional output is possible even when 2/3rd of the ALU is
damaged. Our comparison results with respect to existing polymorphic techniques
and CMOS reveal 28% and 62% reduction in transistor count respectively for the
same functionalities. In conjunction with fault detection algorithms, the
proposed polymorphic circuit concept can be transformative for fault tolerant
circuit design directions with minimum overhead.
"
1030,"XNOR Neural Engine: a Hardware Accelerator IP for 21.6 fJ/op Binary
  Neural Network Inference","  Binary Neural Networks (BNNs) are promising to deliver accuracy comparable to
conventional deep neural networks at a fraction of the cost in terms of memory
and energy. In this paper, we introduce the XNOR Neural Engine (XNE), a fully
digital configurable hardware accelerator IP for BNNs, integrated within a
microcontroller unit (MCU) equipped with an autonomous I/O subsystem and hybrid
SRAM / standard cell memory. The XNE is able to fully compute convolutional and
dense layers in autonomy or in cooperation with the core in the MCU to realize
more complex behaviors. We show post-synthesis results in 65nm and 22nm
technology for the XNE IP and post-layout results in 22nm for the full MCU
indicating that this system can drop the energy cost per binary operation to
21.6fJ per operation at 0.4V, and at the same time is flexible and performant
enough to execute state-of-the-art BNN topologies such as ResNet-34 in less
than 2.2mJ per frame at 8.9 fps.
"
1031,"Medusa: A Scalable Interconnect for Many-Port DNN Accelerators and Wide
  DRAM Controller Interfaces","  To cope with the increasing demand and computational intensity of deep neural
networks (DNNs), industry and academia have turned to accelerator technologies.
In particular, FPGAs have been shown to provide a good balance between
performance and energy efficiency for accelerating DNNs. While significant
research has focused on how to build efficient layer processors, the
computational building blocks of DNN accelerators, relatively little attention
has been paid to the on-chip interconnects that sit between the layer
processors and the FPGA's DRAM controller.
  We observe a disparity between DNN accelerator interfaces, which tend to
comprise many narrow ports, and FPGA DRAM controller interfaces, which tend to
be wide buses. This mismatch causes traditional interconnects to consume
significant FPGA resources. To address this problem, we designed Medusa: an
optimized FPGA memory interconnect which transposes data in the interconnect
fabric, tailoring the interconnect to the needs of DNN layer processors.
Compared to a traditional FPGA interconnect, our design can reduce LUT and FF
use by 4.7x and 6.0x, and improves frequency by 1.8x.
"
1032,"FINN-L: Library Extensions and Design Trade-off Analysis for Variable
  Precision LSTM Networks on FPGAs","  It is well known that many types of artificial neural networks, including
recurrent networks, can achieve a high classification accuracy even with
low-precision weights and activations. The reduction in precision generally
yields much more efficient hardware implementations in regards to hardware
cost, memory requirements, energy, and achievable throughput. In this paper, we
present the first systematic exploration of this design space as a function of
precision for Bidirectional Long Short-Term Memory (BiLSTM) neural network.
Specifically, we include an in-depth investigation of precision vs. accuracy
using a fully hardware-aware training flow, where during training quantization
of all aspects of the network including weights, input, output and in-memory
cell activations are taken into consideration. In addition, hardware resource
cost, power consumption and throughput scalability are explored as a function
of precision for FPGA-based implementations of BiLSTM, and multiple approaches
of parallelizing the hardware. We provide the first open source HLS library
extension of FINN for parameterizable hardware architectures of LSTM layers on
FPGAs which offers full precision flexibility and allows for parameterizable
performance scaling offering different levels of parallelism within the
architecture. Based on this library, we present an FPGA-based accelerator for
BiLSTM neural network designed for optical character recognition, along with
numerous other experimental proof points for a Zynq UltraScale+ XCZU7EV MPSoC
within the given design space.
"
1033,"What Your DRAM Power Models Are Not Telling You: Lessons from a Detailed
  Experimental Study","  Main memory (DRAM) consumes as much as half of the total system power in a
computer today, resulting in a growing need to develop new DRAM architectures
and systems that consume less power. Researchers have long relied on DRAM power
models that are based off of standardized current measurements provided by
vendors, called IDD values. Unfortunately, we find that these models are highly
inaccurate, and do not reflect the actual power consumed by real DRAM devices.
  We perform the first comprehensive experimental characterization of the power
consumed by modern real-world DRAM modules. Our extensive characterization of
50 DDR3L DRAM modules from three major vendors yields four key new observations
about DRAM power consumption: (1) across all IDD values that we measure, the
current consumed by real DRAM modules varies significantly from the current
specified by the vendors; (2) DRAM power consumption strongly depends on the
data value that is read or written; (3) there is significant structural
variation, where the same banks and rows across multiple DRAM modules from the
same model consume more power than other banks or rows; and (4) over successive
process technology generations, DRAM power consumption has not decreased by as
much as vendor specifications have indicated.
  Based on our detailed analysis and characterization data, we develop the
Variation-Aware model of Memory Power Informed by Real Experiments (VAMPIRE).
We show that VAMPIRE has a mean absolute percentage error of only 6.8% compared
to actual measured DRAM power. VAMPIRE enables a wide range of studies that
were not possible using prior DRAM power models. As an example, we use VAMPIRE
to evaluate a new power-aware data encoding mechanism, which can reduce DRAM
energy consumption by an average of 12.2%. We plan to open-source both VAMPIRE
and our extensive raw data collected during our experimental characterization.
"
1034,"Improving 3D NAND Flash Memory Lifetime by Tolerating Early Retention
  Loss and Process Variation","  Compared to planar (i.e., two-dimensional) NAND flash memory, 3D NAND flash
memory uses a new flash cell design, and vertically stacks dozens of silicon
layers in a single chip. This allows 3D NAND flash memory to increase storage
density using a much less aggressive manufacturing process technology than
planar NAND flash memory. The circuit-level and structural changes in 3D NAND
flash memory significantly alter how different error sources affect the
reliability of the memory.
  In this paper, through experimental characterization of real,
state-of-the-art 3D NAND flash memory chips, we find that 3D NAND flash memory
exhibits three new error sources that were not previously observed in planar
NAND flash memory: (1) layer-to-layer process variation, where the average
error rate of each 3D-stacked layer in a chip is significantly different; (2)
early retention loss, a new phenomenon where the number of errors due to charge
leakage increases quickly within several hours after programming; and (3)
retention interference, a new phenomenon where the rate at which charge leaks
from a flash cell is dependent on the data value stored in the neighboring
cell.
  Based on our experimental results, we develop new analytical models of
layer-to-layer process variation and retention loss in 3D NAND flash memory.
Motivated by our new findings and models, we develop four new techniques to
mitigate process variation and early retention loss in 3D NAND flash memory.
These four techniques are complementary, and can be combined together to
significantly improve flash memory reliability. Compared to a state-of-the-art
baseline, our techniques, when combined, improve flash memory lifetime by
1.85x. Alternatively, if a NAND flash vendor wants to keep the lifetime of the
3D NAND flash memory device constant, our techniques reduce the storage
overhead required to hold error correction information by 78.9%.
"
1035,"Deriving AOC C-Models from D&V Languages for Single- or Multi-Threaded
  Execution Using C or C++","  The C language is getting more and more popular as a design and verification
language (DVL). SystemC, ParC [1] and Cx [2] are based on C. C-models of the
design and verification environment can also be generated from new DVLs (e.g.
Chisel [3]) or classical DVLs such as VHDL or Verilog. The execution of these
models is usually license free and presumably faster than their alternative
counterparts (simulators). This paper proposes activity-dependent, ordered,
cycle-accurate (AOC) C-models to speed up simulation time. It compares the
results with alternative concepts. The paper also examines the execution of the
AOC C-model on a multithreaded processor environment.
"
1036,Timing Driven C-Slow Retiming on RTL for MultiCores on FPGAs,"  In this paper C-Slow Retiming (CSR) on RTL is discussed. CSR multiplies the
functionality of cores by adding the same number of registers into each path.
The technique is ideal for FPGAs with their already existing registers.
Previously publications are limited to adding registers on netlist level, which
generates a lot of system verification problems and which is assumed to be the
major drawback to use this technology in the modern multicore times. The paper
shows how CSR can efficiently be done with timing driven automatic RTL
modification. The methodology provided with this paper can be used as guidance
for using CSR in high level synthesis (HLS). The paper shows the results of a
CSR-ed complex RISC core on RTL implemented on FPGAs.
"
1037,A Lyra2 FPGA Core for Lyra2REv2-Based Cryptocurrencies,"  Lyra2REv2 is a hashing algorithm that consists of a chain of individual
hashing algorithms and it is used as a proof-of-work function in several
cryptocurrencies that aim to be ASIC-resistant. The most crucial hashing
algorithm in the Lyra2REv2 chain is a specific instance of the general Lyra2
algorithm. In this work we present the first FPGA implementation of the
aforementioned instance of Lyra2 and we explain how several properties of the
algorithm can be exploited in order to optimize the design.
"
1038,DLA: Compiler and FPGA Overlay for Neural Network Inference Acceleration,"  Overlays have shown significant promise for field-programmable gate-arrays
(FPGAs) as they allow for fast development cycles and remove many of the
challenges of the traditional FPGA hardware design flow. However, this often
comes with a significant performance burden resulting in very little adoption
of overlays for practical applications. In this paper, we tailor an overlay to
a specific application domain, and we show how we maintain its full
programmability without paying for the performance overhead traditionally
associated with overlays. Specifically, we introduce an overlay targeted for
deep neural network inference with only ~1% overhead to support the control and
reprogramming logic using a lightweight very-long instruction word (VLIW)
network. Additionally, we implement a sophisticated domain specific graph
compiler that compiles deep learning languages such as Caffe or Tensorflow to
easily target our overlay. We show how our graph compiler performs
architecture-driven software optimizations to significantly boost performance
of both convolutional and recurrent neural networks (CNNs/RNNs) - we
demonstrate a 3x improvement on ResNet-101 and a 12x improvement for long
short-term memory (LSTM) cells, compared to naive implementations. Finally, we
describe how we can tailor our hardware overlay, and use our graph compiler to
achieve ~900 fps on GoogLeNet on an Intel Arria 10 1150 - the fastest ever
reported on comparable FPGAs.
"
1039,"Cross-layer Optimization for High Speed Adders: A Pareto Driven Machine
  Learning Approach","  In spite of maturity to the modern electronic design automation (EDA) tools,
optimized designs at architectural stage may become sub-optimal after going
through physical design flow. Adder design has been such a long studied
fundamental problem in VLSI industry yet designers cannot achieve optimal
solutions by running EDA tools on the set of available prefix adder
architectures. In this paper, we enhance a state-of-the-art prefix adder
synthesis algorithm to obtain a much wider solution space in architectural
domain. On top of that, a machine learning-based design space exploration
methodology is applied to predict the Pareto frontier of the adders in physical
domain, which is infeasible by exhaustively running EDA tools for innumerable
architectural solutions. Considering the high cost of obtaining the true values
for learning, an active learning algorithm is utilized to select the
representative data during learning process, which uses less labeled data while
achieving better quality of Pareto frontier. Experimental results demonstrate
that our framework can achieve Pareto frontier of high quality over a wide
design space, bridging the gap between architectural and physical designs.
"
1040,"CRAM: Efficient Hardware-Based Memory Compression for Bandwidth
  Enhancement","  This paper investigates hardware-based memory compression designs to increase
the memory bandwidth. When lines are compressible, the hardware can store
multiple lines in a single memory location, and retrieve all these lines in a
single access, thereby increasing the effective memory bandwidth. However,
relocating and packing multiple lines together depending on the compressibility
causes a line to have multiple possible locations. Therefore, memory
compression designs typically require metadata to specify the compressibility
of the line. Unfortunately, even in the presence of dedicated metadata caches,
maintaining and accessing this metadata incurs significant bandwidth overheads
and can degrade performance by as much as 40%. Ideally, we want to implement
memory compression while eliminating the bandwidth overheads of metadata
accesses.
  This paper proposes CRAM, a bandwidth-efficient design for memory compression
that is entirely hardware based and does not require any OS support or changes
to the memory modules or interfaces. CRAM uses a novel implicit-metadata
mechanism, whereby the compressibility of the line can be determined by
scanning the line for a special marker word, eliminating the overheads of
metadata access. CRAM is equipped with a low-cost Line Location Predictor (LLP)
that can determine the location of the line with 98% accuracy. Furthermore, we
also develop a scheme that can dynamically enable or disable compression based
on the bandwidth cost of storing compressed lines and the bandwidth benefits of
obtaining compressed lines, ensuring no degradation for workloads that do not
benefit from compression. Our evaluations, over a diverse set of 27 workloads,
show that CRAM provides a speedup of up to 73% (average 6%) without causing
slowdown for any of the workloads, and consuming a storage overhead of less
than 300 bytes at the memory controller.
"
1041,"Using Multi-Core HW/SW Co-design Architecture for Accelerating K-means
  Clustering Algorithm","  The capability of classifying and clustering a desired set of data is an
essential part of building knowledge from data. However, as the size and
dimensionality of input data increases, the run-time for such clustering
algorithms is expected to grow superlinearly, making it a big challenge when
dealing with BigData. K-mean clustering is an essential tool for many big data
applications including data mining, predictive analysis, forecasting studies,
and machine learning. However, due to large size (volume) of Big-Data, and
large dimensionality of its data points, even the application of a simple
k-mean clustering may become extremely time and resource demanding. Specially
when it is necessary to have a fast and modular dataset analysis flow. In this
paper, we demonstrate that using a two-level filtering algorithm based on
binary kd-tree structure is able to decrease the time of convergence in K-means
algorithm for large datasets. The two-level filtering algorithm based on binary
kd-tree structure evolves the SW to naturally divide the classification into
smaller data sets, based on the number of available cores and size of logic
available in a target FPGA. The empirical result on this two-level structure
over multi-core FPGA-based architecture provides 330X speed-up compared to a
conventional software-only solution.
"
1042,"Rendering Elimination: Early Discard of Redundant Tiles in the Graphics
  Pipeline","  GPUs are one of the most energy-consuming components for real-time rendering
applications, since a large number of fragment shading computations and memory
accesses are involved. Main memory bandwidth is especially taxing
battery-operated devices such as smartphones. Tile-Based Rendering GPUs divide
the screen space into multiple tiles that are independently rendered in on-chip
buffers, thus reducing memory bandwidth and energy consumption. We have
observed that, in many animated graphics workloads, a large number of screen
tiles have the same color across adjacent frames. In this paper, we propose
Rendering Elimination (RE), a novel micro-architectural technique that
accurately determines if a tile will be identical to the same tile in the
preceding frame before rasterization by means of comparing signatures. Since RE
identifies redundant tiles early in the graphics pipeline, it completely avoids
the computation and memory accesses of the most power consuming stages of the
pipeline, which substantially reduces the execution time and the energy
consumption of the GPU. For widely used Android applications, we show that RE
achieves an average speedup of 1.74x and energy reduction of 43% for the
GPU/Memory system, surpassing by far the benefits of Transaction Elimination, a
state-of-the-art memory bandwidth reduction technique available in some
commercial Tile-Based Rendering GPUs.
"
1043,"Asynchronous Ripple Carry Adder based on Area Optimized Early Output
  Dual-Bit Full Adder","  This technical note presents the design of a new area optimized asynchronous
early output dual-bit full adder (DBFA). An asynchronous ripple carry adder
(RCA) is constructed based on the new asynchronous DBFAs and existing
asynchronous early output single-bit full adders (SBFAs). The asynchronous
DBFAs and SBFAs incorporate redundant logic and are encoded using the
delay-insensitive dual-rail code (i.e. homogeneous data encoding) and follow a
4-phase return-to-zero handshaking. Compared to the previous asynchronous RCAs
involving DBFAs and SBFAs, which are based on homogeneous or heterogeneous
delay-insensitive data encodings and which correspond to different timing
models, the early output asynchronous RCA incorporating the proposed DBFAs
and/or SBFAs is found to result in reduced area for the dual-operand addition
operation and feature significantly less latency than the asynchronous RCAs
which consist of only SBFAs. The proposed asynchronous DBFA requires 28.6% less
silicon than the previously reported asynchronous DBFA. For a 32-bit
asynchronous RCA, utilizing 2 stages of SBFAs in the least significant
positions and 15 stages of DBFAs in the more significant positions leads to
optimization in the latency. The new early output 32-bit asynchronous RCA
containing DBFAs and SBFAs reports the following optimizations in design
metrics over its counterparts: i) 18.8% reduction in area than a previously
reported 32-bit early output asynchronous RCA which also has 15 stages of DBFAs
and 2 stages of SBFAs, ii) 29.4% reduction in latency than a 32-bit early
output asynchronous RCA containing only SBFAs.
"
1044,"VLSI Implementation of Novel Class of High Speed Pipelined Digital
  Signal Processing Filter for Wireless Receivers","  The need for a high-performance transceiver with high Signal to Noise Ratio
(SNR) has driven the communication system to utilize the latest technique
identified as oversampling systems. It was the most economical modulator and
decimation in the communication system. It has been proven to increase the SNR
and is used in many high-performance systems such as in the Analog to Digital
Converter (ADC) for wireless transceiver. This research work presented the
design of the novel class of decimation and it's VLSI implementation which was
the sub-component in the oversampling technique. The design and realization of
the main unit of decimation stage that was the Cascaded Integrator Comb (CIC)
filter, the associated half-band filters, and the droop correction are also
designed. The Verilog HDL code in Xilinx ISE environment has been derived to
describe the proposed advanced CIC filter properties. Consequently, Virtex-II
FPGA board was used to implement and test the design on the real hardware. The
ASIC design implementation was performed accordingly and resulted in power and
area measurement on-chip core layout. The proposed design focused on the
trade-off between the high speed and the low power consumption as well as the
silicon area and high resolution for the chip implementation which satisfies
wireless communication systems. The synthesis report illustrates the maximum
clock frequency of 332 MHz with the active core area of 0.308 x 0.308 mm2. It
can be concluded that VLSI implementation of proposed filter architecture is an
enabler in solving problems that affect communication capability in DSP
application.
"
1045,"FPGA-Based CNN Inference Accelerator Synthesized from Multi-Threaded C
  Software","  A deep-learning inference accelerator is synthesized from a C-language
software program parallelized with Pthreads. The software implementation uses
the well-known producer/consumer model with parallel threads interconnected by
FIFO queues. The LegUp high-level synthesis (HLS) tool synthesizes threads into
parallel FPGA hardware, translating software parallelism into spatial
parallelism. A complete system is generated where convolution, pooling and
padding are realized in the synthesized accelerator, with remaining tasks
executing on an embedded ARM processor. The accelerator incorporates reduced
precision, and a novel approach for zero-weight-skipping in convolution. On a
mid-sized Intel Arria 10 SoC FPGA, peak performance on VGG-16 is 138 effective
GOPS.
"
1046,Delay Monitor Circuit for Sensitive Nodes in SRAM-Based FPGA,"  This paper presents a novel monitor circuit architecture and experiments
performed for detection of extra combinational delays in a high frequency
SRAM-Based FPGA on delay sensitive nodes due to transient ionizing radiation.
"
1047,Standard Cell Library Design and Optimization Methodology for ASAP7 PDK,"  Standard cell libraries are the foundation for the entire backend design and
optimization flow in modern application-specific integrated circuit designs. At
7nm technology node and beyond, standard cell library design and optimization
is becoming increasingly difficult due to extremely complex design constraints,
as described in the ASAP7 process design kit (PDK). Notable complexities
include discrete transistor sizing due to FinFETs, complicated design rules
from lithography and restrictive layout space from modern standard cell
architectures. The design methodology presented in this paper enables efficient
and high-quality standard cell library design and optimization with the ASAP7
PDK. The key techniques include exhaustive transistor sizing for cell timing
optimization, transistor placement with generalized Euler paths and back-end
design prototyping for library-level explorations.
"
1048,The BaseJump Manycore Accelerator Network,"  The BaseJump Manycore Accelerator-Network is an open source mesh-based
On-Chip-Network which is designed leveraging the Bespoke Silicon Group's 20+
years of experience in designing manycore architectures. It has been used in
the 16nm 511-core RISC-V compatible Celerity chip Davidson et al. (2018),
forming the basis of both a 1 GHz 496-core RISC-V manycore and a 10-core
always-on low voltage complex. It was also used in the 180nm BSG Ten chip,
which featured ten cores and a mesh that extends over off-chip links to an
FPGA. To facilitate use by the open source community of the BaseJump Manycore
network, we explain the ideas, protocols, interfaces and potential uses of the
mesh network. We also show an example with source code that demonstrates how to
integrate user designs into the mesh network.
"
1049,"Energy-Efficiency Prediction of Multithreaded Workloads on Heterogeneous
  Composite Cores Architectures using Machine Learning Techniques","  Heterogeneous architectures have emerged as a promising alternative for
homogeneous architectures to improve the energy-efficiency of computer systems.
Composite Cores Architecture (CCA), a class of dynamic heterogeneous
architectures enabling the computer system to construct the right core at
run-time for each application by composing cores together to build larger core
or decomposing a large core into multiple smaller cores. While this
architecture provides more flexibility for the running application to find the
best run-time settings to maximize energy-efficiency, due to the
interdependence of various tuning parameters such as the type of the core,
run-time voltage and frequency and the number of threads, it makes it more
challenging for scheduling. Prior studies mainly addressed the scheduling
problem in CCAs by looking at one or two of these tuning parameters. However,
as we will show in this paper, it is important to concurrently optimize and
fine-tune these parameters. In addition, most previous works on CCA mainly
study traditional single threaded CPU applications. This paper describes a
systematic approach to predict the right configurations for running
multithreaded workloads on CCAs. It achieves this by developing a machine
learning-based approach to predict core type, voltage and frequency setting to
maximize the energy-efficiency. Our predictor learns offline from an extensive
set of training multithreaded workloads. It is then applied to predict the
optimal processor configuration at run-time by taking into account the
multithreaded application characteristics and the optimization objective. For
this purpose, five well-known machine learning models are implemented for
energy-efficiency optimization and precisely compared in terms of accuracy and
hardware overhead to guide the scheduling decisions in a CCA.
"
1050,"A Flip-Syndrome-List Polar Decoder Architecture for Ultra-Low-Latency
  Communications","  We consider practical hardware implementation of Polar decoders. To reduce
latency due to the serial nature of successive cancellation (SC), existing
optimizations improve parallelism with two approaches, i.e., multi-bit decision
or reduced path splitting. In this paper, we combine the two procedures into
one with an error-pattern-based architecture. It simultaneously generates a set
of candidate paths for multiple bits with pre-stored patterns. For rate-1 (R1)
or single parity-check (SPC) nodes, we prove that a small number of
deterministic patterns are required to guarantee performance preservation. For
general nodes, low-weight error patterns are indexed by syndrome in a look-up
table and retrieved in O(1) time. The proposed flip-syndrome-list (FSL) decoder
fully parallelizes all constituent code blocks without sacrificing performance,
thus is suitable for ultra-low-latency applications. Meanwhile, two code
construction optimizations are presented to further reduce complexity and
improve performance, respectively.
"
1051,eQASM: An Executable Quantum Instruction Set Architecture,"  A widely-used quantum programming paradigm comprises of both the data flow
and control flow. Existing quantum hardware cannot well support the control
flow, significantly limiting the range of quantum software executable on the
hardware. By analyzing the constraints in the control microarchitecture, we
found that existing quantum assembly languages are either too high-level or too
restricted to support comprehensive flow control on the hardware. Also, as
observed with the quantum microinstruction set QuMIS, the quantum instruction
set architecture (QISA) design may suffer from limited scalability and
flexibility because of microarchitectural constraints. It is an open challenge
to design a scalable and flexible QISA which provides a comprehensive
abstraction of the quantum hardware.
  In this paper, we propose an executable QISA, called eQASM, that can be
translated from quantum assembly language (QASM), supports comprehensive
quantum program flow control, and is executed on a quantum control
microarchitecture. With efficient timing specification,
single-operation-multiple-qubit execution, and a very-long-instruction-word
architecture, eQASM presents better scalability than QuMIS. The definition of
eQASM focuses on the assembly level to be expressive. Quantum operations are
configured at compile time instead of being defined at QISA design time. We
instantiate eQASM into a 32-bit instruction set targeting a seven-qubit
superconducting quantum processor. We validate our design by performing several
experiments on a two-qubit quantum processor.
"
1052,"Hardware realization of residue number system algorithms by Boolean
  functions minimization","  Residue number systems (RNS) represent numbers by their remainders modulo a
set of relatively prime numbers. This paper pro- poses an efficient hardware
implementation of modular multiplication and of the modulo function (X(mod P)),
based on Boolean minimiza- tion. We report experiments showing a performance
advantage up to 30 times for our approach vs. the results obtained by
state-of-art industrial tools.
"
1053,Architectural Techniques for Improving NAND Flash Memory Reliability,"  Raw bit errors are common in NAND flash memory and will increase in the
future. These errors reduce flash reliability and limit the lifetime of a flash
memory device. We aim to improve flash reliability with a multitude of low-cost
architectural techniques. We show that NAND flash memory reliability can be
improved at low cost and with low performance overhead by deploying various
architectural techniques that are aware of higher-level application behavior
and underlying flash device characteristics.
  We analyze flash error characteristics and workload behavior through
experimental characterization, and design new flash controller algorithms that
use the insights gained from our analysis to improve flash reliability at a low
cost. We investigate four directions through this approach. (1) We propose a
new technique called WARM that improves flash reliability by 12.9 times by
managing flash retention differently for write-hot data and write-cold data.
(2) We propose a new framework that learns an online flash channel model for
each chip and enables four new flash controller algorithms to improve flash
reliability by up to 69.9%. (3) We identify three new error characteristics in
3D NAND through a comprehensive experimental characterization of real 3D NAND
chips, and propose four new techniques that mitigate these new errors and
improve 3D NAND reliability by up to 66.9%. (4) We propose a new technique
called HeatWatch that improves 3D NAND reliability by 3.85 times by utilizing
self-healing effect to mitigate retention errors in 3D NAND.
"
1054,"D-RaNGe: Using Commodity DRAM Devices to Generate True Random Numbers
  with Low Latency and High Throughput","  We propose a new DRAM-based true random number generator (TRNG) that
leverages DRAM cells as an entropy source. The key idea is to intentionally
violate the DRAM access timing parameters and use the resulting errors as the
source of randomness. Our technique specifically decreases the DRAM row
activation latency (timing parameter tRCD) below manufacturer-recommended
specifications, to induce read errors, or activation failures, that exhibit
true random behavior. We then aggregate the resulting data from multiple cells
to obtain a TRNG capable of providing a high throughput of random numbers at
low latency.
  To demonstrate that our TRNG design is viable using commodity DRAM chips, we
rigorously characterize the behavior of activation failures in 282
state-of-the-art LPDDR4 devices from three major DRAM manufacturers. We verify
our observations using four additional DDR3 DRAM devices from the same
manufacturers. Our results show that many cells in each device produce random
data that remains robust over both time and temperature variation. We use our
observations to develop D-RanGe, a methodology for extracting true random
numbers from commodity DRAM devices with high throughput and low latency by
deliberately violating the read access timing parameters. We evaluate the
quality of our TRNG using the commonly-used NIST statistical test suite for
randomness and find that D-RaNGe: 1) successfully passes each test, and 2)
generates true random numbers with over two orders of magnitude higher
throughput than the previous highest-throughput DRAM-based TRNG.
"
1055,Scale-Out Processors & Energy Efficiency,"  Scale-out workloads like media streaming or Web search serve millions of
users and operate on a massive amount of data, and hence, require enormous
computational power. As the number of users is increasing and the size of data
is expanding, even more computational power is necessary for powering up such
workloads. Data centers with thousands of servers are providing the
computational power necessary for executing scale-out workloads. As operating
data centers requires enormous capital outlay, it is important to optimize them
to execute scale-out workloads efficiently. Server processors contribute
significantly to the data center capital outlay, and hence, are a prime
candidate for optimizations. While data centers are constrained with power, and
power consumption is one of the major components contributing to the total cost
of ownership (TCO), a recently-introduced scale-out design methodology
optimizes server processors for data centers using performance per unit area.
In this work, we use a more relevant performance-per-power metric as the
optimization criterion for optimizing server processors and reevaluate the
scale-out design methodology. Interestingly, we show that a scale-out processor
that delivers the maximum performance per unit area, also delivers the highest
performance per unit power.
"
1056,"Making Belady-Inspired Replacement Policies More Effective Using
  Expected Hit Count","  Memory-intensive workloads operate on massive amounts of data that cannot be
captured by last-level caches (LLCs) of modern processors. Consequently,
processors encounter frequent off-chip misses, and hence, lose a significant
performance potential. One way to reduce the number of off-chip misses is
through using a well-behaved replacement policy in the LLC. Existing processors
employ a variation of least recently used (LRU) policy to determine a victim
for replacement. Unfortunately, there is a large gap between what LRU offers
and that of Belady's MIN, which is the optimal replacement policy. Belady's MIN
requires selecting a victim with the longest reuse distance, and hence, is
unfeasible due to the need to know the future. Consequently, Belady-inspired
replacement polices use Belady's MIN to derive an indicator to help them choose
a victim for replacement.
  In this work, we show that the indicator that is used in the state-of-the-art
Belady-inspired replacement policy is not decisive in picking a victim in a
considerable number of cases, and hence, the policy has to rely on a standard
metric (e.g., recency or frequency) to pick a victim, which is inefficient. We
observe that there exist strong correlations among the hit counts of cache
blocks in the same region of memory when Belady's MIN is the replacement
policy. Taking advantage of this observation, we propose an expected-hit-count
indicator for the memory regions and use it to improve the victim selection
mechanism of Belady-inspired replacement policies when the main indicator is
not decisive. Our proposal offers a 5.2\% performance improvement over the
baseline LRU and outperforms Hawkeye, which is the state-of-the-art replacement
policy.
"
1057,Wrangling Rogues: Managing Experimental Post-Moore Architectures,"  The Rogues Gallery is a new experimental testbed that is focused on tackling
""rogue"" architectures for the Post-Moore era of computing. While some of these
devices have roots in the embedded and high-performance computing spaces,
managing current and emerging technologies provides a challenge for system
administration that are not always foreseen in traditional data center
environments.
  We present an overview of the motivations and design of the initial Rogues
Gallery testbed and cover some of the unique challenges that we have seen and
foresee with upcoming hardware prototypes for future post-Moore research.
Specifically, we cover the networking, identity management, scheduling of
resources, and tools and sensor access aspects of the Rogues Gallery and
techniques we have developed to manage these new platforms.
"
1058,"TRINITY: Coordinated Performance, Energy and Temperature Management in
  3D Processor-Memory Stacks","  The consistent demand for better performance has lead to innovations at
hardware and microarchitectural levels. 3D stacking of memory and logic dies
delivers an order of magnitude improvement in available memory bandwidth. The
price paid however is, tight thermal constraints.
  In this paper, we study the complex multiphysics interactions between
performance, energy and temperature. Using a cache coherent multicore processor
cycle level simulator coupled with power and thermal estimation tools, we
investigate the interactions between (a) thermal behaviors (b) compute and
memory microarchitecture and (c) application workloads. The key insights from
this exploration reveal the need to manage performance, energy and temperature
in a coordinated fashion. Furthermore, we identify the concept of ""effective
heat capacity"" i.e. the heat generated beyond which no further gains in
performance is observed with increases in voltage-frequency of the compute
logic. Subsequently, a real-time, numerical optimization based, application
agnostic controller (TRINITY) is developed which intelligently manages the
three parameters of interest. We observe up to $30\%$ improvement in Energy
Delay$^2$ Product and up to $8$ Kelvin lower core temperatures as compared to
fixed frequencies. Compared to the \texttt{ondemand} Linux CPU DVFS governor,
for similar energy efficiency, TRINITY keeps the cores cooler by $6$ Kelvin
which increases the lifetime reliability by up to 59\%.
"
1059,"Implications of Integrated CPU-GPU Processors on Thermal and Power
  Management Techniques","  Heterogeneous processors with architecturally different cores (CPU and GPU)
integrated on the same die lead to new challenges and opportunities for thermal
and power management techniques because of shared thermal/power budgets between
these cores. In this paper, we show that new parallel programming paradigms
(e.g., OpenCL) for CPU-GPU processors create a tighter coupling between the
workload, the thermal/power management unit and the operating system. Using
detailed thermal and power maps of the die from infrared imaging, we
demonstrate that in contrast to traditional multi-core CPUs, heterogeneous
processors exhibit higher coupled behavior for dynamic voltage and frequency
scaling and workload scheduling, in terms of their effect on performance,
power, and temperature. Further, we show that by taking the differences in core
architectures and relative proximity of different computing cores on the die
into consideration, better scheduling schemes could be implemented to reduce
both the power density and peak temperature of the die. The findings presented
in the paper can be used to improve thermal and power efficiency of
heterogeneous CPU-GPU processors.
"
1060,"Scalable and Efficient Virtual Memory Sharing in Heterogeneous SoCs with
  TLB Prefetching and MMU-Aware DMA Engine","  Shared virtual memory (SVM) is key in heterogeneous systems on chip (SoCs),
which combine a general-purpose host processor with a many-core accelerator,
both for programmability and to avoid data duplication. However, SVM can bring
a significant run time overhead when translation lookaside buffer (TLB) entries
are missing. Moreover, allowing DMA burst transfers to write SVM traditionally
requires buffers to absorb transfers that miss in the TLB. These buffers have
to be overprovisioned for the maximum burst size, wasting precious on-chip
memory, and stall all SVM accesses once they are full, hampering the
scalability of parallel accelerators.
  In this work, we present our SVM solution that avoids the majority of TLB
misses with prefetching, supports parallel burst DMA transfers without
additional buffers, and can be scaled with the workload and number of parallel
processors. Our solution is based on three novel concepts: To minimize the rate
of TLB misses, the TLB is proactively filled by compiler-generated Prefetching
Helper Threads, which use run-time information to issue timely prefetches. To
reduce the latency of TLB misses, misses are handled by a variable number of
parallel Miss Handling Helper Threads. To support parallel burst DMA transfers
to SVM without additional buffers, we add lightweight hardware to a standard
DMA engine to detect and react to TLB misses. Compared to the state of the art,
our work improves accelerator performance for memory-intensive kernels by up to
4x and by up to 60% for irregular and regular memory access patterns,
respectively.
"
1061,Programmable Memristive Threshold Logic Gate Array,"  This paper proposes the implementation of programmable threshold logic gate
(TLG) crossbar array based on modified TLG cells for high speed processing and
computation. The proposed TLG array operation does not depend on input signal
and time pulses, comparing to the existing architectures. The circuit is
implemented using TSMC $180nm$ CMOS technology. The on-chip area and power
dissipation of the simulated $3\times 4$ TLG array is $1463 \mu m^2$ and $425
\mu W$, respectively.
"
1062,CIDPro: Custom Instructions for Dynamic Program Diversification,"  Timing side-channel attacks pose a major threat to embedded systems due to
their ease of accessibility. We propose CIDPro, a framework that relies on
dynamic program diversification to mitigate timing side-channel leakage. The
proposed framework integrates the widely used LLVM compiler infrastructure and
the increasingly popular RISC-V FPGA soft-processor. The compiler automatically
generates custom instructions in the security critical segments of the program,
and the instructions execute on the RISC-V custom co-processor to produce
diversified timing characteristics on each execution instance. CIDPro has been
implemented on the Zynq7000 XC7Z020 FPGA device to study the performance
overhead and security tradeoffs. Experimental results show that our solution
can achieve 80% and 86% timing side-channel capacity reduction for two
benchmarks with an acceptable performance overhead compared to existing
solutions. In addition, the proposed method incurs only a negligible hardware
area overhead of 1% slices of the entire RISC-V system.
"
1063,A CNN Accelerator on FPGA Using Depthwise Separable Convolution,"  Convolutional neural networks (CNNs) have been widely deployed in the fields
of computer vision and pattern recognition because of their high accuracy.
However, large convolution operations are computing-intensive that often
requires a powerful computing platform such as Graphics Processing Unit (GPU).
This makes it difficult to apply CNNs to portable devices. The state-of-the-art
CNNs, such as MobileNetV2 and Xception, adopt depthwise separable convolution
to replace the standard convolution for embedded platforms. That significantly
reduces operations and parameters with only limited loss in accuracy. This
highly structured model is very suitable for Field-Programmable Gate Array
(FPGA) implementation. In this paper, a scalable high performance depthwise
separable convolution optimized CNN accelerator is proposed. The accelerator
can be fit into an FPGA of different sizes, provided the balancing between
hardware resources and processing speed. As an example, MobileNetV2 is
implemented on Arria 10 SoC FPGA, and the results show this accelerator can
classify each picture from ImageNet in 3.75ms, which is about 266.6 frames per
second. This achieves 20x speedup if compared to CPU.
"
1064,Accelerating Viterbi Algorithm using Custom Instruction Approach,"  In recent years, the decoding algorithms in communication networks are
becoming increasingly complex aiming to achieve high reliability in correctly
decoding received messages. These decoding algorithms involve computationally
complex operations requiring high performance computing hardware, which are
generally expensive. A cost-effective solution is to enhance the Instruction
Set Architecture (ISA) of the processors by creating new custom instructions
for the computational parts of the decoding algorithms. In this paper, we
propose to utilize the custom instruction approach to efficiently implement the
widely used Viterbi decoding algorithm by adding the assembly language
instructions to the ISA of DLX, PicoJava II and NIOS II processors, which
represent RISC, stack and FPGA-based soft-core processor architectures,
respectively. By using the custom instruction approach, the execution time of
the Viterbi algorithm is significantly improved by approximately 3 times for
DLX and PicoJava II, and by 2 times for NIOS II.
"
1065,Is Leakage Power a Linear Function of Temperature?,"  In this work, we present a study of the leakage power modeling techniques
commonly used in the architecture community. We further provide an analysis of
the error in leakage power estimation using the various modeling techniques. We
strongly believe that this study will help researchers determine an appropriate
leakage model to use in their work, based on the desired modeling accuracy and
speed.
"
1066,"FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of
  Quantized Neural Networks","  Convolutional Neural Networks have rapidly become the most successful machine
learning algorithm, enabling ubiquitous machine vision and intelligent
decisions on even embedded computing-systems. While the underlying arithmetic
is structurally simple, compute and memory requirements are challenging. One of
the promising opportunities is leveraging reduced-precision representations for
inputs, activations and model parameters. The resulting scalability in
performance, power efficiency and storage footprint provides interesting design
compromises in exchange for a small reduction in accuracy. FPGAs are ideal for
exploiting low-precision inference engines leveraging custom precisions to
achieve the required numerical accuracy for a given application. In this
article, we describe the second generation of the FINN framework, an end-to-end
tool which enables design space exploration and automates the creation of fully
customized inference engines on FPGAs. Given a neural network description, the
tool optimizes for given platforms, design targets and a specific precision. We
introduce formalizations of resource cost functions and performance
predictions, and elaborate on the optimization algorithms. Finally, we evaluate
a selection of reduced precision neural networks ranging from CIFAR-10
classifiers to YOLO-based object detection on a range of platforms including
PYNQ and AWS\,F1, demonstrating new unprecedented measured throughput at
50TOp/s on AWS-F1 and 5TOp/s on embedded devices.
"
1067,Exploiting Errors for Efficiency: A Survey from Circuits to Algorithms,"  When a computational task tolerates a relaxation of its specification or when
an algorithm tolerates the effects of noise in its execution, hardware,
programming languages, and system software can trade deviations from correct
behavior for lower resource usage. We present, for the first time, a synthesis
of research results on computing systems that only make as many errors as their
users can tolerate, from across the disciplines of computer aided design of
circuits, digital system design, computer architecture, programming languages,
operating systems, and information theory.
  Rather than over-provisioning resources at each layer to avoid errors, it can
be more efficient to exploit the masking of errors occurring at one layer which
can prevent them from propagating to a higher layer. We survey tradeoffs for
individual layers of computing systems from the circuit level to the operating
system level and illustrate the potential benefits of end-to-end approaches
using two illustrative examples. To tie together the survey, we present a
consistent formalization of terminology, across the layers, which does not
significantly deviate from the terminology traditionally used by research
communities in their layer of focus.
"
1068,"The Impact of On-chip Communication on Memory Technologies for
  Neuromorphic Systems","  Emergent nanoscale non-volatile memory technologies with high integration
density offer a promising solution to overcome the scalability limitations of
CMOS-based neural networks architectures, by efficiently exhibiting the key
principle of neural computation. Despite the potential improvements in
computational costs, designing high-performance on-chip communication networks
that support flexible, large-fanout connectivity remains as daunting task. In
this paper, we elaborate on the communication requirements of large-scale
neuromorphic designs, and point out the differences with the conventional
network-on-chip architectures. We present existing approaches for on-chip
neuromorphic routing networks, and discuss how new memory and integration
technologies may help to alleviate the communication issues in constructing
next-generation intelligent computing machines.
"
1069,"AutoAccel: Automated Accelerator Generation and Optimization with
  Composable, Parallel and Pipeline Architecture","  CPU-FPGA heterogeneous architectures are attracting ever-increasing attention
in an attempt to advance computational capabilities and energy efficiency in
today's datacenters. These architectures provide programmers with the ability
to reprogram the FPGAs for flexible acceleration of many workloads.
Nonetheless, this advantage is often overshadowed by the poor programmability
of FPGAs whose programming is conventionally a RTL design practice. Although
recent advances in high-level synthesis (HLS) significantly improve the FPGA
programmability, it still leaves programmers facing the challenge of
identifying the optimal design configuration in a tremendous design space.
  This paper aims to address this challenge and pave the path from software
programs towards high-quality FPGA accelerators. Specifically, we first propose
the composable, parallel and pipeline (CPP) microarchitecture as a template of
accelerator designs. Such a well-defined template is able to support efficient
accelerator designs for a broad class of computation kernels, and more
importantly, drastically reduce the design space. Also, we introduce an
analytical model to capture the performance and resource trade-offs among
different design configurations of the CPP microarchitecture, which lays the
foundation for fast design space exploration. On top of the CPP
microarchitecture and its analytical model, we develop the AutoAccel framework
to make the entire accelerator generation automated. AutoAccel accepts a
software program as an input and performs a series of code transformations
based on the result of the analytical-model-based design space exploration to
construct the desired CPP microarchitecture. Our experiments show that the
AutoAccel-generated accelerators outperform their corresponding software
implementations by an average of 72x for a broad class of computation kernels.
"
1070,A Microbenchmark Characterization of the Emu Chick,"  The Emu Chick is a prototype system designed around the concept of migratory
memory-side processing. Rather than transferring large amounts of data across
power-hungry, high-latency interconnects, the Emu Chick moves lightweight
thread contexts to near-memory cores before the beginning of each memory read.
The current prototype hardware uses FPGAs to implement cache-less ""Gossamer
cores for doing computational work and a stationary core to run basic operating
system functions and migrate threads between nodes. In this multi-node
characterization of the Emu Chick, we extend an earlier single-node
investigation (Hein, et al. AsHES 2018) of the the memory bandwidth
characteristics of the system through benchmarks like STREAM, pointer chasing,
and sparse matrix-vector multiplication. We compare the Emu Chick hardware to
architectural simulation and an Intel Xeon-based platform. Our results
demonstrate that for many basic operations the Emu Chick can use available
memory bandwidth more efficiently than a more traditional, cache-based
architecture although bandwidth usage suffers for computationally intensive
workloads like SpMV. Moreover, the Emu Chick provides stable, predictable
performance with up to 65% of the peak bandwidth utilization on a random-access
pointer chasing benchmark with weak locality.
"
1071,"A Traffic-Aware Medium Access Control Mechanism for Energy-Efficient
  Wireless Network-on-Chip Architectures","  Wireless interconnection has emerged as an energy efficient solution to the
challenges of multi-hop communication over the wireline paths in conventional
Networks-on-Chips (NoCs). However, to ensure the full benefits of this novel
interconnect technology, design of simple, fair and efficient Medium Access
Control (MAC) mechanism to grant access to the on-chip wireless communication
channel is needed. Moreover, to adapt to the varying traffic demands from the
applications running on a multicore environment, MAC mechanisms should
dynamically adjust the transmission slots of the wireless interfaces (WIs).
Such dynamic adjustment in transmission slots will result in improving the
utilization of the wireless medium in a Wireless NoC (WiNoC). In this paper we
present the design of two dynamic MAC mechanisms that adjust the transmission
slots of the WIs based on predicted traffic demands and allow partial packet
transfer. Through system level simulations, we demonstrate that the traffic
aware MAC mechanisms are more energy efficient as well as capable of sustaining
higher data bandwidth in WiNoCs.
"
1072,In-memory multiplication engine with SOT-MRAM based stochastic computing,"  Processing-in-memory (PIM) turns out to be a promising solution to
breakthrough the memory wall and the power wall. While prior PIM designs yield
successful implementation of bitwise Boolean logic operations locally in
memory, it is difficult to accomplish the multiplication (MUL) instruction in a
fast and efficient manner. In this paper, we propose a new stochastic computing
(SC) design to perform MUL with in-memory operations. Instead of using the
stochastic number generators (SNGs), we harness the inherent stochasticity in
the memory write behavior of the magnetic random access memory (MRAM). Each
memory bit serves as an SC engine, performs MUL on operands in the form of
write voltage pulses, and stores the MUL outcome in-situ. The proposed design
provides up to 4x improvement in performance compared with conversational SC
approaches, and achieves 18x speedup over implementing MUL with only in-memory
bitwise Boolean logic operations.
"
1073,"Die-Stacked DRAM: Memory, Cache, or MemCache?","  Die-stacked DRAM is a promising solution for satisfying the ever-increasing
memory bandwidth requirements of multi-core processors. Manufacturing
technology has enabled stacking several gigabytes of DRAM modules on the active
die, thereby providing orders of magnitude higher bandwidth as compared to the
conventional DIMM-based DDR memories. Nevertheless, die-stacked DRAM, due to
its limited capacity, cannot accommodate entire datasets of modern big-data
applications. Therefore, prior proposals use it either as a sizable memory-side
cache or as a part of the software-visible main memory. Cache designs can adapt
themselves to the dynamic variations of applications but suffer from the tag
storage/latency/bandwidth overhead. On the other hand, memory designs eliminate
the need for tags, and hence, provide efficient access to data, but are unable
to capture the dynamic behaviors of applications due to their static nature.
  In this work, we make a case for using the die-stacked DRAM partly as main
memory and partly as a cache. We observe that in modern big-data applications
there are many hot pages with a large number of accesses. Based on this
observation, we propose to use a portion of the die-stacked DRAM as main memory
to host hot pages, enabling serving a significant number of the accesses from
the high-bandwidth DRAM without the overhead of tag-checking, and manage the
rest of the DRAM as a cache, for capturing the dynamic behavior of
applications. In this proposal, a software procedure pre-processes the
application and determines hot pages, then asks the OS to map them to the
memory portion of the die-stacked DRAM. The cache portion of the die-stacked
DRAM is managed by hardware, caching data allocated in the off-chip memory.
"
1074,T-count Optimized Quantum Circuits for Bilinear Interpolation,"  Quantum circuits for basic image processing functions such as bilinear
interpolation are required to implement image processing algorithms on quantum
computers. In this work, we propose quantum circuits for the bilinear
interpolation of NEQR encoded images based on Clifford+T gates. Quantum
circuits for the scale up operation and scale down operation are illustrated.
The proposed quantum circuits are based on quantum Clifford+T gates and are
optimized for T-count. Quantum circuits based on Clifford+T gates can be made
fault tolerant but the T gate is very costly to implement. As a result,
reducing T-count is an important optimization goal. The proposed quantum
bilinear interpolation circuits are based on (i) a quantum adder, (ii) a
proposed quantum subtractor, and (iii) a quantum multiplication circuit.
Further, both designs are compared and shown to be superior to existing work in
terms of T-count. The proposed quantum bilinear interpolation circuits for the
scale down operation and for the scale up operation each have a $92.52\%$
improvement in terms of T-count compared to the existing work.
"
1075,"Quantum Circuit Designs of Integer Division Optimizing T-count and
  T-depth","  Quantum circuits for mathematical functions such as division are necessary to
use quantum computers for scientific computing. Quantum circuits based on
Clifford+T gates can easily be made fault-tolerant but the T gate is very
costly to implement. The small number of qubits available in existing quantum
computers adds another constraint on quantum circuits. As a result, reducing
T-count and qubit cost have become important optimization goals. The design of
quantum circuits for integer division has caught the attention of researchers
and designs have been proposed in the literature. However, these designs suffer
from excessive T gate and qubit costs. Many of these designs also produce
significant garbage output resulting in additional qubit and T gate costs to
eliminate these outputs. In this work, we propose two quantum integer division
circuits. The first proposed quantum integer division circuit is based on the
restoring division algorithm and the second proposed design implements the
non-restoring division algorithm. Both proposed designs are optimized in terms
of T-count, T-depth and qubits. Both proposed quantum circuit designs are based
on (i) a quantum subtractor, (ii) a quantum adder-subtractor circuit, and (iii)
a novel quantum conditional addition circuit. Our proposed restoring division
circuit achieves average T-count savings from $79.03 \%$ to $91.69 \%$ compared
to the existing works. Our proposed non-restoring division circuit achieves
average T-count savings from $49.75 \%$ to $90.37 \%$ compared to the existing
works. Further, both our proposed designs have linear T-depth.
"
1076,"Improving Reliability, Security, and Efficiency of Reconfigurable
  Hardware Systems","  In this treatise, my research on methods to improve efficiency, reliability,
and security of reconfigurable hardware systems, i.e., FPGAs, through partial
dynamic reconfiguration is outlined. The efficiency of reconfigurable systems
can be improved by loading optimized data paths on-the-fly on an FPGA fabric.
This technique was applied to the acceleration of SQL queries for large
database applications as well as for image and signal processing applications.
The focus was not only on performance improvements and resource efficiency, but
also the energy efficiency has been significantly improved. In the area of
reliability, countermeasures against radiation-induced faults and aging effects
for long mission times were investigated and applied to SRAM-FPGA-based
satellite systems. Finally, to increase the security of cryptographic
FPGA-based implementations against physical attacks, i.e., side-channel and
fault injection analysis as well as reverse engineering, it is proposed to
transform static circuit structures into dynamic ones by applying dynamic
partial reconfiguration.
"
1077,Mini-batch Serialization: CNN Training with Inter-layer Data Reuse,"  Training convolutional neural networks (CNNs) requires intense computations
and high memory bandwidth. We find that bandwidth today is over-provisioned
because most memory accesses in CNN training can be eliminated by rearranging
computation to better utilize on-chip buffers and avoid traffic resulting from
large per-layer memory footprints. We introduce the MBS CNN training approach
that significantly reduces memory traffic by partially serializing mini-batch
processing across groups of layers. This optimizes reuse within on-chip buffers
and balances both intra-layer and inter-layer reuse. We also introduce the
WaveCore CNN training accelerator that effectively trains CNNs in the MBS
approach with high functional-unit utilization. Combined, WaveCore and MBS
reduce DRAM traffic by 75%, improve performance by 53%, and save 26% system
energy for modern deep CNN training compared to conventional training
mechanisms and accelerators.
"
1078,Throughput Optimizations for FPGA-based Deep Neural Network Inference,"  Deep neural networks are an extremely successful and widely used technique
for various pattern recognition and machine learning tasks. Due to power and
resource constraints, these computationally intensive networks are difficult to
implement in embedded systems. Yet, the number of applications that can benefit
from the mentioned possibilities is rapidly rising. In this paper, we propose
novel architectures for the inference of previously learned and arbitrary deep
neural networks on FPGA-based SoCs that are able to overcome these limitations.
Our key contributions include the reuse of previously transferred weight
matrices across multiple input samples, which we refer to as batch processing,
and the usage of compressed weight matrices, also known as pruning. An
extensive evaluation of these optimizations is presented. Both techniques allow
a significant mitigation of data transfers and speed-up the network inference
by one order of magnitude. At the same time, we surpass the data throughput of
fully-featured x86-based systems while only using a fraction of their energy
consumption.
"
1079,Performance Comparison of some Synchronous Adders,"  This technical note compares the performance of some synchronous adders which
correspond to the following architectures: i) ripple carry adder (RCA), ii)
recursive carry lookahead adder (RCLA), iii) hybrid RCLA-RCA with the RCA used
in the least significant adder bit positions, iv) block carry lookahead adder
(BCLA), v) hybrid BCLA-RCA with the RCA used in the least significant adder bit
positions, and vi) non-uniform input partitioned carry select adders (CSLAs)
without and with the binary to excess-1 code (BEC) converter. The 32-bit
addition was considered as an example operation. The adder architectures
mentioned were implemented by targeting a typical case PVT specification (high
threshold voltage, supply voltage of 1.05V and operating temperature of 25
degrees Celsius) of the Synopsys 32/28nm CMOS technology. The comparison leads
to the following observations: i) the hybrid CCLA-RCA is preferable to the
other adders in terms of the speed, the power-delay product, and the
energy-delay product, ii) the non-uniform input partitioned CSLA without the
BEC converter is preferable to the other adders in terms of the area-delay
product, and iii) the RCA incorporating the full adder present in the standard
digital cell library is preferable to the other adders in terms of the
power-delay-area product.
"
1080,"Synthesis of Majority Expressions through Primitive Function
  Manipulation","  Due to technology advancements and circuits miniaturization, the study of
logic systems that can be applied to nanotechnology has been progressing
steadily. Among the creation of nanoeletronic circuits reversible and majority
logic stand out. This paper proposes the MPC (Majority Primitives Combination)
algorithm, used for majority logic synthesis. The algorithm receives a truth
table as input and returns a majority function that covers the same set of
minterms. The formulation of a valid output function is made with the
combination of previously optimized functions. As cost criteria the algorithm
searches for a function with the least number of levels, followed by the least
number of gates, inverters, and gate inputs. In this paper it's also presented
a comparison between the MPC and the exact_mig, currently considered the best
algorithm for majority synthesis. The exact_mig encode the exact synthesis of
majority functions using the number of levels and gates as cost criteria. The
MPC considers two additional cost criteria, the number of inverters and the
number of gate inputs, with the goal to further improve exact_mig results.
Tests have shown that both algorithms return optimal solutions for all
functions with 3 input variables. For functions with 4 inputs, the MPC is able
to further improve 42,987 (66%) functions and achieves equal results for 7,198
(11%). For functions with 5 input variables, out of a sample of 1,000 randomly
generated functions, the MPC further improved 477 (48%) functions and achieved
equal results for 112 (11%).
"
1081,"Towards Fast and Energy-Efficient Binarized Neural Network Inference on
  FPGA","  Binarized Neural Network (BNN) removes bitwidth redundancy in classical CNN
by using a single bit (-1/+1) for network parameters and intermediate
representations, which has greatly reduced the off-chip data transfer and
storage overhead. However, a large amount of computation redundancy still
exists in BNN inference. By analyzing local properties of images and the
learned BNN kernel weights, we observe an average of $\sim$78% input similarity
and $\sim$59% weight similarity among weight kernels, measured by our proposed
metric in common network architectures. Thus there does exist redundancy that
can be exploited to further reduce the amount of on-chip computations.
  Motivated by the observation, in this paper, we proposed two types of fast
and energy-efficient architectures for BNN inference. We also provide analysis
and insights to pick the better strategy of these two for different datasets
and network models. By reusing the results from previous computation, much
cycles for data buffer access and computations can be skipped. By experiments,
we demonstrate that 80% of the computation and 40% of the buffer access can be
skipped by exploiting BNN similarity. Thus, our design can achieve 17%
reduction in total power consumption, 54% reduction in on-chip power
consumption and 2.4$\times$ maximum speedup, compared to the baseline without
applying our reuse technique. Our design also shows 1.9$\times$ more
area-efficiency compared to state-of-the-art BNN inference design. We believe
our deployment of BNN on FPGA leads to a promising future of running deep
learning models on mobile devices.
"
1082,"Extended Bit-Plane Compression for Convolutional Neural Network
  Accelerators","  After the tremendous success of convolutional neural networks in image
classification, object detection, speech recognition, etc., there is now rising
demand for deployment of these compute-intensive ML models on tightly power
constrained embedded and mobile systems at low cost as well as for pushing the
throughput in data centers. This has triggered a wave of research towards
specialized hardware accelerators. Their performance is often constrained by
I/O bandwidth and the energy consumption is dominated by I/O transfers to
off-chip memory. We introduce and evaluate a novel, hardware-friendly
compression scheme for the feature maps present within convolutional neural
networks. We show that an average compression ratio of 4.4x relative to
uncompressed data and a gain of 60% over existing method can be achieved for
ResNet-34 with a compression block requiring <300 bit of sequential cells and
minimal combinational logic.
"
1083,"uops.info: Characterizing Latency, Throughput, and Port Usage of
  Instructions on Intel Microarchitectures","  Modern microarchitectures are some of the world's most complex man-made
systems. As a consequence, it is increasingly difficult to predict, explain,
let alone optimize the performance of software running on such
microarchitectures. As a basis for performance predictions and optimizations,
we would need faithful models of their behavior, which are, unfortunately,
seldom available.
  In this paper, we present the design and implementation of a tool to
construct faithful models of the latency, throughput, and port usage of x86
instructions. To this end, we first discuss common notions of instruction
throughput and port usage, and introduce a more precise definition of latency
that, in contrast to previous definitions, considers dependencies between
different pairs of input and output operands. We then develop novel algorithms
to infer the latency, throughput, and port usage based on
automatically-generated microbenchmarks that are more accurate and precise than
existing work.
  To facilitate the rapid construction of optimizing compilers and tools for
performance prediction, the output of our tool is provided in a
machine-readable format. We provide experimental results for processors of all
generations of Intel's Core architecture, i.e., from Nehalem to Coffee Lake,
and discuss various cases where the output of our tool differs considerably
from prior work.
"
1084,Computational ghost imaging using a field-programmable gate array,"  Computational ghost imaging is a promising technique for single-pixel imaging
because it is robust to disturbance and can be operated over broad wavelength
bands, unlike common cameras. However, one disadvantage of this method is that
it has a long calculation time for image reconstruction. In this paper, we have
designed a dedicated calculation circuit that accelerated the process of
computational ghost imaging. We implemented this circuit by using a
field-programmable gate array, which reduced the calculation time for the
circuit compared to a CPU. The dedicated circuit reconstructs images at a frame
rate of 300 Hz.
"
1085,Memory Vulnerability: A Case for Delaying Error Reporting,"  To face future reliability challenges, it is necessary to quantify the risk
of error in any part of a computing system. To this goal, the Architectural
Vulnerability Factor (AVF) has long been used for chips. However, this metric
is used for offline characterisation, which is inappropriate for memory. We
survey the literature and formalise one of the metrics used, the Memory
Vulnerability Factor, and extend it to take into account false errors. These
are reported errors which would have no impact on the program if they were
ignored. We measure the False Error Aware MVF (FEA) and related metrics
precisely in a cycle-accurate simulator, and compare them with the effects of
injecting faults in a program's data, in native parallel runs. Our findings
show that MVF and FEA are the only two metrics that are safe to use at runtime,
as they both consistently give an upper bound on the probability of incorrect
program outcome. FEA gives a tighter bound than MVF, and is the metric that
correlates best with the incorrect outcome probability of all considered
metrics.
"
1086,Morph: Flexible Acceleration for 3D CNN-based Video Understanding,"  The past several years have seen both an explosion in the use of
Convolutional Neural Networks (CNNs) and the design of accelerators to make CNN
inference practical. In the architecture community, the lion share of effort
has targeted CNN inference for image recognition. The closely related problem
of video recognition has received far less attention as an accelerator target.
This is surprising, as video recognition is more computationally intensive than
image recognition, and video traffic is predicted to be the majority of
internet traffic in the coming years.
  This paper fills the gap between algorithmic and hardware advances for video
recognition by providing a design space exploration and flexible architecture
for accelerating 3D Convolutional Neural Networks (3D CNNs) - the core kernel
in modern video understanding. When compared to (2D) CNNs used for image
recognition, efficiently accelerating 3D CNNs poses a significant engineering
challenge due to their large (and variable over time) memory footprint and
higher dimensionality.
  To address these challenges, we design a novel accelerator, called Morph,
that can adaptively support different spatial and temporal tiling strategies
depending on the needs of each layer of each target 3D CNN. We codesign a
software infrastructure alongside the Morph hardware to find good-fit
parameters to control the hardware. Evaluated on state-of-the-art 3D CNNs,
Morph achieves up to 3.4x (2.5x average) reduction in energy consumption and
improves performance/watt by up to 5.1x (4x average) compared to a baseline 3D
CNN accelerator, with an area overhead of 5%. Morph further achieves a 15.9x
average energy reduction on 3D CNNs when compared to Eyeriss.
"
1087,"A Time-domain Analog Weighted-sum Calculation Model for Extremely Low
  Power VLSI Implementation of Multi-layer Neural Networks","  A time-domain analog weighted-sum calculation model is proposed based on an
integrate-and-fire-type spiking neuron model. The proposed calculation model is
applied to multi-layer feedforward networks, in which weighted summations with
positive and negative weights are separately performed in each layer and
summation results are then fed into the next layers without their subtraction
operation. We also propose very large-scale integrated (VLSI) circuits to
implement the proposed model. Unlike the conventional analog voltage or current
mode circuits, the time-domain analog circuits use transient operation in
charging/discharging processes to capacitors. Since the circuits can be
designed without operational amplifiers, they can operate with extremely low
power consumption. However, they have to use very high resistance devices on
the order of G$\rm \Omega$. We designed a proof-of-concept (PoC) CMOS VLSI chip
to verify weighted-sum operation with the same weights and evaluated it by
post-layout circuit simulation using 250-nm fabrication technology. High
resistance operation was realized by using the subthreshold operation region of
MOS transistors. Simulation results showed that energy efficiency for the
weighted-sum calculation was 290~TOPS/W, more than one order of magnitude
higher than that in state-of-the-art digital AI processors, even though the
minimum width of interconnection used in the PoC chip was several times larger
than that in such digital processors. If state-of-the-art VLSI technology is
used to implement the proposed model, an energy efficiency of more than
1,000~TOPS/W will be possible. For practical applications, development of
emerging analog memory devices such as ferroelectric-gate FETs is necessary.
"
1088,"An Area Efficient 2D Fourier Transform Architecture for FPGA
  Implementation","  Two-dimensional Fourier transform plays a significant role in a variety of
image processing problems, such as medical image processing, digital
holography, correlation pattern recognition, hybrid digital optical processing,
optical computing etc. 2D spatial Fourier transformation involves large number
of image samples and hence it requires huge hardware resources of field
programmable gate arrays (FPGA). In this paper, we present an area efficient
architecture of 2D FFT processor that reuses the butterfly units multiple
times. This is achieved by using a control unit that sends back the previous
computed data of N/2 butterfly units to itself for {log_2(N) - 1} times. A RAM
controller is used to synchronize the flow of data samples between the
functional blocks.The 2D FFT processor is simulated by VHDL and the results are
verified on a Virtex-6 FPGA. The proposed method outperforms the conventional
NxN point 2D FFT in terms of area which is reduced by a factor of log_N(2) with
negligible increase in computation time.
"
1089,"On the Off-chip Memory Latency of Real-Time Systems: Is DDR DRAM Really
  the Best Option?","  Predictable execution time upon accessing shared memories in multi-core
real-time systems is a stringent requirement. A plethora of existing works
focus on the analysis of Double Data Rate Dynamic Random Access Memories (DDR
DRAMs), or redesigning its memory to provide predictable memory behavior. In
this paper, we show that DDR DRAMs by construction suffer inherent limitations
associated with achieving such predictability. These limitations lead to 1)
highly variable access latencies that fluctuate based on various factors such
as access patterns and memory state from previous accesses, and 2) overly
pessimistic latency bounds. As a result, DDR DRAMs can be ill-suited for some
real-time systems that mandate a strict predictable performance with tight
timing constraints. Targeting these systems, we promote an alternative off-chip
memory solution that is based on the emerging Reduced Latency DRAM (RLDRAM)
protocol, and propose a predictable memory controller (RLDC) managing accesses
to this memory. Comparing with the state-of-the-art predictable DDR
controllers, the proposed solution provides up to 11x less timing variability
and 6.4x reduction in the worst case memory latency.
"
1090,"Exploring Modern GPU Memory System Design Challenges through Accurate
  Modeling","  This paper explores the impact of simulator accuracy on architecture design
decisions in the general-purpose graphics processing unit (GPGPU) space. We
perform a detailed, quantitative analysis of the most popular publicly
available GPU simulator, GPGPU-Sim, against our enhanced version of the
simulator, updated to model the memory system of modern GPUs in more detail.
Our enhanced GPU model is able to describe the NVIDIA Volta architecture in
sufficient detail to reduce error in memory system even counters by as much as
66X. The reduced error in the memory system further reduces execution time
error versus real hardware by 2.5X. To demonstrate the accuracy of our enhanced
model against a real machine, we perform a counter-by-counter validation
against an NVIDIA TITAN V Volta GPU, demonstrating the relative accuracy of the
new simulator versus the publicly available model.
  We go on to demonstrate that the simpler model discounts the importance of
advanced memory system designs such as out-of-order memory access scheduling,
while overstating the impact of more heavily researched areas like L1 cache
bypassing. Our results demonstrate that it is important for the academic
community to enhance the level of detail in architecture simulators as system
complexity continues to grow. As part of this detailed correlation and modeling
effort, we developed a new Correlator toolset that includes a consolidation of
applications from a variety of popular GPGPU benchmark suites, designed to run
in reasonable simulation times. The Correlator also includes a database of
hardware profiling results for all these applications on NVIDIA cards ranging
from Fermi to Volta and a toolchain that enables users to gather correlation
statistics and create detailed counter-by-counter hardware correlation plots
with minimal effort.
"
1091,"Criticality Aware Soft Error Mitigation in the Configuration Memory of
  SRAM based FPGA","  Efficient low complexity error correcting code(ECC) is considered as an
effective technique for mitigation of multi-bit upset (MBU) in the
configuration memory(CM)of static random access memory (SRAM) based Field
Programmable Gate Array (FPGA) devices. Traditional multi-bit ECCs have large
overhead and complex decoding circuit to correct adjacent multibit error. In
this work, we propose a simple multi-bit ECC which uses Secure Hash Algorithm
for error detection and parity based two dimensional Erasure Product Code for
error correction. Present error mitigation techniques perform error correction
in the CM without considering the criticality or the execution period of the
tasks allocated in different portion of CM. In most of the cases, error
correction is not done in the right instant, which sometimes either suspends
normal system operation or wastes hardware resources for less critical tasks.
In this paper,we advocate for a dynamic priority-based hardware scheduling
algorithm which chooses the tasks for error correction based on their area,
execution period and criticality. The proposed method has been validated in
terms of overhead due to redundant bits, error correction time and system
reliability
"
1092,Architectural exploration of heterogeneous memory systems,"  Heterogeneous systems appear as a viable design alternative for the dark
silicon era. In this paradigm, a processor chip includes several different
technological alternatives for implementing a certain logical block (e.g.,
core, on-chip memories) which cannot be used at the same time due to power
constraints. The programmer and compiler are then responsible for selecting
which of the alternatives should be used for maximizing performance and/or
energy efficiency for a given application. This paper presents an initial
approach for the exploration of different technological alternatives for the
implementation of on-chip memories. It hinges on a linear programming-based
model for theoretically comparing the performance offered by the available
alternatives, namely SRAM and STT-RAM scratchpads or caches. Experimental
results using a cycle-accurate simulation tool confirm that this is a viable
model for implementation into production compilers.
"
1093,Neuromorphic hardware as a self-organizing computing system,"  This paper presents the self-organized neuromorphic architecture named SOMA.
The objective is to study neural-based self-organization in computing systems
and to prove the feasibility of a self-organizing hardware structure.
Considering that these properties emerge from large scale and fully connected
neural maps, we will focus on the definition of a self-organizing hardware
architecture based on digital spiking neurons that offer hardware efficiency.
From a biological point of view, this corresponds to a combination of the
so-called synaptic and structural plasticities. We intend to define
computational models able to simultaneously self-organize at both computation
and communication levels, and we want these models to be hardware-compliant,
fault tolerant and scalable by means of a neuro-cellular structure.
"
1094,"MPNA: A Massively-Parallel Neural Array Accelerator with Dataflow
  Optimization for Convolutional Neural Networks","  The state-of-the-art accelerators for Convolutional Neural Networks (CNNs)
typically focus on accelerating only the convolutional layers, but do not
prioritize the fully-connected layers much. Hence, they lack a synergistic
optimization of the hardware architecture and diverse dataflows for the
complete CNN design, which can provide a higher potential for
performance/energy efficiency. Towards this, we propose a novel
Massively-Parallel Neural Array (MPNA) accelerator that integrates two
heterogeneous systolic arrays and respective highly-optimized dataflow patterns
to jointly accelerate both the convolutional (CONV) and the fully-connected
(FC) layers. Besides fully-exploiting the available off-chip memory bandwidth,
these optimized dataflows enable high data-reuse of all the data types (i.e.,
weights, input and output activations), and thereby enable our MPNA to achieve
high energy savings. We synthesized our MPNA architecture using the ASIC design
flow for a 28nm technology, and performed functional and timing validation
using multiple real-world complex CNNs. MPNA achieves 149.7GOPS/W at 280MHz and
consumes 239mW. Experimental results show that our MPNA architecture provides
1.7x overall performance improvement compared to state-of-the-art accelerator,
and 51% energy saving compared to the baseline architecture.
"
1095,"Amber: Enabling Precise Full-System Simulation with Detailed Modeling of
  All SSD Resources","  SSDs become a major storage component in modern memory hierarchies, and SSD
research demands exploring future simulation-based studies by integrating SSD
subsystems into a full-system environment. However, several challenges exist to
model SSDs under a full-system simulations; SSDs are composed upon their own
complete system and architecture, which employ all necessary hardware, such as
CPUs, DRAM and interconnect network. Employing the hardware components, SSDs
also require to have multiple device controllers, internal caches and software
modules that respect a wide spectrum of storage interfaces and protocols. These
SSD hardware and software are all necessary to incarnate storage subsystems
under full-system environment, which can operate in parallel with the host
system. In this work, we introduce a new SSD simulation framework, SimpleSSD
2.0, namely Amber, that models embedded CPU cores, DRAMs, and various flash
technologies (within an SSD), and operate under the full system simulation
environment by enabling a data transfer emulation. Amber also includes full
firmware stack, including DRAM cache logic, flash firmware, such as FTL and
HIL, and obey diverse standard protocols by revising the host DMA engines and
system buses of a popular full system simulator's all functional and timing CPU
models (gem5). The proposed simulator can capture the details of dynamic
performance and power of embedded cores, DRAMs, firmware and flash under the
executions of various OS systems and hardware platforms. Using Amber, we
characterize several system-level challenges by simulating different types of
fullsystems, such as mobile devices and general-purpose computers, and offer
comprehensive analyses by comparing passive storage and active storage
architectures.
"
1096,On the complexity of cache analysis for different replacement policies,"  Modern processors use cache memory: a memory access that ""hits"" the cache
returns early, while a ""miss"" takes more time. Given a memory access in a
program, cache analysis consists in deciding whether this access is always a
hit, always a miss, or is a hit or a miss depending on execution. Such an
analysis is of high importance for bounding the worst-case execution time of
safety-critical real-time programs.There exist multiple possible policies for
evicting old data from the cache when new data are brought in, and different
policies, though apparently similar in goals and performance, may be very
different from the analysis point of view. In this paper, we explore these
differences from a complexity-theoretical point of view. Specifically, we show
that, among the common replacement policies, LRU (Least Recently Used) is the
only one whose analysis is NP-complete, whereas the analysis problems for the
other policies are PSPACE-complete.
"
1097,Top-Down Transaction-Level Design with TL-Verilog,"  Transaction-Level Verilog (TL-Verilog) is an emerging extension to
SystemVerilog that supports a new design methodology, called transaction-level
design. A transaction, in this methodology, is an entity that moves through
structures like pipelines, arbiters, and queues, A transaction might be a
machine instruction, a flit of a packet, or a memory read/write. Transaction
logic, like packet header decode or instruction execution, that operates on the
transaction can be placed anywhere along the transaction's flow. Tools produce
the logic to carry signals through their flows to stitch the transaction logic.
  We implemented a small library of TL-Verilog flow components, and we
illustrate the use of these components in a top-down design methodology. We
construct a hypothetical microarchitecture simply by instantiating components.
Within the flows created by these components, we add combinational transaction
logic, enabling verification activities and performance evaluation to begin. We
then refine the model by positioning the transaction logic within its flow to
produce a high-quality register-transfer-level (RTL) implementation.
"
1098,SCALE-Sim: Systolic CNN Accelerator Simulator,"  Systolic Arrays are one of the most popular compute substrates within Deep
Learning accelerators today, as they provide extremely high efficiency for
running dense matrix multiplications. However, the research community lacks
tools to insights on both the design trade-offs and efficient mapping
strategies for systolic-array based accelerators. We introduce Systolic CNN
Accelerator Simulator (SCALE-Sim), which is a configurable systolic array based
cycle accurate DNN accelerator simulator. SCALE-Sim exposes various
micro-architectural features as well as system integration parameters to the
designer to enable comprehensive design space exploration. This is the first
systolic-array simulator tuned for running DNNs to the best of our knowledge.
Using SCALE-Sim, we conduct a suite of case studies and demonstrate the effect
of bandwidth, data flow and aspect ratio on the overall runtime and energy of
Deep Learning kernels across vision, speech, text, and games. We believe that
these insights will be highly beneficial to architects and ML practitioners.
"
1099,MGSim + MGMark: A Framework for Multi-GPU System Research,"  The rapidly growing popularity and scale of data-parallel workloads demand a
corresponding increase in raw computational power of GPUs (Graphics Processing
Units). As single-GPU systems struggle to satisfy the performance demands,
multi-GPU systems have begun to dominate the high-performance computing world.
The advent of such systems raises a number of design challenges, including the
GPU microarchitecture, multi-GPU interconnect fabrics, runtime libraries and
associated programming models. The research community currently lacks a
publically available and comprehensive multi-GPU simulation framework and
benchmark suite to evaluate multi-GPU system design solutions.
  In this work, we present MGSim, a cycle-accurate, extensively validated,
multi-GPU simulator, based on AMD's Graphics Core Next 3 (GCN3) instruction set
architecture. We complement MGSim with MGMark, a suite of multi-GPU workloads
that explores multi-GPU collaborative execution patterns. Our simulator is
scalable and comes with in-built support for multi-threaded execution to enable
fast and efficient simulations. In terms of performance accuracy, MGSim differs
$5.5\%$ on average when compared against actual GPU hardware. We also achieve a
$3.5\times$ and a $2.5\times$ average speedup in function emulation and
architectural simulation with 4 CPU cores, while delivering the same accuracy
as the serial simulation.
  We illustrate the novel simulation capabilities provided by our simulator
through a case study exploring programming models based on a unified multi-GPU
system (U-MGPU) and a discrete multi-GPU system (D-MGPU) that both utilize
unified memory space and cross-GPU memory access. We evaluate the design
implications from our case study, suggesting that D-MGPU is an attractive
programming model for future multi-GPU systems.
"
1100,"Hardware-Efficient Structure of the Accelerating Module for
  Implementation of Convolutional Neural Network Basic Operation","  This paper presents a structural design of the hardware-efficient module for
implementation of convolution neural network (CNN) basic operation with reduced
implementation complexity. For this purpose we utilize some modification of the
Winograd minimal filtering method as well as computation vectorization
principles. This module calculate inner products of two consecutive segments of
the original data sequence, formed by a sliding window of length 3, with the
elements of a filter impulse response. The fully parallel structure of the
module for calculating these two inner products, based on the implementation of
a naive method of calculation, requires 6 binary multipliers and 4 binary
adders. The use of the Winograd minimal filtering method allows to construct a
module structure that requires only 4 binary multipliers and 8 binary adders.
Since a high-performance convolutional neural network can contain tens or even
hundreds of such modules, such a reduction can have a significant effect.
"
1101,"A Microprocessor implemented in 65nm CMOS with Configurable and
  Bit-scalable Accelerator for Programmable In-memory Computing","  This paper presents a programmable in-memory-computing processor,
demonstrated in a 65nm CMOS technology. For data-centric workloads, such as
deep neural networks, data movement often dominates when implemented with
today's computing architectures. This has motivated spatial architectures,
where the arrangement of data-storage and compute hardware is distributed and
explicitly aligned to the computation dataflow, most notably for matrix-vector
multiplication. In-memory computing is a spatial architecture where processing
elements correspond to dense bit cells, providing local storage and compute,
typically employing analog operation. Though this raises the potential for high
energy efficiency and throughput, analog operation has significantly limited
robustness, scale, and programmability. This paper describes a 590kb
in-memory-computing accelerator integrated in a programmable processor
architecture, by exploiting recent approaches to charge-domain in-memory
computing. The architecture takes the approach of tight coupling with an
embedded CPU, through accelerator interfaces enabling integration in the
standard processor memory space. Additionally, a near-memory-computing datapath
both enables diverse computations locally, to address operations required
across applications, and enables bit-precision scalability for
matrix/input-vector elements, through a bit-parallel/bit-serial (BP/BS) scheme.
Chip measurements show an energy efficiency of 152/297 1b-TOPS/W and throughput
of 4.7/1.9 1b-TOPS (scaling linearly with the matrix/input-vector element
precisions) at VDD of 1.2/0.85V. Neural network demonstrations with 1-b/4-b
weights and activations for CIFAR-10 classification consume 5.3/105.2
$\mu$J/image at 176/23 fps, with accuracy at the level of digital/software
implementation (89.3/92.4 $\%$ accuracy).
"
1102,"Packing Sparse Convolutional Neural Networks for Efficient Systolic
  Array Implementations: Column Combining Under Joint Optimization","  This paper describes a novel approach of packing sparse convolutional neural
networks for their efficient systolic array implementations. By combining
subsets of columns in the original filter matrix associated with a
convolutional layer, we increase the utilization efficiency of the systolic
array substantially (e.g., ~4x) due to the increased density of nonzeros in the
resulting packed filter matrix. In combining columns, for each row, all filter
weights but one with the largest magnitude are pruned. We retrain the remaining
weights to preserve high accuracy. We demonstrate that in mitigating data
privacy concerns the retraining can be accomplished with only fractions of the
original dataset (e.g., 10\% for CIFAR-10). We study the effectiveness of this
joint optimization for both high utilization and classification accuracy with
ASIC and FPGA designs based on efficient bit-serial implementations of
multiplier-accumulators. We present analysis and empirical evidence on the
superior performance of our column combining approach against prior arts under
metrics such as energy efficiency (3x) and inference latency (12x).
"
1103,"Tetris: Re-architecting Convolutional Neural Network Computation for
  Machine Learning Accelerators","  Inference efficiency is the predominant consideration in designing deep
learning accelerators. Previous work mainly focuses on skipping zero values to
deal with remarkable ineffectual computation, while zero bits in non-zero
values, as another major source of ineffectual computation, is often ignored.
The reason lies on the difficulty of extracting essential bits during operating
multiply-and-accumulate (MAC) in the processing element. Based on the fact that
zero bits occupy as high as 68.9% fraction in the overall weights of modern
deep convolutional neural network models, this paper firstly proposes a weight
kneading technique that could eliminate ineffectual computation caused by
either zero value weights or zero bits in non-zero weights, simultaneously.
Besides, a split-and-accumulate (SAC) computing pattern in replacement of
conventional MAC, as well as the corresponding hardware accelerator design
called Tetris are proposed to support weight kneading at the hardware level.
Experimental results prove that Tetris could speed up inference up to 1.50x,
and improve power efficiency up to 5.33x compared with the state-of-the-art
baselines.
"
1104,"Architectural-Space Exploration of Heterogeneous Reliability and
  Checkpointing Modes for Out-of-Order Superscalar Processors","  Reliability has emerged as a key topic of interest for researchers around the
world to detect and/or mitigate the side effects of decreasing transistor
sizes, such as soft errors. Traditional solutions, like DMR and TMR, incur
significant area and power overheads, which might not always be applicable due
to power restrictions. Therefore, we investigate alternative heterogeneous
reliability modes that can be activated at run-time based on the system
requirements, while reducing the power and area overheads of the processor. Our
heterogeneous reliability modes are successful in reducing the processor
vulnerability by 87% on average, with area and power overheads of 10% and 43%,
respectively. To further enhance the design space of heterogeneous reliability,
we investigate combinations of efficient compression techniques like
Distributed Multi-threaded Checkpointing, Hash-based Incremental Checkpointing,
and GNU zip, to reduce the storage requirements of data that are backed-up at
an application checkpoint. We have successfully reduced checkpoint sizes by a
factor ~6x by combining various state compression techniques. We use gem5 to
implement and simulate the state compression techniques and the heterogeneous
reliability modes discussed in this paper.
"
1105,"JuxtaPiton: Enabling Heterogeneous-ISA Research with RISC-V and SPARC
  FPGA Soft-cores","  Energy efficiency has become an increasingly important concern in computer
architecture due to the end of Dennard scaling. Heterogeneity has been explored
as a way to achieve better energy efficiency and heterogeneous
microarchitecture chips have become common in the mobile setting.
  Recent research has explored using heterogeneous-ISA, heterogeneous
microarchitecture, general-purpose cores to achieve further energy efficiency
gains. However, there is no open-source hardware implementation of a
heterogeneous-ISA processor available for research, and effective research on
heterogeneous-ISA processors necessitates the emulation speed provided by FPGA
prototyping. This work describes our experiences creating JuxtaPiton by
integrating a small RISC-V core into the OpenPiton framework, which uses a
modified OpenSPARC T1 core. This is the first time a new core has been
integrated with the OpenPiton framework, and JuxtaPiton is the first
open-source, general-purpose, heterogeneous-ISA processor. JuxtaPiton inherits
all the capabilities of OpenPiton, including vital FPGA emulation
infrastructure which can boot full-stack Debian Linux. Using this
infrastructure, we investigate area and timing effects of using the new RISC-V
core on FPGA and the performance of the new core running microbenchmarks.
"
1106,Modeling Deep Learning Accelerator Enabled GPUs,"  The efficacy of deep learning has resulted in its use in a growing number of
applications. The Volta graphics processor unit (GPU) architecture from NVIDIA
introduced a specialized functional unit, the ""tensor core"", that helps meet
the growing demand for higher performance for deep learning. In this paper we
study the design of the tensor cores in NVIDIA's Volta and Turing
architectures. We further propose an architectural model for the tensor cores
in Volta. When implemented a GPU simulator, GPGPU-Sim, our tensor core model
achieves 99.6\% correlation versus an NVIDIA Titan~V GPU in terms of average
instructions per cycle when running tensor core enabled GEMM workloads. We also
describe support added to enable GPGPU-Sim to run CUTLASS, an open-source CUDA
C++ template library providing customizable GEMM templates that utilize tensor
cores.
"
1107,Design paradigms of intelligent control systems on a chip,"  This paper focuses on the Field Programmable Gate Array (FPGA) design and
implementation of intelligent control system applications on a chip,
specifically fuzzy logic and genetic algorithm processing units. Initially, an
overview of the FPGA technology is presented, followed by design methodologies,
development tools and the use of hardware description languages (HDL). Two FPGA
design examples with the use of Hardware Description Languages (HDLs) of
parameterized fuzzy logic controller cores are discussed. Thereinafter, a
System-on-a-Chip (SoC) designed by the authors in previous work and realized on
FPGA featuring a Digital Fuzzy Logic Controller (DFLC) and a soft processor
core for the path tracking problem of mobile robots is discussed. Finally a
Genetic Algorithm implementation (previously published by the authors) in FPGA
chip for the Traveling Salesman Problem (TSP) is also discussed.
"
1108,"Ultra-Low Power Crypto-Engine Based on Simon 32/64 for Energy- and
  Area-Constrained Integrated Systems","  This paper proposes an ultra-low power crypto-engine achieving sub-pJ/bit
energy and sub-1K$\mu$$m^2$ in 40nm CMOS, based on the Simon cryptographic
algorithm. Energy and area efficiency are pursued via microarchitectural
exploration, ultra-low voltage operation with high resiliency via latch-based
pipelines, and power reduction techniques via multi-bit sequential elements.
Overall, the comparison with the state of the art shows best-in-class energy
efficiency and area. This makes it well suited for ubiquitous security in
tightly-constrained platforms, e.g. RFIDs, low-end sensor nodes.
"
1109,"Synetgy: Algorithm-hardware Co-design for ConvNet Accelerators on
  Embedded FPGAs","  Using FPGAs to accelerate ConvNets has attracted significant attention in
recent years. However, FPGA accelerator design has not leveraged the latest
progress of ConvNets. As a result, the key application characteristics such as
frames-per-second (FPS) are ignored in favor of simply counting GOPs, and
results on accuracy, which is critical to application success, are often not
even reported. In this work, we adopt an algorithm-hardware co-design approach
to develop a ConvNet accelerator called Synetgy and a novel ConvNet model
called DiracDeltaNet$^{\dagger}$. Both the accelerator and ConvNet are tailored
to FPGA requirements. DiracDeltaNet, as the name suggests, is a ConvNet with
only $1\times 1$ convolutions while spatial convolutions are replaced by more
efficient shift operations. DiracDeltaNet achieves competitive accuracy on
ImageNet (88.7\% top-5), but with 42$\times$ fewer parameters and 48$\times$
fewer OPs than VGG16. We further quantize DiracDeltaNet's weights to 4-bit and
activations to 4-bits, with less than 1\% accuracy loss. These quantizations
exploit well the nature of FPGA hardware. In short, DiracDeltaNet's small model
size, low computational OP count, low precision and simplified operators allow
us to co-design a highly customized computing unit for an FPGA. We implement
the computing units for DiracDeltaNet on an Ultra96 SoC system through
high-level synthesis. Our accelerator's final top-5 accuracy of 88.1\% on
ImageNet, is higher than all the previously reported embedded FPGA
accelerators. In addition, the accelerator reaches an inference speed of 66.3
FPS on the ImageNet classification task, surpassing prior works with similar
accuracy by at least 11.6$\times$.
"
1110,"CapsAcc: An Efficient Hardware Accelerator for CapsuleNets with Data
  Reuse","  Deep Neural Networks (DNNs) have been widely deployed for many Machine
Learning applications. Recently, CapsuleNets have overtaken traditional DNNs,
because of their improved generalization ability due to the multi-dimensional
capsules, in contrast to the single-dimensional neurons. Consequently,
CapsuleNets also require extremely intense matrix computations, making it a
gigantic challenge to achieve high performance. In this paper, we propose
CapsAcc, the first specialized CMOS-based hardware architecture to perform
CapsuleNets inference with high performance and energy efficiency.
State-of-the-art convolutional DNN accelerators would not work efficiently for
CapsuleNets, as their designs do not account for key operations involved in
CapsuleNets, like squashing and dynamic routing, as well as multi-dimensional
matrix processing. Our CapsAcc architecture targets this problem and achieves
significant improvements, when compared to an optimized GPU implementation. Our
architecture exploits the massive parallelism by flexibly feeding the data to a
specialized systolic array according to the operations required in different
layers. It also avoids extensive load and store operations on the on-chip
memory, by reusing the data when possible. We further optimize the routing
algorithm to reduce the computations needed at this stage. We synthesized the
complete CapsAcc architecture in a 32nm CMOS technology using Synopsys design
tools, and evaluated it for the MNIST benchmark (as also done by the original
CapsuleNet paper) to ensure consistent and fair comparisons. This work enables
highly-efficient CapsuleNets inference on embedded platforms.
"
1111,"Building the Case for Temperature Awareness in Energy Consumption
  Models: an Application of the Energy-Frequency Convexity Rule","  Optimizing computing and communication systems that host energy-critical
applications is becoming a key issue for software developers. In previous work,
we introduced and validated the Energy/Frequency Convexity Rule for CPU-bound
benchmarks on recent ARM platforms. This rule states that there exists an
optimal clock frequency that minimizes the CPU's energy consumption for
non-performance-critical programs. We showed that the Energy/Frequency
Convexity Rule is related to the non-linearity of power with respect to
frequency and is not dependent on the supply voltage.
  Here, we discuss the application of an analytical energy consumption model
proposed previously to our target board, a TI AM572x EVM. We show that this
non-linear analytical model can, for our experimental settings, be approximated
by a frequency-linear variant, as our voltage is maintained constant. This,
however, does not fit the measurements on the board, suggesting that a
parameter is currently missing in the analytical model. We conjecture that
accounting for temperature in the model would yield more accurate results that
are in-line with our measurements. This builds the case for the inclusion of
this important parameter in our energy models.
"
1112,Hyperdimensional Computing Nanosystem,"  One viable solution for continuous reduction in energy-per-operation is to
rethink functionality to cope with uncertainty by adopting computational
approaches that are inherently robust to uncertainty. It requires a novel look
at data representations, associated operations, and circuits, and at materials
and substrates that enable them. 3D integrated nanotechnologies combined with
novel brain-inspired computational paradigms that support fast learning and
fault tolerance could lead the way. Recognizing the very size of the brain's
circuits, hyperdimensional (HD) computing can model neural activity patterns
with points in a HD space, that is, with hypervectors as large randomly
generated patterns. At its very core, HD computing is about manipulating and
comparing these patterns inside memory. Emerging nanotechnologies such as
carbon nanotube field effect transistors (CNFETs) and resistive RAM (RRAM), and
their monolithic 3D integration offer opportunities for hardware
implementations of HD computing through tight integration of logic and memory,
energy-efficient computation, and unique device characteristics. We
experimentally demonstrate and characterize an end-to-end HD computing
nanosystem built using monolithic 3D integration of CNFETs and RRAM. With our
nanosystem, we experimentally demonstrate classification of 21 languages with
measured accuracy of up to 98% on >20,000 sentences (6.4 million characters),
training using one text sample (~100,000 characters) per language, and
resilient operation (98% accuracy) despite 78% hardware errors in HD
representation (outputs stuck at 0 or 1). By exploiting the unique properties
of the underlying nanotechnologies, we show that HD computing, when implemented
with monolithic 3D integration, can be up to 420X more energy-efficient while
using 25X less area compared to traditional silicon CMOS implementations.
"
1113,"Formally Verifying WARP-V, an Open-Source TL-Verilog RISC-V Core
  Generator","  Timing-abstract and transaction-level design using TL-Verilog have shown
significant productivity gains for logic design. In this work, we explored the
natural extension of transaction-level design methodology into formal
verification.
  WARP-V is a CPU core generator written in TL-Verilog. Our primary
verification vehicle for WARP-V was a formal verification framework for RISC-V,
called riscv-formal. The timing-abstract and transaction-level logic modeling
techniques of TL-Verilog greatly simplified the task of creating a harness
connecting the WARP-V model to the verification interface of riscv-formal.
Furthermore, the same harness works across all RISC-V configurations of WARP-V.
"
1114,"NTX: An Energy-efficient Streaming Accelerator for Floating-point
  Generalized Reduction Workloads in 22nm FD-SOI","  Specialized coprocessors for Multiply-Accumulate (MAC) intensive workloads
such as Deep Learning are becoming widespread in SoC platforms, from GPUs to
mobile SoCs. In this paper we revisit NTX (an efficient accelerator developed
for training Deep Neural Networks at scale) as a generalized MAC and reduction
streaming engine. The architecture consists of a set of 32 bit floating-point
streaming co-processors that are loosely coupled to a RISC-V core in charge of
orchestrating data movement and computation. Post-layout results of a recent
silicon implementation in 22 nm FD-SOI technology show the accelerator's
capability to deliver up to 20 Gflop/s at 1.25 GHz and 168 mW. Based on these
results we show that a version of NTX scaled down to 14 nm can achieve a 3x
energy efficiency improvement over contemporary GPUs at 10.4x less silicon
area, and a compute performance of 1.4 Tflop/s for training large
state-of-the-art networks with full floating-point precision. An extended
evaluation of MAC-intensive kernels shows that NTX can consistently achieve up
to 87% of its peak performance across general reduction workloads beyond
machine learning. Its modular architecture enables deployment at different
scales ranging from high-performance GPU-class to low-power embedded scenarios.
"
1115,Repairability Enhancement of Scalable Systems with Locally Shared Spares,"  Future systems based on nano-scale devices will provide great potentials for
scaling up in system complexity, yet they will be highly susceptible to
operational faults. While spare units can be generally used to enhance
reliability, they must be shared in a limited way among functional units to
ensure low-cost overheads when systems scale up. Furthermore, the efficiency of
achieving reliability using spare units heavily depends on the replacement
mechanisms of such spares. While global and chained replacement approaches can
take advantage of the entire replacement capabilities in the network, they
usually impose some sort of disturbance to all the functional units in the
system during the repair process, thus are dreadfully expensive in terms of
performance overhead for systems with high fault rates. In this paper, we focus
on a low-cost, fast, immediate replacement mechanism that can be implemented
locally with minimum disturbance to the system. The proposed schemes aim for
maintaining the system with high fault rates in such a low-cost, fast
repairable status for many faults before invoking the more expensive, yet
optimal, approaches. First, we propose an online repair algorithm: as faults
occur during the run-time of the system, the proposed algorithm makes a choice
of a spare unit (among several candidates), such that the overall impact on
system repairability in the future is minimized. Second, we propose a network
enhancement approach, which identifies and connects the vulnerable units to the
exploitable spares, thus strengthening the entire system at a low cost.
"
1116,"TrojanZero: Switching Activity-Aware Design of Undetectable Hardware
  Trojans with Zero Power and Area Footprint","  Conventional Hardware Trojan (HT) detection techniques are based on the
validation of integrated circuits to determine changes in their functionality,
and on non-invasive side-channel analysis to identify the variations in their
physical parameters. In particular, almost all the proposed side-channel
power-based detection techniques presume that HTs are detectable because they
only add gates to the original circuit with a noticeable increase in power
consumption. This paper demonstrates how undetectable HTs can be realized with
zero impact on the power and area footprint of the original circuit. Towards
this, we propose a novel concept of TrojanZero and a systematic methodology for
designing undetectable HTs in the circuits, which conceals their existence by
gate-level modifications. The crux is to salvage the cost of the HT from the
original circuit without being detected using standard testing techniques. Our
methodology leverages the knowledge of transition probabilities of the circuit
nodes to identify and safely remove expendable gates, and embeds malicious
circuitry at the appropriate locations with zero power and area overheads when
compared to the original circuit. We synthesize these designs and then embed in
multiple ISCAS85 benchmarks using a 65nm technology library, and perform a
comprehensive power and area characterization. Our experimental results
demonstrate that the proposed TrojanZero designs are undetectable by the
state-of-the-art power-based detection methods.
"
1117,Real-time Closed Loop Neural Decoding on a Neuromorphic Chip,"  This paper presents for the first time a real-time closed loop neuromorphic
decoder chip-driven intra-cortical brain machine interface (iBMI) in a
non-human primate (NHP) based experimental setup. Decoded results show trial
success rates and mean times to target comparable to those obtained by
hand-controlled joystick. Neural control trial success rates of approximately
96% of those obtained by hand-controlled joystick have been demonstrated. Also,
neural control has shown mean target reach speeds of approximately 85% of those
obtained by hand-controlled joystick . These results pave the way for fast and
accurate, fully implantable neuromorphic neural decoders in iBMIs.
"
1118,An Efficient Hybrid I/O Caching Architecture Using Heterogeneous SSDs,"  SSDs are emerging storage devices which unlike HDDs, do not have mechanical
parts and therefore, have superior performance compared to HDDs. Due to the
high cost of SSDs, entirely replacing HDDs with SSDs is not economically
justified. Additionally, SSDs can endure a limited number of writes before
failing. To mitigate the shortcomings of SSDs while taking advantage of their
high performance, SSD caching is practiced in both academia and industry.
Previously proposed caching architectures have only focused on either
performance or endurance and neglected to address both parameters in suggested
architectures. Moreover, the cost, reliability, and power consumption of such
architectures is not evaluated. This paper proposes a hybrid I/O caching
architecture that while offers higher performance than previous studies, it
also improves power consumption with a similar budget. The proposed
architecture uses DRAM, Read-Optimized SSD, and Write-Optimized SSD in a
three-level cache hierarchy and tries to efficiently redirect read requests to
either DRAM or RO-SSD while sending writes to WO-SSD. To provide high
reliability, dirty pages are written to at least two devices which removes any
single point of failure. The power consumption is also managed by reducing the
number of accesses issued to SSDs. The proposed architecture reconfigures
itself between performance- and endurance-optimized policies based on the
workload characteristics to maintain an effective tradeoff between performance
and endurance. We have implemented the proposed architecture on a server
equipped with industrial SSDs and HDDs. The experimental results show that as
compared to state-of-the-art studies, the proposed architecture improves
performance and power consumption by an average of 8% and 28%, respectively,
and reduces the cost by 5% while increasing the endurance cost by 4.7% and
negligible reliability penalty.
"
1119,"R3-DLA (Reduce, Reuse, Recycle): A More Efficient Approach to Decoupled
  Look-Ahead Architectures","  Modern societies have developed insatiable demands for more computation
capabilities. Exploiting implicit parallelism to provide automatic performance
improvement remains a central goal in engineering future general-purpose
computing systems. One approach is to use a separate thread context to perform
continuous look-ahead to improve the data and instruction supply to the main
pipeline. Such a decoupled look-ahead (DLA) architecture can be quite effective
in accelerating a broad range of applications in a relatively straightforward
implementation. It also has broad design flexibility as the look-ahead agent
need not be concerned with correctness constraints. In this paper, we explore a
number of optimizations that make the look-ahead agent more efficient and yet
extract more utility from it. With these optimizations, a DLA architecture can
achieve an average speedup of 1.4 over a state-of-the-art microarchitecture for
a broad set of benchmark suites, making it a powerful tool to enhance
single-thread performance.
"
1120,"ForASec: Formal Analysis of Security Vulnerabilities in Sequential
  Circuits","  Security vulnerability analysis of Integrated Circuits using conventional
design-time validation and verification techniques (like simulations,
emulations, etc.) is generally a computationally intensive task and incomplete
by nature, especially under limited resources and time constraints. To overcome
this limitation, we propose a novel methodology based on model checking to
formally analyze security vulnerabilities in sequential circuits while
considering side-channel parameters like propagation delay, switching power,
and leakage power. In particular, we present a novel algorithm to efficiently
partition the state-space into corresponding smaller state-spaces to enable
distributed security analysis of complex sequential circuits and thereby
mitigating the associated state-space explosion due to their feedback loops. We
analyze multiple ISCAS89 and trust-hub benchmarks to demonstrate the efficacy
of our framework in identifying security vulnerabilities. The experimental
results show that ForASec successfully performs the complete analysis of the
given complex and large sequential circuits, and provides approximately 11x to
16x speedup in analysis time compared to state-of-the-art model checking-based
techniques. Moreover, it also identifies the number of gates required by an HT
that can go undetected for a given design and variability conditions.
"
1121,Evaluating Row Buffer Locality in Future Non-Volatile Main Memories,"  DRAM-based main memories have read operations that destroy the read data, and
as a result, must buffer large amounts of data on each array access to keep
chip costs low. Unfortunately, system-level trends such as increased memory
contention in multi-core architectures and data mapping schemes that improve
memory parallelism may cause only a small amount of the buffered data to be
accessed. This makes buffering large amounts of data on every memory array
access energy-inefficient.
  Emerging non-volatile memories (NVMs) such as PCM, STT-RAM, and RRAM,
however, do not have destructive read operations, opening up opportunities for
employing small row buffers without incurring additional area penalty and/or
design complexity.
  In this work, we discuss architectural changes to enable small row buffers at
a low cost in NVMs. We provide a memory access protocol, energy model, and
timing model to enable further system-level evaluation. We evaluate the
system-level tradeoffs of employing different row buffer sizes in NVM main
memories in terms of energy, performance, and endurance, with different data
mapping schemes. We find that on a multi-core CMP system, reducing the row
buffer size can greatly reduce main memory dynamic energy compared to a DRAM
baseline with large row sizes, without greatly affecting endurance, and for
some memories, leads to improved performance.
"
1122,Rapid Cycle-Accurate Simulator for High-Level Synthesis,"  A large semantic gap between the high-level synthesis (HLS) design and the
low-level (on-board or RTL) simulation environment often creates a barrier for
those who are not FPGA experts. Moreover, such low-level simulation takes a
long time to complete. Software-based HLS simulators can help bridge this gap
and accelerate the simulation process; however, we found that the current FPGA
HLS commercial software simulators sometimes produce incorrect results. In
order to solve this correctness issue while maintaining the high speed of a
software-based simulator, this paper proposes a new HLS simulation flow named
FLASH. The main idea behind the proposed flow is to extract the scheduling
information from the HLS tool and automatically construct an equivalent
cycle-accurate simulation model while preserving C semantics. Experimental
results show that FLASH runs three orders of magnitude faster than the RTL
simulation.
"
1123,"Digital Neuron: A Hardware Inference Accelerator for Convolutional Deep
  Neural Networks","  We propose a Digital Neuron, a hardware inference accelerator for
convolutional deep neural networks with integer inputs and integer weights for
embedded systems. The main idea to reduce circuit area and power consumption is
manipulating dot products between input feature and weight vectors by Barrel
shifters and parallel adders. The reduced area allows the more computational
engines to be mounted on an inference accelerator, resulting in high throughput
compared to prior HW accelerators. We verified that the multiplication of
integer numbers with 3-partial sub-integers does not cause significant loss of
inference accuracy compared to 32-bit floating point calculation. The proposed
digital neuron can perform 800 MAC operations in one clock for computation for
convolution as well as full-connection. This paper provides a scheme that
reuses input, weight, and output of all layers to reduce DRAM access. In
addition, this paper proposes a configurable architecture that can provide
inference of adaptable feature of convolutional neural networks. The throughput
in terms of Watt of the digital neuron is achieved 754.7 GMACs/W.
"
1124,"RNNFast: An Accelerator for Recurrent Neural Networks Using Domain Wall
  Memory","  Recurrent Neural Networks (RNNs) are an important class of neural networks
designed to retain and incorporate context into current decisions. RNNs are
particularly well suited for machine learning problems in which context is
important, such as speech recognition and language translation. This work
presents RNNFast, a hardware accelerator for RNNs that leverages an emerging
class of non-volatile memory called domain-wall memory (DWM). We show that DWM
is very well suited for RNN acceleration due to its very high density and low
read/write energy. At the same time, the sequential nature of input/weight
processing of RNNs mitigates one of the downsides of DWM, which is the linear
(rather than constant) data access time.RNNFast is very efficient and highly
scalable, with flexible mapping of logical neurons to RNN hardware blocks. The
basic hardware primitive, the RNN processing element (PE) includes custom
DWM-based multiplication, sigmoid and tanh units for high density and
low-energy. The accelerator is designed to minimize data movement by closely
interleaving DWM storage and computation. We compare our design with a
state-of-the-art GPGPU and find21.8x higher performance with70x lower energy
"
1125,Computational RAM to Accelerate String Matching at Scale,"  Traditional Von Neumann computing is falling apart in the era of exploding
data volumes as the overhead of data transfer becomes forbidding. Instead, it
is more energy-efficient to fuse compute capability with memory where the data
reside. This is particularly critical for pattern matching, a key computational
step in large-scale data analytics, which involves repetitive search over very
large databases residing in memory. Emerging spintronic technologies show
remarkable versatility for the tight integration of logic and memory. In this
paper, we introduce CRAM-PM, a novel high-density, reconfigurable spintronic
in-memory compute substrate for pattern matching.
"
1126,A Complexity Reduction Method for Successive Cancellation List Decoding,"  This brief introduces a hardware complexity reduction method for successive
cancellation list (SCL) decoders. Specifically, we propose to use a sorting
scheme so that L paths with smallest path metrics are also sorted according to
their path indexes for path pruning. We prove that such sorting scheme reduces
the input number of multiplexers in any hardware implementation of SCL decoding
from L to (L/2+1) without any changes in the decoding latency. We also propose
sorter architectures for the proposed sorting method. Field programmable gate
array (FPGA) implementations show that the proposed method achieves significant
gain in hardware consumptions of SCL decoder implementations, especially for
large list sizes and block lengths.
"
1127,"A 256kb 9T Near-Threshold SRAM With 1k Cells per Bit-Line and Enhanced
  Write and Read Operations","  In this paper, we present a new 9T SRAM cell that has good write-ability and
improves read stability at the same time. Simulation results show that the
proposed design increases Read SNM (RSNM) and Ion/Ioff of read path by 219% and
113%, respectively at supply voltage of 300mV over conventional 6T SRAM cell in
a 90nm CMOS technology. Proposed design lets us to reduce minimum operating
voltage of SRAM (VDDmin) to 350mV, whereas conventional 6T SRAM cannot operate
successfully with acceptable failure rate at supply voltages bellow 725mV. We
also compared our design with three other SRAM cells from recent literature. To
verify the proposed design, a 256kb SRAM is designed using new 9T and
conventional 6T SRAM cells. Operating at their minimum possible VDDs, the
proposed design decreases write and read power per operation by 92%, and 93%,
respectively over the conventional rival. Area of proposed SRAM cell is
increased by 83% over conventional 6T one. However, due to large Ion/Ioff of
read path for 9T cell, we are able to put 1k cells in each column of 256kb SRAM
block, resulting in the possibility for sharing write and read circuitries of
each column between more cells compared to conventional 6T. Thus, area overhead
of 256kb SRAM based on new 9T cell is reduced to 37% compared to 6T SRAM.
"
1128,"ADMM-NN: An Algorithm-Hardware Co-Design Framework of DNNs Using
  Alternating Direction Method of Multipliers","  To facilitate efficient embedded and hardware implementations of deep neural
networks (DNNs), two important categories of DNN model compression techniques:
weight pruning and weight quantization are investigated. The former leverages
the redundancy in the number of weights, whereas the latter leverages the
redundancy in bit representation of weights. However, there lacks a systematic
framework of joint weight pruning and quantization of DNNs, thereby limiting
the available model compression ratio. Moreover, the computation reduction,
energy efficiency improvement, and hardware performance overhead need to be
accounted for besides simply model size reduction.
  To address these limitations, we present ADMM-NN, the first
algorithm-hardware co-optimization framework of DNNs using Alternating
Direction Method of Multipliers (ADMM), a powerful technique to deal with
non-convex optimization problems with possibly combinatorial constraints. The
first part of ADMM-NN is a systematic, joint framework of DNN weight pruning
and quantization using ADMM. It can be understood as a smart regularization
technique with regularization target dynamically updated in each ADMM
iteration, thereby resulting in higher performance in model compression than
prior work. The second part is hardware-aware DNN optimizations to facilitate
hardware-level implementations.
  Without accuracy loss, we can achieve 85$\times$ and 24$\times$ pruning on
LeNet-5 and AlexNet models, respectively, significantly higher than prior work.
The improvement becomes more significant when focusing on computation
reductions. Combining weight pruning and quantization, we achieve 1,910$\times$
and 231$\times$ reductions in overall model size on these two benchmarks, when
focusing on data storage. Highly promising results are also observed on other
representative DNNs such as VGGNet and ResNet-50.
"
1129,High Performance GNR Power Gating for Low-Voltage CMOS Circuits,"  A robust power gating design using Graphene Nano-Ribbon Field Effect
Transistors (GNRFET) is proposed using 16nm technology. The Power Gating (PG)
structure is composed of GNRFET as a power switch and MOS power gated module.
The proposed structure resolves the main drawbacks of the traditional PG design
from the point of view increasing the propagation delay and wake-up time in low
voltage regions. GNRFET/MOSFET Conjunction (GMC) is employed to build various
structures of PG, GMCPG-SS and GMCPG-NS. In addition to exploiting it to build
two multi-mode PG structures. Circuit analysis for CMOS power gated logic
modules ISCAS85 benchmark of 16nm technology is used to evaluate the
performance of the proposed GNR power switch is compared to the traditional MOS
one. Leakage power, wake-up time and power delay product are used as
performance circuit parameters for the evaluation.
"
1130,"FPGA-based Accelerators of Deep Learning Networks for Learning and
  Classification: A Review","  Due to recent advances in digital technologies, and availability of credible
data, an area of artificial intelligence, deep learning, has emerged, and has
demonstrated its ability and effectiveness in solving complex learning problems
not possible before. In particular, convolution neural networks (CNNs) have
demonstrated their effectiveness in image detection and recognition
applications. However, they require intensive CPU operations and memory
bandwidth that make general CPUs fail to achieve desired performance levels.
Consequently, hardware accelerators that use application specific integrated
circuits (ASICs), field programmable gate arrays (FPGAs), and graphic
processing units (GPUs) have been employed to improve the throughput of CNNs.
More precisely, FPGAs have been recently adopted for accelerating the
implementation of deep learning networks due to their ability to maximize
parallelism as well as due to their energy efficiency. In this paper, we review
recent existing techniques for accelerating deep learning networks on FPGAs. We
highlight the key features employed by the various techniques for improving the
acceleration performance. In addition, we provide recommendations for enhancing
the utilization of FPGAs for CNNs acceleration. The techniques investigated in
this paper represent the recent trends in FPGA-based accelerators of deep
learning networks. Thus, this review is expected to direct the future advances
on efficient hardware accelerators and to be useful for deep learning
researchers.
"
1131,Optimizing Bit-Serial Matrix Multiplication for Reconfigurable Computing,"  Matrix-matrix multiplication is a key computational kernel for numerous
applications in science and engineering, with ample parallelism and data
locality that lends itself well to high-performance implementations. Many
matrix multiplication-dependent applications can use reduced-precision integer
or fixed-point representations to increase their performance and energy
efficiency while still offering adequate quality of results. However, precision
requirements may vary between different application phases or depend on input
data, rendering constant-precision solutions ineffective. BISMO, a vectorized
bit-serial matrix multiplication overlay for reconfigurable computing,
previously utilized the excellent binary-operation performance of FPGAs to
offer a matrix multiplication performance that scales with required precision
and parallelism. We show how BISMO can be scaled up on Xilinx FPGAs using an
arithmetic architecture that better utilizes 6-LUTs. The improved BISMO
achieves a peak performance of 15.4 binary TOPS on the Ultra96 board with a
Xilinx UltraScale+ MPSoC.
"
1132,3DCAM: A Low Overhead Crosstalk Avoidance Mechanism for TSV-Based 3D ICs,"  Three Dimensional Integrated Circuits (3D IC) offer lower power consumption,
higher performance, higher bandwidth, and scalability over the conventional two
dimensional ICs. Through-Silicon Via (TSV) is one of the fabrication mechanisms
that connects stacked dies to each other. The large size of TSVs and the
proximity between them lead to undesirable coupling capacitance. This
interference causes mutual influences between adjacent TSVs and produces
crosstalk noise. Furthermore, this effect threats the reliability of data
during traversal between layers. This paper proposes a mechanism that
efficiently reduces crosstalk noise between TSVs with lower area overhead as
compared to previous works. This mechanism revolves around the fact that
retaining TSV value in current state can reduce coupling in some cases. To
evaluate the mechanism, gem5 simulator is used for data extraction and several
benchmarks are taken from the SPEC2006 suite. The simulation results show that
the proposed mechanism reduces crosstalk noise with only 30% imposed TSV
overhead while delay decreased up to 25.7% as compared to a recent related
work.
"
1133,A Secure and Persistent Memory System for Non-volatile Memory,"  In the non-volatile memory, ensuring the security and correctness of
persistent data is fundamental. However, the security and persistence issues
are usually studied independently in existing work. To achieve both data
security and persistence, simply combining existing persistence schemes with
memory encryption is inefficient due to crash inconsistency and significant
performance degradation. To bridge the gap between security and persistence,
this paper proposes SecPM, a Secure and Persistent Memory system, which
consists of a counter cache write-through (CWT) scheme and a locality-aware
counter write reduction (CWR) scheme. Specifically, SecPM leverages the CWT
scheme to guarantee the crash consistency via ensuring both the data and its
counter are durable before the data flush completes, and leverages the CWR
scheme to improve the system performance via exploiting the spatial locality of
counter storage, log and data writes. We have implemented SecPM in gem5 with
NVMain and evaluated it using five widely-used workloads. Extensive
experimental results demonstrate that SecPM reduces up to half of write
requests and speeds up the transaction execution by 1.3-2.0 times via using the
CWR scheme, and achieves the performance close to an un-encrypted persistent
memory system for large transactions.
"
1134,"FPDeep: Scalable Acceleration of CNN Training on Deeply-Pipelined FPGA
  Clusters","  Deep Neural Networks (DNNs) have revolutionized numerous applications, but
the demand for ever more performance remains unabated. Scaling DNN computations
to larger clusters is generally done by distributing tasks in batch mode using
methods such as distributed synchronous SGD. Among the issues with this
approach is that to make the distributed cluster work with high utilization,
the workload distributed to each node must be large, which implies nontrivial
growth in the SGD mini-batch size.
  In this paper, we propose a framework called FPDeep, which uses a hybrid of
model and layer parallelism to configure distributed reconfigurable clusters to
train DNNs. This approach has numerous benefits. First, the design does not
suffer from batch size growth. Second, novel workload and weight partitioning
leads to balanced loads of both among nodes. And third, the entire system is a
fine-grained pipeline. This leads to high parallelism and utilization and also
minimizes the time features need to be cached while waiting for
back-propagation. As a result, storage demand is reduced to the point where
only on-chip memory is used for the convolution layers. We evaluate FPDeep with
the Alexnet, VGG-16, and VGG-19 benchmarks. Experimental results show that
FPDeep has good scalability to a large number of FPGAs, with the limiting
factor being the FPGA-to-FPGA bandwidth. With 6 transceivers per FPGA, FPDeep
shows linearity up to 83 FPGAs. Energy efficiency is evaluated with respect to
GOPs/J. FPDeep provides, on average, 6.36x higher energy efficiency than
comparable GPU servers.
"
1135,"SNRA: A Spintronic Neuromorphic Reconfigurable Array for In-Circuit
  Training and Evaluation of Deep Belief Networks","  In this paper, a spintronic neuromorphic reconfigurable Array (SNRA) is
developed to fuse together power-efficient probabilistic and in-field
programmable deterministic computing during both training and evaluation phases
of restricted Boltzmann machines (RBMs). First, probabilistic spin logic
devices are used to develop an RBM realization which is adapted to construct
deep belief networks (DBNs) having one to three hidden layers of size 10 to 800
neurons each. Second, we design a hardware implementation for the contrastive
divergence (CD) algorithm using a four-state finite state machine capable of
unsupervised training in N+3 clocks where N denotes the number of neurons in
each RBM. The functionality of our proposed CD hardware implementation is
validated using ModelSim simulations. We synthesize the developed Verilog HDL
implementation of our proposed test/train control circuitry for various DBN
topologies where the maximal RBM dimensions yield resource utilization ranging
from 51 to 2,421 lookup tables (LUTs). Next, we leverage spin Hall effect
(SHE)-magnetic tunnel junction (MTJ) based non-volatile LUTs circuits as an
alternative for static random access memory (SRAM)-based LUTs storing the
deterministic logic configuration to form a reconfigurable fabric. Finally, we
compare the performance of our proposed SNRA with SRAM-based configurable
fabrics focusing on the area and power consumption induced by the LUTs used to
implement both CD and evaluation modes. The results obtained indicate more than
80% reduction in combined dynamic and static power dissipation, while achieving
at least 50% reduction in device count.
"
1136,Application-Specific System Processor for the SHA-1 Hash Algorithm,"  This work proposes an Application-Specific System Processor (ASSP) hardware
for the Secure Hash Algorithm 1 (SHA-1) algorithm. The proposed hardware was
implemented in a Field Programmable Gate Array (FPGA) Xilinx Virtex 6
xc6vlx240t-1ff1156. The throughput and the occupied area were analyzed for
several implementations in parallel instances of the hash algorithm. The
results showed that the hardware proposed for the SHA-1 achieved a throughput
of 0.644 Gbps for a single instance and slightly more than 28 Gbps for 48
instances in a single FPGA. Various applications such as password recovery,
password validation, and high volume data integrity checking can be performed
efficiently and quickly with an ASSP for SHA1.
"
1137,"BioSEAL: In-Memory Biological Sequence Alignment Accelerator for
  Large-Scale Genomic Data","  Genome sequences contain hundreds of millions of DNA base pairs. Finding the
degree of similarity between two genomes requires executing a compute-intensive
dynamic programming algorithm, such as Smith-Waterman. Traditional von Neumann
architectures have limited parallelism and cannot provide an efficient solution
for large-scale genomic data. Approximate heuristic methods (e.g. BLAST) are
commonly used. However, they are suboptimal and still compute-intensive. In
this work, we present BioSEAL, a Biological SEquence ALignment accelerator.
BioSEAL is a massively parallel non-von Neumann processing-in-memory
architecture for large-scale DNA and protein sequence alignment. BioSEAL is
based on resistive content addressable memory, capable of energy-efficient and
high-performance associative processing. We present an associative processing
algorithm for entire database sequence alignment on BioSEAL and compare its
performance and power consumption with state-of-art solutions. We show that
BioSEAL can achieve up to 57x speedup and 156x better energy efficiency,
compared with existing solutions for genome sequence alignment and protein
sequence database search.
"
1138,"Asynchronous Early Output Block Carry Lookahead Adder with Improved
  Quality of Results","  A new asynchronous early output block carry lookahead adder (BCLA)
incorporating redundant carries is proposed. Compared to the best of existing
semi-custom asynchronous carry lookahead adders (CLAs) employing
delay-insensitive data encoding and following a 4-phase handshaking, the
proposed BCLA with redundant carries achieves 13% reduction in forward latency
and 14.8% reduction in cycle time compared to the best of the existing CLAs
featuring redundant carries with no area or power penalty. A hybrid variant
involving a ripple carry adder (RCA) in the least significant stages i.e.
BCLA-RCA is also considered that achieves a further 4% reduction in the forward
latency and a 2.4% reduction in the cycle time compared to the proposed BCLA
featuring redundant carries without area or power penalties.
"
1139,Majority and Minority Voted Redundancy for Safety-Critical Applications,"  A new majority and minority voted redundancy (MMR) scheme is proposed that
can provide the same degree of fault tolerance as N-modular redundancy (NMR)
but with fewer function units and a less sophisticated voting logic. Example
NMR and MMR circuits were implemented using a 32/28nm CMOS process and
compared. The results show that MMR circuits dissipate less power, occupy less
area, and encounter less critical path delay than the corresponding NMR
circuits while providing the same degree of fault tolerance. Hence the MMR is a
promising alternative to the NMR to efficiently implement high levels of
redundancy in safety-critical applications.
"
1140,"Eva-CiM: A System-Level Performance and Energy Evaluation Framework for
  Computing-in-Memory Architectures","  Computing-in-Memory (CiM) architectures aim to reduce costly data transfers
by performing arithmetic and logic operations in memory and hence relieve the
pressure due to the memory wall. However, determining whether a given workload
can really benefit from CiM, which memory hierarchy and what device technology
should be adopted by a CiM architecture requires in-depth study that is not
only time consuming but also demands significant expertise in architectures and
compilers. This paper presents an energy evaluation framework, Eva-CiM, for
systems based on CiM architectures. Eva-CiM encompasses a multi-level (from
device to architecture) comprehensive tool chain by leveraging existing
modeling and simulation tools such as GEM5, McPAT [2] and DESTINY [3]. To
support high-confidence prediction, rapid design space exploration and ease of
use, Eva-CiM introduces several novel modeling/analysis approaches including
models for capturing memory access and dependency-aware ISA traces, and for
quantifying interactions between the host CPU and CiM modules. Eva-CiM can
readily produce energy estimates of the entire system for a given program, a
processor architecture, and the CiM array and technology specifications.
Eva-CiM is validated by comparing with DESTINY [3] and [4], and enables
findings including practical contributions from CiM-supported accesses,
CiM-sensitive benchmarking as well as the pros and cons of increased memory
size for CiM. Eva-CiM also enables exploration over different configurations
and device technologies, showing 1.3-6.0X energy improvement for SRAM and
2.0-7.9X for FeFET-RAM, respectively.
"
1141,"PUMA: A Programmable Ultra-efficient Memristor-based Accelerator for
  Machine Learning Inference","  Memristor crossbars are circuits capable of performing analog matrix-vector
multiplications, overcoming the fundamental energy efficiency limitations of
digital logic. They have been shown to be effective in special-purpose
accelerators for a limited set of neural network applications.
  We present the Programmable Ultra-efficient Memristor-based Accelerator
(PUMA) which enhances memristor crossbars with general purpose execution units
to enable the acceleration of a wide variety of Machine Learning (ML) inference
workloads. PUMA's microarchitecture techniques exposed through a specialized
Instruction Set Architecture (ISA) retain the efficiency of in-memory computing
and analog circuitry, without compromising programmability.
  We also present the PUMA compiler which translates high-level code to PUMA
ISA. The compiler partitions the computational graph and optimizes instruction
scheduling and register allocation to generate code for large and complex
workloads to run on thousands of spatial cores.
  We have developed a detailed architecture simulator that incorporates the
functionality, timing, and power models of PUMA's components to evaluate
performance and energy consumption. A PUMA accelerator running at 1 GHz can
reach area and power efficiency of $577~GOPS/s/mm^2$ and $837~GOPS/s/W$,
respectively. Our evaluation of diverse ML applications from image recognition,
machine translation, and language modelling (5M-800M synapses) shows that PUMA
achieves up to $2,446\times$ energy and $66\times$ latency improvement for
inference compared to state-of-the-art GPUs. Compared to an
application-specific memristor-based accelerator, PUMA incurs small energy
overheads at similar inference latency and added programmability.
"
1142,Generic Connectivity-Based CGRA Mapping via Integer Linear Programming,"  Coarse-grained reconfigurable architectures (CGRAs) are programmable logic
devices with large coarse-grained ALU-like logic blocks, and multi-bit
datapath-style routing. CGRAs often have relatively restricted data routing
networks, so they attract CAD mapping tools that use exact methods, such as
Integer Linear Programming (ILP). However, tools that target general
architectures must use large constraint systems to fully describe an
architecture's flexibility, resulting in lengthy run-times. In this paper, we
propose to derive connectivity information from an otherwise generic device
model, and use this to create simpler ILPs, which we combine in an iterative
schedule and retain most of the exactness of a fully-generic ILP approach. This
new approach has a speed-up geometric mean of 5.88x when considering benchmarks
that do not hit a time-limit of 7.5 hours on the fully-generic ILP, and 37.6x
otherwise. This was measured using the set of benchmarks used to originally
evaluate the fully-generic approach and several more benchmarks representing
computation tasks, over three different CGRA architectures. All run-times of
the new approach are less than 20 minutes, with 90th percentile time of 410
seconds. The proposed mapping techniques are integrated into, and evaluated
using the open-source CGRA-ME architecture modelling and exploration framework.
"
1143,"Approximate Logic Synthesis: A Reinforcement Learning-Based Technology
  Mapping Approach","  Approximate Logic Synthesis (ALS) is the process of synthesizing and mapping
a given Boolean network to a library of logic cells so that the magnitude/rate
of error between outputs of the approximate and initial (exact) Boolean
netlists is bounded from above by a predetermined total error threshold. In
this paper, we present Q-ALS, a novel framework for ALS with focus on the
technology mapping phase. Q-ALS incorporates reinforcement learning and
utilizes Boolean difference calculus to estimate the maximum error rate that
each node of the given network can tolerate such that the total error rate at
non of the outputs of the mapped netlist exceeds a predetermined maximum error
rate, and the worst case delay and the total area are minimized. Maximum
Hamming Distance (MHD) between exact and approximate truth tables of cuts of
each node is used as the error metric. In Q-ALS, a Q-Learning agent is trained
with a sufficient number of iterations aiming to select the fittest values of
MHD for each node, and in a cut-based technology mapping approach, the best
supergates (in terms of delay and area, bounded further by the fittest MHD) are
selected towards implementing each node. Experimental results show that having
set the required accuracy of 95% at the primary outputs, Q-ALS reduces the
total cost in terms of area and delay by up to 70% and 36%, respectively, and
also reduces the run-time by 2.21 times on average, when compared to the best
state-of-the-art academic ALS tools.
"
1144,"Hybrid Cell Assignment and Sizing for Power, Area, Delay Product
  Optimization of SRAM Arrays","  Memory accounts for a considerable portion of the total power budget and area
of digital systems. Furthermore, it is typically the performance bottleneck of
the processing units. Therefore, it is critical to optimize the memory with
respect to the product of power, area, and delay (PAD). We propose a hybrid
cell assignment method based on multi-sized and dual-Vth SRAM cells which
improves the PAD cost function by 34% compared to the conventional cell
assignment. We also utilize the sizing of SRAM cells for minimizing the Data
Retention Voltage (DRV), and voltages for the read and write operations in the
SRAM array. Experimental results in a 32nm technology show that combining the
proposed hybrid cell assignment and the cell sizing methods can lower PAD by up
to 41% when compared to the conventional cell design and assignment.
"
1145,"CapStore: Energy-Efficient Design and Management of the On-Chip Memory
  for CapsuleNet Inference Accelerators","  Deep Neural Networks (DNNs) have been established as the state-of-the-art
algorithm for advanced machine learning applications. Recently, CapsuleNets
have improved the generalization ability, as compared to DNNs, due to their
multi-dimensional capsules. However, they pose high computational and memory
requirements, which makes energy-efficient inference a challenging task. In
this paper, we perform an extensive analysis to demonstrate their key
limitations due to intense memory accesses and large on-chip memory
requirements. To enable efficient CaspuleNet inference accelerators, we propose
a specialized on-chip memory hierarchy which minimizes the off-chip memory
accesses, while efficiently feeding the data to the accelerator. We analyze the
on-chip memory requirements for each memory component of the architecture. By
leveraging this analysis, we propose a methodology to explore different on-chip
memory designs and a power-gating technique to further reduce the energy
consumption, depending upon the utilization across different operations of a
CapsuleNet. Our memory designs can significantly reduce the energy consumption
of the on-chip memory by up to 86%, when compared to a state-of-the-art memory
design. Since the power consumption of the memory elements is the major
contributor in the power breakdown of the CapsuleNet accelerator, as we will
also show in our analyses, the proposed memory design can effectively reduce
the overall energy consumption of the complete CapsuleNet accelerator
architecture.
"
1146,Routing in Networks on Chip with Multiplicative Circulant Topology,"  The development of multi-core processor systems is a demanded branch of
science and technology. The appearance of processors with dozens and hundreds
of cores poses to the developers the question of choosing the optimal topology
capable to provide efficient routing in a network with a large number of nodes.
In this paper, we consider the possibility of using multiplicative circulants
as a topology for networks-on-chip. A specialized routing algorithm for
networks with multiplicative circulant topology, taking into account topology
features and having a high scalability, has been developed.
"
1147,"Architecting Non-Volatile Main Memory to Guard Against Persistence-based
  Attacks","  DRAM-based main memory and its associated components increasingly account for
a significant portion of application performance bottlenecks and power budget
demands inside the computing ecosystem. To alleviate the problems of storage
density and power constraints associated with DRAM, system architects are
investigating alternative non-volatile memory technologies such as Phase Change
Memory (PCM) to either replace or be used alongside DRAM memory. While such
alternative memory types offer many promises to overcome the DRAM-related
issues, they present a significant security threat to the users due to
persistence of memory data even after power down.
  In this paper, we investigate smart mechanisms to obscure the data left in
non-volatile memory after power down. In particular, we analyze the effect of
using a single encryption algorithm versus differentiated encryption based on
the security needs of the application phases. We also explore the effect of
encryption on a hybrid main memory that has a DRAM buffer cache plus PCM main
memory. Our mechanism takes into account the limited write endurance problem
associated with several non-volatile memory technologies including PCM, and
avoids any additional writes beyond those originally issued by the
applications. We evaluate using Gem5 simulator and SPEC 2006 applications, and
show the performance and power overheads of our proposed design.
"
1148,A Case for Superconducting Accelerators,"  As the scaling of conventional CMOS-based technologies slows down, there is
growing interest in alternative technologies that can improve performance or
energy-efficiency. Superconducting circuits based on Josephson Junction (JJ) is
an emerging technology that can provide devices which can be switched with
pico-second latencies and consuming two orders of magnitude lower switching
energy compared to CMOS. While JJ-based circuits can provide high operating
frequency and energy-efficiency, this technology faces three critical
challenges: limited device density and lack of area-efficient technology for
memory structures, reduced gate fanout compared to CMOS, and new failure modes
of Flux-Traps that occurs due to the operating environment.
  The lack of dense memory technology restricts the use of superconducting
technology in the near term to application domains that have high compute
intensity but require negligible amount of memory. In this paper, we study the
use of superconducting technology to build an accelerator for SHA-256 engines
commonly used in Bitcoin mining applications. We show that merely porting
existing CMOS-based accelerator to superconducting technology provides 10.6X
improvement in energy efficiency. Redesigning the accelerator to suit the
unique constraints of superconducting technology (such as low fanout) improves
the energy efficiency to 12.2X. We also investigate solutions to make the
accelerator tolerant of new fault modes and show how this fault-tolerant design
can be leveraged to reduce the operating current, thereby increasing the
overall energy-efficiency to 46X compared to CMOS. Our paper also develops a
workflow for evaluating area, performance, and power for accelerators built in
superconducting technology, and this workflow can help other researchers
explore designs using this technology.
"
1149,Fast Parallel Integer Adder in Binary Representation,"  An integer adder for integers in the binary representation is one of the
basic operations of any digital processor. For adding two integers of N bits
each, the serial adder takes as many clock ticks. For achieving higher speeds,
parallel circuits are discussed in the literature, and these circuits usually
operate in two levels. At the lower level, integers represented by blocks of
smaller number of bits are added, and in a cascade of stages in the next level,
the carries produced in previous addition operations are summed to the augends.
In this paper, we describe a fast method and an improvement of it. The first
attempt resembles the operation method of the merge sort algorithm, from which
some important properties of carries produced in each stage are analysed and
assimilated, resulting in a parallel adder that runs in time comparable to the
existing methods. After that, the crucial insights are brought to fruition in
an improved design, which takes 2 clock ticks to perform the addition operation
requiring only O(square(N)) space. The number of bits N is chosen usually to be
a positive integer power of 2. The speedup is achieved by special purpose
circuits for increment operations by i-th power of 2 , for i = 0, 1, ..., N-1,
each operation taking only a single clock tick to complete. The usefulness of
this adder for multiplication operation is discussed. The standard
multiplication method utilizes quantizer and 3-bit to 2-bit consolidation
circuits to produce an integer that represents in binary the number of 1s in a
column corresponding to a place (weighted coefficient) of nonnegative integer
power of 2. The last two consolidated integers are added by an adder in the
end.
"
1150,"Beyond the Memory Wall: A Case for Memory-centric HPC System for Deep
  Learning","  As the models and the datasets to train deep learning (DL) models scale,
system architects are faced with new challenges, one of which is the memory
capacity bottleneck, where the limited physical memory inside the accelerator
device constrains the algorithm that can be studied. We propose a
memory-centric deep learning system that can transparently expand the memory
capacity available to the accelerators while also providing fast inter-device
communication for parallel training. Our proposal aggregates a pool of memory
modules locally within the device-side interconnect, which are decoupled from
the host interface and function as a vehicle for transparent memory capacity
expansion. Compared to conventional systems, our proposal achieves an average
2.8x speedup on eight DL applications and increases the system-wide memory
capacity to tens of TBs.
"
1151,"ENBB Processor: Towards the ExaScale Numerical Brain Box [Position
  Paper]","  ExaScale systems will be a key driver for simulations that are essential for
advance of science and economic growth. We aim to present a new concept of
microprocessor for floating-point computations useful for being a basic
building block of ExaScale systems and beyond. The proposed microprocessor
architecture has a frontend for programming interface based on the concept of
event-driven simulation. The user program is executed as an event-driven
simulation using a hardware/software co-designed simulator. This is the
flexible part of the system. The back-end exploits the concept of uniform
topology as in a brain: a massive packet switched interconnection network with
flit credit-based flow control with virtual channels that incorporates
seamlessly communication, arithmetic and storage. Floating-point computations
are incorporated as on-line arithmetic operators in the output ports of the
switches as virtual arithmetic output channels, and storage as virtual input
channels. The front-end carries out the event-driven simulation of the user
program, and uses the arithmetic network for the hard floating-point work by
means of virtual dataflows. We expect to reduce significantly the needs of main
memory due to the execution model proposed, where variables are just virtual
interconnections in the network or signals stored in the virtual channels.
Moreover, we have the hypothesis that the problem size assigned to a
microprocessor should allow maximum concurrency and it should not be oversized.
This may lead to systems composed of microprocessors with main memory
incorporated in 3D chips. We identified several challenges that a research to
develop this microprocessor should address, and several hypothesis that should
be demonstrated by means of scientific evidence.
"
1152,Applicability of Partial Ternary Full Adder in Ternary Arithmetic Units,"  This paper explores whether or not a complete ternary full adder, whose input
variables can independently be '0', '1', or '2', is indispensable in the
arithmetic blocks of adder, subtractor, and multiplier. Our investigations show
that none of the mentioned arithmetic units require a complete ternary full
adder. Instead, they can be designed by use of partial ternary full adder,
whose input carry never becomes '2'. Furthermore, some new ternary compressors
are proposed in this paper without the requirement of complete ternary full
adder. The usage of partial ternary full adder can help circuit designers to
simplify their designs, especially in transistor level.
"
1153,"SPINBIS: Spintronics based Bayesian Inference System with Stochastic
  Computing","  Bayesian inference is an effective approach for solving statistical learning
problems, especially with uncertainty and incompleteness. However, Bayesian
inference is a computing-intensive task whose efficiency is physically limited
by the bottlenecks of conventional computing platforms. In this work, a
spintronics based stochastic computing approach is proposed for efficient
Bayesian inference. The inherent stochastic switching behaviors of spintronic
devices are exploited to build stochastic bitstream generator (SBG) for
stochastic computing with hybrid CMOS/MTJ circuits design. Aiming to improve
the inference efficiency, an SBG sharing strategy is leveraged to reduce the
required SBG array scale by integrating a switch network between SBG array and
stochastic computing logic. A device-to-architecture level framework is
proposed to evaluate the performance of spintronics based Bayesian inference
system (SPINBIS). Experimental results on data fusion applications have shown
that SPINBIS could improve the energy efficiency about 12X than MTJ-based
approach with 45% design area overhead and about 26X than FPGA-based approach.
"
1154,"Understanding the Interactions of Workloads and DRAM Types: A
  Comprehensive Experimental Study","  It has become increasingly difficult to understand the complex interaction
between modern applications and main memory, composed of DRAM chips.
Manufacturers are now selling and proposing many different types of DRAM, with
each DRAM type catering to different needs (e.g., high throughput, low power,
high memory density). At the same time, the memory access patterns of prevalent
and emerging workloads are rapidly diverging, as these applications manipulate
larger data sets in very different ways. As a result, the combined
DRAM-workload behavior is often difficult to intuitively determine today, which
can hinder memory optimizations in both hardware and software.
  In this work, we identify important families of workloads, as well as
prevalent types of DRAM chips, and rigorously analyze the combined
DRAM--workload behavior. To this end, we perform a comprehensive experimental
study of the interaction between nine different DRAM types and 115 modern
applications and multiprogrammed workloads. We draw 12 key observations from
our characterization, enabled in part by our development of new metrics that
take into account contention between memory requests due to hardware design.
Notably, we find that (1) newer DRAM types such as DDR4 and HMC often do not
outperform older types such as DDR3, due to higher access latencies and, in the
case of HMC, poor exploitation of locality; (2) there is no single DRAM type
that can cater to all components of a heterogeneous system (e.g., GDDR5
significantly outperforms other memories for multimedia acceleration, while HMC
significantly outperforms other memories for network acceleration); and (3)
there is still a strong need to lower DRAM latency, but unfortunately the
current design trend of commodity DRAM is toward higher latencies to obtain
other benefits. We hope that the trends we identify can drive optimizations in
both hardware and software design.
"
1155,"ERSFQ 8-bit Parallel Binary Shifter for Energy-Efficient Superconducting
  CPU","  We have designed and tested a parallel 8-bit ERSFQ binary shifter that is one
of the essential circuits in the design of the energy-efficient superconducting
CPU. The binary shifter performs a bi-directional SHIFT instruction of an 8-bit
argument. It consists of a bi-direction triple-port shift register controlled
by two (left and right) shift pulse generators asynchronously generating a set
number of shift pulses. At first clock cycle, an 8-bit word is loaded into the
binary shifter and a 3-bit shift argument is loaded into the desired
shift-pulse generator. Next, the generator produces the required number of
shift SFQ pulses (from 0 to 7) asynchronously, with a repetition rate set by
the internal generator delay of ~ 30 ps. These SFQ pulses are applied to the
left (positive) or the right (negative) input of the binary shifter. Finally,
after the shift operation is completed, the resulting 8-bit word goes to the
parallel output. The complete 8-bit ERSFQ binary shifter, consisting of 820
Josephson junctions, was simulated and optimized using PSCAN2. It was
fabricated in MIT Lincoln Lab 10-kA/cm2 SFQ5ee fabrication process with a
high-kinetic inductance layer. We have successfully tested the binary shifter
at both the LSB-to-MSB and MSB-to-LSB propagation regimes for all eight shift
arguments. A single shift operation on a single input word demonstrated
operational margins of +/-16% of the dc bias current. The correct functionality
of the 8-bit ERSFQ binary shifter with the large, exhaustive data pattern was
observed within +/-10% margins of the dc bias current. In this paper, we
describe the design and present the test results for the ERSFQ 8-bit parallel
binary shifter.
"
1156,ERSFQ 8-bit Parallel Arithmetic Logic Unit,"  We have designed and tested a parallel 8-bit ERSFQ arithmetic logic unit
(ALU). The ALU design employs wave-pipelined instruction execution and features
modular bit-slice architecture that is easily extendable to any number of bits
and adaptable to current recycling. A carry signal synchronized with an
asynchronous instruction propagation provides the wave-pipeline operation of
the ALU. The ALU instruction set consists of 14 arithmetical and logical
instructions. It has been designed and simulated for operation up to a 10 GHz
clock rate at the 10-kA/cm2 fabrication process. The ALU is embedded into a
shift-register-based high-frequency testbed with on-chip clock generator to
allow for comprehensive high frequency testing for all possible operands. The
8-bit ERSFQ ALU, comprising 6840 Josephson junctions, has been fabricated with
MIT Lincoln Lab 10-kA/cm2 SFQ5ee fabrication process featuring eight Nb wiring
layers and a high-kinetic inductance layer needed for ERSFQ technology. We
evaluated the bias margins for all instructions and various operands at both
low and high frequency clock. At low frequency, clock and all instruction
propagation through ALU were observed with bias margins of +/-11% and +/-9%,
respectively. Also at low speed, the ALU exhibited correct functionality for
all arithmetical and logical instructions with +/-6% bias margins. We tested
the 8-bit ALU for all instructions up to 2.8 GHz clock frequency.
"
1157,"ROMANet: Fine-Grained Reuse-Driven Off-Chip Memory Access Management and
  Data Organization for Deep Neural Network Accelerators","  Enabling high energy efficiency is crucial for embedded implementations of
deep learning. Several studies have shown that the DRAM-based off-chip memory
accesses are one of the most energy-consuming operations in deep neural network
(DNN) accelerators, and thereby limit the designs from achieving efficiency
gains at the full potential. DRAM access energy varies depending upon the
number of accesses required as well as the energy consumed per-access.
Therefore, searching for a solution towards the minimum DRAM access energy is
an important optimization problem. Towards this, we propose the ROMANet
methodology that aims at reducing the number of memory accesses, by searching
for the appropriate data partitioning and scheduling for each layer of a
network using a design space exploration, based on the knowledge of the
available on-chip memory and the data reuse factors. Moreover, ROMANet also
targets decreasing the number of DRAM row buffer conflicts and misses, by
exploiting the DRAM multi-bank burst feature to improve the energy-per-access.
Besides providing the energy benefits, our proposed DRAM data mapping also
results in an increased effective DRAM throughput, which is useful for
latency-constraint scenarios. Our experimental results show that the ROMANet
saves DRAM access energy by 12% for the AlexNet, by 36% for the VGG-16, and by
46% for the MobileNet, while also improving the DRAM throughput by 10%, as
compared to the state-of-the-art.
"
1158,"FixyNN: Efficient Hardware for Mobile Computer Vision via Transfer
  Learning","  The computational demands of computer vision tasks based on state-of-the-art
Convolutional Neural Network (CNN) image classification far exceed the energy
budgets of mobile devices. This paper proposes FixyNN, which consists of a
fixed-weight feature extractor that generates ubiquitous CNN features, and a
conventional programmable CNN accelerator which processes a dataset-specific
CNN. Image classification models for FixyNN are trained end-to-end via transfer
learning, with the common feature extractor representing the transfered part,
and the programmable part being learnt on the target dataset. Experimental
results demonstrate FixyNN hardware can achieve very high energy efficiencies
up to 26.6 TOPS/W ($4.81 \times$ better than iso-area programmable
accelerator). Over a suite of six datasets we trained models via transfer
learning with an accuracy loss of $<1\%$ resulting in up to 11.2 TOPS/W -
nearly $2 \times$ more efficient than a conventional programmable CNN
accelerator of the same area.
"
1159,"MIPS-Core Application Specific Instruction-Set Processor for IDEA
  Cryptography - Comparison between Single-Cycle and Multi-Cycle Architectures","  A single-cycle processor completes the execution of an instruction in only
one clock cycle. However, its clock period is usually rather long. On the
contrary, although clock frequency is higher in a multi-cycle processor, it
takes several clock cycles to finish an instruction. Therefore, their runtime
efficiencies depend on which program is executed. This paper presents a new
processor for International Data Encryption Algorithm (IDEA) cryptography. The
new design is an Application Specific Instruction-set Processor (ASIP) in which
both general-purpose and special instructions are supported. It is a
single-cycle MIPS-core architecture, whose average Clocks Per Instruction (CPI)
is 1. Furthermore, a comparison is provided in this paper to show the
differences between the proposed single-cycle processor and another comparable
multi-cycle crypto processor. FPGA implementation results show that both
architectures have almost the same encoding/decoding throughput. However, the
previous processor consumes nearly twice as many resources as the new one does.
"
1160,"Denial-of-Service Attacks on Shared Cache in Multicore: Analysis and
  Prevention","  In this paper we investigate the feasibility of denial-of-service (DoS)
attacks on shared caches in multicore platforms. With carefully engineered
attacker tasks, we are able to cause more than 300X execution time increases on
a victim task running on a dedicated core on a popular embedded multicore
platform, regardless of whether we partition its shared cache or not. Based on
careful experimentation on real and simulated multicore platforms, we identify
an internal hardware structure of a non-blocking cache, namely the cache
writeback buffer, as a potential target of shared cache DoS attacks. We propose
an OS-level solution to prevent such DoS attacks by extending a
state-of-the-art memory bandwidth regulation mechanism. We implement the
proposed mechanism in Linux on a real multicore platform and show its
effectiveness in protecting against cache DoS attacks.
"
1161,"On Resistive Memories: One Step Row Readout Technique and Sensing
  Circuitry","  Transistor-based memories are rapidly approaching their maximum density per
unit area. Resistive crossbar arrays enable denser memory due to the small size
of switching devices. However, due to the resistive nature of these memories,
they suffer from current sneak paths complicating the readout procedure. In
this paper, we propose a row readout technique with circuitry that can be used
to read {selector-less} resistive crossbar based memories. High throughput
reading and writing techniques are needed to overcome the memory-wall
bottleneck problem and to enable near memory computing paradigm. The proposed
technique can read the entire row of dense crossbar arrays in one cycle, unlike
previously published techniques. The requirements for the readout circuitry are
discussed and satisfied in the proposed circuit. Additionally, an approximated
expression for the power consumed while reading the array is derived. A figure
of merit is defined and used to compare the proposed approach with existing
reading techniques. Finally, a quantitative analysis of the effect of biasing
mismatch on the array size is discussed.
"
1162,"FUSE: Fusing STT-MRAM into GPUs to Alleviate Off-Chip Memory Access
  Overheads","  In this work, we propose FUSE, a novel GPU cache system that integrates
spin-transfer torque magnetic random-access memory (STT-MRAM) into the on-chip
L1D cache. FUSE can minimize the number of outgoing memory accesses over the
interconnection network of GPU's multiprocessors, which in turn can
considerably improve the level of massive computing parallelism in GPUs.
Specifically, FUSE predicts a read-level of GPU memory accesses by extracting
GPU runtime information and places write-once-read-multiple (WORM) data blocks
into the STT-MRAM, while accommodating write-multiple data blocks over a small
portion of SRAM in the L1D cache. To further reduce the off-chip memory
accesses, FUSE also allows WORM data blocks to be allocated anywhere in the
STT-MRAM by approximating the associativity with the limited number of tag
comparators and I/O peripherals. Our evaluation results show that, in
comparison to a traditional GPU cache, our proposed heterogeneous cache reduces
the number of outgoing memory references by 32% across the interconnection
network, thereby improving the overall performance by 217% and reducing energy
cost by 53%.
"
1163,"Buddy Compression: Enabling Larger Memory for Deep Learning and HPC
  Workloads on GPUs","  GPUs offer orders-of-magnitude higher memory bandwidth than traditional
CPU-only systems. However, GPU device memory tends to be relatively small and
the memory capacity can not be increased by the user. This paper describes
Buddy Compression, a scheme to increase both the effective GPU memory capacity
and bandwidth while avoiding the downsides of conventional memory-expanding
strategies. Buddy Compression compresses GPU memory, splitting each compressed
memory entry between high-speed device memory and a slower-but-larger
disaggregated memory pool (or system memory). Highly-compressible memory
entries can thus be accessed completely from device memory, while
incompressible entries source their data using both on and off-device accesses.
Increasing the effective GPU memory capacity enables us to run
larger-memory-footprint HPC workloads and larger batch-sizes or models for DL
workloads than current memory capacities would allow. We show that our solution
achieves an average compression ratio of 2.2x on HPC workloads and 1.5x on DL
workloads, with a slowdown of just 1~2%.
"
1164,ShiftsReduce: Minimizing Shifts in Racetrack Memory 4.0,"  Racetrack memories (RMs) have significantly evolved since their conception in
2008, making them a serious contender in the field of emerging memory
technologies. Despite key technological advancements, the access latency and
energy consumption of an RM-based system are still highly influenced by the
number of shift operations. These operations are required to move bits to the
right positions in the racetracks. This paper presents data placement
techniques for RMs that maximize the likelihood that consecutive references
access nearby memory locations at runtime thereby minimizing the number of
shifts. We present an integer linear programming (ILP) formulation for optimal
data placement in RMs, and revisit existing offset assignment heuristics,
originally proposed for random-access memories. We introduce a novel heuristic
tailored to a realistic RM and combine it with a genetic search to further
improve the solution. We show a reduction in the number of shifts of up to
52.5%, outperforming the state of the art by up to 16.1%.
"
1165,"Neural Network Model Extraction Attacks in Edge Devices by Hearing
  Architectural Hints","  As neural networks continue their reach into nearly every aspect of software
operations, the details of those networks become an increasingly sensitive
subject. Even those that deploy neural networks embedded in physical devices
may wish to keep the inner working of their designs hidden -- either to protect
their intellectual property or as a form of protection from adversarial inputs.
The specific problem we address is how, through heavy system stack, given noisy
and imperfect memory traces, one might reconstruct the neural network
architecture including the set of layers employed, their connectivity, and
their respective dimension sizes. Considering both the intra-layer architecture
features and the inter-layer temporal association information introduced by the
DNN design empirical experience, we draw upon ideas from speech recognition to
solve this problem. We show that off-chip memory address traces and PCIe events
provide ample information to reconstruct such neural network architectures
accurately. We are the first to propose such accurate model extraction
techniques and demonstrate an end-to-end attack experimentally in the context
of an off-the-shelf Nvidia GPU platform with full system stack. Results show
that the proposed techniques achieve a high reverse engineering accuracy and
improve the one's ability to conduct targeted adversarial attack with success
rate from 14.6\%$\sim$25.5\% (without network architecture knowledge) to 75.9\%
(with extracted network architecture).
"
1166,Processing Data Where It Makes Sense: Enabling In-Memory Computation,"  Today's systems are overwhelmingly designed to move data to computation. This
design choice goes directly against at least three key trends in systems that
cause performance, scalability and energy bottlenecks: (1) data access from
memory is already a key bottleneck as applications become more data-intensive
and memory bandwidth and energy do not scale well, (2) energy consumption is a
key constraint in especially mobile and server systems, (3) data movement is
very expensive in terms of bandwidth, energy and latency, much more so than
computation.
  At the same time, conventional memory technology is facing many scaling
challenges in terms of reliability, energy, and performance. As a result,
memory system architects are open to organizing memory in different ways and
making it more intelligent, at the expense of higher cost. The emergence of
3D-stacked memory plus logic as well as the adoption of error correcting codes
inside DRAM chips, and the necessity for designing new solutions to serious
reliability and security issues, such as the RowHammer phenomenon, are an
evidence of this trend.
  Recent research aims to practically enable computation close to data. We
discuss at least two promising directions for processing-in-memory (PIM): (1)
performing massively-parallel bulk operations in memory by exploiting the
analog operational properties of DRAM, with low-cost changes, (2) exploiting
the logic layer in 3D-stacked memory technology to accelerate important
data-intensive applications. In both approaches, we describe and tackle
relevant cross-layer research, design, and adoption challenges in devices,
architecture, systems, and programming models. Our focus is on the development
of in-memory processing designs that can be adopted in real computing platforms
at low cost.
"
1167,Automated Circuit Approximation Method Driven by Data Distribution,"  We propose an application-tailored data-driven fully automated method for
functional approximation of combinational circuits. We demonstrate how an
application-level error metric such as the classification accuracy can be
translated to a component-level error metric needed for an efficient and fast
search in the space of approximate low-level components that are used in the
application. This is possible by employing a weighted mean error distance
(WMED) metric for steering the circuit approximation process which is conducted
by means of genetic programming. WMED introduces a set of weights (calculated
from the data distribution measured on a selected signal in a given
application) determining the importance of each input vector for the
approximation process. The method is evaluated using synthetic benchmarks and
application-specific approximate MAC (multiply-and-accumulate) units that are
designed to provide the best trade-offs between the classification accuracy and
power consumption of two image classifiers based on neural networks.
"
1168,"Evaluating Modern GPU Interconnect: PCIe, NVLink, NV-SLI, NVSwitch and
  GPUDirect","  High performance multi-GPU computing becomes an inevitable trend due to the
ever-increasing demand on computation capability in emerging domains such as
deep learning, big data and planet-scale simulations. However, the lack of deep
understanding on how modern GPUs can be connected and the real impact of
state-of-the-art interconnect technology on multi-GPU application performance
become a hurdle. In this paper, we fill the gap by conducting a thorough
evaluation on five latest types of modern GPU interconnects: PCIe, NVLink-V1,
NVLink-V2, NVLink-SLI and NVSwitch, from six high-end servers and HPC
platforms: NVIDIA P100-DGX-1, V100-DGX-1, DGX-2, OLCF's SummitDev and Summit
supercomputers, as well as an SLI-linked system with two NVIDIA Turing RTX-2080
GPUs. Based on the empirical evaluation, we have observed four new types of GPU
communication network NUMA effects: three are triggered by NVLink's topology,
connectivity and routing, while one is caused by PCIe chipset design issue.
These observations indicate that, for an application running in a multi-GPU
node, choosing the right GPU combination can impose considerable impact on GPU
communication efficiency, as well as the application's overall performance. Our
evaluation can be leveraged in building practical multi-GPU performance models,
which are vital for GPU task allocation, scheduling and migration in a shared
environment (e.g., AI cloud and HPC centers), as well as communication-oriented
performance tuning.
"
1169,"Graph Processing on FPGAs: Taxonomy, Survey, Challenges","  Graph processing has become an important part of various areas, such as
machine learning, computational sciences, medical applications, social network
analysis, and many others. Various graphs, for example web or social networks,
may contain up to trillions of edges. The sheer size of such datasets, combined
with the irregular nature of graph processing, poses unique challenges for the
runtime and the consumed power. Field Programmable Gate Arrays (FPGAs) can be
an energy-efficient solution to deliver specialized hardware for graph
processing. This is reflected by the recent interest in developing various
graph algorithms and graph processing frameworks on FPGAs. To facilitate
understanding of this emerging domain, we present the first survey and taxonomy
on graph computations on FPGAs. Our survey describes and categorizes existing
schemes and explains key ideas. Finally, we discuss research and engineering
challenges to outline the future of graph computations on FPGAs.
"
1170,A 68 uW 31 kS/s Fully-Capacitive Noise-Shaping SAR ADC with 102 dB SNDR,"  This paper presents a 17 bit analogue-to-digital converter that incorporates
mismatch and quantisation noise-shaping techniques into an energy-saving 10 bit
successive approximation quantiser to increase the dynamic range by another 42
dB. We propose a novel fully-capacitive topology which allows for high-speed
asynchronous conversion together with a background calibration scheme to reduce
the oversampling requirement by 10x compared to prior-art. A 0.18 um CMOS
technology is used to demonstrate preliminary simulation results together with
analytic measures that optimise parameter and topology selection. The proposed
system is able to achieve a FoMS of 183 dB for a maximum signal bandwidth of
15.6 kHz while dissipating 68 uW from a 1.8 V supply. A peak SNDR of 102 dB is
demonstrated for this rate with a 0.201 mm^2 area requirement.
"
1171,Fault-Tolerant Nanosatellite Computing on a Budget,"  Micro- and nanosatellites have become popular platforms for a variety of
commercial and scientific applications, but today are considered suitable
mainly for short and low-priority space missions due to their low reliability.
In part, this can be attributed to their reliance upon cheap, low-feature size,
COTS components originally designed for embedded and mobile-market
applications, for which traditional hardware-voting concepts are ineffective.
Software-fault-tolerance concepts have been shown effective for such systems,
but have largely been ignored by the space industry due to low maturity, as
most have only been researched in theory. In practice, designers of payload
instruments and miniaturized satellites are usually forced to sacrifice
reliability in favor deliver the level of performance necessary for
cutting-edge science and innovative commercial applications. Thus, we developed
a software-fault-tolerance-approach based upon thread-level coarse-grain
lockstep, which was validated using fault-injection. To offer strong long-term
fault coverage, our architecture is implemented as tiled MPSoC on an FPGA,
utilizing partial reconfiguration, as well as mixed criticality. This
architecture can satisfy the high performance requirements of current and
future scientific and commercial space missions at very low cost, while
offering the strong fault-coverage guarantees necessary for platform control
even for missions with a long duration. This architecture was developed for a
4-year ESA project. Together with two industrial partners, we are developing a
prototype to then undergo radiation testing.
"
1172,"Speed and Energy Optimised Quasi-Delay-Insensitive Block Carry Lookahead
  Adder","  We present a new asynchronous quasi-delay-insensitive (QDI) block carry
lookahead adder with redundancy carry (BCLARC) realized using delay-insensitive
dual-rail data encoding and 4-phase return-to-zero (RTZ) and 4-phase
return-to-one (RTO) handshaking. The proposed QDI BCLARC is found to be faster
and energy-efficient than the existing asynchronous adders which are QDI and
non-QDI (i.e., relative-timed). Compared to existing asynchronous adders
corresponding to various architectures such as ripple carry adder (RCA),
conventional carry lookahead adder (CCLA), carry select adder (CSLA), BCLARC,
and hybrid BCLARC-RCA, the proposed BCLARC is found to be faster and more
energy-optimised. The cycle time (CT), which is the sum of forward and reverse
latencies, governs the speed; and the product of average power dissipation and
cycle time viz. the power-cycle time product (PCTP) defines the low
power/energy efficiency. For a 32-bit addition, the proposed QDI BCLARC
achieves the following average reductions in design metrics over its
counterparts when considering RTZ and RTO handshaking: i) 20.5% and 19.6%
reductions in CT and PCTP respectively compared to an optimum QDI early output
RCA, ii) 16.5% and 15.8% reductions in CT and PCTP respectively compared to an
optimum relative-timed RCA, iii) 32.9% and 35.9% reductions in CT and PCTP
respectively compared to an optimum uniform input-partitioned QDI early output
CSLA, iv) 47.5% and 47.2% reductions in CT and PCTP respectively compared to an
optimum QDI early output CCLA, v) 14.2% and 27.3% reductions in CT and PCTP
respectively compared to an optimum QDI early output BCLARC, and vi) 12.2% and
11.6% reductions in CT and PCTP respectively compared to an optimum QDI early
output hybrid BCLARC-RCA. The adders were implemented using a 32/28nm CMOS
technology.
"
1173,"An Analytical Model for Performance and Lifetime Estimation of Hybrid
  DRAM-NVM Main Memories","  NVMs have promising advantages (e.g., lower idle power, higher density) over
the existing predominant main memory technology, DRAM. Yet, NVMs also have
disadvantages (e.g., limited endurance). System architects are therefore
examining hybrid DRAM-NVM main memories to enable the advantages of NVMs while
avoiding the disadvantages as much as possible. Unfortunately, the hybrid
memory design space is very large and complex due to the existence of very
different types of NVMs and their rapidly-changing characteristics. Therefore,
optimization of performance and lifetime of hybrid memory based computing
platforms and their experimental evaluation using traditional simulation
methods can be very time-consuming and sometimes even impractical. As such, it
is necessary to develop a fast and flexible analytical model to estimate the
performance and lifetime of hybrid memories on various workloads. This paper
presents an analytical model for hybrid memories based on Markov decision
processes. The proposed model estimates the hit ratio and lifetime for various
configurations of DRAM-NVM hybrid main memories. Our model also provides
accurate estimation of the effect of data migration policies on the hybrid
memory hit ratio, one of the most important factors in hybrid memory
performance and lifetime. Such an analytical model can aid designers to tune
hybrid memory configurations to improve performance and/or lifetime. We present
several optimizations that make our model more efficient while maintaining its
accuracy. Our experimental evaluations show that the proposed model (a)
accurately predicts the hybrid memory hit ratio with an average error of 4.61%
on a commodity server, (b) accurately estimates the NVM lifetime with an
average error of 2.93%, and (c) is on average 4x faster than conventional
state-of-the-art simulation platforms for hybrid memories.
"
1174,"A Novel Hierarchical Circuit LUT Model for SOI Technology for Rapid
  Prototyping","  This article is withdrawn because the co-authors are not in favor of
publication.
"
1175,"Evaluating Built-in ECC of FPGA on-chip Memories for the Mitigation of
  Undervolting Faults","  Voltage underscaling below the nominal level is an effective solution for
improving energy efficiency in digital circuits, e.g., Field Programmable Gate
Arrays (FPGAs). However, further undervolting below a safe voltage level and
without accompanying frequency scaling leads to timing related faults,
potentially undermining the energy savings. Through experimental voltage
underscaling studies on commercial FPGAs, we observed that the rate of these
faults exponentially increases for on-chip memories, or Block RAMs (BRAMs). To
mitigate these faults, we evaluated the efficiency of the built-in
Error-Correction Code (ECC) and observed that more than 90% of the faults are
correctable and further 7% are detectable (but not correctable). This
efficiency is the result of the single-bit type of these faults, which are then
effectively covered by the Single-Error Correction and Double-Error Detection
(SECDED) design of the built-in ECC. Finally, motivated by the above
experimental observations, we evaluated an FPGA-based Neural Network (NN)
accelerator under low-voltage operations, while built-in ECC is leveraged to
mitigate undervolting faults and thus, prevent NN significant accuracy loss. In
consequence, we achieve 40% of the BRAM power saving through undervolting below
the minimum safe voltage level, with a negligible NN accuracy loss, thanks to
the substantial fault coverage by the built-in ECC.
"
1176,Low Power Artificial Neural Network Architecture,"  Recent artificial neural network architectures improve performance and power
dissipation by leveraging resistive devices to store and multiply synaptic
weights with input data. Negative and positive synaptic weights are stored on
the memristors of a reconfigurable crossbar array (MCA). Existing MCA-based
neural network architectures use high power consuming voltage converters or
operational amplifiers to generate the total synaptic current through each
column of the crossbar array. This paper presents a low power MCA-based
feedforward neural network architecture that uses a spintronic device per pair
of columns to generate the synaptic current for each neuron. It is shown
experimentally that the proposed architecture dissipates significantly less
power compared to existing feedforward memristive neural network architectures.
"
1177,"An Asymmetric Adaptive SCL Decoder Hardware for Ultra-Low-Error-Rate
  Polar Codes","  In theory, Polar codes do not exhibit an error floor under
successive-cancellation (SC) decoding. In practice, frame error rate (FER) down
to $10^{-12}$ has not been reported with a real SC list (SCL) decoder hardware.
This paper presents an asymmetric adaptive SCL (A2SCL) decoder, implemented in
real hardware, for high-throughput and ultra-reliable communications. We
propose to concatenate multiple SC decoders with an SCL decoder, in which the
numbers of SC/SCL decoders are balanced with respect to their area and latency.
In addition, a novel unequal-quantization technique is adopted. The two
optimizations are crucial for improving SCL throughput within limited chip
area. As an application, we build a link-level FPGA emulation platform to
measure ultra-low FERs of 3GPP NR Polar codes (with parity-check and CRC bits).
It is flexible to support all list sizes up to $8$, code lengths up to $1024$
and arbitrary code rates. With the proposed hardware, decoding speed is 7000
times faster than a CPU core. For the first time, FER as low as $10^{-12}$ is
measured and quantization effect is analyzed.
"
1178,"Ring-Mesh: A Scalable and High-Performance Approach for Manycore
  Accelerators","  There are increasing number of works addressing the design challenges of
fast, scalable solutions for the growing number of new type of applications.
Recently, many of the solutions aimed at improving processing element
capabilities to speed up the execution of machine learning application domain.
However, only a few works focused on the interconnection subsystem as a
potential source of performance improvement. Wrapping many cores together offer
excellent parallelism, but it brings other challenges (e.g., adequate
interconnections). Scalable, power-aware interconnects are required to support
such a growing number of processing elements, as well as modern applications.
In this paper, we propose a scalable and energy efficient Network-on-Chip
architecture fusing the advantages of rings as well as the 2D-mesh without
using any bridge router to provide high-performance. A dynamic adaptation
mechanism allows to better adapt to the application requirements. Simulation
results show efficient power consumption (up to 141.3% saving for connecting
1024 cores), 2x (on average) throughput growth with better scalability (up to
1024 processing elements) compared to popular 2D-mesh while tested in multiple
statistical traffic pattern scenarios.
"
1179,Higher-Level Hardware Synthesis of The KASUMI Algorithm,"  Programmable Logic Devices (PLDs) continue to grow in size and currently
contain several millions of gates. At the same time, research effort is going
into higher-level hardware synthesis methodologies for reconfigurable computing
that can exploit PLD technology. In this paper, we explore the effectiveness
and extend one such formal methodology in the design of massively parallel
algorithms. We take a step-wise refinement approach to the development of
correct reconfigurable hardware circuits from formal specifications. A
functional programming notation is used for specifying algorithms and for
reasoning about them. The specifications are realised through the use of a
combination of function decomposition strategies, data refinement techniques,
and off-the-shelf refinements based upon higher-order functions. The
off-the-shelf refinements are inspired by the operators of Communicating
Sequential Processes (CSP) and map easily to programs in Handel-C (a hardware
description language). The Handel-C descriptions are directly compiled into
reconfigurable hardware. The practical realisation of this methodology is
evidenced by a case studying the third generation mobile communication security
algorithms. The investigated algorithm is the KASUM} block cipher. In this
paper, we obtain several hardware implementations with different performance
characteristics by applying different refinements to the algorithm. The
developed designs are compiled and tested under Celoxica's RC-1000
reconfigurable computer with its 2 million gates Virtex-E FPGA. Performance
analysis and evaluation of these implementations are included.
"
1180,SwitchAgg:A Further Step Towards In-Network Computation,"  Many distributed applications adopt a partition/aggregation pattern to
achieve high performance and scalability. The aggregation process, which
usually takes a large portion of the overall execution time, incurs large
amount of network traffic and bottlenecks the system performance. To reduce
network traffic,some researches take advantage of network devices to commit
innetwork aggregation. However, these approaches use either special topology or
middle-boxes, which cannot be easily deployed in current datacenters. The
emerging programmable RMT switch brings us new opportunities to implement
in-network computation task. However, we argue that the architecture of RMT
switch is not suitable for in-network aggregation since it is designed
primarily for implementing traditional network functions. In this paper, we
first give a detailed analysis of in-network aggregation, and point out the key
factor that affects the data reduction ratio. We then propose SwitchAgg, which
is an innetwork aggregation system that is compatible with current datacenter
infrastructures. We also evaluate the performance improvement we have gained
from SwitchAgg. Our results show that, SwitchAgg can process data aggregation
tasks at line rate and gives a high data reduction rate, which helps us to cut
down network traffic and alleviate pressure on server CPU. In the system
performance test, the job-completion-time can be reduced as much as 50%
"
1181,"Enabling Privacy-Preserving, Compute- and Data-Intensive Computing using
  Heterogeneous Trusted Execution Environment","  There is an urgent demand for privacy-preserving techniques capable of
supporting compute and data intensive (CDI) computing in the era of big data.
However, none of existing TEEs can truly support CDI computing tasks, as CDI
requires high throughput accelerators like GPU and TPU but TEEs do not offer
security protection of such accelerators. This paper present HETEE
(Heterogeneous TEE), the first design of TEE capable of strongly protecting
heterogeneous computing with unsecure accelerators. HETEE is uniquely
constructed to work with today's servers, and does not require any changes for
existing commercial CPUs or accelerators. The key idea of our design runs
security controller as a stand-alone computing system to dynamically adjust the
boundary of between secure and insecure worlds through the PCIe switches,
rendering the control of an accelerator to the host OS when it is not needed
for secure computing, and shifting it back when it is. The controller is the
only trust unit in the system and it runs the custom OS and accelerator
runtimes, together with the encryption, authentication and remote attestation
components. The host server and other computing systems communicate with
controller through an in memory task queue that accommodates the computing
tasks offloaded to HETEE, in the form of encrypted and signed code and data.
Also, HETEE offers a generic and efficient programming model to the host CPU.
We have implemented the HETEE design on a hardware prototype system, and
evaluated it with large-scale Neural Networks inference and training tasks. Our
evaluations show that HETEE can easily support such secure computing tasks and
only incurs a 12.34% throughput overhead for inference and 9.87% overhead for
training on average.
"
1182,High Performance Reconfigurable Computing Systems,"  The rapid progress and advancement in electronic chips technology provide a
variety of new implementation options for system engineers. The choice varies
between the flexible programs running on a general-purpose processor (GPP) and
the fixed hardware implementation using an application specific integrated
circuit (ASIC). Many other implementation options present, for instance, a
system with a RISC processor and a DSP core. Other options include graphics
processors and microcontrollers. Specialist processors certainly improve
performance over general-purpose ones, but this comes as a quid pro quo for
flexibility. Combining the flexibility of GPPs and the high performance of
ASICs leads to the introduction of reconfigurable computing (RC) as a new
implementation option with a balance between versatility and speed. The focus
of this chapter is on introducing reconfigurable computers as modern super
computing architectures. The chapter also investigates the main reasons behind
the current advancement in the development of RC-systems. Furthermore, a
technical survey of various RC-systems is included laying common grounds for
comparisons. In addition, this chapter mainly presents case studies implemented
under the MorphoSys RC-system. The selected case studies belong to different
areas of application, such as, computer graphics and information coding.
Parallel versions of the studied algorithms are developed to match the
topologies supported by the MorphoSys. Performance evaluation and results
analyses are included for implementations with different characteristics.
"
1183,"An Application-Specific VLIW Processor with Vector Instruction Set for
  CNN Acceleration","  In recent years, neural networks have surpassed classical algorithms in areas
such as object recognition, e.g. in the well-known ImageNet challenge. As a
result, great effort is being put into developing fast and efficient
accelerators, especially for Convolutional Neural Networks (CNNs). In this work
we present ConvAix, a fully C-programmable processor, which -- contrary to many
existing architectures -- does not rely on a hard-wired array of
multiply-and-accumulate (MAC) units. Instead it maps computations onto
independent vector lanes making use of a carefully designed vector instruction
set. The presented processor is targeted towards latency-sensitive applications
and is capable of executing up to 192 MAC operations per cycle. ConvAix
operates at a target clock frequency of 400 MHz in 28nm CMOS, thereby offering
state-of-the-art performance with proper flexibility within its target domain.
Simulation results for several 2D convolutional layers from well known CNNs
(AlexNet, VGG-16) show an average ALU utilization of 72.5% using vector
instructions with 16 bit fixed-point arithmetic. Compared to other well-known
designs which are less flexible, ConvAix offers competitive energy efficiency
of up to 497 GOP/s/W while even surpassing them in terms of area efficiency and
processing speed.
"
1184,A Configurable Memristor-based Finite Impulse Response Filter,"  There are two main methods to implement FIR filters: software and hardware.
In the software method, an FIR filter can be implemented within the processor
by programming; it uses too much memory and it is extremely time-consuming
while it gives the design more configurability. In most hardware-based
implementations of FIR filters, Analog-to-Digital (A/D) and Digital-to-Analog
(D/A) converters are mandatory and increase the cost. The most important
advantage of hardware implementation of a FIR filter is its higher speed
compared to its software counterpart. In this work, considering the advantages
of software and hardware approaches, a method to implement direct form FIR
filters using analog components and memristors is proposed. Not only the A/D
and D/A converters are omitted, but also using memristors avails
configurability. A new circuit is presented to handle negative coefficients of
the filter and memristance values are calculated using a heuristic method in
order to achieve a better accuracy in setting coefficients. Moreover, an
appropriate sample and delay topology is employed which overcomes the
limitations of the previous research in implementation of high-order filters.
Proper operation and usefulness of the proposed structures are all validated
via simulation in Cadence.
"
1185,"The Cost of Application-Class Processing: Energy and Performance
  Analysis of a Linux-ready 1.7GHz 64bit RISC-V Core in 22nm FDSOI Technology","  The open-source RISC-V ISA is gaining traction, both in industry and
academia. The ISA is designed to scale from micro-controllers to server-class
processors. Furthermore, openness promotes the availability of various
open-source and commercial implementations. Our main contribution in this work
is a thorough power, performance, and efficiency analysis of the RISC-V ISA
targeting baseline ""application class"" functionality, i.e. supporting the Linux
OS and its application environment based on our open-source single-issue
in-order implementation of the 64 bit ISA variant (RV64GC) called Ariane. Our
analysis is based on a detailed power and efficiency analysis of the RISC-V ISA
extracted from silicon measurements and calibrated simulation of an Ariane
instance (RV64IMC) taped-out in GlobalFoundries 22 FDX technology. Ariane runs
at up to 1.7 GHz and achieves up to 40 Gop/sW peak efficiency. We give insight
into the interplay between functionality required for application-class
execution (e.g. virtual memory, caches, multiple modes of privileged operation)
and energy cost. Our analysis indicates that ISA heterogeneity and simpler
cores with a few critical instruction extensions (e.g. packed SIMD) can
significantly boost a RISC-V core's compute energy efficiency.
"
1186,"Accelerating Bulk Bit-Wise X(N)OR Operation in Processing-in-DRAM
  Platform","  With Von-Neumann computing architectures struggling to address
computationally- and memory-intensive big data analytic task today,
Processing-in-Memory (PIM) platforms are gaining growing interests. In this
way, processing-in-DRAM architecture has achieved remarkable success by
dramatically reducing data transfer energy and latency. However, the
performance of such system unavoidably diminishes when dealing with more
complex applications seeking bulk bit-wise X(N)OR- or addition operations,
despite utilizing maximum internal DRAM bandwidth and in-memory parallelism. In
this paper, we develop DRIM platform that harnesses DRAM as computational
memory and transforms it into a fundamental processing unit. DRIM uses the
analog operation of DRAM sub-arrays and elevates it to implement bit-wise
X(N)OR operation between operands stored in the same bit-line, based on a new
dual-row activation mechanism with a modest change to peripheral circuits such
sense amplifiers. The simulation results show that DRIM achieves on average 71x
and 8.4x higher throughput for performing bulk bit-wise X(N)OR-based operations
compared with CPU and GPU, respectively. Besides, DRIM outperforms recent
processing-in-DRAM platforms with up to 3.7x better performance.
"
1187,"The DEEP-ER project: I/O and resiliency extensions for the
  Cluster-Booster architecture","  The recently completed research project DEEP-ER has developed a variety of
hardware and software technologies to improve the I/O capabilities of next
generation high-performance computers, and to enable applications recovering
from the larger hardware failure rates expected on these machines.
  The heterogeneous Cluster-Booster architecture --first introduced in the
predecessor DEEP project-- has been extended by a multi-level memory hierarchy
employing non-volatile and network-attached memory devices. Based on this
hardware infrastructure, an I/O and resiliency software stack has been
implemented combining and extending well established libraries and software
tools, and sticking to standard user-interfaces. Real-world scientific codes
have tested the projects' developments and demonstrated the improvements
achieved without compromising the portability of the applications.
"
1188,"Processing-In-Memory Acceleration of Convolutional Neural Networks for
  Energy-Efficiency, and Power-Intermittency Resilience","  Herein, a bit-wise Convolutional Neural Network (CNN) in-memory accelerator
is implemented using Spin-Orbit Torque Magnetic Random Access Memory (SOT-MRAM)
computational sub-arrays. It utilizes a novel AND-Accumulation method capable
of significantly-reduced energy consumption within convolutional layers and
performs various low bit-width CNN inference operations entirely within MRAM.
Power-intermittence resiliency is also enhanced by retaining the partial state
information needed to maintain computational forward-progress, which is
advantageous for battery-less IoT nodes. Simulation results indicate
$\sim$5.4$\times$ higher energy-efficiency and 9$\times$ speedup over
ReRAM-based acceleration, or roughly $\sim$9.7$\times$ higher energy-efficiency
and 13.5$\times$ speedup over recent CMOS-only approaches, while maintaining
inference accuracy comparable to baseline designs.
"
1189,"Performance Analysis of Linear Algebraic Functions using Reconfigurable
  Computing","  This paper introduces a new mapping of geometrical transformation on the
MorphoSys (M1) reconfigurable computing (RC) system. New mapping techniques for
some linear algebraic functions are recalled. A new mapping for geometrical
transformation operations is introduced and their performance on the M1 system
is evaluated. The translation and scaling transformation addressed in this
mapping employ some vector-vector and vector-scalar operations [6-7]. A
performance analysis study of the M1 RC system is also presented to evaluate
the efficiency of the algorithm execution. Numerical examples were simulated to
validate our results, using the MorphoSys mULATE program, which emulates M1
operations.
"
1190,Memory and Parallelism Analysis Using a Platform-Independent Approach,"  Emerging computing architectures such as near-memory computing (NMC) promise
improved performance for applications by reducing the data movement between CPU
and memory. However, detecting such applications is not a trivial task. In this
ongoing work, we extend the state-of-the-art platform-independent software
analysis tool with NMC related metrics such as memory entropy, spatial
locality, data-level, and basic-block-level parallelism. These metrics help to
identify the applications more suitable for NMC architectures.
"
1191,Energy-Efficient Runtime Adaptable L1 STT-RAM Cache Design,"  Much research has shown that applications have variable runtime cache
requirements. In the context of the increasingly popular Spin-Transfer Torque
RAM (STT-RAM) cache, the retention time, which defines how long the cache can
retain a cache block in the absence of power, is one of the most important
cache requirements that may vary for different applications. In this paper, we
propose a Logically Adaptable Retention Time STT-RAM (LARS) cache that allows
the retention time to be dynamically adapted to applications' runtime
requirements. LARS cache comprises of multiple STT-RAM units with different
retention times, with only one unit being used at a given time. LARS
dynamically determines which STT-RAM unit to use during runtime, based on
executing applications' needs. As an integral part of LARS, we also explore
different algorithms to dynamically determine the best retention time based on
different cache design tradeoffs. Our experiments show that by adapting the
retention time to different applications' requirements, LARS cache can reduce
the average cache energy by 25.31%, compared to prior work, with minimal
overheads.
"
1192,"Development of routing algorithms in networks-on-chip based on ring
  circulant topologies","  This work is devoted to the study of communication subsystem of
networks-onchip (NoCs) development with an emphasis on their topologies. The
main characteristics of NoC topologies and the routing problem in NoCs with
various topologies are considered. It is proposed to use two-dimensional
circulant topologies for NoC design, since they have significantly better
characteristics than most common mesh and torus topologies, and, in contrast to
many other approaches to improving topologies, have a regular structure. The
emphasis is on using ring circulants which although in some cases have somewhat
worse characteristics than the optimal circulants, compensate by one-length
first generatrix in such graphs that greatly facilitate routing in them. The
paper considers three different approaches to routing in NoCs with ring
circulant topology: Table routing, Clockwise routing, and Adaptive routing. The
algorithms of routing are proposed, the results of synthesis of routers, based
on them, are presented, and the cost of chip resources for the implementation
of such communication subsystems in NoCs is estimated.
"
1193,A Parallel Bitstream Generator for Stochastic Computing,"  Stochastic computing (SC) presents high error tolerance and low hardware
cost, and has great potential in applications such as neural networks and image
processing. However, the bitstream generator, which converts a binary number to
bitstreams, occupies a large area and energy consumption, thus weakening the
superiority of SC. In this paper, we propose a novel technique for generating
bitstreams in parallel, which needs only one clock for conversion and
significantly reduces the hardware cost. Synthesis results demonstrate that the
proposed parallel bitstream generator improves 2.5x area and 712x energy
consumption.
"
1194,RowHammer: A Retrospective,"  This retrospective paper describes the RowHammer problem in Dynamic Random
Access Memory (DRAM), which was initially introduced by Kim et al. at the ISCA
2014 conference~\cite{rowhammer-isca2014}. RowHammer is a prime (and perhaps
the first) example of how a circuit-level failure mechanism can cause a
practical and widespread system security vulnerability. It is the phenomenon
that repeatedly accessing a row in a modern DRAM chip causes bit flips in
physically-adjacent rows at consistently predictable bit locations. RowHammer
is caused by a hardware failure mechanism called {\em DRAM disturbance errors},
which is a manifestation of circuit-level cell-to-cell interference in a scaled
memory technology.
  Researchers from Google Project Zero demonstrated in 2015 that this hardware
failure mechanism can be effectively exploited by user-level programs to gain
kernel privileges on real systems. Many other follow-up works demonstrated
other practical attacks exploiting RowHammer. In this article, we
comprehensively survey the scientific literature on RowHammer-based attacks as
well as mitigation techniques to prevent RowHammer. We also discuss what other
related vulnerabilities may be lurking in DRAM and other types of memories,
e.g., NAND flash memory or Phase Change Memory, that can potentially threaten
the foundations of secure systems, as the memory technologies scale to higher
densities. We conclude by describing and advocating a principled approach to
memory reliability and security research that can enable us to better
anticipate and prevent such vulnerabilities.
"
1195,"IRC: Cross-layer design exploration of Intermittent Robust Computation
  units for IoTs","  Energy-harvesting-powered computing offers intriguing and vast opportunities
to dramatically transform the landscape of the Internet of Things (IoT) devices
by utilizing ambient sources of energy to achieve battery-free computing. In
order to operate within the restricted energy capacity and intermittency
profile, it is proposed to innovate Intermittent Robust Computation (IRC) Unit
as a new duty-cycle-variable computing approach leveraging the non-volatility
inherent in spin-based switching devices. The foundations of IRC will be
advanced from the device-level upwards, by extending a Spin Hall Effect
Magnetic Tunnel Junction (SHE-MTJ) device. The device will then be used to
realize SHE-MTJ Majority/Polymorphic Gate (MG/PG) logic approaches and
libraries. Then a Logic-Embedded Flip-Flop (LE-FF) is developed to realize
rudimentary Boolean logic functions along with an inherent state-holding
capability within a compact footprint. Finally, the NV-Clustering synthesis
procedure and corresponding tool module are proposed to instantiate the LE-FF
library cells within conventional Register Transfer Language (RTL)
specifications. This selectively clusters together logic and NV state-holding
functionality, based on energy and area minimization criteria. It also realizes
middleware-coherent, intermittent computation without checkpointing,
micro-tasking, or software bloat and energy overheads vital to IoT. Simulation
results for various benchmark circuits including ISCAS-89 validate
functionality and power dissipation, area, and delay benefits.
"
1196,"Efficient FPGA Floorplanning for Partial Reconfiguration-Based
  Applications","  Partial Reconfiguration (PR) is a technique that allows reconfiguring the
FPGA chip at runtime. However, current design support tools require manual
floorplanning of the partial modules. Several approaches have been proposed in
this field, but only a few of them consider all aspects of PR, like the shape
and the aspect ratio of the reconfigurable region. Most of them are defined for
old FPGA architectures and have a high computational time. This paper
introduces an efficient automatic floorplanning algorithm, which takes into
account the heterogeneous architectures of modern FPGA families, as well as PR
constraints, introducing the aspect ratio constraint to optimize routing. The
algorithm generates possible placements of the partial modules, then applies a
recursive pseudo-bipartitioning heuristic search to find the best floorplan.
The experiments showed that the algorithm's performance is significantly better
than the one of other algorithms in this field.
"
1197,"TS Cache: A Fast Cache with Timing-speculation Mechanism Under Low
  Supply Voltages","  To mitigate the ever-worsening Power Wall problem, more and more applications
need to expand their power supply to the wide-voltage range including the
near-threshold region. However, the read delay distribution of the SRAM cells
under the near-threshold voltage shows a more serious long-tail characteristic
than that under the nominal voltage due to the process fluctuation. Such
degradation of SRAM delay makes the SRAM-based cache a performance bottleneck
of systems as well. To avoid the unreliable data reading, circuit-level studies
use larger/more transistors in a bitcell by scarifying chip area and the static
power of cache arrays. Architectural studies propose the auxiliary error
correction or block disabling/remapping methods in fault-tolerant caches, which
worsen both the hit latency and energy efficiency due to the complex accessing
logic. This paper proposes the Timing-Speculation (TS) cache to boost the cache
frequency and improve energy efficiency under low supply voltages. In the TS
cache, the voltage differences of bitlines are continuously evaluated twice by
a sense amplifier (SA), and the access timing error can be detected much
earlier than that in prior methods. According to the measurement results from
the fabricated chips, the TS L1 cache aggressively increases its frequency to
1.62X and 1.92X compared with the conventional scheme at 0.5V and 0.6V supply
voltages, respectively.
"
1198,A Survey on Tiering and Caching in High-Performance Storage Systems,"  Although every individual invented storage technology made a big step towards
perfection, none of them is spotless. Different data store essentials such as
performance, availability, and recovery requirements have not met together in a
single economically affordable medium, yet. One of the most influential factors
is price. So, there has always been a trade-off between having a desired set of
storage choices and the costs. To address this issue, a network of various
types of storing media is used to deliver the high performance of expensive
devices such as solid state drives and non-volatile memories, along with the
high capacity of inexpensive ones like hard disk drives. In software, caching
and tiering are long-established concepts for handling file operations and
moving data automatically within such a storage network and manage data backup
in low-cost media. Intelligently moving data around different devices based on
the needs is the key insight for this matter. In this survey, we discuss some
recent pieces of research that have been done to improve high-performance
storage systems with caching and tiering techniques.
"
1199,"IRONHIDE: A Secure Multicore that Efficiently Mitigates
  Microarchitecture State Attacks for Interactive Applications","  Microprocessors enable aggressive hardware virtualization by means of which
multiple processes temporally execute on the system. These security-critical
and ordinary processes interact with each other to assure application progress.
However, temporal sharing of hardware resources exposes the processor to
various microarchitecture state attacks. State-of-the-art secure processors,
such as MI6 adopt Intel's SGX enclave execution model. MI6 architects strong
isolation by statically isolating shared memory state, and purging the
microarchitecture state of private core, cache, and TLB resources on every
enclave entry and exit. The purging overhead significantly impacts performance
as the interactivity across the secure and insecure processes increases. This
paper proposes IRONHIDE that implements strong isolation in the context of
multicores to form spatially isolated secure and insecure clusters of cores.
For an interactive application comprising of secure and insecure processes,
IRONHIDE pins the secure process(es) to the secure cluster, where they execute
and interact with the insecure process(es) without incurring the
microarchitecture state purging overheads on every interaction event. IRONHIDE
improves performance by 2.1x over the MI6 baseline for a set of user and OS
interactive applications. Moreover, IRONHIDE improves performance by 20% over
an SGX-like baseline, while also ensuring strong isolation guarantees against
microarchitecture state attacks.
"
1200,Rethinking Arithmetic for Deep Neural Networks,"  We consider efficiency in the implementation of deep neural networks.
Hardware accelerators are gaining interest as machine learning becomes one of
the drivers of high-performance computing. In these accelerators, the directed
graph describing a neural network can be implemented as a directed graph
describing a Boolean circuit. We make this observation precise, leading
naturally to an understanding of practical neural networks as discrete
functions, and show that so-called binarised neural networks are functionally
complete. In general, our results suggest that it is valuable to consider
Boolean circuits as neural networks, leading to the question of which circuit
topologies are promising. We argue that continuity is central to generalisation
in learning, explore the interaction between data coding, network topology, and
node functionality for continuity, and pose some open questions for future
research. As a first step to bridging the gap between continuous and Boolean
views of neural network accelerators, we present some recent results from our
work on LUTNet, a novel Field-Programmable Gate Array inference approach.
Finally, we conclude with additional possible fruitful avenues for research
bridging the continuous and discrete views of neural networks.
"
1201,"Efficient Similarity-aware Compression to Reduce Bit-writes in
  Non-Volatile Main Memory for Image-based Applications","  Image bitmaps have been widely used in in-memory applications, which consume
lots of storage space and energy. Compared with legacy DRAM, non-volatile
memories (NVMs) are suitable for bitmap storage due to the salient features in
capacity and power savings. However, NVMs suffer from higher latency and energy
consumption in writes compared with reads. Although compressing data in write
accesses to NVMs on-the-fly reduces the bit-writes in NVMs, existing precise or
approximate compression schemes show limited performance improvements for data
of bitmaps, due to the irregular data patterns and variance in data. We observe
that the data containing bitmaps show the pixel-level similarity due to the
analogous contents in adjacent pixels. By exploiting the pixel-level
similarity, we propose SimCom, an efficient similarity-aware compression scheme
in hardware layer, to compress data for each write access on-the-fly. The idea
behind SimCom is to compress continuous similar words into the pairs of base
words with runs. With the aid of domain knowledge of images, SimCom adaptively
selects an appropriate compression mode to achieve an efficient trade-off
between image quality and memory performance. We implement SimCom on GEM5 with
NVMain and evaluate the performance with real-world workloads. Our results
demonstrate that SimCom reduces 33.0%, 34.8% write latency and saves 28.3%,
29.0% energy than state-of-the-art FPC and BDI with minor quality loss of 3%.
"
1202,"SAWL:A Self-adaptive Wear-leveling NVM Scheme for High Performance
  Storage Systems","  In order to meet the needs of high performance computing (HPC) in terms of
large memory, high throughput and energy savings, the non-volatile memory (NVM)
has been widely studied due to its salient features of high density, near-zero
standby power, byte-addressable and non-volatile properties. In HPC systems,
the multi-level cell (MLC) technique is used to significantly increase device
density and decrease the cost, which however leads to much weaker endurance
than the single-level cell (SLC) counterpart. Although wear-leveling techniques
can mitigate this weakness in MLC, the improvements upon MLC-based NVM become
very limited due to not achieving uniform write distribution before some cells
are really worn out. To address this problem, our paper proposes a
self-adaptive wear-leveling (SAWL) scheme for MLC-based NVM. The idea behind
SAWL is to dynamically tune the wear-leveling granularities and balance the
writes across the cells of entire memory, thus achieving suitable tradeoff
between the lifetime and cache hit rate. Moreover, to reduce the size of the
address-mapping table, SAWL maintains a few recently-accessed mappings in a
small on-chip cache. Experimental results demonstrate that SAWL significantly
improves the NVM lifetime and the performance for HPC systems, compared with
state-of-the-art schemes.
"
1203,"Optimizing Routerless Network-on-Chip Designs: An Innovative
  Learning-Based Framework","  Machine learning applied to architecture design presents a promising
opportunity with broad applications. Recent deep reinforcement learning (DRL)
techniques, in particular, enable efficient exploration in vast design spaces
where conventional design strategies may be inadequate. This paper proposes a
novel deep reinforcement framework, taking routerless networks-on-chip (NoC) as
an evaluation case study. The new framework successfully resolves problems with
prior design approaches being either unreliable due to random searches or
inflexible due to severe design space restrictions. The framework learns
(near-)optimal loop placement for routerless NoCs with various design
constraints. A deep neural network is developed using parallel threads that
efficiently explore the immense routerless NoC design space with a Monte Carlo
search tree. Experimental results show that, compared with conventional mesh,
the proposed deep reinforcement learning (DRL) routerless design achieves a
3.25x increase in throughput, 1.6x reduction in packet latency, and 5x
reduction in power. Compared with the state-of-the-art routerless NoC, DRL
achieves a 1.47x increase in throughput, 1.18x reduction in packet latency, and
1.14x reduction in average hop count albeit with slightly more power overhead.
"
1204,FPGA-based Binocular Image Feature Extraction and Matching System,"  Image feature extraction and matching is a fundamental but computation
intensive task in machine vision. This paper proposes a novel FPGA-based
embedded system to accelerate feature extraction and matching. It implements
SURF feature point detection and BRIEF feature descriptor construction and
matching. For binocular stereo vision, feature matching includes both tracking
matching and stereo matching, which simultaneously provide feature point
correspondences and parallax information. Our system is evaluated on a ZYNQ
XC7Z045 FPGA. The result demonstrates that it can process binocular video data
at a high frame rate (640$\times$480 @ 162fps). Moreover, an extensive test
proves our system has robustness for image compression, blurring and
illumination.
"
1205,Fully Integrated On-FPGA Molecular Dynamics Simulations,"  The implementation of Molecular Dynamics (MD) on FPGAs has received
substantial attention. Previous work, however, has consisted of either
proof-of-concept implementations of components, usually the range-limited
force; full systems, but with much of the work shared by the host CPU; or
prototype demonstrations, e.g., using OpenCL, that neither implement a whole
system nor have competitive performance. In this paper, we present what we
believe to be the first full-scale FPGA-based simulation engine, and show that
its performance is competitive with a GPU (running Amber in an industrial
production environment). The system features on-chip particle data storage and
management, short- and long-range force evaluation, as well as bonded forces,
motion update, and particle migration. Other contributions of this work include
exploring numerous architectural trade-offs and analysis on various mappings
schemes among particles/cells and the various on-chip compute units. The
potential impact is that this system promises to be the basis for long
timescale Molecular Dynamics with a commodity cluster.
"
1206,Indicating Asynchronous Array Multipliers,"  Multiplication is an important arithmetic operation that is frequently
encountered in microprocessing and digital signal processing applications, and
multiplication is physically realized using a multiplier. This paper discusses
the physical implementation of many indicating asynchronous array multipliers,
which are inherently elastic and modular and are robust to timing, process and
parametric variations. We consider the physical realization of many indicating
asynchronous array multipliers using a 32/28nm CMOS technology. The
weak-indication array multipliers comprise strong-indication or weak-indication
full adders, and strong-indication 2-input AND functions to realize the partial
products. The multipliers were synthesized in a semi-custom ASIC design style
using standard library cells including a custom-designed 2-input C-element. 4x4
and 8x8 multiplication operations were considered for the physical
implementations. The 4-phase return-to-zero (RTZ) and the 4-phase return-to-one
(RTO) handshake protocols were utilized for data communication, and the
delay-insensitive dual-rail code was used for data encoding. Among several
weak-indication array multipliers, a weak-indication array multiplier utilizing
a biased weak-indication full adder and the strong-indication 2-input AND
function is found to have reduced cycle time and power-cycle time product with
respect to RTZ and RTO handshaking for 4x4 and 8x8 multiplications. Further,
the 4-phase RTO handshaking is found to be preferable to the 4-phase RTZ
handshaking for achieving enhanced optimizations of the design metrics.
"
1207,Exploiting Fine-Grain Ordered Parallelism in Dense Matrix Algorithms,"  Dense linear algebra kernels are critical for wireless applications, and the
oncoming proliferation of 5G only amplifies their importance. Many such matrix
algorithms are inductive, and exhibit ample amounts of fine-grain ordered
parallelism -- when multiple computations flow with fine-grain
producer/consumer dependences, and where the iteration domain is not easily
tileable. Synchronization overheads make multi-core parallelism ineffective and
the non-tileable iterations make the vector-VLIW approach less effective,
especially for the typically modest-sized matrices. Because CPUs and DSPs lose
order-of-magnitude performance/hardware utilization, costly and inflexible
ASICs are often employed in signal processing pipelines. A programmable
accelerator with similar performance/power/area would be highly desirable. We
find that fine-grain ordered parallelism can be exploited by supporting: 1.
fine-grain stream-based communication/synchronization; 2. inductive data-reuse
and memory access patterns; 3. implicit vector-masking for partial vectors; 4.
hardware specialization of dataflow criticality. In this work, we propose,
REVEL, as a next-generation DSP architecture. It supports the above features in
its ISA and microarchitecture, and further uses a novel vector-stream control
paradigm to reduce control overheads. Across a suite of linear algebra kernels,
REVEL outperforms equally provisioned DSPs by 4.6x-37x in latency and achieves
a performance per mm 2 of 8.3x. It is only 2.2x higher power to achieve the
same performance as ideal ASICs, at about 55% of the combined area.
"
1208,"Transfer and Online Reinforcement Learning in STT-MRAM Based Embedded
  Systems for Autonomous Drones","  In this paper we present an algorithm-hardware codesign for camera-based
autonomous flight in small drones. We show that the large write-latency and
write-energy for nonvolatile memory (NVM) based embedded systems makes them
unsuitable for real-time reinforcement learning (RL). We address this by
performing transfer learning (TL) on metaenvironments and RL on the last few
layers of a deep convolutional network. While the NVM stores the meta-model
from TL, an on-die SRAM stores the weights of the last few layers. Thus all the
real-time updates via RL are carried out on the SRAM arrays. This provides us
with a practical platform with comparable performance as end-to-end RL and
83.4% lower energy per image frame
"
1209,Fast TLB Simulation for RISC-V Systems,"  Address translation and protection play important roles in today's
processors, supporting multiprocessing and enforcing security. Historically,
the design of the address translation mechanisms has been closely tied to the
instruction set. In contrast, RISC-V defines its privileged specification in a
way that permits a variety of designs.
  An important part of the design space is the organisation of Translation
Lookaside Buffers (TLBs). This paper presents our recent work on simulating TLB
behaviours in multi-core RISC-V systems. Our TLB simulation framework allows
rapid, flexible and versatile prototyping of various hardware TLB design
choices, and enables validation, profiling and benchmarking of software running
on RISC-V systems. We show how this framework can be integrated with the
dynamic binary translated emulator QEMU to perform online simulation. When
simulating complicated multi-level shared TLB designs, the framework runs at
around 400 million instructions per second (MIPS) when simulating an 8-core
system. The performance overhead compared to unmodified QEMU is only 18% when
the benchmark's L1 TLB miss rate is 1%.
  We also demonstrate how this tool can be used to explore the instruction-set
level design space. We test a shared last-level TLB design that is not
currently permitted by the RISC-V's privileged specification. We then propose
an extension to RISC-V's virtual memory system design based on these
experimental results.
"
1210,"Reconfigurable Hardware Implementation of the Successive Overrelaxation
  Method","  In this chapter, we study the feasibility of implementing SOR in
reconfigurable hardware. We use Handel-C, a higher level design tool, to code
our design, which is analyzed, synthesized, and placed and routed using the
FPGAs proprietary software (DK Design Suite, Xilinx ISE 8.1i, and Quartus II
5.1). We target Virtex II Pro, Altera Stratix, and Spartan3L, which is embedded
in the RC10 FPGA-based system from Celoxica. We report our timing results when
targeting Virtex II Pro and compare them to software version results written in
C++ and running on a general purpose processor (GPP).
"
1211,"HALLS: An Energy-Efficient Highly Adaptable Last Level STT-RAM Cache for
  Multicore Systems","  Spin-Transfer Torque RAM (STT-RAM) is widely considered a promising
alternative to SRAM in the memory hierarchy due to STT-RAM's non-volatility,
low leakage power, high density, and fast read speed. The STT-RAM's small
feature size is particularly desirable for the last-level cache (LLC), which
typically consumes a large area of silicon die. However, long write latency and
high write energy still remain challenges of implementing STT-RAMs in the CPU
cache. An increasingly popular method for addressing this challenge involves
trading off the non-volatility for reduced write speed and write energy by
relaxing the STT-RAM's data retention time. However, in order to maximize
energy saving potential, the cache configurations, including STT-RAM's
retention time, must be dynamically adapted to executing applications' variable
memory needs. In this paper, we propose a highly adaptable last level STT-RAM
cache (HALLS) that allows the LLC configurations and retention time to be
adapted to applications' runtime execution requirements. We also propose
low-overhead runtime tuning algorithms to dynamically determine the best
(lowest energy) cache configurations and retention times for executing
applications. Compared to prior work, HALLS reduced the average energy
consumption by 60.57% in a quad-core system, while introducing marginal latency
overhead.
"
1212,"Low-power Programmable Processor for Fast Fourier Transform Based on
  Transport Triggered Architecture","  This paper describes a low-power processor tailored for fast Fourier
transform computations where transport triggering template is exploited. The
processor is software-programmable while retaining an energy-efficiency
comparable to existing fixed-function implementations. The power savings are
achieved by compressing the computation kernel into one instruction word. The
word is stored in an instruction loop buffer, which is more power-efficient
than regular instruction memory storage. The processor supports all
power-of-two FFT sizes from 64 to 16384 and given 1 mJ of energy, it can
compute 20916 transforms of size 1024.
"
1213,Performance Analysis of 6T and 9T SRAM,"  The SRAM cell is made up of latch, which ensures that the cell data is
preserved as long as power is turned on and refresh operation is not required
for the SRAM cell. SRAM is widely used for on-chip cache memory in
microprocessors, game software, computers, workstations, portable handheld
devices due to high data speed, low power consumption, low voltage supply,
no-refresh needed. Therefore, to build a reliable cache/memory, the individual
cell (SRAM) must be designed to have high Static Noise Margin (SNM). In
sub-threshold region, conventional 6T-cell SRAM experiences poor read and write
ability, and reduction in the SNM at various fluctuation of the threshold
voltage, supply voltage down scaling, and technology scaling in nano-meter
ranges (180nm, 90nm, 45nm, 22nm, 16nm and 10nm). Thus, noise margin becomes
worse during read and write operations compared to hold operation which the
internal feedback operates independent of the access transistors. Due to these
limitations of the conventional 6T SRAM cell, we have proposed a 9T SRAM that
will drastically minimize these limitations; the extra three transistors added
to the 6T topology will improve the read, hold and write SNM. The design and
simulation results were carried out using Cadence Virtuoso to evaluate the
performance of 6T and 9T SRAM cells.
"
1214,In-DRAM Bulk Bitwise Execution Engine,"  Many applications heavily use bitwise operations on large bitvectors as part
of their computation. In existing systems, performing such bulk bitwise
operations requires the processor to transfer a large amount of data on the
memory channel, thereby consuming high latency, memory bandwidth, and energy.
In this paper, we describe Ambit, a recently-proposed mechanism to perform bulk
bitwise operations completely inside main memory. Ambit exploits the internal
organization and analog operation of DRAM-based memory to achieve low cost,
high performance, and low energy. Ambit exposes a new bulk bitwise execution
model to the host processor. Evaluations show that Ambit significantly improves
the performance of several applications that use bulk bitwise operations,
including databases.
"
1215,Polystore++: Accelerated Polystore System for Heterogeneous Workloads,"  Modern real-time business analytic consist of heterogeneous workloads (e.g,
database queries, graph processing, and machine learning). These analytic
applications need programming environments that can capture all aspects of the
constituent workloads (including data models they work on and movement of data
across processing engines). Polystore systems suit such applications; however,
these systems currently execute on CPUs and the slowdown of Moore's Law means
they cannot meet the performance and efficiency requirements of modern
workloads. We envision Polystore++, an architecture to accelerate existing
polystore systems using hardware accelerators (e.g, FPGAs, CGRAs, and GPUs).
Polystore++ systems can achieve high performance at low power by identifying
and offloading components of a polystore system that are amenable to
acceleration using specialized hardware. Building a Polystore++ system is
challenging and introduces new research problems motivated by the use of
hardware accelerators (e.g, optimizing and mapping query plans across
heterogeneous computing units and exploiting hardware pipelining and
parallelism to improve performance). In this paper, we discuss these challenges
in detail and list possible approaches to address these problems.
"
1216,Indicating Asynchronous Multipliers,"  Multiplication is a basic arithmetic operation that is encountered in almost
all general-purpose microprocessing and digital signal processing applications,
and multiplication is physically realized using a multiplier. This paper
discusses the physical implementation of indicating asynchronous multipliers,
which are inherently elastic and are robust to timing, process, and parametric
variations, and are modular. We consider the physical implementation of many
weak-indication asynchronous multipliers using a 32/28-nm CMOS technology by
adopting the array multiplier architecture. The multipliers are synthesized in
a semi-custom ASIC-design style. The 4-phase return-to-zero (RTZ) and the
4-phase return-to-one (RTO) handshake protocols are considered for the data
communication. The multipliers are realized using strong-indication or
weak-indication full adders. Strong-indication 2-input AND function is used to
generate the partial products in the case of both RTZ and RTO handshaking. The
full adders considered are derived from different indicating asynchronous logic
design methods. Among the multipliers considered, a weak-indication
asynchronous multiplier utilizing the biased weak-indication full adder is
found to be efficient in terms of the cycle time and the power-cycle time
product with respect to both RTZ and RTO handshaking. Also, the 4-phase RTO
handshake protocol is found to be preferable than the 4-phase RTZ handshake
protocol for achieving enhanced optimizations in the design metrics.
"
1217,Fallout: Reading Kernel Writes From User Space,"  Recently, out-of-order execution, an important performance optimization in
modern high-end processors, has been revealed to pose a significant security
threat, allowing information leaks across security domains. In particular, the
Meltdown attack leaks information from the operating system kernel to user
space, completely eroding the security of the system. To address this and
similar attacks, without incurring the performance costs of software
countermeasures, Intel includes hardware-based defenses in its recent Coffee
Lake R processors.
  In this work, we show that the recent hardware defenses are not sufficient.
Specifically, we present Fallout, a new transient execution attack that leaks
information from a previously unexplored microarchitectural component called
the store buffer. We show how unprivileged user processes can exploit Fallout
to reconstruct privileged information recently written by the kernel. We
further show how Fallout can be used to bypass kernel address space
randomization. Finally, we identify and explore microcode assists as a hitherto
ignored cause of transient execution.
  Fallout affects all processor generations we have tested. However, we notice
a worrying regression, where the newer Coffee Lake R processors are more
vulnerable to Fallout than older generations.
"
1218,"iVAMS 1.0: Polynomial-Metamodel-Integrated Intelligent Verilog-AMS for
  Fast, Accurate Mixed-Signal Design Optimization","  Electronic circuit behavioral models built with hardware description/modeling
languages such as Verilog-AMS for system-level simulations are typically
functional models. They do not capture the physical design (layout) information
of the target design. Numerous iterations of post-layout design adjustments are
usually required to ensure that design specifications are met with the presence
of layout parasitics. In this paper a paradigm shift of the current trend is
presented that integrates layout-level information in Verilog-AMS through
metamodels such that system-level simulation of a mixed-signal circuit/system
is realistic and as accurate as true parasitic netlist simulation. The
simulations performed with these parasitic-aware models can be used to estimate
system performance without layout iterations. We call this new form of
Verilog-AMS as iVAMS (i.e. Intelligent Verilog-AMS). We call this iVAMS 1.0 as
it is simple polynomial-metamodel integrated Intelligent Verilog-AMS. As a
specific case study, a voltage-controlled oscillator (VCO) Verilog-AMS
behavioral model and design flow are proposed to assist fast PLL design space
exploration. The PLL simulation employing quadratic metamodels achieves
approximately 10X speedup compared to that employing the layout extracted,
parasitic netlist. The simulations using this behavioral model attain high
accuracy. The observed error for the simulated lock time and average power
dissipation are 0.7% and 3%, respectively. This behavioral metamodel approach
bridges the gap between layout-accurate but fast simulation and design space
exploration. The proposed method also allows much shorter design verification
and optimization to meet stringent time-to-market requirements. Compared to the
optimization using the layout netlist, the runtime using the behavioral model
is reduced by 88.9%.
"
1219,"Isolation-Aware Timing Analysis and Design Space Exploration for
  Predictable and Composable Many-Core Systems","  Composable many-core systems enable the independent development and analysis
of applications which will be executed on a shared platform where the mix of
concurrently executed applications may change dynamically at run time. For each
individual application, an off-line Design Space Exploration (DSE) is performed
to compute several mapping alternatives on the platform, offering
Pareto-optimal trade-offs in terms of real-time guarantees, resource usage,
etc. At run time, one mapping is then chosen to launch the application on
demand. In this context, to enable an independent analysis of each individual
application at design time, so-called inter-application isolation schemes are
applied which specify temporal or spatial isolation policies between
applications. S.o.t.a. composable many-core systems are developed based on a
fixed isolation scheme that is exclusively applied to every resource in every
mapping of every application and use a timing analysis tailored to that
isolation scheme to derive timing guarantees for each mapping. A fixed
isolation scheme, however, heavily restricts the explored space of solutions
and can, therefore, lead to suboptimality. Lifting this restriction
necessitates a timing analysis that is applicable to mappings with an arbitrary
mix of isolation schemes on different resources. To address this issue, we
present an isolation-aware timing analysis that unlike existing analyses can
handle multiple isolation schemes in combination within one mapping and
delivers safe yet tight timing bounds by identifying and excluding interference
scenarios that can never happen under the given combination of isolation
schemes. Based on the timing analysis, we present a DSE which explores the
choices of isolation scheme per resource within each mapping. Experimental
results demonstrate the advantage of the proposed approach over approaches
based on a fixed isolation scheme.
"
1220,"Sparse Matrix to Matrix Multiplication: A Representation and
  Architecture for Acceleration (long version)","  Accelerators for sparse matrix multiplication are important components in
emerging systems. In this paper, we study the main challenges of accelerating
Sparse Matrix Multiplication (SpMM). For the situations that data is not stored
in the desired order (row/column order), we propose a compact high performance
sparse format, which allows for random access to a dataset with low memory
access overhead. We show that using this format results in a 14-49 times
speedup for SpMM. Next, we propose a high performance systolic architecture for
SpMM, which uses a mesh of comparators to locate the useful (non-zero)
computation. This design maximizes data reuse by sharing the input data among a
row/column of the mesh. We also show that, with similar memory access
assumptions, the proposed architecture results in a 9-30 times speedup in
comparison with the state of the art.
"
1221,"Ara: A 1 GHz+ Scalable and Energy-Efficient RISC-V Vector Processor with
  Multi-Precision Floating Point Support in 22 nm FD-SOI","  In this paper, we present Ara, a 64-bit vector processor based on the version
0.5 draft of RISC-V's vector extension, implemented in GlobalFoundries 22FDX
FD-SOI technology. Ara's microarchitecture is scalable, as it is composed of a
set of identical lanes, each containing part of the processor's vector register
file and functional units. It achieves up to 97% FPU utilization when running a
256 x 256 double precision matrix multiplication on sixteen lanes. Ara runs at
more than 1 GHz in the typical corner (TT/0.80V/25 oC) achieving a performance
up to 33 DP-GFLOPS. In terms of energy efficiency, Ara achieves up to 41
DP-GFLOPS/W under the same conditions, which is slightly superior to similar
vector processors found in literature. An analysis on several vectorizable
linear algebra computation kernels for a range of different matrix and vector
sizes gives insight into performance limitations and bottlenecks for vector
processors and outlines directions to maintain high energy efficiency even for
small matrix sizes where the vector architecture achieves suboptimal
utilization of the available FPUs.
"
1222,Pangloss: a novel Markov chain prefetcher,"  We present Pangloss, an efficient high-performance data prefetcher that
approximates a Markov chain on delta transitions. With a limited information
scope and space/logic complexity, it is able to reconstruct a variety of both
simple and complex access patterns. This is achieved by a highly-efficient
representation of the Markov chain to provide accurate values for transition
probabilities. In addition, we have added a mechanism to reconstruct delta
transitions originally obfuscated by the out-of-order execution or page
transitions, such as when streaming data from multiple sources. Our
single-level (L2) prefetcher achieves a geometric speedup of 1.7% and 3.2% over
selected state-of-the-art baselines (KPCP and BOP). When combined with an
equivalent for the L1 cache (L1 & L2), the speedups rise to 6.8% and 8.4%, and
40.4% over non-prefetch. In the multi-core evaluation, there seems to be a
considerable performance improvement as well.
"
1223,Practical Byte-Granular Memory Blacklisting using Califorms,"  Recent rapid strides in memory safety tools and hardware have improved
software quality and security. While coarse-grained memory safety has improved,
achieving memory safety at the granularity of individual objects remains a
challenge due to high performance overheads which can be between ~1.7x-2.2x. In
this paper, we present a novel idea called Califorms, and associated program
observations, to obtain a low overhead security solution for practical,
byte-granular memory safety.
  The idea we build on is called memory blacklisting, which prohibits a program
from accessing certain memory regions based on program semantics. State of the
art hardware-supported memory blacklisting while much faster than software
blacklisting creates memory fragmentation (of the order of few bytes) for each
use of the blacklisted location. In this paper, we observe that metadata used
for blacklisting can be stored in dead spaces in a program's data memory and
that this metadata can be integrated into microarchitecture by changing the
cache line format. Using these observations, Califorms based system proposed in
this paper reduces the performance overheads of memory safety to ~1.02x-1.16x
while providing byte-granular protection and maintaining very low hardware
overheads.
  The low overhead offered by Califorms enables always on, memory safety for
small and large objects alike, and the fundamental idea of storing metadata in
empty spaces, and microarchitecture can be used for other security and
performance applications.
"
1224,Transport Triggered Array Processor for Vision Applications,"  Low-level sensory data processing in many Internet-of-Things (IoT) devices
pursue energy efficiency by utilizing sleep modes or slowing the clocking to
the minimum. To curb the share of stand-by power dissipation in those designs,
near-threshold/sub-threshold operational points or ultra-low-leakage processes
in fabrication are employed. Those limit the clocking rates significantly,
reducing the computing throughputs of individual processing cores. In this
contribution we explore compensating for the performance loss of operating in
near-threshold region (Vdd =0.6V) through massive parallelization. Benefits of
near-threshold operation and massive parallelism are optimum energy consumption
per instruction operation and minimized memory roundtrips, respectively. The
Processing Elements (PE) of the design are based on Transport Triggered
Architecture. The fine grained programmable parallel solution allows for fast
and efficient computation of learnable low-level features (e.g. local binary
descriptors and convolutions). Other operations, including Max-pooling have
also been implemented. The programmable design achieves excellent energy
efficiency for Local Binary Patterns computations.
"
1225,"Data Conversion in Area-Constrained Applications: the Wireless
  Network-on-Chip Case","  Network-on-Chip (NoC) is currently the paradigm of choice to interconnect the
different components of System-on-Chips (SoCs) or Chip Multiprocessors (CMPs).
As the levels of integration continue to grow, however, current NoCs face
significant scalability limitations and have prompted research in novel
interconnect technologies. Among these, wireless intra-chip communications have
been under intense scrutiny due to their low latency broadcast and
architectural flexibility. Thus far, the practicality of the idea has been
studied from the RF front-end and the network interface perspectives, whereas
little to no attention has been placed on another essential component: the data
converters. This article aims to fill this gap by providing a comprehensive
analysis of the requirements of the scenario, as well as of the current
performance and cost trends of Analog-to-Digital Converters (ADCs). Based on
Murmann's data, we demonstrate that ADCs will not be a roadblock for the
realization of wireless intra-chip communications although current designs do
not meet their demands fully.
"
1226,Thread Batching for High-performance Energy-efficient GPU Memory Design,"  Massive multi-threading in GPU imposes tremendous pressure on memory
subsystems. Due to rapid growth in thread-level parallelism of GPU and slowly
improved peak memory bandwidth, the memory becomes a bottleneck of GPU's
performance and energy efficiency. In this work, we propose an integrated
architectural scheme to optimize the memory accesses and therefore boost the
performance and energy efficiency of GPU. Firstly, we propose a thread batch
enabled memory partitioning (TEMP) to improve GPU memory access parallelism. In
particular, TEMP groups multiple thread blocks that share the same set of pages
into a thread batch and applies a page coloring mechanism to bound each stream
multiprocessor (SM) to the dedicated memory banks. After that, TEMP dispatches
the thread batch to an SM to ensure high-parallel memory-access streaming from
the different thread blocks. Secondly, a thread batch-aware scheduling (TBAS)
scheme is introduced to improve the GPU memory access locality and to reduce
the contention on memory controllers and interconnection networks. Experimental
results show that the integration of TEMP and TBAS can achieve up to 10.3%
performance improvement and 11.3% DRAM energy reduction across diverse GPU
applications. We also evaluate the performance interference of the mixed
CPU+GPU workloads when they are run on a heterogeneous system that employs our
proposed schemes. Our results show that a simple solution can effectively
ensure the efficient execution of both GPU and CPU applications.
"
1227,"An Overview of In-memory Processing with Emerging Non-volatile Memory
  for Data-intensive Applications","  The conventional von Neumann architecture has been revealed as a major
performance and energy bottleneck for rising data-intensive applications. %,
due to the intensive data movements. The decade-old idea of leveraging
in-memory processing to eliminate substantial data movements has returned and
led extensive research activities. The effectiveness of in-memory processing
heavily relies on memory scalability, which cannot be satisfied by traditional
memory technologies. Emerging non-volatile memories (eNVMs) that pose appealing
qualities such as excellent scaling and low energy consumption, on the other
hand, have been heavily investigated and explored for realizing in-memory
processing architecture. In this paper, we summarize the recent research
progress in eNVM-based in-memory processing from various aspects, including the
adopted memory technologies, locations of the in-memory processing in the
system, supported arithmetics, as well as applied applications.
"
1228,"Branch Prediction Is Not a Solved Problem: Measurements, Opportunities,
  and Future Directions","  Modern branch predictors predict the vast majority of conditional branch
instructions with near-perfect accuracy, allowing superscalar, out-of-order
processors to maximize speculative efficiency and thus performance. However,
this impressive overall effectiveness belies a substantial missed opportunity
in single-threaded instructions per cycle (IPC). For example, we show that
correcting the mispredictions made by the state-of-the-art TAGE-SC-L branch
predictor on SPECint 2017 would improve IPC by margins similar to an advance in
process technology node.
  In this work, we measure and characterize these mispredictions. We find that
they categorically arise from either (1) a small number of systematically
hard-to-predict (H2P) branches; or (2) rare branches with low dynamic execution
counts. Using data from SPECint 2017 and additional large code footprint
applications, we quantify the occurrence and IPC impact of these two
categories. We then demonstrate that increasing the resources afforded to
existing branch predictors does not alone address the root causes of most
mispredictions. This leads us to reexamine basic assumptions in branch
prediction and to propose new research directions that, for example, deploy
machine learning to improve pattern matching for H2Ps, and use on-chip phase
learning to track long-term statistics for rare branches.
"
1229,"A Retrospective Recount of Computer Architecture Research with a
  Data-Driven Study of Over Four Decades of ISCA Publications","  This study began with a research project, called DISCvR, conducted at the
IBM-ILLINOIS Center for Cognitive Computing Systems Reseach. The goal of DISCvR
was to build a practical NLP based AI pipeline for document understanding which
will help us better understand the computation patterns and requirements of
modern computing systems. While building such a prototype, an early use case
came to us thanks to the 2017 IEEE/ACM International Symposium on
Microarchitecture (MICRO-50) Program Co-chairs, Drs. Hillery Hunter and Jaime
Moreno. They asked us if we can perform some data-driven analysis of the past
50 years of MICRO papers and show some interesting historical perspectives on
MICRO's 50 years of publication. We learned two important lessons from that
experience: (1) building an AI solution to truly understand unstructured data
is hard in spite of the many claimed successes in natural language
understanding; and (2) providing a data-driven perspective on computer
architecture research is a very interesting and fun project. Recently we
decided to conduct a more thorough study based on all past papers of
International Symposium on Computer Architecture (ISCA) from 1973 to 2018,
which resulted this article. We recognize that we have just scratched the
surface of natural language understanding of unstructured data, and there are
many more aspects that we can improve. But even with our current study, we felt
there were enough interesting findings that may be worthwhile to share with the
community. Hence we decided to write this article to summarize our findings so
far based only on ISCA publications. Our hope is to generate further interests
from the community in this topic, and we welcome collaboration from the
community to deepen our understanding both of the computer architecture
research and of the challenges of NLP-based AI solutions.
"
1230,"Adaptive Precision CNN Accelerator Using Radix-X Parallel Connected
  Memristor Crossbars","  Neural processor development is reducing our reliance on remote server access
to process deep learning operations in an increasingly edge-driven world. By
employing in-memory processing, parallelization techniques, and
algorithm-hardware co-design, memristor crossbar arrays are known to
efficiently compute large scale matrix-vector multiplications. However,
state-of-the-art implementations of negative weights require duplicative column
wires, and high precision weights using single-bit memristors further
distributes computations. These constraints dramatically increase chip area and
resistive losses, which lead to increased power consumption and reduced
accuracy. In this paper, we develop an adaptive precision method by varying the
number of memristors at each crosspoint. We also present a weight mapping
algorithm designed for implementation on our crossbar array. This novel
algorithm-hardware solution is described as the radix-X Convolutional Neural
Network Crossbar Array, and demonstrate how to efficiently represent negative
weights using a single column line, rather than double the number of additional
columns. Using both simulation and experimental results, we verify that our
radix-5 CNN array achieves a validation accuracy of 90.5% on the CIFAR-10
dataset, a 4.5% improvement over binarized neural networks whilst
simultaneously reducing crossbar area by 46% over conventional arrays by
removing the need for duplicate columns to represent signed weights.
"
1231,Automatic Conversion from Flip-flop to 3-phase Latch-based Designs,"  Latch-based designs have many benefits over their flip-flop based
counterparts but have limited use partially because most RTL specifications are
flop-centric and automatic conversion of FF to latch-based designs is
challenging. Conventional conversion algorithms target master-slave latch-based
designs with two non-overlapping clocks. This paper presents a novel automated
design flow that converts flip-flop to 3-phase latch-based designs. The
resulting circuits have the same performance as the master-slave based designs
but require significantly less latches. Our experimental results demonstrate
the potential for savings in the number of latches (21.3%), area (5.8%), and
power (16.3%) on a variety of ISCAS, CEP, and CPU benchmark circuits, compared
to the master-slave conversions.
"
1232,FPGA-based Multi-Chip Module for High-Performance Computing,"  Current integration, architectural design and manufacturing technologies are
not suited for the computing density and power efficiency requested by Exascale
computing. New approaches in hardware architecture are thus needed to overcome
the technological barriers preventing the transition to the Exascale era. In
that scope, we report successful fabrication of first ExaNoDe's MCM prototypes
dedicated to Exascale computing applications. Each MCM was composed of 2 Xilinx
Zynq Ultrascale+ MPSoC, assembled on advanced 68.5 mm x 55 mm laminate
substrates specifically designed and fabricated for the project. Acoustic
microscopy, x-ray, cross-section and Thermo-Moire investigations revealed no
voids, shorts, delamination, cracks or warpage issues. Two MCMs were mounted on
a daughter board by FORTH for testing purposes. The DDR memories on the 4
SODIMMs of the daughter board were successfully tested by running extensive
Xilinx memory tests with clock frequencies of 1866 MHz and 2133 MHz. All 4
FPGAs were programmed with the Xilinx integrated bit error ratio test (IBERT)
tailored for this board for links testing. All intra-board high-speed links
between all FPGAs were stable at 10 Gbps, even under the more demanding 31-bit
PRBS (Pseudorandom Binary Sequence) tests.
"
1233,"Mixed-Signal Charge-Domain Acceleration of Deep Neural networks through
  Interleaved Bit-Partitioned Arithmetic","  Low-power potential of mixed-signal design makes it an alluring option to
accelerate Deep Neural Networks (DNNs). However, mixed-signal circuitry suffers
from limited range for information encoding, susceptibility to noise, and
Analog to Digital (A/D) conversion overheads. This paper aims to address these
challenges by offering and leveraging the insight that a vector dot-product
(the basic operation in DNNs) can be bit-partitioned into groups of spatially
parallel low-bitwidth operations, and interleaved across multiple elements of
the vectors. As such, the building blocks of our accelerator become a group of
wide, yet low-bitwidth multiply-accumulate units that operate in the analog
domain and share a single A/D converter. The low-bitwidth operation tackles the
encoding range limitation and facilitates noise mitigation. Moreover, we
utilize the switched-capacitor design for our bit-level reformulation of DNN
operations. The proposed switched-capacitor circuitry performs the group
multiplications in the charge domain and accumulates the results of the group
in its capacitors over multiple cycles. The capacitive accumulation combined
with wide bit-partitioned operations alleviate the need for A/D conversion per
operation. With such mathematical reformulation and its switched-capacitor
implementation, we define a 3D-stacked microarchitecture, dubbed BIHIWE.
"
1234,"Bridging the Architecture Gap: Abstracting Performance-Relevant
  Properties of Modern Server Processors","  We describe a universal modeling approach for predicting single- and
multicore runtime of steady-state loops on server processors. To this end we
strictly differentiate between application and machine models: An application
model comprises the loop code, problem sizes, and other runtime parameters,
while a machine model is an abstraction of all performance-relevant properties
of a CPU. We introduce a generic method for determining machine models and
present results for relevant server-processor architectures by Intel, AMD, IBM,
and Marvell/Cavium. Considering this wide range of architectures, the set of
features required for adequate performance modeling is surprisingly small. To
validate our approach, we compare performance predictions to empirical data for
an OpenMP-parallel preconditioned CG algorithm, which includes compute- and
memory-bound kernels. Both single- and multicore analysis shows that the model
exhibits average and maximum relative errors of 5% and 10%. Deviations from the
model and insights gained are discussed in detail.
"
1235,HTS: A Hardware Task Scheduler for Heterogeneous Systems,"  As the Moore's scaling era comes to an end, application specific hardware
accelerators appear as an attractive way to improve the performance and power
efficiency of our computing systems. A massively heterogeneous system with a
large number of hardware accelerators along with multiple general purpose CPUs
is a promising direction, but pose several challenges in terms of the run-time
scheduling of tasks on the accelerators and design granularity of accelerators.
This paper addresses these challenges by developing an example heterogeneous
system to enable multiple applications to share the available accelerators. We
propose to design accelerators at a lower abstraction to enable applications to
be broken down into tasks that can be mapped on several accelerators. We
observe that several real-life workloads can be broken down into common
primitives that are shared across many workloads. Finally, we propose and
design a hardware task scheduler inspired by the hardware schedulers in
out-of-order superscalar processors to efficiently utilize the accelerators in
the system by scheduling tasks in out-of-order and even speculatively. We
evaluate the proposed system on both real-life and synthetic benchmarks based
on Digital Signal Processing~(DSP) applications. Compared to executing the
benchmark on a system with sequential scheduling, proposed scheduler achieves
up to 12x improvement in performance.
"
1236,On the Optimal Refresh Power Allocation for Energy-Efficient Memories,"  Refresh is an important operation to prevent loss of data in dynamic
random-access memory (DRAM). However, frequent refresh operations incur
considerable power consumption and degrade system performance. Refresh power
cost is especially significant in high-capacity memory devices and
battery-powered edge/mobile applications. In this paper, we propose a
principled approach to optimizing the refresh power allocation. Given a model
for the bit error rate dependence on power, we formulate a convex optimization
problem to minimize the word mean squared error for a refresh power constraint;
hence we can guarantee the optimality of the obtained refresh power
allocations. In addition, we provide an integer programming problem to optimize
the discrete refresh interval assignments. For an 8-bit accessed word,
numerical results show that the optimized nonuniform refresh intervals reduce
the refresh power by 29% at a peak signal-to-noise ratio of 50dB compared to
the uniform assignment.
"
1237,Tucker Tensor Decomposition on FPGA,"  Tensor computation has emerged as a powerful mathematical tool for solving
high-dimensional and/or extreme-scale problems in science and engineering. The
last decade has witnessed tremendous advancement of tensor computation and its
applications in machine learning and big data. However, its hardware
optimization on resource-constrained devices remains an (almost) unexplored
field. This paper presents an hardware accelerator for a classical tensor
computation framework, Tucker decomposition. We study three modules of this
architecture: tensor-times-matrix (TTM), matrix singular value decomposition
(SVD), and tensor permutation, and implemented them on Xilinx FPGA for
prototyping. In order to further reduce the computing time, a warm-start
algorithm for the Jacobi iterations in SVD is proposed. A fixed-point simulator
is used to evaluate the performance of our design. Some synthetic data sets and
a real MRI data set are used to validate the design and evaluate its
performance. We compare our work with state-of-the-art software toolboxes
running on both CPU and GPU, and our work shows 2.16 - 30.2x speedup on the
cardiac MRI data set.
"
1238,"To Update or Not To Update?: Bandwidth-Efficient Intelligent Replacement
  Policies for DRAM Caches","  This paper investigates intelligent replacement policies for improving the
hit-rate of gigascale DRAM caches. Cache replacement policies are commonly used
to improve the hit-rate of on-chip caches. The most effective replacement
policies often require the cache to track per-line reuse state to inform their
decision. A fundamental challenge on DRAM caches, however, is that stateful
policies would require significant bandwidth to maintain per-line DRAM cache
state. As such, DRAM cache replacement policies have primarily been stateless
policies, such as always-install or probabilistic bypass. Unfortunately, we
find that stateless policies are often too coarse-grain and become ineffective
at the size and associativity of DRAM caches. Ideally, we want a replacement
policy that can obtain the hit-rate benefits of stateful replacement policies,
but keep the bandwidth-efficiency of stateless policies.
  In our study, we find that tracking per-line reuse state can enable an
effective replacement policy that can mitigate common thrashing patterns seen
in gigascale caches. We propose a stateful replacement/bypass policy called
RRIP Age-On-Bypass (RRIP-AOB), that tracks reuse state for high-reuse lines,
protects such lines by bypassing other lines, and Ages the state On cache
Bypass. Unfortunately, such a stateful technique requires significant bandwidth
to update state. To this end, we propose Efficient Tracking of Reuse (ETR). ETR
makes state tracking efficient by accurately tracking the state of only one
line from a region, and using the state of that line to guide the replacement
decisions for other lines in that region. ETR reduces the bandwidth for
tracking replacement state by 70%, and makes stateful policies practical for
DRAM caches. Our evaluations with a 2GB DRAM cache, show that our RRIP-AOB and
ETR techniques provide 18% speedup while needing less than 1KB of SRAM.
"
1239,"TicToc: Enabling Bandwidth-Efficient DRAM Caching for both Hits and
  Misses in Hybrid Memory Systems","  This paper investigates bandwidth-efficient DRAM caching for hybrid DRAM +
3D-XPoint memories. 3D-XPoint is becoming a viable alternative to DRAM as it
enables high-capacity and non-volatile main memory systems; however, 3D-XPoint
has 4-8x slower read, and worse writes. As such, effective DRAM caching in
front of 3D-XPoint is important to enable a high-capacity, low-latency, and
high-write-bandwidth memory. There are two major approaches for DRAM cache
design: (1) a Tag-Inside-Cacheline (TIC) organization that optimizes for hits,
by storing tag next to each line such that one access gets both tag and data,
and (2) a Tag-Outside-Cacheline (TOC) organization that optimizes for misses,
by storing tags from multiple data-lines together such that one tag-access gets
info for several data-lines. Ideally, we desire the low hit-latency of TIC, and
the low miss-bandwidth of TOC. To this end, we propose TicToc, an organization
that provisions both TIC and TOC to get hit and miss benefits of both.
  However, we find that naively combining both actually performs worse than
TIC, because one needs to pay bandwidth to maintain both metadata. The main
contribution of this work is developing architectural techniques to reduce the
bandwidth of maintaining both TIC and TOC metadata. We find the majority of the
bandwidth cost is due to maintaining TOC dirty bits. We propose DRAM Cache
Dirtiness Bit, which carries DRAM cache dirty info to last-level caches, to
prune repeated dirty-bit checks for known dirty lines. We then propose
Preemptive Dirty Marking, which predicts which lines will be written and
proactively marks dirty bit at install time, to amortize the initial dirty-bit
update. Our evaluations on a 4GB DRAM cache with 3D-XPoint memory show that
TicToc enables 10% speedup over baseline TIC, nearing 14% speedup possible with
an idealized DRAM cache w/ 64MB of SRAM tags, while needing only 34KB SRAM.
"
1240,"FusionAccel: A General Re-configurable Deep Learning Inference
  Accelerator on FPGA for Convolutional Neural Networks","  The deep learning accelerator is one of the methods to accelerate deep
learning network computations, which is mainly based on convolutional neural
network acceleration. To address the fact that concurrent convolutional neural
network accelerators are not solely open-source and the exclusiveness of
platforms, FusionAccel, a scalable convolutional neural network accelerator
hardware architecture with supporting software is proposed. It can adapt to
different network structures and can be reconstructed before compilation and
reconfigured at runtime. This paper realizes this RTL convolutional neural
network accelerator design and functional verifications on a Xilinx Spartan-6
FPGA. The result is identical to that of Caffe-CPU. Since the entire project is
based on RTL, it can be migrated to ASIC after replacing some FPGA-specific
IPs.
"
1241,"A Range Matching CAM for Hierarchical Defect Tolerance Technique in NRAM
  Structures","  Due to the small size of nanoscale devices, they are highly prone to process
disturbances which results in manufacturing defects. Some of the defects are
randomly distributed throughout the nanodevice layer. Other disturbances tend
to be local and lead to cluster defects caused by factors such as layer
misintegration and line width variations. In this paper, we propose a method
for identifying cluster defects from random ones. The motivation is to repair
the cluster defects using rectangular ranges in a range matching
content-addressable memory (RM-CAM) and random defects using triple-modular
redundancy (TMR). It is believed a combination of these two approaches is more
effective for repairing defects at high error rate with less resource. With the
proposed fault repairing technique, defect recovery results are examined for
different fault distribution scenarios. Also the mapping circuit structure
required for two conceptual 32*32 and 64*64 bit RAMs are presented and their
speed, power and transistor count are reported.
"
1242,"Fast Modeling L2 Cache Reuse Distance Histograms Using Combined Locality
  Information from Software Traces","  To mitigate the performance gap between CPU and the main memory, multi-level
cache architectures are widely used in modern processors. Therefore, modeling
the behaviors of the downstream caches becomes a critical part of the processor
performance evaluation in the early stage of Design Space Exploration (DSE). In
this paper, we propose a fast and accurate L2 cache reuse distance histogram
model, which can be used to predict the behaviors of the multi-level cache
architectures where the L1 cache uses the LRU replacement policy and the L2
cache uses LRU/Random replacement policies. We use the profiled L1 reuse
distance histogram and two newly proposed metrics, namely the RST table and the
Hit-RDH, that describing more detailed information of the software traces as
the inputs. For a given L1 cache configuration, the profiling results can be
reused for different configurations of the L2 cache. The output of our model is
the L2 cache reuse distance histogram, based on which the L2 cache miss rates
can be evaluated. We compare the L2 cache miss rates with the results from gem5
cycle-accurate simulations of 15 benchmarks chosen from SPEC CPU 2006 and 9
benchmarks from SPEC CPU 2017. The average absolute error is less than 5%,
while the evaluation time for each L2 configuration can be sped up almost 30X
for four L2 cache candidates.
"
1243,"Efficient Uncertainty Modeling for System Design via Mixed Integer
  Programming","  The post-Moore era casts a shadow of uncertainty on many aspects of computer
system design. Managing that uncertainty requires new algorithmic tools to make
quantitative assessments. While prior uncertainty quantification methods, such
as generalized polynomial chaos (gPC), show how to work precisely under the
uncertainty inherent to physical devices, these approaches focus solely on
variables from a continuous domain. However, as one moves up the system stack
to the architecture level many parameters are constrained to a discrete
(integer) domain. This paper proposes an efficient and accurate uncertainty
modeling technique, named mixed generalized polynomial chaos (M-gPC), for
architectural uncertainty analysis. The M-gPC technique extends the generalized
polynomial chaos (gPC) theory originally developed in the uncertainty
quantification community, such that it can efficiently handle the mixed-type
(i.e., both continuous and discrete) uncertainties in computer architecture
design. Specifically, we employ some stochastic basis functions to capture the
architecture-level impact caused by uncertain parameters in a simulator. We
also develop a novel mixed-integer programming method to select a small number
of uncertain parameter samples for detailed simulations. With a few highly
informative simulation samples, an accurate surrogate model is constructed in
place of cycle-level simulators for various architectural uncertainty analysis.
In the chip-multiprocessor (CMP) model, we are able to estimate the propagated
uncertainties with only 95 samples whereas Monte Carlo requires 5*10^4 samples
to achieve the similar accuracy. We also demonstrate the efficiency and
effectiveness of our method on a detailed DRAM subsystem.
"
1244,Coprocessors: failures and successes,"  The appearance and disappearance of coprocessors by integration into the CPU,
the success or failure of coprocessors are examined by summarizing their
characteristics from the mainframes of the 1960s. The coprocessors most
particularly reviewed are the IBM 360 and CDC-6600 I/O processors, the Intel
8087 math coprocessor, the Cell processor, the Intel Xeon Phi coprocessors, the
GPUs, the FPGAs, and the coprocessors of manycores SW26010 and Pezy SC-2 used
in high-ranked supercomputers in the TOP500 or Green500. The conditions for a
coprocessor to be viable in the medium or long-term are defined.
"
1245,CADS: Core-Aware Dynamic Scheduler for Multicore Memory Controllers,"  Memory controller scheduling is crucial in multicore processors, where DRAM
bandwidth is shared. Since increased number of requests from multiple cores of
processors becomes a source of bottleneck, scheduling the requests efficiently
is necessary to utilize all the computing power these processors offer.
However, current multicore processors are using traditional memory controllers,
which are designed for single-core processors. They are unable to adapt to
changing characteristics of memory workloads that run simultaneously on
multiple cores. Existing schedulers may disrupt locality and bank parallelism
among data requests coming from different cores. Hence, novel memory
controllers that consider and adapt to the memory access characteristics, and
share memory resources efficiently and fairly are necessary. We introduce
Core-Aware Dynamic Scheduler (CADS) for multicore memory controller. CADS uses
Reinforcement Learning (RL) to alter its scheduling strategy dynamically at
runtime. Our scheduler utilizes locality among data requests from multiple
cores and exploits parallelism in accessing multiple banks of DRAM. CADS is
also able to share the DRAM while guaranteeing fairness to all cores accessing
memory. Using CADS policy, we achieve 20% better cycles per instruction (CPI)
in running memory intensive and compute intensive PARSEC parallel benchmarks
simultaneously, and 16% better CPI with SPEC 2006 benchmarks.
"
1246,"PPAC: A Versatile In-Memory Accelerator for Matrix-Vector-Product-Like
  Operations","  Processing in memory (PIM) moves computation into memories with the goal of
improving throughput and energy-efficiency compared to traditional von
Neumann-based architectures. Most existing PIM architectures are either
general-purpose but only support atomistic operations, or are specialized to
accelerate a single task. We propose the Parallel Processor in Associative
Content-addressable memory (PPAC), a novel in-memory accelerator that supports
a range of matrix-vector-product (MVP)-like operations that find use in
traditional and emerging applications. PPAC is, for example, able to accelerate
low-precision neural networks, exact/approximate hash lookups, cryptography,
and forward error correction. The fully-digital nature of PPAC enables its
implementation with standard-cell-based CMOS, which facilitates automated
design and portability among technology nodes. To demonstrate the efficacy of
PPAC, we provide post-layout implementation results in 28nm CMOS for different
array sizes. A comparison with recent digital and mixed-signal PIM accelerators
reveals that PPAC is competitive in terms of throughput and energy-efficiency,
while accelerating a wide range of applications and simplifying development.
"
1247,"Reconfigurable multiplier architecture based on memristor-cmos with
  higher flexibility","  Multiplication is an indispensable operation in most of digital signal
processing systems. Recently, many systems need to execute different types of
algorithms on a multiplier. Therefore, it needs complicated computation and
large area occupation. In this regard a fixed multiplier is inefficient and the
development of a reconfigurable multiplier becomes increasingly important. The
advent of memristor-CMOS hybrid circuits provides an opportunity for reducing
area occupation. This paper introduces memristor-CMOS based reconfigurable
multiplier which provides flexible multiplication according to various
bit-width. Performance of the proposed multiplier is estimated with some
applications and comparison with conventional multipliers, using memristor
SPICE model and proprietary 180-nm CMOS process.
"
1248,Performance Comparison of Quasi-Delay-Insensitive Asynchronous Adders,"  In this technical note, we provide a comparison of the design metrics of
various quasi-delay-insensitive (QDI) asynchronous adders, where the adders
correspond to diverse architectures. QDI adders are robust, and the objective
of this technical note is to point to those QDI adders which are suitable for
low power/energy and less area. This information could be valuable for a
resource-constrained low power VLSI design scenario. Non-QDI adders are
excluded from the comparison since they are not robust although they may have
optimized design metrics. All the QDI adders were realized using a 32/28nm CMOS
process.
"
1249,"The Preliminary Evaluation of a Hypervisor-based Virtualization
  Mechanism for Intel Optane DC Persistent Memory Module","  Non-volatile memory (NVM) technologies, being accessible in the same manner
as DRAM, are considered indispensable for expanding main memory capacities.
Intel Optane DCPMM is a long-awaited product that drastically increases main
memory capacities. However, a substantial performance gap exists between DRAM
and DCPMM. In our experiments, the read/write latencies of DCPMM were 400% and
407% higher than those of DRAM, respectively. The read/write bandwidths were
37% and 8% of those of DRAM. This performance gap in main memory presents a new
challenge to researchers; we need a new system software technology supporting
emerging hybrid memory architecture. In this paper, we present RAMinate, a
hypervisor-based virtualization mechanism for hybrid memory systems, and a key
technology to address the performance gap in main memory systems. It provides
great flexibility in memory management and maximizes the performance of virtual
machines (VMs) by dynamically optimizing memory mappings. Through experiments,
we confirmed that even though a VM has only 1% of DRAM in its RAM, the
performance degradation of the VM was drastically alleviated by memory mapping
optimization. The elapsed time to finish the build of Linux Kernel in the VM
was 557 seconds, which was only 13% increase from the 100% DRAM case (i.e., 495
seconds). When the optimization mechanism was disabled, the elapsed time
increased to 624 seconds (i.e. 26% increase from the 100% DRAM case).
"
1250,Mixed-level identification of fault redundancy in microprocessors,"  A new high-level implementation independent functional fault model for
control faults in microprocessors is introduced. The fault model is based on
the instruction set, and is specified as a set of data constraints to be
satisfied by test data generation. We show that the high-level test, which
satisfies these data constraints, will be sufficient to guarantee the detection
of all non-redundant low level faults. The paper proposes a simple and fast
simulation based method of generating test data, which satisfy the constraints
prescribed by the proposed fault model, and a method of evaluating the
high-level control fault coverage for the proposed fault model and for the
given test. A method is presented for identification of the high-level
redundant faults, and it is shown that a test, which provides 100% coverage of
non-redundant high-level faults, will also guarantee 100% non-redundant SAF
coverage, whereas all gate-level SAF not covered by the test are identified as
redundant. Experimental results of test generation for the execution part of a
microprocessor support the results presented in the paper.
"
1251,"A Communication-Centric Observability Selection for Post-Silicon
  System-on-Chip Integration Debug","  Reconstruction of how components communicate with each other during system
execution is crucial for debugging system-on-chip designs. However, limited
observability is the major obstacle to the efficient and accurate
reconstruction in the post-silicon validation stage. This paper addresses that
problem by proposing several communication event selection methods guided by
system-level communication protocols. Such methods are optimized for on-chip
communication event tracing infrastructure to enhance observability. The
effectiveness of these methods are demonstrated with experiments on a
non-trivial multicore SoC prototype. The results show that with the proposed
method, more comprehensive information on system internal execution can be
inferred from traces under limited observability.
"
1252,"A Workload and Programming Ease Driven Perspective of
  Processing-in-Memory","  Many modern and emerging applications must process increasingly large volumes
of data. Unfortunately, prevalent computing paradigms are not designed to
efficiently handle such large-scale data: the energy and performance costs to
move this data between the memory subsystem and the CPU now dominate the total
costs of computation. This forces system architects and designers to
fundamentally rethink how to design computers. Processing-in-memory (PIM) is a
computing paradigm that avoids most data movement costs by bringing computation
to the data. New opportunities in modern memory systems are enabling
architectures that can perform varying degrees of processing inside the memory
subsystem. However, there are many practical system-level issues that must be
tackled to construct PIM architectures, including enabling workloads and
programmers to easily take advantage of PIM. This article examines three key
domains of work towards the practical construction and widespread adoption of
PIM architectures. First, we describe our work on systematically identifying
opportunities for PIM in real applications, and quantify potential gains for
popular emerging applications (e.g., machine learning, data analytics, genome
analysis). Second, we aim to solve several key issues on programming these
applications for PIM architectures. Third, we describe challenges that remain
for the widespread adoption of PIM.
"
1253,"Pyramid: Machine Learning Framework to Estimate the Optimal Timing and
  Resource Usage of a High-Level Synthesis Design","  The emergence of High-Level Synthesis (HLS) tools shifted the paradigm of
hardware design by making the process of mapping high-level programming
languages to hardware design such as C to VHDL/Verilog feasible. HLS tools
offer a plethora of techniques to optimize designs for both area and
performance, but resource usage and timing reports of HLS tools mostly deviate
from the post-implementation results. In addition, to evaluate a hardware
design performance, it is critical to determine the maximum achievable clock
frequency. Obtaining such information using static timing analysis provided by
CAD tools is difficult, due to the multitude of tool options. Moreover, a
binary search to find the maximum frequency is tedious, time-consuming, and
often does not obtain the optimal result. To address these challenges, we
propose a framework, called Pyramid, that uses machine learning to accurately
estimate the optimal performance and resource utilization of an HLS design. For
this purpose, we first create a database of C-to-FPGA results from a diverse
set of benchmarks. To find the achievable maximum clock frequency, we use
Minerva, which is an automated hardware optimization tool. Minerva determines
the close-to-optimal settings of tools, using static timing analysis and a
heuristic algorithm, and targets either optimal throughput or
throughput-to-area. Pyramid uses the database to train an ensemble machine
learning model to map the HLS-reported features to the results of Minerva. To
this end, Pyramid re-calibrates the results of HLS to bridge the accuracy gap
and enable developers to estimate the throughput or throughput-to-area of
hardware design with more than 95% accuracy and alleviates the need to perform
actual implementation for estimation.
"
1254,"Generalized Fault-Tolerance Topology Generation for Application Specific
  Network-on-Chips","  The Network-on-Chips is a promising candidate for addressing communication
bottlenecks in many-core processors and neural network processors. In this
work, we consider the generalized fault-tolerance topology generation problem,
where the link or switch failures can happen, for application-specific
network-on-chips (ASNoC). With a user-defined number, K, we propose an integer
linear programming (ILP) based method to generate ASNoC topologies, which can
tolerate at most K faults in switches or links. Given the communication
requirements between cores and their floorplan, we first propose a
convex-cost-flow based method to solve a core mapping problem for building
connections between the cores and switches. Second, an ILP based method is
proposed to allocate K+1 switch-disjoint routing paths for every communication
flow between the cores. Finally, to reduce switch sizes, we propose sharing the
switch ports for the connections between the cores and switches and formulate
the port sharing problem as a clique-partitioning problem Additionally, we
propose an ILP-based method to simultaneously solve the core mapping and
routing path allocation problems when considering physical link failures only.
Experimental results show that the power consumptions of fault-tolerance
topologies increase almost linearly with K because of the routing path
redundancy. When both switch faults and link faults are considered, port
sharing can reduce the average power consumption of fault-tolerance topologies
with K = 1, K = 2 and K = 3 by 18.08%, 28.88%, and 34.20%, respectively. When
considering only the physical link faults, the experimental results show that
compared to the FTTG algorithm, the proposed method reduces power consumption
and hop count by 10.58% and 6.25%, respectively; compared to the DBG based
method, the proposed method reduces power consumption and hop count by 21.72%
and 9.35%, respectively.
"
1255,"Runtime Mitigation of Packet Drop Attacks in Fault-tolerant
  Networks-on-Chip","  Fault-tolerant routing (FTR) in Networks-on-Chip (NoCs) has become a common
practice to sustain the performance of multi-core systems with an increasing
number of faults on a chip. On the other hand, usage of third-party
intellectual property blocks has made security a primary concern in modern day
designs. This article presents a mechanism to mitigate a denial-of-service
attack, namely packet drop attack, which may arise due to the hardware Trojans
(HTs) in NoCs that adopt FTR algorithms. HTs, associated with external kill
switches, are conditionally triggered to enable the attack scenario. Security
modules, such as authentication unit, buffer shuffler, and control unit, have
been proposed to thwart the attack in runtime and restore secure packet flow in
the NoC. These units work together as a shield to safeguard the packets from
proceeding towards the output ports with faulty links. Synthesis results show
that the proposed secure FT router, when compared with a baseline FT router,
has area and power overheads of at most 4.04% and 0.90%, respectively.
Performance evaluation shows that SeFaR has acceptable overheads in the
execution time, energy consumption, average packet latency, and power-latency
product metrics when compared with a baseline FT router while running real
benchmarks, as well as synthetic traffic. Further, a possible design of a
comprehensive secure router has been presented with a view to addressing and
mitigating multiple attacks that can arise in the NoC routers.
"
1256,"Towards Multidimensional Verification: Where Functional Meets
  Non-Functional","  Trends in advanced electronic systems' design have a notable impact on design
verification technologies. The recent paradigms of Internet-of-Things (IoT) and
Cyber-Physical Systems (CPS) assume devices immersed in physical environments,
significantly constrained in resources and expected to provide levels of
security, privacy, reliability, performance and low power features. In recent
years, numerous extra-functional aspects of electronic systems were brought to
the front and imply verification of hardware design models in multidimensional
space along with the functional concerns of the target system. However,
different from the software domain such a holistic approach remains
underdeveloped. The contributions of this paper are a taxonomy for
multidimensional hardware verification aspects, a state-of-the-art survey of
related research works and trends towards the multidimensional verification
concept. The concept is motivated by an example for the functional and power
verification dimensions.
"
1257,"Analysis and Optimization of I/O Cache Coherency Strategies for SoC-FPGA
  Device","  Unlike traditional PCIe-based FPGA accelerators, heterogeneous SoC-FPGA
devices provide tighter integrations between software running on CPUs and
hardware accelerators. Modern heterogeneous SoC-FPGA platforms support multiple
I/O cache coherence options between CPUs and FPGAs, but these options can have
inadvertent effects on the achieved bandwidths depending on applications and
data access patterns. To provide the most efficient communications between CPUs
and accelerators, understanding the data transaction behaviors and selecting
the right I/O cache coherence method is essential. In this paper, we use Xilinx
Zynq UltraScale+ as the SoC platform to show how certain I/O cache coherence
method can perform better or worse in different situations, ultimately
affecting the overall accelerator performances as well. Based on our analysis,
we further explore possible software and hardware modifications to improve the
I/O performances with different I/O cache coherence options. With our proposed
modifications, the overall performance of SoC design can be averagely improved
by 20%.
"
1258,CREST: Hardware Formal Verification with ANSI-C Reference Specifications,"  This paper presents CREST, a prototype front-end tool intended as an add-on
to commercial EDA formal verifcation environments. CREST is an adaptation of
the CBMC bounded model checker for C, an academic tool widely used in industry
for software analysis and property verification. It leverages the capabilities
of CBMC to process hardware datapath specifications written in arbitrary
ANSI-C, without limiting restrictions to a synthesizable subset. We briefly
sketch the architecture of our tool and show its use in a range of verification
case studies.
"
1259,PERI: A Posit Enabled RISC-V Core,"  Owing to the failure of Dennard's scaling the last decade has seen a steep
growth of prominent new paradigms leveraging opportunities in computer
architecture. Two technologies of interest are Posit and RISC-V. Posit was
introduced in mid-2017 as a viable alternative to IEEE 754-2008. Posit promises
more accuracy, higher dynamic range, and fewer unused states along with simpler
hardware designs as compared to IEEE 754-2008. RISC-V, on the other hand,
provides a commercial-grade open-source ISA. It is not only elegant and simple
but also highly extensible and customizable, thereby facilitating novel
micro-architectural research and exploration. In this paper, we bring these two
technologies together and propose the first Posit Enabled RISC-V core. The
paper provides insights on how the current 'F' extension and the custom op-code
space of RISC-V can be leveraged/modified to support Posit arithmetic. We also
present implementation details of a parameterized and feature-complete Posit
FPU which is integrated with the RISC-V compliant SHAKTI C-class core either as
an execution unit or as an accelerator. To fully leverage the potential of
Posit, we further enhance our Posit FPU, with minimal overheads, to support two
different exponent sizes (with posit-size being 32-bits). This allows
applications to switch from high-accuracy computation mode to a mode with
higher dynamic-range at run-time. In the absence of viable software tool-chain
to enable porting of applications in the Posit domain, we present a workaround
on how certain applications can be modified minimally to exploit the existing
RISC-V tool-chain. We also provide examples of applications which can perform
better with Posit as compared to IEEE 754-2008. The proposed Posit FPU consumes
3507 slice LUTs and 1294 slice registers on an Artix-7-100T Xilinx FPGA while
capable of operating at 100 MHz.
"
1260,Addressing multiple bit/symbol errors in DRAM subsystem,"  As DRAM technology continues to evolve towards smaller feature sizes and
increased densities, faults in DRAM subsystem are becoming more severe. Current
servers mostly use CHIPKILL based schemes to tolerate up-to one/two symbol
errors per DRAM beat. Multi-symbol errors arising due to faults in multiple
data buses and chips may not be detected by these schemes. In this paper, we
introduce Single Symbol Correction Multiple Symbol Detection (SSCMSD) - a novel
error handling scheme to correct single-symbol errors and detect multi-symbol
errors. Our scheme makes use of a hash in combination with Error Correcting
Code (ECC) to avoid silent data corruptions (SDCs). SSCMSD can also enhance the
capability of detecting errors in address bits. We employ 32-bit CRC along with
Reed-Solomon code to implement SSCMSD for a x4 based DDRx system. Our
simulations show that the proposed scheme effectively prevents SDCs in the
presence of multiple symbol errors. Our novel design enabled us to achieve this
without introducing additional READ latency. Also, we need 19 chips per rank
(storage overhead of 18.75 percent), 76 data bus-lines and additional
hash-logic at the memory controller.
"
1261,"3D-aCortex: An Ultra-Compact Energy-Efficient Neurocomputing Platform
  Based on Commercial 3D-NAND Flash Memories","  The first contribution of this paper is the development of extremely dense,
energy-efficient mixed-signal vector-by-matrix-multiplication (VMM) circuits
based on the existing 3D-NAND flash memory blocks, without any need for their
modification. Such compatibility is achieved using time-domain-encoded VMM
design. Our detailed simulations have shown that, for example, the 5-bit VMM of
200-element vectors, using the commercially available 64-layer gate-all-around
macaroni-type 3D-NAND memory blocks designed in the 55-nm technology node, may
provide an unprecedented area efficiency of 0.14 um2/byte and energy efficiency
of ~10 fJ/Op, including the input/output and other peripheral circuitry
overheads. Our second major contribution is the development of 3D-aCortex, a
multi-purpose neuromorphic inference processor that utilizes the proposed
3D-VMM blocks as its core processing units. We have performed rigorous
performance simulations of such a processor on both circuit and system levels,
taking into account non-idealities such as drain-induced barrier lowering,
capacitive coupling, charge injection, parasitics, process variations, and
noise. Our modeling of the 3D-aCortex performing several state-of-the-art
neuromorphic-network benchmarks has shown that it may provide the
record-breaking storage efficiency of 4.34 MB/mm2, the peak energy efficiency
of 70.43 TOps/J, and the computational throughput up to 10.66 TOps/s. The
storage efficiency can be further improved seven-fold by aggressively sharing
VMM peripheral circuits at the cost of slight decrease in energy efficiency and
throughput.
"
1262,"Near-Memory Computing: Past, Present, and Future","  The conventional approach of moving data to the CPU for computation has
become a significant performance bottleneck for emerging scale-out
data-intensive applications due to their limited data reuse. At the same time,
the advancement in 3D integration technologies has made the decade-old concept
of coupling compute units close to the memory --- called near-memory computing
(NMC) --- more viable. Processing right at the ""home"" of data can significantly
diminish the data movement problem of data-intensive applications.
  In this paper, we survey the prior art on NMC across various dimensions
(architecture, applications, tools, etc.) and identify the key challenges and
open issues with future research directions. We also provide a glimpse of our
approach to near-memory computing that includes i) NMC specific
microarchitecture independent application characterization ii) a compiler
framework to offload the NMC kernels on our target NMC platform and iii) an
analytical model to evaluate the potential of NMC.
"
1263,"High-Level Combined Deterministic and Pseudoexhuastive Test Generation
  for RISC Processors","  Recent safety standards set stringent requirements for the target fault
coverage in embedded microprocessors, with the objective to guarantee
robustness and functional safety of the critical electronic systems. This
motivates the need for improving the quality of test generation for
microprocessors. A new high-level implementation-independent test generation
method for RISC processors is proposed. The set of instructions of the
processor is partitioned nto groups. For each group, a dedicated test template
is created, to be used for generating two test programs, for testing the
control and the data paths respectively. For testing the control part, a novel
high-level control fault model is proposed. Using this model, a set of
deterministic test data operands are generated for each instruction of the
given group. The advantage of the high-level fault model is that it covers
larger than SAF fault class including multiple fault coverage in the control
part. For generating the data path test, pseudoexhaustive data operands are
used. We investigated the feasibility of the approach and demonstrated high
efficiency of the generated test programs for testing the execute module of the
miniMIPS RISC processor.
"
1264,"TensorDIMM: A Practical Near-Memory Processing Architecture for
  Embeddings and Tensor Operations in Deep Learning","  Recent studies from several hyperscalars pinpoint to embedding layers as the
most memory-intensive deep learning (DL) algorithm being deployed in today's
datacenters. This paper addresses the memory capacity and bandwidth challenges
of embedding layers and the associated tensor operations. We present our
vertically integrated hardware/software co-design, which includes a custom DIMM
module enhanced with near-data processing cores tailored for DL tensor
operations. These custom DIMMs are populated inside a GPU-centric system
interconnect as a remote memory pool, allowing GPUs to utilize for scalable
memory bandwidth and capacity expansion. A prototype implementation of our
proposal on real DL systems shows an average 6.2-17.6x performance improvement
on state-of-the-art recommender systems.
"
1265,"Work-in-Progress: A Simulation Framework for Domain-Specific
  System-on-Chips","  Heterogeneous system-on-chips (SoCs) have become the standard embedded
computing platforms due to their potential to deliver superior performance and
energy efficiency compared to homogeneous architectures. They can be
particularly suited to target a specific domain of applications. However, this
potential is contingent upon optimizing the SoC for the target domain and
utilizing its resources effectively at run-time. Cycle-accurate instruction set
simulators are not suitable for this optimization, since meaningful temperature
and power consumption evaluations require simulating seconds, if not minutes,
of workloads.
  This paper presents a system-level domain-specific SoC simulation (DS3)
framework to address this need. DS3 enables both design space exploration and
dynamic resource management for power-performance optimization for domain
applications with$~600\times$ speedup compared to commonly used gem5 simulator.
We showcase DS3 using five applications from wireless communications and radar
processing domain. DS3, as well as the reference applications, will be shared
as open-source software to stimulate research in this area.
"
1266,"Reinforcement Learning based Interconnection Routing for Adaptive
  Traffic Optimization","  Applying Machine Learning (ML) techniques to design and optimize computer
architectures is a promising research direction. Optimizing the runtime
performance of a Network-on-Chip (NoC) necessitates a continuous learning
framework. In this work, we demonstrate the promise of applying reinforcement
learning (RL) to optimize NoC runtime performance. We present three RL-based
methods for learning optimal routing algorithms. The experimental results show
the algorithms can successfully learn a near-optimal solution across different
environment states. Reproducible Code:
github.com/huckiyang/interconnect-routing-gym
"
1267,CHoNDA: Near Data Acceleration with Concurrent Host Access,"  Near-data accelerators (NDAs) that are integrated with main memory have the
potential for significant power and performance benefits. Fully realizing these
benefits requires the large available memory capacity to be shared between the
host and the NDAs in a way that permits both regular memory access by some
applications and accelerating others with an NDA, avoids copying data, enables
collaborative processing, and simultaneously offers high performance for both
host and NDA. We identify and solve new challenges in this context: mitigating
row-locality interference from host to NDAs, reducing read/write-turnaround
overhead caused by fine-grain interleaving of host and NDA requests,
architecting a memory layout that supports the locality required for NDAs and
sophisticated address interleaving for host performance, and supporting both
packetized and traditional memory interfaces. We demonstrate our approach in a
simulated system that consists of a multi-core CPU and NDA-enabled DDR4 memory
modules. We show that our mechanisms enable effective and efficient concurrent
access using a set of microbenchmarks, and then demonstrate the potential of
the system for the important stochastic variance-reduced gradient (SVRG)
algorithm.
"
1268,Workload-Aware Opportunistic Energy Efficiency in Multi-FPGA Platforms,"  The continuous growth of big data applications with high computational and
scalability demands has resulted in increasing popularity of cloud computing.
Optimizing the performance and power consumption of cloud resources is
therefore crucial to relieve the costs of data centers. In recent years,
multi-FPGA platforms have gained traction in data centers as low-cost yet
high-performance solutions particularly as acceleration engines, thanks to the
high degree of parallelism they provide. Nonetheless, the size of data centers
workloads varies during service time, leading to significant underutilization
of computing resources while consuming a large amount of power, which turns out
as a key factor of data center inefficiency, regardless of the underlying
hardware structure. In this paper, we propose an efficient framework to
throttle the power consumption of multi-FPGA platforms by dynamically scaling
the voltage and hereby frequency during runtime according to prediction of, and
adjustment to the workload level, while maintaining the desired Quality of
Service (QoS). This is in contrast to, and more efficient than, conventional
approaches that merely scale (i.e., power-gate) the computing nodes or
frequency. The proposed framework carefully exploits a pre-characterized
library of delay-voltage, and power-voltage information of FPGA resources,
which we show is indispensable to obtain the efficient operating point due to
the different sensitivity of resources w.r.t. voltage scaling, particularly
considering multiple power rails residing in these devices. Our evaluations by
implementing state-of-the-art deep neural network accelerators revealed that,
providing an average power reduction of 4.0X, the proposed framework surpasses
the previous works by 33.6% (up to 83%).
"
1269,A Computational Model for Tensor Core Units,"  To respond to the need of efficient training and inference of deep neural
networks, a plethora of domain-specific hardware architectures have been
introduced, such as Google Tensor Processing Units and NVIDIA Tensor Cores. A
common feature of these architectures is a hardware circuit for efficiently
computing a dense matrix multiplication of a given small size. In order to
broaden the class of algorithms that exploit these systems, we propose a
computational model, named the TCU model, that captures the ability to natively
multiply small matrices. We then use the TCU model for designing fast
algorithms for several problems, including matrix operations (dense and sparse
multiplication, Gaussian Elimination), graph algorithms (transitive closure,
all pairs shortest distances), Discrete Fourier Transform, stencil
computations, integer multiplication, and polynomial evaluation. We finally
highlight a relation between the TCU model and the external memory model.
"
1270,"Boosting the Bounds of Symbolic QED for Effective Pre-Silicon
  Verification of Processor Cores","  Existing techniques to ensure functional correctness and hardware trust
during pre-silicon verification face severe limitations. In this work, we
systematically leverage two key ideas: 1) Symbolic Quick Error Detection
(Symbolic QED or SQED), a recent bug detection and localization technique using
Bounded Model Checking (BMC); and 2) Symbolic starting states, to present a
method that: i) Effectively detects both ""difficult"" logic bugs and Hardware
Trojans, even with long activation sequences where traditional BMC techniques
fail; and ii) Does not need skilled manual guidance for writing testbenches,
writing design-specific assertions, or debugging spurious counter-examples.
Using open-source RISC-V cores, we demonstrate the following: 1. Quick (<5
minutes for an in-order scalar core and <2.5 hours for an out-of-order
superscalar core) detection of 100% of hundreds of logic bug and hardware
Trojan scenarios from commercial chips and research literature, and 97.9% of
""extremal"" bugs (randomly-generated bugs requiring ~100,000 activation
instructions taken from random test programs). 2. Quick (~1 minute) detection
of several previously unknown bugs in open-source RISC-V designs.
"
1271,Ternary circuits: why R=3 is not the Optimal Radix for Computation,"  A demonstration that e=2.718 rounded to 3 is the best radix for computation
is disproved. The MOSFET-like CNTFET technology is used to compare inverters,
Nand, adders, multipliers, D Flip-Flops and SRAM cells. The transistor count
ratio between ternary and binary circuits is generally greater than the
log(3)/log(2) information ratio. The only exceptions concern a circuit approach
that combines two circuit drawbacks (an additional power supply and a circuit
conflict between transistors) and only when it implements circuits based on the
ternary inverter. For arithmetic circuits such as adders and multipliers, the
ternary circuits are always outperformed by the binary ones using the same
technology.
"
1272,"XSP: Across-Stack Profiling and Analysis of Machine Learning Models on
  GPUs","  There has been a rapid proliferation of machine learning/deep learning (ML)
models and wide adoption of them in many application domains. This has made
profiling and characterization of ML model performance an increasingly pressing
task for both hardware designers and system providers, as they would like to
offer the best possible system to serve ML models with the target latency,
throughput, cost, and energy requirements while maximizing resource
utilization. Such an endeavor is challenging as the characteristics of an ML
model depend on the interplay between the model, framework, system libraries,
and the hardware (or the HW/SW stack). Existing profiling tools are disjoint,
however, and only focus on profiling within a particular level of the stack,
which limits the thoroughness and usefulness of the profiling results.
  This paper proposes XSP - an across-stack profiling design that gives a
holistic and hierarchical view of ML model execution. XSP leverages distributed
tracing to aggregate and correlates profile data from different sources. XSP
introduces a leveled and iterative measurement approach that accurately
captures the latencies at all levels of the HW/SW stack in spite of the
profiling overhead. We couple the profiling design with an automated analysis
pipeline to systematically analyze 65 state-of-the-art ML models. We
demonstrate that XSP provides insights which would be difficult to discern
otherwise.
"
1273,Comparing ternary and binary adders and multipliers,"  While many papers have proposed implementations of ternary adders and ternary
multipliers, no comparisons have generally been done with the corresponding
binary ones. We compare the implementations of binary and ternary adders and
multipliers with the same computing capability according to the basic blocks
that are 1-bit and 1-trit adders and 1-bit and 1-trit multipliers. Then we
compare the complexity of these basic blocks by using the same CNTFET
technology to evaluate the overall complexity of N-bit adders and M-trit adders
on one side, and NxN bit multipliers and MxM trits multipliers with M = N/IR
(IR = log(3)/log(2) is the information ratio). While ternary adders and
multipliers have less input and output connections and use less basic building
blocks, the complexity of the ternary building blocks is too high and the
ternary adders and multipliers cannot compete with the binary ones.
"
1274,"A bi-directional Address-Event transceiver block for low-latency
  inter-chip communication in neuromorphic systems","  Neuromorphic systems typically use the Address-Event Representation (AER) to
transmit signals among nodes, cores, and chips. Communication of Address-Events
(AEs) between neuromorphic cores/chips typically requires two parallel digital
signal buses for Input/Output (I/O) operations. This requirement can become
very expensive for large-scale systems in terms of both dedicated I/O pins and
power consumption. In this paper we present a compact fully asynchronous
event-driven transmitter/receiver block that is both power efficient and I/O
efficient. This block implements high-throughput low-latency bi-directional
communication through a parallel AER bus. We show that by placing the proposed
AE transceiver block in two separate chips and linking them by a single AER
bus, we can drive the communication and switch the transmission direction of
the shared bus on a single event basis, from either side with low-latency. We
present experimental results that validate the circuits proposed and
demonstrate reliable bi-directional event transmission with high-throughput.
The proposed AE block, integrated in a neuromorphic chip fabricated using a 28
nm FDSOI process, occupies a silicon die area of 140 {\mu}m x 70 {\mu}m. The
experimental measurements show that the event-driven AE block combined with
standard digital I/Os has a direction switch latency of 5 ns and can achieve a
worst-case bi-directional event transmission throughput of 28.6M Events/second
while consuming 11 pJ per event (26-bit) delivery.
"
1275,"Enabling and Exploiting Partition-Level Parallelism (PALP) in Phase
  Change Memories","  Phase-change memory (PCM) devices have multiple banks to serve memory
requests in parallel. Unfortunately, if two requests go to the same bank, they
have to be served one after another, leading to lower system performance. We
observe that a modern PCM bank is implemented as a collection of partitions
that operate mostly independently while sharing a few global peripheral
structures, which include the sense amplifiers (to read) and the write drivers
(to write). Based on this observation, we propose PALP, a new mechanism that
enables partition-level parallelism within each PCM bank, and exploits such
parallelism by using the memory controller's access scheduling decisions. PALP
consists of three new contributions. First, we introduce new PCM commands to
enable parallelism in a bank's partitions in order to resolve the read-write
bank conflicts, with minimal changes needed to PCM logic and its interface.
Second, we propose simple circuit modifications that introduce a new operating
mode for the write drivers, in addition to their default mode of serving write
requests. When configured in this new mode, the write drivers can resolve the
read-read bank conflicts, working jointly with the sense amplifiers. Finally,
we propose a new access scheduling mechanism in PCM that improves performance
by prioritizing those requests that exploit partition-level parallelism over
other requests, including the long outstanding ones. While doing so, the memory
controller also guarantees starvation-freedom and the PCM's
running-average-power-limit (RAPL). We evaluate PALP with workloads from the
MiBench and SPEC CPU2017 Benchmark suites. Our results show that PALP reduces
average PCM access latency by 23%, and improves average system performance by
28% compared to the state-of-the-art approaches.
"
1276,4-Bit High-Speed Binary Ling Adder,"  Binary addition is one of the most primitive and most commonly used
applications in computer arithmetic. A large variety of algorithms and
implementations have been proposed for binary addition. Huey Ling proposed a
simpler form of CLA equations which rely on adjacent pair bits. Along with bit
generate and bit propagate, we introduce another prefix bit, the half sum bit.
Ling adder increases the speed of n-bit binary addition, which is an upgrade
from the existing Carry-Look-Ahead adder. Several variants of the carry
look-ahead equations, like Ling carries, have been presented that simplify
carry computation and can lead to faster structures. Ling adders, make use of
Ling carry and propagate bits, in order to calculate the sum bit. As a result,
dependency on the previous bit addition is reduced; that is, ripple effect is
lowered. This paper provides a comparative study on the implementation of the
above mentioned high-speed adders.
"
1277,Tvarak: Software-managed hardware offload for DAX NVM storage redundancy,"  Tvarak efficiently implements system-level redundancy for direct-access (DAX)
NVM storage. Production storage systems complement device-level ECC (which
covers media errors) with system-checksums and cross-device parity. This
system-level redundancy enables detection of and recovery from data corruption
due to device firmware bugs (e.g., reading data from the wrong physical
location). Direct access to NVM penalizes software-only implementations of
system-level redundancy, forcing a choice between lack of data protection or
significant performance penalties. Offloading the update and verification of
system-level redundancy to Tvarak, a hardware controller co-located with the
last-level cache, enables efficient protection of data from such bugs in memory
controller and NVM DIMM firmware. Simulation-based evaluation with seven
data-intensive applications shows Tvarak's performance and energy efficiency.
For example, Tvarak reduces Redis set-only performance by only 3%, compared to
50% reduction for a state-of-the-art software-only approach.
"
1278,"Cyclic Sequence Generators as Program Counters for High-Speed FPGA-based
  Processors","  This paper compares the performance of conventional radix-2 program counters
with program counters based on Feedback Shift Registers (FSRs), a class of
cyclic sequence generator. FSR counters have constant time scaling with
bit-width, $N$, whereas FPGA-based radix-2 counters typically have $O(N)$
time-complexity due to the carry-chain. Program counter performance is measured
by synthesis of standalone counter circuits, as well as synthesis of three
FPGA-based processor designs modified to incorporate FSR program counters.
Hybrid counters, combining both an FSR and a radix-2 counter, are presented as
a solution to the potential cache-coherency issues of FSR program counters.
Results show that high-speed processor designs benefit more from FSR program
counters, allowing both greater operating frequency and the use of fewer logic
resources.
"
1279,BRISC-V: An Open-Source Architecture Design Space Exploration Toolbox,"  In this work, we introduce a platform for register-transfer level (RTL)
architecture design space exploration. The platform is an open-source,
parameterized, synthesizable set of RTL modules for designing RISC-V based
single and multi-core architecture systems. The platform is designed with a
high degree of modularity. It provides highly-parameterized, composable RTL
modules for fast and accurate exploration of different RISC-V based core
complexities, multi-level caching and memory organizations, system topologies,
router architectures, and routing schemes. The platform can be used for both
RTL simulation and FPGA based emulation. The hardware modules are implemented
in synthesizable Verilog using no vendor-specific blocks. The platform includes
a RISC-V compiler toolchain to assist in developing software for the cores, a
web-based system configuration graphical user interface (GUI) and a web-based
RISC-V assembly simulator. The platform supports a myriad of RISC-V
architectures, ranging from a simple single cycle processor to a multi-core SoC
with a complex memory hierarchy and a network-on-chip. The modules are designed
to support incremental additions and modifications. The interfaces between
components are particularly designed to allow parts of the processor such as
whole cache modules, cores or individual pipeline stages, to be modified or
replaced without impacting the rest of the system. The platform allows
researchers to quickly instantiate complete working RISC-V multi-core systems
with synthesizable RTL and make targeted modifications to fit their needs. The
complete platform (including Verilog source code) can be downloaded at
https://ascslab.org/research/briscv/explorer/explorer.html.
"
1280,"Tiny but Accurate: A Pruned, Quantized and Optimized Memristor Crossbar
  Framework for Ultra Efficient DNN Implementation","  The state-of-art DNN structures involve intensive computation and high memory
storage. To mitigate the challenges, the memristor crossbar array has emerged
as an intrinsically suitable matrix computation and low-power acceleration
framework for DNN applications. However, the high accuracy solution for extreme
model compression on memristor crossbar array architecture is still waiting for
unraveling. In this paper, we propose a memristor-based DNN framework which
combines both structured weight pruning and quantization by incorporating
alternating direction method of multipliers (ADMM) algorithm for better pruning
and quantization performance. We also discover the non-optimality of the ADMM
solution in weight pruning and the unused data path in a structured pruned
model. Motivated by these discoveries, we design a software-hardware
co-optimization framework which contains the first proposed Network
Purification and Unused Path Removal algorithms targeting on post-processing a
structured pruned model after ADMM steps. By taking memristor hardware
constraints into our whole framework, we achieve extreme high compression ratio
on the state-of-art neural network structures with minimum accuracy loss. For
quantizing structured pruned model, our framework achieves nearly no accuracy
loss after quantizing weights to 8-bit memristor weight representation. We
share our models at anonymous link https://bit.ly/2VnMUy0.
"
1281,A Machine Learning Accelerator In-Memory for Energy Harvesting,"  There is increasing demand to bring machine learning capabilities to low
power devices. By integrating the computational power of machine learning with
the deployment capabilities of low power devices, a number of new applications
become possible. In some applications, such devices will not even have a
battery, and must rely solely on energy harvesting techniques. This puts
extreme constraints on the hardware, which must be energy efficient and capable
of tolerating interruptions due to power outages. Here, as a representative
example, we propose an in-memory support vector machine learning accelerator
utilizing non-volatile spintronic memory. The combination of
processing-in-memory and non-volatility provides a key advantage in that
progress is effectively saved after every operation. This enables instant shut
down and restart capabilities with minimal overhead. Additionally, the
operations are highly energy efficient leading to low power consumption.
"
1282,"EBPC: Extended Bit-Plane Compression for Deep Neural Network Inference
  and Training Accelerators","  In the wake of the success of convolutional neural networks in image
classification, object recognition, speech recognition, etc., the demand for
deploying these compute-intensive ML models on embedded and mobile systems with
tight power and energy constraints at low cost, as well as for boosting
throughput in data centers, is growing rapidly. This has sparked a surge of
research into specialized hardware accelerators. Their performance is typically
limited by I/O bandwidth, power consumption is dominated by I/O transfers to
off-chip memory, and on-chip memories occupy a large part of the silicon area.
We introduce and evaluate a novel, hardware-friendly, and lossless compression
scheme for the feature maps present within convolutional neural networks. We
present hardware architectures and synthesis results for the compressor and
decompressor in 65nm. With a throughput of one 8-bit word/cycle at 600MHz, they
fit into 2.8kGE and 3.0kGE of silicon area, respectively - together the size of
less than seven 8-bit multiply-add units at the same throughput. We show that
an average compression ratio of 5.1x for AlexNet, 4x for VGG-16, 2.4x for
ResNet-34 and 2.2x for MobileNetV2 can be achieved - a gain of 45-70% over
existing methods. Our approach also works effectively for various number
formats, has a low frame-to-frame variance on the compression ratio, and
achieves compression factors for gradient map compression during training that
are even better than for inference.
"
1283,"An Ultra-Efficient Memristor-Based DNN Framework with Structured Weight
  Pruning and Quantization Using ADMM","  The high computation and memory storage of large deep neural networks (DNNs)
models pose intensive challenges to the conventional Von-Neumann architecture,
incurring substantial data movements in the memory hierarchy. The memristor
crossbar array has emerged as a promising solution to mitigate the challenges
and enable low-power acceleration of DNNs. Memristor-based weight pruning and
weight quantization have been seperately investigated and proven effectiveness
in reducing area and power consumption compared to the original DNN model.
However, there has been no systematic investigation of memristor-based
neuromorphic computing (NC) systems considering both weight pruning and weight
quantization. In this paper, we propose an unified and systematic
memristor-based framework considering both structured weight pruning and weight
quantization by incorporating alternating direction method of multipliers
(ADMM) into DNNs training. We consider hardware constraints such as crossbar
blocks pruning, conductance range, and mismatch between weight value and real
devices, to achieve high accuracy and low power and small area footprint. Our
framework is mainly integrated by three steps, i.e., memristor-based ADMM
regularized optimization, masked mapping and retraining. Experimental results
show that our proposed framework achieves 29.81X (20.88X) weight compression
ratio, with 98.38% (96.96%) and 98.29% (97.47%) power and area reduction on
VGG-16 (ResNet-18) network where only have 0.5% (0.76%) accuracy loss, compared
to the original DNN models. We share our models at link http://bit.ly/2Jp5LHJ.
"
1284,"Touch\'e: Towards Ideal and Efficient Cache Compression By Mitigating
  Tag Area Overheads","  Compression is seen as a simple technique to increase the effective cache
capacity. Unfortunately, compression techniques either incur tag area overheads
or restrict data placement to only include neighboring compressed cache blocks
to mitigate tag area overheads. Ideally, we should be able to place arbitrary
compressed cache blocks without any placement restrictions and tag area
overheads.
  This paper proposes Touch\'e, a framework that enables storing multiple
arbitrary compressed cache blocks within a physical cacheline without any tag
area overheads. The Touch\'e framework consists of three components. The first
component, called the ``Signature'' (SIGN) engine, creates shortened signatures
from the tag addresses of compressed blocks. Due to this, the SIGN engine can
store multiple signatures in each tag entry. On a cache access, the physical
cacheline is accessed only if there is a signature match (which has a
negligible probability of false positive). The second component, called the
``Tag Appended Data'' (TADA) mechanism, stores the full tag addresses with
data. TADA enables Touch\'e to detect false positive signature matches by
ensuring that the actual tag address is available for comparison. The third
component, called the ``Superblock Marker'' (SMARK) mechanism, uses a unique
marker in the tag entry to indicate the occurrence of compressed cache blocks
from neighboring physical addresses in the same cacheline. Touch\'e is
completely hardware-based and achieves an average speedup of 12\% (ideal 13\%)
when compared to an uncompressed baseline.
"
1285,"SPRING: A Sparsity-Aware Reduced-Precision Monolithic 3D CNN Accelerator
  Architecture for Training and Inference","  CNNs outperform traditional machine learning algorithms across a wide range
of applications. However, their computational complexity makes it necessary to
design efficient hardware accelerators. Most CNN accelerators focus on
exploring dataflow styles that exploit computational parallelism. However,
potential performance speedup from sparsity has not been adequately addressed.
The computation and memory footprint of CNNs can be significantly reduced if
sparsity is exploited in network evaluations. To take advantage of sparsity,
some accelerator designs explore sparsity encoding and evaluation on CNN
accelerators. However, sparsity encoding is just performed on activation or
weight and only in inference. It has been shown that activation and weight also
have high sparsity levels during training. Hence, sparsity-aware computation
should also be considered in training. To further improve performance and
energy efficiency, some accelerators evaluate CNNs with limited precision.
However, this is limited to the inference since reduced precision sacrifices
network accuracy if used in training. In addition, CNN evaluation is usually
memory-intensive, especially in training. In this paper, we propose SPRING, a
SParsity-aware Reduced-precision Monolithic 3D CNN accelerator for trainING and
inference. SPRING supports both CNN training and inference. It uses a binary
mask scheme to encode sparsities in activation and weight. It uses the
stochastic rounding algorithm to train CNNs with reduced precision without
accuracy loss. To alleviate the memory bottleneck in CNN evaluation, especially
in training, SPRING uses an efficient monolithic 3D NVM interface to increase
memory bandwidth. Compared to GTX 1080 Ti, SPRING achieves 15.6X, 4.2X and
66.0X improvements in performance, power reduction, and energy efficiency,
respectively, for CNN training, and 15.5X, 4.5X and 69.1X improvements for
inference.
"
1286,"TMA: Tera-MACs/W Neural Hardware Inference Accelerator with a
  Multiplier-less Massive Parallel Processor","  Computationally intensive Inference tasks of Deep neural networks have
enforced revolution of new accelerator architecture to reduce power consumption
as well as latency. The key figure of merit in hardware inference accelerators
is the number of multiply-and-accumulation operations per watt (MACs/W), where,
the state-of-the-arts MACs/W remains several hundreds Giga-MACs/W. We propose a
Tera-MACS/W neural hardware inference Accelerator (TMA) with 8-bit activations
and scalable integer weights less than 1-byte. The architectures main feature
is configurable neural processing element for matrix-vector operations. The
proposed neural processing element has Multiplier-less Massive Parallel
Processor to work without any multiplications, which makes it attractive for
energy efficient high-performance neural network applications. We benchmark our
systems latency, power, and performance using Alexnet trained on ImageNet.
Finally, we compared our accelerators throughput and power consumption to the
prior works. The proposed accelerator outperforms the state of the art in terms
of energy and area achieving 2.3 TMACS/W@1.0 V, 65 nm CMOS technology.
"
1287,"NoCs in Heterogeneous 3D SoCs: Co-Design of Routing Strategies and
  Microarchitectures","  Heterogeneous 3D System-on-Chips (3D SoCs) are the most promising design
paradigm to combine sensing and computing within a single chip. A special
characteristic of communication networks in heterogeneous 3D SoCs is the
varying latency and throughput in each layer. As shown in this work, this
variance drastically degrades the network performance. We contribute a
co-design of routing algorithms and router microarchitecture that allows to
overcome these performance limitations. We analyze the challenges of
heterogeneity: Technology-aware models are proposed for communication and
thereby identify layers in which packets are transmitted slower. The
communication models are precise for latency and throughput under zero load.
The technology model has an area error and a timing error of less than 7.4% for
various commercial technologies from 90 to 28nm. Second, we demonstrate how to
overcome limitations of heterogeneity by proposing two novel routing algorithms
called Z+(XY)Z- and ZXYZ that enhance latency by up to 6.5x compared to
conventional dimension order routing. Furthermore, we propose a high
vertical-throughput router microarchitecture that is adjusted to the routing
algorithms and that fully overcomes the limitations of slower layers. We
achieve an increased throughput of 2 to 4x compared to a conventional router.
Thereby, the dynamic power of routers is reduced by up to 41.1% and we achieve
improved flit latency of up to 2.26x at small total router area costs between
2.1% and 10.4% for realistic technologies and application scenarios.
"
1288,Packet Chasing: Spying on Network Packets over a Cache Side-Channel,"  This paper presents Packet Chasing, an attack on the network that does not
require access to the network, and works regardless of the privilege level of
the process receiving the packets. A spy process can easily probe and discover
the exact cache location of each buffer used by the network driver. Even more
useful, it can discover the exact sequence in which those buffers are used to
receive packets. This then enables packet frequency and packet sizes to be
monitored through cache side channels. This allows both covert channels between
a sender and a remote spy with no access to the network, as well as direct
attacks that can identify, among other things, the web page access patterns of
a victim on the network. In addition to identifying the potential attack, this
work proposes a software-based short-term mitigation as well as a light-weight,
adaptive, cache partitioning mitigation that blocks the interference of I/O and
CPU requests in the last-level cache.
"
1289,QuTiBench: Benchmarking Neural Networks on Heterogeneous Hardware,"  Neural Networks have become one of the most successful universal machine
learning algorithms. They play a key role in enabling machine vision and speech
recognition for example. Their computational complexity is enormous and comes
along with equally challenging memory requirements, which limits deployment in
particular within energy constrained, embedded environments. In order to
address these implementation challenges, a broad spectrum of new customized and
heterogeneous hardware architectures have emerged, often accompanied with
co-designed algorithms to extract maximum benefit out of the hardware.
Furthermore, numerous optimization techniques are being explored for neural
networks to reduce compute and memory requirements while maintaining accuracy.
This results in an abundance of algorithmic and architectural choices, some of
which fit specific use cases better than others.
  For system level designers, there is currently no good way to compare the
variety of hardware, algorithm and optimization options. While there are many
benchmarking efforts in this field, they cover only subsections of the embedded
design space. None of the existing benchmarks support essential algorithmic
optimizations such as quantization, an important technique to stay on chip, or
specialized heterogeneous hardware architectures. We propose a novel benchmark
suite, QuTiBench, that addresses this need. QuTiBench is a novel multi-tiered
benchmarking methodology that supports algorithmic optimizations such as
quantization and helps system developers understand the benefits and
limitations of these novel compute architectures in regard to specific neural
networks and will help drive future innovation. We invite the community to
contribute to QuTiBench in order to support the full spectrum of choices in
implementing machine learning systems.
"
1290,Instructional Level Parallelism,"  This paper is a review of the developments in Instruction level parallelism.
It takes into account all the changes made in speeding up the execution. The
various drawbacks and dependencies due to pipelining are discussed and various
solutions to overcome them are also incorporated. It goes ahead in the last
section to explain where is the new research leading us.
"
1291,TiM-DNN: Ternary in-Memory accelerator for Deep Neural Networks,"  The use of lower precision has emerged as a popular technique to optimize the
compute and storage requirements of complex Deep Neural Networks (DNNs). In the
quest for lower precision, recent studies have shown that ternary DNNs (which
represent weights and activations by signed ternary values) represent a
promising sweet spot, achieving accuracy close to full-precision networks on
complex tasks. We propose TiM-DNN, a programmable in-memory accelerator that is
specifically designed to execute ternary DNNs. TiM-DNN supports various ternary
representations including unweighted {-1,0,1}, symmetric weighted {-a,0,a}, and
asymmetric weighted {-a,0,b} ternary systems. The building blocks of TiM-DNN
are TiM tiles -- specialized memory arrays that perform massively parallel
signed ternary vector-matrix multiplications with a single access. TiM tiles
are in turn composed of Ternary Processing Cells (TPCs), bit-cells that
function as both ternary storage units and signed ternary multiplication units.
We evaluate an implementation of TiM-DNN in 32nm technology using an
architectural simulator calibrated with SPICE simulations and RTL synthesis. We
evaluate TiM-DNN across a suite of state-of-the-art DNN benchmarks including
both deep convolutional and recurrent neural networks. A 32-tile instance of
TiM-DNN achieves a peak performance of 114 TOPs/s, consumes 0.9W power, and
occupies 1.96mm2 chip area, representing a 300X and 388X improvement in TOPS/W
and TOPS/mm2, respectively, compared to an NVIDIA Tesla V100 GPU. In comparison
to specialized DNN accelerators, TiM-DNN achieves 55X-240X and 160X-291X
improvement in TOPS/W and TOPS/mm2, respectively. Finally, when compared to a
well-optimized near-memory accelerator for ternary DNNs, TiM-DNN demonstrates
3.9x-4.7x improvement in system-level energy and 3.2x-4.2x speedup,
underscoring the potential of in-memory computing for ternary DNNs.
"
1292,"A Data-Center FPGA Acceleration Platform for Convolutional Neural
  Networks","  Intensive computation is entering data centers with multiple workloads of
deep learning. To balance the compute efficiency, performance, and total cost
of ownership (TCO), the use of a field-programmable gate array (FPGA) with
reconfigurable logic provides an acceptable acceleration capacity and is
compatible with diverse computation-sensitive tasks in the cloud. In this
paper, we develop an FPGA acceleration platform that leverages a unified
framework architecture for general-purpose convolutional neural network (CNN)
inference acceleration at a data center. To overcome the computation bound,
4,096 DSPs are assembled and shaped as supertile units (SUs) for different
types of convolution, which provide up to 4.2 TOP/s 16-bit fixed-point
performance at 500 MHz. The interleaved-task-dispatching method is proposed to
map the computation across the SUs, and the memory bound is solved by a
dispatching-assembling buffering model and broadcast caches. For various
non-convolution operators, a filter processing unit is designed for
general-purpose filter-like/pointwise operators. In the experiment, the
performances of CNN models running on server-class CPUs, a GPU, and an FPGA are
compared. The results show that our design achieves the best FPGA peak
performance and a throughput at the same level as that of the state-of-the-art
GPU in data centers, with more than 50 times lower latency.
"
1293,HEAX: An Architecture for Computing on Encrypted Data,"  With the rapid increase in cloud computing, concerns surrounding data
privacy, security, and confidentiality also have been increased significantly.
Not only cloud providers are susceptible to internal and external hacks, but
also in some scenarios, data owners cannot outsource the computation due to
privacy laws such as GDPR, HIPAA, or CCPA. Fully Homomorphic Encryption (FHE)
is a groundbreaking invention in cryptography that, unlike traditional
cryptosystems, enables computation on encrypted data without ever decrypting
it. However, the most critical obstacle in deploying FHE at large-scale is the
enormous computation overhead.
  In this paper, we present HEAX, a novel hardware architecture for FHE that
achieves unprecedented performance improvement. HEAX leverages multiple levels
of parallelism, ranging from ciphertext-level to fine-grained modular
arithmetic level. Our first contribution is a new highly-parallelizable
architecture for number-theoretic transform (NTT) which can be of independent
interest as NTT is frequently used in many lattice-based cryptography systems.
Building on top of NTT engine, we design a novel architecture for computation
on homomorphically encrypted data. We also introduce several techniques to
enable an end-to-end, fully pipelined design as well as reducing on-chip memory
consumption. Our implementation on reconfigurable hardware demonstrates
164-268x performance improvement for a wide range of FHE parameters.
"
1294,Implementation of Goldschmidt's Algorithm with hardware reduction,"  Division algorithms have been developed to reduce latency and to improve the
efficiency of the processors. Floating point division is considered as a high
latency operation. This papers looks into one such division algorithm, examines
the hardware block diagram and suggests an alternative path which may be cost
effective.
"
1295,Appearances of the Birthday Paradox in High Performance Computing,"  We give an elementary statistical analysis of two High Performance Computing
issues, processor cache mapping and network port mapping. In both cases we find
that, as in the birthday paradox, random assignment leads to more frequent
coincidences than one expects a priori. Since these correspond to contention
for limited resources, this phenomenon has important consequences for
performance.
"
1296,"Storage Class Memory: Principles, Problems, and Possibilities","  Storage Class Memory (SCM) is a class of memory technology which has recently
become viable for use. Their namearises from the fact that they exhibit
non-volatility of data, similar to secondary storage while also having
latencies comparable toprimary memory and byte-addressibility. In this area,
Phase Change Memory (PCM), Spin-Transfer-Torque Random Access Memory(STT-RAM),
and Resistive RAM (ReRAM) have emerged as the major contenders for commercial
and industrial use. In this paper, wedescribe how these memory types function,
while highlighting the problems of endurance and performance that these memory
typesface. We also discuss the future possibilities of Multi-Level Cells
(MLCs), as well as how SCM can be used to construct accelerators.
"
1297,New Attacks and Defenses for Randomized Caches,"  The last level cache is vulnerable to timing based side channel attacks
because it is shared by the attacker and the victim processes even if they are
located on different cores. These timing attacks evict the victim cache lines
using small conflict groups(SCG), and monitor the cache to observe when the
victim uses these cache lines again. A conflict group is a collection of cache
lines which will evict the target cache line. Randomization is often used by
defenses to prevent creation of SCGs.
  We introduce new attacks to demonstrate that the current randomization
schemes require an extremely high refresh rate to be secure, on average a 15\%
performance overhead, and upto 50\% in the worst case. Next, we propose a new
randomization strategy using an indirection table, which mitigates this issue.
Addresses of cache lines are encrypted and used to lookup the indirection table
entry. Each indirection table entry stores a mapping to a randomly chosen cache
set. The cache line is placed into this randomly chosen set. The encryption key
changes upto 50x faster than CEASER's default rate, by using evictions to
trigger the re-randomization. Instead of moving cache lines, this mechanism
re-randomizes one iTable entry at a time, whenever the cache lines
corresponding to the iTable entry are naturally evicted. Thus, the miss rate is
not much worse than the baseline.
  We quantitatively show that our scheme does almost as well as a fully
associative cache to defend against these attacks. We also demonstrate new
attacks that target the iTable by oversubscribing its entries, and
quantitatively show that our scheme is resilient against new attacks for
trillions of years. We estimate low area ( < 7\%) and power overhead compared
to a baseline inclusive last-level cache. Lastly, we evaluate a low performance
overhead (<4%) using the SPECrate 2017 and PARSEC 3.0 benchmarks.
"
1298,A Survey of Machine Learning Applied to Computer Architecture Design,"  Machine learning has enabled significant benefits in diverse fields, but,
with a few exceptions, has had limited impact on computer architecture. Recent
work, however, has explored broader applicability for design, optimization, and
simulation. Notably, machine learning based strategies often surpass prior
state-of-the-art analytical, heuristic, and human-expert approaches. This paper
reviews machine learning applied system-wide to simulation and run-time
optimization, and in many individual components, including memory systems,
branch predictors, networks-on-chip, and GPUs. The paper further analyzes
current practice to highlight useful design strategies and identify areas for
future work, based on optimized implementation strategies, opportune extensions
to existing work, and ambitious long term possibilities. Taken together, these
strategies and techniques present a promising future for increasingly automated
architectural design.
"
1299,"Optimizing Design Verification using Machine Learning: Doing better than
  Random","  As integrated circuits have become progressively more complex, constrained
random stimulus has become ubiquitous as a means of stimulating a designs
functionality and ensuring it fully meets expectations. In theory, random
stimulus allows all possible combinations to be exercised given enough time,
but in practice with highly complex designs a purely random approach will have
difficulty in exercising all possible combinations in a timely fashion. As a
result it is often necessary to steer the Design Verification (DV) environment
to generate hard to hit combinations. The resulting constrained-random approach
is powerful but often relies on extensive human expertise to guide the DV
environment in order to fully exercise the design. As designs become more
complex, the guidance aspect becomes progressively more challenging and time
consuming often resulting in design schedules in which the verification time to
hit all possible design coverage points is the dominant schedule limitation.
This paper describes an approach which leverages existing constrained-random DV
environment tools but which further enhances them using supervised learning and
reinforcement learning techniques. This approach provides better than random
results in a highly automated fashion thereby ensuring DV objectives of full
design coverage can be achieved on an accelerated timescale and with fewer
resources.
  Two hardware verification examples are presented, one of a Cache Controller
design and one using the open-source RISCV-Ariane design and Google's RISCV
Random Instruction Generator. We demonstrate that a machine-learning based
approach can perform significantly better on functional coverage and reaching
complex hard-to-hit states than a random or constrained-random approach.
"
1300,"AdaptivFloat: A Floating-point based Data Type for Resilient Deep
  Learning Inference","  Conventional hardware-friendly quantization methods, such as fixed-point or
integer, tend to perform poorly at very low word sizes as their shrinking
dynamic ranges cannot adequately capture the wide data distributions commonly
seen in sequence transduction models. We present AdaptivFloat, a floating-point
inspired number representation format for deep learning that dynamically
maximizes and optimally clips its available dynamic range, at a layer
granularity, in order to create faithful encoding of neural network parameters.
AdaptivFloat consistently produces higher inference accuracies compared to
block floating-point, uniform, IEEE-like float or posit encodings at very low
precision ($\leq$ 8-bit) across a diverse set of state-of-the-art neural
network topologies. And notably, AdaptivFloat is seen surpassing baseline FP32
performance by up to +0.3 in BLEU score and -0.75 in word error rate at weight
bit widths that are $\leq$ 8-bit. Experimental results on a deep neural network
(DNN) hardware accelerator, exploiting AdaptivFloat logic in its computational
datapath, demonstrate per-operation energy and area that is 0.9$\times$ and
1.14$\times$, respectively, that of equivalent bit width integer-based
accelerator variants.
"
1301,"Run-time reconfigurable multi-precision floating point multiplier design
  for high speed, low-power applications","  Floating point multiplication is one of the crucial operations in many
application domains such as image processing, signal processing etc. But every
application requires different working features. Some need high precision, some
need low power consumption, low latency etc. But IEEE-754 format is not really
flexible for these specifications and also design is complex. Optimal run-time
reconfigurable hardware implementations may need the use of custom
floating-point formats that do not necessarily follow IEEE specified sizes. In
this paper, we present a run-time-reconfigurable floating point multiplier
implemented on FPGA with custom floating point format for different
applications. This floating point multiplier can have 6 modes of operations
depending on the accuracy or application requirement. With the use of optimal
design with custom IPs (Intellectual Properties), a better implementation is
done by truncating the inputs before multiplication. And a combination of
Karatsuba algorithm and Urdhva-Tiryagbhyam algorithm (Vedic Mathematics) is
used to implement unsigned binary multiplier. This further increases the
efficiency of the multiplier.
"
1302,"REQ-YOLO: A Resource-Aware, Efficient Quantization Framework for Object
  Detection on FPGAs","  Deep neural networks (DNNs), as the basis of object detection, will play a
key role in the development of future autonomous systems with full autonomy.
The autonomous systems have special requirements of real-time, energy-efficient
implementations of DNNs on a power-constrained system. Two research thrusts are
dedicated to performance and energy efficiency enhancement of the inference
phase of DNNs. The first one is model compression techniques while the second
is efficient hardware implementation. Recent works on extremely-low-bit CNNs
such as the binary neural network (BNN) and XNOR-Net replace the traditional
floating-point operations with binary bit operations which significantly
reduces the memory bandwidth and storage requirement. However, it suffers from
non-negligible accuracy loss and underutilized digital signal processing (DSP)
blocks of FPGAs. To overcome these limitations, this paper proposes REQ-YOLO, a
resource-aware, systematic weight quantization framework for object detection,
considering both algorithm and hardware resource aspects in object detection.
We adopt the block-circulant matrix method and propose a heterogeneous weight
quantization using the Alternating Direction Method of Multipliers (ADMM), an
effective optimization technique for general, non-convex optimization problems.
To achieve real-time, highly-efficient implementations on FPGA, we present the
detailed hardware implementation of block circulant matrices on CONV layers and
develop an efficient processing element (PE) structure supporting the
heterogeneous weight quantization, CONV dataflow and pipelining techniques,
design optimization, and a template-based automatic synthesis framework to
optimally exploit hardware resource. Experimental results show that our
proposed REQ-YOLO framework can significantly compress the YOLO model while
introducing very small accuracy degradation.
"
1303,"System-level optimization of Network-on-Chips for heterogeneous 3D
  System-on-Chips","  For a system-level design of Networks-on-Chip for 3D heterogeneous
System-on-Chip (SoC), the locations of components, routers and vertical links
are determined from an application model and technology parameters. In
conventional methods, the two inputs are accounted for separately; here, we
define an integrated problem that considers both application model and
technology parameters. We show that this problem does not allow for exact
solution in reasonable time, as common for many design problems. Therefore, we
contribute a heuristic by proposing design steps, which are based on separation
of intralayer and interlayer communication. The advantage is that this new
problem can be solved with well-known methods. We use 3D Vision SoC case
studies to quantify the advantages and the practical usability of the proposed
optimization approach. We achieve up to 18.8% reduced white space and up to
12.4% better network performance in comparison to conventional approaches.
"
1304,Analysis and Design of a 32nm FinFET Dynamic Latch Comparator,"  Comparators have multifarious applications in various fields, especially used
in analog to digital converters. Over the years, we have seen many different
designs of single stage, dynamic latch type and double tail type comparators
based on CMOS technology, and all of them had to make the tradeoff between
power consumption and delay time. Meanwhile, to mitigate the short channel
effects of conventional CMOS based design, FinFET has emerged as the most
promising alternative by owning the tremendous gate control feature over the
channel region. In this paper, we have analyzed the performance of some recent
dynamic latch type comparators and proposed a new structure of dynamic latch
comparator; moreover, 32nm FinFET technology has been considered as the common
platform for all of the comparators circuit design. The proposed comparator has
shown impressive performance in case of power consumption, time delay, power
delay product and offset voltage while compared with the other recent
comparators through simulations with LTspice.
"
1305,Optimizing GPU Cache Policies for MI Workloads,"  In recent years, machine intelligence (MI) applications have emerged as a
major driver for the computing industry. Optimizing these workloads is
important but complicated. As memory demands grow and data movement overheads
increasingly limit performance, determining the best GPU caching policy to use
for a diverse range of MI workloads represents one important challenge. To
study this, we evaluate 17 MI applications and characterize their behaviors
using a range of GPU caching strategies. In our evaluations, we find that the
choice of caching policy in GPU caches involves multiple performance trade-offs
and interactions, and there is no one-size-fits-all GPU caching policy for MI
workloads. Based on detailed simulation results, we motivate and evaluate a set
of cache optimizations that consistently match the performance of the best
static GPU caching policies.
"
1306,UltraShare: FPGA-based Dynamic Accelerator Sharing and Allocation,"  Despite all the available commercial and open-source frameworks to ease
deploying FPGAs in accelerating applications, the current schemes fail to
support sharing multiple accelerators among various applications. There are
three main features that an accelerator sharing scheme requires to support:
exploiting dynamic parallelism of multiple accelerators for a single
application, sharing accelerators among multiple applications, and providing a
non-blocking congestion-free environment for applications to invoke the
accelerators. In this paper, we developed a scalable fully functional hardware
controller, called UltraShare, with a supporting software stack that provides a
dynamic accelerator sharing scheme through an accelerators grouping mechanism.
UltraShare allows software applications to fully utilize FPGA accelerators in a
non-blocking congestion-free environment. Our experimental results for a simple
scenario of a combination of three streaming accelerators invocation show an
improvement of up to 8x in throughput of the accelerators by removing
accelerators idle times.
"
1307,"ARCHITECT: Arbitrary-precision Hardware with Digit Elision for Efficient
  Iterative Compute","  Many algorithms feature an iterative loop that converges to the result of
interest. The numerical operations in such algorithms are generally implemented
using finite-precision arithmetic, either fixed- or floating-point, most of
which operate least-significant digit first. This results in a fundamental
problem: if, after some time, the result has not converged, is this because we
have not run the algorithm for enough iterations or because the arithmetic in
some iterations was insufficiently precise? There is no easy way to answer this
question, so users will often over-budget precision in the hope that the answer
will always be to run for a few more iterations. We propose a fundamentally new
approach: with the appropriate arithmetic able to generate results from
most-significant digit first, we show that fixed compute-area hardware can be
used to calculate an arbitrary number of algorithmic iterations to arbitrary
precision, with both precision and approximant index increasing in lockstep.
Consequently, datapaths constructed following our principles demonstrate
efficiency over their traditional arithmetic equivalents where the latter's
precisions are either under- or over-budgeted for the computation of a result
to a particular accuracy. Use of most-significant digit-first arithmetic
additionally allows us to declare certain digits to be stable at runtime,
avoiding their recalculation in subsequent iterations and thereby increasing
performance and decreasing memory footprints. Versus arbitrary-precision
iterative solvers without the optimisations we detail herein, we achieve up-to
16$\times$ performance speedups and 1.9x memory savings for the evaluated
benchmarks.
"
1308,Temperature-Based Hardware Trojan For Ring-Oscillator-Based TRNGs,"  True random number generators (TRNGs) are essential components of
cryptographic designs, which are used to generate private keys for encryption
and authentication, and are used in masking countermeasures. In this work, we
present a mechanism to design a stealthy parametric hardware Trojan for a ring
oscillator based TRNG architecture proposed by Yang et al. at ISSCC 2014. Once
the Trojan is triggered the malicious TRNG generates predictable non-random
outputs. Such a Trojan does not require any additional logic (even a single
gate) and is purely based on subtle manipulations on the sub-transistor level.
The underlying concept is to disable the entropy source at high temperature to
trigger the Trojan, while ensuring that Trojan-infected TRNG works correctly
under normal conditions. We show how an attack can be performed with the
Trojan-infected TRNG design in which the attacker uses a stochastic Markov
Chain model to predict its reduced-entropy outputs.
"
1309,"Side-Channel Hardware Trojan for Provably-Secure SCA-Protected
  Implementations","  Hardware Trojans have drawn the attention of academia, industry and
government agencies. Effective detection mechanisms and countermeasures against
such malicious designs can only be developed when there is a deep understanding
of how hardware Trojans can be built in practice, in particular Trojans
specifically designed to avoid detection. In this work, we present a mechanism
to introduce an extremely stealthy hardware Trojan into cryptographic
primitives equipped with provably-secure first-order side-channel
countermeasures. Once the Trojan is triggered, the malicious design exhibits
exploitable side-channel leakage, leading to successful key recovery attacks.
Generally, such a Trojan requires neither addition nor removal of any logic
which makes it extremely hard to detect. On ASICs, it can be inserted by subtle
manipulations at the sub-transistor level and on FPGAs by changing the routing
of particular signals, leading to \textbf{zero} logic overhead. The underlying
concept is based on modifying a securely-masked hardware implementation in such
a way that running the device at a particular clock frequency violates one of
its essential properties, leading to exploitable leakage. We apply our
technique to a Threshold Implementation of the PRESENT block cipher realized in
two different CMOS technologies, and show that triggering the Trojan makes the
ASIC prototypes vulnerable.
"
1310,"An efficient floating point multiplier design for high speed
  applications using Karatsuba algorithm and Urdhva-Tiryagbhyam algorithm","  Floating point multiplication is a crucial operation in high power computing
applications such as image processing, signal processing etc. And also
multiplication is the most time and power consuming operation. This paper
proposes an efficient method for IEEE 754 floating point multiplication which
gives a better implementation in terms of delay and power. A combination of
Karatsuba algorithm and Urdhva-Tiryagbhyam algorithm (Vedic Mathematics) is
used to implement unsigned binary multiplier for mantissa multiplication. The
multiplier is implemented using Verilog HDL, targeted on Spartan-3E and
Virtex-4 FPGA.
"
1311,DSPatch: Dual Spatial Pattern Prefetcher,"  High main memory latency continues to limit performance of modern
high-performance out-of-order cores. While DRAM latency has remained nearly the
same over many generations, DRAM bandwidth has grown significantly due to
higher frequencies, newer architectures (DDR4, LPDDR4, GDDR5) and 3D-stacked
memory packaging (HBM). Current state-of-the-art prefetchers do not do well in
extracting higher performance when higher DRAM bandwidth is available.
Prefetchers need the ability to dynamically adapt to available bandwidth,
boosting prefetch count and prefetch coverage when headroom exists and
throttling down to achieve high accuracy when the bandwidth utilization is
close to peak. To this end, we present the Dual Spatial Pattern Prefetcher
(DSPatch) that can be used as a standalone prefetcher or as a lightweight
adjunct spatial prefetcher to the state-of-the-art delta-based Signature
Pattern Prefetcher (SPP). DSPatch builds on a novel and intuitive use of
modulated spatial bit-patterns. The key idea is to: (1) represent program
accesses on a physical page as a bit-pattern anchored to the first ""trigger""
access, (2) learn two spatial access bit-patterns: one biased towards coverage
and another biased towards accuracy, and (3) select one bit-pattern at run-time
based on the DRAM bandwidth utilization to generate prefetches. Across a
diverse set of workloads, using only 3.6KB of storage, DSPatch improves
performance over an aggressive baseline with a PC-based stride prefetcher at
the L1 cache and the SPP prefetcher at the L2 cache by 6% (9% in
memory-intensive workloads and up to 26%). Moreover, the performance of
DSPatch+SPP scales with increasing DRAM bandwidth, growing from 6% over SPP to
10% when DRAM bandwidth is doubled.
"
1312,Performance Impact of Memory Channels on Sparse and Irregular Algorithms,"  Graph processing is typically considered to be a memory-bound rather than
compute-bound problem. One common line of thought is that more available memory
bandwidth corresponds to better graph processing performance. However, in this
work we demonstrate that the key factor in the utilization of the memory system
for graph algorithms is not necessarily the raw bandwidth or even the latency
of memory requests. Instead, we show that performance is proportional to the
number of memory channels available to handle small data transfers with limited
spatial locality.
  Using several widely used graph frameworks, including Gunrock (on the GPU)
and GAPBS \& Ligra (for CPUs), we evaluate key graph analytics kernels using
two unique memory hierarchies, DDR-based and HBM/MCDRAM. Our results show that
the differences in the peak bandwidths of several Pascal-generation GPU memory
subsystems aren't reflected in the performance of various analytics.
Furthermore, our experiments on CPU and Xeon Phi systems demonstrate that the
number of memory channels utilized can be a decisive factor in performance
across several different applications. For CPU systems with smaller thread
counts, the memory channels can be underutilized while systems with high thread
counts can oversaturate the memory subsystem, which leads to limited
performance. Finally, we model the potential performance improvements of adding
more memory channels with narrower access widths than are found in current
platforms, and we analyze performance trade-offs for the two most prominent
types of memory accesses found in graph algorithms, streaming and random
accesses.
"
1313,hlslib: Software Engineering for Hardware Design,"  High-level synthesis (HLS) tools have brought FPGA development into the
mainstream, by allowing programmers to design architectures using familiar
languages such as C, C++, and OpenCL. While the move to these languages has
brought significant benefits, many aspects of traditional software engineering
are still unsupported, or not exploited by developers in practice. Furthermore,
designing reconfigurable architectures requires support for hardware
constructs, such as FIFOs and shift registers, that are not native to
CPU-oriented languages. To address this gap, we have developed hlslib, a
collection of software tools, plug-in hardware modules, and code samples,
designed to enhance the productivity of HLS developers. The goal of hlslib is
two-fold: first, create a community-driven arena of bleeding edge development,
which can move quicker, and provides more powerful abstractions than what is
provided by vendors; and second, collect a wide range of example codes, both
minimal proofs of concept, and larger, real-world applications, that can be
reused directly or inspire other work. hlslib is offered as an open source
library, containing CMake files, C++ headers, convenience scripts, and examples
codes, and is receptive to any contribution that can benefit HLS developers,
through general functionality or examples.
"
1314,A Novel Low Power Non-Volatile SRAM Cell with Self Write Termination,"  A non-volatile SRAM cell is proposed for low power applications using Spin
Transfer Torque-Magnetic Tunnel Junction (STT-MTJ) devices. This novel cell
offers non-volatile storage, thus allowing selected blocks of SRAM to be
switched off during standby operation. To further increase the power savings, a
write termination circuit is designed which detects completion of MTJ write and
closes the bidirectional current path for the MTJ. A reduction of 25.81% in the
number of transistors and a reduction of 2.95% in the power consumption is
achieved in comparison to prior work on write termination circuits.
"
1315,"Remote Control: A Simple Deadlock Avoidance Scheme for Modular System on
  Chip","  The increase in design cost and complexity have motivated designers to adopt
modular design of System on Chip (SoC) by integrating independently designed
small chiplets. However, it introduces new challenges for correctness
validation, increasing chances of forming deadlock in the system involving
multiple chiplets. Although there have been many solutions available for
deadlock freedom in flat networks, the study on deadlock issue in chiplet-based
systems is still in its infancy. A recent study suggests adding extra turn
restrictions as a viable solution for this problem. However, imposing extra
turn restrictions reduces chiplet design flexibility and interposer design
complexity. In addition, it may lead to non-minimal route and traffic imbalance
forming hotspots, resulting in high latency and low throughput.
  We propose Remote Control (RC), a simple routing oblivious deadlock avoidance
scheme. Our proposal is based on two key observations. First, packets with
destinations in the current chiplet are blocked by packets with destinations
outside the chiplet. Second, deadlock always involves multiple boundary
routers. Hence, we segregate different traffics to alleviate mutual blocking at
the chiplet's boundary routers. Along with guarantee of deadlock freedom and
performance enhancements, our simple RC scheme also provides more routing
flexibility to both chiplet and SoC designers, as compared to the
state-of-the-art.
"
1316,Threshold Logic in a Flash,"  This paper describes a novel design of a threshold logic gate (a binary
perceptron) and its implementation as a standard cell. This new cell structure,
referred to as flash threshold logic (FTL), uses floating gate (flash)
transistors to realize the weights associated with a threshold function. The
threshold voltages of the flash transistors serve as a proxy for the weights.
An FTL cell can be equivalently viewed as a multi-input, edge-triggered
flipflop which computes a threshold function on a clock edge. Consequently, it
can be used in the automatic synthesis of ASICs. The use of flash transistors
in the FTL cell allows programming of the weights after fabrication, thereby
preventing discovery of its function by a foundry or by reverse engineering.
This paper focuses on the design and characteristics of the FTL cell. We
present a novel method for programming the weights of an FTL cell for a
specified threshold function using a modified perceptron learning algorithm.
The algorithm is further extended to select weights to maximize the robustness
of the design in the presence of process variations. The FTL circuit was
designed in 40nm technology and simulations with layout-extracted parasitics
included, demonstrate significant improvements in the area (79.7%), power
(61.1%), and performance (42.5%) when compared to the equivalent
implementations of the same function in conventional static CMOS design. Weight
selection targeting robustness is demonstrated using Monte Carlo simulations.
The paper also shows how FTL cells can be used for fixing timing errors after
fabrication.
"
1317,"Run-Time-Reconfigurable Multi-Precision Floating-Point Matrix Multiplier
  Intellectual Property Core on FPGA","  In todays world, high-power computing applications such as image processing,
digital signal processing, graphics, and robotics require enormous computing
power. These applications use matrix operations, especially matrix
multiplication. Multiplication operations require a lot of computational time
and are also complex in design. We can use field-programmable gate arrays as
low-cost hardware accelerators along with a low-cost general-purpose processor
instead of a high-cost application-specific processor for such applications. In
this work, we employ an efficient Strassens algorithm for matrix multiplication
and a highly efficient run-time-reconfigurable floating-point multiplier for
matrix element multiplication. The run-time-reconfigurable floating-point
multiplier is implemented with custom floating-point format for
variable-precision applications. A very efficient combination of Karatsuba
algorithm and Urdhva Tiryagbhyam algorithm is used to implement the binary
multiplier. This design can effectively adjust the power and delay requirements
according to different accuracy requirements by reconfiguring itself during run
time.
"
1318,"Mitosis: Transparently Self-Replicating Page-Tables for Large-Memory
  Machines","  Multi-socket machines with 1-100 TBs of physical memory are becoming
prevalent. Applications running on multi-socket machines suffer non-uniform
bandwidth and latency when accessing physical memory. Decades of research have
focused on data allocation and placement policies in NUMA settings, but there
have been no studies on the question of how to place page-tables amongst
sockets. We make the case for explicit page-table allocation policies and show
that page-table placement is becoming crucial to overall performance. We
propose Mitosis to mitigate NUMA effects on page-table walks by transparently
replicating and migrating page-tables across sockets without application
changes. This reduces the frequency of accesses to remote NUMA nodes when
performing page-table walks. Mitosis uses two components: (i) a mechanism to
enable efficient page-table replication and migration; and (ii) policies for
processes to efficiently manage and control page-table replication and
migration. We implement Mitosis in Linux and evaluate its benefits on real
hardware. Mitosis improves performance for large-scale multi-socket workloads
by up to 1.34x by replicating page-tables across sockets. Moreover, it improves
performance by up to 3.24x in cases when the OS migrates a process across
sockets by enabling cross-socket page-table migration.
"
1319,"Hardware/Software Codesign for Training/Testing Multiple Neural Networks
  on Multiple FPGAs","  Most neural network designs for FPGAs are inflexible. In this paper, we
propose a flexible VHDL structure that would allow any neural network to be
implemented on multiple FPGAs. Moreover, the VHDL structure allows for testing
as well as training multiple neural networks. The VHDL design consists of
multiple processor groups. There are two types of processor groups: Mini Vector
Machine Processor Group and Activation Processor Group. Each processor group
consists of individual Mini Vector Machines and Activation Processor. The Mini
Vector Machines apply vector operations to the data, while the Activation
Processors apply activation functions to the data. A ring buffer was
implemented to connect the various processor groups.
"
1320,"Refresh Triggered Computation: Improving the Energy Efficiency of
  Convolutional Neural Network Accelerators","  To employ a Convolutional Neural Network (CNN) in an energy-constrained
embedded system, it is critical for the CNN implementation to be highly energy
efficient. Many recent studies propose CNN accelerator architectures with
custom computation units that try to improve energy-efficiency and performance
of CNNs by minimizing data transfers from DRAM-based main memory. However, in
these architectures, DRAM is still responsible for half of the overall energy
consumption of the system, on average. A key factor of the high energy
consumption of DRAM is the refresh overhead, which is estimated to consume 40%
of the total DRAM energy. In this paper, we propose a new mechanism, Refresh
Triggered Computation (RTC), that exploits the memory access patterns of CNN
applications to reduce the number of refresh operations. We propose three RTC
designs (min-RTC, mid-RTC, and full-RTC), each of which requires a different
level of aggressiveness in terms of customization to the DRAM subsystem. All of
our designs have small overhead. Even the most aggressive RTC design (i.e.,
full-RTC) imposes an area overhead of only 0.18% in a 16 Gb DRAM chip and can
have less overhead for denser chips. Our experimental evaluation on six
well-known CNNs show that RTC reduces average DRAM energy consumption by 24.4%
and 61.3%, for the least aggressive and the most aggressive RTC
implementations, respectively. Besides CNNs, we also evaluate our RTC mechanism
on three workloads from other domains. We show that RTC saves 31.9% and 16.9%
DRAM energy for Face Recognition and Bayesian Confidence Propagation Neural
Network (BCPNN), respectively. We believe RTC can be applied to other
applications whose memory access patterns remain predictable for a sufficiently
long time.
"
1321,"Modern Multicore CPUs are not Energy Proportional: Opportunity for
  Bi-objective Optimization for Performance and Energy","  Energy proportionality is the key design goal followed by architects of
modern multicore CPUs. One of its implications is that optimization of an
application for performance will also optimize it for energy. In this work, we
show that energy proportionality does not hold true for multicore CPUs. This
finding creates the opportunity for bi-objective optimization of applications
for performance and energy. We propose and study the first application-level
method for bi-objective optimization of multithreaded data-parallel
applications for performance and energy. The method uses two decision
variables, the number of identical multithreaded kernels (threadgroups)
executing the application and the number of threads in each threadgroup, with
the workload always partitioned equally between the threadgroups. We
experimentally demonstrate the efficiency of the method using four highly
optimized multithreaded data-parallel applications, 2D fast Fourier transform
based on FFTW and Intel MKL, and dense matrix-matrix multiplication using
OpenBLAS and Intel MKL. Four modern multicore CPUs are used in the experiments.
The experiments show that optimization for performance alone results in the
increase in dynamic energy consumption by up to 89% and optimization for
dynamic energy alone degrades the performance by up to 49%. By solving the
bi-objective optimization problem, the method determines up to 11 globally
Pareto-optimal solutions. Finally, we propose a qualitative dynamic energy
model employing performance monitoring counters as parameters, which we use to
explain the discovered energy nonproportionality and the Pareto-optimal
solutions determined by our method. The model shows that the energy
nonproportionality in our case is due to the activity of the data translation
lookaside buffer (dTLB), which is disproportionately energy expensive.
"
1322,"The Memory Controller Wall: Benchmarking the Intel FPGA SDK for OpenCL
  Memory Interface","  Supported by their high power efficiency and recent advancements in High
Level Synthesis (HLS), FPGAs are quickly finding their way into HPC and cloud
systems. Large amounts of work have been done so far on loop and area
optimizations for different applications on FPGAs using HLS. However, a
comprehensive analysis of the behavior and efficiency of the memory controller
of FPGAs is missing in literature, which becomes even more crucial when the
limited memory bandwidth of modern FPGAs compared to their GPU counterparts is
taken into account. In this work, we will analyze the memory interface
generated by Intel FPGA SDK for OpenCL with different configurations for
input/output arrays, vector size, interleaving, kernel programming model,
on-chip channels, operating frequency, padding, and multiple types of
overlapped blocking. Our results point to multiple shortcomings in the memory
controller of Intel FPGAs, especially with respect to memory access alignment,
that can hinder the programmer's ability in maximizing memory performance in
their design. For some of these cases, we will provide work-arounds to improve
memory bandwidth efficiency; however, a general solution will require major
changes in the memory controller itself.
"
1323,GraVF-M: Graph Processing System Generation for Multi-FPGA Platforms,"  Due to the irregular nature of connections in most graph datasets,
partitioning graph analysis algorithms across multiple computational nodes that
do not share a common memory inevitably leads to large amounts of interconnect
traffic. Previous research has shown that FPGAs can outcompete software-based
graph processing in shared memory contexts, but it remains an open question if
this advantage can be maintained in distributed systems.
  In this work, we present GraVF-M, a framework designed to ease the
implementation of FPGA-based graph processing accelerators for multi-FPGA
platforms with distributed memory. Based on a lightweight description of the
algorithm kernel, the framework automatically generates optimized RTL code for
the whole multi-FPGA design. We exploit an aspect of the programming model to
present a familiar message-passing paradigm to the user, while under the hood
implementing a more efficient architecture that can reduce the necessary
inter-FPGA network traffic by a factor equal to the average degree of the input
graph. A performance model based on a theoretical analysis of the factors
influencing performance serves to evaluate the efficiency of our
implementation. With a throughput of up to 5.8 GTEPS (billions of traversed
edges per second) on a 4-FPGA system, the designs generated by GraVF-M compare
favorably to state-of-the-art frameworks from the literature and reach 94% of
the projected performance limit of the system.
"
1324,"Sapphire: A Configurable Crypto-Processor for Post-Quantum Lattice-based
  Protocols","  Public key cryptography protocols, such as RSA and elliptic curve
cryptography, will be rendered insecure by Shor's algorithm when large-scale
quantum computers are built. Cryptographers are working on quantum-resistant
algorithms, and lattice-based cryptography has emerged as a prime candidate.
However, high computational complexity of these algorithms makes it challenging
to implement lattice-based protocols on low-power embedded devices. To address
this challenge, we present Sapphire - a lattice cryptography processor with
configurable parameters. Efficient sampling, with a SHA-3-based PRNG, provides
two orders of magnitude energy savings; a single-port RAM-based number
theoretic transform memory architecture is proposed, which provides 124k-gate
area savings; while a low-power modular arithmetic unit accelerates polynomial
computations. Our test chip was fabricated in TSMC 40nm low-power CMOS process,
with the Sapphire cryptographic core occupying 0.28 mm2 area consisting of 106k
logic gates and 40.25 KB SRAM. Sapphire can be programmed with custom
instructions for polynomial arithmetic and sampling, and it is coupled with a
low-power RISC-V micro-processor to demonstrate NIST Round 2 lattice-based
CCA-secure key encapsulation and signature protocols Frodo, NewHope, qTESLA,
CRYSTALS-Kyber and CRYSTALS-Dilithium, achieving up to an order of magnitude
improvement in performance and energy-efficiency compared to state-of-the-art
hardware implementations. All key building blocks of Sapphire are constant-time
and secure against timing and simple power analysis side-channel attacks. We
also discuss how masking-based DPA countermeasures can be implemented on the
Sapphire core without any changes to the hardware.
"
1325,Analytical models of Energy and Throughput for Caches in MPSoCs,"  General trends in computer architecture are shifting more towards
parallelism. Multicore architectures have proven to be a major step in
processor evolution. With the advancement in multicore architecture,
researchers are focusing on finding different solutions to fully utilize the
power of multiple cores. With an ever-increasing number of cores on a chip, the
role of cache memory has become pivotal. An ideal memory configuration should
be both large and fast, however, in fact, system architects have to strike a
balance between the size and access time of the memory hierarchy. It is
important to know the impact of a particular cache configuration on the
throughput and energy consumption of the system at design time. This paper
presents an enhanced version of previously proposed cache energy and throughput
models for multicore systems. These models use significantly a smaller number
of input parameters as compared to other models. This paper also validates the
proposed models through cycle accurate simulator and a renowned processor power
estimator. The results show that the proposed energy models provide accuracy
within a maximum error range of 10% for single-core processors and around 5%
for MPSoCs, and the throughput models result in a maximum error of up to 11.5%
for both single and multicore architectures.
"
1326,"ELSA: A Throughput-Optimized Design of an LSTM Accelerator for
  Energy-Constrained Devices","  The next significant step in the evolution and proliferation of artificial
intelligence technology will be the integration of neural network (NN) models
within embedded and mobile systems. This calls for the design of compact,
energy efficient NN models in silicon. In this paper, we present a scalable
ASIC design of an LSTM accelerator named ELSA, that is suitable for
energy-constrained devices. It includes several architectural innovations to
achieve small area and high energy efficiency. To reduce the area and power
consumption of the overall design, the compute-intensive units of ELSA employ
approximate multiplications and still achieve high performance and accuracy.
The performance is further improved through efficient synchronization of the
elastic pipeline stages to maximize the utilization. The paper also includes a
performance model of ELSA, as a function of the hidden nodes and time steps,
permitting its use for the evaluation of any LSTM application. ELSA was
implemented in RTL and was synthesized and placed and routed in 65nm
technology. Its functionality is demonstrated for language modeling-a common
application of LSTM. ELSA is compared against a baseline implementation of an
LSTM accelerator with standard functional units and without any of the
architectural innovations of ELSA. The paper demonstrates that ELSA can achieve
significant improvements in power, area and energy-efficiency when compared to
the baseline design and several ASIC implementations reported in the
literature, making it suitable for use in embedded systems and real-time
applications.
"
1327,"SneakySnake: A Fast and Accurate Universal Genome Pre-Alignment Filter
  for CPUs, GPUs, and FPGAs","  Motivation: We introduce SneakySnake, a highly parallel and highly accurate
pre-alignment filter that remarkably reduces the need for the computationally
costly sequence alignment step. The key idea of SneakySnake is to reduce the
approximate string matching (ASM) problem to the single net routing (SNR)
problem in VLSI chip layout. In the SNR problem, we are interested in only
finding the optimal path that connects two terminals with the least routing
cost on a special grid layout that contains obstacles. The SneakySnake
algorithm quickly solves the SNR problem and uses the found optimal path to
decide whether performing sequence alignment is necessary. Reducing the ASM
problem into SNR also makes SneakySnake efficient to implement for all modern
high-performance computing architectures (CPUs, GPUs, and FPGAs).
  Results: SneakySnake significantly improves the accuracy of pre-alignment
filtering by up to four orders of magnitude compared to the state-of-the-art
pre-alignment filters, Shouji, GateKeeper, and SHD. SneakySnake accelerates
Edlib (state-of-the-art implementation of Myers's bit-vector algorithm) and
Parasail (sequence aligner with configurable scoring function), by up to 37.6x
and 43.9x (>12x on average), respectively, without requiring hardware
acceleration, and by up to 413x and 689x (>400x on average), respectively,
using hardware acceleration. SneakySnake also accelerates the sequence
alignment of minimap2, a state-of-the-art read mapper, by 2.51x to 6.83x
without requiring hardware acceleration. As SneakySnake does not replace
sequence alignment, users can still configure the aligner of their choice for
different scoring functions, surpassing most existing efforts that aim to
accelerate sequence alignment.
  Availability: https://github.com/CMU-SAFARI/SneakySnake
"
1328,"Automatic Generation of Multi-precision Multi-arithmetic CNN
  Accelerators for FPGAs","  Modern deep Convolutional Neural Networks (CNNs) are computationally
demanding, yet real applications often require high throughput and low latency.
To help tackle these problems, we propose Tomato, a framework designed to
automate the process of generating efficient CNN accelerators. The generated
design is pipelined and each convolution layer uses different arithmetics at
various precisions. Using Tomato, we showcase state-of-the-art multi-precision
multi-arithmetic networks, including MobileNet-V1, running on FPGAs. To our
knowledge, this is the first multi-precision multi-arithmetic auto-generation
framework for CNNs. In software, Tomato fine-tunes pretrained networks to use a
mixture of short powers-of-2 and fixed-point weights with a minimal loss in
classification accuracy. The fine-tuned parameters are combined with the
templated hardware designs to automatically produce efficient inference
circuits in FPGAs. We demonstrate how our approach significantly reduces model
sizes and computation complexities, and permits us to pack a complete ImageNet
network onto a single FPGA without accessing off-chip memories for the first
time. Furthermore, we show how Tomato produces implementations of networks with
various sizes running on single or multiple FPGAs. To the best of our
knowledge, our automatically generated accelerators outperform closest
FPGA-based competitors by at least 2-4x for lantency and throughput; the
generated accelerator runs ImageNet classification at a rate of more than 3000
frames per second.
"
1329,"The Bitlet Model: Defining a Litmus Test for the Bitwise
  Processing-in-Memory Paradigm","  This paper describes an analytical modeling tool called Bitlet that can be
used, in a parameterized fashion, to understand the affinity of workloads to
processing-in-memory (PIM) as opposed to traditional computing. The tool
uncovers interesting trade-offs between operation complexity (cycles required
to perform an operation through PIM) and other key parameters, such as system
memory bandwidth, data transfer size, the extent of data alignment, and
effective memory capacity involved in PIM computations. Despite its simplicity,
the model has already proven useful. In the future, we intend to extend and
refine Bitlet to further increase its utility.
"
1330,"SMASH: Co-designing Software Compression and Hardware-Accelerated
  Indexing for Efficient Sparse Matrix Operations","  Important workloads, such as machine learning and graph analytics
applications, heavily involve sparse linear algebra operations. These
operations use sparse matrix compression as an effective means to avoid storing
zeros and performing unnecessary computation on zero elements. However,
compression techniques like Compressed Sparse Row (CSR) that are widely used
today introduce significant instruction overhead and expensive pointer-chasing
operations to discover the positions of the non-zero elements. In this paper,
we identify the discovery of the positions (i.e., indexing) of non-zero
elements as a key bottleneck in sparse matrix-based workloads, which greatly
reduces the benefits of compression. We propose SMASH, a hardware-software
cooperative mechanism that enables highly-efficient indexing and storage of
sparse matrices. The key idea of SMASH is to explicitly enable the hardware to
recognize and exploit sparsity in data. To this end, we devise a novel software
encoding based on a hierarchy of bitmaps. This encoding can be used to
efficiently compress any sparse matrix, regardless of the extent and structure
of sparsity. At the same time, the bitmap encoding can be directly interpreted
by the hardware. We design a lightweight hardware unit, the Bitmap Management
Unit (BMU), that buffers and scans the bitmap hierarchy to perform
highly-efficient indexing of sparse matrices. SMASH exposes an expressive and
rich ISA to communicate with the BMU, which enables its use in accelerating any
sparse matrix computation. We demonstrate the benefits of SMASH on four use
cases that include sparse matrix kernels and graph analytics applications.
"
1331,Sidebar: Scratchpad Based Communication Between CPUs and Accelerators,"  Hardware accelerators for neural networks have shown great promise for both
performance and power. These accelerators are at their most efficient when
optimized for a fixed functionality. But this inflexibility limits the
longevity of the hardware itself as the underlying neural network algorithms
and structures undergo improvements and changes. We propose and evaluate a
flexible design paradigm for accelerators with a close coordination with host
processors. The relatively static matrix operations are implemented in
specialized accelerators while fast-evolving functions, such as activations,
are computed on the host processor. This architecture is enabled by a low
latency shared buffer we call Sidebar. Sidebar memory is shared between the
accelerator and host, exists outside of program address space and holds
intermediate data only. We show that a generalised DMA dependent flexible
accelerator design performs poorly in both perf and energy as compared to an
equivalent fixed function accelerator. Sidebar based accelerator design
achieves near identical performance and energy to equivalent fixed function
accelerator while still providing all the flexibility of computing activations
on the host processor.
"
1332,Regional Clock Tree Generation by Abutment in Synchoros VLSI Design,"  Synchoros VLSI design style has been proposed as an alternative to standard
cell-based design. Standard cells are replaced by synchoros large grain VLSI
design objects called SiLago blocks. This new design style enables end-to-end
automation of large scale designs by abutting the SiLago blocks to eliminate
logic and physical synthesis for the end-users. A key problem in this
automation process is the generation of regional clock tree. Synchoros design
style requires that the clock tree should emerge by abutting its fragments. The
clock tree fragments are absorbed in the SiLago blocks as a one-time
engineering effort. The clock tree should not be ad-hoc, but a structured and
predictable design whose cost metrics are known. Here, we present a new clock
tree design that is compatible with the synchoros design style. The proposed
design has been verified with static timing analysis and compared against
functionally equivalent clock tree synthesised by the commercial EDA tools. The
scheme is scalable and, in principle, can generate arbitrarily complex designs.
In this paper, we show as a proof of concept that a regional clock tree can be
created by abutment. We prove that with the help of the generated clock tree,
it is possible to generate valid VLSI designs from 0.5 to ~2 million gates. The
resulting generated designs do not need a separate regional clock tree
synthesis. More critically, the synthesised design is correct by construction
and requires no further verification. In contrast, the state-of-the-art
hierarchical synthesis flow requires synthesis of the regional clock tree.
Additionally, the conventional clock tree and its design needs a verification
step because it lacks predictability. The results also demonstrate that the
capacitance, slew and the ability to balance skew of the clock tree created by
abutment is comparable to the one generated by commercial EDA tools.
"
1333,"Electromagnetic fault injection against a System-on-Chip, toward new
  micro-architectural fault models","  Electromagnetic fault injection (EMFI) is a well known technique used to
disturb the behaviour of a chip for weakening its security. These attacks are
mostly done on simple microcontrollers. On these targets, the fault effects are
relatively simple and understood. Exploiting EMFI on modern system-on-chips
(SoCs), the fast and complex chips ubiquitous today, requires to understand the
impact of such faults. In this paper, we propose an experimental setup and a
forensic process to create exploitable faults and assess their impact on the
SoC micro-architecture. On our targeted SoC (a BCM2837), the observed
behaviours are radically different to what were obtained with state-of-the-art
fault injection attacks on microcontrollers. SoC subsystems (L1 caches, L2
cache, memory management unit (MMU)) can be individually targeted leading to
new fault models. We also highlight the differences in the fault impact with
and without an operating system (OS). This shows the importance of the software
layers in the exploitation of a fault. With this work, we demonstrate that the
complexity and the speed of SoCs do not protect them against hardware fault
attacks. To conclude our work, we introduce countermeasures to protect the SoC
caches and MMU against EMFI attacks based on the disclosed faults effects.
"
1334,Generalized SAT-Attack-Resistant Logic Locking,"  Logic locking is used to protect integrated circuits (ICs) from piracy and
counterfeiting. An encrypted IC implements correct function only when the right
key is input. Many existing logic locking methods are subject to the powerful
satisfiability (SAT)-based attack. Recently, an Anti-SAT scheme has been
developed. By adopting two complementary logic blocks that consist of AND/NAND
trees, it makes the number of iterations needed by the SAT attack exponential
to the number of input bits. Nevertheless, the Anti-SAT scheme is vulnerable to
the later AppSAT and removal attacks. This paper proposes a generalized
(G-)Anti-SAT scheme. Different from the Anti-SAT scheme, a variety of
complementary or non-complementary functions can be adopted for the two blocks
in our G-Anti-SAT scheme. Pairs of functions that consist of similar number of
minterms can be chosen to resist the AppSAT and removal attacks. Meanwhile, our
design requires the same number of iterations in the SAT attack as the Anti-SAT
scheme, and hence is always resistant to the SAT attack. The Anti-SAT scheme is
just a special case of our proposed design.
"
1335,"Active Access: A Mechanism for High-Performance Distributed Data-Centric
  Computations","  Remote memory access (RMA) is an emerging high-performance programming model
that uses RDMA hardware directly. Yet, accessing remote memories cannot invoke
activities at the target which complicates implementation and limits
performance of data-centric algorithms. We propose Active Access (AA), a
mechanism that integrates well-known active messaging (AM) semantics with RMA
to enable high-performance distributed data-centric computations. AA supports a
new programming model where the user specifies handlers that are triggered when
incoming puts and gets reference designated addresses. AA is based on a set of
extensions to the Input/Output Memory Management Unit (IOMMU), a unit that
provides high-performance hardware support for remapping I/O accesses to
memory. We illustrate that AA outperforms existing AM and RMA designs,
accelerates various codes such as distributed hashtables or logging schemes,
and enables new protocols such as incremental checkpointing for RMA.We also
discuss how extended IOMMUs can support a virtualized global address space in a
distributed system that offers features known from on-node memory
virtualization. We expect that AA can enhance the design of HPC operating and
runtime systems in large computing centers.
"
1336,"MaskedNet: The First Hardware Inference Engine Aiming Power Side-Channel
  Protection","  Differential Power Analysis (DPA) has been an active area of research for the
past two decades to study the attacks for extracting secret information from
cryptographic implementations through power measurements and their defenses.
Unfortunately, the research on power side-channels have so far predominantly
focused on analyzing implementations of ciphers such as AES, DES, RSA, and
recently post-quantum cryptography primitives (e.g., lattices). Meanwhile,
machine-learning, and in particular deep-learning applications are becoming
ubiquitous with several scenarios where the Machine Learning Models are
Intellectual Properties requiring confidentiality. Expanding side-channel
analysis to Machine Learning Model extraction, however, is largely unexplored.
  This paper expands the DPA framework to neural-network classifiers. First, it
shows DPA attacks during inference to extract the secret model parameters such
as weights and biases of a neural network. Second, it proposes the
$\textit{first countermeasures}$ against these attacks by augmenting
$\textit{masking}$. The resulting design uses novel masked components such as
masked adder trees for fully-connected layers and masked Rectifier Linear Units
for activation functions. On a SAKURA-X FPGA board, experiments show that the
first-order DPA attacks on the unprotected implementation can succeed with only
200 traces and our protection respectively increases the latency and area-cost
by 2.8x and 2.3x.
"
1337,"Scalable High Performance SDN Switch Architecture on FPGA for Core
  Networks","  Due to the increasing heterogeneity in network user requirements, dynamically
varying day to day network traffic patterns and delay in-network service
deployment, there is a huge demand for scalability and flexibility in modern
networking infrastructure, which in return has paved way for the introduction
of Software Defined Networking (SDN) in core networks. In this paper, we
present an FPGA-based switch that is fully compliant with OpenFlow; the
pioneering protocol for southbound interface of SDN. The switch architecture is
completely implemented on hardware. The design consists of an OpenFlow
Southbound agent which can process OpenFlow packets at a rate of 10Gbps. The
proposed architecture speed scales up to 400Gbps while it consumes only 60% of
resources on a Xilinx Virtex-7 featuring XC7VX485T FPGA.
"
1338,Optimal Metastability-Containing Sorting via Parallel Prefix Computation,"  Friedrichs et al. (TC 2018) showed that metastability can be contained when
sorting inputs arising from time-to-digital converters, i.e., measurement
values can be correctly sorted without resolving metastability using
synchronizers first. However, this work left open whether this can be done by
small circuits. We show that this is indeed possible, by providing a circuit
that sorts Gray code inputs (possibly containing a metastable bit) and has
asymptotically optimal depth and size. Our solution utilizes the parallel
prefix computation (PPC) framework (JACM 1980). We improve this construction by
bounding its fan-out by an arbitrary $f \geq 3$, without affecting depth and
increasing circuit size by a small constant factor only. Thus, we obtain the
first PPC circuits with asymptotically optimal size, constant fan-out, and
optimal depth. To show that applying the PPC framework to the sorting task is
feasible, we prove that the latter can, despite potential metastability, be
decomposed such that the core operation is associative. We obtain
asymptotically optimal metastability-containing sorting networks. We complement
these results with simulations, independently verifying the correctness as well
as small size and delay of our circuits.
"
1339,"LSTM-Sharp: An Adaptable, Energy-Efficient Hardware Accelerator for Long
  Short-Term Memory","  The effectiveness of LSTM neural networks for popular tasks such as Automatic
Speech Recognition has fostered an increasing interest in LSTM inference
acceleration. Due to the recurrent nature and data dependencies of LSTM
computations, designing a customized architecture specifically tailored to its
computation pattern is crucial for efficiency. Since LSTMs are used for a
variety of tasks, generalizing this efficiency to diverse configurations, i.e.,
adaptiveness, is another key feature of these accelerators. In this work, we
first show the problem of low resource-utilization and adaptiveness for the
state-of-the-art LSTM implementations on GPU, FPGA and ASIC architectures. To
solve these issues, we propose an intelligent tiled-based dispatching mechanism
that efficiently handles the data dependencies and increases the adaptiveness
of LSTM computation. To do so, we propose LSTM-Sharp as a hardware accelerator,
which pipelines LSTM computation using an effective scheduling scheme to hide
most of the dependent serialization. Furthermore, LSTM-Sharp employs dynamic
reconfigurable architecture to adapt to the model's characteristics. LSTM-Sharp
achieves 1.5x, 2.86x, and 82x speedups on average over the state-of-the-art
ASIC, FPGA, and GPU implementations respectively, for different LSTM models and
resource budgets. Furthermore, we provide significant energy-reduction with
respect to the previous solutions, due to the low power dissipation of
LSTM-Sharp (383 GFLOPs/Watt).
"
1340,Using Name Confusion to Enhance Security,"  We introduce a novel concept, called Name Confusion, and demonstrate how it
can be employed to thwart multiple classes of code-reuse attacks. By building
upon Name Confusion, we derive Phantom Name System (PNS): a security protocol
that provides multiple names (addresses) to program instructions. Unlike the
conventional model of virtual memory with a one-to-one mapping between
instructions and virtual memory addresses, PNS creates N mappings for the same
instruction, and randomly switches between them at runtime. PNS achieves fast
randomization, at the granularity of basic blocks, which mitigates a class of
attacks known as (just-in-time) code-reuse.
  If an attacker uses a memory safety-related vulnerability to cause any of the
instruction addresses to be different from the one chosen during a fetch, the
exploited program will crash. We quantitatively evaluate how PNS mitigates
real-world code-reuse attacks by reducing the success probability of typical
exploits to approximately $10^{-12}$. We implement PNS and validate it by
running SPEC CPU2017 benchmark suite. We further verify its practicality by
adding it to a RISC-V core on an FPGA. Lastly, PNS is mainly designed for
resource constrained (wimpy) devices and has negligible performance overhead,
compared to commercially-available, state-of-the-art, hardware-based
protections.
"
1341,"AMOEBA: A Coarse Grained Reconfigurable Architecture for Dynamic GPU
  Scaling","  Different GPU applications exhibit varying scalability patterns with
network-on-chip (NoC), coalescing, memory and control divergence, and L1 cache
behavior. A GPU consists of several StreamingMulti-processors (SMs) that
collectively determine how shared resources are partitioned and accessed.
Recent years have seen divergent paths in SM scaling towards scale-up (fewer,
larger SMs) vs. scale-out (more, smaller SMs). However, neither scaling up nor
scaling out can meet the scalability requirement of all applications running on
a given GPU system, which inevitably results in performance degradation and
resource under-utilization for some applications. In this work, we investigate
major design parameters that influence GPU scaling. We then propose AMOEBA, a
solution to GPU scaling through reconfigurable SM cores. AMOEBA monitors and
predicts application scalability at run-time and adjusts the SM configuration
to meet program requirements. AMOEBA also enables dynamic creation of
heterogeneous SMs through independent fusing or splitting. AMOEBA is a
microarchitecture-based solution and requires no additional programming effort
or custom compiler support. Our experimental evaluations with application
programs from various benchmark suites indicate that AMOEBA is able to achieve
a maximum performance gain of 4.3x, and generates an average performance
improvement of 47% when considering all benchmarks tested.
"
1342,"Enabling Highly Efficient Capsule Networks Processing Through A
  PIM-Based Architecture Design","  In recent years, the CNNs have achieved great successes in the image
processing tasks, e.g., image recognition and object detection. Unfortunately,
traditional CNN's classification is found to be easily misled by increasingly
complex image features due to the usage of pooling operations, hence unable to
preserve accurate position and pose information of the objects. To address this
challenge, a novel neural network structure called Capsule Network has been
proposed, which introduces equivariance through capsules to significantly
enhance the learning ability for image segmentation and object detection. Due
to its requirement of performing a high volume of matrix operations, CapsNets
have been generally accelerated on modern GPU platforms that provide highly
optimized software library for common deep learning tasks. However, based on
our performance characterization on modern GPUs, CapsNets exhibit low
efficiency due to the special program and execution features of their routing
procedure, including massive unshareable intermediate variables and intensive
synchronizations, which are very difficult to optimize at software level. To
address these challenges, we propose a hybrid computing architecture design
named \textit{PIM-CapsNet}. It preserves GPU's on-chip computing capability for
accelerating CNN types of layers in CapsNet, while pipelining with an off-chip
in-memory acceleration solution that effectively tackles routing procedure's
inefficiency by leveraging the processing-in-memory capability of today's 3D
stacked memory. Using routing procedure's inherent parallellization feature,
our design enables hierarchical improvements on CapsNet inference efficiency
through minimizing data movement and maximizing parallel processing in memory.
"
1343,"MERIT: Tensor Transform for Memory-Efficient Vision Processing on
  Parallel Architectures","  Computationally intensive deep neural networks (DNNs) are well-suited to run
on GPUs, but newly developed algorithms usually require the heavily optimized
DNN routines to work efficiently, and this problem could be even more difficult
for specialized DNN architectures. In this paper, we propose a mathematical
formulation which can be useful for transferring the algorithm optimization
knowledge across computing platforms. We discover that data movement and
storage inside parallel processor architectures can be viewed as tensor
transforms across memory hierarchies, making it possible to describe many
memory optimization techniques mathematically. Such transform, which we call
Memory Efficient Ranged Inner-Product Tensor (MERIT) transform, can be applied
to not only DNN tasks but also many traditional machine learning and computer
vision computations. Moreover, the tensor transforms can be readily mapped to
existing vector processor architectures. In this paper, we demonstrate that
many popular applications can be converted to a succinct MERIT notation on
GPUs, speeding up GPU kernels up to 20 times while using only half as many code
tokens. We also use the principle of the proposed transform to design a
specialized hardware unit called MERIT-z processor. This processor can be
applied to a variety of DNN tasks as well as other computer vision tasks while
providing comparable area and power efficiency to dedicated DNN ASICs.
"
1344,"DRAB-LOCUS: An Area-Efficient AES Architecture for Hardware Accelerator
  Co-Location on FPGAs","  Advanced Encryption Standard (AES) implementations on Field Programmable Gate
Arrays (FPGA) commonly focus on maximizing throughput at the cost of utilizing
high volumes of FPGA slice logic. High resource usage limits systems' abilities
to implement other functions (such as video processing or machine learning)
that may want to share the same FPGA resources. In this paper, we address the
shared resource challenge by proposing and evaluating a low-area, but
high-throughput, AES architecture. In contrast to existing work, our
DSP/RAM-Based Low-CLB Usage (DRAB-LOCUS) architecture leverages block RAM tiles
and Digital Signal Processing (DSP) slices to implement the AES Sub Bytes, Mix
Columns, and Add Round Key sub-round transformations, reducing resource usage
by a factor of 3 over traditional approaches. To achieve area-efficiency, we
built an inner-pipelined architecture using the internal registers of block RAM
tiles and DSP slices. Our DRAB-LOCUS architecture features a 12-stage pipeline
capable of producing 7.055 Gbps of interleaved encrypted or decrypted data, and
only uses 909 Look Up tables, 593 Flip Flops, 16 block RAMs, and 18 DSP slices
in the target device.
"
1345,"Coordinated Management of DVFS and Cache Partitioning under QoS
  Constraints to Save Energy in Multi-Core Systems","  Reducing the energy expended to carry out a computational task is important.
In this work, we explore the prospects of meeting Quality-of-Service
requirements of tasks on a multi-core system while adjusting resources to
expend a minimum of energy. This paper considers, for the first time, a
QoS-driven coordinated resource management algorithm (RMA) that dynamically
adjusts the size of the per-core last-level cache partitions and the per-core
voltage-frequency settings to save energy while respecting QoS requirements of
every application in multi-programmed workloads run on multi-core systems. It
does so by doing configuration-space exploration across the spectrum of LLC
partition sizes and Dynamic Voltage Frequency Scaling (DVFS) settings at
runtime at negligible overhead. We show that the energy of 4-core and 8-core
systems can be reduced by up to 18% and 14%, respectively, compared to a
baseline with even distribution of cache resources and a fixed mid-range core
voltage-frequency setting. The energy savings can potentially reach 29% if the
QoS targets are relaxed to 40% longer execution time.
"
1346,"Coordinated Management of Processor Configuration and Cache Partitioning
  to Optimize Energy under QoS Constraints","  An effective way to improve energy efficiency is to throttle hardware
resources to meet a certain performance target, specified as a QoS constraint,
associated with all applications running on a multicore system.
  Prior art has proposed resource management (RM) frameworks in which the share
of the last-level cache (LLC) assigned to each processor and the
voltage-frequency (VF) setting for each processor is managed in a coordinated
fashion to reduce energy. A drawback of such a scheme is that, while one core
gives up LLC resources for another core, the performance drop must be
compensated by a higher VF setting which leads to a quadratic increase in
energy consumption. By allowing each core to be adapted to exploit instruction
and memory-level parallelism (ILP/MLP), substantially higher energy savings are
enabled.
  This paper proposes a coordinated RM for LLC partitioning, processor
adaptation, and per-core VF scaling. A first contribution is a systematic study
of the resource trade-offs enabled when trading between the three classes of
resources in a coordinated fashion. A second contribution is a new RM framework
that utilizes these trade-offs to save more energy. Finally, a challenge to
accurately model the impact of resource throttling on performance is to predict
the amount of MLP with high accuracy. To this end, the paper contributes with a
mechanism that estimates the effect of MLP over different processor
configurations and LLC allocations. Overall, we show that up to 18% of energy,
and on average 10%, can be saved using the proposed scheme.
"
1347,"The Deep Learning Revolution and Its Implications for Computer
  Architecture and Chip Design","  The past decade has seen a remarkable series of advances in machine learning,
and in particular deep learning approaches based on artificial neural networks,
to improve our abilities to build more accurate systems across a broad range of
areas, including computer vision, speech recognition, language translation, and
natural language understanding tasks. This paper is a companion paper to a
keynote talk at the 2020 International Solid-State Circuits Conference (ISSCC)
discussing some of the advances in machine learning, and their implications on
the kinds of computational devices we need to build, especially in the
post-Moore's Law-era. It also discusses some of the ways that machine learning
may also be able to help with some aspects of the circuit design process.
Finally, it provides a sketch of at least one interesting direction towards
much larger-scale multi-task models that are sparsely activated and employ much
more dynamic, example- and task-based routing than the machine learning models
of today.
"
1348,Communication Lower Bound in Convolution Accelerators,"  In current convolutional neural network (CNN) accelerators, communication
(i.e., memory access) dominates the energy consumption. This work provides
comprehensive analysis and methodologies to minimize the communication for CNN
accelerators. For the off-chip communication, we derive the theoretical lower
bound for any convolutional layer and propose a dataflow to reach the lower
bound. This fundamental problem has never been solved by prior studies. The
on-chip communication is minimized based on an elaborate workload and storage
mapping scheme. We in addition design a communication-optimal CNN accelerator
architecture. Evaluations based on the 65nm technology demonstrate that the
proposed architecture nearly reaches the theoretical minimum communication in a
three-level memory hierarchy and it is computation dominant. The gap between
the energy efficiency of our accelerator and the theoretical best value is only
37-87%.
"
1349,A Brief Review on Some Architectures Providing Support for DIFT,"  Dynamic Information Flow Tracking (DIFT) is a technique to track potential
security vulnerabilities in software and hardware systems at run time. The last
fifteen years have seen a lot of research work on DIFT, including both
hardware-based and software-based implementations for different types of
processor architectures. This survey briefly reviews some hardware
architectures that provide DIFT support. Starting from introducing different
approaches for hardware based DIFT, this survey focuses on integrated/in-core
architectures. Protection schemes, including tagging system, tag propagation,
and tag checking for each architecture will be discussed. The survey is
organized in such a way that it illustrates the evolution of integrated DIFT
architectures, each architecture tries to improve the precious proposed
architectures generality/versatility weaknesses. However, improving security
while providing generality and versatility is kind of trade-offs. This survey
compares the architectures from different aspects to show the trade-offs
clearer.
"
1350,"NeuMMU: Architectural Support for Efficient Address Translations in
  Neural Processing Units","  To satisfy the compute and memory demands of deep neural networks, neural
processing units (NPUs) are widely being utilized for accelerating deep
learning algorithms. Similar to how GPUs have evolved from a slave device into
a mainstream processor architecture, it is likely that NPUs will become first
class citizens in this fast-evolving heterogeneous architecture space. This
paper makes a case for enabling address translation in NPUs to decouple the
virtual and physical memory address space. Through a careful data-driven
application characterization study, we root-cause several limitations of prior
GPU-centric address translation schemes and propose a memory management unit
(MMU) that is tailored for NPUs. Compared to an oracular MMU design point, our
proposal incurs only an average 0.06% performance overhead.
"
1351,FPGA Energy Efficiency by Leveraging Thermal Margin,"  Cutting edge FPGAs are not energy efficient as conventionally presumed to be,
and therefore, aggressive power-saving techniques have become imperative. The
clock rate of an FPGA-mapped design is set based on worst-case conditions to
ensure reliable operation under all circumstances. This usually leaves a
considerable timing margin that can be exploited to reduce power consumption by
scaling voltage without lowering clock frequency. There are hurdles for such
opportunistic voltage scaling in FPGAs because (a) critical paths change with
designs, making timing evaluation difficult as voltage changes, (b) each FPGA
resource has particular power-delay trade-off with voltage, (c) data corruption
of configuration cells and memory blocks further hampers voltage scaling. In
this paper, we propose a systematical approach to leverage the available
thermal headroom of FPGA-mapped designs for power and energy improvement. By
comprehensively analyzing the timing and power consumption of FPGA building
blocks under varying temperatures and voltages, we propose a thermal-aware
voltage scaling flow that effectively utilizes the thermal margin to reduce
power consumption without degrading performance. We show the proposed flow can
be employed for energy optimization as well, whereby power consumption and
delay are compromised to accomplish the tasks with minimum energy. Lastly, we
propose a simulation framework to be able to examine the efficiency of the
proposed method for other applications that are inherently tolerant to a
certain amount of error, granting further power saving opportunity.
Experimental results over a set of industrial benchmarks indicate up to 36%
power reduction with the same performance, and 66% total energy saving when
energy is the optimization target.
"
1352,AddNet: Deep Neural Networks Using FPGA-Optimized Multipliers,"  Low-precision arithmetic operations to accelerate deep-learning applications
on field-programmable gate arrays (FPGAs) have been studied extensively,
because they offer the potential to save silicon area or increase throughput.
However, these benefits come at the cost of a decrease in accuracy. In this
article, we demonstrate that reconfigurable constant coefficient multipliers
(RCCMs) offer a better alternative for saving the silicon area than utilizing
low-precision arithmetic. RCCMs multiply input values by a restricted choice of
coefficients using only adders, subtractors, bit shifts, and multiplexers
(MUXes), meaning that they can be heavily optimized for FPGAs. We propose a
family of RCCMs tailored to FPGA logic elements to ensure their efficient
utilization. To minimize information loss from quantization, we then develop
novel training techniques that map the possible coefficient representations of
the RCCMs to neural network weight parameter distributions. This enables the
usage of the RCCMs in hardware, while maintaining high accuracy. We demonstrate
the benefits of these techniques using AlexNet, ResNet-18, and ResNet-50
networks. The resulting implementations achieve up to 50% resource savings over
traditional 8-bit quantized networks, translating to significant speedups and
power savings. Our RCCM with the lowest resource requirements exceeds 6-bit
fixed point accuracy, while all other implementations with RCCMs achieve at
least similar accuracy to an 8-bit uniformly quantized design, while achieving
significant resource savings.
"
1353,"Stream Semantic Registers: A Lightweight RISC-V ISA Extension Achieving
  Full Compute Utilization in Single-Issue Cores","  Single-issue processor cores are very energy efficient but suffer from the
von Neumann bottleneck, in that they must explicitly fetch and issue the
loads/storse necessary to feed their ALU/FPU. Each instruction spent on moving
data is a cycle not spent on computation, limiting ALU/FPU utilization to 33%
on reductions. We propose ""Stream Semantic Registers"" to boost utilization and
increase energy efficiency. SSR is a lightweight, non-invasive RISC-V ISA
extension which implicitly encodes memory accesses as register reads/writes,
eliminating a large number of loads/stores. We implement the proposed extension
in the RTL of an existing multi-core cluster and synthesize the design for a
modern 22nm technology. Our extension provides a significant, 2x to 5x,
architectural speedup across different kernels at a small 11% increase in core
area. Sequential code runs 3x faster on a single core, and 3x fewer cores are
needed in a cluster to achieve the same performance. The utilization increase
to almost 100% in leads to a 2x energy efficiency improvement in a multi-core
cluster. The extension reduces instruction fetches by up to 3.5x and
instruction cache power consumption by up to 5.6x. Compilers can automatically
map loop nests to SSRs, making the changes transparent to the programmer.
"
1354,"MuonTrap: Preventing Cross-Domain Spectre-Like Attacks by Capturing
  Speculative State","  The disclosure of the Spectre speculative-execution attacks in January 2018
has left a severe vulnerability that systems are still struggling with how to
patch. The solutions that currently exist tend to have incomplete coverage,
perform badly, or have highly undesirable edge cases that cause application
domains to break.
  MuonTrap allows processors to continue to speculate, avoiding significant
reductions in performance, without impacting security. We instead prevent the
propagation of any state based on speculative execution, by placing the results
of speculative cache accesses into a small, fast L0 filter cache, that is
non-inclusive, non-exclusive with the rest of the cache hierarchy. This
isolates all parts of the system that can't be quickly cleared on any change in
threat domain.
  MuonTrap uses these speculative filter caches, which are cleared on context
and protection-domain switches, along with a series of extensions to the cache
coherence protocol and prefetcher. This renders systems immune to cross-domain
information leakage via Spectre and a host of similar attacks based on
speculative execution, with low performance impact and few changes to the CPU
design.
"
1355,"Gemmini: An Agile Systolic Array Generator Enabling Systematic
  Evaluations of Deep-Learning Architectures","  Advances in deep learning and neural networks have resulted in the rapid
development of hardware accelerators that support them. A large majority of
ASIC accelerators, however, target a single hardware design point to accelerate
the main computational kernels of deep neural networks such as convolutions or
matrix multiplication. On the other hand, the spectrum of use-cases for neural
network accelerators, ranging from edge devices to cloud, presents a prime
opportunity for agile hardware design and generator methodologies. We present
Gemmini -- an open source and agile systolic array generator enabling
systematic evaluations of deep-learning architectures. Gemmini generates a
custom ASIC accelerator for matrix multiplication based on a systolic array
architecture, complete with additional functions for neural network inference.
Gemmini runs with the RISC-V ISA, and is integrated with the Rocket Chip
System-on-Chip generator ecosystem, including Rocket in-order cores and BOOM
out-of-order cores. Through an elaborate design space exploration case study,
this work demonstrates the selection processes of various parameters for the
use-case of inference on edge devices. Selected design points achieve two to
three orders of magnitude speedup in deep neural network inference compared to
the baseline execution on a host processor. Gemmini-generated accelerators were
used in the fabrication of test systems-on-chip in TSMC 16nm and Intel 22FFL
process technologies.
"
1356,Arsenal of Hardware Prefetchers,"  Hardware prefetching is one of the latency tolerance optimization techniques
that tolerate costly DRAM accesses. Though hardware prefetching is one of the
fundamental mechanisms prevalent on most of the commercial machines, there is
no prefetching technique that works well across all the access patterns and
different types of workloads. Through this paper, we propose Arsenal, a
prefetching framework which allows the advantages provided by different data
prefetchers to be combined, by dynamically selecting the best-suited prefetcher
for the current workload. Thus effectively improving the versatility of the
prefetching system. It bases on the classic Sandbox prefetcher that dynamically
adapts and utilizes multiple offsets for sequential prefetchers. We take it to
the next step by switching between prefetchers like Multi look Ahead Offset
Prefetching and Timing SKID Prefetcher on the run. Arsenal utilizes a
space-efficient pooling filter, Bloom filters, that keeps track of useful
prefetches of each of these component prefetchers and thus helps to maintain a
score for each of the component prefetchers. This approach is shown to provide
better speedup than anyone prefetcher alone. Arsenal provides a performance
improvement of 44.29% on the single-core mixes and 19.5% for some of the
selected 25 representative multi-core mixes.
"
1357,"Shenjing: A low power reconfigurable neuromorphic accelerator with
  partial-sum and spike networks-on-chip","  The next wave of on-device AI will likely require energy-efficient deep
neural networks. Brain-inspired spiking neural networks (SNN) has been
identified to be a promising candidate. Doing away with the need for
multipliers significantly reduces energy. For on-device applications, besides
computation, communication also incurs a significant amount of energy and time.
In this paper, we propose Shenjing, a configurable SNN architecture which fully
exposes all on-chip communications to software, enabling software mapping of
SNN models with high accuracy at low power. Unlike prior SNN architectures like
TrueNorth, Shenjing does not require any model modification and retraining for
the mapping. We show that conventional artificial neural networks (ANN) such as
multilayer perceptron, convolutional neural networks, as well as the latest
residual neural networks can be mapped successfully onto Shenjing, realizing
ANNs with SNN's energy efficiency. For the MNIST inference problem using a
multilayer perceptron, we were able to achieve an accuracy of 96% while
consuming just 1.26mW using 10 Shenjing cores.
"
1358,"System Performance with varying L1 Instruction and Data Cache Sizes: An
  Empirical Analysis","  In this project, we investigate the fluctuations in performance caused by
changing the Instruction (I-cache) size and the Data (D-cache) size in the L1
cache. We employ the Gem5 framework to simulate a system with varying
specifications on a single host machine. We utilize the FreqMine benchmark
available under the PARSEC suite as the workload program to benchmark our
simulated system. The Out-order CPU (O3) with Ruby memory model was simulated
in a Full-System X86 environment with Linux OS. The chosen metrics deal with
Hit Rate, Misses, Memory Latency, Instruction Rate, and Bus Traffic within the
system. Performance observed by varying L1 size within a certain range of
values was used to compute Confidence Interval based statistics for relevant
metrics. Our expectations, corresponding experimental observations, and
discrepancies are also discussed in this report.
"
1359,"3D IC optimal layout design. A parallel and distributed topological
  approach","  The task of 3D ICs layout design involves the assembly of millions of
components taking into account many different requirements and constraints such
as topological, wiring or manufacturability ones. It is a NP-hard problem that
requires new non-deterministic and heuristic algorithms. Considering the time
complexity, the commonly applied Fiduccia-Mattheyses partitioning algorithm is
superior to any other local search method. Nevertheless, it can often miss to
reach a quasi-optimal solution in 3D spaces. The presented approach uses an
original 3D layout graph partitioning heuristics implemented with use of the
extremal optimization method. The goal is to minimize the total wire-length in
the chip. In order to improve the time complexity a parallel and distributed
Java implementation is applied. Inside one Java Virtual Machine separate
optimization algorithms are executed by independent threads. The work may also
be shared among different machines by means of The Java Remote Method
Invocation system.
"
1360,"Neural Network-Inspired Analog-to-Digital Conversion to Achieve
  Super-Resolution with Low-Precision RRAM Devices","  Recent works propose neural network- (NN-) inspired analog-to-digital
converters (NNADCs) and demonstrate their great potentials in many emerging
applications. These NNADCs often rely on resistive random-access memory (RRAM)
devices to realize the NN operations and require high-precision RRAM cells
(6~12-bit) to achieve a moderate quantization resolution (4~8-bit). Such
optimistic assumption of RRAM resolution, however, is not supported by
fabrication data of RRAM arrays in large-scale production process. In this
paper, we propose an NN-inspired super-resolution ADC based on low-precision
RRAM devices by taking the advantage of a co-design methodology that combines a
pipelined hardware architecture with a custom NN training framework. Results
obtained from SPICE simulations demonstrate that our method leads to robust
design of a 14-bit super-resolution ADC using 3-bit RRAM devices with improved
power and speed performance and competitive figure-of-merits (FoMs). In
addition to the linear uniform quantization, the proposed ADC can also support
configurable high-resolution nonlinear quantization with high conversion speed
and low conversion energy, enabling future intelligent analog-to-information
interfaces for near-sensor analytics and processing.
"
1361,Hardware Versus Software Fault Injection of Modern Undervolted SRAMs,"  To improve power efficiency, researchers are experimenting with dynamically
adjusting the supply voltage of systems below the nominal operating points.
However, production systems are typically not allowed to function on voltage
settings that is below the reliable limit. Consequently, existing software
fault tolerance studies are based on fault models, which inject faults on
random fault locations using fault injection techniques. In this work we study
whether random fault injection is accurate to simulate the behavior of
undervolted SRAMs.
  Our study extends the Gem5 simulator to support fault injection on the caches
of the simulated system. The fault injection framework uses fault maps, which
describe the faulty bits of SRAMs, as inputs. To compare random fault injection
and hardware guided fault injection, we use two types of fault maps. The first
type of maps are created through undervolting real SRAMs and observing the
location of the erroneous bits, whereas the second type of maps are created by
corrupting random bits of the SRAMs. During our study we corrupt the L1-Dcache
of the simulated system and we monitor the behavior of the two types of fault
maps on the resiliency of six benchmarks. The difference among the resiliency
of a benchmark when tested with the different fault maps can be up to 24%.
"
1362,"Spin-Orbit-Torque-based Devices, Circuits and Architectures","  Spintronics, the use of spin of an electron instead of its charge, has
received huge attention from research communities for different applications
including memory, interconnects, logic implementation, neuromorphic computing,
and many other applications. Here, in this paper, we review the works within
spintronics, more specifically on spin-orbit torque (SOT) within different
research groups. We also provide researchers an insight into the future
potentials of the SOT-based designs. This comprehensive review paper covers
different aspects of SOT-based design from device and circuit to architecture
level as well as more ambitious and futuristic applications of such technology.
"
1363,"Understanding the Impact of On-chip Communication on DNN Accelerator
  Performance","  Deep Neural Networks have flourished at an unprecedented pace in recent
years. They have achieved outstanding accuracy in fields such as computer
vision, natural language processing, medicine or economics. Specifically,
Convolutional Neural Networks (CNN) are particularly suited to object
recognition or identification tasks. This, however, comes at a high
computational cost, prompting the use of specialized GPU architectures or even
ASICs to achieve high speeds and energy efficiency. ASIC accelerators
streamline the execution of certain dataflows amenable to CNN computation that
imply the constant movement of large amounts of data, thereby turning on-chip
communication into a critical function within the accelerator. This paper
studies the communication flows within CNN inference accelerators of edge
devices, with the aim to justify current and future decisions in the design of
the on-chip networks that interconnect their processing elements. Leveraging
this analysis, we then qualitatively discuss the potential impact of
introducing the novel paradigm of wireless on-chip network in this context.
"
1364,SIFO: Secure Computational Infrastructure using FPGA Overlays,"  Secure Function Evaluation (SFE) has received recent attention due to the
massive collection and mining of personal data, but remains impractical due to
its large computational cost. Garbled Circuits (GC) is a protocol for
implementing SFE which can evaluate any function that can be expressed as a
Boolean circuit and obtain the result while keeping each party's input private.
Recent advances have led to a surge of garbled circuit implementations in
software for a variety of different tasks. However, these implementations are
inefficient and therefore GC is not widely used, especially for large problems.
This research investigates, implements and evaluates secure computation
generation using a heterogeneous computing platform featuring FPGAs. We have
designed and implemented SIFO: Secure computational Infrastructure using FPGA
Overlays. Unlike traditional FPGA design, a coarse grained overlay architecture
is adopted which supports mapping SFE problems that are too large to map to a
single FPGA. Host tools provided include SFE problem generator, parser and
automatic host code generation. Our design allows re-purposing an FPGA to
evaluate different SFE tasks without the need for reprogramming, and fully
explores the parallelism for any GC problem. Our system demonstrates an order
of magnitude speedup compared with an existing software platform.
"
1365,Dissecting the Graphcore IPU Architecture via Microbenchmarking,"  This report focuses on the architecture and performance of the Intelligence
Processing Unit (IPU), a novel, massively parallel platform recently introduced
by Graphcore and aimed at Artificial Intelligence/Machine Learning (AI/ML)
workloads. We dissect the IPU's performance behavior using microbenchmarks that
we crafted for the purpose. We study the IPU's memory organization and
performance. We study the latency and bandwidth that the on-chip and off-chip
interconnects offer, both in point-to-point transfers and in a spectrum of
collective operations, under diverse loads. We evaluate the IPU's compute power
over matrix multiplication, convolution, and AI/ML primitives. We discuss
actual performance in comparison with its theoretical limits. Our findings
reveal how the IPU's architectural design affects its performance. Moreover,
they offer simple mental models to predict an application's performance on the
IPU, on the basis of the computation and communication steps it involves. This
report is the natural extension to a novel architecture of a continuing effort
of ours that focuses on the microbenchmark-based discovery of massively
parallel architectures.
"
1366,"Ratatoskr: An open-source framework for in-depth power, performance and
  area analysis in 3D NoCs","  We introduce ratatoskr, an open-source framework for in-depth power,
performance and area (PPA) analysis in NoCs for 3D-integrated and heterogeneous
System-on-Chips (SoCs). It covers all layers of abstraction by providing a NoC
hardware implementation on RT level, a NoC simulator on cycle-accurate level
and an application model on transaction level. By this comprehensive approach,
ratatoskr can provide the following specific PPA analyses: Dynamic power of
links can be measured within 2.4% accuracy of bit-level simulations while
maintaining cycle-accurate simulation speed. Router power is determined from RT
level synthesis combined with cycle-accurate simulations. The performance of
the whole NoC can be measured both via cycle-accurate and RT level simulations.
The performance of individual routers is obtained from RT level including
gate-level verification. The NoC area is calculated from RT level. Despite
these manifold features, ratatoskr offers easy two-step user interaction:
First, a single point-of-entry that allows to set design parameters and second,
PPA reports are generated automatically. For both the input and the output,
different levels of abstraction can be chosen for high-level rapid network
analysis or low-level improvement of architectural details. The synthesize NoC
model reduces up to 32% total router power and 3% router area in comparison to
a conventional standard router. As a forward-thinking and unique feature not
found in other NoC PPA-measurement tools, ratatoskr supports heterogeneous 3D
integration that is one of the most promising integration paradigms for
upcoming SoCs. Thereby, ratatoskr lies the groundwork to design their
communication architectures.
"
1367,"An Energy-Efficient Heterogeneous Memory Architecture for Future Dark
  Silicon Embedded Chip-Multiprocessors","  Main memories play an important role in overall energy consumption of
embedded systems. Using conventional memory technologies in future designs in
nanoscale era causes a drastic increase in leakage power consumption and
temperature-related problems. Emerging non-volatile memory (NVM) technologies
offer many desirable characteristics such as near-zero leakage power, high
density and non-volatility. They can significantly mitigate the issue of memory
leakage power in future embedded chip-multiprocessor (eCMP) systems. However,
they suffer from challenges such as limited write endurance and high write
energy consumption which restrict them for adoption in modern memory systems.
In this article, we present a convex optimization model to design a 3D stacked
hybrid memory architecture in order to minimize the future embedded systems
energy consumption in the dark silicon era. This proposed approach satisfies
endurance constraint in order to design a reliable memory system. Our convex
model optimizes numbers and placement of eDRAM and STT-RAM memory banks on the
memory layer to exploit the advantages of both technologies in future eCMPs.
Energy consumption, the main challenge in the dark silicon era, is represented
as a major target in this work and it is minimized by the detailed optimization
model in order to design a dark silicon aware 3D Chip-Multiprocessor.
Experimental results show that in comparison with the Baseline memory design,
the proposed architecture improves the energy consumption and performance of
the 3D CMP on average about 61.33 and 9 percent respectively.
"
1368,Adaptive Multi-bit SRAM Topology Based Analog PUF,"  Physically Unclonable Functions (PUFs) are lightweight cryptographic
primitives for generating unique signatures from minuscule manufacturing
variations. In this work, we present lightweight, area efficient and low power
adaptive multi-bit SRAM topology based Current Mirror Array (CMA) analog PUF
design for securing the sensor nodes, authentication and key generation. The
proposed Strong PUF increases the complexity of the machine learning attacks
thus making it difficult for the adversary. The design is based on scl180
library.
"
1369,"SSR: A Stall Scheme Reducing Bubbles in Load-Use Hazard of RISC-V
  Pipeline","  Modern processors usually adopt pipeline structure and often load data from
memory. At that point, the load-use hazard will inevitably occur, which usually
stall the pipeline and reduce performance. This paper introduces and compares
two schemes to solve load-use hazard. One is the traditional scheme that detect
hazard between ID stage and EXE stage, which stalls the pipeline and insert
bubbles between the two instructions. In the scheme we proposed, we add a
simple bypass unit between EXE and MEM stage that disables the stall of
load-use hazard caused by the traditional scheme, which can reduce the bubble
between the two instructions. It's quite a considerable benefit in eliminating
bubbles especially in the long pipeline or programs of plenty load
instructions. The scheme was implemented in the open source RISC-V SoC
generator Rocket-chip and synthesized in SMIC 130-nm technology. The results
show that the performance of the latter scheme is increased by 6.9% in the
Dhrystone benchmark with the reasonable cost of area and power.
"
1370,"PANTHER: A Programmable Architecture for Neural Network Training
  Harnessing Energy-efficient ReRAM","  The wide adoption of deep neural networks has been accompanied by
ever-increasing energy and performance demands due to the expensive nature of
training them. Numerous special-purpose architectures have been proposed to
accelerate training: both digital and hybrid digital-analog using resistive RAM
(ReRAM) crossbars. ReRAM-based accelerators have demonstrated the effectiveness
of ReRAM crossbars at performing matrix-vector multiplication operations that
are prevalent in training. However, they still suffer from inefficiency due to
the use of serial reads and writes for performing the weight gradient and
update step. A few works have demonstrated the possibility of performing outer
products in crossbars, which can be used to realize the weight gradient and
update step without the use of serial reads and writes. However, these works
have been limited to low precision operations which are not sufficient for
typical training workloads. Moreover, they have been confined to a limited set
of training algorithms for fully-connected layers only. To address these
limitations, we propose a bit-slicing technique for enhancing the precision of
ReRAM-based outer products, which is substantially different from bit-slicing
for matrix-vector multiplication only. We incorporate this technique into a
crossbar architecture with three variants catered to different training
algorithms. To evaluate our design on different types of layers in neural
networks (fully-connected, convolutional, etc.) and training algorithms, we
develop PANTHER, an ISA-programmable training accelerator with compiler
support. Our evaluation shows that PANTHER achieves up to $8.02\times$,
$54.21\times$, and $103\times$ energy reductions as well as $7.16\times$,
$4.02\times$, and $16\times$ execution time reductions compared to digital
accelerators, ReRAM-based accelerators, and GPUs, respectively.
"
1371,JackHammer: Efficient Rowhammer on Heterogeneous FPGA-CPU Platforms,"  After years of development, FPGAs are finally making an appearance on
multi-tenant cloud servers. These heterogeneous FPGA-CPU architectures break
common assumptions about isolation and security boundaries. Since the FPGA and
CPU architectures share hardware resources, a new class of vulnerabilities
requires us to reassess the security and dependability of these platforms.
  In this work, we analyze the memory and cache subsystem and study Rowhammer
and cache attacks enabled on two proposed heterogeneous FPGA-CPU platforms by
Intel: the Arria 10 GX with an integrated FPGA-CPU platform, and the Arria 10
GX PAC expansion card which connects the FPGA to the CPU via the PCIe
interface. We show that while Intel PACs currently are immune to cache attacks
from FPGA to CPU, the integrated platform is indeed vulnerable to Prime and
Probe style attacks from the FPGA to the CPU's last level cache. Further, we
demonstrate JackHammer, a novel and efficient Rowhammer from the FPGA to the
host's main memory. Our results indicate that a malicious FPGA can perform
twice as fast as a typical Rowhammer attack from the CPU on the same system and
causes around four times as many bit flips as the CPU attack. We demonstrate
the efficacy of JackHammer from the FPGA through a realistic fault attack on
the WolfSSL RSA signing implementation that reliably causes a fault after an
average of fifty-eight RSA signatures, 25% faster than a CPU rowhammer attack.
In some scenarios our JackHammer attack produces faulty signatures more than
three times more often and almost three times faster than a conventional CPU
rowhammer attack.
"
1372,MTJ-Based Hardware Synapse Design for Quantized Deep Neural Networks,"  Quantized neural networks (QNNs) are being actively researched as a solution
for the computational complexity and memory intensity of deep neural networks.
This has sparked efforts to develop algorithms that support both inference and
training with quantized weight and activation values without sacrificing
accuracy. A recent example is the GXNOR framework for stochastic training of
ternary and binary neural networks. In this paper, we introduce a novel
hardware synapse circuit that uses magnetic tunnel junction (MTJ) devices to
support the GXNOR training. Our solution enables processing near memory (PNM)
of QNNs, therefore can further reduce the data movements from and into the
memory. We simulated MTJ-based stochastic training of a TNN over the MNIST and
SVHN datasets and achieved an accuracy of 98.61% and 93.99%, respectively.
"
1373,"RecNMP: Accelerating Personalized Recommendation with Near-Memory
  Processing","  Personalized recommendation systems leverage deep learning models and account
for the majority of data center AI cycles. Their performance is dominated by
memory-bound sparse embedding operations with unique irregular memory access
patterns that pose a fundamental challenge to accelerate. This paper proposes a
lightweight, commodity DRAM compliant, near-memory processing solution to
accelerate personalized recommendation inference. The in-depth characterization
of production-grade recommendation models shows that embedding operations with
high model-, operator- and data-level parallelism lead to memory bandwidth
saturation, limiting recommendation inference performance. We propose RecNMP
which provides a scalable solution to improve system throughput, supporting a
broad range of sparse embedding models. RecNMP is specifically tailored to
production environments with heavy co-location of operators on a single server.
Several hardware/software co-optimization techniques such as memory-side
caching, table-aware packet scheduling, and hot entry profiling are studied,
resulting in up to 9.8x memory latency speedup over a highly-optimized
baseline. Overall, RecNMP offers 4.2x throughput improvement and 45.8% memory
energy savings.
"
1374,"TrappeD: DRAM Trojan Designs for Information Leakage and Fault Injection
  Attacks","  In this paper, we investigate the advanced circuit features such as wordline-
(WL) underdrive (prevents retention failure) and overdrive (assists write)
employed in the peripherals of Dynamic RAM (DRAM) memories from a security
perspective. In an ideal environment, these features ensure fast and reliable
read and write operations. However, an adversary can re-purpose them by
inserting Trojans to deliver malicious payloads such as fault injections,
Denial-of-Service (DoS), and information leakage attacks when activated by the
adversary. Simulation results indicate that wordline voltage can be increased
to cause retention failure and thereby launch a DoS attack in DRAM memory.
Furthermore, two wordlines or bitlines can be shorted to leak information or
inject faults by exploiting the DRAM's refresh operation. We demonstrate an
information leakage system exploit by implementing TrappeD on RocketChip SoC.
"
1375,Stochastic Rounding: Algorithms and Hardware Accelerator,"  Algorithms and a hardware accelerator for performing stochastic rounding (SR)
are presented. The main goal is to augment the ARM M4F based multi-core
processor SpiNNaker2 with a more flexible rounding functionality than is
available in the ARM processor itself. The motivation of adding such an
accelerator in hardware is based on our previous results showing improvements
in numerical accuracy of ODE solvers in fixed-point arithmetic with SR,
compared to standard round to nearest or bit truncation rounding modes.
Furthermore, performing SR purely in software can be expensive, due to
requirement of a pseudorandom number generator (PRNG), multiple masking and
shifting instructions, and an addition operation. Also, saturation of the
rounded values is included, since rounding is usually followed by saturation,
which is especially important in fixed-point arithmetic due to a narrow dynamic
range of representable values. The main intended use of the accelerator is to
round fixed-point multiplier outputs, which are returned unrounded by the ARM
processor in a wider fixed-point format than the arguments.
"
1376,Low-cost Stochastic Number Generators for Stochastic Computing,"  Stochastic unary computing provides low-area circuits. However, the required
area consuming stochastic number generators (SNGs) in these circuits can
diminish their overall gain in area, particularly if several SNGs are required.
We propose area-efficient SNGs by sharing the permuted output of one linear
feedback shift register (LFSR) among several SNGs. With no hardware overhead,
the proposed architecture generates stochastic bit streams with minimum
stochastic computing correlation (SCC). Compared to the circular shifting
approach presented in prior work, our approach produces stochastic bit streams
with 67% less average SCC when a 10-bit LFSR is shared between two SNGs. To
generalize our approach, we propose an algorithm to find a set of m
permutations (n>m>2) with minimum pairwise SCC, for an n-bit LFSR. The search
space for finding permutations with exact minimum SCC grows rapidly when n
increases and it is intractable to perform a search algorithm using accurately
calculated pairwise SCC values, for n>9. We propose a similarity function that
can be used in the proposed search algorithm to quickly find a set of
permutations with SCC values close to the minimum one. We evaluated our
approach for several applications. The results show that, compared to prior
work, it achieves lower MSE with the same (or even lower) area. Additionally,
based on simulation results, we show that replacing the comparator component of
an SNG circuit with a weighted binary generator can reduce SCC.
"
1377,Optimizing the Write Fidelity of MRAMs,"  Magnetic random-access memory (MRAM) is a promising memory technology due to
its high density, non-volatility, and high endurance. However, achieving high
memory fidelity incurs significant write-energy costs, which should be reduced
for large-scale deployment of MRAMs. In this paper, we formulate an
optimization problem for maximizing the memory fidelity given energy
constraints, and propose a biconvex optimization approach to solve it. The
basic idea is to allocate non-uniform write pulses depending on the importance
of each bit position. The fidelity measure we consider is minimum mean squared
error (MSE), for which we propose an iterative water-filling algorithm.
Although the iterative algorithm does not guarantee global optimality, we can
choose a proper starting point that decreases the MSE exponentially and
guarantees fast convergence. For an 8-bit accessed word, the proposed algorithm
reduces the MSE by a factor of 21.
"
1378,"SERAD: Soft Error Resilient Asynchronous Design using a Bundled Data
  Protocol","  The risk of soft errors due to radiation continues to be a significant
challenge for engineers trying to build systems that can handle harsh
environments. Building systems that are Radiation Hardened by Design (RHBD) is
the preferred approach, but existing techniques are expensive in terms of
performance, power, and/or area. This paper introduces a novel soft-error
resilient asynchronous bundled-data design template, SERAD, which uses a
combination of temporal and spatial redundancy to mitigate Single Event
Transients (SETs) and upsets (SEUs). SERAD uses Error Detecting Logic (EDL) to
detect SETs at the inputs of sequential elements and correct them via
re-sampling. Because SERAD only pays the delay penalty in the presence of an
SET, which rarely occurs, its average performance is comparable to the baseline
synchronous design. We tested the SERAD design using a combination of Spice and
Verilog simulations and evaluated its impact on area, frequency, and power on
an open-core MIPS-like processor using a NCSU 45nm cell library. Our
post-synthesis results show that the SERAD design consumes less than half of
the area of the Triple Modular Redundancy (TMR), exhibits significantly less
performance degradation than Glitch Filtering (GF), and consumes no more total
power than the baseline unhardened design.
"
1379,"CHIPKIT: An agile, reusable open-source framework for rapid test chip
  development","  The current trend for domain-specific architectures (DSAs) has led to renewed
interest in research test chips to demonstrate new specialized hardware.
Tape-outs also offer huge pedagogical value garnered from real hands-on
exposure to the whole system stack. However, successful tape-outs demand
hard-earned experience, and the design process is time consuming and fraught
with challenges. Therefore, custom chips have remained the preserve of a small
number of research groups, typically focused on circuit design research. This
paper describes the CHIPKIT framework. We describe a reusable SoC subsystem
which provides basic IO, an on-chip programmable host, memory and peripherals.
This subsystem can be readily extended with new IP blocks to generate custom
test chips. We also present an agile RTL development flow, including a code
generation tool calledVGEN. Finally, we outline best practices for full-chip
validation across the entire design cycle.
"
1380,Hardware Implementation of Neural Self-Interference Cancellation,"  In-band full-duplex systems can transmit and receive information
simultaneously on the same frequency band. However, due to the strong
self-interference caused by the transmitter to its own receiver, the use of
non-linear digital self-interference cancellation is essential. In this work,
we describe a hardware architecture for a neural network-based non-linear
self-interference (SI) canceller and we compare it with our own hardware
implementation of a conventional polynomial based SI canceller. In particular,
we present implementation results for a shallow and a deep neural network SI
canceller as well as for a polynomial SI canceller. Our results show that the
deep neural network canceller achieves a hardware efficiency of up to $312.8$
Msamples/s/mm$^2$ and an energy efficiency of up to $0.9$ nJ/sample, which is
$2.1\times$ and $2\times$ better than the polynomial SI canceller,
respectively. These results show that NN-based methods applied to
communications are not only useful from a performance perspective, but can also
be a very effective means to reduce the implementation complexity.
"
1381,"Processing Distribution and Architecture Tradeoff for Large Intelligent
  Surface Implementation","  The Large Intelligent Surface (LIS) concept has emerged recently as a new
paradigm for wireless communication, remote sensing and positioning. It
consists of a continuous radiating surface placed relatively close to the
users, which is able to communicate with users by independent transmission and
reception (replacing base stations). Despite of its potential, there are a lot
of challenges from an implementation point of view, with the interconnection
data-rate and computational complexity being the most relevant. Distributed
processing techniques and hierarchical architectures are expected to play a
vital role addressing this while ensuring scalability. In this paper we perform
algorithm-architecture codesign and analyze the hardware requirements and
architecture trade-offs for a discrete LIS to perform uplink detection. By
doing this, we expect to give concrete case studies and guidelines for
efficient implementation of LIS systems.
"
1382,"Noisy Machines: Understanding Noisy Neural Networks and Enhancing
  Robustness to Analog Hardware Errors Using Distillation","  The success of deep learning has brought forth a wave of interest in computer
hardware design to better meet the high demands of neural network inference. In
particular, analog computing hardware has been heavily motivated specifically
for accelerating neural networks, based on either electronic, optical or
photonic devices, which may well achieve lower power consumption than
conventional digital electronics. However, these proposed analog accelerators
suffer from the intrinsic noise generated by their physical components, which
makes it challenging to achieve high accuracy on deep neural networks. Hence,
for successful deployment on analog accelerators, it is essential to be able to
train deep neural networks to be robust to random continuous noise in the
network weights, which is a somewhat new challenge in machine learning. In this
paper, we advance the understanding of noisy neural networks. We outline how a
noisy neural network has reduced learning capacity as a result of loss of
mutual information between its input and output. To combat this, we propose
using knowledge distillation combined with noise injection during training to
achieve more noise robust networks, which is demonstrated experimentally across
different networks and datasets, including ImageNet. Our method achieves models
with as much as two times greater noise tolerance compared with the previous
best attempts, which is a significant step towards making analog hardware
practical for deep learning.
"
1383,"A Scalable Decoder Micro-architecture for Fault-Tolerant Quantum
  Computing","  Quantum computation promises significant computational advantages over
classical computation for some problems. However, quantum hardware suffers from
much higher error rates than in classical hardware. As a result, extensive
quantum error correction is required to execute a useful quantum algorithm. The
decoder is a key component of the error correction scheme whose role is to
identify errors faster than they accumulate in the quantum computer and that
must be implemented with minimum hardware resources in order to scale to the
regime of practical applications. In this work, we consider surface code error
correction, which is the most popular family of error correcting codes for
quantum computing, and we design a decoder micro-architecture for the
Union-Find decoding algorithm. We propose a three-stage fully pipelined
hardware implementation of the decoder that significantly speeds up the
decoder. Then, we optimize the amount of decoding hardware required to perform
error correction simultaneously over all the logical qubits of the quantum
computer. By sharing resources between logical qubits, we obtain a 67%
reduction of the number of hardware units and the memory capacity is reduced by
70%. Moreover, we reduce the bandwidth required for the decoding process by a
factor at least 30x using low-overhead compression algorithms. Finally, we
provide numerical evidence that our optimized micro-architecture can be
executed fast enough to correct errors in a quantum computer.
"
1384,"SPARTA: A Divide and Conquer Approach to Address Translation for
  Accelerators","  Virtual memory (VM) is critical to the usability and programmability of
hardware accelerators. Unfortunately, implementing accelerator VM efficiently
is challenging because the area and power constraints make it difficult to
employ the large multi-level TLBs used in general-purpose CPUs. Recent research
proposals advocate a number of restrictions on virtual-to-physical address
mappings in order to reduce the TLB size or increase its reach. However, such
restrictions are unattractive because they forgo many of the original benefits
of traditional VM, such as demand paging and copy-on-write.
  We propose SPARTA, a divide and conquer approach to address translation.
SPARTA splits the address translation into accelerator-side and memory-side
parts. The accelerator-side translation hardware consists of a tiny TLB
covering only the accelerator's cache hierarchy (if any), while the translation
for main memory accesses is performed by shared memory-side TLBs. Performing
the translation for memory accesses on the memory side allows SPARTA to overlap
data fetch with translation, and avoids the replication of TLB entries for data
shared among accelerators. To further improve the performance and efficiency of
the memory-side translation, SPARTA logically partitions the memory space,
delegating translation to small and efficient per-partition translation
hardware. Our evaluation on index-traversal accelerators shows that SPARTA
virtually eliminates translation overhead, reducing it by over 30x on average
(up to 47x) and improving performance by 57%. At the same time, SPARTA requires
minimal accelerator-side translation hardware, reduces the total number of TLB
entries in the system, gracefully scales with memory size, and preserves all
key VM functionalities.
"
1385,"Occlum: Secure and Efficient Multitasking Inside a Single Enclave of
  Intel SGX","  Intel Software Guard Extensions (SGX) enables user-level code to create
private memory regions called enclaves, whose code and data are protected by
the CPU from software and hardware attacks outside the enclaves. Recent work
introduces library operating systems (LibOSes) to SGX so that legacy
applications can run inside enclaves with few or even no modifications. As
virtually any non-trivial application demands multiple processes, it is
essential for LibOSes to support multitasking. However, none of the existing
SGX LibOSes support multitasking both securely and efficiently.
  This paper presents Occlum, a system that enables secure and efficient
multitasking on SGX. We implement the LibOS processes as SFI-Isolated Processes
(SIPs). SFI is a software instrumentation technique for sandboxing untrusted
modules (called domains). We design a novel SFI scheme named MPX-based,
Multi-Domain SFI (MMDSFI) and leverage MMDSFI to enforce the isolation of SIPs.
We also design an independent verifier to ensure the security guarantees of
MMDSFI. With SIPs safely sharing the single address space of an enclave, the
LibOS can implement multitasking efficiently. The Occlum LibOS outperforms the
state-of-the-art SGX LibOS on multitasking-heavy workloads by up to 6,600X on
micro-benchmarks and up to 500X on application benchmarks.
"
1386,"Achieving Multi-Port Memory Performance on Single-Port Memory with
  Coding Techniques","  Many performance critical systems today must rely on performance
enhancements, such as multi-port memories, to keep up with the increasing
demand of memory-access capacity. However, the large area footprints and
complexity of existing multi-port memory designs limit their applicability.
This paper explores a coding theoretic framework to address this problem. In
particular, this paper introduces a framework to encode data across multiple
single-port memory banks in order to {\em algorithmically} realize the
functionality of multi-port memory.
  This paper proposes three code designs with significantly less storage
overhead compared to the existing replication based emulations of multi-port
memories. To further improve performance, we also demonstrate a memory
controller design that utilizes redundancy across coded memory banks to more
efficiently schedule read and write requests sent across multiple cores.
Furthermore, guided by DRAM traces, the paper explores {\em dynamic coding}
techniques to improve the efficiency of the coding based memory design. We then
show significant performance improvements in critical word read and write
latency in the proposed coded-memory design when compared to a traditional
uncoded-memory design.
"
1387,"Accelerating Transient Fault Injection Campaigns by using Dynamic HDL
  Slicing","  Along with the complexity of electronic systems for safety-critical
applications, the cost of safety mechanisms evaluation by fault injection
simulation is rapidly going up. To reduce these efforts, we propose a fault
injection methodology where Hardware Description Language (HDL) code slicing is
exploited to accelerate transient fault injection campaigns by pruning fault
lists and reducing the number of the injections. In particular, the dynamic HDL
slicing technique provides for a critical fault list and allows avoiding
injections at non-critical time-steps. Experimental results on an industrial
core show that the proposed methodology can successfully reduce the number of
injections by up to 10 percent and speed-up the fault injection campaigns.
"
1388,qBSA: Logic Design of a 32-bit Block-Skewed RSFQ Arithmetic Logic Unit,"  Single flux quantum (SFQ) circuits are an attractive beyond-CMOS technology
because they promise two orders of magnitude lower power at clock frequencies
exceeding 25 GHz.However, every SFQ gate is clocked creating very deep
gate-level pipelines that are difficult to keep full, particularly for
sequences that include data-dependent operations. This paper proposes to
increase the throughput of SFQ pipelines by re-designing the datapath to accept
and operate on least-significant bits (LSBs) clock cycles earlier than more
significant bits. This skewed datapath approach reduces the latency of the LSB
side which can be feedback earlier for use in subsequent data-dependent
operations increasing their throughput. In particular,we propose to group the
bits into 4-bit blocks that are operatedon concurrently and create block-skewed
datapath units for 32-bit operation. This skewed approach allows a subsequent
data-dependent operation to start evaluating as soon as the first 4-bit block
completes. Using this general approach, we developa block-skewed
MIPS-compatible 32-bit ALU. Our gate-level Verilog design improves the
throughput of 32-bit data dependent operations by 2x and 1.5x compared to
previously proposed 4-bit bit-slice and 32-bit Ladner-Fischer ALUs
respectively.
"
1389,"Exploiting RapidWright in the Automatic Generation of
  Application-Specific FPGA Overlays","  Overlay architectures implemented on FPGA devices have been proposed as a
means to increase FPGA adoption in general-purpose computing. They provide the
benefits of software such as flexibility and programmability, thus making it
easier to build dedicated compilers. However, existing overlays are generic,
resource and power hungry with performance usually an order of magnitude lower
than bare metal implementations. As a result, FPGA overlays have been confined
to research and some niche applications. In this paper, we introduce
Application-Specific FPGA Overlays (AS-Overlays), which can provide bare-metal
performance to FPGA overlays, thus opening doors for broader adoption. Our
approach is based on the automatic extraction of hardware kernels from data
flow applications. Extracted kernels are then leveraged for
application-specific generation of hardware accelerators. Reconfiguration of
the overlay is done with RapidWright which allows to bypass the HDL design
flow. Through prototyping, we demonstrated the viability and relevance of our
approach. Experiments show a productivity improvement up to 20x compared to the
state of the art FPGA overlays, while achieving over 1.33x higher Fmax than
direct FPGA implementation and the possibility of lower resource and power
consumption compared to bare metal.
"
1390,Efficient Fault Injection based on Dynamic HDL Slicing Technique,"  This work proposes a fault injection methodology where Hardware Description
Language (HDL) code slicing is exploited to prune fault injection locations,
thus enabling more efficient campaigns for safety mechanisms evaluation. In
particular, the dynamic HDL slicing technique provides for a highly collapsed
critical fault list and allows avoiding injections at redundant locations or
time-steps. Experimental results show that the proposed methodology integrated
into commercial tool flow doubles the simulation speed when comparing to the
state-of-the-art industrial-grade EDA tool flows.
"
1391,"TLB and Pagewalk Performance in Multicore Architectures with Large
  Die-Stacked DRAM Cache","  In this work we study the overheads of virtual-to-physical address
translation in processor architectures, like x86-64, that implement paged
virtual memory using a radix tree which are walked in hardware. Translation
Lookaside Buffers are critical to system performance, particularly as
applications demand larger memory footprints and with the adoption of
virtualization; however the cost of a TLB miss potentially results in multiple
memory accesses to retrieve the translation. Architectural support for
superpages has been introduced to increase TLB hits but are limited by the
operating systems ability to find contiguous memory. Numerous prior studies
have proposed TLB designs to lower miss rates and reduce page walk overhead;
however, these studies have modeled the behavior analytically. Further, to
eschew the paging overhead for big-memory workloads and virtualization, Direct
Segment maps part of a process linear virtual address space with segment
registers albeit requiring a few application and operating system
modifications. The recently evolved die-stacked DRAM technology promises a high
bandwidth and large last-level cache, in the order of Gigabytes, closer to the
processors. With such large caches the amount of data that can be accessed
without causing a TLB fault - the reach of a TLB, is inadequate. TLBs are on
the critical path for data accesses and incurring an expensive page walk can
hinder system performance, especially when the data being accessed is a cache
hit in the LLC. Hence, we are interested in exploring novel address translation
mechanisms, commensurate to the size and latency of stacked DRAM. By accurately
simulating the multitude of multi-level address translation structures using
the QEMU based MARSSx86 full system simulator, we perform detailed study of
TLBs in conjunction with the large LLCs using multi-programmed and
multi-threaded workloads.
"
1392,"Synthesizing Compact Hardware for Accelerating Inference from Physical
  Signals in Sensors","  We present dimensional circuit synthesis, a new method for generating digital
logic circuits that improve the efficiency of training and inference of machine
learning models from sensor data. The hardware accelerators that the method
generates are compact enough (a few thousand gates) to allow integration within
low-cost miniaturized sensor integrated circuits, right next to the sensor
transducer. The method takes as input a description of physical properties of
relevant signals in the sensor transduction process and generates as output a
Verilog register transfer level (RTL) description for a circuit that computes
low-level features that exploit the units of measure of the signals in the
system.
  We implement dimensional circuit synthesis as a backend to the compiler for
Newton, a language for describing physical systems. We evaluate the backend
implementation and the hardware it generates, on descriptions of 7 physical
systems. The results show that our implementation of dimensional circuit
synthesis generates circuits of as little as 1662 logic cells / 1239 gates for
the systems we evaluate.
  We synthesize the designs generated by the dimensional circuit synthesis
compilation backend for a low-power miniature FPGA targeted by its manufacturer
at sensor interface applications. The circuits which the method generated use
as little as 27% of the resources of the 2.15x2.5 mm FPGA. We measure the power
dissipation of the FPGA's isolated core supply rail and show that, driven with
a pseudorandom signal input stream, the synthesized designs use as little as
1.0 mW and no more than 5.8 mW. These results show the feasibility of
integrating physics-inspired machine learning methods within low-cost
miniaturized sensor integrated circuits, right next to the sensor transducer.
"
1393,Fast FPGA emulation of analog dynamics in digitally-driven systems,"  In this paper, we propose an architecture for FPGA emulation of mixed-signal
systems that achieves high accuracy at a high throughput. We represent the
analog output of a block as a superposition of step responses to changes in its
analog input, and the output is evaluated only when needed by the digital
subsystem. Our architecture is therefore intended for digitally-driven systems;
that is, those in which the inputs of analog dynamical blocks change only on
digital clock edges. We implemented a high-speed link transceiver design using
the proposed architecture on a Xilinx FPGA. This design demonstrates how our
approach breaks the link between simulation rate and time resolution that is
characteristic of prior approaches. The emulator is flexible, allowing for the
real-time adjustment of analog dynamics, clock jitter, and various design
parameters. We demonstrate that our architecture achieves 1% accuracy while
running 3 orders of magnitude faster than a comparable high-performance CPU
simulation.
"
1394,"Low Overhead Online Data Flow Tracking for Intermittently Powered
  Non-volatile FPGAs","  Energy harvesting is an attractive way to power future IoT devices since it
can eliminate the need for battery or power cables. However, harvested energy
is intrinsically unstable. While FPGAs have been widely adopted in various
embedded systems, it is hard to survive unstable power since all the memory
components in FPGA are based on volatile SRAMs. The emerging non-volatile
memory based FPGAs provide promising potentials to keep configuration data on
the chip during power outages. Few works have considered implementing efficient
runtime intermediate data checkpoint on non-volatile FPGAs. To realize
accumulative computation under intermittent power on FPGA, this paper proposes
a low-cost design framework, Data-Flow-Tracking FPGA (DFT-FPGA), which utilizes
binary counters to track intermediate data flow. Instead of keeping all on-chip
intermediate data, DFT-FPGA only targets on necessary data that is labeled by
off-line analysis and identified by an online tracking system. The evaluation
shows that compared with state-of-the-art techniques, DFT-FPGA can realize
accumulative computing with less off-line workload and significantly reduce
online roll-back time and resource utilization.
"
1395,FPGA Acceleration of Sequence Alignment: A Survey,"  Genomics is changing our understanding of humans, evolution, diseases, and
medicines to name but a few. As sequencing technology is developed collecting
DNA sequences takes less time thereby generating more genetic data every day.
Today the rate of generating genetic data is outpacing the rate of computation
power growth. Current sequencing machines can sequence 50 humans genome per
day; however, aligning the read sequences against a reference genome and
assembling the genome will take 1300 CPU hours. The main step in constructing
the genome is aligning the reads against a reference genome. Numerous
accelerators have been proposed to accelerate the DNA alignment process.
Providing massive parallelism, FPGA-based accelerators have shown great
performance in accelerating DNA alignment algorithms. Additionally, FPGA-based
accelerators provide better energy efficiency than general-purpose processors.
In this survey, we introduce three main DNA alignment algorithms and FPGA-based
implementation of these algorithms to accelerate the DNA alignment. We also,
compare these three alignment categories and show how accelerators are
developing during the time.
"
1396,RVCoreP : An optimized RISC-V soft processor of five-stage pipelining,"  RISC-V is a RISC based open and loyalty free instruction set architecture
which has been developed since 2010, and can be used for cost-effective soft
processors on FPGAs. The basic 32-bit integer instruction set in RISC-V is
defined as RV32I, which is sufficient to support the operating system
environment and suits for embedded systems. In this paper, we propose an
optimized RV32I soft processor named RVCoreP adopting five-stage pipelining.
The processor applies three effective optimization methods to improve the
operating frequency. These methods are instruction fetch unit optimization
including pipelined branch prediction mechanism, ALU optimization, and data
alignment and sign-extension optimization for data memory output. We implement
RVCoreP in Verilog HDL and verify the behavior using Verilog simulation and an
actual Xilinx Atrix-7 FPGA board. We evaluate IPC (instructions per cycle),
operating frequency, hardware resource utilization, and processor performance.
From the evaluation results, we show that RVCoreP achieves 30.0% performance
improvement compared with VexRiscv, which is a high-performance and open source
RV32I processor selected from some related works.
"
1397,A portable and Linux capable RISC-V computer system in Verilog HDL,"  RISC-V is an open and royalty free instruction set architecture which has
been developed at the University of California, Berkeley. The processors using
RISC-V can be designed and released freely. Because of this, various processor
cores and system on chips (SoCs) have been released so far. However, there are
a few public RISC-V computer systems that are portable and can boot Linux
operating systems. In this paper, we describe a portable and Linux capable
RISC-V computer system targeting FPGAs in Verilog HDL. This system can be
implemented on an FPGA with fewer hardware resources, and can be implemented on
low cost FPGAs or customized by introducing an accelerator. This paper also
describes the knowledge obtained through the development of this RISC-V
computer system.
"
1398,Rainbow: A Composable Coherence Protocol for Multi-Chip Servers,"  The use of multi-chip modules (MCM) and/or multi-socket boards is the most
suitable approach to increase the computation density of servers while keep
chip yield attained. This paper introduces a new coherence protocol suitable,
in terms of complexity and scalability, for this class of systems. The proposal
uses two complementary ideas: (1) A mechanism that dissociates complexity from
performance by means of colored-token counting, (2) A construct that optimizes
performance and cost by means of two functionally symmetrical modules working
in the last level cache of each chip (D|F-LLC) and each memory controller
(D|F-MEM). Each of these structures is divided into two parts: (2.1) The first
one consists of a small loosely inclusive sparse directory where only the most
actively shared data are tracked in the chip (D-LLC) from each memory
controller (D-MEM) and, (2.2) The second is a d-left Counting Bloom Filter
which stores approximate information about the blocks allocated, either inside
the chip (F-LLC) or in the home memory controller (F-MEM). The coordinated work
of both structures minimizes the coherence-related effects on the average
memory latency perceived by the processor. Our proposal is able to improve on
the performance of a HyperTransport-like coherence protocol by from 25%-to-60%.
"
1399,"CSM-NN: Current Source Model Based Logic Circuit Simulation -- A Neural
  Network Approach","  The miniaturization of transistors down to 5nm and beyond, plus the
increasing complexity of integrated circuits, significantly aggravate short
channel effects, and demand analysis and optimization of more design corners
and modes. Simulators need to model output variables related to circuit timing,
power, noise, etc., which exhibit nonlinear behavior. The existing simulation
and sign-off tools, based on a combination of closed-form expressions and
lookup tables are either inaccurate or slow, when dealing with circuits with
more than billions of transistors. In this work, we present CSM-NN, a scalable
simulation framework with optimized neural network structures and processing
algorithms. CSM-NN is aimed at optimizing the simulation time by accounting for
the latency of the required memory query and computation, given the underlying
CPU and GPU parallel processing capabilities. Experimental results show that
CSM-NN reduces the simulation time by up to $6\times$ compared to a
state-of-the-art current source model based simulator running on a CPU. This
speedup improves by up to $15\times$ when running on a GPU. CSM-NN also
provides high accuracy levels, with less than $2\%$ error, compared to HSPICE.
"
1400,"Functional Failure Rate Due to Single-Event Transients in Clock
  Distribution Networks","  With technology scaling, lower supply voltages, and higher operating
frequencies clock distribution networks become more and more vulnerable to
transients faults. These faults can cause circuit-wide effects and thus,
significantly contribute to the functional failure rate of the circuit. This
paper proposes a methodology to analyse how the functional behaviour is
affected by Single-Event Transients in the clock distribution network. The
approach is based on logic-level simulation and thus, only uses the
register-transfer level description of a design. Therefore, a fault model is
proposed which implements the main effects due to radiation-induced transients
in the clock network. This fault model enables the computation of the
functional failure rate caused by Single-Event Transients for each individual
clock buffer, as well as the complete network. Further, it allows the
identification of the most vulnerable flip-flops related to Single-Event
Transients in the clock network.
  The proposed methodology is applied in a practical example and a fault
injection campaign is performed. In order to evaluate the impact of
Single-Event Transients in clock distribution networks, the obtained functional
failure rate is compared to the error rate caused by Single-Event Upsets in the
sequential logic.
"
1401,"RapidLayout: Fast Hard Block Placement of FPGA-optimized Systolic Arrays
  using Evolutionary Algorithms","  Evolutionary algorithms can outperform conventional placement algorithms such
as simulated annealing, analytical placement as well as manual placement on
metrics such as runtime, wirelength, pipelining cost, and clock frequency when
mapping FPGA hard block intensive designs such as systolic arrays on Xilinx
UltraScale+ FPGAs. For certain hard-block intensive, systolic array accelerator
designs, the commercial-grade Xilinx Vivado CAD tool is unable to provide a
legal routing solution without tedious manual placement constraints. Instead,
we formulate an automatic FPGA placement algorithm for these hard blocks as a
multi-objective optimization problem that targets wirelength squared and
maximum bounding box size metrics. We build an end-to-end placement and routing
flow called RapidLayout using the Xilinx RapidWright framework. RapidLayout
runs 5-6$\times$ faster than Vivado with manual constraints and eliminates the
weeks-long effort to generate placement constraints manually for the hard
blocks. We also perform automated post-placement pipelining of the long wires
inside each convolution block to target 650MHz URAM-limited operation.
RapidLayout outperforms (1) the simulated annealer in VPR by 33% in runtime,
1.9-2.4$\times$ in wirelength, and 3-4$\times$ in bounding box size, while also
(2) beating the analytical placer UTPlaceF by 9.3$\times$ in runtime,
1.8-2.2$\times$ in wirelength, and 2-2.7$\times$ in bounding box size. We
employ transfer learning from a base FPGA device to speed-up placement
optimization for similar FPGA devices in the UltraScale+ family by
11-14$\times$ than learning the placements from scratch.
"
1402,"Information Theory as a Means of Determining the Main Factors Affecting
  the Processors Architecture","  In this article we are investigating the computers development process in the
past decades in order to identify the factors that influence it the most. We
describe such factors and use them to predict the direction of further
development. To solve these problems, we use the concept of the Computer
Capacity, which allows us to estimate the performance of computers
theoretically, relying only on the description of its architecture.
"
1403,Design of SEC-DED and SEC-DED-DAEC Codes of different lengths,"  Reliability is an important requirement for both communication and storage
systems. Due to continuous scale down of technology multiple adjacent bits
error probability increases. The data may be corrupted due soft errors. Error
correction codes are used to detect and correct the errors. In this paper,
design of single error correction-double error detection (SEC-DED) and single
error correction-double error detection-double adjacent error correction
(SEC-DED-DAEC) codes of different data lengths have been proposed. Proposed
SEC-DED and SEC-DED-DAEC codes require lower delay and power compared to
existing coding schemes. Area complexity in terms of logic gates of proposed
and existing codes have been presented. ASIC-based synthesis results show a
notable reduction compared to existing SEC-DED codes. All the codec
architectures are synthesized on ASIC platform. Performances of different
SEC-DED-DAEC codes are tabulated in terms of area, power and delay.
"
1404,"An Energy-Efficient Accelerator Architecture with Serial Accumulation
  Dataflow for Deep CNNs","  Convolutional Neural Networks (CNNs) have shown outstanding accuracy for many
vision tasks during recent years. When deploying CNNs on portable devices and
embedded systems, however, the large number of parameters and computations
result in long processing time and low battery life. An important factor in
designing CNN hardware accelerators is to efficiently map the convolution
computation onto hardware resources. In addition, to save battery life and
reduce energy consumption, it is essential to reduce the number of DRAM
accesses since DRAM consumes orders of magnitude more energy compared to other
operations in hardware. In this paper, we propose an energy-efficient
architecture which maximally utilizes its computational units for convolution
operations while requiring a low number of DRAM accesses. The implementation
results show that the proposed architecture performs one image recognition task
using the VGGNet model with a latency of 393 ms and only 251.5 MB of DRAM
accesses.
"
1405,SpArch: Efficient Architecture for Sparse Matrix Multiplication,"  Generalized Sparse Matrix-Matrix Multiplication (SpGEMM) is a ubiquitous task
in various engineering and scientific applications. However, inner product
based SpGENN introduces redundant input fetches for mismatched nonzero
operands, while outer product based approach suffers from poor output locality
due to numerous partial product matrices. Inefficiency in the reuse of either
inputs or outputs data leads to extensive and expensive DRAM access.
  To address this problem, this paper proposes an efficient sparse matrix
multiplication accelerator architecture, SpArch, which jointly optimizes the
data locality for both input and output matrices. We first design a highly
parallelized streaming-based merger to pipeline the multiply and merge stage of
partial matrices so that partial matrices are merged on chip immediately after
produced. We then propose a condensed matrix representation that reduces the
number of partial matrices by three orders of magnitude and thus reduces DRAM
access by 5.4x. We further develop a Huffman tree scheduler to improve the
scalability of the merger for larger sparse matrices, which reduces the DRAM
access by another 1.8x. We also resolve the increased input matrix read induced
by the new representation using a row prefetcher with near-optimal buffer
replacement policy, further reducing the DRAM access by 1.5x. Evaluated on 20
benchmarks, SpArch reduces the total DRAM access by 2.8x over previous
state-of-the-art. On average, SpArch achieves 4x, 19x, 18x, 17x, 1285x speedup
and 6x, 164x, 435x, 307x, 62x energy savings over OuterSPACE, MKL, cuSPARSE,
CUSP, and ARM Armadillo, respectively.
"
1406,Optimality Study of Existing Quantum Computing Layout Synthesis Tools,"  Layout synthesis, an important step in quantum computing, processes quantum
circuits to satisfy device layout constraints. In this paper, we construct
QUEKO benchmarks for this problem, which have known optimal depths and gate
counts. We use QUEKO to evaluate the optimality of current layout synthesis
tools, including Cirq from Google, Qiskit from IBM,
$\mathsf{t}|\mathsf{ket}\rangle$ from Cambridge Quantum Computing, and recent
academic work. To our surprise, despite over a decade of research and
development by academia and industry on compilation and synthesis for quantum
circuits, we are still able to demonstrate large optimality gaps: 1.5-12x on
average on a smaller device and 5-45x on average on a larger device. This
suggests substantial room for improvement of the efficiency of quantum computer
by better layout synthesis tools. Finally, we also prove the NP-completeness of
the layout synthesis problem for quantum computing. We have made the QUEKO
benchmarks open-source.
"
1407,"Snitch: A tiny Pseudo Dual-Issue Processor for Area and Energy Efficient
  Execution of Floating-Point Intensive Workloads","  Data-parallel applications, such as data analytics, machine learning, and
scientific computing, are placing an ever-growing demand on floating-point
operations per second on emerging systems. With increasing integration density,
the quest for energy efficiency becomes the number one design concern. While
dedicated accelerators provide high energy efficiency, they are
over-specialized and hard to adjust to algorithmic changes. We propose an
architectural concept that tackles the issues of achieving extreme energy
efficiency while still maintaining high flexibility as a general-purpose
compute engine. The key idea is to pair a tiny 10kGE control core, called
Snitch, with a double-precision FPU to adjust the compute to control ratio.
While traditionally minimizing non-FPU area and achieving high floating-point
utilization has been a trade-off, with Snitch, we achieve them both, by
enhancing the ISA with two minimally intrusive extensions: stream semantic
registers (SSR) and a floating-point repetition instruction (FREP). SSRs allow
the core to implicitly encode load/store instructions as register reads/writes,
eliding many explicit memory instructions. The FREP extension decouples the
floating-point and integer pipeline by sequencing instructions from a
micro-loop buffer. These ISA extensions significantly reduce the pressure on
the core and free it up for other tasks, making Snitch and FPU effectively
dual-issue at a minimal incremental cost of 3.2%. The two low overhead ISA
extensions make Snitch more flexible than a contemporary vector processor lane,
achieving a $2\times$ energy-efficiency improvement. We have evaluated the
proposed core and ISA extensions on an octa-core cluster in 22nm technology. We
achieve more than $5\times$ multi-core speed-up and a $3.5\times$ gain in
energy efficiency on several parallel microkernels.
"
1408,"sBSNN: Stochastic-Bits Enabled Binary Spiking Neural Network with
  On-Chip Learning for Energy Efficient Neuromorphic Computing at the Edge","  In this work, we propose stochastic Binary Spiking Neural Network (sBSNN)
composed of stochastic spiking neurons and binary synapses (stochastic only
during training) that computes probabilistically with one-bit precision for
power-efficient and memory-compressed neuromorphic computing. We present an
energy-efficient implementation of the proposed sBSNN using 'stochastic bit' as
the core computational primitive to realize the stochastic neurons and
synapses, which are fabricated in 90nm CMOS process, to achieve efficient
on-chip training and inference for image recognition tasks. The measured data
shows that the 'stochastic bit' can be programmed to mimic spiking neurons, and
stochastic Spike Timing Dependent Plasticity (or sSTDP) rule for training the
binary synaptic weights without expensive random number generators. Our results
indicate that the proposed sBSNN realization offers possibility of up to 32x
neuronal and synaptic memory compression compared to full precision (32-bit)
SNN and energy efficiency of 89.49 TOPS/Watt for two-layer fully-connected SNN.
"
1409,"LORAX: Loss-Aware Approximations for Energy-Efficient Silicon Photonic
  Networks-on-Chip","  The approximate computing paradigm advocates for relaxing accuracy goals in
applications to improve energy-efficiency and performance. Recently, this
paradigm has been explored to improve the energy efficiency of silicon photonic
networks-on-chip (PNoCs). In this paper, we propose a novel framework (LORAX)
to enable more aggressive approximation during communication over silicon
photonic links in PNoCs. Given that silicon photonic interconnects have
significant power dissipation due to the laser sources that generate the
wavelengths for photonic communication, our framework attempts to reduce laser
power overheads while intelligently approximating communication such that
application output quality is not distorted beyond an acceptable limit. To the
best of our knowledge, this is the first work that considers loss-aware laser
power management and multilevel signaling to enable effective data
approximation and energy-efficiency in PNoCs. Simulation results show that our
framework can achieve up to 31.4% lower laser power consumption and up to 12.2%
better energy efficiency than the best known prior work on approximate
communication with silicon photonic interconnects, for the same application
output quality
"
1410,A Compiler Infrastructure for FPGA and ASIC Development,"  This whitepaper proposes a unified framework for hardware design tools to
ease the development and inter-operability of said tools. By creating a large
ecosystem of hardware development tools across vendors, academia, and the open
source community, we hope to significantly increase much need productivity in
hardware design.
"
1411,"FPGA Implementation of Minimum Mean Brightness Error Bi-Histogram
  Equalization","  Histogram Equalization (HE) is a popular method for contrast enhancement.
Generally, mean brightness is not conserved in Histogram Equalization.
Initially, Bi-Histogram Equalization (BBHE) was proposed to enhance contrast
while maintaining a the mean brightness. However, when mean brightness is
primary concern, Minimum Mean Brightness Error Bi-Histogram Equalization
(MMBEBHE) is the best technique. There are several implementations of Histogram
Equalization on FPGA, however to our knowledge MMBEBHE has not been implemented
on FPGAs before. Therefore, we present an implementation of MMBEBHE on FPGA.
"
1412,"TimingCamouflage+: Netlist Security Enhancement with Unconventional
  Timing (with Appendix)","  With recent advances in reverse engineering, attackers can reconstruct a
netlist to counterfeit chips by opening the die and scanning all layers of
authentic chips. This relatively easy counterfeiting is made possible by the
use of the standard simple clocking scheme, where all combinational blocks
function within one clock period, so that a netlist of combinational logic
gates and flip-flops is sufficient to duplicate a design. In this paper, we
propose to invalidate the assumption that a netlist completely represents the
function of a circuit with unconventional timing. With the introduced
wave-pipelining paths, attackers have to capture gate and interconnect delays
during reverse engineering, or to test a huge number of combinational paths to
identify the wave-pipelining paths. To hinder the test-based attack, we
construct false paths with wave-pipelining to increase the counterfeiting
challenge. Experimental results confirm that wave-pipelining true paths and
false paths can be constructed in benchmark circuits successfully with only a
negligible cost, thus thwarting the potential attack techniques.
"
1413,"A New MRAM-based Process In-Memory Accelerator for Efficient Neural
  Network Training with Floating Point Precision","  The excellent performance of modern deep neural networks (DNNs) comes at an
often prohibitive training cost, limiting the rapid development of DNN
innovations and raising various environmental concerns. To reduce the dominant
data movement cost of training, process in-memory (PIM) has emerged as a
promising solution as it alleviates the need to access DNN weights. However,
state-of-the-art PIM DNN training accelerators employ either analog/mixed
signal computing which has limited precision or digital computing based on a
memory technology that supports limited logic functions and thus requires
complicated procedure to realize floating point computation. In this paper, we
propose a spin orbit torque magnetic random access memory (SOT-MRAM) based
digital PIM accelerator that supports floating point precision. Specifically,
this new accelerator features an innovative (1) SOT-MRAM cell, (2) full
addition design, and (3) floating point computation. Experiment results show
that the proposed SOT-MRAM PIM based DNN training accelerator can achieve
3.3$\times$, 1.8$\times$, and 2.5$\times$ improvement in terms of energy,
latency, and area, respectively, compared with a state-of-the-art PIM based DNN
training accelerator.
"
1414,"LUXOR: An FPGA Logic Cell Architecture for Efficient Compressor Tree
  Implementations","  We propose two tiers of modifications to FPGA logic cell architecture to
deliver a variety of performance and utilization benefits with only minor area
overheads. In the irst tier, we augment existing commercial logic cell
datapaths with a 6-input XOR gate in order to improve the expressiveness of
each element, while maintaining backward compatibility. This new architecture
is vendor-agnostic, and we refer to it as LUXOR. We also consider a secondary
tier of vendor-speciic modifications to both Xilinx and Intel FPGAs, which we
refer to as X-LUXOR+ and I-LUXOR+ respectively. We demonstrate that compressor
tree synthesis using generalized parallel counters (GPCs) is further improved
with the proposed modifications. Using both the Intel adaptive logic module and
the Xilinx slice at the 65nm technology node for a comparative study, it is
shown that the silicon area overhead is less than 0.5% for LUXOR and 5-6% for
LUXOR+, while the delay increments are 1-6% and 3-9% respectively. We
demonstrate that LUXOR can deliver an average reduction of 13-19% in logic
utilization on micro-benchmarks from a variety of domains.BNN benchmarks
benefit the most with an average reduction of 37-47% in logic utilization,
which is due to the highly-efficient mapping of the XnorPopcount operation on
our proposed LUXOR+ logic cells.
"
1415,"Are We Susceptible to Rowhammer? An End-to-End Methodology for Cloud
  Providers","  Cloud providers are concerned that Rowhammer poses a potentially critical
threat to their servers, yet today they lack a systematic way to test whether
the DRAM used in their servers is vulnerable to Rowhammer attacks. This paper
presents an end-to-end methodology to determine if cloud servers are
susceptible to these attacks. With our methodology, a cloud provider can
construct worst-case testing conditions for DRAM.
  We apply our methodology to three classes of servers from a major cloud
provider. Our findings show that none of the CPU instruction sequences used in
prior work to mount Rowhammer attacks create worst-case DRAM testing
conditions. To address this limitation, we develop an instruction sequence that
leverages microarchitectural side-effects to ``hammer'' DRAM at a near-optimal
rate on modern Intel Skylake and Cascade Lake platforms. We also design a DDR4
fault injector that can reverse engineer row adjacency for any DDR4 DIMM. When
applied to our cloud provider's DIMMs, we find that DRAM rows do not always
follow a linear map.
"
1416,"Cycle-Accurate Evaluation of Software-Hardware Co-Design of Decimal
  Computation in RISC-V Ecosystem","  Software-hardware co-design solutions for decimal computation can provide
several Pareto points to development of embedded systems in terms of hardware
cost and performance. This paper demonstrates how to accurately evaluate such
co-design solutions using RISC-V ecosystem. In a software-hardware co-design
solution, a part of solution requires dedicated hardware. In our evaluation
framework, we develop new decimal oriented instructions supported by an
accelerator. The framework can realize cycle-accurate analysis for performance
as well as hardware overhead for co-design solutions for decimal computation.
The obtained performance result is compared with an estimation with dummy
functions.
"
1417,"A Power-Efficient Binary-Weight Spiking Neural Network Architecture for
  Real-Time Object Classification","  Neural network hardware is considered an essential part of future edge
devices. In this paper, we propose a binary-weight spiking neural network
(BW-SNN) hardware architecture for low-power real-time object classification on
edge platforms. This design stores a full neural network on-chip, and hence
requires no off-chip bandwidth. The proposed systolic array maximizes data
reuse for a typical convolutional layer. A 5-layer convolutional BW-SNN
hardware is implemented in 90nm CMOS. Compared with state-of-the-art designs,
the area cost and energy per classification are reduced by 7$\times$ and
23$\times$, respectively, while also achieving a higher accuracy on the MNIST
benchmark. This is also a pioneering SNN hardware architecture that supports
advanced CNN architectures.
"
1418,New Approximate Multiplier for Low Power Digital Signal Processing,"  In this paper a low power multiplier is proposed. The proposed multiplier
utilizes Broken-Array Multiplier approximation method on the conventional
modified Booth multiplier. This method reduces the total power consumption of
multiplier up to 58% at the cost of a small decrease in output accuracy. The
proposed multiplier is compared with other approximate multipliers in terms of
power consumption and accuracy. Furthermore, to have a better evaluation of the
proposed multiplier efficiency, it has been used in designing a 30-tap low-pass
FIR filter and the power consumption and accuracy are compared with that of a
filter with conventional booth multipliers. The simulation results show a 17.1%
power reduction at the cost of only 0.4dB decrease in the output SNR.
"
1419,"Physical Time-Varying Transfer Functions as Generic Low-Overhead
  Power-SCA Countermeasure","  Mathematically-secure cryptographic algorithms leak significant side channel
information through their power supplies when implemented on a physical
platform. These side channel leakages can be exploited by an attacker to
extract the secret key of an embedded device. The existing state-of-the-art
countermeasures mainly focus on the power balancing, gate-level masking, or
signal-to-noise (SNR) reduction using noise injection and signature
attenuation, all of which suffer either from the limitations of high power/area
overheads, performance degradation or are not synthesizable. In this article,
we propose a generic low-overhead digital-friendly power SCA countermeasure
utilizing physical Time-Varying Transfer Functions (TVTF) by randomly shuffling
distributed switched capacitors to significantly obfuscate the traces in the
time domain. System-level simulation results of the TVTF-AES implemented in
TSMC 65nm CMOS technology show > 4000x MTD improvement over the unprotected
implementation with nearly 1.25x power and 1.2x area overheads, and without any
performance degradation.
"
1420,"Report on power, thermal and reliability prediction for 3D
  Networks-on-Chip","  By combining Three Dimensional Integrated Circuits with the Network-on-Chip
infrastructure to obtain 3D Networks-on-Chip (3D-NoCs), the new on-chip
communication paradigm brings several advantages on lower power, smaller
footprint and lower latency. However, thermal dissipation is one of the most
critical challenges for 3D-ICs where the heat cannot easily transfer through
several layers of silicon. Consequently, the high-temperature area also
confronts the reliability threat as the Mean Time to Failure (MTTF) decreases
exponentially with the operating temperature. Apparently, 3D-NoCs must tackle
this fundamental problem in order to be widely used. Therefore, in this work,
we investigate the thermal distribution and reliability prediction of 3D-NoCs.
We first present a new method to help simulate the temperature (both steady and
transient) using traffics value from realistic and synthetic benchmarks and the
power consumption from standard VLSI design flow. Then, based on the proposed
method, we further predict the relative reliability between different parts of
the network. Experimental results show that the method has an extremely fast
execution time in comparison to the acceleration lifetime test. Furthermore, we
compare the thermal behavior and reliability between Monolithic design and
TSV-based TSV. We also explorer the ability to implement the thermal via a
mechanism to help reduce the operating temperature.
"
1421,DS3: A System-Level Domain-Specific System-on-Chip Simulation Framework,"  Heterogeneous systems-on-chip (SoCs) are highly favorable computing platforms
due to their superior performance and energy efficiency potential compared to
homogeneous architectures. They can be further tailored to a specific domain of
applications by incorporating processing elements (PEs) that accelerate
frequently used kernels in these applications. However, this potential is
contingent upon optimizing the SoC for the target domain and utilizing its
resources effectively at runtime. To this end, system-level design - including
scheduling, power-thermal management algorithms and design space exploration
studies - plays a crucial role. This paper presents a system-level
domain-specific SoC simulation (DS3) framework to address this need. DS3
enables both design space exploration and dynamic resource management for
power-performance optimization of domain applications. We showcase DS3 using
six real-world applications from wireless communications and radar processing
domain. DS3, as well as the reference applications, is shared as open-source
software to stimulate research in this area.
"
1422,"Soft-Error and Hard-fault Tolerant Architecture and Routing Algorithm
  for Reliable 3D-NoC Systems","  Network-on-Chip (NoC) paradigm has been proposed as an auspicious solution to
handle the strict communication requirements between the increasingly large
number of cores on a single multi and many-core chips. However, NoC systems are
exposed to a variety of manufacturing, design and energetic particles factors
making them vulnerable to permanent (hard) faults and transient (soft) errors.
In this paper, we present a comprehensive soft error and hard fault tolerant
3D-NoC architecture, named 3D-Hard-Fault-Soft-Error-Tolerant-OASIS-NoC
(3D-FETO). With the aid of adaptive algorithms, 3D-FETO is capable of detecting
and recovering from soft errors occurring in the routing pipeline stages and is
leveraging on reconfigurable components to handle permanent faults occurrence
in links, input buffers, and crossbar. In-depth evaluation results show that
the 3D-FETO system is able to work around different kinds of hard faults and
soft errors while ensuring graceful performance degradation, minimizing the
additional hardware complexity and remaining power-efficient.
"
1423,"Reliability Assessment and Quantitative Evaluation of Soft-Error
  Resilient 3D Network-on-Chip Systems","  Three-Dimensional Networks-on-Chips (3D-NoCs) have been proposed as an
auspicious solution, merging the high parallelism of the Network-on-Chip (NoC)
paradigm with the high-performance and low-power cost of 3D-ICs. However, as
technology scales down, the reliability issues are becoming more crucial,
especially for complex 3D-NoC which provides the communication requirements of
multi and many-core systems-on-chip. Reliability assessment is prominent for
early stages of the manufacturing process to prevent costly redesigns of a
target system. In this paper, we present an accurate reliability assessment and
quantitative evaluation of a soft-error resilient 3D-NoC based on a soft-error
resilient mechanism. The system can recover from transient errors occurring in
different pipeline stages of the router. Based on this analysis, the effects of
failures in the network's principal components are determined.
"
1424,"A 75kb SRAM in 65nm CMOS for In-Memory Computing Based Neuromorphic
  Image Denoising","  This paper presents an in-memory computing (IMC) architecture for image
denoising. The proposed SRAM based in-memory processing framework works in
tandem with approximate computing on a binary image generated from neuromorphic
vision sensors. Implemented in TSMC 65nm process, the proposed architecture
enables approximately 2000X energy savings (approximately 222X from IMC)
compared to a digital implementation when tested with the video recordings from
a DAVIS sensor and achieves a peak throughput of 1.25-1.66 frames/us.
"
1425,"A distributed memory, local configuration technique for re-configurable
  logic designs","  The use and location of memory in integrated circuits plays a key factor in
their performance. Memory requires large physical area, access times limit
overall system performance and connectivity can result in large fan-out. Modern
FPGA systems and ASICs contain an area of memory used to set the operation of
the device from a series of commands set by a host. Implementing these settings
registers requires a level of care otherwise the resulting implementation can
result in a number of large fan-out nets that consume valuable resources
complicating the placement of timing critical pathways. This paper presents an
architecture for implementing and programming these settings registers in a
distributed method across an FPGA and how the presented architecture works in
both clock-domain crossing and dynamic partial re-configuration applications.
The design is compared to that of a `global' settings register architecture. We
implement the architectures using Intel FPGAs Quartus Prime software targeting
an Intel FPGA Cyclone V. It is shown that the distributed memory architecture
has a smaller resource cost (as small as 25% of the ALMs and 20% of the
registers) compared to the global memory architectures.
"
1426,Memcomputing for Accelerated Optimization,"  In this work, we introduce the concept of an entirely new circuit
architecture based on the novel, physics-inspired computing paradigm:
Memcomputing. In particular, we focus on digital memcomputing machines (DMMs)
that can be designed leveraging properties of non-linear dynamical systems;
ultimate descriptors of electronic circuits. The working principle of these
systems relies on the ability of currents and voltages of the circuit to
self-organize in order to satisfy mathematical relations. In particular for
this work, we discuss self-organizing gates, namely Self-Organizing Algebraic
Gates (SOAGs), aimed to solve linear inequalities and therefore used to solve
optimization problems in Integer Linear Programming (ILP) format. Unlike
conventional I\O gates, SOAGs are terminal-agnostic, meaning each terminal
handles a superposition of input and output signals. When appropriately
assembled to represent a given ILP problem, the corresponding self-organizing
circuit converges to the equilibria that express the solutions to the problem
at hand. Because DMM's components are non-quantum, the ordinary differential
equations describing it can be efficiently simulated on our modern computers in
software, as well as be built in hardware with off-of-the-shelf technology. As
an example, we show the performance of this novel approach implemented as
Software as a Service (MemCPU XPC) to address an ILP problem. Compared to
today's best solution found using a world renowned commercial solver, MemCPU
XPC brings the time to solution down from 23 hours to less than 2 minutes.
"
1427,"A low-overhead soft-hard fault-tolerant architecture, design and
  management scheme for reliable high-performance many-core 3D-NoC systems","  The Network-on-Chip (NoC) paradigm has been proposed as a favorable solution
to handle the strict communication requirements between the increasingly large
number of cores on a single chip. However, NoC systems are exposed to the
aggressive scaling down of transistors, low operating voltages, and high
integration and power densities, making them vulnerable to permanent (hard)
faults and transient (soft) errors. A hard fault in a NoC can lead to external
blocking, causing congestion across the whole network. A soft error is more
challenging because of its silent data corruption, which leads to a large area
of erroneous data due to error propagation, packet re-transmission, and
deadlock. In this paper, we present the architecture and design of a
comprehensive soft error and hard fault-tolerant 3D-NoC system, named
3D-Hard-Fault-Soft-Error-Tolerant-OASIS-NoC (3D-FETO). With the aid of
efficient mechanisms and algorithms, 3D-FETO is capable of detecting and
recovering from soft errors which occur in the routing pipeline stages and
leverages reconfigurable components to handle permanent faults in links, input
buffers, and crossbars. In-depth evaluation results show that the 3D-FETO
system is able to work around different kinds of hard faults and soft errors,
ensuring graceful performance degradation, while minimizing additional hardware
complexity and remaining power efficient.
"
1428,"Verification and Design Methods for the BrainScaleS Neuromorphic
  Hardware System","  This paper presents verification and implementation methods that have been
developed for the design of the BrainScaleS-2 65nm ASICs. The 2nd generation
BrainScaleS chips are mixed-signal devices with tight coupling between
full-custom analog neuromorphic circuits and two general purpose
microprocessors (PPU) with SIMD extension for on-chip learning and plasticity.
Simulation methods for automated analysis and pre-tapeout calibration of the
highly parameterizable analog neuron and synapse circuits and for
hardware-software co-development of the digital logic and software stack are
presented. Accelerated operation of neuromorphic circuits and highly-parallel
digital data buses between the full-custom neuromorphic part and the PPU
require custom methodologies to close the digital signal timing at the
interfaces. Novel extensions to the standard digital physical implementation
design flow are highlighted. We present early results from the first full-size
BrainScaleS-2 ASIC containing 512 neurons and 130K synapses, demonstrating the
successful application of these methods. An application example illustrates the
full functionality of the BrainScaleS-2 hybrid plasticity architecture.
"
1429,"Enabling Efficient and Flexible FPGA Virtualization for Deep Learning in
  the Cloud","  FPGAs have shown great potential in providing low-latency and
energy-efficient solutions for deep neural network (DNN) inference
applications. Currently, the majority of FPGA-based DNN accelerators in the
cloud run in a time-division multiplexing way for multiple users sharing a
single FPGA, and require re-compilation with $\sim$100 s overhead. Such designs
lead to poor isolation and heavy performance loss for multiple users, which are
far away from providing efficient and flexible FPGA virtualization for neither
public nor private cloud scenarios.
  To solve these problems, we introduce a novel virtualization framework for
instruction architecture set (ISA) based on DNN accelerators by sharing a
single FPGA. We enable the isolation by introducing a two-level instruction
dispatch module and a multi-core based hardware resources pool. Such designs
provide isolated and runtime-programmable hardware resources, further leading
to performance isolation for multiple users. On the other hand, to overcome the
heavy re-compilation overheads, we propose a tiling-based instruction frame
package design and two-stage static-dynamic compilation. Only the light-weight
runtime information is re-compiled with $\sim$1 ms overhead, thus the
performance is guaranteed for the private cloud. Our extensive experimental
results show that the proposed virtualization design achieves 1.07-1.69x and
1.88-3.12x throughput improvement over previous static designs using the
single-core and the multi-core architectures, respectively.
"
1430,Workload-Aware DRAM Error Prediction using Machine Learning,"  The aggressive scaling of technology may have helped to meet the growing
demand for higher memory capacity and density, but has also made DRAM cells
more prone to errors. Such a reality triggered a lot of interest in modeling
DRAM behavior for either predicting the errors in advance or for adjusting DRAM
circuit parameters to achieve a better trade-off between energy efficiency and
reliability. Existing modeling efforts may have studied the impact of few
operating parameters and temperature on DRAM reliability using custom FPGAs
setups, however they neglected the combined effect of workload-specific
features that can be systematically investigated only on a real system. In this
paper, we present the results of our study on workload-dependent DRAM error
behavior within a real server considering various operating parameters, such as
the refresh rate, voltage and temperature. We show that the rate of single- and
multi-bit errors may vary across workloads by 8x, indicating that program
inherent features can affect DRAM reliability significantly. Based on this
observation, we extract 249 features, such as the memory access rate, the rate
of cache misses, the memory reuse time and data entropy, from various
compute-intensive, caching and analytics benchmarks. We apply several
supervised learning methods to construct the DRAM error behavior model for 72
server-grade DRAM chips using the memory operating parameters and extracted
program inherent features. Our results show that, with an appropriate choice of
program features and supervised learning method, the rate of single- and
multi-bit errors can be predicted for a specific DRAM module with an average
error of less than 10.5 %, as opposed to the 2.9x estimation error obtained for
a conventional workload-unaware error model.
"
1431,An Automated Framework for Board-level Trojan Benchmarking,"  Economic and operational advantages have led the supply chain of printed
circuit boards (PCBs) to incorporate various untrusted entities. Any of the
untrusted entities are capable of introducing malicious alterations to
facilitate a functional failure or leakage of secret information during field
operation. While researchers have been investigating the threat of malicious
modification within the scale of individual microelectronic components, the
possibility of a board-level malicious manipulation has essentially been
unexplored. In the absence of standard benchmarking solutions, prospective
countermeasures for PCB trust assurance are likely to utilize homegrown
representation of the attacks that undermines their evaluation and does not
provide scope for comparison with other techniques. In this paper, we have
developed the first-ever benchmarking solution to facilitate an unbiased and
comparable evaluation of countermeasures applicable to PCB trust assurance.
Based on a taxonomy tailored for PCB-level alterations, we have developed
high-level Trojan models. From these models, we have generated a custom pool of
board-level Trojan designs of varied complexity and functionality. We have also
developed a tool-flow for automatically inserting these Trojans into various
PCB designs and generate the Trojan benchmarks (i.e., PCB designs with Trojan).
The tool-based Trojan insertion facilitate a comprehensive evaluation against
large number of diverse Trojan implementations and application of data mining
for trust verification. Finally, with experimental measurements from a
fabricated PCB, we analyze the stealthiness of the Trojan designs.
"
1432,"Analytical Model of Memory-Bound Applications Compiled with High Level
  Synthesis","  The increasing demand of dedicated accelerators to improve energy efficiency
and performance has highlighted FPGAs as a promising option to deliver both.
However, programming FPGAs in hardware description languages requires long time
and effort to achieve optimal results, which discourages many programmers from
adopting this technology.
  High Level Synthesis tools improve the accessibility to FPGAs, but the
optimization process is still time expensive due to the large compilation time,
between minutes and days, required to generate a single bitstream. Whereas
placing and routing take most of this time, the RTL pipeline and memory
organization are known in seconds. This early information about the
organization of the upcoming bitstream is enough to provide an accurate and
fast performance model.
  This paper presents a performance analytical model for HLS designs focused on
memory bound applications. With a careful analysis of the generated memory
architecture and DRAM organization, the model predicts the execution time with
a maximum error of 9.2% for a set of representative applications. Compared with
previous works, our predictions reduce on average at least $2\times$ the
estimation error.
"
1433,"Efficient Implementation of Multi-Channel Convolution in Monolithic 3D
  ReRAM Crossbar","  Convolutional neural networks (CNNs) demonstrate promising accuracy in a wide
range of applications. Among all layers in CNNs, convolution layers are the
most computation-intensive and consume the most energy. As the maturity of
device and fabrication technology, 3D resistive random access memory (ReRAM)
receives substantial attention for accelerating large vector-matrix
multiplication and convolution due to its high parallelism and energy
efficiency benefits. However, implementing multi-channel convolution naively in
3D ReRAM will either produce incorrect results or exploit only partial
parallelism of 3D ReRAM. In this paper, we propose a 3D ReRAM-based convolution
accelerator architecture, which efficiently maps multi-channel convolution to
monolithic 3D ReRAM. Our design has two key principles. First, we exploit the
intertwined structure of 3D ReRAM to implement multi-channel convolution by
using a state-of-the-art convolution algorithm. Second, we propose a new
approach to efficiently implement negative weights by separating them from
non-negative weights using configurable interconnects. Our evaluation
demonstrates that our mapping scheme in 16-layer 3D ReRAM achieves a speedup of
5.79X, 927.81X, and 36.8X compared with a custom 2D ReRAM baseline and
state-of-the-art CPU and GPU. Our design also reduces energy consumption by
2.12X, 1802.64X, and 114.1X compared with the same baseline.
"
1434,Hardware Trojan with Frequency Modulation,"  The use of third-party IP cores in implementing applications in FPGAs has
given rise to the threat of malicious alterations through the insertion of
hardware Trojans. To address this threat, it is important to predict the way
hardware Trojans are built and to identify their weaknesses. This paper
describes a logic family for implementing robust hardware Trojans, which can
evade the two major detection methods, namely unused-circuit identification and
side-channel analysis. This robustness is achieved by encoding information in
frequency rather than amplitude so that the Trojan trigger circuitry's state
will never stay constant during 'normal' operation. In addition, the power
consumption of Trojan circuits built using the proposed logic family can be
concealed with minimal design effort and supplementary hardware resources.
Defense measures against hardware Trojans with frequency modulation are
described.
"
1435,High Bandwidth Memory on FPGAs: A Data Analytics Perspective,"  FPGA-based data processing in datacenters is increasing in popularity due to
the demands of modern workloads and the ensuing necessity for specialization in
hardware. Driven by this trend, vendors are rapidly adapting reconfigurable
devices to suit data and compute intensive workloads. Inclusion of High
Bandwidth Memory (HBM) in FPGA devices is a recent example. HBM promises
overcoming the bandwidth bottleneck, faced often by FPGA-based accelerators due
to their throughput oriented design. In this paper, we study the usage and
benefits of HBM on FPGAs from a data analytics perspective. We consider three
workloads that are often performed in analytics oriented databases and
implement them on FPGA showing in which cases they benefit from HBM: range
selection, hash join, and stochastic gradient descent for linear model
training. We integrate our designs into a columnar database (MonetDB) and show
the trade-offs arising from the integration related to data movement and
partitioning. In certain cases, FPGA+HBM based solutions are able to surpass
the highest performance provided by either a 2-socket POWER9 system or a
14-core XeonE5 by up to 1.8x (selection), 12.9x (join), and 3.2x (SGD).
"
1436,"Near-chip Dynamic Vision Filtering for Low-Bandwidth Pedestrian
  Detection","  This paper presents a novel end-to-end system for pedestrian detection using
Dynamic Vision Sensors (DVSs). We target applications where multiple sensors
transmit data to a local processing unit, which executes a detection algorithm.
Our system is composed of (i) a near-chip event filter that compresses and
denoises the event stream from the DVS, and (ii) a Binary Neural Network (BNN)
detection module that runs on a low-computation edge computing device (in our
case a STM32F4 microcontroller). We present the system architecture and provide
an end-to-end implementation for pedestrian detection in an office environment.
Our implementation reduces transmission size by up to 99.6% compared to
transmitting the raw event stream. The average packet size in our system is
only 1397 bits, while 307.2 kb are required to send an uncompressed DVS time
window. Our detector is able to perform a detection every 450 ms, with an
overall testing F1 score of 83%. The low bandwidth and energy properties of our
system make it ideal for IoT applications.
"
1437,RAPPER: Ransomware Prevention via Performance Counters,"  Ransomware can produce direct and controllable economic loss, which makes it
one of the most prominent threats in cyber security. As per the latest
statistics, more than half of malwares reported in Q1 of 2017 are ransomwares
and there is a potent threat of a novice cybercriminals accessing
ransomware-as-a-service. The concept of public-key based data kidnapping and
subsequent extortion was introduced in 1996. Since then, variants of ransomware
emerged with different cryptosystems and larger key sizes, the underlying
techniques remained same. Though there are works in literature which proposes a
generic framework to detect the crypto ransomwares, we present a two step
unsupervised detection tool which when suspects a process activity to be
malicious, issues an alarm for further analysis to be carried in the second
step and detects it with minimal traces. The two step detection framework-
RAPPER uses Artificial Neural Network and Fast Fourier Transformation to
develop a highly accurate, fast and reliable solution to ransomware detection
using minimal trace points. We also introduce a special detection module for
successful identification of disk encryption processes from potential
ransomware operations, both having similar characteristics but with different
objective. We provide a comprehensive solution to tackle almost all scenarios
(standard benchmark, disk encryption and regular high computational processes)
pertaining to the crypto ransomwares in light of software security.
"
1438,"S4oC: A Self-optimizing, Self-adapting Secure System-on-Chip Design
  Framework to Tackle Unknown Threats -- A Network Theoretic, Learning Approach","  We propose a framework for the design and optimization of a secure
self-optimizing, self-adapting system-on-chip (S4oC) architecture. The goal is
to minimize the impact of attacks such as hardware Trojan and side-channel, by
making real-time adjustments. S4oC learns to reconfigure itself, subject to
various security measures and attacks, some of which possibly unknown at design
time. Furthermore, the data types and patterns of the target applications,
environmental conditions, and sources of variations are incorporated. S4oC is a
manycore system, modeled as a four-layer graph, representing the model of
computation (MoCp), model of connection (MoCn), model of memory (MoM) and model
of storage (MoS), with a large number of elements including heterogeneous
reconfigurable processing elements in MoCp, and memory elements in the MoM
layer. Security driven community detection, and neural networks are utilized
for application task clustering, and distributed reinforcement learning (RL)
for task mapping.
"
1439,DRAMDig: A Knowledge-assisted Tool to Uncover DRAM Address Mapping,"  As recently emerged rowhammer exploits require undocumented DRAM address
mapping, we propose a generic knowledge-assisted tool, DRAMDig, which takes
domain knowledge into consideration to efficiently and deterministically
uncover the DRAM address mappings on any Intel-based machines. We test DRAMDig
on a number of machines with different combinations of DRAM chips and
microarchitectures ranging from Intel Sandy Bridge to Coffee Lake. Comparing to
previous works, DRAMDig deterministically reverse-engineered DRAM address
mappings on all the test machines with only 7.8 minutes on average. Based on
the uncovered mappings, we perform double-sided rowhammer tests and the results
show that DRAMDig induced significantly more bit flips than previous works,
justifying the correctness of the uncovered DRAM address mappings.
"
1440,Hardware Trojan Detection Using Controlled Circuit Aging,"  This paper reports a novel approach that uses transistor aging in an
integrated circuit (IC) to detect hardware Trojans. When a transistor is aged,
it results in delays along several paths of the IC. This increase in delay
results in timing violations that reveal as timing errors at the output of the
IC during its operation. We present experiments using aging-aware standard cell
libraries to illustrate the usefulness of the technique in detecting hardware
Trojans. Combining IC aging with over-clocking produces a pattern of bit errors
at the IC output by the induced timing violations. We use machine learning to
learn the bit error distribution at the output of a clean IC. We differentiate
the divergence in the pattern of bit errors because of a Trojan in the IC from
this baseline distribution. We simulate the golden IC and show robustness to
IC-to-IC manufacturing variations. The approach is effective and can detect a
Trojan even if we place it far off the critical paths. Results on benchmarks
from the Trust-hub show a detection accuracy of $\geq$99%.
"
1441,"LogicNets: Co-Designed Neural Networks and Circuits for
  Extreme-Throughput Applications","  Deployment of deep neural networks for applications that require very high
throughput or extremely low latency is a severe computational challenge,
further exacerbated by inefficiencies in mapping the computation to hardware.
We present a novel method for designing neural network topologies that directly
map to a highly efficient FPGA implementation. By exploiting the equivalence of
artificial neurons with quantized inputs/outputs and truth tables, we can train
quantized neural networks that can be directly converted to a netlist of truth
tables, and subsequently deployed as a highly pipelinable, massively parallel
FPGA circuit. However, the neural network topology requires careful
consideration since the hardware cost of truth tables grows exponentially with
neuron fan-in. To obtain smaller networks where the whole netlist can be
placed-and-routed onto a single FPGA, we derive a fan-in driven hardware cost
model to guide topology design, and combine high sparsity with low-bit
activation quantization to limit the neuron fan-in. We evaluate our approach on
two tasks with very high intrinsic throughput requirements in high-energy
physics and network intrusion detection. We show that the combination of
sparsity and low-bit activation quantization results in high-speed circuits
with small logic depth and low LUT cost, demonstrating competitive accuracy
with less than 15 ns of inference latency and throughput in the hundreds of
millions of inferences per second.
"
1442,"SoftWear: Software-Only In-Memory Wear-Leveling for Non-Volatile Main
  Memory","  Several emerging technologies for byte-addressable non-volatile memory (NVM)
have been considered to replace DRAM as the main memory in computer systems
during the last years. The disadvantage of a lower write endurance, compared to
DRAM, of NVM technologies like Phase-Change Memory (PCM) or Ferroelectric RAM
(FeRAM) has been addressed in the literature. As a solution, in-memory
wear-leveling techniques have been proposed, which aim to balance the
wear-level over all memory cells to achieve an increased memory lifetime.
Generally, to apply such advanced aging-aware wear-leveling techniques proposed
in the literature, additional special hardware is introduced into the memory
system to provide the necessary information about the cell age and thus enable
aging-aware wear-leveling decisions.
  This paper proposes software-only aging-aware wear-leveling based on common
CPU features and does not rely on any additional hardware support from the
memory subsystem. Specifically, we exploit the memory management unit (MMU),
performance counters, and interrupts to approximate the memory write counts as
an aging indicator. Although the software-only approach may lead to slightly
worse wear-leveling, it is applicable on commonly available hardware. We
achieve page-level coarse-grained wear-leveling by approximating the current
cell age through statistical sampling and performing physical memory remapping
through the MMU. This method results in non-uniform memory usage patterns
within a memory page. Hence, we further propose a fine-grained wear-leveling in
the stack region of C / C++ compiled software.
  By applying both wear-leveling techniques, we achieve up to $78.43\%$ of the
ideal memory lifetime, which is a lifetime improvement of more than a factor of
$900$ compared to the lifetime without any wear-leveling.
"
1443,"ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine
  Learning","  We present ESP4ML, an open-source system-level design flow to build and
program SoC architectures for embedded applications that require the hardware
acceleration of machine learning and signal processing algorithms. We realized
ESP4ML by combining two established open-source projects (ESP and HLS4ML) into
a new, fully-automated design flow. For the SoC integration of accelerators
generated by HLS4ML, we designed a set of new parameterized interface circuits
synthesizable with high-level synthesis. For accelerator configuration and
management, we developed an embedded software runtime system on top of Linux.
With this HW/SW layer, we addressed the challenge of dynamically shaping the
data traffic on a network-on-chip to activate and support the reconfigurable
pipelines of accelerators that are needed by the application workloads
currently running on the SoC. We demonstrate our vertically-integrated
contributions with the FPGA-based implementations of complete SoC instances
booting Linux and executing computer-vision applications that process images
taken from the Google Street View database.
"
1444,Compiling Spiking Neural Networks to Neuromorphic Hardware,"  Machine learning applications that are implemented with spike-based
computation model, e.g., Spiking Neural Network (SNN), have a great potential
to lower the energy consumption when they are executed on a neuromorphic
hardware. However, compiling and mapping an SNN to the hardware is challenging,
especially when compute and storage resources of the hardware (viz. crossbar)
need to be shared among the neurons and synapses of the SNN. We propose an
approach to analyze and compile SNNs on a resource-constrained neuromorphic
hardware, providing guarantee on key performance metrics such as execution time
and throughput. Our approach makes the following three key contributions.
First, we propose a greedy technique to partition an SNN into clusters of
neurons and synapses such that each cluster can fit on to the resources of a
crossbar. Second, we exploit the rich semantics and expressiveness of
Synchronous Dataflow Graphs (SDFGs) to represent a clustered SNN and analyze
its performance using Max-Plus Algebra, considering the available compute and
storage capacities, buffer sizes, and communication bandwidth. Third, we
propose a self-timed execution-based fast technique to compile and admit
SNN-based applications to a neuromorphic hardware at run-time, adapting
dynamically to the available resources on the hardware. We evaluate our
approach with standard SNN-based applications and demonstrate a significant
performance improvement compared to current practices.
"
1445,"HybridDNN: A Framework for High-Performance Hybrid DNN Accelerator
  Design and Implementation","  To speedup Deep Neural Networks (DNN) accelerator design and enable effective
implementation, we propose HybridDNN, a framework for building high-performance
hybrid DNN accelerators and delivering FPGA-based hardware implementations.
Novel techniques include a highly flexible and scalable architecture with a
hybrid Spatial/Winograd convolution (CONV) Processing Engine (PE), a
comprehensive design space exploration tool, and a complete design flow to
fully support accelerator design and implementation. Experimental results show
that the accelerators generated by HybridDNN can deliver 3375.7 and 83.3 GOPS
on a high-end FPGA (VU9P) and an embedded FPGA (PYNQ-Z1), respectively, which
achieve a 1.8x higher performance improvement compared to the state-of-art
accelerator designs. This demonstrates that HybridDNN is flexible and scalable
and can target both cloud and embedded hardware platforms with vastly different
resource constraints.
"
1446,"A Survey on Coarse-Grained Reconfigurable Architectures from a
  Performance Perspective","  With the end of both Dennard's scaling and Moore's law, computer users and
researchers are aggressively exploring alternative forms of computing in order
to continue the performance scaling that we have come to enjoy. Among the more
salient and practical of the post-Moore alternatives are reconfigurable
systems, with Coarse-Grained Reconfigurable Architectures (CGRAs) seemingly
capable of striking a balance between performance and programmability. In this
paper, we survey the landscape of CGRAs. We summarize nearly three decades of
literature on the subject, with a particular focus on the premise behind the
different CGRAs and how they have evolved. Next, we compile metrics of
available CGRAs and analyze their performance properties in order to understand
and discover knowledge gaps and opportunities for future CGRA research
specialized towards High-Performance Computing (HPC). We find that there are
ample opportunities for future research on CGRAs, in particular with respect to
size, functionality, support for parallel programming models, and to evaluate
more complex applications.
"
1447,Predictable Accelerator Design with Time-Sensitive Affine Types,"  Field-programmable gate arrays (FPGAs) provide an opportunity to co-design
applications with hardware accelerators, yet they remain difficult to program.
High-level synthesis (HLS) tools promise to raise the level of abstraction by
compiling C or C++ to accelerator designs. Repurposing legacy software
languages, however, requires complex heuristics to map imperative code onto
hardware structures. We find that the black-box heuristics in HLS can be
unpredictable: changing parameters in the program that should improve
performance can counterintuitively yield slower and larger designs. This paper
proposes a type system that restricts HLS to programs that can predictably
compile to hardware accelerators. The key idea is to model consumable hardware
resources with a time-sensitive affine type system that prevents simultaneous
uses of the same hardware structure. We implement the type system in Dahlia, a
language that compiles to HLS C++, and show that it can reduce the size of HLS
parameter spaces while accepting Pareto-optimal designs.
"
1448,"SMART Paths for Latency Reduction in ReRAM Processing-In-Memory
  Architecture for CNN Inference","  This research work proposes a design of an analog ReRAM-based PIM
(processing-in-memory) architecture for fast and efficient CNN (convolutional
neural network) inference. For the overall architecture, we use the basic
hardware hierarchy such as node, tile, core, and subarray. On the top of that,
we design intra-layer pipelining, inter-layer pipelining, and batch pipelining
to exploit parallelism in the architecture and increase overall throughput for
the inference of an input image stream. We also optimize the performance of the
NoC (network-on-chip) routers by decreasing hop counts using SMART
(single-cycle multi-hop asynchronous repeated traversal) flow control. Finally,
we experiment with weight replications for different CNN layers in VGG (A-E)
for large-scale data set ImageNet. In our simulation, we achieve 40.4027 TOPS
(tera-operations per second) for the best-case performance, which corresponds
to over 1029 FPS (frames per second). We also achieve 3.5914 TOPS/W
(tera-operaions per second per watt) for the best-case energy efficiency. In
addition, the architecture with aggressive pipelining and weight replications
can achieve 14X speedup compared to the baseline architecture with basic
pipelining, and SMART flow control achieves 1.08X speedup in this architecture
compared to the baseline. Last but not least, we also evaluate the performance
of SMART flow control using synthetic traffic.
"
1449,Hardware Memory Management for Future Mobile Hybrid Memory Systems,"  The current mobile applications have rapidly growing memory footprints,
posing a great challenge for memory system design. Insufficient DRAM main
memory will incur frequent data swaps between memory and storage, a process
that hurts performance, consumes energy and deteriorates the write endurance of
typical flash storage devices. Alternately, a larger DRAM has higher leakage
power and drains the battery faster. Further, DRAM scaling trends make further
growth of DRAMin the mobile space prohibitive due to cost. Emerging
non-volatile memory (NVM) has the potential to alleviate these issues due to
its higher capacity per cost than DRAM and mini-mal static power. Recently, a
wide spectrum of NVM technologies, including phase-change memories (PCM),
memristor, and 3D XPoint have emerged. Despite the mentioned advantages, NVM
has longer access latency compared to DRAMand NVM writes can incur higher
latencies and wear costs. Therefore integration of these new memory
technologies in the memory hierarchy requires a fundamental rearchitect-ing of
traditional system designs. In this work, we propose a hardware-accelerated
memory manager (HMMU) that addresses both types of memory in a flat space
address space. We design a set of data placement and data migration policies
within this memory manager, such that we may exploit the advantages of each
memory technology. By augmenting the system with this HMMU, we reduce the
overall memory latency while also reducing writes to the NVM. Experimental
results show that our design achieves a 39% reduction in energy consumption
with only a 12% performance degradation versus an all-DRAM baseline that is
likely untenable in the future.
"
1450,FPGA Based Emulation Environment for Neuromorphic Architectures,"  Neuromorphic architectures such as IBM's TrueNorth and Intel's Loihi have
been introduced as platforms for energy efficient spiking neural network
execution. However, there is no framework that allows for rapidly experimenting
with neuromorphic architectures and studying the trade space on hardware
performance and network accuracy. Fundamentally, this creates a barrier to
entry for hardware designers looking to explore neuromorphic architectures. In
this paper we present an open-source FPGA based emulation environment for
neuromorphic computing research. We prototype IBM's TrueNorth architecture as a
reference design and discuss FPGA specific design decisions made when
implementing and integrating it's core components. We conduct resource
utilization analysis and realize a streaming-enabled TrueNorth architecture on
the Zynq UltraScale+ MPSoC. We then perform functional verification by
implementing networks for MNIST dataset and vector matrix multiplication (VMM)
in our emulation environment and present an accuracy-based comparison based on
the same networks generated using IBM's Compass simulation environment. We
demonstrate the utility of our emulation environment for hardware designers and
application engineers by altering the neuron behavior for VMM mapping, which
is, to the best of our knowledge, not feasible with any other tool including
IBM's Compass environment. The proposed parameterized and configurable
emulation platform serves as a basis for expanding its features to support
emerging architectures, studying hypothetical neuromorphic architectures, or
rapidly converging to hardware configuration through incremental changes based
on bottlenecks as they become apparent during application mapping process.
"
1451,"Energy-Efficient Hardware-Accelerated Synchronization for
  Shared-L1-Memory Multiprocessor Clusters","  The steeply growing performance demands for highly power- and
energy-constrained processing systems such as end-nodes of the
internet-of-things (IoT) have led to parallel near-threshold computing (NTC),
joining the energy-efficiency benefits of low-voltage operation with the
performance typical of parallel systems. Shared-L1-memory multiprocessor
clusters are a promising architecture, delivering performance in the order of
GOPS and over 100 GOPS/W of energy-efficiency. However, this level of
computational efficiency can only be reached by maximizing the effective
utilization of the processing elements (PEs) available in the clusters. Along
with this effort, the optimization of PE-to-PE synchronization and
communication is a critical factor for performance. In this work, we describe a
light-weight hardware-accelerated synchronization and communication unit (SCU)
for tightly-coupled clusters of processors. We detail the architecture, which
enables fine-grain per-PE power management, and its integration into an
eight-core cluster of RISC-V processors. To validate the effectiveness of the
proposed solution, we implemented the eight-core cluster in advanced 22nm FDX
technology and evaluated performance and energy-efficiency with tunable
microbenchmarks and a set of real-life applications and kernels. The proposed
solution allows synchronization-free regions as small as 42 cycles, over 41
times smaller than the baseline implementation based on fast test-and-set
access to L1 memory when constraining the microbenchmarks to 10%
synchronization overhead. When evaluated on the real-life DSP-applications, the
proposed SCU improves performance by up to 92% and 23% on average and energy
efficiency by up to 98% and 39% on average.
"
1452,The MosaicSim Simulator (Full Technical Report),"  As Moore's Law has slowed and Dennard Scaling has ended, architects are
increasingly turning to heterogeneous parallelism and domain-specific
hardware-software co-designs. These trends present new challenges for
simulation-based performance assessments that are central to early-stage
architectural exploration. Simulators must be lightweight to support rich
heterogeneous combinations of general purpose cores and specialized processing
units. They must also support agile exploration of hardware-software co-design,
i.e. changes in the programming model, compiler, ISA, and specialized hardware.
  To meet these challenges, we introduce MosaicSim, a lightweight, modular
simulator for heterogeneous systems, offering accuracy and agility designed
specifically for hardware-software co-design explorations. By integrating the
LLVM toolchain, MosaicSim enables efficient modeling of instruction
dependencies and flexible additions across the stack. Its modularity also
allows the composition and integration of different hardware components. We
first demonstrate that MosaicSim captures architectural bottlenecks in
applications, and accurately models both scaling trends in a multicore setting
and accelerator behavior. We then present two case-studies where MosaicSim
enables straightforward design space explorations for emerging systems, i.e.
data science application acceleration and heterogeneous parallel architectures.
"
1453,Bridging the Gap: FPGAs as Programmable Switches,"  The emergence of P4, a domain specific language, coupled to PISA, a domain
specific architecture, is revolutionizing the networking field. P4 allows to
describe how packets are processed by a programmable data plane, spanning ASICs
and CPUs, implementing PISA. Because the processing flexibility can be limited
on ASICs, while the CPUs performance for networking tasks lag behind, recent
works have proposed to implement PISA on FPGAs. However, little effort has been
dedicated to analyze whether FPGAs are good candidates to implement PISA. In
this work, we take a step back and evaluate the micro-architecture efficiency
of various PISA blocks. We demonstrate, supported by a theoretical and
experimental analysis, that the performance of a few PISA blocks is severely
limited by the current FPGA architectures. Specifically, we show that match
tables and programmable packet schedulers represent the main performance
bottlenecks for FPGA-based programmable switches. Thus, we explore two avenues
to alleviate these shortcomings. First, we identify network applications well
tailored to current FPGAs. Second, to support a wider range of networking
applications, we propose modifications to the FPGA architectures which can also
be of interest out of the networking field.
"
1454,HCM: Hardware-Aware Complexity Metric for Neural Network Architectures,"  Convolutional Neural Networks (CNNs) have become common in many fields
including computer vision, speech recognition, and natural language processing.
Although CNN hardware accelerators are already included as part of many SoC
architectures, the task of achieving high accuracy on resource-restricted
devices is still considered challenging, mainly due to the vast number of
design parameters that need to be balanced to achieve an efficient solution.
Quantization techniques, when applied to the network parameters, lead to a
reduction of power and area and may also change the ratio between communication
and computation. As a result, some algorithmic solutions may suffer from lack
of memory bandwidth or computational resources and fail to achieve the expected
performance due to hardware constraints. Thus, the system designer and the
micro-architect need to understand at early development stages the impact of
their high-level decisions (e.g., the architecture of the CNN and the amount of
bits used to represent its parameters) on the final product (e.g., the expected
power saving, area, and accuracy). Unfortunately, existing tools fall short of
supporting such decisions.
  This paper introduces a hardware-aware complexity metric that aims to assist
the system designer of the neural network architectures, through the entire
project lifetime (especially at its early stages) by predicting the impact of
architectural and micro-architectural decisions on the final product. We
demonstrate how the proposed metric can help evaluate different design
alternatives of neural network models on resource-restricted devices such as
real-time embedded systems, and to avoid making design mistakes at early
stages.
"
1455,"Non-Blocking Simultaneous Multithreading: Embracing the Resiliency of
  Deep Neural Networks","  Deep neural networks (DNNs) are known for their inability to utilize
underlying hardware resources due to hardware susceptibility to sparse
activations and weights. Even in finer granularities, many of the non-zero
values hold a portion of zero-valued bits that may cause inefficiencies when
executed on hardware. Inspired by conventional CPU simultaneous multithreading
(SMT) that increases computer resource utilization by sharing them across
several threads, we propose non-blocking SMT (NB-SMT) designated for DNN
accelerators. Like conventional SMT, NB-SMT shares hardware resources among
several execution flows. Yet, unlike SMT, NB-SMT is non-blocking, as it handles
structural hazards by exploiting the algorithmic resiliency of DNNs. Instead of
opportunistically dispatching instructions while they wait in a reservation
station for available hardware, NB-SMT temporarily reduces the computation
precision to accommodate all threads at once, enabling a non-blocking
operation. We demonstrate NB-SMT applicability using SySMT, an NB-SMT-enabled
output-stationary systolic array (OS-SA). Compared with a conventional OS-SA, a
2-threaded SySMT consumes 1.4x the area and delivers 2x speedup with 33% energy
savings and less than 1% accuracy degradation of state-of-the-art CNNs with
ImageNet. A 4-threaded SySMT consumes 2.5x the area and delivers, for example,
3.4x speedup and 39% energy savings with 1% accuracy degradation of 40%-pruned
ResNet-18.
"
1456,Secure Boot from Non-Volatile Memory for Programmable SoC Architectures,"  In modern embedded systems, the trust in comprehensive security standards all
along the product life cycle has become an increasingly important
access-to-market requirement. However, these security standards rely on
mandatory immunity assumptions such as the integrity and authenticity of an
initial system configuration typically loaded from Non-Volatile Memory (NVM).
This applies especially to FPGA-based Programmable System-on-Chip (PSoC)
architectures, since object codes as well as configuration data easily exceed
the capacity of a secure bootROM. In this context, an attacker could try to
alter the content of the NVM device in order to manipulate the system. The PSoC
therefore relies on the integrity of the NVM particularly at boot-time. In this
paper, we propose a methodology for securely booting from an NVM in a
potentially unsecure environment by exploiting the reconfigurable logic of the
FPGA. Here, the FPGA serves as a secure anchor point by performing required
integrity and authenticity verifications prior to the configuration and
execution of any user application loaded from the NVM on the PSoC. The proposed
secure boot process is based on the following assumptions and steps: 1) The
boot configurationis stored on a fully encrypted Secure Digital memory card (SD
card) or alternatively Flash acting as NVM. 2) At boot time, a hardware design
called Trusted Memory-Interface Unit (TMIU) is loaded to verify first the
authenticity of the deployed NVM and then after decryption the integrity of its
content. To demonstrate the practicability of our approach, we integrated the
methodology into the vendor-specific secure boot process of a Xilinx Zynq PSoC
and evaluated the design objectives performance, power and resource costs.
"
1457,"MgX: Near-Zero Overhead Memory Protection with an Application to Secure
  DNN Acceleration","  In this paper, we propose MgX, a near-zero overhead memory protection scheme
for hardware accelerators. MgX minimizes the performance overhead of off-chip
memory encryption and integrity verification by exploiting the
application-specific aspect of accelerators. Accelerators tend to explicitly
manage data movement between on-chip and off-chip memory, typically at an
object granularity that is much larger than cache lines. Exploiting these
accelerator-specific characteristics, MgX generates version numbers used in
memory encryption and integrity verification only using on-chip state without
storing them in memory, and also customizes the granularity of the memory
protection to match the granularity used by the accelerator. To demonstrate the
applicability of MgX, we present an in-depth study of MgX for deep neural
network (DNN) and also describe implementations for H.264 video decoding and
genome alignment. Experimental results show that applying MgX has less than 1%
performance overhead for both DNN inference and training on state-of-the-art
DNN architectures.
"
1458,Towards a Hardware DSL Ecosystem : RubyRTL and Friends,"  For several years, hardware design has been undergoing a surprising revival:
fueled by open source initiatives, various tools and architectures have
recently emerged. This resurgence also involves new hardware description
languages. Inspired by the Migen Python community, we present RubyRTL, a novel
internal domain-specific language for hardware design embedded in the Ruby
language. Ruby -- which is best known in the field of web design -- has proven
to be an excellent solution for the design of such DSLs, because of its
meta-programming features. This paper presents the main aspects of RubyRTL,
along with illustrating examples. We also propose a language-neutral
interchange format, named Sexpir, that allows to seamlessly exchange RTL
designs between Migen Python DSL and RubyRTL. This paves the way for
interactions between various agile communities in the field of open source
hardware design.
"
1459,"NOM: Network-On-Memory for Inter-Bank Data Transfer in Highly-Banked
  Memories","  Data copy is a widely-used memory operation in many programs and operating
system services. In conventional computers, data copy is often carried out by
two separate read and write transactions that pass data back and forth between
the DRAM chip and the processor chip. Some prior mechanisms propose to avoid
this unnecessary data movement by using the shared internal bus in the DRAM
chip to directly copy data within the DRAM chip (e.g., between two DRAM banks).
While these methods exhibit superior performance compared to conventional
techniques, data copy across different DRAM banks is still greatly slower than
data copy within the same DRAM bank. Hence, these techniques have limited
benefit for the emerging 3D-stacked memories (e.g., HMC and HBM) that contain
hundreds of DRAM banks across multiple memory controllers. In this paper, we
present Network-on-Memory (NoM), a lightweight inter-bank data communication
scheme that enables direct data copy across both memory banks of a 3D-stacked
memory. NoM adopts a TDM-based circuit-switching design, where circuit setup is
done by the memory controller. Compared to state-of-the-art approaches, NoM
enables both fast data copy between multiple DRAM banks and concurrent data
transfer operations. Our evaluation shows that NoM improves the performance of
data-intensive workloads by 3.8X and 75%, on average, compared to the baseline
conventional 3D-stacked DRAM architecture and state-of-the-art techniques,
respectively.
"
1460,"PMEvo: Portable Inference of Port Mappings for Out-of-Order Processors
  by Evolutionary Optimization","  Achieving peak performance in a computer system requires optimizations in
every layer of the system, be it hardware or software. A detailed understanding
of the underlying hardware, and especially the processor, is crucial to
optimize software. One key criterion for the performance of a processor is its
ability to exploit instruction-level parallelism. This ability is determined by
the port mapping of the processor, which describes the execution units of the
processor for each instruction.
  Processor manufacturers usually do not share the port mappings of their
microarchitectures. While approaches to automatically infer port mappings from
experiments exist, they are based on processor-specific hardware performance
counters that are not available on every platform.
  We present PMEvo, a framework to automatically infer port mappings solely
based on the measurement of the execution time of short instruction sequences.
PMEvo uses an evolutionary algorithm that evaluates the fitness of candidate
mappings with an analytical throughput model formulated as a linear program.
Our prototype implementation infers a port mapping for Intel's Skylake
architecture that predicts measured instruction throughput with an accuracy
that is competitive to existing work. Furthermore, it finds port mappings for
AMD's Zen+ architecture and the ARM Cortex-A72 architecture, which are out of
scope of existing techniques.
"
1461,"DRMap: A Generic DRAM Data Mapping Policy for Energy-Efficient
  Processing of Convolutional Neural Networks","  Many convolutional neural network (CNN) accelerators face performance- and
energy-efficiency challenges which are crucial for embedded implementations,
due to high DRAM access latency and energy. Recently, some DRAM architectures
have been proposed to exploit subarray-level parallelism for decreasing the
access latency. Towards this, we present a design space exploration methodology
to study the latency and energy of different mapping policies on different DRAM
architectures, and identify the pareto-optimal design choices. The results show
that the energy-efficient DRAM accesses can be achieved by a mapping policy
that orderly prioritizes to maximize the row buffer hits, bank- and
subarray-level parallelism.
"
1462,Proactive Aging Mitigation in CGRAs through Utilization-Aware Allocation,"  Resource balancing has been effectively used to mitigate the long-term aging
effects of Negative Bias Temperature Instability (NBTI) in multi-core and
Graphics Processing Unit (GPU) architectures. In this work, we investigate this
strategy in Coarse-Grained Reconfigurable Arrays (CGRAs) with a novel
application-to-CGRA allocation approach. By introducing important extensions to
the reconfiguration logic and the datapath, we enable the dynamic movement of
configurations throughout the fabric and allow overutilized Functional Units
(FUs) to recover from stress-induced NBTI aging. Implementing the approach in a
resource-constrained state-of-the-art CGRA reveals $2.2\times$ lifetime
improvement with negligible performance overheads and less than $10\%$ increase
in area.
"
1463,"Using Libraries of Approximate Circuits in Design of Hardware
  Accelerators of Deep Neural Networks","  Approximate circuits have been developed to provide good tradeoffs between
power consumption and quality of service in error resilient applications such
as hardware accelerators of deep neural networks (DNN). In order to accelerate
the approximate circuit design process and to support a fair benchmarking of
circuit approximation methods, libraries of approximate circuits have been
introduced. For example, EvoApprox8b contains hundreds of 8-bit approximate
adders and multipliers. By means of genetic programming we generated an
extended version of the library in which thousands of 8- to 128-bit approximate
arithmetic circuits are included. These circuits form Pareto fronts with
respect to several error metrics, power consumption and other circuit
parameters. In our case study we show how a large set of approximate
multipliers can be used to perform a resilience analysis of a hardware
accelerator of ResNet DNN and to select the most suitable approximate
multiplier for a given application. Results are reported for various instances
of the ResNet DNN trained on CIFAR-10 benchmark problem.
"
1464,"ApproxFPGAs: Embracing ASIC-Based Approximate Arithmetic Components for
  FPGA-Based Systems","  There has been abundant research on the development of Approximate Circuits
(ACs) for ASICs. However, previous studies have illustrated that ASIC-based ACs
offer asymmetrical gains in FPGA-based accelerators. Therefore, an AC that
might be pareto-optimal for ASICs might not be pareto-optimal for FPGAs. In
this work, we present the ApproxFPGAs methodology that uses machine learning
models to reduce the exploration time for analyzing the state-of-the-art
ASIC-based ACs to determine the set of pareto-optimal FPGA-based ACs. We also
perform a case-study to illustrate the benefits obtained by deploying these
pareto-optimal FPGA-based ACs in a state-of-the-art automation framework to
systematically generate pareto-optimal approximate accelerators that can be
deployed in FPGA-based systems to achieve high performance or low-power
consumption.
"
1465,"Speeding-up Logic Design and Refining Hardware EDA Flow by Exploring
  Chinese Character based Graphical Representation","  Electrical design automation (EDA) techniques have deeply influenced the
computer hardware design, especially in the field of very large scale
Integration (VLSI) circuits. Particularly, the popularity of FPGA, ASIC and SOC
applications have been dramatically increased due to the well developed EDA
tool chains. Over decades, improving EDA tool in terms of functionality,
efficiency, accuracy and intelligence is not only the academic research hot
spot, but the industry attempting goal as well.
  In this paper, a novel perspective is taken to review current mainstream EDA
working flow and design methods, aiming to shorten the EDA design periods and
simplify the logic design overload significantly. Specifically, three major
contributions are devoted. First, a Chinese character based representation
system (CCRS), which is used for presenting logical abstract syntax tree, is
proposed. Second, the register-transfer-level (RTL) level symbolic description
technique for CCRS are introduced to replace traditional text-based programming
methods. Finally, the refined EDA design flow based on CCRS is discussed. It is
convincing that the graphic non-pure-english based EDA flow could lower the
design cost and complexity. As a fundamental trial in this new field, it is
confirmative that a lot of following works will make the related EDA
development prosperous.
"
1466,"PERMDNN: Efficient Compressed DNN Architecture with Permuted Diagonal
  Matrices","  Deep neural network (DNN) has emerged as the most important and popular
artificial intelligent (AI) technique. The growth of model size poses a key
energy efficiency challenge for the underlying computing platform. Thus, model
compression becomes a crucial problem. However, the current approaches are
limited by various drawbacks. Specifically, network sparsification approach
suffers from irregularity, heuristic nature and large indexing overhead. On the
other hand, the recent structured matrix-based approach (i.e., CirCNN) is
limited by the relatively complex arithmetic computation (i.e., FFT), less
flexible compression ratio, and its inability to fully utilize input sparsity.
To address these drawbacks, this paper proposes PermDNN, a novel approach to
generate and execute hardware-friendly structured sparse DNN models using
permuted diagonal matrices. Compared with unstructured sparsification approach,
PermDNN eliminates the drawbacks of indexing overhead, non-heuristic
compression effects and time-consuming retraining. Compared with circulant
structure-imposing approach, PermDNN enjoys the benefits of higher reduction in
computational complexity, flexible compression ratio, simple arithmetic
computation and full utilization of input sparsity. We propose PermDNN
architecture, a multi-processing element (PE) fully-connected (FC)
layer-targeted computing engine. The entire architecture is highly scalable and
flexible, and hence it can support the needs of different applications with
different model configurations. We implement a 32-PE design using CMOS 28nm
technology. Compared with EIE, PermDNN achieves 3.3x~4.8x higher throughout,
5.9x~8.5x better area efficiency and 2.8x~4.0x better energy efficiency on
different workloads. Compared with CirCNN, PermDNN achieves 11.51x higher
throughput and 3.89x better energy efficiency.
"
1467,"Evaluating FPGA Accelerator Performance with a Parameterized OpenCL
  Adaptation of the HPCChallenge Benchmark Suite","  FPGAs have found increasing adoption in data center applications since a new
generation of high-level tools have become available which noticeably reduce
development time for FPGA accelerators and still provide high quality of
results. There is however no high-level benchmark suite available which
specifically enables a comparison of FPGA architectures, programming tools and
libraries for HPC applications.
  To fill this gap, we have developed an OpenCL-based open source
implementation of the HPCC benchmark suite for Xilinx and Intel FPGAs. This
benchmark can serve to analyze the current capabilities of FPGA devices, cards
and development tool flows, track progress over time and point out specific
difficulties for FPGA acceleration in the HPC domain. Additionally, the
benchmark documents proven performance optimization patterns. We will continue
optimizing and porting the benchmark for new generations of FPGAs and design
tools and encourage active participation to create a valuable tool for the
community.
"
1468,Using DSP Slices as Content-Addressable Update Queues,"  Content-Addressable Memory (CAM) is a powerful abstraction for building
memory caches, routing tables and hazard detection logic. Without a native CAM
structure available on FPGA devices, their functionality must be emulated using
the structural primitives at hand. Such an emulation causes significant
overhead in the consumption of the underlying resources, typically
general-purpose fabric and on-chip block RAM (BRAM). This often motivates
mitigating trade-offs, such as the reduction of the associativity of memory
caches. This paper describes a technique to implement the hazard resolution in
a memory update queue that hides the off-chip memory readout latency of
read-modify-write cycles while guaranteeing the delivery of the full memory
bandwidth. The innovative use of DSP slices allows them to assume and combine
the functions of (a) the tag and data storage, (b) the tag matching, and (c)
the data update in this key-value storage scenario. The proposed approach
provides designers with extra flexibility by adding this resource type as
another option to implement CAM.
"
1469,"FlexSA: Flexible Systolic Array Architecture for Efficient Pruned DNN
  Model Training","  Modern deep learning models have high memory and computation cost. To make
them fast and memory-cost efficient, structured model pruning is commonly used.
We find that pruning a model using a common training accelerator with large
systolic arrays is extremely performance-inefficient. To make a systolic array
efficient for pruning and training, we propose FlexSA, a flexible systolic
array architecture. FlexSA dynamically reconfigures the systolic array
structure and offers multiple sub-systolic operating modes, which are designed
for energy- and memory bandwidth-efficient processing of tensors with different
sizes and shapes. We also present a compilation heuristic for tiling
matrix-multiplication-and-accumulation operations in a training workload to
best utilize the resources of FlexSA. Based on our evaluation, FlexSA with the
proposed compilation heuristic improves compute resource utilization of pruning
and training modern CNN models by 37% compared to a conventional training
accelerator with a large systolic array. FlexSA also improves on-chip data
reuse by 1.7X saving 28% energy compared to naive systolic array splitting.
"
1470,"FORECASTER: A Continual Lifelong Learning Approach to Improve Hardware
  Efficiency","  Computer applications are continuously evolving. However, significant
knowledge can be harvested from older applications or versions and applied in
the context of newer applications or versions. Such a vision can be realized
with Continual Lifelong Learning. Therefore, we propose to employ continual
lifelong learning to dynamically tune hardware configurations based on
application behavior. The goal of such tuning is to maximize hardware
efficiency (i.e., maximize an application performance while minimizing the
hardware energy consumption). Our proposed approach, FORECASTER, uses deep
reinforcement learning to continually learn during the execution of an
application as well as propagate and utilize the accumulated knowledge during
subsequent executions of the same or new application. We propose a novel
hardware and ISA support to implement deep reinforcement learning. We implement
FORECASTER and compare its performance against prior learning-based hardware
reconfiguration approaches. Our results show that FORECASTER can save an
average 16% of system power over the baseline setup with full usage of hardware
while sacrificing an average of 4.7% of execution time.
"
1471,"A scalable and efficient convolutional neural network accelerator using
  HLS for a System on Chip design","  This paper presents a configurable Convolutional Neural Network Accelerator
(CNNA) for a System on Chip design (SoC). The goal was to accelerate inference
of different deep learning networks on an embedded SoC platform. The presented
CNNA has a scalable architecture which uses High Level Synthesis (HLS) and
SystemC for the hardware accelerator. It is able to accelerate any
Convolutional Neural Network (CNN) exported from Python and supports a
combination of convolutional, max-pooling, and fully connected layers. A
training method with fixed-point quantized weights is proposed and presented in
the paper. The CNNA is template-based, enabling it to scale for different
targets of the Xilinx Zynq platform. This approach enables design space
exploration, which makes it possible to explore several configurations of the
CNNA during C- and RTL-simulation, fitting it to the desired platform and
model. The CNN VGG16 was used to test the solution on a Xilinx Ultra96 board
using PYNQ. The result gave a high level of accuracy in training with an
auto-scaled fixed-point Q2.14 format compared to a similar floating-point
model. It was able to perform inference in 2.0 seconds, while having an average
power consumption of 2.63 W, which corresponds to a power efficiency of 6.0
GOPS/W.
"
1472,"Run-Time Accuracy Reconfigurable Stochastic Computing for Dynamic
  Reliability and Power Management","  In this paper, we propose a novel accuracy-reconfigurable stochastic
computing (ARSC) framework for dynamic reliability and power management.
Different than the existing stochastic computing works, where the accuracy
versus power/energy trade-off is carried out in the design time, the new ARSC
design can change accuracy or bit-width of the data in the run-time so that it
can accommodate the long-term aging effects by slowing the system clock
frequency at the cost of accuracy while maintaining the throughput of the
computing. We validate the ARSC concept on a discrete cosine transformation
(DCT) and inverse DCT designs for image compressing/decompressing applications,
which are implemented on Xilinx Spartan-6 family XC6SLX45 platform.
Experimental results shows that the new design can easily mitigate the
long-term aging induced effects by accuracy trade-off while maintaining the
throughput of the whole computing process using simple frequency scaling. We
further show that one-bit precision loss for input data, which translated to
3.44dB of the accuracy loss in term of Peak Signal to Noise Ratio for images,
we can sufficiently compensate the NBTI induced aging effects in 10 years while
maintaining the pre-aging computing throughput of 7.19 frames per second. At
the same time, we can save 74\% power consumption by 10.67dB of accuracy loss.
The proposed ARSC computing framework also allows much aggressive frequency
scaling, which can lead to order of magnitude power savings compared to the
traditional dynamic voltage and frequency scaling (DVFS) techniques.
"
1473,Efficiently Reclaiming Space in a Log Structured Store,"  A log structured store uses a single write I/O for a number of diverse and
non-contiguous pages within a large buffer instead of using a write I/O for
each page separately. This requires that pages be relocated on every write,
because pages are never updated in place. Instead, pages are dynamically
remapped on every write. Log structuring was invented for and used initially in
file systems. Today, a form of log structuring is used in SSD controllers
because an SSD requires the erasure of a large block of pages before flash
storage can be reused. No update-in-place requires that the storage for
out-of-date pages be reclaimed (garbage collected or ""cleaned""). We analyze
cleaning performance and introduce a cleaning strategy that uses a new way to
prioritize the order in which stale pages are garbage collected. Our cleaning
strategy approximates an ""optimal cleaning strategy"". Simulation studies
confirm the results of the analysis. This strategy is a significant improvement
over previous cleaning strategies.
"
1474,Lupulus: A Flexible Hardware Accelerator for Neural Networks,"  Neural networks have become indispensable for a wide range of applications,
but they suffer from high computational- and memory-requirements, requiring
optimizations from the algorithmic description of the network to the hardware
implementation. Moreover, the high rate of innovation in machine learning makes
it important that hardware implementations provide a high level of
programmability to support current and future requirements of neural networks.
In this work, we present a flexible hardware accelerator for neural networks,
called Lupulus, supporting various methods for scheduling and mapping of
operations onto the accelerator. Lupulus was implemented in a 28nm FD-SOI
technology and demonstrates a peak performance of 380 GOPS/GHz with latencies
of 21.4ms and 183.6ms for the convolutional layers of AlexNet and VGG-16,
respectively.
"
1475,"TIMELY: Pushing Data Movements and Interfaces in PIM Accelerators
  Towards Local and in Time Domain","  Resistive-random-access-memory (ReRAM) based processing-in-memory (R$^2$PIM)
accelerators show promise in bridging the gap between Internet of Thing
devices' constrained resources and Convolutional/Deep Neural Networks'
(CNNs/DNNs') prohibitive energy cost. Specifically, R$^2$PIM accelerators
enhance energy efficiency by eliminating the cost of weight movements and
improving the computational density through ReRAM's high density. However, the
energy efficiency is still limited by the dominant energy cost of input and
partial sum (Psum) movements and the cost of digital-to-analog (D/A) and
analog-to-digital (A/D) interfaces. In this work, we identify three
energy-saving opportunities in R$^2$PIM accelerators: analog data locality,
time-domain interfacing, and input access reduction, and propose an innovative
R$^2$PIM accelerator called TIMELY, with three key contributions: (1) TIMELY
adopts analog local buffers (ALBs) within ReRAM crossbars to greatly enhance
the data locality, minimizing the energy overheads of both input and Psum
movements; (2) TIMELY largely reduces the energy of each single D/A (and A/D)
conversion and the total number of conversions by using time-domain interfaces
(TDIs) and the employed ALBs, respectively; (3) we develop an only-once input
read (O$^2$IR) mapping method to further decrease the energy of input accesses
and the number of D/A conversions. The evaluation with more than 10 CNN/DNN
models and various chip configurations shows that, TIMELY outperforms the
baseline R$^2$PIM accelerator, PRIME, by one order of magnitude in energy
efficiency while maintaining better computational density (up to 31.2$\times$)
and throughput (up to 736.6$\times$). Furthermore, comprehensive studies are
performed to evaluate the effectiveness of the proposed ALB, TDI, and O$^2$IR
innovations in terms of energy savings and area reduction.
"
1476,"PowerPlanningDL: Reliability-Aware Framework for On-Chip Power Grid
  Design using Deep Learning","  With the increase in the complexity of chip designs, VLSI physical design has
become a time-consuming task, which is an iterative design process. Power
planning is that part of the floorplanning in VLSI physical design where power
grid networks are designed in order to provide adequate power to all the
underlying functional blocks. Power planning also requires multiple iterative
steps to create the power grid network while satisfying the allowed worst-case
IR drop and Electromigration (EM) margin. For the first time, this paper
introduces Deep learning (DL)-based framework to approximately predict the
initial design of the power grid network, considering different reliability
constraints. The proposed framework reduces many iterative design steps and
speeds up the total design cycle. Neural Network-based multi-target regression
technique is used to create the DL model. Feature extraction is done, and the
training dataset is generated from the floorplans of some of the power grid
designs extracted from the IBM processor. The DL model is trained using the
generated dataset. The proposed DL-based framework is validated using a new set
of power grid specifications (obtained by perturbing the designs used in the
training phase). The results show that the predicted power grid design is
closer to the original design with minimal prediction error (~2%). The proposed
DL-based approach also improves the design cycle time with a speedup of ~6X for
standard power grid benchmarks.
"
1477,Estimating Silent Data Corruption Rates Using a Two-Level Model,"  High-performance and safety-critical system architects must accurately
evaluate the application-level silent data corruption (SDC) rates of processors
to soft errors. Such an evaluation requires error propagation all the way from
particle strikes on low-level state up to the program output. Existing
approaches that rely on low-level simulations with fault injection cannot
evaluate full applications because of their slow speeds, while
application-level accelerated fault testing in accelerated particle beams is
often impractical. We present a new two-level methodology for application
resilience evaluation that overcomes these challenges. The proposed approach
decomposes application failure rate estimation into (1) identifying how
particle strikes in low-level unprotected state manifest at the
architecture-level, and (2) measuring how such architecture-level
manifestations propagate to the program output. We demonstrate the
effectiveness of this approach on GPU architectures. We also show that using
just one of the two steps can overestimate SDC rates and produce different
trends---the composition of the two is needed for accurate reliability
modeling.
"
1478,Electromigration-Aware Architecture for Modern Microprocessors,"  Reliability is a fundamental requirement in any microprocessor to guarantee
correct execution over its lifetime. The design rules related to reliability
depend on the process technology being used and the expected operating
conditions of the device. To meet reliability requirements, advanced process
technologies (28 nm and below) impose highly challenging design rules. Such
design-for-reliability rules have become a major burden on the flow of VLSI
implementation because of the severe physical constraints they impose.
  This paper focuses on electromigration (EM), which is one of the major
critical factors affecting semiconductor reliability. EM is the aging process
of on-die wires and vias and is induced by excessive current flow that can
damage wires and may also significantly impact the integrated-circuit clock
frequency. EM exerts a comprehensive global effect on devices because it
impacts wires that may reside inside the standard or custom logical cells,
between logical cells, inside memory elements, and within wires that
interconnect functional blocks.
  The design-implementation flow (synthesis and place-and-route) currently
detects violations of EM-reliability rules and attempts to solve them. In
contrast, this paper proposes a new approach to enhance these flows by using
EM-aware architecture. Our results show that the proposed solution can relax EM
design efforts in microprocessors and more than double microprocessor lifetime.
This work demonstrates this proposed approach for modern microprocessors,
although the principals and ideas can be adapted to other cases as well.
"
1479,"Prevention of Microarchitectural Covert Channels on an Open-Source
  64-bit RISC-V Core","  Covert channels enable information leakage across security boundaries of the
operating system. Microarchitectural covert channels exploit changes in
execution timing resulting from competing access to limited hardware resources.
We use the recent experimental support for time protection, aimed at preventing
covert channels, in the seL4 microkernel and evaluate the efficacy of the
mechanisms against five known channels on Ariane, an open-source 64-bit
application-class RISC-V core. We confirm that without hardware support, these
defences are expensive and incomplete. We show that the addition of a
single-instruction extension to the RISC-V ISA, that flushes microarchitectural
state, can enable the OS to close all five evaluated covert channels with low
increase in context switch costs and negligible hardware overhead. We conclude
that such a mechanism is essential for security.
"
1480,Best implementations of quaternary adders,"  The implementation of a quaternary 1-digit adder composed of a 2-bit binary
adder, quaternary to binary decoders and binary to quaternary encoders is
compared with several recent implementations of quaternary adders. This simple
implementation outperforms all other implementations using only one power
supply. It is equivalent to the best other implementation using three power
supplies. The best quaternary adder using a 2-bit binary adder, the interface
circuits between quaternary and binary levels are just overhead compared to the
binary adder. This result shows that the quaternary approach for adders use
more transistors, more chip area and more power dissipation than the
corresponding binary ones.
"
1481,"Testing Compilers for Programmable Switches Through Switch Hardware
  Simulation","  Programmable switches have emerged as powerful and flexible alternatives to
fixed-function forwarding devices. But because of the unique hardware
constraints of network switches, the design and implementation of compilers
targeting these devices is tedious and error prone. Despite the important role
that compilers play in software development, there is a dearth of tools for
testing compilers for programmable network devices. We present Druzhba, a
programmable switch simulator used for testing compilers targeting programmable
packet-processing substrates. We show that we can model the low-level behavior
of a switch's programmable hardware. We further show how our machine model can
be used by compiler developers to target Druzhba as a compiler backend.
Generated machine code programs are fed into Druzhba and tested using a
fuzzing-based approach that allows compiler developers to test the correctness
of their compilers. Using a program-synthesis-based compiler as a case study,
we demonstrate how Druzhba has been successful in testing compiler-generated
machine code for our simulated switch pipeline instruction set.
"
1482,LiteX: an open-source SoC builder and library based on Migen Python DSL,"  LiteX is a GitHub-hosted SoC builder / IP library and utilities that can be
used to create SoCs and full FPGA designs. Besides being open-source and BSD
licensed, its originality lies in the fact that its IP components are entirely
described using Migen Python internal DSL, which simplifies its design in
depth. LiteX already supports various softcores CPUs and essential peripherals,
with no dependencies on proprietary IP blocks or generators. This paper
provides an overview of LiteX: two real SoC designs on FPGA are presented. They
both leverage the LiteX approach in terms of design entry, libraries and
integration capabilities. The first one is based on RISC-V core, while the
second is based on a LM32 core. In the second use case, we further demonstrate
the use of a fully open-source toolchain coupled with LiteX.
"
1483,A Post-Silicon Trace Analysis Approach for System-on-Chip Protocol Debug,"  Reconstructing system-level behavior from silicon traces is a critical
problem in post-silicon validation of System-on-Chip designs. Current
industrial practice in this area is primarily manual, depending on
collaborative insights of the architects, designers, and validators. This paper
presents a trace analysis approach that exploits architectural models of the
system-level protocols to reconstruct design behavior from partially observed
silicon traces in the presence of ambiguous and noisy data. The output of the
approach is a set of all potential interpretations of a system's internal
executions abstracted to the system-level protocols. To support the trace
analysis approach, a companion trace signal selection framework guided by
system-level protocols is also presented, and its impacts on the complexity and
accuracy of the analysis approach are discussed. That approach and the
framework have been evaluated on a multi-core system-on-chip prototype that
implements a set of common industrial system-level protocols.
"
1484,Comparing quaternary and binary multipliers,"  We compare the implementation of a 8x8 bit multiplier with two different
implementations of a 4x4 quaternary digit multiplier. Interfacing this binary
multiplier with quaternary to binary decoders and binary to quaternary encoders
leads to a 4x4 multiplier that outperforms the best direct implementation of a
4x4 quaternary multiplier. The far greater complexity of the 1-digit
multipliers and 1-digit adders used in this direct implementation compared to
the binary 1-bit multipliers and full adders cannot be compensated by the
reduced count of quaternary operators. As the best quaternary multiplier
includes the corresponding binary one, it means that there is no opportunity to
get less interconnects, less chip area, less power dissipation with the
quaternary multiplier.
"
1485,"Computing-in-Memory for Performance and Energy Efficient Homomorphic
  Encryption","  Homomorphic encryption (HE) allows direct computations on encrypted data.
Despite numerous research efforts, the practicality of HE schemes remains to be
demonstrated. In this regard, the enormous size of ciphertexts involved in HE
computations degrades computational efficiency. Near-memory Processing (NMP)
and Computing-in-memory (CiM) - paradigms where computation is done within the
memory boundaries - represent architectural solutions for reducing latency and
energy associated with data transfers in data-intensive applications such as
HE. This paper introduces CiM-HE, a Computing-in-memory (CiM) architecture that
can support operations for the B/FV scheme, a somewhat homomorphic encryption
scheme for general computation. CiM-HE hardware consists of customized
peripherals such as sense amplifiers, adders, bit-shifters, and sequencing
circuits. The peripherals are based on CMOS technology, and could support
computations with memory cells of different technologies. Circuit-level
simulations are used to evaluate our CiM-HE framework assuming a 6T-SRAM
memory. We compare our CiM-HE implementation against (i) two optimized CPU HE
implementations, and (ii) an FPGA-based HE accelerator implementation. When
compared to a CPU solution, CiM-HE obtains speedups between 4.6x and 9.1x, and
energy savings between 266.4x and 532.8x for homomorphic multiplications (the
most expensive HE operation). Also, a set of four end-to-end tasks, i.e., mean,
variance, linear regression, and inference are up to 1.1x, 7.7x, 7.1x, and 7.5x
faster (and 301.1x, 404.6x, 532.3x, and 532.8x more energy efficient). Compared
to CPU-based HE in a previous work, CiM-HE obtain 14.3x speed-up and >2600x
energy savings. Finally, our design offers 2.2x speed-up with 88.1x energy
savings compared to a state-of-the-art FPGA-based accelerator.
"
1486,"Optimizing Temporal Convolutional Network inference on FPGA-based
  accelerators","  Convolutional Neural Networks are extensively used in a wide range of
applications, commonly including computer vision tasks like image and video
classification, recognition, and segmentation. Recent research results
demonstrate that multilayer(deep) networks involving mono-dimensional
convolutions and dilation can be effectively used in time series and sequences
classification and segmentation, as well as in tasks involving sequence
modelling. These structures, commonly referred to as Temporal Convolutional
Networks (TCNs), have been demonstrated to consistently outperform Recurrent
Neural Networks in terms of accuracy and training time [1]. While FPGA-based
inference accelerators for classic CNNs are widespread, literature is lacking
in a quantitative evaluation of their usability on inference for TCN models. In
this paper we present such an evaluation, considering a CNN accelerator with
specific features supporting TCN kernels as a reference and a set of
state-of-the-art TCNs as a benchmark. Experimental results show that, during
TCN execution, operational intensity can be critical for the overall
performance. We propose a convolution scheduling based on batch processing that
can boost efficiency up to 96% of theoretical peak performance. Overall we can
achieve up to 111,8 GOPS/s and power efficiency of 33,9 GOPS/s/W on an
Ultrascale+ ZU3EG (up to 10x speedup and 3x power efficiency improvement with
respect to pure software implementation).
"
1487,"GOBO: Quantizing Attention-Based NLP Models for Low Latency and Energy
  Efficient Inference","  Attention-based models have demonstrated remarkable success in various
natural language understanding tasks. However, efficient execution remains a
challenge for these models which are memory-bound due to their massive number
of parameters. We present GOBO, a model quantization technique that compresses
the vast majority (typically 99.9%) of the 32-bit floating-point parameters of
state-of-the-art BERT models and their variants to 3 bits while maintaining
their accuracy. Unlike other quantization methods, GOBO does not require
fine-tuning nor retraining to compensate for the quantization error. We present
two practical hardware applications of GOBO. In the first GOBO reduces memory
storage and traffic and as a result inference latency and energy consumption.
This GOBO memory compression mechanism is plug-in compatible with many
architectures; we demonstrate it with the TPU, Eyeriss, and an architecture
using Tensor Cores-like units. Second, we present a co-designed hardware
architecture that also reduces computation. Uniquely, the GOBO architecture
maintains most of the weights in 3b even during computation, a property that:
(1) makes the processing elements area efficient, allowing us to pack more
compute power per unit area, (2) replaces most multiply-accumulations with
additions, and (3) reduces the off-chip traffic by amplifying on-chip memory
capacity.
"
1488,Benchmarking High Bandwidth Memory on FPGAs,"  FPGAs are starting to be enhanced with High Bandwidth Memory (HBM) as a way
to reduce the memory bandwidth bottleneck encountered in some applications and
to give the FPGA more capacity to deal with application state. However, the
performance characteristics of HBM are still not well specified, especially in
the context of FPGAs. In this paper, we bridge the gap between nominal
specifications and actual performance by benchmarkingHBM on a state-of-the-art
FPGA, i.e., a Xilinx Alveo U280 featuring a two-stack HBM subsystem. To this
end, we propose Shuhai, a benchmarking tool that allows us to demystify all the
underlying details of HBM on an FPGA. FPGA-based benchmarking should also
provide a more accurate picture of HBM than doing so on CPUs/GPUs, since
CPUs/GPUs are noisier systems due to their complex control logic and cache
hierarchy. Since the memory itself is complex, leveraging custom hardware logic
to benchmark inside an FPGA provides more details as well as accurate and
deterministic measurements. We observe that 1) HBM is able to provide up to
425GB/s memory bandwidth, and 2) how HBM is used has a significant impact on
performance, which in turn demonstrates the importance of unveiling the
performance characteristics of HBM so as to select the best approach. As a
yardstick, we also applyShuhaito DDR4to show the differences between HBM and
DDR4.Shuhai can be easily generalized to other FPGA boards or other generations
of memory, e.g., HBM3, and DDR3. We will makeShuhaiopen-source, benefiting the
community
"
1489,"Accelerating Deep Neuroevolution on Distributed FPGAs for Reinforcement
  Learning Problems","  Reinforcement learning augmented by the representational power of deep neural
networks, has shown promising results on high-dimensional problems, such as
game playing and robotic control. However, the sequential nature of these
problems poses a fundamental challenge for computational efficiency. Recently,
alternative approaches such as evolutionary strategies and deep neuroevolution
demonstrated competitive results with faster training time on distributed CPU
cores. Here, we report record training times (running at about 1 million frames
per second) for Atari 2600 games using deep neuroevolution implemented on
distributed FPGAs. Combined hardware implementation of the game console, image
pre-processing and the neural network in an optimized pipeline, multiplied with
the system level parallelism enabled the acceleration. These results are the
first application demonstration on the IBM Neural Computer, which is a custom
designed system that consists of 432 Xilinx FPGAs interconnected in a 3D mesh
network topology. In addition to high performance, experiments also showed
improvement in accuracy for all games compared to the CPU-implementation of the
same algorithm.
"
1490,"Power and Accuracy of Multi-Layer Perceptrons (MLPs) under
  Reduced-voltage FPGA BRAMs Operation","  In this paper, we exploit the aggressive supply voltage underscaling
technique in Block RAMs (BRAMs) of Field Programmable Gate Arrays (FPGAs) to
improve the energy efficiency of Multi-Layer Perceptrons (MLPs). Additionally,
we evaluate and improve the resilience of this accelerator. Through experiments
on several representative FPGA fabrics, we observe that until a minimum safe
voltage level, i.e., Vmin the MLP accuracy is not affected. This safe region
involves a large voltage guardband. Also, it involves a narrower voltage region
where faults start to appear in memories due to the increased circuit delay,
but these faults are masked by MLP, and thus, its accuracy is not affected.
However, further undervolting causes significant accuracy loss as a result of
the fast-increasing high fault rates. Based on the characterization of these
undervolting faults, we propose fault mitigation techniques that can
effectively improve the resilience behavior of such accelerator. Our evaluation
is based on four FPGA platforms. On average, we achieve >90% energy saving with
a negligible accuracy loss of up to 0.1%.
"
1491,"Exploiting Inter- and Intra-Memory Asymmetries for Data Mapping in
  Hybrid Tiered-Memories","  Modern computing systems are embracing hybrid memory comprising of DRAM and
non-volatile memory (NVM) to combine the best properties of both memory
technologies, achieving low latency, high reliability, and high density. A
prominent characteristic of DRAM-NVM hybrid memory is that it has NVM access
latency much higher than DRAM access latency. We call this inter-memory
asymmetry. We observe that parasitic components on a long bitline are a major
source of high latency in both DRAM and NVM, and a significant factor
contributing to high-voltage operations in NVM, which impact their reliability.
We propose an architectural change, where each long bitline in DRAM and NVM is
split into two segments by an isolation transistor. One segment can be accessed
with lower latency and operating voltage than the other. By introducing tiers,
we enable non-uniform accesses within each memory type (which we call
intra-memory asymmetry), leading to performance and reliability trade-offs in
DRAM-NVM hybrid memory. We extend existing NVM-DRAM OS in three ways. First, we
exploit both inter- and intra-memory asymmetries to allocate and migrate memory
pages between the tiers in DRAM and NVM. Second, we improve the OS's page
allocation decisions by predicting the access intensity of a newly-referenced
memory page in a program and placing it to a matching tier during its initial
allocation. This minimizes page migrations during program execution, lowering
the performance overhead. Third, we propose a solution to migrate pages between
the tiers of the same memory without transferring data over the memory channel,
minimizing channel occupancy and improving performance. Our overall approach,
which we call MNEME, to enable and exploit asymmetries in DRAM-NVM hybrid
tiered memory improves both performance and reliability for both single-core
and multi-programmed workloads.
"
1492,Improving Phase Change Memory Performance with Data Content Aware Access,"  A prominent characteristic of write operation in Phase-Change Memory (PCM) is
that its latency and energy are sensitive to the data to be written as well as
the content that is overwritten. We observe that overwriting unknown memory
content can incur significantly higher latency and energy compared to
overwriting known all-zeros or all-ones content. This is because all-zeros or
all-ones content is overwritten by programming the PCM cells only in one
direction, i.e., using either SET or RESET operations, not both. In this paper,
we propose data content aware PCM writes (DATACON), a new mechanism that
reduces the latency and energy of PCM writes by redirecting these requests to
overwrite memory locations containing all-zeros or all-ones. DATACON operates
in three steps. First, it estimates how much a PCM write access would benefit
from overwriting known content (e.g., all-zeros, or all-ones) by
comprehensively considering the number of set bits in the data to be written,
and the energy-latency trade-offs for SET and RESET operations in PCM. Second,
it translates the write address to a physical address within memory that
contains the best type of content to overwrite, and records this translation in
a table for future accesses. We exploit data access locality in workloads to
minimize the address translation overhead. Third, it re-initializes unused
memory locations with known all-zeros or all-ones content in a manner that does
not interfere with regular read and write accesses. DATACON overwrites unknown
content only when it is absolutely necessary to do so. We evaluate DATACON with
workloads from state-of-the-art machine learning applications, SPEC CPU2017,
and NAS Parallel Benchmarks. Results demonstrate that DATACON significantly
improves system performance and memory system energy consumption compared to
the best of performance-oriented state-of-the-art techniques.
"
1493,ChewBaccaNN: A Flexible 223 TOPS/W BNN Accelerator,"  Binary Neural Networks enable smart IoT devices, as they significantly reduce
the required memory footprint and computational complexity while retaining a
high network performance and flexibility. This paper presents ChewBaccaNN, a
0.7 mm$^2$ sized binary convolutional neural network (CNN) accelerator designed
in GlobalFoundries 22 nm technology. By exploiting efficient data re-use, data
buffering, latch-based memories, and voltage scaling, a throughput of 241 GOPS
is achieved while consuming just 1.1 mW at 0.4V/154MHz during inference of
binary CNNs with up to 7x7 kernels, leading to a core energy efficiency of 223
TOPS/W. ChewBaccaNN's flexibility allows to run a much wider range of binary
CNNs than other accelerators, drastically improving the accuracy-energy
trade-off beyond what can be captured by the TOPS/W metric. In fact, it can
perform CIFAR-10 inference at 86.8% accuracy with merely 1.3 {\mu}J, thus
exceeding the accuracy while at the same time lowering the energy cost by 2.8x
compared to even the most efficient and much larger analog processing-in-memory
devices, while keeping the flexibility of running larger CNNs for higher
accuracy when needed. It also runs a binary ResNet-18 trained on the 1000-class
ILSVRC dataset and improves the energy efficiency by 4.4x over accelerators of
similar flexibility. Furthermore, it can perform inference on a binarized
ResNet-18 trained with 8-bases Group-Net to achieve a 67.5% Top-1 accuracy with
only 3.0\,mJ/frame - at an accuracy drop of merely 1.8\% from the
full-precision ResNet-18.
"
1494,"SysScale: Exploiting Multi-domain Dynamic Voltage and Frequency Scaling
  for Energy Efficient Mobile Processors","  There are three domains in a modern thermally-constrained mobile
system-on-chip (SoC): compute, IO, and memory. We observe that a modern SoC
typically allocates a fixed power budget, corresponding to worst-case
performance demands, to the IO and memory domains even if they are
underutilized. The resulting unfair allocation of the power budget across
domains can cause two major issues: 1) the IO and memory domains can operate at
a higher frequency and voltage than necessary, increasing power consumption and
2) the unused power budget of the IO and memory domains cannot be used to
increase the throughput of the compute domain, hampering performance. To avoid
these issues, it is crucial to dynamically orchestrate the distribution of the
SoC power budget across the three domains based on their actual performance
demands.
  We propose SysScale, a new multi-domain power management technique to improve
the energy efficiency of mobile SoCs. SysScale is based on three key ideas.
First, SysScale introduces an accurate algorithm to predict the performance
(e.g., bandwidth and latency) demands of the three SoC domains. Second,
SysScale uses a new DVFS (dynamic voltage and frequency scaling) mechanism to
distribute the SoC power to each domain according to the predicted performance
demands. Third, in addition to using a global DVFS mechanism, SysScale uses
domain-specialized techniques to optimize the energy efficiency of each domain
at different operating points.
  We implement SysScale on an Intel Skylake microprocessor for mobile devices
and evaluate it using a wide variety of SPEC CPU2006, graphics (3DMark), and
battery life workloads (e.g., video playback). On a 2-core Skylake, SysScale
improves the performance of SPEC CPU2006 and 3DMark workloads by up to 16% and
8.9% (9.2% and 7.9% on average), respectively.
"
1495,"Systolic Tensor Array: An Efficient Structured-Sparse GEMM Accelerator
  for Mobile CNN Inference","  Convolutional neural network (CNN) inference on mobile devices demands
efficient hardware acceleration of low-precision (INT8) general matrix
multiplication (GEMM). The systolic array (SA) is a pipelined 2D array of
processing elements (PEs), with very efficient local data movement, well suited
to accelerating GEMM, and widely deployed in industry. In this work, we
describe two significant improvements to the traditional SA architecture, to
specifically optimize for CNN inference. Firstly, we generalize the traditional
scalar PE, into a Tensor-PE, which gives rise to a family of new Systolic
Tensor Array (STA) microarchitectures. The STA family increases intra-PE
operand reuse and datapath efficiency, resulting in circuit area and power
dissipation reduction of as much as 2.08x and 1.36x respectively, compared to
the conventional SA at iso-throughput with INT8 operands. Secondly, we extend
this design to support a novel block-sparse data format called density-bound
block (DBB). This variant (STA-DBB) achieves a 3.14x and 1.97x improvement over
the SA baseline at iso-throughput in area and power respectively, when
processing specially-trained DBB-sparse models, while remaining fully backwards
compatible with dense models.
"
1496,A Lightweight Isolation Mechanism for Secure Branch Predictors,"  Recently exposed vulnerabilities reveal the necessity to improve the security
of branch predictors. Branch predictors record history about the execution of
different programs, and such information from different processes are stored in
the same structure and thus accessible to each other. This leaves the attackers
with the opportunities for malicious training and malicious perception. Instead
of flush-based or physical isolation of hardware resources, we want to achieve
isolation of the content in these hardware tables with some lightweight
processing using randomization as follows. (1) Content encoding. We propose to
use hardware-based thread-private random numbers to encode the contents of the
branch predictor tables (both direction and destination histories) which we
call XOR-BP. Specifically, the data is encoded by XOR operation with the key
before written in the table and decoded after read from the table. Such a
mechanism obfuscates the information adding difficulties to cross-process or
cross-privilege level analysis and perception. It achieves a similar effect of
logical isolation but adds little in terms of space or time overheads. (2)
Index encoding. We propose a randomized index mechanism of the branch predictor
(Noisy-XOR-BP). Similar to the XOR-BP, another thread-private random number is
used together with the branch instruction address as the input to compute the
index of the branch predictor. This randomized indexing mechanism disrupts the
correspondence between the branch instruction address and the branch predictor
entry, thus increases the noise for malicious perception attacks. Our analyses
using an FPGA-based RISC-V processor prototype and additional auxiliary
simulations suggest that the proposed mechanisms incur a very small performance
cost while providing strong protection.
"
1497,Energy-Efficient On-Chip Networks through Profiled Hybrid Switching,"  Virtual channel flow control is the de facto choice for modern
networks-on-chip to allow better utilization of the link bandwidth through
buffering and packet switching, which are also the sources of large power
footprint and long per-hop latency. On the other hand, bandwidth can be
plentiful for parallel workloads under virtual channel flow control. Thus,
dated but simpler flow controls such as circuit switching can be utilized to
improve the energy efficiency of modern networks-on-chip. In this paper, we
propose to utilize part of the link bandwidth under circuit switching so that
part of the traffic can be transmitted bufferlessly without routing. Our
evaluations reveal that this proposal leads to a reduction of energy per flit
by up to 32% while also provides very competitive latency per flit when
compared to networks under virtual channel flow control.
"
1498,"In-memory Implementation of On-chip Trainable and Scalable ANN for AI/ML
  Applications","  Traditional von Neumann architecture based processors become inefficient in
terms of energy and throughput as they involve separate processing and memory
units, also known as~\textit{memory wall}. The memory wall problem is further
exacerbated when massive parallelism and frequent data movement are required
between processing and memory units for real-time implementation of artificial
neural network (ANN) that enables many intelligent applications. One of the
most promising approach to address the memory wall problem is to carry out
computations inside the memory core itself that enhances the memory bandwidth
and energy efficiency for extensive computations. This paper presents an
in-memory computing architecture for ANN enabling artificial intelligence (AI)
and machine learning (ML) applications. The proposed architecture utilizes deep
in-memory architecture based on standard six transistor (6T) static random
access memory (SRAM) core for the implementation of a multi-layered perceptron.
Our novel on-chip training and inference in-memory architecture reduces energy
cost and enhances throughput by simultaneously accessing the multiple rows of
SRAM array per precharge cycle and eliminating the frequent access of data. The
proposed architecture realizes backpropagation which is the keystone during the
network training using newly proposed different building blocks such as weight
updation, analog multiplication, error calculation, signed analog to digital
conversion, and other necessary signal control units. The proposed architecture
was trained and tested on the IRIS dataset which exhibits $\approx46\times$
more energy efficient per MAC (multiply and accumulate) operation compared to
earlier classifiers.
"
1499,"The Virtual Block Interface: A Flexible Alternative to the Conventional
  Virtual Memory Framework","  Computers continue to diversify with respect to system designs, emerging
memory technologies, and application memory demands. Unfortunately, continually
adapting the conventional virtual memory framework to each possible system
configuration is challenging, and often results in performance loss or requires
non-trivial workarounds. To address these challenges, we propose a new virtual
memory framework, the Virtual Block Interface (VBI). We design VBI based on the
key idea that delegating memory management duties to hardware can reduce the
overheads and software complexity associated with virtual memory. VBI
introduces a set of variable-sized virtual blocks (VBs) to applications. Each
VB is a contiguous region of the globally-visible VBI address space, and an
application can allocate each semantically meaningful unit of information
(e.g., a data structure) in a separate VB. VBI decouples access protection from
memory allocation and address translation. While the OS controls which programs
have access to which VBs, dedicated hardware in the memory controller manages
the physical memory allocation and address translation of the VBs. This
approach enables several architectural optimizations to (1) efficiently and
flexibly cater to different and increasingly diverse system configurations, and
(2) eliminate key inefficiencies of conventional virtual memory. We demonstrate
the benefits of VBI with two important use cases: (1) reducing the overheads of
address translation (for both native execution and virtual machine
environments), as VBI reduces the number of translation requests and associated
memory accesses; and (2) two heterogeneous main memory architectures, where VBI
increases the effectiveness of managing fast memory regions. For both cases,
VBI significanttly improves performance over conventional virtual memory.
"
1500,"A Way Around UMIP and Descriptor-Table Exiting via TSX-based
  Side-Channel Attack","  Nowadays, in operating systems, numerous protection mechanisms prevent or
limit the user-mode applications to access the kernel's internal information.
This is regularly carried out by software-based defenses such as Address Space
Layout Randomization (ASLR) and Kernel ASLR (KASLR). They play pronounced roles
when the security of sandboxed applications such as Web-browser are considered.
Armed with arbitrary write access in the kernel memory, if these protections
are bypassed, an attacker could find a suitable Where to Write in order to get
an elevation of privilege or maliciously execute codes in ring 0. In this
paper, we introduce a reliable method based on Transactional Synchronization
Extensions (TSX) side-channel attacks to reveal the address of the Global
Descriptor Table (GDT) and Interrupt Descriptor Table (IDT). We indicate that
by detecting these addresses, an attack could be executed to sidestep the
Intel's User-Mode Instruction Prevention (UMIP) and the Hypervisor-based
mitigation and, consequently, neutralized them. The introduced attack is
successfully performed after the most recent patches for Meltdown and Spectre.
Moreover, the implementation of the proposed attack on different platforms,
including the latest releases of Microsoft Windows, Linux, and, Mac OSX with
the latest $9^{th}$ generation of Intel processors, shows that the attack is
independent of the Operating System implementation. We demonstrate that a
combination of this method with call-gate mechanism (available in modern
processors) in a chain of attacks will eventually lead to a full system
compromise despite the limitations of a super-secure sandboxed environment in
the presence of Windows's proprietary Virtualization Based Security (VBS).
Finally, we suggest the software-based mitigation to avoid these attacks with
an acceptable cost.
"
1501,"Memory-Aware Denial-of-Service Attacks on Shared Cache in Multicore
  Real-Time Systems","  In this paper, we identify that memory performance plays a crucial role in
the feasibility and effectiveness for performing denial-of-service attacks on
shared cache. Based on this insight, we introduce new cache DoS attacks, which
can be mounted from the user-space and can cause extreme WCET impacts to
cross-core victims---even if the shared cache is partitioned---by taking
advantage of the platform's memory address mapping information and HugePage
support. We deploy these enhanced attacks on two popular embedded out-of-order
multicore platforms using both synthetic and real-world benchmarks. The
proposed DoS attacks achieve up to 75X WCET increases on the tested platforms.
"
1502,"Stack up your chips: Betting on 3D integration to augment Moore's Law
  scaling","  3D integration, i.e., stacking of integrated circuit layers using parallel or
sequential processing is gaining rapid industry adoption with the slowdown of
Moore's law scaling. 3D stacking promises potential gains in performance, power
and cost but the actual magnitude of gains varies depending on end-application,
technology choices and design. In this talk, we will discuss some key
challenges associated with 3D design and how design-for-3D will require us to
break traditional silos of micro-architecture, circuit/physical design and
manufacturing technology to work across abstractions to enable the gains
promised by 3D technologies.
"
1503,"Accelerate Cycle-Level Full-System Simulation of Multi-Core RISC-V
  Systems with Binary Translation","  It has always been difficult to balance the accuracy and performance of ISSs.
RTL simulators or systems such as gem5 are used to execute programs in a
cycle-accurate manner but are often prohibitively slow. In contrast, functional
simulators such as QEMU can run large benchmarks to completion in a reasonable
time yet capture few performance metrics and fail to model complex interactions
between multiple cores.
  This paper presents a novel multi-purpose simulator that exploits binary
translation to offer fast cycle-level full-system simulations. Its functional
simulation mode outperforms QEMU and, if desired, it is possible to switch
between functional and timing modes at run-time. Cycle-level simulations of
RISC-V multi-core processors are possible at more than 20 MIPS, a useful middle
ground in terms of accuracy and performance with simulation speeds nearly 100
times those of more detailed cycle-accurate models.
"
1504,"CLR-DRAM: A Low-Cost DRAM Architecture Enabling Dynamic Capacity-Latency
  Trade-Off","  DRAM is the prevalent main memory technology, but its long access latency can
limit the performance of many workloads. Although prior works provide DRAM
designs that reduce DRAM access latency, their reduced storage capacities
hinder the performance of workloads that need large memory capacity. Because
the capacity-latency trade-off is fixed at design time, previous works cannot
achieve maximum performance under very different and dynamic workload demands.
  This paper proposes Capacity-Latency-Reconfigurable DRAM (CLR-DRAM), a new
DRAM architecture that enables dynamic capacity-latency trade-off at low cost.
CLR-DRAM allows dynamic reconfiguration of any DRAM row to switch between two
operating modes: 1) max-capacity mode, where every DRAM cell operates
individually to achieve approximately the same storage density as a
density-optimized commodity DRAM chip and 2) high-performance mode, where two
adjacent DRAM cells in a DRAM row and their sense amplifiers are coupled to
operate as a single low-latency logical cell driven by a single logical sense
amplifier.
  We implement CLR-DRAM by adding isolation transistors in each DRAM subarray.
Our evaluations show that CLR-DRAM can improve system performance and DRAM
energy consumption by 18.6% and 29.7% on average with four-core multiprogrammed
workloads. We believe that CLR-DRAM opens new research directions for a system
to adapt to the diverse and dynamically changing memory capacity and access
latency demands of workloads.
"
1505,"Revisiting RowHammer: An Experimental Analysis of Modern DRAM Devices
  and Mitigation Techniques","  In order to shed more light on how RowHammer affects modern and future
devices at the circuit-level, we first present an experimental characterization
of RowHammer on 1580 DRAM chips (408x DDR3, 652x DDR4, and 520x LPDDR4) from
300 DRAM modules (60x DDR3, 110x DDR4, and 130x LPDDR4) with RowHammer
protection mechanisms disabled, spanning multiple different technology nodes
from across each of the three major DRAM manufacturers. Our studies
definitively show that newer DRAM chips are more vulnerable to RowHammer: as
device feature size reduces, the number of activations needed to induce a
RowHammer bit flip also reduces, to as few as 9.6k (4.8k to two rows each) in
the most vulnerable chip we tested.
  We evaluate five state-of-the-art RowHammer mitigation mechanisms using
cycle-accurate simulation in the context of real data taken from our chips to
study how the mitigation mechanisms scale with chip vulnerability. We find that
existing mechanisms either are not scalable or suffer from prohibitively large
performance overheads in projected future devices given our observed trends of
RowHammer vulnerability. Thus, it is critical to research more effective
solutions to RowHammer.
"
1506,Dynamic Merge Point Prediction,"  Despite decades of research, conditional branch mispredictions still pose a
significant problem for performance. Moreover, limit studies on infinite size
predictors show that many of the remaining branches are impossible to predict
by current strategies. Our work focuses on mitigating performance loss in the
face of impossible to predict branches. This paper presents a dynamic merge
point predictor, which uses instructions fetched on the wrong path of the
branch to dynamically detect the merge point. Our predictor locates the merge
point with an accuracy of 95%, even when faced with branches whose direction is
impossible to predict. Furthermore, we introduce a novel confidence-cost
system, which identifies costly hard-to-predict branches. Our complete system
replaces 58% of all branch mispredictions with a correct merge point
prediction, effectively reducing MPKI by 43%. This result demonstrates the
potential for dynamic merge point prediction to significantly improve
performance.
"
1507,"A Unified Hardware Architecture for Convolutions and Deconvolutions in
  CNN","  In this paper, a scalable neural network hardware architecture for image
segmentation is proposed. By sharing the same computing resources, both
convolution and deconvolution operations are handled by the same process
element array. In addition, access to on-chip and off-chip memories is
optimized to alleviate the burden introduced by partial sum. As an example,
SegNet-Basic has been implemented using the proposed unified architecture by
targeting on Xilinx ZC706 FPGA, which achieves the performance of 151.5 GOPS
and 94.3 GOPS for convolution and deconvolution respectively. This unified
convolution/deconvolution design is applicable to other CNNs with
deconvolution.
"
1508,CLARINET: A RISC-V Based Framework for Posit Arithmetic Empiricism,"  Many engineering and scientific applications require high precision
arithmetic. IEEE 754-2008 compliant (floating-point) arithmetic is the de facto
standard for performing these computations. Recently, posit arithmetic has been
proposed as a drop-in replacement for floating-point arithmetic. The posit data
representation and arithmetic offer several absolute advantages over the
floating-point format and arithmetic including higher dynamic range, better
accuracy, and superior performance-area trade-offs.
  In this paper, we present a consolidated general-purpose processor-based
framework to support posit arithmetic empiricism. The end-users of the
framework have the liberty to seamlessly experiment with their applications
using posit and floating-point arithmetic since the framework is designed for
the two number systems to coexist. The framework consists of Melodica and
Clarinet. Melodica is a posit arithmetic core that implements parametric
fused-multiply-accumulate and, more importantly, supports the quire data type.
Clarinet is a Melodica-enabled processor based on the RISC-V ISA. To the best
of our knowledge, this is the first-ever integration of quire to a RISC-V core.
To show the effectiveness of the Clarinet platform, we perform an extensive
application study and benchmarking on some of the common linear algebra and
computer vision kernels. We perform ASIC synthesis of Clarinet and Melodica on
a 90 nm-CMOS Faraday process. Finally, based on our analysis and synthesis
results, we define a quality metric for the different instances of Clarinet
that gives us initial recommendations on the goodness of the instances.
Clarinet-Melodica is an easy-to-experiment platform that will be made available
in open-source for posit arithmetic empiricism.
"
1509,"How to extend the Single-Processor Paradigm to the Explicitly
  Many-Processor Approach","  The computing paradigm invented for processing a small amount of data on a
single segregated processor cannot meet the challenges set by the present-day
computing demands. The paper proposes a new computing paradigm (extending the
old one to use several processors explicitly) and discusses some questions of
its possible implementation. Some advantages of the implemented approach,
illustrated with the results of a loosely-timed simulator, are presented.
"
1510,"Exceeding Conservative Limits: A Consolidated Analysis on Modern
  Hardware Margins","  Modern large-scale computing systems (data centers, supercomputers, cloud and
edge setups and high-end cyber-physical systems) employ heterogeneous
architectures that consist of multicore CPUs, general-purpose many-core GPUs,
and programmable FPGAs. The effective utilization of these architectures poses
several challenges, among which a primary one is power consumption. Voltage
reduction is one of the most efficient methods to reduce power consumption of a
chip. With the galloping adoption of hardware accelerators (i.e., GPUs and
FPGAs) in large datacenters and other large-scale computing infrastructures, a
comprehensive evaluation of the safe voltage reduction levels for each
different chip can be employed for efficient reduction of the total power. We
present a survey of recent studies in voltage margins reduction at the system
level for modern CPUs, GPUs and FPGAs. The pessimistic voltage guardbands
inserted by the silicon vendors can be exploited in all devices for significant
power savings. On average, voltage reduction can reach 12% in multicore CPUs,
20% in manycore GPUs and 39% in FPGAs.
"
1511,"Hardware Security in Spin-Based Computing-In-Memory: Analysis, Exploits,
  and Mitigation Techniques","  Computing-in-memory (CIM) is proposed to alleviate the processor-memory data
transfer bottleneck in traditional Von-Neumann architectures, and
spintronics-based magnetic memory has demonstrated many facilitation in
implementing CIM paradigm. Since hardware security has become one of the major
concerns in circuit designs, this paper, for the first time, investigates
spin-based computing-in-memory (SpinCIM) from a security perspective. We focus
on two fundamental questions: 1) how the new SpinCIM computing paradigm can be
exploited to enhance hardware security? 2) what security concerns has this new
SpinCIM computing paradigm incurred?
"
1512,Operation Merging for Hardware Implementations of Fast Polar Decoders,"  Polar codes are a class of linear block codes that provably achieves channel
capacity. They have been selected as a coding scheme for the control channel of
enhanced mobile broadband (eMBB) scenario for $5^{\text{th}}$ generation
wireless communication networks (5G) and are being considered for additional
use scenarios. As a result, fast decoding techniques for polar codes are
essential. Previous works targeting improved throughput for
successive-cancellation (SC) decoding of polar codes are semi-parallel
implementations that exploit special maximum-likelihood (ML) nodes. In this
work, we present a new fast simplified SC (Fast-SSC) decoder architecture.
Compared to a baseline Fast-SSC decoder, our solution is able to reduce the
memory requirements. We achieve this through a more efficient memory
utilization, which also enables to execute multiple operations in a single
clock cycle. Finally, we propose new special node merging techniques that
improve the throughput further, and detail a new Fast-SSC-based decoder
architecture to support merged operations. The proposed decoder reduces the
operation sequence requirement by up to $39\%$, which enables to reduce the
number of time steps to decode a codeword by $35\%$. ASIC implementation
results with 65 nm TSMC technology show that the proposed decoder has a
throughput improvement of up to $31\%$ compared to previous Fast-SSC decoder
architectures.
"
1513,"Counting Cards: Exploiting Weight and Variance Distributions for Robust
  Compute In-Memory","  Compute in-memory (CIM) is a promising technique that minimizes data
transport, the primary performance bottleneck and energy cost of most data
intensive applications. This has found wide-spread adoption in accelerating
neural networks for machine learning applications. Utilizing a crossbar
architecture with emerging non-volatile memories (eNVM) such as dense resistive
random access memory (RRAM) or phase change random access memory (PCRAM),
various forms of neural networks can be implemented to greatly reduce power and
increase on chip memory capacity. However, compute in-memory faces its own
limitations at both the circuit and the device levels. In this work, we explore
the impact of device variation and peripheral circuit design constraints.
Furthermore, we propose a new algorithm based on device variance and neural
network weight distributions to increase both performance and accuracy for
compute-in memory based designs. We demonstrate a 27% power improvement and 23%
performance improvement for low and high variance eNVM, while satisfying a
programmable threshold for a target error tolerance, which depends on the
application.
"
1514,FP-Stereo: Hardware-Efficient Stereo Vision for Embedded Applications,"  Fast and accurate depth estimation, or stereo matching, is essential in
embedded stereo vision systems, requiring substantial design effort to achieve
an appropriate balance among accuracy, speed and hardware cost. To reduce the
design effort and achieve the right balance, we propose FP-Stereo for building
high-performance stereo matching pipelines on FPGAs automatically. FP-Stereo
consists of an open-source hardware-efficient library, allowing designers to
obtain the desired implementation instantly. Diverse methods are supported in
our library for each stage of the stereo matching pipeline and a series of
techniques are developed to exploit the parallelism and reduce the resource
overhead. To improve the usability, FP-Stereo can generate synthesizable C code
of the FPGA accelerator with our optimized HLS templates automatically. To
guide users for the right design choice meeting specific application
requirements, detailed comparisons are performed on various configurations of
our library to investigate the accuracy/speed/cost trade-off. Experimental
results also show that FP-Stereo outperforms the state-of-the-art FPGA design
from all aspects, including 6.08% lower error, 2x faster speed, 30% less
resource usage and 40% less energy consumption. Compared to GPU designs,
FP-Stereo achieves the same accuracy at a competitive speed while consuming
much less energy.
"
1515,A GPU Register File using Static Data Compression,"  GPUs rely on large register files to unlock thread-level parallelism for high
throughput. Unfortunately, large register files are power hungry, making it
important to seek for new approaches to improve their utilization.
  This paper introduces a new register file organization for efficient
register-packing of narrow integer and floating-point operands designed to
leverage on advances in static analysis. We show that the hardware/software
co-designed register file organization yields a performance improvement of up
to 79%, and 18.6%, on average, at a modest output-quality degradation.
"
1516,"Unified Characterization Platform for Emerging NVM Technology: Neural
  Network Application Benchmarking Using off-the-shelf NVM Chips","  In this paper, we present a unified FPGA based electrical test-bench for
characterizing different emerging NonVolatile Memory (NVM) chips. In
particular, we present detailed electrical characterization and benchmarking of
multiple commercially available, off-the-shelf, NVM chips viz.: MRAM, FeRAM,
CBRAM, and ReRAM. We investigate important NVM parameters such as: (i) current
consumption patterns, (ii) endurance, and (iii) error characterization. The
proposed FPGA based testbench is then utilized for a Proof-of-Concept (PoC)
Neural Network (NN) image classification application. Four emerging NVM chips
are benchmarked against standard SRAM and Flash technology for the AI
application as active weight memory during inference mode.
"
1517,"Improving Dependability of Neuromorphic Computing With Non-Volatile
  Memory","  As process technology continues to scale aggressively, circuit aging in a
neuromorphic hardware due to negative bias temperature instability (NBTI) and
time-dependent dielectric breakdown (TDDB) is becoming a critical reliability
issue and is expected to proliferate when using non-volatile memory (NVM) for
synaptic storage. This is because an NVM requires high voltage and current to
access its synaptic weight, which further accelerates the circuit aging in a
neuromorphic hardware. Current methods for qualifying reliability are overly
conservative, since they estimate circuit aging considering worst-case
operating conditions and unnecessarily constrain performance. This paper
proposes RENEU, a reliability-oriented approach to map machine learning
applications to neuromorphic hardware, with the aim of improving system-wide
reliability without compromising key performance metrics such as execution time
of these applications on the hardware. Fundamental to RENEU is a novel
formulation of the aging of CMOS-based circuits in a neuromorphic hardware
considering different failure mechanisms. Using this formulation, RENEU
develops a system-wide reliability model which can be used inside a
design-space exploration framework involving the mapping of neurons and
synapses to the hardware. To this end, RENEU uses an instance of Particle Swarm
Optimization (PSO) to generate mappings that are Pareto-optimal in terms of
performance and reliability. We evaluate RENEU using different machine learning
applications on a state-of-the-art neuromorphic hardware with NVM synapses. Our
results demonstrate an average 38\% reduction in circuit aging, leading to an
average 18% improvement in the lifetime of the hardware compared to current
practices. RENEU only introduces a marginal performance overhead of 5% compared
to a performance-oriented state-of-the-art.
"
1518,"STONNE: A Detailed Architectural Simulator for Flexible Neural Network
  Accelerators","  The design of specialized architectures for accelerating the inference
procedure of Deep Neural Networks (DNNs) is a booming area of research
nowadays. First-generation rigid proposals have been rapidly replaced by more
advanced flexible accelerator architectures able to efficiently support a
variety of layer types and dimensions. As the complexity of the designs grows,
it is more and more appealing for researchers to have cycle-accurate simulation
tools at their disposal to allow for fast and accurate design-space
exploration, and rapid quantification of the efficacy of architectural
enhancements during the early stages of a design. To this end, we present
STONNE (Simulation TOol of Neural Network Engines), a cycle-accurate,
highly-modular and highly-extensible simulation framework that enables
end-to-end evaluation of flexible accelerator architectures running complete
contemporary DNN models. We use STONNE to model the recently proposed MAERI
architecture and show how it can closely approach the performance results of
the publicly available BSV-coded MAERI implementation. Then, we conduct a
comprehensive evaluation and demonstrate that the folding strategy implemented
for MAERI results in very low compute unit utilization (25% on average across 5
DNN models) which in the end translates into poor performance.
"
1519,"A Unified Learning Platform for Dynamic Frequency Scaling in Pipelined
  Processors","  A machine learning (ML) design framework is proposed for dynamically
adjusting clock frequency based on propagation delay of individual
instructions. A Random Forest model is trained to classify propagation delays
in real-time, utilizing current operation type, current operands, and
computation history as ML features. The trained model is implemented in Verilog
as an additional pipeline stage within a baseline processor. The modified
system is simulated at the gate-level in 45 nm CMOS technology, exhibiting a
speed-up of 68% and energy reduction of 37% with coarse-grained ML
classification. A speed-up of 95% is demonstrated with finer granularities at
additional energy costs.
"
1520,Architecture Support for FPGA Multi-tenancy in the Cloud,"  Cloud deployments now increasingly provision FPGA accelerators as part of
virtual instances. While FPGAs are still essentially single-tenant, the growing
demand for hardware acceleration will inevitably lead to the need for methods
and architectures supporting FPGA multi-tenancy. In this paper, we propose an
architecture supporting space-sharing of FPGA devices among multiple tenants in
the cloud. The proposed architecture implements a network-on-chip (NoC)
designed for fast data movement and low hardware footprint. Prototyping the
proposed architecture on a Xilinx Virtex Ultrascale+ demonstrated near
specification maximum frequency for on-chip data movement and high throughput
in virtual instance access to hardware accelerators. We demonstrate similar
performance compared to single-tenant deployment while increasing FPGA
utilization ( we achieved 6x higher FPGA utilization with our case study),
which is one of the major goals of virtualization. Overall, our NoC
interconnect achieved about 2x higher maximum frequency than the
state-of-the-art and a bandwidth of 25.6 Gbps.
"
1521,Addressing Variability in Reuse Prediction for Last-Level Caches,"  Last-Level Cache (LLC) represents the bulk of a modern CPU processor's
transistor budget and is essential for application performance as LLC enables
fast access to data in contrast to much slower main memory. However,
applications with large working set size often exhibit streaming and/or
thrashing access patterns at LLC. As a result, a large fraction of the LLC
capacity is occupied by dead blocks that will not be referenced again, leading
to inefficient utilization of the LLC capacity. To improve cache efficiency,
the state-of-the-art cache management techniques employ prediction mechanisms
that learn from the past access patterns with an aim to accurately identify as
many dead blocks as possible. Once identified, dead blocks are evicted from LLC
to make space for potentially high reuse cache blocks.
  In this thesis, we identify variability in the reuse behavior of cache blocks
as the key limiting factor in maximizing cache efficiency for state-of-the-art
predictive techniques. Variability in reuse prediction is inevitable due to
numerous factors that are outside the control of LLC. The sources of
variability include control-flow variation, speculative execution and
contention from cores sharing the cache, among others. Variability in reuse
prediction challenges existing techniques in reliably identifying the end of a
block's useful lifetime, thus causing lower prediction accuracy, coverage, or
both. To address this challenge, this thesis aims to design robust cache
management mechanisms and policies for LLC in the face of variability in reuse
prediction to minimize cache misses, while keeping the cost and complexity of
the hardware implementation low. To that end, we propose two cache management
techniques, one domain-agnostic and one domain-specialized, to improve cache
efficiency by addressing variability in reuse prediction.
"
1522,"ZnG: Architecting GPU Multi-Processors with New Flash for Scalable Data
  Analysis","  We propose ZnG, a new GPU-SSD integrated architecture, which can maximize the
memory capacity in a GPU and address performance penalties imposed by an SSD.
Specifically, ZnG replaces all GPU internal DRAMs with an ultra-low-latency SSD
to maximize the GPU memory capacity. ZnG further removes performance bottleneck
of the SSD by replacing its flash channels with a high-throughput flash network
and integrating SSD firmware in the GPU's MMU to reap the benefits of hardware
accelerations. Although flash arrays within the SSD can deliver high
accumulated bandwidth, only a small fraction of such bandwidth can be utilized
by GPU's memory requests due to mismatches of their access granularity. To
address this, ZnG employs a large L2 cache and flash registers to buffer the
memory requests. Our evaluation results indicate that ZnG can achieve 7.5x
higher performance than prior work.
"
1523,"You Only Spike Once: Improving Energy-Efficient Neuromorphic Inference
  to ANN-Level Accuracy","  In the past decade, advances in Artificial Neural Networks (ANNs) have
allowed them to perform extremely well for a wide range of tasks. In fact, they
have reached human parity when performing image recognition, for example.
Unfortunately, the accuracy of these ANNs comes at the expense of a large
number of cache and/or memory accesses and compute operations. Spiking Neural
Networks (SNNs), a type of neuromorphic, or brain-inspired network, have
recently gained significant interest as power-efficient alternatives to ANNs,
because they are sparse, accessing very few weights, and typically only use
addition operations instead of the more power-intensive multiply-and-accumulate
(MAC) operations. The vast majority of neuromorphic hardware designs support
rate-encoded SNNs, where the information is encoded in spike rates.
Rate-encoded SNNs could be seen as inefficient as an encoding scheme because it
involves the transmission of a large number of spikes. A more efficient
encoding scheme, Time-To-First-Spike (TTFS) encoding, encodes information in
the relative time of arrival of spikes. While TTFS-encoded SNNs are more
efficient than rate-encoded SNNs, they have, up to now, performed poorly in
terms of accuracy compared to previous methods. Hence, in this work, we aim to
overcome the limitations of TTFS-encoded neuromorphic systems. To accomplish
this, we propose: (1) a novel optimization algorithm for TTFS-encoded SNNs
converted from ANNs and (2) a novel hardware accelerator for TTFS-encoded SNNs,
with a scalable and low-power design. Overall, our work in TTFS encoding and
training improves the accuracy of SNNs to achieve state-of-the-art results on
MNIST MLPs, while reducing power consumption by 1.46$\times$ over the
state-of-the-art neuromorphic hardware.
"
1524,"Design of a Near-Ideal Fault-Tolerant Routing Algorithm for
  Network-on-Chip-Based Multicores","  With relentless CMOS technology downsizing Networks-on-Chips (NoCs) are
inescapably experiencing escalating susceptibility to wearout and reduced
reliability. While faults in processors and memories may be masked via
redundancy, or mitigated via techniques such as task migration, NoCs are
especially vulnerable to hardware faults as a single link breakdown may cause
inter-tile communication to halt indefinitely, rendering the whole multicore
chip inoperable. As such, NoCs impose the risk of becoming the pivotal point of
failure in chip multicores that utilize them. Aiming towards seamless NoC
operation in the presence of faulty links we propose Hermes, a near-ideal
fault-tolerant routing algorithm that meets the objectives of exhibiting high
levels of robustness, operating in a distributed mode, guaranteeing freedom
from deadlocks, and evening-out traffic, among many. Hermes is a
limited-overhead deadlock-free hybrid routing algorithm, utilizing
load-balancing routing on fault-free paths to sustain high-throughput, while
providing pre-reconfigured escape path selection in the vicinity of faults.
Under such online mechanisms, Hermes's performance degrades gracefully with
increasing faulty link counts, a crucially desirable response lacking in
prior-art. Additionally, Hermes identifies non-communicating network partitions
in scenarios where faulty links are topologically densely distributed such that
packets being routed to physically isolated regions cause no network stagnation
due to indefinite chained blockages starting at sub-network boundaries. An
extensive experimental evaluation, including utilizing traffic workloads
gathered from full-system chip multi-processor simulations, shows that Hermes
improves network throughput by up to $3\times$ when compared against the
state-of-the-art. Further, hardware synthesis results prove Hermes's efficacy.
"
1525,Compiler Directed Speculative Intermittent Computation,"  This paper presents CoSpec, a new architecture/compiler co-design scheme that
works for commodity in-order processors used in energy-harvesting systems. To
achieve crash consistency without requiring unconventional architectural
support, CoSpec leverages speculation assuming that power failure is not going
to occur and thus holds all committed stores in a store buffer (SB), as if they
were speculative, in case of mispeculation. CoSpec compiler first partitions a
given program into a series of recoverable code regions with the SB size in
mind, so that no region overflows the SB. When the program control reaches the
end of each region, the speculation turns out to be successful, thus releasing
all the buffered stores of the region to NVM. If power failure occurs during
the execution of a region, all its speculative stores disappear in the volatile
SB, i.e., they never affect program states in NVM. Consequently, the
interrupted region can be restarted with consistent program states in the wake
of power failure. To hide the latency of the SB release, i.e., essentially NVM
writes, at each region boundary, CoSpec overlaps the NVM writes of the current
region with the speculative execution of the next region. Such instruction
level parallelism gives an illusion of out-of-order execution on top of the
in-order processor, achieving a speedup of more than 1.2X when there is no
power outage. Our experiments on a set of real energy harvesting traces with
frequent outages demonstrate that CoSpec outperforms the state-of-the-art
scheme by 1.8~3X on average.
"
1526,"fault: A Python Embedded Domain-Specific Language For Metaprogramming
  Portable Hardware Verification Components","  While hardware generators have drastically improved design productivity, they
have introduced new challenges for the task of verification. To effectively
cover the functionality of a sophisticated generator, verification engineers
require tools that provide the flexibility of metaprogramming. However,
flexibility alone is not enough; components must also be portable in order to
encourage the proliferation of verification libraries as well as enable new
methodologies. This paper introduces fault, a Python embedded hardware
verification language that aims to empower design teams to realize the full
potential of generators.
"
1527,"Optimizing Placement of Heap Memory Objects in Energy-Constrained Hybrid
  Memory Systems","  Main memory (DRAM) significantly impacts the power and energy utilization of
the overall server system. Non-Volatile Memory (NVM) devices, such as Phase
Change Memory and Spin-Transfer Torque RAM, are suitable candidates for main
memory to reduce energy consumption. But unlike DRAM, NVMs access latencies are
higher than DRAM and NVM writes are more energy sensitive than DRAM write
operations. Thus, Hybrid Main Memory Systems (HMMS) employing DRAM and NVM have
been proposed to reduce the overall energy depletion of main memory while
optimizing the performance of NVM. This paper proposes eMap, an optimal heap
memory object placement planner in HMMS. eMap considers the object-level access
patterns and energy consumption at the application level and provides an ideal
placement strategy for each object to augment performance and energy
utilization. eMap is equipped with two modules, eMPlan and eMDyn. Specifically,
eMPlan is a static placement planner which provides one time placement policies
for memory object to meet the energy budget while eMDyn is a runtime placement
planner to consider the change in energy limiting constraint during the runtime
and shuffles the memory objects by taking into account the access patterns as
well as the migration cost in terms of energy and performance. The evaluation
shows that our proposed solution satisfies both the energy limiting constraint
and the performance. We compare our methodology with the state-of-the-art
memory object classification and allocation (MOCA) framework. Our extensive
evaluation shows that our proposed solution, eMPlan meets the energy constraint
with 4.17 times less costly and reducing the energy consumption up to 14% with
the same performance. eMDyn also satisfies the performance and energy
requirement while considering the migration cost in terms of time and energy.
"
1528,"SCARE: Side Channel Attack on In-Memory Computing for Reverse
  Engineering","  In-memory computing architectures provide a much needed solution to
energy-efficiency barriers posed by Von-Neumann computing due to the movement
of data between the processor and the memory. Functions implemented in such
in-memory architectures are often proprietary and constitute confidential
Intellectual Property. Our studies indicate that IMCs implemented using RRAM
are susceptible to Side Channel Attack. Unlike conventional SCAs that are aimed
to leak private keys from cryptographic implementations, SCARE can reveal the
sensitive IP implemented within the memory. Therefore, the adversary does not
need to perform invasive Reverse Engineering to unlock the functionality. We
demonstrate SCARE by taking recent IMC architectures such as DCIM and MAGIC as
test cases. Simulation results indicate that AND, OR, and NOR gates (building
blocks of complex functions) yield distinct power and timing signatures based
on the number of inputs making them vulnerable to SCA. Although process
variations can obfuscate the signatures due to significant overlap, we show
that the adversary can use statistical modeling and analysis to identify the
structure of the implemented function. SCARE can find the implemented IP by
testing a limited number of patterns. For example, the proposed technique
reduces the number of patterns by 64% compared to a brute force attack for a+bc
function. Additionally, analysis shows improvement in SCAREs detection model
due to adversarial change in supply voltage for both DCIM and MAGIC. We also
propose countermeasures such as redundant inputs and expansion of literals.
Redundant inputs can mask the IP with 25% area and 20% power overhead. However,
functions can be found by greater RE effort. Expansion of literals incurs 36%
power overhead. However, it imposes brute force search by the adversary for
which the RE effort increases by 3.04X.
"
1529,Fetch-Directed Instruction Prefetching Revisited,"  Prior work has observed that fetch-directed prefetching (FDIP) is highly
effective at covering instruction cache misses. The key to FDIP's effectiveness
is having a sufficiently large BTB to accommodate the application's branch
working set. In this work, we introduce several optimizations that
significantly extend the reach of the BTB within the available storage budget.
Our optimizations target nearly every source of storage overhead in each BTB
entry; namely, the tag, target address, and size fields.
  We observe that while most dynamic branch instances have short offsets, a
large number of branches has longer offsets or requires the use of full target
addresses. Based on this insight, we break-up the BTB into multiple smaller
BTBs, each storing offsets of different length. This enables a dramatic
reduction in storage for target addresses. We further compress tags to 16 bits
and avoid the use of the basic-block-oriented BTB advocated in prior FDIP
variants. The latter optimization eliminates the need to store the basic block
size in each BTB entry. Our final design, called FDIP-X, uses an ensemble of 4
BTBs and always outperforms conventional FDIP with a unified
basic-block-oriented BTB for equal storage budgets.
"
1530,Bit Error Robustness for Energy-Efficient DNN Accelerators,"  Deep neural network (DNN) accelerators received considerable attention in
past years due to saved energy compared to mainstream hardware. Low-voltage
operation of DNN accelerators allows to further reduce energy consumption
significantly, however, causes bit-level failures in the memory storing the
quantized DNN weights. In this paper, we show that a combination of robust
fixed-point quantization, weight clipping, and random bit error training
(RandBET) improves robustness against random bit errors in (quantized) DNN
weights significantly. This leads to high energy savings from both low-voltage
operation as well as low-precision quantization. Our approach generalizes
across operating voltages and accelerators, as demonstrated on bit errors from
profiled SRAM arrays. We also discuss why weight clipping alone is already a
quite effective way to achieve robustness against bit errors. Moreover, we
specifically discuss the involved trade-offs regarding accuracy, robustness and
precision: Without losing more than 1% in accuracy compared to a normally
trained 8-bit DNN, we can reduce energy consumption on CIFAR-10 by 20%. Higher
energy savings of, e.g., 30%, are possible at the cost of 2.5% accuracy, even
for 4-bit DNNs.
"
1531,On the Difficulty of Designing Processor Arrays for Deep Neural Networks,"  Systolic arrays are a promising computing concept which is in particular
inline with CMOS technology trends and linear algebra operations found in the
processing of artificial neural networks. The recent success of such deep
learning methods in a wide set of applications has led to a variety of models,
which albeit conceptual similar as based on convolutions and fully-connected
layers, in detail show a huge diversity in operations due to a large design
space: An operand's dimension varies substantially since it depends on design
principles such as receptive field size, number of features, striding, dilating
and grouping of features. Last, recent networks extent previously plain
feedforward models by various connectivity, such as in ResNet or DenseNet. The
problem of choosing an optimal systolic array configuration cannot be solved
analytically, thus instead methods and tools are required that facilitate a
fast and accurate reasoning about optimality in terms of total cycles,
utilization, and amount of data movements. In this work we introduce Camuy, a
lightweight model of a weight-stationary systolic array for linear algebra
operations that allows quick explorations of different configurations, such as
systolic array dimensions and input/output bitwidths. Camuy aids accelerator
designers in either finding optimal configurations for a particular network
architecture or for robust performance across a variety of network
architectures. It offers simple integration into existing machine learning tool
stacks (e.g TensorFlow) through custom operators. We present an analysis of
popular DNN models to illustrate how it can estimate required cycles, data
movement costs, as well as systolic array utilization, and show how the
progress in network architecture design impacts the efficiency of inference on
accelerators based on systolic arrays.
"
1532,Block-matching in FPGA,"  Block-matching and 3D filtering (BM3D) is an image denoising algorithm that
works in two similar steps. Both of these steps need to perform grouping by
block-matching. We implement the block-matching in an FPGA, leveraging its
ability to perform parallel computations. Our goal is to enable other
researchers to use our solution in the future for real-time video denoising in
video cameras that use FPGAs (such as the AXIOM Beta).
"
1533,"Arnold: an eFPGA-Augmented RISC-V SoC for Flexible and Low-Power IoT
  End-Nodes","  A wide range of Internet of Things (IoT) applications require powerful,
energy-efficient and flexible end-nodes to acquire data from multiple sources,
process and distill the sensed data through near-sensor data analytics
algorithms, and transmit it wirelessly. This work presents Arnold: a 0.5 V to
0.8 V, 46.83 uW/MHz, 600 MOPS fully programmable RISC-V Microcontroller unit
(MCU) fabricated in 22 nm Globalfoundries GF22FDX (GF22FDX) technology, coupled
with a stateof-the-art (SoA) microcontroller to an embedded Field Programmable
Gate Array (FPGA). We demonstrate the flexibility of the System-OnChip (SoC) to
tackle the challenges of many emerging IoT applications, such as (i)
interfacing sensors and accelerators with non-standard interfaces, (ii)
performing on-the-fly pre-processing tasks on data streamed from peripherals,
and (iii) accelerating near-sensor analytics, encryption, and machine learning
tasks. A unique feature of the proposed SoC is the exploitation of body-biasing
to reduce leakage power of the embedded FPGA (eFPGA) fabric by up to 18x at 0.5
V, achieving SoA state bitstream-retentive sleep power for the eFPGA fabric, as
low as 20.5 uW. The proposed SoC provides 3.4x better performance and 2.9x
better energy efficiency than other fabricated heterogeneous re-configurable
SoCs of the same class.
"
1534,A Fast Finite Field Multiplier for SIKE,"  Various post-quantum cryptography algorithms have been recently proposed.
Supersingluar isogeny Diffie-Hellman key exchange (SIKE) is one of the most
promising candidates due to its small key size. However, the SIKE scheme
requires numerous finite field multiplications for its isogeny computation, and
hence suffers from slow encryption and decryption process. In this paper, we
propose a fast finite field multiplier design that performs multiplications in
GF(p) with high throughput and low latency. The design accelerates the
computation by adopting deep pipelining, and achieves high hardware utilization
through data interleaving. The proposed finite field multiplier demonstrates
4.48 times higher throughput than prior work based on the identical fast
multiplication algorithm and 1.43 times higher throughput than the
state-of-the-art fast finite field multiplier design aimed at SIKE.
"
1535,"DRACO: Co-Optimizing Hardware Utilization, and Performance of DNNs on
  Systolic Accelerator","  The number of processing elements (PEs) in a fixed-sized systolic accelerator
is well matched for large and compute-bound DNNs; whereas, memory-bound DNNs
suffer from PE underutilization and fail to achieve peak performance and energy
efficiency. To mitigate this, specialized dataflow and/or micro-architectural
techniques have been proposed. However, due to the longer development cycle and
the rapid pace of evolution in the deep learning fields, these hardware-based
solutions can be obsolete and ineffective in dealing with PE underutilization
for state-of-the-art DNNs. In this work, we address the challenge of PE
underutilization at the algorithm front and propose data reuse aware
co-optimization (DRACO). This improves the PE utilization of memory-bound DNNs
without any additional need for dataflow/micro-architecture modifications.
Furthermore, unlike the previous co-optimization methods, DRACO not only
maximizes performance and energy efficiency but also improves the predictive
performance of DNNs. To the best of our knowledge, DRACO is the first work that
resolves the resource underutilization challenge at the algorithm level and
demonstrates a trade-off between computational efficiency, PE utilization, and
predictive performance of DNN. Compared to the state-of-the-art row stationary
dataflow, DRACO achieves 41.8% and 42.6% improvement in average PE utilization
and inference latency (respectively) with negligible loss in predictive
performance in MobileNetV1 on a $64\times64$ systolic array. DRACO provides
seminal insights for utilization-aware DNN design methodologies that can fully
leverage the computation power of systolic array-based hardware accelerators.
"
1536,"End-to-End AI-Based Point-of-Care Diagnosis System for Classifying
  Respiratory Illnesses and Early Detection of COVID-19","  Respiratory symptoms can be a caused by different underlying conditions, and
are often caused by viral infections, such as Influenza-like illnesses or other
emerging viruses like the Coronavirus. These respiratory viruses, often, have
common symptoms, including coughing, high temperature, congested nose, and
difficulty breathing. However, early diagnosis of the type of the virus, can be
crucial, especially in cases such as the recent COVID-19 pandemic. One of the
factors that contributed to the spread of the pandemic, was the late diagnosis
or confusing it with regular flu-like symptoms. Science has proved that one of
the possible differentiators of the underlying causes of these different
respiratory diseases is coughing, which comes in different types and forms.
Therefore, a reliable lab-free tool for early and more accurate diagnosis that
can differentiate between different respiratory diseases is very much needed.
This paper proposes an end-to-end portable system that can record data from
patients with symptom, including coughs (voluntary or involuntary) and
translate them into health data for diagnosis, and with the aid of machine
learning, classify them into different respiratory illnesses, including
COVID-19. With the ongoing efforts to stop the spread of the COVID-19 disease
everywhere today, and against similar diseases in the future, our proposed low
cost and user-friendly solution can play an important part in the early
diagnosis.
"
1537,An Imitation Learning Approach for Cache Replacement,"  Program execution speed critically depends on increasing cache hits, as cache
hits are orders of magnitude faster than misses. To increase cache hits, we
focus on the problem of cache replacement: choosing which cache line to evict
upon inserting a new line. This is challenging because it requires planning far
ahead and currently there is no known practical solution. As a result, current
replacement policies typically resort to heuristics designed for specific
common access patterns, which fail on more diverse and complex access patterns.
In contrast, we propose an imitation learning approach to automatically learn
cache access patterns by leveraging Belady's, an oracle policy that computes
the optimal eviction decision given the future cache accesses. While directly
applying Belady's is infeasible since the future is unknown, we train a policy
conditioned only on past accesses that accurately approximates Belady's even on
diverse and complex access patterns, and call this approach Parrot. When
evaluated on 13 of the most memory-intensive SPEC applications, Parrot
increases cache miss rates by 20% over the current state of the art. In
addition, on a large-scale web search benchmark, Parrot increases cache hit
rates by 61% over a conventional LRU policy. We release a Gym environment to
facilitate research in this area, as data is plentiful, and further
advancements can have significant real-world impact.
"
1538,"SeMPE: Secure Multi Path Execution Architecture for Removing Conditional
  Branch Side Channels","  One of the most prevalent source of side channel vulnerabilities is the
secret-dependent behavior of conditional branches (SDBCB). The state-of-the-art
solution relies on Constant-Time Expressions, which require high programming
effort and incur high performance overheads. In this paper, we propose SeMPE,
an approach that relies on architecture support to eliminate SDBCB without
requiring much programming effort while incurring low performance overheads.
The key idea is that when a secret-dependent branch is encountered, the SeMPE
microarchitecture fetches, executes, and commits both paths of the branch,
preventing the adversary from inferring secret values from the branching
behavior of the program. To enable that, SeMPE relies on an architecture that
is capable of safely executing both branch paths sequentially. Through
microbenchmarks and an evaluation of a real-world library, we show that SeMPE
incurs near ideal execution time overheads, which is the sum of the execution
time of all branch paths of secret-dependent branches. SeMPE outperforms code
generated by FaCT, a constant-time expression language, by up to a factor of
18x.
"
1539,"ReversiSpec: Reversible Coherence Protocol for Defending Transient
  Attacks","  The recent works such as InvisiSpec, SafeSpec, and Cleanup-Spec, among
others, provided promising solutions to defend speculation induced (transient)
attacks. However, they intro-duce delay either when a speculative load becomes
safe in the redo approach or when it is squashed in the undo approach. We argue
that it is due to the lack of fundamental mechanisms for reversing the effects
of speculation in a cache coherence protocol. Based on mostly unmodified
coherence protocol, the redo approach avoids leaving trace at the expense of
double loads; the undo approach ""stops the world"" in recovery to avoid
interference. This paper provides the first solution to the fundamental
problem. Specifically, we propose ReversiSpec, a comprehensive solution to
mitigate speculative induced attacks.ReversiSpec is a reversible approach that
uses speculative buffers in all cache levels to record the effects of
speculative execution. When a speculative load becomes safe, a merge operation
adds the effects of speculative execution to the global state. When a
speculative load is squashed, a purge operation clears the buffered speculative
execution states from speculative buffer. The key problem solved by the paper
is the first demonstration of a reversible cache coherence protocol that
naturally rollbacks the effects of squashed speculative execution. We design
two concrete coherence protocols, ReversiCC-Lazy and ReversiCC-Eager providing
the same functionality with different trade-offs. Our solution closes a crucial
gap in modern architecture: just like the mechanisms to roll back the
speculation effects inside a processor, ReversiSpec provides the mechanisms to
roll back the state of the whole coherence protocol.
"
1540,Firmware Insider: Bluetooth Randomness is Mostly Random,"  Bluetooth chips must include a Random Number Generator (RNG). This RNG is
used internally within cryptographic primitives but also exposed to the
operating system for chip-external applications. In general, it is a black box
with security-critical authentication and encryption mechanisms depending on
it. In this paper, we evaluate the quality of RNGs in various Broadcom and
Cypress Bluetooth chips. We find that the RNG implementation significantly
changed over the last decade. Moreover, most devices implement an insecure
Pseudo-Random Number Generator (PRNG) fallback. Multiple popular devices, such
as the Samsung Galaxy S8 and its variants as well as an iPhone, rely on the
weak fallback due to missing a Hardware Random Number Generator (HRNG). We
statistically evaluate the output of various HRNGs in chips used by hundreds of
millions of devices. While the Broadcom and Cypress HRNGs pass advanced tests,
it remains indistinguishable for users if a Bluetooth chip implements a secure
RNG without an extensive analysis as in this paper. We describe our measurement
methods and publish our tools to enable further public testing.
"
1541,TDO-CIM: Transparent Detection and Offloading for Computation In-memory,"  Computation in-memory is a promising non-von Neumann approach aiming at
completely diminishing the data transfer to and from the memory subsystem.
Although a lot of architectures have been proposed, compiler support for such
architectures is still lagging behind. In this paper, we close this gap by
proposing an end-to-end compilation flow for in-memory computing based on the
LLVM compiler infrastructure. Starting from sequential code, our approach
automatically detects, optimizes, and offloads kernels suitable for in-memory
acceleration. We demonstrate our compiler tool-flow on the PolyBench/C
benchmark suite and evaluate the benefits of our proposed in-memory
architecture simulated in Gem5 by comparing it with a state-of-the-art von
Neumann architecture.
"
1542,"Efficient Communication Acceleration for Next-Gen Scale-up Deep Learning
  Training Platforms","  Deep Learning (DL) training platforms are built by interconnecting multiple
DL accelerators (e.g., GPU/TPU) via fast, customized interconnects. As the size
of DL models and the compute efficiency of the accelerators has continued to
increase, there has also been a corresponding steady increase in the bandwidth
of these interconnects.Systems today provide 100s of gigabytes (GBs) of
inter-connect bandwidth via a mix of solutions such as Multi-Chip packaging
modules (MCM) and proprietary interconnects(e.g., NVlink) that together from
the scale-up network of accelerators. However, as we identify in this work, a
significant portion of this bandwidth goes under-utilized. This is because(i)
using compute cores for executing collective operations such as all-reduce
decreases overall compute efficiency, and(ii) there is memory bandwidth
contention between the accesses for arithmetic operations vs those for
collectives, and(iii) there are significant internal bus congestions that
increase the latency of communication operations. To address this challenge, we
propose a novel microarchitecture, calledAccelerator Collectives Engine(ACE),
forDL collective communication offload. ACE is a smart net-work interface (NIC)
tuned to cope with the high-bandwidth and low latency requirements of scale-up
networks and is able to efficiently drive the various scale-up network
systems(e.g. switch-based or point-to-point topologies). We evaluate the
benefits of the ACE with micro-benchmarks (e.g. single collective performance)
and popular DL models using an end-to-end DL training simulator. For modern DL
workloads, ACE on average increases the net-work bandwidth utilization by
1.97X, resulting in 2.71X and 1.44X speedup in iteration time for ResNet-50 and
GNMT, respectively.
"
1543,"Hardware Acceleration of Sparse and Irregular Tensor Computations of ML
  Models: A Survey and Insights","  Machine learning (ML) models are widely used in many domains including media
processing and generation, computer vision, medical diagnosis, embedded
systems, high-performance and scientific computing, and recommendation systems.
For efficiently processing these computational- and memory-intensive
applications, tensors of these over-parameterized models are compressed by
leveraging sparsity, size reduction, and quantization of tensors. Unstructured
sparsity and tensors with varying dimensions yield irregular-shaped
computation, communication, and memory access patterns; processing them on
hardware accelerators in a conventional manner does not inherently leverage
acceleration opportunities. This paper provides a comprehensive survey on how
to efficiently execute sparse and irregular tensor computations of ML models on
hardware accelerators. In particular, it discusses additional enhancement
modules in architecture design and software support; categorizes different
hardware designs and acceleration techniques and analyzes them in terms of
hardware and execution costs; highlights further opportunities in terms of
hardware/software/algorithm co-design optimizations and joint optimizations
among described hardware and software enhancement modules. The takeaways from
this paper include: understanding the key challenges in accelerating sparse,
irregular-shaped, and quantized tensors; understanding enhancements in
acceleration systems for supporting their efficient computations; analyzing
trade-offs in opting for a specific type of design enhancement; understanding
how to map and compile models with sparse tensors on the accelerators;
understanding recent design trends for efficient accelerations and further
opportunities.
"
1544,Efficient Neural Network Deployment for Microcontroller,"  Edge computing for neural networks is getting important especially for low
power applications and offline devices. TensorFlow Lite and PyTorch Mobile were
released for this purpose. But they mainly support mobile devices instead of
microcontroller level yet. Microcontroller support is an emerging area now.
There are many approaches to reduce network size and compute load like pruning,
binarization and layer manipulation i.e. operator reordering. This paper is
going to explore and generalize convolution neural network deployment for
microcontrollers with two novel optimization proposals offering memory saving
and compute efficiency in 2D convolutions as well as fully connected layers.
The first one is in-place max-pooling, if the stride is greater than or equal
to pooling kernel size. The second optimization is to use ping-pong buffers
between layers to reduce memory consumption significantly. The memory savings
and performance will be compared with CMSIS-NN framework developed for ARM
Cortex-M CPUs. The final purpose is to develop a tool consuming PyTorch model
with trained network weights, and it turns into an optimized inference
engine(forward pass) in C/C++ for low memory(kilobyte level) and limited
computing capable microcontrollers.
"
1545,"DATE: Defense Against TEmperature Side-Channel Attacks in DVFS Enabled
  MPSoCs","  Given the constant rise in utilizing embedded devices in daily life, side
channels remain a challenge to information flow control and security in such
systems. One such important security flaw could be exploited through
temperature side-channel attacks, where heat dissipation and propagation from
the processing elements are observed over time in order to deduce security
flaws. In our proposed methodology, DATE: Defense Against TEmperature
side-channel attacks, we propose a novel approach of reducing spatial and
temporal thermal gradient, which makes the system more secure against
temperature side-channel attacks, and at the same time increases the
reliability of the device in terms of lifespan. In this paper, we have also
introduced a new metric, Thermal-Security-in-Multi-Processors (TSMP), which is
capable of quantifying the security against temperature side-channel attacks on
computing systems, and DATE is evaluated to be 139.24% more secure at the most
for certain applications than the state-of-the-art, while reducing thermal
cycle by 67.42% at the most.
"
1546,"Deep-PowerX: A Deep Learning-Based Framework for Low-Power Approximate
  Logic Synthesis","  This paper aims at integrating three powerful techniques namely Deep
Learning, Approximate Computing, and Low Power Design into a strategy to
optimize logic at the synthesis level. We utilize advances in deep learning to
guide an approximate logic synthesis engine to minimize the dynamic power
consumption of a given digital CMOS circuit, subject to a predetermined error
rate at the primary outputs. Our framework, Deep-PowerX, focuses on replacing
or removing gates on a technology-mapped network and uses a Deep Neural Network
(DNN) to predict error rates at primary outputs of the circuit when a specific
part of the netlist is approximated. The primary goal of Deep-PowerX is to
reduce the dynamic power whereas area reduction serves as a secondary
objective. Using the said DNN, Deep-PowerX is able to reduce the exponential
time complexity of standard approximate logic synthesis to linear time.
Experiments are done on numerous open source benchmark circuits. Results show
significant reduction in power and area by up to 1.47 times and 1.43 times
compared to exact solutions and by up to 22% and 27% compared to
state-of-the-art approximate logic synthesis tools while having orders of
magnitudes lower run-time.
"
1547,"FPnew: An Open-Source Multi-Format Floating-Point Unit Architecture for
  Energy-Proportional Transprecision Computing","  The slowdown of Moore's law and the power wall necessitates a shift towards
finely tunable precision (a.k.a. transprecision) computing to reduce energy
footprint. Hence, we need circuits capable of performing floating-point
operations on a wide range of precisions with high energy-proportionality. We
present FPnew, a highly configurable open-source transprecision floating-point
unit (TP-FPU) capable of supporting a wide range of standard and custom FP
formats. To demonstrate the flexibility and efficiency of FPnew in
general-purpose processor architectures, we extend the RISC-V ISA with
operations on half-precision, bfloat16, and an 8bit FP format, as well as SIMD
vectors and multi-format operations. Integrated into a 32-bit RISC-V core, our
TP-FPU can speed up execution of mixed-precision applications by 1.67x w.r.t.
an FP32 baseline, while maintaining end-to-end precision and reducing system
energy by 37%. We also integrate FPnew into a 64-bit RISC-V core, supporting
five FP formats on scalars or 2, 4, or 8-way SIMD vectors. For this core, we
measured the silicon manufactured in Globalfoundries 22FDX technology across a
wide voltage range from 0.45V to 1.2V. The unit achieves leading-edge measured
energy efficiencies between 178 Gflop/sW (on FP64) and 2.95 Tflop/sW (on 8-bit
mini-floats), and a performance between 3.2 Gflop/s and 25.3 Gflop/s.
"
1548,A Machine Learning Pipeline Stage for Adaptive Frequency Adjustment,"  A machine learning (ML) design framework is proposed for adaptively adjusting
clock frequency based on propagation delay of individual instructions. A random
forest model is trained to classify propagation delays in real time, utilizing
current operation type, current operands, and computation history as ML
features. The trained model is implemented in Verilog as an additional pipeline
stage within a baseline processor. The modified system is experimentally tested
at the gate level in 45 nm CMOS technology, exhibiting a speedup of 70% and
energy reduction of 30% with coarse-grained ML classification. A speedup of 89%
is demonstrated with finer granularities with 15.5% reduction in energy
consumption.
"
1549,"Exploiting Extended Krylov Subspace for the Reduction of Regular and
  Singular Circuit Models","  During the past decade, Model Order Reduction (MOR) has become key enabler
for the efficient simulation of large circuit models. MOR techniques based on
moment-matching are well established due to their simplicity and computational
performance in the reduction process. However, moment-matching methods based on
the ordinary Krylov subspace are usually inadequate to accurately approximate
the original circuit behavior. In this paper, we present a moment-matching
method which is based on the extended Krylov subspace and exploits the
superposition property in order to deal with many terminals. The proposed
method can handle large-scale regular and singular circuits and generate
accurate and efficient reduced-order models for circuit simulation.
Experimental results on industrial IBM power grids demonstrate that our method
achieves an error reduction up to 83.69% over a standard Krylov subspace
method.
"
1550,A Case for Lifetime Reliability-Aware Neuromorphic Computing,"  Neuromorphic computing with non-volatile memory (NVM) can significantly
improve performance and lower energy consumption of machine learning tasks
implemented using spike-based computations and bio-inspired learning
algorithms. High voltages required to operate certain NVMs such as phase-change
memory (PCM) can accelerate aging in a neuron's CMOS circuit, thereby reducing
the lifetime of neuromorphic hardware. In this work, we evaluate the long-term,
i.e., lifetime reliability impact of executing state-of-the-art machine
learning tasks on a neuromorphic hardware, considering failure models such as
negative bias temperature instability (NBTI) and time-dependent dielectric
breakdown (TDDB). Based on such formulation, we show the
reliability-performance trade-off obtained due to periodic relaxation of
neuromorphic circuits, i.e., a stop-and-go style of neuromorphic computing.
"
1551,A Ring Router Microarchitecture for NoCs,"  Network-on-Chip (NoC) has become a popular choice for connecting a large
number of processing cores in chip multiprocessor design. In a conventional NoC
design, most of the area in the router is occupied by the buffers and the
crossbar switch. These two components also consume the majority of the router's
power. Much of the research in NoC has been based on the conventional router
microarchitecture. We propose a novel router microarchitecture that treats the
router itself as a small network of the ring topology. It eliminates the large
crossbar switch in the conventional design. In addition, network latency is
much reduced. Simulation and circuit synthesis show that the proposed
microarchitecture can reduce the latency, area and power by 53%, 34% and 27%,
respectively, compared to the conventional design.
"
1552,The gem5 Simulator: Version 20.0+,"  The open-source and community-supported gem5 simulator is one of the most
popular tools for computer architecture research. This simulation
infrastructure allows researchers to model modern computer hardware at the
cycle level, and it has enough fidelity to boot unmodified Linux-based
operating systems and run full applications for multiple architectures
including x86, Arm, and RISC-V. The gem5 simulator has been under active
development over the last nine years since the original gem5 release. In this
time, there have been over 7500 commits to the codebase from over 250 unique
contributors which have improved the simulator by adding new features, fixing
bugs, and increasing the code quality. In this paper, we give and overview of
gem5's usage and features, describe the current state of the gem5 simulator,
and enumerate the major changes since the initial release of gem5. We also
discuss how the gem5 simulator has transitioned to a formal governance model to
enable continued improvement and community support for the next 20 years of
computer architecture research.
"
1553,Single Storage Semi-Global Matching for Real Time Depth Processing,"  Depth-map is the key computation in computer vision and robotics. One of the
most popular approach is via computation of disparity-map of images obtained
from Stereo Camera. Semi Global Matching (SGM) method is a popular choice for
good accuracy with reasonable computation time. To use such compute-intensive
algorithms for real-time applications such as for autonomous aerial vehicles,
blind Aid, etc. acceleration using GPU, FPGA is necessary. In this paper, we
show the design and implementation of a stereo-vision system, which is based on
FPGA-implementation of More Global Matching(MGM). MGM is a variant of SGM. We
use 4 paths but store a single cumulative cost value for a corresponding pixel.
Our stereo-vision prototype uses Zedboard containing an ARM-based Zynq-SoC,
ZED-stereo-camera / ELP stereo-camera / Intel RealSense D435i, and VGA for
visualization. The power consumption attributed to the custom FPGA-based
acceleration of disparity map computation required for depth-map is just 0.72
watt. The update rate of the disparity map is realistic 10.5 fps.
"
1554,"HALCONE : A Hardware-Level Timestamp-based Cache Coherence Scheme for
  Multi-GPU systems","  While multi-GPU (MGPU) systems are extremely popular for compute-intensive
workloads, several inefficiencies in the memory hierarchy and data movement
result in a waste of GPU resources and difficulties in programming MGPU
systems. First, due to the lack of hardware-level coherence, the MGPU
programming model requires the programmer to replicate and repeatedly transfer
data between the GPUs' memory. This leads to inefficient use of precious GPU
memory. Second, to maintain coherency across an MGPU system, transferring data
using low-bandwidth and high-latency off-chip links leads to degradation in
system performance. Third, since the programmer needs to manually maintain data
coherence, the programming of an MGPU system to maximize its throughput is
extremely challenging. To address the above issues, we propose a novel
lightweight timestamp-based coherence protocol, HALCONE, for MGPU systems and
modify the memory hierarchy of the GPUs to support physically shared memory.
HALCONE replaces the Compute Unit (CU) level logical time counters with cache
level logical time counters to reduce coherence traffic. Furthermore, HALCONE
introduces a novel timestamp storage unit (TSU) with no additional performance
overhead in the main memory to perform coherence actions. Our proposed HALCONE
protocol maintains the data coherence in the memory hierarchy of the MGPU with
minimal performance overhead (less than 1\%). Using a set of standard MGPU
benchmarks, we observe that a 4-GPU MGPU system with shared memory and HALCONE
performs, on average, 4.6$\times$ and 3$\times$ better than a 4-GPU MGPU system
with existing RDMA and with the recently proposed HMG coherence protocol,
respectively. We demonstrate the scalability of HALCONE using different GPU
counts (2, 4, 8, and 16) and different CU counts (32, 48, and 64 CUs per GPU)
for 11 standard benchmarks.
"
1555,"IOCA: High-Speed I/O-Aware LLC Management for Network-Centric
  Multi-Tenant Platform","  In modern server CPUs, last-level cache (LLC) is a critical hardware resource
that exerts significant influence on the performance of the workloads, and how
to manage LLC is a key to the performance isolation and QoS in the cloud with
multi-tenancy. In this paper, we argue that besides CPU cores, high-speed
network I/O is also important for LLC management. This is because of an Intel
architectural innovation -- Data Direct I/O (DDIO) -- that directly injects the
inbound I/O traffic to (part of) the LLC instead of the main memory. We
summarize two problems caused by DDIO and show that (1) the default DDIO
configuration may not always achieve optimal performance, (2) DDIO can decrease
the performance of non-I/O workloads which share LLC with it by as high as 32%.
  We then present IOCA, the first LLC management mechanism for network-centric
platforms that treats the I/O as the first-class citizen. IOCA monitors and
analyzes the performance of the cores, LLC, and DDIO using CPU's hardware
performance counters, and adaptively adjusts the number of LLC ways for DDIO or
the tenants that demand more LLC capacity. In addition, IOCA dynamically
chooses the tenants that share its LLC resource with DDIO, to minimize the
performance interference by both the tenants and the I/O. Our experiments with
multiple microbenchmarks and real-world applications in two major end-host
network models demonstrate that IOCA can effectively reduce the performance
degradation caused by DDIO, with minimal overhead.
"
1556,"Hardware Implementation of Keyless Encryption Scheme for Internet of
  Things Based on Image of Memristors","  The Internet of Things (IoT) is rapidly increasing the number of connected
devices. This causes new concerns towards solutions for authenticating numerous
IoT devices. Most of these devices are resource-constrained. Therefore, the use
of long-secret keys, in traditional cryptography schemes can be hard to
implement. Also, the key generation, distribution, and storage are very
complex. Moreover, the goal of many reported cyber-attacks is accessing the
key. Therefore, researchers have shown an increased interest in designing
keyless encryption schemes recently. In this report, we are going to explain
the details of the implementation of the keyless protocol by taking advantage
of known technology modules such as microcontrollers (MCU), and hash functions.
Physical Unclonable Functions (PUFs) have been used in many cryptographic
applications such as Password Management Systems, key exchange, Key Generation.
In this report, we are going to explain the details of the hardware
implementation of keyless encryption in the MCU. Different kinds of memristors
have been used in the past. In this work, a look-up-table containing memristor
cells value at the various current levels is used since the physical component
is unavailable yet. The hardware that is used to implement the system is an
evaluation-board of SAMV71 MCU, which is used to implement the control system
and hardware hashing.
"
1557,"Hardware Implementation of Deep Network Accelerators Towards Healthcare
  and Biomedical Applications","  With the advent of dedicated Deep Learning (DL) accelerators and neuromorphic
processors, new opportunities are emerging for applying deep and Spiking Neural
Network (SNN) algorithms to healthcare and biomedical applications at the edge.
This can facilitate the advancement of the medical Internet of Things (IoT)
systems and Point of Care (PoC) devices. In this paper, we provide a tutorial
describing how various technologies ranging from emerging memristive devices,
to established Field Programmable Gate Arrays (FPGAs), and mature Complementary
Metal Oxide Semiconductor (CMOS) technology can be used to develop efficient DL
accelerators to solve a wide variety of diagnostic, pattern recognition, and
signal processing problems in healthcare. Furthermore, we explore how spiking
neuromorphic processors can complement their DL counterparts for processing
biomedical signals. After providing the required background, we unify the
sparsely distributed research on neural network and neuromorphic hardware
implementations as applied to the healthcare domain. In addition, we benchmark
various hardware platforms by performing a biomedical electromyography (EMG)
signal processing task and drawing comparisons among them in terms of inference
delay and energy. Finally, we provide our analysis of the field and share a
perspective on the advantages, disadvantages, challenges, and opportunities
that different accelerators and neuromorphic processors introduce to healthcare
and biomedical domains. This paper can serve a large audience, ranging from
nanoelectronics researchers, to biomedical and healthcare practitioners in
grasping the fundamental interplay between hardware, algorithms, and clinical
adoption of these tools, as we shed light on the future of deep networks and
spiking neuromorphic processing systems as proponents for driving biomedical
circuits and systems forward.
"
1558,"The Blockchain Based Auditor on Secret key Life Cycle in Reconfigurable
  Platform","  The growing sophistication of cyber attacks, vulnerabilities in high
computing systems and increasing dependency on cryptography to protect our
digital data make it more important to keep secret keys safe and secure. Few
major issues on secret keys like incorrect use of keys, inappropriate storage
of keys, inadequate protection of keys, insecure movement of keys, lack of
audit logging, insider threats and non-destruction of keys can compromise the
whole security system dangerously. In this article, we have proposed and
implemented an isolated secret key memory which can log life cycle of secret
keys cryptographically using blockchain (BC) technology. We have also
implemented a special custom bus interconnect which receives custom crypto
instruction from Processing Element (PE). During the execution of crypto
instructions, the architecture assures that secret key will never come in the
processor area and the movement of secret keys to various crypto core is
recorded cryptographically after the proper authentication process controlled
by proposed hardware based BC. To the best of our knowledge, this is the first
work which uses blockchain based solution to address the issues of the life
cycle of the secret keys in hardware platform. The additional cost of resource
usage and timing complexity we spent to implement the proposed idea is very
nominal. We have used Xilinx Vivado EDA tool and Artix 7 FPGA board.
"
1559,"HOBFLOPS CNNs: Hardware Optimized Bitsliced Floating-Point Operations
  Convolutional Neural Networks","  Convolutional neural network (CNN) inference is commonly performed with 8-bit
integer values. However, higher precision floating-point inference is required.
Existing processors support 16- or 32 bit FP but do not typically support
custom precision FP. We propose hardware optimized bit-sliced floating-point
operators (HOBFLOPS), a method of generating efficient custom-precision
emulated bitsliced software FP arithmetic, for CNNs. We compare
HOBFLOPS8-HOBFLOPS16 performance against SoftFP16 on Arm Neon and Intel
architectures. HOBFLOPS allows researchers to prototype arbitrary-levels of FP
arithmetic precision for CNN accelerators. Furthermore, HOBFLOPS fast
custom-precision FP CNNs in software may be valuable in cases where memory
bandwidth is limited.
"
1560,CMOS Ising Machines with Coupled Bistable Nodes,"  Ising machines use physics to naturally guide a dynamical system towards an
optimal state which can be read out as a heuristical solution to a
combinatorial optimization problem. Such designs that use nature as a computing
mechanism can lead to higher performance and/or lower operation costs. Quantum
annealers are a prominent example of such efforts. However, existing Ising
machines are generally bulky and energy intensive. Such disadvantages might
lead to intrinsic advantages at some larger scale in the future. But for now,
integrated electronic designs allow more immediate applications. We propose one
such design that uses bistable nodes, coupled with programmable and variable
strengths. The design is fully CMOS compatible for on-chip applications and
demonstrates competitive solution quality and significantly superior execution
time and energy.
"
1561,"Irregular Accesses Reorder Unit: Improving GPGPU Memory Coalescing for
  Graph-Based Workloads","  GPGPU architectures have become established as the dominant parallelization
and performance platform achieving exceptional popularization and empowering
domains such as regular algebra, machine learning, image detection and
self-driving cars. However, irregular applications struggle to fully realize
GPGPU performance as a result of control flow divergence and memory divergence
due to irregular memory access patterns.
  To ameliorate these issues, programmers are obligated to carefully consider
architecture features and devote significant efforts to modify the algorithms
with complex optimization techniques, which shift programmers priorities yet
struggle to quell the shortcomings. We show that in graph-based GPGPU irregular
applications these inefficiencies prevail, yet we find that it is possible to
relax the strict relationship between thread and data processed to empower new
optimizations.
  Based on this key idea, we propose the Irregular accesses Reorder Unit (IRU),
a novel hardware extension tightly integrated in the GPGPU pipeline. The IRU
reorders data processed by the threads on irregular accesses which
significantly improves memory coalescing, and allows increased performance and
energy efficiency. Additionally, the IRU is capable of filtering and merging
duplicated irregular access which further improves graph-based irregular
applications. Programmers can easily utilize the IRU with a simple API, or
compiler optimized generated code with the extended ISA instructions provided.
  We evaluate our proposal for state-of-the-art graph-based algorithms and a
wide selection of applications. Results show that the IRU achieves a memory
coalescing improvement of 1.32x and a 46% reduction in the overall traffic in
the memory hierarchy, which results in 1.33x and 13% improvement in performance
and energy savings respectively, while incurring in a small 5.6% area overhead.
"
1562,High-Throughput VLSI Architecture for GRAND,"  Guessing Random Additive Noise Decoding (GRAND) is a recently proposed
universal decoding algorithm for linear error correcting codes. Since GRAND
does not depend on the structure of the code, it can be used for any code
encountered in contemporary communication standards or may even be used for
random linear network coding. This property makes this new algorithm
particularly appealing. Instead of trying to decode the received vector, GRAND
attempts to identify the noise that corrupted the codeword. To that end, GRAND
relies on the generation of test error patterns that are successively applied
to the received vector. In this paper, we propose the first hardware
architecture for the GRAND algorithm. Considering GRAND with ABandonment
(GRANDAB) that limits the number of test patterns, the proposed architecture
only needs $2+\sum_{i=2}^{n} \left\lfloor\frac{i}{2}\right\rfloor$ time steps
to perform the $\sum_{i=1}^3 \binom{n}{i}$ queries required when $\text{AB}=3$.
For a code length of $128$, our proposed hardware architecture demonstrates
only a fraction ($1.2\%$) of the total number of performed queries as time
steps. Synthesis result using TSMC 65nm CMOS technology shows that average
throughputs of $32$ Gbps to $64$ Gbps can be achieved at an SNR of $10$ dB for
a code length of $128$ and code rates rate higher than $0.75$, transmitted over
an AWGN channel. Comparisons with a decoder tailored for a $(79,64)$ BCH code
show that the proposed architecture can achieve a slightly higher average
throughput at high SNRs, while obtaining the same decoding performance.
"
1563,"Hardware Acceleration of Monte-Carlo Sampling for Energy Efficient
  Robust Robot Manipulation","  Algorithms based on Monte-Carlo sampling have been widely adapted in robotics
and other areas of engineering due to their performance robustness. However,
these sampling-based approaches have high computational requirements, making
them unsuitable for real-time applications with tight energy constraints. In
this paper, we investigate 6 degree-of-freedom (6DoF) pose estimation for robot
manipulation using this method, which uses rendering combined with sequential
Monte-Carlo sampling. While potentially very accurate, the significant
computational complexity of the algorithm makes it less attractive for mobile
robots, where runtime and energy consumption are tightly constrained. To
address these challenges, we develop a novel hardware implementation of
Monte-Carlo sampling on an FPGA with lower computational complexity and memory
usage, while achieving high parallelism and modularization. Our results show
12X-21X improvements in energy efficiency over low-power and high-end GPU
implementations, respectively. Moreover, we achieve real time performance
without compromising accuracy.
"
1564,"Accelerating Geometric Multigrid Preconditioning with Half-Precision
  Arithmetic on GPUs","  With the hardware support for half-precision arithmetic on NVIDIA V100 GPUs,
high-performance computing applications can benefit from lower precision at
appropriate spots to speed up the overall execution time. In this paper, we
investigate a mixed-precision geometric multigrid method to solve large sparse
systems of equations stemming from discretization of elliptic PDEs. While the
final solution is always computed with high-precision accuracy, an iterative
refinement approach with multigrid preconditioning in lower precision and
residuum scaling is employed. We compare the FP64 baseline for Poisson's
equation to purely FP16 multigrid preconditioning and to the employment of
FP16-FP32-FP64 combinations within a mesh hierarchy. While the iteration count
is almost not affected by using lower accuracy, the solver runtime is
considerably decreased due to the reduced memory transfer and a speedup of up
to 2.5x is gained for the overall solver. We investigate the performance of
selected kernels with the hierarchical Roofline model.
"
1565,"Non-Relational Databases on FPGAs: Survey, Design Decisions, Challenges","  Non-relational database systems (NRDS), such as graph, document, key-value,
and wide-column, have gained much attention in various trending (business)
application domains like smart logistics, social network analysis, and medical
applications, due to their data model variety and scalability. The broad data
variety and sheer size of datasets pose unique challenges for the system design
and runtime (incl. power consumption). While CPU performance scaling becomes
increasingly more difficult, we argue that NRDS can benefit from adding field
programmable gate arrays (FPGAs) as accelerators. However, FPGA-accelerated
NRDS have not been systematically studied, yet.
  To facilitate understanding of this emerging domain, we explore the fit of
FPGA acceleration for NRDS with a focus on data model variety. We define the
term NRDS class as a group of non-relational database systems supporting the
same data model. This survey describes and categorizes the inherent differences
and non-trivial trade-offs of relevant NRDS classes as well as their
commonalities in the context of common design decisions when building such a
system with FPGAs. For example, we found in the literature that for key-value
stores the FPGA should be placed into the system as a smart network interface
card (SmartNIC) to benefit from direct access of the FPGA to the network.
However, more complex data models and processing of other classes (e.g., graph
and document) commonly require more elaborate near-data or socket accelerator
placements where the FPGA respectively has the only or shared access to main
memory. Across the different classes, FPGAs can be used as communication layer
or for acceleration of operators and data access. We close with open research
and engineering challenges to outline the future of FPGA-accelerated NRDS.
"
1566,"A 0.5GHz 0.35mW LDO-Powered Constant-Slope Phase Interpolator with
  0.22$\%$ INL","  Clock generators are an essential and critical building block of any
communication link, whether it be wired or wireless, and they are increasingly
critical given the push for lower I/O power and higher bandwidth in
Systems-on-Chip (SoCs) for the Internet-of-Things (IoT). One recurrent issue
with clock generators is multiple-phase generation, especially for low-power
applications; several methods of phase generation have been proposed, one of
which is phase interpolation. We propose a phase interpolator (PI) that employs
the concept of constant-slope operation. Consequently, a low-power
highly-linear operation is coupled with the wide dynamic range (i.e. phase
wrapping) capabilities of a PI. Furthermore, the PI is powered by a low-dropout
regulator (LDO) supporting fast transient operation. Implemented in 65-nm CMOS
technology, it consumes 350$\mu$W at a 1.2-V supply and a 0.5-GHz clock; it
achieves energy efficiency 4$\times$-15$\times$ lower than state-of-the-art
(SoA) digital-to-time converters (DTCs) and an integral non-linearity (INL) of
2.5$\times$-3.1$\times$ better than SoA PIs, striking a good balance between
linearity and energy efficiency.
"
1567,"Enabling Mixed-Precision Quantized Neural Networks in Extreme-Edge
  Devices","  The deployment of Quantized Neural Networks (QNN) on advanced
microcontrollers requires optimized software to exploit digital signal
processing (DSP) extensions of modern instruction set architectures (ISA). As
such, recent research proposed optimized libraries for QNNs (from 8-bit to
2-bit) such as CMSIS-NN and PULP-NN. This work presents an extension to the
PULP-NN library targeting the acceleration of mixed-precision Deep Neural
Networks, an emerging paradigm able to significantly shrink the memory
footprint of deep neural networks with negligible accuracy loss. The library,
composed of 27 kernels, one for each permutation of input feature maps,
weights, and output feature maps precision (considering 8-bit, 4-bit and
2-bit), enables efficient inference of QNN on parallel ultra-low-power (PULP)
clusters of RISC-V based processors, featuring the RV32IMCXpulpV2 ISA. The
proposed solution, benchmarked on an 8-cores GAP-8 PULP cluster, reaches peak
performance of 16 MACs/cycle on 8 cores, performing 21x to 25x faster than an
STM32H7 (powered by an ARM Cortex M7 processor) with 15x to 21x better energy
efficiency.
"
1568,A Survey of Aging Monitors and Reconfiguration Techniques,"  CMOS technology scaling makes aging effects an important concern for the
design and fabrication of integrated circuits. Aging deterioration reduces the
useful life of a circuit, making it fail earlier. This deterioration can affect
all portions of a circuit and impacts its performance and reliability.
Contemporary literature shows solutions to monitor and mitigate aging using
hardware and software monitoring mechanisms and reconfiguration techniques. The
goal of this review of the state-of-the-art is to identify existing monitoring
and reconfiguration solutions for aging. This survey evaluates the aging
research, focusing the years from 2012 to 2019, and proposes a classification
for monitors and reconfiguration techniques. Results show that the most common
monitor type used for aging detection is to monitor timing errors, and the most
common reconfiguration technique used to deal with aging is voltage scaling.
Furthermore, most of the literature contributions are in the digital field,
using hardware solutions for monitoring aging in circuits. There are few
literature contributions in the analog area, being the scope of this survey in
the digital domain. By scrutinizing these solutions, this survey points
directions for further research and development of aging monitors and
reconfiguration techniques
"
1569,"Dagger: Towards Efficient RPCs in Cloud Microservices with Near-Memory
  Reconfigurable NICs","  Cloud applications are increasingly relying on hundreds of loosely-coupled
microservices to complete user requests that meet an applications end-to-end
QoS requirements. Communication time between services accounts for a large
fraction of the end-to-end latency and can introduce performance
unpredictability and QoS violations. This work presents our early work on
Dagger, a hardware acceleration platform for networking, designed specifically
with the unique qualities of microservices in mind. The Dagger architecture
relies on an FPGA-based NIC, closely coupled with the processor over a
configurable memory interconnect, designed to offload and accelerate RPC
stacks. Unlike the traditional cloud systems that use PCIe links as the NIC I/O
interface, we leverage memory-interconnected FPGAs as networking devices to
provide the efficiency, transparency, and programmability needed for
fine-grained microservices. We show that this considerably improves CPU
utilization and performance for cloud RPCs.
"
1570,PThammer: Cross-User-Kernel-Boundary Rowhammer through Implicit Accesses,"  Rowhammer is a hardware vulnerability in DRAM memory, where repeated access
to memory can induce bit flips in neighboring memory locations. Being a
hardware vulnerability, rowhammer bypasses all of the system memory protection,
allowing adversaries to compromise the integrity and confidentiality of data.
Rowhammer attacks have shown to enable privilege escalation, sandbox escape,
and cryptographic key disclosures. Recently, several proposals suggest
exploiting the spatial proximity between the accessed memory location and the
location of the bit flip for a defense against rowhammer. These all aim to deny
the attacker's permission to access memory locations near sensitive data. In
this paper, we question the core assumption underlying these defenses. We
present PThammer, a confused-deputy attack that causes accesses to memory
locations that the attacker is not allowed to access. Specifically, PThammer
exploits the address translation process of modern processors, inducing the
processor to generate frequent accesses to protected memory locations. We
implement PThammer, demonstrating that it is a viable attack, resulting in a
system compromise (e.g., kernel privilege escalation). We further evaluate the
effectiveness of proposed software-only defenses showing that PThammer can
overcome those.
"
1571,"Always-On 674uW @ 4GOP/s Error Resilient Binary Neural Networks with
  Aggressive SRAM Voltage Scaling on a 22nm IoT End-Node","  Binary Neural Networks (BNNs) have been shown to be robust to random
bit-level noise, making aggressive voltage scaling attractive as a power-saving
technique for both logic and SRAMs. In this work, we introduce the first fully
programmable IoT end-node system-on-chip (SoC) capable of executing
software-defined, hardware-accelerated BNNs at ultra-low voltage. Our SoC
exploits a hybrid memory scheme where error-vulnerable SRAMs are complemented
by reliable standard-cell memories to safely store critical data under
aggressive voltage scaling. On a prototype in 22nm FDX technology, we
demonstrate that both the logic and SRAM voltage can be dropped to 0.5Vwithout
any accuracy penalty on a BNN trained for the CIFAR-10 dataset, improving
energy efficiency by 2.2X w.r.t. nominal conditions. Furthermore, we show that
the supply voltage can be dropped to 0.42V (50% of nominal) while keeping more
than99% of the nominal accuracy (with a bit error rate ~1/1000). In this
operating point, our prototype performs 4Gop/s (15.4Inference/s on the CIFAR-10
dataset) by computing up to 13binary ops per pJ, achieving 22.8 Inference/s/mW
while keeping within a peak power envelope of 674uW - low enough to enable
always-on operation in ultra-low power smart cameras, long-lifetime
environmental sensors, and insect-sized pico-drones.
"
1572,"Klessydra-T: Designing Vector Coprocessors for Multi-Threaded
  Edge-Computing Cores","  Convolutional computation kernels are fundamental to today's edge computing
applications. Interleaved-Multi-Threading (IMT) processor cores are an
interesting approach to pursue the highest energy efficiency and lowest
hardware cost in edge computing systems, yet they need hardware acceleration
schemes to deal with heavy computational workloads like convolutional
algorithms. Following a vector approach to accelerate convolutions, this study
explores possible alternatives to implement vector coprocessing units in IMT
cores, showing the application-dependence of the optimal balance among the
hardware architecture parameters.
"
1573,"Runtime Task Scheduling using Imitation Learning for Heterogeneous
  Many-Core Systems","  Domain-specific systems-on-chip, a class of heterogeneous many-core systems,
are recognized as a key approach to narrow down the performance and
energy-efficiency gap between custom hardware accelerators and programmable
processors. Reaching the full potential of these architectures depends
critically on optimally scheduling the applications to available resources at
runtime. Existing optimization-based techniques cannot achieve this objective
at runtime due to the combinatorial nature of the task scheduling problem. As
the main theoretical contribution, this paper poses scheduling as a
classification problem and proposes a hierarchical imitation learning
(IL)-based scheduler that learns from an Oracle to maximize the performance of
multiple domain-specific applications. Extensive evaluations with six streaming
applications from wireless communications and radar domains show that the
proposed IL-based scheduler approximates an offline Oracle policy with more
than 99% accuracy for performance- and energy-based optimization objectives.
Furthermore, it achieves almost identical performance to the Oracle with a low
runtime overhead and successfully adapts to new applications, many-core system
configurations, and runtime variations in application characteristics.
"
1574,"Design Space Exploration of Algorithmic Multi-Port Memories in
  High-Performance Application-Specific Accelerators","  Memory load/store instructions consume an important part in execution time
and energy consumption in domain-specific accelerators. For designing highly
parallel systems, available parallelism at each granularity is extracted from
the workloads. The maximal use of parallelism at each granularity in these
high-performance designs requires the utilization of multi-port memories.
Currently, true multiport designs are less popular because there is no inherent
EDA support for multiport memory beyond 2-ports, utilizing more ports requires
circuit-level implementation and hence a high design time. In this work, we
present a framework for Design Space Exploration of Algorithmic Multi-Port
Memories (AMM) in ASICs. We study different AMM designs in the literature,
discuss how we incorporate them in the Pre-RTL Aladdin Framework with different
memory depth, port configurations and banking structures. From our analysis on
selected applications from the MachSuite (accelerator benchmark suite), we
understand and quantify the potential use of AMMs (as true multiport memories)
for high performance in applications with low spatial locality in memory access
patterns.
"
1575,"DeepDive: An Integrative Algorithm/Architecture Co-Design for Deep
  Separable Convolutional Neural Networks","  Deep Separable Convolutional Neural Networks (DSCNNs) have become the
emerging paradigm by offering modular networks with structural sparsity in
order to achieve higher accuracy with relatively lower operations and
parameters. However, there is a lack of customized architectures that can
provide flexible solutions that fit the sparsity of the DSCNNs. This paper
introduces DeepDive, which is a fully-functional, vertical co-design framework,
for power-efficient implementation of DSCNNs on edge FPGAs. DeepDive's
architecture supports crucial heterogeneous Compute Units (CUs) to fully
support DSCNNs with various convolutional operators interconnected with
structural sparsity. It offers an FPGA-aware training and online quantization
combined with modular synthesizable C++ CUs, customized for DSCNNs. The
execution results on Xilinx's ZCU102 FPGA board, demonstrate 47.4 and 233.3
FPS/Watt for MobileNet-V2 and a compact version of EfficientNet, respectively,
as two state-of-the-art depthwise separable CNNs. These comparisons showcase
how DeepDive improves FPS/Watt by 2.2$\times$ and 1.51$\times$ over Jetson Nano
high and low power modes, respectively. It also enhances FPS/Watt about
2.27$\times$ and 37.25$\times$ over two other FPGA implementations. The
DeepDive output for MobileNetV2 is available at
https://github.com/TeCSAR-UNCC/DeepDive.
"
1576,A New Doctrine for Hardware Security,"  In this paper, we promote the idea that recent woes in hardware security are
not because of a lack of technical solutions but rather because market forces
and incentives prevent those with the ability to fix problems from doing so. At
the root of the problem is the fact that hardware security comes at a cost;
Present issues in hardware security can be seen as the result of the players in
the game of hardware security finding ways of avoiding paying this cost. We
formulate this idea into a doctrine of security, namely the Doctrine of Shared
Burdens. Three cases studies---Rowhammer, Spectre, and Meltdown---are
interpreted though the lens of this doctrine. Our doctrine illuminates why
these problems and exist and what can be done about them.
"
1577,"NeuroMAX: A High Throughput, Multi-Threaded, Log-Based Accelerator for
  Convolutional Neural Networks","  Convolutional neural networks (CNNs) require high throughput hardware
accelerators for real time applications owing to their huge computational cost.
Most traditional CNN accelerators rely on single core, linear processing
elements (PEs) in conjunction with 1D dataflows for accelerating convolution
operations. This limits the maximum achievable ratio of peak throughput per PE
count to unity. Most of the past works optimize their dataflows to attain close
to a 100% hardware utilization to reach this ratio. In this paper, we introduce
a high throughput, multi-threaded, log-based PE core. The designed core
provides a 200% increase in peak throughput per PE count while only incurring a
6% increase in area overhead compared to a single, linear multiplier PE core
with same output bit precision. We also present a 2D weight broadcast dataflow
which exploits the multi-threaded nature of the PE cores to achieve a high
hardware utilization per layer for various CNNs. The entire architecture, which
we refer to as NeuroMAX, is implemented on Xilinx Zynq 7020 SoC at 200 MHz
processing clock. Detailed analysis is performed on throughput, hardware
utilization, area and power breakdown, and latency to show performance
improvement compared to previous FPGA and ASIC designs.
"
1578,"UVMBench: A Comprehensive Benchmark Suite for Researching Unified
  Virtual Memory in GPUs","  The recent introduction of Unified Virtual Memory (UVM) in GPUs offers a new
programming model that allows GPUs and CPUs to share the same virtual memory
space, which shifts the complex memory management from programmers to GPU
driver/ hardware and enables kernel execution even when memory is
oversubscribed. Meanwhile, UVM may also incur considerable performance overhead
due to tracking and data migration along with special handling of page faults
and page table walk. As UVM is attracting significant attention from the
research community to develop innovative solutions to these problems, in this
paper, we propose a comprehensive UVM benchmark suite named UVMBench to
facilitate future research on this important topic. The proposed UVMBench
consists of 32 representative benchmarks from a wide range of application
domains. The suite also features unified programming implementation and diverse
memory access patterns across benchmarks, thus allowing thorough evaluation and
comparison with current state-of-the-art. A set of experiments have been
conducted on real GPUs to verify and analyze the benchmark suite behaviors
under various scenarios.
"
1579,"Energy Efficient Computing Systems: Architectures, Abstractions and
  Modeling to Techniques and Standards","  Computing systems have undergone several inflexion points - while Moore's law
guided the semiconductor industry to cram more and more transistors and logic
into the same volume, the limits of instruction-level parallelism (ILP) and the
end of Dennard's scaling drove the industry towards multi-core chips. We have
now entered the era of domain-specific architectures for new workloads like AI
and ML. These trends continue, arguably with other limits, along with
challenges imposed by tighter integration, extreme form factors and diverse
workloads, making systems more complex from an energy efficiency perspective.
Many research surveys have covered different aspects of techniques in hardware
and microarchitecture across devices, servers, HPC, data center systems along
with software, algorithms, frameworks for energy efficiency and thermal
management. Somewhat in parallel, the semiconductor industry has developed
techniques and standards around specification, modeling and verification of
complex chips; these areas have not been addressed in detail by previous
research surveys. This survey aims to bring these domains together and is
composed of a systematic categorization of key aspects of building energy
efficient systems - (a) specification - the ability to precisely specify the
power intent or properties at different layers (b) modeling and simulation of
the entire system or subsystem (hardware or software or both) so as to be able
to perform what-if analysis, (c) techniques used for implementing energy
efficiency at different levels of the stack, (d) verification techniques used
to provide guarantees that the functionality of complex designs are preserved,
and (e) energy efficiency standards and consortiums that aim to standardize
different aspects of energy efficiency, including cross-layer optimizations.
"
1580,"SHEARer: Highly-Efficient Hyperdimensional Computing by
  Software-Hardware Enabled Multifold Approximation","  Hyperdimensional computing (HD) is an emerging paradigm for machine learning
based on the evidence that the brain computes on high-dimensional, distributed,
representations of data. The main operation of HD is encoding, which transfers
the input data to hyperspace by mapping each input feature to a hypervector,
accompanied by so-called bundling procedure that simply adds up the
hypervectors to realize encoding hypervector. Although the operations of HD are
highly parallelizable, the massive number of operations hampers the efficiency
of HD in embedded domain. In this paper, we propose SHEARer, an
algorithm-hardware co-optimization to improve the performance and energy
consumption of HD computing. We gain insight from a prudent scheme of
approximating the hypervectors that, thanks to inherent error resiliency of HD,
has minimal impact on accuracy while provides high prospect for hardware
optimization. In contrast to previous works that generate the encoding
hypervectors in full precision and then ex-post quantizing, we compute the
encoding hypervectors in an approximate manner that saves a significant amount
of resources yet affords high accuracy. We also propose a novel FPGA
implementation that achieves striking performance through massive parallelism
with low power consumption. Moreover, we develop a software framework that
enables training HD models by emulating the proposed approximate encodings. The
FPGA implementation of SHEARer achieves an average throughput boost of 104,904x
(15.7x) and energy savings of up to 56,044x (301x) compared to state-of-the-art
encoding methods implemented on Raspberry Pi 3 (GeForce GTX 1080 Ti) using
practical machine learning datasets.
"
1581,"HPIPE: Heterogeneous Layer-Pipelined and Sparse-Aware CNN Inference for
  FPGAs","  We present both a novel Convolutional Neural Network (CNN) accelerator
architecture and a network compiler for FPGAs that outperforms all prior work.
Instead of having generic processing elements that together process one layer
at a time, our network compiler statically partitions available device
resources and builds custom-tailored hardware for each layer of a CNN. By
building hardware for each layer we can pack our controllers into fewer lookup
tables and use dedicated routing. These efficiencies enable our accelerator to
utilize 2x the DSPs and operate at more than 2x the frequency of prior work on
sparse CNN acceleration on FPGAs. We evaluate the performance of our
architecture on both sparse Resnet-50 and dense MobileNet Imagenet classifiers
on a Stratix 10 2800 FPGA. We find that the sparse Resnet-50 model has
throughput at a batch size of 1 of 4550 images/s, which is nearly 4x the
throughput of NVIDIA's fastest machine learning targeted GPU, the V100, and
outperforms all prior work on FPGAs.
"
1582,"Exploiting Process Variations to Secure Photonic NoC Architectures from
  Snooping Attacks","  The compact size and high wavelength-selectivity of microring resonators
(MRs) enable photonic networks-on-chip (PNoCs) to utilize
dense-wavelength-division-multiplexing (DWDM) in their photonic waveguides, and
as a result, attain high bandwidth on-chip data transfers. Unfortunately, a
Hardware Trojan in a PNoC can manipulate the electrical driving circuit of its
MRs to cause the MRs to snoop data from the neighboring wavelength channels in
a shared photonic waveguide, which introduces a serious security threat. This
paper presents a framework that utilizes process variation-based authentication
signatures along with architecture-level enhancements to protect against
data-snooping Hardware Trojans during unicast as well as multicast transfers in
PNoCs. Evaluation results indicate that our framework can improve hardware
security across various PNoC architectures with minimal overheads of up to
14.2% in average latency and of up to 14.6% in energy-delay-product (EDP).
"
1583,"TCIM: Triangle Counting Acceleration With Processing-In-MRAM
  Architecture","  Triangle counting (TC) is a fundamental problem in graph analysis and has
found numerous applications, which motivates many TC acceleration solutions in
the traditional computing platforms like GPU and FPGA. However, these
approaches suffer from the bandwidth bottleneck because TC calculation involves
a large amount of data transfers. In this paper, we propose to overcome this
challenge by designing a TC accelerator utilizing the emerging
processing-in-MRAM (PIM) architecture. The true innovation behind our approach
is a novel method to perform TC with bitwise logic operations (such as
\texttt{AND}), instead of the traditional approaches such as matrix
computations. This enables the efficient in-memory implementations of TC
computation, which we demonstrate in this paper with computational
Spin-Transfer Torque Magnetic RAM (STT-MRAM) arrays. Furthermore, we develop
customized graph slicing and mapping techniques to speed up the computation and
reduce the energy consumption. We use a device-to-architecture co-simulation
framework to validate our proposed TC accelerator. The results show that our
data mapping strategy could reduce $99.99\%$ of the computation and $72\%$ of
the memory \texttt{WRITE} operations. Compared with the existing GPU or FPGA
accelerators, our in-memory accelerator achieves speedups of $9\times$ and
$23.4\times$, respectively, and a $20.6\times$ energy efficiency improvement
over the FPGA accelerator.
"
1584,DBOS: A Proposal for a Data-Centric Operating System,"  Current operating systems are complex systems that were designed before
today's computing environments. This makes it difficult for them to meet the
scalability, heterogeneity, availability, and security challenges in current
cloud and parallel computing environments. To address these problems, we
propose a radically new OS design based on data-centric architecture: all
operating system state should be represented uniformly as database tables, and
operations on this state should be made via queries from otherwise stateless
tasks. This design makes it easy to scale and evolve the OS without
whole-system refactoring, inspect and debug system state, upgrade components
without downtime, manage decisions using machine learning, and implement
sophisticated security features. We discuss how a database OS (DBOS) can
improve the programmability and performance of many of today's most important
applications and propose a plan for the development of a DBOS proof of concept.
"
1585,"Analytical Modeling the Multi-Core Shared Cache Behavior with
  Considerations of Data-Sharing and Coherence","  To mitigate the ever worsening ""Power wall"" and ""Memory wall"" problems,
multi-core architectures with multilevel cache hierarchies have been widely
accepted in modern processors. However, the complexity of the architectures
makes modeling of shared caches extremely complex. In this paper, we propose a
data-sharing aware analytical model for estimating the miss rates of the
downstream shared cache under multi-core scenarios. Moreover, the proposed
model can also be integrated with upstream cache analytical models with the
consideration of multi-core private cache coherent effects. This integration
avoids time consuming full simulations of the cache architecture that required
by conventional approaches. We validate our analytical model against gem5
simulation results under 13 applications from PARSEC 2.1 benchmark suites.
Compared to the results from gem5 simulations under 8 hardware configurations
including dual-core and quad-core architectures, the average absolute error of
the predicted shared L2 cache miss rates is less than 2% for all
configurations. After integrated with the refined upstream model with coherence
misses, the overall average absolute error in 4 hardware configurations is
degraded to 8.03% due to the error accumulations. The proposed coherence model
can achieve similar accuracies of state of the art approach with only one tenth
time overhead. As an application case of the integrated model, we also evaluate
the miss rates of 57 different multi-core and multi-level cache configurations.
"
1586,Speculative Interference Attacks: Breaking Invisible Speculation Schemes,"  Recent security vulnerabilities that target speculative execution (e.g.,
Spectre) present a significant challenge for processor design. The highly
publicized vulnerability uses speculative execution to learn victim secrets by
changing cache state. As a result, recent computer architecture research has
focused on invisible speculation mechanisms that attempt to block changes in
cache state due to speculative execution. Prior work has shown significant
success in preventing Spectre and other vulnerabilities at modest performance
costs. In this paper, we introduce speculative interference attacks, which show
that prior invisible speculation mechanisms do not fully block these
speculation-based attacks. We make two key observations. First, misspeculated
younger instructions can change the timing of older, bound-to-retire
instructions, including memory operations. Second, changing the timing of a
memory operation can change the order of that memory operation relative to
other memory operations, resulting in persistent changes to the cache state.
Using these observations, we demonstrate (among other attack variants) that
secret information accessed by mis-speculated instructions can change the order
of bound-to-retire loads. Load timing changes can therefore leave
secret-dependent changes in the cache, even in the presence of invisible
speculation mechanisms. We show that this problem is not easy to fix:
Speculative interference converts timing changes to persistent cache-state
changes, and timing is typically ignored by many cache-based defenses. We
develop a framework to understand the attack and demonstrate concrete
proof-of-concept attacks against invisible speculation mechanisms. We provide
security definitions sufficient to block speculative interference attacks;
describe a simple defense mechanism with a high performance cost; and discuss
how future research can improve its performance.
"
1587,"Comparative Analysis of Polynomial and Rational Approximations of
  Hyperbolic Tangent Function for VLSI Implementation","  Deep neural networks yield the state-of-the-art results in many computer
vision and human machine interface applications such as object detection,
speech recognition etc. Since, these networks are computationally expensive,
customized accelerators are designed for achieving the required performance at
lower cost and power. One of the key building blocks of these neural networks
is non-linear activation function such as sigmoid, hyperbolic tangent (tanh),
and ReLU. A low complexity accurate hardware implementation of the activation
function is required to meet the performance and area targets of the neural
network accelerators. Even though, various methods and implementations of tanh
activation function have been published, a comparative study is missing. This
paper presents comparative analysis of polynomial and rational methods and
their hardware implementation.
"
1588,"Dopant Network Processing Units: Towards Efficient Neural-network
  Emulators with High-capacity Nanoelectronic Nodes","  The rapidly growing computational demands of deep neural networks require
novel hardware designs. Recently, tunable nanoelectronic devices were developed
based on hopping electrons through a network of dopant atoms in silicon. These
""Dopant Network Processing Units"" (DNPUs) are highly energy-efficient and have
potentially very high throughput. By adapting the control voltages applied to
its terminals, a single DNPU can solve a variety of linearly non-separable
classification problems. However, using a single device has limitations due to
the implicit single-node architecture. This paper presents a promising novel
approach to neural information processing by introducing DNPUs as high-capacity
neurons and moving from a single to a multi-neuron framework. By implementing
and testing a small multi-DNPU classifier in hardware, we show that
feed-forward DNPU networks improve the performance of a single DNPU from 77% to
94% test accuracy on a binary classification task with concentric classes on a
plane. Furthermore, motivated by the integration of DNPUs with memristor
arrays, we study the potential of using DNPUs in combination with linear
layers. We show by simulation that a single-layer MNIST classifier with only 10
DNPUs achieves over 96% test accuracy. Our results pave the road towards
hardware neural-network emulators that offer atomic-scale information
processing with low latency and energy consumption.
"
1589,"A concept of a measuring system for probe kinesthetic parameters
  identification during echocardiography examination","  Echocardiography is the most commonly used imaging technique in clinical
cardiology. Due to the high demand for this type of examination and the small
number of specialists, there is a need to support the examination process
through telemedicine. Moreover, specialist training can be supported by
appropriate simulation systems. For (i) creating tailor-made tele-echo robots,
(ii) creating echo system simulators, and (iii) conducting echo examination
with local or remote expert assistance, knowledge about echo probe kinesthetic
parameters during echocardiography examination is advisable. The article
describes the concept of a measuring system for obtaining such data.
"
1590,"Hardware Implementation of Hyperbolic Tangent Function using Catmull-Rom
  Spline Interpolation","  Deep neural networks yield the state of the art results in many computer
vision and human machine interface tasks such as object recognition, speech
recognition etc. Since, these networks are computationally expensive,
customized accelerators are designed for achieving the required performance at
lower cost and power. One of the key building blocks of these neural networks
is non-linear activation function such as sigmoid, hyperbolic tangent (tanh),
and ReLU. A low complexity accurate hardware implementation of the activation
function is required to meet the performance and area targets of the neural
network accelerators. This paper presents an implementation of tanh function
using the Catmull-Rom spline interpolation. State of the art results are
achieved using this method with comparatively smaller logic area.
"
1591,"SparseTrain: Exploiting Dataflow Sparsity for Efficient Convolutional
  Neural Networks Training","  Training Convolutional Neural Networks (CNNs) usually requires a large number
of computational resources. In this paper, \textit{SparseTrain} is proposed to
accelerate CNN training by fully exploiting the sparsity. It mainly involves
three levels of innovations: activation gradients pruning algorithm, sparse
training dataflow, and accelerator architecture. By applying a stochastic
pruning algorithm on each layer, the sparsity of back-propagation gradients can
be increased dramatically without degrading training accuracy and convergence
rate. Moreover, to utilize both \textit{natural sparsity} (resulted from ReLU
or Pooling layers) and \textit{artificial sparsity} (brought by pruning
algorithm), a sparse-aware architecture is proposed for training acceleration.
This architecture supports forward and back-propagation of CNN by adopting
1-Dimensional convolution dataflow. We have built %a simple compiler to map
CNNs topology onto \textit{SparseTrain}, and a cycle-accurate architecture
simulator to evaluate the performance and efficiency based on the synthesized
design with $14nm$ FinFET technologies. Evaluation results on AlexNet/ResNet
show that \textit{SparseTrain} could achieve about $2.7 \times$ speedup and
$2.2 \times$ energy efficiency improvement on average compared with the
original training process.
"
1592,CARAM: A Content-Aware Hybrid PCM/DRAM Main Memory System Framework,"  The emergence of Phase-Change Memory (PCM) provides opportunities for
directly connecting persistent memory to main memory bus. While PCM achieves
high read throughput and low standby power, the critical concerns are its poor
write performance and limited durability, especially when compared to DRAM. A
naturally inspired design is the hybrid memory architecture that fuses DRAM and
PCM, so as to exploit the positive aspects of both types of memory.
Unfortunately, existing solutions are seriously challenged by the limited main
memory size, which is the primary bottleneck of in-memory computing. In this
paper, we introduce a novel Content Aware hybrid PCM/DRAM main memory system
framework - CARAM, which exploits deduplication to improve line sharing with
high memory efficiency. CARAM effectively reduces write traffic to hybrid
memory by removing unnecessary duplicate line writes. It also substantially
extends available free memory space by coalescing redundant lines in hybrid
memory, thereby further improving the wear-leveling efficiency of PCM. To
obtain high data access performance, we also design a set of acceleration
techniques to minimize the overhead caused by extra computation costs. Our
experiment results show that CARAM effectively reduces 15%~42% of memory usage
and improves I/O bandwidth by 13%~116%, while saving 31%~38% energy
consumption, compared to the state-of-the-art of hybrid systems.
"
1593,"Performance-Aware Predictive-Model-Based On-Chip Body-Bias Regulation
  Strategy for an ULP Multi-Core Cluster in 28nm UTBB FD-SOI","  The performance and reliability of Ultra-Low-Power (ULP) computing platforms
are adversely affected by environmental temperature and process variations.
Mitigating the effect of these phenomena becomes crucial when these devices
operate near-threshold, due to the magnification of process variations and to
the strong temperature inversion effect that affects advanced technology nodes
in low-voltage corners, which causes huge overhead due to margining for timing
closure. Supporting an extended range of reverse and forward body-bias, UTBB
FD-SOI technology provides a powerful knob to compensate for such variations.
In this work we propose a methodology to maximize energy efficiency at run-time
exploiting body biasing on a ULP platform operating near-threshold. The
proposed method relies on on-line performance measurements by means of Process
Monitoring Blocks (PMBs) coupled with an on-chip low-power body bias generator.
We correlate the measurement performed by the PMBs to the maximum achievable
frequency of the system, deriving a predictive model able to estimate it with
an error of 9.7% at 0.7V. To minimize the effect of process variations we
propose a calibration procedure that allows to use a PMB model affected by only
the temperature-induced error, which reduces the frequency estimation error by
2.4x (from 9.7% to 4%). We finally propose a controller architecture relying on
the derived models to automatically regulate at run-time the body bias voltage.
We demonstrate that adjusting the body bias voltage against environmental
temperature variations leads up to 2X reduction in the leakage power and a 15%
improvement on the global energy consumption when the system operates at 0.7V
and 170MHz
"
1594,GRIP: A Graph Neural Network Accelerator Architecture,"  We present GRIP, a graph neural network accelerator architecture designed for
low-latency inference. AcceleratingGNNs is challenging because they combine two
distinct types of computation: arithmetic-intensive vertex-centric operations
and memory-intensive edge-centric operations. GRIP splits GNN inference into a
fixed set of edge- and vertex-centric execution phases that can be implemented
in hardware. We then specialize each unit for the unique computational
structure found in each phase.For vertex-centric phases, GRIP uses a high
performance matrix multiply engine coupled with a dedicated memory subsystem
for weights to improve reuse. For edge-centric phases, GRIP use multiple
parallel prefetch and reduction engines to alleviate the irregularity in memory
accesses. Finally, GRIP supports severalGNN optimizations, including a novel
optimization called vertex-tiling which increases the reuse of weight data.We
evaluate GRIP by performing synthesis and place and route for a 28nm
implementation capable of executing inference for several widely-used GNN
models (GCN, GraphSAGE, G-GCN, and GIN). Across several benchmark graphs, it
reduces 99th percentile latency by a geometric mean of 17x and 23x compared to
a CPU and GPU baseline, respectively, while drawing only 5W.
"
1595,"STOMP: A Tool for Evaluation of Scheduling Policies in Heterogeneous
  Multi-Processors","  The proliferation of heterogeneous chip multiprocessors in recent years has
reached unprecedented levels. Traditional homogeneous platforms have shown
fundamental limitations when it comes to enabling high-performance
yet-ultra-low-power computing, in particular in application domains with
real-time execution deadlines or criticality constraints. By combining the
right set of general purpose cores and hardware accelerators together, along
with proper chip interconnects and memory technology, heterogeneous chip
multiprocessors have become an effective high-performance and low-power
computing alternative.
  One of the challenges of heterogeneous architectures relates to efficient
scheduling of application tasks (processes, threads) across the variety of
options in the chip. As a result, it is key to provide tools to enable
early-stage prototyping and evaluation of new scheduling policies for
heterogeneous platforms. In this paper, we present STOMP (Scheduling Techniques
Optimization in heterogeneous Multi-Processors), a simulator for fast
implementation and evaluation of task scheduling policies in
multi-core/multi-processor systems with a convenient interface for ""plugging""
in new scheduling policies in a simple manner. Thorough validation of STOMP
exhibits small relative errors when compared against closed-formed equivalent
models during steady-state analysis.
"
1596,Transaction-level Model Simulator for Communication-Limited Accelerators,"  Rapid design space exploration in early design stage is critical to
algorithm-architecture co-design for accelerators. In this work, a pre-RTL
cycle-accurate accelerator simulator based on SystemC transaction-level
modeling (TLM), AccTLMSim, is proposed for convolutional neural network (CNN)
accelerators. The accelerator simulator keeps track of each bus transaction
between accelerator and DRAM, taking into account the communication bandwidth.
The simulation results are validated against the implementation results on the
Xilinx Zynq. Using the proposed simulator, it is shown that the communication
bandwidth is severely affected by DRAM latency and bus protocol overhead. In
addition, the loop tiling is optimized to maximize the performance under the
constraint of on-chip SRAM size. Furthermore, a new performance estimation
model is proposed to speed up the design space exploration. Thanks to the
proposed simulator and performance estimation model, it is possible to explore
a design space of millions of architectural options within a few tens of
minutes.
"
1597,Fast Thresholded SC-Flip Decoding of Polar Codes,"  SC-Flip (SCF) decoding algorithm shares the attention with the common polar
code decoding approaches due to its low-complexity and improved
error-correction performance. However, the inefficient criterion for locating
the correct bit-flipping position in SCF decoding limits its improvements. Due
to its improved bit-flipping criterion, Thresholded SCF (TSCF) decoding
algorithm exhibits a superior error-correction performance and lower
computational complexity than SCF decoding. However, the parameters of TSCF
decoding depend on multiple channel and code parameters, and are obtained via
Monte-Carlo simulations. Our main goal is to realize TSCF decoding as a
practical polar decoder implementation. To this end, we first realize an
approximated threshold value that is independent of the code parameters and
precomputations. The proposed approximation has negligible error-correction
performance degradation on the TSCF decoding. Then, we validate an alternative
approach for forming a critical set that does not require precomputations,
which also paves the way to the implementation of the Fast-TSCF decoder.
Compared to the existing fast SCF implementations, the proposed Fast-TSCF
decoder has $0.24$ to $0.41$ dB performance gain at frame error rate of
$10^{-3}$, without any extra cost. Compared to the TSCF decoding, Fast-TSCF
does not depend on precomputations and requires $87\%$ fewer decoding steps.
Finally, implementation results in TSMC 65nm CMOS technology show that the
Fast-TSCF decoder is $20\%$ and $82\%$ more area-efficient than the
state-of-the-art fast SCF and fast SC-List decoder architectures, respectively.
"
1598,Optimal Layout Synthesis for Quantum Computing,"  Recent years have witnessed the fast development of quantum computing.
Researchers around the world are eager to run larger and larger quantum
algorithms that promise speedups impossible to any classical algorithm.
However, the available quantum computers are still volatile and error-prone.
Thus, layout synthesis, which transforms quantum programs to meet these
hardware limitations, is a crucial step in the realization of quantum
computing. In this paper, we present two synthesizers, one optimal and one
approximate but nearly optimal. Although a few optimal approaches to this
problem have been published, our optimal synthesizer explores a larger solution
space, thus is optimal in a stronger sense. In addition, it reduces time and
space complexity exponentially compared to some leading optimal approaches. The
key to this success is a more efficient spacetime-based variable encoding of
the layout synthesis problem as a mathematical programming problem. By slightly
changing our formulation, we arrive at an approximate synthesizer that is even
more efficient and outperforms some leading heuristic approaches, in terms of
additional gate cost, by up to 100%, and also fidelity by up to 10x on a
comprehensive set of benchmark programs and architectures. For a specific
family of quantum programs named QAOA, which is deemed to be a promising
application for near-term quantum computers, we further adjust the approximate
synthesizer by taking commutation into consideration, achieving up to 75%
reduction in depth and up to 65% reduction in additional cost compared to the
tool used in a leading QAOA study.
"
1599,"BasicBlocker: Redesigning ISAs to Eliminate Speculative-Execution
  Attacks","  Recent research has revealed an ever-growing class of microarchitectural
attacks that exploit speculative execution, a standard feature in modern
processors. Proposed and deployed countermeasures involve a variety of compiler
updates, firmware updates, and hardware updates. None of the deployed
countermeasures have convincing security arguments, and many of them have
already been broken.
  The obvious way to simplify the analysis of speculative-execution attacks is
to eliminate speculative execution. This is normally dismissed as being
unacceptably expensive, but the underlying cost analyses consider only software
written for current instruction-set architectures, so they do not rule out the
possibility of a new instruction-set architecture providing acceptable
performance without speculative execution. A new ISA requires compiler updates
and hardware updates, but those are happening in any case.
  This paper introduces BasicBlocker, a generic ISA modification that works for
all common ISAs and that removes most of the performance benefit of speculative
execution. To demonstrate feasibility of BasicBlocker, this paper defines a
BBRISC-V variant of the RISC-V ISA, reports implementations of a BBRISC-V soft
core and an associated compiler, and presents a performance comparison for a
variety of benchmark programs.
"
1600,"Hardware/Software Obfuscation against Timing Side-channel Attack on a
  GPU","  GPUs are increasingly being used in security applications, especially for
accelerating encryption/decryption. While GPUs are an attractive platform in
terms of performance, the security of these devices raises a number of
concerns. One vulnerability is the data-dependent timing information, which can
be exploited by adversary to recover the encryption key. Memory system features
are frequently exploited since they create detectable timing variations. In
this paper, our attack model is a coalescing attack, which leverages a critical
GPU microarchitectural feature -- the coalescing unit. As multiple concurrent
GPU memory requests can refer to the same cache block, the coalescing unit
collapses them into a single memory transaction. The access time of an
encryption kernel is dependent on the number of transactions. Correlation
between a guessed key value and the associated timing samples can be exploited
to recover the secret key. In this paper, a series of hardware/software
countermeasures are proposed to obfuscate the memory timing side channel,
making the GPU more resilient without impacting performance. Our hardware-based
approach attempts to randomize the width of the coalescing unit to lower the
signal-to-noise ratio. We present a hierarchical Miss Status Holding Register
(MSHR) design that can merge transactions across different warps. This feature
boosts performance, while, at the same time, secures the execution. We also
present a software-based approach to permute the organization of critical data
structures, significantly changing the coalescing behavior and introducing a
high degree of randomness. Equipped with our new protections, the effort to
launch a successful attack is increased up to 1433X . 178X, while also
improving encryption/decryption performance up to 7%.
"
1601,"Thermal Analysis of a 3D Stacked High-Performance Commercial
  Microprocessor using Face-to-Face Wafer Bonding Technology","  3D integration technologies are seeing widespread adoption in the
semiconductor industry to offset the limitations and slowdown of
two-dimensional scaling. High-density 3D integration techniques such as
face-to-face wafer bonding with sub-10 $\mu$m pitch can enable new ways of
designing SoCs using all 3 dimensions, like folding a microprocessor design
across multiple 3D tiers. However, overlapping thermal hotspots can be a
challenge in such 3D stacked designs due to a general increase in power
density. In this work, we perform a thorough thermal simulation study on
sign-off quality physical design implementation of a state-of-the-art,
high-performance, out-of-order microprocessor on a 7nm process technology. The
physical design of the microprocessor is partitioned and implemented in a
2-tier, 3D stacked configuration with logic blocks and memory instances in
separate tiers (logic-over-memory 3D). The thermal simulation model was
calibrated to temperature measurement data from a high-performance, CPU-based
2D SoC chip fabricated on the same 7nm process technology. Thermal profiles of
different 3D configurations under various workload conditions are simulated and
compared. We find that stacking microprocessor designs in 3D without
considering thermal implications can result in maximum die temperature up to
12{\deg}C higher than their 2D counterparts under the worst-case
power-indicative workload. This increase in temperature would reduce the amount
of time for which a power-intensive workload can be run before throttling is
required. However, logic-over-memory partitioned 3D CPU implementation can
mitigate this temperature increase by half, which makes the temperature of the
3D design only 6$^\circ$C higher than the 2D baseline. We conclude that using
thermal aware design partitioning and improved cooling techniques can overcome
the thermal challenges associated with 3D stacking.
"
1602,Opportunities and Challenges for Next Generation Computing,"  Computing has dramatically changed nearly every aspect of our lives, from
business and agriculture to communication and entertainment. As a nation, we
rely on computing in the design of systems for energy, transportation and
defense; and computing fuels scientific discoveries that will improve our
fundamental understanding of the world and help develop solutions to major
challenges in health and the environment. Computing has changed our world, in
part, because our innovations can run on computers whose performance and
cost-performance has improved a million-fold over the last few decades. A
driving force behind this has been a repeated doubling of the transistors per
chip, dubbed Moore's Law. A concomitant enabler has been Dennard Scaling that
has permitted these performance doublings at roughly constant power, but, as we
will see, both trends face challenges. Consider for a moment the impact of
these two trends over the past 30 years. A 1980's supercomputer (e.g. a Cray 2)
was rated at nearly 2 Gflops and consumed nearly 200 KW of power. At the time,
it was used for high performance and national-scale applications ranging from
weather forecasting to nuclear weapons research. A computer of similar
performance now fits in our pocket and consumes less than 10 watts. What would
be the implications of a similar computing/power reduction over the next 30
years - that is, taking a petaflop-scale machine (e.g. the Cray XK7 which
requires about 500 KW for 1 Pflop (=1015 operations/sec) performance) and
repeating that process? What is possible with such a computer in your pocket?
How would it change the landscape of high capacity computing? In the remainder
of this paper, we articulate some opportunities and challenges for dramatic
performance improvements of both personal to national scale computing, and
discuss some ""out of the box"" possibilities for achieving computing at this
scale.
"
1603,Partial Reconfiguration for Design Optimization,"  FPGA designers have traditionally shared a similar design methodology with
ASIC designers. Most notably, at design time, FPGA designers commit to a fixed
allocation of logic resources to modules in a design. At runtime, some of the
occupied resources could be left idle or under-utilized due to hard-to-avoid
sources of inefficiencies (e.g., operation dependencies). With partial
reconfiguration (PR), FPGA resources can be re-allocated over time. Therefore,
using PR, a designer can attempt to reduce idleness and under-utilization with
better area-time scheduling.
  In this paper, we explain when, how, and why PR-style designs can improve
over the performance-area Pareto front of ASIC-style designs (without PR). We
first introduce the concept of area-time volume to explain why PR-style designs
can improve upon ASIC-style designs. We identify resource under-utilization as
an opportunity that can be exploited by PR-style designs. We then present a
first-order analytical model to help a designer decide if a PR-style design can
be beneficial. When it is the case, the model points to the most suitable PR
execution strategy and provides an estimate of the improvement. The model is
validated in three case studies.
"
1604,"Intelligent Management of Mobile Systems through Computational
  Self-Awareness","  Runtime resource management for many-core systems is increasingly complex.
The complexity can be due to diverse workload characteristics with conflicting
demands, or limited shared resources such as memory bandwidth and power.
Resource management strategies for many-core systems must distribute shared
resource(s) appropriately across workloads, while coordinating the high-level
system goals at runtime in a scalable and robust manner.
  To address the complexity of dynamic resource management in many-core
systems, state-of-the-art techniques that use heuristics have been proposed.
These methods lack the formalism in providing robustness against unexpected
runtime behavior. One of the common solutions for this problem is to deploy
classical control approaches with bounds and formal guarantees. Traditional
control theoretic methods lack the ability to adapt to (1) changing goals at
runtime (i.e., self-adaptivity), and (2) changing dynamics of the modeled
system (i.e., self-optimization).
  In this chapter, we explore adaptive resource management techniques that
provide self-optimization and self-adaptivity by employing principles of
computational self-awareness, specifically reflection. By supporting these
self-awareness properties, the system can reason about the actions it takes by
considering the significance of competing objectives, user requirements, and
operating conditions while executing unpredictable workloads.
"
1605,"DeACT: Architecture-Aware Virtual Memory Support for Fabric Attached
  Memory Systems","  The exponential growth of data has driven technology providers to develop new
protocols, such as cache coherent interconnects and memory semantic fabrics, to
help users and facilities leverage advances in memory technologies to satisfy
these growing memory and storage demands. Using these new protocols,
fabric-attached memories (FAM) can be directly attached to a system
interconnect and be easily integrated with a variety of processing elements
(PEs). Moreover, systems that support FAM can be smoothly upgraded and allow
multiple PEs to share the FAM memory pools using well-defined protocols. The
sharing of FAM between PEs allows efficient data sharing, improves memory
utilization, reduces cost by allowing flexible integration of different PEs and
memory modules from several vendors, and makes it easier to upgrade the system.
One promising use-case for FAMs is in High-Performance Compute (HPC) systems,
where the underutilization of memory is a major challenge. However, adopting
FAMs in HPC systems brings new challenges. In addition to cost, flexibility,
and efficiency, one particular problem that requires rethinking is virtual
memory support for security and performance. To address these challenges, this
paper presents decoupled access control and address translation (DeACT), a
novel virtual memory implementation that supports HPC systems equipped with
FAM. Compared to the state-of-the-art two-level translation approach, DeACT
achieves speedup of up to 4.59x (1.8x on average) without compromising
security.
"
1606,Custom Tailored Suite of Random Forests for Prefetcher Adaptation,"  To close the gap between memory and processors, and in turn improve
performance, there has been an abundance of work in the area of
data/instruction prefetcher designs. Prefetchers are deployed in each level of
the memory hierarchy, but typically, each prefetcher gets designed without
comprehensively accounting for other prefetchers in the system. As a result,
these individual prefetcher designs do not always complement each other, and
that leads to low average performance gains and/or many negative outliers. In
this work, we propose SuitAP (Suite of random forests for Adaptation of
Prefetcher system configuration), which is a hardware prefetcher adapter that
uses a suite of random forests to determine at runtime which prefetcher should
be ON at each memory level, such that they complement each other. Compared to a
design with no prefetchers, using SuitAP we improve IPC by 46% on average
across traces generated from SPEC2017 suite with 12KB overhead. Moreover, we
also reduce negative outliers using SuitAP.
"
1607,Device to Remotely Track and Locate the Position of a Child for Safety,"  Parents are always worried about the wellbeing of their children. As per the
Statistics Report 2017 by Missing Children Europe Organization, a child is
reported missing every 2 minutes. Due to the imminent threat, parents are prone
to buy their children mobile phones to keep in touch with them. However, giving
a Mobile phone to a child can cause issues including cyber bullying, improper
use of social networks, access to mature age and illicit content on the
internet and possibly, phone theft. As an effort to tackle some of those
issues, this paper proposes a solution which enables parents to call, locate
and track their children using a child-friendly mobile device. The common
scenario the device would come to play is in enhancing the safety of a child
who would travel alone on a typical route; for instance a child who walks from
home to school and back. The device can be calibrated to keep track of a
typical route of travel. Then, if the device de-tects some deviation from the
usual route, it would trigger a notification to parents. A probability matrix
based nov-el algorithm is introduced to detect route deviation. De-sign details
of the mobile device, along with the details of the route deviation detection
algorithm are presented in this paper.
"
1608,"Faster Schr\""odinger-style simulation of quantum circuits","  Recent demonstrations of superconducting quantum computers by Google and IBM
and trapped-ion computers from IonQ fueled new research in quantum algorithms,
compilation into quantum circuits, and empirical algorithmics. While online
access to quantum hardware remains too limited to meet the demand, simulating
quantum circuits on conventional computers satisfies many needs. We advance
Schr\""odinger-style simulation of quantum circuits that is useful standalone
and as a building block in layered simulation algorithms, both cases are
illustrated in our results. Our algorithmic contributions show how to simulate
multiple quantum gates at once, how to avoid floating-point multiplies, how to
best use instruction-level and thread-level parallelism as well as CPU cache,
and how to leverage these optimizations by reordering circuit gates. While not
described previously, these techniques implemented by us supported published
high-performance distributed simulations up to 64 qubits. To show additional
impact, we benchmark our simulator against Microsoft, IBM and Google simulators
on hard circuits from Google.
"
1609,"CuttleSys: Data-Driven Resource Management forInteractive Applications
  on Reconfigurable Multicores","  Multi-tenancy for latency-critical applications leads to re-source
interference and unpredictable performance. Core reconfiguration opens up more
opportunities for colocation,as it allows the hardware to adjust to the dynamic
performance and power needs of a specific mix of co-scheduled applications.
However, reconfigurability also introduces challenges, as even for a small
number of reconfigurable cores, exploring the design space becomes more time-
and resource-demanding.
  We present CuttleSys, a runtime for reconfigurable multi-cores that leverages
scalable and lightweight data mining to quickly identify suitable core and
cache configurations for a set of co-scheduled applications. The runtime
combines collaborative filtering to infer the behavior of each job on every
core and cache configuration, with Dynamically Dimensioned Search to
efficiently explore the configuration space. We evaluate CuttleSys on
multicores with tens of reconfigurable cores and show up to 2.46x and 1.55x
performance improvements compared to core-level gating and oracle-like
asymmetric multicores respectively, under stringent power constraints.
"
1610,"High Throughput Matrix-Matrix Multiplication between Asymmetric
  Bit-Width Operands","  Matrix multiplications between asymmetric bit-width operands, especially
between 8- and 4-bit operands are likely to become a fundamental kernel of many
important workloads including neural networks and machine learning. While
existing SIMD matrix multiplication instructions for symmetric bit-width
operands can support operands of mixed precision by zero- or sign-extending the
narrow operand to match the size of the other operands, they cannot exploit the
benefit of narrow bit-width of one of the operands. We propose a new SIMD
matrix multiplication instruction that uses mixed precision on its inputs (8-
and 4-bit operands) and accumulates product values into narrower 16-bit output
accumulators, in turn allowing the SIMD operation at 128-bit vector width to
process a greater number of data elements per instruction to improve processing
throughput and memory bandwidth utilization without increasing the register
read- and write-port bandwidth in CPUs. The proposed asymmetric-operand-size
SIMD instruction offers 2x improvement in throughput of matrix multiplication
in comparison to throughput obtained using existing symmetric-operand-size
instructions while causing negligible (0.05%) overflow from 16-bit accumulators
for representative machine learning workloads. The asymmetric-operand-size
instruction not only can improve matrix multiplication throughput in CPUs, but
also can be effective to support multiply-and-accumulate (MAC) operation
between 8- and 4-bit operands in state-of-the-art DNN hardware accelerators
(e.g., systolic array microarchitecture in Google TPU, etc.) and offer similar
improvement in matrix multiply performance seamlessly without violating the
various implementation constraints. We demonstrate how a systolic array
architecture designed for symmetric-operand-size instructions could be modified
to support an asymmetric-operand-sized instruction.
"
1611,DAMO: Deep Agile Mask Optimization for Full Chip Scale,"  Continuous scaling of the VLSI system leaves a great challenge on
manufacturing and optical proximity correction (OPC) is widely applied in
conventional design flow for manufacturability optimization. Traditional
techniques conducted OPC by leveraging a lithography model and suffered from
prohibitive computational overhead, and mostly focused on optimizing a single
clip without addressing how to tackle the full chip. In this paper, we present
DAMO, a high performance and scalable deep learning-enabled OPC system for full
chip scale. It is an end-to-end mask optimization paradigm which contains a
Deep Lithography Simulator (DLS) for lithography modeling and a Deep Mask
Generator (DMG) for mask pattern generation. Moreover, a novel layout splitting
algorithm customized for DAMO is proposed to handle the full chip OPC problem.
Extensive experiments show that DAMO outperforms the state-of-the-art OPC
solutions in both academia and industrial commercial toolkit.
"
1612,Accelerating Genome Analysis: A Primer on an Ongoing Journey,"  Genome analysis fundamentally starts with a process known as read mapping,
where sequenced fragments of an organism's genome are compared against a
reference genome. Read mapping is currently a major bottleneck in the entire
genome analysis pipeline, because state-of-the-art genome sequencing
technologies are able to sequence a genome much faster than the computational
techniques employed to analyze the genome. We describe the ongoing journey in
significantly improving the performance of read mapping. We explain
state-of-the-art algorithmic methods and hardware-based acceleration
approaches. Algorithmic approaches exploit the structure of the genome as well
as the structure of the underlying hardware. Hardware-based acceleration
approaches exploit specialized microarchitectures or various execution
paradigms (e.g., processing inside or near memory). We conclude with the
challenges of adopting these hardware-accelerated read mappers.
"
1613,"Hardware Accelerator for Adversarial Attacks on Deep Learning Neural
  Networks","  Recent studies identify that Deep learning Neural Networks (DNNs) are
vulnerable to subtle perturbations, which are not perceptible to human visual
system but can fool the DNN models and lead to wrong outputs. A class of
adversarial attack network algorithms has been proposed to generate robust
physical perturbations under different circumstances. These algorithms are the
first efforts to move forward secure deep learning by providing an avenue to
train future defense networks, however, the intrinsic complexity of them
prevents their broader usage.
  In this paper, we propose the first hardware accelerator for adversarial
attacks based on memristor crossbar arrays. Our design significantly improves
the throughput of a visual adversarial perturbation system, which can further
improve the robustness and security of future deep learning systems. Based on
the algorithm uniqueness, we propose four implementations for the adversarial
attack accelerator ($A^3$) to improve the throughput, energy efficiency, and
computational efficiency.
"
1614,"Optimum Reconfiguration of Routing Interconnection Network in APSoC
  Fabrics","  This paper presents an automated algorithm for optimum configuration of
routing interconnection network in Xilinx Zynq-7000 All programmable
system-on-chip (APSoC) fabrics. A method to configure circuits with optimum
routing resources is presented along with their performance parameters with and
without the proposed algorithm. The proposed algorithm enables full control
over routing resources for using different interconnection types in order to
create routing-based circuit-under-test. The algorithm proposes the routing
techniques through the 2-D array of switch matrices inside the interconnection
network and automatically identifies the involved programmable interconnection
points associated with a node. An experimental setup is proposed to measure the
performance parameters such as slack time and power with and without the
applied algorithm on the APSoC routing resources. The proposed setup requires
no external equipment such as manufactured equipments or external instruments
for performance measurement.
"
1615,"Randomized Last-Level Caches Are Still Vulnerable to Cache Side-Channel
  Attacks! But We Can Fix It","  Cache randomization has recently been revived as a promising defense against
conflict-based cache side-channel attacks. As two of the latest
implementations, CEASER-S and ScatterCache both claim to thwart conflict-based
cache side-channel attacks using randomized skewed caches. Unfortunately, our
experiments show that an attacker can easily find a usable eviction set within
the chosen remap period of CEASER-S and increasing the number of partitions
without dynamic remapping, such as ScatterCache, cannot eliminate the threat.
By quantitatively analyzing the access patterns left by various attacks in the
LLC, we have newly discovered several problems with the hypotheses and
implementations of randomized caches, which are also overlooked by the research
on conflict-based cache side-channel attack.
  However, cache randomization is not a false hope and it is an effective
defense that should be widely adopted in future processors. The newly
discovered problems are corresponding to flaws associated with the existing
implementation of cache randomization and are fixable. Several new defense
techniques are proposed in this paper. our experiments show that all the newly
discovered vulnerabilities of existing randomized caches are fixed within the
current performance budget. We also argue that randomized set-associative
caches can be sufficiently strengthened and possess a better chance to be
actually adopted in commercial processors than their skewed counterparts as
they introduce less overhaul to the existing cache structure.
"
1616,"A Novel Method for Scalable VLSI Implementation of Hyperbolic Tangent
  Function","  Hyperbolic tangent and Sigmoid functions are used as non-linear activation
units in the artificial and deep neural networks. Since, these networks are
computationally expensive, customized accelerators are designed for achieving
the required performance at lower cost and power. The activation function and
MAC units are the key building blocks of these neural networks. A low
complexity and accurate hardware implementation of the activation function is
required to meet the performance and area targets of such neural network
accelerators. Moreover, a scalable implementation is required as the recent
studies show that the DNNs may use different precision in different layers.
This paper presents a novel method based on trigonometric expansion properties
of the hyperbolic function for hardware implementation which can be easily
tuned for different accuracy and precision requirements.
"
1617,"SpinAPS: A High-Performance Spintronic Accelerator for Probabilistic
  Spiking Neural Networks","  We discuss a high-performance and high-throughput hardware accelerator for
probabilistic Spiking Neural Networks (SNNs) based on Generalized Linear Model
(GLM) neurons, that uses binary STT-RAM devices as synapses and digital CMOS
logic for neurons. The inference accelerator, termed ""SpinAPS"" for Spintronic
Accelerator for Probabilistic SNNs, implements a principled direct learning
rule for first-to-spike decoding without the need for conversion from
pre-trained ANNs. The proposed solution is shown to achieve comparable
performance with an equivalent ANN on handwritten digit and human activity
recognition benchmarks. The inference engine, SpinAPS, is shown through
software emulation tools to achieve 4x performance improvement in terms of
GSOPS/W/mm2 when compared to an equivalent SRAM-based design. The architecture
leverages probabilistic spiking neural networks that employ first-to-spike
decoding rule to make inference decisions at low latencies, achieving 75% of
the test performance in as few as 4 algorithmic time steps on the handwritten
digit benchmark. The accelerator also exhibits competitive performance with
other memristor-based DNN/SNN accelerators and state-of-the-art GPUs.
"
1618,A Time Leap Challenge for SAT Solving,"  We compare the impact of hardware advancement and algorithm advancement for
SAT solving over the last two decades. In particular, we compare 20-year-old
SAT-solvers on new computer hardware with modern SAT-solvers on 20-year-old
hardware. Our findings show that the progress on the algorithmic side has at
least as much impact as the progress on the hardware side.
"
1619,MGPU-TSM: A Multi-GPU System with Truly Shared Memory,"  The sizes of GPU applications are rapidly growing. They are exhausting the
compute and memory resources of a single GPU, and are demanding the move to
multiple GPUs. However, the performance of these applications scales
sub-linearly with GPU count because of the overhead of data movement across
multiple GPUs. Moreover, a lack of hardware support for coherency exacerbates
the problem because a programmer must either replicate the data across GPUs or
fetch the remote data using high-overhead off-chip links. To address these
problems, we propose a multi-GPU system with truly shared memory (MGPU-TSM),
where the main memory is physically shared across all the GPUs. We eliminate
remote accesses and avoid data replication using an MGPU-TSM system, which
simplifies the memory hierarchy. Our preliminary analysis shows that MGPU-TSM
with 4 GPUs performs, on average, 3.9x? better than the current best performing
multi-GPU configuration for standard application benchmarks.
"
1620,"Modeling Data Reuse in Deep Neural Networks by Taking Data-Types into
  Cognizance","  In recent years, researchers have focused on reducing the model size and
number of computations (measured as ""multiply-accumulate"" or MAC operations) of
DNNs. The energy consumption of a DNN depends on both the number of MAC
operations and the energy efficiency of each MAC operation. The former can be
estimated at design time; however, the latter depends on the intricate data
reuse patterns and underlying hardware architecture. Hence, estimating it at
design time is challenging. This work shows that the conventional approach to
estimate the data reuse, viz. arithmetic intensity, does not always correctly
estimate the degree of data reuse in DNNs since it gives equal importance to
all the data types. We propose a novel model, termed ""data type aware weighted
arithmetic intensity"" ($DI$), which accounts for the unequal importance of
different data types in DNNs. We evaluate our model on 25 state-of-the-art DNNs
on two GPUs. We show that our model accurately models data-reuse for all
possible data reuse patterns for different types of convolution and different
types of layers. We show that our model is a better indicator of the energy
efficiency of DNNs. We also show its generality using the central limit
theorem.
"
1621,"Design of Reconfigurable Multi-Operand Adder for Massively Parallel
  Processing","  The paper presents a systematic study and implementation of a reconfigurable
combinatorial multi-operand adder for use in Deep Learning systems. The size of
carry changes with the number of operands and hence a reliable algorithm to
estimate exact number of carry bits is needed for optimal implementation of a
reconfigurable multi-operand adder. A combinatorial multi-operand adder can be
faster compared to a sequential implementation using a two operand adder. Use
cases for such adders occur in modern processors for deep neural networks. Such
processors require massively parallel computing resources on chip. This paper
presents a method to estimate the upper bound on the size of carry. A method to
compute the exact number of carry bits required for a multi-operand addition
operation. A fast combinatorial parallel 4-operand adder module is presented.
An algorithm to reconfigure these adder modules to implement larger adders is
also described. Further, the paper presents two compact but slower iterative
structures that implement multi-operand addition, iterating with one column at
a time till the entire word is covered. Such serial/iterative operations are
slow but occupy small space while parallel operations are fast but use large
silicon area on chip. Interestingly, the area-to-throughput ratio of two
architectures can tilt in favor of slower, smaller and large number units
instead of the fewer numbers of fast and large compute units. A lemma presented
in the paper may be used to identify the condition when such tilt occurs.
Potentially, this can save silicon space and increase the throughput of chips
for high performance computing. Simulation results of a 16 operand adder and
using an set of 4-operand adders for use in neural networks have been
presented. Simulation results show that performance gain improves as the number
of operations or operands increases.
"
1622,"Helix: Algorithm/Architecture Co-design for Accelerating Nanopore Genome
  Base-calling","  Nanopore genome sequencing is the key to enabling personalized medicine,
global food security, and virus surveillance. The state-of-the-art base-callers
adopt deep neural networks (DNNs) to translate electrical signals generated by
nanopore sequencers to digital DNA symbols. A DNN-based base-caller consumes
$44.5\%$ of total execution time of a nanopore sequencing pipeline. However, it
is difficult to quantize a base-caller and build a power-efficient
processing-in-memory (PIM) to run the quantized base-caller. In this paper, we
propose a novel algorithm/architecture co-designed PIM, Helix, to
power-efficiently and accurately accelerate nanopore base-calling. From
algorithm perspective, we present systematic error aware training to minimize
the number of systematic errors in a quantized base-caller. From architecture
perspective, we propose a low-power SOT-MRAM-based ADC array to process
analog-to-digital conversion operations and improve power efficiency of prior
DNN PIMs. Moreover, we revised a traditional NVM-based dot-product engine to
accelerate CTC decoding operations, and create a SOT-MRAM binary comparator
array to process read voting. Compared to state-of-the-art PIMs, Helix improves
base-calling throughput by $6\times$, throughput per Watt by $11.9\times$ and
per $mm^2$ by $7.5\times$ without degrading base-calling accuracy.
"
1623,"Design Space Exploration of Power Delivery For Advanced Packaging
  Technologies","  In this paper, a design space exploration of power delivery networks is
performed for multi-chip 2.5-D and 3-D IC technologies. The focus of the paper
is the effective placement of the voltage regulator modules (VRMs) for power
supply noise (PSN) suppression. Multiple on-package VRM configurations have
been analyzed and compared. Additionally, 3D IC chip-on-VRM and
backside-of-the-package VRM configurations are studied. From the PSN
perspective, the 3D IC chip-on-VRM case suppresses the PSN the most even with
high current density hotspots. The paper also studies the impact of different
parameters such as VRM-chip distance on the package, on-chip decoupling
capacitor density, etc. on the PSN.
"
1624,"Bit Parallel 6T SRAM In-memory Computing with Reconfigurable
  Bit-Precision","  This paper presents 6T SRAM cell-based bit-parallel in-memory computing (IMC)
architecture to support various computations with reconfigurable bit-precision.
In the proposed technique, bit-line computation is performed with a short WL
followed by BL boosting circuits, which can reduce BL computing delays. By
performing carry-propagation between each near-memory circuit, bit-parallel
complex computations are also enabled by iterating operations with low latency.
In addition, reconfigurable bit-precision is also supported based on
carry-propagation size. Our 128KB in/near memory computing architecture has
been implemented using a 28nm CMOS process, and it can achieve 2.25GHz clock
frequency at 1.0V with 5.2% of area overhead. The proposed architecture also
achieves 0.68, 8.09 TOPS/W for the parallel addition and multiplication,
respectively. In addition, the proposed work also supports a wide range of
supply voltage, from 0.6V to 1.1V.
"
1625,"TransForm: Formally Specifying Transistency Models and Synthesizing
  Enhanced Litmus Tests","  Memory consistency models (MCMs) specify the legal ordering and visibility of
shared memory accesses in a parallel program. Traditionally, instruction set
architecture (ISA) MCMs assume that relevant program-visible memory ordering
behaviors only result from shared memory interactions that take place between
user-level program instructions. This assumption fails to account for virtual
memory (VM) implementations that may result in additional shared memory
interactions between user-level program instructions and both 1) system-level
operations (e.g., address remappings and translation lookaside buffer
invalidations initiated by system calls) and 2) hardware-level operations
(e.g., hardware page table walks and dirty bit updates) during a user-level
program's execution. These additional shared memory interactions can impact the
observable memory ordering behaviors of user-level programs. Thus, memory
transistency models (MTMs) have been coined as a superset of MCMs to
additionally articulate VM-aware consistency rules. However, no prior work has
enabled formal MTM specifications, nor methods to support their automated
analysis.
  To fill the above gap, this paper presents the TransForm framework. First,
TransForm features an axiomatic vocabulary for formally specifying MTMs.
Second, TransForm includes a synthesis engine to support the automated
generation of litmus tests enhanced with MTM features (i.e., enhanced litmus
tests, or ELTs) when supplied with a TransForm MTM specification. As a case
study, we formally define an estimated MTM for Intel x86 processors, called
x86t_elt, that is based on observations made by an ELT-based evaluation of an
Intel x86 MTM implementation from prior work and available public
documentation. Given x86t_elt and a synthesis bound as input, TransForm's
synthesis engine successfully produces a set of ELTs including relevant ELTs
from prior work.
"
1626,SEALing Neural Network Models in Secure Deep Learning Accelerators,"  Deep learning (DL) accelerators are increasingly deployed on edge devices to
support fast local inferences. However, they suffer from a new security
problem, i.e., being vulnerable to physical access based attacks. An adversary
can easily obtain the entire neural network (NN) model by physically snooping
the GDDR memory bus that connects the accelerator chip with DRAM memory.
Therefore, memory encryption becomes important for DL accelerators on edge
devices to improve the security of NN models. Nevertheless, we observe that
traditional memory encryption solutions that have been efficiently used in CPU
systems cause significant performance degradation when directly used in DL
accelerators. The main reason comes from the big bandwidth gap between the GDDR
memory bus and the encryption engine. To address this problem, our paper
proposes SEAL, a Secure and Efficient Accelerator scheme for deep Learning.
SEAL enhances the performance of the encrypted DL accelerator from two aspects,
i.e., improving the data access bandwidth and the efficiency of memory
encryption. Specifically, to improve the data access bandwidth, SEAL leverages
a criticality-aware smart encryption scheme which identifies partial data that
have no impact on the security of NN models and allows them to bypass the
encryption engine, thus reducing the amount of data to be encrypted. To improve
the efficiency of memory encryption, SEAL leverages a colocation mode
encryption scheme to eliminate memory accesses from counters used for
encryption by co-locating data and their counters. Our experimental results
demonstrate that, compared with traditional memory encryption solutions, SEAL
achieves 1.4 ~ 1.6 times IPC improvement and reduces the inference latency by
39% ~ 60%. Compared with a baseline accelerator without memory encryption, SEAL
compromises only 5% ~ 7% IPC for significant security improvement.
"
1627,"Ising Model Optimization Problems on a FPGA Accelerated Restricted
  Boltzmann Machine","  Optimization problems, particularly NP-Hard Combinatorial Optimization
problems, are some of the hardest computing problems with no known polynomial
time algorithm existing. Recently there has been interest in using dedicated
hardware to accelerate the solution to these problems, with physical annealers
and quantum adiabatic computers being some of the state of the art. In this
work we demonstrate usage of the Restricted Boltzmann Machine (RBM) as a
stochastic neural network capable of solving these problems efficiently. We
show that by mapping the RBM onto a reconfigurable Field Programmable Gate
Array (FPGA), we can effectively hardware accelerate the RBM's stochastic
sampling algorithm. We benchmark the RBM against the DWave 2000Q Quantum
Adiabatic Computer and the Optical Coherent Ising Machine on two such
optimization problems: the MAX-CUT problem and finding the ground state of a
Sherrington-Kirkpatrick (SK) spin glass. On these problems, the hardware
accelerated RBM shows best in class performance compared to these other
accelerators, with an empirical scaling performance of $\mathcal{O}(e^{-N})$
for probability of reaching the ground state compared to a similar empirical
$\mathcal{O}(e^{-N})$ for the CIM (with the RBM showing a constant factor of
improvement over the CIM) and empirical $\mathcal{O}(e^{-N^2})$ for the DWave
Annealer. The results show up to $10^7$x and $10^5$x time to solution
improvement compared to the DWave 2000Q on the MAX-CUT and SK problems
respectively, along with a $150$x and $1000$x performance increase compared to
the Coherent Ising Machine annealer on those problems. By using commodity
hardware running at room temperature for acceleration, the RBM also has greater
potential for immediate and scalable use.
"
1628,Trustworthy AI Inference Systems: An Industry Research View,"  In this work, we provide an industry research view for approaching the
design, deployment, and operation of trustworthy Artificial Intelligence (AI)
inference systems. Such systems provide customers with timely, informed, and
customized inferences to aid their decision, while at the same time utilizing
appropriate security protection mechanisms for AI models. Additionally, such
systems should also use Privacy-Enhancing Technologies (PETs) to protect
customers' data at any time.
  To approach the subject, we start by introducing trends in AI inference
systems. We continue by elaborating on the relationship between Intellectual
Property (IP) and private data protection in such systems. Regarding the
protection mechanisms, we survey the security and privacy building blocks
instrumental in designing, building, deploying, and operating private AI
inference systems. For example, we highlight opportunities and challenges in AI
systems using trusted execution environments combined with more recent advances
in cryptographic techniques to protect data in use. Finally, we outline areas
of further development that require the global collective attention of
industry, academia, and government researchers to sustain the operation of
trustworthy AI inference systems.
"
1629,"Area Optimized Quasi Delay Insensitive Majority Voter for TMR
  Applications","  Mission-critical and safety-critical applications generally tend to
incorporate triple modular redundancy (TMR) to embed fault tolerance in their
physical implementations. In a TMR realization, an original function block,
which may be a circuit or a system, and two exact copies of the function block
are used to successfully overcome any temporary fault or permanent failure of
an arbitrary function block during the routine operation. The corresponding
outputs of the function blocks are majority voted using 3-input majority voters
whose outputs define the outputs of a TMR realization. Hence, a 3-input
majority voter forms an important component of a TMR realization. Many
synchronous majority voters and an asynchronous non-delay insensitive majority
voter have been presented in the literature. Recently, quasi delay insensitive
(QDI) asynchronous majority voters for TMR applications were also discussed in
the literature. In this regard, this paper presents a new QDI asynchronous
majority voter for TMR applications, which is better optimized in area compared
to the existing QDI majority voters. The proposed QDI majority voter requires
30.2% less area compared to the best of the existing QDI majority voters, and
this could be useful for resource-constrained fault tolerance applications. The
example QDI TMR circuits were implemented using a 32/28nm complementary metal
oxide semiconductor (CMOS) process. The delay insensitive dual rail code was
used for data encoding, and 4-phase return-to-zero and return-to-one handshake
protocols were used for data communication.
"
1630,Intelligent Architectures for Intelligent Machines,"  Computing is bottlenecked by data. Large amounts of application data
overwhelm storage capability, communication capability, and computation
capability of the modern machines we design today. As a result, many key
applications' performance, efficiency and scalability are bottlenecked by data
movement. In this keynote talk, we describe three major shortcomings of modern
architectures in terms of 1) dealing with data, 2) taking advantage of the vast
amounts of data, and 3) exploiting different semantic properties of application
data. We argue that an intelligent architecture should be designed to handle
data well. We show that handling data well requires designing architectures
based on three key principles: 1) data-centric, 2) data-driven, 3) data-aware.
We give several examples for how to exploit each of these principles to design
a much more efficient and high performance computing system. We especially
discuss recent research that aims to fundamentally reduce memory latency and
energy, and practically enable computation close to data, with at least two
promising novel directions: 1) performing massively-parallel bulk operations in
memory by exploiting the analog operational properties of memory, with low-cost
changes, 2) exploiting the logic layer in 3D-stacked memory technology in
various ways to accelerate important data-intensive applications. We discuss
how to enable adoption of such fundamentally more intelligent architectures,
which we believe are key to efficiency, performance, and sustainability. We
conclude with some guiding principles for future computing architecture and
system designs.
"
1631,PANDA: Processing-in-MRAM Accelerated De Bruijn Graph based DNA Assembly,"  Spurred by widening gap between data processing speed and data communication
speed in Von-Neumann computing architectures, some bioinformatic applications
have harnessed the computational power of Processing-in-Memory (PIM) platforms.
However, the performance of PIMs unavoidably diminishes when dealing with such
complex applications seeking bulk bit-wise comparison or addition operations.
In this work, we present an efficient Processing-in-MRAM Accelerated De Bruijn
Graph based DNA Assembly platform named PANDA based on an optimized and
hardware-friendly genome assembly algorithm. PANDA is able to assemble
large-scale DNA sequence data-set from all-pair overlaps. We first design PANDA
platform that exploits MRAM as a computational memory and converts it to a
potent processing unit for genome assembly. PANDA can execute not only
efficient bulk bit-wise X(N)OR-based comparison/addition operations heavily
required for the genome assembly task but a full-set of 2-/3-input logic
operations inside MRAM chip. We then develop a highly parallel and step-by-step
hardware-friendly DNA assembly algorithm for PANDA that only requires the
developed in-memory logic operations. The platform is then configured with a
novel data partitioning and mapping technique that provides local storage and
processing to fully utilize the algorithm-level's parallelism. The cross-layer
simulation results demonstrate that PANDA reduces the run time and power,
respectively, by a factor of 18 and 11 compared with CPU. Besides, speed-ups of
up-to 2-4x can be obtained over recent processing-in-MRAM platforms to perform
the same task.
"
1632,"Manticore: A 4096-core RISC-V Chiplet Architecture for Ultra-efficient
  Floating-point Computing","  Data-parallel problems, commonly found in data analytics, machine learning,
and scientific computing demand ever growing floating-point operations per
second under tight area- and energy-efficiency constraints.
Application-specific architectures and accelerators, while efficient at a given
task, are hard to adjust to algorithmic changes. In this work, we present
Manticore, a general-purpose, ultra-efficient, RISC-V, chiplet-based
architecture for data-parallel floating-point workloads. We have manufactured a
9$\text{mm}^2$ prototype of the chiplet's computational core in Globalfoundries
22nm FD-SOI process and demonstrate more than 2.5$\times$ improvement in energy
efficiency on floating-point intensive workloads compared to high performance
compute engines (CPUs and GPUs), despite their more advanced FinFET process.
The prototype contains two 64-bit, application-class RISC-V Ariane management
cores that run a full-fledged Linux OS. The compute capability at high energy
and area efficiency is provided by Snitch clusters. Each cluster contains eight
small (20kGE) 32-bit integer RISC-V cores, each controlling a large
double-precision floating-point unit (120kGE). Each core supports two custom
RISC-V ISA extensions: FREP and SSR. The SSR extension elides explicit load and
store instructions by encoding them as register reads and writes. The FREP
extension mostly decouples the integer core from the FPU by allowing a sequence
buffer to issue instructions to the FPU independently. Both extensions allow
the tiny, single-issue, integer core to saturate the instruction bandwidth of
the FPU and achieve FPU utilization above 90%, with more than 80% of core area
dedicated to the FPU.
"
1633,Toward an End-to-End Auto-tuning Framework in HPC PowerStack,"  Efficiently utilizing procured power and optimizing performance of scientific
applications under power and energy constraints are challenging. The HPC
PowerStack defines a software stack to manage power and energy of
high-performance computing systems and standardizes the interfaces between
different components of the stack. This survey paper presents the findings of a
working group focused on the end-to-end tuning of the PowerStack. First, we
provide a background on the PowerStack layer-specific tuning efforts in terms
of their high-level objectives, the constraints and optimization goals,
layer-specific telemetry, and control parameters, and we list the existing
software solutions that address those challenges. Second, we propose the
PowerStack end-to-end auto-tuning framework, identify the opportunities in
co-tuning different layers in the PowerStack, and present specific use cases
and solutions. Third, we discuss the research opportunities and challenges for
collective auto-tuning of two or more management layers (or domains) in the
PowerStack. This paper takes the first steps in identifying and aggregating the
important R&D challenges in streamlining the optimization efforts across the
layers of the PowerStack.
"
1634,"Breaking Barriers: Maximizing Array Utilization for Compute In-Memory
  Fabrics","  Compute in-memory (CIM) is a promising technique that minimizes data
transport, the primary performance bottleneck and energy cost of most data
intensive applications. This has found wide-spread adoption in accelerating
neural networks for machine learning applications. Utilizing a crossbar
architecture with emerging non-volatile memories (eNVM) such as dense resistive
random access memory (RRAM) or phase change random access memory (PCRAM),
various forms of neural networks can be implemented to greatly reduce power and
increase on chip memory capacity. However, compute in-memory faces its own
limitations at both the circuit and the device levels. Although compute
in-memory using the crossbar architecture can greatly reduce data transport,
the rigid nature of these large fixed weight matrices forfeits the flexibility
of traditional CMOS and SRAM based designs. In this work, we explore the
different synchronization barriers that occur from the CIM constraints.
Furthermore, we propose a new allocation algorithm and data flow based on input
data distributions to maximize utilization and performance for compute-in
memory based designs. We demonstrate a 7.47$\times$ performance improvement
over a naive allocation method for CIM accelerators on ResNet18.
"
1635,"Mesorasi: Architecture Support for Point Cloud Analytics via
  Delayed-Aggregation","  Point cloud analytics is poised to become a key workload on battery-powered
embedded and mobile platforms in a wide range of emerging application domains,
such as autonomous driving, robotics, and augmented reality, where efficiency
is paramount. This paper proposes Mesorasi, an algorithm-architecture
co-designed system that simultaneously improves the performance and energy
efficiency of point cloud analytics while retaining its accuracy. Our extensive
characterizations of state-of-the-art point cloud algorithms show that, while
structurally reminiscent of convolutional neural networks (CNNs), point cloud
algorithms exhibit inherent compute and memory inefficiencies due to the unique
characteristics of point cloud data. We propose delayed-aggregation, a new
algorithmic primitive for building efficient point cloud algorithms.
Delayed-aggregation hides the performance bottlenecks and reduces the compute
and memory redundancies by exploiting the approximately distributive property
of key operations in point cloud algorithms. Delayed-aggregation let point
cloud algorithms achieve 1.6x speedup and 51.1% energy reduction on a mobile
GPU while retaining the accuracy (-0.9% loss to 1.2% gains). To maximize the
algorithmic benefits, we propose minor extensions to contemporary CNN
accelerators, which can be integrated into a mobile Systems-on-a-Chip (SoC)
without modifying other SoC components. With additional hardware support,
Mesorasi achieves up to 3.6x speedup.
"
1636,"DORY: Automatic End-to-End Deployment of Real-World DNNs on Low-Cost IoT
  MCUs","  The deployment of Deep Neural Networks (DNNs) on end-nodes at the extreme
edge of the Internet-of-Things is a critical enabler to support pervasive Deep
Learning-enhanced applications. Low-Cost MCU-based end-nodes have limited
on-chip memory and often replace caches with scratchpads, to reduce area
overheads and increase energy efficiency -- requiring explicit DMA-based memory
transfers between different levels of the memory hierarchy. Mapping modern DNNs
on these systems requires aggressive topology-dependent tiling and
double-buffering. In this work, we propose DORY (Deployment Oriented to memoRY)
- an automatic tool to deploy DNNs on low cost MCUs with typically less than
1MB of on-chip SRAM memory. DORY abstracts tiling as a Constraint Programming
(CP) problem: it maximizes L1 memory utilization under the topological
constraints imposed by each DNN layer. Then, it generates ANSI C code to
orchestrate off- and on-chip transfers and computation phases. Furthermore, to
maximize speed, DORY augments the CP formulation with heuristics promoting
performance-effective tile sizes. As a case study for DORY, we target
GreenWaves Technologies GAP8, one of the most advanced parallel ultra-low power
MCU-class devices on the market. On this device, DORY achieves up to 2.5x
better MAC/cycle than the GreenWaves proprietary software solution and 18.1x
better than the state-of-the-art result on an STM32-F746 MCU on single layers.
Using our tool, GAP-8 can perform end-to-end inference of a 1.0-MobileNet-128
network consuming just 63 pJ/MAC on average @ 4.3 fps - 15.4x better than an
STM32-F746. We release all our developments - the DORY framework, the optimized
backend kernels, and the related heuristics - as open-source software.
"
1637,"CARGO : Context Augmented Critical Region Offload for Network-bound
  datacenter Workloads","  Network bound applications, like a database server executing OLTP queries or
a caching server storing objects for a dynamic web applications, are essential
services that consumers and businesses use daily. These services run on a large
datacenters and are required to meet predefined Service Level Objectives (SLO),
or latency targets, with high probability. Thus, efficient datacenter
applications should optimize their execution in terms of power and performance.
However, to support large scale data storage, these workloads make heavy use of
pointer connected data structures (e.g., hash table, large fan-out tree, trie)
and exhibit poor instruction and memory level parallelism. Our experiments show
that due to long memory access latency, these workloads occupy processor
resources (e.g., ROB entries, RS buffers, LS queue entries etc.) for a
prolonged period of time that delay the processing of subsequent requests.
Delayed execution not only increases request processing latency, but also
severely effects an application throughput and power-efficiency. To overcome
this limitation, we present CARGO, a novel mechanism to overlap queuing latency
and request processing by executing select instructions on an application
critical path at the network interface card (NIC) while requests wait for
processor resources to become available. Our mechanism dynamically identifies
the critical instructions and includes the register state needed to compute the
long latency memory accesses. This context-augmented critical region is often
executed at the NIC well before execution begins at the core, effectively
prefetching the data ahead of time. Across a variety of interactive datacenter
applications, our proposal improves latency, throughput, and power efficiency
by 2.7X, 2.7X, and 1.5X, respectively, while incurring a modest amount storage
overhead.
"
1638,"High-Performance Simultaneous Multiprocessing for Heterogeneous
  System-on-Chip","  This paper presents a methodology for simultaneous heterogeneous computing,
named ENEAC, where a quad core ARM Cortex-A53 CPU works in tandem with a
preprogrammed on-board FPGA accelerator. A heterogeneous scheduler distributes
the tasks optimally among all the resources and all compute units run
asynchronously, which allows for improved performance for irregular workloads.
ENEAC achieves up to 17\% performance improvement \ignore{and 14\% energy usage
reduction,} when using all platform resources compared to just using the FPGA
accelerators and up to 865\% performance increase \ignore{and up to 89\% energy
usage decrease} when using just the CPU. The workflow uses existing commercial
tools and C/C++ as a single programming language for both accelerator design
and CPU programming for improved productivity and ease of verification.
"
1639,"ADIC: Anomaly Detection Integrated Circuit in 65nm CMOS utilizing
  Approximate Computing","  In this paper, we present a low-power anomaly detection integrated circuit
(ADIC) based on a one-class classifier (OCC) neural network. The ADIC achieves
low-power operation through a combination of (a) careful choice of algorithm
for online learning and (b) approximate computing techniques to lower average
energy. In particular, online pseudoinverse update method (OPIUM) is used to
train a randomized neural network for quick and resource efficient learning. An
additional 42% energy saving can be achieved when a lighter version of OPIUM
method is used for training with the same number of data samples lead to no
significant compromise on the quality of inference. Instead of a single
classifier with large number of neurons, an ensemble of K base learner approach
is chosen to reduce learning memory by a factor of K. This also enables
approximate computing by dynamically varying the neural network size based on
anomaly detection. Fabricated in 65nm CMOS, the ADIC has K = 7 Base Learners
(BL) with 32 neurons in each BL and dissipates 11.87pJ/OP and 3.35pJ/OP during
learning and inference respectively at Vdd = 0.75V when all 7 BLs are enabled.
Further, evaluated on the NASA bearing dataset, approximately 80% of the chip
can be shut down for 99% of the lifetime leading to an energy efficiency of
0.48pJ/OP, an 18.5 times reduction over full-precision computing running at Vdd
= 1.2V throughout the lifetime.
"
1640,Low-complexity Architecture for AR(1) Inference,"  In this Letter, we propose a low-complexity estimator for the correlation
coefficient based on the signed $\operatorname{AR}(1)$ process. The introduced
approximation is suitable for implementation in low-power hardware
architectures. Monte Carlo simulations reveal that the proposed estimator
performs comparably to the competing methods in literature with maximum error
in order of $10^{-2}$. However, the hardware implementation of the introduced
method presents considerable advantages in several relevant metrics, offering
more than 95% reduction in dynamic power and doubling the maximum operating
frequency when compared to the reference method.
"
1641,Ptolemy: Architecture Support for Robust Deep Learning,"  Deep learning is vulnerable to adversarial attacks, where carefully-crafted
input perturbations could mislead a well-trained Deep Neural Network to produce
incorrect results. Today's countermeasures to adversarial attacks either do not
have capability to detect adversarial samples at inference time, or introduce
prohibitively high overhead to be practical at inference time.
  We propose Ptolemy, an algorithm-architecture co-designed system that detects
adversarial attacks at inference time with low overhead and high accuracy.We
exploit the synergies between DNN inference and imperative program execution:
an input to a DNN uniquely activates a set of neurons that contribute
significantly to the inference output, analogous to the sequence of basic
blocks exercised by an input in a conventional program. Critically, we observe
that adversarial samples tend to activate distinctive paths from those of
benign inputs. Leveraging this insight, we propose an adversarial sample
detection framework, which uses canary paths generated from offline profiling
to detect adversarial samples at runtime. The Ptolemy compiler along with the
co-designed hardware enable efficient execution by exploiting the unique
algorithmic characteristics. Extensive evaluations show that Ptolemy achieves
higher or similar adversarial example detection accuracy than today's
mechanisms with a much lower runtime (as low as 2%) overhead.
"
1642,Tearing Down the Memory Wall,"  We present a vision for the Erudite architecture that redefines the compute
and memory abstractions such that memory bandwidth and capacity become
first-class citizens along with compute throughput. In this architecture, we
envision coupling a high-density, massively parallel memory technology like
Flash with programmable near-data accelerators, like the streaming
multiprocessors in modern GPUs. Each accelerator has a local pool of
storage-class memory that it can access at high throughput by initiating very
large numbers of overlapping requests that help to tolerate long access
latency. The accelerators can also communicate with each other and remote
memory through a high-throughput low-latency interconnect. As a result, systems
based on the Erudite architecture scale compute and memory bandwidth at the
same rate, tearing down the notorious memory wall that has plagued computer
architecture for generations. In this paper, we present the motivation,
rationale, design, benefit, and research challenges for Erudite.
"
1643,"Evaluation of hybrid run-time power models for the ARM big.LITTLE
  architecture","  Heterogeneous processors, formed by binary compatible CPU cores with
different microarchitectures, enable energy reductions by better matching
processing capabilities and software application requirements. This new
hardware platform requires novel techniques to manage power and energy to fully
utilize its capabilities, particularly regarding the mapping of workloads to
appropriate cores. In this paper we validate relevant published work related to
power modelling for heterogeneous systems and propose a new approach for
developing run-time power models that uses a hybrid set of physical predictors,
performance events and CPU state information. We demonstrate the accuracy of
this approach compared with the state-of-the-art and its applicability to
energy aware scheduling. Our results are obtained on a commercially available
platform built around the Samsung Exynos 5 Octa SoC, which features the ARM
big.LITTLE heterogeneous architecture.
"
1644,ALIGN: A System for Automating Analog Layout,"  ALIGN (""Analog Layout, Intelligently Generated from Netlists"") is an
open-source automatic layout generation flow for analog circuits. ALIGN
translates an input SPICE netlist to an output GDSII layout, specific to a
given technology, as specified by a set of design rules. The flow first
automatically detects hierarchies in the circuit netlist and translates layout
synthesis to a problem of hierarchical block assembly. At the lowest level,
parameterized cells are generated using an abstraction of the design rules;
these blocks are then assembled under geometric and electrical constraints to
build the circuit layout. ALIGN has been applied to generate layouts for a
diverse set of analog circuit families: low frequency analog blocks, wireline
circuits, wireless circuits, and power delivery circuits.
"
1645,Optically Connected Memory for Disaggregated Data Centers,"  Recent advances in integrated photonics enable the implementation of
reconfigurable, high-bandwidth, and low energy-per-bit interconnects in
next-generation data centers. We propose and evaluate an Optically Connected
Memory (OCM) architecture that disaggregates the main memory from the
computation nodes in data centers. OCM is based on micro-ring resonators
(MRRs), and it does not require any modification to the DRAM memory modules. We
calculate energy consumption from real photonic devices and integrate them into
a system simulator to evaluate performance. Our results show that (1) OCM is
capable of interconnecting four DDR4 memory channels to a computing node using
two fibers with 1.07 pJ energy-per-bit consumption and (2) OCM performs up to
5.5x faster than a disaggregated memory with 40G PCIe NIC connectors to
computing nodes.
"
1646,"8 Steps to 3.7 TFLOP/s on NVIDIA V100 GPU: Roofline Analysis and Other
  Tricks","  Performance optimization can be a daunting task especially as the hardware
architecture becomes more and more complex. This paper takes a kernel from the
Materials Science code BerkeleyGW, and demonstrates a few performance analysis
and optimization techniques. Despite challenges such as high register usage,
low occupancy, complex data access patterns, and the existence of several
long-latency instructions, we have achieved 3.7 TFLOP/s of double-precision
performance on an NVIDIA V100 GPU, with 8 optimization steps. This is 55% of
the theoretical peak, 6.7 TFLOP/s, at nominal frequency 1312 MHz, and 70% of
the more customized peak based on our 58% FMA ratio, 5.3 TFLOP/s. An array of
techniques used to analyze this OpenACC kernel and optimize its performance are
shown, including the use of hierarchical Roofline performance model and the
performance tool Nsight Compute. This kernel exhibits computational
characteristics that are commonly seen in many high-performance computing (HPC)
applications, and are expected to be very helpful to a general audience of HPC
developers and computational scientists, as they pursue more performance on
NVIDIA GPUs.
"
1647,"Mitigating the Latency-Area Tradeoffs for DRAM Design with
  Coarse-Grained Monolithic 3D (M3D) Integration","  Over the years, the DRAM latency has not scaled proportionally with its
density due to the cost-centric mindset of the DRAM industry. Prior work has
shown that this shortcoming can be overcome by reducing the critical length of
DRAM access path. However, doing so decreases DRAM area-efficiency,
exacerbating the latency-area tradeoffs for DRAM design. In this paper, we show
that reorganizing DRAM cell-arrays using the emerging monolithic 3D (M3D)
integration technology can mitigate these fundamental latency-area tradeoffs.
Based on our evaluation results for PARSEC benchmarks, our designed M3D DRAM
cell-array organizations can yield up to 9.56% less latency, up to 4.96% less
power consumption, and up to 21.21% less energy-delay product (EDP), with up to
14% less DRAM die area, com-pared to the conventional 2D DDR4 DRAM.
"
1648,An Approximate Carry Estimating Simultaneous Adder with Rectification,"  Approximate computing has in recent times found significant applications
towards lowering power, area, and time requirements for arithmetic operations.
Several works done in recent years have furthered approximate computing along
these directions. In this work, we propose a new approximate adder that employs
a carry prediction method. This allows parallel propagation of the carry
allowing faster calculations. In addition to the basic adder design, we also
propose a rectification logic which would enable higher accuracy for larger
computations. Experimental results show that our adder produces results 91.2%
faster than the conventional ripple-carry adder. In terms of accuracy, the
addition of rectification logic to the basic design produces results that are
more accurate than state-of-the-art adders like SARA and BCSA by 74%.
"
1649,GuardNN: Secure DNN Accelerator for Privacy-Preserving Deep Learning,"  This paper proposes GuardNN, a secure deep neural network (DNN) accelerator,
which provides strong hardware-based protection for user data and model
parameters even in an untrusted environment. GuardNN shows that the
architecture and protection can be customized for a specific application to
provide strong confidentiality and integrity protection with negligible
overhead. The design of the GuardNN instruction set reduces the TCB to just the
accelerator and enables confidentiality protection without the overhead of
integrity protection. GuardNN also introduces a new application-specific memory
protection scheme to minimize the overhead of memory encryption and integrity
verification. The scheme shows that most of the off-chip meta-data in today's
state-of-the-art memory protection can be removed by exploiting the known
memory access patterns of a DNN accelerator. GuardNN is implemented as an FPGA
prototype, which demonstrates effective protection with less than 2%
performance overhead for inference over a variety of modern DNN models.
"
1650,"An 8-bit In Resistive Memory Computing Core with Regulated Passive
  Neuron and Bit Line Weight Mapping","  The rapid development of Artificial Intelligence (AI) and Internet of Things
(IoT) increases the requirement for edge computing with low power and
relatively high processing speed devices. The Computing-In-Memory(CIM) schemes
based on emerging resistive Non-Volatile Memory(NVM) show great potential in
reducing the power consumption for AI computing. However, the device
inconsistency of the non-volatile memory may significantly degenerate the
performance of the neural network. In this paper, we propose a low power
Resistive RAM (RRAM) based CIM core to not only achieve high computing
efficiency but also greatly enhance the robustness by bit line regulator and
bit line weight mapping algorithm. The simulation results show that the power
consumption of our proposed 8-bit CIM core is only 3.61mW (256*256). The SFDR
and SNDR of the CIM core achieve 59.13 dB and 46.13 dB, respectively. The
proposed bit line weight mapping scheme improves the top-1 accuracy by 2.46%
and 3.47% for AlexNet and VGG16 on ImageNet Large Scale Visual Recognition
Competition 2012 (ILSVRC 2012) in 8-bit mode, respectively.
"
1651,"A transprecision floating-point cluster for efficient near-sensor data
  analytics","  Recent applications in the domain of near-sensor computing require the
adoption of floating-point arithmetic to reconcile high precision results with
a wide dynamic range. In this paper, we propose a multi-core computing cluster
that leverages the fined-grained tunable principles of transprecision computing
to provide support to near-sensor applications at a minimum power budget. Our
design - based on the open-source RISC-V architecture - combines
parallelization and sub-word vectorization with near-threshold operation,
leading to a highly scalable and versatile system. We perform an exhaustive
exploration of the design space of the transprecision cluster on a
cycle-accurate FPGA emulator, with the aim to identify the most efficient
configurations in terms of performance, energy efficiency, and area efficiency.
We also provide a full-fledged software stack support, including a parallel
runtime and a compilation toolchain, to enable the development of end-to-end
applications. We perform an experimental assessment of our design on a set of
benchmarks representative of the near-sensor processing domain, complementing
the timing results with a post place-&-route analysis of the power consumption.
Finally, a comparison with the state-of-the-art shows that our solution
outperforms the competitors in energy efficiency, reaching a peak of 97
Gflop/s/W on single-precision scalars and 162 Gflop/s/W on half-precision
vectors.
"
1652,"Analysis of Interference between RDMA and Local Access on Hybrid Memory
  System","  We can use a hybrid memory system consisting of DRAM and Intel Optane DC
Persistent Memory (We call it DCPM in this paper) as DCPM is now commercially
available since April 2019. Even if the latency for DCPM is several times
higher than that for DRAM, the capacity for DCPM is several times higher than
that for DRAM and the cost of DCPM is also several times lower than that for
DRAM. In addition, DCPM is non-volatile. A Server with this hybrid memory
system could improve the performance for in-memory database systems and virtual
machine (VM) systems because these systems often consume a large amount of
memory. Moreover, a high-speed shared storage system can be implemented by
accessing DCPM via remote direct memory access (RDMA). I assume that some of
the DCPM is often assigned as a shared area among other remote servers because
applications executed on a server with a hybrid memory system often cannot use
the entire capacity of DCPM. This paper evaluates the interference between
local memory access and RDMA from a remote server. As a result, I indicate that
the interference on this hybrid memory system is significantly different from
that on a conventional DRAM-only memory system. I also believe that some kind
of throttling implementation is needed when this interference occures.
"
1653,"DNNExplorer: A Framework for Modeling and Exploring a Novel Paradigm of
  FPGA-based DNN Accelerator","  Existing FPGA-based DNN accelerators typically fall into two design
paradigms. Either they adopt a generic reusable architecture to support
different DNN networks but leave some performance and efficiency on the table
because of the sacrifice of design specificity. Or they apply a layer-wise
tailor-made architecture to optimize layer-specific demands for computation and
resources but loose the scalability of adaptation to a wide range of DNN
networks. To overcome these drawbacks, this paper proposes a novel FPGA-based
DNN accelerator design paradigm and its automation tool, called DNNExplorer, to
enable fast exploration of various accelerator designs under the proposed
paradigm and deliver optimized accelerator architectures for existing and
emerging DNN networks. Three key techniques are essential for DNNExplorer's
improved performance, better specificity, and scalability, including (1) a
unique accelerator design paradigm with both high-dimensional design space
support and fine-grained adjustability, (2) a dynamic design space to
accommodate different combinations of DNN workloads and targeted FPGAs, and (3)
a design space exploration (DSE) engine to generate optimized accelerator
architectures following the proposed paradigm by simultaneously considering
both FPGAs' computation and memory resources and DNN networks' layer-wise
characteristics and overall complexity. Experimental results show that, for the
same FPGAs, accelerators generated by DNNExplorer can deliver up to 4.2x higher
performances (GOP/s) than the state-of-the-art layer-wise pipelined solutions
generated by DNNBuilder for VGG-like DNN with 38 CONV layers. Compared to
accelerators with generic reusable computation units, DNNExplorer achieves up
to 2.0x and 4.4x DSP efficiency improvement than a recently published
accelerator design from academia (HybridDNN) and a commercial DNN accelerator
IP (Xilinx DPU), respectively.
"
1654,Architectural Analysis of FPGA Technology Impact,"  The use of high-level languages for designing hardware is gaining popularity
since they increase design productivity by providing higher abstractions.
However, one drawback of such abstraction level has been the difficulty of
relating the low-level implementation problems back to the original high-level
design, which is paramount for architectural optimization. In this work
(developed between April 2013 and April 2014), we propose a methodology to
analyze the effects of technology over the architecture, and to generate
architectural-level area, delay and power metrics. Such feedback allows the
designer to quickly gauge the impact of architectural decisions on the quality
of generated hardware and opens the door to automatic architectural analysis.
We demonstrate the use of our technique on three FPGA platforms using two
designs: a Reed-Solomon error correction decoder and a 32-bit pipelined
processor implementation.
"
1655,"Machine Learning Clustering Techniques for Selective Mitigation of
  Critical Design Features","  Selective mitigation or selective hardening is an effective technique to
obtain a good trade-off between the improvements in the overall reliability of
a circuit and the hardware overhead induced by the hardening techniques.
Selective mitigation relies on preferentially protecting circuit instances
according to their susceptibility and criticality. However, ranking circuit
parts in terms of vulnerability usually requires computationally intensive
fault-injection simulation campaigns. This paper presents a new methodology
which uses machine learning clustering techniques to group flip-flops with
similar expected contributions to the overall functional failure rate, based on
the analysis of a compact set of features combining attributes from static
elements and dynamic elements. Fault simulation campaigns can then be executed
on a per-group basis, significantly reducing the time and cost of the
evaluation. The effectiveness of grouping similar sensitive flip-flops by
machine learning clustering algorithms is evaluated on a practical
example.Different clustering algorithms are applied and the results are
compared to an ideal selective mitigation obtained by exhaustive
fault-injection simulation.
"
1656,"Helper Without Threads: Customized Prefetching for Delinquent Irregular
  Loads","  The growing memory footprints of cloud and big data applications mean that
data center CPUs can spend significant time waiting for memory. An attractive
approach to improving performance in such centralized compute settings is to
employ prefetchers that are customized per application, where gains can be
easily scaled across thousands of machines. Helper thread prefetching is such a
technique but has yet to achieve wide adoption since it requires spare thread
contexts or special hardware/firmware support. In this paper, we propose an
inline software prefetching technique that overcomes these restrictions by
inserting the helper code into the main thread itself. Our approach is
complementary to and does not interfere with existing hardware prefetchers
since we target only delinquent irregular load instructions (those with no
constant or striding address patterns). For each chosen load instruction, we
generate and insert a customized software prefetcher extracted from and
mimicking the application's dataflow, all without access to the application
source code. For a set of irregular workloads that are memory-bound, we
demonstrate up to 2X single-thread performance improvement on recent high-end
hardware (Intel Skylake) and up to 83% speedup over a helper thread
implementation on the same hardware, due to the absence of thread spawning
overhead.
"
1657,RISC micrprocessor verification,"  Today's microprocessors have grown significantly in complexity and
functionality. Most of today's processors provide at least three levels of
memory hierarchy, are heavily pipelined, and support some sort of cache
coherency protocol. These features are extremely complex and sophisticated, and
present their own set of unique verification challenges. Verification is
clearly not a point tool, but is part of a process that starts from initial
product conception and is to some degrees complete when the product goes to
market. Functional verification is necessary to verify the functionality at RTL
level. Complex micro-processors like ARM are high performance, low cost and low
power 32-bit RISC processors. In our paper complex microprocessor is ARM cortex
M3, developed for the embedded applications having low interrupt latency, low
gate count, 3- stage pipelining, branch prediction, THUMB and THUMB-2
instruction set. Functional verification is used to verify that the circuit
full fills each abstract assertion under the implementation mapping. we explore
several aspects of processor design, including caches, pipeline depth, ALUs,
and bypass logic.The verification was done concurrently with the design
implementation of the processor.
"
1658,"Reversible Computing with Fast, Fully Static, Fully Adiabatic CMOS","  To advance the energy efficiency of general digital computing far beyond the
thermodynamic limits that apply to conventional digital circuits will require
utilizing the principles of reversible computing. It has been known since the
early 1990s that reversible computing based on adiabatic switching is possible
in CMOS, although almost all of the ""adiabatic"" CMOS logic families in the
literature are not actually fully adiabatic, which limits their achievable
energy savings. The first CMOS logic style that achieved truly, fully adiabatic
operation if leakage was negligible (CRL) is not fully static, which leads to a
number of practical engineering difficulties in the presence of certain
nonidealities. Later, ""static"" adiabatic logic families were described, but
they were not actually fully adiabatic, or fully static, and were much slower.
  In this paper, we describe a new logic family, Static 2-Level Adiabatic Logic
(S2LAL), which is, to our knowledge, the first CMOS logic family that is both
fully static, and truly, fully adiabatic (modulo leakage). In addition, S2LAL
is, we think, the fastest possible such family (among fully pipelined
sequential circuits), having a latency per logic stage of one ""tick""
(transition time), and a minimum clock period (initiation interval) of 8 ticks.
S2LAL requires 8 phases of a trapezoidal power-clock waveform (plus constant
power and ground references) to be supplied. We argue that, if implemented in a
suitable fabrication process designed to aggressively minimize leakage, S2LAL
should be capable of demonstrating a greater level of energy efficiency than
any other semiconductor-based digital logic family known today.
"
1659,"Direct CMOS Implementation of Neuromorphic Temporal Neural Networks for
  Sensory Processing","  Temporal Neural Networks (TNNs) use time as a resource to represent and
process information, mimicking the behavior of the mammalian neocortex. This
work focuses on implementing TNNs using off-the-shelf digital CMOS technology.
A microarchitecture framework is introduced with a hierarchy of building blocks
including: multi-neuron columns, multi-column layers, and multi-layer TNNs. We
present the direct CMOS gate-level implementation of the multi-neuron column
model as the key building block for TNNs. Post-synthesis results are obtained
using Synopsys tools and the 45 nm CMOS standard cell library. The TNN
microarchitecture framework is embodied in a set of characteristic equations
for assessing the total gate count, die area, compute time, and power
consumption for any TNN design. We develop a multi-layer TNN prototype of 32M
gates. In 7 nm CMOS process, it consumes only 1.54 mm^2 die area and 7.26 mW
power and can process 28x28 images at 107M FPS (9.34 ns per image). We evaluate
the prototype's performance and complexity relative to a recent
state-of-the-art TNN model.
"
1660,"Building Application-Specific Overlays on FPGAs with High-Level
  Customizable IPs","  Overlays are virtual, re-configurable architectures that overlay on top of
physical FPGA fabrics. An overlay that is specialized for an application, or a
class of applications, offers both fast reconfiguration and minimized
performance penalty. Such an overlay is usually implemented by hardware
designers in hardware ""assembly"" languages at register-transfer level (RTL).
  This short article proposes an idea for a software programmer, instead of
hardware designers, to quickly implement an application-specific overlay using
high-level customizable IPs. These IPs are expressed succinctly by a
specification language, whose abstraction level is much higher than RTL but can
nonetheless expresses many performance-critical loop and data optimizations on
FPGAs, and thus would offer competitively high performance at a much lower cost
of maintenance and much easier customizations.
  We propose new language features to easily put the IPs together into an
overlay. A compiler automatically implements the specified optimizations to
generate an efficient overlay, exposes a multi-tasking programming interface
for the overlay, and inserts a runtime scheduler for scheduling tasks to run on
the IPs of the overlay, respecting the dependences between the tasks. While an
application written in any language can take advantage of the overlay through
the programming interface, we show a particular usage scenario, where the
application itself is also succinctly specified in the same language.
  We describe the new language features for expressing overlays, and illustrate
the features with an LU decomposer and a convolutional neural network. A system
is under construction to implement the language features and workloads.
"
1661,"A Survey on Recent Hardware Data Prefetching Approaches with An Emphasis
  on Servers","  Data prefetching, i.e., the act of predicting application's future memory
accesses and fetching those that are not in the on-chip caches, is a well-known
and widely-used approach to hide the long latency of memory accesses. The
fruitfulness of data prefetching is evident to both industry and academy:
nowadays, almost every high-performance processor incorporates a few data
prefetchers for capturing various access patterns of applications; besides,
there is a myriad of proposals for data prefetching in the research literature,
where each proposal enhances the efficiency of prefetching in a specific way.
In this survey, we discuss the fundamental concepts in data prefetching and
study state-of-the-art hardware data prefetching approaches. Additional Key
Words and Phrases: Data Prefetching, Scale-Out Workloads, Server Processors,
and Spatio-Temporal Correlation.
"
1662,"TensorDash: Exploiting Sparsity to Accelerate Deep Neural Network
  Training and Inference","  TensorDash is a hardware level technique for enabling data-parallel MAC units
to take advantage of sparsity in their input operand streams. When used to
compose a hardware accelerator for deep learning, TensorDash can speedup the
training process while also increasing energy efficiency. TensorDash combines a
low-cost, sparse input operand interconnect comprising an 8-input multiplexer
per multiplier input, with an area-efficient hardware scheduler. While the
interconnect allows a very limited set of movements per operand, the scheduler
can effectively extract sparsity when it is present in the activations, weights
or gradients of neural networks. Over a wide set of models covering various
applications, TensorDash accelerates the training process by $1.95{\times}$
while being $1.89\times$ more energy-efficient, $1.6\times$ more energy
efficient when taking on-chip and off-chip memory accesses into account. While
TensorDash works with any datatype, we demonstrate it with both
single-precision floating-point units and bfloat16.
"
1663,Architectural Implications of Graph Neural Networks,"  Graph neural networks (GNN) represent an emerging line of deep learning
models that operate on graph structures. It is becoming more and more popular
due to its high accuracy achieved in many graph-related tasks. However, GNN is
not as well understood in the system and architecture community as its
counterparts such as multi-layer perceptrons and convolutional neural networks.
This work tries to introduce the GNN to our community. In contrast to prior
work that only presents characterizations of GCNs, our work covers a large
portion of the varieties for GNN workloads based on a general GNN description
framework. By constructing the models on top of two widely-used libraries, we
characterize the GNN computation at inference stage concerning general-purpose
and application-specific architectures and hope our work can foster more system
and architecture research for GNNs.
"
1664,"HL-Pow: A Learning-Based Power Modeling Framework for High-Level
  Synthesis","  High-level synthesis (HLS) enables designers to customize hardware designs
efficiently. However, it is still challenging to foresee the correlation
between power consumption and HLS-based applications at an early design stage.
To overcome this problem, we introduce HL-Pow, a power modeling framework for
FPGA HLS based on state-of-the-art machine learning techniques. HL-Pow
incorporates an automated feature construction flow to efficiently identify and
extract features that exert a major influence on power consumption, simply
based upon HLS results, and a modeling flow that can build an accurate and
generic power model applicable to a variety of designs with HLS. By using
HL-Pow, the power evaluation process for FPGA designs can be significantly
expedited because the power inference of HL-Pow is established on HLS instead
of the time-consuming register-transfer level (RTL) implementation flow.
Experimental results demonstrate that HL-Pow can achieve accurate power
modeling that is only 4.67% (24.02 mW) away from onboard power measurement. To
further facilitate power-oriented optimizations, we describe a novel design
space exploration (DSE) algorithm built on top of HL-Pow to trade off between
latency and power consumption. This algorithm can reach a close approximation
of the real Pareto frontier while only requiring running HLS flow for 20% of
design points in the entire design space.
"
1665,"CONTRA: Area-Constrained Technology Mapping Framework For Memristive
  Memory Processing Unit","  Data-intensive applications are poised to benefit directly from
processing-in-memory platforms, such as memristive Memory Processing Units,
which allow leveraging data locality and performing stateful logic operations.
Developing design automation flows for such platforms is a challenging and
highly relevant research problem. In this work, we investigate the problem of
minimizing delay under arbitrary area constraint for MAGIC-based in-memory
computing platforms. We propose an end-to-end area constrained technology
mapping framework, CONTRA. CONTRA uses Look-Up Table(LUT) based mapping of the
input function on the crossbar array to maximize parallel operations and uses a
novel search technique to move data optimally inside the array. CONTRA supports
benchmarks in a variety of formats, along with crossbar dimensions as input to
generate MAGIC instructions. CONTRA scales for large benchmarks, as
demonstrated by our experiments. CONTRA allows mapping benchmarks to smaller
crossbar dimensions than achieved by any other technique before, while allowing
a wide variety of area-delay trade-offs. CONTRA improves the composite metric
of area-delay product by 2.1x to 13.1x compared to seven existing technology
mapping approaches.
"
1666,Agile SoC Development with Open ESP,"  ESP is an open-source research platform for heterogeneous SoC design. The
platform combines a modular tile-based architecture with a variety of
application-oriented flows for the design and optimization of accelerators. The
ESP architecture is highly scalable and strikes a balance between regularity
and specialization. The companion methodology raises the level of abstraction
to system-level design and enables an automated flow from software and hardware
development to full-system prototyping on FPGA. For application developers, ESP
offers domain-specific automated solutions to synthesize new accelerators for
their software and to map complex workloads onto the SoC architecture. For
hardware engineers, ESP offers automated solutions to integrate their
accelerator designs into the complete SoC. Conceived as a heterogeneous
integration platform and tested through years of teaching at Columbia
University, ESP supports the open-source hardware community by providing a
flexible platform for agile SoC development.
"
1667,"An Ensemble Learning Approach for In-situ Monitoring of FPGA Dynamic
  Power","  As field-programmable gate arrays become prevalent in critical application
domains, their power consumption is of high concern. In this paper, we present
and evaluate a power monitoring scheme capable of accurately estimating the
runtime dynamic power of FPGAs in a fine-grained timescale, in order to support
emerging power management techniques. In particular, we describe a novel and
specialized ensemble model which can be decomposed into multiple customized
decision-tree-based base learners. To aid in model synthesis, a generic
computer-aided design flow is proposed to generate samples, select features,
tune hyperparameters and train the ensemble estimator. Besides this, a hardware
realization of the trained ensemble estimator is presented for on-chip
real-time power estimation. In the experiments, we first show that a single
decision tree model can achieve prediction error within 4.51% of a commercial
gate-level power estimation tool, which is 2.41--6.07x lower than provided by
the commonly used linear model. More importantly, we study the extra gains in
inference accuracy using the proposed ensemble model. Experimental results
reveal that the ensemble monitoring method can further improve the accuracy of
power predictions to within a maximum error of 1.90%. Moreover, the lookup
table (LUT) overhead of the ensemble monitoring hardware employing up to 64
base learners is within 1.22% of the target FPGA, indicating its light-weight
and scalable characteristics.
"
1668,"Decision Tree Based Hardware Power Monitoring for Run Time Dynamic Power
  Management in FPGA","  Fine-grained runtime power management techniques could be promising solutions
for power reduction. Therefore, it is essential to establish accurate power
monitoring schemes to obtain dynamic power variation in a short period (i.e.,
tens or hundreds of clock cycles). In this paper, we leverage a
decision-tree-based power modeling approach to establish fine-grained hardware
power monitoring on FPGA platforms. A generic and complete design flow is
developed to implement the decision tree power model which is capable of
precisely estimating dynamic power in a fine-grained manner. A flexible
architecture of the hardware power monitoring is proposed, which can be
instrumented in any RTL design for runtime power estimation, dispensing with
the need for extra power measurement devices. Experimental results of applying
the proposed model to benchmarks with different resource types reveal an
average error up to 4% for dynamic power estimation. Moreover, the overheads of
area, power and performance incurred by the power monitoring circuitry are
extremely low. Finally, we apply our power monitoring technique to the power
management using phase shedding with an on-chip multi-phase regulator as a
proof of concept and the results demonstrate 14% efficiency enhancement for the
power supply of the FPGA internal logic.
"
1669,"Scalable Light-Weight Integration of FPGA Based Accelerators with Chip
  Multi-Processors","  Modern multicore systems are migrating from homogeneous systems to
heterogeneous systems with accelerator-based computing in order to overcome the
barriers of performance and power walls. In this trend, FPGA-based accelerators
are becoming increasingly attractive, due to their excellent flexibility and
low design cost. In this paper, we propose the architectural support for
efficient interfacing between FPGA-based multi-accelerators and
chip-multiprocessors (CMPs) connected through the network-on-chip (NoC).
Distributed packet receivers and hierarchical packet senders are designed to
maintain scalability and reduce the critical path delay under a heavy task
load. A dedicated accelerator chaining mechanism is also proposed to facilitate
intra-FPGA data reuse among accelerators to circumvent prohibitive
communication overhead between the FPGA and processors. In order to evaluate
the proposed architecture, a complete system emulation with programmability
support is performed using FPGA prototyping. Experimental results demonstrate
that the proposed architecture has high-performance, and is light-weight and
scalable in characteristics.
"
1670,"Layer-specific Optimization for Mixed Data Flow with Mixed Precision in
  FPGA Design for CNN-based Object Detectors","  Convolutional neural networks (CNNs) require both intensive computation and
frequent memory access, which lead to a low processing speed and large power
dissipation. Although the characteristics of the different layers in a CNN are
frequently quite different, previous hardware designs have employed common
optimization schemes for them. This paper proposes a layer-specific design that
employs different organizations that are optimized for the different layers.
The proposed design employs two layer-specific optimizations: layer-specific
mixed data flow and layer-specific mixed precision. The mixed data flow aims to
minimize the off-chip access while demanding a minimal on-chip memory (BRAM)
resource of an FPGA device. The mixed precision quantization is to achieve both
a lossless accuracy and an aggressive model compression, thereby further
reducing the off-chip access. A Bayesian optimization approach is used to
select the best sparsity for each layer, achieving the best trade-off between
the accuracy and compression. This mixing scheme allows the entire network
model to be stored in BRAMs of the FPGA to aggressively reduce the off-chip
access, and thereby achieves a significant performance enhancement. The model
size is reduced by 22.66-28.93 times compared to that in a full-precision
network with a negligible degradation of accuracy on VOC, COCO, and ImageNet
datasets. Furthermore, the combination of mixed dataflow and mixed precision
significantly outperforms the previous works in terms of both throughput,
off-chip access, and on-chip memory requirement.
"
1671,"Virtualized Logical Qubits: A 2.5D Architecture for Error-Corrected
  Quantum Computing","  Current, near-term quantum devices have shown great progress in recent years
culminating with a demonstration of quantum supremacy. In the medium-term,
however, quantum machines will need to transition to greater reliability
through error correction, likely through promising techniques such as surface
codes which are well suited for near-term devices with limited qubit
connectivity. We discover quantum memory, particularly resonant cavities with
transmon qubits arranged in a 2.5D architecture, can efficiently implement
surface codes with substantial hardware savings and performance/fidelity gains.
Specifically, we *virtualize logical qubits* by storing them in layers
distributed across qubit memories connected to each transmon.
  Surprisingly, distributing each logical qubit across many memories has a
minimal impact on fault tolerance and results in substantially more efficient
operations. Our design permits fast transversal CNOT operations between logical
qubits sharing the same physical address which are 6x faster than lattice
surgery CNOTs. We develop a novel embedding which saves ~10x in transmons with
another 2x from an additional optimization for compactness.
  Although Virtualized Logical Qubits (VLQ) pays a 10x penalty in
serialization, advantages in the transversal CNOT and area efficiency result in
performance comparable to 2D transmon-only architectures. Our simulations show
fault tolerance comparable to 2D architectures while saving substantial
hardware. Furthermore, VLQ can produce magic states 1.22x faster for a fixed
number of transmon qubits. This is a critical benchmark for future
fault-tolerant quantum computers. VLQ substantially reduces the hardware
requirements for fault tolerance and puts within reach a proof-of-concept
experimental demonstration of around 10 logical qubits, requiring only 11
transmons and 9 attached cavities in total.
"
1672,"ConfuciuX: Autonomous Hardware Resource Assignment for DNN Accelerators
  using Reinforcement Learning","  DNN accelerators provide efficiency by leveraging reuse of
activations/weights/outputs during the DNN computations to reduce data movement
from DRAM to the chip. The reuse is captured by the accelerator's dataflow.
While there has been significant prior work in exploring and comparing various
dataflows, the strategy for assigning on-chip hardware resources (i.e., compute
and memory) given a dataflow that can optimize for performance/energy while
meeting platform constraints of area/power for DNN(s) of interest is still
relatively unexplored. The design-space of choices for balancing compute and
memory explodes combinatorially, as we show in this work (e.g., as large as
O(10^(72)) choices for running \mobilenet), making it infeasible to do
manual-tuning via exhaustive searches. It is also difficult to come up with a
specific heuristic given that different DNNs and layer types exhibit different
amounts of reuse.
  In this paper, we propose an autonomous strategy called ConfuciuX to find
optimized HW resource assignments for a given model and dataflow style.
ConfuciuX leverages a reinforcement learning method, REINFORCE, to guide the
search process, leveraging a detailed HW performance cost model within the
training loop to estimate rewards. We also augment the RL approach with a
genetic algorithm for further fine-tuning. ConfuciuX demonstrates the highest
sample-efficiency for training compared to other techniques such as Bayesian
optimization, genetic algorithm, simulated annealing, and other RL methods. It
converges to the optimized hardware configuration 4.7 to 24 times faster than
alternate techniques.
"
1673,CLEANN: Accelerated Trojan Shield for Embedded Neural Networks,"  We propose CLEANN, the first end-to-end framework that enables online
mitigation of Trojans for embedded Deep Neural Network (DNN) applications. A
Trojan attack works by injecting a backdoor in the DNN while training; during
inference, the Trojan can be activated by the specific backdoor trigger. What
differentiates CLEANN from the prior work is its lightweight methodology which
recovers the ground-truth class of Trojan samples without the need for labeled
data, model retraining, or prior assumptions on the trigger or the attack. We
leverage dictionary learning and sparse approximation to characterize the
statistical behavior of benign data and identify Trojan triggers. CLEANN is
devised based on algorithm/hardware co-design and is equipped with specialized
hardware to enable efficient real-time execution on resource-constrained
embedded platforms. Proof of concept evaluations on CLEANN for the
state-of-the-art Neural Trojan attacks on visual benchmarks demonstrate its
competitive advantage in terms of attack resiliency and execution overhead.
"
1674,Sparse Systolic Tensor Array for Efficient CNN Hardware Acceleration,"  Convolutional neural network (CNN) inference on mobile devices demands
efficient hardware acceleration of low-precision (INT8) general matrix
multiplication (GEMM). Exploiting data sparsity is a common approach to further
accelerate GEMM for CNN inference, and in particular, structural sparsity has
the advantages of predictable load balancing and very low index overhead. In
this paper, we address a key architectural challenge with structural sparsity:
how to provide support for a range of sparsity levels while maintaining high
utilization of the hardware. We describe a time unrolled formulation of
variable density-bound block (VDBB) sparsity that allows for a configurable
number of non-zero elements per block, at constant utilization. We then
describe a systolic array microarchitecture that implements this scheme, with
two data reuse optimizations. Firstly, we increase reuse in both operands and
partial products by increasing the number of MACs per PE. Secondly, we
introduce a novel approach of moving the IM2COL transform into the hardware,
which allows us to achieve a 3x data bandwidth expansion just before the
operands are consumed by the datapath, reducing the SRAM power consumption. The
optimizations for weight sparsity, activation sparsity and data reuse are all
interrelated and therefore the optimal combination is not obvious. Therefore,
we perform an design space evaluation to find the pareto-optimal design
characteristics. The resulting design achieves 16.8 TOPS/W in 16nm with modest
50% model sparsity and scales with model sparsity up to 55.7TOPS/W at 87.5%. As
well as successfully demonstrating the variable DBB technique, this result
significantly outperforms previously reported sparse CNN accelerators.
"
1675,"2.5D Root of Trust: Secure System-Level Integration of Untrusted
  Chiplets","  Dedicated, after acceptance and publication, in memory of the late Vassos
Soteriou. For the first time, we leverage the 2.5D interposer technology to
establish system-level security in the face of hardware- and software-centric
adversaries. More specifically, we integrate chiplets (i.e., third-party hard
intellectual property of complex functionality, like microprocessors) using a
security-enforcing interposer. Such hardware organization provides a robust
2.5D root of trust for trustworthy, yet powerful and flexible, computation
systems. The security paradigms for our scheme, employed firmly by design and
construction, are: 1) stringent physical separation of trusted from untrusted
components, and 2) runtime monitoring. The system-level activities of all
untrusted commodity chiplets are checked continuously against security policies
via physically separated security features. Aside from the security promises,
the good economics of outsourced supply chains are still maintained; the system
vendor is free to procure chiplets from the open market, while only producing
the interposer and assembling the 2.5D system oneself. We showcase our scheme
using the Cortex-M0 core and the AHB-Lite bus by ARM, building a secure 64-core
system with shared memories. We evaluate our scheme through hardware
simulation, considering different threat scenarios. Finally, we devise a
physical-design flow for 2.5D systems, based on commercial-grade design tools,
to demonstrate and evaluate our 2.5D root of trust.
"
1676,"Hierarchical Roofline Analysis: How to Collect Data using Performance
  Tools on Intel CPUs and NVIDIA GPUs","  This paper surveys a range of methods to collect necessary performance data
on Intel CPUs and NVIDIA GPUs for hierarchical Roofline analysis. As of
mid-2020, two vendor performance tools, Intel Advisor and NVIDIA Nsight
Compute, have integrated Roofline analysis into their supported feature set.
This paper fills the gap for when these tools are not available, or when users
would like a more customized workflow for certain analysis. Specifically, we
will discuss how to use Intel Advisor, RRZE LIKWID, Intel SDE and Intel
Amplifier on Intel architectures, and nvprof, Nsight Compute metrics, and
Nsight Compute section files on NVIDIA architectures. These tools will be used
to collect information for as many memory/cache levels in the memory hierarchy
as possible in order to provide insights into application's data reuse and
cache locality characteristics.
"
1677,"A Class of Optimal Structures for Node Computations in Message Passing
  Algorithms","  Consider the computations at a node in the message passing algorithms. Assume
that the node has incoming and outgoing messages $\mathbf{x} = (x_1, x_2,
\ldots, x_n)$ and $\mathbf{y} = (y_1, y_2, \ldots, y_n)$, respectively. In this
paper, we investigate a class of structures that can be adopted by the node for
computing $\mathbf{y}$ from $\mathbf{x}$, where each $y_j, j = 1, 2, \ldots, n$
is computed via a binary tree with leaves $\mathbf{x}$ excluding $x_j$. We have
three main contributions regarding this class of structures. First, we prove
that the minimum complexity of such a structure is $3n - 6$, and if a structure
has such complexity, its minimum latency is $\delta + \lceil \log(n-2^{\delta})
\rceil$ with $\delta = \lfloor \log(n/2) \rfloor$. Second, we prove that the
minimum latency of such a structure is $\lceil \log(n-1) \rceil$, and if a
structure has such latency, its minimum complexity is $n \log(n-1)$ when $n-1$
is a power of two. Third, given $(n, \tau)$ with $\tau \geq \lceil \log(n-1)
\rceil$, we propose a construction for a structure which likely has the minimum
complexity among structures with latencies at most $\tau$. Our construction
method runs in $O(n^3 \log^2(n))$ time, and the obtained structure has
complexity at most (generally much smaller than) $n \lceil \log(n) \rceil - 2$.
"
1678,"Critical Business Decision Making for Technology Startups -- A PerceptIn
  Case Study","  Most business decisions are made with analysis, but some are judgment calls
not susceptible to analysis due to time or information constraints. In this
article, we present a real-life case study of critical business decision making
of PerceptIn, an autonomous driving technology startup. In early years of
PerceptIn, PerceptIn had to make a decision on the design of computing systems
for its autonomous vehicle products. By providing details on PerceptIn's
decision process and the results of the decision, we hope to provide some
insights that can be beneficial to entrepreneurs and engineering managers in
technology startups.
"
1679,PolyAdd: Polynomial Formal Verification of Adder Circuits,"  Only by formal verification approaches functional correctness can be ensured.
While for many circuits fast verification is possible, in other cases the
approaches fail. In general no efficient algorithms can be given, since the
underlying verification problem is NP-complete.
  In this paper we prove that for different types of adder circuits polynomial
verification can be ensured based on BDDs. While it is known that the output
functions for addition are polynomially bounded, we show in the following that
the entire construction process can be carried out in polynomial time. This is
shown for the simple Carry Ripple Adder, but also for fast adders like the
Conditional Sum Adder and the Carry Look Ahead Adder. Properties about the
adder function are proven and the core principle of polynomial verification is
described that can also be extended to other classes of functions and circuit
realizations.
"
1680,"Quad-Core RSA Processor with Countermeasure Against Power Analysis
  Attacks","  Rivest-Shamir-Adleman (RSA) cryptosystem uses modular multiplication for
encryption and decryption. So, performance of RSA can be drastically improved
by optimizing modular multiplication. This paper proposes a new parallel,
high-radix Montgomery multiplier for 1024 bits multi-core RSA processor. Each
computation step operates in radix 4. The computation speed is increased by
more than 4 times. We also implement a True Random Number Generator based
resilience block to protect the coprocessor against power attacks.
"
1681,On Architecture to Architecture Mapping for Concurrency,"  Mapping programs from one architecture to another plays a key role in
technologies such as binary translation, decompilation, emulation,
virtualization, and application migration. Although multicore architectures are
ubiquitous, the state-of-the-art translation tools do not handle concurrency
primitives correctly. Doing so is rather challenging because of the subtle
differences in the concurrency models between architectures.
  In response, we address various aspects of the challenge. First, we develop
correct and efficient translations between the concurrency models of two
mainstream architecture families: x86 and ARM (versions 7 and 8). We develop
direct mappings between x86 and ARMv8 and ARMv7, and fence elimination
algorithms to eliminate redundant fences after direct mapping. Although our
mapping utilizes ARMv8 as an intermediate model for mapping between x86 and
ARMv7, we argue that it should not be used as an intermediate model in a
decompiler because it disallows common compiler transformations.
  Second, we propose and implement a technique for inserting memory fences for
safely migrating programs between different architectures. Our technique checks
robustness against x86 and ARM, and inserts fences upon robustness violations.
Our experiments demonstrate that in most of the programs both our techniques
introduce significantly fewer fences compared to naive schemes for porting
applications across these architectures.
"
1682,"High-Bandwidth Spatial Equalization for mmWave Massive MU-MIMO with
  Processing-In-Memory","  All-digital basestation (BS) architectures enable superior spectral
efficiency compared to hybrid solutions in massive multi-user MIMO systems.
However, supporting large bandwidths with all-digital architectures at mmWave
frequencies is challenging as traditional baseband processing would result in
excessively high power consumption and large silicon area. The
recently-proposed concept of finite-alphabet equalization is able to address
both of these issues by using equalization matrices that contain low-resolution
entries to lower the power and complexity of high-throughput matrix-vector
products in hardware. In this paper, we explore two different finite-alphabet
equalization hardware implementations that tightly integrate the memory and
processing elements: (i) a parallel array of multiply-accumulate (MAC) units
and (ii) a bit-serial processing-in-memory (PIM) architecture. Our all-digital
VLSI implementation results in 28nm CMOS show that the bit-serial PIM
architecture reduces the area and power consumption up to a factor of 2x and
3x, respectively, when compared to a parallel MAC array that operates at the
same throughput.
"
1683,Asymmetric Aging Effect on Modern Microprocessors,"  Reliability is a crucial requirement in any modern microprocessor to assure
correct execution over its lifetime. As mission critical components are
becoming common in commodity systems; e.g., control of autonomous cars, the
demand for reliable processing has even further heightened. Latest process
technologies even worsened the situation; thus, microprocessors design has
become highly susceptible to reliability concerns. This paper examines
asymmetric aging phenomenon, which is a major reliability concern in advanced
process nodes. In this phenomenon, logical elements and memory cells suffer
from unequal timing degradation over time and consequently introduce
reliability concerns. So far, most studies approached asymmetric aging from
circuit or physical design viewpoint, but these solutions were quite limited
and suboptimal. In this paper we introduce an asymmetric aging aware
micro-architecture that aims at reducing its impact. The study is mainly
focused on the following subsystems: execution units, register files and the
memory hierarchy. Our experiments indicate that the proposed solutions incur
minimal overhead while significantly mitigating the asymmetric aging stress.
"
1684,"Going Deep: Using deep learning techniques with simplified mathematical
  models against XOR BR and TBR PUFs (Attacks and Countermeasures)","  This paper contributes to the study of PUFs vulnerability against modeling
attacks by evaluating the security of XOR BR PUFs, XOR TBR PUFs, and obfuscated
architectures of XOR BR PUF using a simplified mathematical model and deep
learning (DL) techniques. Obtained results show that DL modeling attacks could
easily break the security of 4-input XOR BR PUFs and 4-input XOR TBR PUFs with
modeling accuracy $\sim$ 99%. Similar attacks were executed using single-layer
neural networks (NN) and support vector machines (SVM) with polynomial kernel
and the obtained results showed that single NNs failed to break the PUF
security. Furthermore, SVM results confirmed the same modeling accuracy
reported in previous research ($\sim$ 50%). For the first time, this research
empirically shows that DL networks can be used as powerful modeling techniques
against these complex PUF architectures for which previous conventional machine
learning techniques had failed. Furthermore, a detailed scalability analysis is
conducted on the DL networks with respect to PUFs' stage size and complexity.
The analysis shows that the number of layers and hidden neurons inside every
layer has a linear relationship with PUFs' stage size, which agrees with the
theoretical findings in deep learning. Consequently, A new obfuscated
architecture is introduced as a first step to counter DL modeling attacks and
it showed significant resistance against such attacks (16% - 40% less
accuracy). This research provides an important step towards prioritizing the
efforts to introduce new PUF architectures that are more secure and
invulnerable to modeling attacks. Moreover, it triggers future discussions on
the removal of influential bits and the level of obfuscation needed to confirm
that a specific PUF architecture is resistant against powerful DL modeling
attacks.
"
1685,Time-Based Roofline for Deep Learning Performance Analysis,"  Deep learning applications are usually very compute-intensive and require a
long run time for training and inference. This has been tackled by researchers
from both hardware and software sides, and in this paper, we propose a
Roofline-based approach to performance analysis to facilitate the optimization
of these applications. This approach is an extension of the Roofline model
widely used in traditional high-performance computing applications, and it
incorporates both compute/bandwidth complexity and run time in its formulae to
provide insights into deep learning-specific characteristics. We take two sets
of representative kernels, 2D convolution and long short-term memory, to
validate and demonstrate the use of this new approach, and investigate how
arithmetic intensity, cache locality, auto-tuning, kernel launch overhead, and
Tensor Core usage can affect performance. Compared to the common ad-hoc
approach, this study helps form a more systematic way to analyze code
performance and identify optimization opportunities for deep learning
applications.
"
1686,"Development of a Predictive Process Design kit for15-nm FinFETs:
  FreePDK15","  FinFETs are predicted to advance semiconductorscaling for sub-20nm devices.
In order to support their intro-duction into research and universities it is
crucial to develop anopen source predictive process design kit. This paper
discussesin detail the design process for such a kit for 15nm FinFETdevices,
called the FreePDK15. The kit consists of a layerstack with thirteen-metal
layers based on hierarchical-scalingused in ASIC architecture, Middle-of-Line
local interconnectlayers and a set of Front-End-of-Line layers. The physical
andgeometrical properties of these layers are defined and theseproperties
determine the density and parasitics of the design. Thedesign rules are laid
down considering additional guidelines forprocess variability, challenges
involved in FinFET fabrication anda unique set of design rules are developed
for critical dimensions.Layout extraction including modified rules for
determining thegeometrical characteristics of FinFET layouts are implementedand
discussed to obtain successful Layout Versus Schematicchecks for a set of
layouts. Moreover, additional parasiticcomponents of a standard FinFET device
are analyzed andthe parasitic extraction of sample layouts is performed.
Theseextraction results are then compared and assessed against thevalidation
models.
"
1687,"MicroGrad: A Centralized Framework for Workload Cloning and Stress
  Testing","  We present MicroGrad, a centralized automated framework that is able to
efficiently analyze the capabilities, limits and sensitivities of complex
modern processors in the face of constantly evolving application domains.
MicroGrad uses Microprobe, a flexible code generation framework as its back-end
and a Gradient Descent based tuning mechanism to efficiently enable the
evolution of the test cases to suit tasks such as Workload Cloning and Stress
Testing. MicroGrad can interface with a variety of execution infrastructure
such as performance and power simulators as well as native hardware. Further,
the modular 'abstract workload model' approach to building MicroGrad allows it
to be easily extended for further use.
  In this paper, we evaluate MicroGrad over different use cases and
architectures and showcase that MicroGrad can achieve greater than 99\%
accuracy across different tasks within few tuning epochs and low resource
requirements. We also observe that MicroGrad's accuracy is 25 to 30\% higher
than competing techniques. At the same time, it is 1.5x to 2.5x faster or would
consume 35 to 60\% less compute resources (depending on implementation) over
alternate mechanisms. Overall, MicroGrad's fast, resource efficient and
accurate test case generation capability allow it to perform rapid evaluation
of complex processors.
"
1688,"Accelerating Recommender Systems via Hardware ""scale-in""","  In today's era of ""scale-out"", this paper makes the case that a specialized
hardware architecture based on ""scale-in""--placing as many specialized
processors as possible along with their memory systems and interconnect links
within one or two boards in a rack--would offer the potential to boost large
recommender system throughput by 12-62x for inference and 12-45x for training
compared to the DGX-2 state-of-the-art AI platform, while minimizing the
performance impact of distributing large models across multiple processors. By
analyzing Facebook's representative model--Deep Learning Recommendation Model
(DLRM)--from a hardware architecture perspective, we quantify the impact on
throughput of hardware parameters such as memory system design, collective
communications latency and bandwidth, and interconnect topology. By focusing on
conditions that stress hardware, our analysis reveals limitations of existing
AI accelerators and hardware platforms.
"
1689,DMR-based Technique for Fault Tolerant AES S-box Architecture,"  This paper presents a high-throughput fault-resilient hardware implementation
of AES S-box, called HFS-box. If a transient natural or even malicious fault in
each pipeline stage is detected, the corresponding error signal becomes high
and as a result, the control unit holds the output of our proposed DMR voter
till the fault effect disappears. The proposed low-cost HFS-box provides a high
capability of fault-tolerant against transient faults with any duration by
putting low area overhead, i.e. 137%, and low throughput degradation, i.e.
11.3%, on the original implementation.
"
1690,"An Open-Source Platform for High-Performance Non-Coherent On-Chip
  Communication","  On-chip communication infrastructure is a central component of modern
systems-on-chip (SoCs), and it continues to gain importance as the number of
cores, the heterogeneity of components, and the on-chip and off-chip bandwidth
continue to grow. Decades of research on on-chip networks enabled
cache-coherent shared-memory multiprocessors. However, communication fabrics
that meet the needs of heterogeneous many-cores and accelerator-rich SoCs,
which are not, or only partially, coherent, are a much less mature research
area.
  In this work, we present a modular, topology-agnostic, high-performance
on-chip communication platform. The platform includes components to build and
link subnetworks with customizable bandwidth and concurrency properties and
adheres to a state-of-the-art, industry-standard protocol. We discuss
microarchitectural trade-offs and timing/area characteristics of our modules
and show that they can be composed to build high-bandwidth (e.g., 2.5 GHz and
1024 bit data width) end-to-end on-chip communication fabrics (not only network
switches but also DMA engines and memory controllers) with high degrees of
concurrency. We design and implement a state-of-the-art ML training
accelerator, where our communication fabric scales to 1024 cores on a die,
providing 32 TB/s cross-sectional bandwidth at only 24 ns round-trip latency
between any two cores.
"
1691,A Survey of FPGA-Based Robotic Computing,"  Recent researches on robotics have shown significant improvement, spanning
from algorithms, mechanics to hardware architectures. Robotics, including
manipulators, legged robots, drones, and autonomous vehicles, are now widely
applied in diverse scenarios. However, the high computation and data complexity
of robotic algorithms pose great challenges to its applications. On the one
hand, CPU platform is flexible to handle multiple robotic tasks. GPU platform
has higher computational capacities and easy-touse development frameworks, so
they have been widely adopted in several applications. On the other hand,
FPGA-based robotic accelerators are becoming increasingly competitive
alternatives, especially in latency-critical and power-limited scenarios. With
specialized designed hardware logic and algorithm kernels, FPGA-based
accelerators can surpass CPU and GPU in performance and energy efficiency. In
this paper, we give an overview of previous work on FPGA-based robotic
accelerators covering different stages of the robotic system pipeline. An
analysis of software and hardware optimization techniques and main technical
issues is presented, along with some commercial and space applications, to
serve as a guide for future work.
"
1692,AutoML for Multilayer Perceptron and FPGA Co-design,"  State-of-the-art Neural Network Architectures (NNAs) are challenging to
design and implement efficiently in hardware. In the past couple of years, this
has led to an explosion in research and development of automatic Neural
Architecture Search (NAS) tools. AutomML tools are now used to achieve state of
the art NNA designs and attempt to optimize for hardware usage and design. Much
of the recent research in the auto-design of NNAs has focused on convolution
networks and image recognition, ignoring the fact that a significant part of
the workload in data centers is general-purpose deep neural networks. In this
work, we develop and test a general multilayer perceptron (MLP) flow that can
take arbitrary datasets as input and automatically produce optimized NNAs and
hardware designs. We test the flow on six benchmarks. Our results show we
exceed the performance of currently published MLP accuracy results and are
competitive with non-MLP based results. We compare general and common GPU
architectures with our scalable FPGA design and show we can achieve higher
efficiency and higher throughput (outputs per second) for the majority of
datasets. Further insights into the design space for both accurate networks and
high performing hardware shows the power of co-design by correlating accuracy
versus throughput, network size versus accuracy, and scaling to
high-performance devices.
"
1693,DANCE: Differentiable Accelerator/Network Co-Exploration,"  To cope with the ever-increasing computational demand of the DNN execution,
recent neural architecture search (NAS) algorithms consider hardware cost
metrics into account, such as GPU latency. To further pursue a fast, efficient
execution, DNN-specialized hardware accelerators are being designed for
multiple purposes, which far-exceeds the efficiency of the GPUs. However, those
hardware-related metrics have been proven to exhibit non-linear relationships
with the network architectures. Therefore it became a chicken-and-egg problem
to optimize the network against the accelerator, or to optimize the accelerator
against the network. In such circumstances, this work presents DANCE, a
differentiable approach towards the co-exploration of the hardware accelerator
and network architecture design. At the heart of DANCE is a differentiable
evaluator network. By modeling the hardware evaluation software with a neural
network, the relation between the accelerator architecture and the hardware
metrics becomes differentiable, allowing the search to be performed with
backpropagation. Compared to the naive existing approaches, our method performs
co-exploration in a significantly shorter time, while achieving superior
accuracy and hardware cost metrics.
"
1694,The Hardware Lottery,"  Hardware, systems and algorithms research communities have historically had
different incentive structures and fluctuating motivation to engage with each
other explicitly. This historical treatment is odd given that hardware and
software have frequently determined which research ideas succeed (and fail).
This essay introduces the term hardware lottery to describe when a research
idea wins because it is suited to the available software and hardware and not
because the idea is superior to alternative research directions. Examples from
early computer science history illustrate how hardware lotteries can delay
research progress by casting successful ideas as failures. These lessons are
particularly salient given the advent of domain specialized hardware which make
it increasingly costly to stray off of the beaten path of research ideas. This
essay posits that the gains from progress in computing are likely to become
even more uneven, with certain research directions moving into the fast-lane
while progress on others is further obstructed.
"
1695,The Cost of Software-Based Memory Management Without Virtual Memory,"  Virtual memory has been a standard hardware feature for more than three
decades. At the price of increased hardware complexity, it has simplified
software and promised strong isolation among colocated processes. In modern
computing systems, however, the costs of virtual memory have increased
significantly. With large memory workloads, virtualized environments, data
center computing, and chips with multiple DMA devices, virtual memory can
degrade performance and increase power usage. We therefore explore the
implications of building applications and operating systems without relying on
hardware support for address translation. Primarily, we investigate the
implications of removing the abstraction of large contiguous memory segments.
Our experiments show that the overhead to remove this reliance is surprisingly
small for real programs. We expect this small overhead to be worth the benefit
of reducing the complexity and energy usage of address translation. In fact, in
some cases, performance can even improve when address translation is avoided.
"
1696,"Secure Internal Communication of a Trustzone-Enabled Heterogeneous Soc
  Lightweight Encryption","  Security in TrustZone-enabled heterogeneous system-on-chip (SoC) is gaining
increasing attention for several years. Mainly because this type of SoC can be
found in more and more applications in servers or in the cloud. The inside-SoC
communication layer is one of the main element of heterogeneous SoC; indeed all
the data goes through it. Monitoring and controlling inside-SoC communications
enables to fend off attacks before system corruption. In this article, we study
the feasibility of encrypted data exchange between the secure software executed
in a trusted execution environment (TEE) and the secure logic part of an
heterogeneous SoC. Experiment are done with a Xilinx Zynq-7010 SoC and two
lightweight stream ciphers. We show that using lightweight stream ciphers is an
efficient solution without excessive overheads.
"
1697,"A Systematic Study of Lattice-based NIST PQC Algorithms: from Reference
  Implementations to Hardware Accelerators","  Security of currently deployed public key cryptography algorithms is foreseen
to be vulnerable against quantum computer attacks. Hence, a community effort
exists to develop post-quantum cryptography (PQC) algorithms, i.e., algorithms
that are resistant to quantum attacks. In this work, we have investigated how
lattice-based candidate algorithms from the NIST PQC standardization
competition fare when conceived as hardware accelerators. To achieve this, we
have assessed the reference implementations of selected algorithms with the
goal of identifying what are their basic building blocks. We assume the
hardware accelerators will be implemented in application specific integrated
circuit (ASIC) and the targeted technology in our experiments is a commercial
65nm node. In order to estimate the characteristics of each algorithm, we have
assessed their memory requirements, use of multipliers, and how each algorithm
employs hashing functions. Furthermore, for these building blocks, we have
collected area and power figures for 12 candidate algorithms. For memories, we
make use of a commercial memory compiler. For logic, we make use of a standard
cell library. In order to compare the candidate algorithms fairly, we select a
reference frequency of operation of 500MHz. Our results reveal that our area
and power numbers are comparable to the state of the art, despite targeting a
higher frequency of operation and a higher security level in our experiments.
The comprehensive investigation of lattice-based NIST PQC algorithms performed
in this paper can be used for guiding ASIC designers when selecting an
appropriate algorithm while respecting requirements and design constraints.
"
1698,"Analog vs. Digital Spatial Transforms: A Throughput, Power, and Area
  Comparison","  Spatial linear transforms that process multiple parallel analog signals to
simplify downstream signal processing find widespread use in multi-antenna
communication systems, machine learning inference, data compression, audio and
ultrasound applications, among many others. In the past, a wide range of
mixed-signal as well as digital spatial transform circuits have been
proposed---it is, however, a longstanding question whether analog or digital
transforms are superior in terms of throughput, power, and area. In this paper,
we focus on Hadamard transforms and perform a systematic comparison of
state-of-the-art analog and digital circuits implementing spatial transforms in
the same 65\,nm CMOS technology. We analyze the trade-offs between throughput,
power, and area, and we identify regimes in which mixed-signal or digital
Hadamard transforms are preferable. Our comparison reveals that (i) there is no
clear winner and (ii) analog-to-digital conversion is often dominating area and
energy efficiency---and not the spatial transform.
"
1699,"GenASM: A High-Performance, Low-Power Approximate String Matching
  Acceleration Framework for Genome Sequence Analysis","  Genome sequence analysis has enabled significant advancements in medical and
scientific areas such as personalized medicine, outbreak tracing, and the
understanding of evolution. Unfortunately, it is currently bottlenecked by the
computational power and memory bandwidth limitations of existing systems, as
many of the steps in genome sequence analysis must process a large amount of
data. A major contributor to this bottleneck is approximate string matching
(ASM).
  We propose GenASM, the first ASM acceleration framework for genome sequence
analysis. We modify the underlying ASM algorithm (Bitap) to significantly
increase its parallelism and reduce its memory footprint, and we design the
first hardware accelerator for Bitap. Our hardware accelerator consists of
specialized compute units and on-chip SRAMs that are designed to match the rate
of computation with memory capacity and bandwidth.
  We demonstrate that GenASM is a flexible, high-performance, and low-power
framework, which provides significant performance and power benefits for three
different use cases in genome sequence analysis: 1) GenASM accelerates read
alignment for both long reads and short reads. For long reads, GenASM
outperforms state-of-the-art software and hardware accelerators by 116x and
3.9x, respectively, while consuming 37x and 2.7x less power. For short reads,
GenASM outperforms state-of-the-art software and hardware accelerators by 111x
and 1.9x. 2) GenASM accelerates pre-alignment filtering for short reads, with
3.7x the performance of a state-of-the-art pre-alignment filter, while
consuming 1.7x less power and significantly improving the filtering accuracy.
3) GenASM accelerates edit distance calculation, with 22-12501x and 9.3-400x
speedups over the state-of-the-art software library and FPGA-based accelerator,
respectively, while consuming 548-582x and 67x less power.
"
1700,"Enabling Virtual Memory Research on RISC-V with a Configurable TLB
  Hierarchy for the Rocket Chip Generator","  The Rocket Chip Generator uses a collection of parameterized processor
components to produce RISC-V-based SoCs. It is a powerful tool that can produce
a wide variety of processor designs ranging from tiny embedded processors to
complex multi-core systems. In this paper we extend the features of the Memory
Management Unit of the Rocket Chip Generator and specifically the TLB
hierarchy. TLBs are essential in terms of performance because they mitigate the
overhead of frequent Page Table Walks, but may harm the critical path of the
processor due to their size and/or associativity. In the original Rocket Chip
implementation the L1 Instruction/Data TLB is fully-associative and the shared
L2 TLB is direct-mapped. We lift these restrictions and design and implement
configurable, set-associative L1 and L2 TLB templates that can create any
organization from direct-mapped to fully-associative to achieve the desired
ratio of performance and resource utilization, especially for larger TLBs. We
evaluate different TLB configurations and present performance, area, and
frequency results of our design using benchmarks from the SPEC2006 suite on the
Xilinx ZCU102 FPGA.
"
1701,SideLine: How Delay-Lines (May) Leak Secrets from your SoC,"  To meet the ever-growing need for performance in silicon devices, SoC
providers have been increasingly relying on software-hardware cooperation. By
controlling hardware resources such as power or clock management from the
software, developers earn the possibility to build more flexible and power
efficient applications. Despite the benefits, these hardware components are now
exposed to software code and can potentially be misused as open-doors to
jeopardize trusted environments, perform privilege escalation or steal
cryptographic secrets. In this work, we introduce SideLine, a novel
side-channel vector based on delay-line components widely implemented in
high-end SoCs. After providing a detailed method on how to access and convert
delay-line data into power consumption information, we demonstrate that these
entities can be used to perform remote power side-channel attacks. We report
experiments carried out on two SoCs from distinct vendors and we recount
several core-vs-core attack scenarios in which an adversary process located in
one processor core aims at eavesdropping the activity of a victim process
located in another core. For each scenario, we demonstrate the adversary
ability to fully recover the secret key of an OpenSSL AES running in the victim
core. Even more detrimental, we show that these attacks are still practicable
if the victim or the attacker program runs over an operating system.
"
1702,"Probabilistic Value-Deviation-Bounded Source-Dependent Bit-Level Channel
  Adaptation for Approximate Communication","  Computing systems that can tolerate effects of errors in their communicated
data values can trade this tolerance for improved resource efficiency. Many
important applications of computing, such as embedded sensor systems, can
tolerate errors that are bounded in their distribution of deviation from
correctness (distortion). We present a channel adaptation technique which
modulates properties of I/O channels typical in embedded sensor systems, to
provide a tradeoff between I/O power dissipation and distortion of communicated
data. We provide an efficient-to-compute formulation for the distribution of
integer distortion accounting for the distribution of transmitted values. Using
this formulation we implement our value-deviation-bounded (VDB) channel
adaptation. We experimentally quantify the achieved reduction in power
dissipation on a hardware prototype integrated with the required programmable
channel modulation circuitry. We augment these experimental measurements with
an analysis of the distributions of distortions. We show that our probabilistic
VDB channel adaptation can provide up to a 2$\times$ reduction in I/O power
dissipation. When synthesized for a miniature low-power FPGA intended for use
in sensor interfaces, a register transfer level implementation of the channel
adaptation control logic requires only 106 flip-flops and 224 4-input LUTs for
implementing per-bit channel adaptation on serialized streams of 8-bit sensor
data.
"
1703,"Bit-Exact ECC Recovery (BEER): Determining DRAM On-Die ECC Functions by
  Exploiting DRAM Data Retention Characteristics","  Increasing single-cell DRAM error rates have pushed DRAM manufacturers to
adopt on-die error-correction coding (ECC), which operates entirely within a
DRAM chip to improve factory yield. The on-die ECC function and its effects on
DRAM reliability are considered trade secrets, so only the manufacturer knows
precisely how on-die ECC alters the externally-visible reliability
characteristics. Consequently, on-die ECC obstructs third-party DRAM customers
(e.g., test engineers, experimental researchers), who typically design, test,
and validate systems based on these characteristics.
  To give third parties insight into precisely how on-die ECC transforms DRAM
error patterns during error correction, we introduce Bit-Exact ECC Recovery
(BEER), a new methodology for determining the full DRAM on-die ECC function
(i.e., its parity-check matrix) without hardware tools, prerequisite knowledge
about the DRAM chip or on-die ECC mechanism, or access to ECC metadata (e.g.,
error syndromes, parity information). BEER exploits the key insight that
non-intrusively inducing data-retention errors with carefully-crafted test
patterns reveals behavior that is unique to a specific ECC function.
  We use BEER to identify the ECC functions of 80 real LPDDR4 DRAM chips with
on-die ECC from three major DRAM manufacturers. We evaluate BEER's correctness
in simulation and performance on a real system to show that BEER is effective
and practical across a wide range of on-die ECC functions. To demonstrate
BEER's value, we propose and discuss several ways that third parties can use
BEER to improve their design and testing practices. As a concrete example, we
introduce and evaluate BEEP, the first error profiling methodology that uses
the known on-die ECC function to recover the number and bit-exact locations of
unobservable raw bit errors responsible for observable post-correction errors.
"
1704,"New Models for Understanding and Reasoning about Speculative Execution
  Attacks","  Spectre and Meltdown attacks and their variants exploit performance
optimization features to cause security breaches. Secret information is
accessed and leaked through micro-architectural covert channels. New attack
variants keep appearing and we do not have a systematic way to capture the
critical characteristics of these attacks and evaluate why they succeed.
  In this paper, we provide a new attack-graph model for reasoning about
speculative micro-architectural attacks. We model attacks as ordered dependency
graphs, and define a new concept, i.e. security dependency, between a resource
access and its prior authorization operation. We prove that a missing security
dependency is equivalent to a race condition between authorization and access,
which is a root cause of speculative execution attacks. We show detailed
examples of how our attack graph models the Spectre and Meltdown attacks, and
is generalizable to all the attack variants published so far. We also show that
this attack model is very useful for identifying new attacks and for
generalizing defense strategies. We show that the defenses proposed so far all
fit under one of our defense strategies. We also explain how attack graphs can
be constructed and point to this as very promising future work for tool
designers.
"
1705,"NERO: A Near High-Bandwidth Memory Stencil Accelerator for Weather
  Prediction Modeling","  Ongoing climate change calls for fast and accurate weather and climate
modeling. However, when solving large-scale weather prediction simulations,
state-of-the-art CPU and GPU implementations suffer from limited performance
and high energy consumption. These implementations are dominated by complex
irregular memory access patterns and low arithmetic intensity that pose
fundamental challenges to acceleration. To overcome these challenges, we
propose and evaluate the use of near-memory acceleration using a reconfigurable
fabric with high-bandwidth memory (HBM). We focus on compound stencils that are
fundamental kernels in weather prediction models. By using high-level synthesis
techniques, we develop NERO, an FPGA+HBM-based accelerator connected through
IBM CAPI2 (Coherent Accelerator Processor Interface) to an IBM POWER9 host
system. Our experimental results show that NERO outperforms a 16-core POWER9
system by 4.2x and 8.3x when running two different compound stencil kernels.
NERO reduces the energy consumption by 22x and 29x for the same two kernels
over the POWER9 system with an energy efficiency of 1.5 GFLOPS/Watt and 17.3
GFLOPS/Watt. We conclude that employing near-memory acceleration solutions for
weather prediction modeling is promising as a means to achieve both high
performance and high energy efficiency.
"
1706,"FIGARO: Improving System Performance via Fine-Grained In-DRAM Data
  Relocation and Caching","  DRAM Main memory is a performance bottleneck for many applications due to the
high access latency. In-DRAM caches work to mitigate this latency by augmenting
regular-latency DRAM with small-but-fast regions of DRAM that serve as a cache
for the data held in the regular-latency region of DRAM. While an effective
in-DRAM cache can allow a large fraction of memory requests to be served from a
fast DRAM region, the latency savings are often hindered by inefficient
mechanisms for relocating copies of data into and out of the fast regions.
Existing in-DRAM caches have two sources of inefficiency: (1) the data
relocation granularity is an entire multi-kilobyte row of DRAM; and (2) because
the relocation latency increases with the physical distance between the slow
and fast regions, multiple fast regions are physically interleaved among slow
regions to reduce the relocation latency, resulting in increased hardware area
and manufacturing complexity. We propose a new substrate, FIGARO, that uses
existing shared global buffers among subarrays within a DRAM bank to provide
support for in-DRAM data relocation across subarrays at the granularity of a
single cache block. FIGARO has a distance-independent latency within a DRAM
bank, and avoids complex modifications to DRAM. Using FIGARO, we design a
fine-grained in-DRAM cache called FIGCache. The key idea of FIGCache is to
cache only small, frequently-accessed portions of different DRAM rows in a
designated region of DRAM. By caching only the parts of each row that are
expected to be accessed in the near future, we can pack more of the
frequently-accessed data into FIGCache, and can benefit from additional row
hits in DRAM. Our evaluations show that FIGCache improves the average
performance of a system using DDR4 DRAM by 16.3% and reduces average DRAM
energy consumption by 7.8% for 8-core workloads, over a conventional system
without in-DRAM caching.
"
1707,"Hardware Accelerator for Multi-Head Attention and Position-Wise
  Feed-Forward in the Transformer","  Designing hardware accelerators for deep neural networks (DNNs) has been much
desired. Nonetheless, most of these existing accelerators are built for either
convolutional neural networks (CNNs) or recurrent neural networks (RNNs).
Recently, the Transformer model is replacing the RNN in the natural language
processing (NLP) area. However, because of intensive matrix computations and
complicated data flow being involved, the hardware design for the Transformer
model has never been reported. In this paper, we propose the first hardware
accelerator for two key components, i.e., the multi-head attention (MHA)
ResBlock and the position-wise feed-forward network (FFN) ResBlock, which are
the two most complex layers in the Transformer. Firstly, an efficient method is
introduced to partition the huge matrices in the Transformer, allowing the two
ResBlocks to share most of the hardware resources. Secondly, the computation
flow is well designed to ensure the high hardware utilization of the systolic
array, which is the biggest module in our design. Thirdly, complicated
nonlinear functions are highly optimized to further reduce the hardware
complexity and also the latency of the entire system. Our design is coded using
hardware description language (HDL) and evaluated on a Xilinx FPGA. Compared
with the implementation on GPU with the same setting, the proposed design
demonstrates a speed-up of 14.6x in the MHA ResBlock, and 3.4x in the FFN
ResBlock, respectively. Therefore, this work lays a good foundation for
building efficient hardware accelerators for multiple Transformer networks.
"
1708,GrateTile: Efficient Sparse Tensor Tiling for CNN Processing,"  We propose GrateTile, an efficient, hardwarefriendly data storage scheme for
sparse CNN feature maps (activations). It divides data into uneven-sized
subtensors and, with small indexing overhead, stores them in a compressed yet
randomly accessible format. This design enables modern CNN accelerators to
fetch and decompressed sub-tensors on-the-fly in a tiled processing manner.
GrateTile is suitable for architectures that favor aligned, coalesced data
access, and only requires minimal changes to the overall architectural design.
We simulate GrateTile with state-of-the-art CNNs and show an average of 55%
DRAM bandwidth reduction while using only 0.6% of feature map size for indexing
storage.
"
1709,"Thermal and IR Drop Analysis Using Convolutional Encoder-Decoder
  Networks","  Computationally expensive temperature and power grid analyses are required
during the design cycle to guide IC design. This paper employs encoder-decoder
based generative (EDGe) networks to map these analyses to fast and accurate
image-to-image and sequence-to-sequence translation tasks. The network takes a
power map as input and outputs the corresponding temperature or IR drop map. We
propose two networks: (i) ThermEDGe: a static and dynamic full-chip temperature
estimator and (ii) IREDGe: a full-chip static IR drop predictor based on input
power, power grid distribution, and power pad distribution patterns. The models
are design-independent and must be trained just once for a particular
technology and packaging solution. ThermEDGe and IREDGe are demonstrated to
rapidly predict the on-chip temperature and IR drop contours in milliseconds
(in contrast with commercial tools that require several hours or more) and
provide an average error of 0.6% and 0.008% respectively.
"
1710,Load Driven Branch Predictor (LDBP),"  Branch instructions dependent on hard-to-predict load data are the leading
branch misprediction contributors. Current state-of-the-art history-based
branch predictors have poor prediction accuracy for these branches. Prior
research backs this observation by showing that increasing the size of a
256-KBit history-based branch predictor to its 1-MBit variant has just a 10%
reduction in branch mispredictions.
  We present the novel Load Driven Branch Predictor(LDBP) specifically
targeting hard-to-predict branches dependent on a load instruction. Though
random load data determines the outcome for these branches, the load address
for most of these data has a predictable pattern. This is an observable
template in data structures like arrays and maps. Our predictor model exploits
this behavior to trigger future loads associated with branches ahead of time
and use its data to predict the branch's outcome. The predictable loads are
tracked, and the precomputed outcomes of the branch instruction are buffered
for making predictions. Our experimental results show that compared to a
standalone 256-Kbit IMLI predictor, when LDBP is augmented with a 150-Kbit
IMLI, it reduces the average branch mispredictions by 20% and improves average
IPC by 13.1% for benchmarks from SPEC CINT2006 and GAP benchmark suite.
"
1711,"Open-Source Synthesizable Analog Blocks for High-Speed Link Designs:
  20-GS/s 5b ENOB Analog-to-Digital Converter and 5-GHz Phase Interpolator","  Using digital standard cells and digital place-and-route (PnR) tools, we
created a 20 GS/s, 8-bit analog-to-digital converter (ADC) for use in
high-speed serial link applications with an ENOB of 5.6, a DNL of 0.96 LSB, and
an INL of 2.39 LSB, which dissipated 175 mW in 0.102 mm2 in a 16nm technology.
The design is entirely described by HDL so that it can be ported to other
processes with minimal effort and shared as open source.
"
1712,"MIRAGE: Mitigating Conflict-Based Cache Attacks with a Practical
  Fully-Associative Design","  Shared caches in modern processors are vulnerable to conflict-based attacks,
whereby an attacker monitors the access pattern of a victim by engineering
cache-set conflicts. Recent mitigations propose a randomized mapping of
addresses to cache locations to obfuscate addresses that can conflict with a
target address. Unfortunately, such designs continue to select eviction
candidates from a small subset of the resident cache lines, which makes such
designs vulnerable to algorithms that can quickly identify the conflicting
addresses.
  This paper presents Mirage, a practical design for a fully associative cache,
wherein eviction candidates are selected randomly from among all the lines
resident in the cache, to be immune to set-conflicts. A key challenge in
naively adopting such designs for large shared caches (containing tens of
thousands of lines) is the complexity of cache-lookup, as that can require
searching through all the lines resident in the cache in such designs. Mirage
practically enables a fully-associative design, while maintaining the access
latency similar to a traditional set-associative cache using: (1) Pointer-based
indirection from the tag-store to the data-store, which allows a newly
installed address to evict data of any resident line, (2) Skewed-associative
tag-store with extra invalid tags, wherein incoming addresses can be installed
without set-conflicts, and (3) Load-aware placement that maximizes the
availability of sets with invalid tags, to eliminate set-conflicts. Our
analysis shows Mirage provides the global-eviction property of a
fully-associative cache throughout the system lifetime (violations of
full-associativity, i.e set-conflicts, occur less than once in 10^4 to 10^17
years), offering a principled defense against set-conflict based attacks.
Mirage incurs negligible slowdown (0.3%) and 12-15% extra storage compared to
the recently proposed Scatter-Cache.
"
1713,"FlexWatts: A Power- and Workload-Aware Hybrid Power Delivery Network for
  Energy-Efficient Microprocessors","  Modern client processors typically use one of three commonly-used power
delivery network (PDN): 1) motherboard voltage regulators (MBVR), 2) integrated
voltage regulators (IVR), and 3) low dropout voltage regulators (LDO). We
observe that the energy-efficiency of each of these PDNs varies with the
processor power (e.g., thermal design power (TDP) and dynamic power-state) and
workload characteristics. This leads to energy inefficiency and performance
loss, as modern client processors operate across a wide spectrum of power
consumption and execute a wide variety of workloads. We propose FlexWatts, a
hybrid adaptive PDN for modern client processors whose goal is to provide high
energy-efficiency across the processor's wide range of power consumption and
workloads by dynamically allocating PDNs to processor domains. FlexWatts is
based on three key ideas. First, it combines IVRs and LDOs in a novel way to
share multiple on-chip and off-chip resources. This hybrid PDN is allocated for
processor domains with a wide power consumption range and it dynamically
switches between two modes: IVR-Mode and LDO-Mode, depending on the power
consumption. Second, for all other processor domains, FlexWatts statically
allocates off-chip VRs. Third, FlexWatts introduces a prediction algorithm that
switches the hybrid PDN to the mode that is the most beneficial. To evaluate
the tradeoffs of PDNs, we develop and open-source PDNspot, the first validated
architectural PDN model that enables quantitative analysis of PDN metrics.
Using PDNspot, we evaluate FlexWatts on a wide variety of SPEC CPU2006,
3DMark06, and battery life workloads against IVR, the state-of-the-art PDN in
modern client processors. For a 4W TDP processor, FlexWatts improves the
average performance of the SPEC CPU2006 and 3DMark06 workloads by 22% and 25%,
respectively. FlexWatts has comparable cost and area overhead to IVR.
"
1714,"Enabling Resource-Aware Mapping of Spiking Neural Networks via Spatial
  Decomposition","  With growing model complexity, mapping Spiking Neural Network (SNN)-based
applications to tile-based neuromorphic hardware is becoming increasingly
challenging. This is because the synaptic storage resources on a tile, viz. a
crossbar, can accommodate only a fixed number of pre-synaptic connections per
post-synaptic neuron. For complex SNN models that have many pre-synaptic
connections per neuron, some connections may need to be pruned after training
to fit onto the tile resources, leading to a loss in model quality, e.g.,
accuracy. In this work, we propose a novel unrolling technique that decomposes
a neuron function with many pre-synaptic connections into a sequence of
homogeneous neural units, where each neural unit is a function computation
node, with two pre-synaptic connections. This spatial decomposition technique
significantly improves crossbar utilization and retains all pre-synaptic
connections, resulting in no loss of the model quality derived from connection
pruning. We integrate the proposed technique within an existing SNN mapping
framework and evaluate it using machine learning applications on the DYNAP-SE
state-of-the-art neuromorphic hardware. Our results demonstrate an average 60%
lower crossbar requirement, 9x higher synapse utilization, 62% lower wasted
energy on the hardware, and between 0.8% and 4.6% increase in model quality.
"
1715,Tb/s Polar Successive Cancellation Decoder 16nm ASIC Implementation,"  This work presents an efficient ASIC implementation of successive
cancellation (SC) decoder for polar codes. SC is a low-complexity depth-first
search decoding algorithm, favorable for beyond-5G applications that require
extremely high throughput and low power. The ASIC implementation of SC in this
work exploits many techniques including pipelining and unrolling to achieve
Tb/s data throughput without compromising power and area metrics. To reduce the
complexity of the implementation, an adaptive log-likelihood ratio (LLR)
quantization scheme is used. This scheme optimizes bit precision of the
internal LLRs within the range of 1-5 bits by considering irregular
polarization and entropy of LLR distribution in SC decoder. The performance
cost of this scheme is less than 0.2 dB when the code block length is 1024 bits
and the payload is 854 bits. Furthermore, some computations in SC take large
space with high degree of parallelization while others take longer time steps.
To optimize these computations and reduce both memory and latency, register
reduction/balancing (R-RB) method is used. The final decoder architecture is
called optimized polar SC (OPSC). The post-placement-routing results at 16nm
FinFet ASIC technology show that OPSC decoder achieves 1.2 Tb/s coded
throughput on 0.79 mm$^2$ area with 0.95 pJ/bit energy efficiency.
"
1716,Long Range Communication on Batteryless Devices,"  Bulk of the existing Wireless Sensor Network (WSN) nodes are usually battery
powered, stationary and mostly designed for short distance communication, with
little to no consideration for constrained devices that operate solely on
harvested energy. On many occasions, batteries and beefy super-capacitors are
used to power these WSN, but these systems are prone to service-life
degradation and current-leakages. Most of the systems implementing super
capacitors do not account for leakages after exceeding the charge cycle
threshold. Frequent battery maintenance and replacement at scale is
non-trivial, labor-intensive and challenging task, especially on sensing nodes
deployed in extreme harsh environments with limited human intervention. In this
paper, we present the technique for achieving Kilometer range communication on
batteryless constraint devices by harnessing the capabilities of LoRa
technology.
"
1717,"A Survey of Resource Management for Processing-in-Memory and Near-Memory
  Processing Architectures","  Due to amount of data involved in emerging deep learning and big data
applications, operations related to data movement have quickly become the
bottleneck. Data-centric computing (DCC), as enabled by processing-in-memory
(PIM) and near-memory processing (NMP) paradigms, aims to accelerate these
types of applications by moving the computation closer to the data. Over the
past few years, researchers have proposed various memory architectures that
enable DCC systems, such as logic layers in 3D stacked memories or charge
sharing based bitwise operations in DRAM. However, application-specific memory
access patterns, power and thermal concerns, memory technology limitations, and
inconsistent performance gains complicate the offloading of computation in DCC
systems. Therefore, designing intelligent resource management techniques for
computation offloading is vital for leveraging the potential offered by this
new paradigm. In this article, we survey the major trends in managing PIM and
NMP-based DCC systems and provide a review of the landscape of resource
management techniques employed by system designers for such systems.
Additionally, we discuss the future challenges and opportunities in DCC
management.
"
1718,"A high-performance MEMRISTOR-based Smith-Waterman DNA sequence alignment
  Using FPNI structure","  This paper aims to present a new re-configuration sequencing method for
difference of read lengths that may take place as input data in which is
crucial drawbacks lay impact on DNA sequencing methods.
"
1719,"A reduced-precision streaming SpMV architecture for Personalized
  PageRank on FPGA","  Sparse matrix-vector multiplication is often employed in many data-analytic
workloads in which low latency and high throughput are more valuable than exact
numerical convergence. FPGAs provide quick execution times while offering
precise control over the accuracy of the results thanks to reduced-precision
fixed-point arithmetic. In this work, we propose a novel streaming
implementation of Coordinate Format (COO) sparse matrix-vector multiplication,
and study its effectiveness when applied to the Personalized PageRank
algorithm, a common building block of recommender systems in e-commerce
websites and social networks. Our implementation achieves speedups up to 6x
over a reference floating-point FPGA architecture and a state-of-the-art
multi-threaded CPU implementation on 8 different data-sets, while preserving
the numerical fidelity of the results and reaching up to 42x higher energy
efficiency compared to the CPU implementation.
"
1720,E-BATCH: Energy-Efficient and High-Throughput RNN Batching,"  Recurrent Neural Network (RNN) inference exhibits low hardware utilization
due to the strict data dependencies across time-steps. Batching multiple
requests can increase throughput. However, RNN batching requires a large amount
of padding since the batched input sequences may largely differ in length.
Schemes that dynamically update the batch every few time-steps avoid padding.
However, they require executing different RNN layers in a short timespan,
decreasing energy efficiency. Hence, we propose E-BATCH, a low-latency and
energy-efficient batching scheme tailored to RNN accelerators. It consists of a
runtime system and effective hardware support. The runtime concatenates
multiple sequences to create large batches, resulting in substantial energy
savings. Furthermore, the accelerator notifies it when the evaluation of a
sequence is done, so that a new sequence can be immediately added to a batch,
thus largely reducing the amount of padding. E-BATCH dynamically controls the
number of time-steps evaluated per batch to achieve the best trade-off between
latency and energy efficiency for the given hardware platform. We evaluate
E-BATCH on top of E-PUR and TPU. In E-PUR, E-BATCH improves throughput by 1.8x
and energy-efficiency by 3.6x, whereas in TPU, it improves throughput by 2.1x
and energy-efficiency by 1.6x, over the state-of-the-art.
"
1721,"Procrustes: a Dataflow and Accelerator for Sparse Deep Neural Network
  Training","  The success of DNN pruning has led to the development of energy-efficient
inference accelerators that support pruned models with sparse weight and
activation tensors. Because the memory layouts and dataflows in these
architectures are optimized for the access patterns during
$\mathit{inference}$, however, they do not efficiently support the emerging
sparse $\mathit{training}$ techniques.
  In this paper, we demonstrate (a) that accelerating sparse training requires
a co-design approach where algorithms are adapted to suit the constraints of
hardware, and (b) that hardware for sparse DNN training must tackle constraints
that do not arise in inference accelerators. As proof of concept, we adapt a
sparse training algorithm to be amenable to hardware acceleration; we then
develop dataflow, data layout, and load-balancing techniques to accelerate it.
  The resulting system is a sparse DNN training accelerator that produces
pruned models with the same accuracy as dense models without first training,
then pruning, and finally retraining, a dense model. Compared to training the
equivalent unpruned models using a state-of-the-art DNN accelerator without
sparse training support, Procrustes consumes up to 3.26$\times$ less energy and
offers up to 4$\times$ speedup across a range of models, while pruning weights
by an order of magnitude and maintaining unpruned accuracy.
"
1722,Extending High-Level Synthesis for Task-Parallel Programs,"  C/C++/OpenCL-based high-level synthesis (HLS) becomes more and more popular
for field-programmable gate array (FPGA) accelerators in many application
domains in recent years, thanks to its competitive quality of result (QoR) and
short development cycle compared with the traditional register-transfer level
(RTL) design approach. Yet, limited by the sequential C semantics, it remains
challenging to adopt the same highly productive high-level programming approach
in many other application domains, where coarse-grained tasks run in parallel
and communicate with each other at a fine-grained level. While current HLS
tools support task-parallel programs, the productivity is greatly limited in
the code development, correctness verification, and QoR tuning cycles, due to
the poor programmability, restricted software simulation, and slow code
generation, respectively. Such limited productivity often defeats the purpose
of HLS and hinder programmers from adopting HLS for task-parallel FPGA
accelerators. In this paper, we extend the HLS C++ language and present a fully
automated framework with programmer-friendly interfaces, universal software
simulation, and fast code generation to overcome these limitations.
Experimental results based on a wide range of real-world task-parallel programs
show that, on average, the lines of kernel and host code are reduced by 22% and
51%, respectively, which considerably improves the programmability. The
correctness verification and the iterative QoR tuning cycles are both greatly
accelerated by 3.2xand 6.8x, respectively.
"
1723,A Study of Runtime Adaptive Prefetching for STTRAM L1 Caches,"  Spin-Transfer Torque RAM (STTRAM) is a promising alternative to SRAM in
on-chip caches due to several advantages. These advantages include
non-volatility, low leakage, high integration density, and CMOS compatibility.
Prior studies have shown that relaxing and adapting the STTRAM retention time
to runtime application needs can substantially reduce overall cache energy
without significant latency overheads, due to the lower STTRAM write energy and
latency in shorter retention times. In this paper, as a first step towards
efficient prefetching across the STTRAM cache hierarchy, we study prefetching
in reduced retention STTRAM L1 caches. Using SPEC CPU 2017 benchmarks, we
analyze the energy and latency impact of different prefetch distances in
different STTRAM cache retention times for different applications. We show that
expired_unused_prefetches---the number of unused prefetches expired by the
reduced retention time STTRAM cache---can accurately determine the best
retention time for energy consumption and access latency. This new metric can
also provide insights into the best prefetch distance for memory bandwidth
consumption and prefetch accuracy. Based on our analysis and insights, we
propose Prefetch-Aware Retention time Tuning (PART) and Retention time-based
Prefetch Control (RPC). Compared to a base STTRAM cache, PART and RPC
collectively reduced the average cache energy and latency by 22.24% and 24.59%,
respectively. When the base architecture was augmented with the
state-of-the-art near-side prefetch throttling (NST), PART+RPC reduced the
average cache energy and latency by 3.50% and 3.59%, respectively, and reduced
the hardware overhead by 54.55%
"
1724,New categories of Safe Faults in a processor-based Embedded System,"  The identification of safe faults (i.e., faults which are guaranteed not to
produce any failure) in an electronic system is a crucial step when analyzing
its dependability and its test plan development. Unfortunately, safe fault
identification is poorly supported by available EDA tools, and thus remains an
open problem. The complexity growth of modern systems used in safety-critical
applications further complicates their identification. In this article, we
identify some classes of safe faults within an embedded system based on a
pipelined processor. A new method for automating the safe fault identification
is also proposed. The safe faults belonging to each class are identified
resorting to Automatic Test Pattern Generation (ATPG) techniques. The proposed
methodology is applied to a sample system built around the OpenRisc1200 open
source processor.
"
1725,Rubik: A Hierarchical Architecture for Efficient Graph Learning,"  Graph convolutional network (GCN) emerges as a promising direction to learn
the inductive representation in graph data commonly used in widespread
applications, such as E-commerce, social networks, and knowledge graphs.
However, learning from graphs is non-trivial because of its mixed computation
model involving both graph analytics and neural network computing. To this end,
we decompose the GCN learning into two hierarchical paradigms: graph-level and
node-level computing. Such a hierarchical paradigm facilitates the software and
hardware accelerations for GCN learning.
  We propose a lightweight graph reordering methodology, incorporated with a
GCN accelerator architecture that equips a customized cache design to fully
utilize the graph-level data reuse. We also propose a mapping methodology aware
of data reuse and task-level parallelism to handle various graphs inputs
effectively. Results show that Rubik accelerator design improves energy
efficiency by 26.3x to 1375.2x than GPU platforms across different datasets and
GCN models.
"
1726,"An OpenCL 3D FFT for Molecular Dynamics Distributed Across Multiple
  FPGAs","  3D FFTs are used to accelerate MD electrostatic forces computations but are
difficult to parallelize due to communications requirements. We present a
distributed OpenCL 3D FFT implementation on Intel Stratix 10 FPGAs for grids up
to {\boldmath $128^3$}. We use FPGA hardware features such as HBM2 memory and
multiple 100 Gbps links to provide scalable memory accesses and communications.
Our implementation outperforms GPUs for smaller FFTs, even without
distribution. For {\boldmath$32^3$} we achieve 4.4 microseconds on a single
FPGA, similar to Anton 1 on 512 nodes. For 8 parallel pipelines (hardware
limited), we reach the same performance both locally and distributed, showing
that communications are not limiting the performance. Our FFT implementation is
designed to be part of the electrostatic force pipeline of a scalable MD
engine.
"
1727,The Smart Parking Management System,"  With growing, Car parking increases with the number of car users. With the
increased use of smartphones and their applications, users prefer mobile
phone-based solutions. This paper proposes the Smart Parking Management System
(SPMS) that depends on Arduino parts, Android applications, and based on IoT.
This gave the client the ability to check available parking spaces and reserve
a parking spot. IR sensors are utilized to know if a car park space is allowed.
Its area data are transmitted using the WI-FI module to the server and are
recovered by the mobile application which offers many options attractively and
with no cost to users and lets the user check reservation details. With IoT
technology, the smart parking system can be connected wirelessly to easily
track available locations.
"
1728,Breaking the Memory Wall for AI Chip with a New Dimension,"  Recent advancements in deep learning have led to the widespread adoption of
artificial intelligence (AI) in applications such as computer vision and
natural language processing. As neural networks become deeper and larger, AI
modeling demands outstrip the capabilities of conventional chip architectures.
Memory bandwidth falls behind processing power. Energy consumption comes to
dominate the total cost of ownership. Currently, memory capacity is
insufficient to support the most advanced NLP models. In this work, we present
a 3D AI chip, called Sunrise, with near-memory computing architecture to
address these three challenges. This distributed, near-memory computing
architecture allows us to tear down the performance-limiting memory wall with
an abundance of data bandwidth. We achieve the same level of energy efficiency
on 40nm technology as competing chips on 7nm technology. By moving to similar
technologies as other AI chips, we project to achieve more than ten times the
energy efficiency, seven times the performance of the current state-of-the-art
chips, and twenty times of memory capacity as compared with the best chip in
each benchmark.
"
1729,RP-Rewriter: An Optimized Rewriter for Large Terms in ACL2,"  RP-Rewriter (Retain-Property) is a verified clause processor that can use
some of the existing ACL2 rewrite rules to prove conjectures through term
rewriting. Optimized for conjectures that can expand into large terms, the
rewriter tries to mimic some of the ACL2 rewriting heuristics but also adds
some extra features. It can attach side-conditions to terms that help the
rewriter retain properties about them and prevent possibly some very expensive
backchaining. The rewriter supports user-defined complex meta rules that can
return a special structure to prevent redundant rewriting. Additionally, it can
store fast alists even when values are not quoted. RP-Rewriter is utilized for
two applications, multiplier design proofs and SVEX simplification, which
involve very large terms.
"
1730,"Performance Modeling of Streaming Kernels and Sparse Matrix-Vector
  Multiplication on A64FX","  The A64FX CPU powers the current number one supercomputer on the Top500 list.
Although it is a traditional cache-based multicore processor, its peak
performance and memory bandwidth rival accelerator devices. Generating
efficient code for such a new architecture requires a good understanding of its
performance features. Using these features, we construct the
Execution-Cache-Memory (ECM) performance model for the A64FX processor in the
FX700 supercomputer and validate it using streaming loops. We also identify
architectural peculiarities and derive optimization hints. Applying the ECM
model to sparse matrix-vector multiplication (SpMV), we motivate why the CRS
matrix storage format is inappropriate and how the SELL-C-sigma format with
suitable code optimizations can achieve bandwidth saturation for SpMV.
"
1731,"AutoDSE: Enabling Software Programmers Design Efficient FPGA
  Accelerators","  Adopting FPGA as an accelerator in datacenters is becoming mainstream for
customized computing, but the fact that FPGAs are hard to program creates a
steep learning curve for software programmers. Even with the help of high-level
synthesis (HLS), accelerator designers still have to manually perform code
reconstruction and cumbersome parameter tuning to achieve the optimal
performance. While many learning models have been leveraged by existing work to
automate the design of efficient accelerators, the unpredictability of modern
HLS tools becomes a major obstacle for them to maintain high accuracy. In this
paper, we address this problem by incorporating an automated DSE
framework-AutoDSE- that leverages bottleneck-guided gradient optimizer to
systematically find abetter design point. AutoDSE finds the bottleneck of the
design in each step and focuses on high-impact parameters to overcome that,
which is similar to the approach an expert would take. The experimental results
show that AutoDSE is able to find the design point that achieves, on the
geometric mean, 19.9x speedup over one CPU core for Machsuite and Rodinia
benchmarks and 1.04x over the manually designed HLS accelerated vision kernels
in Xilinx Vitis libraries yet with 26x reduction of their optimization pragmas.
With less than one optimization pragma per design on average, we are making
progress towards democratizing customizable computing by enabling software
programmers to design efficient FPGA accelerators.
"
1732,System measurement of Intel AEP Optane DIMM,"  In recent years, memory wall has been a great performance bottleneck of
computer system. To overcome it, Non-Volatile Main Memory (NVMM) technology has
been discussed widely to provide a much larger main memory capacity. Last year,
Intel released AEP Optane DIMM, which provides hundreds of GB capacity as a
promising replacement of traditional DRAM memory. But as most key parameters of
AEP is not open to users, there is a need to get to know them because they will
guide a direction of further NVMM research. In this paper, we focus on
measuring performance and architecture features of AEP DIMM. Together, we
explore the design of DRAM cache which is an important part of DRAM-AEP hybrid
memory system. As a result, we estimate the write latency of AEP DIMM which has
not been measured accurately. And, we discover the current design parameters of
DRAM cache, such as tag organization, cache associativity and set index
mapping. All of these features are first published on academic paper which are
greatly helpful to future NVMM optimizations.
"
1733,An Embedded RISC-V Core with Fast Modular Multiplication,"  One of the biggest concerns in IoT is privacy and security. Encryption and
authentication need big power budgets, which battery-operated IoT end-nodes do
not have. Hardware accelerators designed for specific cryptographic operations
provide little to no flexibility for future updates. Custom instruction
solutions are smaller in area and provide more flexibility for new methods to
be implemented. One drawback of custom instructions is that the processor has
to wait for the operation to finish. Eventually, the response time of the
device to real-time events gets longer. In this work, we propose a processor
with an extended custom instruction for modular multiplication, which blocks
the processor, typically, two cycles for any size of modular multiplication
when used in Partial Execution mode. We adopted embedded and compressed
extensions of RISC-V for our proof-of-concept CPU. Our design is benchmarked on
recent cryptographic algorithms in the field of elliptic-curve cryptography.
Our CPU with 128-bit modular multiplication operates at 136MHz on ASIC and
81MHz on FPGA. It achieves up to 13x speed up on software implementations while
reducing overall power consumption by up to 95\% with 41\% average area
overhead over our base architecture.
"
1734,"Weighing up the new kid on the block: Impressions of using Vitis for HPC
  software development","  The use of reconfigurable computing, and FPGAs in particular, has strong
potential in the field of High Performance Computing (HPC). However the
traditionally high barrier to entry when it comes to programming this
technology has, until now, precluded widespread adoption. To popularise
reconfigurable computing with communities such as HPC, Xilinx have recently
released the first version of Vitis, a platform aimed at making the programming
of FPGAs much more a question of software development rather than hardware
design. However a key question is how well this technology fulfils the aim, and
whether the tooling is mature enough such that software developers using FPGAs
to accelerate their codes is now a more realistic proposition, or whether it
simply increases the convenience for existing experts. To examine this question
we use the Himeno benchmark as a vehicle for exploring the Vitis platform for
building, executing and optimising HPC codes, describing the different steps
and potential pitfalls of the technology. The outcome of this exploration is a
demonstration that, whilst Vitis is an excellent step forwards and
significantly lowers the barrier to entry in developing codes for FPGAs, it is
not a silver bullet and an underlying understanding of dataflow style
algorithmic design and appreciation of the architecture is still key to
obtaining good performance on reconfigurable architectures.
"
1735,"CARLA: A Convolution Accelerator with a Reconfigurable and Low-Energy
  Architecture","  Convolutional Neural Networks (CNNs) have proven to be extremely accurate for
image recognition, even outperforming human recognition capability. When
deployed on battery-powered mobile devices, efficient computer architectures
are required to enable fast and energy-efficient computation of costly
convolution operations. Despite recent advances in hardware accelerator design
for CNNs, two major problems have not yet been addressed effectively,
particularly when the convolution layers have highly diverse structures: (1)
minimizing energy-hungry off-chip DRAM data movements; (2) maximizing the
utilization factor of processing resources to perform convolutions. This work
thus proposes an energy-efficient architecture equipped with several optimized
dataflows to support the structural diversity of modern CNNs. The proposed
approach is evaluated by implementing convolutional layers of VGGNet-16 and
ResNet-50. Results show that the architecture achieves a Processing Element
(PE) utilization factor of 98% for the majority of 3x3 and 1x1 convolutional
layers, while limiting latency to 396.9 ms and 92.7 ms when performing
convolutional layers of VGGNet-16 and ResNet-50, respectively. In addition, the
proposed architecture benefits from the structured sparsity in ResNet-50 to
reduce the latency to 42.5 ms when half of the channels are pruned.
"
1736,Synchronizer-Free Digital Link Controller,"  This work presents a producer-consumer link between two independent clock
domains. The link allows for metastability-free, low-latency, high-throughput
communication by slight adjustments to the clock frequencies of the producer
and consumer domains steered by a controller circuit. Any such controller
cannot deterministically avoid, detect, nor resolve metastability. Typically,
this is addressed by synchronizers, incurring a larger dead time in the control
loop. We follow the approach of Friedrichs et al. (TC 2018) who proposed
metastability-containing circuits. The result is a simple control circuit that
may become metastable, yet deterministically avoids buffer underrun or
overflow. More specifically, the controller output may become metastable, but
this may only affect oscillator speeds within specific bounds. In contrast,
communication is guaranteed to remain metastability-free. We formally prove
correctness of the producer-consumer link and a possible implementation that
has only small overhead. With SPICE simulations of the proposed implementation
we further substantiate our claims. The simulation uses 65nm process running at
roughly 2GHz.
"
1737,Learned Hardware/Software Co-Design of Neural Accelerators,"  The use of deep learning has grown at an exponential rate, giving rise to
numerous specialized hardware and software systems for deep learning. Because
the design space of deep learning software stacks and hardware accelerators is
diverse and vast, prior work considers software optimizations separately from
hardware architectures, effectively reducing the search space. Unfortunately,
this bifurcated approach means that many profitable design points are never
explored. This paper instead casts the problem as hardware/software co-design,
with the goal of automatically identifying desirable points in the joint design
space. The key to our solution is a new constrained Bayesian optimization
framework that avoids invalid solutions by exploiting the highly constrained
features of this design space, which are semi-continuous/semi-discrete. We
evaluate our optimization framework by applying it to a variety of neural
models, improving the energy-delay product by 18% (ResNet) and 40% (DQN) over
hand-tuned state-of-the-art systems, as well as demonstrating strong results on
other neural network architectures, such as MLPs and Transformers.
"
1738,NATSA: A Near-Data Processing Accelerator for Time Series Analysis,"  Time series analysis is a key technique for extracting and predicting events
in domains as diverse as epidemiology, genomics, neuroscience, environmental
sciences, economics, and more. Matrix profile, the state-of-the-art algorithm
to perform time series analysis, computes the most similar subsequence for a
given query subsequence within a sliced time series. Matrix profile has low
arithmetic intensity, but it typically operates on large amounts of time series
data. In current computing systems, this data needs to be moved between the
off-chip memory units and the on-chip computation units for performing matrix
profile. This causes a major performance bottleneck as data movement is
extremely costly in terms of both execution time and energy.
  In this work, we present NATSA, the first Near-Data Processing accelerator
for time series analysis. The key idea is to exploit modern 3D-stacked High
Bandwidth Memory (HBM) to enable efficient and fast specialized matrix profile
computation near memory, where time series data resides. NATSA provides three
key benefits: 1) quickly computing the matrix profile for a wide range of
applications by building specialized energy-efficient floating-point arithmetic
processing units close to HBM, 2) improving the energy efficiency and execution
time by reducing the need for data movement over slow and energy-hungry buses
between the computation units and the memory units, and 3) analyzing time
series data at scale by exploiting low-latency, high-bandwidth, and
energy-efficient memory access provided by HBM. Our experimental evaluation
shows that NATSA improves performance by up to 14.2x (9.9x on average) and
reduces energy by up to 27.2x (19.4x on average), over the state-of-the-art
multi-core implementation. NATSA also improves performance by 6.3x and reduces
energy by 10.2x over a general-purpose NDP platform with 64 in-order cores.
"
1739,"WoLFRaM: Enhancing Wear-Leveling and Fault Tolerance in Resistive
  Memories using Programmable Address Decoders","  Resistive memories have limited lifetime caused by limited write endurance
and highly non-uniform write access patterns. Two main techniques to mitigate
endurance-related memory failures are 1) wear-leveling, to evenly distribute
the writes across the entire memory, and 2) fault tolerance, to correct memory
cell failures. However, one of the main open challenges in extending the
lifetime of existing resistive memories is to make both techniques work
together seamlessly and efficiently. To address this challenge, we propose
WoLFRaM, a new mechanism that combines both wear-leveling and fault tolerance
techniques at low cost by using a programmable resistive address decoder
(PRAD). The key idea of WoLFRaM is to use PRAD for implementing 1) a new
efficient wear-leveling mechanism that remaps write accesses to random physical
locations on the fly, and 2) a new efficient fault tolerance mechanism that
recovers from faults by remapping failed memory blocks to available physical
locations. Our evaluations show that, for a Phase Change Memory (PCM) based
system with cell endurance of 108 writes, WoLFRaM increases the memory lifetime
by 68% compared to a baseline that implements the best state-of-the-art
wear-leveling and fault correction mechanisms. WoLFRaM's average / worst-case
performance and energy overheads are 0.51% / 3.8% and 0.47% / 2.1%
respectively.
"
1740,Symbolic Verification of Quantum Circuits,"  This short note proposes a symbolic approach for representing and reasoning
about quantum circuits using complex, vector or matrix-valued Boolean
expressions. A major benefit of this approach is that it allows us to directly
borrow the existing techniques and tools for verification of classical logic
circuits in reasoning about quantum circuits.
"
1741,A Hardware-Aware Heuristic for the Qubit Mapping Problem in the NISQ Era,"  Due to several physical limitations in the realisation of quantum hardware,
today's quantum computers are qualified as Noisy Intermediate-Scale Quantum
(NISQ) hardware. NISQ hardware is characterized by a small number of qubits (50
to a few hundred) and noisy operations. Moreover, current realisations of
superconducting quantum chips do not have the ideal all-to-all connectivity
between qubits but rather at most a nearest-neighbour connectivity. All these
hardware restrictions add supplementary low-level requirements. They need to be
addressed before submitting the quantum circuit to an actual chip. Satisfying
these requirements is a tedious task for the programmer. Instead, the task of
adapting the quantum circuit to a given hardware is left to the compiler. In
this paper, we propose a Hardware-Aware mapping transition algorithm (HA) that
takes the calibration data into account with the aim to improve the overall
fidelity of the circuit. Evaluation results on IBM quantum hardware show that
our HA approach can outperform the state of the art both in terms of the number
of additional gates and circuit fidelity.
"
1742,"DiffTune: Optimizing CPU Simulator Parameters with Learned
  Differentiable Surrogates","  CPU simulators are useful tools for modeling CPU execution behavior. However,
they suffer from inaccuracies due to the cost and complexity of setting their
fine-grained parameters, such as the latencies of individual instructions. This
complexity arises from the expertise required to design benchmarks and
measurement frameworks that can precisely measure the values of parameters at
such fine granularity. In some cases, these parameters do not necessarily have
a physical realization and are therefore fundamentally approximate, or even
unmeasurable.
  In this paper we present DiffTune, a system for learning the parameters of
x86 basic block CPU simulators from coarse-grained end-to-end measurements.
Given a simulator, DiffTune learns its parameters by first replacing the
original simulator with a differentiable surrogate, another function that
approximates the original function; by making the surrogate differentiable,
DiffTune is then able to apply gradient-based optimization techniques even when
the original function is non-differentiable, such as is the case with CPU
simulators. With this differentiable surrogate, DiffTune then applies
gradient-based optimization to produce values of the simulator's parameters
that minimize the simulator's error on a dataset of ground truth end-to-end
performance measurements. Finally, the learned parameters are plugged back into
the original simulator.
  DiffTune is able to automatically learn the entire set of
microarchitecture-specific parameters within the Intel x86 simulation model of
llvm-mca, a basic block CPU simulator based on LLVM's instruction scheduling
model. DiffTune's learned parameters lead llvm-mca to an average error that not
only matches but lowers that of its original, expert-provided parameter values.
"
1743,A Mixed-Precision RISC-V Processor for Extreme-Edge DNN Inference,"  Low bit-width Quantized Neural Networks (QNNs) enable deployment of complex
machine learning models on constrained devices such as microcontrollers (MCUs)
by reducing their memory footprint. Fine-grained asymmetric quantization (i.e.,
different bit-widths assigned to weights and activations on a tensor-by-tensor
basis) is a particularly interesting scheme to maximize accuracy under a tight
memory constraint. However, the lack of sub-byte instruction set architecture
(ISA) support in SoA microprocessors makes it hard to fully exploit this
extreme quantization paradigm in embedded MCUs. Support for sub-byte and
asymmetric QNNs would require many precision formats and an exorbitant amount
of opcode space. In this work, we attack this problem with status-based SIMD
instructions: rather than encoding precision explicitly, each operand's
precision is set dynamically in a core status register. We propose a novel
RISC-V ISA core MPIC (Mixed Precision Inference Core) based on the open-source
RI5CY core. Our approach enables full support for mixed-precision QNN inference
with different combinations of operands at 16-, 8-, 4- and 2-bit precision,
without adding any extra opcode or increasing the complexity of the decode
stage. Our results show that MPIC improves both performance and energy
efficiency by a factor of 1.1-4.9x when compared to software-based
mixed-precision on RI5CY; with respect to commercially available Cortex-M4 and
M7 microcontrollers, it delivers 3.6-11.7x better performance and 41-155x
higher efficiency.
"
1744,"Machine Learning Enabled Scalable Performance Prediction of Scientific
  Codes","  We present the Analytical Memory Model with Pipelines (AMMP) of the
Performance Prediction Toolkit (PPT). PPT-AMMP takes high-level source code and
hardware architecture parameters as input, predicts runtime of that code on the
target hardware platform, which is defined in the input parameters. PPT-AMMP
transforms the code to an (architecture-independent) intermediate
representation, then (i) analyzes the basic block structure of the code, (ii)
processes architecture-independent virtual memory access patterns that it uses
to build memory reuse distance distribution models for each basic block, (iii)
runs detailed basic-block level simulations to determine hardware pipeline
usage.
  PPT-AMMP uses machine learning and regression techniques to build the
prediction models based on small instances of the input code, then integrates
into a higher-order discrete-event simulation model of PPT running on Simian
PDES engine. We validate PPT-AMMP on four standard computational physics
benchmarks, finally present a use case of hardware parameter sensitivity
analysis to identify bottleneck hardware resources on different code inputs. We
further extend PPT-AMMP to predict the performance of scientific application
(radiation transport), SNAP. We analyze the application of multi-variate
regression models that accurately predict the reuse profiles and the basic
block counts. The predicted runtimes of SNAP when compared to that of actual
times are accurate.
"
1745,"An Energy-Efficient Low-Voltage Swing Transceiver for mW-Range IoT
  End-Nodes","  As the Internet-of-Things (IoT) applications become more and more pervasive,
IoT end nodes are requiring more and more computational power within a few mW
of power envelope, coupled with high-speed and energy-efficient inter-chip
communication to deal with the growing input/output and memory bandwidth for
emerging near-sensor analytics applications. While traditional interfaces such
as SPI cannot cope with these tight requirements, low-voltage swing
transceivers can tackle this challenge thanks to their capability to achieve
several Gbps of bandwidth at extremely low power. However, recent research on
high-speed serial links addressed this challenge only partially, proposing only
partial or stand-alone designs, and not addressing their integration in real
systems and the related implications. In this paper, we present for the first
time a complete design and system-level architecture of a low-voltage swing
transceiver integrated within a low-power (mW range) IoT end-node processors,
and we compare it with existing microcontroller interfaces. The transceiver,
implemented in a commercial 65-nm CMOS technology achieves 10.2x higher energy
efficiency at 15.7x higher performance than traditional microcontroller
peripherals (single lane).
"
1746,C for a tiny system,"  We have implemented support for Padauk microcontrollers, tiny 8-Bit devices
with 60 B to 256 B of RAM, in the Small Device C Compiler (SDCC), showing that
the use of (mostly) standard C to program such minimal devices is feasible. We
report on our experience and on the difficulties in supporting the hardware
multithreading present on some of these devices. To make the devices a better
target for C, we propose various enhancements of the architecture, and
empirically evaluated their impact on code size.
"
1747,Cross-Stack Workload Characterization of Deep Recommendation Systems,"  Deep learning based recommendation systems form the backbone of most
personalized cloud services. Though the computer architecture community has
recently started to take notice of deep recommendation inference, the resulting
solutions have taken wildly different approaches - ranging from near memory
processing to at-scale optimizations. To better design future hardware systems
for deep recommendation inference, we must first systematically examine and
characterize the underlying systems-level impact of design decisions across the
different levels of the execution stack. In this paper, we characterize eight
industry-representative deep recommendation models at three different levels of
the execution stack: algorithms and software, systems platforms, and hardware
microarchitectures. Through this cross-stack characterization, we first show
that system deployment choices (i.e., CPUs or GPUs, batch size granularity) can
give us up to 15x speedup. To better understand the bottlenecks for further
optimization, we look at both software operator usage breakdown and CPU
frontend and backend microarchitectural inefficiencies. Finally, we model the
correlation between key algorithmic model architecture features and hardware
bottlenecks, revealing the absence of a single dominant algorithmic component
behind each hardware bottleneck.
"
1748,TaxoNN: A Light-Weight Accelerator for Deep Neural Network Training,"  Emerging intelligent embedded devices rely on Deep Neural Networks (DNNs) to
be able to interact with the real-world environment. This interaction comes
with the ability to retrain DNNs, since environmental conditions change
continuously in time. Stochastic Gradient Descent (SGD) is a widely used
algorithm to train DNNs by optimizing the parameters over the training data
iteratively. In this work, first we present a novel approach to add the
training ability to a baseline DNN accelerator (inference only) by splitting
the SGD algorithm into simple computational elements. Then, based on this
heuristic approach we propose TaxoNN, a light-weight accelerator for DNN
training. TaxoNN can easily tune the DNN weights by reusing the hardware
resources used in the inference process using a time-multiplexing approach and
low-bitwidth units. Our experimental results show that TaxoNN delivers, on
average, 0.97% higher misclassification rate compared to a full-precision
implementation. Moreover, TaxoNN provides 2.1$\times$ power saving and
1.65$\times$ area reduction over the state-of-the-art DNN training accelerator.
"
1749,"MicroRec: Accelerating Deep Recommendation Systems to Microseconds by
  Hardware and Data Structure Solutions","  Deep neural networks are widely used in personalized recommendation systems.
Unlike regular DNN inference workloads, recommendation inference is
memory-bound due to the many random memory accesses needed to lookup the
embedding tables. The inference is also heavily constrained in terms of latency
because producing a recommendation for a user must be done in about tens of
milliseconds. In this paper, we propose MicroRec, a high-performance inference
engine for recommendation systems. MicroRec accelerates recommendation
inference by (1) redesigning the data structures involved in the embeddings to
reduce the number of lookups needed and (2) taking advantage of the
availability of High-Bandwidth Memory (HBM) in FPGA accelerators to tackle the
latency by enabling parallel lookups. We have implemented the resulting design
on an FPGA board including the embedding lookup step as well as the complete
inference process. Compared to the optimized CPU baseline (16 vCPU,
AVX2-enabled), MicroRec achieves 13.8~14.7x speedup on embedding lookup alone
and 2.5$~5.4x speedup for the entire recommendation inference in terms of
throughput. As for latency, CPU-based engines needs milliseconds for inferring
a recommendation while MicroRec only takes microseconds, a significant
advantage in real-time recommendation systems.
"
1750,When HLS Meets FPGA HBM: Benchmarking and Bandwidth Optimization,"  With the recent release of High Bandwidth Memory (HBM) based FPGA boards,
developers can now exploit unprecedented external memory bandwidth. This allows
more memory-bounded applications to benefit from FPGA acceleration. However, we
found that it is not easy to fully utilize the available bandwidth when
developing some applications with high-level synthesis (HLS) tools. This is due
to the limitation of existing HLS tools when accessing HBM board's large number
of independent external memory channels. In this paper, we measure the
performance of three recent representative HBM FPGA boards (Intel's Stratix 10
MX and Xilinx's Alveo U50/U280 boards) with microbenchmarks and analyze the HLS
overhead. Next, we propose HLS-based optimization techniques to improve the
effective bandwidth when a PE accesses multiple HBM channels or multiple PEs
access an HBM channel. Our experiment demonstrates that the effective bandwidth
improves by 2.4X-3.8X. We also provide a list of insights for future
improvement of the HBM FPGA HLS design flow.
"
1751,"High Area/Energy Efficiency RRAM CNN Accelerator with Kernel-Reordering
  Weight Mapping Scheme Based on Pattern Pruning","  Resistive Random Access Memory (RRAM) is an emerging device for
processing-in-memory (PIM) architecture to accelerate convolutional neural
network (CNN). However, due to the highly coupled crossbar structure in the
RRAM array, it is difficult to exploit the sparsity of the network in
RRAM-based CNN accelerator. To optimize the weight mapping of sparse network in
the RRAM array and achieve high area and energy efficiency, we propose a novel
weight mapping scheme and corresponding RRAM-based CNN accelerator architecture
based on pattern pruning and Operation Unit(OU) mechanism. Experimental results
show that our work can achieve 4.16x-5.20x crossbar area efficiency,
1.98x-2.15x energy efficiency, and 1.15x-1.35x performance speedup in
comparison with the traditional weight mapping method.
"
1752,PIUMA: Programmable Integrated Unified Memory Architecture,"  High performance large scale graph analytics is essential to timely analyze
relationships in big data sets. Conventional processor architectures suffer
from inefficient resource usage and bad scaling on graph workloads. To enable
efficient and scalable graph analysis, Intel developed the Programmable
Integrated Unified Memory Architecture (PIUMA). PIUMA consists of many
multi-threaded cores, fine-grained memory and network accesses, a globally
shared address space and powerful offload engines. This paper presents the
PIUMA architecture, and provides initial performance estimations, projecting
that a PIUMA node will outperform a conventional compute node by one to two
orders of magnitude. Furthermore, PIUMA continues to scale across multiple
nodes, which is a challenge in conventional multinode setups.
"
1753,"Effective Algorithm-Accelerator Co-design for AI Solutions on Edge
  Devices","  High quality AI solutions require joint optimization of AI algorithms, such
as deep neural networks (DNNs), and their hardware accelerators. To improve the
overall solution quality as well as to boost the design productivity, efficient
algorithm and accelerator co-design methodologies are indispensable. In this
paper, we first discuss the motivations and challenges for the
Algorithm/Accelerator co-design problem and then provide several effective
solutions. Especially, we highlight three leading works of effective co-design
methodologies: 1) the first simultaneous DNN/FPGA co-design method; 2) a
bi-directional lightweight DNN and accelerator co-design method; 3) a
differentiable and efficient DNN and accelerator co-search method. We
demonstrate the effectiveness of the proposed co-design approaches using
extensive experiments on both FPGAs and GPUs, with comparisons to existing
works. This paper emphasizes the importance and efficacy of
algorithm-accelerator co-design and calls for more research breakthroughs in
this interesting and demanding area.
"
1754,Real-Time Refocusing using an FPGA-based Standard Plenoptic Camera,"  Plenoptic cameras are receiving increasing attention in scientific and
commercial applications because they capture the entire structure of light in a
scene, enabling optical transforms (such as focusing) to be applied
computationally after the fact, rather than once and for all at the time a
picture is taken. In many settings, real-time interactive performance is also
desired, which in turn requires significant computational power due to the
large amount of data required to represent a plenoptic image. Although GPUs
have been shown to provide acceptable performance for real-time plenoptic
rendering, their cost and power requirements make them prohibitive for embedded
uses (such as in-camera). On the other hand, the computation to accomplish
plenoptic rendering is well-structured, suggesting the use of specialized
hardware. Accordingly, this paper presents an array of switch-driven Finite
Impulse Response (FIR) filters, implemented with FPGA to accomplish
high-throughput spatial-domain rendering. The proposed architecture provides a
power-efficient rendering hardware design suitable for full-video applications
as required in broadcasting or cinematography. A benchmark assessment of the
proposed hardware implementation shows that real-time performance can readily
be achieved, with a one order of magnitude performance improvement over a GPU
implementation and three orders of magnitude performance improvement over a
general-purpose CPU implementation.
"
1755,FPRaker: A Processing Element For Accelerating Neural Network Training,"  We present FPRaker, a processing element for composing training accelerators.
FPRaker processes several floating-point multiply-accumulation operations
concurrently and accumulates their result into a higher precision accumulator.
FPRaker boosts performance and energy efficiency during training by taking
advantage of the values that naturally appear during training. Specifically, it
processes the significand of the operands of each multiply-accumulate as a
series of signed powers of two. The conversion to this form is done on-the-fly.
This exposes ineffectual work that can be skipped: values when encoded have few
terms and some of them can be discarded as they would fall outside the range of
the accumulator given the limited precision of floating-point. We demonstrate
that FPRaker can be used to compose an accelerator for training and that it can
improve performance and energy efficiency compared to using conventional
floating-point units under ISO-compute area constraints. We also demonstrate
that FPRaker delivers additional benefits when training incorporates pruning
and quantization. Finally, we show that FPRaker naturally amplifies performance
with training methods that use a different precision per layer.
"
1756,"Towards truly local gradients with CLAPP: Contrastive, Local And
  Predictive Plasticity","  Back-propagation (BP) is costly to implement in hardware and implausible as a
learning rule implemented in the brain. However, BP is surprisingly successful
in explaining neuronal activity patterns found along the cortical processing
stream. We propose a locally implementable, unsupervised learning algorithm,
CLAPP, which minimizes a simple, layer-specific loss function, and thus does
not need to back-propagate error signals. The weight updates only depend on
state variables of the pre- and post-synaptic neurons and a layer-wide third
factor. Networks trained with CLAPP build deep hierarchical representations of
images and speech.
"
1757,"Vector-Vector-Matrix Architecture: A Novel Hardware-Aware Framework for
  Low-Latency Inference in NLP Applications","  Deep neural networks have become the standard approach to building reliable
Natural Language Processing (NLP) applications, ranging from Neural Machine
Translation (NMT) to dialogue systems. However, improving accuracy by
increasing the model size requires a large number of hardware computations,
which can slow down NLP applications significantly at inference time. To
address this issue, we propose a novel vector-vector-matrix architecture
(VVMA), which greatly reduces the latency at inference time for NMT. This
architecture takes advantage of specialized hardware that has low-latency
vector-vector operations and higher-latency vector-matrix operations. It also
reduces the number of parameters and FLOPs for virtually all models that rely
on efficient matrix multipliers without significantly impacting accuracy. We
present empirical results suggesting that our framework can reduce the latency
of sequence-to-sequence and Transformer models used for NMT by a factor of
four. Finally, we show evidence suggesting that our VVMA extends to other
domains, and we discuss novel hardware for its efficient use.
"
1758,Elasticlave: An Efficient Memory Model for Enclaves,"  Trusted-execution environments (TEE), like Intel SGX, isolate user-space
applications into secure enclaves without trusting the OS. Thus, TEEs reduce
the trusted computing base, but add one to two orders of magnitude slow-down.
The performance cost stems from a strict memory model, which we call the
spatial isolation model, where enclaves cannot share memory regions with each
other. In this work, we present Elasticlave---a new TEE memory model that
allows enclaves to selectively and temporarily share memory with other enclaves
and the OS. Elasticlave eliminates the need for expensive data copy operations,
while offering the same level of application-desired security as possible with
the spatial model. We prototype Elasticlave design on an RTL-designed
cycle-level RISC-V core and observe 1 to 2 orders of magnitude performance
improvements over the spatial model implemented with the same processor
configuration. Elasticlave has a small TCB. We find that its performance
characteristics and hardware area footprint scale well with the number of
shared memory regions it is configured to support.
"
1759,"Combinatorics and Geometry for the Many-ported, Distributed and Shared
  Memory Architecture","  Manycore SoC architectures based on on-chip shared memory are preferred for
flexible and programmable solutions in many application domains. However, the
development of many ported memory is becoming increasingly challenging as we
approach the end of Moore's Law while systems requirements demand larger shared
memory and more access ports. Memory can no longer be designed simply to
minimize single transaction access time, but must take into account the
functionality on the SoC. In this paper we examine a common large memory usage
in SoC, where the memory is used as storage for large buffers that are then
moved for time scheduled processing. We merge two aspects of many ported memory
design, combinatorial analysis of interconnect, and geometric analysis of
critical paths, extending both to show that in this case the SoC performance
benefits significantly from a hierarchical, distributed and staged architecture
with lower-radix switches and fractal randomization of memory bank addressing,
along with judicious and geometry aware application of speed up. The results
presented show the new architecture supports 20% higher throughput with 20%
lower latency and 30% less interconnection area at approximately the same power
consumption. We demonstrate the flexibility and scalability of this
architecture on silicon from a physical design perspective by taking the design
through layout. The architecture enables a much easier implementation flow that
works well with physically irregular port access and memory dominant layout,
which is a common issue in real designs.
"
1760,Optimizing Memory Performance of Xilinx FPGAs under Vitis,"  Plenty of research efforts have been devoted to FPGA-based acceleration, due
to its low latency and high energy efficiency. However, using the original
low-level hardware description languages like Verilog to program FPGAs requires
generally good knowledge of hardware design details and hand-on experiences.
Fortunately, the FPGA community intends to address this low programmability
issues. For example, , with the intention that programming FPGAs is just as
easy as programming GPUs. Even though Vitis is proven to increase
programmability, we cannot directly obtain high performance without careful
design regarding hardware pipeline and memory subsystem.In this paper, we focus
on the memory subsystem, comprehensively and systematically benchmarking the
effect of optimization methods on memory performance. Upon benchmarking, we
quantitatively analyze the typical memory access patterns for a broad range of
applications, including AI, HPC, and database. Further, we also provide the
corresponding optimization direction for each memory access pattern so as to
improve overall performance.
"
1761,"NimbRo-OP2X: Affordable Adult-sized 3D-printed Open-Source Humanoid
  Robot for Research","  For several years, high development and production costs of humanoid robots
restricted researchers interested in working in the field. To overcome this
problem, several research groups have opted to work with simulated or smaller
robots, whose acquisition costs are significantly lower. However, due to scale
differences and imperfect simulation replicability, results may not be directly
reproducible on real, adult-sized robots. In this paper, we present the
NimbRo-OP2X, a capable and affordable adult-sized humanoid platform aiming to
significantly lower the entry barrier for humanoid robot research. With a
height of 135 cm and weight of only 19 kg, the robot can interact in an
unmodified, human environment without special safety equipment. Modularity in
hardware and software allow this platform enough flexibility to operate in
different scenarios and applications with minimal effort. The robot is equipped
with an on-board computer with GPU, which enables the implementation of
state-of-the-art approaches for object detection and human perception demanded
by areas such as manipulation and human-robot interaction. Finally, the
capabilities of the NimbRo-OP2X, especially in terms of locomotion stability
and visual perception, are evaluated. This includes the performance at RoboCup
2018, where NimbRo-OP2X won all possible awards in the AdultSize class.
"
1762,"Enabling High-Capacity, Latency-Tolerant, and Highly-Concurrent GPU
  Register Files via Software/Hardware Cooperation","  Graphics Processing Units (GPUs) employ large register files to accommodate
all active threads and accelerate context switching. Unfortunately, register
files are a scalability bottleneck for future GPUs due to long access latency,
high power consumption, and large silicon area provisioning. Prior work
proposes hierarchical register file to reduce the register file power
consumption by caching registers in a smaller register file cache.
Unfortunately, this approach does not improve register access latency due to
the low hit rate in the register file cache.
  In this paper, we propose the Latency-Tolerant Register File (LTRF)
architecture to achieve low latency in a two-level hierarchical structure while
keeping power consumption low. We observe that compile-time interval analysis
enables us to divide GPU program execution into intervals with an accurate
estimate of a warp's aggregate register working-set within each interval. The
key idea of LTRF is to prefetch the estimated register working-set from the
main register file to the register file cache under software control, at the
beginning of each interval, and overlap the prefetch latency with the execution
of other warps. We observe that register bank conflicts while prefetching the
registers could greatly reduce the effectiveness of LTRF. Therefore, we devise
a compile-time register renumbering technique to reduce the likelihood of
register bank conflicts. Our experimental results show that LTRF enables
high-capacity yet long-latency main GPU register files, paving the way for
various optimizations. As an example optimization, we implement the main
register file with emerging high-density high-latency memory technologies,
enabling 8X larger capacity and improving overall GPU performance by 34%.
"
1763,Closed-Loop Neural Interfaces with Embedded Machine Learning,"  Neural interfaces capable of multi-site electrical recording, on-site signal
classification, and closed-loop therapy are critical for the diagnosis and
treatment of neurological disorders. However, deploying machine learning
algorithms on low-power neural devices is challenging, given the tight
constraints on computational and memory resources for such devices. In this
paper, we review the recent developments in embedding machine learning in
neural interfaces, with a focus on design trade-offs and hardware efficiency.
We also present our optimized tree-based model for low-power and
memory-efficient classification of neural signal in brain implants. Using
energy-aware learning and model compression, we show that the proposed oblique
trees can outperform conventional machine learning models in applications such
as seizure or tremor detection and motor decoding.
"
1764,Evaluating the Cost of Atomic Operations on Modern Architectures,"  Atomic operations (atomics) such as Compare-and-Swap (CAS) or Fetch-and-Add
(FAA) are ubiquitous in parallel programming. Yet, performance tradeoffs
between these operations and various characteristics of such systems, such as
the structure of caches, are unclear and have not been thoroughly analyzed. In
this paper we establish an evaluation methodology, develop a performance model,
and present a set of detailed benchmarks for latency and bandwidth of different
atomics. We consider various state-of-the-art x86 architectures: Intel Haswell,
Xeon Phi, Ivy Bridge, and AMD Bulldozer. The results unveil surprising
performance relationships between the considered atomics and architectural
properties such as the coherence state of the accessed cache lines. One key
finding is that all the tested atomics have comparable latency and bandwidth
even if they are characterized by different consensus numbers. Another insight
is that the hardware implementation of atomics prevents any instruction-level
parallelism even if there are no dependencies between the issued operations.
Finally, we discuss solutions to the discovered performance issues in the
analyzed architectures. Our analysis enables simpler and more effective
parallel programming and accelerates data processing on various architectures
deployed in both off-the-shelf machines and large compute systems.
"
1765,A RISC-V SystemC-TLM simulator,"  This work presents a SystemC-TLM based simulator for a RISC-V
microcontroller. This simulator is focused on simplicity and easy expandable of
a RISC-V. It is built around a full RISC-V instruction set simulator that
supports full RISC-V ISA and extensions M, A, C, Zicsr and Zifencei. The ISS is
encapsulated in a TLM-2 wrapper that enables it to communicate with any other
TLM-2 compatible module. The simulator also includes a very basic set of
peripherals to enable a complete SoC simulator. The running code can be
compiled with standard tools and using standard C libraries without
modifications. The simulator is able to correctly execute the riscv-compliance
suite. The entire simulator is published as a docker image to ease its
installation and use by developers. A porting of FreeRTOSv10.2.1 for the
simulated SoC is also published.
"
1766,"Eliminating the Barriers: Demystify Wi-Fi Baseband Design And Introduce
  PicoScenes Wi-Fi Sensing Platform","  Research on Wi-Fi sensing over the past decade has been thriving, but not
smooth. Three major barriers severely hamper the research, namely, the unknown
baseband design and its influence on CSI, inability to access the low-level
hardware controls and the lack of a flexible and versatile software toolkit for
hardware control. This paper tries to break the above three barriers from the
following aspects. First, an in-depth study on the baseband design of QCA9300,
the popular CSI-enabled Wi-Fi NIC, is presented. The lessons learned is of
great guiding significance for understanding what other commercial
off-the-shelf NICs. Second, several valuable features of QCA9300 are unlocked
for research, such as the arbitrary tuning for both the carrier frequency and
baseband sampling rate. By leveraging the unlocked features, we identify three
important types of CSI distortion, and pinpoint their origin through extensive
evaluations. Last, we develop and release PicoScenes, a powerful,
hardware-unified and extensible Wi-Fi sensing system. PicoScenes allows direct
access to the unlocked features of QCA9300 and IWL5300, and therefore greatly
facilitate the research on Wi-Fi sensing. It also supports the SDR-based Wi-Fi
sensing by embedding a 802.11a/g/n/ac/ax software baseband implementation. We
release PicoScenes at https://zpj.io/ps.
"
1767,Monitoring Large Crowds With WiFi: A Privacy-Preserving Approach,"  This paper presents a crowd monitoring system based on the passive detection
of probe requests. The system meets strict privacy requirements and is suited
to monitoring events or buildings with a least a few hundreds of attendees. We
present our counting process and an associated mathematical model. From this
model, we derive a concentration inequality that highlights the accuracy of our
crowd count estimator. Then, we describe our system. We present and discuss our
sensor hardware, our computing system architecture, and an efficient
implementation of our counting algorithm---as well as its space and time
complexity. We also show how our system ensures the privacy of people in the
monitored area. Finally, we validate our system using nine weeks of data from a
public library endowed with a camera-based counting system, which generates
counts against which we compare those of our counting system. This comparison
empirically quantifies the accuracy of our counting system, thereby showing it
to be suitable for monitoring public areas. Similarly, the concentration
inequality provides a theoretical validation of the system.
"
1768,"PIE: A Dynamic TCB for Remote Systems with a Platform Isolation
  Environment","  Trusted execution environments (TEE) remove the OS and the hypervisor from
the trusted computing base (TCB) and provide isolation to applications, known
as enclaves. TEEs also provide remote attestation, which allows a remote
verifier to check if the proper version of the enclave is running. However,
TEEs provide only a static and restricted hardware trusted computing base,
which includes only the CPU. While this might be acceptable for some
applications, it is too restrictive for others, and falls short when one
considers external hardware entities that are connected to the platform.
Current proposals to include specific external components into a TEE exist, but
these remain limited to very specific use cases and cannot be used dynamically.
  In this paper, we investigate platforms where enclaves can utilize a dynamic
hardware TCB. We propose new security properties that are relevant for such
systems, namely, platform-wide attestation and platform awareness. These
properties allow a remote verifier to verify the current state and to define
how the enclave reacts upon a change in connected peripherals. Finally, we
present a prototype based on RISC-V's Keystone to show that such systems are
feasible with only around 350 lines added to the software TCB.
"
1769,NV-Fogstore : Device-aware hybrid caching in fog computing environments,"  Edge caching via the placement of distributed storages throughout the network
is a promising solution to reduce latency and network costs of content
delivery. With the advent of the upcoming 5G future, billions of F-RAN
(Fog-Radio Access Network) nodes will created and used for for the purpose of
Edge Caching. Hence, the total amount of memory deployed at the edge is
expected to increase 100 times.
  Currently, used DRAM-based caches in CDN (Content Delivery Networks) are
extremely power-hungry and costly. Our purpose is to reduce the cost of
ownership and recurring costs (of power consumption) in an F-RAN node while
maintaining Quality of Service.
  For our purpose, we propose NV-FogStore, a scalable hybrid key-value storage
architecture for the utilization of Non-Volatile Memories (such as RRAM, MRAM,
Intel Optane) in Edge Cache.
  We further describe in detail a novel, hierarchical, write-damage, size and
frequency aware content caching policy H-GREEDY for our architecture.
  We show that our policy can be tuned as per performance objectives, to lower
the power, energy consumption and total cost over an only DRAM-based system for
only a relatively smaller trade-off in the average access latency.
"
1770,"Slim NoC: A Low-Diameter On-Chip Network Topology for High Energy
  Efficiency and Scalability","  Emerging chips with hundreds and thousands of cores require networks with
unprecedented energy/area efficiency and scalability. To address this, we
propose Slim NoC (SN): a new on-chip network design that delivers significant
improvements in efficiency and scalability compared to the state-of-the-art.
The key idea is to use two concepts from graph and number theory,
degree-diameter graphs combined with non-prime finite fields, to enable the
smallest number of ports for a given core count. SN is inspired by
state-of-the-art off-chip topologies; it identifies and distills their
advantages for NoC settings while solving several key issues that lead to
significant overheads on-chip. SN provides NoC-specific layouts, which further
enhance area/energy efficiency. We show how to augment SN with state-of-the-art
router microarchitecture schemes such as Elastic Links, to make the network
even more scalable and efficient. Our extensive experimental evaluations show
that SN outperforms both traditional low-radix topologies (e.g., meshes and
tori) and modern high-radix networks (e.g., various Flattened Butterflies) in
area, latency, throughput, and static/dynamic power consumption for both
synthetic and real workloads. SN provides a promising direction in scalable and
energy-efficient NoC topologies.
"
1771,"A Very Compact Embedded CNN Processor Design Based on Logarithmic
  Computing","  In this paper, we propose a very compact embedded CNN processor design based
on a modified logarithmic computing method using very low bit-width
representation. Our high-quality CNN processor can easily fit into edge
devices. For Yolov2, our processing circuit takes only 0.15 mm2 using TSMC 40
nm cell library. The key idea is to constrain the activation and weight values
of all layers uniformly to be within the range [-1, 1] and produce low
bit-width logarithmic representation. With the uniform representations, we
devise a unified, reusable CNN computing kernel and significantly reduce
computing resources. The proposed approach has been extensively evaluated on
many popular image classification CNN models (AlexNet, VGG16, and ResNet-18/34)
and object detection models (Yolov2). The hardware-implemented results show
that our design consumes only minimal computing and storage resources, yet
attains very high accuracy. The design is thoroughly verified on FPGAs, and the
SoC integration is underway with promising results. With extremely efficient
resource and energy usage, our design is excellent for edge computing purposes.
"
1772,"Ultra-low power on-chip learning of speech commands with phase-change
  memories","  Embedding artificial intelligence at the edge (edge-AI) is an elegant
solution to tackle the power and latency issues in the rapidly expanding
Internet of Things. As edge devices typically spend most of their time in sleep
mode and only wake-up infrequently to collect and process sensor data,
non-volatile in-memory computing (NVIMC) is a promising approach to design the
next generation of edge-AI devices. Recently, we proposed an NVIMC-based
neuromorphic accelerator using the phase change memories (PCMs), which we call
as Raven. In this work, we demonstrate the ultra-low-power on-chip training and
inference of speech commands using Raven. We showed that Raven can be trained
on-chip with power consumption as low as 30~uW, which is suitable for edge
applications. Furthermore, we showed that at iso-accuracies, Raven needs 70.36x
and 269.23x less number of computations to be performed than a deep neural
network (DNN) during inference and training, respectively. Owing to such low
power and computational requirements, Raven provides a promising pathway
towards ultra-low-power training and inference at the edge.
"
1773,"The nanoPU: Redesigning the CPU-Network Interface to Minimize RPC Tail
  Latency","  The nanoPU is a new networking-optimized CPU designed to minimize tail
latency for RPCs. By bypassing the cache and memory hierarchy, the nanoPU
directly places arriving messages into the CPU register file. The wire-to-wire
latency through the application is just 65ns, about 13x faster than the current
state-of-the-art. The nanoPU moves key functions from software to hardware:
reliable network transport, congestion control, core selection, and thread
scheduling. It also supports a unique feature to bound the tail latency
experienced by high-priority applications. Our prototype nanoPU is based on a
modified RISC-V CPU; we evaluate its performance using cycle-accurate
simulations of 324 cores on AWS FPGAs, including real applications (MICA and
chain replication).
"
1774,Efficient Floating-Point Givens Rotation Unit,"  High-throughput QR decomposition is a key operation in many advanced signal
processing and communication applications. For some of these applications,
using floating-point computation is becoming almost compulsory. However, there
are scarce works in hardware implementations of floating-point QR decomposition
for embedded systems. In this paper, we propose a very efficient
high-throughput floating-point Givens rotation unit for QR decomposition.
Moreover, the initial proposed design for conventional number formats is
enhanced by using the new Half-Unit Biased format. The provided error analysis
shows the effectiveness of our proposals and the trade-off of different
implementation parameters. FPGA implementation results are also presented and a
thorough comparison between both approaches. These implementation results also
reveal outstanding improvements compared to other previous similar designs in
terms of area, latency, and throughput.
"
1775,"MARS: Multi-macro Architecture SRAM CIM-Based Accelerator with
  Co-designed Compressed Neural Networks","  Convolutional neural networks (CNNs) play a key role in deep learning
applications. However, the large storage overheads and the substantial
computation cost of CNNs are problematic in hardware accelerators.
Computing-in-memory (CIM) architecture has demonstrated great potential to
effectively compute large-scale matrix-vector multiplication. However, the
intensive multiply and accumulation (MAC) operations executed at the crossbar
array and the limited capacity of CIM macros remain bottlenecks for further
improvement of energy efficiency and throughput. To reduce computation costs,
network pruning and quantization are two widely studied compression methods to
shrink the model size. However, most of the model compression algorithms can
only be implemented in digital-based CNN accelerators. For implementation in a
static random access memory (SRAM) CIM-based accelerator, the model compression
algorithm must consider the hardware limitations of CIM macros, such as the
number of word lines and bit lines that can be turned on at the same time, as
well as how to map the weight to the SRAM CIM macro. In this study, a software
and hardware co-design approach is proposed to design an SRAM CIM-based CNN
accelerator and an SRAM CIM-aware model compression algorithm. To lessen the
high-precision MAC required by batch normalization (BN), a quantization
algorithm that can fuse BN into the weights is proposed. Furthermore, to reduce
the number of network parameters, a sparsity algorithm that considers a CIM
architecture is proposed. Last, MARS, a CIM-based CNN accelerator that can
utilize multiple SRAM CIM macros as processing units and support a sparsity
neural network, is proposed.
"
1776,"ExPAN(N)D: Exploring Posits for Efficient Artificial Neural Network
  Design in FPGA-based Systems","  The recent advances in machine learning, in general, and Artificial Neural
Networks (ANN), in particular, has made smart embedded systems an attractive
option for a larger number of application areas. However, the high
computational complexity, memory footprints, and energy requirements of machine
learning models hinder their deployment on resource-constrained embedded
systems. Most state-of-the-art works have considered this problem by proposing
various low bit-width data representation schemes, optimized arithmetic
operators' implementations, and different complexity reduction techniques such
as network pruning. To further elevate the implementation gains offered by
these individual techniques, there is a need to cross-examine and combine these
techniques' unique features. This paper presents ExPAN(N)D, a framework to
analyze and ingather the efficacy of the Posit number representation scheme and
the efficiency of fixed-point arithmetic implementations for ANNs. The Posit
scheme offers a better dynamic range and higher precision for various
applications than IEEE $754$ single-precision floating-point format. However,
due to the dynamic nature of the various fields of the Posit scheme, the
corresponding arithmetic circuits have higher critical path delay and resource
requirements than the single-precision-based arithmetic units. Towards this
end, we propose a novel Posit to fixed-point converter for enabling
high-performance and energy-efficient hardware implementations for ANNs with
minimal drop in the output accuracy. We also propose a modified Posit-based
representation to store the trained parameters of a network. Compared to an
$8$-bit fixed-point-based inference accelerator, our proposed implementation
offers $\approx46\%$ and $\approx18\%$ reductions in the storage requirements
of the parameters and energy consumption of the MAC units, respectively.
"
1777,"Tensor Casting: Co-Designing Algorithm-Architecture for Personalized
  Recommendation Training","  Personalized recommendations are one of the most widely deployed machine
learning (ML) workload serviced from cloud datacenters. As such, architectural
solutions for high-performance recommendation inference have recently been the
target of several prior literatures. Unfortunately, little have been explored
and understood regarding the training side of this emerging ML workload. In
this paper, we first perform a detailed workload characterization study on
training recommendations, root-causing sparse embedding layer training as one
of the most significant performance bottlenecks. We then propose our
algorithm-architecture co-design called Tensor Casting, which enables the
development of a generic accelerator architecture for tensor gather-scatter
that encompasses all the key primitives of training embedding layers. When
prototyped on a real CPU-GPU system, Tensor Casting provides 1.9-21x
improvements in training throughput compared to state-of-the-art approaches.
"
1778,"LazyBatching: An SLA-aware Batching System for Cloud Machine Learning
  Inference","  In cloud ML inference systems, batching is an essential technique to increase
throughput which helps optimize total-cost-of-ownership. Prior graph batching
combines the individual DNN graphs into a single one, allowing multiple inputs
to be concurrently executed in parallel. We observe that the coarse-grained
graph batching becomes suboptimal in effectively handling the dynamic inference
request traffic, leaving significant performance left on the table. This paper
proposes LazyBatching, an SLA-aware batching system that considers both
scheduling and batching in the granularity of individual graph nodes, rather
than the entire graph for flexible batching. We show that LazyBatching can
intelligently determine the set of nodes that can be efficiently batched
together, achieving an average 15x, 1.5x, and 5.5x improvement than graph
batching in terms of average response time, throughput, and SLA satisfaction,
respectively.
"
1779,Security Assessment of Interposer-based Chiplet Integration,"  With transistor scaling reaching its limits, interposer-based integration of
dies (chiplets) is gaining traction. Such an interposer-based integration
enables finer and tighter interconnect pitch than traditional
system-on-packages and offers two key benefits: 1. It reduces design-to-market
time by bypassing the time-consuming process of verification and fabrication.
2. It reduces the design cost by reusing chiplets. While black-boxing of the
slow design stages cuts down the design time, it raises significant security
concerns. We study the security implications of the emerging interposer-based
integration methodology. The black-boxed design stages deploy security measures
against hardware Trojans, reverse engineering, and intellectual property piracy
in traditional systems-on-chip (SoC) designs and hence are not suitable for
interposer-based integration. We propose using functionally diverse chiplets to
detect and thwart hardware Trojans and use the inherent logic redundancy to
shore up anti-piracy measures. Our proposals do not rely on access to the
black-box design stages. We evaluate the security, time and cost benefits of
our plan by implementing a MIPS processor, a DCT core, and an AES core using
various IPs from the Xilinx CORE GENERATOR IP catalog, on an interposer-based
Xilinx FPGA.
"
1780,"Performance Analysis of Scientific Computing Workloads on Trusted
  Execution Environments","  Scientific computing sometimes involves computation on sensitive data.
Depending on the data and the execution environment, the HPC (high-performance
computing) user or data provider may require confidentiality and/or integrity
guarantees. To study the applicability of hardware-based trusted execution
environments (TEEs) to enable secure scientific computing, we deeply analyze
the performance impact of AMD SEV and Intel SGX for diverse HPC benchmarks
including traditional scientific computing, machine learning, graph analytics,
and emerging scientific computing workloads. We observe three main findings: 1)
SEV requires careful memory placement on large scale NUMA machines
(1$\times$$-$3.4$\times$ slowdown without and 1$\times$$-$1.15$\times$ slowdown
with NUMA aware placement), 2) virtualization$-$a prerequisite for
SEV$-$results in performance degradation for workloads with irregular memory
accesses and large working sets (1$\times$$-$4$\times$ slowdown compared to
native execution for graph applications) and 3) SGX is inappropriate for HPC
given its limited secure memory size and inflexible programming model
(1.2$\times$$-$126$\times$ slowdown over unsecure execution). Finally, we
discuss forthcoming new TEE designs and their potential impact on scientific
computing.
"
1781,"RNNAccel: A Fusion Recurrent Neural Network Accelerator for Edge
  Intelligence","  Many edge devices employ Recurrent Neural Networks (RNN) to enhance their
product intelligence. However, the increasing computation complexity poses
challenges for performance, energy efficiency and product development time. In
this paper, we present an RNN deep learning accelerator, called RNNAccel, which
supports Long Short-Term Memory (LSTM) network, Gated Recurrent Unit (GRU)
network, and Fully Connected Layer (FC)/ Multiple-Perceptron Layer (MLP)
networks. This RNN accelerator addresses (1) computing unit utilization
bottleneck caused by RNN data dependency, (2) inflexible design for specific
applications, (3) energy consumption dominated by memory access, (4) accuracy
loss due to coefficient compression, and (5) unpredictable performance
resulting from processor-accelerator integration. Our proposed RNN accelerator
consists of a configurable 32-MAC array and a coefficient decompression engine.
The MAC array can be scaled-up to meet throughput requirement and power budget.
Its sophisticated off-line compression and simple hardware-friendly on-line
decompression, called NeuCompression, reduces memory footprint up to 16x and
decreases memory access power. Furthermore, for easy SOC integration, we
developed a tool set for bit-accurate simulation and integration result
validation. Evaluated using a keyword spotting application, the 32-MAC RNN
accelerator achieves 90% MAC utilization, 1.27 TOPs/W at 40nm process, 8x
compression ratio, and 90% inference accuracy.
"
1782,Exploring Memory Access Patterns for Graph Processing Accelerators,"  Recent trends in business and technology (e.g., machine learning, social
network analysis) benefit from storing and processing growing amounts of
graph-structured data in databases and data science platforms. FPGAs as
accelerators for graph processing with a customizable memory hierarchy promise
solving performance problems caused by inherent irregular memory access
patterns on traditional hardware (e.g., CPU). However, developing such hardware
accelerators is yet time-consuming and difficult and benchmarking is
non-standardized, hindering comprehension of the impact of memory access
pattern changes and systematic engineering of graph processing accelerators.
  In this work, we propose a simulation environment for the analysis of graph
processing accelerators based on simulating their memory access patterns.
Further, we evaluate our approach on two state-of-the-art FPGA graph processing
accelerators and show reproducibility, comparablity, as well as the shortened
development process by an example. Not implementing the cycle-accurate internal
data flow on accelerator hardware like FPGAs significantly reduces the
implementation time, increases the benchmark parameter transparency, and allows
comparison of graph processing approaches.
"
1783,hXDP: Efficient Software Packet Processing on FPGA NICs,"  FPGA accelerators on the NIC enable the offloading of expensive packet
processing tasks from the CPU. However, FPGAs have limited resources that may
need to be shared among diverse applications, and programming them is
difficult.
  We present a solution to run Linux's eXpress Data Path programs written in
eBPF on FPGAs, using only a fraction of the available hardware resources while
matching the performance of high-end CPUs. The iterative execution model of
eBPF is not a good fit for FPGA accelerators. Nonetheless, we show that many of
the instructions of an eBPF program can be compressed, parallelized or
completely removed, when targeting a purpose-built FPGA executor, thereby
significantly improving performance. We leverage that to design hXDP, which
includes (i) an optimizing-compiler that parallelizes and translates eBPF
bytecode to an extended eBPF Instruction-set Architecture defined by us; a (ii)
soft-CPU to execute such instructions on FPGA; and (iii) an FPGA-based
infrastructure to provide XDP's maps and helper functions as defined within the
Linux kernel.
  We implement hXDP on an FPGA NIC and evaluate it running real-world
unmodified eBPF programs. Our implementation is clocked at 156.25MHz, uses
about 15% of the FPGA resources, and can run dynamically loaded programs.
Despite these modest requirements, it achieves the packet processing throughput
of a high-end CPU core and provides a 10x lower packet forwarding latency.
"
1784,$\mu$NAS: Constrained Neural Architecture Search for Microcontrollers,"  IoT devices are powered by microcontroller units (MCUs) which are extremely
resource-scarce: a typical MCU may have an underpowered processor and around 64
KB of memory and persistent storage, which is orders of magnitude fewer
computational resources than is typically required for deep learning. Designing
neural networks for such a platform requires an intricate balance between
keeping high predictive performance (accuracy) while achieving low memory and
storage usage and inference latency. This is extremely challenging to achieve
manually, so in this work, we build a neural architecture search (NAS) system,
called $\mu$NAS, to automate the design of such small-yet-powerful MCU-level
networks. $\mu$NAS explicitly targets the three primary aspects of resource
scarcity of MCUs: the size of RAM, persistent storage and processor speed.
$\mu$NAS represents a significant advance in resource-efficient models,
especially for ""mid-tier"" MCUs with memory requirements ranging from 0.5 KB to
64 KB. We show that on a variety of image classification datasets $\mu$NAS is
able to (a) improve top-1 classification accuracy by up to 4.8%, or (b) reduce
memory footprint by 4--13x, or (c) reduce the number of multiply-accumulate
operations by $\approx$900x, compared to existing MCU specialist literature and
resource-efficient models.
"
1785,Substream-Centric Maximum Matchings on FPGA,"  Developing high-performance and energy-efficient algorithms for maximum
matchings is becoming increasingly important in social network analysis,
computational sciences, scheduling, and others. In this work, we propose the
first maximum matching algorithm designed for FPGAs; it is energy-efficient and
has provable guarantees on accuracy, performance, and storage utilization. To
achieve this, we forego popular graph processing paradigms, such as
vertex-centric programming, that often entail large communication costs.
Instead, we propose a substream-centric approach, in which the input stream of
data is divided into substreams processed independently to enable more
parallelism while lowering communication costs. We base our work on the theory
of streaming graph algorithms and analyze 14 models and 28 algorithms. We use
this analysis to provide theoretical underpinning that matches the physical
constraints of FPGA platforms. Our algorithm delivers high performance (more
than 4x speedup over tuned parallel CPU variants), low memory, high accuracy,
and effective usage of FPGA resources. The substream-centric approach could
easily be extended to other algorithms to offer low-power and high-performance
graph processing on FPGAs.
"
1786,Analysis of Energy Consumption in a Precision Beekeeping System,"  Honey bees have been domesticated by humans for several thousand years and
mainly provide honey and pollination, which is fundamental for plant
reproduction. Nowadays, the work of beekeepers is constrained by external
factors that stress their production (parasites and pesticides among others).
Taking care of large numbers of beehives is time-consuming, so integrating
sensors to track their status can drastically simplify the work of beekeepers.
Precision bee-keeping complements beekeepers' work thanks to the In-ternet of
Things (IoT) technology. If used correctly, data can help to make the right
diagnosis for honey bees colony, increase honey production and decrease bee
mortality. Providing enough energy for on-hive and in-hive sensors is a
challenge. Some solutions rely on energy harvesting, others target usage of
large batteries. Either way, it is mandatory to analyze the energy usage of
embedded equipment in order to design an energy efficient and autonomous bee
monitoring system. This paper relies on a fully autonomous IoT framework that
collects environmental and image data of a beehive. It consists of a data
collecting node (environmental data sensors, camera, Raspberry Pi and Arduino)
and a solar energy supplying node. Supported services are analyzed task by task
from an energy profiling and efficiency standpoint , in order to identify the
highly pressured areas of the framework. This first step will guide our goal of
designing a sustainable precision beekeeping system, both technically and
energy-wise.
"
1787,FPGA Implementation of Stair Matrix based Massive MIMO Detection,"  Approximate matrix inversion based methods is widely used for linear massive
multiple-input multiple-output (MIMO) received symbol vector detection. Such
detectors typically utilize the diagonally dominant channel matrix of a massive
MIMO system. Instead of diagonal matrix, a stair matrix can be utilized to
improve the error-rate performance of a massive MIMO detector. In this paper,
we present very large-scale integration (VLSI) architecture and field
programmable gate array (FPGA) implementation of a stair matrix based iterative
detection algorithm. The architecture supports a base station with 128
antennas, 8 users with single antenna, and 256 quadrature amplitude modulation
(QAM). The stair matrix based detector can deliver a 142.34 Mbps data rate and
reach a clock frequency of 258 MHz in a Xilinx Virtex-7 FPGA. The detector
provides superior error-rate performance and higher scaled throughput than most
contemporary massive MIMO detectors.
"
1788,"RVCoreP-32IM: An effective architecture to implement mul/div
  instructions for five stage RISC-V soft processors","  RISC-V, an open instruction set architecture, is getting the attention of
soft processor developers. Implementing only a basic 32-bit integer instruction
set of RISC-V, which is defined as RV32I, might be satisfactory for embedded
systems. However, multiplication and division instructions are not present in
RV32I, rather than defined as M-extension. Several research projects have
proposed both RV32I and RV32IM processor. However, there is no indication of
how much performance can be improved by adding M-extension to RV32I. In other
words, when we should consider adding M-extension into the soft processor and
how much hardware resource requirements will increase.
  In this paper, we propose an extension of the RVCoreP soft processor (which
implements RV32I instruction set only) to support RISC-V M-extension
instructions. A simple fork-join method is used to expand the execution
capability to support M-extension instructions as well as a possible future
enhancement. We then perform the benchmark using Dhrystone, Coremark, and
Embench programs. We found that RV32IM is 1.87 and 3.13 times better in
performance for radix-4 and DSP multiplier, respectively. In addition to that,
our RV32IM implementation is 13\% better than the equivalent RISC-V processor.
"
1789,"Mitigating Write Disturbance Errors of Phase-Change Memory as In-Module
  Approach","  With the growing demand for technology scaling and storage capacity in server
systems to support high-performance computing, phase-change memory (PCM) has
garnered attention as the next-generation non-volatile memory to satisfy these
requirements. However, write disturbance error (WDE) appears as a serious
reliability problem preventing PCM from general commercialization. WDE occurs
on the neighboring cells of a written cell due to heat dissipation. Previous
studies for the prevention of WDEs are based on the write cache or
verify-n-correction while they often suffer from significant area overhead and
performance degradation, making it unsuitable for high-performance computing.
Therefore, an on-demand correction is required to minimize the performance
overhead. In this paper, an in-module disturbance barrier (IMDB) mitigating
WDEs is proposed. IMDB includes two sets of SRAMs into two levels and evicts
entries with a policy that leverages the characteristics of WDE. In this work,
the comparator dedicated to the replacement policy requires significant
hardware resources and latency. Thus, an approximate comparator is designed to
reduce the area and latency considerably. Furthermore, the exploration of
architecture parameters is conducted to obtain cost-effective design. The
proposed work significantly reduces WDEs without a noticeable speed degradation
and additional energy consumption compared to previous methods.
"
1790,RANC: Reconfigurable Architecture for Neuromorphic Computing,"  Neuromorphic architectures have been introduced as platforms for energy
efficient spiking neural network execution. The massive parallelism offered by
these architectures has also triggered interest from non-machine learning
application domains. In order to lift the barriers to entry for hardware
designers and application developers we present RANC: a Reconfigurable
Architecture for Neuromorphic Computing, an open-source highly flexible
ecosystem that enables rapid experimentation with neuromorphic architectures in
both software via C++ simulation and hardware via FPGA emulation. We present
the utility of the RANC ecosystem by showing its ability to recreate behavior
of the IBM's TrueNorth and validate with direct comparison to IBM's Compass
simulation environment and published literature. RANC allows optimizing
architectures based on application insights as well as prototyping future
neuromorphic architectures that can support new classes of applications
entirely. We demonstrate the highly parameterized and configurable nature of
RANC by studying the impact of architectural changes on improving application
mapping efficiency with quantitative analysis based on Alveo U250 FPGA. We
present post routing resource usage and throughput analysis across
implementations of Synthetic Aperture Radar classification and Vector Matrix
Multiplication applications, and demonstrate a neuromorphic architecture that
scales to emulating 259K distinct neurons and 73.3M distinct synapses.
"
1791,Addressing Resiliency of In-Memory Floating Point Computation,"  In-memory computing (IMC) can eliminate the data movement between processor
and memory which is a barrier to the energy-efficiency and performance in
Von-Neumann computing. Resistive RAM (RRAM) is one of the promising devices for
IMC applications (e.g. integer and Floating Point (FP) operations and random
logic implementation) due to low power consumption, fast operation, and small
footprint in crossbar architecture. In this paper, we propose FAME, a pipelined
FP arithmetic (adder/subtractor) using RRAM crossbar based IMC. A novel shift
circuitry is proposed to lower the shift overhead during FP operations. Since
96% of the RRAMs used in our architecture are in High Resistance State (HRS),
we propose two approaches namely Shift-At-The-Output (SATO) and Force To VDD
(FTV) (ground (FTG)) to mitigate Stuck-at-1 (SA1) failures. In both techniques,
the fault-free RRAMs are exploited to perform the computation by using an extra
clock cycle. Although performance degrades by 50%, SATO can handle 50% of the
faults whereas FTV can handle 99% of the faults in the RRAM-based compute array
at low power and area overhead. Simulation results show that the proposed
single precision FP adder consumes 335 pJ and 322 pJ for NAND-NAND and NOR-NOR
based implementations, respectively. The area overheads of SATO and FTV are
28.5% and 9.5%, respectively.
"
1792,"On the Impact of Partial Sums on Interconnect Bandwidth and Memory
  Accesses in a DNN Accelerator","  Dedicated accelerators are being designed to address the huge resource
requirement of the deep neural network (DNN) applications. The power,
performance and area (PPA) constraints limit the number of MACs available in
these accelerators. The convolution layers which require huge number of MACs
are often partitioned into multiple iterative sub-tasks. This puts huge
pressure on the available system resources such as interconnect and memory
bandwidth. The optimal partitioning of the feature maps for these sub-tasks can
reduce the bandwidth requirement substantially. Some accelerators avoid
off-chip or interconnect transfers by implementing local memories; however, the
memory accesses are still performed and a reduced bandwidth can help in saving
power in such architectures. In this paper, we propose a first order analytical
method to partition the feature maps for optimal bandwidth and evaluate the
impact of such partitioning on the bandwidth. This bandwidth can be saved by
designing an active memory controller which can perform basic arithmetic
operations. It is shown that the optimal partitioning and active memory
controller can achieve up to 40% bandwidth reduction.
"
1793,"SIMDive: Approximate SIMD Soft Multiplier-Divider for FPGAs with Tunable
  Accuracy","  The ever-increasing quest for data-level parallelism and variable precision
in ubiquitous multimedia and Deep Neural Network (DNN) applications has
motivated the use of Single Instruction, Multiple Data (SIMD) architectures. To
alleviate energy as their main resource constraint, approximate computing has
re-emerged,albeit mainly specialized for their Application-Specific Integrated
Circuit (ASIC) implementations. This paper, presents for the first time, an
SIMD architecture based on novel multiplier and divider with tunable accuracy,
targeted for Field-Programmable Gate Arrays (FPGAs). The proposed hybrid
architecture implements Mitchell's algorithms and supports precision
variability from 8 to 32 bits. Experimental results obtained from Vivado,
multimedia and DNN applications indicate superiority of proposed architecture
(both SISD and SIMD) over accurate and state-of-the-art approximate
counterparts. In particular, the proposed SISD divider outperforms the accurate
Intellectual Property (IP) divider provided by Xilinx with 4x higher speed and
4.6x less energy and tolerating only < 0.8% error. Moreover, the proposed SIMD
multiplier-divider supersede accurate SIMD multiplier by achieving up to 26%,
45%, 36%, and 56% improvement in area, throughput, power, and energy,
respectively.
"
1794,"CUTIE: Beyond PetaOp/s/W Ternary DNN Inference Acceleration with
  Better-than-Binary Energy Efficiency","  We present a 3.1 POp/s/W fully digital hardware accelerator for ternary
neural networks. CUTIE, the Completely Unrolled Ternary Inference Engine,
focuses on minimizing non-computational energy and switching activity so that
dynamic power spent on storing (locally or globally) intermediate results is
minimized. This is achieved by 1) a data path architecture completely unrolled
in the feature map and filter dimensions to reduce switching activity by
favoring silencing over iterative computation and maximizing data re-use, 2)
targeting ternary neural networks which, in contrast to binary NNs, allow for
sparse weights which reduce switching activity, and 3) introducing an optimized
training method for higher sparsity of the filter weights, resulting in a
further reduction of the switching activity. Compared with state-of-the-art
accelerators, CUTIE achieves greater or equal accuracy while decreasing the
overall core inference energy cost by a factor of 4.8x-21x.
"
1795,Booster: An Accelerator for Gradient Boosting Decision Trees,"  We propose Booster, a novel accelerator for gradient boosting trees based on
the unique characteristics of gradient boosting models. We observe that the
dominant steps of gradient boosting training (accounting for 90-98% of training
time) involve simple, fine-grained, independent operations on small-footprint
data structures (e.g., accumulate and compare values in the structures).
Unfortunately, existing multicores and GPUs are unable to harness this
parallelism because they do not support massively-parallel data structure
accesses that are irregular and data-dependent. By employing a scalable
sea-of-small-SRAMs approach and an SRAM bandwidth-preserving mapping of data
record fields to the SRAMs, Booster achieves significantly more parallelism
(e.g., 3200-way parallelism) than multicores and GPU. In addition, Booster
employs a redundant data representation that significantly lowers the memory
bandwidth demand. Our simulations reveal that Booster achieves 11.4x speedup
and 6.4x speedup over an ideal 32-core multicore and an ideal GPU,
respectively. Based on ASIC synthesis of FPGA-validated RTL using 45 nm
technology, we estimate a Booster chip to occupy 60 mm^2 of area and dissipate
23 W when operating at 1-GHz clock speed.
"
1796,"An Empirical-cum-Statistical Approach to Power-Performance
  Characterization of Concurrent GPU Kernels","  Growing deployment of power and energy efficient throughput accelerators
(GPU) in data centers demands enhancement of power-performance co-optimization
capabilities of GPUs. Realization of exascale computing using accelerators
requires further improvements in power efficiency. With hardwired kernel
concurrency enablement in accelerators, inter- and intra-workload simultaneous
kernels computation predicts increased throughput at lower energy budget. To
improve Performance-per-Watt metric of the architectures, a systematic
empirical study of real-world throughput workloads (with concurrent kernel
execution) is required. To this end, we propose a multi-kernel throughput
workload generation framework that will facilitate aggressive energy and
performance management of exascale data centers and will stimulate synergistic
power-performance co-optimization of throughput architectures. Also, we
demonstrate a multi-kernel throughput benchmark suite based on the framework
that encapsulates symmetric, asymmetric and co-existing (often appears
together) kernel based workloads. On average, our analysis reveals that spatial
and temporal concurrency within kernel execution in throughput architectures
saves energy consumption by 32%, 26% and 33% in GTX470, Tesla M2050 and Tesla
K20 across 12 benchmarks. Concurrency and enhanced utilization are often
correlated but do not imply significant deviation in power dissipation.
Diversity analysis of proposed multi-kernels confirms characteristic variation
and power-profile diversity within the suite. Besides, we explain several
findings regarding power-performance co-optimization of concurrent throughput
workloads.
"
1797,"Predict and Write: Using K-Means Clustering to Extend the Lifetime of
  NVM Storage","  Non-volatile memory (NVM) technologies suffer from limited write endurance.
To address this challenge, we propose Predict and Write (PNW), a K/V-store that
uses a clustering-based machine learning approach to extend the lifetime of
NVMs. PNW decreases the number of bit flips for PUT/UPDATE operations by
determining the best memory location an updated value should be written to. PNW
leverages the indirection level of K/V-stores to freely choose the target
memory location for any given write based on its value. PNW organizes NVM
addresses in a dynamic address pool clustered by the similarity of the data
values they refer to. We show that, by choosing the right target memory
location for a given PUT/UPDATE operation, the number of total bit flips and
cache lines can be reduced by up to 85% and 56% over the state of the art.
"
1798,Chasing Carbon: The Elusive Environmental Footprint of Computing,"  Given recent algorithm, software, and hardware innovation, computing has
enabled a plethora of new applications. As computing becomes increasingly
ubiquitous, however, so does its environmental impact. This paper brings the
issue to the attention of computer-systems researchers. Our analysis, built on
industry-reported characterization, quantifies the environmental effects of
computing in terms of carbon emissions. Broadly, carbon emissions have two
sources: operational energy consumption, and hardware manufacturing and
infrastructure. Although carbon emissions from the former are decreasing thanks
to algorithmic, software, and hardware innovations that boost performance and
power efficiency, the overall carbon footprint of computer systems continues to
grow. This work quantifies the carbon output of computer systems to show that
most emissions related to modern mobile and data-center equipment come from
hardware manufacturing and infrastructure. We therefore outline future
directions for minimizing the environmental impact of computing systems.
"
1799,ReFloat: Low-Cost Floating-Point Processing in ReRAM,"  We propose ReFloat, a principled approach for low-cost floating-point
processing in ReRAM. The exponent offsets based on a base are stored by a
flexible and fine-grained floating-point number representation. The key
motivation is that, while the number of exponent bits must be reduced due to
the exponential relation to the computation latency and hardware cost, the
convergence still requires sufficient accuracy for exponents. Our design
reconciles the conflicting goals by storing the exponent offsets from a common
base among matrix values in a block, which is the granularity of computation in
ReRAM. Due to the value locality, the differences among the exponents in a
block are small, thus the offsets require much less number of bits to represent
exponents. In essence, ReFloat enables the principled local fine-tuning of
floating-point representation. Based on the idea, we define a flexible ReFloat
format that specifies matrix block size, and the number of bits for exponent
and fraction. To determine the base for each block, we propose an optimization
method that minimizes the difference between the exponents of the original
matrix block and the converted block. We develop the conversion scheme from
default double-precision floating-point format to ReFloat format, the
computation procedure, and the low-cost floating-point processing architecture
in ReRAM.
"
1800,Strawberry Detection Using a Heterogeneous Multi-Processor Platform,"  Over the last few years, the number of precision farming projects has
increased specifically in harvesting robots and many of which have made
continued progress from identifying crops to grasping the desired fruit or
vegetable. One of the most common issues found in precision farming projects is
that successful application is heavily dependent not just on identifying the
fruit but also on ensuring that localisation allows for accurate navigation.
These issues become significant factors when the robot is not operating in a
prearranged environment, or when vegetation becomes too thick, thus covering
crop. Moreover, running a state-of-the-art deep learning algorithm on an
embedded platform is also very challenging, resulting most of the times in low
frame rates. This paper proposes using the You Only Look Once version 3
(YOLOv3) Convolutional Neural Network (CNN) in combination with utilising image
processing techniques for the application of precision farming robots targeting
strawberry detection, accelerated on a heterogeneous multiprocessor platform.
The results show a performance acceleration by five times when implemented on a
Field-Programmable Gate Array (FPGA) when compared with the same algorithm
running on the processor side with an accuracy of 78.3\% over the test set
comprised of 146 images.
"
1801,"EHAP-ORAM: Efficient Hardware-Assisted Persistent ORAM System for
  Non-volatile Memory","  Oblivious RAM (ORAM) protected access pattern is essential for secure NVM. In
the ORAM system, data and PosMap metadata are maps in pairs to perform secure
access. Therefore, we focus on the problem of crash consistency in the ORAM
system. Unfortunately, using traditional software-based support for ORAM system
crash consistency is not only expensive, it can also lead to information leaks.
At present, there is no relevant research on the specific crash consistency
mechanism supporting the ORAM system. To support crash consistency without
damaging ORAM system security and compromising the performance, we propose
EHAP-ORAM. Firstly, we analyze the access steps of basic ORAM to obtain the
basic requirements to support the ORAM system crash consistency. Secondly,
improve the ORAM controller. Thirdly, for the improved hardware system, we
propose several persistence protocols supporting the ORAM system crash
consistency. Finally, we compared our persistent ORAM with the system without
crash consistency support, non-recursive and recursive EHAP-ORAM only incurs
3.36% and 3.65% performance overhead. The results show that EHAP-ORAM not only
supports effective crash consistency with minimal performance and hardware
overhead but also is friendly to NVM lifetime.
"
1802,"Towards Latency-aware DNN Optimization with GPU Runtime Analysis and
  Tail Effect Elimination","  Despite the superb performance of State-Of-The-Art (SOTA) DNNs, the
increasing computational cost makes them very challenging to meet real-time
latency and accuracy requirements. Although DNN runtime latency is dictated by
model property (e.g., architecture, operations), hardware property (e.g.,
utilization, throughput), and more importantly, the effective mapping between
these two, many existing approaches focus only on optimizing model property
such as FLOPS reduction and overlook the mismatch between DNN model and
hardware properties. In this work, we show that the mismatch between the varied
DNN computation workloads and GPU capacity can cause the idle GPU tail effect,
leading to GPU under-utilization and low throughput. As a result, the FLOPs
reduction cannot bring effective latency reduction, which causes sub-optimal
accuracy versus latency trade-offs. Motivated by this, we propose a GPU
runtime-aware DNN optimization methodology to eliminate such GPU tail effect
adaptively on GPU platforms. Our methodology can be applied on top of existing
SOTA DNN optimization approaches to achieve better latency and accuracy
trade-offs. Experiments show 11%-27% latency reduction and 2.5%-4.0% accuracy
improvement over several SOTA DNN pruning and NAS methods, respectively
"
1803,"Graphene-based Wireless Agile Interconnects for Massive Heterogeneous
  Multi-chip Processors","  The main design principles in computer architecture have recently shifted
from a monolithic scaling-driven approach to the development of heterogeneous
architectures that tightly co-integrate multiple specialized processor and
memory chiplets. In such data-hungry multi-chip architectures, current
Networks-in-Package (NiPs) may not be enough to cater to their heterogeneous
and fast-changing communication demands. This position paper makes the case for
wireless in-package nanonetworking as the enabler of efficient and versatile
wired-wireless interconnect fabrics for massive heterogeneous processors. To
that end, the use of graphene-based antennas and transceivers with unique
frequency-beam reconfigurability in the terahertz band is proposed. The
feasibility of such a nanonetworking vision and the main research challenges
towards its realization are analyzed from the technological, communications,
and computer architecture perspectives.
"
1804,Runtime Performances Benchmark for Knowledge Graph Embedding Methods,"  This paper wants to focus on providing a characterization of the runtime
performances of state-of-the-art implementations of KGE alghoritms, in terms of
memory footprint and execution time. Despite the rapidly growing interest in
KGE methods, so far little attention has been devoted to their comparison and
evaluation; in particular, previous work mainly focused on performance in terms
of accuracy in specific tasks, such as link prediction. To this extent, a
framework is proposed for evaluating available KGE implementations against
graphs with different properties, with a particular focus on the effectiveness
of the adopted optimization strategies. Graphs and models have been trained
leveraging different architectures, in order to enlighten features and
properties of both models and the architectures they have been trained on. Some
results enlightened with experiments in this document are the fact that
multithreading is efficient, but benefit deacreases as the number of threads
grows in case of CPU. GPU proves to be the best architecture for the given
task, even if CPU with some vectorized instructions still behaves well.
Finally, RAM utilization for the loading of the graph never changes between
different architectures and depends only on the type of graph, not on the
model.
"
1805,FPGA-based Hyrbid Memory Emulation System,"  Hybrid memory systems, comprised of emerging non-volatile memory (NVM) and
DRAM, have been proposed to address the growing memory demand of applications.
Emerging NVM technologies, such as phase-change memories (PCM), memristor, and
3D XPoint, have higher capacity density, minimal static power consumption and
lower cost per GB. However, NVM has longer access latency and limited write
endurance as opposed to DRAM. The different characteristics of two memory
classes point towards the design of hybrid memory systems containing multiple
classes of main memory.
  In the iterative and incremental development of new architectures, the
timeliness of simulation completion is critical to project progression. Hence,
a highly efficient simulation method is needed to evaluate the performance of
different hybrid memory system designs. Design exploration for hybrid memory
systems is challenging, because it requires emulation of the full system stack,
including the OS, memory controller, and interconnect. Moreover, benchmark
applications for memory performance test typically have much larger working
sets, thus taking even longer simulation warm-up period.
  In this paper, we propose a FPGA-based hybrid memory system emulation
platform. We target at the mobile computing system, which is sensitive to
energy consumption and is likely to adopt NVM for its power efficiency. Here,
because the focus of our platform is on the design of the hybrid memory system,
we leverage the on-board hard IP ARM processors to both improve simulation
performance while improving accuracy of the results. Thus, users can implement
their data placement/migration policies with the FPGA logic elements and
evaluate new designs quickly and effectively. Results show that our emulation
platform provides a speedup of 9280x in simulation time compared to the
software counterpart Gem5.
"
1806,"von Neumann's missing ""Second Draft"": what it should contain","  Computing science is based on a computing paradigm that is not valid anymore
for today's technological conditions. The reason is that the transmission time
even inside the processor chip, but especially between the components of the
system, is not negligible anymore. The paper introduces a quantitative measure
for dispersion, which is vital for both computing performance and energy
consumption, and demonstrates how its value increased with the changing
technology. The temporal behavior (including the dispersion of the commonly
used synchronization clock time) of computing components has a critical impact
on the system's performance at all levels, as demonstrated from gate-level
operation to supercomputing. The same effect limits the utility of the
researched new materials/effects if the related transfer time cannot be
proportionally mitigated. von Neumann's model is perfect, but now it is used
outside of its range of validity. The correct procedure to consider the
transfer time for the present technological background is also derived.
"
1807,"ARENA: Asynchronous Reconfigurable Accelerator Ring to Enable
  Data-Centric Parallel Computing","  The next generation HPC and data centers are likely to be reconfigurable and
data-centric due to the trend of hardware specialization and the emergence of
data-driven applications. In this paper, we propose ARENA -- an asynchronous
reconfigurable accelerator ring architecture as a potential scenario on how the
future HPC and data centers will be like. Despite using the coarse-grained
reconfigurable arrays (CGRAs) as the substrate platform, our key contribution
is not only the CGRA-cluster design itself, but also the ensemble of a new
architecture and programming model that enables asynchronous tasking across a
cluster of reconfigurable nodes, so as to bring specialized computation to the
data rather than the reverse. We presume distributed data storage without
asserting any prior knowledge on the data distribution. Hardware specialization
occurs at runtime when a task finds the majority of data it requires are
available at the present node. In other words, we dynamically generate
specialized CGRA accelerators where the data reside. The asynchronous tasking
for bringing computation to data is achieved by circulating the task token,
which describes the data-flow graphs to be executed for a task, among the CGRA
cluster connected by a fast ring network. Evaluations on a set of HPC and
data-driven applications across different domains show that ARENA can provide
better parallel scalability with reduced data movement (53.9%). Compared with
contemporary compute-centric parallel models, ARENA can bring on average 4.37x
speedup. The synthesized CGRAs and their task-dispatchers only occupy 2.93mm^2
chip area under 45nm process technology and can run at 800MHz with on average
759.8mW power consumption. ARENA also supports the concurrent execution of
multi-applications, offering ideal architectural support for future
high-performance parallel computing and data analytics systems.
"
1808,Mapping Stencils on Coarse-grained Reconfigurable Spatial Architecture,"  Stencils represent a class of computational patterns where an output grid
point depends on a fixed shape of neighboring points in an input grid. Stencil
computations are prevalent in scientific applications engaging a significant
portion of supercomputing resources. Therefore, it has been always important to
optimize stencil programs for the best performance. A rich body of research has
focused on optimizing stencil computations on almost all parallel
architectures. Stencil applications have regular dependency patterns, inherent
pipeline-parallelism, and plenty of data reuse. This makes these applications a
perfect match for a coarse-grained reconfigurable spatial architecture (CGRA).
A CGRA consists of many simple, small processing elements (PEs) connected with
an on-chip network. Each PE can be configured to execute part of a stencil
computation and all PEs run in parallel; the network can also be configured so
that data loaded can be passed from a PE to a neighbor PE directly and thus
reused by many PEs without register spilling and memory traffic. How to
efficiently map a stencil computation to a CGRA is the key to performance. In
this paper, we show a few unique and generalizable ways of mapping one- and
multidimensional stencil computations to a CGRA, fully exploiting the data
reuse opportunities and parallelism. Our simulation experiments demonstrate
that these mappings are efficient and enable the CGRA to outperform
state-of-the-art GPUs.
"
1809,"Coherence Traffic in Manycore Processors with Opaque Distributed
  Directories","  Manycore processors feature a high number of general-purpose cores designed
to work in a multithreaded fashion. Recent manycore processors are kept
coherent using scalable distributed directories. A paramount example is the
Intel Mesh interconnect, which consists of a network-on-chip interconnecting
""tiles"", each of which contains computation cores, local caches, and coherence
masters. The distributed coherence subsystem must be queried for every
out-of-tile access, imposing an overhead on memory latency. This paper studies
the physical layout of an Intel Knights Landing processor, with a particular
focus on the coherence subsystem, and uncovers the pseudo-random mapping
function of physical memory blocks across the pieces of the distributed
directory. Leveraging this knowledge, candidate optimizations to improve memory
latency through the minimization of coherence traffic are studied. Although
these optimizations do improve memory throughput, ultimately this does not
translate into performance gains due to inherent overheads stemming from the
computational complexity of the mapping functions.
"
1810,"Understanding Training Efficiency of Deep Learning Recommendation Models
  at Scale","  The use of GPUs has proliferated for machine learning workflows and is now
considered mainstream for many deep learning models. Meanwhile, when training
state-of-the-art personal recommendation models, which consume the highest
number of compute cycles at our large-scale datacenters, the use of GPUs came
with various challenges due to having both compute-intensive and
memory-intensive components. GPU performance and efficiency of these
recommendation models are largely affected by model architecture configurations
such as dense and sparse features, MLP dimensions. Furthermore, these models
often contain large embedding tables that do not fit into limited GPU memory.
The goal of this paper is to explain the intricacies of using GPUs for training
recommendation models, factors affecting hardware efficiency at scale, and
learnings from a new scale-up GPU server design, Zion.
"
1811,"Customizing Trusted AI Accelerators for Efficient Privacy-Preserving
  Machine Learning","  The use of trusted hardware has become a promising solution to enable
privacy-preserving machine learning. In particular, users can upload their
private data and models to a hardware-enforced trusted execution environment
(e.g. an enclave in Intel SGX-enabled CPUs) and run machine learning tasks in
it with confidentiality and integrity guaranteed. To improve performance, AI
accelerators have been widely employed for modern machine learning tasks.
However, how to protect privacy on an AI accelerator remains an open question.
To address this question, we propose a solution for efficient
privacy-preserving machine learning based on an unmodified trusted CPU and a
customized trusted AI accelerator. We carefully leverage cryptographic
primitives to establish trust and protect the channel between the CPU and the
accelerator. As a case study, we demonstrate our solution based on the
open-source versatile tensor accelerator. The result of evaluation shows that
the proposed solution provides efficient privacy-preserving machine learning at
a small design cost and moderate performance overhead.
"
1812,Memory-Efficient Dataflow Inference for Deep CNNs on FPGA,"  Custom dataflow Convolutional Neural Network (CNN) inference accelerators on
FPGA are tailored to a specific CNN topology and store parameters in On-Chip
Memory (OCM), resulting in high energy efficiency and low inference latency.
However, in these accelerators the shapes of parameter memories are dictated by
throughput constraints and do not map well to the underlying OCM, which becomes
an implementation bottleneck. In this work, we propose an accelerator design
methodology - Frequency Compensated Memory Packing (FCMP) - which improves the
OCM utilization efficiency of dataflow accelerators with minimal reduction in
throughput and no modifications to the physical structure of FPGA OCM. To
validate our methodology, we apply it to several realizations of medium-sized
CIFAR-10 inference accelerators and demonstrate up to 30% reduction in OCM
utilization without loss of inference throughput, allowing us to port the
accelerators from Xilinx Zynq 7020 to 7012S, reducing application cost. We also
implement a custom dataflow FPGA inference accelerator for a quantized
ResNet-50 CNN, utilizing on-chip weights, the largest topology ever implemented
with this accelerator architecture. We demonstrate that by applying FCMP to the
ResNet accelerator, the OCM bottleneck is alleviated which enables the
accelerator to be ported from Alveo U250 to the smaller Alveo U280 board with
less throughput loss compared to alternative techniques. By providing a
finer-grained trade off between throughput and OCM requirements, FCMP increases
the flexibility of custom dataflow CNN inference designs on FPGA.
"
1813,"Channel Tiling for Improved Performance and Accuracy of Optical Neural
  Network Accelerators","  Low latency, high throughput inference on Convolution Neural Networks (CNNs)
remains a challenge, especially for applications requiring large input or large
kernel sizes. 4F optics provides a solution to accelerate CNNs by converting
convolutions into Fourier-domain point-wise multiplications that are
computationally 'free' in optical domain. However, existing 4F CNN systems
suffer from the all-positive sensor readout issue which makes the
implementation of a multi-channel, multi-layer CNN not scalable or even
impractical. In this paper we propose a simple channel tiling scheme for 4F CNN
systems that utilizes the high resolution of 4F system to perform channel
summation inherently in optical domain before sensor detection, so the outputs
of different channels can be correctly accumulated. Compared to state of the
art, channel tiling gives similar accuracy, significantly better robustness to
sensing quantization (33\% improvement in required sensing precision) error and
noise (10dB reduction in tolerable sensing noise), 0.5X total filters required,
10-50X+ throughput improvement and as much as 3X reduction in required output
camera resolution/bandwidth. Not requiring any additional optical hardware, the
proposed channel tiling approach addresses an important throughput and
precision bottleneck of high-speed, massively-parallel optical 4F computing
systems.
"
1814,"Tiny-CFA: A Minimalistic Approach for Control-Flow Attestation Using
  Verified Proofs of Execution","  The design of tiny trust anchors has received significant attention over the
past decade, to secure low-end MCU-s that cannot afford expensive security
mechanisms. In particular, hardware/software (hybrid) co-designs offer low
hardware cost, while retaining similar security guarantees as (more expensive)
hardware-based techniques. Hybrid trust anchors support security services, such
as remote attestation, proofs of software update/erasure/reset, proofs of
remote software execution, in resource-constrained MCU-s, e.g., MSP430 and AVR
AtMega32. Despite these advances, detection of control-flow attacks in low-end
MCU-s remains a challenge, since hardware requirements of the cheapest related
architectures are often more expensive than the MCU-s themselves. In this work,
we tackle this challenge by designing Tiny-CFA - a control-flow attestation
(CFA) technique with a single hardware requirement - the ability to generate
proofs of remote software execution (PoX). In turn, PoX can be implemented very
efficiently and securely in low-end MCU-s. Consequently, our design achieves
the lowest hardware overhead of any CFA architecture (i.e., two orders of
magnitude cheaper), while relying on a formally verified PoX architecture as
its sole hardware requirement. With respect to runtime overhead, Tiny-CFA also
achieves better performance than prior CFA techniques based on code
instrumentation. We implement and evaluate Tiny-CFA, analyze its security, and
demonstrate its practicality using real-world publicly available applications.
"
1815,"Indirection Stream Semantic Register Architecture for Efficient
  Sparse-Dense Linear Algebra","  Sparse-dense linear algebra is crucial in many domains, but challenging to
handle efficiently on CPUs, GPUs, and accelerators alike; multiplications with
sparse formats like CSR and CSF require indirect memory lookups. In this work,
we enhance a memory-streaming RISC-V ISA extension to accelerate sparse-dense
products through streaming indirection. We present efficient dot,
matrix-vector, and matrix-matrix product kernels using our hardware, enabling
single-core FPU utilizations of up to 80% and speedups of up to 7.2x over an
optimized baseline without extensions. A matrix-vector implementation on a
multi-core cluster is up to 5.8x faster and 2.7x more energy-efficient with our
kernels than an optimized baseline. We propose further uses for our indirection
hardware, such as scatter-gather operations and codebook decoding, and compare
our work to state-of-the-art CPU, GPU, and accelerator approaches, measuring a
2.8x higher peak FP64 utilization in CSR matrix-vector multiplication than a
GTX 1080 Ti GPU running a cuSPARSE kernel.
"
1816,AXES: Approximation Manager for Emerging Memory Architectures,"  Memory approximation techniques are commonly limited in scope, targeting
individual levels of the memory hierarchy. Existing approximation techniques
for a full memory hierarchy determine optimal configurations at design-time
provided a goal and application. Such policies are rigid: they cannot adapt to
unknown workloads and must be redesigned for different memory configurations
and technologies. We propose AXES: the first self-optimizing runtime manager
for coordinating configurable approximation knobs across all levels of the
memory hierarchy. AXES continuously updates and optimizes its approximation
management policy throughout runtime for diverse workloads. AXES optimizes the
approximate memory configuration to minimize power consumption without
compromising the quality threshold specified by application developers. AXES
can (1) learn a policy at runtime to manage variable application quality of
service (QoS) constraints, (2) automatically optimize for a target metric
within those constraints, and (3) coordinate runtime decisions for
interdependent knobs and subsystems. We demonstrate AXES' ability to
efficiently provide functions 1-3 on a RISC-V Linux platform with approximate
memory segments in the on-chip cache and main memory. We demonstrate AXES'
ability to save up to 37% energy in the memory subsystem without any
design-time overhead. We show AXES' ability to reduce QoS violations by 75%
with $<5\%$ additional energy.
"
1817,"Optimizing Graph Processing and Preprocessing with Hardware Assisted
  Propagation Blocking","  Extensive prior research has focused on alleviating the characteristic poor
cache locality of graph analytics workloads. However, graph pre-processing
tasks remain relatively unexplored. In many important scenarios, graph
pre-processing tasks can be as expensive as the downstream graph analytics
kernel. We observe that Propagation Blocking (PB), a software optimization
designed for SpMV kernels, generalizes to many graph analytics kernels as well
as common pre-processing tasks. In this work, we identify the lingering
inefficiencies of a PB execution on conventional multicores and propose
architecture support to eliminate PB's bottlenecks, further improving the
performance gains from PB. Our proposed architecture -- COBRA -- optimizes the
PB execution of both graph processing and pre-processing alike to provide
end-to-end speedups of up to 4.6x (3.5x on average).
"
1818,"Revising the classic computing paradigm and its technological
  implementations","  Today's computing is told to be based on the classic paradigm, proposed by
von Neumann, a three-quarter century ago. However, that paradigm was justified
(for the timing relations of) vacuum tubes only. The technological development
invalidated the classic paradigm (but not the model!) and led to catastrophic
performance losses in computing systems, from operating gate level to large
networks, including the neuromorphic ones. The paper reviews the critical
points of the classic paradigm and scrutinizes the confusion made around it. It
discusses some of the consequences of improper technological implementation,
from the shared media to the parallelized operation. The model is perfect, but
it is applied outside of its range of validity. The paradigm is extended by
providing the ""procedure"" that enables computing science to work with cases
where the transfer time is not negligible apart from processing time.
"
1819,Automatic Microprocessor Performance Bug Detection,"  Processor design validation and debug is a difficult and complex task, which
consumes the lion's share of the design process. Design bugs that affect
processor performance rather than its functionality are especially difficult to
catch, particularly in new microarchitectures. This is because, unlike
functional bugs, the correct processor performance of new microarchitectures on
complex, long-running benchmarks is typically not deterministically known.
Thus, when performance benchmarking new microarchitectures, performance teams
may assume that the design is correct when the performance of the new
microarchitecture exceeds that of the previous generation, despite significant
performance regressions existing in the design. In this work, we present a
two-stage, machine learning-based methodology that is able to detect the
existence of performance bugs in microprocessors. Our results show that our
best technique detects 91.5% of microprocessor core performance bugs whose
average IPC impact across the studied applications is greater than 1% versus a
bug-free design with zero false positives. When evaluated on memory system
bugs, our technique achieves 100% detection with zero false positives.
Moreover, the detection is automatic, requiring very little performance
engineer time.
"
1820,"Distributed Injection-Locking in Analog Ising Machines to Solve
  Combinatorial Optimizations","  The oscillator-based Ising machine (OIM) is a network of coupled CMOS
oscillators that solves combinatorial optimization problems. In this paper, the
distribution of the injection-locking oscillations throughout the circuit is
proposed to accelerate the phase-locking of the OIM. The implications of the
proposed technique theoretically investigated and verified by extensive
simulations in EDA tools with a $130~nm$ PTM model. By distributing the
injective signal of the super-harmonic oscillator, the speed is increased by
$219.8\%$ with negligible increase in the power dissipation and phase-locking
error of the device due to the distributed technique.
"
1821,A Survey of System Architectures and Techniques for FPGA Virtualization,"  FPGA accelerators are gaining increasing attention in both cloud and edge
computing because of their hardware flexibility, high computational throughput,
and low power consumption. However, the design flow of FPGAs often requires
specific knowledge of the underlying hardware, which hinders the wide adoption
of FPGAs by application developers. Therefore, the virtualization of FPGAs
becomes extremely important to create a useful abstraction of the hardware
suitable for application developers. Such abstraction also enables the sharing
of FPGA resources among multiple users and accelerator applications, which is
important because, traditionally, FPGAs have been mostly used in single-user,
single-embedded-application scenarios. There are many works in the field of
FPGA virtualization covering different aspects and targeting different
application areas. In this survey, we review the system architectures used in
the literature for FPGA virtualization. In addition, we identify the primary
objectives of FPGA virtualization, based on which we summarize the techniques
for realizing FPGA virtualization. This survey helps researchers to efficiently
learn about FPGA virtualization research by providing a comprehensive review of
the existing literature.
"
1822,"ArSMART: An Improved SMART NoC Design Supporting Arbitrary-Turn
  Transmission","  SMART NoC, which transmits unconflicted flits to distant processing elements
(PEs) in one cycle through the express bypass, is a high-performance NoC design
proposed recently. However, if contention occurs, flits with low priority would
not only be buffered but also could not fully utilize bypass. Although there
exist several routing algorithms that decrease contentions by rounding busy
routers and links, they cannot be directly applicable to SMART since it lacks
the support for arbitrary-turn (i.e., the number and direction of turns are
free of constraints) routing. Thus, in this article, to minimize contentions
and further utilize bypass, we propose an improved SMART NoC, called ArSMART,
in which arbitrary-turn transmission is enabled. Specifically, ArSMART divides
the whole NoC into multiple clusters where the route computation is conducted
by the cluster controller and the data forwarding is performed by the
bufferless reconfigurable router. Since the long-range transmission in SMART
NoC needs to bypass the intermediate arbitration, to enable this feature, we
directly configure the input and output ports connection rather than apply
hop-by-hop table-based arbitration. To further explore the higher communication
capabilities, effective adaptive routing algorithms that are compatible with
ArSMART are proposed. The route computation overhead, one of the main concerns
for adaptive routing algorithms, is hidden by our carefully designed control
mechanism. Compared with the state-of-the-art SMART NoC, the experimental
results demonstrate an average reduction of 40.7% in application schedule
length and 29.7% in energy consumption.
"
1823,Hardware Implementation of Fano Decoder for PAC Codes,"  This paper proposes a hardware implementation architecture for Fano decoding
of polarization-adjusted convolutional (PAC) codes. This architecture maintains
a trade-off between the error-correction performance and throughput of the
decoder by setting a strict limit on its search complexity. The paper presents
analyses of the complexity, combinational delay, and latency of the proposed
architecture. The performance of the proposed decoder is evaluated on FPGA and
ASIC using Xilinx Nexys 4 Artix-7 and TSMC 28 nm 0.72 V library, respectively.
The PAC decoder can be clocked at 384.6 MHz and reach an information throughput
of 9.34 MB/s at 3.5 dB signal-to-noise ratio for a block length of 128 and code
rate of 1/2.
"
1824,Cluster Computing White Paper,"  Cluster computing is not a new area of computing. It is, however, evident
that there is a growing interest in its usage in all areas where applications
have traditionally used parallel or distributed computing platforms. The
growing interest has been fuelled in part by the availability of powerful
microprocessors and high-speed networks as off-the-shelf commodity components
as well as in part by the rapidly maturing software components available to
support high performance and high availability applications.
  This White Paper has been broken down into eleven sections, each of which has
been put together by academics and industrial researchers who are both experts
in their fields and where willing to volunteer their time and effort to put
together this White Paper. The status of this paper is draft and we are at the
stage of publicizing its presence and making a Request For Comments (RFC).
"
1825,Cluster Computing: A High-Performance Contender,"  When you first heard people speak of Piles of PCs, the first thing that came
to mind may have been a cluttered computer room with processors, monitors, and
snarls of cables all around. Collections of computers have undoubtedly become
more sophisticated than in the early days of shared drives and modem
connections. No matter what you call them, Clusters of Workstations (COW),
Networks of Workstations (NOW), Workstation Clusters (WCs), Clusters of PCs
(CoPs), clusters of computers are now filling the processing niche once
occupied by more powerful stand-alone machines. This article discusses the need
for cluster computing technology, Technologies, Components, and Applications,
Supercluster Systems and Issues, The Need for a New Task Force, and Cluster
Computing Educational Resources.
"
1826,Towards a Theory of Cache-Efficient Algorithms,"  We describe a model that enables us to analyze the running time of an
algorithm in a computer with a memory hierarchy with limited associativity, in
terms of various cache parameters. Our model, an extension of Aggarwal and
Vitter's I/O model, enables us to establish useful relationships between the
cache complexity and the I/O complexity of computations. As a corollary, we
obtain cache-optimal algorithms for some fundamental problems like sorting,
FFT, and an important subclass of permutations in the single-level cache model.
We also show that ignoring associativity concerns could lead to inferior
performance, by analyzing the average-case cache behavior of mergesort. We
further extend our model to multiple levels of cache with limited associativity
and present optimal algorithms for matrix transpose and sorting. Our techniques
may be used for systematic exploitation of the memory hierarchy starting from
the algorithm design stage, and dealing with the hitherto unresolved problem of
limited associativity.
"
1827,The Anatomy of the Grid - Enabling Scalable Virtual Organizations,"  ""Grid"" computing has emerged as an important new field, distinguished from
conventional distributed computing by its focus on large-scale resource
sharing, innovative applications, and, in some cases, high-performance
orientation. In this article, we define this new field. First, we review the
""Grid problem,"" which we define as flexible, secure, coordinated resource
sharing among dynamic collections of individuals, institutions, and
resources-what we refer to as virtual organizations. In such settings, we
encounter unique authentication, authorization, resource access, resource
discovery, and other challenges. It is this class of problem that is addressed
by Grid technologies. Next, we present an extensible and open Grid
architecture, in which protocols, services, application programming interfaces,
and software development kits are categorized according to their roles in
enabling resource sharing. We describe requirements that we believe any such
mechanisms must satisfy, and we discuss the central role played by the
intergrid protocols that enable interoperability among different Grid systems.
Finally, we discuss how Grid technologies relate to other contemporary
technologies, including enterprise integration, application service provider,
storage service provider, and peer-to-peer computing. We maintain that Grid
concepts and technologies complement and have much to contribute to these other
approaches.
"
1828,"Verifying Sequential Consistency on Shared-Memory Multiprocessors by
  Model Checking","  The memory model of a shared-memory multiprocessor is a contract between the
designer and programmer of the multiprocessor. The sequential consistency
memory model specifies a total order among the memory (read and write) events
performed at each processor. A trace of a memory system satisfies sequential
consistency if there exists a total order of all memory events in the trace
that is both consistent with the total order at each processor and has the
property that every read event to a location returns the value of the last
write to that location.
  Descriptions of shared-memory systems are typically parameterized by the
number of processors, the number of memory locations, and the number of data
values. It has been shown that even for finite parameter values, verifying
sequential consistency on general shared-memory systems is undecidable. We
observe that, in practice, shared-memory systems satisfy the properties of
causality and data independence. Causality is the property that values of read
events flow from values of write events. Data independence is the property that
all traces can be generated by renaming data values from traces where the
written values are distinct from each other. If a causal and data independent
system also has the property that the logical order of write events to each
location is identical to their temporal order, then sequential consistency can
be verified algorithmically. Specifically, we present a model checking
algorithm to verify sequential consistency on such systems for a finite number
of processors and memory locations and an arbitrary number of data values.
"
1829,Interfacing the ControlLogix PLC over Ethernet/IP,"  The Allen-Bradley ControlLogix line of pro-grammable logic controllers (PLCs)
offers several in-terfaces: Ethernet, ControlNet, DeviceNet, RS-232 and others.
The ControlLogix Ethernet interface module 1756-ENET uses EtherNet/IP, the
ControlNet protocol, encapsulated in Ethernet packages, with specific service
codes. A driver for the Experimental Physics and Industrial Control System
(EPICS) has been developed that utilizes this EtherNet/IP protocol for
controllers running the vxWorks RTOS as well as a Win32 and Unix/Linux test
program. Features, per-formance and limitations of this interface are
presented.
"
1830,Versatile Data Acquisition and Controls for Epics Using Vme-Based Fpgas,"  Field-Programmable Gate Arrays (FPGAs) have provided Thomas Jefferson
National Accelerator Facility (Jefferson Lab) with versatile VME-based data
acquisition and control interfaces with minimal development times. FPGA designs
have been used to interface to VME and provide control logic for numerous
systems. The building blocks of these logic designs can be tailored to the
individual needs of each system and provide system operators with read-backs
and controls via a VME interface to an EPICS based computer. This versatility
allows the system developer to choose components and define operating
parameters and options that are not readily available commercially. Jefferson
Lab has begun developing standard FPGA libraries that result in quick turn
around times and inexpensive designs.
"
1831,"A Dual Digital Signal Processor VME Board For Instrumentation And
  Control Applications","  A Dual Digital Signal Processing VME Board was developed for the Continuous
Electron Beam Accelerator Facility (CEBAF) Beam Current Monitor (BCM) system at
Jefferson Lab. It is a versatile general-purpose digital signal processing
board using an open architecture, which allows for adaptation to various
applications. The base design uses two independent Texas Instrument (TI)
TMS320C6711, which are 900 MFLOPS floating-point digital signal processors
(DSP). Applications that require a fixed point DSP can be implemented by
replacing the baseline DSP with the pin-for-pin compatible TMS320C6211. The
design can be manufactured with a reduced chip set without redesigning the
printed circuit board. For example it can be implemented as a single-channel
DSP with no analog I/O.
"
1832,SNS Timing System,"  This poster describes the timing system being designed for Spallation Neutron
Source being built at Oak Ridge National lab.
"
1833,"Behaviour-based Knowledge Systems: An Epigenetic Path from Behaviour to
  Knowledge","  In this paper we expose the theoretical background underlying our current
research. This consists in the development of behaviour-based knowledge
systems, for closing the gaps between behaviour-based and knowledge-based
systems, and also between the understandings of the phenomena they model. We
expose the requirements and stages for developing behaviour-based knowledge
systems and discuss their limits. We believe that these are necessary
conditions for the development of higher order cognitive capacities, in
artificial and natural cognitive systems.
"
1834,"Synthesis of Low-Power Digital Circuits Derived from Binary Decision
  Diagrams","  This paper introduces a novel method for synthesizing digital circuits
derived from Binary Decision Diagrams (BDDs) that can yield to reduction in
power dissipation. The power reduction is achieved by decreasing the switching
activity in a circuit while paying close attention to information measures as
an optimization criterion. We first present the technique of efficient
BDD-based computation of information measures which are used to guide the power
optimization procedures. Using this technique, we have developed an algorithm
of BDD reordering which leads to reducing the power consumption of the circuits
derived from BDDs. Results produced by the synthesis on the ISCAS benchmark
circuits are very encouraging.
"
1835,On the Information Engine of Circuit Design,"  This paper addresses a new approach to find a spectrum of information
measures for the process of digital circuit synthesis. We consider the problem
from the information engine point of view. The circuit synthesis as a whole and
different steps of the design process (an example of decision diagram is given)
are presented via such measurements as entropy, logical work and information
vitality. We also introduce new information measures to provide better
estimates of synthesis criteria. We show that the basic properties of
information engine, such as the conservation law of information flow and the
equilibrium law of information can be formulated.
"
1836,Analytical formulations of Peer-to-Peer Connection Efficiency,"  Use of Peer-to-Peer (P2P) service networks introduces a new communication
paradigm because peers are both clients and servers and so each peer may
provide/request services to/from other peers. Empirical studies of P2P networks
have been undertaken and reveal useful characteristics. However there is to
date little analytical work to describe P2P networks with respect to their
communication paradigm and their interconnections. This paper provides an
analytical formulation and optimisation of peer connection efficiency, in terms
of minimising the fraction of wasted connection time. Peer connection
efficiency is analysed for both a uni- and multi-connected peer. Given this
fundamental optimisation, the paper optimises the number of connections that
peers should make use of as a function of network load, in terms of minimising
the total queue size that requests in the P2P network experience. The results
of this paper provide a basis for engineering high performance P2P
interconnection networks. The optimisations are useful for reducing bandwidth
and power consumption, e.g. in the case of peers being mobile devices with a
limited power supply. Also these results could be used to determine when a
(virtual) circuit should be switched to support a connection.
"
1837,Fast Parallel I/O on Cluster Computers,"  Today's cluster computers suffer from slow I/O, which slows down
I/O-intensive applications. We show that fast disk I/O can be achieved by
operating a parallel file system over fast networks such as Myrinet or Gigabit
Ethernet.
  In this paper, we demonstrate how the ParaStation3 communication system helps
speed-up the performance of parallel I/O on clusters using the open source
parallel virtual file system (PVFS) as testbed and production system. We will
describe the set-up of PVFS on the Alpha-Linux-Cluster-Engine (ALiCE) located
at Wuppertal University, Germany. Benchmarks on ALiCE achieve
write-performances of up to 1 GB/s from a 32-processor compute-partition to a
32-processor PVFS I/O-partition, outperforming known benchmark results for PVFS
on the same network by more than a factor of 2. Read-performance from
buffer-cache reaches up to 2.2 GB/s. Our benchmarks are giant, I/O-intensive
eigenmode problems from lattice quantum chromodynamics, demonstrating stability
and performance of PVFS over Parastation in large-scale production runs.
"
1838,On a composition of digraphs,"  Many ""good"" topologies for interconnection networks are based on line
digraphs of regular digraphs. These digraphs support unitary matrices. We
propose the property ""being the digraph of a unitary matrix"" as additional
criterion for the design of new interconnection networks. We define a
composition of digraphs, which we call diagonal union. Diagonal union can be
used to construct digraphs of unitary matrices. We remark that digraphs
obtained via diagonal union are state split graphs, as defined in symbolic
dynamics. Finally, we list some potential directions for future research.
"
1839,"Adaptive Domain Model: Dealing With Multiple Attributes of Self-Managing
  Distributed Object Systems","  Self-managing software has emerged as modern systems have become more
complex. Some of the distributed object systems may contain thousands of
objects deployed on tens or even hundreds hosts. Development and support of
such systems often costs a lot. To solve this issue the systems, which are
capable supporting multiple self-managing attributes, should be created. In the
paper, the Adaptive domain concept is introduced as an extension to the basic
domain concept to support a generic adaptation environment for building
distributed object systems with multiple self-managing attributes.
"
1840,High-density and Secure Data Transmission via Linear Combinations,"  Suppose that there are $n$ Senders and $n$ Receivers. Our goal is to send
long messages from Sender $i$ to Receiver $i$ such that no other receiver can
retrieve the message intended for Receiver $i$. The task can easily be
completed using $n$ private channels between the pairs. Solutions, using one
channel needs either encryption or switching elements for routing the messages
to their addressee.
  The main result of the present work is a description of a network in which
The Senders and the Receivers are connected with only $n^{o(1)}$ channels; the
encoding and de-coding is nothing else just very fast linear combinations of
the message-bits; and there are no switching or routing-elements in the
network, just linear combinations are computed, with fixed connections
(channels or wires).
  In the proofs we do not use {\em any} unproven cryptographical or complexity
theoretical assumptions.
"
1841,Using Propagation for Solving Complex Arithmetic Constraints,"  Solving a system of nonlinear inequalities is an important problem for which
conventional numerical analysis has no satisfactory method. With a
box-consistency algorithm one can compute a cover for the solution set to
arbitrarily close approximation. Because of difficulties in the use of
propagation for complex arithmetic expressions, box consistency is computed
with interval arithmetic. In this paper we present theorems that support a
simple modification of propagation that allows complex arithmetic expressions
to be handled efficiently. The version of box consistency that is obtained in
this way is stronger than when interval arithmetic is used.
"
1842,The Graphics Card as a Streaming Computer,"  Massive data sets have radically changed our understanding of how to design
efficient algorithms; the streaming paradigm, whether it in terms of number of
passes of an external memory algorithm, or the single pass and limited memory
of a stream algorithm, appears to be the dominant method for coping with large
data.
  A very different kind of massive computation has had the same effect at the
level of the CPU. The most prominent example is that of the computations
performed by a graphics card. The operations themselves are very simple, and
require very little memory, but require the ability to perform many
computations extremely fast and in parallel to whatever degree possible. What
has resulted is a stream processor that is highly optimized for stream
computations. An intriguing side effect of this is the growing use of a
graphics card as a general purpose stream processing engine. In an
ever-increasing array of applications, researchers are discovering that
performing a computation on a graphics card is far faster than performing it on
a CPU, and so are using a GPU as a stream co-processor.
"
1843,Design and Implementation of MPICH2 over InfiniBand with RDMA Support,"  For several years, MPI has been the de facto standard for writing parallel
applications. One of the most popular MPI implementations is MPICH. Its
successor, MPICH2, features a completely new design that provides more
performance and flexibility. To ensure portability, it has a hierarchical
structure based on which porting can be done at different levels. In this
paper, we present our experiences designing and implementing MPICH2 over
InfiniBand. Because of its high performance and open standard, InfiniBand is
gaining popularity in the area of high-performance computing. Our study focuses
on optimizing the performance of MPI-1 functions in MPICH2. One of our
objectives is to exploit Remote Direct Memory Access (RDMA) in Infiniband to
achieve high performance. We have based our design on the RDMA Channel
interface provided by MPICH2, which encapsulates architecture-dependent
communication functionalities into a very small set of functions. Starting with
a basic design, we apply different optimizations and also propose a
zero-copy-based design. We characterize the impact of our optimizations and
designs using microbenchmarks. We have also performed an application-level
evaluation using the NAS Parallel Benchmarks. Our optimized MPICH2
implementation achieves 7.6 $\mu$s latency and 857 MB/s bandwidth, which are
close to the raw performance of the underlying InfiniBand layer. Our study
shows that the RDMA Channel interface in MPICH2 provides a simple, yet
powerful, abstraction that enables implementations with high performance by
exploiting RDMA operations in InfiniBand. To the best of our knowledge, this is
the first high-performance design and implementation of MPICH2 on InfiniBand
using RDMA support.
"
1844,2 P2P or Not 2 P2P?,"  In the hope of stimulating discussion, we present a heuristic decision tree
that designers can use to judge the likely suitability of a P2P architecture
for their applications. It is based on the characteristics of a wide range of
P2P systems from the literature, both proposed and deployed.
"
1845,"Efficient and Scalable Barrier over Quadrics and Myrinet with a New
  NIC-Based Collective Message Passing Protocol","  Modern interconnects often have programmable processors in the network
interface that can be utilized to offload communication processing from host
CPU. In this paper, we explore different schemes to support collective
operations at the network interface and propose a new collective protocol. With
barrier as an initial case study, we have demontrated that much of the
communication processing can be greatly simplified with this collective
protocol. Accordingly, %with our proposed collective processing scheme, we have
designed and implemented efficient and scalable NIC-based barrier operations
over two high performance interconnects, Quadrics and Myrinet.
  Our evaluation shows that, over a Quadrics cluster of 8 nodes with ELan3
Network, the NIC-based barrier operation achieves a barrier latency of only
5.60$\mu$s. This result is a 2.48 factor of improvement over the Elanlib
tree-based barrier operation. Over a Myrinet cluster of 8 nodes with LANai-XP
NIC cards, a barrier latency of 14.20$\mu$s over 8 nodes is achieved. This is a
2.64 factor of improvement over the host-based barrier algorithm. Furthermore,
an analytical model developed for the proposed scheme indicates that a
NIC-based barrier operation on a 1024-node cluster can be performed with only
22.13$\mu$s latency over Quadrics and with 38.94$\mu$s latency over Myrinet.
These results indicate the potential for developing high performance
communication subsystems for next generation clusters.
"
1846,End-User Effects of Microreboots in Three-Tiered Internet Systems,"  Microreboots restart fine-grained components of software systems ""with a
clean slate,"" and only take a fraction of the time needed for full system
reboot. Microreboots provide an application-generic recovery technique for
Internet services, which can be supported entirely in middleware and requires
no changes to the applications or any a priori knowledge of application
semantics.
  This paper investigates the effect of microreboots on end-users of an
eBay-like online auction application; we find that microreboots are nearly as
effective as full reboots, but are significantly less disruptive in terms of
downtime and lost work. In our experiments, microreboots reduced the number of
failed user requests by 65% and the perceived downtime by 78% compared to a
server process restart. We also show how to replace user-visible transient
failures with transparent call-retry, at the cost of a slight increase in
end-user-visible latency during recovery. Due to their low cost, microreboots
can be used aggressively, even when their necessity is less than certain, hence
adding to the reduced recovery time a reduction in the fault detection time,
which further improves availability.
"
1847,Quantum Computers,"  This research paper gives an overview of quantum computers - description of
their operation, differences between quantum and silicon computers, major
construction problems of a quantum computer and many other basic aspects. No
special scientific knowledge is necessary for the reader.
"
1848,A High-Level Reconfigurable Computing Platform Software Frameworks,"  Reconfigurable computing refers to the use of processors, such as Field
Programmable Gate Arrays (FPGAs), that can be modified at the hardware level to
take on different processing tasks. A reconfigurable computing platform
describes the hardware and software base on top of which modular extensions can
be created, depending on the desired application. Such reconfigurable computing
platforms can take on varied designs and implementations, according to the
constraints imposed and features desired by the scope of applications. This
paper introduces a PC-based reconfigurable computing platform software
frameworks that is flexible and extensible enough to abstract the different
hardware types and functionality that different PCs may have. The requirements
of the software platform, architectural issues addressed, rationale behind the
decisions made, and frameworks design implemented are discussed.
"
1849,Stochastic fuzzy controller,"  A standard approach to building a fuzzy controller based on stochastic logic
uses binary random signals with an average (expected value of a random
variable) in the range [0, 1]. A different approach is presented, founded on a
representation of the membership functions with the probability density
functions.
"
1850,"Exposing Software Defined Radio Functionality To Native Operating System
  Applications via Virtual Devices","  Many reconfigurable platforms require that applications be written
specifically to take advantage of the reconfigurable hardware. In a PC-based
environment, this presents an undesirable constraint in that the many already
available applications cannot leverage on such hardware. Greatest benefit can
only be derived from reconfigurable devices if even native OS applications can
transparently utilize reconfigurable devices as they would normal full-fledged
hardware devices. This paper presents how Proteus Virtual Devices are used to
expose reconfigurable hardware in a transparent manner for use by typical
native OS applications.
"
1851,Collaborative Storage Management In Sensor Networks,"  In this paper, we consider a class of sensor networks where the data is not
required in real-time by an observer; for example, a sensor network monitoring
a scientific phenomenon for later play back and analysis. In such networks, the
data must be stored in the network. Thus, in addition to battery power, storage
is a primary resource: the useful lifetime of the network is constrained by its
ability to store the generated data samples. We explore the use of
collaborative storage technique to efficiently manage data in storage
constrained sensor networks. The proposed collaborative storage technique takes
advantage of spatial correlation among the data collected by nearby sensors to
significantly reduce the size of the data near the data sources. We show that
the proposed approach provides significant savings in the size of the stored
data vs. local buffering, allowing the network to run for a longer time without
running out of storage space and reducing the amount of data that will
eventually be relayed to the observer. In addition, collaborative storage
performs load balancing of the available storage space if data generation rates
are not uniform across sensors (as would be the case in an event driven sensor
network), or if the available storage varies across the network.
"
1852,Topics in asynchronous systems,"  In the paper we define and characterize the asynchronous systems from the
point of view of their autonomy, determinism, order, non-anticipation, time
invariance, symmetry, stability and other important properties. The study is
inspired by the models of the asynchronous circuits.
"
1853,Programmable Ethernet Switches and Their Applications,"  Modern Ethernet switches support many advanced features beyond route learning
and packet forwarding such as VLAN tagging, IGMP snooping, rate limiting, and
status monitoring, which can be controlled through a programmatic interface.
Traditionally, these features are mostly used to statically configure a
network. This paper proposes to apply them as dynamic control mechanisms to
maximize physical network link resources, to minimize failure recovery time, to
enforce QoS requirements, and to support link-layer multicast without
broadcasting. With these advanced programmable control mechanisms, standard
Ethernet switches can be used as effective building blocks for
metropolitan-area Ethernet networks (MEN), storage-area networks (SAN), and
computation cluster interconnects. We demonstrate the usefulness of this new
level of control over Ethernet switches with a MEN architecture that features
multi-fold throughput gains and sub-second failure recovery time.
"
1854,Utilizing Reconfigurable Hardware Processors via Grid Services,"  Computational grids typically consist of nodes utilizing ordinary processors
such as the Intel Pentium. Field Programmable Gate Arrays (FPGAs) are able to
perform certain compute-intensive tasks very well due to their inherent
parallel architecture, often resulting in orders of magnitude speedups. This
paper explores how FPGAs can be transparently exposed for remote use via grid
services, by integrating the Proteus Software Platform with the Globus Toolkit
3.0.
"
1855,A Self-Reconfigurable Computing Platform Hardware Architecture,"  Field Programmable Gate Arrays (FPGAs) have recently been increasingly used
for highly-parallel processing of compute intensive tasks. This paper
introduces an FPGA hardware platform architecture that is PC-based, allows for
fast reconfiguration over the PCI bus, and retains a simple physical hardware
design. The design considerations are first discussed, then the resulting
system architecture designed is illustrated. Finally, experimental results on
the FPGA resources utilized for this design are presented.
"
1856,Data-stationary Architecture to Execute Quantum Algorithms Classically,"  This paper presents a data stationary architecture in which each word has an
attached address field. Address fields massively update in parallel to record
data interchanges. Words do not move until memory is read for post processing.
A sea of such cells can test large-scale quantum algorithms, although other
programming is possible.
"
1857,ScotGrid: A Prototype Tier 2 Centre,"  ScotGrid is a prototype regional computing centre formed as a collaboration
between the universities of Durham, Edinburgh and Glasgow as part of the UK's
national particle physics grid, GridPP. We outline the resources available at
the three core sites and our optimisation efforts for our user communities. We
discuss the work which has been conducted in extending the centre to embrace
new projects both from particle physics and new user communities and explain
our methodology for doing this.
"
1858,CDTP Chain Distributed Transfer Protocol,"  The rapid growth of the internet in general and of bandwidth capacity at
internet clients in particular poses increasing computation and bandwidth
demands on internet servers. Internet access technologies like ADSL [DSL],
Cable Modem and Wireless modem allow internet clients to access the internet
with orders of magnitude more bandwidth than using traditional modems. We
present CDTP a distributed transfer protocol that allows clients to cooperate
and therefore remove the strain from the internet server thus achieving much
better performance than traditional transfer protocols (e.g. FTP [FTP]). The
CDTP server and client tools are presented also as well as results of
experiments. Finally a bandwidth measurement technique is presented. CDTP tools
use this technique to differentiate between slow and fast clients.
"
1859,A Geographic Directed Preferential Internet Topology Model,"  The goal of this work is to model the peering arrangements between Autonomous
Systems (ASes). Most existing models of the AS-graph assume an undirected
graph. However, peering arrangements are mostly asymmetric Customer-Provider
arrangements, which are better modeled as directed edges. Furthermore, it is
well known that the AS-graph, and in particular its clustering structure, is
influenced by geography.
  We introduce a new model that describes the AS-graph as a directed graph,
with an edge going from the customer to the provider, but also models symmetric
peer-to-peer arrangements, and takes geography into account. We are able to
mathematically analyze its power-law exponent and number of leaves. Beyond the
analysis we have implemented our model as a synthetic network generator we call
GdTang. Experimentation with GdTang shows that the networks it produces are
more realistic than those generated by other network generators, in terms of
its power-law exponent, fractions of customer-provider and symmetric peering
arrangements, and the size of its dense core. We believe that our model is the
first to manifest realistic regional dense cores that have a clear geographic
flavor. Our synthetic networks also exhibit path inflation effects that are
similar to those observed in the real AS graph.
"
1860,Tree Parity Machine Rekeying Architectures,"  The necessity to secure the communication between hardware components in
embedded systems becomes increasingly important with regard to the secrecy of
data and particularly its commercial use. We suggest a low-cost (i.e. small
logic-area) solution for flexible security levels and short key lifetimes. The
basis is an approach for symmetric key exchange using the synchronisation of
Tree Parity Machines. Fast successive key generation enables a key exchange
within a few milliseconds, given realistic communication channels with a
limited bandwidth. For demonstration we evaluate characteristics of a
standard-cell ASIC design realisation as IP-core in 0.18-micrometer
CMOS-technology.
"
1861,"A Practical Approach for Circuit Routing on Dynamic Reconfigurable
  Devices","  Management of communication by on-line routing in new FPGAs with a large
amount of logic resources and partial reconfigurability is a new challenging
problem. A Network-on-Chip
  (NoC) typically uses packet routing mechanism, which has often unsafe data
transfers, and network interface overhead. In this paper, circuit routing for
such dynamic NoCs is investigated, and a practical 1-dimensional network with
an efficient routing algorithm is proposed and implemented. Also, this concept
has been extended to the 2-dimensional case. The implementation results show
the low area overhead and high performance of this network.
"
1862,Defragmenting the Module Layout of a Partially Reconfigurable Device,"  Modern generations of field-programmable gate arrays (FPGAs) allow for
partial reconfiguration. In an online context, where the sequence of modules to
be loaded on the FPGA is unknown beforehand, repeated insertion and deletion of
modules leads to progressive fragmentation of the available space, making
defragmentation an important issue. We address this problem by propose an
online and an offline component for the defragmentation of the available space.
We consider defragmenting the module layout on a reconfigurable device. This
corresponds to solving a two-dimensional strip packing problem. Problems of
this type are NP-hard in the strong sense, and previous algorithmic results are
rather limited. Based on a graph-theoretic characterization of feasible
packings, we develop a method that can solve two-dimensional defragmentation
instances of practical size to optimality. Our approach is validated for a set
of benchmark instances.
"
1863,Selfish vs. Unselfish Optimization of Network Creation,"  We investigate several variants of a network creation model: a group of
agents builds up a network between them while trying to keep the costs of this
network small. The cost function consists of two addends, namely (i) a constant
amount for each edge an agent buys and (ii) the minimum number of hops it takes
sending messages to other agents. Despite the simplicity of this model, various
complex network structures emerge depending on the weight between the two
addends of the cost function and on the selfish or unselfish behaviour of the
agents.
"
1864,Quantum Algorithm Processor For Finding Exact Divisors,"  Wiring diagrams are given for a quantum algorithm processor in CMOS to
compute, in parallel, all divisors of an n-bit integer. Lines required in a
wiring diagram are proportional to n. Execution time is proportional to the
square of n.
"
1865,Representing Digital Assets using MPEG-21 Digital Item Declaration,"  Various XML-based approaches aimed at representing compound digital assets
have emerged over the last several years. Approaches that are of specific
relevance to the digital library community include the Metadata Encoding and
Transmission Standard (METS), the IMS Content Packaging XML Binding, and the
XML Formatted Data Units (XFDU) developed by CCSDS Panel 2. The MPEG-21 Digital
Item Declaration (MPEG-21 DID) is another standard specifying the
representation of digital assets in XML that, so far, has received little
attention in the digital library community. This article gives a brief insight
into the MPEG-21 standardization effort, highlights the major characteristics
of the MPEG-21 DID Abstract Model, and describes the MPEG-21 Digital Item
Declaration Language (MPEG-21 DIDL), an XML syntax for the representation of
digital assets based on the MPEG-21 DID Abstract Model. Also, it briefly
demonstrates the potential relevance of MPEG-21 DID to the digital library
community by describing its use in the aDORe repository environment at the
Research Library of the Los Alamos National Laboratory (LANL) for the
representation of digital assets.
"
1866,Quantum Algorithm Processors to Reveal Hamiltonian Cycles,"  Quantum computer versus quantum algorithm processor in CMOS are compared to
find (in parallel) all Hamiltonian cycles in a graph with m edges and n
vertices, each represented by k bits. A quantum computer uses quantum states
analogous to CMOS registers. With efficient initialization, number of CMOS
registers is proportional to (n-1)! Number of qubits in a quantum computer is
approximately proportional to kn+2mn in the approach below. Using CMOS, the
bits per register is about proportional to kn, which is less since bits can be
irreversibly reset. In either concept, number of gates, or operations to
identify Hamiltonian cycles is proportional to kmn. However, a quantum computer
needs an additional exponentially large number of operations to accomplish a
probabilistic readout. In contrast, CMOS is deterministic and readout is
comparable to ordinary memory.
"
1867,"DyNoC: A Dynamic Infrastructure for Communication in Dynamically
  Reconfigurable Devices","  A new paradigm to support the communication among modules dynamically placed
on a reconfigurable device at run-time is presented. Based on the network on
chip (NoC) infrastructure, we developed a dynamic communication infrastructure
as well as routing methodologies capable to handle routing in a NoC with
obstacles created by dynamically placed components. We prove the unrestricted
reachability of components and pins, the deadlock-freeness and we finally show
the feasibility of our approach by means on real life example applications.
"
1868,"Parameters Affecting the Resilience of Scale-Free Networks to Random
  Failures","  It is commonly believed that scale-free networks are robust to massive
numbers of random node deletions. For example, Cohen et al. study scale-free
networks including some which approximate the measured degree distribution of
the Internet. Their results suggest that if each node in this network failed
independently with probability 0.99, the remaining network would continue to
have a giant component. In this paper, we show that a large and important
subclass of scale-free networks are not robust to massive numbers of random
node deletions for practical purposes. In particular, we study finite
scale-free networks which have minimum node degree of 1 and a power-law degree
distribution beginning with nodes of degree 1 (power-law networks). We show
that, in a power-law network approximating the Internet's reported
distribution, when the probability of deletion of each node is 0.5 only about
25% of the surviving nodes in the network remain connected in a giant
component, and the giant component does not persist beyond a critical failure
rate of 0.9. The new result is partially due to improved analytical
accommodation of the large number of degree-0 nodes that result after node
deletions. Our results apply to finite power-law networks with a wide range of
power-law exponents, including Internet-like networks. We give both analytical
and empirical evidence that such networks are not generally robust to massive
random node deletions.
"
1869,Reversible CAM Processor Modeled After Quantum Computer Behavior,"  Proposed below is a reversible digital computer modeled after the natural
behavior of a quantum system. Using approaches usually reserved for idealized
quantum computers, the Reversible CAM, or State Vector Parallel (RSVP)
processor can easily find keywords in an unstructured database (that is, it can
solve a needle in a haystack problem). The RSVP processor efficiently solves a
SAT (Satisfiability of Boolean Formulae) problem; also it can aid in the
solution of a GP (Global Properties of Truth Table) problem. The power delay
product of the RSVP processor is exponentially lower than that of a standard
CAM programmed to perform similar operations.
"
1870,Associative Memory For Reversible Programming and Charge Recovery,"  Presented below is an interesting type of associative memory called toggle
memory based on the concept of T flip flops, as opposed to D flip flops. Toggle
memory supports both reversible programming and charge recovery. Circuits
designed using the principles delineated below permit matchlines to charge and
discharge with near zero energy dissipation. The resulting lethargy is
compensated by the massive parallelism of associative memory. Simulation
indicates over 33x reduction in energy dissipation using a sinusoidal power
supply at 2 MHz, assuming realistic 50 nm MOSFET models.
"
1871,Difficulties in the Implementation of Quantum Computers,"  This paper reviews various engineering hurdles facing the field of quantum
computing. Specifically, problems related to decoherence, state preparation,
error correction, and implementability of gates are considered.
"
1872,"Novel BCD Adders and Their Reversible Logic Implementation for IEEE 754r
  Format","  IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and
a major enhancement to the standard is the addition of decimal format. This
paper proposes two novel BCD adders called carry skip and carry look-ahead BCD
adders respectively. Furthermore, in the recent years, reversible logic has
emerged as a promising technology having its applications in low power CMOS,
quantum computing, nanotechnology, and optical computing. It is not possible to
realize quantum computing without reversible logic. Thus, this paper also paper
provides the reversible logic implementation of the conventional BCD adder as
the well as the proposed Carry Skip BCD adder using a recently proposed TSG
gate. Furthermore, a new reversible gate called TS-3 is also being proposed and
it has been shown that the proposed reversible logic implementation of the BCD
Adders is much better compared to recently proposed one, in terms of number of
reversible gates used and garbage outputs produced. The reversible BCD circuits
designed and proposed here form the basis of the decimal ALU of a primitive
quantum CPU.
"
1873,"A New Reversible TSG Gate and Its Application For Designing Efficient
  Adder Circuits","  In the recent years, reversible logic has emerged as a promising technology
having its applications in low power CMOS, quantum computing, nanotechnology,
and optical computing. The classical set of gates such as AND, OR, and EXOR are
not reversible. This paper proposes a new 4 * 4 reversible gate called TSG
gate. The proposed gate is used to design efficient adder units. The most
significant aspect of the proposed gate is that it can work singly as a
reversible full adder i.e reversible full adder can now be implemented with a
single gate only. The proposed gate is then used to design reversible ripple
carry and carry skip adders. It is demonstrated that the adder architectures
designed using the proposed gate are much better and optimized, compared to
their existing counterparts in literature; in terms of number of reversible
gates and garbage outputs. Thus, this paper provides the initial threshold to
building of more complex system which can execute more complicated operations
using reversible logic.
"
1874,"An Extension to DNA Based Fredkin Gate Circuits: Design of Reversible
  Sequential Circuits using Fredkin Gates","  In recent years, reversible logic has emerged as a promising computing
paradigm having its applications in low power computing, quantum computing,
nanotechnology, optical computing and DNA computing. The classical set of gates
such as AND, OR, and EXOR are not reversible. Recently, it has been shown how
to encode information in DNA and use DNA amplification to implement Fredkin
gates. Furthermore, in the past Fredkin gates have been constructed using DNA,
whose outputs are used as inputs for other Fredkin gates. Thus, it can be
concluded that arbitrary circuits of Fredkin gates can be constructed using
DNA. This paper provides the initial threshold to building of more complex
system having reversible sequential circuits and which can execute more
complicated operations. The novelty of the paper is the reversible designs of
sequential circuits using Fredkin gate. Since, Fredkin gate has already been
realized using DNA, it is expected that this work will initiate the building of
complex systems using DNA. The reversible circuits designed here are highly
optimized in terms of number of gates and garbage outputs. The modularization
approach that is synthesizing small circuits and thereafter using them to
construct bigger circuits is used for designing the optimal reversible
sequential circuits.
"
1875,Implementation of float-float operators on graphics hardware,"  The Graphic Processing Unit (GPU) has evolved into a powerful and flexible
processor. The latest graphic processors provide fully programmable vertex and
pixel processing units that support vector operations up to single
floating-point precision. This computational power is now being used for
general-purpose computations. However, some applications require higher
precision than single precision. This paper describes the emulation of a 44-bit
floating-point number format and its corresponding operations. An
implementation is presented along with performance and accuracy results.
"
1876,Novel Reversible Multiplier Architecture Using Reversible TSG Gate,"  In the recent years, reversible logic has emerged as a promising technology
having its applications in low power CMOS, quantum computing, nanotechnology,
and optical computing. The classical set of gates such as AND, OR, and EXOR are
not reversible. Recently a 4 * 4 reversible gate called TSG is proposed. The
most significant aspect of the proposed gate is that it can work singly as a
reversible full adder, that is reversible full adder can now be implemented
with a single gate only. This paper proposes a NXN reversible multiplier using
TSG gate. It is based on two concepts. The partial products can be generated in
parallel with a delay of d using Fredkin gates and thereafter the addition can
be reduced to log2N steps by using reversible parallel adder designed from TSG
gates. Similar multiplier architecture in conventional arithmetic (using
conventional logic) has been reported in existing literature, but the proposed
one in this paper is totally based on reversible logic and reversible cells as
its building block. A 4x4 architecture of the proposed reversible multiplier is
also designed. It is demonstrated that the proposed multiplier architecture
using the TSG gate is much better and optimized, compared to its existing
counterparts in literature; in terms of number of reversible gates and garbage
outputs. Thus, this paper provides the initial threshold to building of more
complex system which can execute more complicated operations using reversible
logic.
"
1877,Peer to Peer Networks for Defense Against Internet Worms,"  Internet worms, which spread in computer networks without human mediation,
pose a severe threat to computer systems today. The rate of propagation of
worms has been measured to be extremely high and they can infect a large
fraction of their potential hosts in a short time. We study two different
methods of patch dissemination to combat the spread of worms. We first show
that using a fixed number of patch servers performs woefully inadequately
against Internet worms. We then show that by exploiting the exponential data
dissemination capability of P2P systems, the spread of worms can be halted very
effectively. We compare the two methods by using fluid models to compute two
quantities of interest: the time taken to effectively combat the progress of
the worm and the maximum number of infected hosts. We validate our models using
Internet measurements and simulations.
"
1878,Fast and Generalized Polynomial Time Memory Consistency Verification,"  The problem of verifying multi-threaded execution against the memory
consistency model of a processor is known to be an NP hard problem. However
polynomial time algorithms exist that detect almost all failures in such
execution. These are often used in practice for microprocessor verification. We
present a low complexity and fully parallelized algorithm to check program
execution against the processor consistency model. In addition our algorithm is
general enough to support a number of consistency models without any
degradation in performance. An implementation of this algorithm is currently
used in practice to verify processors in the post silicon stage for multiple
architectures.
"
1879,An Internet-enabled technology to support Evolutionary Design,"  This paper discusses the systematic use of product feedback information to
support life-cycle design approaches and provides guidelines for developing a
design at both the product and the system levels. Design activities are
surveyed in the light of the product life cycle, and the design information
flow is interpreted from a semiotic perspective. The natural evolution of a
design is considered, the notion of design expectations is introduced, and the
importance of evaluation of these expectations in dynamic environments is
argued. Possible strategies for reconciliation of the expectations and
environmental factors are described. An Internet-enabled technology is proposed
to monitor product functionality, usage, and operational environment and supply
the designer with relevant information. A pilot study of assessing design
expectations of a refrigerator is outlined, and conclusions are drawn.
"
1880,Combinational Logic Circuit Design with the Buchberger Algorithm,"  We detail a procedure for the computation of the polynomial form of an
electronic combinational circuit from the design equations in a truth table.
The method uses the Buchberger algorithm rather than current traditional
methods based on search algorithms. We restrict the analysis to a single
output, but the procedure can be generalized to multiple outputs. The procedure
is illustrated with the design of a simple arithmetic and logic unit with two
3-bit operands and two control bits.
"
1881,"Int\'{e}gration de la synth\`{e}se m\'{e}moire dans l'outil de
  synth\`{e}se d'architecture GAUT Low Power","  The systems supporting signal and image applications process large amount of
data. That involves an intensive use of the memory which becomes the bottleneck
of systems. Memory limits performances and represents a significant proportion
of total consumption. In the development high level synthesis tool called GAUT
Low Power, we are interested in the synthesis of the memory unit. In this work,
we integrate the data storage and data transfert to constraint the high level
synthesis of the datapath's execution unit.
"
1882,High-level synthesis under I/O Timing and Memory constraints,"  The design of complex Systems-on-Chips implies to take into account
communication and memory access constraints for the integration of dedicated
hardware accelerator. In this paper, we present a methodology and a tool that
allow the High-Level Synthesis of DSP algorithm, under both I/O timing and
memory constraints. Based on formal models and a generic architecture, this
tool helps the designer to find a reasonable trade-off between both the
required I/O timing behavior and the internal memory access parallelism of the
circuit. The interest of our approach is demonstrated on the case study of a
FFT algorithm.
"
1883,A Memory Aware High Level Synthesis Too,"  We introduce a new approach to take into account the memory architecture and
the memory mapping in High- Level Synthesis for data intensive applications. We
formalize the memory mapping as a set of constraints for the synthesis, and
defined a Memory Constraint Graph and an accessibility criterion to be used in
the scheduling step. We use a memory mapping file to include those memory
constraints in our HLS tool GAUT. It is possible, with the help of GAUT, to
explore a wide range of solutions, and to reach a good tradeoff between time,
power-consumption, and area.
"
1884,Memory Aware High-Level Synthesis for Embedded Systems,"  We introduce a new approach to take into account the memory architecture and
the memory mapping in the High- Level Synthesis of Real-Time embedded systems.
We formalize the memory mapping as a set of constraints used in the scheduling
step. We use a memory mapping file to include those memory constraints in our
HLS tool GAUT. Our scheduling algorithm exhibits a relatively low complexity
that permits to tackle complex designs in a reasonable time. Finally, we show
how to explore, with the help of GAUT, a wide range of solutions, and to reach
a good tradeoff between time, power-consumption, and area.
"
1885,"Synth\`{e}se Comportementale Sous Contraintes de Communication et de
  Placement M\'{e}moire pour les composants du TDSI","  The design of complex Digital Signal Processing systems implies to minimize
architectural cost and to maximize timing performances while taking into
account communication and memory accesses constraints for the integration of
dedicated hardware accelerator. Unfortunately, the traditional Matlab/ Simulink
design flows gather not very flexible hardware blocs. In this paper, we present
a methodology and a tool that permit the High-Level Synthesis of DSP
applications, under both I/O timing and memory constraints. Based on formal
models and a generic architecture, our tool GAUT helps the designer in finding
a reasonable trade-off between the circuit's performance and its architectural
complexity. The efficiency of our approach is demonstrated on the case study of
a FFT algorithm.
"
1886,Concurrent Processing Memory,"  A theoretical memory with limited processing power and internal connectivity
at each element is proposed. This memory carries out parallel processing within
itself to solve generic array problems. The applicability of this in-memory
finest-grain massive SIMD approach is studied in some details. For an array of
N items, it reduces the total instruction cycle count of universal operations
such as insertion/deletion and match finding to ~ 1, local operations such as
filtering and template matching to ~ local operation size, and global
operations such as sum, finding global limit and sorting to ~\sqroot{N}
instruction cycles. It eliminates most streaming activities for data processing
purpose on the system bus. Yet it remains general-purposed, easy to use, pin
compatible with conventional memory, and practical for implementation.
"
1887,Design of multimedia processor based on metric computation,"  Media-processing applications, such as signal processing, 2D and 3D graphics
rendering, and image compression, are the dominant workloads in many embedded
systems today. The real-time constraints of those media applications have
taxing demands on today's processor performances with low cost, low power and
reduced design delay. To satisfy those challenges, a fast and efficient
strategy consists in upgrading a low cost general purpose processor core. This
approach is based on the personalization of a general RISC processor core
according the target multimedia application requirements. Thus, if the extra
cost is justified, the general purpose processor GPP core can be enforced with
instruction level coprocessors, coarse grain dedicated hardware, ad hoc
memories or new GPP cores. In this way the final design solution is tailored to
the application requirements. The proposed approach is based on three main
steps: the first one is the analysis of the targeted application using
efficient metrics. The second step is the selection of the appropriate
architecture template according to the first step results and recommendations.
The third step is the architecture generation. This approach is experimented
using various image and video algorithms showing its feasibility.
"
1888,The Effect of Scheduling on Link Capacity in Multi-hopWireless Networks,"  Existing models of Multi-Hop Wireless Networks (MHWNs) assume that
interference estimators of link quality such as observed busy time predict the
capacity of the links. We show that these estimators do not capture the
intricate interactions that occur at the scheduling level, which have a large
impact on effective link capacity under contention based MAC protocols. We
observe that scheduling problems arise only among those interfering sources
whose concurrent transmissions cannot be prevented by the MAC protocol's
collision management mechanisms; other interfering sources can arbitrate the
medium and coexist successfully. Based on this observation, we propose a
methodology for rating links and show that it achieves high correlation with
observed behavior in simulation. We then use this rating as part of a
branch-and-bound framework based on a linear programming formulation for
traffic engineering in static MHWNs and show that it achieves considerable
improvement in performance relative to interference based models.
"
1889,"Novel Reversible TSG Gate and Its Application for Designing Components
  of Primitive Reversible/Quantum ALU","  In recent years, reversible logic has emerged as a promising computing
paradigm having application in low power CMOS, quantum computing,
nanotechnology, and optical computing. The classical set of gates such as AND,
OR, and EXOR are not reversible. This paper utilizes a new 4 * 4 reversible
gate called TSG gate to build the components of a primitive reversible/quantum
ALU. The most significant aspect of the TSG gate is that it can work singly as
a reversible full adder, that is reversible full adder can now be implemented
with a single gate only. A Novel reversible 4:2 compressor is also designed
from the TSG gate which is later used to design a novel 8x8 reversible Wallace
tree multiplier. It is proved that the adder, 4:2 compressor and multiplier
architectures designed using the TSG gate are better than their counterparts
available in literature, in terms of number of reversible gates and garbage
outputs. This is perhaps, the first attempt to design a reversible 4:2
compressor and a reversible Wallace tree multiplier as far as existing
literature and our knowledge is concerned. Thus, this paper provides an initial
threshold to build more complex systems which can execute complicated
operations using reversible logic.
"
1890,"VLSI Implementation of RSA Encryption System Using Ancient Indian Vedic
  Mathematics","  This paper proposes the hardware implementation of RSA encryption/decryption
algorithm using the algorithms of Ancient Indian Vedic Mathematics that have
been modified to improve performance. The recently proposed hierarchical
overlay multiplier architecture is used in the RSA circuitry for multiplication
operation. The most significant aspect of the paper is the development of a
division architecture based on Straight Division algorithm of Ancient Indian
Vedic Mathematics and embedding it in RSA encryption/decryption circuitry for
improved efficiency. The coding is done in Verilog HDL and the FPGA synthesis
is done using Xilinx Spartan library. The results show that RSA circuitry
implemented using Vedic division and multiplication is efficient in terms of
area/speed compared to its implementation using conventional multiplication and
division architectures
"
1891,"Reversible Programmable Logic Array (RPLA) using Fredkin & Feynman Gates
  for Industrial Electronics and Applications","  In recent years, reversible logic has emerged as a promising computing
paradigm having application in low power CMOS, quantum computing,
nanotechnology, and optical computing. The classical set of gates such as AND,
OR, and EXOR are not reversible. In this paper, the authors have proposed
reversible programmable logic array (RPLA) architecture using reversible
Fredkin and Feynman gates. The proposed RPLA has n inputs and m outputs and can
realize m functions of n variables. In order to demonstrate the design of RPLA,
a 3 input RPLA is designed which can perform any 28 functions using the
combination of 8 min terms (23). Furthermore, the application of the designed 3
input RPLA is shown by implementing the full adder and full subtractor
functions through it.
"
1892,Reduced Area Low Power High Throughput BCD Adders for IEEE 754r Format,"  IEEE 754r is the ongoing revision to the IEEE 754 floating point standard and
a major enhancement to the standard is the addition of decimal format. Firstly,
this paper proposes novel two transistor AND and OR gates. The proposed AND
gate has no power supply, thus it can be referred as the Powerless AND gate.
Similarly, the proposed two transistor OR gate has no ground and can be
referred as Groundless OR. Secondly for IEEE 754r format, two novel BCD adders
called carry skip and carry look-ahead BCD adders are also proposed in this
paper. In order to design the carry look-ahead BCD adder, a novel 4 bit carry
look-ahead adder called NCLA is proposed which forms the basic building block
of the proposed carry look-ahead BCD adder. Finally, the proposed two
transistors AND and OR gates are used to provide the optimized small area low
power high throughput circuitries of the proposed BCD adders.
"
1893,A Non-anchored Unified Naming System for Ad Hoc Computing Environments,"  A ubiquitous computing environment consists of many resources that need to be
identified by users and applications. Users and developers require some way to
identify resources by human readable names. In addition, ubiquitous computing
environments impose additional requirements such as the ability to work well
with ad hoc situations and the provision of names that depend on context.
  The Non-anchored Unified Naming (NUN) system was designed to satisfy these
requirements. It is based on relative naming among resources and provides the
ability to name arbitrary types of resources. By having resources themselves
take part in naming, resources are able to able contribute their specialized
knowledge into the name resolution process, making context-dependent mapping of
names to resources possible. The ease of which new resource types can be added
makes it simple to incorporate new types of contextual information within
names.
  In this paper, we describe the naming system and evaluate its use.
"
1894,"Combined Integer and Floating Point Multiplication Architecture(CIFM)
  for FPGAs and Its Reversible Logic Implementation","  In this paper, the authors propose the idea of a combined integer and
floating point multiplier(CIFM) for FPGAs. The authors propose the replacement
of existing 18x18 dedicated multipliers in FPGAs with dedicated 24x24
multipliers designed with small 4x4 bit multipliers. It is also proposed that
for every dedicated 24x24 bit multiplier block designed with 4x4 bit
multipliers, four redundant 4x4 multiplier should be provided to enforce the
feature of self repairability (to recover from the faults). In the proposed
CIFM reconfigurability at run time is also provided resulting in low power. The
major source of motivation for providing the dedicated 24x24 bit multiplier
stems from the fact that single precision floating point multiplier requires
24x24 bit integer multiplier for mantissa multiplication. A reconfigurable,
self-repairable 24x24 bit multiplier (implemented with 4x4 bit multiply
modules) will ideally suit this purpose, making FPGAs more suitable for integer
as well floating point operations. A dedicated 4x4 bit multiplier is also
proposed in this paper. Moreover, in the recent years, reversible logic has
emerged as a promising technology having its applications in low power CMOS,
quantum computing, nanotechnology, and optical computing. It is not possible to
realize quantum computing without reversible logic. Thus, this paper also paper
provides the reversible logic implementation of the proposed CIFM. The
reversible CIFM designed and proposed here will form the basis of the
completely reversible FPGAs.
"
1895,Hard Disk Drive as a Magnetomechanical Logic Device,"  We consider the conditions how two binary numbers can be superimposed on the
same track with the use of different recording magnetic fields. As a result the
average magnetization of longitudinal medium along the track can have three
states: -M, 0 and +M. Possibility to perform logic operations with these states
is considered. We demonstrate OR, AND, XOR and NOT operations and discuss a
modification of a recording device.
"
1896,Power Assignment Problems in Wireless Communication,"  A fundamental class of problems in wireless communication is concerned with
the assignment of suitable transmission powers to wireless devices/stations
such that the resulting communication graph satisfies certain desired
properties and the overall energy consumed is minimized. Many concrete
communication tasks in a wireless network like broadcast, multicast,
point-to-point routing, creation of a communication backbone, etc. can be
regarded as such a power assignment problem.
  This paper considers several problems of that kind; for example one problem
studied before in \cite{Carrots, Bilo} aims to select and assign powers to $k$
of the stations such that all other stations are within reach of at least one
of the selected stations. We improve the running time for obtaining a
$(1+\epsilon)$-approximate solution for this problem from
$n^{((\alpha/\epsilon)^{O(d)})}$ as reported by Bilo et al. (\cite{Bilo}) to
$O(n+ {(\frac{k^{2d+1}}{\epsilon^d})}^{\min{\{2k, (\alpha/\epsilon)^{O(d)}
\}}})$ that is, we obtain a running time that is \emph{linear} in the network
size. Further results include a constant approximation algorithm for the TSP
problem under squared (non-metric!) edge costs, which can be employed to
implement a novel data aggregation protocol, as well as efficient schemes to
perform $k$-hop multicasts.
"
1897,"On the Correlation of Geographic and Network Proximity at Internet Edges
  and its Implications for Mobile Unicast and Multicast Routing","  Significant effort has been invested recently to accelerate handover
operations in a next generation mobile Internet. Corresponding works for
developing efficient mobile multicast management are emergent. Both problems
simultaneously expose routing complexity between subsequent points of
attachment as a characteristic parameter for handover performance in access
networks.
  As continuous mobility handovers necessarily occur between access routers
located in geographic vicinity, this paper investigates on the hypothesis that
geographically adjacent edge networks attain a reduced network distances as
compared to arbitrary Internet nodes. We therefore evaluate and analyze edge
distance distributions in various regions for clustered IP ranges on their
geographic location such as a city. We use traceroute to collect packet
forwarding path and round-trip-time of each intermediate node to scan-wise
derive an upper bound of the node distances. Results of different scanning
origins are compared to obtain the best estimation of network distance of each
pair. Our results are compared with corresponding analysis of CAIDA Skitter
data, overall leading to fairly stable, reproducible edge distance
distributions. As a first conclusion on expected impact on handover performance
measures, our results indicate a general optimum for handover anticipation time
in 802.11 networks of 25 ms.
"
1898,Petascale Computational Systems,"  Computational science is changing to be data intensive. Super-Computers must
be balanced systems; not just CPU farms but also petascale IO and networking
arrays. Anyone building CyberInfrastructure should allocate resources to
support a balanced Tier-1 through Tier-3 design.
"
1899,Empirical Measurements of Disk Failure Rates and Error Rates,"  The SATA advertised bit error rate of one error in 10 terabytes is
frightening. We moved 2 PB through low-cost hardware and saw five disk read
error events, several controller failures, and many system reboots caused by
security patches. We conclude that SATA uncorrectable read errors are not yet a
dominant system-fault source - they happen, but are rare compared to other
problems. We also conclude that UER (uncorrectable error rate) is not the
relevant metric for our needs. When an uncorrectable read error happens, there
are typically several damaged storage blocks (and many uncorrectable read
errors.) Also, some uncorrectable read errors may be masked by the operating
system. The more meaningful metric for data architects is Mean Time To Data
Loss (MTTDL.)
"
1900,Noise Limited Computational Speed,"  In modern transistor based logic gates, the impact of noise on computation
has become increasingly relevant since the voltage scaling strategy, aimed at
decreasing the dissipated power, has increased the probability of error due to
the reduced switching threshold voltages. In this paper we discuss the role of
noise in a two state model that mimic the dynamics of standard logic gates and
show that the presence of the noise sets a fundamental limit to the computing
speed. An optimal idle time interval that minimizes the error probability, is
derived.
"
1901,"Physarum machine: Implementation of Kolmogorov-Uspensky machine in
  biological substrat","  We implement Kolmogorov-Uspensky machine on a plasmodium of true slime mold
{\em Physarum polycephalum}. We provide experimental findings on realization of
the machine instructions, illustrate basic operations, and elements of
programming.
"
1902,Locally Served Network Computers,"  NCs are the natural evolution of PCs, ubiquitous computers everywhere. The
current vision of NCs requires two improbable developments: (1) inexpensive
high-bandwidth WAN links to the Internet, and (2) inexpensive centralized
servers. The large NC bandwidth requirements will force each home or office to
have a local server LAN attached to the NCs. These servers will be much less
expensive to purchase and manage than a centralized solution. Centralized staff
are expensive and unresponsive.
"
1903,Producing NLP-based On-line Contentware,"  For its internal needs as well as for commercial purposes, CDC Group has
produced several NLP-based on-line contentware applications for years. The
development process of such applications is subject to numerous constraints
such as quality of service, integration of new advances in NLP, direct
reactions from users, continuous versioning, short delivery deadlines and cost
control. Following this industrial and commercial experience, malleability of
the applications, their openness towards foreign components, efficiency of
applications and their ease of exploitation have appeared to be key points. In
this paper, we describe TalLab, a powerful architecture for on-line contentware
which fulfils these requirements.
"
1904,"Flysig: Dataflow Oriented Delay-Insensitive Processor for Rapid
  Prototyping of Signal Processing","  As the one-chip integration of HW-modules designed by different companies
becomes more and more popular reliability of a HW-design and evaluation of the
timing behavior during the prototype stage are absolutely necessary. One way to
guarantee reliability is the use of robust design styles, e.g.,
delay-insensitivity. For early timing evaluation two aspects must be
considered: a) The timing needs to be proportional to technology variations and
b) the implemented architecture should be identical for prototype and target.
The first can be met also by delay-insensitive implementation. The latter one
is the key point. A unified architecture is needed for prototyping as well as
implementation. Our new approach to rapid prototyping of signal processing
tasks is based on a configurable, delay-insensitive implemented processor
called Flysig. In essence, the Flysig processor can be understood as a complex
FPGA where the CLBs are substituted by bit-serial operators. In this paper the
general concept is detailed and first experimental results are given for
demonstration of the main advantages: delay-insensitive design style, direct
correspondence between prototyping and target architecture, high performance
and reasonable shortening of the design cycle.
"
1905,"Automatic Hardware Synthesis for a Hybrid Reconfigurable CPU Featuring
  Philips CPLDs","  A high-level architecture of a Hybrid Reconfigurable CPU, based on a
Philips-supported core processor, is introduced. It features the Philips XPLA2
CPLD as a reconfigurable functional unit. A compilation chain is presented, in
which automatic implementation of time-critical program segments in custom
hardware is performed. The entire process is transparent from the programmer's
point of view. The hardware synthesis module of the chain, which translates
segments of assembly code into a hardware netlist, is discussed in details.
Application examples are also presented.
"
1906,"Space-Efficient Routing Tables for Almost All Networks and the
  Incompressibility Method","  We use the incompressibility method based on Kolmogorov complexity to
determine the total number of bits of routing information for almost all
network topologies. In most models for routing, for almost all labeled graphs
$\Theta (n^2)$ bits are necessary and sufficient for shortest path routing. By
`almost all graphs' we mean the Kolmogorov random graphs which constitute a
fraction of $1-1/n^c$ of all graphs on $n$ nodes, where $c > 0$ is an arbitrary
fixed constant. There is a model for which the average case lower bound rises
to $\Omega(n^2 \log n)$ and another model where the average case upper bound
drops to $O(n \log^2 n)$. This clearly exposes the sensitivity of such bounds
to the model under consideration. If paths have to be short, but need not be
shortest (if the stretch factor may be larger than 1), then much less space is
needed on average, even in the more demanding models. Full-information routing
requires $\Theta (n^3)$ bits on average. For worst-case static networks we
prove a $\Omega(n^2 \log n)$ lower bound for shortest path routing and all
stretch factors $<2$ in some networks where free relabeling is not allowed.
"
1907,"Processor Verification Using Efficient Reductions of the Logic of
  Uninterpreted Functions to Propositional Logic","  The logic of equality with uninterpreted functions (EUF) provides a means of
abstracting the manipulation of data by a processor when verifying the
correctness of its control logic. By reducing formulas in this logic to
propositional formulas, we can apply Boolean methods such as Ordered Binary
Decision Diagrams (BDDs) and Boolean satisfiability checkers to perform the
verification.
  We can exploit characteristics of the formulas describing the verification
conditions to greatly simplify the propositional formulas generated. In
particular, we exploit the property that many equations appear only in positive
form. We can therefore reduce the set of interpretations of the function
symbols that must be considered to prove that a formula is universally valid to
those that are ``maximally diverse.''
  We present experimental results demonstrating the efficiency of this approach
when verifying pipelined processors using the method proposed by Burch and
Dill.
"
1908,"Scalability Terminology: Farms, Clones, Partitions, Packs, RACS and RAPS","  Defines a vocabulary for scaleable systems: Geoplexes, Farms, Clones, RACS,
RAPS, clones, partitions, and packs and dicusses the design tradeoffs of using
clones, partitons, and packs.
"
1909,Chaos in computer performance,"  Modern computer microprocessors are composed of hundreds of millions of
transistors that interact through intricate protocols. Their performance during
program execution may be highly variable and present aperiodic oscillations. In
this paper, we apply current nonlinear time series analysis techniques to the
performances of modern microprocessors during the execution of prototypical
programs. Our results present pieces of evidence strongly supporting that the
high variability of the performance dynamics during the execution of several
programs display low-dimensional deterministic chaos, with sensitivity to
initial conditions comparable to textbook models. Taken together, these results
show that the instantaneous performances of modern microprocessors constitute a
complex (or at least complicated) system and would benefit from analysis with
modern tools of nonlinear and complexity science.
"
1910,"Characterizing Self-Developing Biological Neural Networks: A First Step
  Towards their Application To Computing Systems","  Carbon nanotubes are often seen as the only alternative technology to silicon
transistors. While they are the most likely short-term one, other longer-term
alternatives should be studied as well. While contemplating biological neurons
as an alternative component may seem preposterous at first sight, significant
recent progress in CMOS-neuron interface suggests this direction may not be
unrealistic; moreover, biological neurons are known to self-assemble into very
large networks capable of complex information processing tasks, something that
has yet to be achieved with other emerging technologies. The first step to
designing computing systems on top of biological neurons is to build an
abstract model of self-assembled biological neural networks, much like computer
architects manipulate abstract models of transistors and circuits. In this
article, we propose a first model of the structure of biological neural
networks. We provide empirical evidence that this model matches the biological
neural networks found in living organisms, and exhibits the small-world graph
structure properties commonly found in many large and self-organized systems,
including biological neural networks. More importantly, we extract the simple
local rules and characteristics governing the growth of such networks, enabling
the development of potentially large but realistic biological neural networks,
as would be needed for complex information processing/computing tasks. Based on
this model, future work will be targeted to understanding the evolution and
learning properties of such networks, and how they can be used to build
computing systems.
"
