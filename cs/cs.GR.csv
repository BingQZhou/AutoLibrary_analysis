,title,abstract
0,User driven applications - new design paradigm,"  Programs for complicated engineering and scientific tasks always have to deal
with a problem of showing numerous graphical results. The limits of the screen
space and often opposite requirements from different users are the cause of the
infinite discussions between designers and users, but the source of this
ongoing conflict is not in the level of interface design, but in the basic
principle of current graphical output: user may change some views and details,
but in general the output view is absolutely defined and fixed by the
developer. Author was working for several years on the algorithm that will
allow eliminating this problem thus allowing stepping from designer-driven
applications to user-driven. Such type of applications in which user is
deciding what, when and how to show on the screen, is the dream of scientists
and engineers working on the analysis of the most complicated tasks. The new
paradigm is based on movable and resizable graphics, and such type of graphics
can be widely used not only for scientific and engineering applications.
"
1,"The Trade-offs with Space Time Cube Representation of Spatiotemporal
  Patterns","  Space time cube representation is an information visualization technique
where spatiotemporal data points are mapped into a cube. Fast and correct
analysis of such information is important in for instance geospatial and social
visualization applications. Information visualization researchers have
previously argued that space time cube representation is beneficial in
revealing complex spatiotemporal patterns in a dataset to users. The argument
is based on the fact that both time and spatial information are displayed
simultaneously to users, an effect difficult to achieve in other
representations. However, to our knowledge the actual usefulness of space time
cube representation in conveying complex spatiotemporal patterns to users has
not been empirically validated. To fill this gap we report on a
between-subjects experiment comparing novice users error rates and response
times when answering a set of questions using either space time cube or a
baseline 2D representation. For some simple questions the error rates were
lower when using the baseline representation. For complex questions where the
participants needed an overall understanding of the spatiotemporal structure of
the dataset, the space time cube representation resulted in on average twice as
fast response times with no difference in error rates compared to the baseline.
These results provide an empirical foundation for the hypothesis that space
time cube representation benefits users when analyzing complex spatiotemporal
patterns.
"
2,"Network synchronizability analysis: the theory of subgraphs and
  complementary graphs","  In this paper, subgraphs and complementary graphs are used to analyze the
network synchronizability. Some sharp and attainable bounds are provided for
the eigenratio of the network structural matrix, which characterizes the
network synchronizability, especially when the network's corresponding graph
has cycles, chains, bipartite graphs or product graphs as its subgraphs.
"
3,"Virtual Environments for Training: From Individual Learning to
  Collaboration with Humanoids","  The next generation of virtual environments for training is oriented towards
collaborative aspects. Therefore, we have decided to enhance our platform for
virtual training environments, adding collaboration opportunities and
integrating humanoids. In this paper we put forward a model of humanoid that
suits both virtual humans and representations of real users, according to
collaborative training activities. We suggest adaptations to the scenario model
of our platform making it possible to write collaborative procedures. We
introduce a mechanism of action selection made up of a global repartition and
an individual choice. These models are currently being integrated and validated
in GVT, a virtual training tool for maintenance of military equipments,
developed in collaboration with the French company NEXTER-Group.
"
4,"Simple Algorithmic Principles of Discovery, Subjective Beauty, Selective
  Attention, Curiosity & Creativity","  I postulate that human or other intelligent agents function or should
function as follows. They store all sensory observations as they come - the
data is holy. At any time, given some agent's current coding capabilities, part
of the data is compressible by a short and hopefully fast program / description
/ explanation / world model. In the agent's subjective eyes, such data is more
regular and more ""beautiful"" than other data. It is well-known that knowledge
of regularity and repeatability may improve the agent's ability to plan actions
leading to external rewards. In absence of such rewards, however, known beauty
is boring. Then ""interestingness"" becomes the first derivative of subjective
beauty: as the learning agent improves its compression algorithm, formerly
apparently random data parts become subjectively more regular and beautiful.
Such progress in compressibility is measured and maximized by the curiosity
drive: create action sequences that extend the observation history and yield
previously unknown / unpredictable but quickly learnable algorithmic
regularity. We discuss how all of the above can be naturally implemented on
computers, through an extension of passive unsupervised learning to the case of
active data selection: we reward a general reinforcement learner (with access
to the adaptive compressor) for actions that improve the subjective
compressibility of the growing data. An unusually large breakthrough in
compressibility deserves the name ""discovery"". The ""creativity"" of artists,
dancers, musicians, pure mathematicians can be viewed as a by-product of this
principle. Several qualitative examples support this hypothesis.
"
5,Design of moveable and resizable graphics,"  We are communicating with computers on two different levels. On upper level
we have a very flexible system of windows: we can move them, resize, overlap or
put side by side. At any moment we decide what would be the best view and
reorganize the whole view easily. Then we start any application, go to the
inner level, and everything changes. Here we are stripped of all the
flexibility and can work only inside the scenario, developed by the designer of
the program. Interface will allow us to change some tiny details, but in
general everything is fixed: graphics is neither moveable, nor resizable, and
the same with controls. Author designed an extremely powerful mechanism of
turning graphical objects and controls into moveable and resizable. This can
not only significantly improve the existing applications, but this will bring
the applications to another level. (To estimate the possible difference, try to
imagine the Windows system without its flexibility and compare it with the
current one.) This article explains in details the construction and use of
moveable and resizable graphical objects.
"
6,"Efficient Binary and Run Length Morphology and its Application to
  Document Image Processing","  This paper describes the implementation and evaluation of an open source
library for mathematical morphology based on packed binary and run-length
compressed images for document imaging applications. Abstractions and patterns
useful in the implementation of the interval operations are described. A number
of benchmarks and comparisons to bit-blit based implementations on standard
document images are provided.
"
7,Dynamic Multilevel Graph Visualization,"  We adapt multilevel, force-directed graph layout techniques to visualizing
dynamic graphs in which vertices and edges are added and removed in an online
fashion (i.e., unpredictably). We maintain multiple levels of coarseness using
a dynamic, randomized coarsening algorithm. To ensure the vertices follow
smooth trajectories, we employ dynamics simulation techniques, treating the
vertices as point particles. We simulate fine and coarse levels of the graph
simultaneously, coupling the dynamics of adjacent levels. Projection from
coarser to finer levels is adaptive, with the projection determined by an
affine transformation that evolves alongside the graph layouts. The result is a
dynamic graph visualizer that quickly and smoothly adapts to changes in a
graph.
"
8,Toward the Graphics Turing Scale on a Blue Gene Supercomputer,"  We investigate raytracing performance that can be achieved on a class of Blue
Gene supercomputers. We measure a 822 times speedup over a Pentium IV on a 6144
processor Blue Gene/L. We measure the computational performance as a function
of number of processors and problem size to determine the scaling performance
of the raytracing calculation on the Blue Gene. We find nontrivial scaling
behavior at large number of processors. We discuss applications of this
technology to scientific visualization with advanced lighting and high
resolution. We utilize three racks of a Blue Gene/L in our calculations which
is less than three percent of the the capacity of the worlds largest Blue Gene
computer.
"
9,MathPSfrag 2: Convenient LaTeX Labels in Mathematica,"  This article introduces the next version of MathPSfrag. MathPSfrag is a
Mathematica package that during export automatically replaces all expressions
in a plot by corresponding LaTeX commands. The new version can also produce
LaTeX independent images; e.g., PDF files for inclusion in pdfLaTeX. Moreover
from these files a preview is generated and shown within Mathematica.
"
10,Multiple Uncertainties in Time-Variant Cosmological Particle Data,"  Though the mediums for visualization are limited, the potential dimensions of
a dataset are not. In many areas of scientific study, understanding the
correlations between those dimensions and their uncertainties is pivotal to
mining useful information from a dataset. Obtaining this insight can
necessitate visualizing the many relationships among temporal, spatial, and
other dimensionalities of data and its uncertainties. We utilize multiple views
for interactive dataset exploration and selection of important features, and we
apply those techniques to the unique challenges of cosmological particle
datasets. We show how interactivity and incorporation of multiple visualization
techniques help overcome the problem of limited visualization dimensions and
allow many types of uncertainty to be seen in correlation with other variables.
"
11,Complex Eigenvalues for Binary Subdivision Schemes,"  Convergence properties of binary stationary subdivision schemes for curves
have been analyzed using the techniques of z-transforms and eigenanalysis.
Eigenanalysis provides a way to determine derivative continuity at specific
points based on the eigenvalues of a finite matrix. None of the well-known
subdivision schemes for curves have complex eigenvalues. We prove when a
convergent scheme with palindromic mask can have complex eigenvalues and that a
lower limit for the size of the mask exists in this case. We find a scheme with
complex eigenvalues achieving this lower bound. Furthermore we investigate this
scheme numerically and explain from a geometric viewpoint why such a scheme has
not yet been used in computer-aided geometric design.
"
12,Discrete Complex Structure on Surfel Surfaces,"  This paper defines a theory of conformal parametrization of digital surfaces
made of surfels equipped with a normal vector. The main idea is to locally
project each surfel to the tangent plane, therefore deforming its aspect-ratio.
It is a generalization of the theory known for polyhedral surfaces. The main
difference is that the conformal ratios that appear are no longer real in
general. It yields a generalization of the standard Laplacian on weighted
graphs.
"
13,PVM-Distributed Implementation of the Radiance Code,"  The Parallel Virtual Machine (PVM) tool has been used for a distributed
implementation of Greg Ward's Radiance code. In order to generate exactly the
same primary rays with both the sequential and the parallel codes, the quincunx
sampling technique used in Radiance for the reduction of the number of primary
rays by interpolation, must be left untouched in the parallel implementation.
The octree of local ambient values used in Radiance for the indirect
illumination has been shared among all the processors. Both static and dynamic
image partitioning techniques which replicate the octree of the complete scene
in all the processors and have load-balancing, have been developed for one
frame rendering. Speedups larger than 7.5 have been achieved in a network of 8
workstations. For animation sequences, a new dynamic partitioning distribution
technique with superlinear speedups has also been developed.
"
14,"Realistic Haptic Rendering of Interacting Deformable Objects in Virtual
  Environments","  A new computer haptics algorithm to be used in general interactive
manipulations of deformable virtual objects is presented. In multimodal
interactive simulations, haptic feedback computation often comes from contact
forces. Subsequently, the fidelity of haptic rendering depends significantly on
contact space modeling. Contact and friction laws between deformable models are
often simplified in up to date methods. They do not allow a ""realistic""
rendering of the subtleties of contact space physical phenomena (such as slip
and stick effects due to friction or mechanical coupling between contacts). In
this paper, we use Signorini's contact law and Coulomb's friction law as a
computer haptics basis. Real-time performance is made possible thanks to a
linearization of the behavior in the contact space, formulated as the so-called
Delassus operator, and iteratively solved by a Gauss-Seidel type algorithm.
Dynamic deformation uses corotational global formulation to obtain the Delassus
operator in which the mass and stiffness ratio are dissociated from the
simulation time step. This last point is crucial to keep stable haptic
feedback. This global approach has been packaged, implemented, and tested.
Stable and realistic 6D haptic feedback is demonstrated through a clipping task
experiment.
"
15,Discrete schemes for Gaussian curvature and their convergence,"  In this paper, several discrete schemes for Gaussian curvature are surveyed.
The convergence property of a modified discrete scheme for the Gaussian
curvature is considered. Furthermore, a new discrete scheme for Gaussian
curvature is resented. We prove that the new scheme converges at the regular
vertex with valence not less than 5. By constructing a counterexample, we also
show that it is impossible for building a discrete scheme for Gaussian
curvature which converges over the regular vertex with valence 4. Finally,
asymptotic errors of several discrete scheme for Gaussian curvature are
compared.
"
16,"Size matters: performance declines if your pixels are too big or too
  small","  We present a conceptual model that describes the effect of pixel size on
target acquisition. We demonstrate the use of our conceptual model by applying
it to predict and explain the results of an experiment to evaluate users'
performance in a target acquisition task involving three distinct display
sizes: standard desktop, small and large displays. The results indicate that
users are fastest on standard desktop displays, undershoots are the most common
error on small displays and overshoots are the most common error on large
displays. We propose heuristics to maintain usability when changing displays.
Finally, we contribute to the growing body of evidence that amplitude does
affect performance in a display-based pointing task.
"
17,Morphing of Triangular Meshes in Shape Space,"  We present a novel approach to morph between two isometric poses of the same
non-rigid object given as triangular meshes. We model the morphs as linear
interpolations in a suitable shape space $\mathcal{S}$. For triangulated 3D
polygons, we prove that interpolating linearly in this shape space corresponds
to the most isometric morph in $\mathbb{R}^3$. We then extend this shape space
to arbitrary triangulations in 3D using a heuristic approach and show the
practical use of the approach using experiments. Furthermore, we discuss a
modified shape space that is useful for isometric skeleton morphing. All of the
newly presented approaches solve the morphing problem without the need to solve
a minimization problem.
"
18,Neural networks in 3D medical scan visualization,"  For medical volume visualization, one of the most important tasks is to
reveal clinically relevant details from the 3D scan (CT, MRI ...), e.g. the
coronary arteries, without obscuring them with less significant parts. These
volume datasets contain different materials which are difficult to extract and
visualize with 1D transfer functions based solely on the attenuation
coefficient. Multi-dimensional transfer functions allow a much more precise
classification of data which makes it easier to separate different surfaces
from each other. Unfortunately, setting up multi-dimensional transfer functions
can become a fairly complex task, generally accomplished by trial and error.
This paper explains neural networks, and then presents an efficient way to
speed up visualization process by semi-automatic transfer function generation.
We describe how to use neural networks to detect distinctive features shown in
the 2D histogram of the volume data and how to use this information for data
classification.
"
19,"Quasi-Mandelbrot sets for perturbed complex analytic maps: visual
  patterns","  We consider perturbations of the complex quadratic map $ z \to z^2 +c$ and
corresponding changes in their quasi-Mandelbrot sets. Depending on particular
perturbation, visual forms of quasi-Mandelbrot set changes either sharply (when
the perturbation reaches some critical value) or continuously. In the latter
case we have a smooth transition from the classical form of the set to some
forms, constructed from mostly linear structures, as it is typical for
two-dimensional real number dynamics. Two examples of continuous evolution of
the quasi-Mandelbrot set are described.
"
20,On the role of metaphor in information visualization,"  The concept of metaphor, in particular graphical (or visual) metaphor, is
central to the field of information visualization. Information graphics and
interactive information visualization systems employ a variety of metaphorical
devices to make abstract, complex, voluminous, or otherwise
difficult-to-comprehend information understandable in graphical terms. This
paper explores the use of metaphor in information visualization, advancing the
theory previously argued by Johnson, Lakoff, Tversky et al. that many
information graphics are metaphorically understood in terms of cognitively
entrenched spatial patterns known as image schemas. These patterns serve to
structure and constrain abstract reasoning processes via metaphorical
projection operations that are grounded in everyday perceptual experiences with
phenomena such as containment, movement, and force dynamics. Building on
previous research, I argue that information graphics promote comprehension of
their target information through the use of graphical patterns that invoke
these preexisting schematic structures. I further theorize that the degree of
structural alignment of a particular graphic with one or more corresponding
image schemas accounts for its perceived degree of intuitiveness. Accordingly,
image schema theory can provide a powerful explanatory and predictive framework
for visualization research. I review relevant theories of analogy and metaphor,
and discuss the image schematic properties of several common types of
information graphic. I conclude with the proposal that the inventory of image
schemas culled from linguistic studies can serve as the basis for an inventory
of design elements suitable for developing intuitive and effective new
information visualization techniques.
"
21,"Perspective Drawing of Surfaces with Line Hidden Line Elimination,
  Dibujando Superficies En Perspectiva Con Eliminacion De Lineas Ocultas","  An efficient computer algorithm is described for the perspective drawing of a
wide class of surfaces. The class includes surfaces corresponding lo
single-valued, continuous functions which are defined over rectangular domains.
The algorithm automatically computes and eliminates hidden lines. The number of
computations in the algorithm grows linearly with the number of sample points
on the surface to be drawn. An analysis of the algorithm is presented, and
extensions lo certain multi-valued functions are indicated. The algorithm is
implemented and tested on .Net 2.0 platform that left interactive use. Running
times are found lo be exceedingly efficient for visualization, where
interaction on-line and view-point control, enables effective and rapid
examination of a surfaces from many perspectives.
"
22,Visualization Optimization : Application to the RoboCup Rescue Domain,"  In this paper we demonstrate the use of intelligent optimization
methodologies on the visualization optimization of virtual / simulated
environments. The problem of automatic selection of an optimized set of views,
which better describes an on-going simulation over a virtual environment is
addressed in the context of the RoboCup Rescue Simulation domain. A generic
architecture for optimization is proposed and described. We outline the
possible extensions of this architecture and argue on how several problems
within the fields of Interactive Rendering and Visualization can benefit from
it.
"
23,Detecting the Most Unusual Part of a Digital Image,"  The purpose of this paper is to introduce an algorithm that can detect the
most unusual part of a digital image. The most unusual part of a given shape is
defined as a part of the image that has the maximal distance to all non
intersecting shapes with the same form.
  The method can be used to scan image databases with no clear model of the
interesting part or large image databases, as for example medical databases.
"
24,Interchanging Interactive 3-d Graphics for Astronomy,"  We demonstrate how interactive, three-dimensional (3-d) scientific
visualizations can be efficiently interchanged between a variety of mediums.
Through the use of an appropriate interchange format, and a unified interaction
interface, we minimize the effort to produce visualizations appropriate for
undertaking knowledge discovery at the astronomer's desktop, as part of
conference presentations, in digital publications or as Web content. We use
examples from cosmological visualization to address some of the issues of
interchange, and to describe our approach to adapting S2PLOT desktop
visualizations to the Web.
  Supporting demonstrations are available at
http://astronomy.swin.edu.au/s2plot/interchange/
"
25,"GPU-Based Interactive Visualization of Billion Point Cosmological
  Simulations","  Despite the recent advances in graphics hardware capabilities, a brute force
approach is incapable of interactively displaying terabytes of data. We have
implemented a system that uses hierarchical level-of-detailing for the results
of cosmological simulations, in order to display visually accurate results
without loading in the full dataset (containing over 10 billion points). The
guiding principle of the program is that the user should not be able to
distinguish what they are seeing from a full rendering of the original data.
Furthermore, by using a tree-based system for levels of detail, the size of the
underlying data is limited only by the capacity of the IO system containing it.
"
26,String Art: Circle Drawing Using Straight Lines,"  An algorithm to generate the locus of a circle using the intersection points
of straight lines is proposed. The pixels on the circle are plotted independent
of one another and the operations involved in finding the locus of the circle
from the intersection of straight lines are parallelizable. Integer only
arithmetic and algorithmic optimizations are used for speedup. The proposed
algorithm makes use of an envelope to form a parabolic arc which is consequent
transformed into a circle. The use of parabolic arcs for the transformation
results in higher pixel errors as the radius of the circle to be drawn
increases. At its current state, the algorithm presented may be suitable only
for generating circles for string art.
"
27,"The Good, the Bad, and the Ugly: three different approaches to break
  their watermarking system","  The Good is Blondie, a wandering gunman with a strong personal sense of
honor. The Bad is Angel Eyes, a sadistic hitman who always hits his mark. The
Ugly is Tuco, a Mexican bandit who's always only looking out for himself.
Against the backdrop of the BOWS contest, they search for a watermark in gold
buried in three images. Each knows only a portion of the gold's exact location,
so for the moment they're dependent on each other. However, none are
particularly inclined to share...
"
28,"Strong Spatial Mixing and Approximating Partition Functions of Two-State
  Spin Systems without Hard Constrains","  We prove Gibbs distribution of two-state spin systems(also known as binary
Markov random fields) without hard constrains on a tree exhibits strong spatial
mixing(also known as strong correlation decay), under the assumption that, for
arbitrary `external field', the absolute value of `inverse temperature' is
small, or the `external field' is uniformly large or small. The first condition
on `inverse temperature' is tight if the distribution is restricted to
ferromagnetic or antiferromagnetic Ising models.
  Thanks to Weitz's self-avoiding tree, we extends the result for sparse on
average graphs, which generalizes part of the recent work of Mossel and
Sly\cite{MS08}, who proved the strong spatial mixing property for ferromagnetic
Ising model. Our proof yields a different approach, carefully exploiting the
monotonicity of local recursion. To our best knowledge, the second condition of
`external field' for strong spatial mixing in this paper is first considered
and stated in term of `maximum average degree' and `interaction energy'. As an
application, we present an FPTAS for partition functions of two-state spin
models without hard constrains under the above assumptions in a general family
of graphs including interesting bounded degree graphs.
"
29,"Linear-Time Algorithms for Geometric Graphs with Sublinearly Many Edge
  Crossings","  We provide linear-time algorithms for geometric graphs with sublinearly many
crossings. That is, we provide algorithms running in O(n) time on connected
geometric graphs having n vertices and k crossings, where k is smaller than n
by an iterated logarithmic factor. Specific problems we study include Voronoi
diagrams and single-source shortest paths. Our algorithms all run in linear
time in the standard comparison-based computational model; hence, we make no
assumptions about the distribution or bit complexities of edge weights, nor do
we utilize unusual bit-level operations on memory words. Instead, our
algorithms are based on a planarization method that ""zeroes in"" on edge
crossings, together with methods for extending planar separator decompositions
to geometric graphs with sublinearly many crossings. Incidentally, our
planarization algorithm also solves an open computational geometry problem of
Chazelle for triangulating a self-intersecting polygonal chain having n
segments and k crossings in linear time, for the case when k is sublinear in n
by an iterated logarithmic factor.
"
30,An analysis of a random algorithm for estimating all the matchings,"  Counting the number of all the matchings on a bipartite graph has been
transformed into calculating the permanent of a matrix obtained from the
extended bipartite graph by Yan Huo, and Rasmussen presents a simple approach
(RM) to approximate the permanent, which just yields a critical ratio
O($n\omega(n)$) for almost all the 0-1 matrices, provided it's a simple
promising practical way to compute this #P-complete problem. In this paper, the
performance of this method will be shown when it's applied to compute all the
matchings based on that transformation. The critical ratio will be proved to be
very large with a certain probability, owning an increasing factor larger than
any polynomial of $n$ even in the sense for almost all the 0-1 matrices. Hence,
RM fails to work well when counting all the matchings via computing the
permanent of the matrix. In other words, we must carefully utilize the known
methods of estimating the permanent to count all the matchings through that
transformation.
"
31,Polyomino-Based Digital Halftoning,"  In this work, we present a new method for generating a threshold structure.
This kind of structure can be advantageously used in various halftoning
algorithms such as clustered-dot or dispersed-dot dithering, error diffusion
with threshold modulation, etc. The proposed method is based on rectifiable
polyominoes -- a non-periodic hierarchical structure, which tiles the Euclidean
plane with no gaps. Each polyomino contains a fixed number of discrete
threshold values. Thanks to its inherent non-periodic nature combined with
off-line optimization of threshold values, our polyomino-based threshold
structure shows blue-noise spectral properties. The halftone images produced
with this threshold structure have high visual quality. Although the proposed
method is general, and can be applied on any polyomino tiling, we consider one
particular case: tiling with G-hexominoes. We compare our polyomino-based
threshold structure with the best known state-of-the-art methods for generation
threshold matrices, and conclude considerable improvement achieved with our
method.
"
32,Visual tool for estimating the fractal dimension of images,"  This work presents a new Visual Basic 6.0 application for estimating the
fractal dimension of images, based on an optimized version of the box-counting
algorithm. Following the attempt to separate the real information from noise,
we considered also the family of all band-pass filters with the same band-width
(specified as parameter). The fractal dimension can be thus represented as a
function of the pixel color code. The program was used for the study of
paintings cracks, as an additional tool which can help the critic to decide if
an artistic work is original or not. In its second version, the application was
extended for working also with csv files and three-dimensional images.
"
33,A Standalone Markerless 3D Tracker for Handheld Augmented Reality,"  This paper presents an implementation of a markerless tracking technique
targeted to the Windows Mobile Pocket PC platform. The primary aim of this work
is to allow the development of standalone augmented reality applications for
handheld devices based on natural feature tracking. In order to achieve this
goal, a subset of two computer vision libraries was ported to the Pocket PC
platform. They were also adapted to use fixed point math, with the purpose of
improving the overall performance of the routines. The port of these libraries
opens up the possibility of having other computer vision tasks being executed
on mobile platforms. A model based tracking approach that relies on edge
information was adopted. Since it does not require a high processing power, it
is suitable for constrained devices such as handhelds. The OpenGL ES graphics
library was used to perform computer vision tasks, taking advantage of existing
graphics hardware acceleration. An augmented reality application was created
using the implemented technique and evaluations were done regarding tracking
performance and accuracy
"
34,The Digital Restoration of Da Vinci's Sketches,"  A sketch, found in one of Leonardo da Vinci's notebooks and covered by the
written notes of this genius, has been recently restored. The restoration
reveals a possible self-portrait of the artist, drawn when he was young. Here,
we discuss the discovery of this self-portrait and the procedure used for
restoration. Actually, this is a restoration performed on the digital image of
the sketch, a procedure that can easily extended and applied to ancient
documents for studies of art and palaeography.
"
35,"Adaptive Mesh Approach for Predicting Algorithm Behavior with
  Application to Visibility Culling in Computer Graphics","  We propose a concise approximate description, and a method for efficiently
obtaining this description, via adaptive random sampling of the performance
(running time, memory consumption, or any other profileable numerical quantity)
of a given algorithm on some low-dimensional rectangular grid of inputs. The
formal correctness is proven under reasonable assumptions on the algorithm
under consideration; and the approach's practical benefit is demonstrated by
predicting for which observer positions and viewing directions an occlusion
culling algorithm yields a net performance benefit or loss compared to a simple
brute force renderer.
"
36,"Ambient Isotopic Meshing of Implicit Algebraic Surface with
  Singularities","  A complete method is proposed to compute a certified, or ambient isotopic,
meshing for an implicit algebraic surface with singularities. By certified, we
mean a meshing with correct topology and any given geometric precision. We
propose a symbolic-numeric method to compute a certified meshing for the
surface inside a box containing singularities and use a modified
Plantinga-Vegter marching cube method to compute a certified meshing for the
surface inside a box without singularities. Nontrivial examples are given to
show the effectiveness of the algorithm. To our knowledge, this is the first
method to compute a certified meshing for surfaces with singularities.
"
37,"A Distributed Software Architecture for Collaborative Teleoperation
  based on a VR Platform and Web Application Interoperability","  Augmented Reality and Virtual Reality can provide to a Human Operator (HO) a
real help to complete complex tasks, such as robot teleoperation and
cooperative teleassistance. Using appropriate augmentations, the HO can
interact faster, safer and easier with the remote real world. In this paper, we
present an extension of an existing distributed software and network
architecture for collaborative teleoperation based on networked human-scaled
mixed reality and mobile platform. The first teleoperation system was composed
by a VR application and a Web application. However the 2 systems cannot be used
together and it is impossible to control a distant robot simultaneously. Our
goal is to update the teleoperation system to permit a heterogeneous
collaborative teleoperation between the 2 platforms. An important feature of
this interface is based on different Mobile platforms to control one or many
robots.
"
38,On the Complexity of Smooth Spline Surfaces from Quad Meshes,"  This paper derives strong relations that boundary curves of a smooth complex
of patches have to obey when the patches are computed by local averaging. These
relations restrict the choice of reparameterizations for geometric continuity.
In particular, when one bicubic tensor-product B-spline patch is associated
with each facet of a quadrilateral mesh with n-valent vertices and we do not
want segments of the boundary curves forced to be linear, then the relations
dictate the minimal number and multiplicity of knots: For general data, the
tensor-product spline patches must have at least two internal double knots per
edge to be able to model a G^1-conneced complex of C^1 splines. This lower
bound on the complexity of any construction is proven to be sharp by suitably
interpreting an existing surface construction. That is, we have a tight bound
on the complexity of smoothing quad meshes with bicubic tensor-product B-spline
patches.
"
39,A Neural Network Classifier of Volume Datasets,"  Many state-of-the art visualization techniques must be tailored to the
specific type of dataset, its modality (CT, MRI, etc.), the recorded object or
anatomical region (head, spine, abdomen, etc.) and other parameters related to
the data acquisition process. While parts of the information (imaging modality
and acquisition sequence) may be obtained from the meta-data stored with the
volume scan, there is important information which is not stored explicitly
(anatomical region, tracing compound). Also, meta-data might be incomplete,
inappropriate or simply missing.
  This paper presents a novel and simple method of determining the type of
dataset from previously defined categories. 2D histograms based on intensity
and gradient magnitude of datasets are used as input to a neural network, which
classifies it into one of several categories it was trained with. The proposed
method is an important building block for visualization systems to be used
autonomously by non-experts. The method has been tested on 80 datasets, divided
into 3 classes and a ""rest"" class.
  A significant result is the ability of the system to classify datasets into a
specific class after being trained with only one dataset of that class. Other
advantages of the method are its easy implementation and its high computational
performance.
"
40,"Feynman Algorithm Implementation for Comparison with Euler in a Uniform
  Elastic Two-Layer 2D and 3D Object Dynamic Deformation Framework in OpenGL
  with GUI","  We implement for comparative purposes the Feynman algorithm within a
C++-based framework for two-layer uniform facet elastic object for real-time
softbody simulation based on physics modeling methods. To facilitate the
comparison, we implement initial timing measurements on the same hardware
against that of Euler integrator in the softbody framework by varying different
algorithm parameters. Due to a relatively large number of such variations we
implement a GLUI-based user-interface to allow for much more finer control over
the simulation process at real-time, which was lacking completely in the
previous versions of the framework. We show our currents results based on the
enhanced framework. The two-layered elastic object consists of inner and outer
elastic mass-spring surfaces and compressible internal pressure. The density of
the inner layer can be set differently from the density of the outer layer; the
motion of the inner layer can be opposite to the motion of the outer layer.
These special features, which cannot be achieved by a single layered object,
result in improved imitation of a soft body, such as tissue's liquid
non-uniform deformation. The inertial behavior of the elastic object is well
illustrated in environments with gravity and collisions with walls, ceiling,
and floor. The collision detection is defined by elastic collision penalty
method and the motion of the object is guided by the Ordinary Differential
Equation computation. Users can interact with the modeled objects, deform them,
and observe the response to their action in real-time and we provide an
extensible framework and its implementation for comparative studies of
different physical-based modeling and integration algorithm implementations.
"
41,"Personal applications, based on moveable / resizable elements","  All the modern day applications have the interface, absolutely defined by the
developers. The use of adaptive interface or dynamic layout allows some
variations, but even all of them are predetermined on the design stage, because
the best reaction (from designer's view) on any possible users' movement was
hardcoded. But there is a different world of applications, totally constructed
on moveable / resizable elements; such applications turn the full control to
the users. The crucial thing in such programs is that not something but
everything must become moveable and resizable. This article describes the
features of such applications and the algorithm behind their design.
"
42,Physical Modeling Techniques in Active Contours for Image Segmentation,"  Physical modeling method, represented by simulation and visualization of the
principles in physics, is introduced in the shape extraction of the active
contours. The objectives of adopting this concept are to address the several
major difficulties in the application of Active Contours. Primarily, a
technique is developed to realize the topological changes of Parametric Active
Contours (Snakes). The key strategy is to imitate the process of a balloon
expanding and filling in a closed space with several objects. After removing
the touched balloon surfaces, the objects can be identified by surrounded
remaining balloon surfaces. A burned region swept by Snakes is utilized to
trace the contour and to give a criterion for stopping the movement of Snake
curve. When the Snakes terminates evolution totally, through ignoring this
criterion, it can form a connected area by evolving the Snakes again and
continuing the region burning. The contours extracted from the boundaries of
the burned area can represent the child snake of each object respectively.
Secondly, a novel scheme is designed to solve the problems of leakage of the
contour from the large gaps, and the segmentation error in Geometric Active
Contours (GAC). It divides the segmentation procedure into two processing
stages. By simulating the wave propagating in the isotropic substance at the
final stage, it can significantly enhance the effect of image force in GAC
based on Level Set and give the satisfied solutions to the two problems.
Thirdly, to support the physical models for active contours above, we introduce
a general image force field created on a template plane over the image plane.
This force is more adaptable to noisy images with complicated geometric shapes.
"
43,Image Sampling with Quasicrystals,"  We investigate the use of quasicrystals in image sampling. Quasicrystals
produce space-filling, non-periodic point sets that are uniformly discrete and
relatively dense, thereby ensuring the sample sites are evenly spread out
throughout the sampled image. Their self-similar structure can be attractive
for creating sampling patterns endowed with a decorative symmetry. We present a
brief general overview of the algebraic theory of cut-and-project quasicrystals
based on the geometry of the golden ratio. To assess the practical utility of
quasicrystal sampling, we evaluate the visual effects of a variety of
non-adaptive image sampling strategies on photorealistic image reconstruction
and non-photorealistic image rendering used in multiresolution image
representations. For computer visualization of point sets used in image
sampling, we introduce a mosaic rendering technique.
"
44,Dynamic Deformation of Uniform Elastic Two-Layer Objects,"  This thesis presents a two-layer uniform facet elastic object for real-time
simulation based on physics modeling method. It describes the elastic object
procedural modeling algorithm with particle system from the simplest
one-dimensional object, to more complex two-dimensional and three-dimensional
objects.
  The double-layered elastic object consists of inner and outer elastic mass
spring surfaces and compressible internal pressure. The density of the inner
layer can be set different from the density of the outer layer; the motion of
the inner layer can be opposite to the motion of the outer layer. These special
features, which cannot be achieved by a single layered object, result in
improved imitation of a soft body, such as tissue's liquidity non-uniform
deformation. The construction of the double-layered elastic object is closer to
the real tissue's physical structure.
  The inertial behavior of the elastic object is well illustrated in
environments with gravity and collisions with walls, ceiling, and floor. The
collision detection is defined by elastic collision penalty method and the
motion of the object is guided by the Ordinary Differential Equation
computation.
  Users can interact with the modeled objects, deform them, and observe the
response to their action in real time.
"
45,Integrating Post-Newtonian Equations on Graphics Processing Units,"  We report on early results of a numerical and statistical study of binary
black hole inspirals. The two black holes are evolved using post-Newtonian
approximations starting with initially randomly distributed spin vectors. We
characterize certain aspects of the distribution shortly before merger. In
particular we note the uniform distribution of black hole spin vector dot
products shortly before merger and a high correlation between the initial and
final black hole spin vector dot products in the equal-mass, maximally spinning
case. These simulations were performed on Graphics Processing Units, and we
demonstrate a speed-up of a factor 50 over a more conventional CPU
implementation.
"
46,Visualization of Mined Pattern and Its Human Aspects,"  Researchers got success in mining the Web usage data effectively and
efficiently. But representation of the mined patterns is often not in a form
suitable for direct human consumption. Hence mechanisms and tools that can
represent mined patterns in easily understandable format are utilized.
Different techniques are used for pattern analysis, one of them is
visualization. Visualization can provide valuable assistance for data analysis
and decision making tasks. In the data visualization process, technical
representations of web pages are replaced by user attractive text
interpretations. Experiments with the real world problems showed that the
visualization can significantly increase the quality and usefulness of web log
mining results. However, how decision makers perceive and interact with a
visual representation can strongly influence their understanding of the data as
well as the usefulness of the visual presentation. Human factors therefore
contribute significantly to the visualization process and should play an
important role in the design and evaluation of visualization tools. This
electronic document is a live template. The various components of your paper,
title, text, heads, etc., are already defined on the style sheet, as
illustrated by the portions given in this document.
"
47,Succinct Representation of Well-Spaced Point Clouds,"  A set of n points in low dimensions takes Theta(n w) bits to store on a w-bit
machine. Surface reconstruction and mesh refinement impose a requirement on the
distribution of the points they process. I show how to use this assumption to
lossily compress a set of n input points into a representation that takes only
O(n) bits, independent of the word size. The loss can keep inter-point
distances to within 10% relative error while still achieving a factor of three
space savings. The representation allows standard quadtree operations, along
with computing the restricted Voronoi cell of a point, in time O(w^2 + log n),
which can be improved to time O(log n) if w is in Theta(log n). Thus one can
use this compressed representation to perform mesh refinement or surface
reconstruction in O(n) bits with only a logarithmic slowdown.
"
48,"Hard Data on Soft Errors: A Large-Scale Assessment of Real-World Error
  Rates in GPGPU","  Graphics processing units (GPUs) are gaining widespread use in computational
chemistry and other scientific simulation contexts because of their huge
performance advantages relative to conventional CPUs. However, the reliability
of GPUs in error-intolerant applications is largely unproven. In particular, a
lack of error checking and correcting (ECC) capability in the memory subsystems
of graphics cards has been cited as a hindrance to the acceptance of GPUs as
high-performance coprocessors, but the impact of this design has not been
previously quantified.
  In this article we present MemtestG80, our software for assessing memory
error rates on NVIDIA G80 and GT200-architecture-based graphics cards.
Furthermore, we present the results of a large-scale assessment of GPU error
rate, conducted by running MemtestG80 on over 20,000 hosts on the Folding@home
distributed computing network. Our control experiments on consumer-grade and
dedicated-GPGPU hardware in a controlled environment found no errors. However,
our survey over cards on Folding@home finds that, in their installed
environments, two-thirds of tested GPUs exhibit a detectable, pattern-sensitive
rate of memory soft errors. We demonstrate that these errors persist after
controlling for overclocking and environmental proxies for temperature, but
depend strongly on board architecture.
"
49,Complementary Space for Enhanced Uncertainty and Dynamics Visualization,"  Given a computer model of a physical object, it is often quite difficult to
visualize and quantify any global effects on the shape representation caused by
local uncertainty and local errors in the data. This problem is further
amplified when dealing with hierarchical representations containing varying
levels of detail and / or shapes undergoing dynamic deformations. In this
paper, we compute, quantify and visualize the complementary topological and
geometrical features of 3D shape models, namely, the tunnels, pockets and
internal voids of the object. We find that this approach sheds a unique light
on how a model is affected by local uncertainty, errors or modifications and
show how the presence or absence of complementary shape features can be
essential to an object's structural form and function.
"
50,Yet Another Pacman 3D Adventures,"  This game is meant to be extension of the overly-beaten pacman-style game
(code-named ""Yet Another Pacman 3D Adventures"", or YAP3DAD) from the proposed
ideas and other projects with advance visual and computer graphics features,
including a-game-in-a-game approach. The project is an open-source project
published on SourceForge.net for possible future development and extension.
"
51,"Digital Image Watermarking for Arbitrarily Shaped Objects Based On
  SA-DWT","  Many image watermarking schemes have been proposed in recent years, but they
usually involve embedding a watermark to the entire image without considering
only a particular object in the image, which the image owner may be interested
in. This paper proposes a watermarking scheme that can embed a watermark to an
arbitrarily shaped object in an image. Before embedding, the image owner
specifies an object of arbitrary shape that is of a concern to him. Then the
object is transformed into the wavelet domain using in place lifting shape
adaptive DWT(SADWT) and a watermark is embedded by modifying the wavelet
coefficients. In order to make the watermark robust and transparent, the
watermark is embedded in the average of wavelet blocks using the visual model
based on the human visual system. Wavelet coefficients n least significant bits
(LSBs) are adjusted in concert with the average. Simulation results shows that
the proposed watermarking scheme is perceptually invisible and robust against
many attacks such as lossy compression (e.g.JPEG, JPEG2000), scaling, adding
noise, filtering, etc.
"
52,Seeing Science,"  The ability to represent scientific data and concepts visually is becoming
increasingly important due to the unprecedented exponential growth of
computational power during the present digital age. The data sets and
simulations scientists in all fields can now create are literally thousands of
times as large as those created just 20 years ago. Historically successful
methods for data visualization can, and should, be applied to today's huge data
sets, but new approaches, also enabled by technology, are needed as well.
Increasingly, ""modular craftsmanship"" will be applied, as relevant
functionality from the graphically and technically best tools for a job are
combined as-needed, without low-level programming.
"
53,Analyzing Midpoint Subdivision,"  Midpoint subdivision generalizes the Lane-Riesenfeld algorithm for uniform
tensor product splines and can also be applied to non regular meshes. For
example, midpoint subdivision of degree 2 is a specific Doo-Sabin algorithm and
midpoint subdivision of degree 3 is a specific Catmull-Clark algorithm. In
2001, Zorin and Schroeder were able to prove C1-continuity for midpoint
subdivision surfaces analytically up to degree 9. Here, we develop general
analysis tools to show that the limiting surfaces under midpoint subdivision of
any degree >= 2 are C1-continuous at their extraordinary points.
"
54,On the theory of moveable objects,"  User-driven applications belong to the new type of programs, in which users
get the full control of WHAT, WHEN, and HOW must appear on the screen. Such
programs can exist only if the screen view is organized not according with the
predetermined scenario, written by the developers, but if any screen object can
be moved, resized, and reconfigured by any user at any moment. This article
describes the algorithm, by which an object of an arbitrary shape can be turned
into moveable and resizable. It also explains some rules of such design and the
technique, which can be useful in many cases. Both the individual movements of
objects and their synchronous movements are analysed. After discussing the
individually moveable controls, different types of groups are analysed and the
arbitrary grouping of controls is considered.
"
55,"Secure Watermarking Scheme for Color Image Using Intensity of Pixel and
  LSB Substitution","  In this paper a novel spatial domain LSB based watermarking scheme for color
Images is proposed. The proposed scheme is of type blind and invisible
watermarking. Our scheme introduces the concept of storing variable number of
bits in each pixel based on the actual color value of pixel. Equal or higher
the color value of channels with respect to intensity of pixel stores higher
number of watermark bits. The Red, Green and Blue channel of the color image
has been used for watermark embedding. The watermark is embedded into selected
channels of pixel. The proposed method supports high watermark embedding
capacity, which is equivalent to the size of cover image. The security of
watermark is preserved by permuting the watermark bits using secret key. The
proposed scheme is found robust to various image processing operations such as
image compression, blurring, salt and pepper noise, filtering and cropping.
"
56,Computing Principal Components Dynamically,"  In this paper we present closed-form solutions for efficiently updating the
principal components of a set of $n$ points, when $m$ points are added or
deleted from the point set. For both operations performed on a discrete point
set in $\mathbb{R}^d$, we can compute the new principal components in $O(m)$
time for fixed $d$. This is a significant improvement over the commonly used
approach of recomputing the principal components from scratch, which takes
$O(n+m)$ time. An important application of the above result is the dynamical
computation of bounding boxes based on principal component analysis. PCA
bounding boxes are very often used in many fields, among others in computer
graphics for collision detection and fast rendering. We have implemented and
evaluated few algorithms for computing dynamically PCA bounding boxes in
$\mathbb{R}^3$. In addition, we present closed-form solutions for computing
dynamically principal components of continuous point sets in $\mathbb{R}^2$ and
$\mathbb{R}^3$. In both cases, discrete and continuous, to compute the new
principal components, no additional data structures or storage are needed.
"
57,Teaching Physical Based Animation via OpenGL Slides,"  This work expands further our earlier poster presentation and integration of
the OpenGL Slides Framework (OGLSF) - to make presentations with real-time
animated graphics where each slide is a scene with tidgets - and physical based
animation of elastic two-, three-layer softbody objects. The whole project is
very interactive, and serves dual purpose - delivering the teaching material in
a classroom setting with real running animated examples as well as releasing
the source code to the students to show how the actual working things are made.
"
58,Planar Visibility: Testing and Counting,"  In this paper we consider query versions of visibility testing and visibility
counting. Let $S$ be a set of $n$ disjoint line segments in $\R^2$ and let $s$
be an element of $S$. Visibility testing is to preprocess $S$ so that we can
quickly determine if $s$ is visible from a query point $q$. Visibility counting
involves preprocessing $S$ so that one can quickly estimate the number of
segments in $S$ visible from a query point $q$.
  We present several data structures for the two query problems. The structures
build upon a result by O'Rourke and Suri (1984) who showed that the subset,
$V_S(s)$, of $\R^2$ that is weakly visible from a segment $s$ can be
represented as the union of a set, $C_S(s)$, of $O(n^2)$ triangles, even though
the complexity of $V_S(s)$ can be $\Omega(n^4)$. We define a variant of their
covering, give efficient output-sensitive algorithms for computing it, and
prove additional properties needed to obtain approximation bounds. Some of our
bounds rely on a new combinatorial result that relates the number of segments
of $S$ visible from a point $p$ to the number of triangles in $\bigcup_{s\in S}
C_S(s)$ that contain $p$.
"
59,Resolution scalability improvement for JPEG2000 standard color image,"  Removed by arXiv administration. This article was plagiarised from
http://www.dmi.unict.it/~battiato/download/NSIP_2003_VQ.pdf and other
locations.
"
60,"Spatial Domain Watermarking Scheme for Colored Images Based on
  Log-average Luminance","  In this paper a new watermarking scheme is presented based on log-average
luminance. A colored-image is divided into blocks after converting the RGB
colored image to YCbCr color space. A monochrome image of 1024 bytes is used as
the watermark. To embed the watermark, 16 blocks of size 8X8 are selected and
used to embed the watermark image into the original image. The selected blocks
are chosen spirally (beginning form the center of the image) among the blocks
that have log-average luminance higher than or equal the log-average luminance
of the entire image. Each byte of the monochrome watermark is added by updating
a luminance value of a pixel of the image. If the byte of the watermark image
represented white color (255) a value <alpha> is added to the image pixel
luminance value, if it is black (0) the <alpha> is subtracted from the
luminance value. To extract the watermark, the selected blocks are chosen as
the above, if the difference between the luminance value of the watermarked
image pixel and the original image pixel is greater than 0, the watermark pixel
is supposed to be white, otherwise it supposed to be black. Experimental
results show that the proposed scheme is efficient against changing the
watermarked image to grayscale, image cropping, and JPEG compression.
"
61,"Modelacion y Visualizacion Tridimensional Interactiva de Variables
  Electricas en Celdas de Electro-Obtencion con Electrodos Bipolares","  The use of floating bipolar electrodes in electrowinning cells of copper
constitutes a nonconventional technology that promises economic and operational
impacts. This paper presents a computational tool for the simulation and
analysis of such electrochemical cells. A new model is developed for floating
electrodes and a method of finite difference is used to obtain the
threedimensional distribution of the potential and the field of current density
inside the cell. The analysis of the results is based on a technique for the
interactive visualization of three-dimensional vectorial fields as lines of
flow.
"
62,"Aplicacion Grafica para el estudio de un Modelo de Celda Electrolitica
  usando Tecnicas de Visualizacion de Campos Vectoriales","  The use of floating bipolar electrodes in electrowinning cells of copper
constitutes a nonconventional technology that promises economic and operational
impacts. This thesis presents a computational tool for the simulation and
analysis of such electrochemical cells. A new model is developed for floating
electrodes and a method of finite difference is used to obtain the
threedimensional distribution of the potential and the field of current density
inside the cell. The analysis of the results is based on a technique for the
interactive visualization of three-dimensional vectorial fields as lines of
flow.
"
63,"Text/Graphics Separation and Skew Correction of Text Regions of Business
  Card Images for Mobile Devices","  Separation of the text regions from background texture and graphics is an
important step of any optical character recognition system for the images
containing both texts and graphics. In this paper, we have presented a novel
text/graphics separation technique and a method for skew correction of text
regions extracted from business card images captured with a cell-phone camera.
At first, the background is eliminated at a coarse level based on intensity
variance. This makes the foreground components distinct from each other. Then
the non-text components are removed using various characteristic features of
text and graphics. Finally, the text regions are skew corrected for further
processing. Experimenting with business card images of various resolutions, we
have found an optimum performance of 98.25% (recall) with 0.75 MP images, that
takes 0.17 seconds processing time and 1.1 MB peak memory on a moderately
powerful computer (DualCore 1.73 GHz Processor, 1 GB RAM, 1 MB L2 Cache). The
developed technique is computationally efficient and consumes low memory so as
to be applicable on mobile devices.
"
64,CLD-shaped Brushstrokes in Non-Photorealistic Rendering,"  Rendering techniques based on a random grid can be improved by adapting
brushstrokes to the shape of different areas of the original picture. In this
paper, the concept of Coherence Length Diagram is applied to determine the
adaptive brushstrokes, in order to simulate an impressionist painting. Some
examples are provided to instance the proposed algorithm.
"
65,Macro and micro view on steady states in state space,"  This paper describes visualization of chaotic attractor and elements of the
singularities in 3D space. 3D view of these effects enables to create a
demonstrative projection about relations of chaos generated by physical
circuit, the Chua's circuit. Via macro views on chaotic attractor is obtained
not only visual space illustration of representative point motion in state
space, but also its relation to planes of singularity elements. Our created
program enables view on chaotic attractor both in 2D and 3D space together with
plane objects visualization -- elements of singularities.
"
66,Local Space-Time Smoothing for Version Controlled Documents,"  Unlike static documents, version controlled documents are continuously edited
by one or more authors. Such collaborative revision process makes traditional
modeling and visualization techniques inappropriate. In this paper we propose a
new representation based on local space-time smoothing that captures important
revision patterns. We demonstrate the applicability of our framework using
experiments on synthetic and real-world data.
"
67,A Very Simple Approach for 3-D to 2-D Mapping,"  Many times we need to plot 3-D functions e.g., in many scientificc
experiments. To plot this 3-D functions on 2-D screen it requires some kind of
mapping. Though OpenGL, DirectX etc 3-D rendering libraries have made this job
very simple, still these libraries come with many complex pre- operations that
are simply not intended, also to integrate these libraries with any kind of
system is often a tough trial. This article presents a very simple method of
mapping from 3D to 2D, that is free from any complex pre-operation, also it
will work with any graphics system where we have some primitive 2-D graphics
function. Also we discuss the inverse transform and how to do basic computer
graphics transformations using our coordinate mapping system.
"
68,Trends and Techniques in Visual Gaze Analysis,"  Visualizing gaze data is an effective way for the quick interpretation of eye
tracking results. This paper presents a study investigation benefits and
limitations of visual gaze analysis among eye tracking professionals and
researchers. The results were used to create a tool for visual gaze analysis
within a Master's project.
"
69,Text/Graphics Separation for Business Card Images for Mobile Devices,"  Separation of the text regions from background texture and graphics is an
important step of any optical character recognition sytem for the images
containg both texts and graphics. In this paper, we have presented a novel
text/graphics separation technique for business card images captured with a
cell-phone camera. At first, the background is eliminated at a coarse level
based on intensity variance. This makes the foreground components distinct from
each other. Then the non-text components are removed using various
characteristic features of text and graphics. Finally, the text regions are
skew corrected and binarized for further processing. Experimenting with
business card images of various resolutions, we have found an optimum
performance of 98.54% with 0.75 MP images, that takes 0.17 seconds processing
time and 1.1 MB peak memory on a moderately powerful computer (DualCore 1.73
GHz Processor, 1 GB RAM, 1 MB L2 Cache). The developed technique is
computationally efficient and consumes low memory so as to be applicable on
mobile devices.
"
70,Autoplot: A browser for scientific data on the web,"  Autoplot is software developed for the Virtual Observatories in Heliophysics
to provide intelligent and automated plotting capabilities for many typical
data products that are stored in a variety of file formats or databases.
Autoplot has proven to be a flexible tool for exploring, accessing, and viewing
data resources as typically found on the web, usually in the form of a
directory containing data files with multiple parameters contained in each
file. Data from a data source is abstracted into a common internal data model
called QDataSet. Autoplot is built from individually useful components, and can
be extended and reused to create specialized data handling and analysis
applications and is being used in a variety of science visualization and
analysis applications. Although originally developed for viewing
heliophysics-related time series and spectrograms, its flexible and generic
data representation model makes it potentially useful for the Earth sciences.
"
71,"Finding and Classifying Critical Points of 2D Vector Fields: A
  Cell-Oriented Approach Using Group Theory","  We present a novel approach to finding critical points in cell-wise
barycentrically or bilinearly interpolated vector fields on surfaces. The
Poincar\e index of the critical points is determined by investigating the
qualitative behavior of 0-level sets of the interpolants of the vector field
components in parameter space using precomputed combinatorial results, thus
avoiding the computation of the Jacobian of the vector field at the critical
points in order to determine its index. The locations of the critical points
within a cell are determined analytically to achieve accurate results. This
approach leads to a correct treatment of cases with two first-order critical
points or one second-order critical point of bilinearly interpolated vector
fields within one cell, which would be missed by examining the linearized field
only. We show that for the considered interpolation schemes determining the
index of a critical point can be seen as a coloring problem of cell edges. A
complete classification of all possible colorings in terms of the types and
number of critical points yielded by each coloring is given using computational
group theory. We present an efficient algorithm that makes use of these
precomputed classifications in order to find and classify critical points in a
cell-by-cell fashion. Issues of numerical stability, construction of the
topological skeleton, topological simplification, and the statistics of the
different types of critical points are also discussed.
"
72,"Graphic Symbol Recognition using Graph Based Signature and Bayesian
  Network Classifier","  We present a new approach for recognition of complex graphic symbols in
technical documents. Graphic symbol recognition is a well known challenge in
the field of document image analysis and is at heart of most graphic
recognition systems. Our method uses structural approach for symbol
representation and statistical classifier for symbol recognition. In our system
we represent symbols by their graph based signatures: a graphic symbol is
vectorized and is converted to an attributed relational graph, which is used
for computing a feature vector for the symbol. This signature corresponds to
geometry and topology of the symbol. We learn a Bayesian network to encode
joint probability distribution of symbol signatures and use it in a supervised
learning scenario for graphic symbol recognition. We have evaluated our method
on synthetically deformed and degraded images of pre-segmented 2D architectural
and electronic symbols from GREC databases and have obtained encouraging
recognition rates.
"
73,"Employing fuzzy intervals and loop-based methodology for designing
  structural signature: an application to symbol recognition","  Motivation of our work is to present a new methodology for symbol
recognition. We support structural methods for representing visual associations
in graphic documents. The proposed method employs a structural approach for
symbol representation and a statistical classifier for recognition. We
vectorize a graphic symbol, encode its topological and geometrical information
by an ARG and compute a signature from this structural graph. To address the
sensitivity of structural representations to deformations and degradations, we
use data adapted fuzzy intervals while computing structural signature. The
joint probability distribution of signatures is encoded by a Bayesian network.
This network in fact serves as a mechanism for pruning irrelevant features and
choosing a subset of interesting features from structural signatures, for
underlying symbol set. Finally we deploy the Bayesian network in supervised
learning scenario for recognizing query symbols. We have evaluated the
robustness of our method against noise, on synthetically deformed and degraded
images of pre-segmented 2D architectural and electronic symbols from GREC
databases and have obtained encouraging recognition rates. A second set of
experimentation was carried out for evaluating the performance of our method
against context noise i.e. symbols cropped from complete documents. The results
support the use of our signature by a symbol spotting system.
"
74,Virtual Texturing,"  In this thesis a rendering system and an accompanying tool chain for Virtual
Texturing is presented. Our tools allow to automatically retexture existing
geometry in order to apply unique texturing on each face. Furthermore we
investigate several techniques that try to minimize visual artifacts in the
case that only a small amount of pages can be streamed per frame. We analyze
the influence of different heuristics that are responsible for the page
selection. Alongside these results we present a measurement method to allow the
comparison of our heuristics.
"
75,"Multi-sensorial interaction with a nano-scale phenomenon : the force
  curve","  Using Atomic Force Microscopes (AFM) to manipulate nano-objects is an actual
challenge for surface scientists. Basic haptic interfacesbetween the AFM and
experimentalists have already been implemented. Themulti-sensory renderings
(seeing, hearing and feeling) studied from acognitive point of view increase
the efficiency of the actual interfaces. Toallow the experimentalist to feel
and touch the nano-world, we add mixedrealities between an AFM and a force
feedback device, enriching thus thedirect connection by a modeling engine. We
present in this paper the firstresults from a real-time remote-control handling
of an AFM by our ForceFeedback Gestural Device through the example of the
approach-retract curve.
"
76,Dynamical issues in interactive representation of physical objects,"  The quality of a simulator equipped with a haptic interface is given by the
dynamical properties of its components: haptic interface, simulator and control
system. Some application areas of such kind of simulator like musical
synthesis, animation or more general, instrumental art have specific
requirements as for the ""haptic rendering"" of small movements that go beyond
the usual haptic interfaces allow. Object properties variability and different
situations of object combination represent important aspects of such type of
application which makes that the user can be interested as much in the
restitution of certain global properties of an entire object domain as in the
restitution of properties that are specific to an isolate object. In the
traditional approaches, the usual criteria are founded on the paradigm of
transparency and are related to the impedance error introduced by the technical
aspects of the system. As a general aim, rather than to minimize these effects,
we look to characterize them by physical metaphors conferring to haptic medium
the role of a tool. This positioning leads to firstly analyze the natural human
object interaction as a simplified evolutive system and then considers its
synthesis in the case of the interactive physical simulation. By means of a
frequential method, this approach is presented for some elementary
configurations of the simulator
"
77,"From granular avalanches to fluid turbulences through oozing pastes. A
  mesoscopic physically-based particle model","  In this paper, we describe how we can precisely produce complex and various
dynamic morphological features such as structured and chaotic features which
occur in sand pilings (piles, avalanches, internal collapses, arches) , in
flowing fluids (laminar flowing, Kelvin-Helmholtz and Von Karmann eddies), and
in cohesive pastes (twist-and-turn oozing and packing) using only a single
unified model, called ""mesoscopic model"". This model is a physically-based
particle model whose behavior depends on only four simple, but easy to
understand, physically-based parameters : elasticity, viscosity and their local
areas of influence. It is fast to compute and easy to understand by
non-physicist users.
"
78,Groebner bases in Java with applications in computer graphics,"  In this paper we present a Java implementation of the algorithm that computes
Buchbereger's and reduced Groebner's basis step by step. The Java application
enables graphical representation of the intersection of two surfaces in
3-dimensional space and determines conditions of existence and planarity of the
intersection.
"
79,A physically-based particle model of emergent crowd behaviors,"  This paper presents a modeling process in order to produce a realistic
simulation of crowds in the ancient Greek agora of Argos. This place was a
social theater in which two kinds of collective phenomena took place:
interpersonal interactions (small group discussion and negotiation, etc.) and
global collective phenomena, such as flowing and jamming. In this paper, we
focus on the second type of collective human phenomena, called non-deliberative
emergent crowd phenomena. This is a typical case of collective emergent
self-organization. When a great number of individuals move within a confined
environment and under a common fate, collective structures appear
spontaneously: jamming with inner collapses, organized flowing with queues,
curls, and vortices, propagation effects, etc. These are particularly relevant
features to enhance the realism - more precisely the ""truthfulness"" - of models
of this kind of collective phenomena. We assume that this truthfulness is
strongly associated with the concept of emergence: evolutions are not
predetermined by the individual characters, but emerge from the interaction of
numerous characters. The evolutions are not repetitive, and evolve on the basis
of small changes. This paper demonstrates that the physically-based interacting
particles system is an adequate candidate to model emergent crowd effects: it
associates a large number of elementary dynamic actors via elementary
non-linear dynamic interactions. Our model of the scene is regulated as a
large, dynamically coupled network of second order differential automata. We
take advantage of symbolic non-photorealistic and efficient visualization to
render the style of the person, rather than the person itself. As an artistic
representation, NPR reinforces the symbolic acceptance of the scene by the
observer, triggering an immediate and intuitive recognition of the scene as a
plausible scene from ancient Greece.
"
80,"Physically-based particle simulation and visualization of pastes and
  gels","  This paper is focused on the question of simulation and visualiza- tion of 3D
gel and paste dynamic effects. In a first part, we introduce a 3D physically
based particle (or mass-interaction) model, with a small number of masses and
few powerful interaction parameters, which is able to generate the dynamic
features of both gels and pastes. This model proves that the 3D
mass-interaction method is relevant for the simulation of such phenomena,
without an explicit knowledge of their underly- ing physics. In a second part,
we expose an original rendering process, the Flow Structuring Method that
enhances the dynamic properties of the simulation and offers a realistic
visualization. This process ignores all the properties of the underlying
physical model. It leads to a reconstruction of the spatial structure of the
gel (or paste) flow only through an analysis of the output of the simula- tion
which is a set of unorganized points moving in a 3D space. Finally, the paper
presents realistic renderings obtained by using implicit surfaces and
ray-tracing techniques on the Structured Flow previously obtained.
"
81,"A basic gesture and motion format for virtual reality multisensory
  applications","  The question of encoding movements such as those produced by human gestures
may become central in the coming years, given the growing importance of
movement data exchanges between heterogeneous systems and applications (musical
applications, 3D motion control, virtual reality interaction, etc.). For the
past 20 years, various formats have been proposed for encoding movement,
especially gestures. Though, these formats, at different degrees, were designed
in the context of quite specific applications (character animation, motion
capture, musical gesture, biomechanical concerns...). The article introduce a
new file format, called GMS (for 'Gesture and Motion Signal'), with the aim of
being more low-level and generic, by defining the minimal features a format
carrying movement/gesture information needs, rather than by gathering all the
information generally given by the existing formats. The article argues that,
given its growing presence in virtual reality situations, the ""gesture signal""
itself must be encoded, and that a specific format is needed. The proposed
format features the inner properties of such signals: dimensionality,
structural features, types of variables, and spatial and temporal properties.
The article first reviews the various situations with multisensory virtual
objects in which gesture controls intervene. The proposed format is then
deduced, as a mean to encode such versatile and variable ""gestural and animated
scene"".
"
82,L2-optimal image interpolation and its applications to medical imaging,"  Digital medical images are always displayed scaled to fit particular view.
Interpolation is responsible for this scaling, and if not done properly, can
significantly degrade diagnostic image quality. However, theoretically-optimal
interpolation algorithms may also be the most time-consuming and impractical.
We propose a new approach, adapted to the needs of digital medical imaging, to
combine high interpolation speed and superior L2-optimal image quality.
"
83,"Fractal Basins and Boundaries in 2D Maps inspired in Discrete Population
  Models","  Two-dimensional maps can model interactions between populations. Despite
their simplicity, these dynamical systems can show some complex situations, as
multistability or fractal boundaries between basins that lead to remarkable
pictures. Some of them are shown and explained here for three different 2D
discrete models.
"
84,Toric degenerations of Bezier patches,"  The control polygon of a Bezier curve is well-defined and has geometric
significance---there is a sequence of weights under which the limiting position
of the curve is the control polygon. For a Bezier surface patch, there are many
possible polyhedral control structures, and none are canonical. We propose a
not necessarily polyhedral control structure for surface patches, regular
control surfaces, which are certain C^0 spline surfaces. While not unique,
regular control surfaces are exactly the possible limiting positions of a
Bezier patch when the weights are allowed to vary.
"
85,What's wrong with Phong - Designers' appraisal of shading in CAD-systems,"  The Phong illumination model is still widely used in realtime 3D
visualization systems. The aim of this article is to document problems with the
Phong illumination model that are encountered by an important professional user
group, namely digital designers. This leads to a visual evaluation of Phong
illumination, which at least in this condensed form seems still to be missing
in the literature. It is hoped that by explicating these flaws, awareness about
the limitations and interdependencies of the model will increase, both among
fellow users, and among researchers and developers.
"
86,"Multi-GPU Accelerated Multi-Spin Monte Carlo Simulations of the 2D Ising
  Model","  A modern graphics processing unit (GPU) is able to perform massively parallel
scientific computations at low cost. We extend our implementation of the
checkerboard algorithm for the two dimensional Ising model [T. Preis et al., J.
Comp. Phys. 228, 4468 (2009)] in order to overcome the memory limitations of a
single GPU which enables us to simulate significantly larger systems. Using
multi-spin coding techniques, we are able to accelerate simulations on a single
GPU by factors up to 35 compared to an optimized single Central Processor Unit
(CPU) core implementation which employs multi-spin coding. By combining the
Compute Unified Device Architecture (CUDA) with the Message Parsing Interface
(MPI) on the CPU level, a single Ising lattice can be updated by a cluster of
GPUs in parallel. For large systems, the computation time scales nearly
linearly with the number of GPUs used. As proof of concept we reproduce the
critical temperature of the 2D Ising model using finite size scaling
techniques.
"
87,Parametric polynomial minimal surfaces of arbitrary degree,"  Weierstrass representation is a classical parameterization of minimal
surfaces. However, two functions should be specified to construct the
parametric form in Weierestrass representation. In this paper, we propose an
explicit parametric form for a class of parametric polynomial minimal surfaces
of arbitrary degree. It includes the classical Enneper surface for cubic case.
The proposed minimal surfaces also have some interesting properties such as
symmetry, containing straight lines and self-intersections. According to the
shape properties, the proposed minimal surface can be classified into four
categories with respect to $n=4k-1$ $n=4k+1$, $n=4k$ and $n=4k+2$. The explicit
parametric form of corresponding conjugate minimal surfaces is given and the
isometric deformation is also implemented.
"
88,"Fully automatic extraction of salient objects from videos in near
  real-time","  Automatic video segmentation plays an important role in a wide range of
computer vision and image processing applications. Recently, various methods
have been proposed for this purpose. The problem is that most of these methods
are far from real-time processing even for low-resolution videos due to the
complex procedures. To this end, we propose a new and quite fast method for
automatic video segmentation with the help of 1) efficient optimization of
Markov random fields with polynomial time of number of pixels by introducing
graph cuts, 2) automatic, computationally efficient but stable derivation of
segmentation priors using visual saliency and sequential update mechanism, and
3) an implementation strategy in the principle of stream processing with
graphics processor units (GPUs). Test results indicates that our method
extracts appropriate regions from videos as precisely as and much faster than
previous semi-automatic methods even though any supervisions have not been
incorporated.
"
89,Data visualization in political and social sciences,"  The basic objective of data visualization is to provide an efficient
graphical display for summarizing and reasoning about quantitative information.
During the last decades, political science has accumulated a large corpus of
various kinds of data such as comprehensive factbooks and atlases,
characterizing all or most of existing states by multiple and objectively
assessed numerical indicators within certain time lapse. As a consequence,
there exists a continuous trend for political science to gradually become a
more quantitative scientific field and to use quantitative information in the
analysis and reasoning. It is believed that any objective analysis in political
science must be multidimensional and combine various sources of quantitative
information; however, human capabilities for perception of large massifs of
numerical information are limited. Hence, methods and approaches for
visualization of quantitative and qualitative data (and, especially
multivariate data) is an extremely important topic. Data visualization
approaches can be classified into several groups, starting from creating
informative charts and diagrams (statistical graphics and infographics) and
ending with advanced statistical methods for visualizing multidimensional
tables containing both quantitative and qualitative information. In this
article we provide a short review of existing methods of data visualization
methods with applications in political and social science.
"
90,L-systems in Geometric Modeling,"  We show that parametric context-sensitive L-systems with affine geometry
interpretation provide a succinct description of some of the most fundamental
algorithms of geometric modeling of curves. Examples include the
Lane-Riesenfeld algorithm for generating B-splines, the de Casteljau algorithm
for generating Bezier curves, and their extensions to rational curves. Our
results generalize the previously reported geometric-modeling applications of
L-systems, which were limited to subdivision curves.
"
91,"Viewpoints: A high-performance high-dimensional exploratory data
  analysis tool","  Scientific data sets continue to increase in both size and complexity. In the
past, dedicated graphics systems at supercomputing centers were required to
visualize large data sets, but as the price of commodity graphics hardware has
dropped and its capability has increased, it is now possible, in principle, to
view large complex data sets on a single workstation. To do this in practice,
an investigator will need software that is written to take advantage of the
relevant graphics hardware. The Viewpoints visualization package described
herein is an example of such software. Viewpoints is an interactive tool for
exploratory visual analysis of large, high-dimensional (multivariate) data. It
leverages the capabilities of modern graphics boards (GPUs) to run on a single
workstation or laptop. Viewpoints is minimalist: it attempts to do a small set
of useful things very well (or at least very quickly) in comparison with
similar packages today. Its basic feature set includes linked scatter plots
with brushing, dynamic histograms, normalization and outlier detection/removal.
Viewpoints was originally designed for astrophysicists, but it has since been
used in a variety of fields that range from astronomy, quantum chemistry, fluid
dynamics, machine learning, bioinformatics, and finance to information
technology server log mining. In this article, we describe the Viewpoints
package and show examples of its usage.
"
92,A symmetric motion picture of the twist-spun trefoil,"  With the aid of a computer, we provide a motion picture of the twist-spun
trefoil which exhibits the periodicity well.
"
93,Symbolic landforms created by ancient earthworks near Lake Titicaca,"  Interesting landforms created by an ancient network of earthworks are shown,
using Google satellite imagery enhanced by an image processing. This network
covers a large part of the land near the Titicaca Lake. Satellite images
clearly display the slopes of hills criss-crossed with terrace walls and the
surfaces of the plains covered with raised fields, indicating that this was
once a highly productive agricultural place for the south central Andes. Some
of the landforms are rather remarkable, having a clear symbolic function. Among
them, there are structures which seem to represent birds, where ponds are their
eyes.
"
94,Geoglyphs of Titicaca as an ancient example of graphic design,"  The paper proposes an ancient landscape design as an example of graphic
design for an age and place where no written documents existed. It is created
by a network of earthworks, which constitute the remains of an extensive
ancient agricultural system. It can be seen by means of the Google satellite
imagery on the Peruvian region near the Titicaca Lake, as a texture
superimposed to the background landform. In this texture, many drawings
(geoglyphs) can be observed.
"
95,"Intuitive representation of surface properties of biomolecules using
  BioBlender","  In this and the associated article 'BioBlender: Fast and Efficient All Atom
Morphing of Proteins Using Blender Game Engine', by Zini et al., we present
BioBlender, a complete instrument for the elaboration of motion (Zini et al.)
and the visualization (here) of proteins and other macromolecules, using
instruments of computer graphics. The availability of protein structures
enables the study of their surfaces and surface properties such as
electrostatic potential (EP) and hydropathy (MLP), based on atomic
contribution. Recent advances in 3D animation and rendering software have not
yet been exploited for the representation of proteins and other biological
molecules in an intuitive, animated form. Taking advantage of an open-source,
3D animation and rendering software, Blender, we developed BioBlender, a
package dedicated to biological work: elaboration of proteins' motions with the
simultaneous visualization of chemical and physical features. EP and MLP are
calculated using physico-chemical programs and custom programs and scripts,
organized and accessed within BioBlender interface. A new visual code is
introduced for MLP visualization: a range of optical features that permits a
photorealistic rendering of its spatial distribution on the surface of the
protein. EP is represented as animated line particles that flow along field
lines proportional to the total charge of the protein. Our system permits EP
and MLP visualization of molecules and, in the case of moving proteins, the
continuous perception of these features, calculated for each intermediate
conformation. Using real world tactile/sight feelings, the nanoscale world of
proteins becomes more understandable, familiar to our everyday life, making it
easier to introduce ""un-seen"" phenomena (concepts) such as hydropathy or
charges.
"
96,"A Framework for an Ego-centered and Time-aware Visualization of
  Relations in Arbitrary Data Repositories","  Understanding constellations in large data collections has become a common
task. One obstacle a user has to overcome is the internal complexity of these
repositories. For example, extracting connected data from a normalized
relational database requires knowledge of the table structure which might not
be available for the casual user. In this paper we present a visualization
framework which presents the collection as a set of entities and relations (on
the data level). Using rating functions, we divide large relation networks into
small graphs which resemble ego-centered networks. These graphs are connected
so the user can browse from one to another. To further assist the user, we
present two views which embed information on the evolution of the relations
into the graphs. Each view emphasizes another aspect of temporal development.
The framework can be adapted to any repository by a flexible data interface and
a graph configuration file. We present some first web-based applications
including a visualization of the DBLP data set. We use the DBLP visualization
to evaluate our approach.
"
97,"The Need to Support of Data Flow Graph Visualization of Forensic Lucid
  Programs, Forensic Evidence, and their Evaluation by GIPSY","  Lucid programs are data-flow programs and can be visually represented as data
flow graphs (DFGs) and composed visually. Forensic Lucid, a Lucid dialect, is a
language to specify and reason about cyberforensic cases. It includes the
encoding of the evidence (representing the context of evaluation) and the crime
scene modeling in order to validate claims against the model and perform event
reconstruction, potentially within large swaths of digital evidence. To aid
investigators to model the scene and evaluate it, instead of typing a Forensic
Lucid program, we propose to expand the design and implementation of the Lucid
DFG programming onto Forensic Lucid case modeling and specification to enhance
the usability of the language and the system and its behavior. We briefly
discuss the related work on visual programming an DFG modeling in an attempt to
define and select one approach or a composition of approaches for Forensic
Lucid based on various criteria such as previous implementation, wide use,
formal backing in terms of semantics and translation. In the end, we solicit
the readers' constructive, opinions, feedback, comments, and recommendations
within the context of this short discussion.
"
98,Inaccessibility-Inside Theorem for Point in Polygon,"  The manuscript presents a theoretical proof in conglomeration with new
definitions on Inaccessibility and Inside for a point S related to a simple or
self intersecting polygon P. The proposed analytical solution depicts a novel
way of solving the point in polygon problem by employing the properties of
epigraphs and hypographs, explicitly. Contrary to the ambiguous solutions given
by the cross over for the simple and self intersecting polygons and the
solution of a point being multiply inside a self intersecting polygon given by
the winding number rule, the current solution gives unambiguous and singular
result for both kinds of polygons. Finally, the current theoretical solution
proves to be mathematically correct for simple and self intersecting polygons.
"
99,Surface Curvature Effects on Reflectance from Translucent Materials,"  Most of the physically based techniques for rendering translucent objects use
the diffusion theory of light scattering in turbid media. The widely used
dipole diffusion model (Jensen et al. 2001) applies the diffusion-theory
formula derived for a planar interface to objects of arbitrary shapes. This
paper presents first results of our investigation of how surface curvature
affects the diffuse reflectance from translucent materials.
"
100,Fast Color Quantization Using Weighted Sort-Means Clustering,"  Color quantization is an important operation with numerous applications in
graphics and image processing. Most quantization methods are essentially based
on data clustering algorithms. However, despite its popularity as a general
purpose clustering algorithm, k-means has not received much respect in the
color quantization literature because of its high computational requirements
and sensitivity to initialization. In this paper, a fast color quantization
method based on k-means is presented. The method involves several modifications
to the conventional (batch) k-means algorithm including data reduction, sample
weighting, and the use of triangle inequality to speed up the nearest neighbor
search. Experiments on a diverse set of images demonstrate that, with the
proposed modifications, k-means becomes very competitive with state-of-the-art
color quantization methods in terms of both effectiveness and efficiency.
"
101,Volume-Enclosing Surface Extraction,"  In this paper we present a new method, which allows for the construction of
triangular isosurfaces from three-dimensional data sets, such as 3D image data
and/or numerical simulation data that are based on regularly shaped, cubic
lattices. This novel volume-enclosing surface extraction technique, which has
been named VESTA, can produce up to six different results due to the nature of
the discretized 3D space under consideration. VESTA is neither template-based
nor it is necessarily required to operate on 2x2x2 voxel cell neighborhoods
only. The surface tiles are determined with a very fast and robust construction
technique while potential ambiguities are detected and resolved. Here, we
provide an in-depth comparison between VESTA and various versions of the
well-known and very popular Marching Cubes algorithm for the very first time.
In an application section, we demonstrate the extraction of VESTA isosurfaces
for various data sets ranging from computer tomographic scan data to simulation
data of relativistic hydrodynamic fireball expansions.
"
102,Warping Peirce Quincuncial Panoramas,"  The Peirce quincuncial projection is a mapping of the surface of a sphere to
the interior of a square. It is a conformal map except for four points on the
equator. These points of non-conformality cause significant artifacts in
photographic applications. In this paper, we propose an algorithm and
user-interface to mitigate these artifacts. Moreover, in order to facilitate an
interactive user-interface, we present a fast algorithm for calculating the
Peirce quincuncial projection of spherical imagery. We then promote the Peirce
quincuncial projection as a viable alternative to the more popular
stereographic projection in some scenarios.
"
103,Fast GPGPU Data Rearrangement Kernels using CUDA,"  Many high performance-computing algorithms are bandwidth limited, hence the
need for optimal data rearrangement kernels as well as their easy integration
into the rest of the application. In this work, we have built a CUDA library of
fast kernels for a set of data rearrangement operations. In particular, we have
built generic kernels for rearranging m dimensional data into n dimensions,
including Permute, Reorder, Interlace/De-interlace, etc. We have also built
kernels for generic Stencil computations on a two-dimensional data using
templates and functors that allow application developers to rapidly build
customized high performance kernels. All the kernels built achieve or surpass
best-known performance in terms of bandwidth utilization.
"
104,Video Stippling,"  In this paper, we consider rendering color videos using a non-photo-realistic
art form technique commonly called stippling. Stippling is the art of rendering
images using point sets, possibly with various attributes like sizes,
elementary shapes, and colors. Producing nice stippling is attractive not only
for the sake of image depiction but also because it yields a compact vectorial
format for storing the semantic information of media. Moreover, stippling is by
construction easily tunable to various device resolutions without suffering
from bitmap sampling artifacts when resizing. The underlying core technique for
stippling images is to compute a centroidal Voronoi tessellation on a
well-designed underlying density. This density relates to the image content,
and is used to compute a weighted Voronoi diagram. By considering videos as
image sequences and initializing properly the stippling of one image by the
result of its predecessor, one avoids undesirable point flickering artifacts
and can produce stippled videos that nevertheless still exhibit noticeable
artifacts. To overcome this, our method improves over the naive scheme by
considering dynamic point creation and deletion according to the current scene
semantic complexity, and show how to effectively vectorize video while
adjusting for both color and contrast characteristics. Furthermore, we explain
how to produce high quality stippled ``videos'' (eg., fully dynamic
spatio-temporal point sets) for media containing various fading effects, like
quick motions of objects or progressive shot changes. We report on practical
performances of our implementation, and present several stippled video results
rendered on-the-fly using our viewer that allows both spatio-temporal dynamic
rescaling (eg., upscale vectorially frame rate).
"
105,MT4j - A Cross-platform Multi-touch Development Framework,"  This article describes requirements and challenges of crossplatform
multi-touch software engineering, and presents the open source framework
Multi-Touch for Java (MT4j) as a solution. MT4j is designed for rapid
development of graphically rich applications on a variety of contemporary
hardware, from common PCs and notebooks to large-scale ambient displays, as
well as different operating systems. The framework has a special focus on
making multi-touch software development easier and more efficient. Architecture
and abstractions used by MT4j are described, and implementations of several
common use cases are presented.
"
106,Speeding Up the 3D Surface Generator VESTA,"  The very recent volume-enclosing surface extraction algorithm, VESTA, is
revisited. VESTA is used to determine implicit surfaces that are potentially
contained in 3D data sets, such as 3D image data and/or 3D simulation data.
VESTA surfaces are non-degenerate, i.e., they always enclose a volume that is
larger than zero and they never self-intersect, prior to a further processing,
e.g., towards isosurfaces. In addition to its ability to deal with local cell
ambiguities consistently - and thereby avoiding the accidental generation of
holes in the final surfaces - the information of the interior and/or exterior
of enclosed 3D volumes is propagated correctly to each of the final surface
tiles. Particular emphasis is put here on the speed up of the original
formulation of VESTA, while applying the algorithm to 2x2x2 voxel
neighborhoods.
"
107,Curve Reconstruction in Riemannian Manifolds: Ordering Motion Frames,"  In this article we extend the computational geometric curve reconstruction
approach to curves in Riemannian manifolds. We prove that the minimal spanning
tree, given a sufficiently dense sample, correctly reconstructs the smooth arcs
and further closed and simple curves in Riemannian manifolds. The proof is
based on the behaviour of the curve segment inside the tubular neighbourhood of
the curve. To take care of the local topological changes of the manifold, the
tubular neighbourhood is constructed in consideration with the injectivity
radius of the underlying Riemannian manifold. We also present examples of
successfully reconstructed curves and show an applications of curve
reconstruction to ordering motion frames.
"
108,Across Browsers SVG Implementation,"  In this work SVG will be translated into VML or HTML by using Javascript
based on Backbase Client Framework. The target of this project is to implement
SVG to be viewed in Internet Explorer without any plug-in and work together
with other Backbase Client Framework languages. The result of this project will
be added as an extension to the current Backbase Client Framework.
"
109,"High Speed and Area Efficient 2D DWT Processor based Image Compression""
  Signal & Image Processing","  This paper presents a high speed and area efficient DWT processor based
design for Image Compression applications. In this proposed design, pipelined
partially serial architecture has been used to enhance the speed along with
optimal utilization and resources available on target FPGA. The proposed model
has been designed and simulated using Simulink and System Generator blocks,
synthesized with Xilinx Synthesis tool (XST) and implemented on Spartan 2 and 3
based XC2S100-5tq144 and XC3S500E-4fg320 target device. The results show that
proposed design can operate at maximum frequency 231 MHz in case of Spartan 3
by consuming power of 117mW at 28 degree/c junction temperature. The result
comparison has shown an improvement of 15% in speed.
"
110,Specular holography,"  By tooling an spot-illuminated surface to control the flow of specular glints
under motion, one can produce holographic view-dependent imagery. This paper
presents the differential equation that governs the shape of the specular
surfaces, and illustrates how solutions can be constructed for different kinds
of motion, lighting, host surface geometries, and fabrication constraints,
leading to some novel forms of holography.
"
111,Improving the Performance of K-Means for Color Quantization,"  Color quantization is an important operation with many applications in
graphics and image processing. Most quantization methods are essentially based
on data clustering algorithms. However, despite its popularity as a general
purpose clustering algorithm, k-means has not received much respect in the
color quantization literature because of its high computational requirements
and sensitivity to initialization. In this paper, we investigate the
performance of k-means as a color quantizer. We implement fast and exact
variants of k-means with several initialization schemes and then compare the
resulting quantizers to some of the most popular quantizers in the literature.
Experiments on a diverse set of images demonstrate that an efficient
implementation of k-means with an appropriate initialization strategy can in
fact serve as a very effective color quantizer.
"
112,The Role of Computer Graphics in Documentary Film Production,"  We discuss a topic on the role of computer graphics in the production of
documentaries, which is often ignored in favor of other topics. Typically,
except for some rare occasions, documentary producers and computer scientists
or digital artists that do computer graphics are relatively far apart in their
domains and rarely intercommunicate to have a joint production; yet it happens,
and perhaps more so in the present and the future.
  We attempt to classify the documentaries on the amount and techniques of
computer graphics used for documentaries. We come up with the initial
categories such as ""plain"" (no graphics), ""in-between"", ""all-out"" -- nearly
100% of the documentary consisting of computer-generated imagery. Computer
graphics can be used to enhance the scenery, fill in the gaps in the missing
storyline pieces, or animate between scenes. It can incorporate stereoscopic
effects for higher viewer impression as well as interactivity aspects. It can
also be used simply in old archived image and film restoration.
"
113,Chameleon: A Color-Adaptive Web Browser for Mobile OLED Displays,"  Displays based on organic light-emitting diode (OLED) technology are
appearing on many mobile devices. Unlike liquid crystal displays (LCD), OLED
displays consume dramatically different power for showing different colors. In
particular, OLED displays are inefficient for showing bright colors. This has
made them undesirable for mobile devices because much of the web content is of
bright colors.
  To tackle this problem, we present the motivational studies, design, and
realization of Chameleon, a color adaptive web browser that renders web pages
with power-optimized color schemes under user-supplied constraints. Driven by
the findings from our motivational studies, Chameleon provides end users with
important options, offloads tasks that are not absolutely needed in real-time,
and accomplishes real-time tasks by carefully enhancing the codebase of a
browser engine. According to measure-ments with OLED smartphones, Chameleon is
able to re-duce average system power consumption for web browsing by 41% and
reduce display power consumption by 64% without introducing any noticeable
delay.
"
114,Ray-Based Reflectance Model for Diffraction,"  We present a novel method of simulating wave effects in graphics using
ray--based renderers with a new function: the Wave BSDF (Bidirectional
Scattering Distribution Function). Reflections from neighboring surface patches
represented by local BSDFs are mutually independent. However, in many surfaces
with wavelength-scale microstructures, interference and diffraction requires a
joint analysis of reflected wavefronts from neighboring patches. We demonstrate
a simple method to compute the BSDF for the entire microstructure, which can be
used independently for each patch. This allows us to use traditional ray--based
rendering pipelines to synthesize wave effects of light and sound. We exploit
the Wigner Distribution Function (WDF) to create transmissive, reflective, and
emissive BSDFs for various diffraction phenomena in a physically accurate way.
In contrast to previous methods for computing interference, we circumvent the
need to explicitly keep track of the phase of the wave by using BSDFs that
include positive as well as negative coefficients. We describe and compare the
theory in relation to well understood concepts in rendering and demonstrate a
straightforward implementation. In conjunction with standard raytracers, such
as PBRT, we demonstrate wave effects for a range of scenarios such as
multi--bounce diffraction materials, holograms and reflection of high frequency
surfaces.
"
115,Harmonic Functions for Data Reconstruction on 3D Manifolds,"  In computer graphics, smooth data reconstruction on 2D or 3D manifolds
usually refers to subdivision problems. Such a method is only valid based on
dense sample points. The manifold usually needs to be triangulated into meshes
(or patches) and each node on the mesh will have an initial value. While the
mesh is refined the algorithm will provide a smooth function on the redefined
manifolds. However, when data points are not dense and the original mesh is not
allowed to be changed, how is the ""continuous and/or smooth"" reconstruction
possible? This paper will present a new method using harmonic functions to
solve the problem. Our method contains the following steps: (1) Partition the
boundary surfaces of the 3D manifold based on sample points so that each sample
point is on the edge of the partition. (2) Use gradually varied interpolation
on the edges so that each point on edge will be assigned a value. In addition,
all values on the edge are gradually varied. (3) Use discrete harmonic function
to fit the unknown points, i.e. the points inside each partition patch.
  The fitted function will be a harmonic or a local harmonic function in each
partitioned area. The function on edge will be ""near"" continuous (or ""near""
gradually varied). If we need a smoothed surface on the manifold, we can apply
subdivision algorithms. This paper has also a philosophical advantage over
triangulation meshes. People usually use triangulation for data reconstruction.
This paper employs harmonic functions, a generalization of triangulation
because linearity is a form of harmonic. Therefore, local harmonic
initialization is more sophisticated then triangulation. This paper is a
conceptual and methodological paper. This paper does not focus on detailed
mathematical analysis nor fine algorithm design.
"
116,"Glioblastoma Multiforme Segmentation in MRI Data with a Balloon
  Inflation Approach","  Gliomas are the most common primary brain tumors, evolving from the cerebral
supportive cells. For clinical follow-up, the evaluation of the preoperative
tumor volume is essential. Volumetric assessment of tumor volume with manual
segmentation of its outlines is a time-consuming process that can be overcome
with the help of computer-assisted segmentation methods. In this paper, a
semi-automatic approach for World Health Organization (WHO) grade IV glioma
segmentation is introduced that uses balloon inflation forces, and relies on
the detection of high-intensity tumor boundaries that are coupled by using
contrast agent gadolinium. The presented method is evaluated on 27 magnetic
resonance imaging (MRI) data sets and the ground truth data of the tumor
boundaries - for evaluation of the results - are manually extracted by
neurosurgeons.
"
117,Rule-based transformations for geometric modelling,"  The context of this paper is the use of formal methods for topology-based
geometric modelling. Topology-based geometric modelling deals with objects of
various dimensions and shapes. Usually, objects are defined by a graph-based
topological data structure and by an embedding that associates each topological
element (vertex, edge, face, etc.) with relevant data as their geometric shape
(position, curve, surface, etc.) or application dedicated data (e.g. molecule
concentration level in a biological context). We propose to define
topology-based geometric objects as labelled graphs. The arc labelling defines
the topological structure of the object whose topological consistency is then
ensured by labelling constraints. Nodes have as many labels as there are
different data kinds in the embedding. Labelling constraints ensure then that
the embedding is consistent with the topological structure. Thus,
topology-based geometric objects constitute a particular subclass of a category
of labelled graphs in which nodes have multiple labels.
"
118,"An Approximation Algorithm for Computing Shortest Paths in Weighted 3-d
  Domains","  We present the first polynomial time approximation algorithm for computing
shortest paths in weighted three-dimensional domains. Given a polyhedral domain
$\D$, consisting of $n$ tetrahedra with positive weights, and a real number
$\eps\in(0,1)$, our algorithm constructs paths in $\D$ from a fixed source
vertex to all vertices of $\D$, whose costs are at most $1+\eps$ times the
costs of (weighted) shortest paths, in
$O(\C(\D)\frac{n}{\eps^{2.5}}\log\frac{n}{\eps}\log^3\frac{1}{\eps})$ time,
where $\C(\D)$ is a geometric parameter related to the aspect ratios of
tetrahedra. The efficiency of the proposed algorithm is based on an in-depth
study of the local behavior of geodesic paths and additive Voronoi diagrams in
weighted three-dimensional domains, which are of independent interest. The
paper extends the results of Aleksandrov, Maheshwari and Sack [JACM 2005] to
three dimensions.
"
119,"An Efficient and Integrated Algorithm for Video Enhancement in
  Challenging Lighting Conditions","  We describe a novel integrated algorithm for real-time enhancement of video
acquired under challenging lighting conditions. Such conditions include low
lighting, haze, and high dynamic range situations. The algorithm automatically
detects the dominate source of impairment, then depending on whether it is low
lighting, haze or others, a corresponding pre-processing is applied to the
input video, followed by the core enhancement algorithm. Temporal and spatial
redundancies in the video input are utilized to facilitate real-time processing
and to improve temporal and spatial consistency of the output. The proposed
algorithm can be used as an independent module, or be integrated in either a
video encoder or a video decoder for further optimizations.
"
120,"Mathematics of Human Motion: from Animation towards Simulation (A View
  form the Outside)","  Simulation of human motion is the subject of study in a number of
disciplines: Biomechanics, Robotics, Computer Animation, Control Theory,
Neurophysiology, Medicine, Ergonomics. Since the author has never visited any
of these fields, this review is indeed a passer-by's impression. On the other
hand, he happens to be a human (who occasionally is moving) and, as everybody
else, rates himself an expert in Applied Common Sense. Thus the author hopes
that this view from the {\em outside} will be of some interest not only for the
strangers like himself, but for those who are {\em inside} as well.
  Two flaws of the text that follows are inevitable. First, some essential
issues that are too familar to the specialists to discuss them may be missing.
Second, the author probably failed to provide the uniform ""level-of-detail"" for
this wide range of topics.
"
121,"Scientific Visualization in Astronomy: Towards the Petascale Astronomy
  Era","  Astronomy is entering a new era of discovery, coincident with the
establishment of new facilities for observation and simulation that will
routinely generate petabytes of data. While an increasing reliance on automated
data analysis is anticipated, a critical role will remain for
visualization-based knowledge discovery. We have investigated scientific
visualization applications in astronomy through an examination of the
literature published during the last two decades. We identify the two most
active fields for progress - visualization of large-N particle data and
spectral data cubes - discuss open areas of research, and introduce a mapping
between astronomical sources of data and data representations used in general
purpose visualization tools. We discuss contributions using high performance
computing architectures (e.g: distributed processing and GPUs), collaborative
astronomy visualization, the use of workflow systems to store metadata about
visualization parameters, and the use of advanced interaction devices. We
examine a number of issues that may be limiting the spread of scientific
visualization research in astronomy and identify six grand challenges for
scientific visualization research in the Petascale Astronomy Era.
"
122,Augmented reality usage for prototyping speed up,"  The first part of the article describes our approach for solution of this
problem by means of Augmented Reality. The merging of the real world model and
digital objects allows streamline the work with the model and speed up the
whole production phase significantly. The main advantage of augmented reality
is the possibility of direct manipulation with the scene using a portable
digital camera. Also adding digital objects into the scene could be done using
identification markers placed on the surface of the model. Therefore it is not
necessary to work with special input devices and lose the contact with the real
world model. Adjustments are done directly on the model. The key problem of
outlined solution is the ability of identification of an object within the
camera picture and its replacement with the digital object. The second part of
the article is focused especially on the identification of exact position and
orientation of the marker within the picture. The identification marker is
generalized into the triple of points which represents a general plane in
space. There is discussed the space identification of these points and the
description of representation of their position and orientation be means of
transformation matrix. This matrix is used for rendering of the graphical
objects (e. g. in OpenGL and Direct3D).
"
123,Rendering of 3D Dynamic Virtual Environments,"  In this paper we present a framework for the rendering of dynamic 3D virtual
environments which can be integrated in the development of videogames. It
includes methods to manage sounds and particle effects, paged static
geometries, the support of a physics engine and various input systems. It has
been designed with a modular structure to allow future expansions. We exploited
some open-source state-of-the-art components such as OGRE, PhysX,
ParticleUniverse, etc.; all of them have been properly integrated to obtain
peculiar physical and environmental effects. The stand-alone version of the
application is fully compatible with Direct3D and OpenGL APIs and adopts OpenAL
APIs to manage audio cards. Concluding, we devised a showcase demo which
reproduces a dynamic 3D environment, including some particular effects: the
alternation of day and night infuencing the lighting of the scene, the
rendering of terrain, water and vegetation, the reproduction of sounds and
atmospheric agents.
"
124,"User guide to TIM, a ray-tracing program for forbidden ray optics","  This user guide outlines the use of TIM, an interactive ray-tracing program
with a number of special powers. TIM can be customised and embedded into
internet pages, making it suitable not only for research but also for its
dissemination.
"
125,"Hypothesize and Bound: A Computational Focus of Attention Mechanism for
  Simultaneous N-D Segmentation, Pose Estimation and Classification Using Shape
  Priors","  Given the ever increasing bandwidth of the visual information available to
many intelligent systems, it is becoming essential to endow them with a sense
of what is worthwhile their attention and what can be safely disregarded. This
article presents a general mathematical framework to efficiently allocate the
available computational resources to process the parts of the input that are
relevant to solve a given perceptual problem. By this we mean to find the
hypothesis H (i.e., the state of the world) that maximizes a function L(H),
representing how well each hypothesis ""explains"" the input. Given the large
bandwidth of the sensory input, fully evaluating L(H) for each hypothesis H is
computationally infeasible (e.g., because it would imply checking a large
number of pixels). To address this problem we propose a mathematical framework
with two key ingredients. The first one is a Bounding Mechanism (BM) to compute
lower and upper bounds of L(H), for a given computational budget. These bounds
are much cheaper to compute than L(H) itself, can be refined at any time by
increasing the budget allocated to a hypothesis, and are frequently enough to
discard a hypothesis. To compute these bounds, we develop a novel theory of
shapes and shape priors. The second ingredient is a Focus of Attention
Mechanism (FoAM) to select which hypothesis' bounds should be refined next,
with the goal of discarding non-optimal hypotheses with the least amount of
computation. The proposed framework: 1) is very efficient since most hypotheses
are discarded with minimal computation; 2) is parallelizable; 3) is guaranteed
to find the globally optimal hypothesis; and 4) its running time depends on the
problem at hand, not on the bandwidth of the input. We instantiate the proposed
framework for the problem of simultaneously estimating the class, pose, and a
noiseless version of a 2D shape in a 2D image.
"
126,Face Shape and Reflectance Acquisition using a Multispectral Light Stage,"  In this thesis, we discuss the design and calibration (geometric and
radiometric) of a novel shape and reflectance acquisition device called the
""Multispectral Light Stage"". This device can capture highly detailed facial
geometry (down to the level of skin pores detail) and Multispectral reflectance
map which can be used to estimate biophysical skin parameters such as the
distribution of pigmentation and blood beneath the surface of the skin. We
extend the analysis of the original spherical gradient photometric stereo
method to study the effects of deformed diffuse lobes on the quality of
recovered surface normals. Based on our modified radiance equations, we develop
a minimal image set method to recover high quality photometric normals using
only four, instead of six, spherical gradient images. Using the same radiance
equations, we explore a Quadratic Programming (QP) based algorithm for
correction of surface normals obtained using spherical gradient photometric
stereo. Based on the proposed minimal image sets method, we present a
performance capture sequence that significantly reduces the data capture
requirement and post-processing computational cost of existing photometric
stereo based performance geometry capture methods. Furthermore, we explore the
use of images captured in our Light Stage to generate stimuli images for a
psychology experiment exploring the neural representation of 3D shape and
texture of a human face.
"
127,"Time-Dependent 2-D Vector Field Topology: An Approach Inspired by
  Lagrangian Coherent Structures","  This paper presents an approach to a time-dependent variant of the concept of
vector field topology for 2-D vector fields. Vector field topology is defined
for steady vector fields and aims at discriminating the domain of a vector
field into regions of qualitatively different behaviour. The presented approach
represents a generalization for saddle-type critical points and their
separatrices to unsteady vector fields based on generalized streak lines, with
the classical vector field topology as its special case for steady vector
fields. The concept is closely related to that of Lagrangian coherent
structures obtained as ridges in the finite-time Lyapunov exponent field. The
proposed approach is evaluated on both 2-D time-dependent synthetic and vector
fields from computational fluid dynamics.
"
128,Injectivity of 2D Toric B\'{e}zier Patches,"  Rational B\'{e}zier functions are widely used as mapping functions in surface
reparameterization, finite element analysis, image warping and morphing. The
injectivity (one-to-one property) of a mapping function is typically necessary
for these applications. Toric B\'{e}zier patches are generalizations of
classical patches (triangular, tensor product) which are defined on the convex
hull of a set of integer lattice points. We give a geometric condition on the
control points that we show is equivalent to the injectivity of every 2D toric
B\'{e}zier patch with those control points for all possible choices of weights.
This condition refines that of Craciun, et al., which only implied injectivity
on the interior of a patch.
"
129,A Framework for Designing 3D Virtual Environments,"  The process of design and development of virtual environments can be
supported by tools and frameworks, to save time in technical aspects and
focusing on the content. In this paper we present an academic framework which
provides several levels of abstraction to ease this work. It includes
state-of-the-art components we devised or integrated adopting open-source
solutions in order to face specific problems. Its architecture is modular and
customizable, the code is open-source.
"
130,Accelerating Lossless Data Compression with GPUs,"  Huffman compression is a statistical, lossless, data compression algorithm
that compresses data by assigning variable length codes to symbols, with the
more frequently appearing symbols given shorter codes than the less. This work
is a modification of the Huffman algorithm which permits uncompressed data to
be decomposed into indepen- dently compressible and decompressible blocks,
allowing for concurrent compression and decompression on multiple processors.
We create implementations of this modified algorithm on a current NVIDIA GPU
using the CUDA API as well as on a current Intel chip and the performance
results are compared, showing favorable GPU performance for nearly all tests.
Lastly, we discuss the necessity for high performance data compression in
today's supercomputing ecosystem.
"
131,Stereo pairs in Astrophysics,"  Stereoscopic visualization is seldom used in Astrophysical publications and
presentations compared to other scientific fields, e.g., Biochemistry, where it
has been recognized as a valuable tool for decades. We put forth the view that
stereo pairs can be a useful tool for the Astrophysics community in
communicating a truer representation of astrophysical data. Here, we review the
main theoretical aspects of stereoscopy, and present a tutorial to easily
create stereo pairs using Python. We then describe how stereo pairs provide a
way to incorporate 3D data in 2D publications of standard journals. We
illustrate the use of stereo pairs with one conceptual and two Astrophysical
science examples: an integral field spectroscopy study of a supernova remnant,
and numerical simulations of a relativistic AGN jet. We also use these examples
to make the case that stereo pairs are not merely an ostentatious way to
present data, but an enhancement in the communication of scientific results in
publications because they provide the reader with a realistic view of
multi-dimensional data, be it of observational or theoretical nature. In
recognition of the ongoing 3D expansion in the commercial sector, we advocate
an increased use of stereo pairs in Astrophysics publications and presentations
as a first step towards new interactive and multi-dimensional publication
methods.
"
132,Linear-Time Poisson-Disk Patterns,"  We present an algorithm for generating Poisson-disc patterns taking O(N) time
to generate $N$ points. The method is based on a grid of regions which can
contain no more than one point in the final pattern, and uses an explicit model
of point arrival times under a uniform Poisson process.
"
133,"3-Phase Recognition Approach to Pseudo 3D Building Generation from 2D
  Floor Plan","  Nowadays three dimension (3D) architectural visualisation has become a
powerful tool in the conceptualisation, design and presentation of
architectural products in the construction industry, providing realistic
interaction and walkthrough on engineering products. Traditional ways of
implementing 3D models involves the use of specialised 3D authoring tools along
with skilled 3D designers with blueprints of the model and this is a slow and
laborious process. The aim of this paper is to automate this process by simply
analyzing the blueprint document and generating the 3D scene automatically. For
this purpose we have devised a 3-Phase recognition approach to pseudo 3D
building generation from 2D floor plan and developed a software accordingly.
Our 3-phased 3D building system has been implemented using C, C++ and OpenCV
library [24] for the Image Processing module; The Save Module generated an XML
file for storing the processed floor plan objects attributes; while the
Irrlitch [14] game engine was used to implement the Interactive 3D module.
Though still at its infancy, our proposed system gave commendable results. We
tested our system on 6 floor plans with complexities ranging from low to high
and the results seems to be very promising with an average processing time of
around 3s and a 3D generation in 4s. In addition the system provides an
interactive walk-though and allows users to modify components.
"
134,Fat Triangulations and Differential Geometry,"  We study the differential geometric consequences of our previous result on
the existence of fat triangulations, in conjunction with a result of Cheeger,
M\""{u}ller and Schrader, regarding the convergence of Lipschitz-Killing
curvatures of piecewise-flat approximations of smooth Riemannian manifolds. A
further application to the existence of quasiconformal mappings between
manifolds, as well as an extension of the triangulation result to the case of
almost Riemannian manifolds, are also given. In addition, the notion of fatness
of triangulations and its relation to metric curvature and to excess is
explored. Moreover, applications of the main results, and in particular a
purely metric approach to Regge calculus, are also investigated.
"
135,Partial wave analysis at BES III harnessing the power of GPUs,"  Partial wave analysis is a core tool in hadron spectroscopy. With the high
statistics data available at facilities such as the Beijing Spectrometer III,
this procedure becomes computationally very expensive. We have successfully
implemented a framework for performing partial wave analysis on graphics
processors. We discuss the implementation, the parallel computing frameworks
employed and the performance achieved, with a focus on the recent transition to
the OpenCL framework.
"
136,Estimating 3D Human Shapes from Measurements,"  The recent advances in 3-D imaging technologies give rise to databases of
human shapes, from which statistical shape models can be built. These
statistical models represent prior knowledge of the human shape and enable us
to solve shape reconstruction problems from partial information. Generating
human shape from traditional anthropometric measurements is such a problem,
since these 1-D measurements encode 3-D shape information. Combined with a
statistical shape model, these easy-to-obtain measurements can be leveraged to
create 3D human shapes. However, existing methods limit the creation of the
shapes to the space spanned by the database and thus require a large amount of
training data. In this paper, we introduce a technique that extrapolates the
statistically inferred shape to fit the measurement data using nonlinear
optimization. This method ensures that the generated shape is both human-like
and satisfies the measurement conditions. We demonstrate the effectiveness of
the method and compare it to existing approaches through extensive experiments,
using both synthetic data and real human measurements.
"
137,"Jacobians and Hessians of Mean Value Coordinates for Closed Triangular
  Meshes","  In this technical note, we present the formulae of the derivatives of the
Mean Value Coordinates based transformations, using an enclosing triangle mesh,
acting as a cage for the deformation of an interior object.
"
138,"Kara: A System for Visualising and Visual Editing of Interpretations for
  Answer-Set Programs","  In answer-set programming (ASP), the solutions of a problem are encoded in
dedicated models, called answer sets, of a logical theory. These answer sets
are computed from the program that represents the theory by means of an ASP
solver and returned to the user as sets of ground first-order literals. As this
type of representation is often cumbersome for the user to interpret, tools
like ASPVIZ and IDPDraw were developed that allow for visualising answer sets.
The tool Kara, introduced in this paper, follows these approaches, using ASP
itself as a language for defining visualisations of interpretations. Unlike
existing tools that position graphic primitives according to static coordinates
only, Kara allows for more high-level specifications, supporting graph
structures, grids, and relative positioning of graphical elements. Moreover,
generalising the functionality of previous tools, Kara provides modifiable
visualisations such that interpretations can be manipulated by graphically
editing their visualisations. This is realised by resorting to abductive
reasoning techniques. Kara is part of SeaLion, a forthcoming integrated
development environment (IDE) for ASP.
"
139,Evaluation of a Bundling Technique for Parallel Coordinates,"  We describe a technique for bundled curve representations in
parallel-coordinates plots and present a controlled user study evaluating their
effectiveness. Replacing the traditional C^0 polygonal lines by C^1 continuous
piecewise Bezier curves makes it easier to visually trace data points through
each coordinate axis. The resulting Bezier curves can then be bundled to
visualize data with given cluster structures. Curve bundles are efficient to
compute, provide visual separation between data clusters, reduce visual
clutter, and present a clearer overview of the dataset. A controlled user study
with 14 participants confirmed the effectiveness of curve bundling for
parallel-coordinates visualization: 1) compared to polygonal lines, it is
equally capable of revealing correlations between neighboring data attributes;
2) its geometric cues can be effective in displaying cluster information. For
some datasets curve bundling allows the color perceptual channel to be applied
to other data attributes, while for complex cluster patterns, bundling and
color can represent clustering far more clearly than either alone.
"
140,"Using Stereoscopic 3D Technologies for the Diagnosis and Treatment of
  Amblyopia in Children","  The 3D4Amb project aims at developing a system based on the stereoscopic 3D
techonlogy, like the NVIDIA 3D Vision, for the diagnosis and treatment of
amblyopia in young children. It exploits the active shutter technology to
provide binocular vision, i.e. to show different images to the amblyotic (or
lazy) and the normal eye. It would allow easy diagnosis of amblyopia and its
treatment by means of interactive games or other entertainment activities. It
should not suffer from the compliance problems of the classical treatment, it
is suitable to domestic use, and it could at least partially substitute
occlusion or patching of the normal eye.
"
141,"A Survey of Ocean Simulation and Rendering Techniques in Computer
  Graphics","  This paper presents a survey of ocean simulation and rendering methods in
computer graphics. To model and animate the ocean's surface, these methods
mainly rely on two main approaches: on the one hand, those which approximate
ocean dynamics with parametric, spectral or hybrid models and use empirical
laws from oceanographic research. We will see that this type of methods
essentially allows the simulation of ocean scenes in the deep water domain,
without breaking waves. On the other hand, physically-based methods use
Navier-Stokes Equations (NSE) to represent breaking waves and more generally
ocean surface near the shore. We also describe ocean rendering methods in
computer graphics, with a special interest in the simulation of phenomena such
as foam and spray, and light's interaction with the ocean surface.
"
142,"Algorithms to automatically quantify the geometric similarity of
  anatomical surfaces","  We describe new approaches for distances between pairs of 2-dimensional
surfaces (embedded in 3-dimensional space) that use local structures and global
information contained in inter-structure geometric relationships. We present
algorithms to automatically determine these distances as well as geometric
correspondences. This is motivated by the aspiration of students of natural
science to understand the continuity of form that unites the diversity of life.
At present, scientists using physical traits to study evolutionary
relationships among living and extinct animals analyze data extracted from
carefully defined anatomical correspondence points (landmarks). Identifying and
recording these landmarks is time consuming and can be done accurately only by
trained morphologists. This renders these studies inaccessible to
non-morphologists, and causes phenomics to lag behind genomics in elucidating
evolutionary patterns. Unlike other algorithms presented for morphological
correspondences our approach does not require any preliminary marking of
special features or landmarks by the user. It also differs from other seminal
work in computational geometry in that our algorithms are polynomial in nature
and thus faster, making pairwise comparisons feasible for significantly larger
numbers of digitized surfaces. We illustrate our approach using three datasets
representing teeth and different bones of primates and humans, and show that it
leads to highly accurate results.
"
143,Efficient Synchronization Primitives for GPUs,"  In this paper, we revisit the design of synchronization
primitives---specifically barriers, mutexes, and semaphores---and how they
apply to the GPU. Previous implementations are insufficient due to the
discrepancies in hardware and programming model of the GPU and CPU. We create
new implementations in CUDA and analyze the performance of spinning on the GPU,
as well as a method of sleeping on the GPU, by running a set of memory-system
benchmarks on two of the most common GPUs in use, the Tesla- and Fermi-class
GPUs from NVIDIA. From our results we define higher-level principles that are
valid for generic many-core processors, the most important of which is to limit
the number of atomic accesses required for a synchronization operation because
atomic accesses are slower than regular memory accesses. We use the results of
the benchmarks to critique existing synchronization algorithms and guide our
new implementations, and then define an abstraction of GPUs to classify any GPU
based on the behavior of the memory system. We use this abstraction to create
suitable implementations of the primitives specifically targeting the GPU, and
analyze the performance of these algorithms on Tesla and Fermi. We then predict
performance on future GPUs based on characteristics of the abstraction. We also
examine the roles of spin waiting and sleep waiting in each primitive and how
their performance varies based on the machine abstraction, then give a set of
guidelines for when each strategy is useful based on the characteristics of the
GPU and expected contention.
"
144,Spectral descriptors for deformable shapes,"  Informative and discriminative feature descriptors play a fundamental role in
deformable shape analysis. For example, they have been successfully employed in
correspondence, registration, and retrieval tasks. In the recent years,
significant attention has been devoted to descriptors obtained from the
spectral decomposition of the Laplace-Beltrami operator associated with the
shape. Notable examples in this family are the heat kernel signature (HKS) and
the wave kernel signature (WKS). Laplacian-based descriptors achieve
state-of-the-art performance in numerous shape analysis tasks; they are
computationally efficient, isometry-invariant by construction, and can
gracefully cope with a variety of transformations. In this paper, we formulate
a generic family of parametric spectral descriptors. We argue that in order to
be optimal for a specific task, the descriptor should take into account the
statistics of the corpus of shapes to which it is applied (the ""signal"") and
those of the class of transformations to which it is made insensitive (the
""noise""). While such statistics are hard to model axiomatically, they can be
learned from examples. Following the spirit of the Wiener filter in signal
processing, we show a learning scheme for the construction of optimal spectral
descriptors and relate it to Mahalanobis metric learning. The superiority of
the proposed approach is demonstrated on the SHREC'10 benchmark.
"
145,New Zealand involvement in Radio Astronomical VLBI Image Processing,"  With the establishment of the AUT University 12m radio telescope at
Warkworth, New Zealand has now become a part of the international Very Long
Baseline Interferometry (VLBI) community. A major product of VLBI observations
are images in the radio domain of astronomical objects such as Active Galactic
Nuclei (AGN). Using large geographical separations between radio antennas, very
high angular resolution can be achieved. Detailed images can be created using
the technique of VLBI Earth Rotation Aperture Synthesis. We review the current
process of VLBI radio imaging. In addition we model VLBI configurations using
the Warkworth telescope, AuScope (a new array of three 12m antennas in
Australia) and the Australian Square Kilometre Array Pathfinder (ASKAP) array
currently under construction in Western Australia, and discuss how the
configuration of these arrays affects the quality of images. Recent imaging
results that demonstrate the modeled improvements from inclusion of the AUT and
first ASKAP telescope in the Australian Long Baseline Array (LBA) are
presented.
"
146,Student's T Robust Bundle Adjustment Algorithm,"  Bundle adjustment (BA) is the problem of refining a visual reconstruction to
produce better structure and viewing parameter estimates. This problem is often
formulated as a nonlinear least squares problem, where data arises from
interest point matching. Mismatched interest points cause serious problems in
this approach, as a single mismatch will affect the entire reconstruction. In
this paper, we propose a novel robust Student's t BA algorithm (RST-BA). We
model reprojection errors using the heavy tailed Student's t-distribution, and
use an implicit trust region method to compute the maximum a posteriori (MAP)
estimate of the camera and viewing parameters in this model. The resulting
algorithm exploits the sparse structure essential for reconstructing
multi-image scenarios, has the same time complexity as standard L2 bundle
adjustment (L2-BA), and can be implemented with minimal changes to the standard
least squares framework. We show that the RST-BA is more accurate than either
L2-BA or L2-BA with a sigma-edit rule for outlier removal for a range of
simulated error generation scenarios. The new method has also been used to
reconstruct lunar topography using data from the NASA Apollo 15 orbiter, and we
present visual and quantitative comparisons of RST-BA and L2-BA methods for
this application. In particular, using the RST-BA algorithm we were able to
reconstruct a DEM from unprocessed data with many outliers and no ground
control points, which was not possible with the L2-BA method.
"
147,"The Object Projection Feature Estimation Problem in Unsupervised
  Markerless 3D Motion Tracking","  3D motion tracking is a critical task in many computer vision applications.
Existing 3D motion tracking techniques require either a great amount of
knowledge on the target object or specific hardware. These requirements
discourage the wide spread of commercial applications based on 3D motion
tracking. 3D motion tracking systems that require no knowledge on the target
object and run on a single low-budget camera require estimations of the object
projection features (namely, area and position). In this paper, we define the
object projection feature estimation problem and we present a novel 3D motion
tracking system that needs no knowledge on the target object and that only
requires a single low-budget camera, as installed in most computers and
smartphones. Our system estimates, in real time, the three-dimensional position
of a non-modeled unmarked object that may be non-rigid, non-convex, partially
occluded, self occluded, or motion blurred, given that it is opaque, evenly
colored, and enough contrasting with the background in each frame. Our system
is also able to determine the most relevant object to track in the screen. Our
3D motion tracking system does not impose hard constraints, therefore it allows
a market-wide implementation of applications that use 3D motion tracking.
"
148,Shape and Trajectory Tracking of Moving Obstacles,"  This work presents new methods and algorithms for tracking the shape and
trajectory of moving reflecting obstacles with broken rays, or rays reflecting
at an obstacle. While in tomography the focus of the reconstruction method is
to recover the velocity structure of the domain, the shape and trajectory
reconstruction procedure directly finds the shape and trajectory of the
obstacle. The physical signal carrier for this innovative method are ultrasonic
beams. When the speed of sound is constant, the rays are straight line segments
and the shape and trajectory of moving objects will be reconstructed with
methods based on the travel time equation and ellipsoid geometry. For variable
speed of sound, we start with the eikonal equation and a system of differential
equations that has its origins in acoustics and seismology. In this case, the
rays are curves that are not necessarily straight line segments and we develop
algorithms for shape and trajectory tracking based on the numerical solution of
these equations. We present methods and algorithms for shape and trajectory
tracking of moving obstacles with reflected rays when the location of the
receiver of the reflected ray is not known in advance. The shape and trajectory
tracking method is very efficient because it is not necessary for the reflected
signal to traverse the whole domain or the same path back to the transmitter.
It could be received close to the point of reflection or far away from the
transmitter. This optimizes the energy spent by transmitters for tracking the
object, reduces signal attenuation and improves image resolution. It is a safe
and secure method. We also present algorithms for tracking the shape and
trajectory of absorbing obstacles. The new methods and algorithms for shape and
trajectory tracking enable new applications and an application to one-hop
Internet routing is presented.
"
149,GPU-based Image Analysis on Mobile Devices,"  With the rapid advances in mobile technology many mobile devices are capable
of capturing high quality images and video with their embedded camera. This
paper investigates techniques for real-time processing of the resulting images,
particularly on-device utilizing a graphical processing unit. Issues and
limitations of image processing on mobile devices are discussed, and the
performance of graphical processing units on a range of devices measured
through a programmable shader implementation of Canny edge detection.
"
150,A self-rendering digital image encoding,"  Without careful long-term preservation digital data may be lost to a number
of factors, including physical media decay, lack of suitable decoding
equipment, and the absence of software. When raw data can be read but lack
suitable annotations as to provenance, the ability to interpret them is more
straightforward if they can be assessed through simple visual techniques. In
this regard digital images are a special case since their data have a natural
representation on two-dimensional media surfaces. This paper presents a novel
binary image pixel encoding that produces an approximate analog rendering of
encoded images when the image bits are arranged spatially in an appropriate
manner. This simultaneous digital and analog representation acts to inseparably
annotate bits as image data, which may contribute to the longevity of
so-encoded images.
"
151,Fast B-spline Curve Fitting by L-BFGS,"  We propose a novel method for fitting planar B-spline curves to unorganized
data points. In traditional methods, optimization of control points and foot
points are performed in two very time-consuming steps in each iteration: 1)
control points are updated by setting up and solving a linear system of
equations; and 2) foot points are computed by projecting each data point onto a
B-spline curve. Our method uses the L-BFGS optimization method to optimize
control points and foot points simultaneously and therefore it does not need to
perform either matrix computation or foot point projection in every iteration.
As a result, our method is much faster than existing methods.
"
152,Interactive Character Posing by Sparse Coding,"  Character posing is of interest in computer animation. It is difficult due to
its dependence on inverse kinematics (IK) techniques and articulate property of
human characters . To solve the IK problem, classical methods that rely on
numerical solutions often suffer from the under-determination problem and can
not guarantee naturalness. Existing data-driven methods address this problem by
learning from motion capture data. When facing a large variety of poses
however, these methods may not be able to capture the pose styles or be
applicable in real-time environment. Inspired from the low-rank motion
de-noising and completion model in \cite{lai2011motion}, we propose a novel
model for character posing based on sparse coding. Unlike conventional
approaches, our model directly captures the pose styles in Euclidean space to
provide intuitive training error measurements and facilitate pose synthesis. A
pose dictionary is learned in training stage and based on it natural poses are
synthesized to satisfy users' constraints . We compare our model with existing
models for tasks of pose de-noising and completion. Experiments show our model
obtains lower de-noising and completion error. We also provide User
Interface(UI) examples illustrating that our model is effective for interactive
character posing.
"
153,Finding Convex Hulls Using Quickhull on the GPU,"  We present a convex hull algorithm that is accelerated on commodity graphics
hardware. We analyze and identify the hurdles of writing a recursive divide and
conquer algorithm on the GPU and divise a framework for representing this class
of problems. Our framework transforms the recursive splitting step into a
permutation step that is well-suited for graphics hardware. Our convex hull
algorithm of choice is Quickhull. Our parallel Quickhull implementation (for
both 2D and 3D cases) achieves an order of magnitude speedup over standard
computational geometry libraries.
"
154,"Visualizing Flat Spacetime: Viewing Optical versus Special Relativistic
  Effects","  A simple visual representation of Minkowski spacetime appropriate for a
student with a background in geometry and algebra is presented. Minkowski
spacetime can be modeled with a Euclidean 4-space to yield accurate
visualizations as predicted by special relativity theory. The contributions of
relativistic aberration as compared to classical pre-relativistic aberration to
the geometry are discussed in the context of its visual representation.
"
155,"A toolkit to describe and interactively display three-manifolds embedded
  in four-space","  A data structure and toolkit are presented here that allow for the
description and manipulation of mathematical models of three-manifolds and
their interactive display from multiple viewpoints via the OpenGL 3D graphics
package. The data structure and vector math package can be extended to support
an arbitrary number of Euclidean spatial dimensions.
  A model in 4-space is described by its bounding pure simplicial 3-complex. By
intersecting a 3-flat with this 3-manifold, the algorithm will extract the
requested closed pure simplicial 2-complex surface enclosing the desired 3D
slice. The user can interactively rotate, pan, zoom, and shade arbitrary 3D
solid or wire-frame views of the revealed 3D object created by intersection,
thus exploring both expected and unexpected symmetries or asymmetries in the
world of 3-manifolds in 4-space.
"
156,Fully Automatic Expression-Invariant Face Correspondence,"  We consider the problem of computing accurate point-to-point correspondences
among a set of human face scans with varying expressions. Our fully automatic
approach does not require any manually placed markers on the scan. Instead, the
approach learns the locations of a set of landmarks present in a database and
uses this knowledge to automatically predict the locations of these landmarks
on a newly available scan. The predicted landmarks are then used to compute
point-to-point correspondences between a template model and the newly available
scan. To accurately fit the expression of the template to the expression of the
scan, we use as template a blendshape model. Our algorithm was tested on a
database of human faces of different ethnic groups with strongly varying
expressions. Experimental results show that the obtained point-to-point
correspondence is both highly accurate and consistent for most of the tested 3D
face models.
"
157,Personalised product design using virtual interactive techniques,"  Use of Virtual Interactive Techniques for personalized product design is
described in this paper. Usually products are designed and built by considering
general usage patterns and Prototyping is used to mimic the static or working
behaviour of an actual product before manufacturing the product. The user does
not have any control on the design of the product. Personalized design
postpones design to a later stage. It allows for personalized selection of
individual components by the user. This is implemented by displaying the
individual components over a physical model constructed using Cardboard or
Thermocol in the actual size and shape of the original product. The components
of the equipment or product such as screen, buttons etc. are then projected
using a projector connected to the computer into the physical model. Users can
interact with the prototype like the original working equipment and they can
select, shape, position the individual components displayed on the interaction
panel using simple hand gestures. Computer Vision techniques as well as sound
processing techniques are used to detect and recognize the user gestures
captured using a web camera and microphone.
"
158,Semantic Visualization and Navigation in Textual Corpus,"  This paper gives a survey of related work on the information visualization
domain and study the real integration of the cartography paradigms in actual
information search systems. Based on this study, we propose a semantic
visualization and navigation approach which offer to users three search modes:
precise search, connotative search and thematic search. The objective is to
propose to the users of an information search system, new interaction paradigms
which support the semantic aspect of the considered information space and guide
users in their searches by assisting them to locate their interest center and
to improve serendipity.
"
159,Visual definition of procedures for automatic virtual scene generation,"  With more and more digital media, especially in the field of virtual reality
where detailed and convincing scenes are much required, procedural scene
generation is a big helping tool for artists. A problem is that defining scene
descriptions through these procedures usually requires a knowledge in formal
language grammars, programming theory and manually editing textual files using
a strict syntax, making it less intuitive to use. Luckily, graphical user
interfaces has made a lot of tasks on computers easier to perform and out of
the belief that creating computer programs can also be one of them, visual
programming languages (VPLs) have emerged. The goal in VPLs is to shift more
work from the programmer to the integrated development environment (IDE),
making programming an user-friendlier task.
  In this thesis, an approach of using a VPL for defining procedures that
automatically generate virtual scenes is presented. The methods required to
build a VPL are presented, including a novel method of generating readable code
in a structured programming language. Also, the methods for achieving basic
principles of VPLs will be shown -- suitable visual presentation of information
and guiding the programmer in the right direction using constraints. On the
other hand, procedural generation methods are presented in the context of
visual programming -- adapting the application programming interface (API) of
these methods to better serve the user. The main focus will be on the methods
for urban modeling, such as building, city layout and details generation with
random number generation used to create non-deterministic scenes.
"
160,"Efficient and Effective Volume Visualization with Enhanced Isosurface
  Rendering","  Compared with full volume rendering, isosurface rendering has several well
recognized advantages in efficiency and accuracy. However, standard isosurface
rendering has some limitations in effectiveness. First, it uses a monotone
colored approach and can only visualize the geometry features of an isosurface.
The lack of the capability to illustrate the material property and the internal
structures behind an isosurface has been a big limitation of this method in
applications. Another limitation of isosurface rendering is the difficulty to
reveal physically meaningful structures, which are hidden in one or multiple
isosurfaces. As such, the application requirements of extract and recombine
structures of interest can not be implemented effectively with isosurface
rendering. In this work, we develop an enhanced isosurface rendering technique
to improve the effectiveness while maintaining the performance efficiency of
the standard isosurface rendering. First, an isosurface color enhancement
method is proposed to illustrate the neighborhood density and to reveal some of
the internal structures. Second, we extend the structure extraction capability
of isosurface rendering by enabling explicit scene exploration within a
3D-view, using surface peeling, voxel-selecting, isosurface segmentation, and
multi-surface-structure visualization. Our experiments show that the color
enhancement not only improves the visual fidelity of the rendering, but also
reveals the internal structures without significant increase of the
computational cost. Explicit scene exploration is also demonstrated as a
powerful tool in some application scenarios, such as displaying multiple
abdominal organs.
"
161,"Towards an Integrated Visualization Of Semantically Enriched 3D City
  Models: An Ontology of 3D Visualization Techniques","  3D city models - which represent in 3 dimensions the geometric elements of a
city - are increasingly used for an intended wide range of applications. Such
uses are made possible by using semantically enriched 3D city models and by
presenting such enriched 3D city models in a way that allows decision-making
processes to be carried out from the best choices among sets of objectives, and
across issues and scales. In order to help in such a decision-making process we
have defined a framework to find the best visualization technique(s) for a set
of potentially heterogeneous data that have to be visualized within the same 3D
city model, in order to perform a given task in a specific context. We have
chosen an ontology-based approach. This approach and the specification and use
of the resulting ontology of 3D visualization techniques are described in this
paper.
"
162,"Artimate: an articulatory animation framework for audiovisual speech
  synthesis","  We present a modular framework for articulatory animation synthesis using
speech motion capture data obtained with electromagnetic articulography (EMA).
Adapting a skeletal animation approach, the articulatory motion data is applied
to a three-dimensional (3D) model of the vocal tract, creating a portable
resource that can be integrated in an audiovisual (AV) speech synthesis
platform to provide realistic animation of the tongue and teeth for a virtual
character. The framework also provides an interface to articulatory animation
synthesis, as well as an example application to illustrate its use with a 3D
game engine. We rely on cross-platform, open-source software and open standards
to provide a lightweight, accessible, and portable workflow.
"
163,Efficient computational noise in GLSL,"  We present GLSL implementations of Perlin noise and Perlin simplex noise that
run fast enough for practical consideration on current generation GPU hardware.
The key benefits are that the functions are purely computational, i.e. they use
neither textures nor lookup tables, and that they are implemented in GLSL
version 1.20, which means they are compatible with all current GLSL-capable
platforms, including OpenGL ES 2.0 and WebGL 1.0. Their performance is on par
with previously presented GPU implementations of noise, they are very
convenient to use, and they scale well with increasing parallelism in present
and upcoming GPU architectures.
"
164,"Numerical Analysis of Diagonal-Preserving, Ripple-Minimizing and
  Low-Pass Image Resampling Methods","  Image resampling is a necessary component of any operation that changes the
size of an image or its geometry.
  Methods tuned for natural image upsampling (roughly speaking, image
enlargement) are analyzed and developed with a focus on their ability to
preserve diagonal features and suppress overshoots. Monotone, locally bounded
and almost monotone ""direct"" interpolation and filtering methods, as well as
face split and vertex split surface subdivision methods, alone or in
combination, are studied. Key properties are established by way of proofs and
counterexamples as well as numerical experiments involving 1D curve and 2D
diagonal data resampling.
  In addition, the Remez minimax method for the computation of low-cost
polynomial approximations of low-pass filter kernels tuned for natural image
downsampling (roughly speaking, image reduction) is refactored for relative
error minimization in the presence of roots in the interior of the interval of
approximation and so that even and odd functions are approximated with like
polynomials. The accuracy and frequency response of the approximations are
tabulated and plotted against the original, establishing their rapid
convergence.
"
165,Geodesics in Heat,"  We introduce the heat method for computing the shortest geodesic distance to
a specified subset (e.g., point or curve) of a given domain. The heat method is
robust, efficient, and simple to implement since it is based on solving a pair
of standard linear elliptic problems. The method represents a significant
breakthrough in the practical computation of distance on a wide variety of
geometric domains, since the resulting linear systems can be prefactored once
and subsequently solved in near-linear time. In practice, distance can be
updated via the heat method an order of magnitude faster than with
state-of-the-art methods while maintaining a comparable level of accuracy. We
provide numerical evidence that the method converges to the exact geodesic
distance in the limit of refinement; we also explore smoothed approximations of
distance suitable for applications where more regularity is required.
"
166,"A Distributed GPU-based Framework for real-time 3D Volume Rendering of
  Large Astronomical Data Cubes","  We present a framework to interactively volume-render three-dimensional data
cubes using distributed ray-casting and volume bricking over a cluster of
workstations powered by one or more graphics processing units (GPUs) and a
multi-core CPU. The main design target for this framework is to provide an
in-core visualization solution able to provide three-dimensional interactive
views of terabyte-sized data cubes. We tested the presented framework using a
computing cluster comprising 64 nodes with a total of 128 GPUs. The framework
proved to be scalable to render a 204 GB data cube with an average of 30 frames
per second. Our performance analyses also compare between using NVIDIA Tesla
1060 and 2050 GPU architectures and the effect of increasing the visualization
output resolution on the rendering performance. Although our initial focus, and
the examples presented in this work, is volume rendering of spectral data cubes
from radio astronomy, we contend that our approach has applicability to other
disciplines where close to real-time volume rendering of terabyte-order 3D data
sets is a requirement.
"
167,Visualizing 2D Flows with Animated Arrow Plots,"  Flow fields are often represented by a set of static arrows to illustrate
scientific vulgarization, documentary film, meteorology, etc. This simple
schematic representation lets an observer intuitively interpret the main
properties of a flow: its orientation and velocity magnitude. We propose to
generate dynamic versions of such representations for 2D unsteady flow fields.
Our algorithm smoothly animates arrows along the flow while controlling their
density in the domain over time. Several strategies have been combined to lower
the unavoidable popping artifacts arising when arrows appear and disappear and
to achieve visually pleasing animations. Disturbing arrow rotations in low
velocity regions are also handled by continuously morphing arrow glyphs to
semi-transparent discs. To substantiate our method, we provide results for
synthetic and real velocity field datasets.
"
168,From individual to population: Challenges in Medical Visualization,"  In this paper, we first give a high-level overview of medical visualization
development over the past 30 years, focusing on key developments and the trends
that they represent. During this discussion, we will refer to a number of key
papers that we have also arranged on the medical visualization research
timeline. Based on the overview and our observations of the field, we then
identify and discuss the medical visualization research challenges that we
foresee for the coming decade.
"
169,Visualization in Connectomics,"  Connectomics is a field of neuroscience that analyzes neuronal connections. A
connectome is a complete map of a neuronal system, comprising all neuronal
connections between its structures. The term ""connectome"" is close to the word
""genome"" and implies completeness of all neuronal connections, in the same way
as a genome is a complete listing of all nucleotide sequences. The goal of
connectomics is to create a complete representation of the brain's wiring. Such
a representation is believed to increase our understanding of how functional
brain states emerge from their underlying anatomical structure. Furthermore, it
can provide important information for the cure of neuronal dysfunctions like
schizophrenia or autism. In this paper, we review the current state-of-the-art
of visualization and image processing techniques in the field of connectomics
and describe some remaining challenges.
"
170,A novel 2.5D approach for interfacing with web applications,"  Web applications need better user interface to be interactive and attractive.
A new approach/concept of dimensional enhancement - 2.5D ""a 2D display of a
virtual 3D environment"", which can be implemented in social networking sites
and further in other system applications.
"
171,The Ultrasound Visualization Pipeline - A Survey,"  Ultrasound is one of the most frequently used imaging modality in medicine.
The high spatial resolution, its interactive nature and non-invasiveness makes
it the first choice in many examinations. Image interpretation is one of
ultrasound's main challenges. Much training is required to obtain a confident
skill level in ultrasound-based diagnostics. State-of-the-art graphics
techniques is needed to provide meaningful visualizations of ultrasound in
real-time. In this paper we present the process-pipeline for ultrasound
visualization, including an overview of the tasks performed in the specific
steps. To provide an insight into the trends of ultrasound visualization
research, we have selected a set of significant publications and divided them
into a technique-based taxonomy covering the topics pre-processing,
segmentation, registration, rendering and augmented reality. For the different
technique types we discuss the difference between ultrasound-based techniques
and techniques for other modalities.
"
172,"Artist Agent: A Reinforcement Learning Approach to Automatic Stroke
  Generation in Oriental Ink Painting","  Oriental ink painting, called Sumi-e, is one of the most appealing painting
styles that has attracted artists around the world. Major challenges in
computer-based Sumi-e simulation are to abstract complex scene information and
draw smooth and natural brush strokes. To automatically find such strokes, we
propose to model the brush as a reinforcement learning agent, and learn desired
brush-trajectories by maximizing the sum of rewards in the policy search
framework. We also provide elaborate design of actions, states, and rewards
tailored for a Sumi-e agent. The effectiveness of our proposed approach is
demonstrated through simulated Sumi-e experiments.
"
173,Dynamic Domain Classification for Fractal Image Compression,"  Fractal image compression is attractive except for its high encoding time
requirements. The image is encoded as a set of contractive affine
transformations. The image is partitioned into non-overlapping range blocks,
and a best matching domain block larger than the range block is identified.
There are many attempts on improving the encoding time by reducing the size of
search pool for range-domain matching. But these methods are attempting to
prepare a static domain pool that remains unchanged throughout the encoding
process. This paper proposes dynamic preparation of separate domain pool for
each range block. This will result in significant reduction in the encoding
time. The domain pool for a particular range block can be selected based upon a
parametric value. Here we use classification based on local fractal dimension.
"
174,"Improved visualisation of brain arteriovenous malformations using color
  intensity projections with hue cycling","  Color intensity projections (CIP) have been shown to improve the
visualisation of greyscale angiography images by combining greyscale images
into a single color image. A key property of the combined CIP image is the
encoding of the arrival time information from greyscale images into the hue of
the color in the CIP image. A few minor improvements to the calculation of the
CIP image are introduced that substantially improve the quality of the
visualisation. One improvement is interpolating of the greyscale images in time
before calculation of the CIP image. A second is the use of hue cycling - where
the hue of the color is cycled through more than once in an image. The hue
cycling allows the variation of the hue to be concentrated in structures of
interest. If there is a zero time point hue cycling can be applied after zero
time and before zero time can be indicated by greyscale. If there is an end
time point hue cycling can be applied before the end time and pixels can be set
to black after the end time. An angiogram of a brain is used to demonstrate the
substantial improvements hue cycling brings to CIP images. A third improvement
is the use of maximum intensity projection for 2D rendering of a 3D CIP image
volume. A fourth improvement allowing interpreters to interactively adjust the
phase of the hue via standard contrast - brightness controls using lookup
tables. Other potential applications of CIP are also mentioned.
"
175,Visualization of Collaborative Data,"  Collaborative data consist of ratings relating two distinct sets of objects:
users and items. Much of the work with such data focuses on filtering:
predicting unknown ratings for pairs of users and items. In this paper we focus
on the problem of visualizing the information. Given all of the ratings, our
task is to embed all of the users and items as points in the same Euclidean
space. We would like to place users near items that they have rated (or would
rate) high, and far away from those they would give a low rating. We pose this
problem as a real-valued non-linear Bayesian network and employ Markov chain
Monte Carlo and expectation maximization to find an embedding. We present a
metric by which to judge the quality of a visualization and compare our results
to local linear embedding and Eigentaste on three real-world datasets.
"
176,Speckle Reduction using Stochastic Distances,"  This paper presents a new approach for filter design based on stochastic
distances and tests between distributions. A window is defined around each
pixel, samples are compared and only those which pass a goodness-of-fit test
are used to compute the filtered value. The technique is applied to intensity
Synthetic Aperture Radar (SAR) data, using the Gamma model with varying number
of looks allowing, thus, changes in heterogeneity. Modified Nagao-Matsuyama
windows are used to define the samples. The proposal is compared with the Lee's
filter which is considered a standard, using a protocol based on simulation.
Among the criteria used to quantify the quality of filters, we employ the
equivalent number of looks (related to the signal-to-noise ratio), line
contrast, and edge preservation. Moreover, we also assessed the filters by the
Universal Image Quality Index and the Pearson's correlation between edges.
"
177,Generalized Statistical Complexity of SAR Imagery,"  A new generalized Statistical Complexity Measure (SCM) was proposed by Rosso
et al in 2010. It is a functional that captures the notions of order/disorder
and of distance to an equilibrium distribution. The former is computed by a
measure of entropy, while the latter depends on the definition of a stochastic
divergence. When the scene is illuminated by coherent radiation, image data is
corrupted by speckle noise, as is the case of ultrasound-B, sonar, laser and
Synthetic Aperture Radar (SAR) sensors. In the amplitude and intensity formats,
this noise is multiplicative and non-Gaussian requiring, thus, specialized
techniques for image processing and understanding. One of the most successful
family of models for describing these images is the Multiplicative Model which
leads, among other probability distributions, to the G0 law. This distribution
has been validated in the literature as an expressive and tractable model,
deserving the ""universal"" denomination for its ability to describe most types
of targets. In order to compute the statistical complexity of a site in an
image corrupted by speckle noise, we assume that the equilibrium distribution
is that of fully developed speckle, namely the Gamma law in intensity format,
which appears in areas with little or no texture. We use the Shannon entropy
along with the Hellinger distance to measure the statistical complexity of
intensity SAR images, and we show that it is an expressive feature capable of
identifying many types of targets.
"
178,Polarimetric SAR Image Smoothing with Stochastic Distances,"  Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an
important source of information in remote sensing applications. The most
complete format this type of imaging produces consists of complex-valued
Hermitian matrices in every image coordinate and, as such, their visualization
is challenging. They also suffer from speckle noise which reduces the
signal-to-noise ratio. Smoothing techniques have been proposed in the
literature aiming at preserving different features and, analogously,
projections from the cone of Hermitian positive matrices to different color
representation spaces are used for enhancing certain characteristics. In this
work we propose the use of stochastic distances between models that describe
this type of data in a Nagao-Matsuyama-type of smoothing technique. The
resulting images are shown to present good visualization properties (noise
reduction with preservation of fine details) in all the considered
visualization spaces.
"
179,Parametric and Nonparametric Tests for Speckled Imagery,"  Synthetic aperture radar (SAR) has a pivotal role as a remote imaging method.
Obtained by means of coherent illumination, SAR images are contaminated with
speckle noise. The statistical modeling of such contamination is well described
according with the multiplicative model and its implied G0 distribution. The
understanding of SAR imagery and scene element identification is an important
objective in the field. In particular, reliable image contrast tools are
sought. Aiming the proposition of new tools for evaluating SAR image contrast,
we investigated new methods based on stochastic divergence. We propose several
divergence measures specifically tailored for G0 distributed data. We also
introduce a nonparametric approach based on the Kolmogorov-Smirnov distance for
G0 data. We devised and assessed tests based on such measures, and their
performances were quantified according to their test sizes and powers. Using
Monte Carlo simulation, we present a robustness analysis of test statistics and
of maximum likelihood estimators for several degrees of innovative
contamination. It was identified that the proposed tests based on triangular
and arithmetic-geometric measures outperformed the Kolmogorov-Smirnov
methodology.
"
180,Automated Training and Maintenance through Kinect,"  In this paper, we have worked on reducing burden on mechanic involving
complex automobile maintenance activities that are performed in centralised
workshops. We have presented a system prototype that combines Augmented Reality
with Kinect. With the use of Kinect, very high quality sensors are available at
considerably low costs, thus reducing overall expenditure for system design.
The system can be operated either in Speech mode or in Gesture mode. The system
can be controlled by various audio commands if user opts for Speech mode. The
same controlling can also be done by using a set of Gestures in Gesture mode.
  Gesture recognition is the task performed by Kinect system. This system,
bundled with RGB and Depth camera, processes the skeletal data by keeping track
of 20 different body joints. Recognizing Gestures is done by verifying user
movements and checking them against predefined condition. Augmented Reality
module captures real-time image data streams from high resolution camera. This
module then generates 3D model that is superimposed on real time data.
"
181,Hypothesis Testing in Speckled Data with Stochastic Distances,"  Images obtained with coherent illumination, as is the case of sonar,
ultrasound-B, laser and Synthetic Aperture Radar -- SAR, are affected by
speckle noise which reduces the ability to extract information from the data.
Specialized techniques are required to deal with such imagery, which has been
modeled by the G0 distribution and under which regions with different degrees
of roughness and mean brightness can be characterized by two parameters; a
third parameter, the number of looks, is related to the overall signal-to-noise
ratio. Assessing distances between samples is an important step in image
analysis; they provide grounds of the separability and, therefore, of the
performance of classification procedures. This work derives and compares eight
stochastic distances and assesses the performance of hypothesis tests that
employ them and maximum likelihood estimation. We conclude that tests based on
the triangular distance have the closest empirical size to the theoretical one,
while those based on the arithmetic-geometric distances have the best power.
Since the power of tests based on the triangular distance is close to optimum,
we conclude that the safest choice is using this distance for hypothesis
testing, even when compared with classical distances as Kullback-Leibler and
Bhattacharyya.
"
182,"Combining Brain-Computer Interfaces and Haptics: Detecting Mental
  Workload to Adapt Haptic Assistance","  In this paper we introduce the combined use of Brain-Computer Interfaces
(BCI) and Haptic interfaces. We propose to adapt haptic guides based on the
mental activity measured by a BCI system. This novel approach is illustrated
within a proof-of-concept system: haptic guides are toggled during a
path-following task thanks to a mental workload index provided by a BCI. The
aim of this system is to provide haptic assistance only when the user's brain
activity reflects a high mental workload. A user study conducted with 8
participants shows that our proof-of-concept is operational and exploitable.
Results show that activation of haptic guides occurs in the most difficult part
of the path-following task. Moreover it allows to increase task performance by
53% by activating assistance only 59% of the time. Taken together, these
results suggest that BCI could be used to determine when the user needs
assistance during haptic interaction and to enable haptic guides accordingly.
"
183,Fast View Frustum Culling of Spatial Object by Analytical Bounding Bin,"  It is a common sense to apply the VFC (view frustum culling) of spatial
object to bounding cube of the object in 3D graphics. The accuracy of VFC can
not be guaranteed even in cube rotated three-dimensionally. In this paper is
proposed a method which is able to carry out more precise and fast VFC of any
spatial object in the image domain of cube by an analytic mapping, and is
demonstrated the effect of the method for terrain block on global surface.
"
184,"PlotXY: a high quality plotting system for the Herschel Interactive
  Processing Environment (HIPE), and the astronomical community","  The Herschel Interactive Processing Environment (HIPE) was developed by the
European Space Agency (ESA) in collaboration with NASA and the Herschel
Instrument Control Centres to provide the astronomical community a complete
environment to process and analyze the data gathered by the Herschel Space
Observatory. One of the most important components of HIPE is the plotting
system (named PlotXY) that we present here. With PlotXY it is possible to
produce easily high quality publication ready 2D plots. It provides a long list
of features, with fully configurable components, and interactive zooming. The
entire code of HIPE is written in Java and is open source released under the
GNU Lesser General Public License version 3. A new version of PlotXY is being
developed to be independent from the HIPE code base; it is available to the
software development community for the inclusion in other projects at the URL
http://code.google.com/p/jplot2d/.
"
185,Color Assessment and Transfer for Web Pages,"  Colors play a particularly important role in both designing and accessing Web
pages. A well-designed color scheme improves Web pages' visual aesthetic and
facilitates user interactions. As far as we know, existing color assessment
studies focus on images; studies on color assessment and editing for Web pages
are rare. This paper investigates color assessment for Web pages based on
existing online color theme-rating data sets and applies this assessment to Web
color edit. This study consists of three parts. First, we study the extraction
of a Web page's color theme. Second, we construct color assessment models that
score the color compatibility of a Web page by leveraging machine learning
techniques. Third, we incorporate the learned color assessment model into a new
application, namely, color transfer for Web pages. Our study combines
techniques from computer graphics, Web mining, computer vision, and machine
learning. Experimental results suggest that our constructed color assessment
models are effective, and useful in the color transfer for Web pages, which has
received little attention in both Web mining and computer graphics communities.
"
186,"An algorithm for improving the quality of compacted JPEG image by
  minimizes the blocking artifacts","  The Block Transform Coded, JPEG- a lossy image compression format has been
used to keep storage and bandwidth requirements of digital image at practical
levels. However, JPEG compression schemes may exhibit unwanted image artifacts
to appear - such as the 'blocky' artifact found in smooth/monotone areas of an
image, caused by the coarse quantization of DCT coefficients. A number of image
filtering approaches have been analyzed in literature incorporating
value-averaging filters in order to smooth out the discontinuities that appear
across DCT block boundaries. Although some of these approaches are able to
decrease the severity of these unwanted artifacts to some extent, other
approaches have certain limitations that cause excessive blurring to
high-contrast edges in the image. The image deblocking algorithm presented in
this paper aims to filter the blocked boundaries. This is accomplished by
employing smoothening, detection of blocked edges and then filtering the
difference between the pixels containing the blocked edge. The deblocking
algorithm presented has been successful in reducing blocky artifacts in an
image and therefore increases the subjective as well as objective quality of
the reconstructed image.
"
187,General Midpoint Subdivision,"  In this paper, we introduce two generalizations of midpoint subdivision and
analyze the smoothness of the resulting subdivision surfaces at regular and
extraordinary points.
  The smoothing operators used in midpoint and mid-edge subdivision connect the
midpoints of adjacent faces or of adjacent edges, respectively. An arbitrary
combination of these two operators and the refinement operator that splits each
face with m vertices into m quadrilateral subfaces forms a general midpoint
subdivision operator. We analyze the smoothness of the resulting subdivision
surfaces by estimating the norm of a special second order difference scheme and
by using established methods for analyzing midpoint subdivision. The surfaces
are smooth at their regular points and they are also smooth at extraordinary
points for a certain subclass of general midpoint subdivision schemes.
  Generalizing the smoothing rules of non general midpoint subdivision schemes
around extraordinary and regular vertices or faces results in a class of
subdivision schemes, which includes the Catmull-Clark algorithm with restricted
parameters. We call these subdivision schemes generalized Catmull-Clark schemes
and we analyze their smoothness properties.
"
188,A Novel Data Hiding Scheme for Binary Images,"  This paper presents a new scheme for hiding a secret message in binary
images. Given m*n cover image block, the new scheme can conceal as many as
log(m*n +1) bits of data in block, by changing at most one bit in the block.
The hiding ability of the new scheme is the same as Chang et al.'s scheme and
higher than Tseng et al.'s scheme. Additionally, the security of the new scheme
is higher than the two above schemes.
"
189,Visual Exploration of Simulated and Measured Blood Flow,"  Morphology of cardiovascular tissue is influenced by the unsteady behavior of
the blood flow and vice versa. Therefore, the pathogenesis of several
cardiovascular diseases is directly affected by the blood-flow dynamics.
Understanding flow behavior is of vital importance to understand the
cardiovascular system and potentially harbors a considerable value for both
diagnosis and risk assessment. The analysis of hemodynamic characteristics
involves qualitative and quantitative inspection of the blood-flow field.
Visualization plays an important role in the qualitative exploration, as well
as the definition of relevant quantitative measures and its validation. There
are two main approaches to obtain information about the blood flow: simulation
by computational fluid dynamics, and in-vivo measurements. Although research on
blood flow simulation has been performed for decades, many open problems remain
concerning accuracy and patient-specific solutions. Possibilities for real
measurement of blood flow have recently increased considerably by new
developments in magnetic resonance imaging which enable the acquisition of 3D
quantitative measurements of blood-flow velocity fields. This chapter presents
the visualization challenges for both simulation and real measurements of
unsteady blood-flow fields.
"
190,"Using multimodal speech production data to evaluate articulatory
  animation for audiovisual speech synthesis","  The importance of modeling speech articulation for high-quality audiovisual
(AV) speech synthesis is widely acknowledged. Nevertheless, while
state-of-the-art, data-driven approaches to facial animation can make use of
sophisticated motion capture techniques, the animation of the intraoral
articulators (viz. the tongue, jaw, and velum) typically makes use of simple
rules or viseme morphing, in stark contrast to the otherwise high quality of
facial modeling. Using appropriate speech production data could significantly
improve the quality of articulatory animation for AV synthesis.
"
191,"Review of Statistical Shape Spaces for 3D Data with Comparative Analysis
  for Human Faces","  With systems for acquiring 3D surface data being evermore commonplace, it has
become important to reliably extract specific shapes from the acquired data. In
the presence of noise and occlusions, this can be done through the use of
statistical shape models, which are learned from databases of clean examples of
the shape in question. In this paper, we review, analyze and compare different
statistical models: from those that analyze the variation in geometry globally
to those that analyze the variation in geometry locally. We first review how
different types of models have been used in the literature, then proceed to
define the models and analyze them theoretically, in terms of both their
statistical and computational aspects. We then perform extensive experimental
comparison on the task of model fitting, and give intuition about which type of
model is better for a few applications. Due to the wide availability of
databases of high-quality data, we use the human face as the specific shape we
wish to extract from corrupted data.
"
192,Sparse Modeling of Intrinsic Correspondences,"  We present a novel sparse modeling approach to non-rigid shape matching using
only the ability to detect repeatable regions. As the input to our algorithm,
we are given only two sets of regions in two shapes; no descriptors are
provided so the correspondence between the regions is not know, nor we know how
many regions correspond in the two shapes. We show that even with such scarce
information, it is possible to establish very accurate correspondence between
the shapes by using methods from the field of sparse modeling, being this, the
first non-trivial use of sparse models in shape correspondence. We formulate
the problem of permuted sparse coding, in which we solve simultaneously for an
unknown permutation ordering the regions on two shapes and for an unknown
correspondence in functional representation. We also propose a robust variant
capable of handling incomplete matches. Numerically, the problem is solved
efficiently by alternating the solution of a linear assignment and a sparse
coding problem. The proposed methods are evaluated qualitatively and
quantitatively on standard benchmarks containing both synthetic and scanned
objects.
"
193,Coupled quasi-harmonic bases,"  The use of Laplacian eigenbases has been shown to be fruitful in many
computer graphics applications. Today, state-of-the-art approaches to shape
analysis, synthesis, and correspondence rely on these natural harmonic bases
that allow using classical tools from harmonic analysis on manifolds. However,
many applications involving multiple shapes are obstacled by the fact that
Laplacian eigenbases computed independently on different shapes are often
incompatible with each other. In this paper, we propose the construction of
common approximate eigenbases for multiple shapes using approximate joint
diagonalization algorithms. We illustrate the benefits of the proposed approach
on tasks from shape editing, pose transfer, correspondence, and similarity.
"
194,Invariance And Inner Fractals In Polynomial And Transcendental Fractals,"  A lot of formal and informal recreational study took place in the fields of
Meromorphic Maps, since Mandelbrot popularized the map z <- z^2 + c. An
immediate generalization of the Mandelbrot z <-z^n + c also known as the
Multibrot family were also studied. In the current paper, general truncated
polynomial maps of the form z <- \sum_{p>=2} a_px^p +c are studied. Two
fundamental properties of these polynomial maps are hereby presented. One of
them is the existence of shape preserving transformations on fractal images,
and another one is the existence of embedded Multibrot fractals inside a
polynomial fractal. Any transform expression with transcendental terms also
shows embedded Multibrot fractals, due to Taylor series expansion possible on
the transcendental functions. We present a method by which existence of
embedded fractals can be predicted. A gallery of images is presented alongside
to showcase the findings.
"
195,"Schr\""{o}dinger Diffusion for Shape Analysis with Texture","  In recent years, quantities derived from the heat equation have become
popular in shape processing and analysis of triangulated surfaces. Such
measures are often robust with respect to different kinds of perturbations,
including near-isometries, topological noise and partialities. Here, we propose
to exploit the semigroup of a Schr\""{o}dinger operator in order to deal with
texture data, while maintaining the desirable properties of the heat kernel. We
define a family of Schr\""{o}dinger diffusion distances analogous to the ones
associated to the heat kernels, and show that they are continuous under
perturbations of the data. As an application, we introduce a method for
retrieval of textured shapes through comparison of Schr\""{o}dinger diffusion
distance histograms with the earth's mover distance, and present some numerical
experiments showing superior performance compared to an analogous method that
ignores the texture.
"
196,Reduction of Blocking Artifacts In JPEG Compressed Image,"  In JPEG (DCT based) compresses image data by representing the original image
with a small number of transform coefficients. It exploits the fact that for
typical images a large amount of signal energy is concentrated in a small
number of coefficients. The goal of DCT transform coding is to minimize the
number of retained transform coefficients while keeping distortion at an
acceptable level.In JPEG, it is done in 8X8 non overlapping blocks. It divides
an image into blocks of equal size and processes each block independently.
Block processing allows the coder to adapt to the local image statistics,
exploit the correlation present among neighboring image pixels, and to reduce
computational and storage requirements. One of the most degradation of the
block transform coding is the blocking artifact. These artifacts appear as a
regular pattern of visible block boundaries. This degradation is a direct
result of the coarse quantization of the coefficients and the independent
processing of the blocks which does not take into account the existing
correlations among adjacent block pixels. In this paper attempt is being made
to reduce the blocking artifact introduced by the Block DCT Transform in JPEG.
"
197,"Vortices within vortices: hierarchical nature of vortex tubes in
  turbulence","  The JHU turbulence database [1] can be used with a state of the art
visualisation tool [2] to generate high quality fluid dynamics videos. In this
work we investigate the classical idea that smaller structures in turbulent
flows, while engaged in their own internal dynamics, are advected by the larger
structures. They are not advected undistorted, however. We see instead that the
small scale structures are sheared and twisted by the larger scales. This
illuminates the basic mechanisms of the turbulent cascade.
"
198,Textural Approach to Palmprint Identification,"  Biometrics which use of human physiological characteristics for identifying
an individual is now a widespread method of identification and authentication.
Biometric identification is a technology which uses several image processing
techniques and describes the general procedure for identification and
verification using feature extraction, storage and matching from the digitized
image of biometric characters such as Finger Print, Face, Iris or Palm Print.
The current paper uses palm print biometrics. Here we have presented an
identification approach using textural properties of palm print images. The
elegance of the method is that the conventional edge detection technique is
extended to suitably describe the texture features. In this technique all the
characteristics of the palm such as principal lines, edges and wrinkles are
considered with equal importance.
"
199,"Beltrami Representation and its applications to texture map and video
  compression","  Surface parameterizations and registrations are important in computer
graphics and imaging, where 1-1 correspondences between meshes are computed. In
practice, surface maps are usually represented and stored as 3D coordinates
each vertex is mapped to, which often requires lots of storage memory. This
causes inconvenience in data transmission and data storage. To tackle this
problem, we propose an effective algorithm for compressing surface
homeomorphisms using Fourier approximation of the Beltrami representation. The
Beltrami representation is a complex-valued function defined on triangular
faces of the surface mesh with supreme norm strictly less than 1. Under
suitable normalization, there is a 1-1 correspondence between the set of
surface homeomorphisms and the set of Beltrami representations. Hence, every
bijective surface map is associated with a unique Beltrami representation.
Conversely, given a Beltrami representation, the corresponding bijective
surface map can be exactly reconstructed using the Linear Beltrami Solver
introduced in this paper. Using the Beltrami representation, the surface
homeomorphism can be easily compressed by Fourier approximation, without
distorting the bijectivity of the map. The storage memory can be effectively
reduced, which is useful for many practical problems in computer graphics and
imaging. In this paper, we proposed to apply the algorithm to texture map
compression and video compression. With our proposed algorithm, the storage
requirement for the texture properties of a textured surface can be
significantly reduced. Our algorithm can further be applied to compressing
motion vector fields for video compression, which effectively improve the
compression ratio.
"
200,A Simple Algorithm for Computing BOCP,"  In this article, we devise a concise algorithm for computing BOCP. Our method
is simple, easy-to-implement but without loss of efficiency. Given two
circular-arc polygons with $m$ and $n$ edges respectively, our method runs in
$O(m+n+(l+k)\log l)$ time, using $O(m+n+k)$ space, where $k$ is the number of
intersections, and $l$ is the number of {edge}s. Our algorithm has the power to
approximate to linear complexity when $k$ and $l$ are small. The superiority of
the proposed algorithm is also validated through empirical study.
"
201,Nearest Neighbor Value Interpolation,"  This paper presents the nearest neighbor value (NNV) algorithm for high
resolution (H.R.) image interpolation. The difference between the proposed
algorithm and conventional nearest neighbor algorithm is that the concept
applied, to estimate the missing pixel value, is guided by the nearest value
rather than the distance. In other words, the proposed concept selects one
pixel, among four directly surrounding the empty location, whose value is
almost equal to the value generated by the conventional bilinear interpolation
algorithm. The proposed method demonstrated higher performances in terms of
H.R. when compared to the conventional interpolation algorithms mentioned.
"
202,"Teichm\""uller extremal mapping and its applications to landmark matching
  registration","  Registration, which aims to find an optimal 1-1 correspondence between
shapes, is an important process in different research areas. Conformal mappings
have been widely used to obtain a diffeomorphism between shapes that minimizes
angular distortion. Conformal registrations are beneficial since it preserves
the local geometry well. However, when landmark constraints are enforced,
conformal mappings generally do not exist. This motivates us to look for a
unique landmark matching quasi-conformal registration, which minimizes the
conformality distortion. Under suitable condition on the landmark constraints,
a unique diffeomporphism, called the Teichm\""uller extremal mapping between two
surfaces can be obtained, which minimizes the maximal conformality distortion.
In this paper, we propose an efficient iterative algorithm, called the
Quasi-conformal (QC) iterations, to compute the Teichm\""uller mapping. The
basic idea is to represent the set of diffeomorphisms using Beltrami
coefficients (BCs), and look for an optimal BC associated to the desired
Teichm\""uller mapping. The associated diffeomorphism can be efficiently
reconstructed from the optimal BC using the Linear Beltrami Solver(LBS). Using
BCs to represent diffeomorphisms guarantees the diffeomorphic property of the
registration. Using our proposed method, the Teichm\""uller mapping can be
accurately and efficiently computed within 10 seconds. The obtained
registration is guaranteed to be bijective. The proposed algorithm can also be
extended to compute Teichm\""uller mapping with soft landmark constraints. We
applied the proposed algorithm to real applications, such as brain landmark
matching registration, constrained texture mapping and human face registration.
Experimental results shows that our method is both effective and efficient in
computing a non-overlap landmark matching registration with least amount of
conformality distortion.
"
203,Gap Processing for Adaptive Maximal Poisson-Disk Sampling,"  In this paper, we study the generation of maximal Poisson-disk sets with
varying radii. First, we present a geometric analysis of gaps in such disk
sets. This analysis is the basis for maximal and adaptive sampling in Euclidean
space and on manifolds. Second, we propose efficient algorithms and data
structures to detect gaps and update gaps when disks are inserted, deleted,
moved, or have their radius changed. We build on the concepts of the regular
triangulation and the power diagram. Third, we will show how our analysis can
make a contribution to the state-of-the-art in surface remeshing.
"
204,Color scales that are effective in both color and grayscale,"  We consider the problem of finding a color scale which performs well when
converted to a grayscale. We assume that each color is converted to a shade of
gray with the same intensity as the color. We also assume that the color scales
have a linear variation of intensity and hue, and find scales which maximize
the average chroma (or ""colorfulness"") of the colors. We find two classes of
solutions, which traverse the color wheel in opposite directions. The two
classes of scales start with hues near cyan and red. The average chroma of the
scales are 65-77% those of the pure colors.
"
205,Dynamic Facial Expression of Emotion Made Easy,"  Facial emotion expression for virtual characters is used in a wide variety of
areas. Often, the primary reason to use emotion expression is not to study
emotion expression generation per se, but to use emotion expression in an
application or research project. What is then needed is an easy to use and
flexible, but also validated mechanism to do so. In this report we present such
a mechanism. It enables developers to build virtual characters with dynamic
affective facial expressions. The mechanism is based on Facial Action Coding.
It is easy to implement, and code is available for download. To show the
validity of the expressions generated with the mechanism we tested the
recognition accuracy for 6 basic emotions (joy, anger, sadness, surprise,
disgust, fear) and 4 blend emotions (enthusiastic, furious, frustrated, and
evil). Additionally we investigated the effect of VC distance (z-coordinate),
the effect of the VC's face morphology (male vs. female), the effect of a
lateral versus a frontal presentation of the expression, and the effect of
intensity of the expression. Participants (n=19, Western and Asian subjects)
rated the intensity of each expression for each condition (within subject
setup) in a non forced choice manner. All of the basic emotions were uniquely
perceived as such. Further, the blends and confusion details of basic emotions
are compatible with findings in psychology.
"
206,Tera-scale Astronomical Data Analysis and Visualization,"  We present a high-performance, graphics processing unit (GPU)-based framework
for the efficient analysis and visualization of (nearly) terabyte (TB)-sized
3-dimensional images. Using a cluster of 96 GPUs, we demonstrate for a 0.5 TB
image: (1) volume rendering using an arbitrary transfer function at 7--10
frames per second; (2) computation of basic global image statistics such as the
mean intensity and standard deviation in 1.7 s; (3) evaluation of the image
histogram in 4 s; and (4) evaluation of the global image median intensity in
just 45 s. Our measured results correspond to a raw computational throughput
approaching one teravoxel per second, and are 10--100 times faster than the
best possible performance with traditional single-node, multi-core CPU
implementations. A scalability analysis shows the framework will scale well to
images sized 1 TB and beyond. Other parallel data analysis algorithms can be
added to the framework with relative ease, and accordingly, we present our
framework as a possible solution to the image analysis and visualization
requirements of next-generation telescopes, including the forthcoming Square
Kilometre Array pathfinder radiotelescopes.
"
207,Improving Perceptual Color Difference using Basic Color Terms,"  We suggest a new color distance based on two observations. First, perceptual
color differences were designed to be used to compare very similar colors. They
do not capture human perception for medium and large color differences well.
Thresholding was proposed to solve the problem for large color differences,
i.e. two totally different colors are always the same distance apart. We show
that thresholding alone cannot improve medium color differences. We suggest to
alleviate this problem using basic color terms. Second, when a color distance
is used for edge detection, many small distances around the just noticeable
difference may account for false edges. We suggest to reduce the effect of
small distances.
"
208,"Analysis-suitable T-splines: characterization, refineability, and
  approximation","  We establish several fundamental properties of analysis-suitable T-splines
which are important for design and analysis. First, we characterize T-spline
spaces and prove that the space of smooth bicubic polynomials, defined over the
extended T-mesh of an analysis-suitable T-spline, is contained in the
corresponding analysis-suitable T-spline space. This is accomplished through
the theory of perturbed analysis-suitable T-spline spaces and a simple
topological dimension formula. Second, we establish the theory of
analysis-suitable local refinement and describe the conditions under which two
analysis-suitable T-spline spaces are nested. Last, we demonstrate that these
results can be used to establish basic approximation results which are critical
for analysis.
"
209,"A Novel Algorithm for Real-time Procedural Generation of Building Floor
  Plans","  Real-time generation of natural-looking floor plans is vital in games with
dynamic environments. This paper presents an algorithm to generate suburban
house floor plans in real-time. The algorithm is based on the work presented in
[1]. However, the corridor placement is redesigned to produce floor plans
similar to real houses. Moreover, an optimization stage is added to find a
corridor placement with the minimum used space, an approach that is designed to
mimic the real-life practices to minimize the wasted spaces in the design. The
results show very similar floor plans to the ones designed by an architect.
"
210,A Conformal Approach for Surface Inpainting,"  We address the problem of surface inpainting, which aims to fill in holes or
missing regions on a Riemann surface based on its surface geometry. In
practical situation, surfaces obtained from range scanners often have holes
where the 3D models are incomplete. In order to analyze the 3D shapes
effectively, restoring the incomplete shape by filling in the surface holes is
necessary. In this paper, we propose a novel conformal approach to inpaint
surface holes on a Riemann surface based on its surface geometry. The basic
idea is to represent the Riemann surface using its conformal factor and mean
curvature. According to Riemann surface theory, a Riemann surface can be
uniquely determined by its conformal factor and mean curvature up to a rigid
motion. Given a Riemann surface $S$, its mean curvature $H$ and conformal
factor $\lambda$ can be computed easily through its conformal parameterization.
Conversely, given $\lambda$ and $H$, a Riemann surface can be uniquely
reconstructed by solving the Gauss-Codazzi equation on the conformal parameter
domain. Hence, the conformal factor and the mean curvature are two geometric
quantities fully describing the surface. With this $\lambda$-$H$ representation
of the surface, the problem of surface inpainting can be reduced to the problem
of image inpainting of $\lambda$ and $H$ on the conformal parameter domain.
Once $\lambda$ and $H$ are inpainted, a Riemann surface can be reconstructed
which effectively restores the 3D surface with missing holes. Since the
inpainting model is based on the geometric quantities $\lambda$ and $H$, the
restored surface follows the surface geometric pattern. We test the proposed
algorithm on synthetic data as well as real surface data. Experimental results
show that our proposed method is an effective surface inpainting algorithm to
fill in surface holes on an incomplete 3D models based their surface geometry.
"
211,Similarity of Polygonal Curves in the Presence of Outliers,"  The Fr\'{e}chet distance is a well studied and commonly used measure to
capture the similarity of polygonal curves. Unfortunately, it exhibits a high
sensitivity to the presence of outliers. Since the presence of outliers is a
frequently occurring phenomenon in practice, a robust variant of Fr\'{e}chet
distance is required which absorbs outliers. We study such a variant here. In
this modified variant, our objective is to minimize the length of subcurves of
two polygonal curves that need to be ignored (MinEx problem), or alternately,
maximize the length of subcurves that are preserved (MaxIn problem), to achieve
a given Fr\'{e}chet distance. An exact solution to one problem would imply an
exact solution to the other problem. However, we show that these problems are
not solvable by radicals over $\mathbb{Q}$ and that the degree of the
polynomial equations involved is unbounded in general. This motivates the
search for approximate solutions. We present an algorithm, which approximates,
for a given input parameter $\delta$, optimal solutions for the \MinEx\ and
\MaxIn\ problems up to an additive approximation error $\delta$ times the
length of the input curves. The resulting running time is upper bounded by
$\mathcal{O} \left(\frac{n^3}{\delta} \log \left(\frac{n}{\delta}
\right)\right)$, where $n$ is the complexity of the input polygonal curves.
"
212,Dynamic Simulation of Soft Heterogeneous Objects,"  This paper describes a 2D and 3D simulation engine that quantitatively models
the statics, dynamics, and non-linear deformation of heterogeneous soft bodies
in a computationally efficient manner. There is a large body of work simulating
compliant mechanisms. These normally assume small deformations with homogeneous
material properties actuated with external forces. There is also a large body
of research on physically-based deformable objects for applications in computer
graphics with the purpose of generating realistic appearances at the expense of
accuracy. Here we present a simulation framework in which an object may be
composed of any number of interspersed materials with varying properties
(stiffness, density, etc.) to enable true heterogeneous multi-material
simulation. Collisions are handled to prevent self-penetration due to large
deformation, which also allows multiple bodies to interact. A volumetric
actuation method is implemented to impart motion to the structures which opens
the door to the design of novel structures and mechanisms. The simulator was
implemented efficiently such that objects with thousands of degrees of freedom
can be simulated at suitable framerates for user interaction using a single
thread of a typical desktop computer. The code is written in platform agnostic
C++ and is fully open source. This research opens the door to the dynamic
simulation of freeform 3D multi-material mechanisms and objects in a manner
suitable for design automation.
"
213,Single-Pass GPU-Raycasting for Structured Adaptive Mesh Refinement Data,"  Structured Adaptive Mesh Refinement (SAMR) is a popular numerical technique
to study processes with high spatial and temporal dynamic range. It reduces
computational requirements by adapting the lattice on which the underlying
differential equations are solved to most efficiently represent the solution.
Particularly in astrophysics and cosmology such simulations now can capture
spatial scales ten orders of magnitude apart and more. The irregular locations
and extensions of the refined regions in the SAMR scheme and the fact that
different resolution levels partially overlap, poses a challenge for GPU-based
direct volume rendering methods. kD-trees have proven to be advantageous to
subdivide the data domain into non-overlapping blocks of equally sized cells,
optimal for the texture units of current graphics hardware, but previous
GPU-supported raycasting approaches for SAMR data using this data structure
required a separate rendering pass for each node, preventing the application of
many advanced lighting schemes that require simultaneous access to more than
one block of cells. In this paper we present a single-pass GPU-raycasting
algorithm for SAMR data that is based on a kD-tree. The tree is efficiently
encoded by a set of 3D-textures, which allows to adaptively sample complete
rays entirely on the GPU without any CPU interaction. We discuss two different
data storage strategies to access the grid data on the GPU and apply them to
several datasets to prove the benefits of the proposed method.
"
214,Sketch-to-Design: Context-based Part Assembly,"  Designing 3D objects from scratch is difficult, especially when the user
intent is fuzzy without a clear target form. In the spirit of
modeling-by-example, we facilitate design by providing reference and
inspiration from existing model contexts. We rethink model design as navigating
through different possible combinations of part assemblies based on a large
collection of pre-segmented 3D models. We propose an interactive
sketch-to-design system, where the user sketches prominent features of parts to
combine. The sketched strokes are analyzed individually and in context with the
other parts to generate relevant shape suggestions via a design gallery
interface. As the session progresses and more parts get selected, contextual
cues becomes increasingly dominant and the system quickly converges to a final
design. As a key enabler, we use pre-learned part-based contextual information
to allow the user to quickly explore different combinations of parts. Our
experiments demonstrate the effectiveness of our approach for efficiently
designing new variations from existing shapes.
"
215,Discrete Surface Modeling Based on Google Earth: A Case Study,"  Google Earth (GE) has become a powerful tool for geological, geophysical and
geographical modeling; yet GE can be accepted to acquire elevation data of
terrain. In this paper, we present a real study case of building the discrete
surface model (DSM) at Haut-Barr Castle in France based on the elevation data
of terrain points extracted from GE using the COM API. We first locate the
position of Haut-Barr Castle and determine the region of the study area, then
extract elevation data of terrain at Haut-Barr, and thirdly create a planar
triangular mesh that covers the study area and finally generate the desired DSM
by calculating the elevation of vertices in the planar mesh via interpolating
with Universal Kriging (UK) and Inverse Distance Weighting (IDW). The generated
DSM can reflect the features of the ground surface at Haut-Barr well, and can
be used for constructingthe Sealed Engineering Geological Model (SEGM) in
further step.
"
216,"Computer-Assisted Interactive Documentary and Performance Arts in
  Illimitable Space","  This major component of the research described in this thesis is 3D computer
graphics, specifically the realistic physics-based softbody simulation and
haptic responsive environments. Minor components include advanced
human-computer interaction environments, non-linear documentary storytelling,
and theatre performance. The journey of this research has been unusual because
it requires a researcher with solid knowledge and background in multiple
disciplines; who also has to be creative and sensitive in order to combine the
possible areas into a new research direction. [...] It focuses on the advanced
computer graphics and emerges from experimental cinematic works and theatrical
artistic practices. Some development content and installations are completed to
prove and evaluate the described concepts and to be convincing. [...] To
summarize, the resulting work involves not only artistic creativity, but
solving or combining technological hurdles in motion tracking, pattern
recognition, force feedback control, etc., with the available documentary
footage on film, video, or images, and text via a variety of devices [....] and
programming, and installing all the needed interfaces such that it all works in
real-time. Thus, the contribution to the knowledge advancement is in solving
these interfacing problems and the real-time aspects of the interaction that
have uses in film industry, fashion industry, new age interactive theatre,
computer games, and web-based technologies and services for entertainment and
education. It also includes building up on this experience to integrate Kinect-
and haptic-based interaction, artistic scenery rendering, and other forms of
control. This research work connects all the research disciplines, seemingly
disjoint fields of research, such as computer graphics, documentary film,
interactive media, and theatre performance together.
"
217,The Geant4 Visualisation System - a multi-driver graphics system,"  From the beginning the Geant4 Visualisation System was designed to support
several simultaneous graphics systems written to common abstract interfaces.
Today it has matured into a powerful diagnostic and presentational tool. It
comes with a library of models that may be added to the current scene and which
include the representation of the Geant4 geometry hierarchy, simulated
trajectories and user-written hits and digitisations. The workhorse is the
OpenGL suite of drivers for X, Xm, Qt and Win32. There is an Open Inventor
driver. Scenes can be exported in special graphics formats for offline viewing
in the DAWN, VRML, HepRApp and gMocren browsers. PostScript can be generated
through OpenGL, Open Inventor, DAWN and HepRApp. Geant4's own tracking
algorithms are used by the Ray Tracer. Not all drivers support all features but
all drivers bring added functionality of some sort. This paper describes the
interfaces and details the individual drivers.
"
218,"Reconstructing Self Organizing Maps as Spider Graphs for better visual
  interpretation of large unstructured datasets","  Self-Organizing Maps (SOM) are popular unsupervised artificial neural network
used to reduce dimensions and visualize data. Visual interpretation from
Self-Organizing Maps (SOM) has been limited due to grid approach of data
representation, which makes inter-scenario analysis impossible. The paper
proposes a new way to structure SOM. This model reconstructs SOM to show
strength between variables as the threads of a cobweb and illuminate
inter-scenario analysis. While Radar Graphs are very crude representation of
spider web, this model uses more lively and realistic cobweb representation to
take into account the difference in strength and length of threads. This model
allows for visualization of highly unstructured dataset with large number of
dimensions, common in Bigdata sources.
"
219,Apollonian Circumcircles of IFS Fractals,"  Euclidean triangles and IFS fractals seem to be disparate geometrical
concepts, unless we consider the Sierpi\'{n}ski gasket, which is a self-similar
collection of triangles. The ""circumcircle"" hints at a direct link, as it can
be derived for three-map IFS fractals in general, defined in an Apollonian
manner. Following this path, one may discover a broader relationship between
polygons and IFS fractals.
"
220,On Intersecting IFS Fractals with Lines,"  IFS fractals - the attractors of Iterated Function Systems - have motivated
plenty of research to date, partly due to their simplicity and applicability in
various fields, such as the modeling of plants in computer graphics, and the
design of fractal antennas. The statement and resolution of the Fractal-Line
Intersection Problem is imperative for a more efficient treatment of certain
applications. This paper intends to take further steps towards this resolution,
building on the literature. For the broad class of hyperdense fractals, a
verifiable condition guaranteeing intersection with any line passing through
the convex hull of a planar IFS fractal is shown, in general R^d for
hyperplanes. The condition also implies a constructive algorithm for finding
the points of intersection. Under certain conditions, an infinite number of
approximate intersections are guaranteed, if there is at least one.
Quantification of the intersection is done via an explicit formula for the
invariant measure of IFS.
"
221,"3D Geological Modeling and Visualization of Rock Masses Based on Google
  Earth: A Case Study","  Google Earth (GE) has become a powerful tool for geological modeling and
visualization. An interesting and useful feature of GE, Google Street View, can
allow the GE users to view geological structure such as layers of rock masses
at a field site. In this paper, we introduce a practical solution for building
3D geological models for rock masses based on the data acquired by use with GE.
A real study case at Haut-Barr, France is presented to demonstrate our
solution. We first locate the position of Haut-Barr in GE, and then determine
the shape and scale of the rock masses in the study area, and thirdly acquire
the layout of layers of rock masses in the Google Street View, and finally
create the approximate 3D geological models by extruding and intersecting. The
generated 3D geological models can simply reflect the basic structure of the
rock masses at Haut-Barr, and can be used for visualizing the rock bodies
interactively.
"
222,"Applications and a Three-dimensional Desktop Environment for an
  Immersive Virtual Reality System","  We developed an application launcher called Multiverse for scientific
visualizations in a CAVE-type virtual reality (VR) system. Multiverse can be
regarded as a type of three-dimensional (3D) desktop environment. In
Multiverse, a user in a CAVE room can browse multiple visualization
applications with 3D icons and explore movies that float in the air. Touching
one of the movies causes ""teleportation"" into the application's VR space. After
analyzing the simulation data using the application, the user can jump back
into Multiverse's VR desktop environment in the CAVE.
"
223,"An Approach to Exascale Visualization: Interactive Viewing of In-Situ
  Visualization","  In the coming era of exascale supercomputing, in-situ visualization will be a
crucial approach for reducing the output data size. A problem of in-situ
visualization is that it loses interactivity if a steering method is not
adopted. In this paper, we propose a new method for the interactive analysis of
in-situ visualization images produced by a batch simulation job. A key idea is
to apply numerous (thousands to millions) in-situ visualizations
simultaneously. The viewer then analyzes the image database interactively
during postprocessing. If each movie can be compressed to 100 MB, one million
movies will only require 100 TB, which is smaller than the size of the raw
numerical data in exascale supercomputing. We performed a feasibility study
using the proposed method. Multiple movie files were produced by a simulation
and they were analyzed using a specially designed movie player. The user could
change the viewing angle, the visualization method, and the parameters
interactively by retrieving an appropriate sequence of images from the movie
dataset.
"
224,Immersive VR Visualizations by VFIVE. Part 1: Development,"  We have been developing a visualization application for CAVE-type virtual
reality (VR) systems for more than a decade. This application, VFIVE, is
currently used in several CAVE systems in Japan for routine visualizations. It
is also used as a base system of further developments of advanced
visualizations. The development of VFIVE is summarized.
"
225,Immersive VR Visualizations by VFIVE. Part 2: Applications,"  VFIVE is a scientific visualization application for CAVE-type immersive
virtual reality systems. The source codes are freely available. VFIVE is used
as a research tool in various VR systems. It also lays the groundwork for
developments of new visualization software for CAVEs. In this paper, we pick up
five CAVE systems in four different institutions in Japan. Applications of
VFIVE in each CAVE system are summarized. Special emphases will be placed on
scientific and technical achievements made possible by VFIVE.
"
226,Approximation of Polyhedral Surface Uniformization,"  We present a constructive approach for approximating the conformal map
(uniformization) of a polyhedral surface to a canonical domain in the plane.
The main tool is a characterization of convex spaces of quasiconformal
simplicial maps and their approximation properties. As far as we are aware,
this is the first algorithm proved to approximate the uniformization of general
polyhedral surfaces.
"
227,Skeletal Representations and Applications,"  When representing a solid object there are alternatives to the use of
traditional explicit (surface meshes) or implicit (zero crossing of implicit
functions) methods. Skeletal representations encode shape information in a
mixed fashion: they are composed of a set of explicit primitives, yet they are
able to efficiently encode the shape's volume as well as its topology. I will
discuss, in two dimensions, how symmetry can be used to reduce the
dimensionality of the data (from a 2D solid to a 1D curve), and how this
relates to the classical definition of skeletons by Medial Axis Transform.
While the medial axis of a 2D shape is composed of a set of curves, in 3D it
results in a set of sheets connected in a complex fashion. Because of this
complexity, medial skeletons are difficult to use in practical applications.
Curve skeletons address this problem by strictly requiring their geometry to be
one dimensional, resulting in an intuitive yet powerful shape representation.
In this report I will define both medial and curve skeletons and discuss their
mutual relationship. I will also present several algorithms for their
computation and a variety of scenarios where skeletons are employed, with a
special focus on geometry processing and shape analysis.
"
228,Correcting Camera Shake by Incremental Sparse Approximation,"  The problem of deblurring an image when the blur kernel is unknown remains
challenging after decades of work. Recently there has been rapid progress on
correcting irregular blur patterns caused by camera shake, but there is still
much room for improvement. We propose a new blind deconvolution method using
incremental sparse edge approximation to recover images blurred by camera
shake. We estimate the blur kernel first from only the strongest edges in the
image, then gradually refine this estimate by allowing for weaker and weaker
edges. Our method competes with the benchmark deblurring performance of the
state-of-the-art while being significantly faster and easier to generalize.
"
229,"Perception, Attention, and Resources: A Decision-Theoretic Approach to
  Graphics Rendering","  We describe work to control graphics rendering under limited computational
resources by taking a decision-theoretic perspective on perceptual costs and
computational savings of approximations. The work extends earlier work on the
control of rendering by introducing methods and models for computing the
expected cost associated with degradations of scene components. The expected
cost is computed by considering the perceptual cost of degradations and a
probability distribution over the attentional focus of viewers. We review the
critical literature describing findings on visual search and attention, discuss
the implications of the findings, and introduce models of expected perceptual
cost. Finally, we discuss policies that harness information about the expected
cost of scene components.
"
230,User Interface for Volume Rendering in Virtual Reality Environments,"  Volume Rendering applications require sophisticated user interaction for the
definition and refinement of transfer functions. Traditional 2D desktop user
interface elements have been developed to solve this task, but such concepts do
not map well to the interaction devices available in Virtual Reality
environments.
  In this paper, we propose an intuitive user interface for Volume Rendering
specifically designed for Virtual Reality environments. The proposed interface
allows transfer function design and refinement based on intuitive two-handed
operation of Wand-like controllers. Additional interaction modes such as
navigation and clip plane manipulation are supported as well.
  The system is implemented using the Sony PlayStation Move controller system.
This choice is based on controller device capabilities as well as application
and environment constraints.
  Initial results document the potential of our approach.
"
231,k-d Darts: Sampling by k-Dimensional Flat Searches,"  We formalize the notion of sampling a function using k-d darts. A k-d dart is
a set of independent, mutually orthogonal, k-dimensional subspaces called k-d
flats. Each dart has d choose k flats, aligned with the coordinate axes for
efficiency. We show that k-d darts are useful for exploring a function's
properties, such as estimating its integral, or finding an exemplar above a
threshold. We describe a recipe for converting an algorithm from point sampling
to k-d dart sampling, assuming the function can be evaluated along a k-d flat.
  We demonstrate that k-d darts are more efficient than point-wise samples in
high dimensions, depending on the characteristics of the sampling domain: e.g.
the subregion of interest has small volume and evaluating the function along a
flat is not too expensive. We present three concrete applications using line
darts (1-d darts): relaxed maximal Poisson-disk sampling, high-quality
rasterization of depth-of-field blur, and estimation of the probability of
failure from a response surface for uncertainty quantification. In these
applications, line darts achieve the same fidelity output as point darts in
less time. We also demonstrate the accuracy of higher dimensional darts for a
volume estimation problem. For Poisson-disk sampling, we use significantly less
memory, enabling the generation of larger point clouds in higher dimensions.
"
232,3T MR-Guided Brachytherapy for Gynecologic Malignancies,"  Gynecologic malignancies are a leading cause of death in women worldwide.
Standard treatment for many primary and recurrent gynecologic cancer cases
includes a combination of external beam radiation, followed by brachytherapy.
Magnetic Resonance Imaging (MRI) is benefitial in diagnostic evaluation, in
mapping the tumor location to tailor radiation dose, and in monitoring the
tumor response to treatment. Initial studies of MR-guidance in gynecologic
brachtherapy demonstrate the ability to optimize tumor coverage and reduce
radiation dose to normal tissues, resulting in improved outcomes for patients.
In this article we describe a methodology to aid applicator placement and
treatment planning for 3 Tesla (3T) MR-guided brachytherapy that was developed
specifically for gynecologic cancers. This has been used in 18 cases to date in
the Advanced Multimodality Image Guided Operating suite at Brigham and Women's
Hospital. It is comprised of state of the art methods for MR imaging, image
analysis, and treatment planning. An MR sequence using 3D-balanced steady state
free precession in a 3T MR scan was identified as the best sequence for
catheter identification with ballooning artifact at the tip. 3D treatment
planning was performed using MR images. Item in development include a software
module designed to support virtual needle trajectory planning that includes
probabilistic bias correction, graph based segmentation, and image registration
algorithms. The results demonstrate that 3T MR has a role in gynecologic
brachytherapy. These novel developments improve targeted treatment to the tumor
while sparing the normal tissues.
"
233,STEVE - Space-Time-Enclosing Volume Extraction,"  The novel STEVE (i.e., Space-Time-Enclosing Volume Extraction) algorithm is
described here for the very first time. It generates iso-valued hypersurfaces
that may be implicitly contained in four-dimensional (4D) data sets, such as
temporal sequences of three-dimensional images from time-varying computed
tomography. Any final hypersurface that will be generated by STEVE is
guaranteed to be free from accidental rifts, i.e., it always fully encloses a
region in the 4D space under consideration. Furthermore, the information of the
interior/exterior of the enclosed regions is propagated to each one of the
tetrahedrons, which are embedded into 4D and which in their union represent the
final, iso-valued hypersurface(s). STEVE is usually executed in a purely
data-driven mode, and it uses lesser computational resources than other
techniques that also generate simplex-based manifolds of codimension 1.
"
234,Fourth-order flows in surface modelling,"  This short article is a brief account of the usage of fourth-order curvature
flow in surface modelling.
"
235,Using Mathematica & Matlab for CAGD/CAD research and education,"  In CAGD/CAD research and education, users are involved with development of
mathematical algorithms and followed by the analysis of the resultant
algorithm. This process involves geometric display which can only be carried
out with high end graphics display. There are many approaches practiced and one
of the so-called easiest approaches is by using C/C++ programming language and
OpenGL application program interface, API. There are practitioners uses C/C++
programming language to develop the algorithms and finally utilize AutoCAD for
graphics display. On the other hand, high end CAD users manage to use Auto Lisp
as their programming language in AutoCAD. Nevertheless, these traditional ways
are definitely time consuming. This paper introduces an alternative method
whereby the practitioners may maximize scientific computation programs, SCPs:
Mathematica and MATLAB in the context of CAGD/CAD for research and education.
"
236,On Linear Spaces of Polyhedral Meshes,"  Polyhedral meshes (PM) - meshes having planar faces - have enjoyed a rise in
popularity in recent years due to their importance in architectural and
industrial design. However, they are also notoriously difficult to generate and
manipulate. Previous methods start with a smooth surface and then apply
elaborate meshing schemes to create polyhedral meshes approximating the
surface. In this paper, we describe a reverse approach: given the topology of a
mesh, we explore the space of possible planar meshes with that topology.
  Our approach is based on a complete characterization of the maximal linear
spaces of polyhedral meshes contained in the curved manifold of polyhedral
meshes with a given topology. We show that these linear spaces can be described
as nullspaces of differential operators, much like harmonic functions are
nullspaces of the Laplacian operator. An analysis of this operator provides
tools for global and local design of a polyhedral mesh, which fully expose the
geometric possibilities and limitations of the given topology.
"
237,Software for creating pictures in the LaTeX environment,"  To create a text with graphic instructions for output pictures into LATEX
document, we offer software that allows us to build a picture in WIZIWIG mode
and for setting the text with these graphical instructions.
"
238,Glyph Sorting: Interactive Visualization for Multi-dimensional Data,"  Glyph-based visualization is an effective tool for depicting multivariate
information. Since sorting is one of the most common analytical tasks performed
on individual attributes of a multi-dimensional data set, this motivates the
hypothesis that introducing glyph sorting would significantly enhance the
usability of glyph-based visualization. In this paper, we present a glyph-based
conceptual framework as part of a visualization process for interactive sorting
of multivariate data. We examine several technical aspects of glyph sorting and
provide design principles for developing effective, visually sortable glyphs.
Glyphs that are visually sortable provide two key benefits: 1) performing
comparative analysis of multiple attributes between glyphs and 2) to support
multi-dimensional visual search. We describe a system that incorporates focus
and context glyphs to control sorting in a visually intuitive manner and for
viewing sorted results in an Interactive, Multi-dimensional Glyph (IMG) plot
that enables users to perform high-dimensional sorting, analyse and examine
data trends in detail. To demonstrate the usability of glyph sorting, we
present a case study in rugby event analysis for comparing and analysing trends
within matches. This work is undertaken in conjunction with a national rugby
team. From using glyph sorting, analysts have reported the discovery of new
insight beyond traditional match analysis.
"
239,"Speckle Reduction in Polarimetric SAR Imagery with Stochastic Distances
  and Nonlocal Means","  This paper presents a technique for reducing speckle in Polarimetric
Synthetic Aperture Radar (PolSAR) imagery using Nonlocal Means and a
statistical test based on stochastic divergences. The main objective is to
select homogeneous pixels in the filtering area through statistical tests
between distributions. This proposal uses the complex Wishart model to describe
PolSAR data, but the technique can be extended to other models. The weights of
the location-variant linear filter are function of the p-values of tests which
verify the hypothesis that two samples come from the same distribution and,
therefore, can be used to compute a local mean. The test stems from the family
of (h-phi) divergences which originated in Information Theory. This novel
technique was compared with the Boxcar, Refined Lee and IDAN filters. Image
quality assessment methods on simulated and real data are employed to validate
the performance of this approach. We show that the proposed filter also
enhances the polarimetric entropy and preserves the scattering information of
the targets.
"
240,Fast exact digital differential analyzer for circle generation,"  In the first part of the paper we present a short review of applications of
digital differential analyzers (DDA) to generation of circles showing that they
can be treated as one-step numerical schemes. In the second part we present and
discuss a novel fast algorithm based on a two-step numerical scheme (explicit
midpoint rule). Although our algorithm is as cheap as the simplest one-step DDA
algoritm (and can be represented in terms of shifts and additions), it
generates circles with maximal accuracy, i.e., it is exact up to round-off
errors.
"
241,The Logarithmic Curvature Graphs of Generalised Cornu Spirals,"  The Generalized Cornu Spiral (GCS) was first proposed by Ali et al. in 1995
[9]. Due to the monotonocity of its curvature function, the surface generated
with GCS segments has been considered as a high quality surface and it has
potential applications in surface design [2]. In this paper, the analysis of
GCS segment is carried out by determining its aesthetic value using the log
curvature Graph (LCG) as proposed by Kanaya et al.[10]. The analysis of LCG
supports the claim that GCS is indeed a generalized aesthetic curve.
"
242,G2 Transition curve using Quartic Bezier Curve,"  A method to construct transition curves using a family of the quartic Bezier
spiral is described. The transition curves discussed are S-shape and C-shape of
contact, between two separated circles. A spiral is a curve of monotone
increasing or monotone decreasing curvature of one sign. Thus, a spiral cannot
have an inflection point or curvature extreme. The family of quartic Bezier
spiral form which is introduced has more degrees of freedom and will give a
better approximation. It is proved that the methods of constructing transition
curves can be simplified by the transformation process and the ratio of two
radii has no restriction, which extends the application area, and it gives a
family of transition curves that allow more flexible curve designs.
"
243,Characterization of Planar Cubic Alternative curve,"  In this paper, we analyze the planar cubic Alternative curve to determine the
conditions for convex, loops, cusps and inflection points. Thus cubic curve is
represented by linear combination of three control points and basis function
that consist of two shape parameters. By using algebraic manipulation, we can
determine the constraint of shape parameters and sufficient conditions are
derived which ensure that the curve is a strictly convex, loops, cusps and
inflection point. We conclude the result in a shape diagram of parameters. The
simplicity of this form makes characterization more intuitive and efficient to
compute.
"
244,"Variational Formulation of the Log-Aesthetic Surface and Development of
  Discrete Surface Filters","  The log-aesthetic curves include the logarithmic (equiangular) spiral,
clothoid, and involute curves. Although most of them are expressed only by an
integral form of the tangent vector, it is possible to interactively generate
and deform them and they are expected to be utilized for practical use of
industrial and graphical design. The discrete log-aesthetic filter based on the
formulation of the log-aesthetic curve has successfully been introduced not to
impose strong constraints on the designer's activity, to let him/her design
freely and to embed the properties of the log-aesthetic curves for complicated
ones with both increasing and decreasing curvature. In this paper, in order to
define the log-aesthetic surface and develop surface filters based on its
formulation, at first we reformulate the log-aesthetic curve with variational
principle. Then we propose several new functionals to be minimized for
free-form surfaces and define the log-aesthetic surface. Furthermore we propose
new discrete surface filters based on the log-aesthetic surface formulation
"
245,Normal type-2 Fuzzy Rational B-Spline Curve,"  In this paper, we proposed a new form of type-2 fuzzy data points(T2FDPs)
that is normal type-2 data points(NT2FDPs). These brand-new forms of data were
defined by using the definition of normal type-2 triangular fuzzy
number(NT2TFN). Then, we applied fuzzification(alpha-cut) and type-reduction
processes towards NT2FDPs after they had been redefined based on the situation
of NT2FDPs. Furthermore, we redefine the defuzzification definition along with
the new definitions of fuzzification process and type-reduction method to
obtain crisp type-2 fuzzy solution data points. For all these processes from
the defining the NT2FDPs to defuzzification of NT2FDPs, we demonstrate through
curve representation by using the rational B-spline curve function as the
example form modeling these NT2FDPs.
"
246,Various Types of Aesthetic Curves,"  The research on developing planar curves to produce visually pleasing
products (ranges from electric appliances to car body design) and
indentifying/modifying planar curves for special purposes namely for railway
design, highway design and robot trajectories have been progressing since
1970s. The pattern of research in this field of study has branched to five
major groups namely curve synthesis, fairing process, improvement in control of
natural spiral, construction of new type of planar curves and, natural spiral
fitting & approximation techniques. The purpose of is this paper is to briefly
review recent progresses in Computer Aided Geometric Design (CAGD) focusing on
the topics states above.
"
247,An Improvised Algorithm to Identify The Beauty of A Planar Curve,"  An improvised algorithm is proposed based on the work of Yoshimoto and
Harada. The improvised algorithm results a graph which is called LDGC or
Logarithmic Distribution Graph of Curvature. This graph has the capability to
identify the beauty of monotonic planar curves with less effort as compared to
LDDC by Yoshimoto and Harada.
"
248,Perfectly normal type-2 fuzzy interpolation B-spline curve,"  In this paper, we proposed another new form of type-2 fuzzy data
points(T2FDPs) that is perfectly normal type-2 data points(PNT2FDPs). These
kinds of brand-new data were defined by using the existing type-2 fuzzy set
theory(T2FST) and type-2 fuzzy number(T2FN) concept since we dealt with the
problem of defining complex uncertainty data. Along with this restructuring, we
included the fuzzification(alpha-cut operation), type-reduction and
defuzzification processes against PNT2FDPs. In addition, we used interpolation
B-soline curve function to demonstrate the PNT2FDPs.
"
249,Parallel Chen-Han (PCH) Algorithm for Discrete Geodesics,"  In many graphics applications, the computation of exact geodesic distance is
very important. However, the high computational cost of the existing geodesic
algorithms means that they are not practical for large-scale models or
time-critical applications. To tackle this challenge, we propose the parallel
Chen-Han (or PCH) algorithm, which extends the classic Chen-Han (CH) discrete
geodesic algorithm to the parallel setting. The original CH algorithm and its
variant both lack a parallel solution because the windows (a key data structure
that carries the shortest distance in the wavefront propagation) are maintained
in a strict order or a tightly coupled manner, which means that only one window
is processed at a time. We propose dividing the CH's sequential algorithm into
four phases, window selection, window propagation, data organization, and
events processing so that there is no data dependence or conflicts in each
phase and the operations within each phase can be carried out in parallel. The
proposed PCH algorithm is able to propagate a large number of windows
simultaneously and independently. We also adopt a simple yet effective strategy
to control the total number of windows. We implement the PCH algorithm on
modern GPUs (such as Nvidia GTX 580) and analyze the performance in detail. The
performance improvement (compared to the sequential algorithms) is highly
consistent with GPU double-precision performance (GFLOPS). Extensive
experiments on real-world models demonstrate an order of magnitude improvement
in execution time compared to the state-of-the-art.
"
250,"On the variety of planar spirals and their applications in computer
  aided design","  In this paper we discuss the variety of planar spiral segments and their
applications in objects in both the real and artificial world. The discussed
curves with monotonic curvature function are well-known in geometric modelling
and computer aided geometric design as fair curves, and they are very
significant in aesthetic shape modelling. Fair curve segments are used for
two-point G1 and G2 Hermite interpolation, as well as for generating aesthetic
splines.
"
251,MC-curves and aesthetic measurements for pseudospiral curve segments,"  This article studies families of curves with monotonic curvature function
(MC-curves) and their applications in geometric modelling and aesthetic design.
Aesthetic analysis and assessment of the structure and plastic qualities of
pseudospirals, which are curves with monotonic curvature function, are
conducted for the first time in the field of geometric modelling from the
position of technical aesthetics laws. The example of car body surface
modelling with the use of aesthetics splines is given.
"
252,"The effects of computer assisted and distance learning of geometric
  modelling","  The effects of computer-assisted and distance learning of geometric modeling
and computer aided geometric design are studied. It was shown that computer
algebra systems and dynamic geometric environments can be considered as
excellent tools for teaching mathematical concepts of mentioned areas, and
distance education technologies would be indispensable for consolidation of
successfully passed topics.
"
253,Geometric Registration of High-genus Surfaces,"  This paper presents a method to obtain geometric registrations between
high-genus ($g\geq 1$) surfaces. Surface registration between simple surfaces,
such as simply-connected open surfaces, has been well studied. However, very
few works have been carried out for the registration of high-genus surfaces.
The high-genus topology of the surface poses great challenge for surface
registration. A possible approach is to partition surfaces into
simply-connected patches and registration is done patch by patch. Consistent
cuts are required, which are usually difficult to obtain and prone to error. In
this work, we propose an effective way to obtain geometric registration between
high-genus surfaces without introducing consistent cuts. The key idea is to
conformally parameterize the surface into its universal covering space, which
is either the Euclidean plane or the hyperbolic disk embedded in
$\mathbb{R}^2$. Registration can then be done on the universal covering space
by minimizing a shape mismatching energy measuring the geometric dissimilarity
between the two surfaces. Our proposed algorithm effectively computes a smooth
registration between high-genus surfaces that matches geometric information as
much as possible. The algorithm can also be applied to find a smooth and
bijective registration minimizing any general energy functionals. Numerical
experiments on high-genus surface data show that our proposed method is
effective for registering high-genus surfaces with geometric matching. We also
applied the method to register anatomical structures for medical imaging, which
demonstrates the usefulness of the proposed algorithm.
"
254,Sparse Norm Filtering,"  Optimization-based filtering smoothes an image by minimizing a fidelity
function and simultaneously preserves edges by exploiting a sparse norm penalty
over gradients. It has obtained promising performance in practical problems,
such as detail manipulation, HDR compression and deblurring, and thus has
received increasing attentions in fields of graphics, computer vision and image
processing. This paper derives a new type of image filter called sparse norm
filter (SNF) from optimization-based filtering. SNF has a very simple form,
introduces a general class of filtering techniques, and explains several
classic filters as special implementations of SNF, e.g. the averaging filter
and the median filter. It has advantages of being halo free, easy to implement,
and low time and memory costs (comparable to those of the bilateral filter).
Thus, it is more generic than a smoothing operator and can better adapt to
different tasks. We validate the proposed SNF by a wide variety of applications
including edge-preserving smoothing, outlier tolerant filtering, detail
manipulation, HDR compression, non-blind deconvolution, image segmentation, and
colorization.
"
255,Parallel Coordinates Guided High Dimensional Transfer Function Design,"  High-dimensional transfer function design is widely used to provide
appropriate data classification for direct volume rendering of various
datasets. However, its design is a complicated task. Parallel coordinate plot
(PCP), as a powerful visualization tool, can efficiently display
high-dimensional geometry and accurately analyze multivariate data. In this
paper, we propose to combine parallel coordinates with dimensional reduction
methods to guide high-dimensional transfer function design. Our pipeline has
two major advantages: (1) combine and display extracted high-dimensional
features in parameter space; and (2) select appropriate high-dimensional
parameters, with the help of dimensional reduction methods, to obtain
sophisticated data classification as transfer function for volume rendering. In
order to efficiently design high-dimensional transfer functions, the
combination of both parallel coordinate components and dimension reduction
results is necessary to generate final visualization results. We demonstrate
the capability of our method for direct volume rendering using various CT and
MRI datasets.
"
256,New Views of Crystal Symmetry,"  Already Hermann Grassmann's father Justus (1829, 1830) published two works on
the geometrical description of crystals, influenced by the earlier works of
C.S. Weiss (1780-1856) on three main crystal forces governing crystal
formation. In his 1840 essay on the derivation of crystal shapes from the
general law of crystal formation Hermann established the notion of a
three-dimensional vectorial system of forces with rational coefficients, that
represent the interior crystal structure, regulate its formation, its shape and
physical behavior. In the Ausdehnungslehre 1844 (Paragraph 171) he finally
writes: I shall conclude this presentation by one of the most beautiful
applications which can be made of the science treated, i.e. the application to
crystal figures (Scholz, 1996). The geometry of crystals thus certainly
influenced the Ausdehnungslehre. In this paper we see how Grassmann's work
influenced Clifford's creation of geometric algebras, which in turn leads to a
new geometric description of crystal symmetry suitable for modern computer
algebra graphics.
"
257,Pattern Recognition and Revealing using Parallel Coordinates Plot,"  Parallel coordinates plot (PCP) is an excellent tool for multivariate
visualization and analysis, but it may fail to reveal inherent structures for
datasets with a large number of items. In this paper, we propose a suite of
novel clustering, dimension ordering and visualization techniques based on PCP,
to reveal and highlight hidden structures. First, we propose a continuous
spline based polycurves design to extract and classify different cluster
aspects of the data. Then, we provide an efficient and optimal correlation
based sorting technique to reorder coordinates, as a helpful visualization tool
for data analysis. Various results generated by our framework visually
represent much structure, trend and correlation information to guide the user,
and improve the efficacy of analysis, especially for complex and noisy
datasets.
"
258,3D model retrieval using global and local radial distances,"  3D model retrieval techniques can be classified as histogram-based,
view-based and graph-based approaches. We propose a hybrid shape descriptor
which combines the global and local radial distance features by utilizing the
histogram-based and view-based approaches respectively. We define an
area-weighted global radial distance with respect to the center of the bounding
sphere of the model and encode its distribution into a 2D histogram as the
global radial distance shape descriptor. We then uniformly divide the bounding
cube of a 3D model into a set of small cubes and define their centers as local
centers. Then, we compute the local radial distance of a point based on the
nearest local center. By sparsely sampling a set of views and encoding the
local radial distance feature on the rendered views by color coding, we extract
the local radial distance shape descriptor. Based on these two shape
descriptors, we develop a hybrid radial distance shape descriptor for 3D model
retrieval. Experiment results show that our hybrid shape descriptor outperforms
several typical histogram-based and view-based approaches.
"
259,"New views of crystal symmetry guided by profound admiration of the
  extraordinary works of Grassmann and Clifford","  This paper shows how beginning with Justus Grassmann's work, Hermann
Grassmann was influenced in his mathematical thinking by crystallography. H.
Grassmann's Ausdehnungslehre in turn had a decisive influence on W.K. Clifford
in the genesis of geometric algebras. Geometric algebras have been expanded to
conformal geometric algebras, which provide an ideal framework for modern
computer graphics. Within this framework a new visualization of
three-dimensional crystallographic space groups has been created. The complex
beauty of this new visualization is shown by a range of images of a diamond
cell. Mathematical details are given in an appendix.
"
260,"The Orthogonal 2D Planes Split of Quaternions and Steerable Quaternion
  Fourier Transformations","  The two-sided quaternionic Fourier transformation (QFT) was introduced in
\cite{Ell:1993} for the analysis of 2D linear time-invariant
partial-differential systems. In further theoretical investigations
\cite{10.1007/s00006-007-0037-8, EH:DirUP_QFT} a special split of quaternions
was introduced, then called $\pm$split. In the current \change{chapter} we
analyze this split further, interpret it geometrically as \change{an}
\emph{orthogonal 2D planes split} (OPS), and generalize it to a freely
steerable split of $\H$ into two orthogonal 2D analysis planes. The new general
form of the OPS split allows us to find new geometric interpretations for the
action of the QFT on the signal. The second major result of this work is a
variety of \emph{new steerable forms} of the QFT, their geometric
interpretation, and for each form\change{,} OPS split theorems, which allow
fast and efficient numerical implementation with standard FFT software.
"
261,Multimaterial Front Tracking,"  We present the first triangle mesh-based technique for tracking the evolution
of general three-dimensional multimaterial interfaces undergoing complex
topology changes induced by deformations and collisions. Our core
representation is a non-manifold triangle surface mesh with material labels
assigned to each half-face to distinguish volumetric regions. We advect the
vertices of the mesh in a Lagrangian manner, and employ a complete set of
collision-safe mesh improvement and topological operations that track and
update material labels. In particular, we develop a unified, collision-safe
strategy for handling complex topological operations acting on evolving triple-
and higher-valence junctions, and a flexible method to merge colliding
multimaterial meshes. We demonstrate our approach with a number of challenging
geometric flows, including passive advection, normal flow, and mean curvature
flow.
"
262,Visualizing Astronomical Data with Blender,"  Astronomical data take on a multitude of forms -- catalogs, data cubes,
images, and simulations. The availability of software for rendering
high-quality three-dimensional graphics lends itself to the paradigm of
exploring the incredible parameter space afforded by the astronomical sciences.
The software program Blender gives astronomers a useful tool for displaying
data in a manner used by three-dimensional (3D) graphics specialists and
animators. The interface to this popular software package is introduced with
attention to features of interest in astronomy. An overview of the steps for
generating models, textures, animations, camera work, and renders is outlined.
An introduction is presented on the methodology for producing animations and
graphics with a variety of astronomical data. Examples from sub-fields of
astronomy with different kinds of data are shown with resources provided to
members of the astronomical community. An example video showcasing the outlined
principles and features is provided along with scripts and files for sample
visualizations.
"
263,Finite Element Based Tracking of Deforming Surfaces,"  We present an approach to robustly track the geometry of an object that
deforms over time from a set of input point clouds captured from a single
viewpoint. The deformations we consider are caused by applying forces to known
locations on the object's surface. Our method combines the use of prior
information on the geometry of the object modeled by a smooth template and the
use of a linear finite element method to predict the deformation. This allows
the accurate reconstruction of both the observed and the unobserved sides of
the object. We present tracking results for noisy low-quality point clouds
acquired by either a stereo camera or a depth camera, and simulations with
point clouds corrupted by different error terms. We show that our method is
also applicable to large non-linear deformations.
"
264,"Computing a Compact Spline Representation of the Medial Axis Transform
  of a 2D Shape","  We present a full pipeline for computing the medial axis transform of an
arbitrary 2D shape. The instability of the medial axis transform is overcome by
a pruning algorithm guided by a user-defined Hausdorff distance threshold. The
stable medial axis transform is then approximated by spline curves in 3D to
produce a smooth and compact representation. These spline curves are computed
by minimizing the approximation error between the input shape and the shape
represented by the medial axis transform. Our results on various 2D shapes
suggest that our method is practical and effective, and yields faithful and
compact representations of medial axis transforms of 2D shapes.
"
265,4-Dimensional Geometry Lens: A Novel Volumetric Magnification Approach,"  We present a novel methodology that utilizes 4-Dimensional (4D) space
deformation to simulate a magnification lens on versatile volume datasets and
textured solid models. Compared with other magnification methods (e.g.,
geometric optics, mesh editing), 4D differential geometry theory and its
practices are much more flexible and powerful for preserving shape features
(i.e., minimizing angle distortion), and easier to adapt to versatile solid
models. The primary advantage of 4D space lies at the following fact: we can
now easily magnify the volume of regions of interest (ROIs) from the additional
dimension, while keeping the rest region unchanged. To achieve this primary
goal, we first embed a 3D volumetric input into 4D space and magnify ROIs in
the 4th dimension. Then we flatten the 4D shape back into 3D space to
accommodate other typical applications in the real 3D world. In order to
enforce distortion minimization, in both steps we devise the high dimensional
geometry techniques based on rigorous 4D geometry theory for 3D/4D mapping back
and forth to amend the distortion. Our system can preserve not only focus
region, but also context region and global shape. We demonstrate the
effectiveness, robustness, and efficacy of our framework with a variety of
models ranging from tetrahedral meshes to volume datasets.
"
266,Free Instrument for Movement Measure,"  This paper presents the validation of a computational tool that serves to
obtain continuous measurements of moving objects. The software uses techniques
of computer vision, pattern recognition and optical flow, to enable tracking of
objects in videos, generating data trajectory, velocity, acceleration and
angular movement. The program was applied to track a ball around a simple
pendulum. The methodology used to validate it, taking as a basis to compare the
values measured by the program, as well as the theoretical values expected
according to the model of a simple pendulum. The experiment is appropriate to
the method because it was built within the limits of the linear harmonic
oscillator and energy losses due to friction had been minimized, making it the
most ideal possible. The results indicate that the tool is sensitive and
accurate. Deviations of less than a millimeter to the extent of the trajectory,
ensures the applicability of the software on physics, whether in research or in
teaching topics.
"
267,Progressive Blue Surfels,"  In this paper we describe a new technique to generate and use surfels for
rendering of highly complex, polygonal 3D scenes in real time. The basic idea
is to approximate complex parts of the scene by rendering a set of points
(surfels). The points are computed in a preprocessing step and offer two
important properties: They are placed only on the visible surface of the
scene's geometry and they are distributed and sorted in such a way, that every
prefix of points is a good visual representation of the approximated part of
the scene. An early evaluation of the method shows that it is capable of
rendering scenes consisting of several billions of triangles with high image
quality.
"
268,"Anatomical Feature-guided Volumeric Registration of Multimodal Prostate
  MRI","  Radiological imaging of prostate is becoming more popular among researchers
and clinicians in searching for diseases, primarily cancer. Scans might be
acquired at different times, with patient movement between scans, or with
different equipment, resulting in multiple datasets that need to be registered.
For this issue, we introduce a registration method using anatomical
feature-guided mutual information. Prostate scans of the same patient taken in
three different orientations are first aligned for the accurate detection of
anatomical features in 3D. Then, our pipeline allows for multiple modalities
registration through the use of anatomical features, such as the interior
urethra of prostate and gland utricle, in a bijective way. The novelty of this
approach is the application of anatomical features as the pre-specified
corresponding landmarks for prostate registration. We evaluate the registration
results through both artificial and clinical datasets. Registration accuracy is
evaluated by performing statistical analysis of local intensity differences or
spatial differences of anatomical landmarks between various MR datasets.
Evaluation results demonstrate that our method statistics-significantly
improves the quality of registration. Although this strategy is tested for
MRI-guided brachytherapy, the preliminary results from these experiments
suggest that it can be also applied to other settings such as transrectal
ultrasound-guided or CT-guided therapy, where the integration of preoperative
MRI may have a significant impact upon treatment planning and guidance.
"
269,"Detection of Outer Rotations on 3D-Vector Fields with Iterative
  Geometric Correlation and its Efficiency","  Correlation is a common technique for the detection of shifts. Its
generalization to the multidimensional geometric correlation in Clifford
algebras has been proven a useful tool for color image processing, because it
additionally contains information about a rotational misalignment. But so far
the exact correction of a three-dimensional outer rotation could only be
achieved in certain special cases. In this paper we prove that applying the
geometric correlation iteratively has the potential to detect the outer
rotational misalignment for arbitrary three-dimensional vector fields. We
further present the explicit iterative algorithm, analyze its efficiency
detecting the rotational misalignment in the color space of a color image. The
experiments suggest a method for the acceleration of the algorithm, which is
practically tested with great success.
"
270,"Image color transfer to evoke different emotions based on color
  combinations","  In this paper, a color transfer framework to evoke different emotions for
images based on color combinations is proposed. The purpose of this color
transfer is to change the ""look and feel"" of images, i.e., evoking different
emotions. Colors are confirmed as the most attractive factor in images. In
addition, various studies in both art and science areas have concluded that
other than single color, color combinations are necessary to evoke specific
emotions. Therefore, we propose a novel framework to transfer color of images
based on color combinations, using a predefined color emotion model. The
contribution of this new framework is three-fold. First, users do not need to
provide reference images as used in traditional color transfer algorithms. In
most situations, users may not have enough aesthetic knowledge or path to
choose desired reference images. Second, because of the usage of color
combinations instead of single color for emotions, a new color transfer
algorithm that does not require an image library is proposed. Third, again
because of the usage of color combinations, artifacts that are normally seen in
traditional frameworks using single color are avoided. We present encouraging
results generated from this new framework and its potential in several possible
applications including color transfer of photos and paintings.
"
271,"Review of simulating four classes of window materials for daylighting
  with non-standard BSDF using the simulation program Radiance","  This review describes the currently available simulation models for window
material to calculate daylighting with the program ""Radiance"". The review is
based on four abstract and general classes of window materials, depending on
their scattering and redirecting properties (bidirectional scatter distribution
function, BSDF). It lists potential and limits of the older models and includes
the most recent additions to the software. All models are demonstrated using an
exemplary indoor scene and two typical sky conditions. It is intended as
clarification for applying window material models in project work or teaching.
The underlying algorithmic problems apply to all lighting simulation programs,
so the scenarios of materials and skies are applicable to other lighting
programs.
"
272,Electronic Visualisation in Chemistry: From Alchemy to Art,"  Chemists now routinely use software as part of their work. For example,
virtual chemistry allows chemical reactions to be simulated. In particular, a
selection of software is available for the visualisation of complex
3-dimensional molecular structures. Many of these are very beautiful in their
own right. As well as being included as illustrations in academic papers, such
visualisations are often used on the covers of chemistry journals as
artistically decorative and attractive motifs. Chemical images have also been
used as the basis of artworks in exhibitions. This paper explores the
development of the relationship of chemistry, art, and IT. It covers some of
the increasingly sophisticated software used to generate these projections
(e.g., UCSF Chimera) and their progressive use as a visual art form.
"
273,Making Laplacians commute,"  In this paper, we construct multimodal spectral geometry by finding a pair of
closest commuting operators (CCO) to a given pair of Laplacians. The CCOs are
jointly diagonalizable and hence have the same eigenbasis. Our construction
naturally extends classical data analysis tools based on spectral geometry,
such as diffusion maps and spectral clustering. We provide several synthetic
and real examples of applications in dimensionality reduction, shape analysis,
and clustering, demonstrating that our method better captures the inherent
structure of multi-modal data.
"
274,A New 3D Geometric Approach to Focus and Context Lens Effect Simulation,"  We present a novel methodology based on geometric approach to simulate
magnification lens effects. Our aim is to promote new applications of powerful
geometric modeling techniques in visual computing. Conventional image
processing/visualization methods are computed in two dimensional space (2D). We
examine this conventional 2D manipulation from a completely innovative
perspective of 3D geometric processing. Compared with conventional optical lens
design, 3D geometric method are much more capable of preserving shape features
and minimizing distortion. We magnify an area of interest to better visualize
the interior details, while keeping the rest of area without perceivable
distortion. We flatten the mesh back into 2D space for viewing, and further
applications in the screen space. In both steps, we devise an iterative
deformation scheme to minimize distortion around both focus and context region,
while avoiding the noncontinuous transition region between the focus and
context areas. Particularly, our method allows the user to flexibly modify the
ROI shapes to accommodate complex feature. The user can also easily specify a
spectrum of metrics for different visual effects. Various experimental results
demonstrate the effectiveness, robustness, and efficiency of our framework.
"
275,"Calculation reduction method for color computer-generated hologram using
  color space conversion","  We report a calculation reduction method for color computer-generated
holograms (CGHs) using color space conversion. Color CGHs are generally
calculated on RGB space. In this paper, we calculate color CGHs in other color
spaces: for example, YCbCr color space. In YCbCr color space, a RGB image is
converted to the luminance component (Y), blue-difference chroma (Cb) and
red-difference chroma (Cr) components. In terms of the human eye, although the
negligible difference of the luminance component is well-recognized, the
difference of the other components is not. In this method, the luminance
component is normal sampled and the chroma components are down-sampled. The
down-sampling allows us to accelerate the calculation of the color CGHs. We
compute diffraction calculations from the components, and then we convert the
diffracted results in YCbCr color space to RGB color space.
"
276,Inverse Procedural Modeling of Facade Layouts,"  In this paper, we address the following research problem: How can we generate
a meaningful split grammar that explains a given facade layout? To evaluate if
a grammar is meaningful, we propose a cost function based on the description
length and minimize this cost using an approximate dynamic programming
framework. Our evaluation indicates that our framework extracts meaningful
split grammars that are competitive with those of expert users, while some
users and all competing automatic solutions are less successful.
"
277,"A Survey of Spline-based Volumetric Data Modeling Framework and Its
  Applications","  The rapid advances in 3D scanning and acquisition techniques have given rise
to the explosive increase of volumetric digital models in recent years. This
dissertation systematically trailblazes a novel volumetric modeling framework
to represent 3D solids. The need to explore more efficient and robust 3D
modeling framework has gained the prominence. Although the traditional surface
representation (e.g., triangle mesh) has many attractive properties, it is
incapable of expressing the interior space and materials. Such a serious
drawback overshadows many potential modeling and analysis applications.
Consequently volumetric modeling techniques become the well-known solution to
this problem. Nevertheless, many unsolved research issues remain when
developing an efficient modeling paradigm for existing 3D models: complex
geometry (fine details and extreme concaveness), arbitrary topology,
heterogenous materials, large-scale data storage and processing, etc.
"
278,A Spline-based Volumetric Data Modeling Framework and Its Applications,"  In this dissertation, we concentrate on the challenging research issue of
developing a spline-based modeling framework, which converts the conventional
data (e.g., surface meshes) to tensor-product trivariate splines. This
methodology can represent both boundary/volumetric geometry and real volumetric
physical attributes in a compact and continuous fashion. The regular
tensor-product structure enables our new developed methods to be embedded into
the industry standard seamlessly. These properties make our techniques highly
preferable in many physically-based applications including mechanical analysis,
shape deformation and editing, virtual surgery training, etc.
"
279,Barycentric Coordinates as Interpolants,"  Barycentric coordinates are frequently used as interpolants to shade computer
graphics images. A simple equation transforms barycentric coordinates from
screen space into eye space in order to undo the perspective transformation and
permit accurate interpolative shading of texture maps. This technique is
amenable to computation using a block-normalized integer representation.
"
280,Medial Meshes for Volume Approximation,"  Volume approximation is an important problem found in many applications of
computer graphics, vision, and image processing. The problem is about computing
an accurate and compact approximate representation of 3D volumes using some
simple primitives. In this study, we propose a new volume representation,
called medial meshes, and present an efficient method for its computation.
Specifically, we use the union of a novel type of simple volume primitives,
which are spheres and the convex hulls of two or three spheres, to approximate
a given 3D shape. We compute such a volume approximation based on a new method
for medial axis simplification guided by Hausdorff errors. We further
demonstrate the superior efficiency and accuracy of our method over existing
methods for medial axis simplification.
"
281,"SAR Image Despeckling Algorithms using Stochastic Distances and Nonlocal
  Means","  This paper presents two approaches for filter design based on stochastic
distances for intensity speckle reduction. A window is defined around each
pixel, overlapping samples are compared and only those which pass a
goodness-of-fit test are used to compute the filtered value. The tests stem
from stochastic divergences within the Information Theory framework. The
technique is applied to intensity Synthetic Aperture Radar (SAR) data with
homogeneous regions using the Gamma model. The first approach uses a
Nagao-Matsuyama-type procedure for setting the overlapping samples, and the
second uses the nonlocal method. The proposals are compared with the Improved
Sigma filter and with anisotropic diffusion for speckled data (SRAD) using a
protocol based on Monte Carlo simulation. Among the criteria used to quantify
the quality of filters, we employ the equivalent number of looks, and line and
edge preservation. Moreover, we also assessed the filters by the Universal
Image Quality Index and by the Pearson correlation between edges. Applications
to real images are also discussed. The proposed methods show good results.
"
282,A Unified Framework for Multi-Sensor HDR Video Reconstruction,"  One of the most successful approaches to modern high quality HDR-video
capture is to use camera setups with multiple sensors imaging the scene through
a common optical system. However, such systems pose several challenges for HDR
reconstruction algorithms. Previous reconstruction techniques have considered
debayering, denoising, resampling (align- ment) and exposure fusion as separate
problems. In contrast, in this paper we present a unifying approach, performing
HDR assembly directly from raw sensor data. Our framework includes a camera
noise model adapted to HDR video and an algorithm for spatially adaptive HDR
reconstruction based on fitting of local polynomial approximations to observed
sensor data. The method is easy to implement and allows reconstruction to an
arbitrary resolution and output mapping. We present an implementation in CUDA
and show real-time performance for an experimental 4 Mpixel multi-sensor HDR
video system. We further show that our algorithm has clear advantages over
existing methods, both in terms of flexibility and reconstruction quality.
"
283,"Affordable Virtual Reality System Architecture for Representation of
  Implicit Object Properties","  A flexible, scalable and affordable virtual reality software system
architecture is proposed. This solution can be easily implemented on different
hardware configurations: on a single computer or on a computer cluster. The
architecture is aimed to be integrated in the workflow for solving engineering
tasks and oriented towards presenting implicit object properties through
multiple sensorial channels (visual, audio and haptic). Implicit properties
represent hidden object features (i.e. magnetization, radiation, humidity,
toxicity, etc.) which cannot be perceived by the observer through his or her
senses but require specialized equipment in order to expand the sensory ability
of the observer. Our approach extends the underlying general scene graph
structure incorporating additional effects nodes for implicit properties
representation.
"
284,"Post-processing of Engineering Analysis Results for Visualization in VR
  Systems","  The applicability of Virtual Reality for evaluating engineering analysis
results is beginning to receive increased appreciation in the last years. The
problem many engineers are still facing is how to import their model together
with the analysis results in a virtual reality environment for exploration and
results validation. In this paper we propose an algorithm for transforming
model data and results from finite element analysis (FEA) solving application
to a format easily interpretable by a virtual reality application. The
algorithm includes also steps for reducing the face-count of the resulting mesh
by eliminating faces from the inner part of the model in the cases when only
the surfaces of the model is analyzed. We also describe a possibility for
simultaneously assessing multiple analysis results relying on multimodal
results presentation by stimulating different senses of the operator.
"
285,A New Algorithm of Speckle Filtering using Stochastic Distances,"  This paper presents a new approach for filter design based on stochastic
distances and tests between distributions. A window is defined around each
pixel, overlapping samples are compared and only those which pass a
goodness-of-fit test are used to compute the filtered value. The technique is
applied to intensity SAR data with homogeneous regions using the Gamma model.
The proposal is compared with the Lee's filter using a protocol based on Monte
Carlo. Among the criteria used to quantify the quality of filters, we employ
the equivalent number of looks, line and edge preservation. Moreover, we also
assessed the filters by the Universal Image Quality Index and the Pearson's
correlation on edges regions.
"
286,"A Low-Dimensional Representation for Robust Partial Isometric
  Correspondences Computation","  Intrinsic isometric shape matching has become the standard approach for pose
invariant correspondence estimation among deformable shapes. Most existing
approaches assume global consistency, i.e., the metric structure of the whole
manifold must not change significantly. While global isometric matching is well
understood, only a few heuristic solutions are known for partial matching.
Partial matching is particularly important for robustness to topological noise
(incomplete data and contacts), which is a common problem in real-world 3D
scanner data. In this paper, we introduce a new approach to partial, intrinsic
isometric matching. Our method is based on the observation that isometries are
fully determined by purely local information: a map of a single point and its
tangent space fixes an isometry for both global and the partial maps. From this
idea, we develop a new representation for partial isometric maps based on
equivalence classes of correspondences between pairs of points and their
tangent spaces. From this, we derive a local propagation algorithm that find
such mappings efficiently. In contrast to previous heuristics based on RANSAC
or expectation maximization, our method is based on a simple and sound
theoretical model and fully deterministic. We apply our approach to register
partial point clouds and compare it to the state-of-the-art methods, where we
obtain significant improvements over global methods for real-world data and
stronger guarantees than previous heuristic partial matching algorithms.
"
287,Reconstruction and uniqueness of moving obstacles,"  We study the uniqueness and accuracy of the numerical solution of the problem
of reconstruction of the shape and trajectory of a reflecting obstacle moving
in an inhomogeneous medium from travel times, start and end points, and initial
angles of ultrasonic rays reflecting at the obstacle. The speed of sound in the
domain when there is no obstacle present is known and provided as an input
parameter which together with the other initial data enables the algorithm to
trace ray paths and find their reflection points. The reflection points
determine with high-resolution the shape and trajectory of the obstacle. The
method has predictable computational complexity and performance and is very
efficient when it is parallelized and optimized because only a small portion of
the domain is reconstructed.
"
288,Zahir: a Object-Oriented Framework for Computer Graphics,"  In this article we present Zahir, a framework for experimentation in Computer
Graphics that provides a group of object-oriented base components that take
care of common tasks in rendering techniques and algorithms, specially those of
Non Photo-realistic Rendering (NPR). These components allow developers to
implement rendering techniques and algorithms over static and animated meshes.
Currently, Zahir is being used in a Master's Thesis and as support material in
the undergraduate Computer Graphics course in University of Chile.
"
289,On the Relationship Between Dual Photography and Classical Ghost Imaging,"  Classical ghost imaging has received considerable attention in recent years
because of its remarkable ability to image a scene without direct observation
by a light-detecting imaging device. In this article, we show that this imaging
process is actually a realization of a paradigm known as dual photography,
which has been shown to produce full-color dual (ghost) images of 3D objects
with complex materials without using a traditional imaging device.
Specifically, we demonstrate mathematically that the cross-correlation based
methods used to recover ghost images are equivalent to the light transport
measurement process of dual photography. Because of this, we are able to
provide a new explanation for ghost imaging using only classical optics by
leveraging the principle of reciprocity in classical electromagnetics. This
observation also shows how to leverage previous work on light transport
acquisition and dual photography to improve ghost imaging systems in the
future.
"
290,Progressive Compression of 3D Objects with an Adaptive Quantization,"  This paper presents a new progressive compression method for triangular
meshes. This method, in fact, is based on a schema of irregular
multi-resolution analysis and is centered on the optimization of the
rate-distortion trade-off. The quantization precision is adapted to each vertex
during the encoding / decoding process to optimize the rate-distortion
compromise. The Optimization of the treated mesh geometry improves the
approximation quality and the compression ratio at each level of resolution.
The experimental results show that the proposed algorithm gives competitive
results compared to the previous works dealing with the rate-distortion
compromise.
"
291,Mobile augmented reality survey: a bottom-up approach,"  Augmented Reality (AR) is becoming mobile. Mobile devices have many
constraints but also rich new features that traditional desktop computers do
not have. There are several survey papers on AR, but none is dedicated to
Mobile Augmented Reality (MAR). Our work serves the purpose of closing this
gap. The contents are organized with a bottom-up approach. We first present the
state-of-the-art in system components including hardware platforms, software
frameworks and display devices, follows with enabling technologies such as
tracking and data management. We then survey the latest technologies and
methods to improve run-time performance and energy efficiency for practical
implementation. On top of these, we further introduce the application fields
and several typical MAR applications. Finally we conclude the survey with
several challenge problems, which are under exploration and require great
research efforts in the future.
"
292,A constructive approach to triangular trigonometric patches,"  We construct a constrained trivariate extension of the univariate normalized
B-basis of the vector space of trigonometric polynomials of arbitrary (finite)
order n defined on any compact interval [0,\alpha], where \alpha is a fixed
(shape) parameter in (0,\pi). Our triangular extension is a normalized linearly
independent constrained trivariate trigonometric function system of dimension
3n(n+1)+1 that spans the same vector space of functions as the constrained
trivariate extension of the canonical basis of truncated Fourier series of
order n over [0,\alpha]. Although the explicit general basis transformation is
yet unknown, the coincidence of these vector spaces is proved by means of an
appropriate equivalence relation. As a possible application of our triangular
extension, we introduce the notion of (rational) triangular trigonometric
patches of order n and of singularity free parametrization that could be used
as control point based modeling tools in CAGD.
"
293,Detection and Characterization of Intrinsic Symmetry,"  A comprehensive framework for detection and characterization of overlapping
intrinsic symmetry over 3D shapes is proposed. To identify prominent symmetric
regions which overlap in space and vary in form, the proposed framework is
decoupled into a Correspondence Space Voting procedure followed by a
Transformation Space Mapping procedure. In the correspondence space voting
procedure, significant symmetries are first detected by identifying surface
point pairs on the input shape that exhibit local similarity in terms of their
intrinsic geometry while simultaneously maintaining an intrinsic distance
structure at a global level. Since different point pairs can share a common
point, the detected symmetric shape regions can potentially overlap. To this
end, a global intrinsic distance-based voting technique is employed to ensure
the inclusion of only those point pairs that exhibit significant symmetry. In
the transformation space mapping procedure, the Functional Map framework is
employed to generate the final map of symmetries between point pairs. The
transformation space mapping procedure ensures the retrieval of the underlying
dense correspondence map throughout the 3D shape that follows a particular
symmetry. Additionally, the formulation of a novel cost matrix enables the
inner product to succesfully indicate the complexity of the underlying symmetry
transformation. The proposed transformation space mapping procedure is shown to
result in the formulation of a semi-metric symmetry space where each point in
the space represents a specific symmetry transformation and the distance
between points represents the complexity between the corresponding
transformations. Experimental results show that the proposed framework can
successfully process complex 3D shapes that possess rich symmetries.
"
294,Gradient-Domain Processing for Large EM Image Stacks,"  We propose a new gradient-domain technique for processing registered EM image
stacks to remove the inter-image discontinuities while preserving intra-image
detail. To this end, we process the image stack by first performing anisotropic
diffusion to smooth the data along the slice axis and then solving a
screened-Poisson equation within each slice to re-introduce the detail. The
final image stack is both continuous across the slice axis (facilitating the
tracking of information between slices) and maintains sharp details within each
slice (supporting automatic feature detection). To support this editing, we
describe the implementation of the first multigrid solver designed for
efficient gradient domain processing of large, out-of-core, voxel grids.
"
295,Compression of animated 3D models using HO-SVD,"  This work presents an analysis of Higher Order Singular Value Decomposition
(HO-SVD) applied to lossy compression of 3D mesh animations. We describe
strategies for choosing a number of preserved spatial and temporal components
after tensor decomposition. Compression error is measured using three metrics
(MSE, Hausdorff, MSDM). Results are compared with a method based on Principal
Component Analysis (PCA) and presented on a set of animations with typical mesh
deformations.
"
296,"Landmark and Intensity Based Registration with Large Deformations via
  Quasi-conformal Maps","  Registration, which aims to find an optimal one-to-one correspondence between
different data, is an important problem in various fields. This problem is
especially challenging when large deformations occur. In this paper, we present
a novel algorithm to obtain diffeomorphic image or surface registrations with
large deformations via quasi-conformal maps. The basic idea is to minimize an
energy functional involving a Beltrami coefficient term, which measures the
distortion of the quasi-conformal map. The Beltrami coefficient effectively
controls the bijectivity and smoothness of the registration, even with very
large deformations. Using the proposed algorithm, landmark-based registration
between images or surfaces can be effectively computed. The obtained
registration is guaranteed to be diffeomorphic (1-1 and onto), even with a
large deformation or large number of landmark constraints. The proposed
algorithm can also be combined with matching intensity (such as image intensity
or surface curvature) to improve the accuracy of the registration. Experiments
have been carried out on both synthetic and real data. Results demonstrate the
efficacy of the proposed algorithm to obtain diffeomorphic registration between
images or surfaces.
"
297,Composing DTI Visualizations with End-user Programming,"  We present the design and prototype implementation of a scientific
visualization language called Zifazah for composing 3D visualizations of
diffusion tensor magnetic resonance imaging (DT-MRI or DTI) data. Unlike
existing tools allowing flexible customization of data visualizations that are
programmer-oriented, we focus on domain scientists as end users in order to
enable them to freely compose visualizations of their scientific data set. We
analyzed end-user descriptions extracted from interviews with neurologists and
physicians conducting clinical practices using DTI about how they would build
and use DTI visualizations to collect syntax and semantics for the language
design, and have discovered the elements and structure of the proposed
language. Zifazah makes use of the initial set of lexical terms and semantics
to provide a declarative language in the spirit of intuitive syntax and usage.
This work contributes three, among others, main design principles for
scientific visualization language design as well as a practice of such language
for DTI visualization with Zifazah. First, Zifazah incorporated visual symbolic
mapping based on color, size and shape, which is a sub-set of Bertin's taxonomy
migrated to scientific visualizations. Second, Zifazah is defined as a spatial
language whereby lexical representation of spatial relationship for 3D object
visualization and manipulations, which is characteristic of scientific data,
can be programmed. Third, built on top of Bertin's semiology, flexible data
encoding specifically for scientific visualizations is integrated in our
language in order to allow end users to achieve optimal visual composition at
their best. Along with sample scripts representative of our language design
features, some new DTI visualizations as the running results created by end
users using the novel visualization language have also been presented.
"
298,Depth-dependent Parallel Visualization with 3D Stylized Dense Tubes,"  We present a parallel visualization algorithm for the illustrative rendering
of depth-dependent stylized dense tube data at interactive frame rates. While
this computation could be efficiently performed on a GPU device, we target a
parallel framework to enable it to be efficiently running on an ordinary
multi-core CPU platform which is much more available than GPUs for common
users. Our approach is to map the depth information in each tube onto each of
the visual dimensions of shape, color, texture, value, and size on the basis of
Bertin's semiology theory. The purpose is to enable more legible displays in
the dense tube environments. A major contribution of our work is an efficient
and effective parallel depthordering algorithm that makes use of the message
passing interface (MPI) with VTK. We evaluated our framework with
visualizations of depth-stylized tubes derived from 3D diffusion tensor MRI
data by comparing its efficiency with several other alternative parallelization
platforms running the same computations. As our results show, the
parallelization framework we proposed can efficiently render highly dense 3D
data sets like the tube data and thus is useful as a complement to parallel
visualization environments that rely on GPUs.
"
299,ImageSpirit: Verbal Guided Image Parsing,"  Humans describe images in terms of nouns and adjectives while algorithms
operate on images represented as sets of pixels. Bridging this gap between how
humans would like to access images versus their typical representation is the
goal of image parsing, which involves assigning object and attribute labels to
pixel. In this paper we propose treating nouns as object labels and adjectives
as visual attribute labels. This allows us to formulate the image parsing
problem as one of jointly estimating per-pixel object and attribute labels from
a set of training images. We propose an efficient (interactive time) solution.
Using the extracted labels as handles, our system empowers a user to verbally
refine the results. This enables hands-free parsing of an image into pixel-wise
object/attribute labels that correspond to human semantics. Verbally selecting
objects of interests enables a novel and natural interaction modality that can
possibly be used to interact with new generation devices (e.g. smart phones,
Google Glass, living room devices). We demonstrate our system on a large number
of real-world images with varying complexity. To help understand the tradeoffs
compared to traditional mouse based interactions, results are reported for both
a large scale quantitative evaluation and a user study.
"
300,Matching LBO eigenspace of non-rigid shapes via high order statistics,"  A fundamental tool in shape analysis is the virtual embedding of the
Riemannian manifold describing the geometry of a shape into Euclidean space.
Several methods have been proposed to embed isometric shapes in flat domains
while preserving distances measured on the manifold. Recently, attention has
been given to embedding shapes into the eigenspace of the Lapalce-Beltrami
operator. The Laplace-Beltrami eigenspace preserves the diffusion distance, and
is invariant under isometric transformations. However, Laplace-Beltrami
eigenfunctions computed independently for different shapes are often
incompatible with each other. Applications involving multiple shapes, such as
pointwise correspondence, would greatly benefit if their respective
eigenfunctions were somehow matched. Here, we introduce a statistical approach
for matching eigenfunctions. We consider the values of the eigenfunctions over
the manifold as sampling of random variables, and try to match their
multivariate distributions. Comparing distributions is done indirectly, using
high order statistics. We show that the permutation and sign ambiguities of low
order eigenfunctions, can be inferred by minimizing the difference of their
third order moments. The sign ambiguities of antisymmetric eigenfunctions can
be resolved by exploiting isometric invariant relations between the gradients
of the eigenfunctions and the surface normal. We present experiments
demonstrating the success of the proposed method applied to feature point
correspondence.
"
301,Structure-preserving color transformations using Laplacian commutativity,"  Mappings between color spaces are ubiquitous in image processing problems
such as gamut mapping, decolorization, and image optimization for color-blind
people. Simple color transformations often result in information loss and
ambiguities (for example, when mapping from RGB to grayscale), and one wishes
to find an image-specific transformation that would preserve as much as
possible the structure of the original image in the target color space. In this
paper, we propose Laplacian colormaps, a generic framework for
structure-preserving color transformations between images. We use the image
Laplacian to capture the structural information, and show that if the color
transformation between two images preserves the structure, the respective
Laplacians have similar eigenvectors, or in other words, are approximately
jointly diagonalizable. Employing the relation between joint diagonalizability
and commutativity of matrices, we use Laplacians commutativity as a criterion
of color mapping quality and minimize it w.r.t. the parameters of a color
transformation to achieve optimal structure preservation. We show numerous
applications of our approach, including color-to-gray conversion, gamut
mapping, multispectral image fusion, and image optimization for color deficient
viewers.
"
302,A Dual-Beam Method-of-Images 3D Searchlight BSSRDF,"  We present a novel BSSRDF for rendering translucent materials. Angular
effects lacking in previous BSSRDF models are incorporated by using a dual-beam
formulation. We employ a Placzek's Lemma interpretation of the method of images
and discard diffusion theory. Instead, we derive a plane-parallel
transformation of the BSSRDF to form the associated BRDF and optimize the image
confiurations such that the BRDF is close to the known analytic solutions for
the associated albedo problem. This ensures reciprocity, accurate colors, and
provides an automatic level-of-detail transition for translucent objects that
appear at various distances in an image. Despite optimizing the subsurface
fluence in a plane-parallel setting, we find that this also leads to fairly
accurate fluence distributions throughout the volume in the original 3D
searchlight problem. Our method-of-images modifications can also improve the
accuracy of previous BSSRDFs.
"
303,"Understanding Visualization: A Formal Approach using Category Theory and
  Semiotics","  This article combines the vocabulary of semiotics and category theory to
provide a formal analysis of visualization. It shows how familiar processes of
visualization fit the semiotic frameworks of both Saussure and Peirce, and
extends these structures using the tools of category theory to provide a
general framework for understanding visualization in practice, including:
relationships between systems, data collected from those systems, renderings of
those data in the form of representations, the reading of those representations
to create visualizations, and the use of those visualizations to create
knowledge and understanding of the system under inspection. The resulting
framework is validated by demonstrating how familiar information visualization
concepts (such as literalness, sensitivity, redundancy, ambiguity,
generalizability, and chart junk) arise naturally from it and can be defined
formally and precisely. This article generalizes previous work on the formal
characterization of visualization by, inter alia, Ziemkiewicz and Kosara and
allows us to formally distinguish properties of the visualization process that
previous work does not.
"
304,"Analysis of Farthest Point Sampling for Approximating Geodesics in a
  Graph","  A standard way to approximate the distance between any two vertices $p$ and
$q$ on a mesh is to compute, in the associated graph, a shortest path from $p$
to $q$ that goes through one of $k$ sources, which are well-chosen vertices.
Precomputing the distance between each of the $k$ sources to all vertices of
the graph yields an efficient computation of approximate distances between any
two vertices. One standard method for choosing $k$ sources, which has been used
extensively and successfully for isometry-invariant surface processing, is the
so-called Farthest Point Sampling (FPS), which starts with a random vertex as
the first source, and iteratively selects the farthest vertex from the already
selected sources.
  In this paper, we analyze the stretch factor $\mathcal{F}_{FPS}$ of
approximate geodesics computed using FPS, which is the maximum, over all pairs
of distinct vertices, of their approximated distance over their geodesic
distance in the graph. We show that $\mathcal{F}_{FPS}$ can be bounded in terms
of the minimal value $\mathcal{F}^*$ of the stretch factor obtained using an
optimal placement of $k$ sources as $\mathcal{F}_{FPS}\leq 2 r_e^2
\mathcal{F}^*+ 2 r_e^2 + 8 r_e + 1$, where $r_e$ is the ratio of the lengths of
the longest and the shortest edges of the graph. This provides some evidence
explaining why farthest point sampling has been used successfully for
isometry-invariant shape processing. Furthermore, we show that it is
NP-complete to find $k$ sources that minimize the stretch factor.
"
305,"On the impact of explicit or semi-implicit integration methods over the
  stability of real-time numerical simulations","  Physics-based animation of soft or rigid bodies for real-time applications
often suffers from numerical instabilities. We analyse one of the most common
sources of unwanted behaviour: the numerical integration strategy. To assess
the impact of popular integration methods, we consider a scenario where soft
and hard constraints are added to a custom designed deformable linear object.
Since the goal for this class of simulation methods is to attain interactive
frame-rates, we present the drawbacks of using explicit integration methods
over inherently stable, implicit integrators. To help numerical solver
designers better understand the impact of an integrator on a certain simulated
world, we have conceived a method of benchmarking the efficiency of an
integrator with respect to its speed, stability and symplecticity.
"
306,On Nonrigid Shape Similarity and Correspondence,"  An important operation in geometry processing is finding the correspondences
between pairs of shapes. The Gromov-Hausdorff distance, a measure of
dissimilarity between metric spaces, has been found to be highly useful for
nonrigid shape comparison. Here, we explore the applicability of related shape
similarity measures to the problem of shape correspondence, adopting spectral
type distances. We propose to evaluate the spectral kernel distance, the
spectral embedding distance and the novel spectral quasi-conformal distance,
comparing the manifolds from different viewpoints. By matching the shapes in
the spectral domain, important attributes of surface structure are being
aligned. For the purpose of testing our ideas, we introduce a fully automatic
framework for finding intrinsic correspondence between two shapes. The proposed
method achieves state-of-the-art results on the Princeton isometric shape
matching protocol applied, as usual, to the TOSCA and SCAPE benchmarks.
"
307,"Digitize Your Body and Action in 3-D at Over 10 FPS: Real Time Dense
  Voxel Reconstruction and Marker-less Motion Tracking via GPU Acceleration","  In this paper, we present an approach to reconstruct 3-D human motion from
multi-cameras and track human skeleton using the reconstructed human 3-D point
(voxel) cloud. We use an improved and more robust algorithm, probabilistic
shape from silhouette to reconstruct human voxel. In addition, the annealed
particle filter is applied for tracking, where the measurement is computed
using the reprojection of reconstructed voxel. We use two different ways to
accelerate the approach. For the CPU only acceleration, we leverage Intel TBB
to speed up the hot spot of the computational overhead and reached an
accelerating ratio of 3.5 on a 4-core CPU. Moreover, we implement an
intensively paralleled version via GPU acceleration without TBB. Taking account
all data transfer and computing time, the GPU version is about 400 times faster
than the original CPU implementation, leading the approach to run at a
real-time speed.
"
308,Real-time High Resolution Fusion of Depth Maps on GPU,"  A system for live high quality surface reconstruction using a single moving
depth camera on a commodity hardware is presented. High accuracy and real-time
frame rate is achieved by utilizing graphics hardware computing capabilities
via OpenCL and by using sparse data structure for volumetric surface
representation. Depth sensor pose is estimated by combining serial texture
registration algorithm with iterative closest points algorithm (ICP) aligning
obtained depth map to the estimated scene model. Aligned surface is then fused
into the scene. Kalman filter is used to improve fusion quality. Truncated
signed distance function (TSDF) stored as block-based sparse buffer is used to
represent surface. Use of sparse data structure greatly increases accuracy of
scanned surfaces and maximum scanning area. Traditional GPU implementation of
volumetric rendering and fusion algorithms were modified to exploit sparsity to
achieve desired performance. Incorporation of texture registration for sensor
pose estimation and Kalman filter for measurement integration improved accuracy
and robustness of scanning process.
"
309,"A local Gaussian filter and adaptive morphology as tools for completing
  partially discontinuous curves","  This paper presents a method for extraction and analysis of curve--type
structures which consist of disconnected components. Such structures are found
in electron--microscopy (EM) images of metal nanograins, which are widely used
in the field of nanosensor technology.
  The topography of metal nanograins in compound nanomaterials is crucial to
nanosensor characteristics. The method of completing such templates consists of
three steps. In the first step, a local Gaussian filter is used with different
weights for each neighborhood. In the second step, an adaptive morphology
operation is applied to detect the endpoints of curve segments and connect
them. In the last step, pruning is employed to extract a curve which optimally
fits the template.
"
310,Continuous Collision Detection for Composite Quadric Models,"  A composite quadric model (CQM) is an object modeled by piecewise linear or
quadric patches. We study the continuous detection problem of a special type of
CQM objects which are commonly used in CAD/CAM, that is, the boundary surfaces
of such a CQM intersect only in straight line segments or conic curve segments.
We present a framework for continuous collision detection (CCD) of this special
type of CQM (which we also call CQM for brevity) in motion. We derive algebraic
formulations and compute numerically the first contact time instants and the
contact points of two moving CQMs in $\mathbb R^3$. Since it is difficult to
process CCD of two CQMs in a direct manner because they are composed of
semi-algebraic varieties, we break down the problem into subproblems of solving
CCD of pairs of boundary elements of the CQMs. We present procedures to solve
CCD of different types of boundary element pairs in different dimensions. Some
CCD problems are reduced to their equivalents in a lower dimensional setting,
where they can be solved more efficiently.
"
311,Compact Part-Based Shape Spaces for Dense Correspondences,"  We consider the problem of establishing dense correspondences within a set of
related shapes of strongly varying geometry. For such input, traditional shape
matching approaches often produce unsatisfactory results. We propose an
ensemble optimization method that improves given coarse correspondences to
obtain dense correspondences. Following ideas from minimum description length
approaches, it maximizes the compactness of the induced shape space to obtain
high-quality correspondences. We make a number of improvements that are
important for computer graphics applications: Our approach handles meshes of
general topology and handles partial matching between input of varying
topology. To this end we introduce a novel part-based generative statistical
shape model. We develop a novel analysis algorithm that learns such models from
training shapes of varying topology. We also provide a novel synthesis method
that can generate new instances with varying part layouts and subject to
generic variational constraints. In practical experiments, we obtain a
substantial improvement in correspondence quality over state-of-the-art
methods. As example application, we demonstrate a system that learns shape
families as assemblies of deformable parts and permits real-time editing with
continuous and discrete variability.
"
312,"Rigorous asymptotic and moment-preserving diffusion approximations for
  generalized linear Boltzmann transport in arbitrary dimension","  We derive new diffusion solutions to the monoenergetic generalized linear
Boltzmann transport equation (GLBE) for the stationary collision density and
scalar flux about an isotropic point source in an infinite $d$-dimensional
absorbing medium with isotropic scattering. We consider both classical
transport theory with exponentially-distributed free paths in arbitrary
dimensions as well as a number of non-classical transport theories
(non-exponential random flights) that describe a broader class of transport
processes within partially-correlated random media. New rigorous asymptotic
diffusion approximations are derived where possible. We also generalize
Grosjean's moment-preserving approach of separating the first (or uncollided)
distribution from the collided portion and approximating only the latter using
diffusion. We find that for any spatial dimension and for many free-path
distributions Grosjean's approach produces compact, analytic approximations
that are, overall, more accurate for high absorption and for small
source-detector separations than either $P_1$ diffusion or rigorous asymptotic
diffusion. These diffusion-based approximations are exact in the first two even
spatial moments, which we derive explicitly for various non-classical transport
types. We also discuss connections between the random-flight-theory derivation
of the Green's function and the discrete spectrum of the transport operator and
report some new observations regarding the discrete eigenvalues of the
transport operator for general dimensions and free-path distributions.
"
313,"Introduction to computer animation and its possible educational
  applications","  Animation, which is basically a form of pictorial presentation, has become
the most prominent feature of technology-based learning environments. It refers
to simulated motion pictures showing movement of drawn objects. Recently,
educational computer animation has turned out to be one of the most elegant
tools for presenting multimedia materials for learners, and its significance in
helping to understand and remember information has greatly increased since the
advent of powerful graphics-oriented computers. In this book chapter we
introduce and discuss the history of computer animation, its well-known
fundamental principles and some educational applications. It is however still
debatable if truly educational computer animations help in learning, as the
research on whether animation aids learners' understanding of dynamic phenomena
has come up with positive, negative and neutral results. We have tried to
provide as much detailed information on computer animation as we could, and we
hope that this book chapter will be useful for students who study computer
science, computer-assisted education or some other courses connected with
contemporary education, as well as researchers who conduct their research in
the field of computer animation.
"
314,Estimation of Human Body Shape and Posture Under Clothing,"  Estimating the body shape and posture of a dressed human subject in motion
represented as a sequence of (possibly incomplete) 3D meshes is important for
virtual change rooms and security. To solve this problem, statistical shape
spaces encoding human body shape and posture variations are commonly used to
constrain the search space for the shape estimate. In this work, we propose a
novel method that uses a posture-invariant shape space to model body shape
variation combined with a skeleton-based deformation to model posture
variation. Our method can estimate the body shape and posture of both static
scans and motion sequences of dressed human body scans. In case of motion
sequences, our method takes advantage of motion cues to solve for a single body
shape estimate along with a sequence of posture estimates. We apply our
approach to both static scans and motion sequences and demonstrate that using
our method, higher fitting accuracy is achieved than when using a variant of
the popular SCAPE model as statistical model.
"
315,"Application of polynomial texture mapping in process of digitalization
  of cultural heritage","  In this paper we present modern texture mapping techniques and several
applications of polynomial texture mapping in cultural heritage programs. We
also consider some well-known and some new methods for mathematical procedure
that is involved in generation of polynomial texture maps.
"
316,"A Topologically-informed Hyperstreamline Seeding Method for Alignment
  Tensor Fields","  A topologically-informed method is presented for seeding of hyperstreamlines
for visualization of alignment tensor fields. The method is inspired by and
applied to visualization of nematic liquid crystal (LC) reorientation dynamics
simulations. The method distributes hyperstreamlines along domain boundaries
and edges of a nearest-neighbor graph whose vertices are degenerate regions of
the alignment tensor field, which correspond to orientational defects in a
nematic LC domain. This is accomplished without iteration while conforming to a
user-specified spacing between hyperstreamlines and avoids possible failure
modes associated with hyperstreamline integration in the vicinity of
degeneracies of alignment (orientational defects). It is shown that the
presented seeding method enables automated hyperstreamline-based visualization
of a broad range of alignment tensor fields which enhances the ability of
researchers to interpret these fields and provides an alternative to using
glyph-based techniques.
"
317,Connectivity-preserving Geometry Images,"  We propose connectivity-preserving geometry images (CGIMs), which map a
three-dimensional mesh onto a rectangular regular array of an image, such that
the reconstructed mesh produces no sampling errors, but merely round-off
errors. We obtain a V-matrix with respect to the original mesh, whose elements
are vertices of the mesh, which intrinsically preserves the vertex-set and the
connectivity of the original mesh in the sense of allowing round-off errors. We
generate a CGIM array by using the Cartesian coordinates of corresponding
vertices of the V-matrix. To reconstruct a mesh, we obtain a vertex-set and an
edge-set by collecting all the elements with different pixels, and all
different pairwise adjacent elements from the CGIM array respectively. Compared
with traditional geometry images, CGIMs achieve minimum reconstruction errors
with an efficient parametrization-free algorithm via elementary permutation
techniques. We apply CGIMs to lossy compression of meshes, and the experimental
results show that CGIMs perform well in reconstruction precision and detail
preservation.
"
318,"A Framework for Creating a Distributed Rendering Environment on the
  Compute Clusters","  This paper discusses the deployment of existing render farm manager in a
typical compute cluster environment such as a university. Usually, both a
render farm and a compute cluster use different queue managers and assume total
control over the physical resources. But, taking out the physical resources
from an existing compute cluster in a university-like environment whose primary
use of the cluster is to run numerical simulations may not be possible. It can
potentially reduce the overall resource utilization in a situation where
compute tasks are more than rendering tasks. Moreover, it can increase the
system administration cost. In this paper, a framework has been proposed that
creates a dynamic distributed rendering environment on top of the compute
clusters using existing render farm managers without requiring the physical
separation of the resources.
"
319,Forward and Inverse Kinematics Seamless Matching Using Jacobian,"  In this paper the problem of matching Forward Kinematics (FK) motion of a 3
Dimensional (3D) joint chain to the Inverse Kinematics (IK) movement and vice
versa has been addressed. The problem lies at the heart of animating a 3D
character having controller and manipulator based rig for animation within any
3D modeling and animation software. The seamless matching has been achieved
through the use of pseudo-inverse of Jacobian Matrix. The Jacobian Matrix is
used to determine the rotation values of each joint of character body part such
as arms, between the inverse kinematics and forward kinematics motion. Then
moving the corresponding kinematic joint system to the desired place,
automatically eliminating the jumping or popping effect which would reduce the
complexity of the system.
"
320,Content Based Image Indexing and Retrieval,"  In this paper, we present the efficient content based image retrieval systems
which employ the color, texture and shape information of images to facilitate
the retrieval process. For efficient feature extraction, we extract the color,
texture and shape feature of images automatically using edge detection which is
widely used in signal processing and image compression. For facilitated the
speedy retrieval we are implements the antipole-tree algorithm for indexing the
images.
"
321,Multilinear Wavelets: A Statistical Shape Space for Human Faces,"  We present a statistical model for $3$D human faces in varying expression,
which decomposes the surface of the face using a wavelet transform, and learns
many localized, decorrelated multilinear models on the resulting coefficients.
Using this model we are able to reconstruct faces from noisy and occluded $3$D
face scans, and facial motion sequences. Accurate reconstruction of face shape
is important for applications such as tele-presence and gaming. The localized
and multi-scale nature of our model allows for recovery of fine-scale detail
while retaining robustness to severe noise and occlusion, and is
computationally efficient and scalable. We validate these properties
experimentally on challenging data in the form of static scans and motion
sequences. We show that in comparison to a global multilinear model, our model
better preserves fine detail and is computationally faster, while in comparison
to a localized PCA model, our model better handles variation in expression, is
faster, and allows us to fix identity parameters for a given subject.
"
322,"A programme to determine the exact interior of any connected digital
  picture","  Region filling is one of the most important and fundamental operations in
computer graphics and image processing. Many filling algorithms and their
implementations are based on the Euclidean geometry, which are then translated
into computational models moving carelessly from the continuous to the finite
discrete space of the computer. The consequences of this approach is that most
implementations fail when tested for challenging degenerate and nearly
degenerate regions. We present a correct integer-only procedure that works for
all connected digital pictures. It finds all possible interior points, which
are then displayed and stored in a locating matrix. Namely, we present a
filling and locating procedure that can be used in computer graphics and image
processing applications.
"
323,Heliostat blocking and shadowing efficiency in the video-game era,"  Blocking and shadowing is one of the key effects in designing and evaluating
a thermal central receiver solar tower plant. Therefore it is convenient to
develop efficient algorithms to compute the area of an heliostat blocked or
shadowed by the rest of the field. In this paper we explore the possibility of
using very efficient clipping algorithms developed for the video game and
imaging industry to compute the blocking and shadowing efficiency of a solar
thermal plant layout. We propose an algorithm valid for arbitrary position,
orientation and size of the heliostats. This algorithm turns out to be very
accurate, free of assumptions and fast. We show the feasibility of the use of
this algorithm to the optimization of a solar plant by studying a couple of
examples in detail.
"
324,"Surfaces Representation with Sharp Features Using Sqrt(3) and Loop
  Subdivision Schemes","  This paper presents a hybrid algorithm that combines features form both
Sqrt(3) and Loop Subdivision schemes. The algorithm aims at preserving sharp
features and trim regions, during the surfaces subdivision, using a set of
rules. The implementation is nontrivial due to the computational, topological,
and smoothness constraints, which should be satisfied by the underlying
surface. The fundamental innovation, in this research work, is the ability to
preserve sharp features anywhere on a surface. In addition, the resulting
representation remains within the multiresolution subdivision framework.
Preserving the original representation has a core advantage that all the
applicable operations to the multiresolution subdivision surfaces can
subsequently be applied to the edited model. Experimental results, including
surfaces coarsening and smoothing, were performed using the proposed algorithm
for validation purposes, and the results revealed that the proposed algorithm
outperforms the other recent state of the art algorithms.
"
325,"Animation of 3D Human Model Using Markerless Motion Capture Applied To
  Sports","  Markerless motion capture is an active research in 3D virtualization. In
proposed work we presented a system for markerless motion capture for 3D human
character animation, paper presents a survey on motion and skeleton tracking
techniques which are developed or are under development. The paper proposed a
method to transform the motion of a performer to a 3D human character (model),
the 3D human character performs similar movements as that of a performer in
real time. In the proposed work, human model data will be captured by Kinect
camera, processed data will be applied on 3D human model for animation. 3D
human model is created using open source software (MakeHuman). Anticipated
dataset for sport activity is considered as input which can be applied to any
HCI application.
"
326,Ergonomic-driven Geometric Exploration and Reshaping,"  The paper addresses the following problem: given a set of man-made shapes,
e.g., chairs, can we quickly rank and explore the set of shapes with respect to
a given avatar pose? Answering this question requires identifying which shapes
are more suitable for the defined avatar and pose; and moreover, to provide
fast preview of how to alter the input geometry to better fit the deformed
shapes to the given avatar pose? The problem naturally links physical
proportions of human body and its interaction with object shapes in an attempt
to connect ergonomics with shape geometry. We designed an interaction system
that allows users to explore shape collections using the deformation of human
characters while at the same time providing interactive previews of how to
alter the shapes to better fit the user-specified character. We achieve this by
first mapping ergonomics guidelines into a set of simultaneous multi-part
constraints based on target contacts; and then, proposing a novel contact-based
deformation model to realize multi-contact constraints. We evaluate our
framework on various chair models and validate the results via a small user
study.
"
327,Scaling hypothesis for the Euclidean bipartite matching problem,"  We propose a simple yet very predictive form, based on a Poisson's equation,
for the functional dependence of the cost from the density of points in the
Euclidean bipartite matching problem. This leads, for quadratic costs, to the
analytic prediction of the large $N$ limit of the average cost in dimension
$d=1,2$ and of the subleading correction in higher dimension. A non-trivial
scaling exponent, $\gamma_d=\frac{d-2}{d}$, which differs from the
monopartite's one, is found for the subleading correction. We argue that the
same scaling holds true for a generic cost exponent in dimension $d>2$.
"
328,Temporal Image Fusion,"  This paper introduces temporal image fusion. The proposed technique builds
upon previous research in exposure fusion and expands it to deal with the
limited Temporal Dynamic Range of existing sensors and camera technologies. In
particular, temporal image fusion enables the rendering of long-exposure
effects on full frame-rate video, as well as the generation of arbitrarily long
exposures from a sequence of images of the same scene taken over time. We
explore the problem of temporal under-exposure, and show how it can be
addressed by selectively enhancing dynamic structure. Finally, we show that the
use of temporal image fusion together with content-selective image filters can
produce a range of striking visual effects on a given input sequence.
"
329,A Novel Method for Vectorization,"  Vectorization of images is a key concern uniting computer graphics and
computer vision communities. In this paper we are presenting a novel idea for
efficient, customizable vectorization of raster images, based on Catmull Rom
spline fitting. The algorithm maintains a good balance between photo-realism
and photo abstraction, and hence is applicable to applications with artistic
concerns or applications where less information loss is crucial. The resulting
algorithm is fast, parallelizable and can satisfy general soft realtime
requirements. Moreover, the smoothness of the vectorized images aesthetically
outperforms outputs of many polygon-based methods
"
330,"An Extension Of Weiler-Atherton Algorithm To Cope With The
  Self-intersecting Polygon","  In this paper a new algorithm has been proposed which can fix the problem of
Weiler Atherton algorithm. The problem of Weiler Atherton algorithm lies in
clipping self intersecting polygon. Clipping self intersecting polygon is not
considered in Weiler Atherton algorithm and hence it is also a main
disadvantage of this algorithm. In our new algorithm a self intersecting
polygon has been divided into non self intersecting contours and then perform
the Weiler Atherton clipping algorithm on those sub polygons. For holes we have
to store the edges that is not own boundary of hole contour from recently
clipped polygon. Thus if both contour is hole then we have to store all the
edges of the recently clipped polygon. Finally the resultant polygon has been
produced by eliminating all the stored edges.
"
331,Image Retargeting by Content-Aware Synthesis,"  Real-world images usually contain vivid contents and rich textural details,
which will complicate the manipulation on them. In this paper, we design a new
framework based on content-aware synthesis to enhance content-aware image
retargeting. By detecting the textural regions in an image, the textural image
content can be synthesized rather than simply distorted or cropped. This method
enables the manipulation of textural & non-textural regions with different
strategy since they have different natures. We propose to retarget the textural
regions by content-aware synthesis and non-textural regions by fast
multi-operators. To achieve practical retargeting applications for general
images, we develop an automatic and fast texture detection method that can
detect multiple disjoint textural regions. We adjust the saliency of the image
according to the features of the textural regions. To validate the proposed
method, comparisons with state-of-the-art image targeting techniques and a user
study were conducted. Convincing visual results are shown to demonstrate the
effectiveness of the proposed method.
"
332,"Implementation of interaction between soft tissues and foreign bodies
  using modified voxel model","  Interactive bodies collision detection and elimination is one of the most
popular task nowadays. Collisions can be detected in different ways. Collision
search using space voxelization is one of the most fast. This paper describes
improved voxel model that covers only area of collision interest and quickly
eliminates collisions. This new method can be useful in real time collision
processing of different rigid and soft bodies grids.
"
333,Flux-Limited Diffusion for Multiple Scattering in Participating Media,"  For the rendering of multiple scattering effects in participating media,
methods based on the diffusion approximation are an extremely efficient
alternative to Monte Carlo path tracing. However, in sufficiently transparent
regions, classical diffusion approximation suffers from non-physical radiative
fluxes which leads to a poor match to correct light transport. In particular,
this prevents the application of classical diffusion approximation to
heterogeneous media, where opaque material is embedded within transparent
regions. To address this limitation, we introduce flux-limited diffusion, a
technique from the astrophysics domain. This method provides a better
approximation to light transport than classical diffusion approximation,
particularly when applied to heterogeneous media, and hence broadens the
applicability of diffusion-based techniques. We provide an algorithm for
flux-limited diffusion, which is validated using the transport theory for a
point light source in an infinite homogeneous medium. We further demonstrate
that our implementation of flux-limited diffusion produces more accurate
renderings of multiple scattering in various heterogeneous datasets than
classical diffusion approximation, by comparing both methods to ground truth
renderings obtained via volumetric path tracing.
"
334,A Computational Framework for Boundary Representation of Solid Sweeps,"  This paper proposes a robust algorithmic and computational framework to
address the problem of modeling the volume obtained by sweeping a solid along a
trajectory of rigid motions. The boundary representation (simply brep) of the
input solid naturally induces a brep of the swept volume. We show that it is
locally similar to the input brep and this serves as the basis of the
framework. All the same, it admits several intricacies: (i) geometric, in terms
of parametrizations and, (ii) topological, in terms of orientations. We provide
a novel analysis for their resolution. More specifically, we prove a
non-trivial lifting theorem which allows to locally orient the output using the
orientation of the input. We illustrate the framework by providing many
examples from a pilot implementation.
"
335,New Julia and Mandelbrot Sets for Jungck Ishikawa Iterates,"  The generation of fractals and study of the dynamics of polynomials is one of
the emerging and interesting field of research nowadays. We introduce in this
paper the dynamics of polynomials z^ n - z + c = 0 for n>=2 and applied Jungck
Ishikawa Iteration to generate new Relative Superior Mandelbrot sets and
Relative Superior Julia sets. In order to solve this function by Jungck type
iterative schemes, we write it in the form of Sz = Tz, where the function T, S
are defined as Tz = z^ n + c and Sz = z. Only mathematical explanations are
derived by applying Jungck Ishikawa Iteration for polynomials in the literature
but in this paper we have generated Relative Mandelbrot sets and Relative Julia
sets.
"
336,Expression driven Trignometric based Procedural Animation of Quadrupeds,"  This research paper addresses the problem of generating involuntary and
precise animation of quadrupeds with automatic rigging system of various
character types. The technique proposed through this research is based on a two
tier animation control curve with base simulation being driven through dynamic
mathematical model using procedural algorithm and the top layer with a custom
user controlled animation provided with intuitive Graphical User Interface
(GUI). The character rig is based on forward and inverse kinematics driven
through trigonometric based motion equations. The User is provided with various
manipulators and attributes to control and handle the locomotion gaits of the
characters and choose between various types of simulated motions from walking,
running, trotting, ambling and galloping with complete custom controls to
easily extend the base simulation as per requirements.
"
337,Real-time Decolorization using Dominant Colors,"  Decolorization is the process to convert a color image or video to its
grayscale version, and it has received great attention in recent years. An
ideal decolorization algorithm should preserve the original color contrast as
much as possible. Meanwhile, it should provide the final decolorized result as
fast as possible. However, most of the current methods are suffering from
either unsatisfied color information preservation or high computational cost,
limiting their application value. In this paper, a simple but effective
technique is proposed for real-time decolorization. Based on the typical
rgb2gray() color conversion model, which produces a grayscale image by linearly
combining R, G, and B channels, we propose a dominant color hypothesis and a
corresponding distance measurement metric to evaluate the quality of grayscale
conversion. The local optimum scheme provides several ""good"" candidates in a
confidence interval, from which the ""best"" result can be extracted.
Experimental results demonstrate that remarkable simplicity of the proposed
method facilitates the process of high resolution images and videos in
real-time using a common CPU.
"
338,"Automated detection of coherent Lagrangian vortices in two-dimensional
  unsteady flows","  Coherent boundaries of Lagrangian vortices in fluid flows have recently been
identified as closed orbits of line fields associated with the Cauchy-Green
strain tensor. Here we develop a fully automated procedure for the detection of
such closed orbits in large-scale velocity data sets. We illustrate the power
of our method on ocean surface velocities derived from satellite altimetry.
"
339,"Interactive Isogeometric Volume Visualization with Pixel-Accurate
  Geometry","  A recent development, called isogeometric analysis, provides a unified
approach for design, analysis and optimization of functional products in
industry. Traditional volume rendering methods for inspecting the results from
the numerical simulations cannot be applied directly to isogeometric models. We
present a novel approach for interactive visualization of isogeometric analysis
results, ensuring correct, i.e., pixel-accurate geometry of the volume
including its bounding surfaces. The entire OpenGL pipeline is used in a
multi-stage algorithm leveraging techniques from surface rendering,
order-independent transparency, as well as theory and numerical methods for
ordinary differential equations. We showcase the efficiency of our approach on
different models relevant to industry, ranging from quality inspection of the
parametrization of the geometry, to stress analysis in linear elasticity, to
visualization of computational fluid dynamics results.
"
340,"Control point based exact description of higher dimensional
  trigonometric and hyperbolic curves and multivariate surfaces","  Using the normalized B-bases of vector spaces of trigonometric and hyperbolic
polynomials of finite order, we specify control point configurations for the
exact description of higher dimensional (rational) curves and (hybrid)
multivariate surfaces determined by coordinate functions that are exclusively
given either by traditional trigonometric or hyperbolic polynomials in each of
their variables. The usefulness and applicability of theoretical results and
proposed algorithms are illustrated by many examples that also comprise the
control point based exact description of several famous curves (like epi- and
hypocycloids, foliums, torus knots, Bernoulli's lemniscate, hyperbolas),
surfaces (such as pure trigonometric or hybrid surfaces of revolution like tori
and hyperboloids, respectively) and 3-dimensional volumes. The core of the
proposed modeling methods relies on basis transformation matrices with entries
that can be efficiently obtained by order elevation. Providing subdivision
formulae for curves described by convex combinations of these normalized
B-basis functions and control points, we also ensure the possible incorporation
of all proposed techniques into today's CAD systems.
"
341,Finding safe strategies for competitive diffusion on trees,"  We study the two-player safe game of Competitive Diffusion, a game-theoretic
model for the diffusion of technologies or influence through a social network.
In game theory, safe strategies are mixed strategies with a minimal expected
gain against unknown strategies of the opponents. Safe strategies for
competitive diffusion lead to maximum spread of influence in the presence of
uncertainty about the other players. We study the safe game on two specific
classes of trees, spiders and complete trees, and give tight bounds on the
minimal expected gain. We then use these results to give an algorithm which
suggests a safe strategy for a player on any tree. We test this algorithm on
randomly generated trees, and show that it finds strategies that are close to
optimal.
"
342,Piko: A Design Framework for Programmable Graphics Pipelines,"  We present Piko, a framework for designing, optimizing, and retargeting
implementations of graphics pipelines on multiple architectures. Piko
programmers express a graphics pipeline by organizing the computation within
each stage into spatial bins and specifying a scheduling preference for these
bins. Our compiler, Pikoc, compiles this input into an optimized implementation
targeted to a massively-parallel GPU or a multicore CPU.
  Piko manages work granularity in a programmable and flexible manner, allowing
programmers to build load-balanced parallel pipeline implementations, to
exploit spatial and producer-consumer locality in a pipeline implementation,
and to explore tradeoffs between these considerations. We demonstrate that Piko
can implement a wide range of pipelines, including rasterization, Reyes, ray
tracing, rasterization/ray tracing hybrid, and deferred rendering. Piko allows
us to implement efficient graphics pipelines with relative ease and to quickly
explore design alternatives by modifying the spatial binning configurations and
scheduling preferences for individual stages, all while delivering real-time
performance that is within a factor six of state-of-the-art rendering systems.
"
343,Proofs of two Theorems concerning Sparse Spacetime Constraints,"  In the SIGGRAPH 2014 paper [SvTSH14] an approach for animating deformable
objects using sparse spacetime constraints is introduced. This report contains
the proofs of two theorems presented in the paper.
"
344,Newton-Type Iterative Solver for Multiple View $L2$ Triangulation,"  In this note, we show that the L2 optimal solutions to most real multiple
view L2 triangulation problems can be efficiently obtained by two-stage
Newton-like iterative methods, while the difficulty of such problems mainly
lies in how to verify the L2 optimality. Such a working two-stage bundle
adjustment approach features: first, the algorithm is initialized by symmedian
point triangulation, a multiple-view generalization of the mid-point method;
second, a symbolic-numeric method is employed to compute derivatives
accurately; third, globalizing strategy such as line search or trust region is
smoothly applied to the underlying iteration which assures algorithm robustness
in general cases.
  Numerical comparison with tfml method shows that the local minimizers
obtained by the two-stage iterative bundle adjustment approach proposed here
are also the L2 optimal solutions to all the calibrated data sets available
online by the Oxford visual geometry group. Extensive numerical experiments
indicate the bundle adjustment approach solves more than 99% the real
triangulation problems optimally. An IEEE 754 double precision C++
implementation shows that it takes only about 0.205 second tocompute allthe
4983 points in the Oxford dinosaur data setvia Gauss-Newton iteration hybrid
with a line search strategy on a computer with a 3.4GHz Intel i7 CPU.
"
345,A General Framework for Bilateral and Mean Shift Filtering,"  We present a generalization of the bilateral filter that can be applied to
feature-preserving smoothing of signals on images, meshes, and other domains
within a single unified framework. Our discretization is competitive with
state-of-the-art smoothing techniques in terms of both accuracy and speed, is
easy to implement, and has parameters that are straightforward to understand.
Unlike previous bilateral filters developed for meshes and other irregular
domains, our construction reduces exactly to the image bilateral on rectangular
domains and comes with a rigorous foundation in both the smooth and discrete
settings. These guarantees allow us to construct unconditionally convergent
mean-shift schemes that handle a variety of extremely noisy signals. We also
apply our framework to geometric edge-preserving effects like feature
enhancement and show how it is related to local histogram techniques.
"
346,"Robust Temporally Coherent Laplacian Protrusion Segmentation of 3D
  Articulated Bodies","  In motion analysis and understanding it is important to be able to fit a
suitable model or structure to the temporal series of observed data, in order
to describe motion patterns in a compact way, and to discriminate between them.
In an unsupervised context, i.e., no prior model of the moving object(s) is
available, such a structure has to be learned from the data in a bottom-up
fashion. In recent times, volumetric approaches in which the motion is captured
from a number of cameras and a voxel-set representation of the body is built
from the camera views, have gained ground due to attractive features such as
inherent view-invariance and robustness to occlusions. Automatic, unsupervised
segmentation of moving bodies along entire sequences, in a temporally-coherent
and robust way, has the potential to provide a means of constructing a
bottom-up model of the moving body, and track motion cues that may be later
exploited for motion classification. Spectral methods such as locally linear
embedding (LLE) can be useful in this context, as they preserve ""protrusions"",
i.e., high-curvature regions of the 3D volume, of articulated shapes, while
improving their separation in a lower dimensional space, making them in this
way easier to cluster. In this paper we therefore propose a spectral approach
to unsupervised and temporally-coherent body-protrusion segmentation along time
sequences. Volumetric shapes are clustered in an embedding space, clusters are
propagated in time to ensure coherence, and merged or split to accommodate
changes in the body's topology. Experiments on both synthetic and real
sequences of dense voxel-set data are shown. This supports the ability of the
proposed method to cluster body-parts consistently over time in a totally
unsupervised fashion, its robustness to sampling density and shape quality, and
its potential for bottom-up model construction
"
347,Incorporating Sharp Features in the General Solid Sweep Framework,"  This paper extends a recently proposed robust computational framework for
constructing the boundary representation (brep) of the volume swept by a given
smooth solid moving along a one parameter family $h$ of rigid motions. Our
extension allows the input solid to have sharp features, i.e., to be of class
G0 wherein, the unit outward normal to the solid may be discontinuous. In the
earlier framework, the solid to be swept was restricted to be G1, and thus this
is a significant and useful extension of that work. This naturally requires a
precise description of the geometry of the surface generated by the sweep of a
sharp edge supported by two intersecting smooth faces. We uncover the geometry
along with the related issues like parametrization, self-intersection and
singularities via a novel mathematical analysis. Correct trimming of such a
surface is achieved by a delicate analysis of the interplay between the cone of
normals at a sharp point and its trajectory under $h$. The overall topology is
explicated by a key lifting theorem which allows us to compute the adjacency
relations amongst entities in the swept volume by relating them to
corresponding adjacencies in the input solid. Moreover, global issues related
to body-check such as orientation are efficiently resolved. Many examples from
a pilot implementation illustrate the efficiency and effectiveness of our
framework.
"
348,"Consistently Orienting Facets in Polygon Meshes by Minimizing the
  Dirichlet Energy of Generalized Winding Numbers","  Jacobson et al. [JKSH13] hypothesized that the local coherency of the
generalized winding number function could be used to correctly determine
consistent facet orientations in polygon meshes. We report on an approach to
consistently orienting facets in polygon meshes by minimizing the Dirichlet
energy of generalized winding numbers. While the energy can be concisely
formulated and efficiently computed, we found that this approach is
fundamentally flawed and is unfortunately not applicable for most handmade
meshes shared on popular mesh repositories such as Google 3D Warehouse.
"
349,3D Texture Coordinates on Polygon Mesh Sequences,"  A method for creating 3D texture coordinates for a sequence of polygon meshes
with changing topology and vertex motion vectors.
"
350,DASS: Detail Aware Sketch-Based Surface Modeling,"  We present a sketch-based modeling system suitable for detail editing, based
on a multilevel representation for surfaces. The main advantage of this
representation allowing for the control of local (details) and global changes
of the model. We used an adaptive mesh (4-8 mesh) and developed a label theory
to construct a manifold structure, which is responsible for controlling local
editing of the model. The overall shape and global modifications are defined by
a variational implicit surface (Hermite RBF). Our system assembles the manifold
structures to allow the user to add details without changing the overall shape,
as well as edit the overall shape while repositioning details coherently.
"
351,Order-Independent Texture Synthesis,"  Search-based texture synthesis algorithms are sensitive to the order in which
texture samples are generated; different synthesis orders yield different
textures. Unfortunately, most polygon rasterizers and ray tracers do not
guarantee the order with which surfaces are sampled. To circumvent this
problem, textures are synthesized beforehand at some maximum resolution and
rendered using texture mapping.
  We describe a search-based texture synthesis algorithm in which samples can
be generated in arbitrary order, yet the resulting texture remains identical.
The key to our algorithm is a pyramidal representation in which each texture
sample depends only on a fixed number of neighboring samples at each level of
the pyramid. The bottom (coarsest) level of the pyramid consists of a noise
image, which is small and predetermined. When a sample is requested by the
renderer, all samples on which it depends are generated at once. Using this
approach, samples can be generated in any order. To make the algorithm
efficient, we propose storing texture samples and their dependents in a
pyramidal cache. Although the first few samples are expensive to generate,
there is substantial reuse, so subsequent samples cost less. Fortunately, most
rendering algorithms exhibit good coherence, so cache reuse is high.
"
352,"A Cylindrical Basis Function for Solving Partial Differential Equations
  on Manifolds","  Numerical solutions of partial differential equations (PDEs) on manifolds
continues to generate a lot of interest among scientists in the natural and
applied sciences. On the other hand, recent developments of 3D scanning and
computer vision technologies have produced a large number of 3D surface models
represented as point clouds. Herein, we develop a simple and efficient method
for solving PDEs on closed surfaces represented as point clouds. By projecting
the radial vector of standard radial basis function(RBF) kernels onto the local
tangent plane, we are able to produce a representation of functions that
permits the replacement of surface differential operators with their Cartesian
equivalent. We demonstrate, numerically, the efficiency of the method in
discretizing the Laplace Beltrami operator.
"
353,"Visualization of Large Volumetric Multi-Channel Microscopy Data Streams
  on Standard PCs","  Background: Visualization of multi-channel microscopy data plays a vital role
in biological research. With the ever-increasing resolution of modern
microscopes the data set size of the scanned specimen grows steadily. On
commodity hardware this size easily exceeds the available main memory and the
even more limited GPU memory. Common volume rendering techniques require the
entire data set to be present in the GPU memory. Existing out-of-core rendering
approaches for large volume data sets either are limited to single-channel
volumes, or require a computer cluster, or have long preprocessing times.
Results: We introduce a ray-casting technique for rendering large volumetric
multi-channel microscopy data streams on commodity hardware. The volumetric
data is managed at different levels of detail by an octree structure. In
contrast to previous octree-based techniques, the octree is built incrementally
and therefore supports streamed microscopy data as well as data set sizes
exceeding the available main memory. Furthermore, our approach allows the user
to interact with the partially rendered data set at all stages of the octree
construction. After a detailed description of our method, we present
performance results for different multi-channel data sets with a size of up to
24 GB on a standard desktop PC. Conclusions: Our rendering technique allows
biologists to visualize their scanned specimen on their standard desktop
computers without high-end hardware requirements. Furthermore, the user can
interact with the data set during the initial loading to explore the already
loaded parts, change rendering parameters like color maps or adjust clipping
planes. Thus, the time of biologists being idle is reduced. Also, streamed data
can be visualized to detect and stop flawed scans early during the scan
process.
"
354,"Visualization and Correction of Automated Segmentation, Tracking and
  Lineaging from 5-D Stem Cell Image Sequences","  Results: We present an application that enables the quantitative analysis of
multichannel 5-D (x, y, z, t, channel) and large montage confocal fluorescence
microscopy images. The image sequences show stem cells together with blood
vessels, enabling quantification of the dynamic behaviors of stem cells in
relation to their vascular niche, with applications in developmental and cancer
biology. Our application automatically segments, tracks, and lineages the image
sequence data and then allows the user to view and edit the results of
automated algorithms in a stereoscopic 3-D window while simultaneously viewing
the stem cell lineage tree in a 2-D window. Using the GPU to store and render
the image sequence data enables a hybrid computational approach. An
inference-based approach utilizing user-provided edits to automatically correct
related mistakes executes interactively on the system CPU while the GPU handles
3-D visualization tasks. Conclusions: By exploiting commodity computer gaming
hardware, we have developed an application that can be run in the laboratory to
facilitate rapid iteration through biological experiments. There is a pressing
need for visualization and analysis tools for 5-D live cell image data. We
combine accurate unsupervised processes with an intuitive visualization of the
results. Our validation interface allows for each data set to be corrected to
100% accuracy, ensuring that downstream data analysis is accurate and
verifiable. Our tool is the first to combine all of these aspects, leveraging
the synergies obtained by utilizing validation information from stereo
visualization to improve the low level image processing tasks.
"
355,"iGPSe: A Visual Analytic System for Integrative Genomic Based Cancer
  Patient Stratification","  Background: Cancers are highly heterogeneous with different subtypes. These
subtypes often possess different genetic variants, present different
pathological phenotypes, and most importantly, show various clinical outcomes
such as varied prognosis and response to treatment and likelihood for
recurrence and metastasis. Recently, integrative genomics (or panomics)
approaches are often adopted with the goal of combining multiple types of omics
data to identify integrative biomarkers for stratification of patients into
groups with different clinical outcomes. Results: In this paper we present a
visual analytic system called Interactive Genomics Patient Stratification
explorer (iGPSe) which significantly reduces the computing burden for
biomedical researchers in the process of exploring complicated integrative
genomics data. Our system integrates unsupervised clustering with graph and
parallel sets visualization and allows direct comparison of clinical outcomes
via survival analysis. Using a breast cancer dataset obtained from the The
Cancer Genome Atlas (TCGA) project, we are able to quickly explore different
combinations of gene expression (mRNA) and microRNA features and identify
potential combined markers for survival prediction. Conclusions: Visualization
plays an important role in the process of stratifying given population
patients. Visual tools allowed for the selection of possibly features across
various datasets for the given patient population. We essentially made a case
for visualization for a very important problem in translational informatics.
"
356,"Addressing the unmet need for visualizing Conditional Random Fields in
  Biological Data","  Background: The biological world is replete with phenomena that appear to be
ideally modeled and analyzed by one archetypal statistical framework - the
Graphical Probabilistic Model (GPM). The structure of GPMs is a uniquely good
match for biological problems that range from aligning sequences to modeling
the genome-to-phenome relationship. The fundamental questions that GPMs address
involve making decisions based on a complex web of interacting factors.
Unfortunately, while GPMs ideally fit many questions in biology, they are not
an easy solution to apply. Building a GPM is not a simple task for an end user.
Moreover, applying GPMs is also impeded by the insidious fact that the complex
web of interacting factors inherent to a problem might be easy to define and
also intractable to compute upon. Discussion: We propose that the visualization
sciences can contribute to many domains of the bio-sciences, by developing
tools to address archetypal representation and user interaction issues in GPMs,
and in particular a variety of GPM called a Conditional Random Field(CRF). CRFs
bring additional power, and additional complexity, because the CRF dependency
network can be conditioned on the query data. Conclusions: In this manuscript
we examine the shared features of several biological problems that are amenable
to modeling with CRFs, highlight the challenges that existing visualization and
visual analytics paradigms induce for these data, and document an experimental
solution called StickWRLD which, while leaving room for improvement, has been
successfully applied in several biological research projects.
"
357,"MCA: Multiresolution Correlation Analysis, a graphical tool for
  subpopulation identification in single-cell gene expression data","  Background: Biological data often originate from samples containing mixtures
of subpopulations, corresponding e.g. to distinct cellular phenotypes. However,
identification of distinct subpopulations may be difficult if biological
measurements yield distributions that are not easily separable. Results: We
present Multiresolution Correlation Analysis (MCA), a method for visually
identifying subpopulations based on the local pairwise correlation between
covariates, without needing to define an a priori interaction scale. We
demonstrate that MCA facilitates the identification of differentially regulated
subpopulations in simulated data from a small gene regulatory network, followed
by application to previously published single-cell qPCR data from mouse
embryonic stem cells. We show that MCA recovers previously identified
subpopulations, provides additional insight into the underlying correlation
structure, reveals potentially spurious compartmentalizations, and provides
insight into novel subpopulations. Conclusions: MCA is a useful method for the
identification of subpopulations in low-dimensional expression data, as
emerging from qPCR or FACS measurements. With MCA it is possible to investigate
the robustness of covariate correlations with respect subpopulations,
graphically identify outliers, and identify factors contributing to
differential regulation between pairs of covariates. MCA thus provides a
framework for investigation of expression correlations for genes of interests
and biological hypothesis generation.
"
358,"Visualization of gene expression information within the context of the
  mouse anatomy","  Background: The eMouse Atlas of Gene Expression (EMAGE) is an online resource
that publishes the results of in situ gene expression experiments on the
developmental mouse. The resource provides comprehensive search facilities, but
few analytical tools or visual mechanisms for navigating the data set. To deal
with the missing visual navigation, this paper explores the application of
sunburst and icicle visualizations within EMAGE. Results: A prototype solution
delivered a simple user interface that helps the user query EMAGE and generate
a sunburst/icicle diagram. An evaluation featuring test subjects from the EMAGE
staff studied the visualizations and provided a range of suggested
improvements. Moreover the evaluation discovered that in addition to providing
a visual means of walking through the data, when grouped, the sunburst delivers
an interactive overview that assists with analysing sets of related genes.
Conclusions: The sunburst and icicle visualizations have been shown to be
effective tools for summarising gene expression data. The sunburst with its
space saving radial layout was found especially useful for providing an
overview of gene families or pathways. Work is ongoing to integrate these
visualizations into EMAGE.
"
359,Determining surfaces of revolution from their implicit equations,"  Results of number of geometric operations (often used in technical practise,
as e.g. the operation of blending) are in many cases surfaces described
implicitly. Then it is a challenging task to recognize the type of the obtained
surface, find its characteristics and for the rational surfaces compute also
their parameterizations. In this contribution we will focus on surfaces of
revolution. These objects, widely used in geometric modelling, are generated by
rotating a generatrix around a given axis. If the generatrix is an algebraic
curve then so is also the resulting surface, described uniquely by a polynomial
which can be found by some well-established implicitation technique. However,
starting from a polynomial it is not known how to decide if the corresponding
algebraic surface is rotational or not. Motivated by this, our goal is to
formulate a simple and efficient algorithm whose input is a polynomial with the
coefficients from some subfield of $\mathbb{R}$ and the output is the answer
whether the shape is a surface of revolution. In the affirmative case we also
find the equations of its axis and generatrix. Furthermore, we investigate the
problem of rationality and unirationality of surfaces of revolution and show
that this question can be efficiently answered discussing the rationality of a
certain associated planar curve.
"
360,"Numerical investigation of lensless zoomable holographic multiple
  projections to tilted planes","  This paper numerically investigates the feasibility of lensless zoomable
holographic multiple projections to tilted planes. We have already developed
lensless zoomable holographic single projection using scaled diffraction, which
calculates diffraction between parallel planes with different sampling pitches.
The structure of this zoomable holographic projection is very simple because it
does not need a lens; however, it only projects a single image to a plane
parallel to the hologram. The lensless zoomable holographic projection in this
paper is capable of projecting multiple images onto tilted planes
simultaneously.
"
361,"SketchBio: A Scientist's 3D Interface for Molecular Modeling and
  Animation","  Background: Because of the difficulties involved in learning and using 3D
modeling and rendering software, many scientists hire programmers or animators
to create models and animations. This both slows the discovery process and
provides opportunities for miscommunication. Working with multiple
collaborators, we developed a set of design goals for a tool that would enable
them to directly construct models and animations. Results: We present
SketchBio, a tool that incorporates state-of-the-art bimanual interaction and
drop shadows to enable rapid construction of molecular structures and
animations. It includes three novel features: crystal by example, pose-mode
physics, and spring-based layout that accelerate operations common in the
formation of molecular models. We present design decisions and their
consequences, including cases where iterative design was required to produce
effective approaches. Conclusions: The design decisions, novel features, and
inclusion of state-of-the-art techniques enabled SketchBio to meet all of its
design goals. These features and decisions can be incorporated into existing
and new tools to improve their effectiveness
"
362,Development & Implementation of a PyMOL 'putty' Representation,"  The PyMOL molecular graphics program has been modified to introduce a new
'putty' cartoon representation, akin to the 'sausage'-style representation of
the MOLMOL molecular visualization (MolVis) software package. This document
outlines the development and implementation of the putty representation.
"
363,"A Moving Least Squares Based Approach for Contour Visualization of
  Multi-Dimensional Data","  Analysis of high dimensional data is a common task. Often, small multiples
are used to visualize 1 or 2 dimensions at a time, such as in a scatterplot
matrix. Associating data points between different views can be difficult
though, as the points are not fixed. Other times, dimensional reduction
techniques are employed to summarize the whole dataset in one image, but
individual dimensions are lost in this view. In this paper, we present a means
of augmenting a dimensional reduction plot with isocontours to reintroduce the
original dimensions. By applying this to each dimension in the original data,
we create multiple views where the points are consistent, which facilitates
their comparison. Our approach employs a combination of a novel, graph-based
projection technique with a GPU accelerated implementation of moving least
squares to interpolate space between the points. We also present evaluations of
this approach both with a case study and with a user study.
"
364,Spoke-Darts for High-Dimensional Blue-Noise Sampling,"  Blue noise sampling has proved useful for many graphics applications, but
remains underexplored in high-dimensional spaces due to the difficulty of
generating distributions and proving properties about them. We present a blue
noise sampling method with good quality and performance across different
dimensions. The method, spoke-dart sampling, shoots rays from prior samples and
selects samples from these rays. It combines the advantages of two major
high-dimensional sampling methods: the locality of advancing front with the
dimensionality-reduction of hyperplanes, specifically line sampling. We prove
that the output sampling is saturated with high probability, with bounds on
distances between pairs of samples and between any domain point and its nearest
sample. We demonstrate spoke-dart applications for approximate Delaunay graph
construction, global optimization, and robotic motion planning. Both the
blue-noise quality of the output distribution and the adaptability of the
intermediate processes of our method are useful in these applications.
"
365,Regularized Harmonic Surface Deformation,"  Harmonic surface deformation is a well-known geometric modeling method that
creates plausible deformations in an interactive manner. However, this method
is susceptible to artifacts, in particular close to the deformation handles.
These artifacts often correlate with strong gradients of the deformation
energy.In this work, we propose a novel formulation of harmonic surface
deformation, which incorporates a regularization of the deformation energy. To
do so, we build on and extend a recently introduced generic linear
regularization approach. It can be expressed as a change of norm for the linear
optimization problem, i.e., the regularization is baked into the optimization.
This minimizes the implementation complexity and has only a small impact on
runtime. Our results show that a moderate use of regularization suppresses many
deformation artifacts common to the well-known harmonic surface deformation
method, without introducing new artifacts.
"
366,Voronoi Grid-Shell Structures,"  We introduce a framework for the generation of grid-shell structures that is
based on Voronoi diagrams and allows us to design tessellations that achieve
excellent static performances. We start from an analysis of stress on the input
surface and we use the resulting tensor field to induce an anisotropic
non-Euclidean metric over it. Then we compute a Centroidal Voronoi Tessellation
under the same metric. The resulting mesh is hex-dominant and made of cells
with a variable density, which depends on the amount of stress, and anisotropic
shape, which depends on the direction of maximum stress. This mesh is further
optimized taking into account symmetry and regularity of cells to improve
aesthetics. We demonstrate that our grid-shells achieve better static
performances with respect to quad-based grid shells, while offering an
innovative and aesthetically pleasing look.
"
367,Fast Disk Conformal Parameterization of Simply-connected Open Surfaces,"  Surface parameterizations have been widely used in computer graphics and
geometry processing. In particular, as simply-connected open surfaces are
conformally equivalent to the unit disk, it is desirable to compute the disk
conformal parameterizations of the surfaces. In this paper, we propose a novel
algorithm for the conformal parameterization of a simply-connected open surface
onto the unit disk, which significantly speeds up the computation, enhances the
conformality and stability, and guarantees the bijectivity. The conformality
distortions at the inner region and on the boundary are corrected by two steps,
with the aid of an iterative scheme using quasi-conformal theories.
Experimental results demonstrate the effectiveness of our proposed method.
"
368,A level set based method for fixing overhangs in 3D printing,"  3D printers based on the Fused Decomposition Modeling create objects
layer-by-layer dropping fused material. As a consequence, strong overhangs
cannot be printed because the new-come material does not find a suitable
support over the last deposed layer. In these cases, one can add some support
structures (scaffolds) which make the object printable, to be removed at the
end. In this paper we propose a level set method to create object-dependent
support structures, specifically conceived to reduce both the amount of
additional material and the printing time. We also review some open problems
about 3D printing which can be of interests for the mathematical community.
"
369,History-free Collision Response for Deformable Surfaces,"  Continuous collision detection (CCD) and response methods are widely adopted
in dynamics simulation of deformable models. They are history-based, as their
success is strictly based on an assumption of a collision-free state at the
start of each time interval. On the other hand, in many applications surfaces
have normals defined to designate their orientation (i.e. front- and
back-face), yet CCD methods are totally blind to such orientation
identification (thus are orientation-free). We notice that if such information
is utilized, many penetrations can be untangled. In this paper we present a
history-free method for separation of two penetrating meshes, where at least
one of them has clarified surface orientation. This method first computes all
edge-face (E-F) intersections with discrete collision detection (DCD), and then
builds a number of penetration stencils. On response, the stencil vertices are
relocated into a penetration-free state, via a global displacement minimizer.
Our method is very effective for handling penetration between two meshes, being
it an initial configuration or in the middle of physics simulation. The major
limitation is that it is not applicable to self-collision within one mesh at
the time being.
"
370,"Tracing Analytic Ray Curves for Light and Sound Propagation in
  Non-linear Media","  The physical world consists of spatially varying media, such as the
atmosphere and the ocean, in which light and sound propagates along non-linear
trajectories. This presents a challenge to existing ray-tracing based methods,
which are widely adopted to simulate propagation due to their efficiency and
flexibility, but assume linear rays. We present a novel algorithm that traces
analytic ray curves computed from local media gradients, and utilizes the
closed-form solutions of both the intersections of the ray curves with planar
surfaces, and the travel distance. By constructing an adaptive unstructured
mesh, our algorithm is able to model general media profiles that vary in three
dimensions with complex boundaries consisting of terrains and other scene
objects such as buildings. We trace the analytic ray curves using the adaptive
unstructured mesh, which considerably improves the efficiency over prior
methods. We highlight the algorithm's application on simulation of sound and
visual propagation in outdoor scenes.
"
371,"Comparative Study of Geometric and Image Based Modelling and Rendering
  Techniques","  This is a comparative study of the traditional 3D computer graphics technique
of geometric modelling and image-based rendering techniques that were surveyed
and implemented.We have discussed the classifications and representative
methods of both the techniques. The study has shown that there is a strong
continuum between both the techniques and a hybrid of the two is most suitable
for further implementations.This hybridisation study is underway to create
models of real life situations and provide disaster management training.
"
372,Effects of Coupling in Human-Virtual Agent Body Interaction,"  This paper presents a study of the dynamic coupling between a user and a
virtual character during body interaction. Coupling is directly linked with
other dimensions, such as co-presence, engagement, and believability, and was
measured in an experiment that allowed users to describe their subjective
feelings about those dimensions of interest. The experiment was based on a
theatrical game involving the imitation of slow upper-body movements and the
proposal of new movements by the user and virtual agent. The agent's behaviour
varied in autonomy: the agent could limit itself to imitating the user's
movements only, initiate new movements, or combine both behaviours. After the
game, each participant completed a questionnaire regarding their engagement in
the interaction, their subjective feeling about the co-presence of the agent,
etc. Based on four main dimensions of interest, we tested several hypotheses
against our experimental results, which are discussed here.
"
373,Reactive Programming for Interactive Graphics,"  One of the big challenges of developing interactive statistical applications
is the management of the data pipeline, which controls transformations from
data to plot. The user's interactions needs to be propagated through these
modules and reflected in the output representation at a fast pace. Each
individual module may be easy to develop and manage, but the dependency
structure can be quite challenging. The MVC (Model/View/Controller) pattern is
an attempt to solve the problem by separating the user's interaction from the
representation of the data. In this paper we discuss the paradigm of reactive
programming in the framework of the MVC architecture and show its applicability
to interactive graphics. Under this paradigm, developers benefit from the
separation of user interaction from the graphical representation, which makes
it easier for users and developers to extend interactive applications. We show
the central role of reactive data objects in an interactive graphics system,
implemented as the R package cranvas, which is freely available on GitHub and
the main developers include the authors of this paper.
"
374,Using 3D Printing to Visualize Social Media Big Data,"  Big data volume continues to grow at unprecedented rates. One of the key
features that makes big data valuable is the promise to find unknown patterns
or correlations that may be able to improve the quality of processes or
systems. Unfortunately, with the exponential growth in data, users often have
difficulty in visualizing the often-unstructured, non-homogeneous data coming
from a variety of sources. The recent growth in popularity of 3D printing has
ushered in a revolutionary way to interact with big data. Using a 3D printed
mockup up a physical or notional environment, one can display data on the
mockup to show real-time data patterns. In this poster and demonstration, we
describe the process of 3D printing and demonstrate an application of
displaying Twitter data on a 3D mockup of the Massachusetts Institute of
Technology (MIT) campus, known as LuminoCity.
"
375,Real-time animation of human characters with fuzzy controllers,"  The production of animation is a resource intensive process in game
companies. Therefore, techniques to synthesize animations have been developed.
However, these procedural techniques offer limited adaptability by animation
artists. In order to solve this, a fuzzy neural network model of the animation
is proposed, where the parameters can be tuned either by machine learning
techniques that use motion capture data as training data or by the animation
artist himself. This paper illustrates how this real time procedural animation
system can be developed, taking the human gait on flat terrain and inclined
surfaces as example. Currently, the parametric model is capable of synthesizing
animations for various limb sizes and step sizes.
"
376,Image compression overview,"  Compression plays a significant role in a data storage and a transmission. If
we speak about a generall data compression, it has to be a lossless one. It
means, we are able to recover the original data 1:1 from the compressed file.
Multimedia data (images, video, sound...), are a special case. In this area, we
can use something called a lossy compression. Our main goal is not to recover
data 1:1, but only keep them visually similar. This article is about an image
compression, so we will be interested only in image compression. For a human
eye, it is not a huge difference, if we recover RGB color with values
[150,140,138] instead of original [151,140,137]. The magnitude of a difference
determines the loss rate of the compression. The bigger difference usually
means a smaller file, but also worse image quality and noticable differences
from the original image. We want to cover compression techniques mainly from
the last decade. Many of them are variations of existing ones, only some of
them uses new principes.
"
377,Computing minimum area homologies,"  Calculating and categorizing the similarity of curves is a fundamental
problem which has generated much recent interest. However, to date there are no
implementations of these algorithms for curves on surfaces with provable
guarantees on the quality of the measure. In this paper, we present a
similarity measure for any two cycles that are homologous, where we calculate
the minimum area of any homology (or connected bounding chain) between the two
cycles. The minimum area homology exists for broader classes of cycles than
previous measures which are based on homotopy. It is also much easier to
compute than previously defined measures, yielding an efficient implementation
that is based on linear algebra tools. We demonstrate our algorithm on a range
of inputs, showing examples which highlight the feasibility of this similarity
measure.
"
378,"A mathematical design and evaluation of Bernstein-Bezier curves' shape
  features using the laws of technical aesthetics","  We present some notes on the definition of mathematical design as well as on
the methods of mathematical modeling which are used in the process of the
artistic design of the environment and its components. For the first time in
the field of geometric modeling, we perform an aesthetic analysis of planar
Bernstein-Bezier curves from the standpoint of the laws of technical
aesthetics. The shape features of the curve segments' geometry were evaluated
using the following criteria: conciseness-integrity, expressiveness,
proportional consistency, compositional balance, structural organization,
imagery, rationality, dynamism, scale, flexibility and harmony. In the
non-Russian literature, Bernstein-Bezier curves using a monotonic curvature
function (i.e., a class A Bezier curve) are considered to be fair (i.e.,
beautiful) curves, but their aesthetic analysis has never been performed. The
aesthetic analysis performed by the authors of this work means that this is no
longer the case. To confirm the conclusions of the authors' research, a survey
of the ""aesthetic appropriateness"" of certain Bernstein-Bezier curve segments
was conducted among 240 children, aged 14-17. The results of this survey have
shown themselves to be in full accordance with the authors' results.
"
379,"TiQuant: Software for tissue analysis, quantification and surface
  reconstruction","  Motivation: TiQuant is a modular software tool for efficient quantification
of biological tissues based on volume data obtained by biomedical image
modalities. It includes a number of versatile image and volume processing
chains tailored to the analysis of different tissue types which have been
experimentally verified. TiQuant implements a novel method for the
reconstruction of three-dimensional surfaces of biological systems, data that
often cannot be obtained experimentally but which is of utmost importance for
tissue modelling in systems biology. Availability: TiQuant is freely available
for non-commercial use at msysbio.com/tiquant. Windows, OSX and Linux are
supported.
"
380,"Efficient Distance Computation Algorithm between Nearly Intersected
  Objects Using Dynamic Pivot Point in Virtual Environment Application","  Finding nearly accurate distance between two or more nearly intersecting
three-dimensional (3D) objects is vital especially for collision determination
such as in virtual surgeon simulation and real-time car crash simulation.
Instead of performing broad phase collision detection, we need to check for
accuracy of detection by running narrow phase collision detection. One of the
important elements for narrow phase collision detection is to determine the
precise distance between two or more nearly intersecting objects or polygons in
order to prepare the area for potential colliding. Distance computation plays
important roles in determine the exact point of contact between two or more
nearly intersecting polygons where the preparation for collision detection is
determined at the earlier stage. In this paper, we describes our current works
of determining the distance between objects using dynamic pivot point that will
be used as reference point to reduce the complexity searching for potential
point of contacts. By using Axis-Aligned Bounding Box for each polygon, we
calculate a dynamic pivot point that will become our reference point to
determine the potential candidates for distance computation. The test our
finding distance will be simplified by using our method instead of performing
unneeded operations. Our method provides faster solution than the previous
method where it helps to determine the point of contact efficiently and faster
than the other method.
"
381,The physics of volume rendering,"  Radiation transfer is an important topic in several physical disciplines,
probably most prominently in astrophysics. Computer scientists use radiation
transfer, among other things, for the visualisation of complex data sets with
direct volume rendering. In this note, I point out the connection between
physical radiation transfer and volume rendering, and I describe an
implementation of direct volume rendering in the astrophysical radiation
transfer code RADMC-3D. I show examples for the use of this module on
analytical models and simulation data.
"
382,Visualising Large Datasets in TOPCAT v4,"  TOPCAT is a widely used desktop application for manipulation of astronomical
catalogues and other tables, which has long provided fast interactive
visualisation features including 1, 2 and 3-d plots, multiple datasets, linked
views, color coding, transparency and more. In Version 4 a new plotting library
has been written from scratch to deliver new and enhanced visualisation
capabilities. This paper describes some of the considerations in the design and
implementation, particularly in regard to providing comprehensible interactive
visualisation for multi-million point datasets.
"
383,Footprint-Driven Locomotion Composition,"  One of the most efficient ways of generating goal-directed walking motions is
synthesising the final motion based on footprints. Nevertheless, current
implementations have not examined the generation of continuous motion based on
footprints, where different behaviours can be generated automatically.
Therefore, in this paper a flexible approach for footprint-driven locomotion
composition is presented. The presented solution is based on the ability to
generate footprint-driven locomotion, with flexible features like jumping,
running, and stair stepping. In addition, the presented system examines the
ability of generating the desired motion of the character based on predefined
footprint patterns that determine which behaviour should be performed. Finally,
it is examined the generation of transition patterns based on the velocity of
the root and the number of footsteps required to achieve the target behaviour
smoothly and naturally.
"
384,Mesh2Fab: Reforming Shapes for Material-specific Fabrication,"  As humans, we regularly associate shape of an object with its built material.
In the context of geometric modeling, however, this interrelation between form
and material is rarely explored. In this work, we propose a novel data-driven
reforming (i.e., reshaping) algorithm that adapts an input multi-component
model for a target fabrication material. The algorithm adapts both the part
geometry and the inter-part topology of the input shape to better align with
material specific fabrication requirements. As output, we produce the reshaped
model along with respective part dimensions and inter-part junction
specifications. We evaluate our algorithm on a range of man-made models and
demonstrate non-trivial model reshaping examples focusing only on metal and
wooden materials. We also appraise the output of our algorithm using a user
study.
"
385,GASP : Geometric Association with Surface Patches,"  A fundamental challenge to sensory processing tasks in perception and
robotics is the problem of obtaining data associations across views. We present
a robust solution for ascertaining potentially dense surface patch (superpixel)
associations, requiring just range information. Our approach involves
decomposition of a view into regularized surface patches. We represent them as
sequences expressing geometry invariantly over their superpixel neighborhoods,
as uniquely consistent partial orderings. We match these representations
through an optimal sequence comparison metric based on the Damerau-Levenshtein
distance - enabling robust association with quadratic complexity (in contrast
to hitherto employed joint matching formulations which are NP-complete). The
approach is able to perform under wide baselines, heavy rotations, partial
overlaps, significant occlusions and sensor noise.
  The technique does not require any priors -- motion or otherwise, and does
not make restrictive assumptions on scene structure and sensor movement. It
does not require appearance -- is hence more widely applicable than appearance
reliant methods, and invulnerable to related ambiguities such as textureless or
aliased content. We present promising qualitative and quantitative results
under diverse settings, along with comparatives with popular approaches based
on range as well as RGB-D data.
"
386,"Reverse Engineering Point Clouds to Fit Tensor Product B-Spline Surfaces
  by Blending Local Fits","  Being able to reverse engineer from point cloud data to obtain 3D models is
important in modeling. As our main contribution, we present a new method to
obtain a tensor product B-spline representation from point cloud data by
fitting surfaces to appropriately segmented data. By blending multiple local
fits our method is more efficient than existing techniques, with the ability to
deal with more detail by efficiently introducing a high number of knots.
Further point cloud data obtained by digitizing 3D data, typically presents
many associated complications like noise and missing data. As our second
contribution, we propose an end-to-end framework for smoothing, hole filling,
parameterization, knot selection and B-spline fitting that addresses these
issues, works robustly with large irregularly shaped data containing holes and
is straightforward to implement.
"
387,"BigDataViewer: Interactive Visualization and Image Processing for
  Terabyte Data Sets","  The increasingly popular light sheet microscopy techniques generate very
large 3D time-lapse recordings of living biological specimen. The necessity to
make large volumetric datasets available for interactive visualization and
analysis has been widely recognized. However, existing solutions build on
dedicated servers to generate virtual slices that are transferred to the client
applications, practically leading to insufficient frame rates (less than 10
frames per second) for truly interactive experience. An easily accessible open
source solution for interactive arbitrary virtual re-slicing of very large
volumes and time series of volumes has yet been missing. We fill this gap with
BigDataViewer, a Fiji plugin to interactively navigate and visualize large
image sequences from both local and remote data sources.
"
388,"Ceramics Fragments Digitization by Photogrammetry, Reconstructions and
  Applications","  This paper presents an application of photogrammetry on ceramic fragments
from two excavation sites located north-west of France. The restitution by
photogrammetry of these different fragments allowed reconstructions of the
potteries in their original state or at least to get to as close as possible.
We used the 3D reconstructions to compute some metrics and to generate a
presentation support by using a 3D printer. This work is based on affordable
tools and illustrates how 3D technologies can be quite easily integrated in
archaeology process with limited financial resources. 1. INTRODUCTION Today,
photogrammetry and 3D modelling are an integral part of the methods used in
archeology and heritage management. They provide answers to scientific needs in
the fields of conservation, preservation, restoration and mediation of
architectural, archaeological and cultural heritage [2] [6] [7] [9].
Photogrammetry on ceramic fragments was one of the first applications
contemporary of the development of this technique applied in the archaeological
community [3]. More recently and due to its democratization, it was applied
more generally to artifacts [5]. Finally joined today by the rise of 3D
printing [8] [10], it can restore fragmented artifacts [1] [12]. These examples
target one or several particular objects and use different types of equipment
that can be expensive. These aspects can put off uninitiated archaeologists. So
it would be appropriate to see if these techniques could be generalized to a
whole class of geometrically simple and common artifacts, such as ceramics.
From these observations, associated to ceramics specialists with fragments of
broken ceramics, we aimed at arranging different tools and methods, including
photogrammetry, to explore opportunities for a cheap and attainable
reconstruction methodology and its possible applications. Our first objective
was to establish a protocol for scanning fragments with photogrammetry, and for
reconstruction of original ceramics. We used the digital reconstitutions of the
ceramics we got following our process to calculate some metrics and to design
and 3D print a display for the remaining fragments of one pottery.
"
389,Throat Finding Algorithms based on Throat Types,"  The three-dimensional geometry and connectivity of pore space determines the
flow of single-phase incompressible flow. Herein I report on new throat finding
algorithms that contribute to finding the exact flow-relevant geometrical
properties of the void space, including high porosity samples of X2B images,
three-dimensional synchrotron X-ray computed microtomographic images, and
amounting to over 20% porosity. These new algorithms use the modified medial
axis that comes from the 3DMA-Rock software package. To find accurate throats,
we classify three major throat types: mostly planar and simply connected type,
non-planar and simply connected type, and non-planar and non-simply connected
type. For each type, we make at least one algorithm to find the throats. Here I
introduce an example that has a non-planar and simply connected throat, and my
solution indicated by one of my algorithms. My five algorithms each calculate
the throat for each path. It selects one of them, which has the smallest inner
area. New algorithms find accurate throats at least 98% among 12 high porosity
samples (over 20%). Also, I introduce a new length calculation in the digitized
image. The new calculation uses three mathematical concepts: i)
differentiability, ii) implicit function theorem, iii) line integral. The
result can convert the discrete boundary of the XMCT image to the real
boundary. When the real boundary has an arc shape, the new calculation has less
than 1% relative error.
"
390,Merging of B\'ezier curves with box constraints,"  In this paper, we present a novel approach to the problem of merging of
B\'ezier curves with respect to the $L_2$-norm. We give illustrative examples
to show that the solution of the conventional merging problem may not be
suitable for further modification and applications. As in the case of the
degree reduction problem, we apply the so-called restricted area approach --
proposed recently in (P. Gospodarczyk, Computer-Aided Design 62 (2015),
143--151) -- to avoid certain defects and make the resulting curve more useful.
A method of solving the new problem is based on box-constrained quadratic
programming approach.
"
391,A Canonical Representation of Data-Linear Visualization Algorithms,"  We introduce linear-state dataflows, a canonical model for a large set of
visualization algorithms that we call data-linear visualizations. Our model
defines a fixed dataflow architecture: partitioning and subpartitioning of
input data, ordering, graphic primitives, and graphic attributes generation.
Local variables and accumulators are specific concepts that extend the
expressiveness of the dataflow to support features of visualization algorithms
that require state handling. We first show the flexibility of our model: it
enables the declarative construction of many common algorithms with just a few
mappings. Furthermore, the model enables easy mixing of visual mappings, such
as creating treemaps of histograms and 2D plots, plots of histograms...
Finally, we introduce our model in a more formal way and present some of its
important properties. We have implemented this model in a visualization
framework built around the concept of linear-state dataflows.
"
392,"Qualitative shape representation based on the qualitative relative
  direction and distance calculus eOPRAm","  This document serves as a brief technical report, detailing the processes
used to represent and reconstruct simplified polygons using qualitative spatial
descriptions, as defined by the eOPRAm qualitative spatial calculus.
"
393,SVEN: Informative Visual Representation of Complex Dynamic Structure,"  Graphs change over time, and typically variations on the small multiples or
animation pattern is used to convey this dynamism visually. However, both of
these classical techniques have significant drawbacks, so a new approach,
Storyline Visualization of Events on a Network (SVEN) is proposed. SVEN builds
on storyline techniques, conveying nodes as contiguous lines over time. SVEN
encodes time in a natural manner, along the horizontal axis, and optimizes the
vertical placement of storylines to decrease clutter (line crossings,
straightness, and bends) in the drawing. This paper demonstrates SVEN on
several different flavors of real-world dynamic data, and outlines the
remaining near-term future work.
"
394,Automatic Photo Adjustment Using Deep Neural Networks,"  Photo retouching enables photographers to invoke dramatic visual impressions
by artistically enhancing their photos through stylistic color and tone
adjustments. However, it is also a time-consuming and challenging task that
requires advanced skills beyond the abilities of casual photographers. Using an
automated algorithm is an appealing alternative to manual work but such an
algorithm faces many hurdles. Many photographic styles rely on subtle
adjustments that depend on the image content and even its semantics. Further,
these adjustments are often spatially varying. Because of these
characteristics, existing automatic algorithms are still limited and cover only
a subset of these challenges. Recently, deep machine learning has shown unique
abilities to address hard problems that resisted machine algorithms for long.
This motivated us to explore the use of deep learning in the context of photo
editing. In this paper, we explain how to formulate the automatic photo
adjustment problem in a way suitable for this approach. We also introduce an
image descriptor that accounts for the local semantics of an image. Our
experiments demonstrate that our deep learning formulation applied using these
descriptors successfully capture sophisticated photographic styles. In
particular and unlike previous techniques, it can model local adjustments that
depend on the image semantics. We show on several examples that this yields
results that are qualitatively and quantitatively better than previous work.
"
395,"Interactive Visual Exploration of Halos in Large Scale Cosmology
  Simulation","  Halo is one of the most important basic elements in cosmology simulation,
which merges from small clumps to ever larger objects. The processes of the
birth and merging of the halos play a fundamental role in studying the
evolution of large scale cosmological structures. In this paper, a visual
analysis system is developed to interactively identify and explore the
evolution histories of thousands of halos. In this system, an intelligent
structure-aware selection method in What You See Is What You Get manner is
designed to efficiently define the interesting region in 3D space with 2D
hand-drawn lasso input. Then the exact information of halos within this 3D
region is identified by data mining in the merger tree files. To avoid visual
clutter, all the halos are projected in 2D space with a MDS method. Through the
linked view of 3D View and 2D graph, Users can interactively explore these
halos, including the tracing path and evolution history tree.
"
396,"HSI based colour image equalization using iterative nth root and nth
  power","  In this paper an equalization technique for colour images is introduced. The
method is based on nth root and nth power equalization approach but with
optimization of the mean of the image in different colour channels such as RGB
and HSI. The performance of the proposed method has been measured by the means
of peak signal to noise ratio. The proposed algorithm has been compared with
conventional histogram equalization and the visual and quantitative
experimental results are showing that the proposed method over perform the
histogram equalization.
"
397,"$G^{k,l}$-constrained multi-degree reduction of B\'ezier curves","  We present a new approach to the problem of $G^{k,l}$-constrained ($k,l \leq
3$) multi-degree reduction of B\'{e}zier curves with respect to the least
squares norm. First, to minimize the least squares error, we consider two
methods of determining the values of geometric continuity parameters. One of
them is based on quadratic and nonlinear programming, while the other uses some
simplifying assumptions and solves a system of linear equations. Next, for
prescribed values of these parameters, we obtain control points of the
multi-degree reduced curve, using the properties of constrained dual Bernstein
basis polynomials. Assuming that the input and output curves are of degree $n$
and $m$, respectively, we determine these points with the complexity $O(mn)$,
which is significantly less than the cost of other known methods. Finally, we
give several examples to demonstrate the effectiveness of our algorithms.
"
398,"Feature Lines for Illustrating Medical Surface Models: Mathematical
  Background and Survey","  This paper provides a tutorial and survey for a specific kind of illustrative
visualization technique: feature lines. We examine different feature line
methods. For this, we provide the differential geometry behind these concepts
and adapt this mathematical field to the discrete differential geometry. All
discrete differential geometry terms are explained for triangulated surface
meshes. These utilities serve as basis for the feature line methods. We provide
the reader with all knowledge to re-implement every feature line method.
Furthermore, we summarize the methods and suggest a guideline for which kind of
surface which feature line algorithm is best suited. Our work is motivated by,
but not restricted to, medical and biological surface models.
"
399,A Novel Implementation of QuickHull Algorithm on the GPU,"  We present a novel GPU-accelerated implementation of the QuickHull algorihtm
for calculating convex hulls of planar point sets. We also describe a practical
solution to demonstrate how to efficiently implement a typical
Divide-and-Conquer algorithm on the GPU. We highly utilize the parallel
primitives provided by the library Thrust such as the parallel segmented scan
for better efficiency and simplicity. To evaluate the performance of our
implementation, we carry out four groups of experimental tests using two groups
of point sets in two modes on the GPU K20c. Experimental results indicate that:
our implementation can achieve the speedups of up to 10.98x over the
state-of-art CPU-based convex hull implementation Qhull [16]. In addition, our
implementation can find the convex hull of 20M points in about 0.2 seconds.
"
400,GPU Programming - Speeding Up the 3D Surface Generator VESTA,"  The novel ""Volume-Enclosing Surface exTraction Algorithm"" (VESTA) generates
triangular isosurfaces from computed tomography volumetric images and/or
three-dimensional (3D) simulation data. Here, we present various benchmarks for
GPU-based code implementations of both VESTA and the current state-of-the-art
Marching Cubes Algorithm (MCA). One major result of this study is that VESTA
runs significantly faster than the MCA.
"
401,Interactive 3D Face Stylization Using Sculptural Abstraction,"  Sculptors often deviate from geometric accuracy in order to enhance the
appearance of their sculpture. These subtle stylizations may emphasize anatomy,
draw the viewer's focus to characteristic features of the subject, or symbolize
textures that might not be accurately reproduced in a particular sculptural
medium, while still retaining fidelity to the unique proportions of an
individual. In this work we demonstrate an interactive system for enhancing
face geometry using a class of stylizations based on visual decomposition into
abstract semantic regions, which we call sculptural abstraction. We propose an
interactive two-scale optimization framework for stylization based on
sculptural abstraction, allowing real-time adjustment of both global and local
parameters. We demonstrate this system's effectiveness in enhancing physical 3D
prints of scans from various sources.
"
402,"Marching Surfaces: Isosurface Approximation using G$^1$ Multi-Sided
  Surfaces","  Marching surfaces is a method for isosurface extraction and approximation
based on a $G^1$ multi-sided patch interpolation scheme. Given a 3D grid of
scalar values, an underlying curve network is formed using second order
information and cubic Hermite splines. Circular arc fitting defines the tangent
vectors for the Hermite curves at specified isovalues. Once the boundary curve
network is formed, a loop of curves is determined for each grid cell and then
interpolated with multi-sided surface patches, which are $G^1$ continuous at
the joins. The data economy of the method and its continuity preserving
properties provide an effective compression scheme, ideal for indirect volume
rendering on mobile devices, or collaborating on the Internet, while enhancing
visual fidelity. The use of multi-sided patches enables a more natural way to
approximate the isosurfaces than using a fixed number of sides or polygons as
is proposed in the literature. This assertion is supported with comparisons to
the traditional Marching Cubes algorithm and other $G^1$ methods.
"
403,Avatar-independent scripting for real-time gesture animation,"  When animation of a humanoid figure is to be generated at run-time, instead
of by replaying pre-composed motion clips, some method is required of
specifying the avatar's movements in a form from which the required motion data
can be automatically generated. This form must be of a more abstract nature
than raw motion data: ideally, it should be independent of the particular
avatar's proportions, and both writable by hand and suitable for automatic
generation from higher-level descriptions of the required actions.
  We describe here the development and implementation of such a scripting
language for the particular area of sign languages of the deaf, called SiGML
(Signing Gesture Markup Language), based on the existing HamNoSys notation for
sign languages.
  We conclude by suggesting how this work may be extended to more general
animation for interactive virtual reality applications.
"
404,Sketch-based Shape Retrieval using Pyramid-of-Parts,"  We present a multi-scale approach to sketch-based shape retrieval. It is
based on a novel multi-scale shape descriptor called Pyramidof- Parts, which
encodes the features and spatial relationship of the semantic parts of query
sketches. The same descriptor can also be used to represent 2D projected views
of 3D shapes, allowing effective matching of query sketches with 3D shapes
across multiple scales. Experimental results show that the proposed method
outperforms the state-of-the-art method, whether the sketch segmentation
information is obtained manually or automatically by considering each stroke as
a semantic part.
"
405,"Relative Squared Distances to a Conic Berserkless 8-Connected Midpoint
  Algorithm","  The midpoint method or technique is a measurement and as each measurement it
has a tolerance, but worst of all it can be invalid, called Out-of-Control or
OoC. The core of all midpoint methods is the accurate measurement of the
difference of the squared distances of two points to the polar of their
midpoint with respect to the conic. When this measurement is valid, it also
measures the difference of the squared distances of these points to the conic,
although it may be inaccurate, called Out-of-Accuracy or OoA. The primary
condition is the necessary and sufficient condition that a measurement is
valid. It is comletely new and it can be checked ultra fast and before the
actual measurement starts. Modeling an incremental algorithm, shows that the
curve must be subdivided into piecewise monotonic sections, the start point
must be optimal, and it explains that the 2D-incremental method can find,
locally, the global Least Square Distance. Locally means that there are at most
three candidate points for a given monotonic direction; therefore the
2D-midpoint method has, locally, at most three measurements. When all the
possible measurements are invalid, the midpoint method cannot be applied, and
in that case the ultra fast OoC-rule selects the candidate point. This
guarantees, for the first time, a 100% stable, ultra-fast, berserkless midpoint
algorithm, which can be easily transformed to hardware.
"
406,"Analysis of Design Principles and Requirements for Procedural Rigging of
  Bipeds and Quadrupeds Characters with Custom Manipulators for Animation","  Character rigging is a process of endowing a character with a set of custom
manipulators and controls making it easy to animate by the animators. These
controls consist of simple joints, handles, or even separate character
selection windows.This research paper present an automated rigging system for
quadruped characters with custom controls and manipulators for animation.The
full character rigging mechanism is procedurally driven based on various
principles and requirements used by the riggers and animators. The automation
is achieved initially by creating widgets according to the character type.
These widgets then can be customized by the rigger according to the character
shape, height and proportion. Then joint locations for each body parts are
calculated and widgets are replaced programmatically.Finally a complete and
fully operational procedurally generated character control rig is created and
attached with the underlying skeletal joints. The functionality and feasibility
of the rig was analyzed from various source of actual character motion and a
requirements criterion was met. The final rigged character provides an
efficient and easy to manipulate control rig with no lagging and at high frame
rate.
"
407,Data-Driven Shape Analysis and Processing,"  Data-driven methods play an increasingly important role in discovering
geometric, structural, and semantic relationships between 3D shapes in
collections, and applying this analysis to support intelligent modeling,
editing, and visualization of geometric data. In contrast to traditional
approaches, a key feature of data-driven approaches is that they aggregate
information from a collection of shapes to improve the analysis and processing
of individual shapes. In addition, they are able to learn models that reason
about properties and relationships of shapes without relying on hard-coded
rules or explicitly programmed instructions. We provide an overview of the main
concepts and components of these techniques, and discuss their application to
shape classification, segmentation, matching, reconstruction, modeling and
exploration, as well as scene analysis and synthesis, through reviewing the
literature and relating the existing works with both qualitative and numerical
comparisons. We conclude our report with ideas that can inspire future research
in data-driven shape analysis and processing.
"
408,Landmark-Guided Elastic Shape Analysis of Human Character Motions,"  Motions of virtual characters in movies or video games are typically
generated by recording actors using motion capturing methods. Animations
generated this way often need postprocessing, such as improving the periodicity
of cyclic animations or generating entirely new motions by interpolation of
existing ones. Furthermore, search and classification of recorded motions
becomes more and more important as the amount of recorded motion data grows.
  In this paper, we will apply methods from shape analysis to the processing of
animations. More precisely, we will use the by now classical elastic metric
model used in shape matching, and extend it by incorporating additional inexact
feature point information, which leads to an improved temporal alignment of
different animations.
"
409,Efficient Upsampling of Natural Images,"  We propose a novel method of efficient upsampling of a single natural image.
Current methods for image upsampling tend to produce high-resolution images
with either blurry salient edges, or loss of fine textural detail, or spurious
noise artifacts.
  In our method, we mitigate these effects by modeling the input image as a sum
of edge and detail layers, operating upon these layers separately, and merging
the upscaled results in an automatic fashion. We formulate the upsampled output
image as the solution to a non-convex energy minimization problem, and propose
an algorithm to obtain a tractable approximate solution. Our algorithm
comprises two main stages. 1) For the edge layer, we use a nonparametric
approach by constructing a dictionary of patches from a given image, and
synthesize edge regions in a higher-resolution version of the image. 2) For the
detail layer, we use a global parametric texture enhancement approach to
synthesize detail regions across the image.
  We demonstrate that our method is able to accurately reproduce sharp edges as
well as synthesize photorealistic textures, while avoiding common artifacts
such as ringing and haloing. In addition, our method involves no training phase
or estimation of model parameters, and is easily parallelizable. We demonstrate
the utility of our method on a number of challenging standard test photos.
"
410,Facial Expression Cloning with Elastic and Muscle Models,"  Expression cloning plays an important role in facial expression synthesis. In
this paper, a novel algorithm is proposed for facial expression cloning. The
proposed algorithm first introduces a new elastic model to balance the global
and local warping effects, such that the impacts from facial feature diversity
among people can be minimized, and thus more effective geometric warping
results can be achieved. Furthermore, a muscle-distribution-based (MD) model is
proposed, which utilizes the muscle distribution of the human face and results
in more accurate facial illumination details. In addition, we also propose a
new distance-based metric to automatically select the optimal parameters such
that the global and local warping effects in the elastic model can be suitably
balanced. Experimental results show that our proposed algorithm outperforms the
existing methods.
"
411,"On Integrating Information Visualization Techniques into Data Mining: A
  Review","  The exploding growth of digital data in the information era and its
immeasurable potential value has called for different types of data-driven
techniques to exploit its value for further applications. Information
visualization and data mining are two research field with such goal. While the
two communities advocates different approaches of problem solving, the vision
of combining the sophisticated algorithmic techniques from data mining as well
as the intuitivity and interactivity of information visualization is tempting.
In this paper, we attempt to survey recent researches and real world systems
integrating the wisdom in two fields towards more effective and efficient data
analytics. More specifically, we study the intersection from a data mining
point of view, explore how information visualization can be used to complement
and improve different stages of data mining through established theories for
optimized visual presentation as well as practical toolsets for rapid
development. We organize the survey by identifying three main stages of typical
process of data mining, the preliminary analysis of data, the model
construction, as well as the model evaluation, and study how each stage can
benefit from information visualization.
"
412,Frequency Domain TOF: Encoding Object Depth in Modulation Frequency,"  Time of flight cameras may emerge as the 3-D sensor of choice. Today, time of
flight sensors use phase-based sampling, where the phase delay between emitted
and received, high-frequency signals encodes distance. In this paper, we
present a new time of flight architecture that relies only on frequency---we
refer to this technique as frequency-domain time of flight (FD-TOF). Inspired
by optical coherence tomography (OCT), FD-TOF excels when frequency bandwidth
is high. With the increasing frequency of TOF sensors, new challenges to time
of flight sensing continue to emerge. At high frequencies, FD-TOF offers
several potential benefits over phase-based time of flight methods.
"
413,"Partial light field tomographic reconstruction from a fixed-camera focal
  stack","  This paper describes a novel approach to partially reconstruct
high-resolution 4D light fields from a stack of differently focused photographs
taken with a fixed camera. First, a focus map is calculated from this stack
using a simple approach combining gradient detection and region expansion with
graph-cut. Then, this focus map is converted into a depth map thanks to the
calibration of the camera. We proceed after this with the tomographic
reconstruction of the epipolar images by back-projecting the focused regions of
the scene only. We call it masked back-projection. The angles of
back-projection are calculated from the depth map. Thanks to the high angular
resolution we achieve by suitably exploiting the image content captured over a
large interval of focus distances, we are able to render puzzling perspective
shifts although the original photographs were taken from a single fixed camera
at a fixed position.
"
414,Deep Convolutional Inverse Graphics Network,"  This paper presents the Deep Convolution Inverse Graphics Network (DC-IGN), a
model that learns an interpretable representation of images. This
representation is disentangled with respect to transformations such as
out-of-plane rotations and lighting variations. The DC-IGN model is composed of
multiple layers of convolution and de-convolution operators and is trained
using the Stochastic Gradient Variational Bayes (SGVB) algorithm. We propose a
training procedure to encourage neurons in the graphics code layer to represent
a specific transformation (e.g. pose or light). Given a single input image, our
model can generate new images of the same object with variations in pose and
lighting. We present qualitative and quantitative results of the model's
efficacy at learning a 3D rendering engine.
"
415,"Interactive Illustrative Line Styles and Line Style Transfer Functions
  for Flow Visualization","  We present a flexible illustrative line style model for the visualization of
streamline data. Our model partitions view-oriented line strips into parallel
bands whose basic visual properties can be controlled independently. We thus
extend previous line stylization techniques specifically for visualization
purposes by allowing the parametrization of these bands based on the local line
data attributes. Moreover, our approach supports emphasis and abstraction by
introducing line style transfer functions that map local line attribute values
to complete line styles. With a flexible GPU implementation of this line style
model we enable the interactive exploration of visual representations of
streamlines. We demonstrate the effectiveness of our model by applying it to 3D
flow field datasets.
"
416,"Developing Educational Computer Animation Based on Human Personality
  Types","  Computer animation in the past decade has become one of the most noticeable
features of technology-based learning environments. With today's high
educational demands as well as the lack of time provided for certain courses,
classical educational methods have shown deficiencies in keeping up with the
drastic changes observed in the digital era. Without taking into account
various significant factors such as gender, age, level of interest and memory
level, educational animation may turn out to be insufficient for learners or
fail to meet their needs. However, we have noticed that the applications of
animation for education have been given only inadequate attention, and
students' personality types have never been taken into account. We suggest
there is an interesting relationship here, and propose essential factors in
creating educational animations based on students' personality types.
Particularly, we investigate how information in computer animation may be
presented in a preferable way based on the fundamental elements of computer
animation. The present study believes that it is likely to have wide benefits
in the field of education. Considering the personality types in designing
educational computer animations with the aid of gathered empirical results
might be a promising avenue to enhance the learning process.
"
417,"Interpolation of a spline developable surface between a curve and two
  rulings","  In this paper we address the problem of interpolating a spline developable
patch bounded by a given spline curve and the first and the last rulings of the
developable surface. In order to complete the boundary of the patch a second
spline curve is to be given. Up to now this interpolation problem could be
solved, but without the possibility of choosing both endpoints for the rulings.
We circumvent such difficulty here by resorting to degree elevation of the
developable surface. This is useful not only to solve this problem, but also
other problems dealing with triangular developable patches.
"
418,Conformal Surface Morphing with Applications on Facial Expressions,"  Morphing is the process of changing one figure into another. Some numerical
methods of 3D surface morphing by deformable modeling and conformal mapping are
shown in this study. It is well known that there exists a unique Riemann
conformal mapping from a simply connected surface into a unit disk by the
Riemann mapping theorem. The dilation and relative orientations of the 3D
surfaces can be linked through the M\""obius transformation due to the conformal
characteristic of the Riemann mapping. On the other hand, a 3D surface
deformable model can be built via various approaches such as mutual
parameterization from direct interpolation or surface matching using landmarks.
In this paper, we take the advantage of the unique representation of 3D
surfaces by the mean curvatures and the conformal factors associated with the
Riemann mapping. By registering the landmarks on the conformal parametric
domains, the correspondence of the mean curvatures and the conformal factors
for each surfaces can be obtained. As a result, we can construct the 3D
deformation field from the surface reconstruction algorithm proposed by Gu and
Yau. Furthermore, by composition of the M\""obius transformation and the 3D
deformation field, the morphing sequence can be generated from the mean
curvatures and the conformal factors on a unified mesh structure by using the
cubic spline homotopy. Several numerical experiments of the face morphing are
presented to demonstrate the robustness of our approach.
"
419,"Preprint Extending Touch-less Interaction on Vision Based Wearable
  Device","  This is the preprint version of our paper on IEEE Virtual Reality Conference
2015. A touch-less interaction technology on vision based wearable device is
designed and evaluated. Users interact with the application with dynamic
hands/feet gestures in front of the camera. Several proof-of-concept prototypes
with eleven dynamic gestures are developed based on the touch-less interaction.
At last, a comparing user study evaluation is proposed to demonstrate the
usability of the touch-less approach, as well as the impact on user's emotion,
running on a wearable framework or Google Glass.
"
420,3D visual analysis of seabed on smartphone,"  We create a 'virtual-seabed' platform to realize the 3D visual analysis of
seabed on smartphone. The 3D seabed platform is based on a 'section-drilling'
model, implementing visualization and analysis of the integrated data of seabed
on the 3D browser on smartphone. Some 3D visual analysis functions are
developed. This work presents a thorough and interesting way of presenting
seabed data on smartphone, which raises many application possibilities. This
platform is another practical proof based on our WebVRGIS platform.
"
421,"Fast algorithms for morphological operations using run-length encoded
  binary images","  This paper presents innovative algorithms to efficiently compute erosions and
dilations of run-length encoded (RLE) binary images with arbitrary shaped
structuring elements. An RLE image is given by a set of runs, where a run is a
horizontal concatenation of foreground pixels. The proposed algorithms extract
the skeleton of the structuring element and build distance tables of the input
image, which are storing the distance to the next background pixel on the left
and right hand sides. This information is then used to speed up the
calculations of the erosion and dilation operator by enabling the use of
techniques which allow to skip the analysis of certain pixels whenever a hit or
miss occurs. Additionally the input image gets trimmed during the preprocessing
steps on the base of two primitive criteria. Experimental results show the
advantages over other algorithms. The source code of our algorithms is
available in C++.
"
422,Preprint Big City 3D Visual Analysis,"  This is the preprint version of our paper on EUROGRAPHICS 2015. A big city
visual analysis platform based on Web Virtual Reality Geographical Information
System (WEBVRGIS) is presented. Extensive model editing functions and spatial
analysis functions are available, including terrain analysis, spatial analysis,
sunlight analysis, traffic analysis, population analysis and community
analysis.
"
423,3D Density Histograms for Criteria-driven Edge Bundling,"  This paper presents a graph bundling algorithm that agglomerates edges taking
into account both spatial proximity as well as user-defined criteria in order
to reveal patterns that were not perceivable with previous bundling techniques.
Each edge belongs to a group that may either be an input of the problem or
found by clustering one or more edge properties such as origin, destination,
orientation, length or domain-specific properties. Bundling is driven by a
stack of density maps, with each map capturing both the edge density of a given
group as well as interactions with edges from other groups. Density maps are
efficiently calculated by smoothing 2D histograms of edge occurrence using
repeated averaging filters based on integral images.
  A CPU implementation of the algorithm is tested on several graphs, and
different grouping criteria are used to illustrate how the proposed technique
can render different visualizations of the same data. Bundling performance is
much higher than on previous approaches, being particularly noticeable on large
graphs, with millions of edges being bundled in seconds.
"
424,"Real-time Tool for Affine Transformations of Two Dimensional IFS
  Fractals","  This work introduces a novel tool for interactive, real-time transformations
of two dimensional IFS fractals. We assign barycentric coordinates (relative to
an arbitrary affine basis of $\mathbb{R}^2$) to the points that constitute the
image of a fractal. The tool uses some of the nice properties of the
barycentric coordinates, enabling any affine transformation of the basis, done
by click-and-drag, to be immediately followed by the same affine transformation
of the IFS fractal attractor. In order to have a better control over the
fractal, as affine basis we use a kind of minimal simplex that contains the
attractor. We give theoretical grounds of the tool and then the software
application.
"
425,Massively Parallel Ray Tracing Algorithm Using GPU,"  Ray tracing is a technique for generating an image by tracing the path of
light through pixels in an image plane and simulating the effects of
high-quality global illumination at a heavy computational cost. Because of the
high computation complexity, it can't reach the requirement of real-time
rendering. The emergence of many-core architectures, makes it possible to
reduce significantly the running time of ray tracing algorithm by employing the
powerful ability of floating point computation. In this paper, a new GPU
implementation and optimization of the ray tracing to accelerate the rendering
process is presented.
"
426,"Real-time correction of panoramic images using hyperbolic M\""obius
  transformations","  Wide-angle images gained a huge popularity in the last years due to the
development of computational photography and imaging technological advances.
They present the information of a scene in a way which is more natural for the
human eye but, on the other hand, they introduce artifacts such as bent lines.
These artifacts become more and more unnatural as the field of view increases.
  In this work, we present a technique aimed to improve the perceptual quality
of panorama visualization. The main ingredients of our approach are, on one
hand, considering the viewing sphere as a Riemann sphere, what makes natural
the application of M\""obius (complex) transformations to the input image, and,
on the other hand, a projection scheme which changes in function of the field
of view used.
  We also introduce an implementation of our method, compare it against images
produced with other methods and show that the transformations can be done in
real-time, which makes our technique very appealing for new settings, as well
as for existing interactive panorama applications.
"
427,"Simple Derivation of the Lifetime and the Distribution of Faces for a
  Binary Subdivision Model","  The iterative random subdivision of rectangles is used as a generation model
of networks in physics, computer science, and urban planning. However, these
researches were independent. We consider some relations in them, and derive
fundamental properties for the average lifetime depending on birth-time and the
balanced distribution of rectangle faces.
"
428,Bijective Deformations in $\mathbb{R}^n$ via Integral Curve Coordinates,"  We introduce Integral Curve Coordinates, which identify each point in a
bounded domain with a parameter along an integral curve of the gradient of a
function $f$ on that domain; suitable functions have exactly one critical
point, a maximum, in the domain, and the gradient of the function on the
boundary points inward. Because every integral curve intersects the boundary
exactly once, Integral Curve Coordinates provide a natural bijective mapping
from one domain to another given a bijection of the boundary. Our approach can
be applied to shapes in any dimension, provided that the boundary of the shape
(or cage) is topologically equivalent to an $n$-sphere. We present a simple
algorithm for generating a suitable function space for $f$ in any dimension. We
demonstrate our approach in 2D and describe a practical (simple and robust)
algorithm for tracing integral curves on a (piecewise-linear) triangulated
regular grid.
"
429,Multi-view Convolutional Neural Networks for 3D Shape Recognition,"  A longstanding question in computer vision concerns the representation of 3D
shapes for recognition: should 3D shapes be represented with descriptors
operating on their native 3D formats, such as voxel grid or polygon mesh, or
can they be effectively represented with view-based descriptors? We address
this question in the context of learning to recognize 3D shapes from a
collection of their rendered views on 2D images. We first present a standard
CNN architecture trained to recognize the shapes' rendered views independently
of each other, and show that a 3D shape can be recognized even from a single
view at an accuracy far higher than using state-of-the-art 3D shape
descriptors. Recognition rates further increase when multiple views of the
shapes are provided. In addition, we present a novel CNN architecture that
combines information from multiple views of a 3D shape into a single and
compact shape descriptor offering even better recognition performance. The same
architecture can be applied to accurately recognize human hand-drawn sketches
of shapes. We conclude that a collection of 2D views can be highly informative
for 3D shape recognition and is amenable to emerging CNN architectures and
their derivatives.
"
430,Learning Style Similarity for Searching Infographics,"  Infographics are complex graphic designs integrating text, images, charts and
sketches. Despite the increasing popularity of infographics and the rapid
growth of online design portfolios, little research investigates how we can
take advantage of these design resources. In this paper we present a method for
measuring the style similarity between infographics. Based on human perception
data collected from crowdsourced experiments, we use computer vision and
machine learning algorithms to learn a style similarity metric for infographic
designs. We evaluate different visual features and learning algorithms and find
that a combination of color histograms and Histograms-of-Gradients (HoG)
features is most effective in characterizing the style of infographics. We
demonstrate our similarity metric on a preliminary image retrieval test.
"
431,"B$\acute{e}$zier curves based on Lupa\c{s} $(p,q)$-analogue of Bernstein
  polynomials in CAGD","  In this paper, we use the blending functions of Lupa\c{s} type (rational)
$(p,q)$-Bernstein operators based on $(p,q)$-integers for construction of
Lupa\c{s} $(p,q)$-B$\acute{e}$zier curves (rational curves) and surfaces
(rational surfaces) with shape parameters. We study the nature of degree
elevation and degree reduction for Lupa\c{s} $(p,q)$-B$\acute{e}$zier Bernstein
functions. Parametric curves are represented using Lupa\c{s} $(p,q)$-Bernstein
basis. We introduce affine de Casteljau algorithm for Lupa\c{s} type
$(p,q)$-Bernstein B$\acute{e}$zier curves. The new curves have some properties
similar to $q$-B$\acute{e}$zier curves. Moreover, we construct the
corresponding tensor product surfaces over the rectangular domain $(u, v) \in
[0, 1] \times [0, 1] $ depending on four parameters. We also study the de
Casteljau algorithm and degree evaluation properties of the surfaces for these
generalization over the rectangular domain. We get $q$-B$\acute{e}$zier
surfaces for $(u, v) \in [0, 1] \times [0, 1] $ when we set the parameter
$p_1=p_2=1.$ In comparison to $q$-B$\acute{e}$zier curves and surfaces based on
Lupa\c{s} $q$-Bernstein polynomials, our generalization gives us more
flexibility in controlling the shapes of curves and surfaces.
  We also show that the $(p,q)$-analogue of Lupa\c{s} Bernstein operator
sequence $L^{n}_{p_n,q_n}(f,x)$ converges uniformly to $f(x)\in C[0,1]$ if and
only if $0<q_n<p_n\leq1$ such that $\lim\limits_{n\to\infty} q_n=1, $
$\lim\limits_{n\to\infty} p_n=1$ and $\lim\limits_{n\to\infty}p_n^n=a,$
$\lim\limits_{n\to\infty}q_n^n=b$ with $0<a,b\leq1.$ On the other hand, for any
$p>0$ fixed and $p \neq 1,$ the sequence $L^{n}_{p,q}(f,x)$ converges uniformly
to $f(x)~ \in C[0,1]$ if and only if $f(x)=ax+b$ for some $a, b \in
\mathbb{R}.$
"
432,"Control point based exact description of curves and surfaces in extended
  Chebyshev spaces","  Extended Chebyshev spaces that also comprise the constants represent large
families of functions that can be used in real-life modeling or engineering
applications that also involve important (e.g. transcendental) integral or
rational curves and surfaces. Concerning computer aided geometric design, the
unique normalized B-bases of such vector spaces ensure optimal shape preserving
properties, important evaluation or subdivision algorithms and useful shape
parameters. Therefore, we propose global explicit formulas for the entries of
those transformation matrices that map these normalized B-bases to the
traditional (or ordinary) bases of the underlying vector spaces. Then, we also
describe general and ready to use control point configurations for the exact
representation of those traditional integral parametric curves and (hybrid)
surfaces that are specified by coordinate functions given as (products of
separable) linear combinations of ordinary basis functions. The obtained
results are also extended to the control point and weight based exact
description of the rational counterpart of these integral parametric curves and
surfaces. The universal applicability of our methods is presented through
polynomial, trigonometric, hyperbolic or mixed extended Chebyshev vector
spaces.
"
433,"A Connectivity-Aware Multi-level Finite-Element System for Solving
  Laplace-Beltrami Equations","  Recent work on octree-based finite-element systems has developed a multigrid
solver for Poisson equations on meshes. While the idea of defining a regularly
indexed function space has been successfully used in a number of applications,
it has also been noted that the richness of the function space is limited
because the function values can be coupled across locally disconnected regions.
In this work, we show how to enrich the function space by introducing functions
that resolve the coupling while still preserving the nesting hierarchy that
supports multigrid. A spectral analysis reveals the superior quality of the
resulting Laplace-Beltrami operator and applications to surface flow
demonstrate that our new solver more efficiently converges to the correct
solution.
"
434,A wide diversity of 3D surfaces Generator using a new implicit function,"  We present in this paper a new family of implicit function for synthesizing a
wide variety of 3D surfaces. The basis of this family consists of the usual
functions that are: the function rectangular pulses, the function saw-tooth
pulses, the function of triangular pulses, the staircase function and the power
function. By combining these common functions, named constituent functions, in
one implicit function and by varying some parameters of this function we can
synthesize a wide variety of 3D surfaces with the possibility to set their
deformations.
"
435,"Constructing Intrinsic Delaunay Triangulations from the Dual of Geodesic
  Voronoi Diagrams","  Intrinsic Delaunay triangulation (IDT) is a fundamental data structure in
computational geometry and computer graphics. However, except for some
theoretical results, such as existence and uniqueness, little progress has been
made towards computing IDT on simplicial surfaces. To date the only way for
constructing IDTs is the edge-flipping algorithm, which iteratively flips the
non-Delaunay edge to be locally Delaunay. Although the algorithm is
conceptually simple and guarantees to stop in finite steps, it has no known
time complexity. Moreover, the edge-flipping algorithm may produce non-regular
triangulations, which contain self-loops and/or faces with only two edges. In
this paper, we propose a new method for constructing IDT on manifold triangle
meshes. Based on the duality of geodesic Voronoi diagrams, our method can
guarantee the resultant IDTs are regular. Our method has a theoretical
worst-case time complexity $O(n^2\log n)$ for a mesh with $n$ vertices. We
observe that most real-world models are far from their Delaunay triangulations,
thus, the edge-flipping algorithm takes many iterations to fix the non-Delaunay
edges. In contrast, our method is non-iterative and insensitive to the number
of non-Delaunay edges. Empirically, it runs in linear time $O(n)$ on real-world
models.
"
436,Implementing a Photorealistic Rendering System using GLSL,"  Ray tracing on GPUs is becoming quite common these days. There are many
publicly available documents on how to implement basic ray tracing on GPUs for
spheres and implicit surfaces. We even have some general frameworks for ray
tracing on GPUs. We however hardly find details on how to implement more
complex ray tracing algorithms themselves that are commonly used for
photorealistic rendering. This paper explains an implementation of a
stand-alone rendering system on GPUs which supports the bounding volume
hierarchy and stochastic progressive photon mapping. The key characteristic of
the system is that it uses only GLSL shaders without relying on any platform
dependent feature. The system can thus run on many platforms that support
OpenGL, making photorealistic rendering on GPUs widely accessible. This paper
also sketches practical ideas for stackless traversal and pseudorandom number
generation which both fit well with the limited system configuration.
"
437,Text to 3D Scene Generation with Rich Lexical Grounding,"  The ability to map descriptions of scenes to 3D geometric representations has
many applications in areas such as art, education, and robotics. However, prior
work on the text to 3D scene generation task has used manually specified object
categories and language that identifies them. We introduce a dataset of 3D
scenes annotated with natural language descriptions and learn from this data
how to ground textual descriptions to physical objects. Our method successfully
grounds a variety of lexical terms to concrete referents, and we show
quantitatively that our method improves 3D scene generation over previous work
using purely rule-based methods. We evaluate the fidelity and plausibility of
3D scenes generated with our grounding approach through human judgments. To
ease evaluation on this task, we also introduce an automated metric that
strongly correlates with human judgments.
"
438,"A survey on Information Visualization in light of Vision and Cognitive
  sciences","  Information Visualization techniques are built on a context with many factors
related to both vision and cognition, making it difficult to draw a clear
picture of how data visually turns into comprehension. In the intent of
promoting a better picture, here, we survey concepts on vision, cognition, and
Information Visualization organized in a theorization named Visual Expression
Process. Our theorization organizes the basis of visualization techniques with
a reduced level of complexity; still, it is complete enough to foster
discussions related to design and analytical tasks. Our work introduces the
following contributions: (1) a Theoretical compilation of vision, cognition,
and Information Visualization; (2) Discussions supported by vast literature;
and (3) Reflections on visual-cognitive aspects concerning use and design. We
expect our contributions will provide further clarification about how users and
designers think about InfoVis, leveraging the potential of systems and
techniques.
"
439,"Prototyping Information Visualization in 3D City Models: a Model-based
  Approach","  When creating 3D city models, selecting relevant visualization techniques is
a particularly difficult user interface design task. A first obstacle is that
current geodata-oriented tools, e.g. ArcGIS, have limited 3D capabilities and
limited sets of visualization techniques. Another important obstacle is the
lack of unified description of information visualization techniques for 3D city
models. If many techniques have been devised for different types of data or
information (wind flows, air quality fields, historic or legal texts, etc.)
they are generally described in articles, and not really formalized. In this
paper we address the problem of visualizing information in (rich) 3D city
models by presenting a model-based approach for the rapid prototyping of
visualization techniques. We propose to represent visualization techniques as
the composition of graph transformations. We show that these transformations
can be specified with SPARQL construction operations over RDF graphs. These
specifications can then be used in a prototype generator to produce 3D scenes
that contain the 3D city model augmented with data represented using the
desired technique.
"
440,"The Spatial-Perceptual Design Space: a new comprehension for Data
  Visualization","  We revisit the design space of visualizations aiming at identifying and
relating its components. In this sense, we establish a model to examine the
process through which visualizations become expressive for users. This model
has leaded us to a taxonomy oriented to the human visual perception, a
conceptualization that provides natural criteria in order to delineate a novel
understanding for the visualization design space. The new organization of
concepts that we introduce is our main contribution: a grammar for the
visualization design based on the review of former works and of classical and
state-of-the-art techniques. Like so, the paper is presented as a survey whose
structure introduces a new conceptualization for the space of techniques
concerning visual analysis.
"
441,"Continuous Mental Effort Evaluation during 3D Object Manipulation Tasks
  based on Brain and Physiological Signals","  Designing 3D User Interfaces (UI) requires adequate evaluation tools to
ensure good usability and user experience. While many evaluation tools are
already available and widely used, existing approaches generally cannot provide
continuous and objective measures of usa-bility qualities during interaction
without interrupting the user. In this paper, we propose to use brain (with
ElectroEncephaloGraphy) and physiological (ElectroCardioGraphy, Galvanic Skin
Response) signals to continuously assess the mental effort made by the user to
perform 3D object manipulation tasks. We first show how this mental effort
(a.k.a., mental workload) can be estimated from such signals, and then measure
it on 8 participants during an actual 3D object manipulation task with an input
device known as the CubTile. Our results suggest that monitoring workload
enables us to continuously assess the 3DUI and/or interaction technique
ease-of-use. Overall, this suggests that this new measure could become a useful
addition to the repertoire of available evaluation tools, enabling a finer
grain assessment of the ergonomic qualities of a given 3D user interface.
"
442,"Variance Analysis for Monte Carlo Integration: A
  Representation-Theoretic Perspective","  In this report, we revisit the work of Pilleboue et al. [2015], providing a
representation-theoretic derivation of the closed-form expression for the
expected value and variance in homogeneous Monte Carlo integration. We show
that the results obtained for the variance estimation of Monte Carlo
integration on the torus, the sphere, and Euclidean space can be formulated as
specific instances of a more general theory. We review the related
representation theory and show how it can be used to derive a closed-form
solution.
"
443,Shape Analysis on Lie Groups with Applications in Computer Animation,"  Shape analysis methods have in the past few years become very popular, both
for theoretical exploration as well as from an application point of view.
Originally developed for planar curves, these methods have been expanded to
higher dimensional curves, surfaces, activities, character motions and many
other objects. In this paper, we develop a framework for shape analysis of
curves in Lie groups for problems of computer animations. In particular, we
will use these methods to find cyclic approximations of non-cyclic character
animations and interpolate between existing animations to generate new ones.
"
444,"Geometric elements and classification of quadrics in rational B\'ezier
  form","  In this paper we classify and derive closed formulas for geometric elements
of quadrics in rational B\'ezier triangular form (such as the center, the conic
at infinity, the vertex and the axis of paraboloids and the principal planes),
using just the control vertices and the weights for the quadric patch. The
results are extended also to quadric tensor product patches. Our results rely
on using techniques from projective algebraic geometry to find suitable
bilinear forms for the quadric in a coordinate-free fashion, considering a
pencil of quadrics that are tangent to the given quadric along a conic. Most of
the information about the quadric is encoded in one coefficient, involving the
weights of the patch, which allows us to tell apart oval from ruled quadrics.
This coefficient is also relevant to determine the affine type of the quadric.
Spheres and quadrics of revolution are characterised within this framework.
"
445,Gradient-Domain Fusion for Color Correction in Large EM Image Stacks,"  We propose a new gradient-domain technique for processing registered EM image
stacks to remove inter-image discontinuities while preserving intra-image
detail. To this end, we process the image stack by first performing anisotropic
smoothing along the slice axis and then solving a Poisson equation within each
slice to re-introduce the detail. The final image stack is continuous across
the slice axis and maintains sharp details within each slice. Adapting existing
out-of-core techniques for solving the linear system, we describe a parallel
algorithm with time complexity that is linear in the size of the data and space
complexity that is sub-linear, allowing us to process datasets as large as five
teravoxels with a 600 MB memory footprint.
"
446,"Pushing the Limits of 3D Color Printing: Error Diffusion with
  Translucent Materials","  Accurate color reproduction is important in many applications of 3D printing,
from design prototypes to 3D color copies or portraits. Although full color is
available via other technologies, multi-jet printers have greater potential for
graphical 3D printing, in terms of reproducing complex appearance properties.
However, to date these printers cannot produce full color, and doing so poses
substantial technical challenges, from the shear amount of data to the
translucency of the available color materials. In this paper, we propose an
error diffusion halftoning approach to achieve full color with multi-jet
printers, which operates on multiple isosurfaces or layers within the object.
We propose a novel traversal algorithm for voxel surfaces, which allows the
transfer of existing error diffusion algorithms from 2D printing. The resulting
prints faithfully reproduce colors, color gradients and fine-scale details.
"
447,Reviewing Data Visualization: an Analytical Taxonomical Study,"  This paper presents an analytical taxonomy that can suitably describe, rather
than simply classify, techniques for data presentation. Unlike previous works,
we do not consider particular aspects of visualization techniques, but their
mechanisms and foundational vision perception. Instead of just adjusting
visualization research to a classification system, our aim is to better
understand its process. For doing so, we depart from elementary concepts to
reach a model that can describe how visualization techniques work and how they
convey meaning.
"
448,"A Clustering Based Approach for Realistic and Efficient Data-Driven
  Crowd Simulation","  In this paper, we present a data-driven approach to generate realistic
steering behaviors for virtual crowds in crowd simulation. We take advantage of
both rule-based models and data-driven models by applying the interaction
patterns discovered from crowd videos. Unlike existing example-based models in
which current states are matched to states extracted from crowd videos
directly, our approach adopts a hierarchical mechanism to generate the steering
behaviors of agents. First, each agent is classified into one of the
interaction patterns that are automatically discovered from crowd video before
simulation. Then the most matched action is selected from the associated
interaction pattern to generate the steering behaviors of the agent. By doing
so, agents can avoid performing a simple state matching as in the traditional
example-based approaches, and can perform a wider variety of steering behaviors
as well as mimic the cognitive process of pedestrians. Simulation results on
scenarios with different crowd densities and main motion directions demonstrate
that our approach performs better than two state-of-the-art simulation models,
in terms of prediction accuracy. Besides, our approach is efficient enough to
run at interactive rates in real time simulation.
"
449,"A Novel Semantics and Feature Preserving Perspective for Content Aware
  Image Retargeting","  There is an increasing requirement for efficient image retargeting techniques
to adapt the content to various forms of digital media. With rapid growth of
mobile communications and dynamic web page layouts, one often needs to resize
the media content to adapt to the desired display sizes. For various layouts of
web pages and typically small sizes of handheld portable devices, the
importance in the original image content gets obfuscated after resizing it with
the approach of uniform scaling. Thus, there occurs a need for resizing the
images in a content aware manner which can automatically discard irrelevant
information from the image and present the salient features with more
magnitude. There have been proposed some image retargeting techniques keeping
in mind the content awareness of the input image. However, these techniques
fail to prove globally effective for various kinds of images and desired sizes.
The major problem is the inefficiency of these algorithms to process these
images with minimal visual distortion while also retaining the meaning conveyed
from the image. In this dissertation, we present a novel perspective for
content aware image retargeting, which is well implementable in real time. We
introduce a novel method of analysing semantic information within the input
image while also maintaining the important and visually significant features.
We present the various nuances of our algorithm mathematically and logically,
and show that the results prove better than the state-of-the-art techniques.
"
450,Graph-based compression of dynamic 3D point cloud sequences,"  This paper addresses the problem of compression of 3D point cloud sequences
that are characterized by moving 3D positions and color attributes. As
temporally successive point cloud frames are similar, motion estimation is key
to effective compression of these sequences. It however remains a challenging
problem as the point cloud frames have varying numbers of points without
explicit correspondence information. We represent the time-varying geometry of
these sequences with a set of graphs, and consider 3D positions and color
attributes of the points clouds as signals on the vertices of the graphs. We
then cast motion estimation as a feature matching problem between successive
graphs. The motion is estimated on a sparse set of representative vertices
using new spectral graph wavelet descriptors. A dense motion field is
eventually interpolated by solving a graph-based regularization problem. The
estimated motion is finally used for removing the temporal redundancy in the
predictive coding of the 3D positions and the color characteristics of the
point cloud sequences. Experimental results demonstrate that our method is able
to accurately estimate the motion between consecutive frames. Moreover, motion
estimation is shown to bring significant improvement in terms of the overall
compression performance of the sequence. To the best of our knowledge, this is
the first paper that exploits both the spatial correlation inside each frame
(through the graph) and the temporal correlation between the frames (through
the motion estimation) to compress the color and the geometry of 3D point cloud
sequences in an efficient way.
"
451,The 12 prophets dataset,"  The ""Ajeijadinho 3D"" project is an initiative supported by the University of
S\~ao Paulo (Museum of Science and Dean of Culture and Extension), which
involves the 3D digitization of art works of Brazilian sculptor Antonio
Francisco Lisboa, better known as Aleijadinho. The project made use of advanced
acquisition and processing of 3D meshes for preservation and dissemination of
the cultural heritage. The dissemination occurs through a Web portal, so that
the population has the opportunity to meet the art works in detail using 3D
visualization and interaction. The portal address is
http://www.aleijadinho3d.icmc.usp.br. The 3D acquisitions were conducted over a
week at the end of July 2013 in the cities of Ouro Preto, MG, Brazil and
Congonhas do Campo, MG, Brazil. The scanning was done with a special equipment
supplied by company Leica Geosystems, which allowed the work to take place at
distances between 10 and 30 meters, defining a non-invasive procedure,
simplified logistics, and without the need for preparation or isolation of the
sites. In Ouro Preto, we digitized the churches of Francisco of Assis, Our Lady
of Carmo, and Our Lady of Mercy; in Congonhas do Campo we scanned the entire
Sanctuary of Bom Jesus de Matosinhos and his 12 prophets. Once scanned, the art
works went through a long process of preparation, which required careful
handling of meshes done by experts from the University of S\~ao Paulo in
partnership with company Imprimate.
"
452,A Borsuk-Ulam theorem for digital images,"  The Borsuk-Ulam theorem states that a continuous function $f:S^n \to \R^n$
has a point $x\in S^n$ with $f(x)=f(-x)$. We give an analogue of this theorem
for digital images, which are modeled as discrete spaces of adjacent pixels
equipped with $\Z^n$-valued functions.
  In particular, for a concrete two-dimensional rectangular digital image whose
pixels all have an assigned ""brightness"" function, we prove that there must
exist a pair of opposite boundary points whose brightnesses are approximately
equal. This theorem applies generally to any integer-valued function on an
abstract simple graph.
  We also discuss generalizations to digital images of dimension 3 and higher.
We give some partial results for higher dimensional images, and show a counter
example which demonstrates that the full results obtained in lower dimensions
cannot hold generally.
"
453,"3D Geometric Analysis of Tubular Objects based on Surface Normal
  Accumulation","  This paper proposes a simple and efficient method for the reconstruction and
extraction of geometric parameters from 3D tubular objects. Our method
constructs an image that accumulates surface normal information, then peaks
within this image are located by tracking. Finally, the positions of these are
optimized to lie precisely on the tubular shape centerline. This method is very
versatile, and is able to process various input data types like full or partial
mesh acquired from 3D laser scans, 3D height map or discrete volumetric images.
The proposed algorithm is simple to implement, contains few parameters and can
be computed in linear time with respect to the number of surface faces. Since
the extracted tube centerline is accurate, we are able to decompose the tube
into rectilinear parts and torus-like parts. This is done with a new linear
time 3D torus detection algorithm, which follows the same principle of a
previous work on 2D arc circle recognition. Detailed experiments show the
versatility, accuracy and robustness of our new method.
"
454,"Fairy Lights in Femtoseconds: Aerial and Volumetric Graphics Rendered by
  Focused Femtosecond Laser Combined with Computational Holographic Fields","  We present a method of rendering aerial and volumetric graphics using
femtosecond lasers. A high-intensity laser excites a physical matter to emit
light at an arbitrary 3D position. Popular applications can then be explored
especially since plasma induced by a femtosecond laser is safer than that
generated by a nanosecond laser. There are two methods of rendering graphics
with a femtosecond laser in air: Producing holograms using spatial light
modulation technology, and scanning of a laser beam by a galvano mirror. The
holograms and workspace of the system proposed here occupy a volume of up to 1
cm^3; however, this size is scalable depending on the optical devices and their
setup. This paper provides details of the principles, system setup, and
experimental evaluation, and discussions on scalability, design space, and
applications of this system. We tested two laser sources: an adjustable (30-100
fs) laser which projects up to 1,000 pulses per second at energy up to 7 mJ per
pulse, and a 269-fs laser which projects up to 200,000 pulses per second at an
energy up to 50 uJ per pulse. We confirmed that the spatiotemporal resolution
of volumetric displays, implemented with these laser sources, is 4,000 and
200,000 dots per second. Although we focus on laser-induced plasma in air, the
discussion presented here is also applicable to other rendering principles such
as fluorescence and microbubble in solid/liquid materials.
"
455,GraphMaps: Browsing Large Graphs as Interactive Maps,"  Algorithms for laying out large graphs have seen significant progress in the
past decade. However, browsing large graphs remains a challenge. Rendering
thousands of graphical elements at once often results in a cluttered image, and
navigating these elements naively can cause disorientation. To address this
challenge we propose a method called GraphMaps, mimicking the browsing
experience of online geographic maps.
  GraphMaps creates a sequence of layers, where each layer refines the previous
one. During graph browsing, GraphMaps chooses the layer corresponding to the
zoom level, and renders only those entities of the layer that intersect the
current viewport. The result is that, regardless of the graph size, the number
of entities rendered at each view does not exceed a predefined threshold, yet
all graph elements can be explored by the standard zoom and pan operations.
  GraphMaps preprocesses a graph in such a way that during browsing, the
geometry of the entities is stable, and the viewer is responsive. Our case
studies indicate that GraphMaps is useful in gaining an overview of a large
graph, and also in exploring a graph on a finer level of detail.
"
456,Modeling and Correspondence of Topologically Complex 3D Shapes,"  3D shape creation and modeling remains a challenging task especially for
novice users. Many methods in the field of computer graphics have been proposed
to automate the often repetitive and precise operations needed during the
modeling of detailed shapes. This report surveys different approaches of shape
modeling and correspondence especially for shapes exhibiting topological
complexity. We focus on methods designed to help generate or process shapes
with large number of interconnected components often found in man-made shapes.
We first discuss a variety of modeling techniques, that leverage existing
shapes, in easy to use creative modeling systems. We then discuss possible
correspondence strategies for topologically different shapes as it is a
requirement for such systems. Finally, we look at different shape
representations and tools that facilitate the modification of shape topology
and we focus on those particularly useful in free-form 3D modeling.
"
457,"A Survey on Distributed Visualization Techniques over Clusters of
  Personal Computers","  In the last years, Distributed Visualization over Personal Computer (PC)
clusters has become important for research and industrial communities. They
have made large-scale visualizations practical and more accessible. In this
work we survey Distributed Visualization techniques aiming at compiling last
decade's literature on the use of PC clusters as suitable alternatives to
high-end workstations. We review the topic by defining basic concepts,
enumerating system requirements and implementation challenges, and presenting
up-to-date methodologies. Our work fulfills the needs of newcomers and seasoned
professionals as an introductory compilation at the same time that it can help
experienced personnel by organizing ideas.
"
458,The Vector Space of Convex Curves: How to Mix Shapes,"  We present a novel, log-radius profile representation for convex curves and
define a new operation for combining the shape features of curves. Unlike the
standard, angle profile-based methods, this operation accurately combines the
shape features in a visually intuitive manner. This method have implications in
shape analysis as well as in investigating how the brain perceives and
generates curved shapes and motions.
"
459,Ebb: A DSL for Physical Simulation on CPUs and GPUs,"  Designing programming environments for physical simulation is challenging
because simulations rely on diverse algorithms and geometric domains. These
challenges are compounded when we try to run efficiently on heterogeneous
parallel architectures. We present Ebb, a domain-specific language (DSL) for
simulation, that runs efficiently on both CPUs and GPUs. Unlike previous DSLs,
Ebb uses a three-layer architecture to separate (1) simulation code, (2)
definition of data structures for geometric domains, and (3) runtimes
supporting parallel architectures. Different geometric domains are implemented
as libraries that use a common, unified, relational data model. By structuring
the simulation framework in this way, programmers implementing simulations can
focus on the physics and algorithms for each simulation without worrying about
their implementation on parallel computers. Because the geometric domain
libraries are all implemented using a common runtime based on relations, new
geometric domains can be added as needed, without specifying the details of
memory management, mapping to different parallel architectures, or having to
expand the runtime's interface.
  We evaluate Ebb by comparing it to several widely used simulations,
demonstrating comparable performance to hand-written GPU code where available,
and surpassing existing CPU performance optimizations by up to 9$\times$ when
no GPU code exists.
"
460,"Combining Visual Analytics and Content Based Data Retrieval Technology
  for Efficient Data Analysis","  One of the most useful techniques to help visual data analysis systems is
interactive filtering (brushing). However, visualization techniques often
suffer from overlap of graphical items and multiple attributes complexity,
making visual selection inefficient. In these situations, the benefits of data
visualization are not fully observable because the graphical items do not pop
up as comprehensive patterns. In this work we propose the use of content-based
data retrieval technology combined with visual analytics. The idea is to use
the similarity query functionalities provided by metric space systems in order
to select regions of the data domain according to user-guidance and interests.
After that, the data found in such regions feed multiple visualization
workspaces so that the user can inspect the correspondent datasets. Our
experiments showed that the methodology can break the visual analysis process
into smaller problems (views) and that the views hold the expectations of the
analyst according to his/her similarity query selection, improving data
perception and analytical possibilities. Our contribution introduces a
principle that can be used in all sorts of visualization techniques and
systems, this principle can be extended with different kinds of integration
visualization-metric-space, and with different metrics, expanding the
possibilities of visual data analysis in aspects such as semantics and
scalability.
"
461,On the Approximation Theory of Linear Variational Subspace Design,"  Solving large-scale optimization on-the-fly is often a difficult task for
real-time computer graphics applications. To tackle this challenge, model
reduction is a well-adopted technique. Despite its usefulness, model reduction
often requires a handcrafted subspace that spans a domain that hypothetically
embodies desirable solutions. For many applications, obtaining such subspaces
case-by-case either is impossible or requires extensive human labors, hence
does not readily have a scalable solution for growing number of tasks. We
propose linear variational subspace design for large-scale constrained
quadratic programming, which can be computed automatically without any human
interventions. We provide meaningful approximation error bound that
substantiates the quality of calculated subspace, and demonstrate its empirical
success in interactive deformable modeling for triangular and tetrahedral
meshes.
"
462,Lens Factory: Automatic Lens Generation Using Off-the-shelf Components,"  Custom optics is a necessity for many imaging applications. Unfortunately,
custom lens design is costly (thousands to tens of thousands of dollars), time
consuming (10-12 weeks typical lead time), and requires specialized optics
design expertise. By using only inexpensive, off-the-shelf lens components the
Lens Factory automatic design system greatly reduces cost and time. Design,
ordering of parts, delivery, and assembly can be completed in a few days, at a
cost in the low hundreds of dollars. Lens design constraints, such as focal
length and field of view, are specified in terms familiar to the graphics
community so no optics expertise is necessary. Unlike conventional lens design
systems, which only use continuous optimization methods, Lens Factory adds a
discrete optimization stage. This stage searches the combinatorial space of
possible combinations of lens elements to find novel designs, evolving simple
canonical lens designs into more complex, better designs. Intelligent pruning
rules make the combinatorial search feasible. We have designed and built
several high performance optical systems which demonstrate the practicality of
the system.
"
463,Aging display's effect on interpretation of digital pathology slides,"  It is our conjecture that the variability of colors in a pathology image
effects the interpretation of pathology cases, whether it is diagnostic
accuracy, diagnostic confidence, or workflow efficiency. In this paper, digital
pathology images are analyzed to quantify the perceived difference in color
that occurs due to display aging, in particular a change in the maximum
luminance, white point, and color gamut. The digital pathology images studied
include diagnostically important features, such as the conspicuity of nuclei.
Three different display aging models are applied to images: aging of luminance
& chrominance, aging of chrominance only, and a stabilized luminance &
chrominance (i.e., no aging). These display models and images are then used to
compare conspicuity of nuclei using CIE deltaE2000, a perceptual color
difference metric. The effect of display aging using these display models and
images is further analyzed through a human reader study designed to quantify
the effects from a clinical perspective. Results from our reader study indicate
significant impact of aged displays on workflow as well as diagnosis as follow.
As compared to the originals (no-aging), slides with the effect of aging
simulated were significantly more difficult to read (p-value of 0.0005) and
took longer to score (p-value of 0.02). Moreover, luminance+chrominance aging
significantly reduced inter-session percent agreement of diagnostic scores
(p-value of 0.0418).
"
464,"A Hybrid Graph-drawing Algorithm for Large, Naturally-clustered,
  Disconnected Graphs","  In this paper, we present a hybrid graph-drawing algorithm (GDA) for
layouting large, naturally-clustered, disconnected graphs. We called it a
hybrid algorithm because it is an implementation of a series of already known
graph-drawing and graph-theoretic procedures. We remedy in this hybrid the
problematic nature of the current force-based GDA which has the inability to
scale to large, naturally-clustered, and disconnected graphs. These kinds of
graph usually model the complex inter-relationships among entities in social,
biological, natural, and artificial networks. Obviously, the hybrid runs longer
than the current GDAs. By using two extreme cases of graphs as inputs, we
present in this paper the derivation of the time complexity of the hybrid which
we found to be $O(|\V|^3)$.
"
465,Meshfree C^2-Weighting for Shape Deformation,"  Handle-driven deformation based on linear blending is widely used in many
applications because of its merits in intuitiveness, efficiency and easiness of
implementation. We provide a meshfree method to compute the smooth weights of
linear blending for shape deformation. The C2-continuity of weighting is
guaranteed by the carefully formulated basis functions, with which the
computation of weights is in a closed-form. Criteria to ensure the quality of
deformation are preserved by the basis functions after decomposing the shape
domain according to the Voronoi diagram of handles. The cost of inserting a new
handle is only the time to evaluate the distances from the new handle to all
sample points in the space of deformation. Moreover, a virtual handle insertion
algorithm has been developed to allow users freely placing handles while
preserving the criteria on weights. Experimental examples for real-time 2D/3D
deformations are shown to demonstrate the effectiveness of this method.
"
466,A Closed-Form Formulation of HRBF-Based Surface Reconstruction,"  The Hermite radial basis functions (HRBFs) implicits have been used to
reconstruct surfaces from scattered Hermite data points. In this work, we
propose a closed-form formulation to construct HRBF-based implicits by a
quasi-solution approximating the exact solution. A scheme is developed to
automatically adjust the support sizes of basis functions to hold the error
bound of a quasi-solution. Our method can generate an implicit function from
positions and normals of scattered points without taking any global operation.
Working together with an adaptive sampling algorithm, the HRBF-based implicits
can also reconstruct surfaces from point clouds with non-uniformity and noises.
Robust and efficient reconstruction has been observed in our experimental tests
on real data captured from a variety of scenes.
"
467,On Smooth 3D Frame Field Design,"  We analyze actual methods that generate smooth frame fields both in 2D and in
3D. We formalize the 2D problem by representing frames as functions (as it was
done in 3D), and show that the derived optimization problem is the one that
previous work obtain via ""representation vectors."" We show (in 2D) why this non
linear optimization problem is easier to solve than directly minimizing the
rotation angle of the field, and observe that the 2D algorithm is able to find
good fields.
  Now, the 2D and the 3D optimization problems are derived from the same
formulation (based on representing frames by functions). Their energies share
some similarities from an optimization point of view (smoothness, local minima,
bounds of partial derivatives, etc.), so we applied the 2D resolution mechanism
to the 3D problem. Our evaluation of all existing 3D methods suggests to
initialize the field by this new algorithm, but possibly use another method for
further smoothing.
"
468,"A de Casteljau Algorithm for Bernstein type Polynomials based on
  (p,q)-integers","  In this paper, a de Casteljau algorithm to compute (p,q)-Bernstein Bezier
curves based on (p,q)-integers is introduced. We study the nature of degree
elevation and degree reduction for (p,q)-Bezier Bernstein functions. The new
curves have some properties similar to q-Bezier curves. Moreover, we construct
the corresponding tensor product surfaces over the rectangular domain (u, v)
\in [0, 1] \times [0, 1] depending on four parameters. We also study the de
Casteljau algorithm and degree evaluation properties of the surfaces for these
generalization over the rectangular domain. Furthermore, some fundamental
properties for (p,q)-Bernstein Bezier curves are discussed. We get q-Bezier
curves and surfaces for (u, v) \in [0, 1] \times [0, 1] when we set the
parameter p1 = p2 = 1.
"
469,GPU-based visualization of domain-coloured algebraic Riemann surfaces,"  We examine an algorithm for the visualization of domain-coloured Riemann
surfaces of plane algebraic curves. The approach faithfully reproduces the
topology and the holomorphic structure of the Riemann surface. We discuss how
the algorithm can be implemented efficiently in OpenGL with geometry shaders,
and (less efficiently) even in WebGL with multiple render targets and floating
point textures. While the generation of the surface takes noticeable time in
both implementations, the visualization of a cached Riemann surface mesh is
possible with interactive performance. This allows us to visually explore
otherwise almost unimaginable mathematical objects. As examples, we look at the
complex square root and the folium of Descartes. For the folium of Descartes,
the visualization reveals features of the algebraic curve which are not obvious
from its equation.
"
470,A concise parametrisation of affine transformation,"  Good parametrisations of affine transformations are essential to
interpolation, deformation, and analysis of shape, motion, and animation. It
has been one of the central research topics in computer graphics. However,
there is no single perfect method and each one has both advantages and
disadvantages. In this paper, we propose a novel parametrisation of affine
transformations, which is a generalisation to or an improvement of existing
methods. Our method adds yet another choice to the existing toolbox and shows
better performance in some applications. A C++ implementation is available to
make our framework ready to use in various applications.
"
471,A Hyperelastic Two-Scale Optimization Model for Shape Matching,"  We suggest a novel shape matching algorithm for three-dimensional surface
meshes of disk or sphere topology. The method is based on the physical theory
of nonlinear elasticity and can hence handle large rotations and deformations.
Deformation boundary conditions that supplement the underlying equations are
usually unknown. Given an initial guess, these are optimized such that the
mechanical boundary forces that are responsible for the deformation are of a
simple nature. We show a heuristic way to approximate the nonlinear
optimization problem by a sequence of convex problems using finite elements.
The deformation cost, i.e, the forces, is measured on a coarse scale while
ICP-like matching is done on the fine scale. We demonstrate the plausibility of
our algorithm on examples taken from different datasets.
"
472,"Agglomerative clustering and collectiveness measure via exponent
  generating function","  The key in agglomerative clustering is to define the affinity measure between
two sets. A novel agglomerative clustering method is proposed by utilizing the
path integral to define the affinity measure. Firstly, the path integral
descriptor of an edge, a node and a set is computed by path integral and
exponent generating function. Then, the affinity measure between two sets is
obtained by path integral descriptor of sets. Several good properties of the
path integral descriptor is proposed in this paper. In addition, we give the
physical interpretation of the proposed path integral descriptor of a set. The
proposed path integral descriptor of a set can be regard as the collectiveness
measure of a set, which can be a moving system such as human crowd, sheep herd
and so on. Self-driven particle (SDP) model is used to test the ability of the
proposed method in measuring collectiveness.
"
473,"A Linear Formulation for Disk Conformal Parameterization of
  Simply-Connected Open Surfaces","  Surface parameterization is widely used in computer graphics and geometry
processing. It simplifies challenging tasks such as surface registrations,
morphing, remeshing and texture mapping. In this paper, we present an efficient
algorithm for computing the disk conformal parameterization of simply-connected
open surfaces. A double covering technique is used to turn a simply-connected
open surface into a genus-0 closed surface, and then a fast algorithm for
parameterization of genus-0 closed surfaces can be applied. The symmetry of the
double covered surface preserves the efficiency of the computation. A planar
parameterization can then be obtained with the aid of a M\""obius transformation
and the stereographic projection. After that, a normalization step is applied
to guarantee the circular boundary. Finally, we achieve a bijective disk
conformal parameterization by a composition of quasi-conformal mappings.
Experimental results demonstrate a significant improvement in the computational
time by over 60%. At the same time, our proposed method retains comparable
accuracy, bijectivity and robustness when compared with the state-of-the-art
approaches. Applications to texture mapping are presented for illustrating the
effectiveness of our proposed algorithm.
"
474,"Inappropriate use of L-BFGS, Illustrated on frame field design","  L-BFGS is a hill climbing method that is guarantied to converge only for
convex problems. In computer graphics, it is often used as a black box solver
for a more general class of non linear problems, including problems having many
local minima. Some works obtain very nice results by solving such difficult
problems with L-BFGS. Surprisingly, the method is able to escape local minima:
our interpretation is that the approximation of the Hessian is smoother than
the real Hessian, making it possible to evade the local minima. We analyse the
behavior of L-BFGS on the design of 2D frame fields. It involves an energy
function that is infinitly continuous, strongly non linear and having many
local minima. Moreover, the local minima have a clear visual interpretation:
they corresponds to differents frame field topologies. We observe that the
performances of LBFGS are almost unpredictables: they are very competitive when
the field is sampled on the primal graph, but really poor when they are sampled
on the dual graph.
"
475,Light-field Microscopy with a Consumer Light-field Camera,"  We explore the use of inexpensive consumer light- field camera technology for
the purpose of light-field mi- croscopy. Our experiments are based on the Lytro
(first gen- eration) camera. Unfortunately, the optical systems of the Lytro
and those of microscopes are not compatible, lead- ing to a loss of light-field
information due to angular and spatial vignetting when directly recording
microscopic pic- tures. We therefore consider an adaptation of the Lytro op-
tical system. We demonstrate that using the Lytro directly as an oc- ular
replacement, leads to unacceptable spatial vignetting. However, we also found a
setting that allows the use of the Lytro camera in a virtual imaging mode which
prevents the information loss to a large extent. We analyze the new vir- tual
imaging mode and use it in two different setups for im- plementing light-field
microscopy using a Lytro camera. As a practical result, we show that the camera
can be used for low magnification work, as e.g. common in quality control,
surface characterization, etc. We achieve a maximum spa- tial resolution of
about 6.25{\mu}m, albeit at a limited SNR for the side views.
"
476,Borobudur was Built Algorithmically,"  The self-similarity of Indonesian Borobudur Temple is observed through the
dimensionality of stupa that is hypothetically closely related to whole
architectural body. Fractal dimension is calculated by using the cube counting
method and found that the dimension is 2.325, which is laid between the
two-dimensional plane and three dimensional space. The applied fractal geometry
and self-similarity of the building is emerged as the building process
implement the metric rules, since there is no universal metric standard known
in ancient traditional Javanese culture thus the architecture is not based on
final master plan. The paper also proposes how the hypothetical algorithmic
architecture might be applied computationally in order to see some experimental
generations of similar building. The paper ends with some conjectures for
further challenge and insights related to fractal geometry in Javanese
traditional cultural heritages.
"
477,3D-Computer Animation for a Yoruba Native Folktale,"  Computer graphics has wide range of applications which are implemented into
computer animation, computer modeling among others. Since the invention of
computer graphics researchers have not paid much of attentions toward the
possibility of converting oral tales otherwise known as folktales into possible
cartoon animated videos. This paper is based on how to develop cartoons of
local folktales that will be of huge benefits to Nigerians. The activities were
divided into 5 stages; analysis, design, development, implementation and
evaluation which involved various processes and use of various specialized
software and hardware. After the implementation of this project, the video
characteristics were evaluated using likert scale. Analysis of 30 user
responses indicated that 17 users (56.7 percent) rated the image quality as
excellent, the video and image synchronization was rated as excellent by 9
users (30 percent), the Background noise was rated excellent by 18 users (60
percent), the Character Impression was rated Excellent by 11 users (36.67
percent), the general assessment of the storyline was rated excellent by 17
users (56.7 percent), the video Impression was rated excellent by 11 users
(36.67 percent) and the voice quality was rated by 10 users (33.33 percent) as
excellent.
"
478,"High-Contrast Color-Stripe Pattern for Rapid Structured-Light Range
  Imaging","  For structured-light range imaging, color stripes can be used for increasing
the number of distinguishable light patterns compared to binary BW stripes.
Therefore, an appropriate use of color patterns can reduce the number of light
projections and range imaging is achievable in single video frame or in ""one
shot"". On the other hand, the reliability and range resolution attainable from
color stripes is generally lower than those from multiply projected binary BW
patterns since color contrast is affected by object color reflectance and
ambient light. This paper presents new methods for selecting stripe colors and
designing multiple-stripe patterns for ""one-shot"" and ""two-shot"" imaging. We
show that maximizing color contrast between the stripes in one-shot imaging
reduces the ambiguities resulting from colored object surfaces and limitations
in sensor/projector resolution. Two-shot imaging adds an extra video frame and
maximizes the color contrast between the first and second video frames to
diminish the ambiguities even further. Experimental results demonstrate the
effectiveness of the presented one-shot and two-shot color-stripe imaging
schemes.
"
479,"BREN: Body Reflection Essence-Neuter Model for Separation of Reflection
  Components","  We propose a novel reflection color model consisting of body essence and
(mixed) neuter, and present an effective method for separating dichromatic
reflection components using a single image. Body essence is an entity invariant
to interface reflection, and has two degrees of freedom unlike hue and maximum
chromaticity. As a result, the proposed method is insensitive to noise and
proper for colors around CMY (cyan, magenta, and yellow) as well as RGB (red,
green, and blue), contrary to the maximum chromaticity-based methods. Interface
reflection is separated by using a Gaussian function, which removes a critical
thresholding problem. Furthermore, the method does not require any region
segmentation. Experimental results show the efficacy of the proposed model and
method.
"
480,"PolyDepth: Real-time Penetration Depth Computation using Iterative
  Contact-Space Projection","  We present a real-time algorithm that finds the Penetration Depth (PD)
between general polygonal models based on iterative and local optimization
techniques. Given an in-collision configuration of an object in configuration
space, we find an initial collision-free configuration using several methods
such as centroid difference, maximally clear configuration, motion coherence,
random configuration, and sampling-based search. We project this configuration
on to a local contact space using a variant of continuous collision detection
algorithm and construct a linear convex cone around the projected
configuration. We then formulate a new projection of the in-collision
configuration onto the convex cone as a Linear Complementarity Problem (LCP),
which we solve using a type of Gauss-Seidel iterative algorithm. We repeat this
procedure until a locally optimal PD is obtained. Our algorithm can process
complicated models consisting of tens of thousands triangles at interactive
rates.
"
481,Spherical Conformal Parameterization of Genus-0 Point Clouds for Meshing,"  Point cloud is the most fundamental representation of 3D geometric objects.
Analyzing and processing point cloud surfaces is important in computer graphics
and computer vision. However, most of the existing algorithms for surface
analysis require connectivity information. Therefore, it is desirable to
develop a mesh structure on point clouds. This task can be simplified with the
aid of a parameterization. In particular, conformal parameterizations are
advantageous in preserving the geometric information of the point cloud data.
In this paper, we extend a state-of-the-art spherical conformal
parameterization algorithm for genus-0 closed meshes to the case of point
clouds, using an improved approximation of the Laplace-Beltrami operator on
data points. Then, we propose an iterative scheme called the North-South
reiteration for achieving a spherical conformal parameterization. A balancing
scheme is introduced to enhance the distribution of the spherical
parameterization. High quality triangulations and quadrangulations can then be
built on the point clouds with the aid of the parameterizations. Also, the
meshes generated are guaranteed to be genus-0 closed meshes. Moreover, using
our proposed spherical conformal parameterization, multilevel representations
of point clouds can be easily constructed. Experimental results demonstrate the
effectiveness of our proposed framework.
"
482,"The Prose Storyboard Language: A Tool for Annotating and Directing
  Movies","  The prose storyboard language is a formal language for describing movies shot
by shot, where each shot is described with a unique sentence. The language uses
a simple syntax and limited vocabulary borrowed from working practices in
traditional movie-making, and is intended to be readable both by machines and
humans. The language is designed to serve as a high-level user interface for
intelligent cinematography and editing systems.
"
483,Multi-Projector Color Structured-Light Vision,"  Research interest in rapid structured-light imaging has grown increasingly
for the modeling of moving objects, and a number of methods have been suggested
for the range capture in a single video frame. The imaging area of a 3D object
using a single projector is restricted since the structured light is projected
only onto a limited area of the object surface. Employing additional projectors
to broaden the imaging area is a challenging problem since simultaneous
projection of multiple patterns results in their superposition in the
light-intersected areas and the recognition of original patterns is by no means
trivial. This paper presents a novel method of multi-projector color
structured-light vision based on projector-camera triangulation. By analyzing
the behavior of superposed-light colors in a chromaticity domain, we show that
the original light colors cannot be properly extracted by the conventional
direct estimation. We disambiguate multiple projectors by multiplexing the
orientations of projector patterns so that the superposed patterns can be
separated by explicit derivative computations. Experimental studies are carried
out to demonstrate the validity of the presented method. The proposed method
increases the efficiency of range acquisition compared to conventional active
stereo using multiple projectors.
"
484,Light Efficient Flutter Shutter,"  Flutter shutter is a technique in which the exposure is chopped into segments
and light is only integrated part of the time. By carefully selecting the
chopping sequence it is possible to better condition the data for
reconstruction problems such as motion deblurring, focal sweeping, and
compressed sensing. The partial exposure trades better conditioning for less
energy. In problems such as motion deblurring the available energy is what
caused the problem in the first place (as strong illumination allows short
exposure thus eliminates motion blur). It is still beneficial because the
benefit from the better conditioning outweighs the cost in energy.
  This documents is focused on light efficient flutter shutter that provides
better conditioning and better energy utilization than conventional flutter
shutter.
"
485,Decomposing Digital Paintings into Layers via RGB-space Geometry,"  In digital painting software, layers organize paintings. However, layers are
not explicitly represented, transmitted, or published with the final digital
painting. We propose a technique to decompose a digital painting into layers.
In our decomposition, each layer represents a coat of paint of a single paint
color applied with varying opacity throughout the image. Our decomposition is
based on the painting's RGB-space geometry. In RGB-space, a geometric structure
is revealed due to the linear nature of the standard Porter-Duff ""over"" pixel
compositing operation. The vertices of the convex hull of pixels in RGB-space
suggest paint colors. Users choose the degree of simplification to perform on
the convex hull, as well as a layer order for the colors. We solve a
constrained optimization problem to find maximally translucent, spatially
coherent opacity for each layer, such that the composition of the layers
reproduces the original image. We demonstrate the utility of the resulting
decompositions for re-editing.
"
486,Good Colour Maps: How to Design Them,"  Many colour maps provided by vendors have highly uneven perceptual contrast
over their range. It is not uncommon for colour maps to have perceptual flat
spots that can hide a feature as large as one tenth of the total data range.
Colour maps may also have perceptual discontinuities that induce the appearance
of false features. Previous work in the design of perceptually uniform colour
maps has mostly failed to recognise that CIELAB space is only designed to be
perceptually uniform at very low spatial frequencies. The most important factor
in designing a colour map is to ensure that the magnitude of the incremental
change in perceptual lightness of the colours is uniform. The specific
requirements for linear, diverging, rainbow and cyclic colour maps are
developed in detail. To support this work two test images for evaluating colour
maps are presented. The use of colour maps in combination with relief shading
is considered and the conditions under which colour can enhance or disrupt
relief shading are identified. Finally, a set of new basis colours for the
construction of ternary images are presented. Unlike the RGB primaries these
basis colours produce images whereby the salience of structures are consistent
irrespective of the assignment of basis colours to data channels.
"
487,"Color-Phase Analysis for Sinusoidal Structured Light in Rapid Range
  Imaging","  Active range sensing using structured-light is the most accurate and reliable
method for obtaining 3D information. However, most of the work has been limited
to range sensing of static objects, and range sensing of dynamic (moving or
deforming) objects has been investigated recently only by a few researchers.
Sinusoidal structured-light is one of the well-known optical methods for 3D
measurement. In this paper, we present a novel method for rapid high-resolution
range imaging using color sinusoidal pattern. We consider the real-world
problem of nonlinearity and color-band crosstalk in the color light projector
and color camera, and present methods for accurate recovery of color-phase. For
high-resolution ranging, we use high-frequency patterns and describe new
unwrapping algorithms for reliable range recovery. The experimental results
demonstrate the effectiveness of our methods.
"
488,Humans Are Easily Fooled by Digital Images,"  Digital images are ubiquitous in our modern lives, with uses ranging from
social media to news, and even scientific papers. For this reason, it is
crucial evaluate how accurate people are when performing the task of identify
doctored images. In this paper, we performed an extensive user study evaluating
subjects capacity to detect fake images. After observing an image, users have
been asked if it had been altered or not. If the user answered the image has
been altered, he had to provide evidence in the form of a click on the image.
We collected 17,208 individual answers from 383 users, using 177 images
selected from public forensic databases. Different from other previously
studies, our method propose different ways to avoid lucky guess when evaluating
users answers. Our results indicate that people show inaccurate skills at
differentiating between altered and non-altered images, with an accuracy of
58%, and only identifying the modified images 46.5% of the time. We also track
user features such as age, answering time, confidence, providing deep analysis
of how such variables influence on the users' performance.
"
489,"Elements of Validation of Artificial Lighting through the Software
  CODYRUN: Application to a Test Case of the International Commission on
  Illumination (CIE)","  CODYRUN is a software for computational aeraulic and thermal simulation in
buildings developed by the Laboratory of Building Physics and Systems
(L.P.B.S). Numerical simulation codes of artificial lighting have been
introduced to extend the tool capacity. These calculation codes are able to
predict the amount of light received by any point of a given working plane and
from one or more sources installed on the ceiling of the room. The model used
for these calculations is original and semi-detailed (simplified). The test
case references of the task-3 TC-33 International Commission on Illumination
(CIE) were applied to the software to ensure reliability to properly handle
this photometric aspect. This allowed having a precise idea about the
reliability of the results of numerical simulations.
"
490,Color-Stripe Structured Light Robust to Surface Color and Discontinuity,"  Multiple color stripes have been employed for structured light-based rapid
range imaging to increase the number of uniquely identifiable stripes. The use
of multiple color stripes poses two problems: (1) object surface color may
disturb the stripe color and (2) the number of adjacent stripes required for
identifying a stripe may not be maintained near surface discontinuities such as
occluding boundaries. In this paper, we present methods to alleviate those
problems. Log-gradient filters are employed to reduce the influence of object
colors, and color stripes in two and three directions are used to increase the
chance of identifying correct stripes near surface discontinuities.
Experimental results demonstrate the effectiveness of our methods.
"
491,"Deformation Lamps: A Projection Technique to Make a Static Object
  Dynamic","  Light projection is a powerful technique to edit appearances of objects in
the real world. Based on pixel-wise modification of light transport, previous
techniques have successfully modified static surface properties such as surface
color, dynamic range, gloss and shading. Here, we propose an alternative light
projection technique that adds a variety of illusory, yet realistic distortions
to a wide range of static 2D and 3D projection targets. The key idea of our
technique, named Deformation Lamps, is to project only dynamic luminance
information, which effectively activates the motion (and shape) processing in
the visual system, while preserving the color and texture of the original
object. Although the projected dynamic luminance information is spatially
inconsistent with the color and texture of the target object, the observer's
brain automatically com- bines these sensory signals in such a way as to
correct the inconsistency across visual attributes. We conducted a
psychophysical experiment to investigate the characteristics of the
inconsistency correction, and found that the correction was dependent
critically on the retinal magnitude of inconsistency. Another experiment showed
that perceived magnitude of image deformation by our techniques was
underestimated. The results ruled out the possibility that the effect by our
technique stemmed simply from the physical change of object appearance by light
projection. Finally, we discuss how our techniques can make the observers
perceive a vivid and natural movement, deformation, or oscillation of a variety
of static objects, including drawn pictures, printed photographs, sculptures
with 3D shading, objects with natural textures including human bodies.
"
492,Visualization techniques for the developing chicken heart,"  We present a geometric surface parameterization algorithm and several
visualization techniques adapted to the problem of understanding the 4D
peristaltic-like motion of the outflow tract (OFT) in an embryonic chick heart.
We illustrated the techniques using data from hearts under normal conditions
(four embryos), and hearts in which blood flow conditions are altered through
OFT banding (four embryos). The overall goal is to create quantitative measures
of the temporal heart-shape change both within a single subject and between
multiple subjects. These measures will help elucidate how altering hemodynamic
conditions changes the shape and motion of the OFT walls, which in turn
influence the stresses and strains on the developing heart, causing it to
develop differently. We take advantage of the tubular shape and periodic motion
of the OFT to produce successively lower dimensional visualizations of the
cardiac motion (e.g. curvature, volume, and cross-section) over time, and
quantifications of such visualizations.
"
493,RAID: A Relation-Augmented Image Descriptor,"  As humans, we regularly interpret images based on the relations between image
regions. For example, a person riding object X, or a plank bridging two
objects. Current methods provide limited support to search for images based on
such relations. We present RAID, a relation-augmented image descriptor that
supports queries based on inter-region relations. The key idea of our
descriptor is to capture the spatial distribution of simple point-to-region
relationships to describe more complex relationships between two image regions.
We evaluate the proposed descriptor by querying into a large subset of the
Microsoft COCO database and successfully extract nontrivial images
demonstrating complex inter-region relations, which are easily missed or
erroneously classified by existing methods.
"
494,Procams-Based Cybernetics,"  Procams-based cybernetics is a unique, emerging research field, which aims at
enhancing and supporting our activities by naturally connecting human and
computers/machines as a cooperative integrated system via projector-camera
systems (procams). It rests on various research domains such as
virtual/augmented reality, computer vision, computer graphics, projection
display, human computer interface, human robot interaction and so on. This
laboratory presentation provides a brief history including recent achievements
of our procams-based cybernetics project.
"
495,Printed Perforated Lampshades for Continuous Projective Images,"  We present a technique for designing 3D-printed perforated lampshades, which
project continuous grayscale images onto the surrounding walls. Given the
geometry of the lampshade and a target grayscale image, our method computes a
distribution of tiny holes over the shell, such that the combined footprints of
the light emanating through the holes form the target image on a nearby diffuse
surface. Our objective is to approximate the continuous tones and the spatial
detail of the target image, to the extent possible within the constraints of
the fabrication process.
  To ensure structural integrity, there are lower bounds on the thickness of
the shell, the radii of the holes, and the minimal distances between adjacent
holes. Thus, the holes are realized as thin tubes distributed over the
lampshade surface. The amount of light passing through a single tube may be
controlled by the tube's radius and by its direction (tilt angle). The core of
our technique thus consists of determining a suitable configuration of the
tubes: their distribution across the relevant portion of the lampshade, as well
as the parameters (radius, tilt angle) of each tube. This is achieved by
computing a capacity-constrained Voronoi tessellation over a suitably defined
density function, and embedding a tube inside the maximal inscribed circle of
each tessellation cell. The density function for a particular target image is
derived from a series of simulated images, each corresponding to a different
uniform density tube pattern on the lampshade.
"
496,Surface Approximation via Asymptotic Optimal Geometric Partition,"  In this paper, we present a surface remeshing method with high approximation
quality based on Principal Component Analysis. Given a triangular mesh and a
user assigned polygon/vertex budget, traditional methods usually require the
extra curvature metric field for the desired anisotropy to best approximate the
surface, even though the estimated curvature metric is known to be imperfect
and already self-contained in the surface. In our approach, this anisotropic
control is achieved through the optimal geometry partition without this
explicit metric field. The minimization of our proposed partition energy has
the following properties: Firstly, on a C2 surface, it is theoretically
guaranteed to have the optimal aspect ratio and cluster size as specified in
approximation theory for L1 piecewise linear approximation. Secondly, it
captures sharp features on practical models without any pre-tagging. We develop
an effective merging-swapping framework to seek the optimal partition and
construct polygonal/triangular mesh afterwards. The effectiveness and
efficiency of our method are demonstrated through the comparison with other
state-of-the-art remeshing methods.
"
497,The Theory of Computational Quasi-conformal Geometry on Point Clouds,"  Quasi-conformal (QC) theory is an important topic in complex analysis, which
studies geometric patterns of deformations between shapes. Recently,
computational QC geometry has been developed and has made significant
contributions to medical imaging, computer graphics and computer vision.
Existing computational QC theories and algorithms have been built on
triangulation structures. In practical situations, many 3D acquisition
techniques often produce 3D point cloud (PC) data of the object, which does not
contain connectivity information. It calls for a need to develop computational
QC theories on PCs. In this paper, we introduce the concept of computational QC
geometry on PCs. We define PC quasi-conformal (PCQC) maps and their associated
PC Beltrami coefficients (PCBCs). The PCBC is analogous to the Beltrami
differential in the continuous setting. Theoretically, we show that the PCBC
converges to its continuous counterpart as the density of the PC tends to zero.
We also theoretically and numerically validate the ability of PCBCs to measure
local geometric distortions of PC deformations. With these concepts, many
existing QC based algorithms for geometry processing and shape analysis can be
easily extended to PC data.
"
498,Simulating the Dynamic Behavior of Shear Thickening Fluids,"  While significant research has been dedicated to the simulation of fluids,
not much attention has been given to exploring new interesting behavior that
can be generated with the different types of non-Newtonian fluids with
non-constant viscosity. Going in this direction, this paper introduces a
computational model for simulating the interesting phenomena observed in
non-Newtonian shear thickening fluids, which are fluids where the viscosity
increases with increased stress. These fluids have unique and unconventional
behavior, and they often appear in real world scenarios such as when sinking in
quicksand or when experimenting with popular cornstarch and water mixtures.
While interesting behavior of shear thickening fluids can be easily observed in
the real world, the most interesting phenomena of these fluids have not been
simulated before in computer graphics. The fluid exhibits unique phase changes
between solid and liquid states, great impact resistance in its solid state and
strong hysteresis effects. Our proposed approach builds on existing
non-Newtonian fluid models in computer graphics and introduces an efficient
history-based stiffness term that is essential to produce the most interesting
shear thickening phenomena. The history-based stiffness is formulated through
the use of fractional derivatives, leveraging the fractional calculus ability
to depict both the viscoelastic behavior and the history effects of
history-dependent systems. Simulations produced by our method are compared
against real experiments and the results demonstrate that the proposed model
successfully captures key phenomena observed in shear thickening fluids.
"
499,Computational Network Design from Functional Specifications,"  Connectivity and layout of underlying networks largely determine the behavior
of many environments. For example, transportation networks determine the flow
of traffic in cities, or maps determine the difficulty and flow in games.
Designing such networks from scratch is challenging as even local network
changes can have large global effects. We investigate how to computationally
create networks starting from {\em only} high-level functional specifications.
Such specifications can be in the form of network density, travel time versus
network length, traffic type, destination locations, etc. We propose an integer
programming-based approach that guarantees that the resultant networks are
valid by fulfilling all specified hard constraints, and score favorably in
terms of the objective function. We evaluate our algorithm in three different
design settings (i.e., street layout, floorplanning, and game level design) and
demonstrate, for the first time, that diverse networks can emerge purely from
high-level functional specifications.
"
500,On Intra Prediction for Screen Content Video Coding,"  Screen content coding (SCC) is becoming increasingly important in various
applications, such as desktop sharing, video conferencing, and remote
education. When compared to natural camera- captured content, screen content
has different characteristics, in particular sharper edges. In this paper, we
propose a novel intra prediction scheme for screen content video. In the
proposed scheme, bilinear interpolation in angular intra prediction in HEVC is
selectively replaced by nearest-neighbor intra prediction to preserve the sharp
edges in screen content video. We present three different variants of the
proposed nearest neighbor prediction algorithm: two implicit methods where both
the encoder, and the decoder derive whether to perform nearest neighbor
prediction or not based on either (a) the sum of the absolute difference, or
(b) the difference between the boundary pixels from which prediction is
performed; and another variant where Rate-Distortion-Optimization (RDO) search
is performed at the encoder to decide whether or not to use the nearest
neighbor interpolation, and explicitly signaled to the decoder. We also discuss
the various underlying trade-offs in terms of the complexity of the three
variants. All the three proposed variants provide significant gains over HEVC,
and simulation results show that average gains of 3.3% BD-bitrate in
Intra-frame coding are achieved by the RDO variant for screen content video. To
the best of our knowledge, this is the first paper that 1) points out current
HEVC intra prediction scheme with bilinear interpolation does not work
efficiently for screen content video and 2) uses different filters adaptively
in the HEVC intra prediction interpolation.
"
501,Procedural wood textures,"  Existing bidirectional reflectance distribution function (BRDF) models are
capable of capturing the distinctive highlights produced by the fibrous nature
of wood. However, capturing parameter textures for even a single specimen
remains a laborious process requiring specialized equipment. In this paper we
take a procedural approach to generating parameters for the wood BSDF. We
characterize the elements of trees that are important for the appearance of
wood, discuss techniques appropriate for representing those features, and
present a complete procedural wood shader capable of reproducing the growth
patterns responsible for the distinctive appearance of highly prized
``figured'' wood. Our procedural wood shader is random-access, 3D, modular, and
is fast enough to generate a preview for design.
"
502,Graph-based denoising for time-varying point clouds,"  Noisy 3D point clouds arise in many applications. They may be due to errors
when constructing a 3D model from images or simply to imprecise depth sensors.
Point clouds can be given geometrical structure using graphs created from the
similarity information between points. This paper introduces a technique that
uses this graph structure and convex optimization methods to denoise 3D point
clouds. A short discussion presents how those methods naturally generalize to
time-varying inputs such as 3D point cloud time series.
"
503,Dense Human Body Correspondences Using Convolutional Networks,"  We propose a deep learning approach for finding dense correspondences between
3D scans of people. Our method requires only partial geometric information in
the form of two depth maps or partial reconstructed surfaces, works for humans
in arbitrary poses and wearing any clothing, does not require the two people to
be scanned from similar viewpoints, and runs in real time. We use a deep
convolutional neural network to train a feature descriptor on depth map pixels,
but crucially, rather than training the network to solve the shape
correspondence problem directly, we train it to solve a body region
classification problem, modified to increase the smoothness of the learned
descriptors near region boundaries. This approach ensures that nearby points on
the human body are nearby in feature space, and vice versa, rendering the
feature descriptor suitable for computing dense correspondences between the
scans. We validate our method on real and synthetic data for both clothed and
unclothed humans, and show that our correspondences are more robust than is
possible with state-of-the-art unsupervised methods, and more accurate than
those found using methods that require full watertight 3D geometry.
"
504,Bezier curves and surfaces based on modified Bernstein polynomials,"  In this paper, we use the blending functions of Bernstein polynomials with
shifted knots for construction of Bezier curves and surfaces. We study the
nature of degree elevation and degree reduction for Bezier Bernstein functions
with shifted knots.
  Parametric curves are represented using these modified Bernstein basis and
the concept of total positivity is applied to investigate the shape properties
of the curve. We get Bezier curve defined on [0, 1] when we set the parameter
\alpha=\beta to the value 0. We also present a de Casteljau algorithm to
compute Bernstein Bezier curves and surfaces with shifted knots. The new curves
have some properties similar to Bezier curves. Furthermore, some fundamental
properties for Bernstein Bezier curves and surfaces are discussed.
"
505,"TEMPO: Feature-Endowed Teichm\""uller Extremal Mappings of Point Clouds","  In recent decades, the use of 3D point clouds has been widespread in computer
industry. The development of techniques in analyzing point clouds is
increasingly important. In particular, mapping of point clouds has been a
challenging problem. In this paper, we develop a discrete analogue of the
Teichm\""{u}ller extremal mappings, which guarantee uniform conformality
distortions, on point cloud surfaces. Based on the discrete analogue, we
propose a novel method called TEMPO for computing Teichm\""{u}ller extremal
mappings between feature-endowed point clouds. Using our proposed method, the
Teichm\""{u}ller metric is introduced for evaluating the dissimilarity of point
clouds. Consequently, our algorithm enables accurate recognition and
classification of point clouds. Experimental results demonstrate the
effectiveness of our proposed method.
"
506,Embedding of Hypercube into Cylinder,"  Task mapping in modern high performance parallel computers can be modeled as
a graph embedding problem, which simulates the mapping as embedding one graph
into another and try to find the minimum wirelength for the mapping. Though
embedding problems have been considered for several regular graphs, such as
hypercubes into grids, binary trees into grids, et al, it is still an open
problem for hypercubes into cylinders. In this paper, we consider the problem
of embedding hypercubes into cylinders to minimize the wirelength. We obtain
the exact wirelength formula of embedding hypercube $Q^r$ into cylinder
$C_{2^3}\times P_{2^{r-3}}$ with $r\ge3$.
"
507,"SlicerPET: A workflow based software module for PET/CT guided needle
  biopsy","  Biopsy is commonly used to confirm cancer diagnosis when radiologically
indicated. Given the ability of PET to localize malignancies in heterogeneous
tumors and tumors that do not have a CT correlate, PET/CT guided biopsy may
improve the diagnostic yield of biopsies. To facilitate PET/CT guided needle
biopsy, we developed a workflow that allows us to bring PET image guidance into
the interventional CT suite. In this abstract, we present SlicerPET, a
user-friendly workflow based module developed using open source software
libraries to guide needle biopsy in the interventional suite.
"
508,ShapeNet: An Information-Rich 3D Model Repository,"  We present ShapeNet: a richly-annotated, large-scale repository of shapes
represented by 3D CAD models of objects. ShapeNet contains 3D models from a
multitude of semantic categories and organizes them under the WordNet taxonomy.
It is a collection of datasets providing many semantic annotations for each 3D
model such as consistent rigid alignments, parts and bilateral symmetry planes,
physical sizes, keywords, as well as other planned annotations. Annotations are
made available through a public web-based interface to enable data
visualization of object attributes, promote data-driven geometric analysis, and
provide a large-scale quantitative benchmark for research in computer graphics
and vision. At the time of this technical report, ShapeNet has indexed more
than 3,000,000 models, 220,000 models out of which are classified into 3,135
categories (WordNet synsets). In this report we describe the ShapeNet effort as
a whole, provide details for all currently available datasets, and summarize
future plans.
"
509,Interactive Volumetry Of Liver Ablation Zones,"  Percutaneous radiofrequency ablation (RFA) is a minimally invasive technique
that destroys cancer cells by heat. The heat results from focusing energy in
the radiofrequency spectrum through a needle. Amongst others, this can enable
the treatment of patients who are not eligible for an open surgery. However,
the possibility of recurrent liver cancer due to incomplete ablation of the
tumor makes post-interventional monitoring via regular follow-up scans
mandatory. These scans have to be carefully inspected for any conspicuousness.
Within this study, the RF ablation zones from twelve post-interventional CT
acquisitions have been segmented semi-automatically to support the visual
inspection. An interactive, graph-based contouring approach, which prefers
spherically shaped regions, has been applied. For the quantitative and
qualitative analysis of the algorithm's results, manual slice-by-slice
segmentations produced by clinical experts have been used as the gold standard
(which have also been compared among each other). As evaluation metric for the
statistical validation, the Dice Similarity Coefficient (DSC) has been
calculated. The results show that the proposed tool provides lesion
segmentation with sufficient accuracy much faster than manual segmentation. The
visual feedback and interactivity make the proposed tool well suitable for the
clinical workflow.
"
510,Improving Style Similarity Metrics of 3D Shapes,"  The idea of style similarity metrics has been recently developed for various
media types such as 2D clip art and 3D shapes. We explore this style metric
problem and improve existing style similarity metrics of 3D shapes in four
novel ways. First, we consider the color and texture of 3D shapes which are
important properties that have not been previously considered. Second, we
explore the effect of clustering a dataset of 3D models by comparing between
style metrics for a single object type and style metrics that combine clusters
of object types. Third, we explore the idea of user-guided learning for this
problem. Fourth, we introduce an iterative approach that can learn a metric
from a general set of 3D models. We demonstrate these contributions with
various classes of 3D shapes and with applications such as style-based
similarity search and scene composition.
"
511,Shape Animation with Combined Captured and Simulated Dynamics,"  We present a novel volumetric animation generation framework to create new
types of animations from raw 3D surface or point cloud sequence of captured
real performances. The framework considers as input time incoherent 3D
observations of a moving shape, and is thus particularly suitable for the
output of performance capture platforms. In our system, a suitable virtual
representation of the actor is built from real captures that allows seamless
combination and simulation with virtual external forces and objects, in which
the original captured actor can be reshaped, disassembled or reassembled from
user-specified virtual physics. Instead of using the dominant surface-based
geometric representation of the capture, which is less suitable for volumetric
effects, our pipeline exploits Centroidal Voronoi tessellation decompositions
as unified volumetric representation of the real captured actor, which we show
can be used seamlessly as a building block for all processing stages, from
capture and tracking to virtual physic simulation. The representation makes no
human specific assumption and can be used to capture and re-simulate the actor
with props or other moving scenery elements. We demonstrate the potential of
this pipeline for virtual reanimation of a real captured event with various
unprecedented volumetric visual effects, such as volumetric distortion,
erosion, morphing, gravity pull, or collisions.
"
512,Anti-commutative Dual Complex Numbers and 2D Rigid Transformation,"  We introduce a new presentation of the two dimensional rigid transformation
which is more concise and efficient than the standard matrix presentation. By
modifying the ordinary dual number construction for the complex numbers, we
define the ring of the anti-commutative dual complex numbers, which
parametrizes two dimensional rotation and translation all together. With this
presentation, one can easily interpolate or blend two or more rigid
transformations at a low computational cost. We developed a library for C++
with the MIT-licensed source code and demonstrate its facility by an
interactive deformation tool developed for iPad.
"
513,Implicit equations of non-degenerate rational Bezier quadric triangles,"  In this paper we review the derivation of implicit equations for
non-degenerate quadric patches in rational Bezier triangular form. These are
the case of Steiner surfaces of degree two. We derive the bilinear forms for
such quadrics in a coordinate-free fashion in terms of their control net and
their list of weights in a suitable form. Our construction relies on projective
geometry and is grounded on the pencil of quadrics circumscribed to a
tetrahedron formed by vertices of the control net and an additional point which
is required for the Steiner surface to be a non-degenerate quadric.
"
514,"Development of a wheelchair simulator for children with multiple
  disabilities","  Virtual reality allows to create situations which can be experimented under
the control of the user, without risks, in a very flexible way. This allows to
develop skills and to have confidence to work in real conditions with real
equipment. VR is then widely used as a training and learning tool. More
recently, VR has also showed its potential in rehabilitation and therapy fields
because it provides users with the ability of repeat their actions several
times and to progress at their own pace. In this communication, we present our
work in the development of a wheelchair simulator designed to allow children
with multiple disabilities to familiarize themselves with the wheelchair.
"
515,"Which tone-mapping operator is the best? A comparative study of
  perceptual quality","  Tone-mapping operators (TMO) are designed to generate perceptually similar
low-dynamic range images from high-dynamic range ones. We studied the
performance of fifteen TMOs in two psychophysical experiments where observers
compared the digitally generated tone-mapped images to their corresponding
physical scenes. All experiments were performed in a controlled environment and
the setups were designed to emphasise different image properties: in the first
experiment we evaluated the local relationships among intensity-levels, and in
the second one we evaluated global visual appearance among physical scenes and
tone-mapped images, which were presented side by side. We ranked the TMOs
according to how well they reproduce the results obtained in the physical
scene. Our results show that ranking position clearly depends on the adopted
evaluation criteria, which implies that, in general, these tone-mapping
algorithms consider either local or global image attributes but rarely both. We
conclude that a more thorough and standardized evaluation criteria are needed
to study all the characteristics of TMOs, as there is ample room for
improvement in future developments.
"
516,Tetrisation of triangular meshes and its application in shape blending,"  The As-Rigid-As-Possible (ARAP) shape deformation framework is a versatile
technique for morphing, surface modelling, and mesh editing. We discuss an
improvement of the ARAP framework in a few aspects: 1. Given a triangular mesh
in 3D space, we introduce a method to associate a tetrahedral structure, which
encodes the geometry of the original mesh. 2. We use a Lie algebra based method
to interpolate local transformation, which provides better handling of rotation
with large angle. 3. We propose a new error function to compile local
transformations into a global piecewise linear map, which is rotation invariant
and easy to minimise. We implemented a shape blender based on our algorithm and
its MIT licensed source code is available online.
"
517,"B-spline Shape from Motion & Shading: An Automatic Free-form Surface
  Modeling for Face Reconstruction","  Recently, many methods have been proposed for face reconstruction from
multiple images, most of which involve fundamental principles of Shape from
Shading and Structure from motion. However, a majority of the methods just
generate discrete surface model of face. In this paper, B-spline Shape from
Motion and Shading (BsSfMS) is proposed to reconstruct continuous B-spline
surface for multi-view face images, according to an assumption that shading and
motion information in the images contain 1st- and 0th-order derivative of
B-spline face respectively. Face surface is expressed as a B-spline surface
that can be reconstructed by optimizing B-spline control points. Therefore,
normals and 3D feature points computed from shading and motion of images
respectively are used as the 1st- and 0th- order derivative information, to be
jointly applied in optimizing the B-spline face. Additionally, an IMLS
(iterative multi-least-square) algorithm is proposed to handle the difficult
control point optimization. Furthermore, synthetic samples and LFW dataset are
introduced and conducted to verify the proposed approach, and the experimental
results demonstrate the effectiveness with different poses, illuminations,
expressions etc., even with wild images.
"
518,"3D digital reassembling of archaeological ceramic pottery fragments
  based on their thickness profile","  The reassembly of a broken archaeological ceramic pottery is an open and
complex problem, which remains a scientific process of extreme interest for the
archaeological community. Usually, the solutions suggested by various research
groups and universities depend on various aspects such as the matching process
of the broken surfaces, the outline of sherds or their colors and geometric
characteris-tics, their axis of symmetry, the corners of their contour, the
theme portrayed on the surface, the concentric circular rills that are left
during the base construction in the inner pottery side by the fingers of the
potter artist etc. In this work the reassembly process is based on a different
and more secure idea, since it is based on the thick-ness profile, which is
appropriately identified in every fragment. Specifically, our approach is based
on information encapsulated in the inner part of the sherd (i.e. thickness),
which is not -or at least not heavily- affected by the presence of harsh
environmental conditions, but is safely kept within the sherd itself. Our
method is verified in various use case experiments, using cutting edge
technologies such as 3D representations and precise measurements on surfaces
from the acquired 3D models.
"
519,Virtual Rephotography: Novel View Prediction Error for 3D Reconstruction,"  The ultimate goal of many image-based modeling systems is to render
photo-realistic novel views of a scene without visible artifacts. Existing
evaluation metrics and benchmarks focus mainly on the geometric accuracy of the
reconstructed model, which is, however, a poor predictor of visual accuracy.
Furthermore, using only geometric accuracy by itself does not allow evaluating
systems that either lack a geometric scene representation or utilize coarse
proxy geometry. Examples include light field or image-based rendering systems.
We propose a unified evaluation approach based on novel view prediction error
that is able to analyze the visual quality of any method that can render novel
views from input images. One of the key advantages of this approach is that it
does not require ground truth geometry. This dramatically simplifies the
creation of test datasets and benchmarks. It also allows us to evaluate the
quality of an unknown scene during the acquisition and reconstruction process,
which is useful for acquisition planning. We evaluate our approach on a range
of methods including standard geometry-plus-texture pipelines as well as
image-based rendering techniques, compare it to existing geometry-based
benchmarks, and demonstrate its utility for a range of use cases.
"
520,SculptStat: Statistical Analysis of Digital Sculpting Workflows,"  Targeted user studies are often employed to measure how well artists can
perform specific tasks. But these studies cannot properly describe editing
workflows as wholes, since they guide the artists both by choosing the tasks
and by using simplified interfaces. In this paper, we investigate digital
sculpting workflows used to produce detailed models. In our experiment design,
artists can choose freely what and how to model. We recover whole-workflow
trends with sophisticated statistical analyzes and validate these trends with
goodness-of-fits measures. We record brush strokes and mesh snapshots by
instrumenting a sculpting program and analyze the distribution of these
properties and their spatial and temporal characteristics. We hired expert
artists that can produce relatively sophisticated models in short time, since
their workflows are representative of best practices. We analyze 13 meshes
corresponding to roughly 25 thousand strokes in total. We found that artists
work mainly with short strokes, with average stroke length dependent on model
features rather than the artist itself. Temporally, artists do not work
coarse-to-fine but rather in bursts. Spatially, artists focus on some selected
regions by dedicating different amounts of edits and by applying different
techniques. Spatio-temporally, artists return to work on the same area multiple
times without any apparent periodicity. We release the entire dataset and all
code used for the analyzes as reference for the community.
"
521,Boolean Operations using Generalized Winding Numbers,"  The generalized winding number function measures insideness for arbitrary
oriented triangle meshes. Exploiting this, I similarly generalize binary
boolean operations to act on such meshes. The resulting operations for union,
intersection, difference, etc. avoid volumetric discretization or
pre-processing.
"
522,Novel Views of Objects from a Single Image,"  Taking an image of an object is at its core a lossy process. The rich
information about the three-dimensional structure of the world is flattened to
an image plane and decisions such as viewpoint and camera parameters are final
and not easily revertible. As a consequence, possibilities of changing
viewpoint are limited. Given a single image depicting an object, novel-view
synthesis is the task of generating new images that render the object from a
different viewpoint than the one given. The main difficulty is to synthesize
the parts that are disoccluded; disocclusion occurs when parts of an object are
hidden by the object itself under a specific viewpoint. In this work, we show
how to improve novel-view synthesis by making use of the correlations observed
in 3D models and applying them to new image instances. We propose a technique
to use the structural information extracted from a 3D model that matches the
image object in terms of viewpoint and shape. For the latter part, we propose
an efficient 2D-to-3D alignment method that associates precisely the image
appearance with the 3D model geometry with minimal user interaction. Our
technique is able to simulate plausible viewpoint changes for a variety of
object classes within seconds. Additionally, we show that our synthesized
images can be used as additional training data that improves the performance of
standard object detectors.
"
523,Smooth surface interpolation using patches with rational offsets,"  We present a new method for the interpolation of given data points and
associated normals with surface parametric patches with rational normal fields.
We give some arguments why a dual approach is the most convenient for these
surfaces, which are traditionally called Pythagorean normal vector (PN)
surfaces. Our construction is based on the isotropic model of the dual space to
which the original data are pushed. Then the bicubic Coons patches are
constructed in the isotropic space and then pulled back to the standard three
dimensional space. As a result we obtain the patch construction which is
completely local and produces surfaces with the global G1~continuity.
"
524,A semi-automatic computer-aided method for surgical template design,"  This paper presents a generalized integrated framework of semi-automatic
surgical template design. Several algorithms were implemented including the
mesh segmentation, offset surface generation, collision detection, ruled
surface generation, etc., and a special software named TemDesigner was
developed. With a simple user interface, a customized template can be semi-
automatically designed according to the preoperative plan. Firstly, mesh
segmentation with signed scalar of vertex is utilized to partition the inner
surface from the input surface mesh based on the indicated point loop. Then,
the offset surface of the inner surface is obtained through contouring the
distance field of the inner surface, and segmented to generate the outer
surface. Ruled surface is employed to connect inner and outer surfaces.
Finally, drilling tubes are generated according to the preoperative plan
through collision detection and merging. It has been applied to the template
design for various kinds of surgeries, including oral implantology, cervical
pedicle screw insertion, iliosacral screw insertion and osteotomy,
demonstrating the efficiency, functionality and generality of our method.
"
525,"Effective Clipart Image Vectorization Through Direct Optimization of
  Bezigons","  Bezigons, i.e., closed paths composed of B\'ezier curves, have been widely
employed to describe shapes in image vectorization results. However, most
existing vectorization techniques infer the bezigons by simply approximating an
intermediate vector representation (such as polygons). Consequently, the
resultant bezigons are sometimes imperfect due to accumulated errors, fitting
ambiguities, and a lack of curve priors, especially for low-resolution images.
In this paper, we describe a novel method for vectorizing clipart images. In
contrast to previous methods, we directly optimize the bezigons rather than
using other intermediate representations; therefore, the resultant bezigons are
not only of higher fidelity compared with the original raster image but also
more reasonable because they were traced by a proficient expert. To enable such
optimization, we have overcome several challenges and have devised a
differentiable data energy as well as several curve-based prior terms. To
improve the efficiency of the optimization, we also take advantage of the local
control property of bezigons and adopt an overlapped piecewise optimization
strategy. The experimental results show that our method outperforms both the
current state-of-the-art method and commonly used commercial software in terms
of bezigon quality.
"
526,Preoperative Volume Determination for Pituitary Adenoma,"  The most common sellar lesion is the pituitary adenoma, and sellar tumors are
approximately 10-15% of all intracranial neoplasms. Manual slice-by-slice
segmentation takes quite some time that can be reduced by using the appropriate
algorithms. In this contribution, we present a segmentation method for
pituitary adenoma. The method is based on an algorithm that we have applied
recently to segmenting glioblastoma multiforme. A modification of this scheme
is used for adenoma segmentation that is much harder to perform, due to lack of
contrast-enhanced boundaries. In our experimental evaluation, neurosurgeons
performed manual slice-by-slice segmentation of ten magnetic resonance imaging
(MRI) cases. The segmentations were compared to the segmentation results of the
proposed method using the Dice Similarity Coefficient (DSC). The average DSC
for all datasets was 75.92% +/- 7.24%. A manual segmentation took about four
minutes and our algorithm required about one second.
"
527,Efficient Multi-view Performance Capture of Fine-Scale Surface Detail,"  We present a new effective way for performance capture of deforming meshes
with fine-scale time-varying surface detail from multi-view video. Our method
builds up on coarse 4D surface reconstructions, as obtained with commonly used
template-based methods. As they only capture models of coarse-to-medium scale
detail, fine scale deformation detail is often done in a second pass by using
stereo constraints, features, or shading-based refinement. In this paper, we
propose a new effective and stable solution to this second step. Our framework
creates an implicit representation of the deformable mesh using a dense
collection of 3D Gaussian functions on the surface, and a set of 2D Gaussians
for the images. The fine scale deformation of all mesh vertices that maximizes
photo-consistency can be efficiently found by densely optimizing a new
model-to-image consistency energy on all vertex positions. A principal
advantage is that our problem formulation yields a smooth closed form energy
with implicit occlusion handling and analytic derivatives. Error-prone
correspondence finding, or discrete sampling of surface displacement values are
also not needed. We show several reconstructions of human subjects wearing
loose clothing, and we qualitatively and quantitatively show that we robustly
capture more detail than related methods.
"
528,"A simple method for estimating the fractal dimension from digital
  images: The compression dimension","  The fractal structure of real world objects is often analyzed using digital
images. In this context, the compression fractal dimension is put forward. It
provides a simple method for the direct estimation of the dimension of fractals
stored as digital image files. The computational scheme can be implemented
using readily available free software. Its simplicity also makes it very
interesting for introductory elaborations of basic concepts of fractal
geometry, complexity, and information theory. A test of the computational
scheme using limited-quality images of well-defined fractal sets obtained from
the Internet and free software has been performed. Also, a systematic
evaluation of the proposed method using computer generated images of the
Weierstrass cosine function shows an accuracy comparable to those of the
methods most commonly used to estimate the dimension of fractal data sequences
applied to the same test problem.
"
529,A Large Dataset of Object Scans,"  We have created a dataset of more than ten thousand 3D scans of real objects.
To create the dataset, we recruited 70 operators, equipped them with
consumer-grade mobile 3D scanning setups, and paid them to scan objects in
their environments. The operators scanned objects of their choosing, outside
the laboratory and without direct supervision by computer vision professionals.
The result is a large and diverse collection of object scans: from shoes, mugs,
and toys to grand pianos, construction vehicles, and large outdoor sculptures.
We worked with an attorney to ensure that data acquisition did not violate
privacy constraints. The acquired data was irrevocably placed in the public
domain and is available freely at http://redwood-data.org/3dscan .
"
530,"Simulation of bifurcated stent grafts to treat abdominal aortic
  aneurysms (AAA)","  In this paper a method is introduced, to visualize bifurcated stent grafts in
CT-Data. The aim is to improve therapy planning for minimal invasive treatment
of abdominal aortic aneurysms (AAA). Due to precise measurement of the
abdominal aortic aneurysm and exact simulation of the bifurcated stent graft,
physicians are supported in choosing a suitable stent prior to an intervention.
The presented method can be used to measure the dimensions of the abdominal
aortic aneurysm as well as simulate a bifurcated stent graft. Both of these
procedures are based on a preceding segmentation and skeletonization of the
aortic, right and left iliac. Using these centerlines (aortic, right and left
iliac) a bifurcated initial stent is constructed. Through the implementation of
an ACM method the initial stent is fit iteratively to the vessel walls - due to
the influence of external forces (distance- as well as balloonforce). Following
the fitting process, the crucial values for choosing a bifurcated stent graft
are measured, e.g. aortic diameter, right and left common iliac diameter,
minimum diameter of distal neck. The selected stent is then simulated to the
CT-Data - starting with the initial stent. It hereby becomes apparent if the
dimensions of the bifurcated stent graft are exact, i.e. the fitting to the
arteries was done properly and no ostium was covered.
"
531,Automatic Face Reenactment,"  We propose an image-based, facial reenactment system that replaces the face
of an actor in an existing target video with the face of a user from a source
video, while preserving the original target performance. Our system is fully
automatic and does not require a database of source expressions. Instead, it is
able to produce convincing reenactment results from a short source video
captured with an off-the-shelf camera, such as a webcam, where the user
performs arbitrary facial gestures. Our reenactment pipeline is conceived as
part image retrieval and part face transfer: The image retrieval is based on
temporal clustering of target frames and a novel image matching metric that
combines appearance and motion to select candidate frames from the source
video, while the face transfer uses a 2D warping strategy that preserves the
user's identity. Our system excels in simplicity as it does not rely on a 3D
face model, it is robust under head motion and does not require the source and
target performance to be similar. We show convincing reenactment results for
videos that we recorded ourselves and for low-quality footage taken from the
Internet.
"
532,"Detection and Visualization of Endoleaks in CT Data for Monitoring of
  Thoracic and Abdominal Aortic Aneurysm Stents","  In this paper we present an efficient algorithm for the segmentation of the
inner and outer boundary of thoratic and abdominal aortic aneurysms (TAA & AAA)
in computed tomography angiography (CTA) acquisitions. The aneurysm
segmentation includes two steps: first, the inner boundary is segmented based
on a grey level model with two thresholds; then, an adapted active contour
model approach is applied to the more complicated outer boundary segmentation,
with its initialization based on the available inner boundary segmentation. An
opacity image, which aims at enhancing important features while reducing
spurious structures, is calculated from the CTA images and employed to guide
the deformation of the model. In addition, the active contour model is extended
by a constraint force that prevents intersections of the inner and outer
boundary and keeps the outer boundary at a distance, given by the thrombus
thickness, to the inner boundary. Based upon the segmentation results, we can
measure the aneurysm size at each centerline point on the centerline orthogonal
multiplanar reformatting (MPR) plane. Furthermore, a 3D TAA or AAA model is
reconstructed from the set of segmented contours, and the presence of endoleaks
is detected and highlighted. The implemented method has been evaluated on nine
clinical CTA data sets with variations in anatomy and location of the pathology
and has shown promising results.
"
533,Design of false color palettes for grayscale reproduction,"  Design of false color palette is quite easy but some effort has to be done to
achieve good dynamic range, contrast and overall appearance of the palette.
Such palettes, for instance, are commonly used in scientific papers for
presenting the data. However, to lower the cost of the paper most scientists
decide to let the data to be printed in grayscale. The same applies to e-book
readers based on e-ink where most of them are still grayscale. For majority of
false color palettes reproducing them in grayscale results in ambiguous mapping
of the colors and may be misleading for the reader. In this article design of
false color palettes suitable for grayscale reproduction is described. Due to
the monotonic change of luminance of these palettes grayscale representation is
very similar to the data directly presented with a grayscale palette. Some
suggestions and examples how to design such palettes are provided.
"
534,Gabor Wavelets in Image Processing,"  This work shows the use of a two-dimensional Gabor wavelets in image
processing. Convolution with such a two-dimensional wavelet can be separated
into two series of one-dimensional ones. The key idea of this work is to
utilize a Gabor wavelet as a multiscale partial differential operator of a
given order. Gabor wavelets are used here to detect edges, corners and blobs. A
performance of such an interest point detector is compared to detectors
utilizing a Haar wavelet and a derivative of a Gaussian function. The proposed
approach may be useful when a fast implementation of the Gabor transform is
available or when the transform is already precomputed.
"
535,"Segmentation Rectification for Video Cutout via One-Class Structured
  Learning","  Recent works on interactive video object cutout mainly focus on designing
dynamic foreground-background (FB) classifiers for segmentation propagation.
However, the research on optimally removing errors from the FB classification
is sparse, and the errors often accumulate rapidly, causing significant errors
in the propagated frames. In this work, we take the initial steps to addressing
this problem, and we call this new task \emph{segmentation rectification}. Our
key observation is that the possibly asymmetrically distributed false positive
and false negative errors were handled equally in the conventional methods. We,
alternatively, propose to optimally remove these two types of errors. To this
effect, we propose a novel bilayer Markov Random Field (MRF) model for this new
task. We also adopt the well-established structured learning framework to learn
the optimal model from data. Additionally, we propose a novel one-class
structured SVM (OSSVM) which greatly speeds up the structured learning process.
Our method naturally extends to RGB-D videos as well. Comprehensive experiments
on both RGB and RGB-D data demonstrate that our simple and effective method
significantly outperforms the segmentation propagation methods adopted in the
state-of-the-art video cutout systems, and the results also suggest the
potential usefulness of our method in image cutout system.
"
536,2D SEM images turn into 3D object models,"  The scanning electron microscopy (SEM) is probably one the most fascinating
examination approach that has been used since more than two decades to detailed
inspection of micro scale objects. Most of the scanning electron microscopes
could only produce 2D images that could not assist operational analysis of
microscopic surface properties. Computer vision algorithms combined with very
advanced geometry and mathematical approaches turn any SEM into a full 3D
measurement device. This work focuses on a methodical literature review for
automatic 3D surface reconstruction of scanning electron microscope images.
"
537,Weighted Unsupervised Learning for 3D Object Detection,"  This paper introduces a novel weighted unsupervised learning for object
detection using an RGB-D camera. This technique is feasible for detecting the
moving objects in the noisy environments that are captured by an RGB-D camera.
The main contribution of this paper is a real-time algorithm for detecting each
object using weighted clustering as a separate cluster. In a preprocessing
step, the algorithm calculates the pose 3D position X, Y, Z and RGB color of
each data point and then it calculates each data point's normal vector using
the point's neighbor. After preprocessing, our algorithm calculates k-weights
for each data point; each weight indicates membership. Resulting in clustered
objects of the scene.
"
538,"On a recursive construction of circular paths and the search for $\pi$
  on the integer lattice $\mathbb{Z}^2$","  Digital circles not only play an important role in various technological
settings, but also provide a lively playground for more fundamental
number-theoretical questions. In this paper, we present a new recursive
algorithm for the construction of digital circles on the integer lattice
$\mathbb{Z}^2$, which makes sole use of the signum function. By briefly
elaborating on the nature of discretization of circular paths, we then find
that this algorithm recovers, in a space endowed with $\ell^1$-norm, the
defining constant $\pi$ of a circle in $\mathbb{R}^2$.
"
539,Creating Simplified 3D Models with High Quality Textures,"  This paper presents an extension to the KinectFusion algorithm which allows
creating simplified 3D models with high quality RGB textures. This is achieved
through (i) creating model textures using images from an HD RGB camera that is
calibrated with Kinect depth camera, (ii) using a modified scheme to update
model textures in an asymmetrical colour volume that contains a higher number
of voxels than that of the geometry volume, (iii) simplifying dense polygon
mesh model using quadric-based mesh decimation algorithm, and (iv) creating and
mapping 2D textures to every polygon in the output 3D model. The proposed
method is implemented in real-time by means of GPU parallel processing.
Visualization via ray casting of both geometry and colour volumes provides
users with a real-time feedback of the currently scanned 3D model. Experimental
results show that the proposed method is capable of keeping the model texture
quality even for a heavily decimated model and that, when reconstructing small
objects, photorealistic RGB textures can still be reconstructed.
"
540,Computer Aided Restoration of Handwritten Character Strokes,"  This work suggests a new variational approach to the task of computer aided
restoration of incomplete characters, residing in a highly noisy document. We
model character strokes as the movement of a pen with a varying radius.
Following this model, a cubic spline representation is being utilized to
perform gradient descent steps, while maintaining interpolation at some initial
(manually sampled) points. The proposed algorithm was utilized in the process
of restoring approximately 1000 ancient Hebrew characters (dating to ca.
8th-7th century BCE), some of which are presented herein and show that the
algorithm yields plausible results when applied on deteriorated documents.
"
541,"US-Cut: Interactive Algorithm for rapid Detection and Segmentation of
  Liver Tumors in Ultrasound Acquisitions","  Ultrasound (US) is the most commonly used liver imaging modality worldwide.
It plays an important role in follow-up of cancer patients with liver
metastases. We present an interactive segmentation approach for liver tumors in
US acquisitions. Due to the low image quality and the low contrast between the
tumors and the surrounding tissue in US images, the segmentation is very
challenging. Thus, the clinical practice still relies on manual measurement and
outlining of the tumors in the US images. We target this problem by applying an
interactive segmentation algorithm to the US data, allowing the user to get
real-time feedback of the segmentation results. The algorithm has been
developed and tested hand-in-hand by physicians and computer scientists to make
sure a future practical usage in a clinical setting is feasible. To cover
typical acquisitions from the clinical routine, the approach has been evaluated
with dozens of datasets where the tumors are hyperechoic (brighter), hypoechoic
(darker) or isoechoic (similar) in comparison to the surrounding liver tissue.
Due to the interactive real-time behavior of the approach, it was possible even
in difficult cases to find satisfying segmentations of the tumors within
seconds and without parameter settings, and the average tumor deviation was
only 1.4mm compared with manual measurements. However, the long term goal is to
ease the volumetric acquisition of liver tumors in order to evaluate for
treatment response. Additional aim is the registration of intraoperative US
images via the interactive segmentations to the patient's pre-interventional CT
acquisitions.
"
542,LevelMerge: Collaborative Game Level Editing by Merging Labeled Graphs,"  Game level editing is the process of constructing a full game level starting
from 3D asset libraries, e.g. 3d models, textures, shaders, scripts. In level
editing, designers define the look and behavior of the whole level by placing
objects, assigning materials and lighting parameters, setting animations and
physics properties and customizing the objects AI and behavior by editing
scripts. The heterogeneity of the task usually translates to a workflow where a
team of people, experts on separate aspects, cooperate to edit the game level,
often working on the same objects (e.g.: a programmer working on the AI of a
character, while an artist works on its 3D model or its materials). Today this
collaboration is established by using version control systems designed for text
documents, such as Git, to manage different versions and share them amongst
users. The merge algorithms used in these systems though does not perform well
in our case since it does not respect the relations between game objects
necessary to maintain the semantic of the game level behavior and look. This is
a known problem and commercial systems for game level merging exists, e.g.
PlasticSCM, but these are only slightly more robust than text-based ones. This
causes designers to often merge scenes manually, essentially reapplying others
edits in the game level editor.
"
543,"Cellular Automata Segmentation of the Boundary between the Compacta of
  Vertebral Bodies and Surrounding Structures","  Due to the aging population, spinal diseases get more and more common
nowadays; e.g., lifetime risk of osteoporotic fracture is 40% for white women
and 13% for white men in the United States. Thus the numbers of surgical spinal
procedures are also increasing with the aging population and precise diagnosis
plays a vital role in reducing complication and recurrence of symptoms. Spinal
imaging of vertebral column is a tedious process subjected to interpretation
errors. In this contribution, we aim to reduce time and error for vertebral
interpretation by applying and studying the GrowCut-algorithm for boundary
segmentation between vertebral body compacta and surrounding structures.
GrowCut is a competitive region growing algorithm using cellular automata. For
our study, vertebral T2-weighted Magnetic Resonance Imaging (MRI) scans were
first manually outlined by neurosurgeons. Then, the vertebral bodies were
segmented in the medical images by a GrowCut-trained physician using the
semi-automated GrowCut-algorithm. Afterwards, results of both segmentation
processes were compared using the Dice Similarity Coefficient (DSC) and the
Hausdorff Distance (HD) which yielded to a DSC of 82.99+/-5.03% and a HD of
18.91+/-7.2 voxel, respectively. In addition, the times have been measured
during the manual and the GrowCut segmentations, showing that a
GrowCut-segmentation - with an average time of less than six minutes
(5.77+/-0.73) - is significantly shorter than a pure manual outlining.
"
544,"Interactive and Scale Invariant Segmentation of the Rectum/Sigmoid via
  User-Defined Templates","  Among all types of cancer, gynecological malignancies belong to the 4th most
frequent type of cancer among women. Besides chemotherapy and external beam
radiation, brachytherapy is the standard procedure for the treatment of these
malignancies. In the progress of treatment planning, localization of the tumor
as the target volume and adjacent organs of risks by segmentation is crucial to
accomplish an optimal radiation distribution to the tumor while simultaneously
preserving healthy tissue. Segmentation is performed manually and represents a
time-consuming task in clinical daily routine. This study focuses on the
segmentation of the rectum/sigmoid colon as an Organ-At-Risk in gynecological
brachytherapy. The proposed segmentation method uses an interactive,
graph-based segmentation scheme with a user-defined template. The scheme
creates a directed two dimensional graph, followed by the minimal cost closed
set computation on the graph, resulting in an outlining of the rectum. The
graphs outline is dynamically adapted to the last calculated cut. Evaluation
was performed by comparing manual segmentations of the rectum/sigmoid colon to
results achieved with the proposed method. The comparison of the algorithmic to
manual results yielded to a Dice Similarity Coefficient value of 83.85+/-4.08%,
in comparison to 83.97+/-8.08% for the comparison of two manual segmentations
of the same physician. Utilizing the proposed methodology resulted in a median
time of 128 seconds per dataset, compared to 300 seconds needed for pure manual
segmentation.
"
545,Predicting Chroma from Luma with Frequency Domain Intra Prediction,"  This paper describes a technique for performing intra prediction of the
chroma planes based on the reconstructed luma plane in the frequency domain.
This prediction exploits the fact that while RGB to YUV color conversion has
the property that it decorrelates the color planes globally across an image,
there is still some correlation locally at the block level. Previous proposals
compute a linear model of the spatial relationship between the luma plane (Y)
and the two chroma planes (U and V). In codecs that use lapped transforms this
is not possible since transform support extends across the block boundaries and
thus neighboring blocks are unavailable during intra-prediction. We design a
frequency domain intra predictor for chroma that exploits the same local
correlation with lower complexity than the spatial predictor and which works
with lapped transforms. We then describe a low-complexity algorithm that
directly uses luma coefficients as a chroma predictor based on gain-shape
quantization and band partitioning. An experiment is performed that compares
these two techniques inside the experimental Daala video codec and shows the
lower complexity algorithm to be a better chroma predictor.
"
546,Modelling Developable Ribbons Using Ruling Bending Coordinates,"  This paper presents a new method for modelling the dynamic behaviour of
developable ribbons, two dimensional strips with much smaller width than
length. Instead of approximating such surface with a general triangle mesh, we
characterize it by a set of creases and bending angles across them. This
representation allows the developability to be satisfied everywhere while still
leaves enough degree of freedom to represent salient global deformation. We
show how the potential and kinetic energies can be properly discretized in this
configuration space and time integrated in a fully implicit manner. The result
is a dynamic simulator with several desirable features: We can model
non-trivial deformation using much fewer elements than conventional FEM method.
It is stable under extreme deformation, external force or large timestep size.
And we can readily handle various user constraints in Euclidean space.
"
547,A linear algorithm for Brick Wang tiling,"  The Wang tiling is a classical problem in combinatorics. A major theoretical
question is to find a (small) set of tiles which tiles the plane only
aperiodically. In this case, resulting tilings are rather restrictive. On the
other hand, Wang tiles are used as a tool to generate textures and patterns in
computer graphics. In these applications, a set of tiles is normally chosen so
that it tiles the plane or its sub-regions easily in many different ways. With
computer graphics applications in mind, we introduce a class of such tileset,
which we call sequentially permissive tilesets, and consider tiling problems
with constrained boundary. We apply our methodology to a special set of Wang
tiles, called Brick Wang tiles, introduced by Derouet-Jourdan et al. in 2015 to
model wall patterns. We generalise their result by providing a linear algorithm
to decide and solve the tiling problem for arbitrary planar regions with holes.
"
548,Degree reduction of composite B\'ezier curves,"  This paper deals with the problem of multi-degree reduction of a composite
B\'ezier curve with the parametric continuity constraints at the endpoints of
the segments. We present a novel method which is based on the idea of using
constrained dual Bernstein polynomials to compute the control points of the
reduced composite curve. In contrast to other methods, ours minimizes the
$L_2$-error for the whole composite curve instead of minimizing the
$L_2$-errors for each segment separately. As a result, an additional
optimization is possible. Examples show that the new method gives much better
results than multiple application of the degree reduction of a single B\'ezier
curve.
"
549,Deep Shading: Convolutional Neural Networks for Screen-Space Shading,"  In computer vision, convolutional neural networks (CNNs) have recently
achieved new levels of performance for several inverse problems where RGB pixel
appearance is mapped to attributes such as positions, normals or reflectance.
In computer graphics, screen-space shading has recently increased the visual
quality in interactive image synthesis, where per-pixel attributes such as
positions, normals or reflectance of a virtual 3D scene are converted into RGB
pixel appearance, enabling effects like ambient occlusion, indirect light,
scattering, depth-of-field, motion blur, or anti-aliasing. In this paper we
consider the diagonal problem: synthesizing appearance from given per-pixel
attributes using a CNN. The resulting Deep Shading simulates various
screen-space effects at competitive quality and speed while not being
programmed by human experts but learned from example images.
"
550,"Neurally-Guided Procedural Models: Amortized Inference for Procedural
  Graphics Programs using Neural Networks","  Probabilistic inference algorithms such as Sequential Monte Carlo (SMC)
provide powerful tools for constraining procedural models in computer graphics,
but they require many samples to produce desirable results. In this paper, we
show how to create procedural models which learn how to satisfy constraints. We
augment procedural models with neural networks which control how the model
makes random choices based on the output it has generated thus far. We call
such models neurally-guided procedural models. As a pre-computation, we train
these models to maximize the likelihood of example outputs generated via SMC.
They are then used as efficient SMC importance samplers, generating
high-quality results with very few samples. We evaluate our method on
L-system-like models with image-based constraints. Given a desired quality
threshold, neurally-guided models can generate satisfactory results up to 10x
faster than unguided models.
"
551,A Report on Shape Deformation with a Stretching and Bending Energy,"  In this report we describe a mesh editing system that we implemented that
uses a natural stretching and bending energy defined over smooth surfaces. As
such, this energy behaves uniformly under various mesh resolutions. All of the
elements of our approach already exist in the literature. We hope that our
discussions of these energies helps to shed light on the behaviors of these
methods and provides a unified discussion of these methods.
"
552,Graphs Drawing through Fuzzy Clustering,"  Many problems can be presented in an abstract form through a wide range of
binary objects and relations which are defined over problem domain. In these
problems, graphical demonstration of defined binary objects and solutions is
the most suitable representation approach. In this regard, graph drawing
problem discusses the methods for transforming combinatorial graphs to
geometrical drawings in order to visualize them. This paper studies the
force-directed algorithms and multi-surface techniques for drawing general
undirected graphs. Particularly, this research describes force-directed
approach to model the drawing of a general graph as a numerical optimization
problem. So, it can use rich knowledge which is presented as an established
system by the numerical optimization. Moreover, this research proposes the
multi-surface approach as an efficient tool for overcoming local minimums in
standard force-directed algorithms. Next, we introduce a new method for
multi-surface approach based on fuzzy clustering algorithms.
"
553,"Genetic cellular neural networks for generating three-dimensional
  geometry","  There are a number of ways to procedurally generate interesting
three-dimensional shapes, and a method where a cellular neural network is
combined with a mesh growth algorithm is presented here. The aim is to create a
shape from a genetic code in such a way that a crude search can find
interesting shapes. Identical neural networks are placed at each vertex of a
mesh which can communicate with neural networks on neighboring vertices. The
output of the neural networks determine how the mesh grows, allowing
interesting shapes to be produced emergently, mimicking some of the complexity
of biological organism development. Since the neural networks' parameters can
be freely mutated, the approach is amenable for use in a genetic algorithm.
"
554,Curve Networks for Surface Reconstruction,"  Man-made objects usually exhibit descriptive curved features (i.e., curve
networks). The curve network of an object conveys its high-level geometric and
topological structure. We present a framework for extracting feature curve
networks from unstructured point cloud data. Our framework first generates a
set of initial curved segments fitting highly curved regions. We then optimize
these curved segments to respect both data fitting and structural regularities.
Finally, the optimized curved segments are extended and connected into curve
networks using a clustering method. To facilitate effectiveness in case of
severe missing data and to resolve ambiguities, we develop a user interface for
completing the curve networks. Experiments on various imperfect point cloud
data validate the effectiveness of our curve network extraction framework. We
demonstrate the usefulness of the extracted curve networks for surface
reconstruction from incomplete point clouds.
"
555,SMASH: Physics-guided Reconstruction of Collisions from Videos,"  Collision sequences are commonly used in games and entertainment to add drama
and excitement. Authoring even two body collisions in the real world can be
difficult, as one has to get timing and the object trajectories to be correctly
synchronized. After tedious trial-and-error iterations, when objects can
actually be made to collide, then they are difficult to capture in 3D. In
contrast, synthetically generating plausible collisions is difficult as it
requires adjusting different collision parameters (e.g., object mass ratio,
coefficient of restitution, etc.) and appropriate initial parameters. We
present SMASH to directly read off appropriate collision parameters directly
from raw input video recordings. Technically we enable this by utilizing laws
of rigid body collision to regularize the problem of lifting 2D trajectories to
a physically valid 3D reconstruction of the collision. The reconstructed
sequences can then be modified and combined to easily author novel and
plausible collisions. We evaluate our system on a range of synthetic scenes and
demonstrate the effectiveness of our method by accurately reconstructing
several complex real world collision events.
"
556,Towards Zero-Waste Furniture Design,"  In traditional design, shapes are first conceived, and then fabricated. While
this decoupling simplifies the design process, it can result in inefficient
material usage, especially where off-cut pieces are hard to reuse. The
designer, in absence of explicit feedback on material usage remains helpless to
effectively adapt the design -- even though design variabilities exist. In this
paper, we investigate {\em waste minimizing furniture design} wherein based on
the current design, the user is presented with design variations that result in
more effective usage of materials. Technically, we dynamically analyze material
space layout to determine {\em which} parts to change and {\em how}, while
maintaining original design intent specified in the form of design constraints.
We evaluate the approach on simple and complex furniture design scenarios, and
demonstrate effective material usage that is difficult, if not impossible, to
achieve without computational support.
"
557,"BundleFusion: Real-time Globally Consistent 3D Reconstruction using
  On-the-fly Surface Re-integration","  Real-time, high-quality, 3D scanning of large-scale scenes is key to mixed
reality and robotic applications. However, scalability brings challenges of
drift in pose estimation, introducing significant errors in the accumulated
model. Approaches often require hours of offline processing to globally correct
model errors. Recent online methods demonstrate compelling results, but suffer
from: (1) needing minutes to perform online correction preventing true
real-time use; (2) brittle frame-to-frame (or frame-to-model) pose estimation
resulting in many tracking failures; or (3) supporting only unstructured
point-based representations, which limit scan quality and applicability. We
systematically address these issues with a novel, real-time, end-to-end
reconstruction framework. At its core is a robust pose estimation strategy,
optimizing per frame for a global set of camera poses by considering the
complete history of RGB-D input with an efficient hierarchical approach. We
remove the heavy reliance on temporal tracking, and continually localize to the
globally optimized frames instead. We contribute a parallelizable optimization
framework, which employs correspondences based on sparse features and dense
geometric and photometric matching. Our approach estimates globally optimized
(i.e., bundle adjusted) poses in real-time, supports robust tracking with
recovery from gross tracking failures (i.e., relocalization), and re-estimates
the 3D model in real-time to ensure global consistency; all within a single
framework. Our approach outperforms state-of-the-art online systems with
quality on par to offline methods, but with unprecedented speed and scan
completeness. Our framework leads to a comprehensive online scanning solution
for large indoor environments, enabling ease of use and high-quality results.
"
558,"Reading Between the Pixels: Photographic Steganography for Camera
  Display Messaging","  We exploit human color metamers to send light-modulated messages less visible
to the human eye, but recoverable by cameras. These messages are a key
component to camera-display messaging, such as handheld smartphones capturing
information from electronic signage. Each color pixel in the display image is
modified by a particular color gradient vector. The challenge is to find the
color gradient that maximizes camera response, while minimizing human response.
The mismatch in human spectral and camera sensitivity curves creates an
opportunity for hidden messaging. Our approach does not require knowledge of
these sensitivity curves, instead we employ a data-driven method. We learn an
ellipsoidal partitioning of the six-dimensional space of colors and color
gradients. This partitioning creates metamer sets defined by the base color at
the display pixel and the color gradient direction for message encoding. We
sample from the resulting metamer sets to find color steps for each base color
to embed a binary message into an arbitrary image with reduced visible
artifacts. Unlike previous methods that rely on visually obtrusive intensity
modulation, we embed with color so that the message is more hidden. Ordinary
displays and cameras are used without the need for expensive LEDs or high speed
devices. The primary contribution of this work is a framework to map the pixels
in an arbitrary image to a metamer pair for steganographic photo messaging.
"
559,"Nielson-type transfinite triangular interpolants by means of quadratic
  energy functional optimizations","  We generalize the transfinite triangular interpolant of (Nielson, 1987) in
order to generate visually smooth (not necessarily polynomial) local
interpolating quasi-optimal triangular spline surfaces. Given as input a
triangular mesh stored in a half-edge data structure, at first we produce a
local interpolating network of curves by optimizing quadratic energy
functionals described along the arcs as weighted combinations of squared length
variations of first and higher order derivatives, then by optimizing weighted
combinations of first and higher order quadratic thin-plate-spline-like
energies we locally interpolate each curvilinear face of the previous curve
network with triangular patches that are usually only $C^0$ continuous along
their common boundaries. In a following step, these local interpolating optimal
triangular surface patches are used to construct quasi-optimal continuous
vector fields of averaged unit normals along the joints, and finally we extend
the $G^1$ continuous transfinite triangular interpolation scheme of (Nielson,
1987) by imposing further optimality constraints concerning the isoparametric
lines of those groups of three side-vertex interpolants that have to be
convexly blended in order to generate the final visually smooth local
interpolating quasi-optimal triangular spline surface. While we describe the
problem in a general context, we present examples in special polynomial,
trigonometric, hyperbolic and algebraic-trigonometric vector spaces of
functions that may be useful both in computer-aided geometric design and in
computer graphics.
"
560,Keyboard Based Control of Four Dimensional Rotations,"  Aiming at applications to the scientific visualization of three dimensional
simulations with time evolution, a keyboard based control method to specify
rotations in four dimensions is proposed. It is known that four dimensional
rotations are generally so-called double rotations, and a double rotation is a
combination of simultaneously applied two simple rotations. The proposed method
can specify both the simple and double rotations by single key typings of the
keyboard. The method is tested in visualizations of a regular pentachoron in
four dimensional space by a hyperplane slicing.
"
561,Infrared Colorization Using Deep Convolutional Neural Networks,"  This paper proposes a method for transferring the RGB color spectrum to
near-infrared (NIR) images using deep multi-scale convolutional neural
networks. A direct and integrated transfer between NIR and RGB pixels is
trained. The trained model does not require any user guidance or a reference
image database in the recall phase to produce images with a natural appearance.
To preserve the rich details of the NIR image, its high frequency features are
transferred to the estimated RGB image. The presented approach is trained and
evaluated on a real-world dataset containing a large amount of road scene
images in summer. The dataset was captured by a multi-CCD NIR/RGB camera, which
ensures a perfect pixel to pixel registration.
"
562,On the Hessian of Shape Matching Energy,"  In this technical report we derive the analytic form of the Hessian matrix
for shape matching energy. Shape matching is a useful technique for meshless
deformation, which can be easily combined with multiple techniques in real-time
dynamics. Nevertheless, it has been rarely applied in scenarios where implicit
integrators are required, and hence strong viscous damping effect, though
popular in simulation systems nowadays, is forbidden for shape matching. The
reason lies in the difficulty to derive the Hessian matrix of the shape
matching energy. Computing the Hessian matrix correctly, and stably, is the key
to more broadly application of shape matching in implicitly-integrated systems.
"
563,"Algorithms and Identities for B$\acute{e}$zier curves via Post Quantum
  Blossom","  In this paper, a new analogue of blossom based on post quantum calculus is
introduced. The post quantum blossom has been adapted for developing identities
and algorithms for Bernstein bases and B$\acute{e}$zier curves. By applying the
post quantum blossom, various new identities and formulae expressing the
monomials in terms of the post quantun Bernstein basis functions and a post
quantun variant of Marsden's identity are investigated. For each post quantum
B$\acute{e}$zier curves of degree $m,$ a collection of $m!$ new, affine
invariant, recursive evaluation algorithms are derived.
"
564,VConv-DAE: Deep Volumetric Shape Learning Without Object Labels,"  With the advent of affordable depth sensors, 3D capture becomes more and more
ubiquitous and already has made its way into commercial products. Yet,
capturing the geometry or complete shapes of everyday objects using scanning
devices (e.g. Kinect) still comes with several challenges that result in noise
or even incomplete shapes. Recent success in deep learning has shown how to
learn complex shape distributions in a data-driven way from large scale 3D CAD
Model collections and to utilize them for 3D processing on volumetric
representations and thereby circumventing problems of topology and
tessellation. Prior work has shown encouraging results on problems ranging from
shape completion to recognition. We provide an analysis of such approaches and
discover that training as well as the resulting representation are strongly and
unnecessarily tied to the notion of object labels. Thus, we propose a full
convolutional volumetric auto encoder that learns volumetric representation
from noisy data by estimating the voxel occupancy grids. The proposed method
outperforms prior work on challenging tasks like denoising and shape
completion. We also show that the obtained deep embedding gives competitive
performance when used for classification and promising results for shape
interpolation.
"
565,"Opt: A Domain Specific Language for Non-linear Least Squares
  Optimization in Graphics and Imaging","  Many graphics and vision problems can be expressed as non-linear least
squares optimizations of objective functions over visual data, such as images
and meshes. The mathematical descriptions of these functions are extremely
concise, but their implementation in real code is tedious, especially when
optimized for real-time performance on modern GPUs in interactive applications.
In this work, we propose a new language, Opt (available under
http://optlang.org), for writing these objective functions over image- or
graph-structured unknowns concisely and at a high level. Our compiler
automatically transforms these specifications into state-of-the-art GPU solvers
based on Gauss-Newton or Levenberg-Marquardt methods. Opt can generate
different variations of the solver, so users can easily explore tradeoffs in
numerical precision, matrix-free methods, and solver approaches. In our
results, we implement a variety of real-world graphics and vision applications.
Their energy functions are expressible in tens of lines of code, and produce
highly-optimized GPU solver implementations. These solver have performance
competitive with the best published hand-tuned, application-specific GPU
solvers, and orders of magnitude beyond a general-purpose auto-generated
solver.
"
566,Towards Real-time Simulation of Hyperelastic Materials,"  We present a new method for real-time physics-based simulation supporting
many different types of hyperelastic materials. Previous methods such as
Position Based or Projective Dynamics are fast, but support only limited
selection of materials; even classical materials such as the Neo-Hookean
elasticity are not supported. Recently, Xu et al. [2015] introduced new
""spline-based materials"" which can be easily controlled by artists to achieve
desired animation effects. Simulation of these types of materials currently
relies on Newton's method, which is slow, even with only one iteration per
timestep. In this paper, we show that Projective Dynamics can be interpreted as
a quasi-Newton method. This insight enables very efficient simulation of a
large class of hyperelastic materials, including the Neo-Hookean, spline-based
materials, and others. The quasi-Newton interpretation also allows us to
leverage ideas from numerical optimization. In particular, we show that our
solver can be further accelerated using L-BFGS updates (Limited-memory
Broyden-Fletcher-Goldfarb-Shanno algorithm). Our final method is typically more
than 10 times faster than one iteration of Newton's method without compromising
quality. In fact, our result is often more accurate than the result obtained
with one iteration of Newton's method. Our method is also easier to implement,
implying reduced software development costs.
"
567,Context Encoders: Feature Learning by Inpainting,"  We present an unsupervised visual feature learning algorithm driven by
context-based pixel prediction. By analogy with auto-encoders, we propose
Context Encoders -- a convolutional neural network trained to generate the
contents of an arbitrary image region conditioned on its surroundings. In order
to succeed at this task, context encoders need to both understand the content
of the entire image, as well as produce a plausible hypothesis for the missing
part(s). When training context encoders, we have experimented with both a
standard pixel-wise reconstruction loss, as well as a reconstruction plus an
adversarial loss. The latter produces much sharper results because it can
better handle multiple modes in the output. We found that a context encoder
learns a representation that captures not just appearance but also the
semantics of visual structures. We quantitatively demonstrate the effectiveness
of our learned features for CNN pre-training on classification, detection, and
segmentation tasks. Furthermore, context encoders can be used for semantic
inpainting tasks, either stand-alone or as initialization for non-parametric
methods.
"
568,"A Collaborative Untethered Virtual Reality Environment for Interactive
  Social Network Visualization","  The increasing prevalence of Virtual Reality technologies as a platform for
gaming and video playback warrants research into how to best apply the current
state of the art to challenges in data visualization. Many current VR systems
are noncollaborative, while data analysis and visualization is often a
multi-person process. Our goal in this paper is to address the technical and
user experience challenges that arise when creating VR environments for
collaborative data visualization. We focus on the integration of multiple
tracking systems and the new interaction paradigms that this integration can
enable, along with visual design considerations that apply specifically to
collaborative network visualization in virtual reality. We demonstrate a system
for collaborative interaction with large 3D layouts of Twitter friend/follow
networks. The system is built by combining a 'Holojam' architecture (multiple
GearVR Headsets within an OptiTrack motion capture stage) and Perception Neuron
motion suits, to offer an untethered, full-room multi-person visualization
experience.
"
569,Multiview Differential Geometry of Curves,"  The field of multiple view geometry has seen tremendous progress in
reconstruction and calibration due to methods for extracting reliable point
features and key developments in projective geometry. Point features, however,
are not available in certain applications and result in unstructured point
cloud reconstructions. General image curves provide a complementary feature
when keypoints are scarce, and result in 3D curve geometry, but face challenges
not addressed by the usual projective geometry of points and algebraic curves.
We address these challenges by laying the theoretical foundations of a
framework based on the differential geometry of general curves, including
stationary curves, occluding contours, and non-rigid curves, aiming at stereo
correspondence, camera estimation (including calibration, pose, and multiview
epipolar geometry), and 3D reconstruction given measured image curves. By
gathering previous results into a cohesive theory, novel results were made
possible, yielding three contributions. First we derive the differential
geometry of an image curve (tangent, curvature, curvature derivative) from that
of the underlying space curve (tangent, curvature, curvature derivative,
torsion). Second, we derive the differential geometry of a space curve from
that of two corresponding image curves. Third, the differential motion of an
image curve is derived from camera motion and the differential geometry and
motion of the space curve. The availability of such a theory enables novel
curve-based multiview reconstruction and camera estimation systems to augment
existing point-based approaches. This theory has been used to reconstruct a ""3D
curve sketch"", to determine camera pose from local curve geometry, and
tracking; other developments are underway.
"
570,Augmented Reality Oculus Rift,"  This paper covers the whole process of developing an Augmented Reality
Stereoscopig Render Engine for the Oculus Rift. To capture the real world in
form of a camera stream, two cameras with fish-eye lenses had to be installed
on the Oculus Rift DK1 hardware. The idea was inspired by Steptoe
\cite{steptoe2014presence}. After the introduction, a theoretical part covers
all the most neccessary elements to achieve an AR System for the Oculus Rift,
following the implementation part where the code from the AR Stereo Engine is
explained in more detail. A short conclusion section shows some results,
reflects some experiences and in the final chapter some future works will be
discussed. The project can be accessed via the git repository
https://github.com/MaXvanHeLL/ARift.git.
"
571,Isogeometric analysis using manifold-based smooth basis functions,"  We present an isogeometric analysis technique that builds on manifold-based
smooth basis functions for geometric modelling and analysis. Manifold-based
surface construction techniques are well known in geometric modelling and a
number of variants exist. Common to all is the concept of constructing a smooth
surface by blending together overlapping patches (or, charts), as in
differential geometry description of manifolds. Each patch on the surface has a
corresponding planar patch with a smooth one-to-one mapping onto the surface.
In our implementation, manifold techniques are combined with conformal
parametrisations and the partition-of-unity method for deriving smooth basis
functions on unstructured quadrilateral meshes. Each vertex and its adjacent
elements on the surface control mesh have a corresponding planar patch of
elements. The star-shaped planar patch with congruent wedge-shaped elements is
smoothly parameterised with copies of a conformally mapped unit square. The
conformal maps can be easily inverted in order to compute the transition
functions between the different planar patches that have an overlap on the
surface. On the collection of star-shaped planar patches the partition of unity
method is used for approximation. The smooth partition of unity, or blending
functions, are assembled from tensor-product b-spline segments defined on a
unit square. On each patch a polynomial with a prescribed degree is used as a
local approximant. To obtain a mesh-based approximation scheme, the
coefficients of the local approximants are expressed in dependence of vertex
coefficients. This yields a basis function for each vertex of the mesh which is
smooth and non-zero over a vertex and its adjacent elements. Our numerical
simulations indicate the optimal convergence of the resulting approximation
scheme for Poisson problems and near optimal convergence for thin-plate and
thin-shell problems.
"
572,Squares that Look Round: Transforming Spherical Images,"  We propose M\""obius transformations as the natural rotation and scaling tools
for editing spherical images. As an application we produce spherical Droste
images. We obtain other self-similar visual effects using rational functions,
elliptic functions, and Schwarz-Christoffel maps.
"
573,Adaptive Mesh Booleans,"  We present a new method for performing Boolean operations on volumes
represented as triangle meshes. In contrast to existing methods which treat
meshes as 3D polyhedra and try to partition the faces at their exact
intersection curves, we treat meshes as adaptive surfaces which can be
arbitrarily refined. Rather than depending on computing precise face
intersections, our approach refines the input meshes in the intersection
regions, then discards intersecting triangles and fills the resulting holes
with high-quality triangles. The original intersection curves are approximated
to a user-definable precision, and our method can identify and preserve creases
and sharp features. Advantages of our approach include the ability to trade
speed for accuracy, support for open meshes, and the ability to incorporate
tolerances to handle cases where large numbers of faces are slightly
inter-penetrating or near-coincident.
"
574,"Sufficient Conditions for Tuza's Conjecture on Packing and Covering
  Triangles","  Given a simple graph $G=(V,E)$, a subset of $E$ is called a triangle cover if
it intersects each triangle of $G$. Let $\nu_t(G)$ and $\tau_t(G)$ denote the
maximum number of pairwise edge-disjoint triangles in $G$ and the minimum
cardinality of a triangle cover of $G$, respectively. Tuza conjectured in 1981
that $\tau_t(G)/\nu_t(G)\le2$ holds for every graph $G$. In this paper, using a
hypergraph approach, we design polynomial-time combinatorial algorithms for
finding small triangle covers. These algorithms imply new sufficient conditions
for Tuza's conjecture on covering and packing triangles. More precisely,
suppose that the set $\mathscr T_G$ of triangles covers all edges in $G$. We
show that a triangle cover of $G$ with cardinality at most $2\nu_t(G)$ can be
found in polynomial time if one of the following conditions is satisfied: (i)
$\nu_t(G)/|\mathscr T_G|\ge\frac13$, (ii) $\nu_t(G)/|E|\ge\frac14$, (iii)
$|E|/|\mathscr T_G|\ge2$.
  Keywords: Triangle cover, Triangle packing, Linear 3-uniform hypergraphs,
Combinatorial algorithms
"
575,Real-time collision detection method for deformable bodies,"  This paper presents a real-time solution for collision detection between
objects based on the physics properties. Traditional approaches on collision
detection often rely on the geometric relationships that computing the
intersections between polygons. Such technique is very computationally
expensive when applied for deformable objects. As an alternative, we
approximate the 3D mesh in an spherical surface implicitly. This allows us to
perform a coarse-level collision detection at extremely fast speed. Then a
dynamic programming based procedure is applied to identify the collision in
fine details. Our method demonstrates better prevention to collision tunnelling
and works more efficiently than the state-of-the-arts.
"
576,CNN based texture synthesize with Semantic segment,"  Deep learning algorithm display powerful ability in Computer Vision area, in
recent year, the CNN has been applied to solve problems in the subarea of
Image-generating, which has been widely applied in areas such as photo editing,
image design, computer animation, real-time rendering for large scale of scenes
and for visual effects in movies. However in the texture synthesize procedure.
The state-of-art CNN can not capture the spatial location of texture in image,
lead to significant distortion after texture synthesize, we propose a new way
to generating-image by adding the semantic segment step with deep learning
algorithm as Pre-Processing and analyze the outcome.
"
577,"Thingi10K: A Dataset of 10,000 3D-Printing Models","  Empirically validating new 3D-printing related algorithms and implementations
requires testing data representative of inputs encountered \emph{in the wild}.
An ideal benchmarking dataset should not only draw from the same distribution
of shapes people print in terms of class (e.g., toys, mechanisms, jewelry),
representation type (e.g., triangle soup meshes) and complexity (e.g., number
of facets), but should also capture problems and artifacts endemic to 3D
printing models (e.g., self-intersections, non-manifoldness). We observe that
the contextual and geometric characteristics of 3D printing models differ
significantly from those used for computer graphics applications, not to
mention standard models (e.g., Stanford bunny, Armadillo, Fertility). We
present a new dataset of 10,000 models collected from an online 3D printing
model-sharing database. Via analysis of both geometric (e.g., triangle aspect
ratios, manifoldness) and contextual (e.g., licenses, tags, classes)
characteristics, we demonstrate that this dataset represents a more concise
summary of real-world models used for 3D printing compared to existing
datasets. To facilitate future research endeavors, we also present an online
query interface to select subsets of the dataset according to project-specific
characteristics. The complete dataset and per-model statistical data are freely
available to the public.
"
578,"Efficient Feature-based Image Registration by Mapping Sparsified
  Surfaces","  With the advancement in the digital camera technology, the use of high
resolution images and videos has been widespread in the modern society. In
particular, image and video frame registration is frequently applied in
computer graphics and film production. However, conventional registration
approaches usually require long computational time for high resolution images
and video frames. This hinders the application of the registration approaches
in the modern industries. In this work, we first propose a new image
representation method to accelerate the registration process by triangulating
the images effectively. For each high resolution image or video frame, we
compute an optimal coarse triangulation which captures the important features
of the image. Then, we apply a surface registration algorithm to obtain a
registration map which is used to compute the registration of the high
resolution image. Experimental results suggest that our overall algorithm is
efficient and capable to achieve a high compression rate while the accuracy of
the registration is well retained when compared with the conventional
grid-based approach. Also, the computational time of the registration is
significantly reduced using our triangulation-based approach.
"
579,Visualization of Publication Impact,"  Measuring scholarly impact has been a topic of much interest in recent years.
While many use the citation count as a primary indicator of a publications
impact, the quality and impact of those citations will vary. Additionally, it
is often difficult to see where a paper sits among other papers in the same
research area. Questions we wished to answer through this visualization were:
is a publication cited less than publications in the field?; is a publication
cited by high or low impact publications?; and can we visually compare the
impact of publications across a result set? In this work we address the above
questions through a new visualization of publication impact. Our technique has
been applied to the visualization of citation information in INSPIREHEP
(http://www.inspirehep.net), the largest high energy physics publication
repository.
"
580,As-exact-as-possible repair of unprintable STL files,"  Purpose: The class of models that can be represented by STL files is larger
than the class of models that can be printed using additive manufacturing
technologies. Stated differently, there exist well-formed STL files that cannot
be printed. In this paper such a gap is formalized and a fully automatic
procedure is described to turn any such file into a printable model.
  Approach: Based on well-established concepts from combinatorial topology, we
provide an unambiguous description of all the mathematical entities involved in
the modeling-printing pipeline. Specifically, we formally define the conditions
that an STL file must satisfy to be printable and, based on these, we design an
as-exact-as-possible repairing algorithm.
  Findings: We have found that, in order to cope with all the possible triangle
configurations, the algorithm must distinguish between triangles that bound
solid parts and triangles that constitute zero-thickness sheets. Only the
former set can be fixed without distortion.
  Originality: Previous methods that are guaranteed to fix all the possible
configurations provide only approximate solutions with an unnecessary
distortion. Conversely, our procedure is as exact as possible, meaning that no
visible distortion is introduced unless it is strictly imposed by limitations
of the printing device. Thanks to such an unprecedented flexibility and
accuracy, this algorithm is expected to significantly simplify the
modeling-printing process, in particular within the continuously emerging
non-professional ""maker"" communities.
"
581,Quantitative Analysis of Saliency Models,"  Previous saliency detection research required the reader to evaluate
performance qualitatively, based on renderings of saliency maps on a few
shapes. This qualitative approach meant it was unclear which saliency models
were better, or how well they compared to human perception. This paper provides
a quantitative evaluation framework that addresses this issue. In the first
quantitative analysis of 3D computational saliency models, we evaluate four
computational saliency models and two baseline models against ground-truth
saliency collected in previous work.
"
582,3D Printed Stencils for Texturing Flat Surfaces,"  We address the problem of texturing flat surfaces by spray-painting through
3D printed stencils. We propose a system that (1) decomposes an image into
alpha-blended layers; (2) computes a stippling given a transparency channel;
(3) generates a 3D printed stencil given a stippling and (4) simulates the
effects of spray-painting through the stencil.
"
583,Optically lightweight tracking of objects around a corner,"  The observation of objects located in inaccessible regions is a recurring
challenge in a wide variety of important applications. Recent work has shown
that indirect diffuse light reflections can be used to reconstruct objects and
two-dimensional (2D) patterns around a corner. However, these prior methods
always require some specialized setup involving either ultrafast detectors or
narrowband light sources. Here we show that occluded objects can be tracked in
real time using a standard 2D camera and a laser pointer. Unlike previous
methods based on the backprojection approach, we formulate the problem in an
analysis-by-synthesis sense. By repeatedly simulating light transport through
the scene, we determine the set of object parameters that most closely fits the
measured intensity distribution. We experimentally demonstrate that this
approach is capable of following the translation of unknown objects, and
translation and orientation of a known object, in real time.
"
584,"Isogeometric computation reuse method for complex objects with
  topology-consistent volumetric parameterization","  Volumetric spline parameterization and computational efficiency are two main
challenges in isogeometric analysis (IGA). To tackle this problem, we propose a
framework of computation reuse in IGA on a set of three-dimensional models with
similar semantic features. Given a template domain, B-spline based consistent
volumetric parameterization is first constructed for a set of models with
similar semantic features. An efficient quadrature-free method is investigated
in our framework to compute the entries of stiffness matrix by Bezier
extraction and polynomial approximation. In our approach, evaluation on the
stiffness matrix and imposition of the boundary conditions can be pre-computed
and reused during IGA on a set of CAD models. Examples with complex geometry
are presented to show the effectiveness of our methods, and efficiency similar
to the computation in linear finite element analysis can be achieved for IGA
taken on a set of models.
"
585,Automatic 3D Reconstruction for Symmetric Shapes,"  Generic 3D reconstruction from a single image is a difficult problem. A lot
of data loss occurs in the projection. A domain based approach to
reconstruction where we solve a smaller set of problems for a particular use
case lead to greater returns. The project provides a way to automatically
generate full 3-D renditions of actual symmetric images that have some prior
information provided in the pipeline by a recognition algorithm. We provide a
critical analysis on how this can be enhanced and improved to provide a general
reconstruction framework for automatic reconstruction for any symmetric shape.
"
586,Manifold Approximation by Moving Least-Squares Projection (MMLS),"  In order to avoid the curse of dimensionality, frequently encountered in Big
Data analysis, there was a vast development in the field of linear and
nonlinear dimension reduction techniques in recent years. These techniques
(sometimes referred to as manifold learning) assume that the scattered input
data is lying on a lower dimensional manifold, thus the high dimensionality
problem can be overcome by learning the lower dimensionality behavior. However,
in real life applications, data is often very noisy. In this work, we propose a
method to approximate $\mathcal{M}$ a $d$-dimensional $C^{m+1}$ smooth
submanifold of $\mathbb{R}^n$ ($d \ll n$) based upon noisy scattered data
points (i.e., a data cloud). We assume that the data points are located ""near""
the lower dimensional manifold and suggest a non-linear moving least-squares
projection on an approximating $d$-dimensional manifold. Under some mild
assumptions, the resulting approximant is shown to be infinitely smooth and of
high approximation order (i.e., $O(h^{m+1})$, where $h$ is the fill distance
and $m$ is the degree of the local polynomial approximation). The method
presented here assumes no analytic knowledge of the approximated manifold and
the approximation algorithm is linear in the large dimension $n$. Furthermore,
the approximating manifold can serve as a framework to perform operations
directly on the high dimensional data in a computationally efficient manner.
This way, the preparatory step of dimension reduction, which induces
distortions to the data, can be avoided altogether.
"
587,SurfCuit: Surface Mounted Circuits on 3D Prints,"  We present, SurfCuit, a novel approach to design and construction of electric
circuits on the surface of 3D prints. Our surface mounting technique allows
durable construction of circuits on the surface of 3D prints. SurfCuit does not
require tedious circuit casing design or expensive set-ups, thus we can
expedite the process of circuit construction for 3D models. Our technique
allows the user to construct complex circuits for consumer-level desktop fused
decomposition modeling (FDM) 3D printers. The key idea behind our technique is
that FDM plastic forms a strong bond with metal when it is melted. This
observation enables construction of a robust circuit traces using copper tape
and soldering. We also present an interactive tool to design such circuits on
arbitrary 3D geometry. We demonstrate the effectiveness of our approach through
various actual construction examples.
"
588,Visualizing Natural Language Descriptions: A Survey,"  A natural language interface exploits the conceptual simplicity and
naturalness of the language to create a high-level user-friendly communication
channel between humans and machines. One of the promising applications of such
interfaces is generating visual interpretations of semantic content of a given
natural language that can be then visualized either as a static scene or a
dynamic animation. This survey discusses requirements and challenges of
developing such systems and reports 26 graphical systems that exploit natural
language interfaces and addresses both artificial intelligence and
visualization aspects. This work serves as a frame of reference to researchers
and to enable further advances in the field.
"
589,Neural ideals and stimulus space visualization,"  A neural code $\mathcal{C}$ is a collection of binary vectors of a given
length n that record the co-firing patterns of a set of neurons. Our focus is
on neural codes arising from place cells, neurons that respond to geographic
stimulus. In this setting, the stimulus space can be visualized as subset of
$\mathbb{R}^2$ covered by a collection $\mathcal{U}$ of convex sets such that
the arrangement $\mathcal{U}$ forms an Euler diagram for $\mathcal{C}$. There
are some methods to determine whether such a convex realization $\mathcal{U}$
exists; however, these methods do not describe how to draw a realization. In
this work, we look at the problem of algorithmically drawing Euler diagrams for
neural codes using two polynomial ideals: the neural ideal, a pseudo-monomial
ideal; and the neural toric ideal, a binomial ideal. In particular, we study
how these objects are related to the theory of piercings in information
visualization, and we show how minimal generating sets of the ideals reveal
whether or not a code is $0$, $1$, or $2$-inductively pierced.
"
590,"A Visualization Method of Four Dimensional Polytopes by Oval Display of
  Parallel Hyperplane Slices","  A method to visualize polytopes in a four dimensional euclidian space
$(x,y,z,w)$ is proposed. A polytope is sliced by multiple hyperplanes that are
parallel each other and separated by uniform intervals. Since the hyperplanes
are perpendicular to the $w$ axis, the resulting multiple slices appear in the
three-dimensional $(x,y,z)$ space and they are shown by the standard computer
graphics. The polytope is rotated extrinsically in the four dimensional space
by means of a simple input method based on keyboard typings. The multiple
slices are placed on a parabola curve in the three-dimensional world
coordinates. The slices in a view window form an oval appearance. Both the
simple and the double rotations in the four dimensional space are applied to
the polytope. All slices synchronously change their shapes when a rotation is
applied to the polytope. The compact display in the oval of many slices with
the help of quick rotations facilitate a grasp of the four dimensional
configuration of the polytope.
"
591,"Model-Driven Feed-Forward Prediction for Manipulation of Deformable
  Objects","  Robotic manipulation of deformable objects is a difficult problem especially
because of the complexity of the many different ways an object can deform.
Searching such a high dimensional state space makes it difficult to recognize,
track, and manipulate deformable objects. In this paper, we introduce a
predictive, model-driven approach to address this challenge, using a
pre-computed, simulated database of deformable object models. Mesh models of
common deformable garments are simulated with the garments picked up in
multiple different poses under gravity, and stored in a database for fast and
efficient retrieval. To validate this approach, we developed a comprehensive
pipeline for manipulating clothing as in a typical laundry task. First, the
database is used for category and pose estimation for a garment in an arbitrary
position. A fully featured 3D model of the garment is constructed in real-time
and volumetric features are then used to obtain the most similar model in the
database to predict the object category and pose. Second, the database can
significantly benefit the manipulation of deformable objects via non-rigid
registration, providing accurate correspondences between the reconstructed
object model and the database models. Third, the accurate model simulation can
also be used to optimize the trajectories for manipulation of deformable
objects, such as the folding of garments. Extensive experimental results are
shown for the tasks above using a variety of different clothing.
"
592,"Optimized Automatic Code Generation for Geometric Algebra Based
  Algorithms with Ray Tracing Application","  Automatic code generation for low-dimensional geometric algorithms is capable
of producing efficient low-level software code through a high-level geometric
domain specific language. Geometric Algebra (GA) is one of the most suitable
algebraic systems for being the base for such code generator. This work
presents an attempt at realizing such idea in practice. A novel GA-based
geometric code generator, called GMac, is proposed. Comparisons to similar
GA-based code generators are provided. The possibility of fully benefiting from
the symbolic power of GA while obtaining good performance and maintainability
of software implementations is illustrated through a ray tracing application.
"
593,HoloMed: A Low-Cost Gesture-Based Holographic,"  During medicine studies, visualization of certain elements is common and
indispensable in order to get more information about the way they work.
Currently, we resort to the use of photographs -which are insufficient due to
being static- or tests in patients, which can be invasive or even risky.
Therefore, a low-cost approach is proposed by using a 3D visualization. This
paper presents a holographic system built with low-cost materials for teaching
obstetrics, where student interaction is performed by using voice and gestures.
Our solution, which we called HoloMed, is focused on the projection of a
euthocic normal delivery under a web-based infrastructure which also employs a
Kinect. HoloMed is divided in three (3) essential modules: a gesture analyzer,
a data server, and a holographic projection architecture, which can be executed
in several interconnected computers using different network protocols. Tests
used for determining the user's position, illumination factors, and response
times, demonstrate HoloMed's effectiveness as a low-cost system for teaching,
using a natural user interface and 3D images.
"
594,Dappled tiling,"  We consider a certain tiling problem of a planar region in which there are no
long horizontal or vertical strips consisting of copies of the same tile.
Intuitively speaking, we would like to create a dappled pattern with two or
more kinds of tiles. We give an efficient algorithm to turn any tiling into one
satisfying the condition, and discuss its applications in texturing.
"
595,Mesh Denoising based on Normal Voting Tensor and Binary Optimization,"  This paper presents a tensor multiplication based smoothing algorithm that
follows a two step denoising method. Unlike other traditional averaging
approaches, our approach uses an element based normal voting tensor to compute
smooth surfaces. By introducing a binary optimization on the proposed tensor
together with a local binary neighborhood concept, our algorithm better retains
sharp features and produces smoother umbilical regions than previous
approaches. On top of that, we provide a stochastic analysis on the different
kinds of noise based on the average edge length. The quantitative and visual
results demonstrate the performance our method is better compared to state of
the art smoothing approaches.
"
596,How2Sketch: Generating Easy-To-Follow Tutorials for Sketching 3D Objects,"  Accurately drawing 3D objects is difficult for untrained individuals, as it
requires an understanding of perspective and its effects on geometry and
proportions. Step-by-step tutorials break the complex task of sketching an
entire object down into easy-to-follow steps that even a novice can follow.
However, creating such tutorials requires expert knowledge and is a
time-consuming task. As a result, the availability of tutorials for a given
object or viewpoint is limited. How2Sketch addresses this problem by
automatically generating easy-to-follow tutorials for arbitrary 3D objects.
Given a segmented 3D model and a camera viewpoint,it computes a sequence of
steps for constructing a drawing scaffold comprised of geometric primitives,
which helps the user draw the final contours in correct perspective and
proportion. To make the drawing scaffold easy to construct, the algorithm
solves for an ordering among the scaffolding primitives and explicitly makes
small geometric modifications to the size and location of the object parts to
simplify relative positioning. Technically, we formulate this scaffold
construction as a single selection problem that simultaneously solves for the
ordering and geometric changes of the primitives. We demonstrate our algorithm
for generating tutorials on a variety of man-made objects and evaluate how
easily the tutorials can be followed with a user study.
"
597,3D visualization of astronomy data cubes using immersive displays,"  We report on an exploratory project aimed at performing immersive 3D
visualization of astronomical data, starting with spectral-line radio data
cubes from galaxies. This work is done as a collaboration between the
Department of Physics and Astronomy and the Department of Computer Science at
the University of Manitoba. We are building our prototype using the 3D engine
Unity, because of its ease of use for integration with advanced displays such
as a CAVE environment, a zSpace tabletop, or virtual reality headsets. We
address general issues regarding 3D visualization, such as: load and convert
astronomy data, perform volume rendering on the GPU, and produce physically
meaningful visualizations using principles of visual literacy. We discuss some
challenges to be met when designing a user interface that allows us to take
advantage of this new way of exploring data. We hope to lay the foundations for
an innovative framework useful for all astronomers who use spectral line data
cubes, and encourage interested parties to join our efforts. This pilot project
addresses the challenges presented by frontier astronomy experiments, such as
the Square Kilometre Array and its precursors.
"
598,Registration of Volumetric Prostate Scans using Curvature Flow,"  Radiological imaging of the prostate is becoming more popular among
researchers and clinicians in searching for diseases, primarily cancer. Scans
might be acquired with different equipment or at different times for prognosis
monitoring, with patient movement between scans, resulting in multiple datasets
that need to be registered. For these cases, we introduce a method for
volumetric registration using curvature flow. Multiple prostate datasets are
mapped to canonical solid spheres, which are in turn aligned and registered
through the use of identified landmarks on or within the gland. Theoretical
proof and experimental results show that our method produces homeomorphisms
with feature constraints. We provide thorough validation of our method by
registering prostate scans of the same patient in different orientations, from
different days and using different modes of MRI. Our method also provides the
foundation for a general group-wise registration using a standard reference,
defined on the complex plane, for any input. In the present context, this can
be used for registering as many scans as needed for a single patient or
different patients on the basis of age, weight or even malignant and
non-malignant attributes to study the differences in general population. Though
we present this technique with a specific application to the prostate, it is
generally applicable for volumetric registration problems.
"
599,Multimodal Brain Visualization,"  Current connectivity diagrams of human brain image data are either overly
complex or overly simplistic. In this work we introduce simple yet accurate
interactive visual representations of multiple brain image structures and the
connectivity among them. We map cortical surfaces extracted from human brain
magnetic resonance imaging (MRI) data onto 2D surfaces that preserve shape
(angle), extent (area), and spatial (neighborhood) information for 2D (circular
disk) and 3D (spherical) mapping, split these surfaces into separate patches,
and cluster functional and diffusion tractography MRI connections between pairs
of these patches. The resulting visualizations are easier to compute on and
more visually intuitive to interact with than the original data, and facilitate
simultaneous exploration of multiple data sets, modalities, and statistical
maps.
"
600,Efficient Optimal Control of Smoke using Spacetime Multigrid,"  We present a novel algorithm to control the physically-based animation of
smoke. Given a set of keyframe smoke shapes, we compute a dense sequence of
control force fields that can drive the smoke shape to match several keyframes
at certain time instances. Our approach formulates this control problem as a
PDE constrained spacetime optimization and computes locally optimal control
forces as the stationary point of the Karush-Kuhn-Tucker conditions. In order
to reduce the high complexity of multiple passes of fluid resimulation, we
utilize the coherence between consecutive fluid simulation passes and update
our solution using a novel spacetime full approximation scheme (STFAS). We
demonstrate the benefits of our approach by computing accurate solutions on 2D
and 3D benchmarks. In practice, we observe more than an order of magnitude
improvement over prior methods.
"
601,"Fast Spherical Quasiconformal Parameterization of Genus-0 Closed
  Surfaces with Application to Adaptive Remeshing","  In this work, we are concerned with the spherical quasiconformal
parameterization of genus-0 closed surfaces. Given a genus-0 closed
triangulated surface and an arbitrary user-defined quasiconformal distortion,
we propose a fast algorithm for computing a spherical parameterization of the
surface that satisfies the prescribed distortion. The proposed algorithm can be
effectively applied to adaptive surface remeshing for improving the
visualization in computer graphics and animations. Experimental results are
presented to illustrate the effectiveness of our algorithm.
"
602,Geoplotlib: a Python Toolbox for Visualizing Geographical Data,"  We introduce geoplotlib, an open-source python toolbox for visualizing
geographical data. geoplotlib supports the development of hardware-accelerated
interactive visualizations in pure python, and provides implementations of dot
maps, kernel density estimation, spatial graphs, Voronoi tesselation,
shapefiles and many more common spatial visualizations. We describe geoplotlib
design, functionalities and use cases.
"
603,Semi-Automated SVG Programming via Direct Manipulation,"  Direct manipulation interfaces provide intuitive and interactive features to
a broad range of users, but they often exhibit two limitations: the built-in
features cannot possibly cover all use cases, and the internal representation
of the content is not readily exposed. We believe that if direct manipulation
interfaces were to (a) use general-purpose programs as the representation
format, and (b) expose those programs to the user, then experts could customize
these systems in powerful new ways and non-experts could enjoy some of the
benefits of programmable systems.
  In recent work, we presented a prototype SVG editor called Sketch-n-Sketch
that offered a step towards this vision. In that system, the user wrote a
program in a general-purpose lambda-calculus to generate a graphic design and
could then directly manipulate the output to indirectly change design
parameters (i.e. constant literals) in the program in real-time during the
manipulation. Unfortunately, the burden of programming the desired
relationships rested entirely on the user.
  In this paper, we design and implement new features for Sketch-n-Sketch that
assist in the programming process itself. Like typical direct manipulation
systems, our extended Sketch-n-Sketch now provides GUI-based tools for drawing
shapes, relating shapes to each other, and grouping shapes together. Unlike
typical systems, however, each tool carries out the user's intention by
transforming their general-purpose program. This novel, semi-automated
programming workflow allows the user to rapidly create high-level, reusable
abstractions in the program while at the same time retaining direct
manipulation capabilities. In future work, our approach may be extended with
more graphic design features or realized for other application domains.
"
604,Curvature transformation,"  A transformation based on mean curvature is introduced which morphs
triangulated surfaces into round spheres.
"
605,"A weighted binary average of point-normal pairs with application to
  subdivision schemes","  Subdivision is a well-known and established method for generating smooth
curves and surfaces from discrete data by repeated refinements. The typical
input for such a process is a mesh of vertices. In this work we propose to
refine 2D data consisting of vertices of a polygon and a normal at each vertex.
Our core refinement procedure is based on a circle average, which is a new
non-linear weighted average of two points and their corresponding normals. The
ability to locally approximate curves by the circle average is demonstrated.
With this ability, the circle average is a candidate for modifying linear
subdivision schemes refining points, to schemes refining point-normal pairs.
This is done by replacing the weighted binary arithmetic means in a linear
subdivision scheme, expressed in terms of repeated binary averages, by circle
averages with the same weights. Here we investigate the modified
Lane-Riesenfeld algorithm and the 4-point scheme. For the case that the initial
data consists of a control polygon only, a naive method for choosing initial
normals is proposed. An example demonstrates the superiority of the above two
modified schemes, with the naive choice of initial normals over the
corresponding linear schemes, when applied to a control polygon with edges of
significantly different lengths.
"
606,"Infill Optimization for Additive Manufacturing -- Approaching Bone-like
  Porous Structures","  Porous structures such as trabecular bone are widely seen in nature. These
structures exhibit superior mechanical properties whilst being lightweight. In
this paper, we present a method to generate bone-like porous structures as
lightweight infill for additive manufacturing. Our method builds upon and
extends voxel-wise topology optimization. In particular, for the purpose of
generating sparse yet stable structures distributed in the interior of a given
shape, we propose upper bounds on the localized material volume in the
proximity of each voxel in the design domain. We then aggregate the local
per-voxel constraints by their p-norm into an equivalent global constraint, in
order to facilitate an efficient optimization process. Implemented on a
high-resolution topology optimization framework, our results demonstrate
mechanically optimized, detailed porous structures which mimic those found in
nature. We further show variants of the optimized structures subject to
different design specifications, and analyze the optimality and robustness of
the obtained structures.
"
607,"Adaptive Position-Based Fluids: Improving Performance of Fluid
  Simulations for Real-Time Applications","  The Position Based Fluids (PBF) method is a state-of-the-art approach for
fluid simulations in the context of real-time applications like games. It uses
an iterative solver concept that tries to maintain a constant fluid density
(incompressibility) to realize incompressible fluids like water. However,
larger fluid volumes that consist of several hundred thousand particles (e.g.
for the simulation of oceans) require many iterations and a lot of simulation
power. We present a lightweight and easy-to-integrate extension to PBF that
adaptively adjusts the number of solver iterations on a fine-grained basis.
Using a novel adaptive-simulation approach, we are able to achieve significant
improvements in performance on our evaluation scenarios while maintaining
high-quality results in terms of visualization quality, which makes it a
perfect choice for game developers. Furthermore, our method does not weaken the
advantages of prior work and seamlessly integrates into other position-based
methods for physically-based simulations.
"
608,A Perceptual Aesthetics Measure for 3D Shapes,"  While the problem of image aesthetics has been well explored, the study of 3D
shape aesthetics has focused on specific manually defined features. In this
paper, we learn an aesthetics measure for 3D shapes autonomously from raw voxel
data and without manually-crafted features by leveraging the strength of deep
learning. We collect data from humans on their aesthetics preferences for
various 3D shape classes. We take a deep convolutional 3D shape ranking
approach to compute a measure that gives an aesthetics score for a 3D shape. We
demonstrate our approach with various types of shapes and for applications such
as aesthetics-based visualization, search, and scene composition.
"
609,Tree-decomposable and Underconstrained Geometric Constraint Problems,"  In this paper, we are concerned with geometric constraint solvers, i.e., with
programs that find one or more solutions of a geometric constraint problem. If
no solution exists, the solver is expected to announce that no solution has
been found. Owing to the complexity, type or difficulty of a constraint
problem, it is possible that the solver does not find a solution even though
one may exist. Thus, there may be false negatives, but there should never be
false positives. Intuitively, the ability to find solutions can be considered a
measure of solver's competence. We consider static constraint problems and
their solvers. We do not consider dynamic constraint solvers, also known as
dynamic geometry programs, in which specific geometric elements are moved,
interactively or along prescribed trajectories, while continually maintaining
all stipulated constraints. However, if we have a solver for static constraint
problems that is sufficiently fast and competent, we can build a dynamic
geometry program from it by solving the static problem for a sufficiently dense
sampling of the trajectory of the moving element(s). The work we survey has its
roots in applications, especially in mechanical computer-aided design (MCAD).
The constraint solvers used in MCAD took a quantum leap in the 1990s. These
approaches solve a geometric constraint problem by an initial, graph-based
structural analysis that extracts generic subproblems and determines how they
would combine to form a complete solution. These subproblems are then handed to
an algebraic solver that solves the specific instances of the generic
subproblems and combines them.
"
610,"Design and Implementation of a Procedural Content Generation Web
  Application for Vertex Shaders","  We present a web application for the procedural generation of transformations
of 3D models. We generate the transformations by algorithmically generating the
vertex shaders of the 3D models. The vertex shaders are created with an
interactive genetic algorithm, which displays to the user the visual effect
caused by each vertex shader, allows the user to select the visual effect the
user likes best, and produces a new generation of vertex shaders using the user
feedback as the fitness measure of the genetic algorithm. We use genetic
programming to represent each vertex shader as a computer program. This paper
presents details of requirements specification, software architecture, high and
low-level design, and prototype user interface. We discuss the project's
current status and development challenges.
"
611,A Data-Driven Approach for Mapping Multivariate Data to Color,"  A wide variety of color schemes have been devised for mapping scalar data to
color. Some use the data value to index a color scale. Others assign colors to
different, usually blended disjoint materials, to handle areas where materials
overlap. A number of methods can map low-dimensional data to color, however,
these methods do not scale to higher dimensional data. Likewise, schemes that
take a more artistic approach through color mixing and the like also face
limits when it comes to the number of variables they can encode. We address the
challenge of mapping multivariate data to color and avoid these limitations at
the same time. It is a data driven method, which first gauges the similarity of
the attributes and then arranges them according to the periphery of a convex 2D
color space, such as HSL. The color of a multivariate data sample is then
obtained via generalized barycentric coordinate (GBC) interpolation.
"
612,Extending Scatterplots to Scalar Fields,"  Embedding high-dimensional data into a 2D canvas is a popular strategy for
their visualization.
"
613,Segmenting a Surface Mesh into Pants Using Morse Theory,"  A pair of pants is a genus zero orientable surface with three boundary
components. A pants decomposition of a surface is a finite collection of
unordered pairwise disjoint simple closed curves embedded in the surface that
decompose the surface into pants. In this paper we present two Morse theory
based algorithms for pants decomposition of a surface mesh. Both algorithms
operates on a choice of an appropriate Morse function on the surface. The first
algorithm uses this Morse function to identify handles that are glued
systematically to obtain a pant decomposition. The second algorithm uses the
Reeb graph of the Morse function to obtain a pant decomposition. Both
algorithms work for surfaces with or without boundaries. Our preliminary
implementation of the two algorithms shows that both algorithms run in much
less time than an existing state-of-the-art method, and the Reeb graph based
algorithm achieves the best time efficiency. Finally, we demonstrate the
robustness of our algorithms against noise.
"
614,Urban Pulse: Capturing the Rhythm of Cities,"  Cities are inherently dynamic. Interesting patterns of behavior typically
manifest at several key areas of a city over multiple temporal resolutions.
Studying these patterns can greatly help a variety of experts ranging from city
planners and architects to human behavioral experts. Recent technological
innovations have enabled the collection of enormous amounts of data that can
help in these studies. However, techniques using these data sets typically
focus on understanding the data in the context of the city, thus failing to
capture the dynamic aspects of the city. The goal of this work is to instead
understand the city in the context of multiple urban data sets. To do so, we
define the concept of an ""urban pulse"" which captures the spatio-temporal
activity in a city across multiple temporal resolutions. The prominent pulses
in a city are obtained using the topology of the data sets, and are
characterized as a set of beats. The beats are then used to analyze and compare
different pulses. We also design a visual exploration framework that allows
users to explore the pulses within and across multiple cities under different
conditions. Finally, we present three case studies carried out by experts from
two different domains that demonstrate the utility of our framework.
"
615,Interpolations of Smoke and Liquid Simulations,"  We present a novel method to interpolate smoke and liquid simulations in
order to perform data-driven fluid simulations. Our approach calculates a dense
space-time deformation using grid-based signed-distance functions of the
inputs. A key advantage of this implicit Eulerian representation is that it
allows us to use powerful techniques from the optical flow area. We employ a
five-dimensional optical flow solve. In combination with a projection
algorithm, and residual iterations, we achieve a robust matching of the inputs.
Once the match is computed, arbitrary in between variants can be created very
efficiently. To concatenate multiple long-range deformations, we propose a
novel alignment technique. Our approach has numerous advantages, including
automatic matches without user input, volumetric deformations that can be
applied to details around the surface, and the inherent handling of topology
changes. As a result, we can interpolate swirling smoke clouds, and splashing
liquid simulations. We can even match and interpolate phenomena with
fundamentally different physics: a drop of liquid, and a blob of heavy smoke.
"
616,A heuristic extending the Squarified treemapping algorithm,"  A heuristic extending the Squarified Treemap technique for the representation
of hierarchical information as treemaps is presented. The original technique
gives high quality treemap views, since items are laid out with rectangles that
approximate squares, allowing easy comparison and selection operations. New key
steps, with a low computational impact, have been introduced to yield treemaps
with even better aspect ratios and higher homogeneity among items.
"
617,"High performance volume ray casting: A branchless generalized Joseph
  projector","  A concise and highly performant branchless formulation of a Joseph-type
interpolating ray-casting algorithm for the computation of X-ray projections is
presented. It efficiently utilizes the hardware resources of modern graphics
processing units at the scale of their theoretic maximum performance reaching
access rates of 600 GB/s within read-and-write memory, and is further shown to
do so without compromising on image quality. The computation of X-ray
projections from discrete voxel grids is an ubiquitous task in many problems
related to volume image processing, including tomographic reconstruction and
visualization. Although its central role has given rise to numerous
publications discussing the optimal modeling of ray-volume intersections, a
unique benchmark in this respect does not exist. Here, a 3D Shepp-Logan phantom
is used, which allows the computation of analytic reference projections that
can further serve as input to iterative reconstructions without committing the
inverse crime. The proposed algorithm (GJP) is compared to the competing and
widely adopted digital differential analyzer (DDA), which computes exact
line-box intersections. It is thereby found to outperform the DDA on recent
graphics processors in all respects: Despite accessing twice as much memory,
the GJP is still able to calculate projections twice as fast. It further
exhibits considerably less discretization artifacts, and neither oversampling
of the DDA nor a smooth interpolation kernel within the GJP are able to improve
on these results in any respect.
"
618,Volume Raycasting mit OpenCL,"  This German paper was written entirely at the University of Duisburg-Essen in
2011 for a 3D modeling masters course in applied computer science. We publish
this paper, thus, interested people can acquire a first impression of the topic
""volume raycasting"". In addition to writing this paper, we developed a
functioning open-source OpenCL raycaster. A video of this raycaster is
available: http://www.youtube.com/watch?v=VMMsQnf4zEY. Additionally, we
archived and published the complete source code of the raycaster in the Google
Code Archive: http://code.google.com/p/gputracer/. If this is no longer the
case, those who are interested can also write an email to the author, hence, we
can provide the source code.
  This paper provides an introduction and overview of the topic ""volume ray
casting with OpenCL"". We show how volume data can be loaded, manipulated, and
visualized by modern GPUs in real time. In addition, we present basic
algorithms and data structures that are necessary for building such a
raycaster. Then, we describe how we built a rudimentary raycaster using OpenCL
and .NET C#. Furthermore, we analyze different gradient operators
(CentralDifference, Sobel3D and Zucker-Hummel) for surface detection and show
an evaluation of these with respect to their performance. Finally, we present
optimization techniques (hitpoint refinement, adaptive sampling, octrees, and
empty-space-skipping) for improving a raycaster.
"
619,Depth Estimation Through a Generative Model of Light Field Synthesis,"  Light field photography captures rich structural information that may
facilitate a number of traditional image processing and computer vision tasks.
A crucial ingredient in such endeavors is accurate depth recovery. We present a
novel framework that allows the recovery of a high quality continuous depth map
from light field data. To this end we propose a generative model of a light
field that is fully parametrized by its corresponding depth map. The model
allows for the integration of powerful regularization techniques such as a
non-local means prior, facilitating accurate depth map estimation.
"
620,Sampling BSSRDFs with non-perpendicular incidence,"  Sub-surface scattering is key to our perception of translucent materials.
Models based on diffusion theory are used to render such materials in a
realistic manner by evaluating an approximation of the material BSSRDF at any
two points of the surface. Under the assumption of perpendicular incidence,
this BSSRDF approximation can be tabulated over 2 dimensions to provide fast
evaluation and importance sampling. However, accounting for non-perpendicular
incidence with the same approach would require to tabulate over 4 dimensions,
making the model too large for practical applications. In this report, we
present a method to efficiently evaluate and importance sample the
multi-scattering component of diffusion based BSSRDFs for non-perpendicular
incidence. Our approach is based on tabulating a compressed angular model of
Photon Beam Diffusion. We explain how to generate, evaluate and sample our
model. We show that 1 MiB is enough to store a model of the multi-scattering
BSSRDF that is within $0.5\%$ relative error of Photon Beam Diffusion. Finally,
we present a method to use our model in a Monte Carlo particle tracer and show
results of our implementation in PBRT.
"
621,Generating Videos with Scene Dynamics,"  We capitalize on large amounts of unlabeled video in order to learn a model
of scene dynamics for both video recognition tasks (e.g. action classification)
and video generation tasks (e.g. future prediction). We propose a generative
adversarial network for video with a spatio-temporal convolutional architecture
that untangles the scene's foreground from the background. Experiments suggest
this model can generate tiny videos up to a second at full frame rate better
than simple baselines, and we show its utility at predicting plausible futures
of static images. Moreover, experiments and visualizations show the model
internally learns useful features for recognizing actions with minimal
supervision, suggesting scene dynamics are a promising signal for
representation learning. We believe generative video models can impact many
applications in video understanding and simulation.
"
622,Learning-Based View Synthesis for Light Field Cameras,"  With the introduction of consumer light field cameras, light field imaging
has recently become widespread. However, there is an inherent trade-off between
the angular and spatial resolution, and thus, these cameras often sparsely
sample in either spatial or angular domain. In this paper, we use machine
learning to mitigate this trade-off. Specifically, we propose a novel
learning-based approach to synthesize new views from a sparse set of input
views. We build upon existing view synthesis techniques and break down the
process into disparity and color estimation components. We use two sequential
convolutional neural networks to model these two components and train both
networks simultaneously by minimizing the error between the synthesized and
ground truth images. We show the performance of our approach using only four
corner sub-aperture views from the light fields captured by the Lytro Illum
camera. Experimental results show that our approach synthesizes high-quality
images that are superior to the state-of-the-art techniques on a variety of
challenging real-world scenes. We believe our method could potentially decrease
the required angular resolution of consumer light field cameras, which allows
their spatial resolution to increase.
"
623,Simultaneous independent image display technique on multiple 3D objects,"  We propose a new system to visualize depth-dependent patterns and images on
solid objects with complex geometry using multiple projectors. The system,
despite consisting of conventional passive LCD projectors, is able to project
different images and patterns depending on the spatial location of the object.
The technique is based on the simple principle that multiple patterns projected
from multiple projectors interfere constructively with each other when their
patterns are projected on the same object. Previous techniques based on the
same principle can only achieve 1) low resolution volume colorization or 2)
high resolution images but only on a limited number of flat planes. In this
paper, we discretize a 3D object into a number of 3D points so that high
resolution images can be projected onto the complex shapes. We also propose a
dynamic ranges expansion technique as well as an efficient optimization
procedure based on epipolar constraints.
  Such technique can be used to the extend projection mapping to have spatial
dependency, which is desirable for practical applications. We also demonstrate
the system potential as a visual instructor for object placement and
assembling. Experiments prove the effectiveness of our method.
"
624,Anti-aliasing for fused filament deposition,"  Layered manufacturing inherently suffers from staircase defects along
surfaces that are gently slopped with respect to the build direction. Reducing
the slice thickness improves the situation but never resolves it completely as
flat layers remain a poor approximation of the true surface in these regions.
In addition, reducing the slice thickness largely increases the print time. In
this work we focus on a simple yet effective technique to improve the print
accuracy for layered manufacturing by filament deposition. Our method works
with standard three-axis 3D filament printers (e.g. the typical, widely
available 3D printers), using standard extrusion nozzles. It better reproduces
the geometry of sloped surfaces without increasing the print time. Our key idea
is to perform a local anti-aliasing, working at a sub-layer accuracy to produce
slightly curved deposition paths and reduce approximation errors. This is
inspired by Computer Graphics anti-aliasing techniques which consider sub-pixel
precision to treat aliasing effects. We show that the necessary deviation in
height compared to standard slicing is bounded by half the layer thickness.
Therefore, the height changes remain small and plastic deposition remains
reliable. We further split and order paths to minimize defects due to the
extruder nozzle shape, avoiding any change to the existing hardware. We apply
and analyze our approach on 3D printed examples, showing that our technique
greatly improves surface accuracy and silhouette quality while keeping the
print time nearly identical.
"
625,"High-Dimensional Data Visualization by Interactive Construction of
  Low-Dimensional Parallel Coordinate Plots","  Parallel coordinate plots (PCPs) are among the most useful techniques for the
visualization and exploration of high-dimensional data spaces. They are
especially useful for the representation of correlations among the dimensions,
which identify relationships and interdependencies between variables. However,
within these high-dimensional spaces, PCPs face difficulties in displaying the
correlation between combinations of dimensions and generally require additional
display space as the number of dimensions increases. In this paper, we present
a new technique for high-dimensional data visualization in which a set of
low-dimensional PCPs are interactively constructed by sampling user-selected
subsets of the high-dimensional data space. In our technique, we first
construct a graph visualization of sets of well-correlated dimensions. Users
observe this graph and are able to interactively select the dimensions by
sampling from its cliques, thereby dynamically specifying the most relevant
lower dimensional data to be used for the construction of focused PCPs. Our
interactive sampling overcomes the shortcomings of the PCPs by enabling the
visualization of the most meaningful dimensions (i.e., the most relevant
information) from high-dimensional spaces. We demonstrate the effectiveness of
our technique through two case studies, where we show that the proposed
interactive low-dimensional space constructions were pivotal for visualizing
the high-dimensional data and discovering new patterns.
"
626,Converting Basic D3 Charts into Reusable Style Templates,"  We present a technique for converting a basic D3 chart into a reusable style
template. Then, given a new data source we can apply the style template to
generate a chart that depicts the new data, but in the style of the template.
To construct the style template we first deconstruct the input D3 chart to
recover its underlying structure: the data, the marks and the mappings that
describe how the marks encode the data. We then rank the perceptual
effectiveness of the deconstructed mappings. To apply the resulting style
template to a new data source we first obtain importance ranks for each new
data field. We then adjust the template mappings to depict the source data by
matching the most important data fields to the most perceptually effective
mappings. We show how the style templates can be applied to source data in the
form of either a data table or another D3 chart. While our implementation
focuses on generating templates for basic chart types (e.g. variants of bar
charts, line charts, dot plots, scatterplots, etc.), these are the most
commonly used chart types today. Users can easily find such basic D3 charts on
the Web, turn them into templates, and immediately see how their own data would
look in the visual style (e.g. colors, shapes, fonts, etc.) of the templates.
We demonstrate the effectiveness of our approach by applying a diverse set of
style templates to a variety of source datasets.
"
627,"Hermite interpolation by piecewise polynomial surfaces with polynomial
  area element","  This paper is devoted to the construction of polynomial 2-surfaces which
possess a polynomial area element. In particular we study these surfaces in the
Euclidean space $\mathbb R^3$ (where they are equivalent to the PN surfaces)
and in the Minkowski space $\mathbb R^{3,1}$ (where they provide the MOS
surfaces). We show generally in real vector spaces of any dimension and any
metric that the Gram determinant of a parametric set of subspaces is a perfect
square if and only if the Gram determinant of its orthogonal complement is a
perfect square. Consequently the polynomial surfaces of a given degree with
polynomial area element can be constructed from the prescribed normal fields
solving a system of linear equations. The degree of the constructed surface
depending on the degree and the quality of the prescribed normal field is
investigated and discussed. We use the presented approach to interpolate a
network of points and associated normals with piecewise polynomial surfaces
with polynomial area element and demonstrate our method on a number of examples
(constructions of quadrilateral as well as triangular patches
"
628,Optimisations for Real-Time Volumetric Cloudscapes,"  Volumetric cloudscapes are prohibitively expensive to render in real time
without extensive optimisations. Previous approaches render the clouds to an
offscreen buffer at one quarter resolution and update a fraction of the pixels
per frame, drawing the remaining pixels by temporal reprojection. We present an
alternative approach, reducing the number of raymarching steps and adding a
randomly jittered offset to the raymarch. We use an analytical integration
technique to make results consistent with a lower number of raymarching steps.
To remove noise from the resulting image we apply a temporal anti-aliasing
implementation. The result is a technique producing visually similar results
with 1/16 the number of steps.
"
629,From Multiview Image Curves to 3D Drawings,"  Reconstructing 3D scenes from multiple views has made impressive strides in
recent years, chiefly by correlating isolated feature points, intensity
patterns, or curvilinear structures. In the general setting - without
controlled acquisition, abundant texture, curves and surfaces following
specific models or limiting scene complexity - most methods produce unorganized
point clouds, meshes, or voxel representations, with some exceptions producing
unorganized clouds of 3D curve fragments. Ideally, many applications require
structured representations of curves, surfaces and their spatial relationships.
This paper presents a step in this direction by formulating an approach that
combines 2D image curves into a collection of 3D curves, with topological
connectivity between them represented as a 3D graph. This results in a 3D
drawing, which is complementary to surface representations in the same sense as
a 3D scaffold complements a tent taut over it. We evaluate our results against
truth on synthetic and real datasets.
"
630,"Production-Level Facial Performance Capture Using Deep Convolutional
  Neural Networks","  We present a real-time deep learning framework for video-based facial
performance capture -- the dense 3D tracking of an actor's face given a
monocular video. Our pipeline begins with accurately capturing a subject using
a high-end production facial capture pipeline based on multi-view stereo
tracking and artist-enhanced animations. With 5-10 minutes of captured footage,
we train a convolutional neural network to produce high-quality output,
including self-occluded regions, from a monocular video sequence of that
subject. Since this 3D facial performance capture is fully automated, our
system can drastically reduce the amount of labor involved in the development
of modern narrative-driven video games or films involving realistic digital
doubles of actors and potentially hours of animated dialogue per character. We
compare our results with several state-of-the-art monocular real-time facial
capture techniques and demonstrate compelling animation inference in
challenging areas such as eyes and lips.
"
631,Customized Facial Constant Positive Air Pressure (CPAP) Masks,"  Sleep apnea is a syndrome that is characterized by sudden breathing halts
while sleeping. One of the common treatments involves wearing a mask that
delivers continuous air flow into the nostrils so as to maintain a steady air
pressure. These masks are designed for an average facial model and are often
difficult to adjust due to poor fit to the actual patient. The incompatibility
is characterized by gaps between the mask and the face, which deteriorates the
impermeability of the mask and leads to air leakage. We suggest a fully
automatic approach for designing a personalized nasal mask interface using a
facial depth scan. The interfaces generated by the proposed method accurately
fit the geometry of the scanned face, and are easy to manufacture. The proposed
method utilizes cheap commodity depth sensors and 3D printing technologies to
efficiently design and manufacture customized masks for patients suffering from
sleep apnea.
"
632,Fast Blended Transformations for Partial Shape Registration,"  Automatic estimation of skinning transformations is a popular way to deform a
single reference shape into a new pose by providing a small number of control
parameters. We generalize this approach by efficiently enabling the use of
multiple exemplar shapes. Using a small set of representative natural poses, we
propose to express an unseen appearance by a low-dimensional linear subspace,
specified by a redundant dictionary of weighted vertex positions. Minimizing a
nonlinear functional that regulates the example manifold, the suggested
approach supports local-rigid deformations of articulated objects, as well as
nearly isometric embeddings of smooth shapes. A real-time non-rigid deformation
system is demonstrated, and a shape completion and partial registration
framework is introduced. These applications can recover a target pose and
implicit inverse kinematics from a small number of examples and just a few
vertex positions. The result reconstruction is more accurate compared to
state-of-the-art reduced deformable models.
"
633,Unsupervised Co-segmentation of 3D Shapes via Functional Maps,"  We present an unsupervised method for co-segmentation of a set of 3D shapes
from the same class with the aim of segmenting the input shapes into consistent
semantic parts and establishing their correspondence across the set. Starting
from meaningful pre-segmentation of all given shapes individually, we construct
the correspondence between same candidate parts and obtain the labels via
functional maps. And then, we use these labels to mark the input shapes and
obtain results of co-segmentation. The core of our algorithm is to seek for an
optimal correspondence between semantically similar parts through functional
maps and mark such shape parts. Experimental results on the benchmark datasets
show the efficiency of this method and comparable accuracy to the
state-of-the-art algorithms.
"
634,Understanding and Exploiting Object Interaction Landscapes,"  Interactions play a key role in understanding objects and scenes, for both
virtual and real world agents. We introduce a new general representation for
proximal interactions among physical objects that is agnostic to the type of
objects or interaction involved. The representation is based on tracking
particles on one of the participating objects and then observing them with
sensors appropriately placed in the interaction volume or on the interaction
surfaces. We show how to factorize these interaction descriptors and project
them into a particular participating object so as to obtain a new functional
descriptor for that object, its interaction landscape, capturing its observed
use in a spatio-temporal framework. Interaction landscapes are independent of
the particular interaction and capture subtle dynamic effects in how objects
move and behave when in functional use. Our method relates objects based on
their function, establishes correspondences between shapes based on functional
key points and regions, and retrieves peer and partner objects with respect to
an interaction.
"
635,Adaptive 360 VR Video Streaming: Divide and Conquer!,"  While traditional multimedia applications such as games and videos are still
popular, there has been a significant interest in the recent years towards new
3D media such as 3D immersion and Virtual Reality (VR) applications, especially
360 VR videos. 360 VR video is an immersive spherical video where the user can
look around during playback. Unfortunately, 360 VR videos are extremely
bandwidth intensive, and therefore are difficult to stream at acceptable
quality levels. In this paper, we propose an adaptive bandwidth-efficient 360
VR video streaming system using a divide and conquer approach. In our approach,
we propose a dynamic view-aware adaptation technique to tackle the huge
streaming bandwidth demands of 360 VR videos. We spatially divide the videos
into multiple tiles while encoding and packaging, use MPEG-DASH SRD to describe
the spatial relationship of tiles in the 360-degree space, and prioritize the
tiles in the Field of View (FoV). In order to describe such tiled
representations, we extend MPEG-DASH SRD to the 3D space of 360 VR videos. We
spatially partition the underlying 3D mesh, and construct an efficient 3D
geometry mesh called hexaface sphere to optimally represent a tiled 360 VR
video in the 3D space. Our initial evaluation results report up to 72%
bandwidth savings on 360 VR video streaming with minor negative quality impacts
compared to the baseline scenario when no adaptations is applied.
"
636,Dynamic Polygon Clouds: Representation and Compression for VR/AR,"  We introduce the {\em polygon cloud}, also known as a polygon set or {\em
soup}, as a compressible representation of 3D geometry (including its
attributes, such as color texture) intermediate between polygonal meshes and
point clouds. Dynamic or time-varying polygon clouds, like dynamic polygonal
meshes and dynamic point clouds, can take advantage of temporal redundancy for
compression, if certain challenges are addressed. In this paper, we propose
methods for compressing both static and dynamic polygon clouds, specifically
triangle clouds. We compare triangle clouds to both triangle meshes and point
clouds in terms of compression, for live captured dynamic colored geometry. We
find that triangle clouds can be compressed nearly as well as triangle meshes,
while being far more robust to noise and other structures typically found in
live captures, which violate the assumption of a smooth surface manifold, such
as lines, points, and ragged boundaries. We also find that triangle clouds can
be used to compress point clouds with significantly better performance than
previously demonstrated point cloud compression methods. In particular, for
intra-frame coding of geometry, our method improves upon octree-based
intra-frame coding by a factor of 5-10 in bit rate. Inter-frame coding improves
this by another factor of 2-5. Overall, our dynamic triangle cloud compression
improves over the previous state-of-the-art in dynamic point cloud compression
by 33\% or more.
"
637,"Towards a Drone Cinematographer: Guiding Quadrotor Cameras using Visual
  Composition Principles","  We present a system to capture video footage of human subjects in the real
world. Our system leverages a quadrotor camera to automatically capture
well-composed video of two subjects. Subjects are tracked in a large-scale
outdoor environment using RTK GPS and IMU sensors. Then, given the tracked
state of our subjects, our system automatically computes static shots based on
well-established visual composition principles and canonical shots from
cinematography literature. To transition between these static shots, we
calculate feasible, safe, and visually pleasing transitions using a novel
real-time trajectory planning algorithm. We evaluate the performance of our
tracking system, and experimentally show that RTK GPS significantly outperforms
conventional GPS in capturing a variety of canonical shots. Lastly, we
demonstrate our system guiding a consumer quadrotor camera autonomously
capturing footage of two subjects in a variety of use cases. This is the first
end-to-end system that enables people to leverage the mobility of quadrotors,
as well as the knowledge of expert filmmakers, to autonomously capture
high-quality footage of people in the real world.
"
638,Inverse Diffusion Curves using Shape Optimization,"  The inverse diffusion curve problem focuses on automatic creation of
diffusion curve images that resemble user provided color fields. This problem
is challenging since the 1D curves have a nonlinear and global impact on
resulting color fields via a partial differential equation (PDE). We introduce
a new approach complementary to previous methods by optimizing curve geometry.
In particular, we propose a novel iterative algorithm based on the theory of
shape derivatives. The resulting diffusion curves are clean and well-shaped,
and the final image closely approximates the input. Our method provides a
user-controlled parameter to regularize curve complexity, and generalizes to
handle input color fields represented in a variety of formats.
"
639,Polynomial methods for Procedural Terrain Generation,"  A new method is presented, allowing for the generation of 3D terrain and
texture from coherent noise. The method is significantly faster than prevailing
fractal brownian motion approaches, while producing results of equivalent
quality. The algorithm is derived through a systematic approach that
generalizes to an arbitrary number of spatial dimensions and gradient
smoothness. The results are compared, in terms of performance and quality, to
fundamental and efficient gradient noise methods widely used in the domain of
fast terrain generation: Perlin noise and OpenSimplex noise. Finally, to
objectively quantify the degree of realism of the results, a fractal analysis
of the generated landscapes is performed and compared to real terrain data.
"
640,"Scale Stain: Multi-Resolution Feature Enhancement in Pathology
  Visualization","  Digital whole-slide images of pathological tissue samples have recently
become feasible for use within routine diagnostic practice. These gigapixel
sized images enable pathologists to perform reviews using computer workstations
instead of microscopes. Existing workstations visualize scanned images by
providing a zoomable image space that reproduces the capabilities of the
microscope. This paper presents a novel visualization approach that enables
filtering of the scale-space according to color preference. The visualization
method reveals diagnostically important patterns that are otherwise not
visible. The paper demonstrates how this approach has been implemented into a
fully functional prototype that lets the user navigate the visualization
parameter space in real time. The prototype was evaluated for two common
clinical tasks with eight pathologists in a within-subjects study. The data
reveal that task efficiency increased by 15% using the prototype, with
maintained accuracy. By analyzing behavioral strategies, it was possible to
conclude that efficiency gain was caused by a reduction of the panning needed
to perform systematic search of the images. The prototype system was well
received by the pathologists who did not detect any risks that would hinder use
in clinical routine.
"
641,"Augmented Reality with Hololens: Experiential Architectures Embedded in
  the Real World","  Early hands-on experiences with the Microsoft Hololens augmented/mixed
reality device are reported and discussed, with a general aim of exploring
basic 3D visualization. A range of usage cases are tested, including data
visualization and immersive data spaces, in-situ visualization of 3D models and
full scale architectural form visualization. Ultimately, the Hololens is found
to provide a remarkable tool for moving from traditional visualization of 3D
objects on a 2D screen, to fully experiential 3D visualizations embedded in the
real world.
"
642,"Numerical Inversion of SRNF Maps for Elastic Shape Analysis of
  Genus-Zero Surfaces","  Recent developments in elastic shape analysis (ESA) are motivated by the fact
that it provides comprehensive frameworks for simultaneous registration,
deformation, and comparison of shapes. These methods achieve computational
efficiency using certain square-root representations that transform invariant
elastic metrics into Euclidean metrics, allowing for applications of standard
algorithms and statistical tools. For analyzing shapes of embeddings of
$\mathbb{S}^2$ in $\mathbb{R}^3$, Jermyn et al. introduced square-root normal
fields (SRNFs) that transformed an elastic metric, with desirable invariant
properties, into the $\mathbb{L}^2$ metric. These SRNFs are essentially surface
normals scaled by square-roots of infinitesimal area elements. A critical need
in shape analysis is to invert solutions (deformations, averages, modes of
variations, etc) computed in the SRNF space, back to the original surface space
for visualizations and inferences. Due to the lack of theory for understanding
SRNFs maps and their inverses, we take a numerical approach and derive an
efficient multiresolution algorithm, based on solving an optimization problem
in the surface space, that estimates surfaces corresponding to given SRNFs.
This solution is found effective, even for complex shapes, e.g. human bodies
and animals, that undergo significant deformations including bending and
stretching. Specifically, we use this inversion for computing elastic shape
deformations, transferring deformations, summarizing shapes, and for finding
modes of variability in a given collection, while simultaneously registering
the surfaces. We demonstrate the proposed algorithms using a statistical
analysis of human body shapes, classification of generic surfaces and analysis
of brain structures.
"
643,Digital Makeup from Internet Images,"  We present a novel approach of color transfer between images by exploring
their high-level semantic information. First, we set up a database which
consists of the collection of downloaded images from the internet, which are
segmented automatically by using matting techniques. We then, extract image
foregrounds from both source and multiple target images. Then by using image
matting algorithms, the system extracts the semantic information such as faces,
lips, teeth, eyes, eyebrows, etc., from the extracted foregrounds of the source
image. And, then the color is transferred between corresponding parts with the
same semantic information. Next we get the color transferred result by
seamlessly compositing different parts together using alpha blending. In the
final step, we present an efficient method of color consistency to optimize the
color of a collection of images showing the common scene. The main advantage of
our method over existing techniques is that it does not need face matching, as
one could use more than one target images. It is not restricted to head shot
images as we can also change the color style in the wild. Moreover, our
algorithm does not require to choose the same color style, same pose and image
size between source and target images. Our algorithm is not restricted to
one-to-one image color transfer and can make use of more than one target images
to transfer the color in different parts in the source image. Comparing with
other approaches, our algorithm is much better in color blending in the input
data.
"
644,Partial Procedural Geometric Model Fitting for Point Clouds,"  Geometric model fitting is a fundamental task in computer graphics and
computer vision. However, most geometric model fitting methods are unable to
fit an arbitrary geometric model (e.g. a surface with holes) to incomplete
data, due to that the similarity metrics used in these methods are unable to
measure the rigid partial similarity between arbitrary models. This paper hence
proposes a novel rigid geometric similarity metric, which is able to measure
both the full similarity and the partial similarity between arbitrary geometric
models. The proposed metric enables us to perform partial procedural geometric
model fitting (PPGMF). The task of PPGMF is to search a procedural geometric
model space for the model rigidly similar to a query of non-complete point set.
Models in the procedural model space are generated according to a set of
parametric modeling rules. A typical query is a point cloud. PPGMF is very
useful as it can be used to fit arbitrary geometric models to non-complete
(incomplete, over-complete or hybrid-complete) point cloud data. For example,
most laser scanning data is non-complete due to occlusion. Our PPGMF method
uses Markov chain Monte Carlo technique to optimize the proposed similarity
metric over the model space. To accelerate the optimization process, the method
also employs a novel coarse-to-fine model dividing strategy to reject
dissimilar models in advance. Our method has been demonstrated on a variety of
geometric models and non-complete data. Experimental results show that the
PPGMF method based on the proposed metric is able to fit non-complete data,
while the method based on other metrics is unable. It is also shown that our
method can be accelerated by several times via early rejection.
"
645,Spline surfaces with T-junctions,"  This paper develops a new way to create smooth piecewise polynomial free-form
spline surfaces from quad- meshes that include T-junctions, where surface
strips start or terminate. All mesh nodes can be interpreted as control points
of geometrically-smooth, piecewise polynomials that we call GT-splines.
GT-splines are B-spline-like and cover T-junctions by two or four patches of
degree bi-4. They complement multi-sided surface constructions in generating
free-form surfaces with adaptive layout. Since GT-splines do not require a
global coordination of knot intervals, GT-constructions are easy to deploy and
can provide smooth surfaces with T-junctions where T-splines can not have a
smooth parameterization. GT-constructions display a uniform highlight line
distribution on input meshes where alternatives, such as Catmull-Clark
subdivision, exhibit oscillations.
"
646,Simplification of Multi-Scale Geometry using Adaptive Curvature Fields,"  We present a novel algorithm to compute multi-scale curvature fields on
triangle meshes. Our algorithm is based on finding robust mean curvatures using
the ball neighborhood, where the radius of a ball corresponds to the scale of
the features. The essential problem is to find a good radius for each ball to
obtain a reliable curvature estimation. We propose an algorithm that finds
suitable radii in an automatic way. In particular, our algorithm is applicable
to meshes produced by image-based reconstruction systems. These meshes often
contain geometric features at various scales, for example if certain regions
have been captured in greater detail. We also show how such a multi-scale
curvature field can be converted to a density field and used to guide
applications like mesh simplification.
"
647,"FlyCap: Markerless Motion Capture Using Multiple Autonomous Flying
  Cameras","  Aiming at automatic, convenient and non-instrusive motion capture, this paper
presents a new generation markerless motion capture technique, the FlyCap
system, to capture surface motions of moving characters using multiple
autonomous flying cameras (autonomous unmanned aerial vehicles(UAV) each
integrated with an RGBD video camera). During data capture, three cooperative
flying cameras automatically track and follow the moving target who performs
large scale motions in a wide space. We propose a novel non-rigid surface
registration method to track and fuse the depth of the three flying cameras for
surface motion tracking of the moving target, and simultaneously calculate the
pose of each flying camera. We leverage the using of visual-odometry
information provided by the UAV platform, and formulate the surface tracking
problem in a non-linear objective function that can be linearized and
effectively minimized through a Gaussian-Newton method. Quantitative and
qualitative experimental results demonstrate the competent and plausible
surface and motion reconstruction results
"
648,Selecting the Best Quadrilateral Mesh for Given Planar Shape,"  The problem of mesh matching is addressed in this work. For a given n-sided
planar region bounded by one loop of n polylines we are selecting optimal
quadrilateral mesh from existing catalogue of meshes. The formulation of
matching between planar shape and quadrilateral mesh from the catalogue is
based on the problem of finding longest common subsequence (LCS). Theoretical
foundation of mesh matching method is provided. Suggested method represents a
viable technique for selecting best mesh for planar region and stepping stone
for further parametrization of the region.
"
649,"Deconfliction and Surface Generation from Bathymetry Data Using LR
  B-splines","  A set of bathymetry point clouds acquired by different measurement techniques
at different times, having different accuracy and varying patterns of points,
are approximated by an LR B-spline surface. The aim is to represent the sea
bottom with good accuracy and at the same time reduce the data size
considerably. In this process the point clouds must be cleaned by selecting the
""best"" points for surface generation. This cleaning process is called
deconfliction, and we use a rough approximation of the combined point clouds as
a reference surface to select a consistent set of points. The reference surface
is updated with the selected points to create an accurate approximation. LR
B-splines is the selected surface format due to its suitability for adaptive
refinement and approximation, and its ability to represent local detail without
a global increase in the data size of the surface
"
650,"Recent Advances in Transient Imaging: A Computer Graphics and Vision
  Perspective","  Transient imaging has recently made a huge impact in the computer graphics
and computer vision fields. By capturing, reconstructing, or simulating light
transport at extreme temporal resolutions, researchers have proposed novel
techniques to show movies of light in motion, see around corners, detect
objects in highly-scattering media, or infer material properties from a
distance, to name a few. The key idea is to leverage the wealth of information
in the temporal domain at the pico or nanosecond resolution, information
usually lost during the capture-time temporal integration. This paper presents
recent advances in this field of transient imaging from a graphics and vision
perspective, including capture techniques, analysis, applications and
simulation.
"
651,"Learning Locomotion Skills Using DeepRL: Does the Choice of Action Space
  Matter?","  The use of deep reinforcement learning allows for high-dimensional state
descriptors, but little is known about how the choice of action representation
impacts the learning difficulty and the resulting performance. We compare the
impact of four different action parameterizations (torques, muscle-activations,
target joint angles, and target joint-angle velocities) in terms of learning
time, policy robustness, motion quality, and policy query rates. Our results
are evaluated on a gait-cycle imitation task for multiple planar articulated
figures and multiple gaits. We demonstrate that the local feedback provided by
higher-level action parameterizations can significantly impact the learning,
robustness, and quality of the resulting policies.
"
652,A Survey on 3D CAD model quality assurance and testing tools,"  A new taxonomy of issues related to CAD model quality is presented, which
distinguishes between explicit and procedural models. For each type of model,
morphologic, syntactic, and semantic errors are characterized. The taxonomy was
validated successfully when used to classify quality testing tools, which are
aimed at detecting and repairing data errors that may affect the
simplification, interoperability, and reusability of CAD models. The study
shows that low semantic level errors that hamper simplification are reasonably
covered in explicit representations, although many CAD quality testers are
still unaffordable for Small and Medium Enterprises, both in terms of cost and
training time. Interoperability has been reasonably solved by standards like
STEP AP 203 and AP214, but model reusability is not feasible in explicit
representations. Procedural representations are promising, as interactive
modeling editors automatically prevent most morphologic errors derived from
unsuitable modeling strategies. Interoperability problems between procedural
representations are expected to decrease dramatically with STEP AP242. Higher
semantic aspects of quality such as assurance of design intent, however, are
hardly supported by current CAD quality testers.
"
653,Hamiltonian operator for spectral shape analysis,"  Many shape analysis methods treat the geometry of an object as a metric space
that can be captured by the Laplace-Beltrami operator. In this paper, we
propose to adapt the classical Hamiltonian operator from quantum mechanics to
the field of shape analysis. To this end we study the addition of a potential
function to the Laplacian as a generator for dual spaces in which shape
processing is performed. We present a general optimization approach for solving
variational problems involving the basis defined by the Hamiltonian using
perturbation theory for its eigenvectors. The suggested operator is shown to
produce better functional spaces to operate with, as demonstrated on different
shape analysis tasks.
"
654,"Error-Bounded and Feature Preserving Surface Remeshing with Minimal
  Angle Improvement","  The typical goal of surface remeshing consists in finding a mesh that is (1)
geometrically faithful to the original geometry, (2) as coarse as possible to
obtain a low-complexity representation and (3) free of bad elements that would
hamper the desired application. In this paper, we design an algorithm to
address all three optimization goals simultaneously. The user specifies desired
bounds on approximation error {\delta}, minimal interior angle {\theta} and
maximum mesh complexity N (number of vertices). Since such a desired mesh might
not even exist, our optimization framework treats only the approximation error
bound {\delta} as a hard constraint and the other two criteria as optimization
goals. More specifically, we iteratively perform carefully prioritized local
operators, whenever they do not violate the approximation error bound and
improve the mesh otherwise. In this way our optimization framework greedily
searches for the coarsest mesh with minimal interior angle above {\theta} and
approximation error bounded by {\delta}. Fast runtime is enabled by a local
approximation error estimation, while implicit feature preservation is obtained
by specifically designed vertex relocation operators. Experiments show that our
approach delivers high-quality meshes with implicitly preserved features and
better balances between geometric fidelity, mesh complexity and element quality
than the state-of-the-art.
"
655,Fractal Art Generation using GPUs,"  Fractal image generation algorithms exhibit extreme parallelizability. Using
general purpose graphics processing unit (GPU) programming to implement
escape-time algorithms for Julia sets of functions,parallel methods generate
visually attractive fractal images much faster than traditional methods. Vastly
improved speeds are achieved using this method of computation, which allow
real-time generation and display of images. A comparison is made between
sequential and parallel implementations of the algorithm. An application
created by the authors demonstrates using the increased speed to create dynamic
imaging of fractals where the user may explore paths of parameter values
corresponding to a given function's Mandelbrot set. Examples are given of
artistic and mathematical insights gained by experiencing fractals
interactively and from the ability to sample the parameter space quickly and
comprehensively.
"
656,"Oriented bounding boxes using multiresolution contours for fast
  interference detection of arbitrary geometry objects","  Interference detection of arbitrary geometric objects is not a trivial task
due to the heavy computational load imposed by implementation issues. The
hierarchically structured bounding boxes help us to quickly isolate the contour
of segments in interference. In this paper, a new approach is introduced to
treat the interference detection problem involving the representation of
arbitrary shaped objects. Our proposed method relies upon searching for the
best possible way to represent contours by means of hierarchically structured
rectangular oriented bounding boxes. This technique handles 2D objects
boundaries defined by closed B-spline curves with roughness details. Each
oriented box is adapted and fitted to the segments of the contour using second
order statistical indicators from some elements of the segments of the object
contour in a multiresolution framework. Our method is efficient and robust when
it comes to 2D animations in real time. It can deal with smooth curves and
polygonal approximations as well results are present to illustrate the
performance of the new method.
"
657,Primal-Dual Optimization for Fluids,"  We apply a novel optimization scheme from the image processing and machine
learning areas, a fast Primal-Dual method, to achieve controllable and
realistic fluid simulations. While our method is generally applicable to many
problems in fluid simulations, we focus on the two topics of fluid guiding and
separating solid-wall boundary conditions. Each problem is posed as an
optimization problem and solved using our method, which contains acceleration
schemes tailored to each problem. In fluid guiding, we are interested in
partially guiding fluid motion to exert control while preserving fluid
characteristics. With our method, we achieve explicit control over both
large-scale motions and small-scale details which is valuable for many
applications, such as level-of-detail adjustment (after running the coarse
simulation), spatially varying guiding strength, domain modification, and
resimulation with different fluid parameters. For the separating solid-wall
boundary conditions problem, our method effectively eliminates unrealistic
artifacts of fluid crawling up solid walls and sticking to ceilings, requiring
few changes to existing implementations. We demonstrate the fast convergence of
our Primal-Dual method with a variety of test cases for both model problems.
"
658,"CAS-CNN: A Deep Convolutional Neural Network for Image Compression
  Artifact Suppression","  Lossy image compression algorithms are pervasively used to reduce the size of
images transmitted over the web and recorded on data storage media. However, we
pay for their high compression rate with visual artifacts degrading the user
experience. Deep convolutional neural networks have become a widespread tool to
address high-level computer vision tasks very successfully. Recently, they have
found their way into the areas of low-level computer vision and image
processing to solve regression problems mostly with relatively shallow
networks.
  We present a novel 12-layer deep convolutional network for image compression
artifact suppression with hierarchical skip connections and a multi-scale loss
function. We achieve a boost of up to 1.79 dB in PSNR over ordinary JPEG and an
improvement of up to 0.36 dB over the best previous ConvNet result. We show
that a network trained for a specific quality factor (QF) is resilient to the
QF used to compress the input image - a single network trained for QF 60
provides a PSNR gain of more than 1.5 dB over the wide QF range from 40 to 76.
"
659,Geometry of 3D Environments and Sum of Squares Polynomials,"  Motivated by applications in robotics and computer vision, we study problems
related to spatial reasoning of a 3D environment using sublevel sets of
polynomials. These include: tightly containing a cloud of points (e.g.,
representing an obstacle) with convex or nearly-convex basic semialgebraic
sets, computation of Euclidean distances between two such sets, separation of
two convex basic semalgebraic sets that overlap, and tight containment of the
union of several basic semialgebraic sets with a single convex one. We use
algebraic techniques from sum of squares optimization that reduce all these
tasks to semidefinite programs of small size and present numerical experiments
in realistic scenarios.
"
660,Long-Term Image Boundary Prediction,"  Boundary estimation in images and videos has been a very active topic of
research, and organizing visual information into boundaries and segments is
believed to be a corner stone of visual perception. While prior work has
focused on estimating boundaries for observed frames, our work aims at
predicting boundaries of future unobserved frames. This requires our model to
learn about the fate of boundaries and corresponding motion patterns --
including a notion of ""intuitive physics"". We experiment on natural video
sequences along with synthetic sequences with deterministic physics-based and
agent-based motions. While not being our primary goal, we also show that fusion
of RGB and boundary prediction leads to improved RGB predictions.
"
661,Navigable videos for presenting scientific data on head-mounted displays,"  Immersive, stereoscopic viewing enables scientists to better analyze the
spatial structures of visualized physical phenomena. However, their findings
cannot be properly presented in traditional media, which lack these core
attributes. Creating a presentation tool that captures this environment poses
unique challenges, namely related to poor viewing accessibility. Immersive
scientific renderings often require high-end equipment, which can be
impractical to obtain. We address these challenges with our authoring tool and
navigational interface, which is designed for affordable head-mounted displays.
With the authoring tool, scientists can show salient data features as connected
360{\deg} video paths, resulting in a ""choose-your-own-adventure"" experience.
Our navigational interface features bidirectional video playback for added
viewing control when users traverse the tailor-made content. We evaluate our
system's benefits by authoring case studies on several data sets and conducting
a usability study on the navigational interface's design. In summary, our
approach provides scientists an immersive medium to visually present their
research to the intended audience--spanning from students to colleagues--on
affordable virtual reality headsets.
"
662,"The Bricklayer Ecosystem - Art, Math, and Code","  This paper describes the Bricklayer Ecosystem - a freely-available online
educational ecosystem created for people of all ages and coding backgrounds.
Bricklayer is designed in accordance with a ""low-threshold infinite ceiling""
philosophy and has been successfully used to teach coding to primary school
students, middle school students, university freshmen, and in-service secondary
math teachers. Bricklayer programs are written in the functional programming
language SML and, when executed, create 2D and 3D artifacts. These artifacts
can be viewed using a variety of third-party tools such as LEGO Digital
Designer (LDD), LDraw, Minecraft clients, Brickr, as well as STereoLithography
viewers.
"
663,"CDVAE: Co-embedding Deep Variational Auto Encoder for Conditional
  Variational Generation","  Problems such as predicting a new shading field (Y) for an image (X) are
ambiguous: many very distinct solutions are good. Representing this ambiguity
requires building a conditional model P(Y|X) of the prediction, conditioned on
the image. Such a model is difficult to train, because we do not usually have
training data containing many different shadings for the same image. As a
result, we need different training examples to share data to produce good
models. This presents a danger we call ""code space collapse"" - the training
procedure produces a model that has a very good loss score, but which
represents the conditional distribution poorly. We demonstrate an improved
method for building conditional models by exploiting a metric constraint on
training data that prevents code space collapse. We demonstrate our model on
two example tasks using real data: image saturation adjustment, image
relighting. We describe quantitative metrics to evaluate ambiguous generation
results. Our results quantitatively and qualitatively outperform different
strong baselines.
"
664,A Visual Representation for Editing Face Images,"  We propose a new approach for editing face images, which enables numerous
exciting applications including face relighting, makeup transfer and face
detail editing. Our face edits are based on a visual representation, which
includes geometry, face segmentation, albedo, illumination and detail map. To
recover our visual representation, we start by estimating geometry using a
morphable face model, then decompose the face image to recover the albedo, and
then shade the geometry with the albedo and illumination. The residual between
our shaded geometry and the input image produces our detail map, which carries
high frequency information that is either insufficiently or incorrectly
captured by our shading process. By manipulating the detail map, we can edit
face images with reality and identity preserved. Our representation allows
various applications. First, it allows a user to directly manipulate various
illumination. Second, it allows non-parametric makeup transfer with input
face's distinctive identity features preserved. Third, it allows non-parametric
modifications to the face appearance by transferring details. For face
relighting and detail editing, we evaluate via a user study and our method
outperforms other methods. For makeup transfer, we evaluate via an online
attractiveness evaluation system, and can reliably make people look younger and
more attractive. We also show extensive qualitative comparisons to existing
methods, and have significant improvements over previous techniques.
"
665,Photorealistic Facial Texture Inference Using Deep Neural Networks,"  We present a data-driven inference method that can synthesize a
photorealistic texture map of a complete 3D face model given a partial 2D view
of a person in the wild. After an initial estimation of shape and low-frequency
albedo, we compute a high-frequency partial texture map, without the shading
component, of the visible face area. To extract the fine appearance details
from this incomplete input, we introduce a multi-scale detail analysis
technique based on mid-layer feature correlations extracted from a deep
convolutional neural network. We demonstrate that fitting a convex combination
of feature correlations from a high-resolution face database can yield a
semantically plausible facial detail description of the entire face. A complete
and photorealistic texture map can then be synthesized by iteratively
optimizing for the reconstructed feature correlations. Using these
high-resolution textures and a commercial rendering framework, we can produce
high-fidelity 3D renderings that are visually comparable to those obtained with
state-of-the-art multi-view face capture systems. We demonstrate successful
face reconstructions from a wide range of low resolution input images,
including those of historical figures. In addition to extensive evaluations, we
validate the realism of our results using a crowdsourced user study.
"
666,"Perspective Transformer Nets: Learning Single-View 3D Object
  Reconstruction without 3D Supervision","  Understanding the 3D world is a fundamental problem in computer vision.
However, learning a good representation of 3D objects is still an open problem
due to the high dimensionality of the data and many factors of variation
involved. In this work, we investigate the task of single-view 3D object
reconstruction from a learning agent's perspective. We formulate the learning
process as an interaction between 3D and 2D representations and propose an
encoder-decoder network with a novel projection loss defined by the perspective
transformation. More importantly, the projection loss enables the unsupervised
learning using 2D observation without explicit 3D supervision. We demonstrate
the ability of the model in generating 3D volume from a single 2D image with
three sets of experiments: (1) learning from single-class objects; (2) learning
from multi-class objects and (3) testing on novel object classes. Results show
superior performance and better generalization ability for 3D object
reconstruction when the projection loss is involved.
"
667,"Porous Structure Design in Tissue Engineering Using Anisotropic Radial
  Basis Function","  Development of additive manufacturing in last decade greatly improves tissue
engineering. During the manufacturing of porous scaffold, simplified but
functionally equivalent models are getting focused for practically reasons.
Scaffolds can be classified into regular porous scaffolds and irregular porous
scaffolds. Several methodologies are developed to design these scaffolds. A
novel method is proposed in this paper using anisotropic radial basis function
(ARBF) interpolation. This is method uses geometric models such as volumetric
meshes as input and proves to be flexible because geometric models are able to
capture the characteristics of complex tissues easily. Moreover, this method is
straightforward and easy to implement.
"
668,Sparse Geometric Representation Through Local Shape Probing,"  We propose a new shape analysis approach based on the non-local analysis of
local shape variations. Our method relies on a novel description of shape
variations, called Local Probing Field (LPF), which describes how a local
probing operator transforms a pattern onto the shape. By carefully optimizing
the position and orientation of each descriptor, we are able to capture shape
similarities and gather them into a geometrically relevant dictionary over
which the shape decomposes sparsely. This new representation permits to handle
shapes with mixed intrinsic dimensionality (e.g. shapes containing both
surfaces and curves) and to encode various shape features such as boundaries.
Our shape representation has several potential applications; here we
demonstrate its efficiency for shape resampling and point set denoising for
both synthetic and real data.
"
669,Geodesics using Waves: Computing Distances using Wave Propagation,"  In this paper, we present a new method for computing approximate geodesic
distances. We introduce the wave method for approximating geodesic distances
from a point on a manifold mesh. Our method involves the solution of two linear
systems of equations. One system of equations is solved repeatedly to propagate
the wave on the entire mesh, and one system is solved once after wave
propagation is complete in order to compute the approximate geodesic distances
up to an additive constant. However, these systems need to be pre-factored only
once, and can be solved efficiently at each iteration. All of our tests
required approximately between 300 and 400 iterations, which were completed in
a few seconds. Therefore, this method can approximate geodesic distances
quickly, and the approximation is highly accurate.
"
670,3D Shape Segmentation with Projective Convolutional Networks,"  This paper introduces a deep architecture for segmenting 3D objects into
their labeled semantic parts. Our architecture combines image-based Fully
Convolutional Networks (FCNs) and surface-based Conditional Random Fields
(CRFs) to yield coherent segmentations of 3D shapes. The image-based FCNs are
used for efficient view-based reasoning about 3D object parts. Through a
special projection layer, FCN outputs are effectively aggregated across
multiple views and scales, then are projected onto the 3D object surfaces.
Finally, a surface-based CRF combines the projected outputs with geometric
consistency cues to yield coherent segmentations. The whole architecture
(multi-view FCNs and CRF) is trained end-to-end. Our approach significantly
outperforms the existing state-of-the-art methods in the currently largest
segmentation benchmark (ShapeNet). Finally, we demonstrate promising
segmentation results on noisy 3D shapes acquired from consumer-grade depth
cameras.
"
671,"CFD results calibration from sparse sensor observations with a case
  study for indoor thermal map","  Current CFD calibration work has mainly focused on the CFD model calibration.
However no known work has considered the calibration of the CFD results. In
this paper, we take inspiration from the image editing problem to develop a
methodology to calibrate CFD simulation results based on sparse sensor
observations. We formulate the calibration of CFD results as an optimization
problem. The cost function consists of two terms. One term guarantees a good
local adjustment of the simulation results based on the sparse sensor
observations. The other term transmits the adjustment from local regions around
sensing locations to the global domain. The proposed method can enhance the CFD
simulation results while preserving the overall original profile. An experiment
in an air-conditioned room was implemented to verify the effectiveness of the
proposed method. In the experiment, four sensor observations were used to
calibrate a simulated thermal map with 167x365 data points. The experimental
results show that the proposed method is effective and practical.
"
672,A Qualitative and Quantitative Evaluation of 8 Clear Sky Models,"  We provide a qualitative and quantitative evaluation of 8 clear sky models
used in Computer Graphics. We compare the models with each other as well as
with measurements and with a reference model from the physics community. After
a short summary of the physics of the problem, we present the measurements and
the reference model, and how we ""invert"" it to get the model parameters. We
then give an overview of each CG model, and detail its scope, its algorithmic
complexity, and its results using the same parameters as in the reference
model. We also compare the models with a perceptual study. Our quantitative
results confirm that the less simplifications and approximations are used to
solve the physical equations, the more accurate are the results. We conclude
with a discussion of the advantages and drawbacks of each model, and how to
further improve their accuracy.
"
673,Fast Patch-based Style Transfer of Arbitrary Style,"  Artistic style transfer is an image synthesis problem where the content of an
image is reproduced with the style of another. Recent works show that a
visually appealing style transfer can be achieved by using the hidden
activations of a pretrained convolutional neural network. However, existing
methods either apply (i) an optimization procedure that works for any style
image but is very expensive, or (ii) an efficient feedforward network that only
allows a limited number of trained styles. In this work we propose a simpler
optimization objective based on local matching that combines the content
structure and style textures in a single layer of the pretrained network. We
show that our objective has desirable properties such as a simpler optimization
landscape, intuitive parameter tuning, and consistent frame-by-frame
performance on video. Furthermore, we use 80,000 natural images and 80,000
paintings to train an inverse network that approximates the result of the
optimization. This results in a procedure for artistic style transfer that is
efficient but also allows arbitrary content and style images.
"
674,Cloud Dictionary: Sparse Coding and Modeling for Point Clouds,"  With the development of range sensors such as LIDAR and time-of-flight
cameras, 3D point cloud scans have become ubiquitous in computer vision
applications, the most prominent ones being gesture recognition and autonomous
driving. Parsimony-based algorithms have shown great success on images and
videos where data points are sampled on a regular Cartesian grid. We propose an
adaptation of these techniques to irregularly sampled signals by using
continuous dictionaries. We present an example application in the form of point
cloud denoising.
"
675,Orthogonal Edge Routing for the EditLens,"  The EditLens is an interactive lens technique that supports the editing of
graphs. The user can insert, update, or delete nodes and edges while
maintaining an already existing layout of the graph. For the nodes and edges
that are affected by an edit operation, the EditLens suggests suitable
locations and routes, which the user can accept or adjust. For this purpose,
the EditLens requires an efficient routing algorithm that can compute results
at interactive framerates. Existing algorithms cannot fully satisfy the needs
of the EditLens. This paper describes a novel algorithm that can compute
orthogonal edge routes for incremental edit operations of graphs. Tests
indicate that, in general, the algorithm is better than alternative solutions.
"
676,Charted Metropolis Light Transport,"  In this manuscript, inspired by a simpler reformulation of primary sample
space Metropolis light transport, we derive a novel family of general Markov
chain Monte Carlo algorithms called charted Metropolis-Hastings, that
introduces the notion of sampling charts to extend a given sampling domain and
making it easier to sample the desired target distribution and escape from
local maxima through coordinate changes. We further apply the novel algorithms
to light transport simulation, obtaining a new type of algorithm called charted
Metropolis light transport, that can be seen as a bridge between primary sample
space and path space Metropolis light transport. The new algorithms require to
provide only right inverses of the sampling functions, a property that we
believe crucial to make them practical in the context of light transport
simulation. We further propose a method to integrate density estimation into
this framework through a novel scheme that uses it as an independence sampler.
"
677,Data-driven Shoulder Inverse Kinematics,"  This paper proposes a shoulder inverse kinematics (IK) technique. Shoulder
complex is comprised of the sternum, clavicle, ribs, scapula, humerus, and four
joints. The shoulder complex shows specific motion pattern, such as Scapulo
humeral rhythm. As a result, if a motion of the shoulder isgenerated without
the knowledge of kinesiology, it will be seen as un-natural. The proposed
technique generates motion of the shoulder complex about the orientation of the
upper arm by interpolating the measurement data. The shoulder IK method allows
novice animators to generate natural shoulder motions easily. As a result, this
technique improves the quality of character animation.
"
678,Quantum Optimal Transport for Tensor Field Processing,"  This article introduces a new notion of optimal transport (OT) between tensor
fields, which are measures whose values are positive semidefinite (PSD)
matrices. This ""quantum"" formulation of OT (Q-OT) corresponds to a relaxed
version of the classical Kantorovich transport problem, where the fidelity
between the input PSD-valued measures is captured using the geometry of the
Von-Neumann quantum entropy. We propose a quantum-entropic regularization of
the resulting convex optimization problem, which can be solved efficiently
using an iterative scaling algorithm. This method is a generalization of the
celebrated Sinkhorn algorithm to the quantum setting of PSD matrices. We extend
this formulation and the quantum Sinkhorn algorithm to compute barycenters
within a collection of input tensor fields. We illustrate the usefulness of the
proposed approach on applications to procedural noise generation, anisotropic
meshing, diffusion tensor imaging and spectral texture synthesis.
"
679,Fast color transfer from multiple images,"  Color transfer between images uses the statistics information of image
effectively. We present a novel approach of local color transfer between images
based on the simple statistics and locally linear embedding. A sketching
interface is proposed for quickly and easily specifying the color
correspondences between target and source image. The user can specify the
correspondences of local region using scribes, which more accurately transfers
the target color to the source image while smoothly preserving the boundaries,
and exhibits more natural output results. Our algorithm is not restricted to
one-to-one image color transfer and can make use of more than one target images
to transfer the color in different regions in the source image. Moreover, our
algorithm does not require to choose the same color style and image size
between source and target images. We propose the sub-sampling to reduce the
computational load. Comparing with other approaches, our algorithm is much
better in color blending in the input data. Our approach preserves the other
color details in the source image. Various experimental results show that our
approach specifies the correspondences of local color region in source and
target images. And it expresses the intention of users and generates more
actual and natural results of visual effect.
"
680,Analysis of Framelet Transforms on a Simplex,"  In this paper, we construct framelets associated with a sequence of
quadrature rules on the simplex $T^{2}$ in $\mathbb{R}^{2}$. We give the
framelet transforms -- decomposition and reconstruction of the coefficients for
framelets of a function on $T^{2}$. We prove that the reconstruction is exact
when the framelets are tight. We give an example of construction of framelets
and show that the framelet transforms can be computed as fast as FFT.
"
681,Green-Blue Stripe Pattern for Range Sensing from a Single Image,"  In this paper, we present a novel method for rapid high-resolution range
sensing using green-blue stripe pattern. We use green and blue for designing
high-frequency stripe projection pattern. For accurate and reliable range
recovery, we identify the stripe patterns by our color-stripe segmentation and
unwrapping algorithms. The experimental result for a naked human face shows the
effectiveness of our method.
"
682,"Son of Zorn's Lemma: Targeted Style Transfer Using Instance-aware
  Semantic Segmentation","  Style transfer is an important task in which the style of a source image is
mapped onto that of a target image. The method is useful for synthesizing
derivative works of a particular artist or specific painting. This work
considers targeted style transfer, in which the style of a template image is
used to alter only part of a target image. For example, an artist may wish to
alter the style of only one particular object in a target image without
altering the object's general morphology or surroundings. This is useful, for
example, in augmented reality applications (such as the recently released
Pokemon GO), where one wants to alter the appearance of a single real-world
object in an image frame to make it appear as a cartoon. Most notably, the
rendering of real-world objects into cartoon characters has been used in a
number of films and television show, such as the upcoming series Son of Zorn.
We present a method for targeted style transfer that simultaneously segments
and stylizes single objects selected by the user. The method uses a Markov
random field model to smooth and anti-alias outlier pixels near object
boundaries, so that stylized objects naturally blend into their surroundings.
"
683,Surface Reconstruction with Data-driven Exemplar Priors,"  In this paper, we propose a framework to reconstruct 3D models from raw
scanned points by learning the prior knowledge of a specific class of objects.
Unlike previous work that heuristically specifies particular regularities and
defines parametric models, our shape priors are learned directly from existing
3D models under a framework based on affinity propagation. Given a database of
3D models within the same class of objects, we build a comprehensive library of
3D local shape priors. We then formulate the problem to select
as-few-as-possible priors from the library, referred to as exemplar priors.
These priors are sufficient to represent the 3D shapes of the whole class of
objects from where they are generated. By manipulating these priors, we are
able to reconstruct geometrically faithful models with the same class of
objects from raw point clouds. Our framework can be easily generalized to
reconstruct various categories of 3D objects that have more geometrically or
topologically complex structures. Comprehensive experiments exhibit the power
of our exemplar priors for gracefully solving several problems in 3D shape
reconstruction such as preserving sharp features, recovering fine details and
so on.
"
684,"LayerBuilder: Layer Decomposition for Interactive Image and Video Color
  Editing","  Exploring and editing colors in images is a common task in graphic design and
photography. However, allowing for interactive recoloring while preserving
smooth color blends in the image remains a challenging problem. We present
LayerBuilder, an algorithm that decomposes an image or video into a linear
combination of colored layers to facilitate color-editing applications. These
layers provide an interactive and intuitive means for manipulating individual
colors. Our approach reduces color layer extraction to a fast iterative linear
system. Layer Builder uses locally linear embedding, which represents pixels as
linear combinations of their neighbors, to reduce the number of variables in
the linear solve and extract layers that can better preserve color blending
effects. We demonstrate our algorithm on recoloring a variety of images and
videos, and show its overall effectiveness in recoloring quality and time
complexity compared to previous approaches. We also show how this
representation can benefit other applications, such as automatic recoloring
suggestion, texture synthesis, and color-based filtering.
"
685,"A feasibility study on SSVEP-based interaction with motivating and
  immersive virtual and augmented reality","  Non-invasive steady-state visual evoked potential (SSVEP) based
brain-computer interface (BCI) systems offer high bandwidth compared to other
BCI types and require only minimal calibration and training. Virtual reality
(VR) has been already validated as effective, safe, affordable and motivating
feedback modality for BCI experiments. Augmented reality (AR) enhances the
physical world by superimposing informative, context sensitive, computer
generated content. In the context of BCI, AR can be used as a friendlier and
more intuitive real-world user interface, thereby facilitating a more seamless
and goal directed interaction. This can improve practicality and usability of
BCI systems and may help to compensate for their low bandwidth. In this
feasibility study, three healthy participants had to finish a complex
navigation task in immersive VR and AR conditions using an online SSVEP BCI.
Two out of three subjects were successful in all conditions. To our knowledge,
this is the first work to present an SSVEP BCI that operates using target
stimuli integrated in immersive VR and AR (head-mounted display and camera).
This research direction can benefit patients by introducing more intuitive and
effective real-world interaction (e.g. smart home control). It may also be
relevant for user groups that require or benefit from hands free operation
(e.g. due to temporary situational disability).
"
686,Poisson Vector Graphics (PVG) and Its Closed-Form Solver,"  This paper presents Poisson vector graphics, an extension of the popular
first-order diffusion curves, for generating smooth-shaded images. Armed with
two new types of primitives, namely Poisson curves and Poisson regions, PVG can
easily produce photorealistic effects such as specular highlights, core
shadows, translucency and halos. Within the PVG framework, users specify color
as the Dirichlet boundary condition of diffusion curves and control tone by
offsetting the Laplacian, where both controls are simply done by mouse click
and slider dragging. The separation of color and tone not only follows the
basic drawing principle that is widely adopted by professional artists, but
also brings three unique features to PVG, i.e., local hue change, ease of
extrema control, and permit of intersection among geometric primitives, making
PVG an ideal authoring tool.
  To render PVG, we develop an efficient method to solve 2D Poisson's equations
with piecewise constant Laplacians. In contrast to the conventional finite
element method that computes numerical solutions only, our method expresses the
solution using harmonic B-spline, whose basis functions can be constructed
locally and the control coefficients are obtained by solving a small sparse
linear system. Our closed-form solver is numerically stable and it supports
random access evaluation, zooming-in of arbitrary resolution and anti-aliasing.
Although the harmonic B-spline based solutions are approximate, computational
results show that the relative mean error is less than 0.3%, which cannot be
distinguished by naked eyes.
"
687,"Automatic Knot Adjustment Using Dolphin Echolocation Algorithm for
  B-Spline Curve Approximation","  In this paper, a new approach to solve the cubic B-spline curve fitting
problem is presented based on a meta-heuristic algorithm called "" dolphin
echolocation "". The method minimizes the proximity error value of the selected
nodes that measured using the least squares method and the Euclidean distance
method of the new curve generated by the reverse engineering. The results of
the proposed method are compared with the genetic algorithm. As a result, this
new method seems to be successful.
"
688,User-guided free-form asset modelling,"  In this paper a new system for piecewise primitive surface recovery on point
clouds is presented, which allows a novice user to sketch areas of interest in
order to guide the fitting process. The algorithm is demonstrated against a
benchmark technique for autonomous surface fitting, and, contrasted against
existing literature in user guided surface recovery, with empirical evidence.
It is concluded that the system is an improvement to the current documented
literature for its visual quality when modelling objects which are composed of
piecewise primitive shapes, and, in its ability to fill large holes on occluded
surfaces using free-form input.
"
689,Plausible Shading Decomposition For Layered Photo Retouching,"  Photographers routinely compose multiple manipulated photos of the same scene
(layers) into a single image, which is better than any individual photo could
be alone. Similarly, 3D artists set up rendering systems to produce layered
images to contain only individual aspects of the light transport, which are
composed into the final result in post-production. Regrettably, both approaches
either take considerable time to capture, or remain limited to synthetic
scenes. In this paper, we suggest a system to allow decomposing a single image
into a plausible shading decomposition (PSD) that approximates effects such as
shadow, diffuse illumination, albedo, and specular shading. This decomposition
can then be manipulated in any off-the-shelf image manipulation software and
recomposited back. We perform such a decomposition by learning a convolutional
neural network trained using synthetic data. We demonstrate the effectiveness
of our decomposition on synthetic (i.e., rendered) and real data (i.e.,
photographs), and use them for common photo manipulation, which are nearly
impossible to perform otherwise from single images.
"
690,Perceptually Optimized Image Rendering,"  We develop a framework for rendering photographic images, taking into account
display limitations, so as to optimize perceptual similarity between the
rendered image and the original scene. We formulate this as a constrained
optimization problem, in which we minimize a measure of perceptual
dissimilarity, the Normalized Laplacian Pyramid Distance (NLPD), which mimics
the early stage transformations of the human visual system. When rendering
images acquired with higher dynamic range than that of the display, we find
that the optimized solution boosts the contrast of low-contrast features
without introducing significant artifacts, yielding results of comparable
visual quality to current state-of-the art methods with no manual intervention
or parameter settings. We also examine a variety of other display constraints,
including limitations on minimum luminance (black point), mean luminance (as a
proxy for energy consumption), and quantized luminance levels (halftoning).
Finally, we show that the method may be used to enhance details and contrast of
images degraded by optical scattering (e.g. fog).
"
691,"By chance is not enough: Preserving relative density through non uniform
  sampling","  Dealing with visualizations containing large data set is a challenging issue
and, in the field of Information Visualization, almost every visual technique
reveals its drawback when visualizing large number of items. To deal with this
problem we introduce a formal environment, modeling in a virtual space the
image features we are interested in (e.g, absolute and relative density,
clusters, etc.) and we define some metrics able to characterize the image
decay. Such metrics drive our automatic techniques (i.e., not uniform sampling)
rescuing the image features and making them visible to the user. In this paper
we focus on 2D scatter-plots, devising a novel non uniform data sampling
strategy able to preserve in an effective way relative densities.
"
692,Learning Light Transport the Reinforced Way,"  We show that the equations of reinforcement learning and light transport
simulation are related integral equations. Based on this correspondence, a
scheme to learn importance while sampling path space is derived. The new
approach is demonstrated in a consistent light transport simulation algorithm
that uses reinforcement learning to progressively learn where light comes from.
As using this information for importance sampling includes information about
visibility, too, the number of light transport paths with zero contribution is
dramatically reduced, resulting in much less noisy images within a fixed time
budget.
"
693,"Stable and Controllable Neural Texture Synthesis and Style Transfer
  Using Histogram Losses","  Recently, methods have been proposed that perform texture synthesis and style
transfer by using convolutional neural networks (e.g. Gatys et al.
[2015,2016]). These methods are exciting because they can in some cases create
results with state-of-the-art quality. However, in this paper, we show these
methods also have limitations in texture quality, stability, requisite
parameter tuning, and lack of user controls. This paper presents a multiscale
synthesis pipeline based on convolutional neural networks that ameliorates
these issues. We first give a mathematical explanation of the source of
instabilities in many previous approaches. We then improve these instabilities
by using histogram losses to synthesize textures that better statistically
match the exemplar. We also show how to integrate localized style losses in our
multiscale framework. These losses can improve the quality of large features,
improve the separation of content and style, and offer artistic controls such
as paint by numbers. We demonstrate that our approach offers improved quality,
convergence in fewer iterations, and more stability over the optimization.
"
694,"Inkjet printing-based volumetric display projecting multiple full-colour
  2D patterns","  In this study, a method to construct a full-colour volumetric display is
presented using a commercially available inkjet printer. Photoreactive
luminescence materials are minutely and automatically printed as the volume
elements, and volumetric displays are constructed with high resolution using
easy-to-fabricate means that exploit inkjet printing technologies. The results
experimentally demonstrate the first prototype of an inkjet printing-based
volumetric display composed of multiple layers of transparent films that yield
a full-colour three-dimensional (3D) image. Moreover, we propose a design
algorithm with 3D structures that provide multiple different 2D full-colour
patterns when viewed from different directions and experimentally demonstrates
prototypes. It is considered that these types of 3D volumetric structures and
their fabrication methods based on widely deployed existing printing
technologies can be utilised as novel information display devices and systems,
including digital signage, media art, entertainment and security.
"
695,HoNVis: Visualizing and Exploring Higher-Order Networks,"  Unlike the conventional first-order network (FoN), the higher-order network
(HoN) provides a more accurate description of transitions by creating
additional nodes to encode higher-order dependencies. However, there exists no
visualization and exploration tool for the HoN. For applications such as the
development of strategies to control species invasion through global shipping
which is known to exhibit higher-order dependencies, the existing FoN
visualization tools are limited. In this paper, we present HoNVis, a novel
visual analytics framework for exploring higher-order dependencies of the
global ocean shipping network. Our framework leverages coordinated multiple
views to reveal the network structure at three levels of detail (i.e., the
global, local, and individual port levels). Users can quickly identify ports of
interest at the global level and specify a port to investigate its higher-order
nodes at the individual port level. Investigating a larger-scale impact is
enabled through the exploration of HoN at the local level. Using the global
ocean shipping network data, we demonstrate the effectiveness of our approach
with a real-world use case conducted by domain experts specializing in species
invasion. Finally, we discuss the generalizability of this framework to other
real-world applications such as information diffusion in social networks and
epidemic spreading through air transportation.
"
696,Ray tracing method for stereo image synthesis using CUDA,"  This paper presents a realization of the approach to spatial 3D stereo of
visualization of 3D images with use parallel Graphics processing unit (GPU).
The experiments of realization of synthesis of images of a 3D stage by a method
of trace of beams on GPU with Compute Unified Device Architecture (CUDA) have
shown that 60 % of the time is spent for the decision of a computing problem
approximately, the major part of time (40 %) is spent for transfer of data
between the central processing unit and GPU for computations and the
organization process of visualization. The study of the influence of increase
in the size of the GPU network at the speed of computations showed importance
of the correct task of structure of formation of the parallel computer network
and general mechanism of parallelization. Keywords: Volumetric 3D
visualization, stereo 3D visualization, ray tracing, parallel computing on GPU,
CUDA
"
697,"Conceptual and algorithmic development of Pseudo 3D Graphics and Video
  Content Visualization","  The article presents a general concept of the organization of pseudo three
dimension visualization of graphics and video content for three dimension
visualization systems. The steps of algorithms for solving the problem of
synthesis of three dimension stereo images based on two dimension images are
introduced. The features of synthesis organization of standard format of three
dimension stereo frame are presented. Moreover, the performed experimental
simulation for generating complete stereoframes and the results of its time
complexity are shown. Keywords:Three dimension visualization, pseudo three
dimension stereo, a stereo pair, three dimension stereo format, algorithm,
modeling, time complexity.
"
698,"Generalized 3D Voxel Image Synthesis Architecture for Volumetric Spatial
  Visualization","  A general concept of 3D volumetric visualization systems is described based
on 3D discrete voxel scenes (worlds) representation. Definitions of 3D discrete
voxel scene (world) basic elements and main steps of the image synthesis
algorithm are formulated. An algorithm for solving the problem of the voxelized
world 3D image synthesis, intended for the systems of volumetric spatial
visualization, is proposed. A computer-based architecture for 3D volumetric
visualization of 3D discrete voxel world is presented. On the basis of the
proposed overall concept of discrete voxel representation, the proposed
architecture successfully adapts the ray tracing technique for the synthesis of
3D volumetric images. Since it is algorithmically simple and effectively
supports parallelism, it can efficiently be implemented.
  Key words:Volumetric spatial visualization, 3D volumetric imagesynthesis,
discrete voxel world, ray tracing.
"
699,"A Region Based Easy Path Wavelet Transform For Sparse Image
  Representation","  The Easy Path Wavelet Transform is an adaptive transform for bivariate
functions (in particular natural images) which has been proposed in [1]. It
provides a sparse representation by finding a path in the domain of the
function leveraging the local correlations of the function values. It then
applies a one dimensional wavelet transform to the obtained vector, decimates
the points and iterates the procedure. The main drawback of such method is the
need to store, for each level of the transform, the path which vectorizes the
two dimensional data. Here we propose a variation on the method which consists
of firstly applying a segmentation procedure to the function domain,
partitioning it into regions where the variation in the function values is low;
in a second step, inside each such region, a path is found in some
deterministic way, i.e. not data-dependent. This circumvents the need to store
the paths at each level, while still obtaining good quality lossy compression.
This method is particularly well suited to encode a Region of Interest in the
image with different quality than the rest of the image.
  [1] Gerlind Plonka. The easy path wavelet transform: A new adaptive wavelet
transform for sparse representation of two-dimensional data. Multiscale
Modeling & Simulation, 7(3):1474$-$1496, 2008.
"
700,Video Frame Synthesis using Deep Voxel Flow,"  We address the problem of synthesizing new video frames in an existing video,
either in-between existing frames (interpolation), or subsequent to them
(extrapolation). This problem is challenging because video appearance and
motion can be highly complex. Traditional optical-flow-based solutions often
fail where flow estimation is challenging, while newer neural-network-based
methods that hallucinate pixel values directly often produce blurry results. We
combine the advantages of these two methods by training a deep network that
learns to synthesize video frames by flowing pixel values from existing ones,
which we call deep voxel flow. Our method requires no human supervision, and
any video can be used as training data by dropping, and then learning to
predict, existing frames. The technique is efficient, and can be applied at any
video resolution. We demonstrate that our method produces results that both
quantitatively and qualitatively improve upon the state-of-the-art.
"
701,Monocular LSD-SLAM Integration within AR System,"  In this paper, we cover the process of integrating Large-Scale Direct
Simultaneous Localization and Mapping (LSD-SLAM) algorithm into our existing AR
stereo engine, developed for our modified ""Augmented Reality Oculus Rift"". With
that, we are able to track one of our realworld cameras which are mounted on
the rift, within a complete unknown environment. This makes it possible to
achieve a constant and full augmentation, synchronizing our 3D movement (x, y,
z) in both worlds, the real world and the virtual world. The development for
the basic AR setup using the Oculus Rift DK1 and two fisheye cameras is fully
documented in our previous paper. After an introduction to image-based
registration, we detail the LSD-SLAM algorithm and document our code
implementing our integration. The AR stereo engine with Oculus Rift support can
be accessed via the GIT repository https://github.com/MaXvanHeLL/ARift.git and
the modified LSD-SLAM project used for the integration is available here
https://github.com/MaXvanHeLL/LSD-SLAM.git.
"
702,Bezier developable surfaces,"  In this paper we address the issue of designing developable surfaces with
Bezier patches. We show that developable surfaces with a polynomial edge of
regression are the set of developable surfaces which can be constructed with
Aumann's algorithm. We also obtain the set of polynomial developable surfaces
which can be constructed using general polynomial curves. The conclusions can
be extended to spline surfaces as well.
"
703,"Towards Developing an Easy-To-Use Scripting Environment for Animating
  Virtual Characters","  This paper presents the three scripting commands and main functionalities of
a novel character animation environment called CHASE. CHASE was developed for
enabling inexperienced programmers, animators, artists, and students to animate
in meaningful ways virtual reality characters. This is achieved by scripting
simple commands within CHASE. The commands identified, which are associated
with simple parameters, are responsible for generating a number of predefined
motions and actions of a character. Hence, the virtual character is able to
animate within a virtual environment and to interact with tasks located within
it. An additional functionality of CHASE is supplied. It provides the ability
to generate multiple tasks of a character, such as providing the user the
ability to generate scenario-related animated sequences. However, since
multiple characters may require simultaneous animation, the ability to script
actions of different characters at the same time is also provided.
"
704,"Visualization and Analysis of Large-Scale, Tree-Based, Adaptive Mesh
  Refinement Simulations with Arbitrary Rectilinear Geometry","  We present here the first systematic treatment of the problems posed by the
visualization and analysis of large-scale, parallel adaptive mesh refinement
(AMR) simulations on an Eulerian grid. When compared to those obtained by
constructing an intermediate unstructured mesh with fully described
connectivity, our primary results indicate a gain of at least 80\% in terms of
memory footprint, with a better rendering while retaining similar execution
speed. In this article, we describe the key concepts that allow us to obtain
these results, together with the methodology that facilitates the design,
implementation, and optimization of algorithms operating directly on such
refined meshes. This native support for AMR meshes has been contributed to the
open source Visualization Toolkit (VTK). This work pertains to a broader
long-term vision, with the dual goal to both improve interactivity when
exploring such data sets in 2 and 3 dimensions, and optimize resource
utilization.
"
705,"Learning to Generate Posters of Scientific Papers by Probabilistic
  Graphical Models","  Researchers often summarize their work in the form of scientific posters.
Posters provide a coherent and efficient way to convey core ideas expressed in
scientific papers. Generating a good scientific poster, however, is a complex
and time consuming cognitive task, since such posters need to be readable,
informative, and visually aesthetic. In this paper, for the first time, we
study the challenging problem of learning to generate posters from scientific
papers. To this end, a data-driven framework, that utilizes graphical models,
is proposed. Specifically, given content to display, the key elements of a good
poster, including attributes of each panel and arrangements of graphical
elements are learned and inferred from data. During the inference stage, an MAP
inference framework is employed to incorporate some design principles. In order
to bridge the gap between panel attributes and the composition within each
panel, we also propose a recursive page splitting algorithm to generate the
panel layout for a poster. To learn and validate our model, we collect and
release a new benchmark dataset, called NJU-Fudan Paper-Poster dataset, which
consists of scientific papers and corresponding posters with exhaustively
labelled panels and attributes. Qualitative and quantitative results indicate
the effectiveness of our approach.
"
706,Fast and robust curve skeletonization for real-world elongated objects,"  We consider the problem of extracting curve skeletons of three-dimensional,
elongated objects given a noisy surface, which has applications in agricultural
contexts such as extracting the branching structure of plants. We describe an
efficient and robust method based on breadth-first search that can determine
curve skeletons in these contexts. Our approach is capable of automatically
detecting junction points as well as spurious segments and loops. All of that
is accomplished with only one user-adjustable parameter. The run time of our
method ranges from hundreds of milliseconds to less than four seconds on large,
challenging datasets, which makes it appropriate for situations where real-time
decision making is needed. Experiments on synthetic models as well as on data
from real world objects, some of which were collected in challenging field
conditions, show that our approach compares favorably to classical thinning
algorithms as well as to recent contributions to the field.
"
707,A Data-driven Approach for Furniture and Indoor Scene Colorization,"  We present a data-driven approach that colorizes 3D furniture models and
indoor scenes by leveraging indoor images on the internet. Our approach is able
to colorize the furniture automatically according to an example image. The core
is to learn image-guided mesh segmentation to segment the model into different
parts according to the image object. Given an indoor scene, the system supports
colorization-by-example, and has the ability to recommend the colorization
scheme that is consistent with a user-desired color theme. The latter is
realized by formulating the problem as a Markov random field model that imposes
user input as an additional constraint. We contribute to the community a
hierarchically organized image-model database with correspondences between each
image and the corresponding model at the part-level. Our experiments and a user
study show that our system produces perceptually convincing results comparable
to those generated by interior designers.
"
708,SceneSeer: 3D Scene Design with Natural Language,"  Designing 3D scenes is currently a creative task that requires significant
expertise and effort in using complex 3D design interfaces. This effortful
design process starts in stark contrast to the easiness with which people can
use language to describe real and imaginary environments. We present SceneSeer:
an interactive text to 3D scene generation system that allows a user to design
3D scenes using natural language. A user provides input text from which we
extract explicit constraints on the objects that should appear in the scene.
Given these explicit constraints, the system then uses a spatial knowledge base
learned from an existing database of 3D scenes and 3D object models to infer an
arrangement of the objects forming a natural scene matching the input
description. Using textual commands the user can then iteratively refine the
created scene by adding, removing, replacing, and manipulating objects. We
evaluate the quality of 3D scenes generated by SceneSeer in a perceptual
evaluation experiment where we compare against manually designed scenes and
simpler baselines for 3D scene generation. We demonstrate how the generated
scenes can be iteratively refined through simple natural language commands.
"
709,SceneSuggest: Context-driven 3D Scene Design,"  We present SceneSuggest: an interactive 3D scene design system providing
context-driven suggestions for 3D model retrieval and placement. Using a
point-and-click metaphor we specify regions in a scene in which to
automatically place and orient relevant 3D models. Candidate models are ranked
using a set of static support, position, and orientation priors learned from 3D
scenes. We show that our suggestions enable rapid assembly of indoor scenes. We
perform a user study comparing suggestions to manual search and selection, as
well as to suggestions with no automatic orientation. We find that suggestions
reduce total modeling time by 32%, that orientation priors reduce time spent
re-orienting objects by 27%, and that context-driven suggestions reduce the
number of text queries by 50%.
"
710,"Two New Contributions to the Visualization of AMR Grids: I. Interactive
  Rendering of Extreme-Scale 2-Dimensional Grids II. Novel Selection Filters in
  Arbitrary Dimension","  We present here the result of continuation work, performed to further fulfill
the vision we outlined in [Harel,Lekien,P\'eba\""y-2017] for the visualization
and analysis of tree-based adaptive mesh refinement (AMR) simulations, using
the hypertree grid paradigm which we proposed.
  The first filter presented hereafter implements an adaptive approach in order
to accelerate the rendering of 2-dimensional AMR grids, hereby solving the
problem posed by the loss of interactivity that occurs when dealing with large
and/or deeply refined meshes. Specifically, view parameters are taken into
account, in order to: on one hand, avoid creating surface elements that are
outside of the view area; on the other hand, utilize level-of-detail properties
to cull those cells that are deemed too small to be visible with respect to the
given view parameters. This adaptive approach often results in a massive
increase in rendering performance.
  In addition, two new selection filters provide data analysis capabilities, by
means of allowing for the extraction of those cells within a hypertree grid
that are deemed relevant in some sense, either geometrically or topologically.
After a description of these new algorithms, we illustrate their use within the
Visualization Toolkit (VTK) in which we implemented them. This note ends with
some suggestions for subsequent work.
"
711,The Signals and Systems Approach to Animation,"  Animation is ubiquitous in visualization systems, and a common technique for
creating these animations is the transition. In the transition approach,
animations are created by smoothly interpolating a visual attribute between a
start and end value, reaching the end value after a specified duration. This
approach works well when each transition for an attribute is allowed to finish
before the next is triggered, but performs poorly when a new transition is
triggered before the current transition has finished. In particular,
interruptions introduce velocity discontinuities, and frequent interruptions
can slow down the resulting animation. To solve these problems, we model the
problem of animation as a signal processing problem. In our technique,
animations are produced by transformations of signals, or functions over time.
In particular, an animation is produced by transforming an input signal, a
function from time to target attribute value, into an output signal, a function
from time to displayed attribute value. We show that well-known
signal-processing techniques can be applied to produce animations that are free
from velocity discontinuities even when interrupted.
"
712,A Machine-Learning Framework for Design for Manufacturability,"  this is a duplicate submission(original is arXiv:1612.02141). Hence want to
withdraw it
"
713,Fast Back-Projection for Non-Line of Sight Reconstruction,"  Recent works have demonstrated non-line of sight (NLOS) reconstruction by
using the time-resolved signal frommultiply scattered light. These works
combine ultrafast imaging systems with computation, which back-projects the
recorded space-time signal to build a probabilistic map of the hidden geometry.
Unfortunately, this computation is slow, becoming a bottleneck as the imaging
technology improves. In this work, we propose a new back-projection technique
for NLOS reconstruction, which is up to a thousand times faster than previous
work, with almost no quality loss. We base on the observation that the hidden
geometry probability map can be built as the intersection of the three-bounce
space-time manifolds defined by the light illuminating the hidden geometry and
the visible point receiving the scattered light from such hidden geometry. This
allows us to pose the reconstruction of the hidden geometry as the voxelization
of these space-time manifolds, which has lower theoretic complexity and is
easily implementable in the GPU. We demonstrate the efficiency and quality of
our technique compared against previous methods in both captured and synthetic
data
"
714,"A Computational Model of a Single-Photon Avalanche Diode Sensor for
  Transient Imaging","  Single-Photon Avalanche Diodes (SPAD) are affordable photodetectors, capable
to collect extremely fast low-energy events, due to their single-photon
sensibility. This makes them very suitable for time-of-flight-based range
imaging systems, allowing to reduce costs and power requirements, without
sacrifizing much temporal resolution. In this work we describe a computational
model to simulate the behaviour of SPAD sensors, aiming to provide a realistic
camera model for time-resolved light transport simulation, with applications on
prototyping new reconstructions techniques based on SPAD time-of-flight data.
Our model accounts for the major effects of the sensor on the incoming signal.
We compare our model against real-world measurements, and apply it to a variety
of scenarios, including complex multiply-scattered light transport.
"
715,"Development of a computer-aided design software for dental splint in
  orthognathic surgery","  In the orthognathic surgery, dental splints are important and necessary to
help the surgeon reposition the maxilla or mandible. However, the traditional
methods of manual design of dental splints are difficult and time-consuming.
The research on computer-aided design software for dental splints is rarely
reported. Our purpose is to develop a novel special software named EasySplint
to design the dental splints conveniently and efficiently. The design can be
divided into two steps, which are the generation of initial splint base and the
Boolean operation between it and the maxilla-mandibular model. The initial
splint base is formed by ruled surfaces reconstructed using the manually picked
points. Then, a method to accomplish Boolean operation based on the distance
filed of two meshes is proposed. The interference elimination can be conducted
on the basis of marching cubes algorithm and Boolean operation. The accuracy of
the dental splint can be guaranteed since the original mesh is utilized to form
the result surface. Using EasySplint, the dental splints can be designed in
about 10 minutes and saved as a stereo lithography (STL) file for 3D printing
in clinical applications. Three phantom experiments were conducted and the
efficiency of our method was demonstrated.
"
716,"Interactive reconstructions of cranial 3D implants under MeVisLab as an
  alternative to commercial planning software","  In this publication, the interactive planning and reconstruction of cranial
3D Implants under the medical prototyping platform MeVisLab as alternative to
commercial planning software is introduced. In doing so, a MeVisLab prototype
consisting of a customized data-flow network and an own C++ module was set up.
As a result, the Computer-Aided Design (CAD) software prototype guides a user
through the whole workflow to generate an implant. Therefore, the workflow
begins with loading and mirroring the patients head for an initial curvature of
the implant. Then, the user can perform an additional Laplacian smoothing,
followed by a Delaunay triangulation. The result is an aesthetic looking and
well-fitting 3D implant, which can be stored in a CAD file format, e.g.
STereoLithography (STL), for 3D printing. The 3D printed implant can finally be
used for an in-depth pre-surgical evaluation or even as a real implant for the
patient. In a nutshell, our research and development shows that a customized
MeVisLab software prototype can be used as an alternative to complex commercial
planning software, which may also not be available in every clinic. Finally,
not to conform ourselves directly to available commercial software and look for
other options that might improve the workflow.
"
717,"Robust Non-Rigid Registration with Reweighted Position and
  Transformation Sparsity","  Non-rigid registration is challenging because it is ill-posed with high
degrees of freedom and is thus sensitive to noise and outliers. We propose a
robust non-rigid registration method using reweighted sparsities on position
and transformation to estimate the deformations between 3-D shapes. We
formulate the energy function with position and transformation sparsity on both
the data term and the smoothness term, and define the smoothness constraint
using local rigidity. The double sparsity based non-rigid registration model is
enhanced with a reweighting scheme, and solved by transferring the model into
four alternately-optimized subproblems which have exact solutions and
guaranteed convergence. Experimental results on both public datasets and real
scanned datasets show that our method outperforms the state-of-the-art methods
and is more robust to noise and outliers than conventional non-rigid
registration methods.
"
718,Autocomplete Textures for 3D Printing,"  Texture is an essential property of physical objects that affects aesthetics,
usability, and functionality. However, designing and applying textures to 3D
objects with existing tools remains difficult and time-consuming; it requires
proficient 3D modeling skills. To address this, we investigated an
auto-completion approach for efficient texture creation that automates the
tedious, repetitive process of applying texture while allowing flexible
customization. We developed techniques for users to select a target surface,
sketch and manipulate a texture with 2D drawings, and then generate 3D
printable textures onto an arbitrary curved surface. In a controlled experiment
our tool sped texture creation by 80% over conventional tools, a performance
gain that is higher with more complex target surfaces. This result confirms
that auto-completion is powerful for creating 3D textures.
"
719,"Color Orchestra: Ordering Color Palettes for Interpolation and
  Prediction","  Color theme or color palette can deeply influence the quality and the feeling
of a photograph or a graphical design. Although color palettes may come from
different sources such as online crowd-sourcing, photographs and graphical
designs, in this paper, we consider color palettes extracted from fine art
collections, which we believe to be an abundant source of stylistic and unique
color themes. We aim to capture color styles embedded in these collections by
means of statistical models and to build practical applications upon these
models. As artists often use their personal color themes in their paintings,
making these palettes appear frequently in the dataset, we employed density
estimation to capture the characteristics of palette data. Via density
estimation, we carried out various predictions and interpolations on palettes,
which led to promising applications such as photo-style exploration, real-time
color suggestion, and enriched photo recolorization. It was, however,
challenging to apply density estimation to palette data as palettes often come
as unordered sets of colors, which make it difficult to use conventional
metrics on them. To this end, we developed a divide-and-conquer sorting
algorithm to rearrange the colors in the palettes in a coherent order, which
allows meaningful interpolation between color palettes. To confirm the
performance of our model, we also conducted quantitative experiments on
datasets of digitized paintings collected from the Internet and received
favorable results.
"
720,"Volumetric parametrization from a level set boundary representation with
  PHT Splines","  A challenge in isogeometric analysis is constructing analysis-suitable
volumetric meshes which can accurately represent the geometry of a given
physical domain. In this paper, we propose a method to derive a spline-based
representation of a domain of interest from voxel-based data. We show an
efficient way to obtain a boundary representation of the domain by a level-set
function. Then, we use the geometric information from the boundary (the normal
vectors and curvature) to construct a matching C1 representation with
hierarchical cubic splines. The approximation is done by a single template and
linear transformations (scaling, translations and rotations) without the need
for solving an optimization problem. We illustrate our method with several
examples in two and three dimensions, and show good performance on some
standard benchmark test problems.
"
721,ZM-Net: Real-time Zero-shot Image Manipulation Network,"  Many problems in image processing and computer vision (e.g. colorization,
style transfer) can be posed as 'manipulating' an input image into a
corresponding output image given a user-specified guiding signal. A holy-grail
solution towards generic image manipulation should be able to efficiently alter
an input image with any personalized signals (even signals unseen during
training), such as diverse paintings and arbitrary descriptive attributes.
However, existing methods are either inefficient to simultaneously process
multiple signals (let alone generalize to unseen signals), or unable to handle
signals from other modalities. In this paper, we make the first attempt to
address the zero-shot image manipulation task. We cast this problem as
manipulating an input image according to a parametric model whose key
parameters can be conditionally generated from any guiding signal (even unseen
ones). To this end, we propose the Zero-shot Manipulation Net (ZM-Net), a
fully-differentiable architecture that jointly optimizes an
image-transformation network (TNet) and a parameter network (PNet). The PNet
learns to generate key transformation parameters for the TNet given any guiding
signal while the TNet performs fast zero-shot image manipulation according to
both signal-dependent parameters from the PNet and signal-invariant parameters
from the TNet itself. Extensive experiments show that our ZM-Net can perform
high-quality image manipulation conditioned on different forms of guiding
signals (e.g. style images and attributes) in real-time (tens of milliseconds
per image) even for unseen signals. Moreover, a large-scale style dataset with
over 20,000 style images is also constructed to promote further research.
"
722,HTC Vive MeVisLab integration via OpenVR for medical applications,"  Virtual Reality, an immersive technology that replicates an environment via
computer-simulated reality, gets a lot of attention in the entertainment
industry. However, VR has also great potential in other areas, like the medical
domain, Examples are intervention planning, training and simulation. This is
especially of use in medical operations, where an aesthetic outcome is
important, like for facial surgeries. Alas, importing medical data into Virtual
Reality devices is not necessarily trivial, in particular, when a direct
connection to a proprietary application is desired. Moreover, most researcher
do not build their medical applications from scratch, but rather leverage
platforms like MeVisLab, MITK, OsiriX or 3D Slicer. These platforms have in
common that they use libraries like ITK and VTK, and provide a convenient
graphical interface. However, ITK and VTK do not support Virtual Reality
directly. In this study, the usage of a Virtual Reality device for medical data
under the MeVisLab platform is presented. The OpenVR library is integrated into
the MeVisLab platform, allowing a direct and uncomplicated usage of the head
mounted display HTC Vive inside the MeVisLab platform. Medical data coming from
other MeVisLab modules can directly be connected per drag-and-drop to the
Virtual Reality module, rendering the data inside the HTC Vive for immersive
virtual reality inspection.
"
723,Graffinity: Visualizing Connectivity In Large Graphs,"  Multivariate graphs are prolific across many fields, including transportation
and neuroscience. A key task in graph analysis is the exploration of
connectivity, to, for example, analyze how signals flow through neurons, or to
explore how well different cities are connected by flights. While standard
node-link diagrams are helpful in judging connectivity, they do not scale to
large networks. Adjacency matrices also do not scale to large networks and are
only suitable to judge connectivity of adjacent nodes. A key approach to
realize scalable graph visualization are queries: instead of displaying the
whole network, only a relevant subset is shown. Query-based techniques for
analyzing connectivity in graphs, however, can also easily suffer from
cluttering if the query result is big enough. To remedy this, we introduce
techniques that provide an overview of the connectivity and reveal details on
demand. We have two main contributions: (1) two novel visualization techniques
that work in concert for summarizing graph connectivity; and (2) Graffinity, an
open-source implementation of these visualizations supplemented by detail views
to enable a complete analysis workflow. Graffinity was designed in a close
collaboration with neuroscientists and is optimized for connectomics data
analysis, yet the technique is applicable across domains. We validate the
connectivity overview and our open-source tool with illustrative examples using
flight and connectomics data.
"
724,Adaptive User Perspective Rendering for Handheld Augmented Reality,"  Handheld Augmented Reality commonly implements some variant of magic lens
rendering, which turns only a fraction of the user's real environment into AR
while the rest of the environment remains unaffected. Since handheld AR devices
are commonly equipped with video see-through capabilities, AR magic lens
applications often suffer from spatial distortions, because the AR environment
is presented from the perspective of the camera of the mobile device. Recent
approaches counteract this distortion based on estimations of the user's head
position, rendering the scene from the user's perspective. To this end,
approaches usually apply face-tracking algorithms on the front camera of the
mobile device. However, this demands high computational resources and therefore
commonly affects the performance of the application beyond the already high
computational load of AR applications. In this paper, we present a method to
reduce the computational demands for user perspective rendering by applying
lightweight optical flow tracking and an estimation of the user's motion before
head tracking is started. We demonstrate the suitability of our approach for
computationally limited mobile devices and we compare it to device perspective
rendering, to head tracked user perspective rendering, as well as to fixed
point of view user perspective rendering.
"
725,"Sparse Inertial Poser: Automatic 3D Human Pose Estimation from Sparse
  IMUs","  We address the problem of making human motion capture in the wild more
practical by using a small set of inertial sensors attached to the body. Since
the problem is heavily under-constrained, previous methods either use a large
number of sensors, which is intrusive, or they require additional video input.
We take a different approach and constrain the problem by: (i) making use of a
realistic statistical body model that includes anthropometric constraints and
(ii) using a joint optimization framework to fit the model to orientation and
acceleration measurements over multiple frames. The resulting tracker Sparse
Inertial Poser (SIP) enables 3D human pose estimation using only 6 sensors
(attached to the wrists, lower legs, back and head) and works for arbitrary
human motions. Experiments on the recently released TNT15 dataset show that,
using the same number of sensors, SIP achieves higher accuracy than the dataset
baseline without using any video data. We further demonstrate the effectiveness
of SIP on newly recorded challenging motions in outdoor scenarios such as
climbing or jumping over a wall.
"
726,Image Restoration using Autoencoding Priors,"  We propose to leverage denoising autoencoder networks as priors to address
image restoration problems. We build on the key observation that the output of
an optimal denoising autoencoder is a local mean of the true data density, and
the autoencoder error (the difference between the output and input of the
trained autoencoder) is a mean shift vector. We use the magnitude of this mean
shift vector, that is, the distance to the local mean, as the negative log
likelihood of our natural image prior. For image restoration, we maximize the
likelihood using gradient descent by backpropagating the autoencoder error. A
key advantage of our approach is that we do not need to train separate networks
for different image restoration tasks, such as non-blind deconvolution with
different kernels, or super-resolution at different magnification factors. We
demonstrate state of the art results for non-blind deconvolution and
super-resolution using the same autoencoding prior.
"
727,Autocomplete 3D Sculpting,"  Digital sculpting is a popular means to create 3D models but remains a
challenging task for many users. This can be alleviated by recent advances in
data-driven and procedural modeling, albeit bounded by the underlying data and
procedures. We propose a 3D sculpting system that assists users in freely
creating models without predefined scope. With a brushing interface similar to
common sculpting tools, our system silently records and analyzes users'
workflows, and predicts what they might or should do in the future to reduce
input labor or enhance output quality. Users can accept, ignore, or modify the
suggestions and thus maintain full control and individual style. They can also
explicitly select and clone past workflows over output model regions. Our key
idea is to consider how a model is authored via dynamic workflows in addition
to what it is shaped in static geometry, for more accurate analysis of user
intentions and more general synthesis of shape structures. The workflows
contain potential repetitions for analysis and synthesis, including user inputs
(e.g. pen strokes on a pressure sensing tablet), model outputs (e.g. extrusions
on an object surface), and camera viewpoints. We evaluate our method via user
feedbacks and authored models.
"
728,Learning to Predict Indoor Illumination from a Single Image,"  We propose an automatic method to infer high dynamic range illumination from
a single, limited field-of-view, low dynamic range photograph of an indoor
scene. In contrast to previous work that relies on specialized image capture,
user input, and/or simple scene models, we train an end-to-end deep neural
network that directly regresses a limited field-of-view photo to HDR
illumination, without strong assumptions on scene geometry, material
properties, or lighting. We show that this can be accomplished in a three step
process: 1) we train a robust lighting classifier to automatically annotate the
location of light sources in a large dataset of LDR environment maps, 2) we use
these annotations to train a deep neural network that predicts the location of
lights in a scene from a single limited field-of-view photo, and 3) we
fine-tune this network using a small dataset of HDR environment maps to predict
light intensities. This allows us to automatically recover high-quality HDR
illumination estimates that significantly outperform previous state-of-the-art
methods. Consequently, using our illumination estimates for applications like
3D object insertion, we can achieve results that are photo-realistic, which is
validated via a perceptual user study.
"
729,Density-equalizing maps for simply-connected open surfaces,"  In this paper, we are concerned with the problem of creating flattening maps
of simply-connected open surfaces in $\mathbb{R}^3$. Using a natural principle
of density diffusion in physics, we propose an effective algorithm for
computing density-equalizing flattening maps with any prescribed density
distribution. By varying the initial density distribution, a large variety of
mappings with different properties can be achieved. For instance,
area-preserving parameterizations of simply-connected open surfaces can be
easily computed. Experimental results are presented to demonstrate the
effectiveness of our proposed method. Applications to data visualization and
surface remeshing are explored.
"
730,CanvoX: High-resolution VR Painting in Large Volumetric Canvas,"  With virtual reality, digital painting on 2D canvases is now being extended
to 3D spaces. Tilt Brush and Oculus Quill are widely accepted among artists as
tools that pave the way to a new form of art - 3D emmersive painting. Current
3D painting systems are only a start, emitting textured triangular geometries.
In this paper, we advance this new art of 3D painting to 3D volumetric painting
that enables an artist to draw a huge scene with full control of spatial color
fields. Inspired by the fact that 2D paintings often use vast space to paint
background and small but detailed space for foreground, we claim that
supporting a large canvas in varying detail is essential for 3D painting. In
order to help artists focus and audiences to navigate the large canvas space,
we provide small artist-defined areas, called rooms, that serve as beacons for
artist-suggested scales, spaces, locations for intended appreciation view of
the painting. Artists and audiences can easily transport themselves between
different rooms. Technically, our canvas is represented as an array of deep
octrees of depth 24 or higher, built on CPU for volume painting and on GPU for
volume rendering using accurate ray casting. In CPU side, we design an
efficient iterative algorithm to refine or coarsen octree, as a result of
volumetric painting strokes, at highly interactive rates, and update the
corresponding GPU textures. Then we use GPU-based ray casting algorithms to
render the volumetric painting result. We explore precision issues stemming
from ray-casting the octree of high depth, and provide a new analysis and
verification. From our experimental results as well as the positive feedback
from the participating artists, we strongly believe that our new 3D volume
painting system can open up a new possibility for VR-driven digital art medium
to professional artists as well as to novice users.
"
731,Projection Mapping Technologies for AR,"  This invited talk will present recent projection mapping technologies for
augmented reality. First, fundamental technologies are briefly explained, which
have been proposed to overcome the technical limitations of ordinary
projectors. Second, augmented reality (AR) applications using projection
mapping technologies are introduced.
"
732,Multi-Agent Diverse Generative Adversarial Networks,"  We propose MAD-GAN, an intuitive generalization to the Generative Adversarial
Networks (GANs) and its conditional variants to address the well known problem
of mode collapse. First, MAD-GAN is a multi-agent GAN architecture
incorporating multiple generators and one discriminator. Second, to enforce
that different generators capture diverse high probability modes, the
discriminator of MAD-GAN is designed such that along with finding the real and
fake samples, it is also required to identify the generator that generated the
given fake sample. Intuitively, to succeed in this task, the discriminator must
learn to push different generators towards different identifiable modes. We
perform extensive experiments on synthetic and real datasets and compare
MAD-GAN with different variants of GAN. We show high quality diverse sample
generations for challenging tasks such as image-to-image translation and face
generation. In addition, we also show that MAD-GAN is able to disentangle
different modalities when trained using highly challenging diverse-class
dataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the
end, we show its efficacy on the unsupervised feature representation task. In
Appendix, we introduce a similarity based competing objective (MAD-GAN-Sim)
which encourages different generators to generate diverse samples based on a
user defined similarity metric. We show its performance on the image-to-image
translation, and also show its effectiveness on the unsupervised feature
representation task.
"
733,"Restoration of Atmospheric Turbulence-distorted Images via RPCA and
  Quasiconformal Maps","  We address the problem of restoring a high-quality image from an observed
image sequence strongly distorted by atmospheric turbulence. A novel algorithm
is proposed in this paper to reduce geometric distortion as well as
space-and-time-varying blur due to strong turbulence. By considering a suitable
energy functional, our algorithm first obtains a sharp reference image and a
subsampled image sequence containing sharp and mildly distorted image frames
with respect to the reference image. The subsampled image sequence is then
stabilized by applying the Robust Principal Component Analysis (RPCA) on the
deformation fields between image frames and warping the image frames by a
quasiconformal map associated with the low-rank part of the deformation matrix.
After image frames are registered to the reference image, the low-rank part of
them are deblurred via a blind deconvolution, and the deblurred frames are then
fused with the enhanced sparse part. Experiments have been carried out on both
synthetic and real turbulence-distorted video. Results demonstrate that our
method is effective in alleviating distortions and blur, restoring image
details and enhancing visual quality.
"
734,"Reconstruction of~3-D Rigid Smooth Curves Moving Free when Two Traceable
  Points Only are Available","  This paper extends previous research in that sense that for orthogonal
projections of rigid smooth (true-3D) curves moving totally free it reduces the
number of required traceable points to two only (the best results known so far
to the author are 3 points from free motion and 2 for motion restricted to
rotation around a fixed direction and and 2 for motion restricted to influence
of a homogeneous force field). The method used is exploitation of information
on tangential projections. It discusses also possibility of simplification of
reconstruction of flat curves moving free for prospective projections.
"
735,Denoising a Point Cloud for Surface Reconstruction,"  Surface reconstruction from an unorganized point cloud is an important
problem due to its widespread applications. White noise, possibly clustered
outliers, and noisy perturbation may be generated when a point cloud is sampled
from a surface. Most existing methods handle limited amount of noise. We
develop a method to denoise a point cloud so that the users can run their
surface reconstruction codes or perform other analyses afterwards. Our
experiments demonstrate that our method is computationally efficient and it has
significantly better noise handling ability than several existing surface
reconstruction codes.
"
736,Liquid Splash Modeling with Neural Networks,"  This paper proposes a new data-driven approach to model detailed splashes for
liquid simulations with neural networks. Our model learns to generate
small-scale splash detail for the fluid-implicit-particle method using training
data acquired from physically parametrized, high resolution simulations. We use
neural networks to model the regression of splash formation using a classifier
together with a velocity modifier. For the velocity modification, we employ a
heteroscedastic model. We evaluate our method for different spatial scales,
simulation setups, and solvers. Our simulation results demonstrate that our
model significantly improves visual fidelity with a large amount of realistic
droplet formation and yields splash detail much more efficiently than finer
discretizations.
"
737,A learning-based approach for automatic image and video colorization,"  In this paper, we present a color transfer algorithm to colorize a broad
range of gray images without any user intervention. The algorithm uses a
machine learning-based approach to automatically colorize grayscale images. The
algorithm uses the superpixel representation of the reference color images to
learn the relationship between different image features and their corresponding
color values. We use this learned information to predict the color value of
each grayscale image superpixel. As compared to processing individual image
pixels, our use of superpixels helps us to achieve a much higher degree of
spatial consistency as well as speeds up the colorization process. The
predicted color values of the gray-scale image superpixels are used to provide
a 'micro-scribble' at the centroid of the superpixels. These color scribbles
are refined by using a voting based approach. To generate the final
colorization result, we use an optimization-based approach to smoothly spread
the color scribble across all pixels within a superpixel. Experimental results
on a broad range of images and the comparison with existing state-of-the-art
colorization methods demonstrate the greater effectiveness of the proposed
algorithm.
"
738,"Interactive Outlining of Pancreatic Cancer Liver Metastases in
  Ultrasound Images","  Ultrasound (US) is the most commonly used liver imaging modality worldwide.
Due to its low cost, it is increasingly used in the follow-up of cancer
patients with metastases localized in the liver. In this contribution, we
present the results of an interactive segmentation approach for liver
metastases in US acquisitions. A (semi-) automatic segmentation is still very
challenging because of the low image quality and the low contrast between the
metastasis and the surrounding liver tissue. Thus, the state of the art in
clinical practice is still manual measurement and outlining of the metastases
in the US images. We tackle the problem by providing an interactive
segmentation approach providing real-time feedback of the segmentation results.
The approach has been evaluated with typical US acquisitions from the clinical
routine, and the datasets consisted of pancreatic cancer metastases. Even for
difficult cases, satisfying segmentations results could be achieved because of
the interactive real-time behavior of the approach. In total, 40 clinical
images have been evaluated with our method by comparing the results against
manual ground truth segmentations. This evaluation yielded to an average Dice
Score of 85% and an average Hausdorff Distance of 13 pixels.
"
739,"The Design, Implementation, and Deployment of a System to Transparently
  Compress Hundreds of Petabytes of Image Files for a File-Storage Service","  We report the design, implementation, and deployment of Lepton, a
fault-tolerant system that losslessly compresses JPEG images to 77% of their
original size on average. Lepton replaces the lowest layer of baseline JPEG
compression-a Huffman code-with a parallelized arithmetic code, so that the
exact bytes of the original JPEG file can be recovered quickly. Lepton matches
the compression efficiency of the best prior work, while decoding more than
nine times faster and in a streaming manner. Lepton has been released as
open-source software and has been deployed for a year on the Dropbox
file-storage backend. As of February 2017, it had compressed more than 203 PiB
of user JPEG files, saving more than 46 PiB.
"
740,Reversible Jump Metropolis Light Transport using Inverse Mappings,"  We study Markov Chain Monte Carlo (MCMC) methods operating in primary sample
space and their interactions with multiple sampling techniques. We observe that
incorporating the sampling technique into the state of the Markov Chain, as
done in Multiplexed Metropolis Light Transport (MMLT), impedes the ability of
the chain to properly explore the path space, as transitions between sampling
techniques lead to disruptive alterations of path samples. To address this
issue, we reformulate Multiplexed MLT in the Reversible Jump MCMC framework
(RJMCMC) and introduce inverse sampling techniques that turn light paths into
the random numbers that would produce them. This allows us to formulate a novel
perturbation that can locally transition between sampling techniques without
changing the geometry of the path, and we derive the correct acceptance
probability using RJMCMC. We investigate how to generalize this concept to
non-invertible sampling techniques commonly found in practice, and introduce
probabilistic inverses that extend our perturbation to cover most sampling
methods found in light transport simulations. Our theory reconciles the
inverses with RJMCMC yielding an unbiased algorithm, which we call Reversible
Jump MLT (RJMLT). We verify the correctness of our implementation in canonical
and practical scenarios and demonstrate improved temporal coherence, decrease
in structured artifacts, and faster convergence on a wide variety of scenes.
"
741,Boundary First Flattening,"  A conformal flattening maps a curved surface to the plane without distorting
angles---such maps have become a fundamental building block for problems in
geometry processing, numerical simulation, and computational design. Yet
existing methods provide little direct control over the shape of the flattened
domain, or else demand expensive nonlinear optimization. Boundary first
flattening (BFF) is a linear method for conformal parameterization which is
faster than traditional linear methods, yet provides control and quality
comparable to sophisticated nonlinear schemes. The key insight is that the
boundary data for many conformal mapping problems can be efficiently
constructed via the Cherrier formula together with a pair of Poincare-Steklov
operators; once the boundary is known, the map can be easily extended over the
rest of the domain. Since computation demands only a single factorization of
the real Laplace matrix, the amortized cost is about 50x less than any
previously published technique for boundary-controlled conformal flattening. As
a result, BFF opens the door to real-time editing or fast optimization of
high-resolution maps, with direct control over boundary length or angle. We
show how this method can be used to construct maps with sharp corners, cone
singularities, minimal area distortion, and uniformization over the unit disk;
we also demonstrate for the first time how a surface can be conformally
flattened directly onto any given target shape.
"
742,Automatic Content-aware Projection for 360{\deg} Videos,"  To watch 360{\deg} videos on normal 2D displays, we need to project the
selected part of the 360{\deg} image onto the 2D display plane. In this paper,
we propose a fully-automated framework for generating content-aware 2D
normal-view perspective videos from 360{\deg} videos. Especially, we focus on
the projection step preserving important image contents and reducing image
distortion. Basically, our projection method is based on Pannini projection
model. At first, the salient contents such as linear structures and salient
regions in the image are preserved by optimizing the single Panini projection
model. Then, the multiple Panini projection models at salient regions are
interpolated to suppress image distortion globally. Finally, the temporal
consistency for image projection is enforced for producing temporally stable
normal-view videos. Our proposed projection method does not require any
user-interaction and is much faster than previous content-preserving methods.
It can be applied to not only images but also videos taking the temporal
consistency of projection into account. Experiments on various 360{\deg} videos
show the superiority of the proposed projection method quantitatively and
qualitatively.
"
743,Generating Liquid Simulations with Deformation-aware Neural Networks,"  We propose a novel approach for deformation-aware neural networks that learn
the weighting and synthesis of dense volumetric deformation fields. Our method
specifically targets the space-time representation of physical surfaces from
liquid simulations. Liquids exhibit highly complex, non-linear behavior under
changing simulation conditions such as different initial conditions. Our
algorithm captures these complex phenomena in two stages: a first neural
network computes a weighting function for a set of pre-computed deformations,
while a second network directly generates a deformation field for refining the
surface. Key for successful training runs in this setting is a suitable loss
function that encodes the effect of the deformations, and a robust calculation
of the corresponding gradients. To demonstrate the effectiveness of our
approach, we showcase our method with several complex examples of flowing
liquids with topology changes. Our representation makes it possible to rapidly
generate the desired implicit surfaces. We have implemented a mobile
application to demonstrate that real-time interactions with complex liquid
effects are possible with our approach.
"
744,"Epsilon-shapes: characterizing, detecting and thickening thin features
  in geometric models","  We focus on the analysis of planar shapes and solid objects having thin
features and propose a new mathematical model to characterize them. Based on
our model, that we call an epsilon-shape, we show how thin parts can be
effectively and efficiently detected by an algorithm, and propose a novel
approach to thicken these features while leaving all the other parts of the
shape unchanged. When compared with state-of-the-art solutions, our proposal
proves to be particularly flexible, efficient and stable, and does not require
any unintuitive parameter to fine-tune the process. Furthermore, our method is
able to detect thin features both in the object and in its complement, thus
providing a useful tool to detect thin cavities and narrow channels. We discuss
the importance of this kind of analysis in the design of robust structures and
in the creation of geometry to be fabricated with modern additive manufacturing
technology.
"
745,Accelerating Discrete Wavelet Transforms on Parallel Architectures,"  The 2-D discrete wavelet transform (DWT) can be found in the heart of many
image-processing algorithms. Until recently, several studies have compared the
performance of such transform on various shared-memory parallel architectures,
especially on graphics processing units (GPUs). All these studies, however,
considered only separable calculation schemes. We show that corresponding
separable parts can be merged into non-separable units, which halves the number
of steps. In addition, we introduce an optional optimization approach leading
to a reduction in the number of arithmetic operations. The discussed schemes
were adapted on the OpenCL framework and pixel shaders, and then evaluated
using GPUs of two biggest vendors. We demonstrate the performance of the
proposed non-separable methods by comparison with existing separable schemes.
The non-separable schemes outperform their separable counterparts on numerous
setups, especially considering the pixel shaders.
"
746,"Topologically Robust 3D Shape Matching via Gradual Deflation and
  Inflation","  Despite being vastly ignored in the literature, coping with topological noise
is an issue of increasing importance, especially as a consequence of the
increasing number and diversity of 3D polygonal models that are captured by
devices of different qualities or synthesized by algorithms of different
stabilities. One approach for matching 3D shapes under topological noise is to
replace the topology-sensitive geodesic distance with distances that are less
sensitive to topological changes. We propose an alternative approach utilising
gradual deflation (or inflation) of the shape volume, of which purpose is to
bring the pair of shapes to be matched to a \emph{comparable} topology before
the search for correspondences. Illustrative experiments using different
datasets demonstrate that as the level of topological noise increases, our
approach outperforms the other methods in the literature.
"
747,"Scalable Surface Reconstruction from Point Clouds with Extreme Scale and
  Density Diversity","  In this paper we present a scalable approach for robustly computing a 3D
surface mesh from multi-scale multi-view stereo point clouds that can handle
extreme jumps of point density (in our experiments three orders of magnitude).
The backbone of our approach is a combination of octree data partitioning,
local Delaunay tetrahedralization and graph cut optimization. Graph cut
optimization is used twice, once to extract surface hypotheses from local
Delaunay tetrahedralizations and once to merge overlapping surface hypotheses
even when the local tetrahedralizations do not share the same topology.This
formulation allows us to obtain a constant memory consumption per sub-problem
while at the same time retaining the density independent interpolation
properties of the Delaunay-based optimization. On multiple public datasets, we
demonstrate that our approach is highly competitive with the state-of-the-art
in terms of accuracy, completeness and outlier resilience. Further, we
demonstrate the multi-scale potential of our approach by processing a newly
recorded dataset with 2 billion points and a point density variation of more
than four orders of magnitude - requiring less than 9GB of RAM per process.
"
748,Shading Annotations in the Wild,"  Understanding shading effects in images is critical for a variety of vision
and graphics problems, including intrinsic image decomposition, shadow removal,
image relighting, and inverse rendering. As is the case with other vision
tasks, machine learning is a promising approach to understanding shading - but
there is little ground truth shading data available for real-world images. We
introduce Shading Annotations in the Wild (SAW), a new large-scale, public
dataset of shading annotations in indoor scenes, comprised of multiple forms of
shading judgments obtained via crowdsourcing, along with shading annotations
automatically generated from RGB-D imagery. We use this data to train a
convolutional neural network to predict per-pixel shading information in an
image. We demonstrate the value of our data and network in an application to
intrinsic images, where we can reduce decomposition artifacts produced by
existing algorithms. Our database is available at
http://opensurfaces.cs.cornell.edu/saw/.
"
749,The Iray Light Transport Simulation and Rendering System,"  While ray tracing has become increasingly common and path tracing is well
understood by now, a major challenge lies in crafting an easy-to-use and
efficient system implementing these technologies. Following a purely
physically-based paradigm while still allowing for artistic workflows, the Iray
light transport simulation and rendering system allows for rendering complex
scenes by the push of a button and thus makes accurate light transport
simulation widely available. In this document we discuss the challenges and
implementation choices that follow from our primary design decisions,
demonstrating that such a rendering system can be made a practical, scalable,
and efficient real-world application that has been adopted by various companies
across many fields and is in use by many industry professionals today.
"
750,Data-Driven Synthesis of Smoke Flows with CNN-based Feature Descriptors,"  We present a novel data-driven algorithm to synthesize high-resolution flow
simulations with reusable repositories of space-time flow data. In our work, we
employ a descriptor learning approach to encode the similarity between fluid
regions with differences in resolution and numerical viscosity. We use
convolutional neural networks to generate the descriptors from fluid data such
as smoke density and flow velocity. At the same time, we present a deformation
limiting patch advection method which allows us to robustly track deformable
fluid regions. With the help of this patch advection, we generate stable
space-time data sets from detailed fluids for our repositories. We can then use
our learned descriptors to quickly localize a suitable data set when running a
new simulation. This makes our approach very efficient, and resolution
independent. We will demonstrate with several examples that our method yields
volumes with very high effective resolutions, and non-dissipative small scale
details that naturally integrate into the motions of the underlying flow.
"
751,VNect: Real-time 3D Human Pose Estimation with a Single RGB Camera,"  We present the first real-time method to capture the full global 3D skeletal
pose of a human in a stable, temporally consistent manner using a single RGB
camera. Our method combines a new convolutional neural network (CNN) based pose
regressor with kinematic skeleton fitting. Our novel fully-convolutional pose
formulation regresses 2D and 3D joint positions jointly in real time and does
not require tightly cropped input frames. A real-time kinematic skeleton
fitting method uses the CNN output to yield temporally stable 3D global pose
reconstructions on the basis of a coherent kinematic skeleton. This makes our
approach the first monocular RGB method usable in real-time applications such
as 3D character control---thus far, the only monocular methods for such
applications employed specialized RGB-D cameras. Our method's accuracy is
quantitatively on par with the best offline 3D monocular RGB pose estimation
methods. Our results are qualitatively comparable to, and sometimes better
than, results from monocular RGB-D approaches, such as the Kinect. However, we
show that our approach is more broadly applicable than RGB-D solutions, i.e. it
works for outdoor scenes, community videos, and low quality commodity RGB
cameras.
"
752,"Learning Hierarchical Shape Segmentation and Labeling from Online
  Repositories","  We propose a method for converting geometric shapes into hierarchically
segmented parts with part labels. Our key idea is to train category-specific
models from the scene graphs and part names that accompany 3D shapes in public
repositories. These freely-available annotations represent an enormous,
untapped source of information on geometry. However, because the models and
corresponding scene graphs are created by a wide range of modelers with
different levels of expertise, modeling tools, and objectives, these models
have very inconsistent segmentations and hierarchies with sparse and noisy
textual tags. Our method involves two analysis steps. First, we perform a joint
optimization to simultaneously cluster and label parts in the database while
also inferring a canonical tag dictionary and part hierarchy. We then use this
labeled data to train a method for hierarchical segmentation and labeling of
new 3D shapes. We demonstrate that our method can mine complex information,
detecting hierarchies in man-made objects and their constituent parts,
obtaining finer scale details than existing alternatives. We also show that, by
performing domain transfer using a few supervised examples, our technique
outperforms fully-supervised techniques that require hundreds of
manually-labeled models.
"
753,Semi-Global Weighted Least Squares in Image Filtering,"  Solving the global method of Weighted Least Squares (WLS) model in image
filtering is both time- and memory-consuming. In this paper, we present an
alternative approximation in a time- and memory- efficient manner which is
denoted as Semi-Global Weighed Least Squares (SG-WLS). Instead of solving a
large linear system, we propose to iteratively solve a sequence of subsystems
which are one-dimensional WLS models. Although each subsystem is
one-dimensional, it can take two-dimensional neighborhood information into
account due to the proposed special neighborhood construction. We show such a
desirable property makes our SG-WLS achieve close performance to the original
two-dimensional WLS model but with much less time and memory cost. While
previous related methods mainly focus on the 4-connected/8-connected
neighborhood system, our SG-WLS can handle a more general and larger
neighborhood system thanks to the proposed fast solution. We show such a
generalization can achieve better performance than the 4-connected/8-connected
neighborhood system in some applications. Our SG-WLS is $\sim20$ times faster
than the WLS model. For an image of $M\times N$, the memory cost of SG-WLS is
at most at the magnitude of $max\{\frac{1}{M}, \frac{1}{N}\}$ of that of the
WLS model. We show the effectiveness and efficiency of our SG-WLS in a range of
applications. The code is publicly available at:
https://github.com/wliusjtu/Semi-Global-Weighted-Least-Squares-in-Image-Filtering.
"
754,"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360{\deg}
  Sports Video","  Watching a 360{\deg} sports video requires a viewer to continuously select a
viewing angle, either through a sequence of mouse clicks or head movements. To
relieve the viewer from this ""360 piloting"" task, we propose ""deep 360 pilot""
-- a deep learning-based agent for piloting through 360{\deg} sports videos
automatically. At each frame, the agent observes a panoramic image and has the
knowledge of previously selected viewing angles. The task of the agent is to
shift the current viewing angle (i.e. action) to the next preferred one (i.e.,
goal). We propose to directly learn an online policy of the agent from data. We
use the policy gradient technique to jointly train our pipeline: by minimizing
(1) a regression loss measuring the distance between the selected and ground
truth viewing angles, (2) a smoothness loss encouraging smooth transition in
viewing angle, and (3) maximizing an expected reward of focusing on a
foreground object. To evaluate our method, we build a new 360-Sports video
dataset consisting of five sports domains. We train domain-specific agents and
achieve the best performance on viewing angle selection accuracy and transition
smoothness compared to [51] and other baselines.
"
755,GRASS: Generative Recursive Autoencoders for Shape Structures,"  We introduce a novel neural network architecture for encoding and synthesis
of 3D shapes, particularly their structures. Our key insight is that 3D shapes
are effectively characterized by their hierarchical organization of parts,
which reflects fundamental intra-shape relationships such as adjacency and
symmetry. We develop a recursive neural net (RvNN) based autoencoder to map a
flat, unlabeled, arbitrary part layout to a compact code. The code effectively
captures hierarchical structures of man-made 3D objects of varying structural
complexities despite being fixed-dimensional: an associated decoder maps a code
back to a full hierarchy. The learned bidirectional mapping is further tuned
using an adversarial setup to yield a generative model of plausible structures,
from which novel structures can be sampled. Finally, our structure synthesis
framework is augmented by a second trained module that produces fine-grained
part geometry, conditioned on global and local structural context, leading to a
full generative pipeline for 3D shapes. We demonstrate that without
supervision, our network learns meaningful structural hierarchies adhering to
perceptual grouping principles, produces compact codes which enable
applications such as shape classification and partial matching, and supports
shape synthesis and interpolation with significant variations in topology and
geometry.
"
756,On Discrete Conformal Seamless Similarity Maps,"  An algorithm for the computation of global discrete conformal
parametrizations with prescribed global holonomy signatures for triangle meshes
was recently described in [Campen and Zorin 2017]. In this paper we provide a
detailed analysis of convergence and correctness of this algorithm. We
generalize and extend ideas of [Springborn et al. 2008] to show a connection of
the algorithm to Newton's algorithm applied to solving the system of
constraints on angles in the parametric domain, and demonstrate that this
system can be obtained as a gradient of a convex energy.
"
757,Light Field Video Capture Using a Learning-Based Hybrid Imaging System,"  Light field cameras have many advantages over traditional cameras, as they
allow the user to change various camera settings after capture. However,
capturing light fields requires a huge bandwidth to record the data: a modern
light field camera can only take three images per second. This prevents current
consumer light field cameras from capturing light field videos. Temporal
interpolation at such extreme scale (10x, from 3 fps to 30 fps) is infeasible
as too much information will be entirely missing between adjacent frames.
Instead, we develop a hybrid imaging system, adding another standard video
camera to capture the temporal information. Given a 3 fps light field sequence
and a standard 30 fps 2D video, our system can then generate a full light field
video at 30 fps. We adopt a learning-based approach, which can be decomposed
into two steps: spatio-temporal flow estimation and appearance estimation. The
flow estimation propagates the angular information from the light field
sequence to the 2D video, so we can warp input images to the target view. The
appearance estimation then combines these warped images to output the final
pixels. The whole process is trained end-to-end using convolutional neural
networks. Experimental results demonstrate that our algorithm outperforms
current video interpolation methods, enabling consumer light field videography,
and making applications such as refocusing and parallax view generation
achievable on videos for the first time.
"
758,Real-Time User-Guided Image Colorization with Learned Deep Priors,"  We propose a deep learning approach for user-guided image colorization. The
system directly maps a grayscale image, along with sparse, local user ""hints""
to an output colorization with a Convolutional Neural Network (CNN). Rather
than using hand-defined rules, the network propagates user edits by fusing
low-level cues along with high-level semantic information, learned from
large-scale data. We train on a million images, with simulated user inputs. To
guide the user towards efficient input selection, the system recommends likely
colors based on the input image and current user inputs. The colorization is
performed in a single feed-forward pass, enabling real-time use. Even with
randomly simulated user inputs, we show that the proposed system helps novice
users quickly create realistic colorizations, and offers large improvements in
colorization quality with just a minute of use. In addition, we demonstrate
that the framework can incorporate other user ""hints"" to the desired
colorization, showing an application to color histogram transfer. Our code and
models are available at https://richzhang.github.io/ideepcolor.
"
759,Signal reconstruction via operator guiding,"  Signal reconstruction from a sample using an orthogonal projector onto a
guiding subspace is theoretically well justified, but may be difficult to
practically implement. We propose more general guiding operators, which
increase signal components in the guiding subspace relative to those in a
complementary subspace, e.g., iterative low-pass edge-preserving filters for
super-resolution of images. Two examples of super-resolution illustrate our
technology: a no-flash RGB photo guided using a high resolution flash RGB
photo, and a depth image guided using a high resolution RGB photo.
"
760,New Transforms for JPEG Format,"  The two-dimensional discrete cosine transform (DCT) can be found in the heart
of many image compression algorithms. Specifically, the JPEG format uses a
lossy form of compression based on that transform. Since the standardization of
the JPEG, many other transforms become practical in lossy data compression.
This article aims to analyze the use of these transforms as the DCT replacement
in the JPEG compression chain. Each transform is examined for different image
datasets and subsequently compared to other transforms using the peak
signal-to-noise ratio (PSNR). Our experiments show that an overlapping
variation of the DCT, the local cosine transform (LCT), overcame the original
block-wise transform at low bitrates. At high bitrates, the discrete wavelet
transform employing the Cohen-Daubechies-Feauveau 9/7 wavelet offers about the
same compression performance as the DCT.
"
761,From 3D Models to 3D Prints: an Overview of the Processing Pipeline,"  Due to the wide diffusion of 3D printing technologies, geometric algorithms
for Additive Manufacturing are being invented at an impressive speed. Each
single step, in particular along the Process Planning pipeline, can now count
on dozens of methods that prepare the 3D model for fabrication, while analysing
and optimizing geometry and machine instructions for various objectives. This
report provides a classification of this huge state of the art, and elicits the
relation between each single algorithm and a list of desirable objectives
during Process Planning. The objectives themselves are listed and discussed,
along with possible needs for tradeoffs. Additive Manufacturing technologies
are broadly categorized to explicitly relate classes of devices and supported
features. Finally, this report offers an analysis of the state of the art while
discussing open and challenging problems from both an academic and an
industrial perspective.
"
762,"GeneGAN: Learning Object Transfiguration and Attribute Subspace from
  Unpaired Data","  Object Transfiguration replaces an object in an image with another object
from a second image. For example it can perform tasks like ""putting exactly
those eyeglasses from image A on the nose of the person in image B"". Usage of
exemplar images allows more precise specification of desired modifications and
improves the diversity of conditional image generation. However, previous
methods that rely on feature space operations, require paired data and/or
appearance models for training or disentangling objects from background. In
this work, we propose a model that can learn object transfiguration from two
unpaired sets of images: one set containing images that ""have"" that kind of
object, and the other set being the opposite, with the mild constraint that the
objects be located approximately at the same place. For example, the training
data can be one set of reference face images that have eyeglasses, and another
set of images that have not, both of which spatially aligned by face landmarks.
Despite the weak 0/1 labels, our model can learn an ""eyeglasses"" subspace that
contain multiple representatives of different types of glasses. Consequently,
we can perform fine-grained control of generated images, like swapping the
glasses in two images by swapping the projected components in the ""eyeglasses""
subspace, to create novel images of people wearing eyeglasses.
  Overall, our deterministic generative model learns disentangled attribute
subspaces from weakly labeled data by adversarial training. Experiments on
CelebA and Multi-PIE datasets validate the effectiveness of the proposed model
on real world data, in generating images with specified eyeglasses, smiling,
hair styles, and lighting conditions etc. The code is available online.
"
763,A Correspondence Relaxation Approach for 3D Shape Reconstruction,"  This paper presents a new method for 3D shape reconstruction based on two
existing methods. A 3D reconstruction from a single photograph is introduced by
both papers: the first one uses a photograph and a set of existing 3D model to
generate the 3D object in the photograph, while the second one uses a
photograph and a selected similar model to create the 3D object in the
photograph. According to their difference, we propose a relaxation based method
for more accurate correspondence establishment and shape recovery. The
experiment demonstrates promising results compared to the state-of-the-art work
on 3D shape estimation.
"
764,Visualization of Feature Separation in Advected Scalar Fields,"  Scalar features in time-dependent fluid flow are traditionally visualized
using 3D representation, and their topology changes over time are often
conveyed with abstract graphs. Using such techniques, however, the structural
details of feature separation and the temporal evolution of features undergoing
topological changes are difficult to analyze. In this paper, we propose a novel
approach for the spatio-temporal visualization of feature separation that
segments feature volumes into regions with respect to their contribution to
distinct features after separation. To this end, we employ particle-based
feature tracking to find volumetric correspondences between features at two
different instants of time. We visualize this segmentation by constructing mesh
boundaries around each volume segment of a feature at the initial time that
correspond to the separated features at the later time. To convey temporal
evolution of the partitioning within the investigated time interval, we
complement our approach with spatio-temporal separation surfaces. For the
application of our approach to multiphase flow, we additionally present a
feature-based corrector method to ensure phase-consistent particle
trajectories. The utility of our technique is demonstrated by application to
two-phase (liquid-gas) and multi-component (liquid-liquid) flows where the
scalar field represents the fraction of one of the phases.
"
765,Automated Body Structure Extraction from Arbitrary 3D Mesh,"  This paper presents an automated method for 3D character skeleton extraction
that can be applied for generic 3D shapes. Our work is motivated by the
skeleton-based prior work on automatic rigging focused on skeleton extraction
and can automatically aligns the extracted structure to fit the 3D shape of the
given 3D mesh. The body mesh can be subsequently skinned based on the extracted
skeleton and thus enables rigging process. In the experiment, we apply public
dataset to drive the estimated skeleton from different body shapes, as well as
the real data obtained from 3D scanning systems. Satisfactory results are
obtained compared to the existing approaches.
"
766,"Computed Axial Lithography (CAL): Toward Single Step 3D Printing of
  Arbitrary Geometries","  Most additive manufacturing processes today operate by printing voxels (3D
pixels) serially point-by-point to build up a 3D part. In some more
recently-developed techniques, for example optical printing methods such as
projection stereolithography [Zheng et al. 2012], [Tumbleston et al. 2015],
parts are printed layer-by-layer by curing full 2d (very thin in one dimension)
layers of the 3d part in each print step. There does not yet exist a technique
which is able to print arbitrarily-defined 3D geometries in a single print
step. If such a technique existed, it could be used to expand the range of
printable geometries in additive manufacturing and relax constraints on factors
such as overhangs in topology optimization. It could also vastly increase print
speed for 3D parts. In this work, we develop the principles for an approach for
single exposure 3D printing of arbitrarily defined geometries. The approach,
termed Computed Axial Lithgography (CAL), is based on tomographic
reconstruction, with mathematical optimization to generate a set of projections
to optically define an arbitrary dose distribution within a target volume. We
demonstrate the potential ability of the technique to print 3D parts using a
prototype CAL system based on sequential illumination from many angles. We also
propose new hardware designs which will help us to realize true single-shot
arbitrary-geometry 3D CAL.
"
767,"Scratch iridescence: Wave-optical rendering of diffractive surface
  structure","  The surface of metal, glass and plastic objects is often characterized by
microscopic scratches caused by manufacturing and/or wear. A closer look onto
such scratches reveals iridescent colors with a complex dependency on viewing
and lighting conditions. The physics behind this phenomenon is well understood;
it is caused by diffraction of the incident light by surface features on the
order of the optical wavelength. Existing analytic models are able to reproduce
spatially unresolved microstructure such as the iridescent appearance of
compact disks and similar materials. Spatially resolved scratches, on the other
hand, have proven elusive due to the highly complex wave-optical light
transport simulations needed to account for their appearance. In this paper, we
propose a wave-optical shading model based on non-paraxial scalar diffraction
theory to render this class of effects. Our model expresses surface roughness
as a collection of line segments. To shade a point on the surface, the
individual diffraction patterns for contributing scratch segments are computed
analytically and superimposed coherently. This provides natural transitions
from localized glint-like iridescence to smooth BRDFs representing the
superposition of many reflections at large viewing distances. We demonstrate
that our model is capable of recreating the overall appearance as well as
characteristic detail effects observed on real-world examples.
"
768,"DS++: A flexible, scalable and provably tight relaxation for matching
  problems","  Correspondence problems are often modelled as quadratic optimization problems
over permutations. Common scalable methods for approximating solutions of these
NP-hard problems are the spectral relaxation for non-convex energies and the
doubly stochastic (DS) relaxation for convex energies. Lately, it has been
demonstrated that semidefinite programming relaxations can have considerably
improved accuracy at the price of a much higher computational cost. We present
a convex quadratic programming relaxation which is provably stronger than both
DS and spectral relaxations, with the same scalability as the DS relaxation.
The derivation of the relaxation also naturally suggests a projection method
for achieving meaningful integer solutions which improves upon the standard
closest-permutation projection. Our method can be easily extended to
optimization over doubly stochastic matrices, partial or injective matching,
and problems with additional linear constraints. We employ recent advances in
optimization of linear-assignment type problems to achieve an efficient
algorithm for solving the convex relaxation.
  We present experiments indicating that our method is more accurate than local
minimization or competing relaxations for non-convex problems. We successfully
apply our algorithm to shape matching and to the problem of ordering images in
a grid, obtaining results which compare favorably with state of the art
methods. We believe our results indicate that our method should be considered
the method of choice for quadratic optimization over permutations.
"
769,Shape Classification using Spectral Graph Wavelets,"  Spectral shape descriptors have been used extensively in a broad spectrum of
geometry processing applications ranging from shape retrieval and segmentation
to classification. In this pa- per, we propose a spectral graph wavelet
approach for 3D shape classification using the bag-of-features paradigm. In an
effort to capture both the local and global geometry of a 3D shape, we present
a three-step feature description framework. First, local descriptors are
extracted via the spectral graph wavelet transform having the Mexican hat
wavelet as a generating ker- nel. Second, mid-level features are obtained by
embedding lo- cal descriptors into the visual vocabulary space using the soft-
assignment coding step of the bag-of-features model. Third, a global descriptor
is constructed by aggregating mid-level fea- tures weighted by a geodesic
exponential kernel, resulting in a matrix representation that describes the
frequency of appearance of nearby codewords in the vocabulary. Experimental
results on two standard 3D shape benchmarks demonstrate the effective- ness of
the proposed classification approach in comparison with state-of-the-art
methods.
"
770,Snapshot Difference Imaging using Time-of-Flight Sensors,"  Computational photography encompasses a diversity of imaging techniques, but
one of the core operations performed by many of them is to compute image
differences. An intuitive approach to computing such differences is to capture
several images sequentially and then process them jointly. Usually, this
approach leads to artifacts when recording dynamic scenes. In this paper, we
introduce a snapshot difference imaging approach that is directly implemented
in the sensor hardware of emerging time-of-flight cameras. With a variety of
examples, we demonstrate that the proposed snapshot difference imaging
technique is useful for direct-global illumination separation, for direct
imaging of spatial and temporal image gradients, for direct depth edge imaging,
and more.
"
771,"Evaluation of Direct Haptic 4D Volume Rendering of Partially Segmented
  Data for Liver Puncture Simulation","  This work presents an evaluation study using a force feedback evaluation
framework for a novel direct needle force volume rendering concept in the
context of liver puncture simulation. PTC/PTCD puncture interventions targeting
the bile ducts have been selected to illustrate this concept. The haptic
algorithms of the simulator system are based on (1) partially segmented patient
image data and (2) a non-linear spring model effective at organ borders. The
primary aim is to quantitatively evaluate force errors caused by our patient
modeling approach, in comparison to haptic force output obtained from using
gold-standard, completely manually-segmented data. The evaluation of the force
algorithms compared to a force output from fully manually segmented
gold-standard patient models, yields a low mean of 0.12 N root mean squared
force error and up to 1.6 N for systematic maximum absolute errors. Force
errors were evaluated on 31,222 preplanned test paths from 10 patients. Only
twelve percent of the emitted forces along these paths were affected by errors.
This is the first study evaluating haptic algorithms with deformable virtual
patients in silico. We prove haptic rendering plausibility on a very high
number of test paths. Important errors are below just noticeable differences
for the hand-arm system.
"
772,Dynamics Based 3D Skeletal Hand Tracking,"  Tracking the full skeletal pose of the hands and fingers is a challenging
problem that has a plethora of applications for user interaction. Existing
techniques either require wearable hardware, add restrictions to user pose, or
require significant computation resources. This research explores a new
approach to tracking hands, or any articulated model, by using an augmented
rigid body simulation. This allows us to phrase 3D object tracking as a linear
complementarity problem with a well-defined solution. Based on a depth sensor's
samples, the system generates constraints that limit motion orthogonal to the
rigid body model's surface. These constraints, along with prior motion,
collision/contact constraints, and joint mechanics, are resolved with a
projected Gauss-Seidel solver. Due to camera noise properties and attachment
errors, the numerous surface constraints are impulse capped to avoid
overpowering mechanical constraints. To improve tracking accuracy, multiple
simulations are spawned at each frame and fed a variety of heuristics,
constraints and poses. A 3D error metric selects the best-fit simulation,
helping the system handle challenging hand motions. Such an approach enables
real-time, robust, and accurate 3D skeletal tracking of a user's hand on a
variety of depth cameras, while only utilizing a single x86 CPU core for
processing.
"
773,Towards Metamerism via Foveated Style Transfer,"  The problem of $\textit{visual metamerism}$ is defined as finding a family of
perceptually indistinguishable, yet physically different images. In this paper,
we propose our NeuroFovea metamer model, a foveated generative model that is
based on a mixture of peripheral representations and style transfer
forward-pass algorithms. Our gradient-descent free model is parametrized by a
foveated VGG19 encoder-decoder which allows us to encode images in high
dimensional space and interpolate between the content and texture information
with adaptive instance normalization anywhere in the visual field. Our
contributions include: 1) A framework for computing metamers that resembles a
noisy communication system via a foveated feed-forward encoder-decoder network
-- We observe that metamerism arises as a byproduct of noisy perturbations that
partially lie in the perceptual null space; 2) A perceptual optimization scheme
as a solution to the hyperparametric nature of our metamer model that requires
tuning of the image-texture tradeoff coefficients everywhere in the visual
field which are a consequence of internal noise; 3) An ABX psychophysical
evaluation of our metamers where we also find that the rate of growth of the
receptive fields in our model match V1 for reference metamers and V2 between
synthesized samples. Our model also renders metamers at roughly a second,
presenting a $\times1000$ speed-up compared to the previous work, which allows
for tractable data-driven metamer experiments.
"
774,Surface Networks,"  We study data-driven representations for three-dimensional triangle meshes,
which are one of the prevalent objects used to represent 3D geometry. Recent
works have developed models that exploit the intrinsic geometry of manifolds
and graphs, namely the Graph Neural Networks (GNNs) and its spectral variants,
which learn from the local metric tensor via the Laplacian operator. Despite
offering excellent sample complexity and built-in invariances, intrinsic
geometry alone is invariant to isometric deformations, making it unsuitable for
many applications. To overcome this limitation, we propose several upgrades to
GNNs to leverage extrinsic differential geometry properties of
three-dimensional surfaces, increasing its modeling power.
  In particular, we propose to exploit the Dirac operator, whose spectrum
detects principal curvature directions --- this is in stark contrast with the
classical Laplace operator, which directly measures mean curvature. We coin the
resulting models \emph{Surface Networks (SN)}. We prove that these models
define shape representations that are stable to deformation and to
discretization, and we demonstrate the efficiency and versatility of SNs on two
challenging tasks: temporal prediction of mesh deformations under non-linear
dynamics and generative models using a variational autoencoder framework with
encoders/decoders given by SNs.
"
775,3D Mesh Segmentation via Multi-branch 1D Convolutional Neural Networks,"  There is an increasing interest in applying deep learning to 3D mesh
segmentation. We observe that 1) existing feature-based techniques are often
slow or sensitive to feature resizing, 2) there are minimal comparative studies
and 3) techniques often suffer from reproducibility issue. This study
contributes in two ways. First, we propose a novel convolutional neural network
(CNN) for mesh segmentation. It uses 1D data, filters and a multi-branch
architecture for separate training of multi-scale features. Together with a
novel way of computing conformal factor (CF), our technique clearly
out-performs existing work. Secondly, we publicly provide implementations of
several deep learning techniques, namely, neural networks (NNs), autoencoders
(AEs) and CNNs, whose architectures are at least two layers deep. The
significance of this study is that it proposes a robust form of CF, offers a
novel and accurate CNN technique, and a comprehensive study of several deep
learning techniques for baseline comparison.
"
776,Megapixel Size Image Creation using Generative Adversarial Networks,"  Since its appearance, Generative Adversarial Networks (GANs) have received a
lot of interest in the AI community. In image generation several projects
showed how GANs are able to generate photorealistic images but the results so
far did not look adequate for the quality standard of visual media production
industry. We present an optimized image generation process based on a Deep
Convolutional Generative Adversarial Networks (DCGANs), in order to create
photorealistic high-resolution images (up to 1024x1024 pixels). Furthermore,
the system was fed with a limited dataset of images, less than two thousand
images. All these results give more clue about future exploitation of GANs in
Computer Graphics and Visual Effects.
"
777,On the Design and Invariants of a Ruled Surface,"  This paper deals with a kind of design of a ruled surface. It combines
concepts from the fields of computer aided geometric design and kinematics. A
dual unit spherical B\'ezier-like curve on the dual unit sphere (DUS) is
obtained with respect the control points by a new method. So, with the aid of
Study [1] transference principle, a dual unit spherical B\'ezier-like curve
corresponds to a ruled surface. Furthermore, closed ruled surfaces are
determined via control points and integral invariants of these surfaces are
investigated. The results are illustrated by examples.
"
778,Where and Who? Automatic Semantic-Aware Person Composition,"  Image compositing is a method used to generate realistic yet fake imagery by
inserting contents from one image to another. Previous work in compositing has
focused on improving appearance compatibility of a user selected foreground
segment and a background image (i.e. color and illumination consistency). In
this work, we instead develop a fully automated compositing model that
additionally learns to select and transform compatible foreground segments from
a large collection given only an input image background. To simplify the task,
we restrict our problem by focusing on human instance composition, because
human segments exhibit strong correlations with their background and because of
the availability of large annotated data. We develop a novel branching
Convolutional Neural Network (CNN) that jointly predicts candidate person
locations given a background image. We then use pre-trained deep feature
representations to retrieve person instances from a large segment database.
Experimental results show that our model can generate composite images that
look visually convincing. We also develop a user interface to demonstrate the
potential application of our method.
"
779,"Approximate Program Smoothing Using Mean-Variance Statistics, with
  Application to Procedural Shader Bandlimiting","  This paper introduces a general method to approximate the convolution of an
arbitrary program with a Gaussian kernel. This process has the effect of
smoothing out a program. Our compiler framework models intermediate values in
the program as random variables, by using mean and variance statistics. Our
approach breaks the input program into parts and relates the statistics of the
different parts, under the smoothing process. We give several approximations
that can be used for the different parts of the program. These include the
approximation of Dorn et al., a novel adaptive Gaussian approximation, Monte
Carlo sampling, and compactly supported kernels. Our adaptive Gaussian
approximation is accurate up to the second order in the standard deviation of
the smoothing kernel, and mathematically smooth. We show how to construct a
compiler that applies chosen approximations to given parts of the input
program. Because each expression can have multiple approximation choices, we
use a genetic search to automatically select the best approximations. We apply
this framework to the problem of automatically bandlimiting procedural shader
programs. We evaluate our method on a variety of complex shaders, including
shaders with parallax mapping, animation, and spatially varying statistics. The
resulting smoothed shader programs outperform previous approaches both
numerically, and aesthetically, due to the smoothing properties of our
approximations.
"
780,QuickCSG: Fast Arbitrary Boolean Combinations of N Solids,"  QuickCSG computes the result for general N-polyhedron boolean expressions
without an intermediate tree of solids. We propose a vertex-centric view of the
problem, which simplifies the identification of final geometric contributions,
and facilitates its spatial decomposition. The problem is then cast in a single
KD-tree exploration, geared toward the result by early pruning of any region of
space not contributing to the final surface. We assume strong regularity
properties on the input meshes and that they are in general position. This
simplifying assumption, in combination with our vertex-centric approach,
improves the speed of the approach. Complemented with a task-stealing
parallelization, the algorithm achieves breakthrough performance, one to two
orders of magnitude speedups with respect to state-of-the-art CPU algorithms,
on boolean operations over two to dozens of polyhedra. The algorithm also
outperforms GPU implementations with approximate discretizations, while
producing an output without redundant facets. Despite the restrictive
assumptions on the input, we show the usefulness of QuickCSG for applications
with large CSG problems and strong temporal constraints, e.g. modeling for 3D
printers, reconstruction from visual hulls and collision detection.
"
781,"DeepSketch2Face: A Deep Learning Based Sketching System for 3D Face and
  Caricature Modeling","  Face modeling has been paid much attention in the field of visual computing.
There exist many scenarios, including cartoon characters, avatars for social
media, 3D face caricatures as well as face-related art and design, where
low-cost interactive face modeling is a popular approach especially among
amateur users. In this paper, we propose a deep learning based sketching system
for 3D face and caricature modeling. This system has a labor-efficient
sketching interface, that allows the user to draw freehand imprecise yet
expressive 2D lines representing the contours of facial features. A novel CNN
based deep regression network is designed for inferring 3D face models from 2D
sketches. Our network fuses both CNN and shape based features of the input
sketch, and has two independent branches of fully connected layers generating
independent subsets of coefficients for a bilinear face representation. Our
system also supports gesture based interactions for users to further manipulate
initial face models. Both user studies and numerical results indicate that our
sketching system can help users create face models quickly and effectively. A
significantly expanded face database with diverse identities, expressions and
levels of exaggeration is constructed to promote further research and
evaluation of face modeling techniques.
"
782,TextureGAN: Controlling Deep Image Synthesis with Texture Patches,"  In this paper, we investigate deep image synthesis guided by sketch, color,
and texture. Previous image synthesis methods can be controlled by sketch and
color strokes but we are the first to examine texture control. We allow a user
to place a texture patch on a sketch at arbitrary locations and scales to
control the desired output texture. Our generative network learns to synthesize
objects consistent with these texture suggestions. To achieve this, we develop
a local texture loss in addition to adversarial and content loss to train the
generative network. We conduct experiments using sketches generated from real
images and textures sampled from a separate texture database and results show
that our proposed algorithm is able to generate plausible images that are
faithful to user controls. Ablation studies show that our proposed pipeline can
generate more realistic images than adapting existing methods directly.
"
783,"A Physically Plausible Model for Rendering Highly Scattering Fluorescent
  Participating Media","  We present a novel extension of the path tracing algorithm that is capable of
treating highly scattering participating media in the presence of fluorescent
structures. The extension is based on the formulation of the full radiative
transfer equation when solved on a per-wavelength-basis, resulting in accurate
model and unbiased algorithm for rendering highly scattering fluorescent
participating media. The model accounts for the intrinsic properties of
fluorescent dyes including their absorption and emission spectra, molar
absorptivity and quantum yield and also their concentration. Our algorithm is
applied to render highly scattering isotropic fluorescent solutions under
different illumination conditions. The spectral performance of the model is
validated against emission spectra of different fluorescent dyes that are of
significance in spectroscopy.
"
784,A filter based approach for inbetweening,"  We present a filter based approach for inbetweening. We train a convolutional
neural network to generate intermediate frames. This network aim to generate
smooth animation of line drawings. Our method can process scanned images
directly. Our method does not need to compute correspondence of lines and
topological changes explicitly. We experiment our method with real animation
production data. The results show that our method can generate intermediate
frames partially.
"
785,Procedural Wang Tile Algorithm for Stochastic Wall Patterns,"  The game and movie industries always face the challenge of reproducing
materials. This problem is tackled by combining illumination models and various
textures (painted or procedural patterns). Gnerating stochastic wall patterns
is crucial in the creation of a wide range of backgrounds (castles, temples,
ruins...). A specific Wang tile set was introduced previously to tackle this
problem, in a non-procedural fashion. Long lines may appear as visual
artifacts. We use this tile set in a new procedural algorithm to generate
stochastic wall patterns. For this purpose, we introduce specific hash
functions implementing a constrained Wang tiling. This technique makes possible
the generation of boundless textures while giving control over the maximum line
length. The algorithm is simple and easy to implement, and the wall structure
we get from the tiles allows to achieve visuals that reproduce all the small
details of artist painted walls.
"
786,Interactive Shape Perturbation,"  We present a web application for the procedural generation of perturbations
of 3D models. We generate the perturbations by generating vertex shaders that
change the positions of vertices that make up the 3D model. The vertex shaders
are created with an interactive genetic algorithm, which displays to the user
the visual effect caused by each vertex shader, allows the user to select the
visual effect the user likes best, and produces a new generation of vertex
shaders using the user feedback as the fitness measure of the genetic
algorithm. We use genetic programming to represent each vertex shader as a
computer program. This paper presents details of requirements specification,
software architecture, high and low-level design, and prototype user interface.
We discuss the project's current status and development challenges.
"
787,"Learning Local Shape Descriptors from Part Correspondences With
  Multi-view Convolutional Networks","  We present a new local descriptor for 3D shapes, directly applicable to a
wide range of shape analysis problems such as point correspondences, semantic
segmentation, affordance prediction, and shape-to-scan matching. The descriptor
is produced by a convolutional network that is trained to embed geometrically
and semantically similar points close to one another in descriptor space. The
network processes surface neighborhoods around points on a shape that are
captured at multiple scales by a succession of progressively zoomed out views,
taken from carefully selected camera positions. We leverage two extremely large
sources of data to train our network. First, since our network processes
rendered views in the form of 2D images, we repurpose architectures pre-trained
on massive image datasets. Second, we automatically generate a synthetic dense
point correspondence dataset by non-rigid alignment of corresponding shape
parts in a large collection of segmented 3D models. As a result of these design
choices, our network effectively encodes multi-scale local context and
fine-grained surface detail. Our network can be trained to produce either
category-specific descriptors or more generic descriptors by learning from
multiple shape categories. Once trained, at test time, the network extracts
local descriptors for shapes without requiring any part segmentation as input.
Our method can produce effective local descriptors even for shapes whose
category is unknown or different from the ones used while training. We
demonstrate through several experiments that our learned local descriptors are
more discriminative compared to state of the art alternatives, and are
effective in a variety of shape analysis applications.
"
788,Interactive 3D Modeling with a Generative Adversarial Network,"  This paper proposes the idea of using a generative adversarial network (GAN)
to assist a novice user in designing real-world shapes with a simple interface.
The user edits a voxel grid with a painting interface (like Minecraft). Yet, at
any time, he/she can execute a SNAP command, which projects the current voxel
grid onto a latent shape manifold with a learned projection operator and then
generates a similar, but more realistic, shape using a learned generator
network. Then the user can edit the resulting shape and snap again until he/she
is satisfied with the result. The main advantage of this approach is that the
projection and generation operators assist novice users to create 3D models
characteristic of a background distribution of object shapes, but without
having to specify all the details. The core new research idea is to use a GAN
to support this application. 3D GANs have previously been used for shape
generation, interpolation, and completion, but never for interactive modeling.
The new challenge for this application is to learn a projection operator that
takes an arbitrary 3D voxel model and produces a latent vector on the shape
manifold from which a similar and realistic shape can be generated. We develop
algorithms for this and other steps of the SNAP processing pipeline and
integrate them into a simple modeling tool. Experiments with these algorithms
and tool suggest that GANs provide a promising approach to computer-assisted
interactive modeling.
"
789,Comicolorization: Semi-Automatic Manga Colorization,"  We developed ""Comicolorization"", a semi-automatic colorization system for
manga images. Given a monochrome manga and reference images as inputs, our
system generates a plausible color version of the manga. This is the first work
to address the colorization of an entire manga title (a set of manga pages).
Our method colorizes a whole page (not a single panel) semi-automatically, with
the same color for the same character across multiple panels. To colorize the
target character by the color from the reference image, we extract a color
feature from the reference and feed it to the colorization network to help the
colorization. Our approach employs adversarial loss to encourage the effect of
the color features. Optionally, our tool allows users to revise the
colorization result interactively. By feeding the color features to our deep
colorization network, we accomplish colorization of the entire manga using the
desired colors for each panel.
"
790,cGAN-based Manga Colorization Using a Single Training Image,"  The Japanese comic format known as Manga is popular all over the world. It is
traditionally produced in black and white, and colorization is time consuming
and costly. Automatic colorization methods generally rely on greyscale values,
which are not present in manga. Furthermore, due to copyright protection,
colorized manga available for training is scarce. We propose a manga
colorization method based on conditional Generative Adversarial Networks
(cGAN). Unlike previous cGAN approaches that use many hundreds or thousands of
training images, our method requires only a single colorized reference image
for training, avoiding the need of a large dataset. Colorizing manga using
cGANs can produce blurry results with artifacts, and the resolution is limited.
We therefore also propose a method of segmentation and color-correction to
mitigate these issues. The final results are sharp, clear, and in high
resolution, and stay true to the character's original color scheme.
"
791,Degenerations of NURBS curves while all of weights approaching infinity,"  NURBS curve is widely used in Computer Aided Design and Computer Aided
Geometric Design. When a single weight approaches infinity, the limit of a
NURBS curve tends to the corresponding control point. In this paper, a kind of
control structure of a NURBS curve, called regular control curve, is defined.
We prove that the limit of the NURBS curve is exactly its regular control curve
when all of weights approach infinity, where each weight is multiplied by a
certain one-parameter function tending to infinity, different for each control
point. Moreover, some representative examples are presented to show this
property and indicate its application for shape deformation.
"
792,Way to Go! Automatic Optimization of Wayfinding Design,"  Wayfinding signs play an important role in guiding users to navigate in a
virtual environment and in helping pedestrians to find their ways in a
real-world architectural site. Conventionally, the wayfinding design of a
virtual environment is created manually, so as the wayfinding design of a
real-world architectural site. The many possible navigation scenarios, as well
as the interplay between signs and human navigation, can make the manual design
process overwhelming and non-trivial. As a result, creating a wayfinding design
for a typical layout can take months to several years. In this paper, we
introduce the Way to Go! approach for automatically generating a wayfinding
design for a given layout. The designer simply has to specify some navigation
scenarios; our approach will automatically generate an optimized wayfinding
design with signs properly placed considering human agents' visibility and
possibility of making mistakes during a navigation. We demonstrate the
effectiveness of our approach in generating wayfinding designs for different
layouts such as a train station, a downtown and a canyon. We evaluate our
results by comparing different wayfinding designs and show that our optimized
wayfinding design can guide pedestrians to their destinations effectively and
efficiently. Our approach can also help the designer visualize the
accessibility of a destination from different locations, and correct any ""blind
zone"" with additional signs.
"
793,"A Pig, an Angel and a Cactus Walk Into a Blender: A Descriptive Approach
  to Visual Blending","  A descriptive approach for automatic generation of visual blends is
presented. The implemented system, the Blender, is composed of two components:
the Mapper and the Visual Blender. The approach uses structured visual
representations along with sets of visual relations which describe how the
elements (in which the visual representation can be decomposed) relate among
each other. Our system is a hybrid blender, as the blending process starts at
the Mapper (conceptual level) and ends at the Visual Blender (visual
representation level). The experimental results show that the Blender is able
to create analogies from input mental spaces and produce well-composed blends,
which follow the rules imposed by its base-analogy and its relations. The
resulting blends are visually interesting and some can be considered as
unexpected.
"
794,Analysis and Modeling of 3D Indoor Scenes,"  We live in a 3D world, performing activities and interacting with objects in
the indoor environments everyday. Indoor scenes are the most familiar and
essential environments in everyone's life. In the virtual world, 3D indoor
scenes are also ubiquitous in 3D games and interior design. With the fast
development of VR/AR devices and the emerging applications, the demand of
realistic 3D indoor scenes keeps growing rapidly. Currently, designing detailed
3D indoor scenes requires proficient 3D designing and modeling skills and is
often time-consuming. For novice users, creating realistic and complex 3D
indoor scenes is even more difficult and challenging.
  Many efforts have been made in different research communities, e.g. computer
graphics, vision and robotics, to capture, analyze and generate the 3D indoor
data. This report mainly focuses on the recent research progress in graphics on
geometry, structure and semantic analysis of 3D indoor data and different
modeling techniques for creating plausible and realistic indoor scenes. We
first review works on understanding and semantic modeling of scenes from
captured 3D data of the real world. Then, we focus on the virtual scenes
composed of 3D CAD models and study methods for 3D scene analysis and
processing. After that, we survey various modeling paradigms for creating 3D
indoor scenes and investigate human-centric scene analysis and modeling, which
bridge indoor scene studies of graphics, vision and robotics. At last, we
discuss open problems in indoor scene processing that might bring interests to
graphics and all related communities.
"
795,"From Big Data to Big Displays: High-Performance Visualization at Blue
  Brain","  Blue Brain has pushed high-performance visualization (HPV) to complement its
HPC strategy since its inception in 2007. In 2011, this strategy has been
accelerated to develop innovative visualization solutions through increased
funding and strategic partnerships with other research institutions.
  We present the key elements of this HPV ecosystem, which integrates C++
visualization applications with novel collaborative display systems. We
motivate how our strategy of transforming visualization engines into services
enables a variety of use cases, not only for the integration with high-fidelity
displays, but also to build service oriented architectures, to link into web
applications and to provide remote services to Python applications.
"
796,Examplar-Based Face Colorization Using Image Morphing,"  Colorization of gray-scale images relies on prior color information.
Examplar-based methods use a color image as source of such information. Then
the colors of the source image are transferred to the gray-scale image. In the
literature, this transfer is mainly guided by texture descriptors. Face images
usually contain few texture so that the common approaches frequently fail. In
this paper we propose a new method based on image morphing. This technique is
able to compute a correspondence map between images with similar shapes. It is
based on the geometric structure of the images rather than textures which is
more reliable for faces. Our numerical experiments show that our morphing based
approach clearly outperforms state-of-the-art methods.
"
797,"Direct interactive visualization of locally refined spline volumes for
  scalar and vector fields","  We present a novel approach enabling interactive visualization of volumetric
Locally Refined B-splines (LR-splines). To this end we propose a highly
efficient algorithm for direct visualization of scalar and vector fields given
by an LR-spline. In both cases, our main contribution to achieve interactive
frame rates is an acceleration structure for fast element look-up and a change
of basis for efficient evaluation. To further improve the efficiency, we
present a heuristic for adaptive sampling distance for the numerical
integration. A comparison with existing adaptive approaches is performed. The
algorithms are designed to fully utilize modern graphics processing unit (GPU)
capabilities. Important applications where LR-spline volumes emerge are given
for instance by approximation of large-scale simulation and sensor data, and
Isogeometric Analysis (IGA). We showcase interactive rendering achieved by our
approach on different representative use cases, stemming from simulations of
wind flow around a telescope, Magnetic Resonance (MR) imaging of a human brain,
and simulations of a fluidized bed used for mixing and coating particles in
industrial processes.
"
798,"Nonlinear dance motion analysis and motion editing using Hilbert-Huang
  transform","  Human motions (especially dance motions) are very noisy, and it is hard to
analyze and edit the motions. To resolve this problem, we propose a new method
to decompose and modify the motions using the Hilbert-Huang transform (HHT).
First, HHT decomposes a chromatic signal into ""monochromatic"" signals that are
the so-called Intrinsic Mode Functions (IMFs) using an Empirical Mode
Decomposition (EMD) [6]. After applying the Hilbert Transform to each IMF, the
instantaneous frequencies of the ""monochromatic"" signals can be obtained. The
HHT has the advantage to analyze non-stationary and nonlinear signals such as
human-joint-motions over FFT or Wavelet transform.
  In the present paper, we propose a new framework to analyze and extract some
new features from a famous Japanese threesome pop singer group called
""Perfume"", and compare it with Waltz and Salsa dance. Using the EMD, their
dance motions can be decomposed into motion (choreographic) primitives or IMFs.
Therefore we can scale, combine, subtract, exchange, and modify those IMFs, and
can blend them into new dance motions self-consistently. Our analysis and
framework can lead to a motion editing and blending method to create a new
dance motion from different dance motions.
"
799,Localized Manifold Harmonics for Spectral Shape Analysis,"  The use of Laplacian eigenfunctions is ubiquitous in a wide range of computer
graphics and geometry processing applications. In particular, Laplacian
eigenbases allow generalizing the classical Fourier analysis to manifolds. A
key drawback of such bases is their inherently global nature, as the Laplacian
eigenfunctions carry geometric and topological structure of the entire
manifold. In this paper, we introduce a new framework for local spectral shape
analysis. We show how to efficiently construct localized orthogonal bases by
solving an optimization problem that in turn can be posed as the
eigendecomposition of a new operator obtained by a modification of the standard
Laplacian. We study the theoretical and computational aspects of the proposed
framework and showcase our new construction on the classical problems of shape
approximation and correspondence. We obtain significant improvement compared to
classical Laplacian eigenbases as well as other alternatives for constructing
localized bases.
"
800,Deep Bilateral Learning for Real-Time Image Enhancement,"  Performance is a critical challenge in mobile image processing. Given a
reference imaging pipeline, or even human-adjusted pairs of images, we seek to
reproduce the enhancements and enable real-time evaluation. For this, we
introduce a new neural network architecture inspired by bilateral grid
processing and local affine color transforms. Using pairs of input/output
images, we train a convolutional neural network to predict the coefficients of
a locally-affine model in bilateral space. Our architecture learns to make
local, global, and content-dependent decisions to approximate the desired image
transformation. At runtime, the neural network consumes a low-resolution
version of the input image, produces a set of affine transformations in
bilateral space, upsamples those transformations in an edge-preserving fashion
using a new slicing node, and then applies those upsampled transformations to
the full-resolution image. Our algorithm processes high-resolution images on a
smartphone in milliseconds, provides a real-time viewfinder at 1080p
resolution, and matches the quality of state-of-the-art approximation
techniques on a large class of image operators. Unlike previous work, our model
is trained off-line from data and therefore does not require access to the
original operator at runtime. This allows our model to learn complex,
scene-dependent transformations for which no reference implementation is
available, such as the photographic edits of a human retoucher.
"
801,Natural Boundary Conditions for Smoothing in Geometry Processing,"  In geometry processing, smoothness energies are commonly used to model
scattered data interpolation, dense data denoising, and regularization during
shape optimization. The squared Laplacian energy is a popular choice of energy
and has a corresponding standard implementation: squaring the discrete
Laplacian matrix. For compact domains, when values along the boundary are not
known in advance, this construction bakes in low-order boundary conditions.
This causes the geometric shape of the boundary to strongly bias the solution.
For many applications, this is undesirable. Instead, we propose using the
squared Frobenious norm of the Hessian as a smoothness energy. Unlike the
squared Laplacian energy, this energy's natural boundary conditions (those that
best minimize the energy) correspond to meaningful high-order boundary
conditions. These boundary conditions model free boundaries where the shape of
the boundary should not bias the solution locally. Our analysis begins in the
smooth setting and concludes with discretizations using finite-differences on
2D grids or mixed finite elements for triangle meshes. We demonstrate the core
behavior of the squared Hessian as a smoothness energy for various tasks.
"
802,A Streamline Selection Technique Overlaying with Isosurfaces,"  Integration of scalar and vector visualization has been an interesting topic.
This paper presents a technique to appropriately select and display multiple
streamlines while overlaying with isosurfaces, aiming an integrated scalar and
vector field visualization. The technique visualizes a scalar field by multiple
semitransparent isosurfaces, and a vector field by multiple streamlines, while
the technique adequately selects the streamlines considering reduction of
cluttering among the isosurfaces and streamlines. The technique first selects
and renders isosurfaces, and then generates large number of streamlines from
randomly selected seed points. The technique evaluates each of the streamlines
according to their shapes on a 2D display space, distances to critical points
of the given vector fields, and occlusion by isosurfaces. It then selects the
specified number of highly evaluated streamlines. As a result, we can visualize
both scalar and vector fields as a set of view-independently selected
isosurfaces and view-dependently selected streamlines.
"
803,AirCode: Unobtrusive Physical Tags for Digital Fabrication,"  We present AirCode, a technique that allows the user to tag physically
fabricated objects with given information. An AirCode tag consists of a group
of carefully designed air pockets placed beneath the object surface. These air
pockets are easily produced during the fabrication process of the object,
without any additional material or postprocessing. Meanwhile, the air pockets
affect only the scattering light transport under the surface, and thus are hard
to notice to our naked eyes. But, by using a computational imaging method, the
tags become detectable. We present a tool that automates the design of air
pockets for the user to encode information. AirCode system also allows the user
to retrieve the information from captured images via a robust decoding
algorithm. We demonstrate our tagging technique with applications for metadata
embedding, robotic grasping, as well as conveying object affordances.
"
804,"GPU accelerated computation of Polarized Subsurface BRDF for Flat
  Particulate Layers","  BRDF of most real world materials has two components, the surface BRDF due to
the light reflecting at the surface of the material and the subsurface BRDF due
to the light entering and going through many scattering events inside the
material. Each of these events modifies light's path, power, polarization
state. Computing polarized subsurface BRDF of a material requires simulating
the light transport inside the material. The transport of polarized light is
modeled by the Vector Radiative Transfer Equation (VRTE), an
integro-differential equation. Computing solution to that equation is
expensive. The Discrete Ordinate Method (DOM) is a common approach to solving
the VRTE. Such solvers are very time consuming for complex uses such as BRDF
computation, where one must solve VRTE for surface radiance distribution due to
light incident from every direction of the hemisphere above the surface. In
this paper, we present a GPU based DOM solution of the VRTE to expedite the
subsurface BRDF computation. As in other DOM based solutions, our solution is
based on Fourier expansions of the phase function and the radiance function.
This allows us to independently solve the VRTE for each order of expansion. We
take advantage of those repetitions and of the repetitions in each of the
sub-steps of the solution process. Our solver is implemented to run mainly on
graphics hardware using the OpenCL library and runs up to seven times faster
than its CPU equivalent, allowing the computation of subsurface BRDF in a
matter of minutes. We compute and present the subsurface BRDF lobes due to
powders and paints of a few materials. We also show the rendering of objects
with the computed BRDF. The solver is available for public use through the
authors' web site.
"
805,Shape Generation using Spatially Partitioned Point Clouds,"  We propose a method to generate 3D shapes using point clouds. Given a
point-cloud representation of a 3D shape, our method builds a kd-tree to
spatially partition the points. This orders them consistently across all
shapes, resulting in reasonably good correspondences across all shapes. We then
use PCA analysis to derive a linear shape basis across the spatially
partitioned points, and optimize the point ordering by iteratively minimizing
the PCA reconstruction error. Even with the spatial sorting, the point clouds
are inherently noisy and the resulting distribution over the shape coefficients
can be highly multi-modal. We propose to use the expressive power of neural
networks to learn a distribution over the shape coefficients in a
generative-adversarial framework. Compared to 3D shape generative models
trained on voxel-representations, our point-based method is considerably more
light-weight and scalable, with little loss of quality. It also outperforms
simpler linear factor models such as Probabilistic PCA, both qualitatively and
quantitatively, on a number of categories from the ShapeNet dataset.
Furthermore, our method can easily incorporate other point attributes such as
normal and color information, an additional advantage over voxel-based
representations.
"
806,"3D Shape Reconstruction from Sketches via Multi-view Convolutional
  Networks","  We propose a method for reconstructing 3D shapes from 2D sketches in the form
of line drawings. Our method takes as input a single sketch, or multiple
sketches, and outputs a dense point cloud representing a 3D reconstruction of
the input sketch(es). The point cloud is then converted into a polygon mesh. At
the heart of our method lies a deep, encoder-decoder network. The encoder
converts the sketch into a compact representation encoding shape information.
The decoder converts this representation into depth and normal maps capturing
the underlying surface from several output viewpoints. The multi-view maps are
then consolidated into a 3D point cloud by solving an optimization problem that
fuses depth and normals across all viewpoints. Based on our experiments,
compared to other methods, such as volumetric networks, our architecture offers
several advantages, including more faithful reconstruction, higher output
surface resolution, better preservation of topology and shape structure.
"
807,"Visual Detection of Structural Changes in Time-Varying Graphs Using
  Persistent Homology","  Topological data analysis is an emerging area in exploratory data analysis
and data mining. Its main tool, persistent homology, has become a popular
technique to study the structure of complex, high-dimensional data. In this
paper, we propose a novel method using persistent homology to quantify
structural changes in time-varying graphs. Specifically, we transform each
instance of the time-varying graph into metric spaces, extract topological
features using persistent homology, and compare those features over time. We
provide a visualization that assists in time-varying graph exploration and
helps to identify patterns of behavior within the data. To validate our
approach, we conduct several case studies on real world data sets and show how
our method can find cyclic patterns, deviations from those patterns, and
one-time events in time-varying graphs. We also examine whether
persistence-based similarity measure as a graph metric satisfies a set of
well-established, desirable properties for graph metrics.
"
808,Steklov Spectral Geometry for Extrinsic Shape Analysis,"  We propose using the Dirichlet-to-Neumann operator as an extrinsic
alternative to the Laplacian for spectral geometry processing and shape
analysis. Intrinsic approaches, usually based on the Laplace-Beltrami operator,
cannot capture the spatial embedding of a shape up to rigid motion, and many
previous extrinsic methods lack theoretical justification. Instead, we consider
the Steklov eigenvalue problem, computing the spectrum of the
Dirichlet-to-Neumann operator of a surface bounding a volume. A remarkable
property of this operator is that it completely encodes volumetric geometry. We
use the boundary element method (BEM) to discretize the operator, accelerated
by hierarchical numerical schemes and preconditioning; this pipeline allows us
to solve eigenvalue and linear problems on large-scale meshes despite the
density of the Dirichlet-to-Neumann discretization. We further demonstrate that
our operators naturally fit into existing frameworks for geometry processing,
making a shift from intrinsic to extrinsic geometry as simple as substituting
the Laplace-Beltrami operator with the Dirichlet-to-Neumann operator.
"
809,Pigmento: Pigment-Based Image Analysis and Editing,"  The colorful appearance of a physical painting is determined by the
distribution of paint pigments across the canvas, which we model as a per-pixel
mixture of a small number of pigments with multispectral absorption and
scattering coefficients. We present an algorithm to efficiently recover this
structure from an RGB image, yielding a plausible set of pigments and a low RGB
reconstruction error. We show that under certain circumstances we are able to
recover pigments that are close to ground truth, while in all cases our results
are always plausible. Using our decomposition, we repose standard digital image
editing operations as operations in pigment space rather than RGB, with
interestingly novel results. We demonstrate tonal adjustments, selection
masking, cut-copy-paste, recoloring, palette summarization, and edge
enhancement.
"
810,Notes on optimal approximations for importance sampling,"  In this manuscript, we derive optimal conditions for building function
approximations that minimize variance when used as importance sampling
estimators for Monte Carlo integration problems. Particularly, we study the
problem of finding the optimal projection $g$ of an integrand $f$ onto certain
classes of piecewise constant functions, in order to minimize the variance of
the unbiased importance sampling estimator $E_g[f/g]$, as well as the related
problem of finding optimal mixture weights to approximate and importance sample
a target mixture distribution $f = \sum_i \alpha_i f_i$ with components $f_i$
in a family $\mathcal{F}$, through a corresponding mixture of importance
sampling densities $g_i$ that are only approximately proportional to $f_i$. We
further show that in both cases the optimal projection is different from the
commonly used $\ell_1$ projection, and provide an intuitive explanation for the
difference.
"
811,Discrete Geodesic Nets for Modeling Developable Surfaces,"  We present a discrete theory for modeling developable surfaces as
quadrilateral meshes satisfying simple angle constraints. The basis of our
model is a lesser known characterization of developable surfaces as manifolds
that can be parameterized through orthogonal geodesics. Our model is simple,
local, and, unlike previous works, it does not directly encode the surface
rulings. This allows us to model continuous deformations of discrete
developable surfaces independently of their decomposition into torsal and
planar patches or the surface topology. We prove and experimentally demonstrate
strong ties to smooth developable surfaces, including a theorem stating that
every sampling of the smooth counterpart satisfies our constraints up to second
order. We further present an extension of our model that enables a local
definition of discrete isometry. We demonstrate the effectiveness of our
discrete model in a developable surface editing system, as well as computation
of an isometric interpolation between isometric discrete developable shapes.
"
812,3D Sketching using Multi-View Deep Volumetric Prediction,"  Sketch-based modeling strives to bring the ease and immediacy of drawing to
the 3D world. However, while drawings are easy for humans to create, they are
very challenging for computers to interpret due to their sparsity and
ambiguity. We propose a data-driven approach that tackles this challenge by
learning to reconstruct 3D shapes from one or more drawings. At the core of our
approach is a deep convolutional neural network (CNN) that predicts occupancy
of a voxel grid from a line drawing. This CNN provides us with an initial 3D
reconstruction as soon as the user completes a single drawing of the desired
shape. We complement this single-view network with an updater CNN that refines
an existing prediction given a new drawing of the shape created from a novel
viewpoint. A key advantage of our approach is that we can apply the updater
iteratively to fuse information from an arbitrary number of viewpoints, without
requiring explicit stroke correspondences between the drawings. We train both
CNNs by rendering synthetic contour drawings from hand-modeled shape
collections as well as from procedurally-generated abstract shapes. Finally, we
integrate our CNNs in a minimal modeling interface that allows users to
seamlessly draw an object, rotate it to see its 3D reconstruction, and refine
it by re-drawing from another vantage point using the 3D reconstruction as
guidance. The main strengths of our approach are its robustness to freehand
bitmap drawings, its ability to adapt to different object categories, and the
continuum it offers between single-view and multi-view sketch-based modeling.
"
813,"Research on Shape Mapping of 3D Mesh Models based on Hidden Markov
  Random Field and EM Algorithm","  How to establish the matching (or corresponding) between two different 3D
shapes is a classical problem. This paper focused on the research on shape
mapping of 3D mesh models, and proposed a shape mapping algorithm based on
Hidden Markov Random Field and EM algorithm, as introducing a hidden state
random variable associated with the adjacent blocks of shape matching when
establishing HMRF. This algorithm provides a new theory and method to ensure
the consistency of the edge data of adjacent blocks, and the experimental
results show that the algorithm in this paper has a great improvement on the
shape mapping of 3D mesh models.
"
814,"Continuous Global Optimization in Surface Reconstruction from an
  Oriented Point Cloud","  We introduce a continuous global optimization method to the field of surface
reconstruction from discrete noisy cloud of points with weak information on
orientation. The proposed method uses an energy functional combining flux-based
data-fit measures and a regularization term. A continuous convex relaxation
scheme assures the global minima of the geometric surface functional. The
reconstructed surface is implicitly represented by the binary segmentation of
vertices of a 3D uniform grid and a triangulated surface can be obtained by
extracting an appropriate isosurface. Unlike the discrete graph-cut solution,
the continuous global optimization entails advantages like memory requirements,
reduction of metrication errors for geometric quantities, allowing globally
optimal surface reconstruction at higher grid resolutions. We demonstrate the
performance of the proposed method on several oriented point clouds captured by
laser scanners. Experimental results confirm that our approach is robust to
noise, large holes and non-uniform sampling density under the condition of very
coarse orientation information.
"
815,Photographic Image Synthesis with Cascaded Refinement Networks,"  We present an approach to synthesizing photographic images conditioned on
semantic layouts. Given a semantic label map, our approach produces an image
with photographic appearance that conforms to the input layout. The approach
thus functions as a rendering engine that takes a two-dimensional semantic
specification of the scene and produces a corresponding photographic image.
Unlike recent and contemporaneous work, our approach does not rely on
adversarial training. We show that photographic images can be synthesized from
semantic layouts by a single feedforward network with appropriate structure,
trained end-to-end with a direct regression objective. The presented approach
scales seamlessly to high resolutions; we demonstrate this by synthesizing
photographic images at 2-megapixel resolution, the full resolution of our
training data. Extensive perceptual experiments on datasets of outdoor and
indoor scenes demonstrate that images synthesized by the presented approach are
considerably more realistic than alternative approaches. The results are shown
in the supplementary video at https://youtu.be/0fhUJT21-bs
"
816,Generation of concept-representative symbols,"  The visual representation of concepts or ideas through the use of simple
shapes has always been explored in the history of Humanity, and it is believed
to be the origin of writing. We focus on computational generation of visual
symbols to represent concepts. We aim to develop a system that uses background
knowledge about the world to find connections among concepts, with the goal of
generating symbols for a given concept. We are also interested in exploring the
system as an approach to visual dissociation and visual conceptual blending.
This has a great potential in the area of Graphic Design as a tool to both
stimulate creativity and aid in brainstorming in projects such as logo,
pictogram or signage design.
"
817,"Kernel Projection of Latent Structures Regression for Facial Animation
  Retargeting","  Inspired by kernel methods that have been used extensively in achieving
efficient facial animation retargeting, this paper presents a solution to
retargeting facial animation in virtual character's face model based on the
kernel projection of latent structure (KPLS) regression between semantically
similar facial expressions. Specifically, a given number of corresponding
semantically similar facial expressions are projected into the latent space. By
using the Nonlinear Iterative Partial Least Square method, decomposition of the
latent variables is achieved. Finally, the KPLS is achieved by solving a
kernalized version of the eigenvalue problem. By evaluating our methodology
with other kernel-based solutions, the efficiency of the presented methodology
in transferring facial animation to face models with different morphological
variations is demonstrated.
"
818,"Numerical analysis of shell-based geometric image inpainting algorithms
  and their semi-implicit extension","  In this paper we study a class of fast geometric image inpainting methods
based on the idea of filling the inpainting domain in successive shells from
its boundary inwards. Image pixels are filled by assigning them a color equal
to a weighted average of their already filled neighbors. However, there is
flexibility in terms of the order in which pixels are filled, the weights used
for averaging, and the neighborhood that is averaged over. Varying these
degrees of freedom leads to different algorithms, and indeed the literature
contains several methods falling into this general class. All of them are very
fast, but at the same time all of them leave undesirable artifacts such as
""kinking"" (bending) or blurring of extrapolated isophotes. Our objective in
this paper is to build a theoretical model, based on a continuum limit and a
connection to stopped random walks, in order to understand why these artifacts
occur and what, if anything, can be done about them. At the same time, we
consider a semi-implicit extension in which pixels in a given shell are solved
for simultaneously by solving a linear system. We prove (within the continuum
limit) that this extension is able to completely eliminate kinking artifacts,
which we also prove must always be present in the direct method. Although our
analysis makes the strong assumption of a square inpainting domain, it makes
weak smoothness assumptions and is thus applicable to the low regularity
inherent in images.
"
819,Superposition de calques monochromes d'opacit\'es variables,"  For a monochrome layer $x$ of opacity $0\le o_x\le1 $ placed on another
monochrome layer of opacity 1, the result given by the standard formula is
$$\small\Pi\left({\bf
C}_\varphi\right)=1+\sum_{n=1}^2\left(2-n-(-1)^no_{\chi(\varphi+1)}\right)\left(\chi(n+\varphi-1)-o_{\chi(n+\varphi-1)}\right),$$
the formula being of course explained in detail in this paper. We will
eventually deduce a very simple theorem, generalize it and then see its
validity with alternative formulas to this standard containing the same main
properties here exposed.
"
820,"Learning to Hallucinate Face Images via Component Generation and
  Enhancement","  We propose a two-stage method for face hallucination. First, we generate
facial components of the input image using CNNs. These components represent the
basic facial structures. Second, we synthesize fine-grained facial structures
from high resolution training images. The details of these structures are
transferred into facial components for enhancement. Therefore, we generate
facial components to approximate ground truth global appearance in the first
stage and enhance them through recovering details in the second stage. The
experiments demonstrate that our method performs favorably against
state-of-the-art methods
"
821,Fast Preprocessing for Robust Face Sketch Synthesis,"  Exemplar-based face sketch synthesis methods usually meet the challenging
problem that input photos are captured in different lighting conditions from
training photos. The critical step causing the failure is the search of similar
patch candidates for an input photo patch. Conventional illumination invariant
patch distances are adopted rather than directly relying on pixel intensity
difference, but they will fail when local contrast within a patch changes. In
this paper, we propose a fast preprocessing method named Bidirectional
Luminance Remapping (BLR), which interactively adjust the lighting of training
and input photos. Our method can be directly integrated into state-of-the-art
exemplar-based methods to improve their robustness with ignorable computational
cost.
"
822,"Generation of High Dynamic Range Illumination from a Single Image for
  the Enhancement of Undesirably Illuminated Images","  This paper presents an algorithm that enhances undesirably illuminated images
by generating and fusing multi-level illuminations from a single image.The
input image is first decomposed into illumination and reflectance components by
using an edge-preserving smoothing filter. Then the reflectance component is
scaled up to improve the image details in bright areas. The illumination
component is scaled up and down to generate several illumination images that
correspond to certain camera exposure values different from the original. The
virtual multi-exposure illuminations are blended into an enhanced illumination,
where we also propose a method to generate appropriate weight maps for the tone
fusion. Finally, an enhanced image is obtained by multiplying the equalized
illumination and enhanced reflectance. Experiments show that the proposed
algorithm produces visually pleasing output and also yields comparable
objective results to the conventional enhancement methods, while requiring
modest computational loads.
"
823,ComplementMe: Weakly-Supervised Component Suggestions for 3D Modeling,"  Assembly-based tools provide a powerful modeling paradigm for non-expert
shape designers. However, choosing a component from a large shape repository
and aligning it to a partial assembly can become a daunting task. In this paper
we describe novel neural network architectures for suggesting complementary
components and their placement for an incomplete 3D part assembly. Unlike most
existing techniques, our networks are trained on unlabeled data obtained from
public online repositories, and do not rely on consistent part segmentations or
labels. Absence of labels poses a challenge in indexing the database of parts
for the retrieval. We address it by jointly training embedding and retrieval
networks, where the first indexes parts by mapping them to a low-dimensional
feature space, and the second maps partial assemblies to appropriate
complements. The combinatorial nature of part arrangements poses another
challenge, since the retrieval network is not a function: several complements
can be appropriate for the same input. Thus, instead of predicting a single
output, we train our network to predict a probability distribution over the
space of part embeddings. This allows our method to deal with ambiguities and
naturally enables a UI that seamlessly integrates user preferences into the
design process. We demonstrate that our method can be used to design complex
shapes with minimal or no user input. To evaluate our approach we develop a
novel benchmark for component suggestion systems demonstrating significant
improvement over state-of-the-art techniques.
"
824,"Wasserstein Dictionary Learning: Optimal Transport-based unsupervised
  non-linear dictionary learning","  This paper introduces a new nonlinear dictionary learning method for
histograms in the probability simplex. The method leverages optimal transport
theory, in the sense that our aim is to reconstruct histograms using so-called
displacement interpolations (a.k.a. Wasserstein barycenters) between dictionary
atoms; such atoms are themselves synthetic histograms in the probability
simplex. Our method simultaneously estimates such atoms, and, for each
datapoint, the vector of weights that can optimally reconstruct it as an
optimal transport barycenter of such atoms. Our method is computationally
tractable thanks to the addition of an entropic regularization to the usual
optimal transportation problem, leading to an approximation scheme that is
efficient, parallel and simple to differentiate. Both atoms and weights are
learned using a gradient-based descent method. Gradients are obtained by
automatic differentiation of the generalized Sinkhorn iterations that yield
barycenters with entropic smoothing. Because of its formulation relying on
Wasserstein barycenters instead of the usual matrix product between dictionary
and codes, our method allows for nonlinear relationships between atoms and the
reconstruction of input data. We illustrate its application in several
different image processing settings.
"
825,MonoPerfCap: Human Performance Capture from Monocular Video,"  We present the first marker-less approach for temporally coherent 3D
performance capture of a human with general clothing from monocular video. Our
approach reconstructs articulated human skeleton motion as well as medium-scale
non-rigid surface deformations in general scenes. Human performance capture is
a challenging problem due to the large range of articulation, potentially fast
motion, and considerable non-rigid deformations, even from multi-view data.
Reconstruction from monocular video alone is drastically more challenging,
since strong occlusions and the inherent depth ambiguity lead to a highly
ill-posed reconstruction problem. We tackle these challenges by a novel
approach that employs sparse 2D and 3D human pose detections from a
convolutional neural network using a batch-based pose estimation strategy.
Joint recovery of per-batch motion allows to resolve the ambiguities of the
monocular reconstruction problem based on a low dimensional trajectory
subspace. In addition, we propose refinement of the surface geometry based on
fully automatically extracted silhouettes to enable medium-scale non-rigid
alignment. We demonstrate state-of-the-art performance capture results that
enable exciting applications such as video editing and free viewpoint video,
previously infeasible from monocular video. Our qualitative and quantitative
evaluation demonstrates that our approach significantly outperforms previous
monocular methods in terms of accuracy, robustness and scene complexity that
can be handled.
"
826,"Weakly- and Self-Supervised Learning for Content-Aware Deep Image
  Retargeting","  This paper proposes a weakly- and self-supervised deep convolutional neural
network (WSSDCNN) for content-aware image retargeting. Our network takes a
source image and a target aspect ratio, and then directly outputs a retargeted
image. Retargeting is performed through a shift map, which is a pixel-wise
mapping from the source to the target grid. Our method implicitly learns an
attention map, which leads to a content-aware shift map for image retargeting.
As a result, discriminative parts in an image are preserved, while background
regions are adjusted seamlessly. In the training phase, pairs of an image and
its image-level annotation are used to compute content and structure losses. We
demonstrate the effectiveness of our proposed method for a retargeting
application with insightful analyses.
"
827,Interacting with Acoustic Simulation and Fabrication,"  Incorporating accurate physics-based simulation into interactive design tools
is challenging. However, adding the physics accurately becomes crucial to
several emerging technologies. For example, in virtual/augmented reality
(VR/AR) videos, the faithful reproduction of surrounding audios is required to
bring the immersion to the next level. Similarly, as personal fabrication is
made possible with accessible 3D printers, more intuitive tools that respect
the physical constraints can help artists to prototype designs. One main hurdle
is the sheer amount of computation complexity to accurately reproduce the
real-world phenomena through physics-based simulation. In my thesis research, I
develop interactive tools that implement efficient physics-based simulation
algorithms for automatic optimization and intuitive user interaction.
"
828,"Personalized Cinemagraphs using Semantic Understanding and Collaborative
  Learning","  Cinemagraphs are a compelling way to convey dynamic aspects of a scene. In
these media, dynamic and still elements are juxtaposed to create an artistic
and narrative experience. Creating a high-quality, aesthetically pleasing
cinemagraph requires isolating objects in a semantically meaningful way and
then selecting good start times and looping periods for those objects to
minimize visual artifacts (such a tearing). To achieve this, we present a new
technique that uses object recognition and semantic segmentation as part of an
optimization method to automatically create cinemagraphs from videos that are
both visually appealing and semantically meaningful. Given a scene with
multiple objects, there are many cinemagraphs one could create. Our method
evaluates these multiple candidates and presents the best one, as determined by
a model trained to predict human preferences in a collaborative way. We
demonstrate the effectiveness of our approach with multiple results and a user
study.
"
829,Learning to Synthesize a 4D RGBD Light Field from a Single Image,"  We present a machine learning algorithm that takes as input a 2D RGB image
and synthesizes a 4D RGBD light field (color and depth of the scene in each ray
direction). For training, we introduce the largest public light field dataset,
consisting of over 3300 plenoptic camera light fields of scenes containing
flowers and plants. Our synthesis pipeline consists of a convolutional neural
network (CNN) that estimates scene geometry, a stage that renders a Lambertian
light field using that geometry, and a second CNN that predicts occluded rays
and non-Lambertian effects. Our algorithm builds on recent view synthesis
methods, but is unique in predicting RGBD for each light field ray and
improving unsupervised single image depth estimation by enforcing consistency
of ray depths that should intersect the same scene point. Please see our
supplementary video at https://youtu.be/yLCvWoQLnms
"
830,SkyLens: Visual Analysis of Skyline on Multi-dimensional Data,"  Skyline queries have wide-ranging applications in fields that involve
multi-criteria decision making, including tourism, retail industry, and human
resources. By automatically removing incompetent candidates, skyline queries
allow users to focus on a subset of superior data items (i.e., the skyline),
thus reducing the decision-making overhead. However, users are still required
to interpret and compare these superior items manually before making a
successful choice. This task is challenging because of two issues. First,
people usually have fuzzy, unstable, and inconsistent preferences when
presented with multiple candidates. Second, skyline queries do not reveal the
reasons for the superiority of certain skyline points in a multi-dimensional
space. To address these issues, we propose SkyLens, a visual analytic system
aiming at revealing the superiority of skyline points from different
perspectives and at different scales to aid users in their decision making. Two
scenarios demonstrate the usefulness of SkyLens on two datasets with a dozen of
attributes. A qualitative study is also conducted to show that users can
efficiently accomplish skyline understanding and comparison tasks with SkyLens.
"
831,Visualizing Time-Varying Particle Flows with Diffusion Geometry,"  The tasks of identifying separation structures and clusters in flow data are
fundamental to flow visualization. Significant work has been devoted to these
tasks in flow represented by vector fields, but there are unique challenges in
addressing these tasks for time-varying particle data. The unstructured nature
of particle data, nonuniform and sparse sampling, and the inability to access
arbitrary particles in space-time make it difficult to define separation and
clustering for particle data. We observe that weaker notions of separation and
clustering through continuous measures of these structures are meaningful when
coupled with user exploration. We achieve this goal by defining a measure of
particle similarity between pairs of particles. More specifically, separation
occurs when spatially-localized particles are dissimilar, while clustering is
characterized by sets of particles that are similar to one another. To be
robust to imperfections in sampling we use diffusion geometry to compute
particle similarity. Diffusion geometry is parameterized by a scale that allows
a user to explore separation and clustering in a continuous manner. We
illustrate the benefits of our technique on a variety of 2D and 3D flow
datasets, from particles integrated in fluid simulations based on time-varying
vector fields, to particle-based simulations in astrophysics.
"
832,Calipso: Physics-based Image and Video Editing through CAD Model Proxies,"  We present Calipso, an interactive method for editing images and videos in a
physically-coherent manner. Our main idea is to realize physics-based
manipulations by running a full physics simulation on proxy geometries given by
non-rigidly aligned CAD models. Running these simulations allows us to apply
new, unseen forces to move or deform selected objects, change physical
parameters such as mass or elasticity, or even add entire new objects that
interact with the rest of the underlying scene. In Calipso, the user makes
edits directly in 3D; these edits are processed by the simulation and then
transfered to the target 2D content using shape-to-image correspondences in a
photo-realistic rendering process. To align the CAD models, we introduce an
efficient CAD-to-image alignment procedure that jointly minimizes for rigid and
non-rigid alignment while preserving the high-level structure of the input
shape. Moreover, the user can choose to exploit image flow to estimate scene
motion, producing coherent physical behavior with ambient dynamics. We
demonstrate Calipso's physics-based editing on a wide range of examples
producing myriad physical behavior while preserving geometric and visual
consistency.
"
833,Temporal Upsampling of Depth Maps Using a Hybrid Camera,"  In recent years, consumer-level depth cameras have been adopted for various
applications. However, they often produce depth maps at only a moderately high
frame rate (approximately 30 frames per second), preventing them from being
used for applications such as digitizing human performance involving fast
motion. On the other hand, low-cost, high-frame-rate video cameras are
available. This motivates us to develop a hybrid camera that consists of a
high-frame-rate video camera and a low-frame-rate depth camera and to allow
temporal interpolation of depth maps with the help of auxiliary color images.
To achieve this, we develop a novel algorithm that reconstructs intermediate
depth maps and estimates scene flow simultaneously. We test our algorithm on
various examples involving fast, non-rigid motions of single or multiple
objects. Our experiments show that our scene flow estimation method is more
precise than a tracking-based method and the state-of-the-art techniques.
"
834,"Fast, large-scale hologram calculation in wavelet domain","  We propose a large-scale hologram calculation using WAvelet ShrinkAge-Based
superpositIon (WASABI), a wavelet transform-based algorithm. An image-type
hologram calculated using the WASABI method is printed on a glass substrate
with the resolution of $65,536 \times 65,536$ pixels and a pixel pitch of $1
\mu$m. The hologram calculation time amounts to approximately 354 s on a
commercial CPU, which is approximately 30 times faster than conventional
methods.
"
835,"An OpenGL and C++ based function library for curve and surface modeling
  in a large class of extended Chebyshev spaces","  We propose a platform-independent multi-threaded function library that
provides data structures to generate, differentiate and render both the
ordinary basis and the normalized B-basis of a user-specified extended
Chebyshev (EC) space that comprises the constants and can be identified with
the solution space of a constant-coefficient homogeneous linear differential
equation defined on a sufficiently small interval. Using the obtained
normalized B-bases, our library can also generate, (partially) differentiate,
modify and visualize a large family of so-called B-curves and tensor product
B-surfaces. Moreover, the library also implements methods that can be used to
perform dimension elevation, to subdivide B-curves and B-surfaces by means of
de Casteljau-like B-algorithms, and to generate basis transformations for the
B-representation of arbitrary integral curves and surfaces that are described
in traditional parametric form by means of the ordinary bases of the underlying
EC spaces. Independently of the algebraic, exponential, trigonometric or mixed
type of the applied EC space, the proposed library is numerically stable and
efficient up to a reasonable dimension number and may be useful for academics
and engineers in the fields of Approximation Theory, Computer Aided Geometric
Design, Computer Graphics, Isogeometric and Numerical Analysis.
"
836,"DeformNet: Free-Form Deformation Network for 3D Shape Reconstruction
  from a Single Image","  3D reconstruction from a single image is a key problem in multiple
applications ranging from robotic manipulation to augmented reality. Prior
methods have tackled this problem through generative models which predict 3D
reconstructions as voxels or point clouds. However, these methods can be
computationally expensive and miss fine details. We introduce a new
differentiable layer for 3D data deformation and use it in DeformNet to learn a
model for 3D reconstruction-through-deformation. DeformNet takes an image
input, searches the nearest shape template from a database, and deforms the
template to match the query image. We evaluate our approach on the ShapeNet
dataset and show that - (a) the Free-Form Deformation layer is a powerful new
building block for Deep Learning models that manipulate 3D data (b) DeformNet
uses this FFD layer combined with shape retrieval for smooth and
detail-preserving 3D reconstruction of qualitatively plausible point clouds
with respect to a single query image (c) compared to other state-of-the-art 3D
reconstruction methods, DeformNet quantitatively matches or outperforms their
benchmarks by significant margins. For more information, visit:
https://deformnet-site.github.io/DeformNet-website/ .
"
837,"Light in Power: A General and Parameter-free Algorithm for Caustic
  Design","  We present in this paper a generic and parameter-free algorithm to
efficiently build a wide variety of optical components, such as mirrors or
lenses, that satisfy some light energy constraints. In all of our problems, one
is given a collimated or point light source and a desired illumination after
reflection or refraction and the goal is to design the geometry of a mirror or
lens which transports exactly the light emitted by the source onto the target.
We first propose a general framework and show that eight different optical
component design problems amount to solving a light energy conservation
equation that involves the computation of visibility diagrams. We then show
that these diagrams all have the same structure and can be obtained by
intersecting a 3D Power diagram with a planar or spherical domain. This allows
us to propose an efficient and fully generic algorithm capable to solve these
eight optical component design problems. The support of the prescribed target
illumination can be a set of directions or a set of points located at a finite
distance. Our solutions satisfy design constraints such as convexity or
concavity. We show the effectiveness of our algorithm on simulated and
fabricated examples.
"
838,PixelNN: Example-based Image Synthesis,"  We present a simple nearest-neighbor (NN) approach that synthesizes
high-frequency photorealistic images from an ""incomplete"" signal such as a
low-resolution image, a surface normal map, or edges. Current state-of-the-art
deep generative models designed for such conditional image synthesis lack two
important things: (1) they are unable to generate a large set of diverse
outputs, due to the mode collapse problem. (2) they are not interpretable,
making it difficult to control the synthesized output. We demonstrate that NN
approaches potentially address such limitations, but suffer in accuracy on
small datasets. We design a simple pipeline that combines the best of both
worlds: the first stage uses a convolutional neural network (CNN) to maps the
input to a (overly-smoothed) image, and the second stage uses a pixel-wise
nearest neighbor method to map the smoothed output to multiple high-quality,
high-frequency outputs in a controllable manner. We demonstrate our approach
for various input modalities, and for various domains ranging from human faces
to cats-and-dogs to shoes and handbags.
"
839,Eccentricity Effects on Blur and Depth Perception,"  Foveation and focus cue are the two most discussed topics on vision in
designing near-eye displays. Foveation reduces rendering load by omitting
spatial details in the content that the peripheral vision cannot appreciate;
Providing richer focal cue can resolve vergence-accommodation conflict thereby
lessening visual discomfort in using near-eye displays. We performed two
psychophysical experiments to investigate the relationship between foveation
and focus cue. The first study measured blur discrimination sensitivity as a
function of visual eccentricity, where we found discrimination thresholds
significantly lower than previously reported. The second study measured depth
discrimination threshold where we found a clear dependency on visual
eccentricity. We discuss the results from the two studies and suggest further
investigation.
"
840,Tags2Parts: Discovering Semantic Regions from Shape Tags,"  We propose a novel method for discovering shape regions that strongly
correlate with user-prescribed tags. For example, given a collection of chairs
tagged as either ""has armrest"" or ""lacks armrest"", our system correctly
highlights the armrest regions as the main distinctive parts between the two
chair types. To obtain point-wise predictions from shape-wise tags we develop a
novel neural network architecture that is trained with tag classification loss,
but is designed to rely on segmentation to predict the tag. Our network is
inspired by U-Net, but we replicate shallow U structures several times with new
skip connections and pooling layers, and call the resulting architecture
""WU-Net"". We test our method on segmentation benchmarks and show that even with
weak supervision of whole shape tags, our method can infer meaningful semantic
regions, without ever observing shape segmentations. Further, once trained, the
model can process shapes for which the tag is entirely unknown. As a bonus, our
architecture is directly operational under full supervision and performs
strongly on standard benchmarks. We validate our method through experiments
with many variant architectures and prior baselines, and demonstrate several
applications.
"
841,"Fractions, Projective Representation, Duality, Linear Algebra and
  Geometry","  This contribution describes relationship between fractions, projective
representation, duality, linear algebra and geometry. Many problems lead to a
system of linear equations. This paper presents equivalence of the
Cross-product operation and solution of a system of linear equations Ax=0 or
Ax=b using projective space representation and homogeneous coordinates. It
leads to conclusion that division operation is not required for a solution of a
system of linear equations, if the projective representation and homogeneous
coordinates are used. An efficient solution on CPU and GPU based architectures
is presented with an application to barycentric coordinates computation as
well.
"
842,"A two-level approach to implicit surface modeling with compactly
  supported radial basis functions","  We describe a two-level method for computing a function whose zero-level set
is the surface reconstructed from given points scattered over the surface and
associated with surface normal vectors. The function is defined as a linear
combination of compactly supported radial basis functions (CSRBFs). The method
preserves the simplicity and efficiency of implicit surface interpolation with
CSRBFs and the reconstructed implicit surface owns the attributes, which are
previously only associated with globally supported or globally regularized
radial basis functions, such as exhibiting less extra zero-level sets, suitable
for inside and outside tests. First, in the coarse scale approximation, we
choose basis function centers on a grid that covers the enlarged bounding box
of the given point set and compute their signed distances to the underlying
surface using local quadratic approximations of the nearest surface points.
Then a fitting to the residual errors on the surface points and additional
off-surface points is performed with fine scale basis functions. The final
function is the sum of the two intermediate functions and is a good
approximation of the signed distance field to the surface in the bounding box.
Examples of surface reconstruction and set operations between shapes are
provided.
"
843,"A Novel Stretch Energy Minimization Algorithm for Equiareal
  Parameterizations","  Surface parameterizations have been widely applied to computer graphics and
digital geometry processing. In this paper, we propose a novel stretch energy
minimization (SEM) algorithm for the computation of equiareal parameterizations
of simply connected open surfaces with a very small area distortion and a
highly improved computational efficiency. In addition, the existence of
nontrivial limit points of the SEM algorithm is guaranteed under some mild
assumptions of the mesh quality. Numerical experiments indicate that the
efficiency, accuracy, and robustness of the proposed SEM algorithm outperform
other state-of-the-art algorithms. Applications of the SEM on surface remeshing
and surface registration for simply connected open surfaces are demonstrated
thereafter. Thanks to the SEM algorithm, the computations for these
applications can be carried out efficiently and robustly.
"
844,Efficient barycentric point sampling on meshes,"  We present an easy-to-implement and efficient analytical inversion algorithm
for the unbiased random sampling of a set of points on a triangle mesh whose
surface density is specified by barycentric interpolation of non-negative
per-vertex weights. The correctness of the inversion algorithm is verified via
statistical tests, and we show that it is faster on average than rejection
sampling.
"
845,"Active Animations of Reduced Deformable Models with Environment
  Interactions","  We present an efficient spacetime optimization method to automatically
generate animations for a general volumetric, elastically deformable body. Our
approach can model the interactions between the body and the environment and
automatically generate active animations. We model the frictional contact
forces using contact invariant optimization and the fluid drag forces using a
simplified model. To handle complex objects, we use a reduced deformable model
and present a novel hybrid optimizer to search for the local minima
efficiently. This allows us to use long-horizon motion planning to
automatically generate animations such as walking, jumping, swimming, and
rolling. We evaluate the approach on different shapes and animations, including
deformable body navigation and combining with an open-loop controller for
realtime forward simulation.
"
846,Stylizing Face Images via Multiple Exemplars,"  We address the problem of transferring the style of a headshot photo to face
images. Existing methods using a single exemplar lead to inaccurate results
when the exemplar does not contain sufficient stylized facial components for a
given photo. In this work, we propose an algorithm to stylize face images using
multiple exemplars containing different subjects in the same style. Patch
correspondences between an input photo and multiple exemplars are established
using a Markov Random Field (MRF), which enables accurate local energy transfer
via Laplacian stacks. As image patches from multiple exemplars are used, the
boundaries of facial components on the target image are inevitably
inconsistent. The artifacts are removed by a post-processing step using an
edge-preserving filter. Experimental results show that the proposed algorithm
consistently produces visually pleasing results.
"
847,"A simple en,ex marking rule for degenerate intersection points in 2D
  polygon clipping","  A simple en,ex rule to mark the intersection points of 2D input polygon
contours separating the polygon interior from its exterior in the vicinity of
the intersections is presented. Its form is close to the original Greiner &
Hormann algorithm rule but encompasses degenerate intersections that are not
self-intersections. It only uses local geometric information once the hand of
the two input contours is known. The approach foundation is the distinction
between two features of the studied intersections: the geometric intersection
point and the assembling/concatenation point of the result contour/border. No
special form of the intersection finding procedure is required.
"
848,Fast Image Processing with Fully-Convolutional Networks,"  We present an approach to accelerating a wide variety of image processing
operators. Our approach uses a fully-convolutional network that is trained on
input-output pairs that demonstrate the operator's action. After training, the
original operator need not be run at all. The trained network operates at full
resolution and runs in constant time. We investigate the effect of network
architecture on approximation accuracy, runtime, and memory footprint, and
identify a specific architecture that balances these considerations. We
evaluate the presented approach on ten advanced image processing operators,
including multiple variational models, multiscale tone and detail manipulation,
photographic style transfer, nonlocal dehazing, and nonphotorealistic
stylization. All operators are approximated by the same model. Experiments
demonstrate that the presented approach is significantly more accurate than
prior approximation schemes. It increases approximation accuracy as measured by
PSNR across the evaluated operators by 8.5 dB on the MIT-Adobe dataset (from
27.5 to 36 dB) and reduces DSSIM by a multiplicative factor of 3 compared to
the most accurate prior approximation scheme, while being the fastest. We show
that our models generalize across datasets and across resolutions, and
investigate a number of extensions of the presented approach. The results are
shown in the supplementary video at https://youtu.be/eQyfHgLx8Dc
"
849,Simulated Annealing for JPEG Quantization,"  JPEG is one of the most widely used image formats, but in some ways remains
surprisingly unoptimized, perhaps because some natural optimizations would go
outside the standard that defines JPEG. We show how to improve JPEG compression
in a standard-compliant, backward-compatible manner, by finding improved
default quantization tables. We describe a simulated annealing technique that
has allowed us to find several quantization tables that perform better than the
industry standard, in terms of both compressed size and image fidelity.
Specifically, we derive tables that reduce the FSIM error by over 10% while
improving compression by over 20% at quality level 95 in our tests; we also
provide similar results for other quality levels. While we acknowledge our
approach can in some images lead to visible artifacts under large
magnification, we believe use of these quantization tables, or additional
tables that could be found using our methodology, would significantly reduce
JPEG file sizes with improved overall image quality.
"
850,MLSEB: Edge Bundling using Moving Least Squares Approximation,"  Edge bundling methods can effectively alleviate visual clutter and reveal
high-level graph structures in large graph visualization. Researchers have
devoted significant efforts to improve edge bundling according to different
metrics. As the edge bundling family evolve rapidly, the quality of edge
bundles receives increasing attention in the literature accordingly. In this
paper, we present MLSEB, a novel method to generate edge bundles based on
moving least squares (MLS) approximation. In comparison with previous edge
bundling methods, we argue that our MLSEB approach can generate better results
based on a quantitative metric of quality, and also ensure scalability and the
efficiency for visualizing large graphs.
"
851,Sparse Data Driven Mesh Deformation,"  Example-based mesh deformation methods are powerful tools for realistic shape
editing. However, existing techniques typically combine all the example
deformation modes, which can lead to overfitting, i.e. using a overly
complicated model to explain the user-specified deformation. This leads to
implausible or unstable deformation results, including unexpected global
changes outside the region of interest. To address this fundamental limitation,
we propose a sparse blending method that automatically selects a smaller number
of deformation modes to compactly describe the desired deformation. This along
with a suitably chosen deformation basis including spatially localized
deformation modes leads to significant advantages, including more meaningful,
reliable, and efficient deformations because fewer and localized deformation
modes are applied. To cope with large rotations, we develop a simple but
effective representation based on polar decomposition of deformation gradients,
which resolves the ambiguity of large global rotations using an
as-consistent-as-possible global optimization. This simple representation has a
closed form solution for derivatives, making it efficient for sparse localized
representation and thus ensuring interactive performance. Experimental results
show that our method outperforms state-of-the-art data-driven mesh deformation
methods, for both quality of results and efficiency.
"
852,"SketchParse : Towards Rich Descriptions for Poorly Drawn Sketches using
  Multi-Task Hierarchical Deep Networks","  The ability to semantically interpret hand-drawn line sketches, although very
challenging, can pave way for novel applications in multimedia. We propose
SketchParse, the first deep-network architecture for fully automatic parsing of
freehand object sketches. SketchParse is configured as a two-level fully
convolutional network. The first level contains shared layers common to all
object categories. The second level contains a number of expert sub-networks.
Each expert specializes in parsing sketches from object categories which
contain structurally similar parts. Effectively, the two-level configuration
enables our architecture to scale up efficiently as additional categories are
added. We introduce a router layer which (i) relays sketch features from shared
layers to the correct expert (ii) eliminates the need to manually specify
object category during inference. To bypass laborious part-level annotation, we
sketchify photos from semantic object-part image datasets and use them for
training. Our architecture also incorporates object pose prediction as a novel
auxiliary task which boosts overall performance while providing supplementary
information regarding the sketch. We demonstrate SketchParse's abilities (i) on
two challenging large-scale sketch datasets (ii) in parsing unseen,
semantically related object categories (iii) in improving fine-grained
sketch-based image retrieval. As a novel application, we also outline how
SketchParse's output can be used to generate caption-style descriptions for
hand-drawn sketches.
"
853,"Multi-color image compression-encryption algorithm based on chaotic
  system and fuzzy transform","  In this paper an algorithm for multi-color image compression-encryption is
introduced. For compression step fuzzy transform based on exponential b-spline
function is used. In encryption step, a novel combination chaotic system based
on Sine and Tent systems is proposed. Also in the encryption algorithm, 3D
shift based on chaotic system is introduced. The simulation results and
security analysis show that the proposed algorithm is secure and efficient.
"
854,360 Panorama Cloning on Sphere,"  In this paper, we address a novel problem of cloning a patch of the source
spherical panoramic image to the target spherical panoramic image, which we
call 360 panorama cloning. Considering the sphere geometry constraint embedded
in spherical panoramic images, we develop a coordinate-based method that
directly clones in the spherical domain. Our method neither differentiates the
polar regions and equatorial regions, nor identifies the boundaries in the
unrolled planar-formatted panorama. We discuss in depth two unique issues in
panorama cloning, i.e. preserving the patch's orientation, and handling the
large-patch cloning (covering over 180 field of view) which may suffer from
discoloration artifacts. As experimental results demonstrate, our method is
able to get visually pleasing cloning results and achieve real time cloning
performance.
"
855,"On the correlation between a level of structure order and properties of
  composites. In Memory of Yu.L. Klimontovich","  Proposed the computerized method for calculating the relative level of order
composites. Correlation between a level of structure order and properties of
solids is shown. Discussed the possibility of clarifying the terminology used
in describing the structure.
"
856,"Global spectral graph wavelet signature for surface analysis of carpal
  bones","  In this paper, we present a spectral graph wavelet approach for shape
analysis of carpal bones of human wrist. We apply a metric called global
spectral graph wavelet signature for representation of cortical surface of the
carpal bone based on eigensystem of Laplace-Beltrami operator. Furthermore, we
propose a heuristic and efficient way of aggregating local descriptors of a
carpal bone surface to global descriptor. The resultant global descriptor is
not only isometric invariant, but also much more efficient and requires less
memory storage. We perform experiments on shape of the carpal bones of ten
women and ten men from a publicly-available database. Experimental results show
the excellency of the proposed GSGW compared to recent proposed GPS embedding
approach for comparing shapes of the carpal bones across populations.
"
857,Mesh-based Autoencoders for Localized Deformation Component Analysis,"  Spatially localized deformation components are very useful for shape analysis
and synthesis in 3D geometry processing. Several methods have recently been
developed, with an aim to extract intuitive and interpretable deformation
components. However, these techniques suffer from fundamental limitations
especially for meshes with noise or large-scale deformations, and may not
always be able to identify important deformation components. In this paper we
propose a novel mesh-based autoencoder architecture that is able to cope with
meshes with irregular topology. We introduce sparse regularization in this
framework, which along with convolutional operations, helps localize
deformations. Our framework is capable of extracting localized deformation
components from mesh data sets with large-scale deformations and is robust to
noise. It also provides a nonlinear approach to reconstruction of meshes using
the extracted basis, which is more effective than the current linear
combination approach. Extensive experiments show that our method outperforms
state-of-the-art methods in both qualitative and quantitative evaluations.
"
858,Variational Autoencoders for Deforming 3D Mesh Models,"  3D geometric contents are becoming increasingly popular. In this paper, we
study the problem of analyzing deforming 3D meshes using deep neural networks.
Deforming 3D meshes are flexible to represent 3D animation sequences as well as
collections of objects of the same category, allowing diverse shapes with
large-scale non-linear deformations. We propose a novel framework which we call
mesh variational autoencoders (mesh VAE), to explore the probabilistic latent
space of 3D surfaces. The framework is easy to train, and requires very few
training examples. We also propose an extended model which allows flexibly
adjusting the significance of different latent variables by altering the prior
distribution. Extensive experiments demonstrate that our general framework is
able to learn a reasonable representation for a collection of deformable
shapes, and produce competitive results for a variety of applications,
including shape generation, shape interpolation, shape space embedding and
shape exploration, outperforming state-of-the-art methods.
"
859,"The wave method of building color palette and its application in
  computer graphics","  This article describes a method of getting a harmonious combination of
colors, developed by us on the basis of the relationship of color and acoustic
waves. Presents a parallel between harmoniously matched colors and the concept
of harmony in music theory (consonance). Describes the physical assumption of
the essence of the phenomenon of harmony (consonance). The article also
provides algorithm of implementation wave method for the sRGB color model.
"
860,Dynamic Network: Graphical Deformation of Penetrated Objects,"  In a computer-based virtual environment, objects may collide with each other.
Therefore, different algorithms are needed to detect the collision and perform
a correct action in order to avoid penetration. Based on the application and
objects physical characteristics, a correct action can include separating or
deforming the penetrated objects. In this article, by using the concepts of
dynamic networks and simple physics, a method for deforming two penetrated 3D
objects is proposed. In this method, we consider each primitive of the objects
as an element interacting with the other elements in a dynamic network. These
kinds of interactions make the elements impose force on each other and change
their position, until a force-balance happens. The proposed method is
implemented and tested on 3D sample objects, and the resulted deformation
proved to be visually satisfying.
"
861,Learning Compact Geometric Features,"  We present an approach to learning features that represent the local geometry
around a point in an unstructured point cloud. Such features play a central
role in geometric registration, which supports diverse applications in robotics
and 3D vision. Current state-of-the-art local features for unstructured point
clouds have been manually crafted and none combines the desirable properties of
precision, compactness, and robustness. We show that features with these
properties can be learned from data, by optimizing deep networks that map
high-dimensional histograms into low-dimensional Euclidean spaces. The
presented approach yields a family of features, parameterized by dimension,
that are both more compact and more accurate than existing descriptors.
"
862,"Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting
  Neural Networks","  We present a technique for efficiently synthesizing images of atmospheric
clouds using a combination of Monte Carlo integration and neural networks. The
intricacies of Lorenz-Mie scattering and the high albedo of cloud-forming
aerosols make rendering of clouds---e.g. the characteristic silverlining and
the ""whiteness"" of the inner body---challenging for methods based solely on
Monte Carlo integration or diffusion theory. We approach the problem
differently. Instead of simulating all light transport during rendering, we
pre-learn the spatial and directional distribution of radiant flux from tens of
cloud exemplars. To render a new scene, we sample visible points of the cloud
and, for each, extract a hierarchical 3D descriptor of the cloud geometry with
respect to the shading location and the light source. The descriptor is input
to a deep neural network that predicts the radiance function for each shading
configuration. We make the key observation that progressively feeding the
hierarchical descriptor into the network enhances the network's ability to
learn faster and predict with high accuracy while using few coefficients. We
also employ a block design with residual connections to further improve
performance. A GPU implementation of our method synthesizes images of clouds
that are nearly indistinguishable from the reference solution within seconds
interactively. Our method thus represents a viable solution for applications
such as cloud design and, thanks to its temporal stability, also for
high-quality production of animated content.
"
863,"Hierarchical Detail Enhancing Mesh-Based Shape Generation with 3D
  Generative Adversarial Network","  Automatic mesh-based shape generation is of great interest across a wide
range of disciplines, from industrial design to gaming, computer graphics and
various other forms of digital art. While most traditional methods focus on
primitive based model generation, advances in deep learning made it possible to
learn 3-dimensional geometric shape representations in an end-to-end manner.
However, most current deep learning based frameworks focus on the
representation and generation of voxel and point-cloud based shapes, making it
not directly applicable to design and graphics communities. This study
addresses the needs for automatic generation of mesh-based geometries, and
propose a novel framework that utilizes signed distance function representation
that generates detail preserving three-dimensional surface mesh by a deep
learning based approach.
"
864,"High-Resolution Shape Completion Using Deep Neural Networks for Global
  Structure and Local Geometry Inference","  We propose a data-driven method for recovering miss-ing parts of 3D shapes.
Our method is based on a new deep learning architecture consisting of two
sub-networks: a global structure inference network and a local geometry
refinement network. The global structure inference network incorporates a long
short-term memorized context fusion module (LSTM-CF) that infers the global
structure of the shape based on multi-view depth information provided as part
of the input. It also includes a 3D fully convolutional (3DFCN) module that
further enriches the global structure representation according to volumetric
information in the input. Under the guidance of the global structure network,
the local geometry refinement network takes as input lo-cal 3D patches around
missing regions, and progressively produces a high-resolution, complete surface
through a volumetric encoder-decoder architecture. Our method jointly trains
the global structure inference and local geometry refinement networks in an
end-to-end manner. We perform qualitative and quantitative evaluations on six
object categories, demonstrating that our method outperforms existing
state-of-the-art work on shape completion.
"
865,Exploring the Design Space of Immersive Urban Analytics,"  Recent years have witnessed the rapid development and wide adoption of
immersive head-mounted devices, such as HTC VIVE, Oculus Rift, and Microsoft
HoloLens. These immersive devices have the potential to significantly extend
the methodology of urban visual analytics by providing critical 3D context
information and creating a sense of presence. In this paper, we propose an
theoretical model to characterize the visualizations in immersive urban
analytics. Further more, based on our comprehensive and concise model, we
contribute a typology of combination methods of 2D and 3D visualizations that
distinguish between linked views, embedded views, and mixed views. We also
propose a supporting guideline to assist users in selecting a proper view under
certain circumstances by considering visual geometry and spatial distribution
of the 2D and 3D visualizations. Finally, based on existing works, possible
future research opportunities are explored and discussed.
"
866,Exposure: A White-Box Photo Post-Processing Framework,"  Retouching can significantly elevate the visual appeal of photos, but many
casual photographers lack the expertise to do this well. To address this
problem, previous works have proposed automatic retouching systems based on
supervised learning from paired training images acquired before and after
manual editing. As it is difficult for users to acquire paired images that
reflect their retouching preferences, we present in this paper a deep learning
approach that is instead trained on unpaired data, namely a set of photographs
that exhibits a retouching style the user likes, which is much easier to
collect. Our system is formulated using deep convolutional neural networks that
learn to apply different retouching operations on an input image. Network
training with respect to various types of edits is enabled by modeling these
retouching operations in a unified manner as resolution-independent
differentiable filters. To apply the filters in a proper sequence and with
suitable parameters, we employ a deep reinforcement learning approach that
learns to make decisions on what action to take next, given the current state
of the image. In contrast to many deep learning systems, ours provides users
with an understandable solution in the form of conventional retouching edits,
rather than just a ""black-box"" result. Through quantitative comparisons and
user studies, we show that this technique generates retouching results
consistent with the provided photo set.
"
867,Functional Characterization of Deformation Fields,"  In this paper we present a novel representation for deformation fields of 3D
shapes, by considering the induced changes in the underlying metric. In
particular, our approach allows to represent a deformation field in a
coordinate-free way as a linear operator acting on real-valued functions
defined on the shape. Such a representation both provides a way to relate
deformation fields to other classical functional operators and enables analysis
and processing of deformation fields using standard linear-algebraic tools.
This opens the door to a wide variety of applications such as explicitly adding
extrinsic information into the computation of functional maps, intrinsic shape
symmetrization, joint deformation design through precise control of metric
distortion, and coordinate-free deformation transfer without requiring
pointwise correspondences. Our method is applicable to both surface and
volumetric shape representations and we guarantee the equivalence between the
operator-based and standard deformation field representation under mild
genericity conditions in the discrete setting. We demonstrate the utility of
our approach by comparing it with existing techniques and show how our
representation provides a powerful toolbox for a wide variety of challenging
problems.
"
868,Photometric Stabilization for Fast-forward Videos,"  Videos captured by consumer cameras often exhibit temporal variations in
color and tone that are caused by camera auto-adjustments like white-balance
and exposure. When such videos are sub-sampled to play fast-forward, as in the
increasingly popular forms of timelapse and hyperlapse videos, these temporal
variations are exacerbated and appear as visually disturbing high frequency
flickering. Previous techniques to photometrically stabilize videos typically
rely on computing dense correspondences between video frames, and use these
correspondences to remove all color changes in the video sequences. However,
this approach is limited in fast-forward videos that often have large content
changes and also might exhibit changes in scene illumination that should be
preserved. In this work, we propose a novel photometric stabilization algorithm
for fast-forward videos that is robust to large content-variation across
frames. We compute pairwise color and tone transformations between neighboring
frames and smooth these pair-wise transformations while taking in account the
possibility of scene/content variations. This allows us to eliminate
high-frequency fluctuations, while still adapting to real variations in scene
characteristics. We evaluate our technique on a new dataset consisting of
controlled synthetic and real videos, and demonstrate that our techniques
outperforms the state-of-the-art.
"
869,Redefining A in RGBA: Towards a Standard for Graphical 3D Printing,"  Advances in multimaterial 3D printing have the potential to reproduce various
visual appearance attributes of an object in addition to its shape. Since many
existing 3D file formats encode color and translucency by RGBA textures mapped
to 3D shapes, RGBA information is particularly important for practical
applications. In contrast to color (encoded by RGB), which is specified by the
object's reflectance, selected viewing conditions and a standard observer,
translucency (encoded by A) is neither linked to any measurable physical nor
perceptual quantity. Thus, reproducing translucency encoded by A is open for
interpretation.
  In this paper, we propose a rigorous definition for A suitable for use in
graphical 3D printing, which is independent of the 3D printing hardware and
software, and which links both optical material properties and perceptual
uniformity for human observers. By deriving our definition from the absorption
and scattering coefficients of virtual homogeneous reference materials with an
isotropic phase function, we achieve two important properties. First, a simple
adjustment of A is possible, which preserves the translucency appearance if an
object is re-scaled for printing. Second, determining the value of A for a real
(potentially non-homogeneous) material, can be achieved by minimizing a
distance function between light transport measurements of this material and
simulated measurements of the reference materials. Such measurements can be
conducted by commercial spectrophotometers used in graphic arts.
  Finally, we conduct visual experiments employing the method of constant
stimuli, and derive from them an embedding of A into a nearly perceptually
uniform scale of translucency for the reference materials.
"
870,Simulating Structure-from-Motion,"  The implementation of a Structure-from-Motion (SfM) pipeline from a
synthetically generated scene as well as the investigation of the faithfulness
of diverse reconstructions is the subject of this project. A series of
different SfM reconstructions are implemented and their camera pose estimations
are being contrasted with their respective ground truth locations. Finally,
injection of ground truth location data into the rendered images in order to
reduce the estimation error of the camera poses is studied as well.
"
871,Automatic Structural Scene Digitalization,"  In this paper, we present an automatic system for the analysis and labeling
of structural scenes, floor plan drawings in Computer-aided Design (CAD)
format. The proposed system applies a fusion strategy to detect and recognize
various components of CAD floor plans, such as walls, doors, windows and other
ambiguous assets. Technically, a general rule-based filter parsing method is
fist adopted to extract effective information from the original floor plan.
Then, an image-processing based recovery method is employed to correct
information extracted in the first step. Our proposed method is fully automatic
and real-time. Such analysis system provides high accuracy and is also
evaluated on a public website that, on average, archives more than ten
thousands effective uses per day and reaches a relatively high satisfaction
rate.
"
872,Clustrophile: A Tool for Visual Clustering Analysis,"  While clustering is one of the most popular methods for data mining, analysts
lack adequate tools for quick, iterative clustering analysis, which is
essential for hypothesis generation and data reasoning. We introduce
Clustrophile, an interactive tool for iteratively computing discrete and
continuous data clusters, rapidly exploring different choices of clustering
parameters, and reasoning about clustering instances in relation to data
dimensions. Clustrophile combines three basic visualizations -- a table of raw
datasets, a scatter plot of planar projections, and a matrix diagram (heatmap)
of discrete clusterings -- through interaction and intermediate visual
encoding. Clustrophile also contributes two spatial interaction techniques,
$\textit{forward projection}$ and $\textit{backward projection}$, and a
visualization method, $\textit{prolines}$, for reasoning about two-dimensional
projections obtained through dimensionality reductions.
"
873,Towards High-quality Visualization of Superfluid Vortices,"  Superfluidity is a special state of matter exhibiting macroscopic quantum
phenomena and acting like a fluid with zero viscosity. In such a state,
superfluid vortices exist as phase singularities of the model equation with
unique distributions. This paper presents novel techniques to aid the visual
understanding of superfluid vortices based on the state-of-the-art non-linear
Klein-Gordon equation, which evolves a complex scalar field, giving rise to
special vortex lattice/ring structures with dynamic vortex formation,
reconnection, and Kelvin waves, etc. By formulating a numerical model with
theoretical physicists in superfluid research, we obtain high-quality
superfluid flow data sets without noise-like waves, suitable for vortex
visualization. By further exploring superfluid vortex properties, we develop a
new vortex identification and visualization method: a novel mechanism with
velocity circulation to overcome phase singularity and an orthogonal-plane
strategy to avoid ambiguity. Hence, our visualizations can help reveal various
superfluid vortex structures and enable domain experts for related visual
analysis, such as the steady vortex lattice/ring structures, dynamic vortex
string interactions with reconnections and energy radiations, where the famous
Kelvin waves and decaying vortex tangle were clearly observed. These
visualizations have assisted physicists to verify the superfluid model, and
further explore its dynamic behavior more intuitively.
"
874,"Texture Fuzzy Segmentation using Skew Divergence Adaptive Affinity
  Functions","  Digital image segmentation is the process of assigning distinct labels to
different objects in a digital image, and the fuzzy segmentation algorithm has
been successfully used in the segmentation of images from a wide variety of
sources. However, the traditional fuzzy segmentation algorithm fails to segment
objects that are characterized by textures whose patterns cannot be
successfully described by simple statistics computed over a very restricted
area. In this paper, we propose an extension of the fuzzy segmentation
algorithm that uses adaptive textural affinity functions to perform the
segmentation of such objects on bidimensional images. The adaptive affinity
functions compute their appropriate neighborhood size as they compute the
texture descriptors surrounding the seed spels (spatial elements), according to
the characteristics of the texture being processed. The algorithm then segments
the image with an appropriate neighborhood for each object. We performed
experiments on mosaic images that were composed using images from the Brodatz
database, and compared our results with the ones produced by a recently
published texture segmentation algorithm, showing the applicability of our
method.
"
875,Exploration of Heterogeneous Data Using Robust Similarity,"  Heterogeneous data pose serious challenges to data analysis tasks, including
exploration and visualization. Current techniques often utilize dimensionality
reductions, aggregation, or conversion to numerical values to analyze
heterogeneous data. However, the effectiveness of such techniques to find
subtle structures such as the presence of multiple modes or detection of
outliers is hindered by the challenge to find the proper subspaces or prior
knowledge to reveal the structures. In this paper, we propose a generic
similarity-based exploration technique that is applicable to a wide variety of
datatypes and their combinations, including heterogeneous ensembles. The
proposed concept of similarity has a close connection to statistical analysis
and can be deployed for summarization, revealing fine structures such as the
presence of multiple modes, and detection of anomalies or outliers. We then
propose a visual encoding framework that enables the exploration of a
heterogeneous dataset in different levels of detail and provides insightful
information about both global and local structures. We demonstrate the utility
of the proposed technique using various real datasets, including ensemble data.
"
876,"Algorithm guided outlining of 105 pancreatic cancer liver metastases in
  Ultrasound","  Manual segmentation of hepatic metastases in ultrasound images acquired from
patients suffering from pancreatic cancer is common practice. Semiautomatic
measurements promising assistance in this process are often assessed using a
small number of lesions performed by examiners who already know the algorithm.
In this work, we present the application of an algorithm for the segmentation
of liver metastases due to pancreatic cancer using a set of 105 different
images of metastases. The algorithm and the two examiners had never assessed
the images before. The examiners first performed a manual segmentation and,
after five weeks, a semiautomatic segmentation using the algorithm. They were
satisfied in up to 90% of the cases with the semiautomatic segmentation
results. Using the algorithm was significantly faster and resulted in a median
Dice similarity score of over 80%. Estimation of the inter-operator variability
by using the intra class correlation coefficient was good with 0.8. In
conclusion, the algorithm facilitates fast and accurate segmentation of liver
metastases, comparable to the current gold standard of manual segmentation.
"
877,"Standard detectors aren't (currently) fooled by physical adversarial
  stop signs","  An adversarial example is an example that has been adjusted to produce the
wrong label when presented to a system at test time. If adversarial examples
existed that could fool a detector, they could be used to (for example) wreak
havoc on roads populated with smart vehicles. Recently, we described our
difficulties creating physical adversarial stop signs that fool a detector.
More recently, Evtimov et al. produced a physical adversarial stop sign that
fools a proxy model of a detector. In this paper, we show that these physical
adversarial stop signs do not fool two standard detectors (YOLO and Faster
RCNN) in standard configuration. Evtimov et al.'s construction relies on a crop
of the image to the stop sign; this crop is then resized and presented to a
classifier. We argue that the cropping and resizing procedure largely
eliminates the effects of rescaling and of view angle. Whether an adversarial
attack is robust under rescaling and change of view direction remains moot. We
argue that attacking a classifier is very different from attacking a detector,
and that the structure of detectors - which must search for their own bounding
box, and which cannot estimate that box very accurately - likely makes it
difficult to make adversarial patterns. Finally, an adversarial pattern on a
physical object that could fool a detector would have to be adversarial in the
face of a wide family of parametric distortions (scale; view angle; box shift
inside the detector; illumination; and so on). Such a pattern would be of great
theoretical and practical interest. There is currently no evidence that such
patterns exist.
"
878,Image retargeting via Beltrami representation,"  Image retargeting aims to resize an image to one with a prescribed aspect
ratio. Simple scaling inevitably introduces unnatural geometric distortions on
the important content of the image. In this paper, we propose a simple and yet
effective method to resize an image, which preserves the geometry of the
important content, using the Beltrami representation. Our algorithm allows
users to interactively label content regions as well as line structures. Image
resizing can then be achieved by warping the image by an orientation-preserving
bijective warping map with controlled distortion. The warping map is
represented by its Beltrami representation, which captures the local geometric
distortion of the map. By carefully prescribing the values of the Beltrami
representation, images with different complexity can be effectively resized.
Our method does not require solving any optimization problems and tuning
parameters throughout the process. This results in a simple and efficient
algorithm to solve the image retargeting problem. Extensive experiments have
been carried out, which demonstrate the efficacy of our proposed method.
"
879,"What Would a Graph Look Like in This Layout? A Machine Learning Approach
  to Large Graph Visualization","  Using different methods for laying out a graph can lead to very different
visual appearances, with which the viewer perceives different information.
Selecting a ""good"" layout method is thus important for visualizing a graph. The
selection can be highly subjective and dependent on the given task. A common
approach to selecting a good layout is to use aesthetic criteria and visual
inspection. However, fully calculating various layouts and their associated
aesthetic metrics is computationally expensive. In this paper, we present a
machine learning approach to large graph visualization based on computing the
topological similarity of graphs using graph kernels. For a given graph, our
approach can show what the graph would look like in different layouts and
estimate their corresponding aesthetic metrics. An important contribution of
our work is the development of a new framework to design graph kernels. Our
experimental study shows that our estimation calculation is considerably faster
than computing the actual layouts and their aesthetic metrics. Also, our graph
kernels outperform the state-of-the-art ones in both time and accuracy. In
addition, we conducted a user study to demonstrate that the topological
similarity computed with our graph kernel matches perceptual similarity
assessed by human users.
"
880,Single-image Tomography: 3D Volumes from 2D Cranial X-Rays,"  As many different 3D volumes could produce the same 2D x-ray image, inverting
this process is challenging. We show that recent deep learning-based
convolutional neural networks can solve this task. As the main challenge in
learning is the sheer amount of data created when extending the 2D image into a
3D volume, we suggest firstly to learn a coarse, fixed-resolution volume which
is then fused in a second step with the input x-ray into a high-resolution
volume. To train and validate our approach we introduce a new dataset that
comprises of close to half a million computer-simulated 2D x-ray images of 3D
volumes scanned from 175 mammalian species. Applications of our approach
include stereoscopic rendering of legacy x-ray images, re-rendering of x-rays
including changes of illumination, view pose or geometry. Our evaluation
includes comparison to previous tomography work, previous learning methods
using our data, a user study and application to a set of real x-rays.
"
881,"A graphical, scalable and intuitive method for the placement and the
  connection of biological cells","  We introduce a graphical method originating from the computer graphics domain
that is used for the arbitrary and intuitive placement of cells over a
two-dimensional manifold. Using a bitmap image as input, where the color
indicates the identity of the different structures and the alpha channel
indicates the local cell density, this method guarantees a discrete
distribution of cell position respecting the local density function. This
method scales to any number of cells, allows to specify several different
structures at once with arbitrary shapes and provides a scalable and versatile
alternative to the more classical assumption of a uniform non-spatial
distribution. Furthermore, several connection schemes can be derived from the
paired distances between cells using either an automatic mapping or a
user-defined local reference frame, providing new computational properties for
the underlying model. The method is illustrated on a discrete homogeneous
neural field, on the distribution of cones and rods in the retina and on a
coronal view of the basal ganglia.
"
882,Robust Structure-based Shape Correspondence,"  We present a robust method to find region-level correspondences between
shapes, which are invariant to changes in geometry and applicable across
multiple shape representations. We generate simplified shape graphs by jointly
decomposing the shapes, and devise an adapted graph-matching technique, from
which we infer correspondences between shape regions. The simplified shape
graphs are designed to primarily capture the overall structure of the shapes,
without reflecting precise information about the geometry of each region, which
enables us to find correspondences between shapes that might have significant
geometric differences. Moreover, due to the special care we take to ensure the
robustness of each part of our pipeline, our method can find correspondences
between shapes with different representations, such as triangular meshes and
point clouds. We demonstrate that the region-wise matching that we obtain can
be used to find correspondences between feature points, reveal the intrinsic
self-similarities of each shape, and even construct point-to-point maps across
shapes. Our method is both time and space efficient, leading to a pipeline that
is significantly faster than comparable approaches. We demonstrate the
performance of our approach through an extensive quantitative and qualitative
evaluation on several benchmarks where we achieve comparable or superior
performance to existing methods.
"
883,Subtractive Color Mixture Computation,"  Modeling subtractive color mixture (e.g., the way that paints mix) is
difficult when working with colors described only by three-dimensional color
space values, such as RGB. Although RGB values are sufficient to describe a
specific color sensation, they do not contain enough information to predict the
RGB color that would result from a subtractive mixture of two specified RGB
colors. Methods do exist for accurately modeling subtractive mixture, such as
the Kubelka-Munk equations, but require extensive spectrophotometric
measurements of the mixed components, making them unsuitable for many computer
graphics applications. This paper presents a strategy for modeling subtractive
color mixture given only the RGB information of the colors being mixed, written
for a general audience. The RGB colors are first transformed to generic,
representative spectral distributions, and then this spectral information is
used to perform the subtractive mixture, using the weighted
arithmetic-geometric mean. This strategy provides reasonable, representative
subtractive mixture colors with only modest computational effort and no
experimental measurements. As such, it provides a useful way to model
subtractive color mixture in computer graphics applications.
"
884,"Embedded Spectral Descriptors: Learning the point-wise correspondence
  metric via Siamese neural networks","  A robust and informative local shape descriptor plays an important role in
mesh registration. In this regard, spectral descriptors that are based on the
spectrum of the Laplace-Beltrami operator have been a popular subject of
research for the last decade due to their advantageous properties, such as
isometry invariance. Despite such, however, spectral descriptors often fail to
give a correct similarity measure for non-isometric cases where the metric
distortion between the models is large. Hence, they are not reliable for
correspondence matching problems when the models are not isometric. In this
paper, it is proposed a method to improve the similarity metric of spectral
descriptors for correspondence matching problems. We embed a spectral shape
descriptor into a different metric space where the Euclidean distance between
the elements directly indicates the geometric dissimilarity. We design and
train a Siamese neural network to find such an embedding, where the embedded
descriptors are promoted to rearrange based on the geometric similarity. We
demonstrate our approach can significantly enhance the performance of the
conventional spectral descriptors by the simple augmentation achieved via the
Siamese neural network in comparison to other state-of-the-art methods.
"
885,Amending the Characterization of Guidance in Visual Analytics,"  At VAST 2016, a characterization of guidance has been presented. It includes
a definition of guidance and a model of guidance based on van Wijk's model of
visualization. This note amends the original characterization of guidance in
two aspects. First, we provide a clarification of what guidance actually is
(and is not). Second, we insert into the model a conceptually relevant link
that was missing in the original version.
"
886,Photo-Guided Exploration of Volume Data Features,"  In this work, we pose the question of whether, by considering qualitative
information such as a sample target image as input, one can produce a rendered
image of scientific data that is similar to the target. The algorithm resulting
from our research allows one to ask the question of whether features like those
in the target image exists in a given dataset. In that way, our method is one
of imagery query or reverse engineering, as opposed to manual parameter
tweaking of the full visualization pipeline. For target images, we can use
real-world photographs of physical phenomena. Our method leverages deep neural
networks and evolutionary optimization. Using a trained similarity function
that measures the difference between renderings of a phenomenon and real-world
photographs, our method optimizes rendering parameters. We demonstrate the
efficacy of our method using a superstorm simulation dataset and images found
online. We also discuss a parallel implementation of our method, which was run
on NCSA's Blue Waters.
"
887,Quasi-random Agents for Image Transition and Animation,"  Quasi-random walks show similar features as standard random walks, but with
much less randomness. We utilize this established model from discrete
mathematics and show how agents carrying out quasi-random walks can be used for
image transition and animation. The key idea is to generalize the notion of
quasi-random walks and let a set of autonomous agents perform quasi-random
walks painting an image. Each agent has one particular target image that they
paint when following a sequence of directions for their quasi-random walk. The
sequence can easily be chosen by an artist and allows them to produce a wide
range of different transition patterns and animations.
"
888,HDR image reconstruction from a single exposure using deep CNNs,"  Camera sensors can only capture a limited range of luminance simultaneously,
and in order to create high dynamic range (HDR) images a set of different
exposures are typically combined. In this paper we address the problem of
predicting information that have been lost in saturated image areas, in order
to enable HDR reconstruction from a single exposure. We show that this problem
is well-suited for deep learning algorithms, and propose a deep convolutional
neural network (CNN) that is specifically designed taking into account the
challenges in predicting HDR values. To train the CNN we gather a large dataset
of HDR images, which we augment by simulating sensor saturation for a range of
cameras. To further boost robustness, we pre-train the CNN on a simulated HDR
dataset created from a subset of the MIT Places database. We demonstrate that
our approach can reconstruct high-resolution visually convincing HDR results in
a wide range of situations, and that it generalizes well to reconstruction of
images captured with arbitrary and low-end cameras that use unknown camera
response functions and post-processing. Furthermore, we compare to existing
methods for HDR expansion, and show high quality results also for image based
lighting. Finally, we evaluate the results in a subjective experiment performed
on an HDR display. This shows that the reconstructed HDR images are visually
convincing, with large improvements as compared to existing methods.
"
889,Joint Material and Illumination Estimation from Photo Sets in the Wild,"  Faithful manipulation of shape, material, and illumination in 2D Internet
images would greatly benefit from a reliable factorization of appearance into
material (i.e., diffuse and specular) and illumination (i.e., environment
maps). On the one hand, current methods that produce very high fidelity
results, typically require controlled settings, expensive devices, or
significant manual effort. To the other hand, methods that are automatic and
work on 'in the wild' Internet images, often extract only low-frequency
lighting or diffuse materials. In this work, we propose to make use of a set of
photographs in order to jointly estimate the non-diffuse materials and sharp
lighting in an uncontrolled setting. Our key observation is that seeing
multiple instances of the same material under different illumination (i.e.,
environment), and different materials under the same illumination provide
valuable constraints that can be exploited to yield a high-quality solution
(i.e., specular materials and environment illumination) for all the observed
materials and environments. Similar constraints also arise when observing
multiple materials in a single environment, or a single material across
multiple environments. The core of this approach is an optimization procedure
that uses two neural networks that are trained on synthetic images to predict
good gradients in parametric space given observation of reflected light. We
evaluate our method on a range of synthetic and real examples to generate
high-quality estimates, qualitatively compare our results against
state-of-the-art alternatives via a user study, and demonstrate
photo-consistent image manipulation that is otherwise very challenging to
achieve.
"
890,B\'ezier curves that are close to elastica,"  We study the problem of identifying those cubic B\'ezier curves that are
close in the L2 norm to planar elastic curves. The problem arises in design
situations where the manufacturing process produces elastic curves; these are
difficult to work with in a digital environment. We seek a sub-class of special
B\'ezier curves as a proxy. We identify an easily computable quantity, which we
call the lambda-residual, that accurately predicts a small L2 distance. We then
identify geometric criteria on the control polygon that guarantee that a
B\'ezier curve has lambda-residual below 0.4, which effectively implies that
the curve is within 1 percent of its arc-length to an elastic curve in the L2
norm. Finally we give two projection algorithms that take an input B\'ezier
curve and adjust its length and shape, whilst keeping the end-points and
end-tangent angles fixed, until it is close to an elastic curve.
"
891,A Generative Model for Volume Rendering,"  We present a technique to synthesize and analyze volume-rendered images using
generative models. We use the Generative Adversarial Network (GAN) framework to
compute a model from a large collection of volume renderings, conditioned on
(1) viewpoint and (2) transfer functions for opacity and color. Our approach
facilitates tasks for volume analysis that are challenging to achieve using
existing rendering techniques such as ray casting or texture-based methods. We
show how to guide the user in transfer function editing by quantifying expected
change in the output image. Additionally, the generative model transforms
transfer functions into a view-invariant latent space specifically designed to
synthesize volume-rendered images. We use this space directly for rendering,
enabling the user to explore the space of volume-rendered images. As our model
is independent of the choice of volume rendering process, we show how to
analyze volume-rendered images produced by direct and global illumination
lighting, for a variety of volume datasets.
"
892,"Deep Illumination: Approximating Dynamic Global Illumination with
  Generative Adversarial Network","  We present Deep Illumination, a novel machine learning technique for
approximating global illumination (GI) in real-time applications using a
Conditional Generative Adversarial Network. Our primary focus is on generating
indirect illumination and soft shadows with offline rendering quality at
interactive rates. Inspired from recent advancement in image-to-image
translation problems using deep generative convolutional networks, we introduce
a variant of this network that learns a mapping from Gbuffers (depth map,
normal map, and diffuse map) and direct illumination to any global illumination
solution. Our primary contribution is showing that a generative model can be
used to learn a density estimation from screen space buffers to an advanced
illumination model for a 3D environment. Once trained, our network can
approximate global illumination for scene configurations it has never
encountered before within the environment it was trained on. We evaluate Deep
Illumination through a comparison with both a state of the art real-time GI
technique (VXGI) and an offline rendering GI technique (path tracing). We show
that our method produces effective GI approximations and is also
computationally cheaper than existing GI techniques. Our technique has the
potential to replace existing precomputed and screen-space techniques for
producing global illumination effects in dynamic scenes with physically-based
rendering quality.
"
893,"Approximation of Functions over Manifolds: A Moving Least-Squares
  Approach","  We present an algorithm for approximating a function defined over a
$d$-dimensional manifold utilizing only noisy function values at locations
sampled from the manifold with noise. To produce the approximation we do not
require any knowledge regarding the manifold other than its dimension $d$. We
use the Manifold Moving Least-Squares approach of (Sober and Levin 2016) to
reconstruct the atlas of charts and the approximation is built on-top of those
charts. The resulting approximant is shown to be a function defined over a
neighborhood of a manifold, approximating the originally sampled manifold. In
other words, given a new point, located near the manifold, the approximation
can be evaluated directly on that point. We prove that our construction yields
a smooth function, and in case of noiseless samples the approximation order is
$\mathcal{O}(h^{m+1})$, where $h$ is a local density of sample parameter (i.e.,
the fill distance) and $m$ is the degree of a local polynomial approximation,
used in our algorithm. In addition, the proposed algorithm has linear time
complexity with respect to the ambient-space's dimension. Thus, we are able to
avoid the computational complexity, commonly encountered in high dimensional
approximations, without having to perform non-linear dimension reduction, which
inevitably introduces distortions to the geometry of the data. Additionaly, we
show numerical experiments that the proposed approach compares favorably to
statistical approaches for regression over manifolds and show its potential.
"
894,Dynamic Influence Networks for Rule-based Models,"  We introduce the Dynamic Influence Network (DIN), a novel visual analytics
technique for representing and analyzing rule-based models of protein-protein
interaction networks. Rule-based modeling has proved instrumental in developing
biological models that are concise, comprehensible, easily extensible, and that
mitigate the combinatorial complexity of multi-state and multi-component
biological molecules. Our technique visualizes the dynamics of these rules as
they evolve over time. Using the data produced by KaSim, an open source
stochastic simulator of rule-based models written in the Kappa language, DINs
provide a node-link diagram that represents the influence that each rule has on
the other rules. That is, rather than representing individual biological
components or types, we instead represent the rules about them (as nodes) and
the current influence of these rules (as links). Using our interactive DIN-Viz
software tool, researchers are able to query this dynamic network to find
meaningful patterns about biological processes, and to identify salient aspects
of complex rule-based models. To evaluate the effectiveness of our approach, we
investigate a simulation of a circadian clock model that illustrates the
oscillatory behavior of the KaiC protein phosphorylation cycle.
"
895,Robust Statistics for Image Deconvolution,"  We present a blind multiframe image-deconvolution method based on robust
statistics. The usual shortcomings of iterative optimization of the likelihood
function are alleviated by minimizing the M-scale of the residuals, which
achieves more uniform convergence across the image. We focus on the
deconvolution of astronomical images, which are among the most challenging due
to their huge dynamic ranges and the frequent presence of large noise-dominated
regions in the images. We show that high-quality image reconstruction is
possible even in super-resolution and without the use of traditional
regularization terms. Using a robust \r{ho}-function is straightforward to
implement in a streaming setting and, hence our method is applicable to the
large volumes of astronomy images. The power of our method is demonstrated on
observations from the Sloan Digital Sky Survey (Stripe 82) and we briefly
discuss the feasibility of a pipeline based on Graphical Processing Units for
the next generation of telescope surveys.
"
896,"An Application of Mosaic Diagrams to the Visualization of Set
  Relationships","  We present an application of mosaic diagrams to the visualisation of set
relations. Venn and Euler diagrams are the best known visual representations of
sets and their relationships (intersections, containment or subsets, exclusion
or disjointness). In recent years, alternative forms of visualisation have been
proposed. Among them, linear diagrams have been shown to compare favourably to
Venn and Euler diagrams, in supporting non-interactive assessment of set
relationships. Recent studies that compared several variants of linear diagrams
have demonstrated that users perform best at tasks involving identification of
intersections, disjointness and subsets when using a horizontally drawn linear
diagram with thin lines representing sets, and employing vertical lines as
guide lines. The essential visual task the user needs to perform in order to
interpret this kind of diagram is vertical alignment of parallel lines and
detection of overlaps. Space-filling mosaic diagrams which support this same
visual task have been used in other applications, such as the visualization of
schedules of activities, where they have been shown to be superior to linear
Gantt charts. In this paper, we present an application of mosaic diagrams for
visualization of set relationships, and compare it to linear diagrams in terms
of accuracy, time-to-answer, and subjective ratings of perceived task
difficulty. The study participants exhibited similar performance on both
visualisations, suggesting that mosaic diagrams are a good alternative to Venn
and Euler diagrams, and that the choice between linear diagrams and mosaics may
be solely guided by visual design considerations.
"
897,"Hydra: An Accelerator for Real-Time Edge-Aware Permeability Filtering in
  65nm CMOS","  Many modern video processing pipelines rely on edge-aware (EA) filtering
methods. However, recent high-quality methods are challenging to run in
real-time on embedded hardware due to their computational load. To this end, we
propose an area-efficient and real-time capable hardware implementation of a
high quality EA method. In particular, we focus on the recently proposed
permeability filter (PF) that delivers promising quality and performance in the
domains of HDR tone mapping, disparity and optical flow estimation. We present
an efficient hardware accelerator that implements a tiled variant of the PF
with low on-chip memory requirements and a significantly reduced external
memory bandwidth (6.4x w.r.t. the non-tiled PF). The design has been taped out
in 65 nm CMOS technology, is able to filter 720p grayscale video at 24.8 Hz and
achieves a high compute density of 6.7 GFLOPS/mm2 (12x higher than embedded
GPUs when scaled to the same technology node). The low area and bandwidth
requirements make the accelerator highly suitable for integration into SoCs
where silicon area budget is constrained and external memory is typically a
heavily contended resource.
"
898,Self-Supervised Intrinsic Image Decomposition,"  Intrinsic decomposition from a single image is a highly challenging task, due
to its inherent ambiguity and the scarcity of training data. In contrast to
traditional fully supervised learning approaches, in this paper we propose
learning intrinsic image decomposition by explaining the input image. Our
model, the Rendered Intrinsics Network (RIN), joins together an image
decomposition pipeline, which predicts reflectance, shape, and lighting
conditions given a single image, with a recombination function, a learned
shading model used to recompose the original input based off of intrinsic image
predictions. Our network can then use unsupervised reconstruction error as an
additional signal to improve its intermediate representations. This allows
large-scale unlabeled data to be useful during training, and also enables
transferring learned knowledge to images of unseen object categories, lighting
conditions, and shapes. Extensive experiments demonstrate that our method
performs well on both intrinsic image decomposition and knowledge transfer.
"
899,"Software for full-color 3D reconstruction of the biological tissues
  internal structure","  A software for processing sets of full-color images of biological tissue
histological sections is developed. We used histological sections obtained by
the method of high-precision layer-by-layer grinding of frozen biological
tissues. The software allows restoring the image of the tissue for an arbitrary
cross-section of the tissue sample. Thus, our method is designed to create a
full-color 3D reconstruction of the biological tissue structure. The resolution
of 3D reconstruction is determined by the quality of the initial histological
sections. The newly developed technology available to us provides a resolution
of up to 5 - 10 {\mu}m in three dimensions.
"
900,"Full-Body Locomotion Reconstruction of Virtual Characters Using a Single
  IMU","  This paper presents a method of reconstructing full-body locomotion sequences
for virtual characters in real-time, using data from a single inertial
measurement unit (IMU). This process can be characterized by its difficulty
because of the need to reconstruct a high number of degrees of freedom (DOFs)
from a very low number of DOFs. To solve such a complex problem, the presented
method is divided into several steps. The user's full-body locomotion and the
IMU's data are recorded simultaneously. Then, the data is preprocessed in such
a way that would be handled more efficiently. By developing a hierarchical
multivariate hidden Markov model with reactive interpolation functionality the
system learns the structure of the motion sequences. Specifically, the phases
of the locomotion sequence are assigned in the higher hierarchical level, and
the frame structure of the motion sequences are assigned at the lower
hierarchical level. During the runtime of the method, the forward algorithm is
used for reconstructing the full-body motion of a virtual character. Firstly,
the method predicts the phase where the input motion belongs (higher
hierarchical level). Secondly, the method predicts the closest trajectories and
their progression and interpolates the most probable of them to reconstruct the
virtual character's full-body motion (lower hierarchical level). Evaluating the
proposed method shows that it works on reasonable framerates and minimizes the
reconstruction errors compared with previous approaches.
"
901,"Overlaying Quantitative Measurement on Networks: An Evaluation of Three
  Positioning and Nine Visual Marker Techniques","  We report results from an experiment on ranking visual markers and node
positioning techniques for network visualizations. Inspired by prior ranking
studies, we rethink the ranking when the dataset size increases and when the
markers are distributed in space. Centrality indices are visualized as node
attributes. Our experiment studies nine visual markers and three positioning
methods. Our results suggest that direct encoding of quantities improves
accuracy by about 20% compared to previous results. Of the three positioning
techniques, circular was always in the top group, and matrix and projection
switch orders depending on two factors: whether or not the tasks demand
symmetry, or the nodes are within closely proximity. Among the most interesting
results of ranking the visual markers for comparison tasks are that hue and
area fall into the top groups for nearly all multi-scale comparison tasks;
Shape (ordered by curvature) is perhaps not as scalable as we have thought and
can support more accurate answers only when two quantities are compared;
Lightness and slope are least accurate for quantitative comparisons regardless
of scale of the comparison tasks. Our experiment is among the first to acquire
a complete picture of ranking visual markers in different scales for comparison
tasks.
"
902,"Vertebral body segmentation with GrowCut: Initial experience, workflow
  and practical application","  In this contribution, we used the GrowCut segmentation algorithm publicly
available in three-dimensional Slicer for three-dimensional segmentation of
vertebral bodies. To the best of our knowledge, this is the first time that the
GrowCut method has been studied for the usage of vertebral body segmentation.
In brief, we found that the GrowCut segmentation times were consistently less
than the manual segmentation times. Hence, GrowCut provides an alternative to a
manual slice-by-slice segmentation process.
"
903,Analytic Methods for Geometric Modeling via Spherical Decomposition,"  Analytic methods are emerging in solid and configuration modeling, while
providing new insights into a variety of shape and motion related problems by
exploiting tools from group morphology, convolution algebras, and harmonic
analysis. However, most convolution-based methods have used uniform grid-based
sampling to take advantage of the fast Fourier transform (FFT) algorithm. We
propose a new paradigm for more efficient computation of analytic correlations
that relies on a grid-free discretization of arbitrary shapes as countable
unions of balls, in turn described as sublevel sets of summations of smooth
radial kernels at adaptively sampled 'knots'. Using a simple geometric lifting
trick, we interpret this combination as a convolution of an impulsive skeletal
density and primitive kernels with conical support, which faithfully embeds
into the convolution formulation of interactions across different objects. Our
approach enables fusion of search-efficient combinatorial data structures
prevalent in time-critical collision and proximity queries with analytic
methods popular in path planning and protein docking, and outperforms uniform
grid-based FFT methods by leveraging nonequispaced FFTs. We provide example
applications in formulating holonomic collision constraints, shape
complementarity metrics, and morphological operations, unified within a single
analytic framework.
"
904,Robust and High Fidelity Mesh Denoising,"  This paper presents a simple and effective two-stage mesh denoising
algorithm, where in the first stage, the face normal filtering is done by using
the bilateral normal filtering in the robust statistics framework. Tukey's
bi-weight function is used as similarity function in the bilateral weighting,
which is a robust estimator and stops the diffusion at sharp edges to retain
features and removes noise from flat regions effectively. In the second stage,
an edge weighted Laplace operator is introduced to compute a differential
coordinate. This differential coordinate helps the algorithm to produce a
high-quality mesh without any face normal flips and makes the method robust
against high-intensity noise.
"
905,Solving Poisson's Equation on the Microsoft HoloLens,"  We present a mixed reality application (HoloFEM) for the Microsoft HoloLens.
The application lets a user define and solve a physical problem governed by
Poisson's equation with the surrounding real world geometry as input data.
Holograms are used to visualise both the problem and the solution. The finite
element method is used to solve Poisson's equation. Solving and visualising
partial differential equations in mixed reality could have potential usage in
areas such as building planning and safety engineering.
"
906,Optimized Visibility Functions for Revectorization-Based Shadow Mapping,"  High-quality shadow anti-aliasing is a challenging problem in shadow mapping.
Revectorization-based shadow mapping (RBSM) minimizes shadow aliasing by
revectorizing the jagged shadow edges generated with shadow mapping, keeping
low memory footprint and real-time performance for the shadow computation.
However, the current implementation of RBSM is not so well optimized because
its visibility functions are composed of a set of 43 cases, each one of them
handling a specific revectorization scenario and being implemented as a
specific branch in the shader. Here, we take advantage of the shadow shape
patterns to reformulate the RBSM visibility functions, simplifying the
implementation of the technique and further providing an optimized version of
the RBSM. Our results indicate that our implementation runs faster than the
original implementation of RBSM, while keeping its same visual quality and
memory consumption. Furthermore, we show GLSL source codes to ease the
implementation of our technique, provide a comparison between the optimized
RBSM and related work, and discuss the limitations of the shadow
revectorization.
"
907,"Photometric Stereo by UV-Induced Fluorescence to Detect Protrusions on
  Georgia O'Keeffe's Paintings","  A significant number of oil paintings produced by Georgia O'Keeffe
(1887-1986) show surface protrusions of varying width, up to several hundreds
of microns. These protrusions are similar to those described in the art
conservation literature as metallic soaps. Since the presence of these
protrusions raises questions about the state of conservation and long-term
prospects for deterioration of these artworks, a 3D-imaging technique,
photometric stereo using ultraviolet illumination, was developed for the
long-term monitoring of the surface-shape of the protrusions and the
surrounding paint. Because the UV fluorescence response of painting materials
is isotropic, errors typically caused by non-Lambertian (anisotropic)
specularities when using visible reflected light can be avoided providing a
more accurate estimation of shape. As an added benefit, fluorescence provides
additional contrast information contributing to materials characterization. The
developed methodology aims to detect, characterize, and quantify the
distribution of micro-protrusions and their development over the surface of
entire artworks. Combined with a set of analytical in-situ techniques, and
computational tools, this approach constitutes a novel methodology to
investigate the selective distribution of protrusions in correlation with the
composition of painting materials at the macro-scale. While focused on
O'Keeffe's paintings as a case study, we expect the proposed approach to have
broader significance by providing a non-invasive protocol to the conservation
community to probe topological changes for any relatively flat painted surface
of an artwork, and more specifically to monitor the dynamic formation of
protrusions, in relation to paint composition and modifications of
environmental conditions, loans, exhibitions and storage over the long-term.
"
908,Cascaded 3D Full-body Pose Regression from Single Depth Image at 100 FPS,"  There are increasing real-time live applications in virtual reality, where it
plays an important role in capturing and retargetting 3D human pose. But it is
still challenging to estimate accurate 3D pose from consumer imaging devices
such as depth camera. This paper presents a novel cascaded 3D full-body pose
regression method to estimate accurate pose from a single depth image at 100
fps. The key idea is to train cascaded regressors based on Gradient Boosting
algorithm from pre-recorded human motion capture database. By incorporating
hierarchical kinematics model of human pose into the learning procedure, we can
directly estimate accurate 3D joint angles instead of joint positions. The
biggest advantage of this model is that the bone length can be preserved during
the whole 3D pose estimation procedure, which leads to more effective features
and higher pose estimation accuracy. Our method can be used as an
initialization procedure when combining with tracking methods. We demonstrate
the power of our method on a wide range of synthesized human motion data from
CMU mocap database, Human3.6M dataset and real human movements data captured in
real time. In our comparison against previous 3D pose estimation methods and
commercial system such as Kinect 2017, we achieve the state-of-the-art
accuracy.
"
909,"Visual Analytics of Group Differences in Tensor Fields: Application to
  Clinical DTI","  We present a visual analytics system for exploring group differences in
tensor fields with respect to all six degrees of freedom that are inherent in
symmetric second-order tensors. Our framework closely integrates quantitative
analysis, based on multivariate hypothesis testing and spatial cluster
enhancement, with suitable visualization tools that facilitate interpretation
of results, and forming of new hypotheses. Carefully chosen and linked spatial
and abstract views show clusters of strong differences, and allow the analyst
to relate them to the affected structures, to reveal the exact nature of the
differences, and to investigate potential correlations. A mechanism for
visually comparing the results of different tests or levels of smoothing is
also provided.
  We carefully justify the need for such a visual analytics tool from a
practical and theoretical point of view. In close collaboration with our
clinical co-authors, we apply it to the results of a diffusion tensor imaging
study of systemic lupus erythematosus, in which it revealed previously unknown
group differences.
"
910,A Gamut-Mapping Framework for Color-Accurate Reproduction of HDR Images,"  Few tone mapping operators (TMOs) take color management into consideration,
limiting compression to luminance values only. This may lead to changes in
image chroma and hues which are typically managed with a post-processing step.
However, current post-processing techniques for tone reproduction do not
explicitly consider the target display gamut. Gamut mapping on the other hand,
deals with mapping images from one color gamut to another, usually smaller,
gamut but has traditionally focused on smaller scale, chromatic changes. In
this context, we present a novel gamut and tone management framework for
color-accurate reproduction of high dynamic range (HDR) images, which is
conceptually and computationally simple, parameter-free, and compatible with
existing TMOs. In the CIE LCh color space, we compress chroma to fit the gamut
of the output color space. This prevents hue and luminance shifts while taking
gamut boundaries into consideration. We also propose a compatible lightness
compression scheme that minimizes the number of color space conversions. Our
results show that our gamut management method effectively compresses the chroma
of tone mapped images, respecting the target gamut and without reducing image
quality.
"
911,Deep High Dynamic Range Imaging with Large Foreground Motions,"  This paper proposes the first non-flow-based deep framework for high dynamic
range (HDR) imaging of dynamic scenes with large-scale foreground motions. In
state-of-the-art deep HDR imaging, input images are first aligned using optical
flows before merging, which are still error-prone due to occlusion and large
motions. In stark contrast to flow-based methods, we formulate HDR imaging as
an image translation problem without optical flows. Moreover, our simple
translation network can automatically hallucinate plausible HDR details in the
presence of total occlusion, saturation and under-exposure, which are otherwise
almost impossible to recover by conventional optimization approaches. Our
framework can also be extended for different reference images. We performed
extensive qualitative and quantitative comparisons to show that our approach
produces excellent results where color artifacts and geometric distortions are
significantly reduced compared to existing state-of-the-art methods, and is
robust across various inputs, including images without radiometric calibration.
"
912,Visual Subpopulation Discovery and Validation in Cohort Study Data,"  Epidemiology aims at identifying subpopulations of cohort participants that
share common characteristics (e.g. alcohol consumption) to explain risk factors
of diseases in cohort study data. These data contain information about the
participants' health status gathered from questionnaires, medical examinations,
and image acquisition. Due to the growing volume and heterogeneity of
epidemiological data, the discovery of meaningful subpopulations is
challenging. Subspace clustering can be leveraged to find subpopulations in
large and heterogeneous cohort study datasets. In our collaboration with
epidemiologists, we realized their need for a tool to validate discovered
subpopulations. For this purpose, identified subpopulations should be searched
for independent cohorts to check whether the findings apply there as well. In
this paper we describe our interactive Visual Analytics framework S-ADVIsED for
SubpopulAtion Discovery and Validation In Epidemiological Data. S-ADVIsED
enables epidemiologists to explore and validate findings derived from subspace
clustering. We provide a coordinated multiple view system, which includes a
summary view of all subpopulations, detail views, and statistical information.
Users can assess the quality of subspace clusters by considering different
criteria via visualization. Furthermore, intervals for variables involved in a
subspace cluster can be adjusted. This extension was suggested by
epidemiologists. We investigated the replication of a selected subpopulation
with multiple variables in another population by considering different
measurements. As a specific result, we observed that study participants
exhibiting high liver fat accumulation deviate strongly from other
subpopulations and from the total study population with respect to age, body
mass index, thyroid volume and thyroid-stimulating hormone.
"
913,Compression for Smooth Shape Analysis,"  Most 3D shape analysis methods use triangular meshes to discretize both the
shape and functions on it as piecewise linear functions. With this
representation, shape analysis requires fine meshes to represent smooth shapes
and geometric operators like normals, curvatures, or Laplace-Beltrami
eigenfunctions at large computational and memory costs.
  We avoid this bottleneck with a compression technique that represents a
smooth shape as subdivision surfaces and exploits the subdivision scheme to
parametrize smooth functions on that shape with a few control parameters. This
compression does not affect the accuracy of the Laplace-Beltrami operator and
its eigenfunctions and allow us to compute shape descriptors and shape
matchings at an accuracy comparable to triangular meshes but a fraction of the
computational cost.
  Our framework can also compress surfaces represented by point clouds to do
shape analysis of 3D scanning data.
"
914,Automatic Generation of Constrained Furniture Layouts,"  Efficient authoring of vast virtual environments hinges on algorithms that
are able to automatically generate content while also being controllable. We
propose a method to automatically generate furniture layouts for indoor
environments. Our method is simple, efficient, human-interpretable and amenable
to a wide variety of constraints. We model the composition of rooms into
classes of objects and learn joint (co-occurrence) statistics from a database
of training layouts. We generate new layouts by performing a sequence of
conditional sampling steps, exploiting the statistics learned from the
database. The generated layouts are specified as 3D object models, along with
their positions and orientations. We show they are of equivalent perceived
quality to the training layouts, and compare favorably to a state-of-the-art
method. We incorporate constraints using a general mechanism -- rejection
sampling -- which provides great flexibility at the cost of extra computation.
We demonstrate the versatility of our method by applying a wide variety of
constraints relevant to real-world applications.
"
915,A Novel Image-centric Approach Towards Direct Volume Rendering,"  Transfer Function (TF) generation is a fundamental problem in Direct Volume
Rendering (DVR). A TF maps voxels to color and opacity values to reveal inner
structures. Existing TF tools are complex and unintuitive for the users who are
more likely to be medical professionals than computer scientists. In this
paper, we propose a novel image-centric method for TF generation where instead
of complex tools, the user directly manipulates volume data to generate DVR.
The user's work is further simplified by presenting only the most informative
volume slices for selection. Based on the selected parts, the voxels are
classified using our novel Sparse Nonparametric Support Vector Machine
classifier, which combines both local and near-global distributional
information of the training data. The voxel classes are mapped to aesthetically
pleasing and distinguishable color and opacity values using harmonic colors.
Experimental results on several benchmark datasets and a detailed user survey
show the effectiveness of the proposed method.
"
916,High Dynamic Range Imaging Technology,"  In this lecture note, we describe high dynamic range (HDR) imaging systems;
such systems are able to represent luminances of much larger brightness and,
typically, also a larger range of colors than conventional standard dynamic
range (SDR) imaging systems. The larger luminance range greatly improve the
overall quality of visual content, making it appears much more realistic and
appealing to observers. HDR is one of the key technologies of the future
imaging pipeline, which will change the way the digital visual content is
represented and manipulated today.
"
917,"Constraint Bubbles: Adding Efficient Zero-Density Bubbles to
  Incompressible Free Surface Flow","  Liquid simulations for computer animation often avoid simulating the air
phase to reduce computational costs and ensure good conditioning of the linear
systems required to enforce incompressibility. However, this free surface
assumption leads to an inability to realistically treat bubbles: submerged gaps
in the liquid are interpreted as empty voids that immediately collapse. To
address this shortcoming, we present an efficient, practical, and conceptually
simple approach to augment free surface flows with negligible density bubbles.
Our method adds a new constraint to each disconnected air region that
guarantees zero net flux across its entire surface, and requires neither
simulating both phases nor reformulating into stream function variables.
Implementation of the method requires only minor modifications to the pressure
solve of a standard grid-based fluid solver, and yields linear systems that
remain sparse and symmetric positive definite. In our evaluations, solving the
modified pressure projection system took no more than 10% longer than the
corresponding free surface solve. We demonstrate the method's effectiveness and
flexibility by incorporating it into commercial fluid animation software and
using it to generate a variety of dynamic bubble scenarios showcasing glugging
effects, viscous and inviscid bubbles, interactions with irregularly-shaped and
moving solid boundaries, and surface tension effects.
"
918,"High-Resolution Image Synthesis and Semantic Manipulation with
  Conditional GANs","  We present a new method for synthesizing high-resolution photo-realistic
images from semantic label maps using conditional generative adversarial
networks (conditional GANs). Conditional GANs have enabled a variety of
applications, but the results are often limited to low-resolution and still far
from realistic. In this work, we generate 2048x1024 visually appealing results
with a novel adversarial loss, as well as new multi-scale generator and
discriminator architectures. Furthermore, we extend our framework to
interactive visual manipulation with two additional features. First, we
incorporate object instance segmentation information, which enables object
manipulations such as removing/adding objects and changing the object category.
Second, we propose a method to generate diverse results given the same input,
allowing users to edit the object appearance interactively. Human opinion
studies demonstrate that our method significantly outperforms existing methods,
advancing both the quality and the resolution of deep image synthesis and
editing.
"
919,Toward Multimodal Image-to-Image Translation,"  Many image-to-image translation problems are ambiguous, as a single input
image may correspond to multiple possible outputs. In this work, we aim to
model a \emph{distribution} of possible outputs in a conditional generative
modeling setting. The ambiguity of the mapping is distilled in a
low-dimensional latent vector, which can be randomly sampled at test time. A
generator learns to map the given input, combined with this latent code, to the
output. We explicitly encourage the connection between output and the latent
code to be invertible. This helps prevent a many-to-one mapping from the latent
code to the output during training, also known as the problem of mode collapse,
and produces more diverse results. We explore several variants of this approach
by employing different training objectives, network architectures, and methods
of injecting the latent code. Our proposed method encourages bijective
consistency between the latent encoding and output modes. We present a
systematic comparison of our method and other variants on both perceptual
realism and diversity.
"
920,Shape Complementarity Analysis for Objects of Arbitrary Shape,"  The basic problem of shape complementarity analysis appears fundamental to
applications as diverse as mechanical design, assembly automation, robot motion
planning, micro- and nano-fabrication, protein-ligand binding, and rational
drug design. However, the current challenge lies in the lack of a general
mathematical formulation that applies to objects of arbitrary shape. We propose
that a measure of shape complementarity can be obtained from the extent of
approximate overlap between shape skeletons. A space-continuous implicit
generalization of the skeleton, called the skeletal density function (SDF) is
defined over the Euclidean space that contains the individual assembly
partners. The SDF shape descriptors capture the essential features that are
relevant to proper contact alignment, and are considerably more robust than the
conventional explicit skeletal representations. We express the shape
complementarity score as a convolution of the individual SDFs. The problem then
breaks down to a global optimization of the score over the configuration space
of spatial relations, which can be efficiently implemented using fast Fourier
transforms (FFTs) on nonequispaced samples. We demonstrate the effectiveness of
the scoring approach for several examples from 2D peg-in-hole alignment to more
complex 3D examples in mechanical assembly and protein docking. We show that
the proposed method is reliable, inherently robust against small perturbations,
and effective in steering gradient-based optimization.
"
921,Haptic Assembly and Prototyping: An Expository Review,"  An important application of haptic technology to digital product development
is in virtual prototyping (VP), part of which deals with interactive planning,
simulation, and verification of assembly-related activities, collectively
called virtual assembly (VA). In spite of numerous research and development
efforts over the last two decades, the industrial adoption of haptic-assisted
VP/VA has been slower than expected. Putting hardware limitations aside, the
main roadblocks faced in software development can be traced to the lack of
effective and efficient computational models of haptic feedback. Such models
must 1) accommodate the inherent geometric complexities faced when assembling
objects of arbitrary shape; and 2) conform to the computation time limitation
imposed by the notorious frame rate requirements---namely, 1 kHz for haptic
feedback compared to the more manageable 30-60 Hz for graphic rendering. The
simultaneous fulfillment of these competing objectives is far from trivial.
  This survey presents some of the conceptual and computational challenges and
opportunities as well as promising future directions in haptic-assisted VP/VA,
with a focus on haptic assembly from a geometric modeling and spatial reasoning
perspective. The main focus is on revisiting definitions and classifications of
different methods used to handle the constrained multibody simulation in
real-time, ranging from physics-based and geometry-based to hybrid and unified
approaches using a variety of auxiliary computational devices to specify,
impose, and solve assembly constraints. Particular attention is given to the
newly developed 'analytic methods' inherited from motion planning and protein
docking that have shown great promise as an alternative paradigm to the more
popular combinatorial methods.
"
922,"Fuzzy-Based Dialectical Non-Supervised Image Classification and
  Clustering","  The materialist dialectical method is a philosophical investigative method to
analyze aspects of reality. These aspects are viewed as complex processes
composed by basic units named poles, which interact with each other. Dialectics
has experienced considerable progress in the 19th century, with Hegel's
dialectics and, in the 20th century, with the works of Marx, Engels, and
Gramsci, in Philosophy and Economics. The movement of poles through their
contradictions is viewed as a dynamic process with intertwined phases of
evolution and revolutionary crisis. In order to build a computational process
based on dialectics, the interaction between poles can be modeled using fuzzy
membership functions. Based on this assumption, we introduce the Objective
Dialectical Classifier (ODC), a non-supervised map for classification based on
materialist dialectics and designed as an extension of fuzzy c-means
classifier. As a case study, we used ODC to classify 181 magnetic resonance
synthetic multispectral images composed by proton density, $T_1$- and
$T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means,
and Kohonen's self-organized maps, concerning with image fidelity indexes as
estimatives of quantization distortion, we proved that ODC can reach almost the
same quantization performance as optimal non-supervised classifiers like
Kohonen's self-organized maps.
"
923,"Dialectical Multispectral Classification of Diffusion-Weighted Magnetic
  Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to
  Perform Anatomical Analysis","  Multispectral image analysis is a relatively promising field of research with
applications in several areas, such as medical imaging and satellite
monitoring. A considerable number of current methods of analysis are based on
parametric statistics. Alternatively, some methods in Computational
Intelligence are inspired by biology and other sciences. Here we claim that
Philosophy can be also considered as a source of inspiration. This work
proposes the Objective Dialectical Method (ODM): a method for classification
based on the Philosophy of Praxis. ODM is instrumental in assembling evolvable
mathematical tools to analyze multispectral images. In the case study described
in this paper, multispectral images are composed of diffusion-weighted (DW)
magnetic resonance (MR) images. The results are compared to ground-truth images
produced by polynomial networks using a morphological similarity index. The
classification results are used to improve the usual analysis of the apparent
diffusion coefficient map. Such results proved that gray and white matter can
be distinguished in DW-MR multispectral analysis and, consequently, DW-MR
images can also be used to furnish anatomical information.
"
924,"Bivariate Separable-Dimension Glyphs can Improve Visual Analysis of
  Holistic Features","  We introduce the cause of the inefficiency of bivariate glyphs by defining
the corresponding error. To recommend efficient and perceptually accurate
bivariate-glyph design, we present an empirical study of five bivariate glyphs
based on three psychophysics principles: integral-separable dimensions, visual
hierarchy, and pre-attentive pop out, to choose one integral pair
($length_y-length_x$), three separable pairs ($length-color$, $length-texture$,
$length_y-length_y$), and one redundant pair ($length_y-color/length_x$).
Twenty participants performed four tasks requiring: reading numerical values,
estimating ratio, comparing two points, and looking for extreme values among a
subset of points belonging to the same sub-group. The most surprising result
was that $length-texture$ was among the most effective methods, suggesting that
local spatial frequency features can lead to global pattern detection that
facilitate visual search in complex 3D structure. Our results also reveal the
following: $length-color$ bivariate glyphs led to the most accurate answers and
the least task execution time, while $length_y-length_x$ (integral) dimensions
were among the worst and is not recommended; it achieved high performance only
when pop-up color was added.
"
925,Adversarial Examples that Fool Detectors,"  An adversarial example is an example that has been adjusted to produce a
wrong label when presented to a system at test time. To date, adversarial
example constructions have been demonstrated for classifiers, but not for
detectors. If adversarial examples that could fool a detector exist, they could
be used to (for example) maliciously create security hazards on roads populated
with smart vehicles. In this paper, we demonstrate a construction that
successfully fools two standard detectors, Faster RCNN and YOLO. The existence
of such examples is surprising, as attacking a classifier is very different
from attacking a detector, and that the structure of detectors - which must
search for their own bounding box, and which cannot estimate that box very
accurately - makes it quite likely that adversarial patterns are strongly
disrupted. We show that our construction produces adversarial examples that
generalize well across sequences digitally, even though large perturbations are
needed. We also show that our construction yields physical objects that are
adversarial.
"
926,A Deep Recurrent Framework for Cleaning Motion Capture Data,"  We present a deep, bidirectional, recurrent framework for cleaning noisy and
incomplete motion capture data. It exploits temporal coherence and joint
correlations to infer adaptive filters for each joint in each frame. A single
model can be trained to denoise a heterogeneous mix of action types, under
substantial amounts of noise. A signal that has both noise and gaps is
preprocessed with a second bidirectional network that synthesizes missing
frames from surrounding context. The approach handles a wide variety of noise
types and long gaps, does not rely on knowledge of the noise distribution, and
operates in a streaming setting. We validate our approach through extensive
evaluations on noise both in joint angles and in joint positions, and show that
it improves upon various alternatives.
"
927,Static/Dynamic Filtering for Mesh Geometry,"  The joint bilateral filter, which enables feature-preserving signal smoothing
according to the structural information from a guidance, has been applied for
various tasks in geometry processing. Existing methods either rely on a static
guidance that may be inconsistent with the input and lead to unsatisfactory
results, or a dynamic guidance that is automatically updated but sensitive to
noises and outliers. Inspired by recent advances in image filtering, we propose
a new geometry filtering technique called static/dynamic filter, which utilizes
both static and dynamic guidances to achieve state-of-the-art results. The
proposed filter is based on a nonlinear optimization that enforces smoothness
of the signal while preserving variations that correspond to features of
certain scales. We develop an efficient iterative solver for the problem, which
unifies existing filters that are based on static or dynamic guidances. The
filter can be applied to mesh face normals followed by vertex position update,
to achieve scale-aware and feature-preserving filtering of mesh geometry. It
also works well for other types of signals defined on mesh surfaces, such as
texture colors. Extensive experimental results demonstrate the effectiveness of
the proposed filter for various geometry processing applications such as mesh
denoising, geometry feature enhancement, and texture color filtering.
"
928,"A practical guide and software for analysing pairwise comparison
  experiments","  Most popular strategies to capture subjective judgments from humans involve
the construction of a unidimensional relative measurement scale, representing
order preferences or judgments about a set of objects or conditions. This
information is generally captured by means of direct scoring, either in the
form of a Likert or cardinal scale, or by comparative judgments in pairs or
sets. In this sense, the use of pairwise comparisons is becoming increasingly
popular because of the simplicity of this experimental procedure. However, this
strategy requires non-trivial data analysis to aggregate the comparison ranks
into a quality scale and analyse the results, in order to take full advantage
of the collected data. This paper explains the process of translating pairwise
comparison data into a measurement scale, discusses the benefits and
limitations of such scaling methods and introduces a publicly available
software in Matlab. We improve on existing scaling methods by introducing
outlier analysis, providing methods for computing confidence intervals and
statistical testing and introducing a prior, which reduces estimation error
when the number of observers is low. Most of our examples focus on image
quality assessment.
"
929,"MINOS: Multimodal Indoor Simulator for Navigation in Complex
  Environments","  We present MINOS, a simulator designed to support the development of
multisensory models for goal-directed navigation in complex indoor
environments. The simulator leverages large datasets of complex 3D environments
and supports flexible configuration of multimodal sensor suites. We use MINOS
to benchmark deep-learning-based navigation methods, to analyze the influence
of environmental complexity on navigation performance, and to carry out a
controlled study of multimodality in sensorimotor learning. The experiments
show that current deep reinforcement learning approaches fail in large
realistic environments. The experiments also indicate that multimodality is
beneficial in learning to navigate cluttered scenes. MINOS is released
open-source to the research community at http://minosworld.org . A video that
shows MINOS can be found at https://youtu.be/c0mL9K64q84
"
930,Continuous Optimization of Adaptive Quadtree Structures,"  We present a novel continuous optimization method to the discrete problem of
quadtree optimization. The optimization aims at achieving a quadtree structure
with the highest mechanical stiffness, where the edges in the quadtree are
interpreted as structural elements carrying mechanical loads. We formulate
quadtree optimization as a continuous material distribution problem. The
discrete design variables (i.e., to refine or not to refine) are replaced by
continuous variables on multiple levels in the quadtree hierarchy. In discrete
quadtree optimization, a cell is only eligible for refinement if its parent
cell has been refined. We propose a continuous analogue to this dependency for
continuous multi-level design variables, and integrate it in the iterative
optimization process. Our results show that the continuously optimized quadtree
structures perform much stiffer than uniform patterns and the heuristically
optimized counterparts. We demonstrate the use of adaptive structures as
lightweight infill for 3D printed parts, where uniform geometric patterns have
been typically used in practice.
"
931,Persistent Homology Guided Force-Directed Graph Layouts,"  Graphs are commonly used to encode relationships among entities, yet their
abstractness makes them difficult to analyze. Node-link diagrams are popular
for drawing graphs, and force-directed layouts provide a flexible method for
node arrangements that use local relationships in an attempt to reveal the
global shape of the graph. However, clutter and overlap of unrelated structures
can lead to confusing graph visualizations. This paper leverages the persistent
homology features of an undirected graph as derived information for interactive
manipulation of force-directed layouts. We first discuss how to efficiently
extract 0-dimensional persistent homology features from both weighted and
unweighted undirected graphs. We then introduce the interactive persistence
barcode used to manipulate the force-directed graph layout. In particular, the
user adds and removes contracting and repulsing forces generated by the
persistent homology features, eventually selecting the set of persistent
homology features that most improve the layout. Finally, we demonstrate the
utility of our approach across a variety of synthetic and real datasets.
"
932,"graphTPP: A multivariate based method for interactive graph layout and
  analysis","  Graph layout is the process of creating a visual representation of a graph
through a node-link diagram. Node-attribute graphs have additional data stored
on the nodes which describe certain properties of the nodes called attributes.
Typical force-directed representations often produce hairball-like structures
that neither aid in understanding the graph's topology nor the relationship to
its attributes. The aim of this research was to investigate the use of
node-attributes for graph layout in order to improve the analysis process and
to give further insight into the graph over purely topological layouts. In this
article we present graphTPP, a graph based extension to targeted projection
pursuit (TPP) --- an interactive, linear, dimension reduction technique --- as
a method for graph layout and subsequent further analysis. TPP allows users to
control the projection and is optimised for clustering. Three case studies were
conducted in the areas of influence graphs, network security, and citation
networks. In each case graphTPP was shown to outperform standard force-directed
techniques and even other dimension reduction methods in terms of clarity of
clustered structure in the layout, the association between the structure and
the attributes and the insights elicited in each domain area.
"
933,Integral Equations and Machine Learning,"  As both light transport simulation and reinforcement learning are ruled by
the same Fredholm integral equation of the second kind, reinforcement learning
techniques may be used for photorealistic image synthesis: Efficiency may be
dramatically improved by guiding light transport paths by an approximate
solution of the integral equation that is learned during rendering. In the
light of the recent advances in reinforcement learning for playing games, we
investigate the representation of an approximate solution of an integral
equation by artificial neural networks and derive a loss function for that
purpose. The resulting Monte Carlo and quasi-Monte Carlo methods train neural
networks with standard information instead of linear information and naturally
are able to generate an arbitrary number of training samples. The methods are
demonstrated for applications in light transport simulation.
"
934,Graphic Narrative with Interactive Stylization Design,"  We present a system to convert any set of images (e.g., a video clip or a
photo album) into a storyboard. We aim to create multiple pleasing graphic
representations of the content at interactive rates, so the user can explore
and find the storyboard (images, layout, and stylization) that best suits their
needs and taste. The main challenges of this work are: selecting the content
images, placing them into panels, and applying a stylization. For the latter,
we propose an interactive design tool to create new stylizations using a wide
range of filter blocks. This approach unleashes the creativity by allowing the
user to tune, modify, and intuitively design new sequences of filters. In
parallel to this manual design, we propose a novel procedural approach that
automatically assembles sequences of filters for innovative results. We aim to
keep the algorithm complexity as low as possible such that it can run
interactively on a mobile device. Our results include examples of styles
designed using both our interactive and procedural tools, as well as their
final composition into interesting and appealing storyboards.
"
935,"On the one method of a third-degree bezier type spline curve
  construction","  A method is proposed for constructing a spline curve of the Bezier type,
which is continuous along with its first derivative by a piecewise polynomial
function. Conditions for its existence and uniqueness are given. The
constructed curve lies inside the convex hull of the control points, and the
segments of the broken line connecting the control points are tangent to the
curve. To construct the curve, we use the approach proposed earlier for
constructing a parabolic spline. The idea is to use additional points with
unknown values of some function. Additional points are used as spline nodes,
and the function values are determined from the condition of the first
derivative continuity of a piecewise polynomial curve. In multiple
interpolation nodes, the function takes the given values and the values of the
first derivative, which are determined by the control points. Examples of
constructing a spline curve are given.
"
936,Image Registration Techniques: A Survey,"  Image Registration is the process of aligning two or more images of the same
scene with reference to a particular image. The images are captured from
various sensors at different times and at multiple view-points. Thus to get a
better picture of any change of a scene or object over a considerable period of
time image registration is important. Image registration finds application in
medical sciences, remote sensing and in computer vision. This paper presents a
detailed review of several approaches which are classified accordingly along
with their contributions and drawbacks. The main steps of an image registration
procedure are also discussed. Different performance measures are presented that
determine the registration quality and accuracy. The scope for the future
research are presented as well.
"
937,Geometry Processing of Conventionally Produced Mouse Brain Slice Images,"  Brain mapping research in most neuroanatomical laboratories relies on
conventional processing techniques, which often introduce histological
artifacts such as tissue tears and tissue loss. In this paper we present
techniques and algorithms for automatic registration and 3D reconstruction of
conventionally produced mouse brain slices in a standardized atlas space. This
is achieved first by constructing a virtual 3D mouse brain model from annotated
slices of Allen Reference Atlas (ARA). Virtual re-slicing of the reconstructed
model generates ARA-based slice images corresponding to the microscopic images
of histological brain sections. These image pairs are aligned using a geometric
approach through contour images. Histological artifacts in the microscopic
images are detected and removed using Constrained Delaunay Triangulation before
performing global alignment. Finally, non-linear registration is performed by
solving Laplace's equation with Dirichlet boundary conditions. Our methods
provide significant improvements over previously reported registration
techniques for the tested slices in 3D space, especially on slices with
significant histological artifacts. Further, as an application we count the
number of neurons in various anatomical regions using a dataset of 51
microscopic slices from a single mouse brain. This work represents a
significant contribution to this subfield of neuroscience as it provides tools
to neuroanatomist for analyzing and processing histological data.
"
938,A Comparative Study of LOWESS and RBF Approximations for Visualization,"  Approximation methods are widely used in many fields and many techniques have
been published already. This comparative study presents a comparison of LOWESS
(Locally weighted scatterplot smoothing) and RBF (Radial Basis Functions)
approximation methods on noisy data as they use different approaches. The RBF
approach is generally convenient for high dimensional scattered data sets. The
LOWESS method needs finding a subset of nearest points if data are scattered.
The experiments proved that LOWESS approximation gives slightly better results
than RBF in the case of lower dimension, while in the higher dimensional case
"
939,A Fast Algorithm for Line Clipping by Convex Polyhedron in E3,"  A new algorithm for line clipping against convex polyhedron is given. The
suggested algorithm is faster for higher number of facets of the given
polyhedron than the traditional Cyrus-Beck's and others algorithms with
complexity O(N) . The suggested algorithm has O(N) complexity in the worst N
case and expected O(sqrt(N))) complexity. The speed up is achieved because of
'known order' of triangles. Some principal results of comparisons of selected
algorithms are presented and give some imagination how the proposed algorithm
could be used effectively.
"
940,O(lgN) Line Clipping Algorithm in E2,"  A new O(lg N) line clipping algorithm in E2 against a convex window is
presented. The main advantage of the presented algorithm is the principal
acceleration of the line clipping problem solution. A comparison of the
proposed algorithm with others shows a significant improvement in run-time.
Experimental results for selected known algorithms are also shown.
"
941,Joint convolutional neural pyramid for depth map super-resolution,"  High-resolution depth map can be inferred from a low-resolution one with the
guidance of an additional high-resolution texture map of the same scene.
Recently, deep neural networks with large receptive fields are shown to benefit
applications such as image completion. Our insight is that super resolution is
similar to image completion, where only parts of the depth values are precisely
known. In this paper, we present a joint convolutional neural pyramid model
with large receptive fields for joint depth map super-resolution. Our model
consists of three sub-networks, two convolutional neural pyramids concatenated
by a normal convolutional neural network. The convolutional neural pyramids
extract information from large receptive fields of the depth map and guidance
map, while the convolutional neural network effectively transfers useful
structures of the guidance image to the depth image. Experimental results show
that our model outperforms existing state-of-the-art algorithms not only on
data pairs of RGB/depth images, but also on other data pairs like
color/saliency and color-scribbles/colorized images.
"
942,A Voxel-based Rendering Pipeline for Large 3D Line Sets,"  We present a voxel-based rendering pipeline for large 3D line sets that
employs GPU ray-casting to achieve scalable rendering including transparency
and global illumination effects that cannot be achieved with GPU rasterization.
Even for opaque lines we demonstrate superior rendering performance compared to
GPU rasterization of lines, and when transparency is used we can interactively
render large amounts of lines that are infeasible to be rendered via
rasterization. To achieve this, we propose a direction-preserving encoding of
lines into a regular voxel grid, along with the quantization of directions
using face-to-face connectivity in this grid. On the regular grid structure,
parallel GPU ray-casting is used to determine visible fragments in correct
visibility order. To enable interactive rendering of global illumination
effects like low-frequency shadows and ambient occlusions, illumination
simulation is performed during ray-casting on a level-of-detail (LoD) line
representation that considers the number of lines and their lengths per voxel.
In this way we can render effects which are very difficult to render via GPU
rasterization. A detailed performance and quality evaluation compares our
approach to rasterization-based rendering of lines.
"
943,Vectorization of Line Drawings via PolyVector Fields,"  Image tracing is a foundational component of the workflow in graphic design,
engineering, and computer animation, linking hand-drawn concept images to
collections of smooth curves needed for geometry processing and editing. Even
for clean line drawings, modern algorithms often fail to faithfully vectorize
junctions, or points at which curves meet; this produces vector drawings with
incorrect connectivity. This subtle issue undermines the practical application
of vectorization tools and accounts for hesitance among artists and engineers
to use automatic vectorization software. To address this issue, we propose a
novel image vectorization method based on state-of-the-art mathematical
algorithms for frame field processing. Our algorithm is tailored specifically
to disambiguate junctions without sacrificing quality.
"
944,Reversible Harmonic Maps between Discrete Surfaces,"  Information transfer between triangle meshes is of great importance in
computer graphics and geometry processing. To facilitate this process, a smooth
and accurate map is typically required between the two meshes. While such maps
can sometimes be computed between nearly-isometric meshes, the more general
case of meshes with diverse geometries remains challenging. We propose a novel
approach for direct map computation between triangle meshes without mapping to
an intermediate domain, which optimizes for the harmonicity and reversibility
of the forward and backward maps. Our method is general both in the information
it can receive as input, e.g. point landmarks, a dense map or a functional map,
and in the diversity of the geometries to which it can be applied. We
demonstrate that our maps exhibit lower conformal distortion than the
state-of-the-art, while succeeding in correctly mapping key features of the
input shapes.
"
945,The Unreasonable Effectiveness of Deep Features as a Perceptual Metric,"  While it is nearly effortless for humans to quickly assess the perceptual
similarity between two images, the underlying processes are thought to be quite
complex. Despite this, the most widely used perceptual metrics today, such as
PSNR and SSIM, are simple, shallow functions, and fail to account for many
nuances of human perception. Recently, the deep learning community has found
that features of the VGG network trained on ImageNet classification has been
remarkably useful as a training loss for image synthesis. But how perceptual
are these so-called ""perceptual losses""? What elements are critical for their
success? To answer these questions, we introduce a new dataset of human
perceptual similarity judgments. We systematically evaluate deep features
across different architectures and tasks and compare them with classic metrics.
We find that deep features outperform all previous metrics by large margins on
our dataset. More surprisingly, this result is not restricted to
ImageNet-trained VGG features, but holds across different deep architectures
and levels of supervision (supervised, self-supervised, or even unsupervised).
Our results suggest that perceptual similarity is an emergent property shared
across deep visual representations.
"
946,Can Computers Create Art?,"  This essay discusses whether computers, using Artificial Intelligence (AI),
could create art. First, the history of technologies that automated aspects of
art is surveyed, including photography and animation. In each case, there were
initial fears and denial of the technology, followed by a blossoming of new
creative and professional opportunities for artists. The current hype and
reality of Artificial Intelligence (AI) tools for art making is then discussed,
together with predictions about how AI tools will be used. It is then
speculated about whether it could ever happen that AI systems could be credited
with authorship of artwork. It is theorized that art is something created by
social agents, and so computers cannot be credited with authorship of art in
our current understanding. A few ways that this could change are also
hypothesized.
"
947,Innovative Non-parametric Texture Synthesis via Patch Permutations,"  In this work, we present a non-parametric texture synthesis algorithm capable
of producing plausible images without copying large tiles of the exemplar. We
focus on a simple synthesis algorithm, where we explore two patch match
heuristics; the well known Bidirectional Similarity (BS) measure and a
heuristic that finds near permutations using the solution of an entropy
regularized optimal transport (OT) problem. Innovative synthesis is achieved
with a small patch size, where global plausibility relies on the qualities of
the match. For OT, less entropic regularization also meant near permutations
and more plausible images. We examine the tile maps of the synthesized images,
showing that they are indeed novel superpositions of the input and contain few
or no verbatim copies. Synthesis results are compared to a statistical method,
namely a random convolutional network. We conclude by remarking simple
algorithms using only the input image can synthesize textures decently well and
call for more modest approaches in future algorithm design.
"
948,"Adaptive Reversible Watermarking Based on Linear Prediction for Medical
  Videos","  Reversible video watermarking can guarantee that the watermark logo and the
original frame can be recovered from the watermarked frame without any
distortion. Although reversible video watermarking has successfully been
applied in multimedia, its application has not been extensively explored in
medical videos. Reversible watermarking in medical videos is still a
challenging problem. The existing reversible video watermarking algorithms,
which are based on error prediction expansion, use motion vectors for
prediction. In this study, we propose an adaptive reversible watermarking
method for medical videos. We suggest using temporal correlations for improving
the prediction accuracy. Hence, two temporal neighbor pixels in upcoming frames
are used alongside the four spatial rhombus neighboring pixels to minimize the
prediction error. To the best of our knowledge, this is the first time this
method is applied to medical videos. The method helps to protect patients'
personal and medical information by watermarking, i.e., increase the security
of Health Information Systems (HIS). Experimental results demonstrate the high
quality of the proposed watermarking method based on PSNR metric and a large
capacity for data hiding in medical videos.
"
949,PU-Net: Point Cloud Upsampling Network,"  Learning and analyzing 3D point clouds with deep networks is challenging due
to the sparseness and irregularity of the data. In this paper, we present a
data-driven point cloud upsampling technique. The key idea is to learn
multi-level features per point and expand the point set via a multi-branch
convolution unit implicitly in feature space. The expanded feature is then
split to a multitude of features, which are then reconstructed to an upsampled
point set. Our network is applied at a patch-level, with a joint loss function
that encourages the upsampled points to remain on the underlying surface with a
uniform distribution. We conduct various experiments using synthesis and scan
data to evaluate our method and demonstrate its superiority over some baseline
methods and an optimization-based method. Results show that our upsampled
points have better uniformity and are located closer to the underlying
surfaces.
"
950,"Edge-Preserving Piecewise Linear Image Smoothing Using Piecewise
  Constant Filters","  Most image smoothing filters in the literature assume a piecewise constant
model of smoothed output images. However, the piecewise constant model
assumption can cause artifacts such as gradient reversals in applications such
as image detail enhancement, HDR tone mapping, etc. In these applications, a
piecewise linear model assumption is more preferred. In this paper, we propose
a simple yet very effective framework to smooth images of piecewise linear
model assumption using classical filters with the piecewise constant model
assumption. Our method is capable of handling with gradient reversal artifacts
caused by the piecewise constant model assumption. In addition, our method can
further help accelerated methods, which need to quantize image intensity values
into different bins, to achieve similar results that need a large number of
bins using a much smaller number of bins. This can greatly reduce the
computational cost. We apply our method to various classical filters with the
piecewise constant model assumption. Experimental results of several
applications show the effectiveness of the proposed method.
"
951,"High Resolution Face Completion with Multiple Controllable Attributes
  via Fully End-to-End Progressive Generative Adversarial Networks","  We present a deep learning approach for high resolution face completion with
multiple controllable attributes (e.g., male and smiling) under arbitrary
masks. Face completion entails understanding both structural meaningfulness and
appearance consistency locally and globally to fill in ""holes"" whose content do
not appear elsewhere in an input image. It is a challenging task with the
difficulty level increasing significantly with respect to high resolution, the
complexity of ""holes"" and the controllable attributes of filled-in fragments.
Our system addresses the challenges by learning a fully end-to-end framework
that trains generative adversarial networks (GANs) progressively from low
resolution to high resolution with conditional vectors encoding controllable
attributes.
  We design novel network architectures to exploit information across multiple
scales effectively and efficiently. We introduce new loss functions encouraging
sharp completion. We show that our system can complete faces with large
structural and appearance variations using a single feed-forward pass of
computation with mean inference time of 0.007 seconds for images at 1024 x 1024
resolution. We also perform a pilot human study that shows our approach
outperforms state-of-the-art face completion methods in terms of rank analysis.
The code will be released upon publication.
"
952,PointCNN: Convolution On $\mathcal{X}$-Transformed Points,"  We present a simple and general framework for feature learning from point
clouds. The key to the success of CNNs is the convolution operator that is
capable of leveraging spatially-local correlation in data represented densely
in grids (e.g. images). However, point clouds are irregular and unordered, thus
directly convolving kernels against features associated with the points, will
result in desertion of shape information and variance to point ordering. To
address these problems, we propose to learn an $\mathcal{X}$-transformation
from the input points, to simultaneously promote two causes. The first is the
weighting of the input features associated with the points, and the second is
the permutation of the points into a latent and potentially canonical order.
Element-wise product and sum operations of the typical convolution operator are
subsequently applied on the $\mathcal{X}$-transformed features. The proposed
method is a generalization of typical CNNs to feature learning from point
clouds, thus we call it PointCNN. Experiments show that PointCNN achieves on
par or better performance than state-of-the-art methods on multiple challenging
benchmark datasets and tasks.
"
953,Generative Image Inpainting with Contextual Attention,"  Recent deep learning based approaches have shown promising results for the
challenging task of inpainting large missing regions in an image. These methods
can generate visually plausible image structures and textures, but often create
distorted structures or blurry textures inconsistent with surrounding areas.
This is mainly due to ineffectiveness of convolutional neural networks in
explicitly borrowing or copying information from distant spatial locations. On
the other hand, traditional texture and patch synthesis approaches are
particularly suitable when it needs to borrow textures from the surrounding
regions. Motivated by these observations, we propose a new deep generative
model-based approach which can not only synthesize novel image structures but
also explicitly utilize surrounding image features as references during network
training to make better predictions. The model is a feed-forward, fully
convolutional neural network which can process images with multiple holes at
arbitrary locations and with variable sizes during the test time. Experiments
on multiple datasets including faces (CelebA, CelebA-HQ), textures (DTD) and
natural images (ImageNet, Places2) demonstrate that our proposed approach
generates higher-quality inpainting results than existing ones. Code, demo and
models are available at: https://github.com/JiahuiYu/generative_inpainting.
"
954,Learning Symmetric and Low-energy Locomotion,"  Learning locomotion skills is a challenging problem. To generate realistic
and smooth locomotion, existing methods use motion capture, finite state
machines or morphology-specific knowledge to guide the motion generation
algorithms. Deep reinforcement learning (DRL) is a promising approach for the
automatic creation of locomotion control. Indeed, a standard benchmark for DRL
is to automatically create a running controller for a biped character from a
simple reward function. Although several different DRL algorithms can
successfully create a running controller, the resulting motions usually look
nothing like a real runner. This paper takes a minimalist learning approach to
the locomotion problem, without the use of motion examples, finite state
machines, or morphology-specific knowledge. We introduce two modifications to
the DRL approach that, when used together, produce locomotion behaviors that
are symmetric, low-energy, and much closer to that of a real person. First, we
introduce a new term to the loss function (not the reward function) that
encourages symmetric actions. Second, we introduce a new curriculum learning
method that provides modulated physical assistance to help the character with
left/right balance and forward movement. The algorithm automatically computes
appropriate assistance to the character and gradually relaxes this assistance,
so that eventually the character learns to move entirely without help. Because
our method does not make use of motion capture data, it can be applied to a
variety of character morphologies. We demonstrate locomotion controllers for
the lower half of a biped, a full humanoid, a quadruped, and a hexapod. Our
results show that learned policies are able to produce symmetric, low-energy
gaits. In addition, speed-appropriate gait patterns emerge without any guidance
from motion examples or contact planning.
"
955,DVQA: Understanding Data Visualizations via Question Answering,"  Bar charts are an effective way to convey numeric information, but today's
algorithms cannot parse them. Existing methods fail when faced with even minor
variations in appearance. Here, we present DVQA, a dataset that tests many
aspects of bar chart understanding in a question answering framework. Unlike
visual question answering (VQA), DVQA requires processing words and answers
that are unique to a particular bar chart. State-of-the-art VQA algorithms
perform poorly on DVQA, and we propose two strong baselines that perform
considerably better. Our work will enable algorithms to automatically extract
numeric and semantic information from vast quantities of bar charts found in
scientific publications, Internet articles, business reports, and many other
areas.
"
956,Big Data Visualization Tools,"  Data visualization is the presentation of data in a pictorial or graphical
format, and a data visualization tool is the software that generates this
presentation. Data visualization provides users with intuitive means to
interactively explore and analyze data, enabling them to effectively identify
interesting patterns, infer correlations and causalities, and supports
sense-making activities.
"
957,3D Scanning: A Comprehensive Survey,"  This paper provides an overview of 3D scanning methodologies and technologies
proposed in the existing scientific and industrial literature. Throughout the
paper, various types of the related techniques are reviewed, which consist,
mainly, of close-range, aerial, structure-from-motion and terrestrial
photogrammetry, and mobile, terrestrial and airborne laser scanning, as well as
time-of-flight, structured-light and phase-comparison methods, along with
comparative and combinational studies, the latter being intended to help make a
clearer distinction on the relevance and reliability of the possible choices.
Moreover, outlier detection and surface fitting procedures are discussed
concisely, which are necessary post-processing stages.
"
958,"Smooth, Efficient, and Interruptible Zooming and Panning","  This paper introduces a novel technique for smooth and efficient zooming and
panning based on dynamical systems in hyperbolic space. Unlike the technique of
van Wijk and Nuij, the animations produced by our technique are smooth at the
endpoints and when interrupted by a change of target. To analyze the results of
our technique, we introduce world/screen diagrams, a novel technique for
visualizing zooming and panning animations.
"
959,"tempoGAN: A Temporally Coherent, Volumetric GAN for Super-resolution
  Fluid Flow","  We propose a temporally coherent generative model addressing the
super-resolution problem for fluid flows. Our work represents a first approach
to synthesize four-dimensional physics fields with neural networks. Based on a
conditional generative adversarial network that is designed for the inference
of three-dimensional volumetric data, our model generates consistent and
detailed results by using a novel temporal discriminator, in addition to the
commonly used spatial one. Our experiments show that the generator is able to
infer more realistic high-resolution details by using additional physical
quantities, such as low-resolution velocities or vorticities. Besides
improvements in the training process and in the generated outputs, these inputs
offer means for artistic control as well. We additionally employ a
physics-aware data augmentation step, which is crucial to avoid overfitting and
to reduce memory requirements. In this way, our network learns to generate
advected quantities with highly detailed, realistic, and temporally coherent
features. Our method works instantaneously, using only a single time-step of
low-resolution fluid data. We demonstrate the abilities of our method using a
variety of complex inputs and applications in two and three dimensions.
"
960,Open3D: A Modern Library for 3D Data Processing,"  Open3D is an open-source library that supports rapid development of software
that deals with 3D data. The Open3D frontend exposes a set of carefully
selected data structures and algorithms in both C++ and Python. The backend is
highly optimized and is set up for parallelization. Open3D was developed from a
clean slate with a small and carefully considered set of dependencies. It can
be set up on different platforms and compiled from source with minimal effort.
The code is clean, consistently styled, and maintained via a clear code review
mechanism. Open3D has been used in a number of published research projects and
is actively deployed in the cloud. We welcome contributions from the
open-source community.
"
961,Animation-by-Demonstration Computer Puppetry Authoring Framework,"  This paper presents Master of Puppets (MOP), an animation-by-demonstration
framework that allows users to control the motion of virtual characters
(puppets) in real time. In the first step, the user is asked to perform the
necessary actions that correspond to the character's motions. The user's
actions are recorded, and a hidden Markov model (HMM) is used to learn the
temporal profile of the actions. During the runtime of the framework, the user
controls the motions of the virtual character based on the specified
activities. The advantage of the MOP framework is that it recognizes and
follows the progress of the user's actions in real time. Based on the forward
algorithm, the method predicts the evolution of the user's actions, which
corresponds to the evolution of the character's motion. This method treats
characters as puppets that can perform only one motion at a time. This means
that combinations of motion segments (motion synthesis), as well as the
interpolation of individual motion sequences, are not provided as
functionalities. By implementing the framework and presenting several computer
puppetry scenarios, its efficiency and flexibility in animating virtual
characters is demonstrated.
"
962,Robust 3D Human Motion Reconstruction Via Dynamic Template Construction,"  In multi-view human body capture systems, the recovered 3D geometry or even
the acquired imagery data can be heavily corrupted due to occlusions, noise,
limited field of- view, etc. Direct estimation of 3D pose, body shape or motion
on these low-quality data has been traditionally challenging.In this paper, we
present a graph-based non-rigid shape registration framework that can
simultaneously recover 3D human body geometry and estimate pose/motion at high
fidelity.Our approach first generates a global full-body template by
registering all poses in the acquired motion sequence.We then construct a
deformable graph by utilizing the rigid components in the global template. We
directly warp the global template graph back to each motion frame in order to
fill in missing geometry. Specifically, we combine local rigidity and temporal
coherence constraints to maintain geometry and motion consistencies.
Comprehensive experiments on various scenes show that our method is accurate
and robust even in the presence of drastic motions.
"
963,Isotropic Scattering in a Flatland Half-Space,"  We solve the Milne, constant-source and albedo problems for isotropic
scattering in a two-dimensional ""Flatland"" half-space via the Wiener-Hopf
method. The Flatland $H$-function is derived and benchmark values and some
identities unique to Flatland are presented. A number of the derivations are
supported by Monte Carlo simulation.
"
964,"Position-Based Multi-Agent Dynamics for Real-Time Crowd Simulation (MiG
  paper)","  Exploiting the efficiency and stability of Position-Based Dynamics (PBD), we
introduce a novel crowd simulation method that runs at interactive rates for
hundreds of thousands of agents. Our method enables the detailed modeling of
per-agent behavior in a Lagrangian formulation. We model short-range and
long-range collision avoidance to simulate both sparse and dense crowds. On the
particles representing agents, we formulate a set of positional constraints
that can be readily integrated into a standard PBD solver. We augment the
tentative particle motions with planning velocities to determine the preferred
velocities of agents, and project the positions onto the constraint manifold to
eliminate colliding configurations. The local short-range interaction is
represented with collision and frictional contact between agents, as in the
discrete simulation of granular materials. We incorporate a cohesion model for
modeling collective behaviors and propose a new constraint for dealing with
potential future collisions. Our new method is suitable for use in interactive
games.
"
965,Topologically Controlled Lossy Compression,"  This paper presents a new algorithm for the lossy compression of scalar data
defined on 2D or 3D regular grids, with topological control. Certain techniques
allow users to control the pointwise error induced by the compression. However,
in many scenarios it is desirable to control in a similar way the preservation
of higher-level notions, such as topological features , in order to provide
guarantees on the outcome of post-hoc data analyses. This paper presents the
first compression technique for scalar data which supports a strictly
controlled loss of topological features. It provides users with specific
guarantees both on the preservation of the important features and on the size
of the smaller features destroyed during compression. In particular, we present
a simple compression strategy based on a topologically adaptive quantization of
the range. Our algorithm provides strong guarantees on the bottleneck distance
between persistence diagrams of the input and decompressed data, specifically
those associated with extrema. A simple extension of our strategy additionally
enables a control on the pointwise error. We also show how to combine our
approach with state-of-the-art compressors, to further improve the geometrical
reconstruction. Extensive experiments, for comparable compression rates,
demonstrate the superiority of our algorithm in terms of the preservation of
topological features. We show the utility of our approach by illustrating the
compatibility between the output of post-hoc topological data analysis
pipelines, executed on the input and decompressed data, for simulated or
acquired data sets. We also provide a lightweight VTK-based C++ implementation
of our approach for reproduction purposes.
"
966,Hierarchical Cloth Simulation using Deep Neural Networks,"  Fast and reliable physically-based simulation techniques are essential for
providing flexible visual effects for computer graphics content. In this paper,
we propose a fast and reliable hierarchical cloth simulation method, which
combines conventional physically-based simulation with deep neural networks
(DNN). Simulations of the coarsest level of the hierarchical model are
calculated using conventional physically-based simulations, and more detailed
levels are generated by inference using DNN models. We demonstrate that our
method generates reliable and fast cloth simulation results through experiments
under various conditions.
"
967,Automatic thread painting generation,"  ThreadTone is an NPR representation of an input image by half-toning using
threads on a circle. Current approaches to create ThreadTone paintings greedily
draw the chords on the circle. We introduce the concept of chord space, and
design a new algorithm to improve the quality of the thread painting. We use an
optimization process that estimates the fitness of every chord in the chord
space, and an error-diffusion based sampling process that selects a moderate
number of chords to produce the output painting. We used an image similarity
measure to evaluate the quality of our thread painting and also conducted a
user study. Our approach can produce high quality results on portraits,
sketches as well as cartoon pictures.
"
968,Be-Educated: Multimedia Learning through 3D Animation,"  Multimedia learning tools and techniques are placing its importance with
large scale in education sector. With the help of multimedia learning, various
complex phenomenon and theories can be explained and taught easily and
conveniently. This project aims to teach and spread the importance of education
and respecting the tools of education: pen, paper, pencil, rubber. To achieve
this cognitive learning, a 3D animated movie has been developed using
principles of multimedia learning with 3D cartoon characters resembling the
actual educational objects, where the buildings have also been modelled to
resemble real books and diaries. For modelling and animation of these
characters, polygon mesh tools are used in 3D Studio Max. Additionally, the
final composition of video and audio is performed in adobe premiere. This 3D
animated video aims to highlight a message of importance for education and
stationary. The Moral of movie is that do not waste your stationary material,
use your Pen and Paper for the purpose they are made for. To be a good citizen
you have to Be-Educated yourself and for that you need to give value to Pen.
The final rendered and composited 3D animated video reflects this moral and
portrays the intended message with very vibrant visuals
"
969,Sensor-topology based simplicial complex reconstruction,"  We propose a new method for the reconstruction of simplicial complexes
(combining points, edges and triangles) from 3D point clouds from Mobile Laser
Scanning (MLS). Our main goal is to produce a reconstruction of a scene that is
adapted to the local geometry of objects. Our method uses the inherent topology
of the MLS sensor to define a spatial adjacency relationship between points. We
then investigate each possible connexion between adjacent points and filter
them by searching collinear structures in the scene, or structures
perpendicular to the laser beams. Next, we create triangles for each triplet of
self-connected edges. Last, we improve this method with a regularization based
on the co-planarity of triangles and collinearity of remaining edges. We
compare our results to a naive simplicial complexes reconstruction based on
edge length.
"
970,"ViTac: Feature Sharing between Vision and Tactile Sensing for Cloth
  Texture Recognition","  Vision and touch are two of the important sensing modalities for humans and
they offer complementary information for sensing the environment. Robots could
also benefit from such multi-modal sensing ability. In this paper, addressing
for the first time (to the best of our knowledge) texture recognition from
tactile images and vision, we propose a new fusion method named Deep Maximum
Covariance Analysis (DMCA) to learn a joint latent space for sharing features
through vision and tactile sensing. The features of camera images and tactile
data acquired from a GelSight sensor are learned by deep neural networks. But
the learned features are of a high dimensionality and are redundant due to the
differences between the two sensing modalities, which deteriorates the
perception performance. To address this, the learned features are paired using
maximum covariance analysis. Results of the algorithm on a newly collected
dataset of paired visual and tactile data relating to cloth textures show that
a good recognition performance of greater than 90\% can be achieved by using
the proposed DMCA framework. In addition, we find that the perception
performance of either vision or tactile sensing can be improved by employing
the shared representation space, compared to learning from unimodal data.
"
971,"$C^1$ analysis of 2D subdivision schemes refining point-normal pairs
  with the circle average","  This article continues the investigation started in [9] on subdivision
schemes refining 2D point-normal pairs, obtained by modifying linear
subdivision schemes using the circle average. While in [9] the convergence of
the Modified Lane-Riesenfeld algorithm and the Modified 4-Point schemes is
proved, here we show that the curves generated by these two schemes are $C^1$.
"
972,"Least Square Error Method Robustness of Computation: What is not usually
  considered and taught","  There are many practical applications based on the Least Square Error (LSE)
approximation. It is based on a square error minimization 'on a vertical' axis.
The LSE method is simple and easy also for analytical purposes. However, if
data span is large over several magnitudes or non-linear LSE is used, severe
numerical instability can be expected. The presented contribution describes a
simple method for large span of data LSE computation. It is especially
convenient if large span of data are to be processed, when the 'standard'
pseudoinverse matrix is ill conditioned. It is actually based on a LSE solution
using orthogonal basis vectors instead of orthonormal basis vectors. The
presented approach has been used for a linear regression as well as for
approximation using radial basis functions.
"
973,"""How to squash a mathematical tomato"", Rubic's cube-like surfaces and
  their connection to reversible computation","  Here we show how reversible computation processes, like Margolus diffusion,
can be envisioned as physical turning operations on a 2-dimensional rigid
surface that is cut by a regular pattern of intersecting circles. We then
briefly explore the design-space of these patterns, and report on the discovery
of an interesting fractal subdivision of space by iterative circle packings. We
devise two different ways for creating this fractal, both showing interesting
properties, some resembling properties of the dragon curve. The patterns
presented here can have interesting applications to the engineering of modular,
kinetic, active surfaces.
"
974,Medical Volume Reconstruction Techniques,"  Medical visualization is the use of computers to create 3D images from
medical imaging data sets, almost all surgery and cancer treatment in the
developed world relies on it.Volume visualization techniques includes
iso-surface visualization, mesh visualization and point cloud visualization
techniques, these techniques have revolutionized medicine. Much of modern
medicine relies on the 3D imaging that is possible with magnetic resonance
imaging (MRI) scanners, functional magnetic resonance imaging (fMRI)scanners,
positron emission tomography (PET) scanners, ultrasound imaging (US) scanners,
X-Ray scanners, bio-marker microscopy imaging scanners and computed tomography
(CT) scanners, which make 3D images out of 2D slices. The primary goal of this
report is the application-oriented optimization of existing volume rendering
methods providing interactive frame rates. Techniques are presented for
traditional alpha-blending rendering, surface-shaded display, maximum intensity
projection (MIP), and fast previewing with fully interactive parameter control.
Different preprocessing strategies are proposed for interactive iso-surface
rendering and fast previewing, such as the well-known marching cube algorithm.
"
975,Equalizer 2.0 - Convergence of a Parallel Rendering Framework,"  Developing complex, real world graphics applications which leverage multiple
GPUs and computers for interactive 3D rendering tasks is a complex task. It
requires expertise in distributed systems and parallel rendering in addition to
the application domain itself. We present a mature parallel rendering framework
which provides a large set of features, algorithms and system integration for a
wide range of real-world research and industry applications. Using the
Equalizer parallel rendering framework, we show how a wide set of generic
algorithms can be integrated in the framework to help application scalability
and development in many different domains, highlighting how concrete
applications benefit from the diverse aspects and use cases of Equalizer. We
present novel parallel rendering algorithms, powerful abstractions for large
visualization setups and virtual reality, as well as new experimental results
for parallel rendering and data distribution.
"
976,Deep Online Video Stabilization,"  Video stabilization technique is essential for most hand-held captured videos
due to high-frequency shakes. Several 2D-, 2.5D- and 3D-based stabilization
techniques are well studied, but to our knowledge, no solutions based on deep
neural networks had been proposed. The reason for this is mostly the shortage
of training data, as well as the challenge of modeling the problem using neural
networks. In this paper, we solve the video stabilization problem using a
convolutional neural network (ConvNet). Instead of dealing with offline
holistic camera path smoothing based on feature matching, we focus on
low-latency real-time camera path smoothing without explicitly representing the
camera path. Our network, called StabNet, learns a transformation for each
input unsteady frame progressively along the time-line, while creating a more
stable latent camera path. To train the network, we create a dataset of
synchronized steady/unsteady video pairs via a well designed hand-held
hardware. Experimental results shows that the proposed online method (without
using future frames) performs comparatively to traditional offline video
stabilization methods, while running about 30 times faster. Further, the
proposed StabNet is able to handle night-time and blurry videos, where existing
methods fail in robust feature matching.
"
977,SPLATNet: Sparse Lattice Networks for Point Cloud Processing,"  We present a network architecture for processing point clouds that directly
operates on a collection of points represented as a sparse set of samples in a
high-dimensional lattice. Naively applying convolutions on this lattice scales
poorly, both in terms of memory and computational cost, as the size of the
lattice increases. Instead, our network uses sparse bilateral convolutional
layers as building blocks. These layers maintain efficiency by using indexing
structures to apply convolutions only on occupied parts of the lattice, and
allow flexible specifications of the lattice structure enabling hierarchical
and spatially-aware feature learning, as well as joint 2D-3D reasoning. Both
point-based and image-based representations can be easily incorporated in a
network with such layers and the resulting model can be trained in an
end-to-end manner. We present results on 3D segmentation tasks where our
approach outperforms existing state-of-the-art techniques.
"
978,Cost-benefit Analysis of Visualization in Virtual Environments,"  Visualization and virtual environments (VEs) have been two interconnected
parallel strands in visual computing for decades. Some VEs have been purposely
developed for visualization applications, while many visualization applications
are exemplary showcases in general-purpose VEs. Because of the development and
operation costs of VEs, the majority of visualization applications in practice
are yet to benefit from the capacity of VEs. In this paper, we examine this
perplexity from an information-theoretic perspective. Our objectives are to
conduct cost-benefit analysis on typical VE systems (including augmented and
mixed reality, theatre-based systems, and large powerwalls), to explain why
some visualization applications benefit more from VEs than others, and to
sketch out pathways for the future development of visualization applications in
VEs. We support our theoretical propositions and analysis using theories and
discoveries in the literature of cognitive sciences and the practical evidence
reported in the literatures of visualization and VEs.
"
979,"Latent-space Physics: Towards Learning the Temporal Evolution of Fluid
  Flow","  We propose a method for the data-driven inference of temporal evolutions of
physical functions with deep learning. More specifically, we target fluid
flows, i.e. Navier-Stokes problems, and we propose a novel LSTM-based approach
to predict the changes of pressure fields over time. The central challenge in
this context is the high dimensionality of Eulerian space-time data sets. We
demonstrate for the first time that dense 3D+time functions of physics system
can be predicted within the latent spaces of neural networks, and we arrive at
a neural-network based simulation algorithm with significant practical
speed-ups. We highlight the capabilities of our method with a series of complex
liquid simulations, and with a set of single-phase buoyancy simulations. With a
set of trained networks, our method is more than two orders of magnitudes
faster than a traditional pressure solver. Additionally, we present and discuss
a series of detailed evaluations for the different components of our algorithm.
"
980,"Resolution Improvement of the Common Method for Presentating Arbitrary
  Space Curves Voxel","  The task of voxel resolution for a space curve in video memory of 3D display
is set. Furthermore, an approach solution of voxel resolution of arbitrary
space curve, given in parametric form, is studied. Numerous numbers of
intensive experiments are conducted and interesting results with significant
recommendations are presented.
"
981,"Interactive Sound Rendering on Mobile Devices using Ray-Parameterized
  Reverberation Filters","  We present a new sound rendering pipeline that is able to generate plausible
sound propagation effects for interactive dynamic scenes. Our approach combines
ray-tracing-based sound propagation with reverberation filters using robust
automatic reverb parameter estimation that is driven by impulse responses
computed at a low sampling rate.We propose a unified spherical harmonic
representation of directional sound in both the propagation and auralization
modules and use this formulation to perform a constant number of convolution
operations for any number of sound sources while rendering spatial audio. In
comparison to previous geometric acoustic methods, we achieve a speedup of over
an order of magnitude while delivering similar audio to high-quality
convolution rendering algorithms. As a result, our approach is the first
capable of rendering plausible dynamic sound propagation effects on commodity
smartphones.
"
982,Protecting JPEG Images Against Adversarial Attacks,"  As deep neural networks (DNNs) have been integrated into critical systems,
several methods to attack these systems have been developed. These adversarial
attacks make imperceptible modifications to an image that fool DNN classifiers.
We present an adaptive JPEG encoder which defends against many of these
attacks. Experimentally, we show that our method produces images with high
visual quality while greatly reducing the potency of state-of-the-art attacks.
Our algorithm requires only a modest increase in encoding time, produces a
compressed image which can be decompressed by an off-the-shelf JPEG decoder,
and classified by an unmodified classifier
"
983,"ExpandNet: A Deep Convolutional Neural Network for High Dynamic Range
  Expansion from Low Dynamic Range Content","  High dynamic range (HDR) imaging provides the capability of handling real
world lighting as opposed to the traditional low dynamic range (LDR) which
struggles to accurately represent images with higher dynamic range. However,
most imaging content is still available only in LDR. This paper presents a
method for generating HDR content from LDR content based on deep Convolutional
Neural Networks (CNNs) termed ExpandNet. ExpandNet accepts LDR images as input
and generates images with an expanded range in an end-to-end fashion. The model
attempts to reconstruct missing information that was lost from the original
signal due to quantization, clipping, tone mapping or gamma correction. The
added information is reconstructed from learned features, as the network is
trained in a supervised fashion using a dataset of HDR images. The approach is
fully automatic and data driven; it does not require any heuristics or human
expertise. ExpandNet uses a multiscale architecture which avoids the use of
upsampling layers to improve image quality. The method performs well compared
to expansion/inverse tone mapping operators quantitatively on multiple metrics,
even for badly exposed inputs.
"
984,"A reciprocal formulation of non-exponential radiative transfer. 1:
  Sketch and motivation","  Previous proposals to permit non-exponential free-path statistics in
radiative transfer have not included support for volume and boundary sources
that are spatially uncorrelated from the scattering events in the medium.
Birth-collision free paths are treated identically to collision-collision free
paths and application of this to general, bounded scenes with inclusions leads
to non-reciprocal transport. Beginning with reciprocity as a desired property,
we propose a new way to integrate non-exponential transport theory into general
scenes. We distinguish between the free-path-length statistics between
correlated medium particles and the free-path-length statistics beginning at
locations not correlated to medium particles, such as boundary surfaces,
inclusions and uncorrelated sources. Reciprocity requires that the uncorrelated
free-path distributions are simply the normalized transmittance of the
correlated free-path distributions. The combination leads to an equilibrium
imbedding of a previously derived generalized transport equation into bounded
domains. We compare predictions of this approach to Monte Carlo simulation of
multiple scattering from negatively-correlated suspensions of monodispersive
hard spheres in bounded two-dimensional domains and demonstrate improved
performance relative to previous work. We also derive new, exact, reciprocal,
single-scattering solutions for plane-parallel half-spaces over a variety of
non-exponential media types.
"
985,"An Efficient Volumetric Mesh Representation for Real-time Scene
  Reconstruction using Spatial Hashing","  Mesh plays an indispensable role in dense real-time reconstruction essential
in robotics. Efforts have been made to maintain flexible data structures for 3D
data fusion, yet an efficient incremental framework specifically designed for
online mesh storage and manipulation is missing. We propose a novel framework
to compactly generate, update, and refine mesh for scene reconstruction upon a
volumetric representation. Maintaining a spatial-hashed field of cubes, we
distribute vertices with continuous value on discrete edges that support O(1)
vertex accessing and forbid memory redundancy. By introducing Hamming distance
in mesh refinement, we further improve the mesh quality regarding the triangle
type consistency with a low cost. Lock-based and lock-free operations were
applied to avoid thread conflicts in GPU parallel computation. Experiments
demonstrate that the mesh memory consumption is significantly reduced while the
running speed is kept in the online reconstruction process.
"
986,Light Transport Simulation via Generalized Multiple Importance Sampling,"  Multiple importance sampling (MIS) is employed to reduce variance of
estimators, but when sampling and weighting are not suitable to the integrand,
the estimators would have extra variance. Therefore, robust light transport
simulation algorithms based on Monte Carlo sampling for different types of
scenes are still uncompleted. In this paper, we address this problem by present
a general method, named generalized multiple importance sampling (GMIS), to
enhance the robustness of light transport simulation based on MIS. GMIS
combines different sampling techniques and weighting functions, extending MIS
to a more generalized framework. Meanwhile, we implement the GMIS in common
renderers and illustrate how it increase the robustness of light transport
simulation. Experiments show that, by applying GMIS, we obtain better
convergence performance and lower variance, and increase the rendering of
ambient light and specular shadow effects apparently.
"
987,Procedural Planetary Multi-resolution Terrain Generation for Games,"  Terrains are the main part of an electronic game. To reduce human effort on
game development, procedural techniques are used to generate synthetic
terrains. However rendering a terrain is not a trivial task. Their rendering
techniques must be optimal for gaming. Specially planetary terrains, which must
account for precision and scale conversion. Multi-resolution models are best
fit to planetary terrains. An observer can change his point of view without
noticing any decrease in visual quality. There are several proposals regarding
real-time terrain rendering with multi-resolution models, and there are game
engines capable of generating large scale terrains with fixed resolution.
However for the best of our knowledge, it was noticed that there are no
techniques which combine both aspects. In this paper we present a new technique
capable of generating large-scale multi-resolution terrains, whichcan be
rendered and viewed at different scales. Rendering large scale models with high
definition and low scale areas with finer details added with the aid of
procedural content generation.
"
988,Effect of Eye Dominance on the Perception of Stereoscopic 3D Video,"  Asymmetric schemes have widespread applications in the 3D video transmission
pipeline. The significance of eye dominance becomes a concern when designing
such schemes. In this paper, in order to investigate the effect of eye
dominance on the perceptual 3D video quality, a database of representative
asymmetric stereoscopic sequences is prepared and the overall 3D quality of
these sequences is evaluated through subjective experiments. Experiment results
showed that viewers find an asymmetric video more pleasant when the view with
higher quality is projected to their dominant eye. Moreover, the eye dominance
changes the mean opinion quality score by 16 % at most, a result caused by
slight asymmetric video compression. For all other representative types of
asymmetry, the statistical difference is much lower and in some cases even
negligible.
"
989,"DeepN-JPEG: A Deep Neural Network Favorable JPEG-based Image Compression
  Framework","  As one of most fascinating machine learning techniques, deep neural network
(DNN) has demonstrated excellent performance in various intelligent tasks such
as image classification. DNN achieves such performance, to a large extent, by
performing expensive training over huge volumes of training data. To reduce the
data storage and transfer overhead in smart resource-limited Internet-of-Thing
(IoT) systems, effective data compression is a ""must-have"" feature before
transferring real-time produced dataset for training or classification. While
there have been many well-known image compression approaches (such as JPEG), we
for the first time find that a human-visual based image compression approach
such as JPEG compression is not an optimized solution for DNN systems,
especially with high compression ratios. To this end, we develop an image
compression framework tailored for DNN applications, named ""DeepN-JPEG"", to
embrace the nature of deep cascaded information process mechanism of DNN
architecture. Extensive experiments, based on ""ImageNet"" dataset with various
state-of-the-art DNNs, show that ""DeepN-JPEG"" can achieve ~3.5x higher
compression rate over the popular JPEG solution while maintaining the same
accuracy level for image recognition, demonstrating its great potential of
storage and power efficiency in DNN-based smart IoT system design.
"
990,"Convolutional Point-set Representation: A Convolutional Bridge Between a
  Densely Annotated Image and 3D Face Alignment","  We present a robust method for estimating the facial pose and shape
information from a densely annotated facial image. The method relies on
Convolutional Point-set Representation (CPR), a carefully designed matrix
representation to summarize different layers of information encoded in the set
of detected points in the annotated image. The CPR disentangles the
dependencies of shape and different pose parameters and enables updating
different parameters in a sequential manner via convolutional neural networks
and recurrent layers. When updating the pose parameters, we sample reprojection
errors along with a predicted direction and update the parameters based on the
pattern of reprojection errors. This technique boosts the model's capability in
searching a local minimum under challenging scenarios. We also demonstrate that
annotation from different sources can be merged under the framework of CPR and
contributes to outperforming the current state-of-the-art solutions for 3D face
alignment. Experiments indicate the proposed CPRFA (CPR-based Face Alignment)
significantly improves 3D alignment accuracy when the densely annotated image
contains noise and missing values, which is common under ""in-the-wild""
acquisition scenarios.
"
991,Low Rank Matrix Approximation for Geometry Filtering,"  We propose a robust normal estimation method for both point clouds and meshes
using a low rank matrix approximation algorithm. First, we compute a local
feature descriptor for each point and find similar, non-local neighbors that we
organize into a matrix. We then show that a low rank matrix approximation
algorithm can robustly estimate normals for both point clouds and meshes.
Furthermore, we provide a new filtering method for point cloud data to smooth
the position data to fit the estimated normals. We show applications of our
method to point cloud filtering, point set upsampling, surface reconstruction,
mesh denoising, and geometric texture removal. Our experiments show that our
method outperforms current methods in both visual quality and accuracy.
"
992,Linear-time geometric algorithm for evaluating B\'ezier curves,"  A new algorithm for computing a point on a polynomial or rational curve in
B\'{e}zier form is proposed. The method has a geometric interpretation and uses
only convex combinations of control points. The new algorithm's computational
complexity is linear with respect to the number of control points and its
memory complexity is $O(1)$. Some remarks on similar methods for surfaces in
rectangular and triangular B\'{e}zier form are also given.
"
993,"Joint 3D Face Reconstruction and Dense Alignment with Position Map
  Regression Network","  We propose a straightforward method that simultaneously reconstructs the 3D
facial structure and provides dense alignment. To achieve this, we design a 2D
representation called UV position map which records the 3D shape of a complete
face in UV space, then train a simple Convolutional Neural Network to regress
it from a single 2D image. We also integrate a weight mask into the loss
function during training to improve the performance of the network. Our method
does not rely on any prior face model, and can reconstruct full facial geometry
along with semantic meaning. Meanwhile, our network is very light-weighted and
spends only 9.8ms to process an image, which is extremely faster than previous
works. Experiments on multiple challenging datasets show that our method
surpasses other state-of-the-art methods on both reconstruction and alignment
tasks by a large margin.
"
994,"Text2Shape: Generating Shapes from Natural Language by Learning Joint
  Embeddings","  We present a method for generating colored 3D shapes from natural language.
To this end, we first learn joint embeddings of freeform text descriptions and
colored 3D shapes. Our model combines and extends learning by association and
metric learning approaches to learn implicit cross-modal connections, and
produces a joint representation that captures the many-to-many relations
between language and physical properties of 3D shapes such as color and shape.
To evaluate our approach, we collect a large dataset of natural language
descriptions for physical 3D objects in the ShapeNet dataset. With this learned
joint embedding we demonstrate text-to-shape retrieval that outperforms
baseline approaches. Using our embeddings with a novel conditional Wasserstein
GAN framework, we generate colored 3D shapes from text. Our method is the first
to connect natural language text with realistic 3D objects exhibiting rich
variations in color, texture, and shape detail. See video at
https://youtu.be/zraPvRdl13Q
"
995,DeepWarp: DNN-based Nonlinear Deformation,"  DeepWarp is an efficient and highly re-usable deep neural network (DNN) based
nonlinear deformable simulation framework. Unlike other deep learning
applications such as image recognition, where different inputs have a uniform
and consistent format (e.g. an array of all the pixels in an image), the input
for deformable simulation is quite variable, high-dimensional, and
parametrization-unfriendly. Consequently, even though DNN is known for its rich
expressivity of nonlinear functions, directly using DNN to reconstruct the
force-displacement relation for general deformable simulation is nearly
impossible. DeepWarp obviates this difficulty by partially restoring the
force-displacement relation via warping the nodal displacement simulated using
a simplistic constitutive model -- the linear elasticity. In other words,
DeepWarp yields an incremental displacement fix based on a simplified
(therefore incorrect) simulation result other than returning the unknown
displacement directly. We contrive a compact yet effective feature vector
including geodesic, potential and digression to sort training pairs of per-node
linear and nonlinear displacement. DeepWarp is robust under different model
shapes and tessellations. With the assistance of deformation substructuring,
one DNN training is able to handle a wide range of 3D models of various
geometries including most examples shown in the paper. Thanks to the linear
elasticity and its constant system matrix, the underlying simulator only needs
to perform one pre-factorized matrix solve at each time step, and DeepWarp is
able to simulate large models in real time.
"
996,P2P-NET: Bidirectional Point Displacement Net for Shape Transform,"  We introduce P2P-NET, a general-purpose deep neural network which learns
geometric transformations between point-based shape representations from two
domains, e.g., meso-skeletons and surfaces, partial and complete scans, etc.
The architecture of the P2P-NET is that of a bi-directional point displacement
network, which transforms a source point set to a target point set with the
same cardinality, and vice versa, by applying point-wise displacement vectors
learned from data. P2P-NET is trained on paired shapes from the source and
target domains, but without relying on point-to-point correspondences between
the source and target point sets. The training loss combines two
uni-directional geometric losses, each enforcing a shape-wise similarity
between the predicted and the target point sets, and a cross-regularization
term to encourage consistency between displacement vectors going in opposite
directions. We develop and present several different applications enabled by
our general-purpose bidirectional P2P-NET to highlight the effectiveness,
versatility, and potential of our network in solving a variety of point-based
shape transformation problems.
"
997,"Scalable closed-form trajectories for periodic and non-periodic
  human-like walking","  We present a new framework to generate human-like lower-limb trajectories in
periodic and non-periodic walking conditions. In our method, walking dynamics
is encoded in 3LP, a linear simplified model composed of three pendulums to
model falling, swing and torso balancing dynamics. To stabilize the motion, we
use an optimal time-projecting controller which suggests new footstep
locations. On top of gait generation and stabilization in the simplified space,
we introduce a kinematic conversion method that synthesizes more human-like
trajectories by combining geometric variables of the 3LP model adaptively.
Without any tuning, numerical optimization or off-line data, our walking gaits
are scalable with respect to body properties and gait parameters. We can change
various parameters such as body mass and height, walking direction, speed,
frequency, double support time, torso style, ground clearance and terrain
inclination. We can also simulate the effect of constant external dragging
forces or momentary perturbations. The proposed framework offers closed-form
solutions in all the three stages which enable simulation speeds orders of
magnitude faster than real time. This can be used for video games and
animations on portable electronic devices with a limited power. It also gives
insights for generation of more human-like walking gaits with humanoid robots.
"
998,H-CNN: Spatial Hashing Based CNN for 3D Shape Analysis,"  We present a novel spatial hashing based data structure to facilitate 3D
shape analysis using convolutional neural networks (CNNs). Our method well
utilizes the sparse occupancy of 3D shape boundary and builds hierarchical hash
tables for an input model under different resolutions. Based on this data
structure, we design two efficient GPU algorithms namely hash2col and col2hash
so that the CNN operations like convolution and pooling can be efficiently
parallelized. The spatial hashing is nearly minimal, and our data structure is
almost of the same size as the raw input. Compared with state-of-the-art
octree-based methods, our data structure significantly reduces the memory
footprint during the CNN training. As the input geometry features are more
compactly packed, CNN operations also run faster with our data structure. The
experiment shows that, under the same network structure, our method yields
comparable or better benchmarks compared to the state-of-the-art while it has
only one-third memory consumption. Such superior memory performance allows the
CNN to handle high-resolution shape analysis.
"
999,Deep Appearance Maps,"  We propose a deep representation of appearance, i. e., the relation of color,
surface orientation, viewer position, material and illumination. Previous
approaches have useddeep learning to extract classic appearance
representationsrelating to reflectance model parameters (e. g., Phong)
orillumination (e. g., HDR environment maps). We suggest todirectly represent
appearance itself as a network we call aDeep Appearance Map (DAM). This is a 4D
generalizationover 2D reflectance maps, which held the view direction fixed.
First, we show how a DAM can be learned from images or video frames and later
be used to synthesize appearance, given new surface orientations and viewer
positions. Second, we demonstrate how another network can be used to map from
an image or video frames to a DAM network to reproduce this appearance, without
using a lengthy optimization such as stochastic gradient descent
(learning-to-learn). Finally, we show the example of an appearance
estimation-and-segmentation task, mapping from an image showingmultiple
materials to multiple deep appearance maps.
"
1000,"Palette-based image decomposition, harmonization, and color transfer","  We present a palette-based framework for color composition for visual
applications. Color composition is a critical aspect of visual applications in
art, design, and visualization. The color wheel is often used to explain
pleasing color combinations in geometric terms, and, in digital design, to
provide a user interface to visualize and manipulate colors. We abstract
relationships between palette colors as a compact set of axes describing
harmonic templates over perceptually uniform color wheels. Our framework
provides a basis for a variety of color-aware image operations, such as color
harmonization and color transfer, and can be applied to videos. To enable our
approach, we introduce an extremely scalable and efficient yet simple
palette-based image decomposition algorithm. Our approach is based on the
geometry of images in RGBXY-space. This new geometric approach is orders of
magnitude more efficient than previous work and requires no numerical
optimization. We demonstrate a real-time layer decomposition tool. After
preprocessing, our algorithm can decompose 6 MP images into layers in 20
milliseconds. We also conducted three large-scale, wide-ranging perceptual
studies on the perception of harmonic colors and harmonization algorithms.
"
1001,"How could we ignore the lens and pupils of eyeballs: Metamaterial optics
  for retinal projection","  Retinal projection is required for xR applications that can deliver immersive
visual experience throughout the day. If general-purpose retinal projection
methods can be realized at a low cost, not only could the image be displayed on
the retina using less energy, but there is also the possibility of cutting off
the weight of projection unit itself from the AR goggles. Several retinal
projection methods have been previously proposed; however, as the lenses and
iris of the eyeball are in front of the retina, which is a limitation of the
eyeball, the proposal of retinal projection is generally fraught with narrow
viewing angles and small eyebox problems. In this short technical report, we
introduce ideas and samples of an optical system for solving the common
problems of retinal projection by using the metamaterial mirror (plane
symmetric transfer optical system). Using this projection method, the designing
of retinal projection can becomes easy, and if appropriate optics are
available, it would be possible to construct an optical system that allows the
quick follow-up of retinal projection hardware.
"
1002,Learning-based Video Motion Magnification,"  Video motion magnification techniques allow us to see small motions
previously invisible to the naked eyes, such as those of vibrating airplane
wings, or swaying buildings under the influence of the wind. Because the motion
is small, the magnification results are prone to noise or excessive blurring.
The state of the art relies on hand-designed filters to extract representations
that may not be optimal. In this paper, we seek to learn the filters directly
from examples using deep convolutional neural networks. To make training
tractable, we carefully design a synthetic dataset that captures small motion
well, and use two-frame input for training. We show that the learned filters
achieve high-quality results on real videos, with less ringing artifacts and
better noise characteristics than previous methods. While our model is not
trained with temporal filters, we found that the temporal filters can be used
with our extracted representations up to a moderate magnification, enabling a
frequency-based motion selection. Finally, we analyze the learned filters and
show that they behave similarly to the derivative filters used in previous
works. Our code, trained model, and datasets will be available online.
"
1003,"DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based
  Character Skills","  A longstanding goal in character animation is to combine data-driven
specification of behavior with a system that can execute a similar behavior in
a physical simulation, thus enabling realistic responses to perturbations and
environmental variation. We show that well-known reinforcement learning (RL)
methods can be adapted to learn robust control policies capable of imitating a
broad range of example motion clips, while also learning complex recoveries,
adapting to changes in morphology, and accomplishing user-specified goals. Our
method handles keyframed motions, highly-dynamic actions such as
motion-captured flips and spins, and retargeted motions. By combining a
motion-imitation objective with a task objective, we can train characters that
react intelligently in interactive settings, e.g., by walking in a desired
direction or throwing a ball at a user-specified target. This approach thus
combines the convenience and motion quality of using motion clips to define the
desired style and appearance, with the flexibility and generality afforded by
RL methods and physics-based animation. We further explore a number of methods
for integrating multiple clips into the learning process to develop
multi-skilled agents capable of performing a rich repertoire of diverse skills.
We demonstrate results using multiple characters (human, Atlas robot, bipedal
dinosaur, dragon) and a large variety of skills, including locomotion,
acrobatics, and martial arts.
"
1004,Deep Painterly Harmonization,"  Copying an element from a photo and pasting it into a painting is a
challenging task. Applying photo compositing techniques in this context yields
subpar results that look like a collage --- and existing painterly stylization
algorithms, which are global, perform poorly when applied locally. We address
these issues with a dedicated algorithm that carefully determines the local
statistics to be transferred. We ensure both spatial and inter-scale
statistical consistency and demonstrate that both aspects are key to generating
quality results. To cope with the diversity of abstraction levels and types of
paintings, we introduce a technique to adjust the parameters of the transfer
depending on the painting. We show that our algorithm produces significantly
better results than photo compositing or global stylization techniques and that
it enables creative painterly edits that would be otherwise difficult to
achieve.
"
1005,Poly-Spline Finite Element Method,"  We introduce an integrated meshing and finite element method pipeline
enabling black-box solution of partial differential equations in the volume
enclosed by a boundary representation. We construct a hybrid
hexahedral-dominant mesh, which contains a small number of star-shaped
polyhedra, and build a set of high-order basis on its elements, combining
triquadratic B-splines, triquadratic hexahedra (27 degrees of freedom), and
harmonic elements. We demonstrate that our approach converges cubically under
refinement, while requiring around 50% of the degrees of freedom than a
similarly dense hexahedral mesh composed of triquadratic hexahedra. We validate
our approach solving Poisson's equation on a large collection of models, which
are automatically processed by our algorithm, only requiring the user to
provide boundary conditions on their surface.
"
1006,ModelFactory: A Matlab/Octave based toolbox to create human body models,"  Background: Model-based analysis of movements can help better understand
human motor control. Here, the models represent the human body as an
articulated multi-body system that reflects the characteristics of the human
being studied.
  Results: We present an open-source toolbox that allows for the creation of
human models with easy-to-setup, customizable configurations. The toolbox
scripts are written in Matlab/Octave and provide a command-based interface as
well as a graphical interface to construct, visualize and export models.
Built-in software modules provide functionalities such as automatic scaling of
models based on subject height and weight, custom scaling of segment lengths,
mass and inertia, addition of body landmarks, and addition of motion capture
markers. Users can set up custom definitions of joints, segments and other body
properties using the many included examples as templates. In addition to the
human, any number of objects (e.g. exoskeletons, orthoses, prostheses, boxes)
can be added to the modeling environment.
  Conclusions: The ModelFactory toolbox is published as open-source software
under the permissive zLib license. The toolbox fulfills an important function
by making it easier to create human models, and should be of interest to human
movement researchers.
  This document is the author's version of this article.
"
1007,"RSGAN: Face Swapping and Editing using Face and Hair Representation in
  Latent Spaces","  In this paper, we present an integrated system for automatically generating
and editing face images through face swapping, attribute-based editing, and
random face parts synthesis. The proposed system is based on a deep neural
network that variationally learns the face and hair regions with large-scale
face image datasets. Different from conventional variational methods, the
proposed network represents the latent spaces individually for faces and hairs.
We refer to the proposed network as region-separative generative adversarial
network (RSGAN). The proposed network independently handles face and hair
appearances in the latent spaces, and then, face swapping is achieved by
replacing the latent-space representations of the faces, and reconstruct the
entire face image with them. This approach in the latent space robustly
performs face swapping even for images which the previous methods result in
failure due to inappropriate fitting or the 3D morphable models. In addition,
the proposed system can further edit face-swapped images with the same network
by manipulating visual attributes or by composing them with randomly generated
face or hair parts.
"
1008,Edge-based LBP description of surfaces with colorimetric patterns,"  In this paper we target the problem of the retrieval of colour patterns over
surfaces. We generalize to surface tessellations the well known Local Binary
Pattern (LBP) descriptor for images. The key concept of the LBP is to code the
variability of the colour values around each pixel. In the case of a surface
tessellation we adopt rings around vertices that are obtained with a
sphere-mesh intersection driven by the edges of the mesh; for this reason, we
name our method edgeLBP. Experimental results are provided to show how this
description performs well for pattern retrieval, also when patterns come from
degraded and corrupted archaeological fragments.
"
1009,"Experimental similarity assessment for a collection of fragmented
  artifacts","  In the Visual Heritage domain, search engines are expected to support
archaeologists and curators to address cross-correlation and searching across
multiple collections. Archaeological excavations return artifacts that often
are damaged with parts that are fragmented in more pieces or totally missing.
The notion of similarity among fragments cannot simply base on the geometric
shape but style, material, color, decorations, etc. are all important factors
that concur to this concept. In this work, we discuss to which extent the
existing techniques for 3D similarity matching are able to approach fragment
similarity, what is missing and what is necessary to be further developed.
"
1010,"Weighted simplicial complex reconstruction from mobile laser scanning
  using sensor topology","  We propose a new method for the reconstruction of simplicial complexes
(combining points, edges and triangles) from 3D point clouds from Mobile Laser
Scanning (MLS). Our method uses the inherent topology of the MLS sensor to
define a spatial adjacency relationship between points. We then investigate
each possible connexion between adjacent points, weighted according to its
distance to the sensor, and filter them by searching collinear structures in
the scene, or structures perpendicular to the laser beams. Next, we create and
filter triangles for each triplet of self-connected edges and according to
their local planarity. We compare our results to an unweighted simplicial
complex reconstruction.
"
1011,Deformation Capture via Soft and Stretchable Sensor Arrays,"  We propose a hardware and software pipeline to fabricate flexible wearable
sensors and use them to capture deformations without line of sight. Our first
contribution is a low-cost fabrication pipeline to embed multiple aligned
conductive layers with complex geometries into silicone compounds. Overlapping
conductive areas from separate layers form local capacitors that measure dense
area changes. Contrary to existing fabrication methods, the proposed technique
only requires hardware that is readily available in modern fablabs. While area
measurements alone are not enough to reconstruct the full 3D deformation of a
surface, they become sufficient when paired with a data-driven prior. A novel
semi-automatic tracking algorithm, based on an elastic surface geometry
deformation, allows to capture ground-truth data with an optical mocap system,
even under heavy occlusions or partially unobservable markers. The resulting
dataset is used to train a regressor based on deep neural networks, directly
mapping the area readings to global positions of surface vertices. We
demonstrate the flexibility and accuracy of the proposed hardware and software
in a series of controlled experiments, and design a prototype of wearable
wrist, elbow and biceps sensors, which do not require line-of-sight and can be
worn below regular clothing.
"
1012,Visualization and Labeling of Point Clouds in Virtual Reality,"  We present a Virtual Reality (VR) application for labeling and handling point
cloud data sets. A series of room-scale point clouds are recorded as a video
sequence using a Microsoft Kinect. The data can be played and paused, and
frames can be skipped just like in a video player. The user can walk around and
inspect the data while it is playing or paused. Using the tracked hand-held
controller, the user can select and label individual parts of the point cloud.
The points are highlighted with a color when they are labeled. With a tracking
algorithm, the labeled points can be tracked from frame to frame to ease the
labeling process. Our sample data is an RGB point cloud recording of two people
juggling with pins. Here, the user can select and label, for example, the
juggler pins as shown in Figure 1. Each juggler pin is labeled with various
colors to indicate di erent labels.
"
1013,Image Correction via Deep Reciprocating HDR Transformation,"  Image correction aims to adjust an input image into a visually pleasing one.
Existing approaches are proposed mainly from the perspective of image pixel
manipulation. They are not effective to recover the details in the under/over
exposed regions. In this paper, we revisit the image formation procedure and
notice that the missing details in these regions exist in the corresponding
high dynamic range (HDR) data. These details are well perceived by the human
eyes but diminished in the low dynamic range (LDR) domain because of the tone
mapping process. Therefore, we formulate the image correction task as an HDR
transformation process and propose a novel approach called Deep Reciprocating
HDR Transformation (DRHT). Given an input LDR image, we first reconstruct the
missing details in the HDR domain. We then perform tone mapping on the
predicted HDR data to generate the output LDR image with the recovered details.
To this end, we propose a united framework consisting of two CNNs for HDR
reconstruction and tone mapping. They are integrated end-to-end for joint
training and prediction. Experiments on the standard benchmarks demonstrate
that the proposed method performs favorably against state-of-the-art image
correction methods.
"
1014,TomoReal: Tomographic Displays,"  Since the history of display technologies began, people have dreamed an
ultimate 3D display system. In order to get close to the dream, 3D displays
should provide both of psychological and physiological cues for recognition of
depth information. However, it is challenging to satisfy the essential features
without sacrifice in conventional technical values including resolution, frame
rate, and eye-box. Here, we present a new type of 3D displays: tomographic
displays. We claim that tomographic displays may support extremely wide depth
of field, quasi-continuous accommodation, omni-directional motion parallax,
preserved resolution, full frame, and moderate field of view within enough
eye-box. Tomographic displays consist of focus-tunable optics, 2D display
panel, and fast spatially adjustable backlight. The synchronization of the
focus-tunable optics and the backlight enables the 2D display panel to express
the depth information. Tomographic displays have various applications including
tabletop 3D displays, head-up displays, and near-eye stereoscopes. In this
study, we implement a near-eye display named TomoReal, which is one of the most
promising application of tomographic displays. We conclude with the detailed
analysis and thorough discussion for tomographic displays, which would open a
new research field.
"
1015,Physics-driven Fire Modeling from Multi-view Images,"  Fire effects are widely used in various computer graphics applications such
as visual effects and video games. Modeling the shape and appearance of fire
phenomenon is challenging as the underlying effects are driven by complex laws
of physics. State-of-the-art fire modeling techniques rely on sophisticated
physical simulations which require intensive parameter tuning, or use
simplifications which produce physically invalid results. In this paper, we
present a novel method of reconstructing physically valid fire models from
multi-view stereo images. Our method, for the first time, provides plausible
estimation of physical properties (e.g., temperature, density) of a fire volume
using RGB cameras. This allows for a number of novel phenomena such as global
fire illumination effects. The effectiveness and usefulness of our method are
tested by generating fire models from a variety of input data, and applying the
reconstructed fire models for realistic illumination of virtual scenes.
"
1016,A Novel Parallel Ray-Casting Algorithm,"  The Ray-Casting algorithm is an important method for fast real-time surface
display from 3D medical images. Based on the Ray-Casting algorithm, a novel
parallel Ray-Casting algorithm is proposed in this paper. A novel operation is
introduced and defined as a star operation, and star operations can be computed
in parallel in the proposed algorithm compared with the serial chain of star
operations in the Ray-Casting algorithm. The computation complexity of the
proposed algorithm is reduced from $O(n)$ to $O(\log^n_2)$.
"
1017,Normal Image Manipulation for Bas-relief Generation with Hybrid Styles,"  We introduce a normal-based bas-relief generation and stylization method
which is motivated by the recent advancement in this topic. Creating bas-relief
from normal images has successfully facilitated bas-relief modeling in image
space. However, the use of normal images in previous work is often restricted
to certain type of operations only. This paper is intended to extend
normal-based methods and construct bas-reliefs from normal images in a
versatile way. Our method can not only generate a new normal image by combining
various frequencies of existing normal images and details transferring, but
also build bas-reliefs from a single RGB image and its edge-based sketch image.
In addition, we introduce an auxiliary function to represent a smooth base
surface and generate a layered global shape. To integrate above considerations
into our framework, we formulate the bas- relief generation as a variational
problem which can be solved by a screened Poisson equation. Some advantages of
our method are that it expands the bas-relief shape space and generates
diversified styles of results, and that it is capable of transferring details
from one region to other regions. Our method is easy to implement, and produces
good-quality bas-relief models. We experiment our method on a range of normal
images and it compares favorably to other popular classic and state-of-the-art
methods.
"
1018,Semi-Supervised Co-Analysis of 3D Shape Styles from Projected Lines,"  We present a semi-supervised co-analysis method for learning 3D shape styles
from projected feature lines, achieving style patch localization with only weak
supervision. Given a collection of 3D shapes spanning multiple object
categories and styles, we perform style co-analysis over projected feature
lines of each 3D shape and then backproject the learned style features onto the
3D shapes. Our core analysis pipeline starts with mid-level patch sampling and
pre-selection of candidate style patches. Projective features are then encoded
via patch convolution. Multi-view feature integration and style clustering are
carried out under the framework of partially shared latent factor (PSLF)
learning, a multi-view feature learning scheme. PSLF achieves effective
multi-view feature fusion by distilling and exploiting consistent and
complementary feature information from multiple views, while also selecting
style patches from the candidates. Our style analysis approach supports both
unsupervised and semi-supervised analysis. For the latter, our method accepts
both user-specified shape labels and style-ranked triplets as clustering
constraints.We demonstrate results from 3D shape style analysis and patch
localization as well as improvements over state-of-the-art methods. We also
present several applications enabled by our style analysis.
"
1019,A New Radial Basis Function Approximation with Reproduction,"  Approximation of scattered geometric data is often a task in many engineering
problems. The Radial Basis Function (RBF) approximation is appropriate for
large scattered (unordered) datasets in d-dimensional space. This method is
useful for a higher dimension d>=2, because the other methods require a
conversion of a scattered dataset to a semi-regular mesh using some
tessellation techniques, which is computationally expensive. The RBF
approximation is non-separable, as it is based on a distance of two points. It
leads to a solution of overdetermined Linear System of Equations (LSE). In this
paper a new RBF approximation method is derived and presented. The presented
approach is applicable for d dimensional cases in general.
"
1020,Metamorphs: Bistable Planar Structures,"  Extreme deformation can drastically morph a structure from one structural
form into another. Programming such deformation properties into the structure
is often challenging and in many cases an impossible task. The morphed forms do
not hold and usually relapse to the original form, where the structure is in
its lowest energy state. For example, a stick, when bent, resists its bent form
and tends to go back to its initial straight form, where it holds the least
amount of potential energy.
  In this project, we present a computational design method which can create
fabricable planar structure that can morph into two different bistable forms.
Once the user provides the initial desired forms, the method automatically
creates support structures (internal springs), such that, the structure can not
only morph, but also hold the respective forms under external force
application. We achieve this through an iterative nonlinear optimization
strategy for shaping the potential energy of the structure in the two forms
simultaneously. Our approach guarantees first and second-order stability with
respect to the potential energy of the bistable structure.
"
1021,"Large Margin Structured Convolution Operator for Thermal Infrared Object
  Tracking","  Compared with visible object tracking, thermal infrared (TIR) object tracking
can track an arbitrary target in total darkness since it cannot be influenced
by illumination variations. However, there are many unwanted attributes that
constrain the potentials of TIR tracking, such as the absence of visual color
patterns and low resolutions. Recently, structured output support vector
machine (SOSVM) and discriminative correlation filter (DCF) have been
successfully applied to visible object tracking, respectively. Motivated by
these, in this paper, we propose a large margin structured convolution operator
(LMSCO) to achieve efficient TIR object tracking. To improve the tracking
performance, we employ the spatial regularization and implicit interpolation to
obtain continuous deep feature maps, including deep appearance features and
deep motion features, of the TIR targets. Finally, a collaborative optimization
strategy is exploited to significantly update the operators. Our approach not
only inherits the advantage of the strong discriminative capability of SOSVM
but also achieves accurate and robust tracking with higher-dimensional features
and more dense samples. To the best of our knowledge, we are the first to
incorporate the advantages of DCF and SOSVM for TIR object tracking.
Comprehensive evaluations on two thermal infrared tracking benchmarks, i.e.
VOT-TIR2015 and VOT-TIR2016, clearly demonstrate that our LMSCO tracker
achieves impressive results and outperforms most state-of-the-art trackers in
terms of accuracy and robustness with sufficient frame rate.
"
1022,A Complementary Tracking Model with Multiple Features,"  Discriminative Correlation Filters based tracking algorithms exploiting
conventional handcrafted features have achieved impressive results both in
terms of accuracy and robustness. Template handcrafted features have shown
excellent performance, but they perform poorly when the appearance of target
changes rapidly such as fast motions and fast deformations. In contrast,
statistical handcrafted features are insensitive to fast states changes, but
they yield inferior performance in the scenarios of illumination variations and
background clutters. In this work, to achieve an efficient tracking
performance, we propose a novel visual tracking algorithm, named MFCMT, based
on a complementary ensemble model with multiple features, including Histogram
of Oriented Gradients (HOGs), Color Names (CNs) and Color Histograms (CHs).
Additionally, to improve tracking results and prevent targets drift, we
introduce an effective fusion method by exploiting relative entropy to coalesce
all basic response maps and get an optimal response. Furthermore, we suggest a
simple but efficient update strategy to boost tracking performance.
Comprehensive evaluations are conducted on two tracking benchmarks demonstrate
and the experimental results demonstrate that our method is competitive with
numerous state-of-the-art trackers. Our tracker achieves impressive performance
with faster speed on these benchmarks.
"
1023,"syGlass: Interactive Exploration of Multidimensional Images Using
  Virtual Reality Head-mounted Displays","  The quest for deeper understanding of biological systems has driven the
acquisition of increasingly larger multidimensional image datasets. Inspecting
and manipulating data of this complexity is very challenging in traditional
visualization systems. We developed syGlass, a software package capable of
visualizing large scale volumetric data with inexpensive virtual reality
head-mounted display technology. This allows leveraging stereoscopic vision to
significantly improve perception of complex 3D structures, and provides
immersive interaction with data directly in 3D. We accomplished this by
developing highly optimized data flow and volume rendering pipelines, tested on
datasets up to 16TB in size, as well as tools available in a virtual reality
GUI to support advanced data exploration, annotation, and cataloguing.
"
1024,ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning,"  The process of aligning a pair of shapes is a fundamental operation in
computer graphics. Traditional approaches rely heavily on matching
corresponding points or features to guide the alignment, a paradigm that
falters when significant shape portions are missing. These techniques generally
do not incorporate prior knowledge about expected shape characteristics, which
can help compensate for any misleading cues left by inaccuracies exhibited in
the input shapes. We present an approach based on a deep neural network,
leveraging shape datasets to learn a shape-aware prior for source-to-target
alignment that is robust to shape incompleteness. In the absence of ground
truth alignments for supervision, we train a network on the task of shape
alignment using incomplete shapes generated from full shapes for
self-supervision. Our network, called ALIGNet, is trained to warp complete
source shapes to incomplete targets, as if the target shapes were complete,
thus essentially rendering the alignment partial-shape agnostic. We aim for the
network to develop specialized expertise over the common characteristics of the
shapes in each dataset, thereby achieving a higher-level understanding of the
expected shape space to which a local approach would be oblivious. We constrain
ALIGNet through an anisotropic total variation identity regularization to
promote piecewise smooth deformation fields, facilitating both partial-shape
agnosticism and post-deformation applications. We demonstrate that ALIGNet
learns to align geometrically distinct shapes, and is able to infer plausible
mappings even when the target shape is significantly incomplete. We show that
our network learns the common expected characteristics of shape collections,
without over-fitting or memorization, enabling it to produce plausible
deformations on unseen data during test time.
"
1025,Half-Space Power Diagrams and Discrete Surface Offsets,"  We present an efficient, trivially parallelizable algorithm to compute offset
surfaces of shapes discretized using a dexel data structure. Our algorithm is
based on a two-stage sweeping procedure that is simple to implement and
efficient, entirely avoiding volumetric distance field computations typical of
existing methods. Our construction is based on properties of half-space power
diagrams, where each seed is only visible by a half-space, which were never
used before for the computation of surface offsets. The primary application of
our method is interactive modeling for digital fabrication. Our technique
enables a user to interactively process high-resolution models. It is also
useful in a plethora of other geometry processing tasks requiring fast,
approximate offsets, such as topology optimization, collision detection, and
skeleton extraction. We present experimental timings, comparisons with previous
approaches, and provide a reference implementation in the supplemental
material.
"
1026,FaceShop: Deep Sketch-based Face Image Editing,"  We present a novel system for sketch-based face image editing, enabling users
to edit images intuitively by sketching a few strokes on a region of interest.
Our interface features tools to express a desired image manipulation by
providing both geometry and color constraints as user-drawn strokes. As an
alternative to the direct user input, our proposed system naturally supports a
copy-paste mode, which allows users to edit a given image region by using parts
of another exemplar image without the need of hand-drawn sketching at all. The
proposed interface runs in real-time and facilitates an interactive and
iterative workflow to quickly express the intended edits. Our system is based
on a novel sketch domain and a convolutional neural network trained end-to-end
to automatically learn to render image regions corresponding to the input
strokes. To achieve high quality and semantically consistent results we train
our neural network on two simultaneous tasks, namely image completion and image
translation. To the best of our knowledge, we are the first to combine these
two tasks in a unified framework for interactive image editing. Our results
show that the proposed sketch domain, network architecture, and training
procedure generalize well to real user input and enable high quality synthesis
results without additional post-processing.
"
1027,Layered Fields for Natural Tessellations on Surfaces,"  Mimicking natural tessellation patterns is a fascinating multi-disciplinary
problem. Geometric methods aiming at reproducing such partitions on surface
meshes are commonly based on the Voronoi model and its variants, and are often
faced with challenging issues such as metric estimation, geometric, topological
complications, and most critically parallelization. In this paper, we introduce
an alternate model which may be of value for resolving these issues. We drop
the assumption that regions need to be separated by lines. Instead, we regard
region boundaries as narrow bands and we model the partition as a set of smooth
functions layered over the surface. Given an initial set of seeds or regions,
the partition emerges as the solution of a time dependent set of partial
differential equations describing concurrently evolving fronts on the surface.
Our solution does not require geodesic estimation, elaborate numerical solvers,
or complicated bookkeeping data structures. The cost per time-iteration is
dominated by the multiplication and addition of two sparse matrices. Extension
of our approach in a Lloyd's algorithm fashion can be easily achieved and the
extraction of the dual mesh can be conveniently preformed in parallel through
matrix algebra. As our approach relies mainly on basic linear algebra kernels,
it lends itself to efficient implementation on modern graphics hardware.
"
1028,Taichi: An Open-Source Computer Graphics Library,"  An ideal software system in computer graphics should be a combination of
innovative ideas, solid software engineering and rapid development. However, in
reality these requirements are seldom met simultaneously. In this paper, we
present early results on an open-source library named Taichi
(http://taichi.graphics), which alleviates this practical issue by providing an
accessible, portable, extensible, and high-performance infrastructure that is
reusable and tailored for computer graphics. As a case study, we share our
experience in building a novel physical simulation system using Taichi.
"
1029,Probabilistic Plant Modeling via Multi-View Image-to-Image Translation,"  This paper describes a method for inferring three-dimensional (3D) plant
branch structures that are hidden under leaves from multi-view observations.
Unlike previous geometric approaches that heavily rely on the visibility of the
branches or use parametric branching models, our method makes statistical
inferences of branch structures in a probabilistic framework. By inferring the
probability of branch existence using a Bayesian extension of image-to-image
translation applied to each of multi-view images, our method generates a
probabilistic plant 3D model, which represents the 3D branching pattern that
cannot be directly observed. Experiments demonstrate the usefulness of the
proposed approach in generating convincing branch structures in comparison to
prior approaches.
"
1030,Semi-parametric Image Synthesis,"  We present a semi-parametric approach to photographic image synthesis from
semantic layouts. The approach combines the complementary strengths of
parametric and nonparametric techniques. The nonparametric component is a
memory bank of image segments constructed from a training set of images. Given
a novel semantic layout at test time, the memory bank is used to retrieve
photographic references that are provided as source material to a deep network.
The synthesis is performed by a deep network that draws on the provided
photographic material. Experiments on multiple semantic segmentation datasets
show that the presented approach yields considerably more realistic images than
recent purely parametric techniques. The results are shown in the supplementary
video at https://youtu.be/U4Q98lenGLQ
"
1031,"Hatching for 3D prints: line-based halftoning for dual extrusion fused
  deposition modeling","  This work presents a halftoning technique to manufacture 3D objects with the
appearance of continuous grayscale imagery for Fused Deposition Modeling (FDM)
printers. While droplet-based dithering is a common halftoning technique, this
is not applicable to FDM printing, since FDM builds up objects by extruding
material in semi-continuous paths. The line-based halftoning principle called
'hatching' is applied to the line patterns naturally occuring in FDM prints,
which are built up in a layer-by-layer fashion. The proposed halftoning
technique isn't limited by the challenges existing techniques face; existing
FDM coloring techniques greatly influence the surface geometry and deteriorate
with surface slopes deviating from vertical or greatly influence the basic
parameters of the printing process and thereby the structural properties of the
resulting product. Furthermore, the proposed technique has little effect on
printing time. Experiments on a dual-nozzle FDM printer show promising results.
Future work is required to calibrate the perceived tone.
"
1032,Learning to See in the Dark,"  Imaging in low light is challenging due to low photon count and low SNR.
Short-exposure images suffer from noise, while long exposure can induce blur
and is often impractical. A variety of denoising, deblurring, and enhancement
techniques have been proposed, but their effectiveness is limited in extreme
conditions, such as video-rate imaging at night. To support the development of
learning-based pipelines for low-light image processing, we introduce a dataset
of raw short-exposure low-light images, with corresponding long-exposure
reference images. Using the presented dataset, we develop a pipeline for
processing low-light images, based on end-to-end training of a
fully-convolutional network. The network operates directly on raw sensor data
and replaces much of the traditional image processing pipeline, which tends to
perform poorly on such data. We report promising results on the new dataset,
analyze factors that affect performance, and highlight opportunities for future
work. The results are shown in the supplementary video at
https://youtu.be/qWKUFK7MWvg
"
1033,"GeneVis - An interactive visualization tool for combining
  cross-discipline datasets within genetics","  GeneVis is a web-based tool to visualize complementary data sets of different
disciplines within the field of genetics. It overlays gene-cluster information,
gene-interaction data and gene-disease association data by means of web-based
interactive graph visualizations. This allows an intuitive and quick assessment
of possible relations between the different datasets. By starting from a
high-level graph abstraction based on gene clusters, which can be selected for
detailed inspection at the gene-interaction level in a separate window, GeneVis
circumvents the common visual clutter problem when using gene datasets with a
high number of gene entries.
"
1034,A Radiative Transfer Framework for Spatially-Correlated Materials,"  We introduce a non-exponential radiative framework that takes into account
the local spatial correlation of scattering particles in a medium. Most
previous works in graphics have ignored this, assuming uncorrelated media with
a uniform, random local distribution of particles. However, positive and
negative correlation lead to slower- and faster-than-exponential attenuation
respectively, which cannot be predicted by the Beer-Lambert law. As our results
show, this has a major effect on extinction, and thus appearance. From recent
advances in neutron transport, we first introduce our Extended Generalized
Boltzmann Equation, and develop a general framework for light transport in
correlated media. We lift the limitations of the original formulation,
including an analysis of the boundary conditions, and present a model suitable
for computer graphics, based on optical properties of the media and statistical
distributions of scatterers. In addition, we present an analytic expression for
transmittance in the case of positive correlation, and show how to incorporate
it efficiently into a Monte Carlo renderer. We show results with a wide range
of both positive and negative correlation, and demonstrate the differences
compared to classic light transport.
"
1035,Full 3D Reconstruction of Transparent Objects,"  Numerous techniques have been proposed for reconstructing 3D models for
opaque objects in past decades. However, none of them can be directly applied
to transparent objects. This paper presents a fully automatic approach for
reconstructing complete 3D shapes of transparent objects. Through positioning
an object on a turntable, its silhouettes and light refraction paths under
different viewing directions are captured. Then, starting from an initial rough
model generated from space carving, our algorithm progressively optimizes the
model under three constraints: surface and refraction normal consistency,
surface projection and silhouette consistency, and surface smoothness.
Experimental results on both synthetic and real objects demonstrate that our
method can successfully recover the complex shapes of transparent objects and
faithfully reproduce their light refraction properties.
"
1036,"LSTM-Based Facial Performance Capture Using Embedding Between
  Expressions","  We present a novel end-to-end framework for facial performance capture given
a monocular video of an actor's face. Our framework are comprised of 2 parts.
First, to extract the information in the frames, we optimize a triplet loss to
learn the embedding space which ensures the semantically closer facial
expressions are closer in the embedding space and the model can be transferred
to distinguish the expressions that are not presented in the training dataset.
Second, the embeddings are fed into an LSTM network to learn the deformation
between frames. In the experiments, we demonstrated that compared to other
methods, our method can distinguish the delicate motion around lips and
significantly reduce jitters between the tracked meshes.
"
1037,Non-Stationary Texture Synthesis by Adversarial Expansion,"  The real world exhibits an abundance of non-stationary textures. Examples
include textures with large-scale structures, as well as spatially variant and
inhomogeneous textures. While existing example-based texture synthesis methods
can cope well with stationary textures, non-stationary textures still pose a
considerable challenge, which remains unresolved. In this paper, we propose a
new approach for example-based non-stationary texture synthesis. Our approach
uses a generative adversarial network (GAN), trained to double the spatial
extent of texture blocks extracted from a specific texture exemplar. Once
trained, the fully convolutional generator is able to expand the size of the
entire exemplar, as well as of any of its sub-blocks. We demonstrate that this
conceptually simple approach is highly effective for capturing large-scale
structures, as well as other non-stationary attributes of the input exemplar.
As a result, it can cope with challenging textures, which, to our knowledge, no
other existing method can handle.
"
1038,Unsupervised Learning for Fast Probabilistic Diffeomorphic Registration,"  Traditional deformable registration techniques achieve impressive results and
offer a rigorous theoretical treatment, but are computationally intensive since
they solve an optimization problem for each image pair. Recently,
learning-based methods have facilitated fast registration by learning spatial
deformation functions. However, these approaches use restricted deformation
models, require supervised labels, or do not guarantee a diffeomorphic
(topology-preserving) registration. Furthermore, learning-based registration
tools have not been derived from a probabilistic framework that can offer
uncertainty estimates. In this paper, we present a probabilistic generative
model and derive an unsupervised learning-based inference algorithm that makes
use of recent developments in convolutional neural networks (CNNs). We
demonstrate our method on a 3D brain registration task, and provide an
empirical analysis of the algorithm. Our approach results in state of the art
accuracy and very fast runtimes, while providing diffeomorphic guarantees and
uncertainty estimates. Our implementation is available online at
http://voxelmorph.csail.mit.edu .
"
1039,Scene-Aware Audio for 360\textdegree{} Videos,"  Although 360\textdegree{} cameras ease the capture of panoramic footage, it
remains challenging to add realistic 360\textdegree{} audio that blends into
the captured scene and is synchronized with the camera motion. We present a
method for adding scene-aware spatial audio to 360\textdegree{} videos in
typical indoor scenes, using only a conventional mono-channel microphone and a
speaker. We observe that the late reverberation of a room's impulse response is
usually diffuse spatially and directionally. Exploiting this fact, we propose a
method that synthesizes the directional impulse response between any source and
listening locations by combining a synthesized early reverberation part and a
measured late reverberation tail. The early reverberation is simulated using a
geometric acoustic simulation and then enhanced using a frequency modulation
method to capture room resonances. The late reverberation is extracted from a
recorded impulse response, with a carefully chosen time duration that separates
out the late reverberation from the early reverberation. In our validations, we
show that our synthesized spatial audio matches closely with recordings using
ambisonic microphones. Lastly, we demonstrate the strength of our method in
several applications.
"
1040,Anderson Acceleration for Geometry Optimization and Physics Simulation,"  Many computer graphics problems require computing geometric shapes subject to
certain constraints. This often results in non-linear and non-convex
optimization problems with globally coupled variables, which pose great
challenge for interactive applications. Local-global solvers developed in
recent years can quickly compute an approximate solution to such problems,
making them an attractive choice for applications that prioritize efficiency
over accuracy. However, these solvers suffer from lower convergence rate, and
may take a long time to compute an accurate result. In this paper, we propose a
simple and effective technique to accelerate the convergence of such solvers.
By treating each local-global step as a fixed-point iteration, we apply
Anderson acceleration, a well-established technique for fixed-point solvers, to
speed up the convergence of a local-global solver. To address the stability
issue of classical Anderson acceleration, we propose a simple strategy to
guarantee the decrease of target energy and ensure its global convergence. In
addition, we analyze the connection between Anderson acceleration and
quasi-Newton methods, and show that the canonical choice of its mixing
parameter is suitable for accelerating local-global solvers. Moreover, our
technique is effective beyond classical local-global solvers, and can be
applied to iterative methods with a common structure. We evaluate the
performance of our technique on a variety of geometry optimization and physics
simulation problems. Our approach significantly reduces the number of
iterations required to compute an accurate result, with only a slight increase
of computational cost per iteration. Its simplicity and effectiveness makes it
a promising tool for accelerating existing algorithms as well as designing
efficient new algorithms.
"
1041,Building Anatomically Realistic Jaw Kinematics Model from Data,"  This paper considers a different aspect of anatomical face modeling:
kinematic modeling of the jaw, i.e., the Temporo-Mandibular Joint (TMJ).
Previous work often relies on simple models of jaw kinematics, even though the
actual physiological behavior of the TMJ is quite complex, allowing not only
for mouth opening, but also for some amount of sideways (lateral) and
front-to-back (protrusion) motions. Fortuitously, the TMJ is the only joint
whose kinematics can be accurately measured with optical methods, because the
bones of the lower and upper jaw are rigidly connected to the lower and upper
teeth. We construct a person-specific jaw kinematic model by asking an actor to
exercise the entire range of motion of the jaw while keeping the lips open so
that the teeth are at least partially visible. This performance is recorded
with three calibrated cameras. We obtain highly accurate 3D models of the teeth
with a standard dental scanner and use these models to reconstruct the rigid
body trajectories of the teeth from the videos (markerless tracking). The
relative rigid transformations samples between the lower and upper teeth are
mapped to the Lie algebra of rigid body motions in order to linearize the
rotational motion. Our main contribution is to fit these samples with a
three-dimensional nonlinear model parameterizing the entire range of motion of
the TMJ. We show that standard Principal Component Analysis (PCA) fails to
capture the nonlinear trajectories of the moving mandible. However, we found
these nonlinearities can be captured with a special modification of autoencoder
neural networks known as Nonlinear PCA. By mapping back to the Lie group of
rigid transformations, we obtain parameterization of the jaw kinematics which
provides an intuitive interface allowing the animators to explore realistic jaw
motions in a user-friendly way.
"
1042,"RLFC: Random Access Light Field Compression using Key Views and Bounded
  Integer Encoding","  We present a new hierarchical compression scheme for encoding light field
images (LFI) that is suitable for interactive rendering. Our method (RLFC)
exploits redundancies in the light field images by constructing a tree
structure. The top level (root) of the tree captures the common high-level
details across the LFI, and other levels (children) of the tree capture
specific low-level details of the LFI. Our decompressing algorithm corresponds
to tree traversal operations and gathers the values stored at different levels
of the tree. Furthermore, we use bounded integer sequence encoding which
provides random access and fast hardware decoding for compressing the blocks of
children of the tree. We have evaluated our method for 4D two-plane
parameterized light fields. The compression rates vary from 0.08 - 2.5 bits per
pixel (bpp), resulting in compression ratios of around 200:1 to 20:1 for a PSNR
quality of 40 to 50 dB. The decompression times for decoding the blocks of LFI
are 1 - 3 microseconds per channel on an NVIDIA GTX-960 and we can render new
views with a resolution of 512X512 at 200 fps. Our overall scheme is simple to
implement and involves only bit manipulations and integer arithmetic
operations.
"
1043,Topological Eulerian Synthesis of Slow Motion Periodic Videos,"  We consider the problem of taking a video that is comprised of multiple
periods of repetitive motion, and reordering the frames of the video into a
single period, producing a detailed, single cycle video of motion. This problem
is challenging, as such videos often contain noise, drift due to camera motion
and from cycle to cycle, and irrelevant background motion/occlusions, and these
factors can confound the relevant periodic motion we seek in the video. To
address these issues in a simple and efficient manner, we introduce a tracking
free Eulerian approach for synthesizing a single cycle of motion. Our approach
is geometric: we treat each frame as a point in high-dimensional Euclidean
space, and analyze the sliding window embedding formed by this sequence of
points, which yields samples along a topological loop regardless of the type of
periodic motion. We combine tools from topological data analysis and spectral
geometric analysis to estimate the phase of each window, and we exploit the
sliding window structure to robustly reorder frames. We show quantitative
results that highlight the robustness of our technique to camera shake, noise,
and occlusions, and qualitative results of single-cycle motion synthesis across
a variety of scenarios.
"
1044,Automated Process Planning for Hybrid Manufacturing,"  Hybrid manufacturing (HM) technologies combine additive and subtractive
manufacturing (AM/SM) capabilities, leveraging AM's strengths in fabricating
complex geometries and SM's precision and quality to produce finished parts. We
present a systematic approach to automated computer-aided process planning
(CAPP) for HM that can identify non-trivial, qualitatively distinct, and
cost-optimal combinations of AM/SM modalities. A multimodal HM process plan is
represented by a finite Boolean expression of AM and SM manufacturing
primitives, such that the expression evaluates to an 'as-manufactured'
artifact. We show that primitives that respect spatial constraints such as
accessibility and collision avoidance may be constructed by solving inverse
configuration space problems on the 'as-designed' artifact and manufacturing
instruments. The primitives generate a finite Boolean algebra (FBA) that
enumerates the entire search space for planning. The FBA's canonical
intersection terms (i.e., 'atoms') provide the complete domain decomposition to
reframe manufacturability analysis and process planning into purely symbolic
reasoning, once a subcollection of atoms is found to be interchangeable with
the design target. The approach subsumes unimodal (all-AM or all-SM) process
planning as special cases. We demonstrate the practical potency of our
framework and its computational efficiency when applied to process planning of
complex 3D parts with dramatically different AM and SM instruments.
"
1045,Scanner: Efficient Video Analysis at Scale,"  A growing number of visual computing applications depend on the analysis of
large video collections. The challenge is that scaling applications to operate
on these datasets requires efficient systems for pixel data access and parallel
processing across large numbers of machines. Few programmers have the
capability to operate efficiently at these scales, limiting the field's ability
to explore new applications that leverage big video data. In response, we have
created Scanner, a system for productive and efficient video analysis at scale.
Scanner organizes video collections as tables in a data store optimized for
sampling frames from compressed video, and executes pixel processing
computations, expressed as dataflow graphs, on these frames. Scanner schedules
video analysis applications expressed using these abstractions onto
heterogeneous throughput computing hardware, such as multi-core CPUs, GPUs, and
media processing ASICs, for high-throughput pixel processing. We demonstrate
the productivity of Scanner by authoring a variety of video processing
applications including the synthesis of stereo VR video streams from
multi-camera rigs, markerless 3D human pose reconstruction from video, and
data-mining big video datasets such as hundreds of feature-length films or over
70,000 hours of TV news. These applications achieve near-expert performance on
a single machine and scale efficiently to hundreds of machines, enabling
formerly long-running big video data analysis tasks to be carried out in
minutes to hours.
"
1046,Object-Aware Guidance for Autonomous Scene Reconstruction,"  To carry out autonomous 3D scanning and online reconstruction of unknown
indoor scenes, one has to find a balance between global exploration of the
entire scene and local scanning of the objects within it. In this work, we
propose a novel approach, which provides object-aware guidance for
autoscanning, for exploring, reconstructing, and understanding an unknown scene
within one navigation pass. Our approach interleaves between object analysis to
identify the next best object (NBO) for global exploration, and object-aware
information gain analysis to plan the next best view (NBV) for local scanning.
First, an objectness-based segmentation method is introduced to extract
semantic objects from the current scene surface via a multi-class graph cuts
minimization. Then, an object of interest (OOI) is identified as the NBO which
the robot aims to visit and scan. The robot then conducts fine scanning on the
OOI with views determined by the NBV strategy. When the OOI is recognized as a
full object, it can be replaced by its most similar 3D model in a shape
database. The algorithm iterates until all of the objects are recognized and
reconstructed in the scene. Various experiments and comparisons have shown the
feasibility of our proposed approach.
"
1047,Improved Shortest Path Maps with GPU Shaders,"  We present in this paper several improvements for computing shortest path
maps using OpenGL shaders. The approach explores GPU rasterization as a way to
propagate optimal costs on a polygonal 2D environment, producing shortest path
maps which can efficiently be queried at run-time. Our improved method relies
on Compute Shaders for improved performance, does not require any CPU
pre-computation, and handles shortest path maps both with source points and
with line segment sources. The produced path maps partition the input
environment into regions sharing a same parent point along the shortest path to
the closest source point or segment source. Our method produces paths with
global optimality, a characteristic which has been mostly neglected in animated
virtual environments. The proposed approach is particularly suitable for the
animation of multiple agents moving toward the entrances or exits of a virtual
environment, a situation which is efficiently represented with the proposed
path maps.
"
1048,Analyzing Interfaces and Workflows for Light Field Editing,"  With the increasing number of available consumer light field cameras, such as
Lytro TM, Raytrix TM, or Pelican Imaging TM, this new form of photography is
progressively becoming more common. However, there are still very few tools for
light field editing, and the interfaces to create those edits remain largely
unexplored. Given the extended dimensionality of light field data, it is not
clear what the most intuitive interfaces and optimal workflows are, in contrast
with well-studied 2D image manipulation software. In this work we provide a
detailed description of subjects' performance and preferences for a number of
simple editing tasks, which form the basis for more complex operations. We
perform a detailed state sequence analysis and hidden Markov chain analysis
based on the sequence of tools and interaction paradigms users employ while
editing light fields. These insights can aid researchers and designers in
creating new light field editing tools and interfaces, thus helping to close
the gap between 4D and 2D image editing.
"
1049,"One machine, one minute, three billion tetrahedra","  This paper presents a new scalable parallelization scheme to generate the 3D
Delaunay triangulation of a given set of points. Our first contribution is an
efficient serial implementation of the incremental Delaunay insertion
algorithm. A simple dedicated data structure, an efficient sorting of the
points and the optimization of the insertion algorithm have permitted to
accelerate reference implementations by a factor three. Our second contribution
is a multi-threaded version of the Delaunay kernel that is able to concurrently
insert vertices. Moore curve coordinates are used to partition the point set,
avoiding heavy synchronization overheads. Conflicts are managed by modifying
the partitions with a simple rescaling of the space-filling curve. The
performances of our implementation have been measured on three different
processors, an Intel core-i7, an Intel Xeon Phi and an AMD EPYC, on which we
have been able to compute 3 billion tetrahedra in 53 seconds. This corresponds
to a generation rate of over 55 million tetrahedra per second. We finally show
how this very efficient parallel Delaunay triangulation can be integrated in a
Delaunay refinement mesh generator which takes as input the triangulated
surface boundary of the volume to mesh.
"
1050,"On-the-fly Vertex Reuse for Massively-Parallel Software Geometry
  Processing","  Compute-mode rendering is becoming more and more attractive for non-standard
rendering applications, due to the high flexibility of compute-mode execution.
These newly designed pipelines often include streaming vertex and geometry
processing stages. In typical triangle meshes, the same transformed vertex is
on average required six times during rendering. To avoid redundant computation,
a post-transform cache is traditionally suggested to enable reuse of vertex
processing results. However, traditional caching neither scales well as the
hardware becomes more parallel, nor can be efficiently implemented in a
software design. We investigate alternative strategies to reusing vertex
shading results on-the-fly for massively parallel software geometry processing.
Forming static and dynamic batching on the data input stream, we analyze the
effectiveness of identifying potential local reuse based on sorting, hashing,
and efficient intra-thread-group communication. Altogether, we present four
vertex reuse strategies, tailored to modern parallel architectures. Our
simulations showcase that our batch-based strategies significantly outperform
parallel caches in terms of reuse. On actual GPU hardware, our evaluation shows
that our strategies not only lead to good reuse of processing results, but also
boost performance by $2-3\times$ compared to na\""ively ignoring reuse in a
variety of practical applications.
"
1051,Area-preserving parameterizations for spherical ellipses,"  We present new methods for uniformly sampling the solid angle subtended by a
disk. To achieve this, we devise two novel area-preserving mappings from the
unit square $[0,1]^2$ to a spherical ellipse (i.e. the projection of the disk
onto the unit sphere). These mappings allow for low-variance stratified
sampling of direct illumination from disk-shaped light sources. We discuss how
to efficiently incorporate our methods into a production renderer and
demonstrate the quality of our maps, showing significantly lower variance than
previous work.
"
1052,The Topology ToolKit,"  This system paper presents the Topology ToolKit (TTK), a software platform
designed for topological data analysis in scientific visualization. TTK
provides a unified, generic, efficient, and robust implementation of key
algorithms for the topological analysis of scalar data, including: critical
points, integral lines, persistence diagrams, persistence curves, merge trees,
contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots,
Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due
to a tight integration with ParaView. It is also easily accessible to
developers through a variety of bindings (Python, VTK/C++) for fast prototyping
or through direct, dependence-free, C++, to ease integration into pre-existing
complex systems. While developing TTK, we faced several algorithmic and
software engineering challenges, which we document in this paper. In
particular, we present an algorithm for the construction of a discrete gradient
that complies to the critical points extracted in the piecewise-linear setting.
This algorithm guarantees a combinatorial consistency across the topological
abstractions supported by TTK, and importantly, a unified implementation of
topological data simplification for multi-scale exploration and analysis. We
also present a cached triangulation data structure, that supports time
efficient and generic traversals, which self-adjusts its memory usage on demand
for input simplicial meshes and which implicitly emulates a triangulation for
regular grids with no memory overhead. Finally, we describe an original
software architecture, which guarantees memory efficient and direct accesses to
TTK features, while still allowing for researchers powerful and easy bindings
and extensions. TTK is open source (BSD license) and its code, online
documentation and video tutorials are available on TTK's website.
"
1053,The Vector Heat Method,"  This paper describes a method for efficiently computing parallel transport of
tangent vectors on curved surfaces, or more generally, any vector-valued data
on a curved manifold. More precisely, it extends a vector field defined over
any region to the rest of the domain via parallel transport along shortest
geodesics. This basic operation enables fast, robust algorithms for
extrapolating level set velocities, inverting the exponential map, computing
geometric medians and Karcher/Fr\'{e}chet means of arbitrary distributions,
constructing centroidal Voronoi diagrams, and finding consistently ordered
landmarks. Rather than evaluate parallel transport by explicitly tracing
geodesics, we show that it can be computed via a short-time heat flow involving
the connection Laplacian. As a result, transport can be achieved by solving
three prefactored linear systems, each akin to a standard Poisson problem. To
implement the method we need only a discrete connection Laplacian, which we
describe for a variety of geometric data structures (point clouds, polygon
meshes, etc). We also study the numerical behavior of our method, showing
empirically that it converges under refinement, and augment the construction of
intrinsic Delaunay triangulations (iDT) so that they can be used in the context
of tangent vector field processing.
"
1054,Second-Order Occlusion-Aware Volumetric Radiance Caching,"  We present a second-order gradient analysis of light transport in
participating media and use this to develop an improved radiance caching
algorithm for volumetric light transport. We adaptively sample and interpolate
radiance from sparse points in the medium using a second-order Hessian-based
error metric to determine when interpolation is appropriate. We derive our
metric from each point's incoming light field, computed by using a proxy
triangulation-based representation of the radiance reflected by the surrounding
medium and geometry. We use this representation to efficiently compute the
first- and second-order derivatives of the radiance at the cache points while
accounting for occlusion changes.
  We also propose a self-contained two-dimensional model for light transport in
media and use it to validate and analyze our approach, demonstrating that our
method outperforms previous radiance caching algorithms both in terms of
accurate derivative estimates and final radiance extrapolation. We generalize
these findings to practical three-dimensional scenarios, where we show improved
results while reducing computation time by up to 30\% compared to previous
work.
"
1055,"DeepToF: Off-the-Shelf Real-Time Correction of Multipath Interference in
  Time-of-Flight Imaging","  Time-of-flight (ToF) imaging has become a widespread technique for depth
estimation, allowing affordable off-the-shelf cameras to provide depth maps in
real time. However, multipath interference (MPI) resulting from indirect
illumination significantly degrades the captured depth. Most previous works
have tried to solve this problem by means of complex hardware modifications or
costly computations. In this work we avoid these approaches, and propose a new
technique that corrects errors in depth caused by MPI that requires no camera
modifications, and corrects depth in just 10 milliseconds per frame. By
observing that most MPI information can be expressed as a function of the
captured depth, we pose MPI removal as a convolutional approach, and model it
using a convolutional neural network. In particular, given that the input and
output data present similar structure, we base our network in an autoencoder,
which we train in two stages: first, we use the encoder (convolution filters)
to learn a suitable basis to represent corrupted range images; then, we train
the decoder (deconvolution filters) to correct depth from the learned basis
from synthetically generated scenes. This approach allows us to tackle the lack
of reference data, by using a large-scale captured training set with corrupted
depth to train the encoder, and a smaller synthetic training set with ground
truth depth to train the corrector stage of the network, which we generate by
using a physically-based, time-resolved rendering. We demonstrate and validate
our method on both synthetic and real complex scenarios, using an off-the-shelf
ToF camera, and with only the captured incorrect depth as input.
"
1056,VisemeNet: Audio-Driven Animator-Centric Speech Animation,"  We present a novel deep-learning based approach to producing animator-centric
speech motion curves that drive a JALI or standard FACS-based production
face-rig, directly from input audio. Our three-stage Long Short-Term Memory
(LSTM) network architecture is motivated by psycho-linguistic insights:
segmenting speech audio into a stream of phonetic-groups is sufficient for
viseme construction; speech styles like mumbling or shouting are strongly
co-related to the motion of facial landmarks; and animator style is encoded in
viseme motion curve profiles. Our contribution is an automatic real-time
lip-synchronization from audio solution that integrates seamlessly into
existing animation pipelines. We evaluate our results by: cross-validation to
ground-truth data; animator critique and edits; visual comparison to recent
deep-learning lip-synchronization solutions; and showing our approach to be
resilient to diversity in speaker and language.
"
1057,Progressive Transient Photon Beams,"  In this work we introduce a novel algorithm for transient rendering in
participating media. Our method is consistent, robust, and is able to generate
animations of time-resolved light transport featuring complex caustic light
paths in media. We base our method on the observation that the spatial
continuity provides an increased coverage of the temporal domain, and
generalize photon beams to transient-state. We extend the beam steady-state
radiance estimates to include the temporal domain. Then, we develop a
progressive version of spatio-temporal density estimations, that converges to
the correct solution with finite memory requirements by iteratively averaging
several realizations of independent renders with a progressively reduced kernel
bandwidth. We derive the optimal convergence rates accounting for space and
time kernels, and demonstrate our method against previous consistent transient
rendering methods for participating media.
"
1058,Stereo Magnification: Learning View Synthesis using Multiplane Images,"  The view synthesis problem--generating novel views of a scene from known
imagery--has garnered recent attention due in part to compelling applications
in virtual and augmented reality. In this paper, we explore an intriguing
scenario for view synthesis: extrapolating views from imagery captured by
narrow-baseline stereo cameras, including VR cameras and now-widespread
dual-lens camera phones. We call this problem stereo magnification, and propose
a learning framework that leverages a new layered representation that we call
multiplane images (MPIs). Our method also uses a massive new data source for
learning view extrapolation: online videos on YouTube. Using data mined from
such videos, we train a deep network that predicts an MPI from an input stereo
image pair. This inferred MPI can then be used to synthesize a range of novel
views of the scene, including views that extrapolate significantly beyond the
input baseline. We show that our method compares favorably with several recent
view synthesis methods, and demonstrate applications in magnifying
narrow-baseline stereo images.
"
1059,Deep Video Portraits,"  We present a novel approach that enables photo-realistic re-animation of
portrait videos using only an input video. In contrast to existing approaches
that are restricted to manipulations of facial expressions only, we are the
first to transfer the full 3D head position, head rotation, face expression,
eye gaze, and eye blinking from a source actor to a portrait video of a target
actor. The core of our approach is a generative neural network with a novel
space-time architecture. The network takes as input synthetic renderings of a
parametric face model, based on which it predicts photo-realistic video frames
for a given target actor. The realism in this rendering-to-video transfer is
achieved by careful adversarial training, and as a result, we can create
modified target videos that mimic the behavior of the synthetically-created
input. In order to enable source-to-target video re-animation, we render a
synthetic target video with the reconstructed head animation parameters from a
source video, and feed it into the trained network -- thus taking full control
of the target. With the ability to freely recombine source and target
parameters, we are able to demonstrate a large variety of video rewrite
applications without explicitly modeling hair, body or background. For
instance, we can reenact the full head using interactive user-controlled
editing, and realize high-fidelity visual dubbing. To demonstrate the high
quality of our output, we conduct an extensive series of experiments and
evaluations, where for instance a user study shows that our video edits are
hard to detect.
"
1060,HeadOn: Real-time Reenactment of Human Portrait Videos,"  We propose HeadOn, the first real-time source-to-target reenactment approach
for complete human portrait videos that enables transfer of torso and head
motion, face expression, and eye gaze. Given a short RGB-D video of the target
actor, we automatically construct a personalized geometry proxy that embeds a
parametric head, eye, and kinematic torso model. A novel real-time reenactment
algorithm employs this proxy to photo-realistically map the captured motion
from the source actor to the target actor. On top of the coarse geometric
proxy, we propose a video-based rendering technique that composites the
modified target portrait video via view- and pose-dependent texturing, and
creates photo-realistic imagery of the target actor under novel torso and head
poses, facial expressions, and gaze directions. To this end, we propose a
robust tracking of the face and torso of the source actor. We extensively
evaluate our approach and show significant improvements in enabling much
greater flexibility in creating realistic reenacted output videos.
"
1061,Path Throughput Importance Weights,"  Many Monte Carlo light transport simulations use multiple importance sampling
(MIS) to weight between different path sampling strategies. We propose to use
the path throughput to compute the MIS weights instead of the commonly used
probability density per area measure. This new formulation is equivalent to the
previous approach and results in the same weights as well as implementation.
However, it is more intuitive and can help in understanding the effects of
modifications to the weight function. We show some examples of required
modifications which are often neglected in implementations. Also, our new
perspective might help to derive MIS strategies for new samplers in the future.
"
1062,Deep Fluids: A Generative Network for Parameterized Fluid Simulations,"  This paper presents a novel generative model to synthesize fluid simulations
from a set of reduced parameters. A convolutional neural network is trained on
a collection of discrete, parameterizable fluid simulation velocity fields. Due
to the capability of deep learning architectures to learn representative
features of the data, our generative model is able to accurately approximate
the training data set, while providing plausible interpolated in-betweens. The
proposed generative model is optimized for fluids by a novel loss function that
guarantees divergence-free velocity fields at all times. In addition, we
demonstrate that we can handle complex parameterizations in reduced spaces, and
advance simulations in time by integrating in the latent space with a second
network. Our method models a wide variety of fluid behaviors, thus enabling
applications such as fast construction of simulations, interpolation of fluids
with different parameters, time re-sampling, latent space simulations, and
compression of fluid simulation data. Reconstructed velocity fields are
generated up to 700x faster than re-simulating the data with the underlying CPU
solver, while achieving compression rates of up to 1300x.
"
1063,Color Sails: Discrete-Continuous Palettes for Deep Color Exploration,"  We present color sails, a discrete-continuous color gamut representation that
extends the color gradient analogy to three dimensions and allows interactive
control of the color blending behavior. Our representation models a wide
variety of color distributions in a compact manner, and lends itself to
applications such as color exploration for graphic design, illustration and
similar fields. We propose a Neural Network that can fit a color sail to any
image. Then, the user can adjust color sail parameters to change the base
colors, their blending behavior and the number of colors, exploring a wide
range of options for the original design. In addition, we propose a Deep
Learning model that learns to automatically segment an image into
color-compatible alpha masks, each equipped with its own color sail. This
allows targeted color exploration by either editing their corresponding color
sails or using standard software packages. Our model is trained on a custom
diverse dataset of art and design. We provide both quantitative evaluations,
and a user study, demonstrating the effectiveness of color sail interaction.
Interactive demos are available at www.colorsails.com.
"
1064,"The Saturated Subpaths Decomposition in Z 2 : a short note on
  generalized Tangential Cover","  In this short note, we generalized the Tangential Cover used in Digital
Geometry in order to use very general geometric predicates. We present the
required notions of saturated $\alpha$-paths of a digital curve as well as
conservative predicates which indeed cover nearly all geometric digital
primitives published so far. The goal of this note is to prove that under a
very general situation, the size of the Tangential Cover is linear with the
number of points of the input curve. The computation complexity of the
Tangential Cover depends on the complexity of incremental recognition of
geometric predicates. Moreover, in the discussion, we show that our approach
does not rely on connectivity of points as it might be though first.
"
1065,Free-Form Image Inpainting with Gated Convolution,"  We present a generative image inpainting system to complete images with
free-form mask and guidance. The system is based on gated convolutions learned
from millions of images without additional labelling efforts. The proposed
gated convolution solves the issue of vanilla convolution that treats all input
pixels as valid ones, generalizes partial convolution by providing a learnable
dynamic feature selection mechanism for each channel at each spatial location
across all layers. Moreover, as free-form masks may appear anywhere in images
with any shape, global and local GANs designed for a single rectangular mask
are not applicable. Thus, we also present a patch-based GAN loss, named
SN-PatchGAN, by applying spectral-normalized discriminator on dense image
patches. SN-PatchGAN is simple in formulation, fast and stable in training.
Results on automatic image inpainting and user-guided extension demonstrate
that our system generates higher-quality and more flexible results than
previous methods. Our system helps user quickly remove distracting objects,
modify image layouts, clear watermarks and edit faces. Code, demo and models
are available at: https://github.com/JiahuiYu/generative_inpainting
"
1066,Latent Space Representation for Shape Analysis and Learning,"  We propose a novel shape representation useful for analyzing and processing
shape collections, as well for a variety of learning and inference tasks.
Unlike most approaches that capture variability in a collection by using a
template model or a base shape, we show that it is possible to construct a full
shape representation by using the latent space induced by a functional map net-
work, allowing us to represent shapes in the context of a collection without
the bias induced by selecting a template shape. Key to our construction is a
novel analysis of latent functional spaces, which shows that after proper
regularization they can be endowed with a natural geometric structure, giving
rise to a well-defined, stable and fully informative shape representation. We
demonstrate the utility of our representation in shape analysis tasks, such as
highlighting the most distorted shape parts in a collection or separating
variability modes between shape classes. We further exploit our representation
in learning applications by showing how it can naturally be used within deep
learning and convolutional neural networks for shape classi cation or
reconstruction, signi cantly outperforming existing point-based techniques.
"
1067,Synthetic Depth-of-Field with a Single-Camera Mobile Phone,"  Shallow depth-of-field is commonly used by photographers to isolate a subject
from a distracting background. However, standard cell phone cameras cannot
produce such images optically, as their short focal lengths and small apertures
capture nearly all-in-focus images. We present a system to computationally
synthesize shallow depth-of-field images with a single mobile camera and a
single button press. If the image is of a person, we use a person segmentation
network to separate the person and their accessories from the background. If
available, we also use dense dual-pixel auto-focus hardware, effectively a
2-sample light field with an approximately 1 millimeter baseline, to compute a
dense depth map. These two signals are combined and used to render a defocused
image. Our system can process a 5.4 megapixel image in 4 seconds on a mobile
phone, is fully automatic, and is robust enough to be used by non-experts. The
modular nature of our system allows it to degrade naturally in the absence of a
dual-pixel sensor or a human subject.
"
1068,"Continuous and Orientation-preserving Correspondences via Functional
  Maps","  We propose a method for efficiently computing orientation-preserving and
approximately continuous correspondences between non-rigid shapes, using the
functional maps framework. We first show how orientation preservation can be
formulated directly in the functional (spectral) domain without using landmark
or region correspondences and without relying on external symmetry information.
This allows us to obtain functional maps that promote orientation preservation,
even when using descriptors, that are invariant to orientation changes. We then
show how higher quality, approximately continuous and bijective pointwise
correspondences can be obtained from initial functional maps by introducing a
novel refinement technique that aims to simultaneously improve the maps both in
the spectral and spatial domains. This leads to a general pipeline for
computing correspondences between shapes that results in high-quality maps,
while admitting an efficient optimization scheme. We show through extensive
evaluation that our approach improves upon state-of-the-art results on
challenging isometric and non-isometric correspondence benchmarks according to
both measures of continuity and coverage as well as producing semantically
meaningful correspondences as measured by the distance to ground truth maps.
"
1069,Movie Editing and Cognitive Event Segmentation in Virtual Reality Video,"  Traditional cinematography has relied for over a century on a
well-established set of editing rules, called continuity editing, to create a
sense of situational continuity. Despite massive changes in visual content
across cuts, viewers in general experience no trouble perceiving the
discontinuous flow of information as a coherent set of events. However, Virtual
Reality (VR) movies are intrinsically different from traditional movies in that
the viewer controls the camera orientation at all times. As a consequence,
common editing techniques that rely on camera orientations, zooms, etc., cannot
be used. In this paper we investigate key relevant questions to understand how
well traditional movie editing carries over to VR. To do so, we rely on recent
cognition studies and the event segmentation theory, which states that our
brains segment continuous actions into a series of discrete, meaningful events.
We first replicate one of these studies to assess whether the predictions of
such theory can be applied to VR. We next gather gaze data from viewers
watching VR videos containing different edits with varying parameters, and
provide the first systematic analysis of viewers' behavior and the perception
of continuity in VR. From this analysis we make a series of relevant findings;
for instance, our data suggests that predictions from the cognitive event
segmentation theory are useful guides for VR editing; that different types of
edits are equally well understood in terms of continuity; and that spatial
misalignments between regions of interest at the edit boundaries favor a more
exploratory behavior even after viewers have fixated on a new region of
interest. In addition, we propose a number of metrics to describe viewers'
attentional behavior in VR. We believe the insights derived from our work can
be useful as guidelines for VR content creation.
"
1070,Convolutional sparse coding for capturing high speed video content,"  Video capture is limited by the trade-off between spatial and temporal
resolution: when capturing videos of high temporal resolution, the spatial
resolution decreases due to bandwidth limitations in the capture system.
Achieving both high spatial and temporal resolution is only possible with
highly specialized and very expensive hardware, and even then the same basic
trade-off remains. The recent introduction of compressive sensing and sparse
reconstruction techniques allows for the capture of single-shot high-speed
video, by coding the temporal information in a single frame, and then
reconstructing the full video sequence from this single coded image and a
trained dictionary of image patches. In this paper, we first analyze this
approach, and find insights that help improve the quality of the reconstructed
videos. We then introduce a novel technique, based on convolutional sparse
coding (CSC), and show how it outperforms the state-of-the-art, patch-based
approach in terms of flexibility and efficiency, due to the convolutional
nature of its filter banks. The key idea for CSC high-speed video acquisition
is extending the basic formulation by imposing an additional constraint in the
temporal dimension, which enforces sparsity of the first-order derivatives over
time.
"
1071,Convolutional Sparse Coding for High Dynamic Range Imaging,"  Current HDR acquisition techniques are based on either (i) fusing
multibracketed, low dynamic range (LDR) images, (ii) modifying existing
hardware and capturing different exposures simultaneously with multiple
sensors, or (iii) reconstructing a single image with spatially-varying pixel
exposures. In this paper, we propose a novel algorithm to recover high-quality
HDRI images from a single, coded exposure. The proposed reconstruction method
builds on recently-introduced ideas of convolutional sparse coding (CSC); this
paper demonstrates how to make CSC practical for HDR imaging. We demonstrate
that the proposed algorithm achieves higher-quality reconstructions than
alternative methods, we evaluate optical coding schemes, analyze algorithmic
parameters, and build a prototype coded HDR camera that demonstrates the
utility of convolutional sparse HDRI coding with a custom hardware platform.
"
1072,An intuitive control space for material appearance,"  Many different techniques for measuring material appearance have been
proposed in the last few years. These have produced large public datasets,
which have been used for accurate, data-driven appearance modeling. However,
although these datasets have allowed us to reach an unprecedented level of
realism in visual appearance, editing the captured data remains a challenge. In
this paper, we present an intuitive control space for predictable editing of
captured BRDF data, which allows for artistic creation of plausible novel
material appearances, bypassing the difficulty of acquiring novel samples. We
first synthesize novel materials, extending the existing MERL dataset up to 400
mathematically valid BRDFs. We then design a large-scale experiment, gathering
56,000 subjective ratings on the high-level perceptual attributes that best
describe our extended dataset of materials. Using these ratings, we build and
train networks of radial basis functions to act as functionals mapping the
perceptual attributes to an underlying PCA-based representation of BRDFs. We
show that our functionals are excellent predictors of the perceived attributes
of appearance. Our control space enables many applications, including intuitive
material editing of a wide range of visual properties, guidance for gamut
mapping, analysis of the correlation between perceptual attributes, or novel
appearance similarity metrics. Moreover, our methodology can be used to derive
functionals applicable to classic analytic BRDF representations. We release our
code and dataset publicly, in order to support and encourage further research
in this direction.
"
1073,"Geometric Shape Features Extraction Using a Steady State Partial
  Differential Equation System","  A unified method for extracting geometric shape features from binary image
data using a steady state partial differential equation (PDE) system as a
boundary value problem is presented in this paper. The PDE and functions are
formulated to extract the thickness, orientation, and skeleton simultaneously.
The main advantages of the proposed method is that the orientation is defined
without derivatives and thickness computation is not imposed a topological
constraint on the target shape. A one-dimensional analytical solution is
provided to validate the proposed method. In addition, two-dimensional
numerical examples are presented to confirm the usefulness of the proposed
method.
"
1074,Perceptual Rasterization for Head-mounted Display Image Synthesis,"  We suggest a rasterization pipeline tailored towards the need of head-mounted
displays (HMD), where latency and field-of-view requirements pose new
challenges beyond those of traditional desktop displays. Instead of rendering
and warping for low latency, or using multiple passes for foveation, we show
how both can be produced directly in a single perceptual rasterization pass. We
do this with per-fragment ray-casting. This is enabled by derivations of tight
space-time-fovea pixel bounds, introducing just enough flexibility for
requisite geometric tests, but retaining most of the the simplicity and
efficiency of the traditional rasterizaton pipeline. To produce foveated
images, we rasterize to an image with spatially varying pixel density. To
reduce latency, we extend the image formation model to directly produce
""rolling"" images where the time at each pixel depends on its display location.
Our approach overcomes limitations of warping with respect to disocclusions,
object motion and view-dependent shading, as well as geometric aliasing
artifacts in other foveated rendering techniques. A set of perceptual user
studies demonstrates the efficacy of our approach.
"
1075,TTHRESH: Tensor Compression for Multidimensional Visual Data,"  Memory and network bandwidth are decisive bottlenecks when handling
high-resolution multidimensional data sets in visualization applications, and
they increasingly demand suitable data compression strategies. We introduce a
novel lossy compression algorithm for multidimensional data over regular grids.
It leverages the higher-order singular value decomposition (HOSVD), a
generalization of the SVD to three dimensions and higher, together with
bit-plane, run-length and arithmetic coding to compress the HOSVD transform
coefficients. Our scheme degrades the data particularly smoothly and achieves
lower mean squared error than other state-of-the-art algorithms at
low-to-medium bit rates, as it is required in data archiving and management for
visualization purposes. Further advantages of the proposed algorithm include
very fine bit rate selection granularity and the ability to manipulate data at
very small cost in the compression domain, for example to reconstruct filtered
and/or subsampled versions of all (or selected parts) of the data set.
"
1076,Mumford-Shah Mesh Processing using the Ambrosio-Tortorelli Functional,"  The Mumford-Shah functional approximates a function by a piecewise smooth
function. Its versatility makes it ideal for tasks such as image segmentation
or restoration, and it is now a widespread tool of image processing. Recent
work has started to investigate its use for mesh segmentation and feature lines
detection, but we take the stance that the power of this functional could reach
far beyond these tasks and integrate the everyday mesh processing toolbox. In
this paper, we discretize an Ambrosio-Tortorelli approximation via a Discrete
Exterior Calculus formulation. We show that, combined with a new shape
optimization routine, several mesh processing problems can be readily tackled
within the same framework. In particular, we illustrate applications in mesh
denoising, normal map embossing, mesh inpainting and mesh segmentation.
"
1077,Coupled Fluid Density and Motion from Single Views,"  We present a novel method to reconstruct a fluid's 3D density and motion
based on just a single sequence of images. This is rendered possible by using
powerful physical priors for this strongly under-determined problem. More
specifically, we propose a novel strategy to infer density updates strongly
coupled to previous and current estimates of the flow motion. Additionally, we
employ an accurate discretization and depth-based regularizers to compute
stable solutions. Using only one view for the reconstruction reduces the
complexity of the capturing setup drastically and could even allow for online
video databases or smart-phone videos as inputs. The reconstructed 3D velocity
can then be flexibly utilized, e.g., for re-simulation, domain modification or
guiding purposes. We will demonstrate the capacity of our method with a series
of synthetic test cases and the reconstruction of real smoke plumes captured
with a Raspberry Pi camera.
"
1078,HexaLab.net: an online viewer for hexahedral meshes,"  We introduce HexaLab: a WebGL application for real time visualization,
exploration and assessment of hexahedral meshes. HexaLab can be used by simply
opening www.hexalab.net. Our visualization tool targets both users and
scholars. Practitioners who employ hexmeshes for Finite Element Analysis, can
readily check mesh quality and assess its usability for simulation. Researchers
involved in mesh generation may use HexaLab to perform a detailed analysis of
the mesh structure, isolating weak points and testing new solutions to improve
on the state of the art and generate high quality images. To this end, we
support a wide variety of visualization and volume inspection tools. Our system
offers also immediate access to a repository containing all the publicly
available meshes produced with the most recent techniques for hexmesh
generation. We believe HexaLab, providing a common tool for visualizing,
assessing and distributing results, will push forward the recent strive for
replicability in our scientific community.
"
1079,End-to-end Sampling Patterns,"  Sample patterns have many uses in Computer Graphics, ranging from procedural
object placement over Monte Carlo image synthesis to non-photorealistic
depiction. Their properties such as discrepancy, spectra, anisotropy, or
progressiveness have been analyzed extensively. However, designing methods to
produce sampling patterns with certain properties can require substantial
hand-crafting effort, both in coding, mathematical derivation and compute time.
In particular, there is no systematic way to derive the best sampling algorithm
for a specific end-task.
  Tackling this issue, we suggest another level of abstraction: a toolkit to
end-to-end optimize over all sampling methods to find the one producing
user-prescribed properties such as discrepancy or a spectrum that best fit the
end-task. A user simply implements the forward losses and the sampling method
is found automatically -- without coding or mathematical derivation -- by
making use of back-propagation abilities of modern deep learning frameworks.
While this optimization takes long, at deployment time the sampling method is
quick to execute as iterated unstructured non-linear filtering using radial
basis functions (RBFs) to represent high-dimensional kernels. Several important
previous methods are special cases of this approach, which we compare to
previous work and demonstrate its usefulness in several typical Computer
Graphics applications. Finally, we propose sampling patterns with properties
not shown before, such as high-dimensional blue noise with projective
properties.
"
1080,"FrankenGAN: Guided Detail Synthesis for Building Mass-Models Using
  Style-Synchonized GANs","  Coarse building mass models are now routinely generated at scales ranging
from individual buildings through to whole cities. For example, they can be
abstracted from raw measurements, generated procedurally, or created manually.
However, these models typically lack any meaningful semantic or texture
details, making them unsuitable for direct display. We introduce the problem of
automatically and realistically decorating such models by adding semantically
consistent geometric details and textures. Building on the recent success of
generative adversarial networks (GANs), we propose FrankenGAN, a cascade of
GANs to create plausible details across multiple scales over large
neighborhoods. The various GANs are synchronized to produce consistent style
distributions over buildings and neighborhoods. We provide the user with direct
control over the variability of the output. We allow her to interactively
specify style via images and manipulate style-adapted sliders to control style
variability. We demonstrate our system on several large-scale examples. The
generated outputs are qualitatively evaluated via a set of user studies and are
found to be realistic, semantically-plausible, and style-consistent.
"
1081,"HairNet: Single-View Hair Reconstruction using Convolutional Neural
  Networks","  We introduce a deep learning-based method to generate full 3D hair geometry
from an unconstrained image. Our method can recover local strand details and
has real-time performance. State-of-the-art hair modeling techniques rely on
large hairstyle collections for nearest neighbor retrieval and then perform
ad-hoc refinement. Our deep learning approach, in contrast, is highly efficient
in storage and can run 1000 times faster while generating hair with 30K
strands. The convolutional neural network takes the 2D orientation field of a
hair image as input and generates strand features that are evenly distributed
on the parameterized 2D scalp. We introduce a collision loss to synthesize more
plausible hairstyles, and the visibility of each strand is also used as a
weight term to improve the reconstruction accuracy. The encoder-decoder
architecture of our network naturally provides a compact and continuous
representation for hairstyles, which allows us to interpolate naturally between
hairstyles. We use a large set of rendered synthetic hair models to train our
network. Our method scales to real images because an intermediate 2D
orientation field, automatically calculated from the real image, factors out
the difference between synthetic and real hairs. We demonstrate the
effectiveness and robustness of our method on a wide range of challenging real
Internet pictures and show reconstructed hair sequences from videos.
"
1082,Void Space Surfaces to Convey Depth in Vessel Visualizations,"  To enhance depth perception and thus data comprehension, additional depth
cues are often used in 3D visualizations of complex vascular structures.
Accordingly, there is a variety of different approaches described in the
literature, ranging from chromadepth color coding over depth of field to
glyph-based encodings. Unfortunately, the majority of existing approaches
suffers from the same problem. As these cues are directly applied to the
geometry's surface, the display of additional information, such as other
modalities or derived attributes, associated with a vessel is impaired. To
overcome this limitation we propose Void Space Surfaces which utilize the empty
space in between vessel branches to communicate depth and their relative
positioning. This allows us to enhance the depth perception of vascular
structures without interfering with the spatial data and potentially
superimposed parameter information. Within this paper we introduce Void Space
Surfaces, describe their technical realization, and show their application to
various vessel trees. Moreover, we report the outcome of a user study which we
have conducted in order to evaluate the perceptual impact of Void Space
Surfaces as compared to existing vessel visualization techniques.
"
1083,"iMapper: Interaction-guided Joint Scene and Human Motion Mapping from
  Monocular Videos","  A long-standing challenge in scene analysis is the recovery of scene
arrangements under moderate to heavy occlusion, directly from monocular video.
While the problem remains a subject of active research, concurrent advances
have been made in the context of human pose reconstruction from monocular
video, including image-space feature point detection and 3D pose recovery.
These methods, however, start to fail under moderate to heavy occlusion as the
problem becomes severely under-constrained. We approach the problems
differently. We observe that people interact similarly in similar scenes.
Hence, we exploit the correlation between scene object arrangement and motions
performed in that scene in both directions: first, typical motions performed
when interacting with objects inform us about possible object arrangements; and
second, object arrangements, in turn, constrain the possible motions.
  We present iMapper, a data-driven method that focuses on identifying
human-object interactions, and jointly reasons about objects and human movement
over space-time to recover both a plausible scene arrangement and consistent
human interactions. We first introduce the notion of characteristic
interactions as regions in space-time when an informative human-object
interaction happens. This is followed by a novel occlusion-aware matching
procedure that searches and aligns such characteristic snapshots from an
interaction database to best explain the input monocular video. Through
extensive evaluations, both quantitative and qualitative, we demonstrate that
iMapper significantly improves performance over both dedicated state-of-the-art
scene analysis and 3D human pose recovery approaches, especially under medium
to heavy occlusion.
"
1084,Topological Data Analysis Made Easy with the Topology ToolKit,"  This tutorial presents topological methods for the analysis and visualization
of scientific data from a user's perspective, with the Topology ToolKit (TTK),
a recently released open-source library for topological data analysis.
Topological methods have gained considerably in popularity and maturity over
the last twenty years and success stories of established methods have been
documented in a wide range of applications (combustion, chemistry,
astrophysics, material sciences, etc.) with both acquired and simulated data,
in both post-hoc and in-situ contexts. While reference textbooks have been
published on the topic, no tutorial at IEEE VIS has covered this area in recent
years, and never at a software level and from a user's point-of-view. This
tutorial fills this gap by providing a beginner's introduction to topological
methods for practitioners, researchers, students, and lecturers. In particular,
instead of focusing on theoretical aspects and algorithmic details, this
tutorial focuses on how topological methods can be useful in practice for
concrete data analysis tasks such as segmentation, feature extraction or
tracking. The tutorial describes in detail how to achieve these tasks with TTK.
First, after an introduction to topological methods and their application in
data analysis, a brief overview of TTK's main entry point for end users, namely
ParaView, will be presented. Second, an overview of TTK's main features will be
given. A running example will be described in detail, showcasing how to access
TTK's features via ParaView, Python, VTK/C++, and C++. Third, hands-on sessions
will concretely show how to use TTK in ParaView for multiple, representative
data analysis tasks. Fourth, the usage of TTK will be presented for developers,
in particular by describing several examples of visualization and data analysis
projects that were built on top of TTK. Finally, some feedback regarding the
usage of TTK as a teaching platform for topological analysis will be given.
Presenters of this tutorial include experts in topological methods, core
authors of TTK as well as active users, coming from academia, labs, or
industry. A large part of the tutorial will be dedicated to hands-on exercises
and a rich material package (including TTK pre-installs in virtual machines,
code, data, demos, video tutorials, etc.) will be provided to the participants.
This tutorial mostly targets students, practitioners and researchers who are
not experts in topological methods but who are interested in using them in
their daily tasks. We also target researchers already familiar to topological
methods and who are interested in using or contributing to TTK.
"
1085,"Homology-Preserving Dimensionality Reduction via Manifold Landmarking
  and Tearing","  Dimensionality reduction is an integral part of data visualization. It is a
process that obtains a structure preserving low-dimensional representation of
the high-dimensional data. Two common criteria can be used to achieve a
dimensionality reduction: distance preservation and topology preservation.
Inspired by recent work in topological data analysis, we are on the quest for a
dimensionality reduction technique that achieves the criterion of homology
preservation, a generalized version of topology preservation. Specifically, we
are interested in using topology-inspired manifold landmarking and manifold
tearing to aid such a process and evaluate their effectiveness.
"
1086,"Shape-from-Mask: A Deep Learning Based Human Body Shape Reconstruction
  from Binary Mask Images","  3D content creation is referred to as one of the most fundamental tasks of
computer graphics. And many 3D modeling algorithms from 2D images or curves
have been developed over the past several decades. Designers are allowed to
align some conceptual images or sketch some suggestive curves, from front,
side, and top views, and then use them as references in constructing a 3D model
automatically or manually. However, to the best of our knowledge, no studies
have investigated on 3D human body reconstruction in a similar manner. In this
paper, we propose a deep learning based reconstruction of 3D human body shape
from 2D orthographic views. A novel CNN-based regression network, with two
branches corresponding to frontal and lateral views respectively, is designed
for estimating 3D human body shape from 2D mask images. We train our networks
separately to decouple the feature descriptors which encode the body parameters
from different views, and fuse them to estimate an accurate human body shape.
In addition, to overcome the shortage of training data required for this
purpose, we propose some significantly data augmentation schemes for 3D human
body shapes, which can be used to promote further research on this topic.
Extensive experimen- tal results demonstrate that visually realistic and
accurate reconstructions can be achieved effectively using our algorithm.
Requiring only binary mask images, our method can help users create their own
digital avatars quickly, and also make it easy to create digital human body for
3D game, virtual reality, online fashion shopping.
"
1087,"Point cloud segmentation using hierarchical tree for architectural
  models","  Recent developments in the 3D scanning technologies have made the generation
of highly accurate 3D point clouds relatively easy but the segmentation of
these point clouds remains a challenging area. A number of techniques have set
precedent of either planar or primitive based segmentation in literature. In
this work, we present a novel and an effective primitive based point cloud
segmentation algorithm. The primary focus, i.e. the main technical contribution
of our method is a hierarchical tree which iteratively divides the point cloud
into segments. This tree uses an exclusive energy function and a 3D
convolutional neural network, HollowNets to classify the segments. We test the
efficacy of our proposed approach using both real and synthetic data obtaining
an accuracy greater than 90% for domes and minarets.
"
1088,"Combining Recurrent Neural Networks and Adversarial Training for Human
  Motion Synthesis and Control","  This paper introduces a new generative deep learning network for human motion
synthesis and control. Our key idea is to combine recurrent neural networks
(RNNs) and adversarial training for human motion modeling. We first describe an
efficient method for training a RNNs model from prerecorded motion data. We
implement recurrent neural networks with long short-term memory (LSTM) cells
because they are capable of handling nonlinear dynamics and long term temporal
dependencies present in human motions. Next, we train a refiner network using
an adversarial loss, similar to Generative Adversarial Networks (GANs), such
that the refined motion sequences are indistinguishable from real motion
capture data using a discriminative network. We embed contact information into
the generative deep learning model to further improve the performance of our
generative model. The resulting model is appealing to motion synthesis and
control because it is compact, contact-aware, and can generate an infinite
number of naturally looking motions with infinite lengths. Our experiments show
that motions generated by our deep learning model are always highly realistic
and comparable to high-quality motion capture data. We demonstrate the power
and effectiveness of our models by exploring a variety of applications, ranging
from random motion synthesis, online/offline motion control, and motion
filtering. We show the superiority of our generative model by comparison
against baseline models.
"
1089,Golden interpolation,"  For the classic aesthetic interpolation problem, we propose an entirely new
thought: apply the golden section. For how to apply the golden section to
interpolation methods, we present three examples: the golden step
interpolation, the golden piecewise linear interpolation and the golden curve
interpolation, which respectively deal with the applications of golden section
in the interpolation of degree 0, 1, and 2 in the plane. In each example, we
present our basic ideas, the specific methods, comparative examples and
applications, and relevant criteria. And it is worth mentioning that for
aesthetics, we propose two novel concepts: the golden cuspidal hill and the
golden domed hill. This paper aims to provide the reference for the combination
of golden section and interpolation, and stimulate more and better related
researches.
"
1090,Generative Models for Pose Transfer,"  We investigate nearest neighbor and generative models for transferring pose
between persons. We take in a video of one person performing a sequence of
actions and attempt to generate a video of another person performing the same
actions. Our generative model (pix2pix) outperforms k-NN at both generating
corresponding frames and generalizing outside the demonstrated action set. Our
most salient contribution is determining a pipeline (pose detection, face
detection, k-NN based pairing) that is effective at perform-ing the desired
task. We also detail several iterative improvements and failure modes.
"
1091,"Dilated Temporal Fully-Convolutional Network for Semantic Segmentation
  of Motion Capture Data","  Semantic segmentation of motion capture sequences plays a key part in many
data-driven motion synthesis frameworks. It is a preprocessing step in which
long recordings of motion capture sequences are partitioned into smaller
segments. Afterwards, additional methods like statistical modeling can be
applied to each group of structurally-similar segments to learn an abstract
motion manifold. The segmentation task however often remains a manual task,
which increases the effort and cost of generating large-scale motion databases.
We therefore propose an automatic framework for semantic segmentation of motion
capture data using a dilated temporal fully-convolutional network. Our model
outperforms a state-of-the-art model in action segmentation, as well as three
networks for sequence modeling. We further show our model is robust against
high noisy training labels.
"
1092,Tracking Emerges by Colorizing Videos,"  We use large amounts of unlabeled video to learn models for visual tracking
without manual human supervision. We leverage the natural temporal coherency of
color to create a model that learns to colorize gray-scale videos by copying
colors from a reference frame. Quantitative and qualitative experiments suggest
that this task causes the model to automatically learn to track visual regions.
Although the model is trained without any ground-truth labels, our method
learns to track well enough to outperform the latest methods based on optical
flow. Moreover, our results suggest that failures to track are correlated with
failures to colorize, indicating that advancing video colorization may further
improve self-supervised visual tracking.
"
1093,Evotype: Towards the Evolution of Type Stencils,"  Typefaces are an essential resource employed by graphic designers. The
increasing demand for innovative type design work increases the need for good
technological means to assist the designer in the creation of a typeface. We
present an evolutionary computation approach for the generation of type
stencils to draw coherent glyphs for different characters. The proposed system
employs a Genetic Algorithm to evolve populations of type stencils. The
evaluation of each candidate stencil uses a hill climbing algorithm to search
the best configurations to draw the target glyphs. We study the interplay
between legibility, coherence and expressiveness, and show how our framework
can be used in practice.
"
1094,Divergence-Free Shape Interpolation and Correspondence,"  We present a novel method to model and calculate deformation fields between
shapes embedded in $\mathbb{R}^D$. Our framework combines naturally
interpolating the two input shapes and calculating correspondences at the same
time. The key idea is to compute a divergence-free deformation field
represented in a coarse-to-fine basis using the Karhunen-Lo\`eve expansion. The
advantages are that there is no need to discretize the embedding space and the
deformation is volume-preserving. Furthermore, the optimization is done on
downsampled versions of the shapes but the morphing can be applied to any
resolution without a heavy increase in complexity. We show results for shape
correspondence, registration, inter- and extrapolation on the TOSCA and FAUST
data sets.
"
1095,"Towards automatic initialization of registration algorithms using
  simulated endoscopy images","  Registering images from different modalities is an active area of research in
computer aided medical interventions. Several registration algorithms have been
developed, many of which achieve high accuracy. However, these results are
dependent on many factors, including the quality of the extracted features or
segmentations being registered as well as the initial alignment. Although
several methods have been developed towards improving segmentation algorithms
and automating the segmentation process, few automatic initialization
algorithms have been explored. In many cases, the initial alignment from which
a registration is initiated is performed manually, which interferes with the
clinical workflow. Our aim is to use scene classification in endoscopic
procedures to achieve coarse alignment of the endoscope and a preoperative
image of the anatomy. In this paper, we show using simulated scenes that a
neural network can predict the region of anatomy (with respect to a
preoperative image) that the endoscope is located in by observing a single
endoscopic video frame. With limited training and without any hyperparameter
tuning, our method achieves an accuracy of 76.53 (+/-1.19)%. There are several
avenues for improvement, making this a promising direction of research. Code is
available at https://github.com/AyushiSinha/AutoInitialization.
"
1096,Learning a Shared Shape Space for Multimodal Garment Design,"  Designing real and virtual garments is becoming extremely demanding with
rapidly changing fashion trends and increasing need for synthesizing realistic
dressed digital humans for various applications. This necessitates creating
simple and effective workflows to facilitate authoring sewing patterns
customized to garment and target body shapes to achieve desired looks.
Traditional workflow involves a trial-and-error procedure wherein a mannequin
is draped to judge the resultant folds and the sewing pattern iteratively
adjusted until the desired look is achieved. This requires time and experience.
Instead, we present a data-driven approach wherein the user directly indicates
desired fold patterns simply by sketching while our system estimates
corresponding garment and body shape parameters at interactive rates. The
recovered parameters can then be further edited and the updated draped garment
previewed. Technically, we achieve this via a novel shared shape space that
allows the user to seamlessly specify desired characteristics across multimodal
input {\em without} requiring to run garment simulation at design time. We
evaluate our approach qualitatively via a user study and quantitatively against
test datasets, and demonstrate how our system can generate a rich quality of
on-body garments targeted for a range of body shapes while achieving desired
fold characteristics.
"
1097,"cilantro: A Lean, Versatile, and Efficient Library for Point Cloud Data
  Processing","  We introduce cilantro, an open-source C++ library for geometric and
general-purpose point cloud data processing. The library provides functionality
that covers low-level point cloud operations, spatial reasoning, various
methods for point cloud segmentation and generic data clustering, flexible
algorithms for robust or local geometric alignment, model fitting, as well as
powerful visualization tools. To accommodate all kinds of workflows, cilantro
is almost fully templated, and most of its generic algorithms operate in
arbitrary data dimension. At the same time, the library is easy to use and
highly expressive, promoting a clean and concise coding style. cilantro is
highly optimized, has a minimal set of external dependencies, and supports
rapid development of performant point cloud processing software in a wide
variety of contexts.
"
1098,$P_N$-Method for Multiple Scattering in Participating Media,"  Rendering highly scattering participating media using brute force path
tracing is a challenge. The diffusion approximation reduces the problem to
solving a simple linear partial differential equation. Flux-limited diffusion
introduces non-linearities to improve the accuracy of the solution, especially
in low optical depth media, but introduces several ad-hoc assumptions. Both
methods are based on a spherical harmonics expansion of the radiance field that
is truncated after the first order. In this paper, we investigate the open
question of whether going to higher spherical harmonic orders provides a viable
improvement to these two approaches. Increasing the order introduces a set of
complex coupled partial differential equations (the $P_N$-equations), whose
growing number make them difficult to work with at higher orders. We thus use a
computer algebra framework for representing and manipulating the underlying
mathematical equations, and use it to derive the real-valued $P_N$-equations
for arbitrary orders. We further present a staggered-grid $P_N$-solver and
generate its stencil code directly from the expression tree of the
$P_N$-equations. Finally, we discuss how our method compares to prior work for
various standard problems.
"
1099,Simplifying Urban Data Fusion with BigSUR,"  Our ability to understand data has always lagged behind our ability to
collect it. This is particularly true in urban environments, where mass data
capture is particularly valuable, but the objects captured are more varied,
denser, and complex. To understand the structure and content of the
environment, we must process the unstructured data to a structured form. BigSUR
is an urban reconstruction algorithm which fuses GIS data, photogrammetric
meshes, and street level photography, to create clean representative,
semantically labelled, geometry. However, we have identified three problems
with the system i) the street level photography is often difficult to acquire;
ii) novel fa\c{c}ade styles often frustrate the detection of windows and doors;
iii) the computational requirements of the system are large, processing a large
city block can take up to 15 hours. In this paper we describe the process of
simplifying and validating the BigSUR semantic reconstruction system. In
particular, the requirement for street level images is removed, and greedy
post-process profile assignment is introduced to accelerate the system. We
accomplish this by modifying the binary integer programming (BIP) optimization,
and re-evaluating the effects of various parameters. The new variant of the
system is evaluated over a variety of urban areas. We objectively measure mean
squared error (MSE) terms over the unstructured geometry, showing that BigSUR
is able to accurately recover omissions from the input meshes. Further, we
evaluate the ability of the system to label the walls and roofs of input
meshes, concluding that our new BigSUR variant achieves highly accurate
semantic labelling with shorter computational time and less input data.
"
1100,Solid Geometry Processing on Deconstructed Domains,"  Many tasks in geometry processing are modeled as variational problems solved
numerically using the finite element method. For solid shapes, this requires a
volumetric discretization, such as a boundary conforming tetrahedral mesh.
Unfortunately, tetrahedral meshing remains an open challenge and existing
methods either struggle to conform to complex boundary surfaces or require
manual intervention to prevent failure. Rather than create a single volumetric
mesh for the entire shape, we advocate for solid geometry processing on
deconstructed domains, where a large and complex shape is composed of
overlapping solid subdomains. As each smaller and simpler part is now easier to
tetrahedralize, the question becomes how to account for overlaps during problem
modeling and how to couple solutions on each subdomain together algebraically.
We explore how and why previous coupling methods fail, and propose a method
that couples solid domains only along their boundary surfaces. We demonstrate
the superiority of this method through empirical convergence tests and
qualitative applications to solid geometry processing on a variety of popular
second-order and fourth-order partial differential equations.
"
1101,"Learning Fuzzy Set Representations of Partial Shapes on Dual Embedding
  Spaces","  Modeling relations between components of 3D objects is essential for many
geometry editing tasks. Existing techniques commonly rely on labeled
components, which requires substantial annotation effort and limits components
to a dictionary of predefined semantic parts. We propose a novel framework
based on neural networks that analyzes an uncurated collection of 3D models
from the same category and learns two important types of semantic relations
among full and partial shapes: complementarity and interchangeability. The
former helps to identify which two partial shapes make a complete plausible
object, and the latter indicates that interchanging two partial shapes from
different objects preserves the object plausibility. Our key idea is to jointly
encode both relations by embedding partial shapes as fuzzy sets in dual
embedding spaces. We model these two relations as fuzzy set operations
performed across the dual embedding spaces, and within each space,
respectively. We demonstrate the utility of our method for various retrieval
tasks that are commonly needed in geometric modeling interfaces.
"
1102,"Digital Geometry, a Survey","  This paper provides an overview of modern digital geometry and topology
through mathematical principles, algorithms, and measurements. It also covers
recent developments in the applications of digital geometry and topology
including image processing, computer vision, and data science. Recent research
strongly showed that digital geometry has made considerable contributions to
modelings and algorithms in image segmentation, algorithmic analysis, and
BigData analytics.
"
1103,Continuous-Scale Kinetic Fluid Simulation,"  Kinetic approaches, i.e., methods based on the lattice Boltzmann equations,
have long been recognized as an appealing alternative for solving
incompressible Navier-Stokes equations in computational fluid dynamics.
However, such approaches have not been widely adopted in graphics mainly due to
the underlying inaccuracy, instability and inflexibility. In this paper, we try
to tackle these problems in order to make kinetic approaches practical for
graphical applications. To achieve more accurate and stable simulations, we
propose to employ the non-orthogonal central-moment-relaxation model, where we
develop a novel adaptive relaxation method to retain both stability and
accuracy in turbulent flows. To achieve flexibility, we propose a novel
continuous-scale formulation that enables samples at arbitrary resolutions to
easily communicate with each other in a more continuous sense and with loose
geometrical constraints, which allows efficient and adaptive sample
construction to better match the physical scale. Such a capability directly
leads to an automatic sample construction which generates static and dynamic
scales at initialization and during simulation, respectively. This effectively
makes our method suitable for simulating turbulent flows with arbitrary
geometrical boundaries. Our simulation results with applications to smoke
animations show the benefits of our method, with comparisons for justification
and verification.
"
1104,Evolution of natural patterns from random fields,"  In the article a transition from pattern evolution equation of
reaction-diffusion type to a cellular automaton (CA) is described. The
applicability of CA is demonstrated by generating patterns of complex irregular
structure on a hexagonal and quadratic lattice. With this aim a random initial
field is transformed by a sequence of CA actions into a new pattern. On the
hexagonal lattice this pattern resembles a lizard skin. The properties of CA
are specified by the most simple majority rule that adapts selected cell state
to the most frequent state of cells in its surrounding. The method could be of
interest for manufacturing of textiles as well as for modeling of patterns on
skin of various animals.
"
1105,"Guided Proceduralization: Optimizing Geometry Processing and Grammar
  Extraction for Architectural Models","  We describe a guided proceduralization framework that optimizes geometry
processing on architectural input models to extract target grammars. We aim to
provide efficient artistic workflows by creating procedural representations
from existing 3D models, where the procedural expressiveness is controlled by
the user. Architectural reconstruction and modeling tasks have been handled as
either time consuming manual processes or procedural generation with difficult
control and artistic influence. We bridge the gap between creation and
generation by converting existing manually modeled architecture to procedurally
editable parametrized models, and carrying the guidance to procedural domain by
letting the user define the target procedural representation. Additionally, we
propose various applications of such procedural representations, including
guided completion of point cloud models, controllable 3D city modeling, and
other benefits of procedural modeling.
"
1106,"Inferring Quality in Point Cloud-based 3D Printed Objects using
  Topological Data Analysis","  Assessing the quality of 3D printed models before they are printed remains a
challeng- ing problem, particularly when considering point cloud-based models.
This paper introduces an approach to quality assessment, which uses techniques
from the field of Topological Data Analy- sis (TDA) to compute a topological
abstraction of the eventual printed model. Two main tools of TDA, Mapper and
persistent homology, are used to analyze both the printed space and empty space
created by the model. This abstraction enables investigating certain qualities
of the model, with respect to print quality, and identifies potential anomalies
that may appear in the final product.
"
1107,"Fashion is Taking Shape: Understanding Clothing Preference Based on Body
  Shape From Online Sources","  To study the correlation between clothing garments and body shape, we
collected a new dataset (Fashion Takes Shape), which includes images of users
with clothing category annotations. We employ our multi-photo approach to
estimate body shapes of each user and build a conditional model of clothing
categories given body-shape. We demonstrate that in real-world data, clothing
categories and body-shapes are correlated and show that our multi-photo
approach leads to a better predictive model for clothing categories compared to
models based on single-view shape estimates or manually annotated body types.
We see our method as the first step towards the large-scale understanding of
clothing preferences from body shape.
"
1108,StyleBlit: Fast Example-Based Stylization with Local Guidance,"  We present StyleBlit---an efficient example-based style transfer algorithm
that can deliver high-quality stylized renderings in real-time on a single-core
CPU. Our technique is especially suitable for style transfer applications that
use local guidance - descriptive guiding channels containing large spatial
variations. Local guidance encourages transfer of content from the source
exemplar to the target image in a semantically meaningful way. Typical local
guidance includes, e.g., normal values, texture coordinates or a displacement
field. Contrary to previous style transfer techniques, our approach does not
involve any computationally expensive optimization. We demonstrate that when
local guidance is used, optimization-based techniques converge to solutions
that can be well approximated by simple pixel-level operations. Inspired by
this observation, we designed an algorithm that produces results visually
similar to, if not better than, the state-of-the-art, and is several orders of
magnitude faster. Our approach is suitable for scenarios with low computational
budget such as games and mobile applications.
"
1109,"Detecting Socio-Economic Impact of Cultural Investment Through
  Geo-Social Network Analysis","  Taking advantage of nearly 4 million transition records for three years in
London from a popular location-based social network service, Foursquare, we
study how to track the impact and measure the effectiveness of cultural
investment in small urban areas. We reveal the underlying relationships between
socio-economic status, local cultural expenditure, and network features
extracted from user mobility trajectories. This research presents how
geo-social and mobile services more generally can be used as a proxy to track
local changes as government financial effort is put in developing urban areas,
and thus gives evidence and suggestions for further policy-making and
investment optimization.
"
1110,Multiresolution Tree Networks for 3D Point Cloud Processing,"  We present multiresolution tree-structured networks to process point clouds
for 3D shape understanding and generation tasks. Our network represents a 3D
shape as a set of locality-preserving 1D ordered list of points at multiple
resolutions. This allows efficient feed-forward processing through 1D
convolutions, coarse-to-fine analysis through a multi-grid architecture, and it
leads to faster convergence and small memory footprint during training. The
proposed tree-structured encoders can be used to classify shapes and outperform
existing point-based architectures on shape classification benchmarks, while
tree-structured decoders can be used for generating point clouds directly and
they outperform existing approaches for image-to-shape inference tasks learned
using the ShapeNet dataset. Our model also allows unsupervised learning of
point-cloud based shapes by using a variational autoencoder, leading to
higher-quality generated shapes.
"
1111,Indy: a virtual reality multi-player game for navigation skills training,"  Working in complex industrial facilities requires spatial navigation skills
that people build up with time and field experience. Training sessions
consisting in guided tours help discover places but they are insufficient to
become intimately familiar with their layout. They imply passive learning
postures, are time-limited and can be experienced only once because of
organization constraints and potential interferences with ongoing activities in
the buildings. To overcome these limitations and improve the acquisition of
navigation skills, we developed Indy, a virtual reality system consisting in a
collaborative game of treasure hunting. It has several key advantages: it
focuses learners' attention on navigation tasks, implies their active
engagement and provides them with feedbacks on their achievements. Virtual
reality makes it possible to multiply the number and duration of situations
that learners can experience to better consolidate their skills. This paper
discusses the main design principles and a typical usage scenario of Indy.
"
1112,"IntroVAE: Introspective Variational Autoencoders for Photographic Image
  Synthesis","  We present a novel introspective variational autoencoder (IntroVAE) model for
synthesizing high-resolution photographic images. IntroVAE is capable of
self-evaluating the quality of its generated samples and improving itself
accordingly. Its inference and generator models are jointly trained in an
introspective way. On one hand, the generator is required to reconstruct the
input images from the noisy outputs of the inference model as normal VAEs. On
the other hand, the inference model is encouraged to classify between the
generated and real samples while the generator tries to fool it as GANs. These
two famous generative frameworks are integrated in a simple yet efficient
single-stream architecture that can be trained in a single stage. IntroVAE
preserves the advantages of VAEs, such as stable training and nice latent
manifold. Unlike most other hybrid models of VAEs and GANs, IntroVAE requires
no extra discriminators, because the inference model itself serves as a
discriminator to distinguish between the generated and real samples.
Experiments demonstrate that our method produces high-resolution
photo-realistic images (e.g., CELEBA images at \(1024^{2}\)), which are
comparable to or better than the state-of-the-art GANs.
"
1113,"A Deep Learning Driven Active Framework for Segmentation of Large 3D
  Shape Collections","  High-level shape understanding and technique evaluation on large repositories
of 3D shapes often benefit from additional information known about the shapes.
One example of such information is the semantic segmentation of a shape into
functional or meaningful parts. Generating accurate segmentations with
meaningful segment boundaries is, however, a costly process, typically
requiring large amounts of user time to achieve high quality results. In this
paper we present an active learning framework for large dataset segmentation,
which iteratively provides the user with new predictions by training new models
based on already segmented shapes. Our proposed pipeline consists of three
novel components. First, we a propose a fast and relatively accurate
feature-based deep learning model to provide dataset-wide segmentation
predictions. Second, we propose an information theory measure to estimate the
prediction quality and for ordering subsequent fast and meaningful shape
selection. Our experiments show that such suggestive ordering helps reduce
users time and effort, produce high quality predictions, and construct a model
that generalizes well. Finally, we provide effective segmentation refinement
features to help the user quickly correct any incorrect predictions. We show
that our framework is more accurate and in general more efficient than
state-of-the-art, for massive dataset segmentation with while also providing
consistent segment boundaries.
"
1114,CNNs based Viewpoint Estimation for Volume Visualization,"  Viewpoint estimation from 2D rendered images is helpful in understanding how
users select viewpoints for volume visualization and guiding users to select
better viewpoints based on previous visualizations. In this paper, we propose a
viewpoint estimation method based on Convolutional Neural Networks (CNNs) for
volume visualization. We first design an overfit-resistant image rendering
pipeline to generate the training images with accurate viewpoint annotations,
and then train a category-specific viewpoint classification network to estimate
the viewpoint for the given rendered image. Our method can achieve good
performance on images rendered with different transfer functions and rendering
parameters in several categories. We apply our model to recover the viewpoints
of the rendered images in publications, and show how experts look at volumes.
We also introduce a CNN feature-based image similarity measure for similarity
voting based viewpoint selection, which can suggest semantically meaningful
optimal viewpoints for different volumes and transfer functions.
"
1115,Deep Learning Parametrization for B-Spline Curve Approximation,"  In this paper we present a method using deep learning to compute
parametrizations for B-spline curve approximation. Existing methods consider
the computation of parametric values and a knot vector as separate problems. We
propose to train interdependent deep neural networks to predict parametric
values and knots. We show that it is possible to include B-spline curve
approximation directly into the neural network architecture. The resulting
parametrizations yield tight approximations and are able to outperform
state-of-the-art methods.
"
1116,Robust Edge-Preserved Surface Mesh Polycube Deformation,"  The problem of polycube construction or deformation is an essential problem
in computer graphics. In this paper, we present a robust, simple, efficient and
automatic algorithm to deform the meshes of arbitrary shapes into their
polycube ones. We derive a clear relationship between a mesh and its
corresponding polycube shape. Our algorithm is edge-preserved, and works on
surface meshes with or without boundaries. Our algorithm outperforms previous
ones in speed, robustness, efficiency. Our method is simple to implement. To
demonstrate the robustness and effectiveness of our method, we apply it to
hundreds of models of varying complexity and topology. We demonstrat that our
method compares favorably to other state-of-the-art polycube deformation
methods.
"
1117,Conformal Mesh Parameterization Using Discrete Calabi Flow,"  In this paper, we introduce discrete Calabi flow to the graphics research
community and present a novel conformal mesh parameterization algorithm. Calabi
energy has a succinct and explicit format. Its corresponding flow is conformal
and convergent under certain conditions. Our method is based on the Calabi
energy and Calabi flow with solid theoretical and mathematical base. We
demonstrate our approach on dozens of models and compare it with other related
flow based methods, such as the well-known Ricci flow and CETM. Our experiments
show that the performance of our algorithm is comparably the same with other
methods. The discrete Calabi flow in our method provides another perspective on
conformal flow and conformal parameterization.
"
1118,CaricatureShop: Personalized and Photorealistic Caricature Sketching,"  In this paper, we propose the first sketching system for interactively
personalized and photorealistic face caricaturing. Input an image of a human
face, the users can create caricature photos by manipulating its facial feature
curves. Our system firstly performs exaggeration on the recovered 3D face model
according to the edited sketches, which is conducted by assigning the laplacian
of each vertex a scaling factor. To construct the mapping between 2D sketches
and a vertex-wise scaling field, a novel deep learning architecture is
developed. With the obtained 3D caricature model, two images are generated, one
obtained by applying 2D warping guided by the underlying 3D mesh deformation
and the other obtained by re-rendering the deformed 3D textured model. These
two images are then seamlessly integrated to produce our final output. Due to
the severely stretching of meshes, the rendered texture is of blurry
appearances. A deep learning approach is exploited to infer the missing details
for enhancing these blurry regions. Moreover, a relighting operation is
invented to further improve the photorealism of the result. Both quantitative
and qualitative experiment results validated the efficiency of our sketching
system and the superiority of our proposed techniques against existing methods.
"
1119,GRAINS: Generative Recursive Autoencoders for INdoor Scenes,"  We present a generative neural network which enables us to generate plausible
3D indoor scenes in large quantities and varieties, easily and highly
efficiently. Our key observation is that indoor scene structures are inherently
hierarchical. Hence, our network is not convolutional; it is a recursive neural
network or RvNN. Using a dataset of annotated scene hierarchies, we train a
variational recursive autoencoder, or RvNN-VAE, which performs scene object
grouping during its encoding phase and scene generation during decoding.
Specifically, a set of encoders are recursively applied to group 3D objects
based on support, surround, and co-occurrence relations in a scene, encoding
information about object spatial properties, semantics, and their relative
positioning with respect to other objects in the hierarchy. By training a
variational autoencoder (VAE), the resulting fixed-length codes roughly follow
a Gaussian distribution. A novel 3D scene can be generated hierarchically by
the decoder from a randomly sampled code from the learned distribution. We coin
our method GRAINS, for Generative Recursive Autoencoders for INdoor Scenes. We
demonstrate the capability of GRAINS to generate plausible and diverse 3D
indoor scenes and compare with existing methods for 3D scene synthesis. We show
applications of GRAINS including 3D scene modeling from 2D layouts, scene
editing, and semantic scene segmentation via PointNet whose performance is
boosted by the large quantity and variety of 3D scenes generated by our method.
"
1120,Constraint-Based Visual Generation,"  In the last few years the systematic adoption of deep learning to visual
generation has produced impressive results that, amongst others, definitely
benefit from the massive exploration of convolutional architectures. In this
paper, we propose a general approach to visual generation that combines
learning capabilities with logic descriptions of the target to be generated.
The process of generation is regarded as a constrained satisfaction problem,
where the constraints describe a set of properties that characterize the
target. Interestingly, the constraints can also involve logic variables, while
all of them are converted into real-valued functions by means of the t-norm
theory. We use deep architectures to model the involved variables, and propose
a computational scheme where the learning process carries out a satisfaction of
the constraints. We propose some examples in which the theory can naturally be
used, including the modeling of GAN and auto-encoders, and report promising
results in problems with the generation of handwritten characters and face
transformations.
"
1121,FARM: Functional Automatic Registration Method for 3D Human Bodies,"  We introduce a new method for non-rigid registration of 3D human shapes. Our
proposed pipeline builds upon a given parametric model of the human, and makes
use of the functional map representation for encoding and inferring shape maps
throughout the registration process. This combination endows our method with
robustness to a large variety of nuisances observed in practical settings,
including non-isometric transformations, downsampling, topological noise, and
occlusions; further, the pipeline can be applied invariably across different
shape representations (e.g. meshes and point clouds), and in the presence of
(even dramatic) missing parts such as those arising in real-world depth sensing
applications. We showcase our method on a selection of challenging tasks,
demonstrating results in line with, or even surpassing, state-of-the-art
methods in the respective areas.
"
1122,ReenactGAN: Learning to Reenact Faces via Boundary Transfer,"  We present a novel learning-based framework for face reenactment. The
proposed method, known as ReenactGAN, is capable of transferring facial
movements and expressions from monocular video input of an arbitrary person to
a target person. Instead of performing a direct transfer in the pixel space,
which could result in structural artifacts, we first map the source face onto a
boundary latent space. A transformer is subsequently used to adapt the boundary
of source face to the boundary of target face. Finally, a target-specific
decoder is used to generate the reenacted target face. Thanks to the effective
and reliable boundary-based transfer, our method can perform photo-realistic
face reenactment. In addition, ReenactGAN is appealing in that the whole
reenactment process is purely feed-forward, and thus the reenactment process
can run in real-time (30 FPS on one GTX 1080 GPU). Dataset and model will be
publicly available at
https://wywu.github.io/projects/ReenactGAN/ReenactGAN.html
"
1123,Persistence Atlas for Critical Point Variability in Ensembles,"  This paper presents a new approach for the visualization and analysis of the
spatial variability of features of interest represented by critical points in
ensemble data. Our framework, called Persistence Atlas, enables the
visualization of the dominant spatial patterns of critical points, along with
statistics regarding their occurrence in the ensemble. The persistence atlas
represents in the geometrical domain each dominant pattern in the form of a
confidence map for the appearance of critical points. As a by-product, our
method also provides 2-dimensional layouts of the entire ensemble, highlighting
the main trends at a global level. Our approach is based on the new notion of
Persistence Map, a measure of the geometrical density in critical points which
leverages the robustness to noise of topological persistence to better
emphasize salient features. We show how to leverage spectral embedding to
represent the ensemble members as points in a low-dimensional Euclidean space,
where distances between points measure the dissimilarities between critical
point layouts and where statistical tasks, such as clustering, can be easily
carried out. Further, we show how the notion of mandatory critical point can be
leveraged to evaluate for each cluster confidence regions for the appearance of
critical points. Most of the steps of this framework can be trivially
parallelized and we show how to efficiently implement them. Extensive
experiments demonstrate the relevance of our approach. The accuracy of the
confidence regions provided by the persistence atlas is quantitatively
evaluated and compared to a baseline strategy using an off-the-shelf clustering
approach. We illustrate the importance of the persistence atlas in a variety of
real-life datasets, where clear trends in feature layouts are identified and
analyzed.
"
1124,"AniCode: Authoring Coded Artifacts for Network-Free Personalized
  Animations","  Time-based media (videos, synthetic animations, and virtual reality
experiences) are used for communication, in applications such as manufacturers
explaining the operation of a new appliance to consumers and scientists
illustrating the basis of a new conclusion. However, authoring time-based media
that are effective and personalized for the viewer remains a challenge. We
introduce AniCode, a novel framework for authoring and consuming time-based
media. An author encodes a video animation in a printed code, and affixes the
code to an object. A consumer uses a mobile application to capture an image of
the object and code, and to generate a video presentation on the fly.
Importantly, AniCode presents the video personalized in the consumer's visual
context. Our system is designed to be low cost and easy to use. By not
requiring an internet connection, and through animations that decode correctly
only in the intended context, AniCode enhances privacy of communication using
time-based media. Animation schemes in the system include a series of 2D and 3D
geometric transformations, color transformation, and annotation. We demonstrate
the AniCode framework with sample applications from a wide range of domains,
including product ""how to"" examples, cultural heritage, education, creative
art, and design. We evaluate the ease of use and effectiveness of our system
with a user study.
"
1125,On-the-Fly Power-Aware Rendering,"  Power saving is a prevailing concern in desktop computers and, especially, in
battery-powered devices such as mobile phones. This is generating a growing
demand for power-aware graphics applications that can extend battery life,
while preserving good quality. In this paper, we address this issue by
presenting a real-time power-efficient rendering framework, able to dynamically
select the rendering configuration with the best quality within a given power
budget. Different from the current state of the art, our method does not
require precomputation of the whole camera-view space, nor Pareto curves to
explore the vast power-error space; as such, it can also handle dynamic scenes.
Our algorithm is based on two key components: our novel power prediction model,
and our runtime quality error estimation mechanism. These components allow us
to search for the optimal rendering configuration at runtime, being transparent
to the user. We demonstrate the performance of our framework on two different
platforms: a desktop computer, and a mobile device. In both cases, we produce
results close to the maximum quality, while achieving significant power
savings.
"
1126,Fast Sketch Segmentation and Labeling with Deep Learning,"  We present a simple and efficient method based on deep learning to
automatically decompose sketched objects into semantically valid parts. We
train a deep neural network to transfer existing segmentations and labelings
from 3D models to freehand sketches without requiring numerous well-annotated
sketches as training data. The network takes the binary image of a sketched
object as input and produces a corresponding segmentation map with per-pixel
labelings as output. A subsequent post-process procedure with multi-label graph
cuts further refines the segmentation and labeling result. We validate our
proposed method on two sketch datasets. Experiments show that our method
outperforms the state-of-the-art method in terms of segmentation and labeling
accuracy and is significantly faster, enabling further integration in
interactive drawing systems. We demonstrate the efficiency of our method in a
sketch-based modeling application that automatically transforms input sketches
into 3D models by part assembly.
"
1127,"There is more to PCG than Meets the Eye: NPC AI, Dynamic Camera, PVS and
  Lightmaps","  Procedural content generation (PCG) concerns all sorts of algorithms and
tools which automatically produce game content, without requiring manual
authoring by game artists. Besides generating com-plex static meshes, the PCG
core usually encompasses geometrical information about the game world that can
be useful in supporting other critical subsystems of the game engine. We
discuss our experi-ence from the development of the iOS game title named
""Fallen God: Escape Underworld"", and show how our PCG produced extra metadata
regarding the game world, in particular: (i) an annotated dun-geon graph to
support path finding for NPC AI to attack or avoid the player (working for
bipeds, birds, insects and serpents); (ii) a quantized voxel space to allow
discrete A* for the dynamic camera system to work in the continuous 3d space;
(iii) dungeon portals to support a dynamic PVS; and (iv) procedural ambient
occlusion and tessellation of a separate set of simplified meshes to support
very-fast and high-quality light mapping.
"
1128,Deep Appearance Models for Face Rendering,"  We introduce a deep appearance model for rendering the human face. Inspired
by Active Appearance Models, we develop a data-driven rendering pipeline that
learns a joint representation of facial geometry and appearance from a
multiview capture setup. Vertex positions and view-specific textures are
modeled using a deep variational autoencoder that captures complex nonlinear
effects while producing a smooth and compact latent representation.
View-specific texture enables the modeling of view-dependent effects such as
specularity. In addition, it can also correct for imperfect geometry stemming
from biased or low resolution estimates. This is a significant departure from
the traditional graphics pipeline, which requires highly accurate geometry as
well as all elements of the shading model to achieve realism through
physically-inspired light transport. Acquiring such a high level of accuracy is
difficult in practice, especially for complex and intricate parts of the face,
such as eyelashes and the oral cavity. These are handled naturally by our
approach, which does not rely on precise estimates of geometry. Instead, the
shading model accommodates deficiencies in geometry though the flexibility
afforded by the neural network employed. At inference time, we condition the
decoding network on the viewpoint of the camera in order to generate the
appropriate texture for rendering. The resulting system can be implemented
simply using existing rendering engines through dynamic textures with flat
lighting. This representation, together with a novel unsupervised technique for
mapping images to facial states, results in a system that is naturally suited
to real-time interactive settings such as Virtual Reality (VR).
"
1129,"Toward A Deep Understanding of What Makes a Scientific Visualization
  Memorable","  We report results from a preliminary study exploring the memorability of
spatial scientific visualizations, the goal of which is to understand the
visual features that contribute to memorability. The evaluation metrics include
three objective measures (entropy, feature congestion, the number of edges),
four subjective ratings (clutter, the number of distinct colors, familiarity,
and realism), and two sentiment ratings (interestingness and happiness). We
curate 1142 scientific visualization (SciVis) images from the original 2231
images in published IEEE SciVis papers from 2008 to 2017 and compute
memorability scores of 228 SciVis images from data collected on Amazon
Mechanical Turk (MTurk). Results showed that the memorability of SciVis images
is mostly correlated with clutter and the number of distinct colors. We further
investigate the differences between scientific visualization and infographics
as a means to understand memorability differences by data attributes.
"
1130,"Evaluating the Readability of Force Directed Graph Layouts: A Deep
  Learning Approach","  Existing graph layout algorithms are usually not able to optimize all the
aesthetic properties desired in a graph layout. To evaluate how well the
desired visual features are reflected in a graph layout, many readability
metrics have been proposed in the past decades. However, the calculation of
these readability metrics often requires access to the node and edge
coordinates and is usually computationally inefficient, especially for dense
graphs. Importantly, when the node and edge coordinates are not accessible, it
becomes impossible to evaluate the graph layouts quantitatively. In this paper,
we present a novel deep learning-based approach to evaluate the readability of
graph layouts by directly using graph images. A convolutional neural network
architecture is proposed and trained on a benchmark dataset of graph images,
which is composed of synthetically-generated graphs and graphs created by
sampling from real large networks. Multiple representative readability metrics
(including edge crossing, node spread, and group overlap) are considered in the
proposed approach. We quantitatively compare our approach to traditional
methods and qualitatively evaluate our approach using a case study and
visualizing convolutional layers. This work is a first step towards using deep
learning based methods to evaluate images from the visualization field
quantitatively.
"
1131,The Normal Map Based on Area-Preserving Parameterization,"  In this paper, we present an approach to enhance and improve the current
normal map rendering technique. Our algorithm is based on semi-discrete Optimal
Mass Transportation (OMT) theory and has a solid theoretical base. The key
difference from previous normal map method is that we preserve the local area
when we unwrap a disk-like 3D surface onto 2D plane. Compared to the currently
used techniques which is based on conformal parameterization, our method does
not need to cut a surface into many small pieces to avoid the large area
distortion. The following charts packing step is also unnecessary in our
framework. Our method is practical and makes the normal map technique more
robust and efficient.
"
1132,Structure-Aware Shape Synthesis,"  We propose a new procedure to guide training of a data-driven shape
generative model using a structure-aware loss function. Complex 3D shapes often
can be summarized using a coarsely defined structure which is consistent and
robust across variety of observations. However, existing synthesis techniques
do not account for structure during training, and thus often generate
implausible and structurally unrealistic shapes. During training, we enforce
structural constraints in order to enforce consistency and structure across the
entire manifold. We propose a novel methodology for training 3D generative
models that incorporates structural information into an end-to-end training
pipeline.
"
1133,"Beyond Pixel Norm-Balls: Parametric Adversaries using an Analytically
  Differentiable Renderer","  Many machine learning image classifiers are vulnerable to adversarial
attacks, inputs with perturbations designed to intentionally trigger
misclassification. Current adversarial methods directly alter pixel colors and
evaluate against pixel norm-balls: pixel perturbations smaller than a specified
magnitude, according to a measurement norm. This evaluation, however, has
limited practical utility since perturbations in the pixel space do not
correspond to underlying real-world phenomena of image formation that lead to
them and has no security motivation attached. Pixels in natural images are
measurements of light that has interacted with the geometry of a physical
scene. As such, we propose the direct perturbation of physical parameters that
underly image formation: lighting and geometry. As such, we propose a novel
evaluation measure, parametric norm-balls, by directly perturbing physical
parameters that underly image formation. One enabling contribution we present
is a physically-based differentiable renderer that allows us to propagate pixel
gradients to the parametric space of lighting and geometry. Our approach
enables physically-based adversarial attacks, and our differentiable renderer
leverages models from the interactive rendering literature to balance the
performance and accuracy trade-offs necessary for a memory-efficient and
scalable adversarial data augmentation workflow.
"
1134,"Cinematic Visualization of Multiresolution Data: Ytini for Adaptive Mesh
  Refinement in Houdini","  We have entered the era of large multidimensional datasets represented by
increasingly complex data structures. Current tools for scientific
visualization are not optimized to efficiently and intuitively create cinematic
production quality, time-evolving representations of numerical data for broad
impact science communication via film, media, or journalism. To present such
data in a cinematic environment, it is advantageous to develop methods that
integrate these complex data structures into industry standard visual effects
software packages, which provide a myriad of control features otherwise
unavailable in traditional scientific visualization software. In this paper, we
present the general methodology for the import and visualization of nested
multiresolution datasets into commercially available visual effects software.
We further provide a specific example of importing Adaptive Mesh Refinement
data into the software Houdini. This paper builds on our previous work, which
describes a method for using Houdini to visualize uniform Cartesian datasets.
We summarize a tutorial available on the website www.ytini.com, which includes
sample data downloads, Python code, and various other resources to simplify the
process of importing and rendering multiresolution data.
"
1135,DeepMag: Source Specific Motion Magnification Using Gradient Ascent,"  Many important physical phenomena involve subtle signals that are difficult
to observe with the unaided eye, yet visualizing them can be very informative.
Current motion magnification techniques can reveal these small temporal
variations in video, but require precise prior knowledge about the target
signal, and cannot deal with interference motions at a similar frequency. We
present DeepMag an end-to-end deep neural video-processing framework based on
gradient ascent that enables automated magnification of subtle color and motion
signals from a specific source, even in the presence of large motions of
various velocities. While the approach is generalizable, the advantages of
DeepMag are highlighted via the task of video-based physiological
visualization. Through systematic quantitative and qualitative evaluation of
the approach on videos with different levels of head motion, we compare the
magnification of pulse and respiration to existing state-of-the-art methods.
Our method produces magnified videos with substantially fewer artifacts and
blurring whilst magnifying the physiological changes by a similar degree.
"
1136,"Learning Discriminative 3D Shape Representations by View Discerning
  Networks","  In view-based 3D shape recognition, extracting discriminative visual
representation of 3D shapes from projected images is considered the core
problem. Projections with low discriminative ability can adversely influence
the final 3D shape representation. Especially under the real situations with
background clutter and object occlusion, the adverse effect is even more
severe. To resolve this problem, we propose a novel deep neural network, View
Discerning Network, which learns to judge the quality of views and adjust their
contributions to the representation of shapes. In this network, a Score
Generation Unit is devised to evaluate the quality of each projected image with
score vectors. These score vectors are used to weight the image features and
the weighted features perform much better than original features in 3D shape
recognition task. In particular, we introduce two structures of Score
Generation Unit, Channel-wise Score Unit and Part-wise Score Unit, to assess
the quality of feature maps from different perspectives. Our network aggregates
features and scores in an end-to-end framework, so that final shape descriptors
are directly obtained from its output. Our experiments on ModelNet and ShapeNet
Core55 show that View Discerning Network outperforms the state-of-the-arts in
terms of the retrieval task, with excellent robustness against background
clutter and object occlusion.
"
1137,Neural Importance Sampling,"  We propose to use deep neural networks for generating samples in Monte Carlo
integration. Our work is based on non-linear independent components estimation
(NICE), which we extend in numerous ways to improve performance and enable its
application to integration problems. First, we introduce piecewise-polynomial
coupling transforms that greatly increase the modeling power of individual
coupling layers. Second, we propose to preprocess the inputs of neural networks
using one-blob encoding, which stimulates localization of computation and
improves inference. Third, we derive a gradient-descent-based optimization for
the KL and the $\chi^2$ divergence for the specific application of Monte Carlo
integration with unnormalized stochastic estimates of the target distribution.
Our approach enables fast and accurate inference and efficient sample
generation independently of the dimensionality of the integration domain. We
show its benefits on generating natural images and in two applications to
light-transport simulation: first, we demonstrate learning of joint
path-sampling densities in the primary sample space and importance sampling of
multi-dimensional path prefixes thereof. Second, we use our technique to
extract conditional directional densities driven by the product of incident
illumination and the BSDF in the rendering equation, and we leverage the
densities for path guiding. In all applications, our approach yields on-par or
higher performance than competing techniques at equal sample count.
"
1138,SAGNet:Structure-aware Generative Network for 3D-Shape Modeling,"  We present SAGNet, a structure-aware generative model for 3D shapes. Given a
set of segmented objects of a certain class, the geometry of their parts and
the pairwise relationships between them (the structure) are jointly learned and
embedded in a latent space by an autoencoder. The encoder intertwines the
geometry and structure features into a single latent code, while the decoder
disentangles the features and reconstructs the geometry and structure of the 3D
model. Our autoencoder consists of two branches, one for the structure and one
for the geometry. The key idea is that during the analysis, the two branches
exchange information between them, thereby learning the dependencies between
structure and geometry and encoding two augmented features, which are then
fused into a single latent code. This explicit intertwining of information
enables separately controlling the geometry and the structure of the generated
models. We evaluate the performance of our method and conduct an ablation
study. We explicitly show that encoding of shapes accounts for both
similarities in structure and geometry. A variety of quality results generated
by SAGNet are presented. The data and code are at
https://github.com/zhijieW-94/SAGNet.
"
1139,Image Inpainting Based on a Novel Criminisi Algorithm,"  In view of the problem of image inpainting error continuation and the
deviation of finding best match block, an improved Criminisi algorithm is
proposed. The improvement was mainly embodied in two aspects. In the repairing
order aspect, we redefine the calculation formula of the priority. In order to
solve the problem of error continuation caused by local confidence item
updating, the mean value of Manhattan distance is used for replace the
confidence item. In the matching strategy aspect, finding the best match block
not only depend on the difference of the two pixels, but also consider the
matching region. Therefore, Euclidean distance is introduced. Experiments
confirm that the improved algorithm can overcome the insufficiencies of the
original algorithm. The repairing effect has been improved, and the results
have a better visual appearance.
"
1140,"MT-VAE: Learning Motion Transformations to Generate Multimodal Human
  Dynamics","  Long-term human motion can be represented as a series of motion
modes---motion sequences that capture short-term temporal dynamics---with
transitions between them. We leverage this structure and present a novel Motion
Transformation Variational Auto-Encoders (MT-VAE) for learning motion sequence
generation. Our model jointly learns a feature embedding for motion modes (that
the motion sequence can be reconstructed from) and a feature transformation
that represents the transition of one motion mode to the next motion mode. Our
model is able to generate multiple diverse and plausible motion sequences in
the future from the same input. We apply our approach to both facial and full
body motion, and demonstrate applications like analogy-based motion transfer
and video synthesis.
"
1141,"Neural Material: Learning Elastic Constitutive Material and Damping
  Models from Sparse Data","  The accuracy and fidelity of deformation simulations are highly dependent
upon the underlying constitutive material model. Commonly used linear or
nonlinear constitutive material models only cover a tiny part of possible
material behavior. In this work we propose a unified framework for modeling
deformable material. The key idea is to use a neural network to correct a
nominal model of the elastic and damping properties of the object. The neural
network encapsulates a complex function that is hard to explicitly model. It
injects force corrections that help the forward simulation to more accurately
predict the true behavior of a given soft object, which includes non-linear
elastic forces and damping. Attempting to satisfy the requirement from real
material interference and animation design scenarios, we learn material models
from examples of dynamic behavior of a deformable object's surface. The
challenge is that such data is sparse as it is consistently given only on part
of the surface. Sparse reduced space-time optimization is employed to gradually
generate increasingly accurate training data, which further refines and
enhances the neural network. We evaluate our choice of network architecture and
show evidence that the modest amount of training data we use is suitable for
the problem tackled. Our method is demonstrated with a set of synthetic
examples.
"
1142,"PFCNN: Convolutional Neural Networks on 3D Surfaces Using Parallel
  Frames","  Surface meshes are widely used shape representations and capture finer
geometry data than point clouds or volumetric grids, but are challenging to
apply CNNs directly due to their non-Euclidean structure. We use parallel
frames on surface to define PFCNNs that enable effective feature learning on
surface meshes by mimicking standard convolutions faithfully. In particular,
the convolution of PFCNN not only maps local surface patches onto flat tangent
planes, but also aligns the tangent planes such that they locally form a flat
Euclidean structure, thus enabling recovery of standard convolutions. The
alignment is achieved by the tool of locally flat connections borrowed from
discrete differential geometry, which can be efficiently encoded and computed
by parallel frame fields. In addition, the lack of canonical axis on surface is
handled by sampling with the frame directions. Experiments show that for tasks
including classification, segmentation and registration on deformable geometric
domains, as well as semantic scene segmentation on rigid domains, PFCNNs
achieve robust and superior performances without using sophisticated input
features than state-of-the-art surface based CNNs.
"
1143,Recycle-GAN: Unsupervised Video Retargeting,"  We introduce a data-driven approach for unsupervised video retargeting that
translates content from one domain to another while preserving the style native
to a domain, i.e., if contents of John Oliver's speech were to be transferred
to Stephen Colbert, then the generated content/speech should be in Stephen
Colbert's style. Our approach combines both spatial and temporal information
along with adversarial losses for content translation and style preservation.
In this work, we first study the advantages of using spatiotemporal constraints
over spatial constraints for effective retargeting. We then demonstrate the
proposed approach for the problems where information in both space and time
matters such as face-to-face translation, flower-to-flower, wind and cloud
synthesis, sunrise and sunset.
"
1144,"Self-supervised CNN for Unconstrained 3D Facial Performance Capture from
  an RGB-D Camera","  We present a novel method for real-time 3D facial performance capture with
consumer-level RGB-D sensors. Our capturing system is targeted at robust and
stable 3D face capturing in the wild, in which the RGB-D facial data contain
noise, imperfection and occlusion, and often exhibit high variability in
motion, pose, expression and lighting conditions, thus posing great challenges.
The technical contribution is a self-supervised deep learning framework, which
is trained directly from raw RGB-D data. The key novelties include: (1)
learning both the core tensor and the parameters for refining our parametric
face model; (2) using vertex displacement and UV map for learning surface
detail; (3) designing the loss function by incorporating temporal coherence and
same identity constraints based on pairs of RGB-D images and utilizing sparse
norms, in addition to the conventional terms for photo-consistency, feature
similarity, regularization as well as geometry consistency; and (4) augmenting
the training data set in new ways. The method is demonstrated in a live setup
that runs in real-time on a smartphone and an RGB-D sensor. Extensive
experiments show that our method is robust to severe occlusion, fast motion,
large rotation, exaggerated facial expressions and diverse lighting.
"
1145,Lifted Wasserstein Matcher for Fast and Robust Topology Tracking,"  This paper presents a robust and efficient method for tracking topological
features in time-varying scalar data. Structures are tracked based on the
optimal matching between persistence diagrams with respect to the Wasserstein
metric. This fundamentally relies on solving the assignment problem, a special
case of optimal transport, for all consecutive timesteps. Our approach relies
on two main contributions. First, we revisit the seminal assignment algorithm
by Kuhn and Munkres which we specifically adapt to the problem of matching
persistence diagrams in an efficient way. Second, we propose an extension of
the Wasserstein metric that significantly improves the geometrical stability of
the matching of domain-embedded persistence pairs. We show that this
geometrical lifting has the additional positive side-effect of improving the
assignment matrix sparsity and therefore computing time. The global framework
implements a coarse-grained parallelism by computing persistence diagrams and
finding optimal matchings in parallel for every couple of consecutive
timesteps. Critical trajectories are constructed by associating successively
matched persistence pairs over time. Merging and splitting events are detected
with a geometrical threshold in a post-processing stage. Extensive experiments
on real-life datasets show that our matching approach is an order of magnitude
faster than the seminal Munkres algorithm. Moreover, compared to a modern
approximation method, our method provides competitive runtimes while yielding
exact results. We demonstrate the utility of our global framework by extracting
critical point trajectories from various simulated time-varying datasets and
compare it to the existing methods based on associated overlaps of volumes.
Robustness to noise and temporal resolution downsampling is empirically
demonstrated.
"
1146,"Universal software platform for visualizing class F curves,
  log-aesthetic curves and development of applied CAD systems","  This article describes the capabilities of a universal software platform for
visualizing class F curves and developing specialized applications for CAD
systems based on Microsoft Excel VBA, the software complex FairCurveModeler,
and computer algebra systems. Additionally, it demonstrates the use of a
software platform for visualizing functional and log-aesthetic curves
integrated with CAD Fusion360. The value of the curves is evident in
visualizing the qualitative geometry of the product shape in industrial design.
Moreover, the requirements for the characteristics of class F curves are
emphasized to form a visual purity of shape in industrial design and to provide
a positive emotional perception of the visual image of the product by a person.
"
1147,Intelligent Middle-Level Game Control,"  We propose the concept of intelligent middle-level game control, which lies
on a continuum of control abstraction levels between the following two dual
opposites: 1) high-level control that translates player's simple commands into
complex actions (such as pressing Space key for jumping), and 2) low-level
control which simulates real-life complexities by directly manipulating, e.g.,
joint rotations of the character as it is done in the runner game QWOP. We
posit that various novel control abstractions can be explored using recent
advances in movement intelligence of game characters. We demonstrate this
through design and evaluation of a novel 2-player martial arts game prototype.
In this game, each player guides a simulated humanoid character by clicking and
dragging body parts. This defines the cost function for an online continuous
control algorithm that executes the requested movement. Our control algorithm
uses Covariance Matrix Adaptation Evolution Strategy (CMA-ES) in a rolling
horizon manner with custom population seeding techniques. Our playtesting data
indicates that intelligent middle-level control results in producing novel and
innovative gameplay without frustrating interface complexities.
"
1148,Video-to-Video Synthesis,"  We study the problem of video-to-video synthesis, whose goal is to learn a
mapping function from an input source video (e.g., a sequence of semantic
segmentation masks) to an output photorealistic video that precisely depicts
the content of the source video. While its image counterpart, the
image-to-image synthesis problem, is a popular topic, the video-to-video
synthesis problem is less explored in the literature. Without understanding
temporal dynamics, directly applying existing image synthesis approaches to an
input video often results in temporally incoherent videos of low visual
quality. In this paper, we propose a novel video-to-video synthesis approach
under the generative adversarial learning framework. Through carefully-designed
generator and discriminator architectures, coupled with a spatio-temporal
adversarial objective, we achieve high-resolution, photorealistic, temporally
coherent video results on a diverse set of input formats including segmentation
masks, sketches, and poses. Experiments on multiple benchmarks show the
advantage of our method compared to strong baselines. In particular, our model
is capable of synthesizing 2K resolution videos of street scenes up to 30
seconds long, which significantly advances the state-of-the-art of video
synthesis. Finally, we apply our approach to future video prediction,
outperforming several state-of-the-art competing systems.
"
1149,"VERAM: View-Enhanced Recurrent Attention Model for 3D Shape
  Classification","  Multi-view deep neural network is perhaps the most successful approach in 3D
shape classification. However, the fusion of multi-view features based on max
or average pooling lacks a view selection mechanism, limiting its application
in, e.g., multi-view active object recognition by a robot. This paper presents
VERAM, a recurrent attention model capable of actively selecting a sequence of
views for highly accurate 3D shape classification. VERAM addresses an important
issue commonly found in existing attention-based models, i.e., the unbalanced
training of the subnetworks corresponding to next view estimation and shape
classification. The classification subnetwork is easily overfitted while the
view estimation one is usually poorly trained, leading to a suboptimal
classification performance. This is surmounted by three essential
view-enhancement strategies: 1) enhancing the information flow of gradient
backpropagation for the view estimation subnetwork, 2) devising a highly
informative reward function for the reinforcement training of view estimation
and 3) formulating a novel loss function that explicitly circumvents view
duplication. Taking grayscale image as input and AlexNet as CNN architecture,
VERAM with 9 views achieves instance-level and class-level accuracy of 95:5%
and 95:3% on ModelNet10, 93:7% and 92:1% on ModelNet40, both are the
state-of-the-art performance under the same number of views.
"
1150,Image-based remapping of spatially-varying material appearance,"  BRDF models are ubiquitous tools for the representation of material
appearance. However, there is now an astonishingly large number of different
models in practical use. Both a lack of BRDF model standardisation across
implementations found in different renderers, as well as the often semantically
different capabilities of various models, have grown to be a major hindrance to
the interchange of production assets between different rendering systems.
Current attempts to solve this problem rely on manually finding visual
similarities between models, or mathematical ones between their functional
shapes, which requires access to the shader implementation, usually unavailable
in commercial renderers. We present a method for automatic translation of
material appearance between different BRDF models, which uses an image-based
metric for appearance comparison, and that delegates the interaction with the
model to the renderer. We analyse the performance of the method, both with
respect to robustness and visual differences of the fits for multiple
combinations of BRDF models. While it is effective for individual BRDFs, the
computational cost does not scale well for spatially-varying BRDFs. Therefore,
we further present a parametric regression scheme that approximates the shape
of the transformation function and generates a reduced representation which
evaluates instantly and without further interaction with the renderer. We
present respective visual comparisons of the remapped SVBRDF models for
commonly used renderers and shading models, and show that our approach is able
to extrapolate transformed BRDF parameters better than other complex regression
schemes.
"
1151,Deep Video-Based Performance Cloning,"  We present a new video-based performance cloning technique. After training a
deep generative network using a reference video capturing the appearance and
dynamics of a target actor, we are able to generate videos where this actor
reenacts other performances. All of the training data and the driving
performances are provided as ordinary video segments, without motion capture or
depth information. Our generative model is realized as a deep neural network
with two branches, both of which train the same space-time conditional
generator, using shared weights. One branch, responsible for learning to
generate the appearance of the target actor in various poses, uses
\emph{paired} training data, self-generated from the reference video. The
second branch uses unpaired data to improve generation of temporally coherent
video renditions of unseen pose sequences. We demonstrate a variety of
promising results, where our method is able to generate temporally coherent
videos, for challenging scenarios where the reference and driving videos
consist of very different dance performances. Supplementary video:
https://youtu.be/JpwsEeqNhhA.
"
1152,The Turtleback Diagram for Conditional Probability,"  We elaborate on an alternative representation of conditional probability to
the usual tree diagram. We term the representation `turtleback diagram' for its
resemblance to the pattern on turtle shells. Adopting the set theoretic view of
events and the sample space, the turtleback diagram uses elements from Venn
diagrams---set intersection, complement and partition---for conditioning, with
the additional notion that the area of a set indicates probability whereas the
ratio of areas for conditional probability. Once parts of the diagram are drawn
and properly labeled, the calculation of conditional probability involves only
simple arithmetic on the area of relevant sets. We discuss turtleback diagrams
in relation to other visual representations of conditional probability, and
detail several scenarios in which turtleback diagrams prove useful. By the
equivalence of recursive space partition and the tree, the turtleback diagram
is seen to be equally expressive as the tree diagram for representing abstract
concepts. We also provide empirical data on the use of turtleback diagrams with
undergraduate students in elementary statistics or probability courses.
"
1153,Everybody Dance Now,"  This paper presents a simple method for ""do as I do"" motion transfer: given a
source video of a person dancing, we can transfer that performance to a novel
(amateur) target after only a few minutes of the target subject performing
standard moves. We approach this problem as video-to-video translation using
pose as an intermediate representation. To transfer the motion, we extract
poses from the source subject and apply the learned pose-to-appearance mapping
to generate the target subject. We predict two consecutive frames for
temporally coherent video results and introduce a separate pipeline for
realistic face synthesis. Although our method is quite simple, it produces
surprisingly compelling results (see video). This motivates us to also provide
a forensics tool for reliable synthetic content detection, which is able to
distinguish videos synthesized by our system from real data. In addition, we
release a first-of-its-kind open-source dataset of videos that can be legally
used for training and motion transfer.
"
1154,"Optimizing B-spline surfaces for developability and paneling
  architectural freeform surfaces","  Motivated by applications in architecture and design, we present a novel
method for increasing the developability of a B-spline surface. We use the
property that the Gauss image of a developable surface is 1-dimensional and can
be locally well approximated by circles. This is cast into an algorithm for
thinning the Gauss image by increasing the planarity of the Gauss images of
appropriate neighborhoods. A variation of the main method allows us to tackle
the problem of paneling a freeform architectural surface with developable
panels, in particular enforcing rotational cylindrical, rotational conical and
planar panels, which are the main preferred types of developable panels in
architecture due to the reduced cost of manufacturing.
"
1155,Deep Portrait Image Completion and Extrapolation,"  General image completion and extrapolation methods often fail on portrait
images where parts of the human body need to be recovered - a task that
requires accurate human body structure and appearance synthesis. We present a
two-stage deep learning framework for tacking this problem. In the first stage,
given a portrait image with an incomplete human body, we extract a complete,
coherent human body structure through a human parsing network, which focuses on
structure recovery inside the unknown region with the help of pose estimation.
In the second stage, we use an image completion network to fill the unknown
region, guided by the structure map recovered in the first stage. For realistic
synthesis the completion network is trained with both perceptual loss and
conditional adversarial loss. We evaluate our method on public portrait image
datasets, and show that it outperforms other state-of-art general image
completion methods. Our method enables new portrait image editing applications
such as occlusion removal and portrait extrapolation. We further show that the
proposed general learning framework can be applied to other types of images,
e.g. animal images.
"
1156,"StretchDenoise: Parametric Curve Reconstruction with Guarantees by
  Separating Connectivity from Residual Uncertainty of Samples","  We reconstruct a closed denoised curve from an unstructured and highly noisy
2D point cloud. Our proposed method uses a two- pass approach: Previously
recovered manifold connectivity is used for ordering noisy samples along this
manifold and express these as residuals in order to enable parametric
denoising. This separates recovering low-frequency features from denoising high
frequencies, which avoids over-smoothing. The noise probability density
functions (PDFs) at samples are either taken from sensor noise models or from
estimates of the connectivity recovered in the first pass. The output curve
balances the signed distances (inside/outside) to the samples. Additionally,
the angles between edges of the polygon representing the connectivity become
minimized in the least-square sense. The movement of the polygon's vertices is
restricted to their noise extent, i.e., a cut-off distance corresponding to a
maximum variance of the PDFs. We approximate the resulting optimization model,
which consists of higher-order functions, by a linear model with good
correspondence. Our algorithm is parameter-free and operates fast on the local
neighborhoods determined by the connectivity. We augment a least-squares solver
constrained by a linear system to also handle bounds. This enables us to
guarantee stochastic error bounds for sampled curves corrupted by noise, e.g.,
silhouettes from sensed data, and we improve on the reconstruction error from
ground truth. Open source to reproduce figures and tables in this paper is
available at: https://github.com/stefango74/stretchdenoise
"
1157,Learning to Importance Sample in Primary Sample Space,"  Importance sampling is one of the most widely used variance reduction
strategies in Monte Carlo rendering. In this paper, we propose a novel
importance sampling technique that uses a neural network to learn how to sample
from a desired density represented by a set of samples. Our approach considers
an existing Monte Carlo rendering algorithm as a black box. During a
scene-dependent training phase, we learn to generate samples with a desired
density in the primary sample space of the rendering algorithm using maximum
likelihood estimation. We leverage a recent neural network architecture that
was designed to represent real-valued non-volume preserving ('Real NVP')
transformations in high dimensional spaces. We use Real NVP to non-linearly
warp primary sample space and obtain desired densities. In addition, Real NVP
efficiently computes the determinant of the Jacobian of the warp, which is
required to implement the change of integration variables implied by the warp.
A main advantage of our approach is that it is agnostic of underlying light
transport effects, and can be combined with many existing rendering techniques
by treating them as a black box. We show that our approach leads to effective
variance reduction in several practical scenarios.
"
1158,Wide Activation for Efficient and Accurate Image Super-Resolution,"  In this report we demonstrate that with same parameters and computational
budgets, models with wider features before ReLU activation have significantly
better performance for single image super-resolution (SISR). The resulted SR
residual network has a slim identity mapping pathway with wider (\(2\times\) to
\(4\times\)) channels before activation in each residual block. To further
widen activation (\(6\times\) to \(9\times\)) without computational overhead,
we introduce linear low-rank convolution into SR networks and achieve even
better accuracy-efficiency tradeoffs. In addition, compared with batch
normalization or no normalization, we find training with weight normalization
leads to better accuracy for deep super-resolution networks. Our proposed SR
network \textit{WDSR} achieves better results on large-scale DIV2K image
super-resolution benchmark in terms of PSNR with same or lower computational
complexity. Based on WDSR, our method also won 1st places in NTIRE 2018
Challenge on Single Image Super-Resolution in all three realistic tracks.
Experiments and ablation studies support the importance of wide activation for
image super-resolution. Code is released at:
https://github.com/JiahuiYu/wdsr_ntire2018
"
1159,3D-Aware Scene Manipulation via Inverse Graphics,"  We aim to obtain an interpretable, expressive, and disentangled scene
representation that contains comprehensive structural and textural information
for each object. Previous scene representations learned by neural networks are
often uninterpretable, limited to a single object, or lacking 3D knowledge. In
this work, we propose 3D scene de-rendering networks (3D-SDN) to address the
above issues by integrating disentangled representations for semantics,
geometry, and appearance into a deep generative model. Our scene encoder
performs inverse graphics, translating a scene into a structured object-wise
representation. Our decoder has two components: a differentiable shape renderer
and a neural texture generator. The disentanglement of semantics, geometry, and
appearance supports 3D-aware scene manipulation, e.g., rotating and moving
objects freely while keeping the consistent shape and texture, and changing the
object appearance without affecting its shape. Experiments demonstrate that our
editing scheme based on 3D-SDN is superior to its 2D counterpart.
"
1160,Differential and integral invariants under Mobius transformation,"  One of the most challenging problems in the domain of 2-D image or 3-D shape
is to handle the non-rigid deformation. From the perspective of transformation
groups, the conformal transformation is a key part of the diffeomorphism.
According to the Liouville Theorem, an important part of the conformal
transformation is the Mobius transformation, so we focus on Mobius
transformation and propose two differential expressions that are invariable
under 2-D and 3-D Mobius transformation respectively. Next, we analyze the
absoluteness and relativity of invariance on them and their components. After
that, we propose integral invariants under Mobius transformation based on the
two differential expressions. Finally, we propose a conjecture about the
structure of differential invariants under conformal transformation according
to our observation on the composition of the above two differential invariants.
"
1161,Gibson Env: Real-World Perception for Embodied Agents,"  Developing visual perception models for active agents and sensorimotor
control are cumbersome to be done in the physical world, as existing algorithms
are too slow to efficiently learn in real-time and robots are fragile and
costly. This has given rise to learning-in-simulation which consequently casts
a question on whether the results transfer to real-world. In this paper, we are
concerned with the problem of developing real-world perception for active
agents, propose Gibson Virtual Environment for this purpose, and showcase
sample perceptual tasks learned therein. Gibson is based on virtualizing real
spaces, rather than using artificially designed ones, and currently includes
over 1400 floor spaces from 572 full buildings. The main characteristics of
Gibson are: I. being from the real-world and reflecting its semantic
complexity, II. having an internal synthesis mechanism, ""Goggles"", enabling
deploying the trained models in real-world without needing further domain
adaptation, III. embodiment of agents and making them subject to constraints of
physics and space.
"
1162,"Modeling Surface Appearance from a Single Photograph using
  Self-augmented Convolutional Neural Networks","  We present a convolutional neural network (CNN) based solution for modeling
physically plausible spatially varying surface reflectance functions (SVBRDF)
from a single photograph of a planar material sample under unknown natural
illumination. Gathering a sufficiently large set of labeled training pairs
consisting of photographs of SVBRDF samples and corresponding reflectance
parameters, is a difficult and arduous process. To reduce the amount of
required labeled training data, we propose to leverage the appearance
information embedded in unlabeled images of spatially varying materials to
self-augment the training process. Starting from an initial approximative
network obtained from a small set of labeled training pairs, we estimate
provisional model parameters for each unlabeled training exemplar. Given this
provisional reflectance estimate, we then synthesize a novel temporary labeled
training pair by rendering the exact corresponding image under a new lighting
condition. After refining the network using these additional training samples,
we re-estimate the provisional model parameters for the unlabeled data and
repeat the self-augmentation process until convergence. We demonstrate the
efficacy of the proposed network structure on spatially varying wood, metals,
and plastics, as well as thoroughly validate the effectiveness of the
self-augmentation training process.
"
1163,Distributed-Memory Forest-of-Octrees Raycasting,"  We present an MPI-parallel algorithm for the in-situ visualization of
computational data that is built around a distributed linear forest-of-octrees
data structure. Such octrees are frequently used in element-based numerical
simulations; they store the leaves of the tree that are local in the curent
parallel partition.
  We proceed in three stages. First, we prune all elements whose bounding box
is not visible by a parallel top-down traversal, and repartition the remaining
ones for load-balancing. Second, we intersect each element with every ray
passing its box to derive color and opacity values for the ray segment. To
reduce data, we aggregate the segments up the octree in a strictly distributed
fashion in cycles of coarsening and repartition. Third, we composite all
remaining ray segments to a tiled partition of the image and write it to disk
using parallel I/O.
  The scalability of the method derives from three concepts: By exploiting the
space filling curve encoding of the octrees and by relying on recently
developed tree algorithms for top-down partition traversal, we are able to
determine sender/receiver pairs without handshaking and/or collective
communication. Furthermore, by partnering the linear traversal of tree leaves
with the group action of the attenuation/emission ODE along each segment, we
avoid back-to-front sorting of elements throughout. Lastly, the method is
problem adaptive with respect to the refinement and partition of the elements
and to the accuracy of ODE integration.
"
1164,Semantic Human Matting,"  Human matting, high quality extraction of humans from natural images, is
crucial for a wide variety of applications. Since the matting problem is
severely under-constrained, most previous methods require user interactions to
take user designated trimaps or scribbles as constraints. This user-in-the-loop
nature makes them difficult to be applied to large scale data or time-sensitive
scenarios. In this paper, instead of using explicit user input constraints, we
employ implicit semantic constraints learned from data and propose an automatic
human matting algorithm (SHM). SHM is the first algorithm that learns to
jointly fit both semantic information and high quality details with deep
networks. In practice, simultaneously learning both coarse semantics and fine
details is challenging. We propose a novel fusion strategy which naturally
gives a probabilistic estimation of the alpha matte. We also construct a very
large dataset with high quality annotations consisting of 35,513 unique
foregrounds to facilitate the learning and evaluation of human matting.
Extensive experiments on this dataset and plenty of real images show that SHM
achieves comparable results with state-of-the-art interactive matting methods.
"
1165,Chest X-ray Inpainting with Deep Generative Models,"  Generative adversarial networks have been successfully applied to inpainting
in natural images. However, the current state-of-the-art models have not yet
been widely adopted in the medical imaging domain. In this paper, we
investigate the performance of three recently published deep learning based
inpainting models: context encoders, semantic image inpainting, and the
contextual attention model, applied to chest x-rays, as the chest exam is the
most commonly performed radiological procedure. We train these generative
models on 1.2M 128 $\times$ 128 patches from 60K healthy x-rays, and learn to
predict the center 64 $\times$ 64 region in each patch. We test the models on
both the healthy and abnormal radiographs. We evaluate the results by visual
inspection and comparing the PSNR scores. The outputs of the models are in most
cases highly realistic. We show that the methods have potential to enhance and
detect abnormalities. In addition, we perform a 2AFC observer study and show
that an experienced human observer performs poorly in detecting inpainted
regions, particularly those generated by the contextual attention model.
"
1166,Extending Mandelbox Fractals with Shape Inversions,"  The Mandelbox is a recently discovered class of escape-time fractals which
use a conditional combination of reflection, spherical inversion, scaling, and
translation to transform points under iteration. In this paper we introduce a
new extension to Mandelbox fractals which replaces spherical inversion with a
more generalized shape inversion. We then explore how this technique can be
used to generate new fractals in 2D, 3D, and 4D.
"
1167,"Full-body High-resolution Anime Generation with Progressive
  Structure-conditional Generative Adversarial Networks","  We propose Progressive Structure-conditional Generative Adversarial Networks
(PSGAN), a new framework that can generate full-body and high-resolution
character images based on structural information. Recent progress in generative
adversarial networks with progressive training has made it possible to generate
high-resolution images. However, existing approaches have limitations in
achieving both high image quality and structural consistency at the same time.
Our method tackles the limitations by progressively increasing the resolution
of both generated images and structural conditions during training. In this
paper, we empirically demonstrate the effectiveness of this method by showing
the comparison with existing approaches and video generation results of diverse
anime characters at 1024x1024 based on target pose sequences. We also create a
novel dataset containing full-body 1024x1024 high-resolution images and exact
2D pose keypoints using Unity 3D Avatar models.
"
1168,Surface Light Field Fusion,"  We present an approach for interactively scanning highly reflective objects
with a commodity RGBD sensor. In addition to shape, our approach models the
surface light field, encoding scene appearance from all directions. By
factoring the surface light field into view-independent and
wavelength-independent components, we arrive at a representation that can be
robustly estimated with IR-equipped commodity depth sensors, and achieves high
quality results.
"
1169,A Deeper Look at 3D Shape Classifiers,"  We investigate the role of representations and architectures for classifying
3D shapes in terms of their computational efficiency, generalization, and
robustness to adversarial transformations. By varying the number of training
examples and employing cross-modal transfer learning we study the role of
initialization of existing deep architectures for 3D shape classification. Our
analysis shows that multiview methods continue to offer the best generalization
even without pretraining on large labeled image datasets, and even when trained
on simplified inputs such as binary silhouettes. Furthermore, the performance
of voxel-based 3D convolutional networks and point-based architectures can be
improved via cross-modal transfer from image representations. Finally, we
analyze the robustness of 3D shape classifiers to adversarial transformations
and present a novel approach for generating adversarial perturbations of a 3D
shape for multiview classifiers using a differentiable renderer. We find that
point-based networks are more robust to point position perturbations while
voxel-based and multiview networks are easily fooled with the addition of
imperceptible noise to the input.
"
1170,Texturing and Deforming Meshes with Casual Images,"  Using (casual) images to texture 3D models is a common way to create
realistic 3D models, which is a very important task in computer graphics.
However, if the shape of the casual image does not look like the target model
or the target mapping area, the textured model will become strange since the
image will be distorted very much. In this paper, we present a novel texturing
and deforming approach for mapping the pattern and shape of a casual image to a
3D model at the same time based on an alternating least-square approach.
Through a photogrammetric method, we project the target model onto the source
image according to the estimated camera model. Then, the target model is
deformed according to the shape of the source image using a surface-based
deformation method while minimizing the image distortion simultaneously. The
processes are performed iteratively until convergence. Hence, our method can
achieve texture mapping, shape deformation, and detail-preserving at once, and
can obtain more reasonable texture mapped results than traditional methods.
"
1171,"Visualization of High-dimensional Scalar Functions Using Principal
  Parameterizations","  Insightful visualization of multidimensional scalar fields, in particular
parameter spaces, is key to many fields in computational science and
engineering. We propose a principal component-based approach to visualize such
fields that accurately reflects their sensitivity to input parameters. The
method performs dimensionality reduction on the vast $L^2$ Hilbert space formed
by all possible partial functions (i.e., those defined by fixing one or more
input parameters to specific values), which are projected to low-dimensional
parameterized manifolds such as 3D curves, surfaces, and ensembles thereof. Our
mapping provides a direct geometrical and visual interpretation in terms of
Sobol's celebrated method for variance-based sensitivity analysis. We
furthermore contribute a practical realization of the proposed method by means
of tensor decomposition, which enables accurate yet interactive integration and
multilinear principal component analysis of high-dimensional models.
"
1172,Video to Fully Automatic 3D Hair Model,"  Imagine taking a selfie video with your mobile phone and getting as output a
3D model of your head (face and 3D hair strands) that can be later used in VR,
AR, and any other domain. State of the art hair reconstruction methods allow
either a single photo (thus compromising 3D quality) or multiple views, but
they require manual user interaction (manual hair segmentation and capture of
fixed camera views that span full 360 degree). In this paper, we describe a
system that can completely automatically create a reconstruction from any video
(even a selfie video), and we don't require specific views, since taking your
-90 degree, 90 degree, and full back views is not feasible in a selfie capture.
  In the core of our system, in addition to the automatization components, hair
strands are estimated and deformed in 3D (rather than 2D as in state of the
art) thus enabling superior results. We provide qualitative, quantitative, and
Mechanical Turk human studies that support the proposed system, and show
results on a diverse variety of videos (8 different celebrity videos, 9 selfie
mobile videos, spanning age, gender, hair length, type, and styling).
"
1173,Learning to Group and Label Fine-Grained Shape Components,"  A majority of stock 3D models in modern shape repositories are assembled with
many fine-grained components. The main cause of such data form is the
component-wise modeling process widely practiced by human modelers. These
modeling components thus inherently reflect some function-based shape
decomposition the artist had in mind during modeling. On the other hand,
modeling components represent an over-segmentation since a functional part is
usually modeled as a multi-component assembly. Based on these observations, we
advocate that labeled segmentation of stock 3D models should not overlook the
modeling components and propose a learning solution to grouping and labeling of
the fine-grained components. However, directly characterizing the shape of
individual components for the purpose of labeling is unreliable, since they can
be arbitrarily tiny and semantically meaningless. We propose to generate part
hypotheses from the components based on a hierarchical grouping strategy, and
perform labeling on those part groups instead of directly on the components.
Part hypotheses are mid-level elements which are more probable to carry
semantic information. A multiscale 3D convolutional neural network is trained
to extract context-aware features for the hypotheses. To accomplish a labeled
segmentation of the whole shape, we formulate higher-order conditional random
fields (CRFs) to infer an optimal label assignment for all components.
Extensive experiments demonstrate that our method achieves significantly robust
labeling results on raw 3D models from public shape repositories. Our work also
contributes the first benchmark for component-wise labeling.
"
1174,SCORES: Shape Composition with Recursive Substructure Priors,"  We introduce SCORES, a recursive neural network for shape composition. Our
network takes as input sets of parts from two or more source 3D shapes and a
rough initial placement of the parts. It outputs an optimized part structure
for the composed shape, leading to high-quality geometry construction. A unique
feature of our composition network is that it is not merely learning how to
connect parts. Our goal is to produce a coherent and plausible 3D shape,
despite large incompatibilities among the input parts. The network may
significantly alter the geometry and structure of the input parts and
synthesize a novel shape structure based on the inputs, while adding or
removing parts to minimize a structure plausibility loss. We design SCORES as a
recursive autoencoder network. During encoding, the input parts are recursively
grouped to generate a root code. During synthesis, the root code is decoded,
recursively, to produce a new, coherent part assembly. Assembled shape
structures may be novel, with little global resemblance to training exemplars,
yet have plausible substructures. SCORES therefore learns a hierarchical
substructure shape prior based on per-node losses. It is trained on structured
shapes from ShapeNet, and is applied iteratively to reduce the plausibility
loss.We showresults of shape composition from multiple sources over different
categories of man-made shapes and compare with state-of-the-art alternatives,
demonstrating that our network can significantly expand the range of composable
shapes for assembly-based modeling.
"
1175,MoSculp: Interactive Visualization of Shape and Time,"  We present a system that allows users to visualize complex human motion via
3D motion sculptures---a representation that conveys the 3D structure swept by
a human body as it moves through space. Given an input video, our system
computes the motion sculptures and provides a user interface for rendering it
in different styles, including the options to insert the sculpture back into
the original video, render it in a synthetic scene or physically print it.
  To provide this end-to-end workflow, we introduce an algorithm that estimates
that human's 3D geometry over time from a set of 2D images and develop a
3D-aware image-based rendering approach that embeds the sculpture back into the
scene. By automating the process, our system takes motion sculpture creation
out of the realm of professional artists, and makes it applicable to a wide
range of existing video material.
  By providing viewers with 3D information, motion sculptures reveal space-time
motion information that is difficult to perceive with the naked eye, and allow
viewers to interpret how different parts of the object interact over time. We
validate the effectiveness of this approach with user studies, finding that our
motion sculpture visualizations are significantly more informative about motion
than existing stroboscopic and space-time visualization methods.
"
1176,"A Reciprocal Formulation of Nonexponential Radiative Transfer. 2: Monte
  Carlo Estimation and Diffusion Approximation","  When lifting the assumption of spatially-independent scattering centers in
classical linear transport theory, collision rate is no longer proportional to
angular flux / radiance because the macroscopic cross-section $\Sigma_t(s)$
depends on the distance $s$ to the previous collision or boundary. We
generalize collision and track-length estimators to support unbiased estimation
of either flux integrals or collision rates in generalized radiative transfer
(GRT). To provide benchmark solutions for the Monte Carlo estimators, we derive
the four Green's functions for the isotropic point source in infinite media
with isotropic scattering. Additionally, new moment-preserving diffusion
approximations for these Green's functions are derived, which reduce to
algebraic expressions involving the first four moments of the free-path lengths
between collisions.
"
1177,MeshCNN: A Network with an Edge,"  Polygonal meshes provide an efficient representation for 3D shapes. They
explicitly capture both shape surface and topology, and leverage non-uniformity
to represent large flat regions as well as sharp, intricate features. This
non-uniformity and irregularity, however, inhibits mesh analysis efforts using
neural networks that combine convolution and pooling operations. In this paper,
we utilize the unique properties of the mesh for a direct analysis of 3D shapes
using MeshCNN, a convolutional neural network designed specifically for
triangular meshes. Analogous to classic CNNs, MeshCNN combines specialized
convolution and pooling layers that operate on the mesh edges, by leveraging
their intrinsic geodesic connections. Convolutions are applied on edges and the
four edges of their incident triangles, and pooling is applied via an edge
collapse operation that retains surface topology, thereby, generating new mesh
connectivity for the subsequent convolutions. MeshCNN learns which edges to
collapse, thus forming a task-driven process where the network exposes and
expands the important features while discarding the redundant ones. We
demonstrate the effectiveness of our task-driven pooling on various learning
tasks applied to 3D meshes.
"
1178,AlSub: Fully Parallel and Modular Subdivision,"  In recent years, mesh subdivision---the process of forging smooth free-form
surfaces from coarse polygonal meshes---has become an indispensable production
instrument. Although subdivision performance is crucial during simulation,
animation and rendering, state-of-the-art approaches still rely on serial
implementations for complex parts of the subdivision process. Therefore, they
often fail to harness the power of modern parallel devices, like the graphics
processing unit (GPU), for large parts of the algorithm and must resort to
time-consuming serial preprocessing. In this paper, we show that a complete
parallelization of the subdivision process for modern architectures is
possible. Building on sparse matrix linear algebra, we show how to structure
the complete subdivision process into a sequence of algebra operations. By
restructuring and grouping these operations, we adapt the process for different
use cases, such as regular subdivision of dynamic meshes, uniform subdivision
for immutable topology, and feature-adaptive subdivision for efficient
rendering of animated models. As the same machinery is used for all use cases,
identical subdivision results are achieved in all parts of the production
pipeline. As a second contribution, we show how these linear algebra
formulations can effectively be translated into efficient GPU kernels. Applying
our strategies to $\sqrt{3}$, Loop and Catmull-Clark subdivision shows
significant speedups of our approach compared to state-of-the-art solutions,
while we completely avoid serial preprocessing.
"
1179,"Novel Approach to Measure Motion-To-Photon and Mouth-To-Ear Latency in
  Distributed Virtual Reality Systems","  Distributed Virtual Reality systems enable globally dispersed users to
interact with each other in a shared virtual environment. In such systems,
different types of latencies occur. For a good VR experience, they need to be
controlled. The time delay between the user's head motion and the corresponding
display output of the VR system might lead to adverse effects such as a reduced
sense of presence or motion sickness. Additionally, high network latency among
worldwide locations makes collaboration between users more difficult and leads
to misunderstandings. To evaluate the performance and optimize dispersed VR
solutions it is therefore important to measure those delays. In this work, a
novel, easy to set up, and inexpensive method to measure local and remote
system latency will be described. The measuring setup consists of a
microcontroller, a microphone, a piezo buzzer, a photosensor, and a
potentiometer. With these components, it is possible to measure
motion-to-photon and mouth-to-ear latency of various VR systems. By using
GPS-receivers for timecode-synchronization it is also possible to obtain the
end-to-end delays between different worldwide locations. The described system
was used to measure local and remote latencies of two HMD based distributed VR
systems.
"
1180,"A Simple Approach to Intrinsic Correspondence Learning on Unstructured
  3D Meshes","  The question of representation of 3D geometry is of vital importance when it
comes to leveraging the recent advances in the field of machine learning for
geometry processing tasks. For common unstructured surface meshes
state-of-the-art methods rely on patch-based or mapping-based techniques that
introduce resampling operations in order to encode neighborhood information in
a structured and regular manner. We investigate whether such resampling can be
avoided, and propose a simple and direct encoding approach. It does not only
increase processing efficiency due to its simplicity - its direct nature also
avoids any loss in data fidelity. To evaluate the proposed method, we perform a
number of experiments in the challenging domain of intrinsic, non-rigid shape
correspondence estimation. In comparisons to current methods we observe that
our approach is able to achieve highly competitive results.
"
1181,"Testing SensoGraph, a geometric approach for fast sensory evaluation","  This paper introduces SensoGraph, a novel approach for fast sensory
evaluation using two-dimensional geometric techniques. In the tasting sessions,
the assessors follow their own criteria to place samples on a tablecloth,
according to the similarity between samples. In order to analyse the data
collected, first a geometric clustering is performed to each tablecloth,
extracting connections between the samples. Then, these connections are used to
construct a global similarity matrix. Finally, a graph drawing algorithm is
used to obtain a 2D consensus graphic, which reflects the global opinion of the
panel by (1) positioning closer those samples that have been globally perceived
as similar and (2) showing the strength of the connections between samples. The
proposal is validated by performing four tasting sessions, with three types of
panels tasting different wines, and by developing a new software to implement
the proposed techniques. The results obtained show that the graphics provide
similar positionings of the samples as the consensus maps obtained by multiple
factor analysis (MFA), further providing extra information about connections
between samples, not present in any previous method. The main conclusion is
that the use of geometric techniques provides information complementary to MFA,
and of a different type. Finally, the method proposed is computationally able
to manage a significantly larger number of assessors than MFA, which can be
useful for the comparison of pictures by a huge number of consumers, via the
Internet.
"
1182,Light Field Neural Network,"  We introduce an optical neural network system made by off-the-shelf
components. In order to test the evaluate the physical property of the proposed
system, we are making a prototype. After further discussions with our
cooperators, we are agreed that the prototype implementation may take longer
time than we expected earlier. Therefore we reach a consensus on withdrawing
the paper until the physical data is available.
"
1183,Deep Part Induction from Articulated Object Pairs,"  Object functionality is often expressed through part articulation -- as when
the two rigid parts of a scissor pivot against each other to perform the
cutting function. Such articulations are often similar across objects within
the same functional category. In this paper, we explore how the observation of
different articulation states provides evidence for part structure and motion
of 3D objects. Our method takes as input a pair of unsegmented shapes
representing two different articulation states of two functionally related
objects, and induces their common parts along with their underlying rigid
motion. This is a challenging setting, as we assume no prior shape structure,
no prior shape category information, no consistent shape orientation, the
articulation states may belong to objects of different geometry, plus we allow
inputs to be noisy and partial scans, or point clouds lifted from RGB images.
Our method learns a neural network architecture with three modules that
respectively propose correspondences, estimate 3D deformation flows, and
perform segmentation. To achieve optimal performance, our architecture
alternates between correspondence, deformation flow, and segmentation
prediction iteratively in an ICP-like fashion. Our results demonstrate that our
method significantly outperforms state-of-the-art techniques in the task of
discovering articulated parts of objects. In addition, our part induction is
object-class agnostic and successfully generalizes to new and unseen objects.
"
1184,Adaptive O-CNN: A Patch-based Deep Representation of 3D Shapes,"  We present an Adaptive Octree-based Convolutional Neural Network (Adaptive
O-CNN) for efficient 3D shape encoding and decoding. Different from
volumetric-based or octree-based CNN methods that represent a 3D shape with
voxels in the same resolution, our method represents a 3D shape adaptively with
octants at different levels and models the 3D shape within each octant with a
planar patch. Based on this adaptive patch-based representation, we propose an
Adaptive O-CNN encoder and decoder for encoding and decoding 3D shapes. The
Adaptive O-CNN encoder takes the planar patch normal and displacement as input
and performs 3D convolutions only at the octants at each level, while the
Adaptive O-CNN decoder infers the shape occupancy and subdivision status of
octants at each level and estimates the best plane normal and displacement for
each leaf octant. As a general framework for 3D shape analysis and generation,
the Adaptive O-CNN not only reduces the memory and computational cost, but also
offers better shape generation capability than the existing 3D-CNN approaches.
We validate Adaptive O-CNN in terms of efficiency and effectiveness on
different shape analysis and generation tasks, including shape classification,
3D autoencoding, shape prediction from a single image, and shape completion for
noisy and incomplete point clouds.
"
1185,Non-Line-of-Sight Reconstruction using Efficient Transient Rendering,"  Being able to see beyond the direct line of sight is an intriguing
prospective and could benefit a wide variety of important applications. Recent
work has demonstrated that time-resolved measurements of indirect diffuse light
contain valuable information for reconstructing shape and reflectance
properties of objects located around a corner. In this paper, we introduce a
novel reconstruction scheme that, by design, produces solutions that are
consistent with state-of-the-art physically-based rendering. Our method
combines an efficient forward model (a custom renderer for time-resolved
three-bounce indirect light transport) with an optimization framework to
reconstruct object geometry in an analysis-by-synthesis sense. We evaluate our
algorithm on a variety of synthetic and experimental input data, and show that
it gracefully handles uncooperative scenes with high levels of noise or
non-diffuse material reflectance.
"
1186,"SPOT: Open Source framework for scientific data repository and
  interactive visualization","  SPOT is an open source and free visual data analytics tool for
multi-dimensional data-sets. Its web-based interface allows a quick analysis of
complex data interactively. The operations on data such as aggregation and
filtering are implemented. The generated charts are responsive and OpenGL
supported. It follows FAIR principles to allow reuse and comparison of the
published data-sets. The software also support PostgreSQL database for
scalability.
"
1187,Next Generation of Star Patterns,"  In this paper we present two new ideas for generating star patterns and
filling the gaps during the tile operation. Firstly, we introduce a novel
parametric method based on concentric circles for generating stars and
rosettes. Using proposed method, completely different stars and rosettes and a
set of new and complex star patterns convert to each other only by changing
nine parameters. Secondly, we demonstrate how three equal tangent circles can
be used as a base for generating tile elements. For this reason a surrounded
circle is created among tangent circles, which represents the gaps in hexagonal
packing. Afterwards, we use our first idea for filling the tangent circles and
surrounded circle. This parametric approach can be used for generating infinite
new star patterns, which some of them will be presented in result section.Two
Android apps of proposed method called Starking and Tilerking are available in
Google app store.
"
1188,PhotoShape: Photorealistic Materials for Large-Scale Shape Collections,"  Existing online 3D shape repositories contain thousands of 3D models but lack
photorealistic appearance. We present an approach to automatically assign
high-quality, realistic appearance models to large scale 3D shape collections.
The key idea is to jointly leverage three types of online data -- shape
collections, material collections, and photo collections, using the photos as
reference to guide assignment of materials to shapes. By generating a large
number of synthetic renderings, we train a convolutional neural network to
classify materials in real photos, and employ 3D-2D alignment techniques to
transfer materials to different parts of each shape model. Our system produces
photorealistic, relightable, 3D shapes (PhotoShapes).
"
1189,3D Face Synthesis Driven by Personality Impression,"  Synthesizing 3D faces that give certain personality impressions is commonly
needed in computer games, animations, and virtual world applications for
producing realistic virtual characters. In this paper, we propose a novel
approach to synthesize 3D faces based on personality impression for creating
virtual characters. Our approach consists of two major steps. In the first
step, we train classifiers using deep convolutional neural networks on a
dataset of images with personality impression annotations, which are capable of
predicting the personality impression of a face. In the second step, given a 3D
face and a desired personality impression type as user inputs, our approach
optimizes the facial details against the trained classifiers, so as to
synthesize a face which gives the desired personality impression. We
demonstrate our approach for synthesizing 3D faces giving desired personality
impressions on a variety of 3D face models. Perceptual studies show that the
perceived personality impressions of the synthesized faces agree with the
target personality impressions specified for synthesizing the faces. Please
refer to the supplementary materials for all results.
"
1190,Fast and Scalable Position-Based Layout Synthesis,"  The arrangement of objects into a layout can be challenging for non-experts,
as is affirmed by the existence of interior design professionals. Recent
research into the automation of this task has yielded methods that can
synthesize layouts of objects respecting aesthetic and functional constraints
that are non-linear and competing. These methods usually adopt a stochastic
optimization scheme, which samples from different layout configurations, a
process that is slow and inefficient. We introduce an physics-motivated,
continuous layout synthesis technique, which results in a significant gain in
speed and is readily scalable. We demonstrate our method on a variety of
examples and show that it achieves results similar to conventional layout
synthesis based on Markov chain Monte Carlo (McMC) state-search, but is faster
by at least an order of magnitude and can handle layouts of unprecedented size
as well as tightly-packed layouts that can overwhelm McMC.
"
1191,Functional Maps Representation on Product Manifolds,"  We consider the tasks of representing, analyzing and manipulating maps
between shapes. We model maps as densities over the product manifold of the
input shapes; these densities can be treated as scalar functions and therefore
are manipulable using the language of signal processing on manifolds. Being a
manifold itself, the product space endows the set of maps with a geometry of
its own, which we exploit to define map operations in the spectral domain; we
also derive relationships with other existing representations (soft maps and
functional maps). To apply these ideas in practice, we discretize product
manifolds and their Laplace--Beltrami operators, and we introduce localized
spectral analysis of the product manifold as a novel tool for map processing.
Our framework applies to maps defined between and across 2D and 3D shapes
without requiring special adjustment, and it can be implemented efficiently
with simple operations on sparse matrices.
"
1192,"An inverse scattering approach for geometric body generation: a machine
  learning perspective","  In this paper, we are concerned with the 2D and 3D geometric shape generation
by prescribing a set of characteristic values of a specific geometric body. One
of the major motivations of our study is the 3D human body generation in
various applications. We develop a novel method that can generate the desired
body with customized characteristic values. The proposed method follows a
machine-learning flavour that generates the inferred geometric body with the
input characteristic parameters from a training dataset. One of the critical
ingredients and novelties of our method is the borrowing of inverse scattering
techniques in the theory of wave propagation to the body generation. This is
done by establishing a delicate one-to-one correspondence between a geometric
body and the far-field pattern of a source scattering problem governed by the
Helmholtz system. It in turn enables us to establish a one-to-one
correspondence between the geometric body space and the function space defined
by the far-field patterns. Hence, the far-field patterns can act as the shape
generators. The shape generation with prescribed characteristic parameters is
achieved by first manipulating the shape generators and then reconstructing the
corresponding geometric body from the obtained shape generator by a stable
multiple-frequency Fourier method. Our method is easy to implement and produces
more efficient and stable body generations. We provide both theoretical
analysis and extensive numerical experiments for the proposed method. The study
is the first attempt to introduce inverse scattering approaches in combination
with machine learning to the geometric body generation and it opens up many
opportunities for further developments.
"
1193,Data-Driven Modeling of Group Entitativity in Virtual Environments,"  We present a data-driven algorithm to model and predict the socio-emotional
impact of groups on observers. Psychological research finds that highly
entitative i.e. cohesive and uniform groups induce threat and unease in
observers. Our algorithm models realistic trajectory-level behaviors to
classify and map the motion-based entitativity of crowds. This mapping is based
on a statistical scheme that dynamically learns pedestrian behavior and
computes the resultant entitativity induced emotion through group motion
characteristics. We also present a novel interactive multi-agent simulation
algorithm to model entitative groups and conduct a VR user study to validate
the socio-emotional predictive power of our algorithm. We further show that
model-generated high-entitativity groups do induce more negative emotions than
low-entitative groups.
"
1194,Superimposition-guided Facial Reconstruction from Skull,"  We develop a new algorithm to perform facial reconstruction from a given
skull. This technique has forensic application in helping the identification of
skeletal remains when other information is unavailable. Unlike most existing
strategies that directly reconstruct the face from the skull, we utilize a
database of portrait photos to create many face candidates, then perform a
superimposition to get a well matched face, and then revise it according to the
superimposition. To support this pipeline, we build an effective autoencoder
for image-based facial reconstruction, and a generative model for constrained
face inpainting. Our experiments have demonstrated that the proposed pipeline
is stable and accurate.
"
1195,Designing Volumetric Truss Structures,"  We present the first algorithm for designing volumetric Michell Trusses. Our
method uses a parametrization approach to generate trusses made of structural
elements aligned with the primary direction of an object's stress field. Such
trusses exhibit high strength-to-weight ratios. We demonstrate the structural
robustness of our designs via a posteriori physical simulation. We believe our
algorithm serves as an important complement to existing structural optimization
tools and as a novel standalone design tool itself.
"
1196,"ChainQueen: A Real-Time Differentiable Physical Simulator for Soft
  Robotics","  Physical simulators have been widely used in robot planning and control.
Among them, differentiable simulators are particularly favored, as they can be
incorporated into gradient-based optimization algorithms that are efficient in
solving inverse problems such as optimal control and motion planning.
Simulating deformable objects is, however, more challenging compared to rigid
body dynamics. The underlying physical laws of deformable objects are more
complex, and the resulting systems have orders of magnitude more degrees of
freedom and therefore they are significantly more computationally expensive to
simulate. Computing gradients with respect to physical design or controller
parameters is typically even more computationally challenging. In this paper,
we propose a real-time, differentiable hybrid Lagrangian-Eulerian physical
simulator for deformable objects, ChainQueen, based on the Moving Least Squares
Material Point Method (MLS-MPM). MLS-MPM can simulate deformable objects
including contact and can be seamlessly incorporated into inference, control
and co-design systems. We demonstrate that our simulator achieves high
precision in both forward simulation and backward gradient computation. We have
successfully employed it in a diverse set of control tasks for soft robots,
including problems with nearly 3,000 decision variables.
"
1197,Line Drawings from 3D Models,"  This tutorial describes the geometry and algorithms for generating line
drawings from 3D models, focusing on occluding contours.
  The geometry of occluding contours on meshes and on smooth surfaces is
described in detail, together with algorithms for extracting contours,
computing their visibility, and creating stylized renderings and animations.
Exact methods and hardware-accelerated fast methods are both described, and the
trade-offs between different methods are discussed. The tutorial brings
together and organizes material that, at present, is scattered throughout the
literature. It also includes some novel explanations, and implementation tips.
  A thorough survey of the field of non-photorealistic 3D rendering is also
included, covering other kinds of line drawings and artistic shading.
"
1198,Super-Resolution via Conditional Implicit Maximum Likelihood Estimation,"  Single-image super-resolution (SISR) is a canonical problem with diverse
applications. Leading methods like SRGAN produce images that contain various
artifacts, such as high-frequency noise, hallucinated colours and shape
distortions, which adversely affect the realism of the result. In this paper,
we propose an alternative approach based on an extension of the method of
Implicit Maximum Likelihood Estimation (IMLE). We demonstrate greater
effectiveness at noise reduction and preservation of the original colours and
shapes, yielding more realistic super-resolved images.
"
1199,Deep Fundamental Matrix Estimation without Correspondences,"  Estimating fundamental matrices is a classic problem in computer vision.
Traditional methods rely heavily on the correctness of estimated key-point
correspondences, which can be noisy and unreliable. As a result, it is
difficult for these methods to handle image pairs with large occlusion or
significantly different camera poses. In this paper, we propose novel neural
network architectures to estimate fundamental matrices in an end-to-end manner
without relying on point correspondences. New modules and layers are introduced
in order to preserve mathematical properties of the fundamental matrix as a
homogeneous rank-2 matrix with seven degrees of freedom. We analyze performance
of the proposed models using various metrics on the KITTI dataset, and show
that they achieve competitive performance with traditional methods without the
need for extracting correspondences.
"
1200,"Learning Bidirectional LSTM Networks for Synthesizing 3D Mesh Animation
  Sequences","  In this paper, we present a novel method for learning to synthesize 3D mesh
animation sequences with long short-term memory (LSTM) blocks and mesh-based
convolutional neural networks (CNNs). Synthesizing realistic 3D mesh animation
sequences is a challenging and important task in computer animation. To achieve
this, researchers have long been focusing on shape analysis to develop new
interpolation and extrapolation techniques. However, such techniques have
limited learning capabilities and therefore can produce unrealistic animation.
Deep architectures that operate directly on mesh sequences remain unexplored,
due to the following major barriers: meshes with irregular triangles, sequences
containing rich temporal information and flexible deformations. To address
these, we utilize convolutional neural networks defined on triangular meshes
along with a shape deformation representation to extract useful features,
followed by LSTM cells that iteratively process the features. To allow
completion of a missing mesh sequence from given endpoints, we propose a new
weight-shared bidirectional structure. The bidirectional generation loss also
helps mitigate error accumulation over iterations. Benefiting from all these
technical advances, our approach outperforms existing methods in sequence
prediction and completion both qualitatively and quantitatively. Moreover, this
network can also generate follow-up frames conditioned on initial shapes and
improve the accuracy as more bootstrap models are provided, which other works
in the geometry processing domain cannot achieve.
"
1201,Multi-directional Geodesic Neural Networks via Equivariant Convolution,"  We propose a novel approach for performing convolution of signals on curved
surfaces and show its utility in a variety of geometric deep learning
applications. Key to our construction is the notion of directional functions
defined on the surface, which extend the classic real-valued signals and which
can be naturally convolved with with real-valued template functions. As a
result, rather than trying to fix a canonical orientation or only keeping the
maximal response across all alignments of a 2D template at every point of the
surface, as done in previous works, we show how information across all
rotations can be kept across different layers of the neural network. Our
construction, which we call multi-directional geodesic convolution, or
directional convolution for short, allows, in particular, to propagate and
relate directional information across layers and thus different regions on the
shape. We first define directional convolution in the continuous setting, prove
its key properties and then show how it can be implemented in practice, for
shapes represented as triangle meshes. We evaluate directional convolution in a
wide variety of learning scenarios ranging from classification of signals on
surfaces, to shape segmentation and shape matching, where we show a significant
improvement over several baselines.
"
1202,Recurrent Transition Networks for Character Locomotion,"  Manually authoring transition animations for a complete locomotion system can
be a tedious and time-consuming task, especially for large games that allow
complex and constrained locomotion movements, where the number of transitions
grows exponentially with the number of states. In this paper, we present a
novel approach, based on deep recurrent neural networks, to automatically
generate such transitions given a past context of a few frames and a target
character state to reach. We present the Recurrent Transition Network (RTN),
based on a modified version of the Long-Short-Term-Memory (LSTM) network,
designed specifically for transition generation and trained without any gait,
phase, contact or action labels. We further propose a simple yet principled way
to initialize the hidden states of the LSTM layer for a given sequence which
improves the performance and generalization to new motions. We both
quantitatively and qualitatively evaluate our system and show that making the
network terrain-aware by adding a local terrain representation to the input
yields better performance for rough-terrain navigation on long transitions. Our
system produces realistic and fluid transitions that rival the quality of
Motion Capture-based ground-truth motions, even before applying any
inverse-kinematics postprocess. Direct benefits of our approach could be to
accelerate the creation of transition variations for large coverage, or even to
entirely replace transition nodes in an animation graph. We further explore
applications of this model in a animation super-resolution setting where we
temporally decompress animations saved at 1 frame per second and show that the
network is able to reconstruct motions that are hard to distinguish from
un-compressed locomotion sequences.
"
1203,Seamless Parametrization with Arbitrarily Prescribed Cones,"  Seamless global parametrization of surfaces is a key operation in geometry
processing, e.g. for high-quality quad mesh generation. A common approach is to
prescribe the parametric domain structure, in particular the locations of
parametrization singularities (cones), and solve a non-convex optimization
problem minimizing a distortion measure, with local injectivity imposed through
either constraints or barrier terms. In both cases, an initial valid
parametrization is essential to serve as feasible starting point for obtaining
an optimized solution. While convexified versions of the constraints eliminate
this initialization requirement, they narrow the range of solutions, causing
some problem instances that actually do have a solution to become infeasible.
We demonstrate that for arbitrary given sets of topologically admissible
parametric cones with prescribed curvature, a global seamless parametrization
always exists (with the exception of one well-known case). Importantly, our
proof is constructive and directly leads to a general algorithm for computing
such parametrizations. Most distinctively, this algorithm is bootstrapped with
a convex optimization problem (solving for a conformal map), in tandem with a
simple linear equation system (determining a seamless modification of this
map). This initial map can then serve as valid starting point and be optimized
with respect to application specific distortion measures using existing
injectivity preserving methods.
"
1204,SFV: Reinforcement Learning of Physical Skills from Videos,"  Data-driven character animation based on motion capture can produce highly
naturalistic behaviors and, when combined with physics simulation, can provide
for natural procedural responses to physical perturbations, environmental
changes, and morphological discrepancies. Motion capture remains the most
popular source of motion data, but collecting mocap data typically requires
heavily instrumented environments and actors. In this paper, we propose a
method that enables physically simulated characters to learn skills from videos
(SFV). Our approach, based on deep pose estimation and deep reinforcement
learning, allows data-driven animation to leverage the abundance of publicly
available video clips from the web, such as those from YouTube. This has the
potential to enable fast and easy design of character controllers simply by
querying for video recordings of the desired behavior. The resulting
controllers are robust to perturbations, can be adapted to new settings, can
perform basic object interactions, and can be retargeted to new morphologies
via reinforcement learning. We further demonstrate that our method can predict
potential human motions from still images, by forward simulation of learned
controllers initialized from the observed pose. Our framework is able to learn
a broad range of dynamic skills, including locomotion, acrobatics, and martial
arts.
"
1205,"Deep Inertial Poser: Learning to Reconstruct Human Pose from Sparse
  Inertial Measurements in Real Time","  We demonstrate a novel deep neural network capable of reconstructing human
full body pose in real-time from 6 Inertial Measurement Units (IMUs) worn on
the user's body. In doing so, we address several difficult challenges. First,
the problem is severely under-constrained as multiple pose parameters produce
the same IMU orientations. Second, capturing IMU data in conjunction with
ground-truth poses is expensive and difficult to do in many target application
scenarios (e.g., outdoors). Third, modeling temporal dependencies through
non-linear optimization has proven effective in prior work but makes real-time
prediction infeasible. To address this important limitation, we learn the
temporal pose priors using deep learning. To learn from sufficient data, we
synthesize IMU data from motion capture datasets. A bi-directional RNN
architecture leverages past and future information that is available at
training time. At test time, we deploy the network in a sliding window fashion,
retaining real time capabilities. To evaluate our method, we recorded DIP-IMU,
a dataset consisting of $10$ subjects wearing 17 IMUs for validation in $64$
sequences with $330\,000$ time instants; this constitutes the largest IMU
dataset publicly available. We quantitatively evaluate our approach on multiple
datasets and show results from a real-time implementation. DIP-IMU and the code
are available for research purposes.
"
1206,Deep Surface Light Fields,"  A surface light field represents the radiance of rays originating from any
points on the surface in any directions. Traditional approaches require
ultra-dense sampling to ensure the rendering quality. In this paper, we present
a novel neural network based technique called deep surface light field or DSLF
to use only moderate sampling for high fidelity rendering. DSLF automatically
fills in the missing data by leveraging different sampling patterns across the
vertices and at the same time eliminates redundancies due to the network's
prediction capability. For real data, we address the image registration problem
as well as conduct texture-aware remeshing for aligning texture edges with
vertices to avoid blurring. Comprehensive experiments show that DSLF can
further achieve high data compression ratio while facilitating real-time
rendering on the GPU.
"
1207,Subdivision Directional Fields,"  We present a novel linear subdivision scheme for face-based tangent
directional fields on triangle meshes. Our subdivision scheme is based on a
novel coordinate-free representation of directional fields as halfedge-based
scalar quantities, bridging the finite-element representation with discrete
exterior calculus. By commuting with differential operators, our subdivision is
structure-preserving: it reproduces curl-free fields precisely, and reproduces
divergence-free fields in the weak sense. Moreover, our subdivision scheme
directly extends to directional fields with several vectors per face by working
on the branched covering space. Finally, we demonstrate how our scheme can be
applied to directional-field design, advection, and robust earth mover's
distance computation, for efficient and robust computation.
"
1208,"Reverse engineering of CAD models via clustering and approximate
  implicitization","  In applications like computer aided design, geometric models are often
represented numerically as polynomial splines or NURBS, even when they
originate from primitive geometry. For purposes such as redesign and
isogeometric analysis, it is of interest to extract information about the
underlying geometry through reverse engineering. In this work we develop a
novel method to determine these primitive shapes by combining clustering
analysis with approximate implicitization. The proposed method is automatic and
can recover algebraic hypersurfaces of any degree in any dimension. In exact
arithmetic, the algorithm returns exact results. All the required parameters,
such as the implicit degree of the patches and the number of clusters of the
model, are inferred using numerical approaches in order to obtain an algorithm
that requires as little manual input as possible. The effectiveness, efficiency
and robustness of the method are shown both in a theoretical analysis and in
numerical examples implemented in Python.
"
1209,"Measuring the Effects of Scalar and Spherical Colormaps on Ensembles of
  DMRI Tubes","  We report empirical study results on the color encoding of ensemble scalar
and orientation to visualize diffusion magnetic resonance imaging (DMRI) tubes.
The experiment tested six scalar colormaps for average fractional anisotropy
(FA) tasks (grayscale, blackbody, diverging, isoluminant-rainbow,
extended-blackbody, and coolwarm) and four three-dimensional (3D) directional
encodings for tract tracing tasks (uniform gray, absolute, eigenmap, and Boy's
surface embedding). We found that extended-blackbody, coolwarm, and blackbody
remain the best three approaches for identifying ensemble average in 3D.
Isoluminant-rainbow coloring led to the same ensemble mean accuracy as other
colormaps. However, more than 50% of the answers consistently had higher
estimates of the ensemble average, independent of the mean values. Hue, not
luminance, influences ensemble estimates of mean values. For ensemble
orientation-tracing tasks, we found that the Boy's surface embedding (greatest
spatial resolution and contrast) and absolute color (lowest spatial resolution
and contrast) schemes led to more accurate answers than the eigenmaps scheme
(medium resolution and contrast), acting as the uncanny-valley phenomenon of
visualization design in terms of accuracy.
"
1210,"Interrogation of spline surfaces with application to isogeometric design
  and analysis of lattice-skin structures","  A novel surface interrogation technique is proposed to compute the
intersection of curves with spline surfaces in isogeometric analysis. The
intersection points are determined in one-shot without resorting to a
Newton-Raphson iteration or successive refinement. Surface-curve intersection
is required in a wide range of applications, including contact, immersed
boundary methods and lattice-skin structures, and requires usually the solution
of a system of nonlinear equations. It is assumed that the surface is given in
form of a spline, such as a NURBS, T-spline or Catmull-Clark subdivision
surface, and is convertible into a collection of B\'ezier patches. First, a
hierarchical bounding volume tree is used to efficiently identify the B\'ezier
patches with a convex-hull intersecting the convex-hull of a given curve
segment. For ease of implementation convex-hulls are approximated with k-dops
(discrete orientation polytopes). Subsequently, the intersections of the
identified B\'ezier patches with the curve segment are determined with a
matrix-based implicit representation leading to the computation of a sequence
of small singular value decompositions (SVDs). As an application of the
developed interrogation technique the isogeometric design and analysis of
lattice-skin structures is investigated. The skin is a spline surface that is
usually created in a computer-aided design (CAD) system and the periodic
lattice to be fitted consists of unit cells, each containing a small number of
struts. The lattice-skin structure is generated by projecting selected lattice
nodes onto the surface after determining the intersection of unit cell edges
with the surface. For mechanical analysis, the skin is modelled as a
Kirchhoff-Love thin-shell and the lattice as a pin-jointed truss. The two types
of structures are coupled with a standard Lagrange multiplier approach.
"
1211,"A System for Acquiring, Processing, and Rendering Panoramic Light Field
  Stills for Virtual Reality","  We present a system for acquiring, processing, and rendering panoramic light
field still photography for display in Virtual Reality (VR). We acquire
spherical light field datasets with two novel light field camera rigs designed
for portable and efficient light field acquisition. We introduce a novel
real-time light field reconstruction algorithm that uses a per-view geometry
and a disk-based blending field. We also demonstrate how to use a light field
prefiltering operation to project from a high-quality offline reconstruction
model into our real-time model while suppressing artifacts. We introduce a
practical approach for compressing light fields by modifying the VP9 video
codec to provide high quality compression with real-time, random access
decompression.
  We combine these components into a complete light field system offering
convenient acquisition, compact file size, and high-quality rendering while
generating stereo views at 90Hz on commodity VR hardware. Using our system, we
built a freely available light field experience application called Welcome to
Light Fields featuring a library of panoramic light field stills for consumer
VR which has been downloaded over 15,000 times.
"
1212,Spherical Parameterization Balancing Angle and Area Distortions,"  This work presents a novel framework for spherical mesh parameterization. An
efficient angle-preserving spherical parameterization algorithm is introduced,
which is based on dynamic Yamabe flow and the conformal welding method with
solid theoretic foundation. An area-preserving spherical parameterization is
also discussed, which is based on discrete optimal mass transport theory.
Furthermore, a spherical parameterization algorithm, which is based on the
polar decomposition method, balancing angle distortion and area distortion is
presented. The algorithms are tested on 3D geometric data and the experiments
demonstrate the efficiency and efficacy of the proposed methods.
"
1213,Single-Image SVBRDF Capture with a Rendering-Aware Deep Network,"  Texture, highlights, and shading are some of many visual cues that allow
humans to perceive material appearance in single pictures. Yet, recovering
spatially-varying bi-directional reflectance distribution functions (SVBRDFs)
from a single image based on such cues has challenged researchers in computer
graphics for decades. We tackle lightweight appearance capture by training a
deep neural network to automatically extract and make sense of these visual
cues. Once trained, our network is capable of recovering per-pixel normal,
diffuse albedo, specular albedo and specular roughness from a single picture of
a flat surface lit by a hand-held flash. We achieve this goal by introducing
several innovations on training data acquisition and network design. For
training, we leverage a large dataset of artist-created, procedural SVBRDFs
which we sample and render under multiple lighting directions. We further
amplify the data by material mixing to cover a wide diversity of shading
effects, which allows our network to work across many material classes.
Motivated by the observation that distant regions of a material sample often
offer complementary visual cues, we design a network that combines an
encoder-decoder convolutional track for local feature extraction with a
fully-connected track for global feature extraction and propagation. Many
important material effects are view-dependent, and as such ambiguous when
observed in a single image. We tackle this challenge by defining the loss as a
differentiable SVBRDF similarity metric that compares the renderings of the
predicted maps against renderings of the ground truth from several lighting and
viewing directions. Combined together, these novel ingredients bring clear
improvement over state of the art methods for single-shot capture of spatially
varying BRDFs.
"
1214,"Immercity: a curation content application in Virtual and Augmented
  reality","  When working with emergent and appealing technologies as Virtual Reality,
Mixed Reality and Augmented Reality, the issue of definitions appear very
often. Indeed, our experience with various publics allows us to notice that
technology definitions pose ambiguity and representation problems for informed
as well as novice users. In this paper we present Immercity, a content curation
system designed in the context of a collaboration between the University of
Montpellier and CapGemi-ni, to deliver a technology watch. It is also used as a
testbed for our experiences with Virtual, Mixed and Augmented reality to
explore new interaction techniques and devices, artificial intelligence
integration, visual affordances, performance , etc. But another, very
interesting goal appeared: use Immercity to communicate about Virtual, Mixed
and Augmented Reality by using them as a support.
"
1215,Practical Shape Analysis and Segmentation Methods for Point Cloud Models,"  Current point cloud processing algorithms do not have the capability to
automatically extract semantic information from the observed scenes, except in
very specialized cases. Furthermore, existing mesh analysis paradigms cannot be
directly employed to automatically perform typical shape analysis tasks
directly on point cloud models.
  We present a potent framework for shape analysis, similarity, and
segmentation of noisy point cloud models for real objects of engineering
interest, models that may be incomplete. The proposed framework relies on
spectral methods and the heat diffusion kernel to construct compact shape
signatures, and we show that the framework supports a variety of clustering
techniques that have traditionally been applied only on mesh models. We
developed and implemented one practical and convergent estimate of the
Laplace-Beltrami operator for point clouds as well as a number of clustering
techniques adapted to work directly on point clouds to produce geometric
features of engineering interest. The key advantage of this framework is that
it supports practical shape analysis capabilities that operate directly on
point cloud models of objects without requiring surface reconstruction or
global meshing. We show that the proposed technique is robust against typical
noise present in possibly incomplete point clouds, and segment point clouds
scanned by depth cameras (e.g. Kinect) into semantically-meaningful sub-shapes.
"
1216,Lightweight Structure Design Under Force Location Uncertainty,"  We introduce a lightweight structure optimization approach for problems in
which there is uncertainty in the force locations. Such uncertainty may arise
due to force contact locations that change during use or are simply unknown a
priori. Given an input 3D model, regions on its boundary where arbitrary normal
forces may make contact, and a total force-magnitude budget, our algorithm
generates a minimum weight 3D structure that withstands any force configuration
capped by the budget. Our approach works by repeatedly finding the most
critical force configuration and altering the internal structure accordingly. A
key issue, however, is that the critical force configuration changes as the
structure evolves, resulting in a significant computational challenge. To
address this, we propose an efficient critical instant analysis approach.
Combined with a reduced order formulation, our method provides a practical
solution to the structural optimization problem. We demonstrate our method on a
variety of models and validate it with mechanical tests.
"
1217,Content-Preserving Image Stitching with Regular Boundary Constraints,"  This paper proposes an approach to content-preserving stitching of images
with regular boundary constraints, which aims to stitch multiple images to
generate a panoramic image with regular boundary. Existing methods treat image
stitching and rectangling as two separate steps, which may result in suboptimal
results as the stitching process is not aware of the further warping needs for
rectangling. We address these limitations by formulating image stitching with
regular boundaries in a unified optimization. Starting from the initial
stitching results produced by traditional warping-based optimization, we obtain
the irregular boundary from the warped meshes by polygon Boolean operations
which robustly handle arbitrary mesh compositions, and by analyzing the
irregular boundary construct a piecewise rectangular boundary. Based on this,
we further incorporate straight line preserving and regular boundary
constraints into the image stitching framework, and conduct iterative
optimization to obtain an optimal piecewise rectangular boundary, thus can make
the panoramic boundary as close as possible to a rectangle, while reducing
unwanted distortions. We further extend our method to panoramic videos and
selfie photography, by integrating the temporal coherence and portrait
preservation into the optimization. Experiments show that our method
efficiently produces visually pleasing panoramas with regular boundaries and
unnoticeable distortions.
"
1218,"Automatic Graphics Program Generation using Attention-Based Hierarchical
  Decoder","  Recent progress on deep learning has made it possible to automatically
transform the screenshot of Graphic User Interface (GUI) into code by using the
encoder-decoder framework. While the commonly adopted image encoder (e.g., CNN
network), might be capable of extracting image features to the desired level,
interpreting these abstract image features into hundreds of tokens of code puts
a particular challenge on the decoding power of the RNN-based code generator.
Considering the code used for describing GUI is usually hierarchically
structured, we propose a new attention-based hierarchical code generation
model, which can describe GUI images in a finer level of details, while also
being able to generate hierarchically structured code in consistency with the
hierarchical layout of the graphic elements in the GUI. Our model follows the
encoder-decoder framework, all the components of which can be trained jointly
in an end-to-end manner. The experimental results show that our method
outperforms other current state-of-the-art methods on both a publicly available
GUI-code dataset as well as a dataset established by our own.
"
1219,Tabby: Explorable Design for 3D Printing Textures,"  This paper presents Tabby, an interactive and explorable design tool for 3D
printing textures. Tabby allows texture design with direct manipulation in the
following workflow: 1) select a target surface, 2) sketch and manipulate a
texture with 2D drawings, and then 3) generate 3D printing textures onto an
arbitrary curved surface. To enable efficient texture creation, Tabby leverages
an auto-completion approach which automates the tedious, repetitive process of
applying texture, while allowing flexible customization. Our user evaluation
study with seven participants confirms that Tabby can effectively support the
design exploration of different patterns for both novice and experienced users.
"
1220,CariGANs: Unpaired Photo-to-Caricature Translation,"  Facial caricature is an art form of drawing faces in an exaggerated way to
convey humor or sarcasm. In this paper, we propose the first Generative
Adversarial Network (GAN) for unpaired photo-to-caricature translation, which
we call ""CariGANs"". It explicitly models geometric exaggeration and appearance
stylization using two components: CariGeoGAN, which only models the
geometry-to-geometry transformation from face photos to caricatures, and
CariStyGAN, which transfers the style appearance from caricatures to face
photos without any geometry deformation. In this way, a difficult cross-domain
translation problem is decoupled into two easier tasks. The perceptual study
shows that caricatures generated by our CariGANs are closer to the hand-drawn
ones, and at the same time better persevere the identity, compared to
state-of-the-art methods. Moreover, our CariGANs allow users to control the
shape exaggeration degree and change the color/texture style by tuning the
parameters or giving an example caricature.
"
1221,AMPS: A Real-time Mesh Cutting Algorithm for Surgical Simulations,"  We present the AMPS algorithm, a finite element solution method that combines
principal submatrix updates and Schur complement techniques, well-suited for
interactive simulations of deformation and cutting of finite element meshes.
Our approach features real-time solutions to the updated stiffness matrix
systems to account for interactive changes in mesh connectivity and boundary
conditions. Updates are accomplished by an augmented matrix formulation of the
stiffness equations to maintain its consistency with changes to the underlying
model without refactorization at each timestep. As changes accumulate over
multiple simulation timesteps, the augmented solution algorithm enables tens or
hundreds of updates per second. Acceleration schemes that exploit sparsity,
memoization and parallelization lead to the updates being computed in
real-time. The complexity analysis and experimental results for this method
demonstrate that it scales linearly with the problem size. Results for cutting
and deformation of 3D elastic models are reported for meshes with node counts
up to 50,000, and involve models of astigmatism surgery and the brain.
"
1222,Enhancing the Structural Performance of Additively Manufactured Objects,"  The ability to accurately quantify the performance an additively manufactured
(AM) product is important for a widespread industry adoption of AM as the
design is required to: (1) satisfy geometrical constraints, (2) satisfy
structural constraints dictated by its intended function, and (3) be cost
effective compared to traditional manufacturing methods. Optimization
techniques offer design aids in creating cost-effective structures that meet
the prescribed structural objectives. The fundamental problem in existing
approaches lies in the difficulty to quantify the structural performance as
each unique design leads to a new set of analyses to determine the structural
robustness and such analyses can be very costly due to the complexity of in-use
forces experienced by the structure. This work develops computationally
tractable methods tailored to maximize the structural performance of AM
products. A geometry preserving build orientation optimization method as well
as data-driven shape optimization approaches to structural design are
presented. Proposed methods greatly enhance the value of AM technology by
taking advantage of the design space enabled by it for a broad class of
problems involving complex in-use loads.
"
1223,NeuralDrop: DNN-based Simulation of Small-Scale Liquid Flows on Solids,"  Small-scale liquid flows on solid surfaces provide convincing details in
liquid animation, but they are difficult to be simulated with efficiency and
fidelity, mostly due to the complex nature of the surface tension at the
contact front where liquid, air, and solid meet. In this paper, we propose to
simulate the dynamics of new liquid drops from captured real-world liquid flow
data, using deep neural networks. To achieve this goal, we develop a data
capture system that acquires liquid flow patterns from hundreds of real-world
water drops. We then convert raw data into compact data for training neural
networks, in which liquid drops are represented by their contact fronts in a
Lagrangian form. Using the LSTM units based on recurrent neural networks, our
neural networks serve three purposes in our simulator: predicting the contour
of a contact front, predicting the color field gradient of a contact front, and
finally predicting whether a contact front is going to break or not. Using
these predictions, our simulator recovers the overall shape of a liquid drop at
every time step, and handles merging and splitting events by simple operations.
The experiment shows that our trained neural networks are able to perform
predictions well. The whole simulator is robust, convenient to use, and capable
of generating realistic small-scale liquid effects in animation.
"
1224,Printable Aggregate Elements,"  Aggregating base elements into rigid objects such as furniture or sculptures
is a great way for designers to convey a specific look and feel. Unfortunately,
there is no existing solution to help model structurally sound aggregates. The
challenges stem from the fact that the final shape and its structural
properties emerge from the arrangements of the elements, whose sizes are large
so that they remain easily identifiable. Therefore there is a very tight
coupling between the object shape, structural properties, and the precise
layout of the elements.
  We present the first method to create aggregates of elements that are
structurally sound and can be manufactured on 3D printers. Rather than having
to assemble an aggregate shape by painstakingly positioning elements one by
one, users of our method only have to describe the structural purpose of the
desired object. This is done by specifying a set of external forces and
attachment points. The algorithm then automatically optimizes a layout of
user-provided elements that answers the specified scenario. The elements can
have arbitrary shapes: convex, concave, elongated, and can be allowed to
deform.
  Our approach creates connections between elements through small overlaps
preserving their appearance, while optimizing for the global rigidity of the
resulting aggregate. We formulate a topology optimization problem whose design
variables are the positions and orientations of individual elements. Global
rigidity is maximized through a dedicated gradient descent scheme. Due to the
challenging setting -- number of elements, arbitrary shapes, orientation, and
constraints in 3D -- we propose several novel steps to achieve convergence.
"
1225,"DragonPaint: Rule based bootstrapping for small data with an application
  to cartoon coloring","  In this paper, we confront the problem of deep learning's big labeled data
requirements, offer a rule based strategy for extreme augmentation of small
data sets and apply that strategy with the image to image translation model by
Isola et al. (2016) to automate cel style cartoon coloring with very limited
training data. While our experimental results using geometric rules and
transformations demonstrate the performance of our methods on an image
translation task with industry applications in art, design and animation, we
also propose the use of rules on partial data sets as a generalizable small
data strategy, potentially applicable across data types and domains.
"
1226,"Fast, High Precision Ray/Fiber Intersection using Tight, Disjoint
  Bounding Volumes","  Analyzing and identifying the shortcomings of current subdivision methods for
finding intersections of rays with fibers defined by the surface of a circular
contour swept along a B\'ezier curve, we present a new algorithm that improves
precision and performance. Instead of the inefficient pruning using overlapping
axis aligned bounding boxes and determining the closest point of approach of
the ray and the curve, we prune using disjoint bounding volumes defined by
cylinders and calculate the intersections on the limit surface. This in turn
allows for computing accurate parametric position and normal in the point of
intersection. The iteration requires only one bit per subdivision to avoid
costly stack memory operations. At a low number of subdivisions, the
performance of the high precision algorithm is competitive, while for a high
number of subdivisions it dramatically outperforms the state-of-the-art.
Besides an extensive mathematical analysis, source code is provided.
"
1227,"Massively Parallel Stackless Ray Tracing of Catmull-Clark Subdivision
  Surfaces","  We present a fast and efficient method for intersecting rays with
Catmull-Clark subdivision surfaces. It takes advantage of the approximation
democratized by OpenSubdiv, in which regular patches are represented by tensor
product B\'ezier surfaces and irregular ones are approximated using Gregory
patches. Our algorithm operates solely on the original patch data and can
process both patch types simultaneously with only a small amount of control
flow divergence. Besides introducing an optimized method to determine axis
aligned bounding boxes of Gregory patches restricted in the parametric domain,
several techniques are introduced that accelerate the recursive subdivision
process including stackless operation, efficient work distribution, and control
flow optimizations. The algorithm is especially useful for quick turnarounds
during patch editing and animation playback.
"
1228,"VV-Net: Voxel VAE Net with Group Convolutions for Point Cloud
  Segmentation","  We present a novel algorithm for point cloud segmentation. Our approach
transforms unstructured point clouds into regular voxel grids, and further uses
a kernel-based interpolated variational autoencoder (VAE) architecture to
encode the local geometry within each voxel. Traditionally, the voxel
representation only comprises Boolean occupancy information which fails to
capture the sparsely distributed points within voxels in a compact manner. In
order to handle sparse distributions of points, we further employ radial basis
functions (RBF) to compute a local, continuous representation within each
voxel. Our approach results in a good volumetric representation that
effectively tackles noisy point cloud datasets and is more robust for learning.
Moreover, we further introduce group equivariant CNN to 3D, by defining the
convolution operator on a symmetry group acting on $\mathbb{Z}^3$ and its
isomorphic sets. This improves the expressive capacity without increasing
parameters, leading to more robust segmentation results. We highlight the
performance on standard benchmarks and show that our approach outperforms
state-of-the-art segmentation algorithms on the ShapeNet and S3DIS datasets.
"
1229,Deep-learning the Latent Space of Light Transport,"  We suggest a method to directly deep-learn light transport, i. e., the
mapping from a 3D geometry-illumination-material configuration to a shaded 2D
image. While many previous learning methods have employed 2D convolutional
neural networks applied to images, we show for the first time that light
transport can be learned directly in 3D. The benefit of 3D over 2D is, that the
former can also correctly capture illumination effects related to occluded
and/or semi-transparent geometry. To learn 3D light transport, we represent the
3D scene as an unstructured 3D point cloud, which is later, during rendering,
projected to the 2D output image. Thus, we suggest a two-stage operator
comprising of a 3D network that first transforms the point cloud into a latent
representation, which is later on projected to the 2D output image using a
dedicated 3D-2D network in a second step. We will show that our approach
results in improved quality in terms of temporal coherence while retaining most
of the computational efficiency of common 2D methods. As a consequence, the
proposed two stage-operator serves as a valuable extension to modern deferred
shading approaches.
"
1230,"Web3D Graphics enabled through Sensor Networks for Cost-Effective
  Assessment and Management of Energy Efficiency in Buildings","  The past decade has seen the advent of numerous building energy efficiency
visualization and simulation systems; however, most of them rely on theoretical
thermal models to suggest building structural design for new constructions and
modifications for existing ones. Sustainable methods of construction have made
tremendous progress. The example of the German Energy-Plus- House technology
uses a combination of (almost) zero-carbon passive heating technologies. A
web-enabled X3D visualization and simulation system coupled with a
cost-effective set of temperature/humidity sensors can provide valuable
insights into building design, materials and construction that can lead to
significant energy savings and an improved thermal comfort for residents,
resulting in superior building energy efficiency. A cost-effective
hardware-software prototype system is proposed in this paper that can provide
real-time data driven visualization or offline simulation of 3D thermal maps
for residential and/or commercial buildings on the Web.
"
1231,Total Positivity of A Kind of Generalized Toric-Bernstein Basis,"  The normalized totally positive bases are widely used in many fields.Based on
the generalized Vandermonde determinant, the normalized total positivity of a
kind of generalized toric-Bernstein basis is proved, which is defined on a set
of real points. By this result, the progressive iterative approximation
property of the generalized toric-B\'{e}zier curve is obtained.
"
1232,Hair-GANs: Recovering 3D Hair Structure from a Single Image,"  We introduce Hair-GANs, an architecture of generative adversarial networks,
to recover the 3D hair structure from a single image. The goal of our networks
is to build a parametric transformation from 2D hair maps to 3D hair structure.
The 3D hair structure is represented as a 3D volumetric field which encodes
both the occupancy and the orientation information of the hair strands. Given a
single hair image, we first align it with a bust model and extract a set of 2D
maps encoding the hair orientation information in 2D, along with the bust depth
map to feed into our Hair-GANs. With our generator network, we compute the 3D
volumetric field as the structure guidance for the final hair synthesis. The
modeling results not only resemble the hair in the input image but also
possesses many vivid details in other views. The efficacy of our method is
demonstrated by using a variety of hairstyles and comparing with the prior art.
"
1233,Iso-parametric tool path planning for point clouds,"  The computational consuming and non-robust reconstruction from point clouds
to either meshes or spline surfaces motivates the direct tool path planning for
point clouds. In this paper, a novel approach for planning iso-parametric tool
path from a point cloud is presented. The planning depends on the
parameterization of point clouds. Accordingly, a conformal map is employed to
build the parameterization which leads to a significant simplification of
computing tool path parameters and boundary conformed paths. Then, Tool path is
generated through linear interpolation with the forward and side step computed
against specified chord deviation and scallop height, respectively.
Experimental results are given to illustrate effectiveness of the proposed
methods.
"
1234,Fast quasi-conformal regional flattening of the left atrium,"  Two-dimensional representation of 3D anatomical structures is a simple and
intuitive way for analysing patient information across populations and image
modalities. It also allows convenient visualizations that can be included in
clinical reports for a fast overview of the whole structure. While cardiac
ventricles, especially the left ventricle, have an established standard
representation (e.g. bull's eye plot), the 2D depiction of the left atrium (LA)
is challenging due to its sub-structural complexity including the pulmonary
veins (PV) and the left atrial appendage (LAA). Quasi-conformal flattening
techniques, successfully applied to cardiac ventricles, require additional
constraints in the case of the LA to place the PV and LAA in the same
geometrical 2D location for different cases. Some registration-based methods
have been proposed but 3D (or 2D) surface registration is time-consuming and
prone to errors if the geometries are very different. We propose a novel atrial
flattening methodology where a quasi-conformal 2D map of the LA is obtained
quickly and without errors related to registration. In our approach, the LA is
divided into 5 regions which are then mapped to their analogue two-dimensional
regions. A dataset of 67 human left atria from magnetic resonance images (MRI)
was studied to derive a population-based 2D LA template representing the
averaged relative locations of the PVs and LAA. The clinical application of the
proposed methodology is illustrated on different use cases including the
integration of MRI and electroanatomical data.
"
1235,Topology-Aware Non-Rigid Point Cloud Registration,"  In this paper, we introduce a non-rigid registration pipeline for pairs of
unorganized point clouds that may be topologically different. Standard warp
field estimation algorithms, even under robust, discontinuity-preserving
regularization, tend to produce erratic motion estimates on boundaries
associated with `close-to-open' topology changes. We overcome this limitation
by exploiting backward motion: in the opposite motion direction, a
`close-to-open' event becomes `open-to-close', which is by default handled
correctly. At the core of our approach lies a general, topology-agnostic warp
field estimation algorithm, similar to those employed in recently introduced
dynamic reconstruction systems from RGB-D input. We improve motion estimation
on boundaries associated with topology changes in an efficient post-processing
phase. Based on both forward and (inverted) backward warp hypotheses, we
explicitly detect regions of the deformed geometry that undergo topological
changes by means of local deformation criteria and broadly classify them as
`contacts' or `separations'. Subsequently, the two motion hypotheses are
seamlessly blended on a local basis, according to the type and proximity of
detected events. Our method achieves state-of-the-art motion estimation
accuracy on the MPI Sintel dataset. Experiments on a custom dataset with
topological event annotations demonstrate the effectiveness of our pipeline in
estimating motion on event boundaries, as well as promising performance in
explicit topological event detection.
"
1236,"An Infinite Parade of Giraffes: Expressive Augmentation and Complexity
  Layers for Cartoon Drawing","  In this paper, we explore creative image generation constrained by small
data. To partially automate the creation of cartoon sketches consistent with a
specific designer's style, where acquiring a very large original image set is
impossible or cost prohibitive, we exploit domain specific knowledge for a huge
reduction in original image requirements, creating an effectively infinite
number of cartoon giraffes from just nine original drawings. We introduce
""expressive augmentations"" for cartoon sketches, mathematical transformations
that create broad domain appropriate variation, far beyond the usual affine
transformations, and we show that chained GANs models trained on the temporal
stages of drawing or ""complexity layers"" can effectively add character
appropriate details and finish new drawings in the designer's style.
  We discuss the application of these tools in design processes for textiles,
graphics, architectural elements and interior design.
"
1237,STOAViz: Visualizing Saturated Thickness of Ogallala Aquifer,"  In this paper, we introduce STOAViz, a visual analytics tool for analyzing
the saturated thickness of the Ogallala aquifer. The saturated thicknesses are
monitored by sensors integrated on wells distributed on a vast geographic area.
Our analytics application also captures the trends and patterns (such as
average/standard deviation over time, sudden increase/decrease of saturated
thicknesses) of water on an individual well and a group of wells based on their
geographic locations. To highlight the usefulness and effectiveness of STOAViz,
we demonstrate it on the Southern High Plains Aquifer of Texas. The work was
developed using feedback from experts at the water resource center at a
university. Moreover, our technique can be applied on any geographic areas
where wells and their measurements are available.
"
1238,A Study on 3D Surface Graph Representations,"  Surface graphs have been used in many application domains to represent
three-dimensional (3D) data. Another approach to representing 3D data is making
projections onto two-dimensional (2D) graphs. This approach will result in
multiple displays, which is time-consuming in switching between different
screens for a different perspective. In this work, we study the performance of
3D version of popular 2D visualization techniques for time series: horizon
graph, small multiple, and simple line graph. We explore discrimination tasks
with respect to each visualization technique that requires simultaneous
representations. We demonstrate our study by visualizing saturated thickness of
the Ogallala aquifer - the Southern High Plains Aquifer of Texas in multiple
years. For the evaluation, we design comparison and discrimination tasks and
automatically record result performed by a group of students at a university.
Our results show that 3D small multiples perform well with stable accuracy over
numbers of occurrences. On the other hand, shared-space visualization within a
single 3D coordinate system is more efficient with small number of simultaneous
graphs. 3D horizon graph loses its competence in the 3D coordinate system with
the lowest accuracy comparing to other techniques. Our demonstration of 3D
spatial-temporal is also presented on the Southern High Plains Aquifer of Texas
from 2010 to 2016.
"
1239,"CompoNet: Learning to Generate the Unseen by Part Synthesis and
  Composition","  Data-driven generative modeling has made remarkable progress by leveraging
the power of deep neural networks. A reoccurring challenge is how to enable a
model to generate a rich variety of samples from the entire target
distribution, rather than only from a distribution confined to the training
data. In other words, we would like the generative model to go beyond the
observed samples and learn to generate ``unseen'', yet still plausible, data.
In our work, we present CompoNet, a generative neural network for 2D or 3D
shapes that is based on a part-based prior, where the key idea is for the
network to synthesize shapes by varying both the shape parts and their
compositions. Treating a shape not as an unstructured whole, but as a
(re-)composable set of deformable parts, adds a combinatorial dimension to the
generative process to enrich the diversity of the output, encouraging the
generator to venture more into the ``unseen''. We show that our part-based
model generates richer variety of plausible shapes compared with baseline
generative models. To this end, we introduce two quantitative metrics to
evaluate the diversity of a generative model and assess how well the generated
data covers both the training data and unseen data from the same target
distribution. Code is available at https://github.com/nschor/CompoNet.
"
1240,Iso-level tool path planning for free-form surfaces,"  The aim of tool path planning is to maximize the efficiency against some
given precision criteria. In practice, scallop height should be kept constant
to avoid unnecessary cutting, while the tool path should be smooth enough to
maintain a high feed rate. However, iso-scallop and smoothness often conflict
with each other. Existing methods smooth iso-scallop paths one-by-one, which
make the final tool path far from being globally optimal. This paper proposes a
new framework for tool path optimization. It views a family of iso-level curves
of a scalar function defined over the surface as tool path so that desired tool
path can be generated by finding the function that minimizes certain energy
functional and different objectives can be considered simultaneously. We use
the framework to plan globally optimal tool path with respect to iso-scallop
and smoothness. The energy functionals for planning iso-scallop, smoothness,
and optimal tool path are respectively derived, and the path topology is
studied too. Experimental results are given to show the effectiveness of the
proposed methods.
"
1241,"Deep Shape-from-Template: Wide-Baseline, Dense and Fast Registration and
  Deformable Reconstruction from a Single Image","  We present Deep Shape-from-Template (DeepSfT), a novel Deep Neural Network
(DNN) method for solving real-time automatic registration and 3D reconstruction
of a deformable object viewed in a single monocular image.DeepSfT advances the
state-of-the-art in various aspects. Compared to existing DNN SfT methods, it
is the first fully convolutional real-time approach that handles an arbitrary
object geometry, topology and surface representation. It also does not require
ground truth registration with real data and scales well to very complex object
models with large numbers of elements. Compared to previous non-DNN SfT
methods, it does not involve numerical optimization at run-time, and is a
dense, wide-baseline solution that does not demand, and does not suffer from,
feature-based matching. It is able to process a single image with significant
deformation and viewpoint changes, and handles well the core challenges of
occlusions, weak texture and blur. DeepSfT is based on residual encoder-decoder
structures and refining blocks. It is trained end-to-end with a novel
combination of supervised learning from simulated renderings of the object
model and semi-supervised automatic fine-tuning using real data captured with a
standard RGB-D camera. The cameras used for fine-tuning and run-time can be
different, making DeepSfT practical for real-world use. We show that DeepSfT
significantly outperforms state-of-the-art wide-baseline approaches for
non-trivial templates, with quantitative and qualitative evaluation.
"
1242,Photorealistic Facial Synthesis in the Dimensional Affect Space,"  This paper presents a novel approach for synthesizing facial affect, which is
based on our annotating 600,000 frames of the 4DFAB database in terms of
valence and arousal. The input of this approach is a pair of these emotional
state descriptors and a neutral 2D image of a person to whom the corresponding
affect will be synthesized. Given this target pair, a set of 3D facial meshes
is selected, which is used to build a blendshape model and generate the new
facial affect. To synthesize the affect on the 2D neutral image, 3DMM fitting
is performed and the reconstructed face is deformed to generate the target
facial expressions. Last, the new face is rendered into the original image.
Both qualitative and quantitative experimental studies illustrate the
generation of realistic images, when the neutral image is sampled from a
variety of well known databases, such as the Aff-Wild, AFEW, Multi-PIE,
AFEW-VA, BU-3DFE, Bosphorus.
"
1243,"Generating Classes of 3D Virtual Mandibles for AR-Based Medical
  Simulation","  Simulation and modeling represent promising tools for several application
domains from engineering to forensic science and medicine. Advances in 3D
imaging technology convey paradigms such as augmented reality (AR) and mixed
reality inside promising simulation tools for the training industry. Motivated
by the requirement for superimposing anatomically correct 3D models on a Human
Patient Simulator (HPS) and visualizing them in an AR environment, the purpose
of this research effort is to derive method for scaling a source human mandible
to a target human mandible. Results show that, given a distance between two
same landmarks on two different mandibles, a relative scaling factor may be
computed. Using this scaling factor, results show that a 3D virtual mandible
model can be made morphometrically equivalent to a real target-specific
mandible within a 1.30 millimeter average error bound. The virtual mandible may
be further used as a reference target for registering other anatomical models,
such as the lungs, on the HPS. Such registration will be made possible by
physical constraints among the mandible and the spinal column in the horizontal
normal rest position.
"
1244,Sketch-R2CNN: An Attentive Network for Vector Sketch Recognition,"  Freehand sketching is a dynamic process where points are sequentially sampled
and grouped as strokes for sketch acquisition on electronic devices. To
recognize a sketched object, most existing methods discard such important
temporal ordering and grouping information from human and simply rasterize
sketches into binary images for classification. In this paper, we propose a
novel single-branch attentive network architecture RNN-Rasterization-CNN
(Sketch-R2CNN for short) to fully leverage the dynamics in sketches for
recognition. Sketch-R2CNN takes as input only a vector sketch with grouped
sequences of points, and uses an RNN for stroke attention estimation in the
vector space and a CNN for 2D feature extraction in the pixel space
respectively. To bridge the gap between these two spaces in neural networks, we
propose a neural line rasterization module to convert the vector sketch along
with the attention estimated by RNN into a bitmap image, which is subsequently
consumed by CNN. The neural line rasterization module is designed in a
differentiable way to yield a unified pipeline for end-to-end learning. We
perform experiments on existing large-scale sketch recognition benchmarks and
show that by exploiting the sketch dynamics with the attention mechanism, our
method is more robust and achieves better performance than the state-of-the-art
methods.
"
1245,Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints,"  Recent advances in Generative Adversarial Networks (GANs) have shown
increasing success in generating photorealistic images. But they also raise
challenges to visual forensics and model attribution. We present the first
study of learning GAN fingerprints towards image attribution and using them to
classify an image as real or GAN-generated. For GAN-generated images, we
further identify their sources. Our experiments show that (1) GANs carry
distinct model fingerprints and leave stable fingerprints in their generated
images, which support image attribution; (2) even minor differences in GAN
training can result in different fingerprints, which enables fine-grained model
authentication; (3) fingerprints persist across different image frequencies and
patches and are not biased by GAN artifacts; (4) fingerprint finetuning is
effective in immunizing against five types of adversarial image perturbations;
and (5) comparisons also show our learned fingerprints consistently outperform
several baselines in a variety of setups.
"
1246,Procedural Crowd Generation for Semantically Augmented Virtual Cities,"  Authoring realistic behaviors to populate a large virtual city can be a
cumbersome, time-consuming and error-prone task. Believable crowds require the
effort of storytellers and programming experts working together for long
periods of time. In this work, we present a new framework to allow users to
generate populated environments in an easier and faster way, by relying on the
use of procedural techniques. Our framework consists of the procedural
generation of semantically-augmented virtual cities to drive the procedural
generation and simulation of crowds. The main novelty lies in the generation of
agendas for each individual inhabitant (alone or as part of a family) by using
a rule-based grammar that combines city semantics with the autonomous persons'
characteristics. Real-world data can be used to accommodate the generation of a
virtual population, thus enabling the recreation of more realistic scenarios.
Users can author a new population or city by editing rule files with the
flexibility of re-using, combining or extending the rules of previous
populations. The results show how logical and consistent behaviors can be
easily generated for a large crowd providing a good starting point to bring
virtual cities to life.
"
1247,"Foreground Clustering for Joint Segmentation and Localization in Videos
  and Images","  This paper presents a novel framework in which video/image segmentation and
localization are cast into a single optimization problem that integrates
information from low level appearance cues with that of high level localization
cues in a very weakly supervised manner. The proposed framework leverages two
representations at different levels, exploits the spatial relationship between
bounding boxes and superpixels as linear constraints and simultaneously
discriminates between foreground and background at bounding box and superpixel
level. Different from previous approaches that mainly rely on discriminative
clustering, we incorporate a foreground model that minimizes the histogram
difference of an object across all image frames. Exploiting the geometric
relation between the superpixels and bounding boxes enables the transfer of
segmentation cues to improve localization output and vice-versa. Inclusion of
the foreground model generalizes our discriminative framework to video data
where the background tends to be similar and thus, not discriminative. We
demonstrate the effectiveness of our unified framework on the YouTube Object
video dataset, Internet Object Discovery dataset and Pascal VOC 2007.
"
1248,"Multilevel active registration for kinect human body scans: from low
  quality to high quality","  Registration of 3D human body has been a challenging research topic for over
decades. Most of the traditional human body registration methods require manual
assistance, or other auxiliary information such as texture and markers. The
majority of these methods are tailored for high-quality scans from expensive
scanners. Following the introduction of the low-quality scans from
cost-effective devices such as Kinect, the 3D data capturing of human body
becomes more convenient and easier. However, due to the inevitable holes,
noises and outliers in the low-quality scan, the registration of human body
becomes even more challenging. To address this problem, we propose a fully
automatic active registration method which deforms a high-resolution template
mesh to match the low-quality human body scans. Our registration method
operates on two levels of statistical shape models: (1) the first level is a
holistic body shape model that defines the basic figure of human; (2) the
second level includes a set of shape models for every body part, aiming at
capturing more body details. Our fitting procedure follows a coarse-to-fine
approach that is robust and efficient. Experiments show that our method is
comparable with the state-of-the-art methods.
"
1249,"EFANet: Exchangeable Feature Alignment Network for Arbitrary Style
  Transfer","  Style transfer has been an important topic both in computer vision and
graphics. Since the seminal work of Gatys et al. first demonstrates the power
of stylization through optimization in the deep feature space, quite a few
approaches have achieved real-time arbitrary style transfer with
straightforward statistic matching techniques. In this work, our key
observation is that only considering features in the input style image for the
global deep feature statistic matching or local patch swap may not always
ensure a satisfactory style transfer; see e.g., Figure 1. Instead, we propose a
novel transfer framework, EFANet, that aims to jointly analyze and better align
exchangeable features extracted from content and style image pair. In this way,
the style features from the style image seek for the best compatibility with
the content information in the content image, leading to more structured
stylization results. In addition, a new whitening loss is developed for
purifying the computed content features and better fusion with styles in
feature space. Qualitative and quantitative experiments demonstrate the
advantages of our approach.
"
1250,"GAN Dissection: Visualizing and Understanding Generative Adversarial
  Networks","  Generative Adversarial Networks (GANs) have recently achieved impressive
results for many real-world applications, and many GAN variants have emerged
with improvements in sample quality and training stability. However, they have
not been well visualized or understood. How does a GAN represent our visual
world internally? What causes the artifacts in GAN results? How do
architectural choices affect GAN learning? Answering such questions could
enable us to develop new insights and better models.
  In this work, we present an analytic framework to visualize and understand
GANs at the unit-, object-, and scene-level. We first identify a group of
interpretable units that are closely related to object concepts using a
segmentation-based network dissection method. Then, we quantify the causal
effect of interpretable units by measuring the ability of interventions to
control objects in the output. We examine the contextual relationship between
these units and their surroundings by inserting the discovered object concepts
into new images. We show several practical applications enabled by our
framework, from comparing internal representations across different layers,
models, and datasets, to improving GANs by locating and removing
artifact-causing units, to interactively manipulating objects in a scene. We
provide open source interpretation tools to help researchers and practitioners
better understand their GAN models.
"
1251,Deep Geometric Prior for Surface Reconstruction,"  The reconstruction of a discrete surface from a point cloud is a fundamental
geometry processing problem that has been studied for decades, with many
methods developed. We propose the use of a deep neural network as a geometric
prior for surface reconstruction. Specifically, we overfit a neural network
representing a local chart parameterization to part of an input point cloud
using the Wasserstein distance as a measure of approximation. By jointly
fitting many such networks to overlapping parts of the point cloud, while
enforcing a consistency condition, we compute a manifold atlas. By sampling
this atlas, we can produce a dense reconstruction of the surface approximating
the input cloud. The entire procedure does not require any training data or
explicit regularization, yet, we show that it is able to perform remarkably
well: not introducing typical overfitting artifacts, and approximating sharp
features closely at the same time. We experimentally show that this geometric
prior produces good results for both man-made objects containing sharp features
and smoother organic objects, as well as noisy inputs. We compare our method
with a number of well-known reconstruction methods on a standard surface
reconstruction benchmark.
"
1252,"FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained
  Object Generation and Discovery","  We propose FineGAN, a novel unsupervised GAN framework, which disentangles
the background, object shape, and object appearance to hierarchically generate
images of fine-grained object categories. To disentangle the factors without
supervision, our key idea is to use information theory to associate each factor
to a latent code, and to condition the relationships between the codes in a
specific way to induce the desired hierarchy. Through extensive experiments, we
show that FineGAN achieves the desired disentanglement to generate realistic
and diverse images belonging to fine-grained classes of birds, dogs, and cars.
Using FineGAN's automatically learned features, we also cluster real images as
a first attempt at solving the novel problem of unsupervised fine-grained
object category discovery. Our code/models/demo can be found at
https://github.com/kkanshul/finegan
"
1253,Patch-based Progressive 3D Point Set Upsampling,"  We present a detail-driven deep neural network for point set upsampling. A
high-resolution point set is essential for point-based rendering and surface
reconstruction. Inspired by the recent success of neural image super-resolution
techniques, we progressively train a cascade of patch-based upsampling networks
on different levels of detail end-to-end. We propose a series of architectural
design contributions that lead to a substantial performance boost. The effect
of each technical contribution is demonstrated in an ablation study.
Qualitative and quantitative experiments show that our method significantly
outperforms the state-of-the-art learning-based and optimazation-based
approaches, both in terms of handling low-resolution inputs and revealing
high-fidelity details.
"
1254,"Isospectralization, or how to hear shape, style, and correspondence","  The question whether one can recover the shape of a geometric object from its
Laplacian spectrum ('hear the shape of the drum') is a classical problem in
spectral geometry with a broad range of implications and applications. While
theoretically the answer to this question is negative (there exist examples of
iso-spectral but non-isometric manifolds), little is known about the practical
possibility of using the spectrum for shape reconstruction and optimization. In
this paper, we introduce a numerical procedure called isospectralization,
consisting of deforming one shape to make its Laplacian spectrum match that of
another. We implement the isospectralization procedure using modern
differentiable programming techniques and exemplify its applications in some of
the classical and notoriously hard problems in geometry processing, computer
vision, and graphics such as shape reconstruction, pose and style transfer, and
dense deformable correspondence.
"
1255,Image Reconstruction with Predictive Filter Flow,"  We propose a simple, interpretable framework for solving a wide range of
image reconstruction problems such as denoising and deconvolution. Given a
corrupted input image, the model synthesizes a spatially varying linear filter
which, when applied to the input image, reconstructs the desired output. The
model parameters are learned using supervised or self-supervised training. We
test this model on three tasks: non-uniform motion blur removal,
lossy-compression artifact reduction and single image super resolution. We
demonstrate that our model substantially outperforms state-of-the-art methods
on all these tasks and is significantly faster than optimization-based
approaches to deconvolution. Unlike models that directly predict output pixel
values, the predicted filter flow is controllable and interpretable, which we
demonstrate by visualizing the space of predicted filters for different tasks.
"
1256,Escaping Plato's Cave: 3D Shape From Adversarial Rendering,"  We introduce PlatonicGAN to discover the 3D structure of an object class from
an unstructured collection of 2D images, i.e., where no relation between photos
is known, except that they are showing instances of the same category. The key
idea is to train a deep neural network to generate 3D shapes which, when
rendered to images, are indistinguishable from ground truth images (for a
discriminator) under various camera poses. Discriminating 2D images instead of
3D shapes allows tapping into unstructured 2D photo collections instead of
relying on curated (e.g., aligned, annotated, etc.) 3D data sets. To establish
constraints between 2D image observation and their 3D interpretation, we
suggest a family of rendering layers that are effectively differentiable. This
family includes visual hull, absorption-only (akin to x-ray), and
emission-absorption. We can successfully reconstruct 3D shapes from
unstructured 2D images and extensively evaluate PlatonicGAN on a range of
synthetic and real data sets achieving consistent improvements over baseline
methods. We further show that PlatonicGAN can be combined with 3D supervision
to improve on and in some cases even surpass the quality of 3D-supervised
methods.
"
1257,Learning to Synthesize Motion Blur,"  We present a technique for synthesizing a motion blurred image from a pair of
unblurred images captured in succession. To build this system we motivate and
design a differentiable ""line prediction"" layer to be used as part of a neural
network architecture, with which we can learn a system to regress from image
pairs to motion blurred images that span the capture time of the input image
pair. Training this model requires an abundance of data, and so we design and
execute a strategy for using frame interpolation techniques to generate a
large-scale synthetic dataset of motion blurred images and their respective
inputs. We additionally capture a high quality test set of real motion blurred
images, synthesized from slow motion videos, with which we evaluate our model
against several baseline techniques that can be used to synthesize motion blur.
Our model produces higher accuracy output than our baselines, and is
significantly faster than baselines with competitive accuracy.
"
1258,Interactive X-ray and proton therapy training and simulation,"  External beam X-ray therapy (XRT) and proton therapy (PT) are effective and
widely accepted forms of treatment for many types of cancer. However, the
procedures require extensive computerized planning. Current planning systems
for both XRT and PT have insufficient visual aid to combine real patient data
with the treatment device geometry to account for unforeseen collisions among
system components and the patient. We are proposing a cost-effective method to
extract patient specific S-reps in real time, and combine them with the
treatment system geometry to provide a comprehensive simulation of the XRT/PT
treatment room. The X3D standard is used to implement and deploy the simulator
on the web, enabling its use not only for remote specialists' collaboration,
simulation, and training, but also for patient education.
"
1259,Online External Beam Radiation Treatment Simulator,"  Radiation therapy is an effective and widely accepted form of treatment for
many types of cancer that requires extensive computerized planning.
Unfortunately, current treatment planning systems have limited or no visual aid
that combines patient volumetric models extracted from patient-specific CT data
with the treatment device geometry in a 3D interactive simulation. We
illustrate the potential of 3D simulation in radiation therapy with a web-based
interactive system that combines novel standards and technologies. We discuss
related research efforts in this area and present in detail several components
of the simulator. An objective assessment of the accuracy of the simulator and
a usability study prove the potential of such a system for simulation and
training.
"
1260,Diverse Image Synthesis from Semantic Layouts via Conditional IMLE,"  Most existing methods for conditional image synthesis are only able to
generate a single plausible image for any given input, or at best a fixed
number of plausible images. In this paper, we focus on the problem of
generating images from semantic segmentation maps and present a simple new
method that can generate an arbitrary number of images with diverse appearance
for the same semantic layout. Unlike most existing approaches which adopt the
GAN framework, our method is based on the recently introduced Implicit Maximum
Likelihood Estimation (IMLE) framework. Compared to the leading approach, our
method is able to generate more diverse images while producing fewer artifacts
despite using the same architecture. The learned latent space also has sensible
structure despite the lack of supervision that encourages such behaviour.
Videos and code are available at
https://people.eecs.berkeley.edu/~ke.li/projects/imle/scene_layouts/.
"
1261,"Fast and Flexible Indoor Scene Synthesis via Deep Convolutional
  Generative Models","  We present a new, fast and flexible pipeline for indoor scene synthesis that
is based on deep convolutional generative models. Our method operates on a
top-down image-based representation, and inserts objects iteratively into the
scene by predicting their category, location, orientation and size with
separate neural network modules. Our pipeline naturally supports automatic
completion of partial scenes, as well as synthesis of complete scenes. Our
method is significantly faster than the previous image-based method and
generates result that outperforms it and other state-of-the-art deep generative
scene models in terms of faithfulness to training data and perceived visual
quality.
"
1262,"Increasing the Capability of Neural Networks for Surface Reconstruction
  from Noisy Point Clouds","  This paper builds upon the current methods to increase their capability and
automation for 3D surface construction from noisy and potentially sparse point
clouds. It presents an analysis of an artificial neural network surface
regression and mapping method, describing caveats, improvements and
justification for the different approach.
"
1263,Inviwo -- A Visualization System with Usage Abstraction Levels,"  The complexity of today's visualization applications demands specific
visualization systems tailored for the development of these applications.
Frequently, such systems utilize levels of abstraction to improve the
application development process, for instance by providing a data flow network
editor. Unfortunately, these abstractions result in several issues, which need
to be circumvented through an abstraction-centered system design. Often, a high
level of abstraction hides low level details, which makes it difficult to
directly access the underlying computing platform, which would be important to
achieve an optimal performance. Therefore, we propose a layer structure
developed for modern and sustainable visualization systems allowing developers
to interact with all contained abstraction levels. We refer to this interaction
capabilities as usage abstraction levels, since we target application
developers with various levels of experience. We formulate the requirements for
such a system, derive the desired architecture, and present how the concepts
have been exemplary realized within the Inviwo visualization system.
Furthermore, we address several specific challenges that arise during the
realization of such a layered architecture, such as communication between
different computing platforms, performance centered encapsulation, as well as
layer-independent development by supporting cross layer documentation and
debugging capabilities.
"
1264,Topology-Aware Surface Reconstruction for Point Clouds,"  We present an approach to inform the reconstruction of a surface from a point
scan through topological priors. The reconstruction is based on basis functions
which are optimized to provide a good fit to the point scan while satisfying
predefined topological constraints. We optimize the parameters of a model to
obtain likelihood function over the reconstruction domain. The topological
constraints are captured by persistence diagrams which are incorporated in the
optimization algorithm promote the correct topology. The result is a novel
topology-aware technique which can: 1.) weed out topological noise from point
scans, and 2.) capture certain nuanced properties of the underlying shape which
could otherwise be lost while performing surface reconstruction. We showcase
results reconstructing shapes with multiple potential topologies, compare to
other classical surface construction techniques, and show the completion of
real scan data.
"
1265,"Constructing Trivariate B-splines with Positive Jacobian by Pillow
  Operation and Geometric Iterative Fitting","  The advent of isogeometric analysis has prompted a need for methods to
generate Trivariate B-spline Solids (TBS) with positive Jacobian. However, it
is difficult to guarantee a positive Jacobian of a TBS since the geometric
pre-condition for ensuring the positive Jacobian is very complicated. In this
paper, we propose a method for generating TBSs with guaranteed positive
Jacobian. For the study, we used a tetrahedral (tet) mesh model and segmented
it into sub-volumes using the pillow operation. Then, to reduce the difficulty
in ensuring a positive Jacobian, we separately fitted the boundary curves and
surfaces and the sub-volumes using a geometric iterative fitting algorithm.
Finally, the smoothness between adjacent TBSs is improved. The experimental
examples presented in this paper demonstrate the effectiveness and efficiency
of the developed algorithm.
"
1266,"Gregory Solid Construction for Polyhedral Volume Parameterization by
  Sparse Optimization","  In isogeometric analysis, it is frequently required to handle the geometric
models enclosed by four-sided or non-four-sided boundary patches, such as
trimmed surfaces. In this paper, we develop a Gregory solid based method to
parameterize those models. First, we extend the Gregory patch representation to
the trivariate Gregory solid representation. Second, the trivariate Gregory
solid representation is employed to interpolate the boundary patches of a
geometric model, thus generating the polyhedral volume parametrization. To
improve the regularity of the polyhedral volume parametrization, we formulate
the construction of the trivariate Gregory solid as a sparse optimization
problem, where the optimization objective function is a linear combination of
some terms, including a sparse term aiming to reduce the negative Jacobian area
of the Gregory solid. Then, the alternating direction method of multipliers
(ADMM) is used to solve the sparse optimization problem. Lots of experimental
examples illustrated in this paper demonstrate the effectiveness and efficiency
of the developed method.
"
1267,Instance-level Facial Attributes Transfer with Geometry-Aware Flow,"  We address the problem of instance-level facial attribute transfer without
paired training data, e.g. faithfully transferring the exact mustache from a
source face to a target face. This is a more challenging task than the
conventional semantic-level attribute transfer, which only preserves the
generic attribute style instead of instance-level traits. We propose the use of
geometry-aware flow, which serves as a well-suited representation for modeling
the transformation between instance-level facial attributes. Specifically, we
leverage the facial landmarks as the geometric guidance to learn the
differentiable flows automatically, despite of the large pose gap existed.
Geometry-aware flow is able to warp the source face attribute into the target
face context and generate a warp-and-blend result. To compensate for the
potential appearance gap between source and target faces, we propose a
hallucination sub-network that produces an appearance residual to further
refine the warp-and-blend result. Finally, a cycle-consistency framework
consisting of both attribute transfer module and attribute removal module is
designed, so that abundant unpaired face images can be used as training data.
Extensive evaluations validate the capability of our approach in transferring
instance-level facial attributes faithfully across large pose and appearance
gaps. Thanks to the flow representation, our approach can readily be applied to
generate realistic details on high-resolution images.
"
1268,"Computational paper wrapping transforms non-stretchable 2D devices into
  wearable and conformable 3D devices","  This study starts from the counter-intuitive question of how we can render a
conventional stiff, non-stretchable and even brittle material conformable so
that it can fully wrap around a curved surface, such as a sphere, without
failure. Here, we answer this conundrum by extending geometrical design in
computational kirigami (paper cutting and folding) to paper wrapping. Our
computational paper wrapping-based approach provides the more robust and
reliable fabrication of conformal devices than paper folding approaches. This
in turn leads to a significant increase in the applicability of computational
kirigami to real-world fabrication. This new computer-aided design transforms
2D-based conventional materials, such as Si and copper, into a variety of
targeted conformal structures that can fully wrap the desired 3D structure
without plastic deformation or fracture. We further demonstrated that our novel
approach enables a pluripotent design platform to transform conventional
non-stretchable 2D-based devices, such as electroluminescent lighting and a
paper battery, into wearable and conformable 3D curved devices.
"
1269,Auto-Grading for 3D Modeling Assignments in MOOCs,"  Bottlenecks such as the latency in correcting assignments and providing a
grade for Massive Open Online Courses (MOOCs) could impact the levels of
interest among learners. In this proposal for an auto-grading system, we
present a method to simplify grading for an online course that focuses on 3D
Modeling, thus addressing a critical component of the MOOC ecosystem that
affects. Our approach involves a live auto-grader that is capable of attaching
descriptive labels to assignments which will be deployed for evaluating
submissions. This paper presents a brief overview of this auto-grading system
and the reasoning behind its inception. Preliminary internal tests show that
our system presents results comparable to human graders.
"
1270,"Accurate control of a pan-tilt system based on parameterization of
  rotational motion","  A pan-tilt camera system has been adopted by a variety of fields since it can
cover a wide range of region compared to a single fixated camera setup. Yet
many studies rely on factory-assembled and calibrated platforms and assume an
ideal rotation where rotation axes are perfectly aligned with the optical axis
of the local camera. However, in a user-created setup where a pan-tilting
mechanism is arbitrarily assembled, the kinematic configurations may be
inaccurate or unknown, violating ideal rotation. These discrepancies in the
model with the real physics result in erroneous servo manipulation of the
pan-tilting system. In this paper, we propose an accurate control mechanism for
arbitrarily-assembled pan-tilt camera systems. The proposed method formulates
pan-tilt rotations as motion along great circle trajectories and calibrates its
model parameters, such as positions and vectors of rotation axes, in 3D space.
Then, one can accurately servo pan-tilt rotations with pose estimation from
inverse kinematics of their transformation. The comparative experiment
demonstrates out-performance of the proposed method, in terms of accurately
localizing target points in world coordinates, after being rotated from their
captured camera frames.
"
1271,AIR: Anywhere Immersive Reality with User-Perspective Projection,"  Projection-based augmented reality (AR) has much potential, but is limited in
that it requires burdensome installations and prone to geometric distortions on
display surface. To overcome these limitations, we propose AIR. It can be
carried and placed anywhere to project AR using pan/tilting motors, while
providing the user with distortion-free projection of a correct 3D view.
"
1272,"Fast and Accurate Reconstruction of Pan-Tilt RGB-D Scans via Axis Bound
  Registration","  A fast and accurate algorithm is presented for registering scans from an
RGB-D camera on a pan-tilt platform. The pan-tilt RGB-D camera rotates and
scans the entire scene in an automated fashion. The proposed algorithm exploits
the movement of the camera that is bound by the two rotation axes of the servo
motors so as to realize fast and accurate registration of acquired point
clouds. The rotation parameters, including the rotation axes, pan-tilt
transformations and the servo control mechanism, are calibrated beforehand.
Subsequently, fast global registration can be performed during online operation
with transformation matrices formed by the calibrated rotation axes and angles.
In local registration, features are extracted and matched between two scenes.
False-positive correspondences, whose distances to the rotation trajectories
exceed a threshold, are rejected. Then, a more accurate registration can be
achieved by minimizing the residual distances between corresponding points,
while transformations are bound to the rotation axes. Finally, the preliminary
alignment result is input to the iterative closed point algorithm to compute
the final transformation. Results of comparative experiments validate that the
proposed method outperforms state-of-the-art algorithms of various approaches
based on camera calibration, global registration, and
simultaneous-localization-and-mapping in terms of root-mean-square error and
computation time.
"
1273,"Heter-Sim: Heterogeneous multi-agent systems simulation by interactive
  data-driven optimization","  Interactive multi-agent simulation algorithms are used to compute the
trajectories and behaviors of different entities in virtual reality scenarios.
However, current methods involve considerable parameter tweaking to generate
plausible behaviors. We introduce a novel approach (Heter-Sim) that combines
physics-based simulation methods with data-driven techniques using an
optimization-based formulation. Our approach is general and can simulate
heterogeneous agents corresponding to human crowds, traffic, vehicles, or
combinations of different agents with varying dynamics. We estimate motion
states from real-world datasets that include information about position,
velocity, and control direction. Our optimization algorithm considers several
constraints, including velocity continuity, collision avoidance, attraction,
and direction control. To accelerate the computations, we reduce the search
space for both collision avoidance and optimal solution computation. Heter-Sim
can simulate tens or hundreds of agents at interactive rates and we compare its
accuracy with real-world datasets and prior algorithms. We also perform user
studies that evaluate the plausible behaviors generated by our algorithm and a
user study that evaluates the plausibility of our algorithm via VR.
"
1274,"General Support-Effective Decomposition for Multi-Directional 3D
  Printing","  We present a method for fabricating general models with multi-directional 3D
printing systems by printing different model regions along with different
directions. The core of our method is a support-effective volume decomposition
algorithm that minimizes the area of the regions with large overhangs. A
beam-guided searching algorithm with manufacturing constraints determines the
optimal volume decomposition, which is represented by a sequence of clipping
planes. While current approaches require manually assembling separate
components into a final model, our algorithm allows for directly printing the
final model in a single pass. It can also be applied to models with loops and
handles. A supplementary algorithm generates special supporting structures for
models where supporting structures for large overhangs cannot be eliminated. We
verify the effectiveness of our method using two hardware systems: a
Cartesian-motion based system and an angular-motion based system. A variety of
3D models have been successfully fabricated on these systems.
"
1275,Estimating 6D Pose From Localizing Designated Surface Keypoints,"  In this paper, we present an accurate yet effective solution for 6D pose
estimation from an RGB image. The core of our approach is that we first
designate a set of surface points on target object model as keypoints and then
train a keypoint detector (KPD) to localize them. Finally a PnP algorithm can
recover the 6D pose according to the 2D-3D relationship of keypoints. Different
from recent state-of-the-art CNN-based approaches that rely on a time-consuming
post-processing procedure, our method can achieve competitive accuracy without
any refinement after pose prediction. Meanwhile, we obtain a 30% relative
improvement in terms of ADD accuracy among methods without using refinement.
Moreover, we succeed in handling heavy occlusion by selecting the most
confident keypoints to recover the 6D pose. For the sake of reproducibility, we
will make our code and models publicly available soon.
"
1276,A Face-to-Face Neural Conversation Model,"  Neural networks have recently become good at engaging in dialog. However,
current approaches are based solely on verbal text, lacking the richness of a
real face-to-face conversation. We propose a neural conversation model that
aims to read and generate facial gestures alongside with text. This allows our
model to adapt its response based on the ""mood"" of the conversation. In
particular, we introduce an RNN encoder-decoder that exploits the movement of
facial muscles, as well as the verbal conversation. The decoder consists of two
layers, where the lower layer aims at generating the verbal response and coarse
facial expressions, while the second layer fills in the subtle gestures, making
the generated output more smooth and natural. We train our neural network by
having it ""watch"" 250 movies. We showcase our joint face-text model in
generating more natural conversations through automatic metrics and a human
study. We demonstrate an example application with a face-to-face chatting
avatar.
"
1277,"Monocular Total Capture: Posing Face, Body, and Hands in the Wild","  We present the first method to capture the 3D total motion of a target person
from a monocular view input. Given an image or a monocular video, our method
reconstructs the motion from body, face, and fingers represented by a 3D
deformable mesh model. We use an efficient representation called 3D Part
Orientation Fields (POFs), to encode the 3D orientations of all body parts in
the common 2D image space. POFs are predicted by a Fully Convolutional Network
(FCN), along with the joint confidence maps. To train our network, we collect a
new 3D human motion dataset capturing diverse total body motion of 40 subjects
in a multiview system. We leverage a 3D deformable human model to reconstruct
total body pose from the CNN outputs by exploiting the pose and shape prior in
the model. We also present a texture-based tracking method to obtain temporally
coherent motion capture output. We perform thorough quantitative evaluations
including comparison with the existing body-specific and hand-specific methods,
and performance analysis on camera viewpoint and human pose changes. Finally,
we demonstrate the results of our total body motion capture on various
challenging in-the-wild videos. Our code and newly collected human motion
dataset will be publicly shared.
"
1278,"Generating High Fidelity Images with Subscale Pixel Networks and
  Multidimensional Upscaling","  The unconditional generation of high fidelity images is a longstanding
benchmark for testing the performance of image decoders. Autoregressive image
models have been able to generate small images unconditionally, but the
extension of these methods to large images where fidelity can be more readily
assessed has remained an open problem. Among the major challenges are the
capacity to encode the vast previous context and the sheer difficulty of
learning a distribution that preserves both global semantic coherence and
exactness of detail. To address the former challenge, we propose the Subscale
Pixel Network (SPN), a conditional decoder architecture that generates an image
as a sequence of sub-images of equal size. The SPN compactly captures
image-wide spatial dependencies and requires a fraction of the memory and the
computation required by other fully autoregressive models. To address the
latter challenge, we propose to use Multidimensional Upscaling to grow an image
in both size and depth via intermediate stages utilising distinct SPNs. We
evaluate SPNs on the unconditional generation of CelebAHQ of size 256 and of
ImageNet from size 32 to 256. We achieve state-of-the-art likelihood results in
multiple settings, set up new benchmark results in previously unexplored
settings and are able to generate very high fidelity large scale samples on the
basis of both datasets.
"
1279,A Pixel-Based Framework for Data-Driven Clothing,"  With the aim of creating virtual cloth deformations more similar to real
world clothing, we propose a new computational framework that recasts three
dimensional cloth deformation as an RGB image in a two dimensional pattern
space. Then a three dimensional animation of cloth is equivalent to a sequence
of two dimensional RGB images, which in turn are driven/choreographed via
animation parameters such as joint angles. This allows us to leverage popular
CNNs to learn cloth deformations in image space. The two dimensional cloth
pixels are extended into the real world via standard body skinning techniques,
after which the RGB values are interpreted as texture offsets and displacement
maps. Notably, we illustrate that our approach does not require accurate
unclothed body shapes or robust skinning techniques. Additionally, we discuss
how standard image based techniques such as image partitioning for higher
resolution, GANs for merging partitioned image regions back together, etc., can
readily be incorporated into our framework.
"
1280,Photo Wake-Up: 3D Character Animation from a Single Photo,"  We present a method and application for animating a human subject from a
single photo. E.g., the character can walk out, run, sit, or jump in 3D. The
key contributions of this paper are: 1) an application of viewing and animating
humans in single photos in 3D, 2) a novel 2D warping method to deform a posable
template body model to fit the person's complex silhouette to create an
animatable mesh, and 3) a method for handling partial self occlusions. We
compare to state-of-the-art related methods and evaluate results with human
studies. Further, we present an interactive interface that allows re-posing the
person in 3D, and an augmented reality setup where the animated 3D person can
emerge from the photo into the real world. We demonstrate the method on photos,
posters, and art.
"
1281,"Learning to Predict Image-based Rendering Artifacts with Respect to a
  Hidden Reference Image","  Image metrics predict the perceived per-pixel difference between a reference
image and its degraded (e. g., re-rendered) version. In several important
applications, the reference image is not available and image metrics cannot be
applied. We devise a neural network architecture and training procedure that
allows predicting the MSE, SSIM or VGG16 image difference from the distorted
image alone while the reference is not observed. This is enabled by two
insights: The first is to inject sufficiently many un-distorted natural image
patches, which can be found in arbitrary amounts and are known to have no
perceivable difference to themselves. This avoids false positives. The second
is to balance the learning, where it is carefully made sure that all image
errors are equally likely, avoiding false negatives. Surprisingly, we observe,
that the resulting no-reference metric, subjectively, can even perform better
than the reference-based one, as it had to become robust against
mis-alignments. We evaluate the effectiveness of our approach in an image-based
rendering context, both quantitatively and qualitatively. Finally, we
demonstrate two applications which reduce light field capture time and provide
guidance for interactive depth adjustment.
"
1282,"Visual Object Networks: Image Generation with Disentangled 3D
  Representation","  Recent progress in deep generative models has led to tremendous breakthroughs
in image generation. However, while existing models can synthesize
photorealistic images, they lack an understanding of our underlying 3D world.
We present a new generative model, Visual Object Networks (VON), synthesizing
natural images of objects with a disentangled 3D representation. Inspired by
classic graphics rendering pipelines, we unravel our image formation process
into three conditionally independent factors---shape, viewpoint, and
texture---and present an end-to-end adversarial learning framework that jointly
models 3D shapes and 2D images. Our model first learns to synthesize 3D shapes
that are indistinguishable from real shapes. It then renders the object's 2.5D
sketches (i.e., silhouette and depth map) from its shape under a sampled
viewpoint. Finally, it learns to add realistic texture to these 2.5D sketches
to generate natural images. The VON not only generates images that are more
realistic than state-of-the-art 2D image synthesis methods, but also enables
many 3D operations such as changing the viewpoint of a generated image, editing
of shape and texture, linear interpolation in texture and shape space, and
transferring appearance across different objects and viewpoints.
"
1283,Learning Implicit Fields for Generative Shape Modeling,"  We advocate the use of implicit fields for learning generative models of
shapes and introduce an implicit field decoder, called IM-NET, for shape
generation, aimed at improving the visual quality of the generated shapes. An
implicit field assigns a value to each point in 3D space, so that a shape can
be extracted as an iso-surface. IM-NET is trained to perform this assignment by
means of a binary classifier. Specifically, it takes a point coordinate, along
with a feature vector encoding a shape, and outputs a value which indicates
whether the point is outside the shape or not. By replacing conventional
decoders by our implicit decoder for representation learning (via IM-AE) and
shape generation (via IM-GAN), we demonstrate superior results for tasks such
as generative shape modeling, interpolation, and single-view 3D reconstruction,
particularly in terms of visual quality. Code and supplementary material are
available at https://github.com/czq142857/implicit-decoder.
"
1284,Analysis of tagging latency when comparing event-related potentials,"  Event-related potentials (ERPs) are very small voltage produced by the brain
in response to external stimulation. In order to detect and evaluate an ERP in
an ongoing electroencephalogram (EEG), it is necessary to tag the EEG with the
exact onset time of the stimulus. We define the latency as the delay between
the time the tagging command is sent and the detection of the stimulus on the
screen. Failing to control sequencing in the tagging pipeline causes problems
when interpreting latency, in particular when comparing ERPs generated from
stimuli displayed by different systems. In this work, we present number of
technical aspects which can influence latency such as the refresh rate of the
screen or the display of a stimulus at different screen location. A few
propositions are suggested to estimate and correct this latency.
"
1285,Unsupervised Deep Learning for Structured Shape Matching,"  We present a novel method for computing correspondences across 3D shapes
using unsupervised learning. Our method computes a non-linear transformation of
given descriptor functions, while optimizing for global structural properties
of the resulting maps, such as their bijectivity or approximate isometry. To
this end, we use the functional maps framework, and build upon the recent FMNet
architecture for descriptor learning. Unlike that approach, however, we show
that learning can be done in a purely \emph{unsupervised setting}, without
having access to any ground truth correspondences. This results in a very
general shape matching method that we call SURFMNet for Spectral Unsupervised
FMNet, and which can be used to establish correspondences within 3D shape
collections without any prior information. We demonstrate on a wide range of
challenging benchmarks, that our approach leads to state-of-the-art results
compared to the existing unsupervised methods and achieves results that are
comparable even to the supervised learning techniques. Moreover, our framework
is an order of magnitude faster, and does not rely on geodesic distance
computation or expensive post-processing.
"
1286,"Techniques for modeling a high-quality B-spline curves by S-polygons in
  a float format","  This article proposes a technique for the geometrically stable modeling of
high-degree B-spline curves based on S-polygon in a float format, which will
allow the accurate positioning of the end points of curves and the direction of
the tangent vectors. The method of shape approximation is described with the
purpose of providing geometrical proximity between the original and
approximating curve. The content of the notion of a harmonious, regular form of
B-spline curve's S-polygon in a float format is revealed as a factor in
achieving a high-quality of fit for the generated curve. The expediency of the
shape modeling method based on S-polygon in a float format at the end portions
of the curve for quality control of curve modeling and editing is
substantiated. The results of a comparative test are presented, demonstrating
the superlative efficacy of using the Mineur-Farin configuration for
constructing constant and monotone curvature curves based on an S-polygon in a
float format. The findings presented in this article confirm that it is
preferable to employ the principle of ""constructing a control polygon of a
harmonious form (or the Mineur-Farin configuration) of a parametric polynomial""
to a B-spline curve's S-polygon in a float format, and not to a B-polygon of
the Bezier curve. Recommendations are given for prospective studies in the
field of applying the technique of constructing a high-quality B-spline curves
to the approximation of log-aesthetic curves, Ziatdinov's superspirals, etc.
The authors of the article developed a technique for constructing smooth
connections of B-spline curves with ensuring a high order of smoothness of the
composite curve. The proposed techniques are implemented in the
FairCurveModeler program as a plug-in to engineering CAD systems.
"
1287,Antara: An Interactive 3D Volume Rendering and Visualization Framework,"  The goal of 3D visualization is to provide the user with an intuitive
interface which enables him to explore the 3D data in an interactive manner.
The aim of the exploration is to identify and analyze anomalies or to give
proof of the non-anomaly of the visualized organic structures. For 3D Medical
Data, Magnetic Resonance Images (MRI) has been used. To create the 3D model, we
used the Direct Volume Rendering technique. In the input 3D data, we have $x,
y$ and $z$ coordinates and an intensity value for each voxel. The 3D data is
used by Volume Ray Casting to compute 2D projections from 3D volumetric data
sets. In ray casting, a ray of light is made to pass through the volume data.
The interaction of each voxel with this ray is used to assign RGB and alpha
values for every voxel in the volume. As a result, we are able to generate the
3D model of the region of interest using the 3D data. The 3D model is
interactive, thus enabling us to visualize the different layers of the 3D
volume by adjusting the transfer function.
"
1288,Analytic heuristics for a fast DSC-MRI,"  In this paper we propose a deterministic approach for the reconstruction of
Dynamic Susceptibility Contrast magnetic resonance imaging data and compare it
with the compressed sensing solution existing in the literature for the same
problem. Our study is based on the mathematical analysis of the problem, which
is computationally intractable because of its non polynomial complexity, but
suggests simple heuristics that perform quite well. We give results on real
images and on artificial phantoms with added noise.
"
1289,Parallel and Scalable Heat Methods for Geodesic Distance Computation,"  In this paper, we propose a parallel and scalable approach for geodesic
distance computation on triangle meshes. Our key observation is that the
recovery of geodesic distance with the heat method from [Crane et al. 2013] can
be reformulated as optimization of its gradients subject to integrability,
which can be solved using an efficient first-order method that requires no
linear system solving and converges quickly. Afterward, the geodesic distance
is efficiently recovered by parallel integration of the optimized gradients in
breadth-first order. Moreover, we employ a similar breadth-first strategy to
derive a parallel Gauss-Seidel solver for the diffusion step in the heat
method. To further lower the memory consumption from gradient optimization on
faces, we also propose a formulation that optimizes the projected gradients on
edges, which reduces the memory footprint by about 50%. Our approach is
trivially parallelizable, with a low memory footprint that grows linearly with
respect to the model size. This makes it particularly suitable for handling
large models. Experimental results show that it can efficiently compute
geodesic distance on meshes with more than 200 million vertices on a desktop PC
with 128GB RAM, outperforming the original heat method and other
state-of-the-art geodesic distance solvers.
"
1290,ABC: A Big CAD Model Dataset For Geometric Deep Learning,"  We introduce ABC-Dataset, a collection of one million Computer-Aided Design
(CAD) models for research of geometric deep learning methods and applications.
Each model is a collection of explicitly parametrized curves and surfaces,
providing ground truth for differential quantities, patch segmentation,
geometric feature detection, and shape reconstruction. Sampling the parametric
descriptions of surfaces and curves allows generating data in different formats
and resolutions, enabling fair comparisons for a wide range of geometric
learning algorithms. As a use case for our dataset, we perform a large-scale
benchmark for estimation of surface normals, comparing existing data driven
methods and evaluating their performance against both the ground truth and
traditional normal estimation methods.
"
1291,"Embedding Bilateral Filter in Least Squares for Efficient
  Edge-preserving Image Smoothing","  Edge-preserving smoothing is a fundamental procedure for many computer vision
and graphic applications. This can be achieved with either local methods or
global methods. In most cases, global methods can yield superior performance
over local ones. However, local methods usually run much faster than global
ones. In this paper, we propose a new global method that embeds the bilateral
filter in the least squares model for efficient edge-preserving smoothing. The
proposed method can show comparable performance with the state-of-the-art
global method. Meanwhile, since the proposed method can take advantages of the
efficiency of the bilateral filter and least squares model, it runs much
faster. In addition, we show the flexibility of our method which can be easily
extended by replacing the bilateral filter with its variants. They can be
further modified to handle more applications. We validate the effectiveness and
efficiency of the proposed method through comprehensive experiments in a range
of applications.
"
1292,"cellPACKexplorer: Interactive Model Building for Volumetric Data of
  Complex Cells","  Given an algorithm the quality of the output largely depends on a proper
specification of the input parameters. A lot of work has been done to analyze
tasks related to using a fixed model [25] and finding a good set of inputs. In
this paper we present a different scenario, model building. In contrast to
model usage the underlying algorithm, i.e. the underlying model, changes and
therefore the associated parameters also change. Developing a new algorithm
requires a particular set of parameters that, on the one hand, give access to
an expected range of outputs and, on the other hand, are still interpretable.
As the model is developed and parameters are added, deleted, or changed
different features of the outputs are of interest. Therefore it is important to
find objective measures that quantify these features. In a model building
process these features are prone to change and need to be adaptable as the
model changes. We discuss these problems in the application of cellPACK, a tool
that generates virtual 3D cells. Our analysis is based on an output set
generated by sampling the input parameter space. Hence we also present
techniques and metrics to analyze an ensemble of probabilistic volumes.
"
1293,Learning Direct Optimization for Scene Understanding,"  We develop a Learning Direct Optimization (LiDO) method for the refinement of
a latent variable model that describes input image x. Our goal is to explain a
single image x with an interpretable 3D computer graphics model having scene
graph latent variables z (such as object appearance, camera position). Given a
current estimate of z we can render a prediction of the image g(z), which can
be compared to the image x. The standard way to proceed is then to measure the
error E(x, g(z)) between the two, and use an optimizer to minimize the error.
However, it is unknown which error measure E would be most effective for
simultaneously addressing issues such as misaligned objects, occlusions,
textures, etc. In contrast, the LiDO approach trains a Prediction Network to
predict an update directly to correct z, rather than minimizing the error with
respect to z. Experiments show that our LiDO method converges rapidly as it
does not need to perform a search on the error landscape, produces better
solutions than error-based competitors, and is able to handle the mismatch
between the data and the fitted scene model. We apply LiDO to a realistic
synthetic dataset, and show that the method also transfers to work well with
real images.
"
1294,"Training on Art Composition Attributes to Influence CycleGAN Art
  Generation","  I consider how to influence CycleGAN, image-to-image translation, by using
additional constraints from a neural network trained on art composition
attributes. I show how I trained the the Art Composition Attributes Network
(ACAN) by incorporating domain knowledge based on the rules of art evaluation
and the result of applying each art composition attribute to apple2orange image
translation.
"
1295,Animating Arbitrary Objects via Deep Motion Transfer,"  This paper introduces a novel deep learning framework for image animation.
Given an input image with a target object and a driving video sequence
depicting a moving object, our framework generates a video in which the target
object is animated according to the driving sequence. This is achieved through
a deep architecture that decouples appearance and motion information. Our
framework consists of three main modules: (i) a Keypoint Detector unsupervisely
trained to extract object keypoints, (ii) a Dense Motion prediction network for
generating dense heatmaps from sparse keypoints, in order to better encode
motion information and (iii) a Motion Transfer Network, which uses the motion
heatmaps and appearance information extracted from the input image to
synthesize the output frames. We demonstrate the effectiveness of our method on
several benchmark datasets, spanning a wide variety of object appearances, and
show that our approach outperforms state-of-the-art image animation and video
generation methods. Our source code is publicly available.
"
1296,"The algorithm of formation of a training set for an artificial neural
  network for image segmentation","  This article suggests an algorithm of formation a training set for artificial
neural network in case of image segmentation. The distinctive feature of this
algorithm is that it using only one image for segmentation. The segmentation
performs using three-layer perceptron. The main method of the segmentation is a
method of region growing. Neural network is using for get a decision to include
pixel into an area or not. Impulse noise is using for generation of a training
set. Pixels damaged by noise are not related to the same region. Suggested
method has been tested with help of computer experiment in automatic and
interactive modes.
"
1297,Perceptual deep depth super-resolution,"  RGBD images, combining high-resolution color and lower-resolution depth from
various types of depth sensors, are increasingly common. One can significantly
improve the resolution of depth maps by taking advantage of color information;
deep learning methods make combining color and depth information particularly
easy. However, fusing these two sources of data may lead to a variety of
artifacts. If depth maps are used to reconstruct 3D shapes, e.g., for virtual
reality applications, the visual quality of upsampled images is particularly
important. The main idea of our approach is to measure the quality of depth map
upsampling using renderings of resulting 3D surfaces. We demonstrate that a
simple visual appearance-based loss, when used with either a trained CNN or
simply a deep prior, yields significantly improved 3D shapes, as measured by a
number of existing perceptual metrics. We compare this approach with a number
of existing optimization and learning-based techniques.
"
1298,"The algorithm of the impulse noise filtration in images based on an
  algorithm of community detection in graphs","  This article suggests an algorithm of impulse noise filtration, based on the
community detection in graphs. The image is representing as non-oriented
weighted graph. Each pixel of an image is corresponding to a vertex of the
graph. Community detection algorithm is running on the given graph. Assumed
that communities that contain only one pixel are corresponding to noised pixels
of an image. Suggested method was tested with help of computer experiment. This
experiment was conducted on grayscale, and on colored images, on artificial
images and on photos. It is shown that the suggested method is better than
median filter by 20% regardless of noise percent. Higher efficiency is
justified by the fact that most of filters are changing all of image pixels,
but suggested method is finding and restoring only noised pixels. The
dependence of the effectiveness of the proposed method on the percentage of
noise in the image is shown.
"
1299,A Survey on Non-rigid 3D Shape Analysis,"  Shape is an important physical property of natural and manmade 3D objects
that characterizes their external appearances. Understanding differences
between shapes and modeling the variability within and across shape classes,
hereinafter referred to as \emph{shape analysis}, are fundamental problems to
many applications, ranging from computer vision and computer graphics to
biology and medicine. This chapter provides an overview of some of the recent
techniques that studied the shape of 3D objects that undergo non-rigid
deformations including bending and stretching. Recent surveys that covered some
aspects such classification, retrieval, recognition, and rigid or nonrigid
registration, focused on methods that use shape descriptors. Descriptors,
however, provide abstract representations that do not enable the exploration of
shape variability. In this chapter, we focus on recent techniques that treated
the shape of 3D objects as points in some high dimensional space where paths
describe deformations. Equipping the space with a suitable metric enables the
quantification of the range of deformations of a given shape, which in turn
enables (1) comparing and classifying 3D objects based on their shape, (2)
computing smooth deformations, i.e. geodesics, between pairs of objects, and
(3) modeling and exploring continuous shape variability in a collection of 3D
models. This article surveys and classifies recent developments in this field,
outlines fundamental issues, discusses their potential applications in computer
vision and graphics, and highlights opportunities for future research. Our
primary goal is to bridge the gap between various techniques that have been
often independently proposed by different communities including mathematics and
statistics, computer vision and graphics, and medical image analysis.
"
1300,"Derivation of an Algorithm for Calculation of the Intersection Area of a
  Circle with a Grid with Finite Fill Factor","  The problem deals with an exact calculation of the intersection area of a
circle arbitrary placed on a grid of square shaped elements with gaps between
them (finite fill factor). Usually an approximation is used for the calculation
of the intersection area of the circle and the squares of the grid. We analyze
the geometry of the problem and derive an algorithm for the exact computation
of the intersection areas. The results of the analysis are summarized in the
tally sheet. In a real world example this might be a CCD or CMOS chip, or the
tile structure of a floor.
"
1301,Eyes on the Prize: Improved Registration via Forward Propagation,"  We develop a robust method for improving pairwise correspondences for a
collection of shapes in a metric space. Given a collection $f_{ji}: S_{i} \to
S_{j}$ of correspondences, we use a simple metric condition, which has a
natural interpretation when considering the analogy of parallel transport, to
construct a Gibbs measure on the space of correspondences between any pair of
shapes that are generated by the $f_{ji}.$ We demonstrate that this measure can
be used to more accurately compute correspondences between feature points
compared to currently employed, less robust methods. As an application, we use
our results to propose a novel method for computing homeomorphisms between
pairs of shapes that are similar to one another after alignment.
"
1302,Sampling Using Neural Networks for colorizing the grayscale images,"  The main idea of this paper is to explore the possibilities of generating
samples from the neural networks, mostly focusing on the colorization of the
grey-scale images. I will compare the existing methods for colorization and
explore the possibilities of using new generative modeling to the task of
colorization. The contributions of this paper are to compare the existing
structures with similar generating structures(Decoders) and to apply the novel
structures including Conditional VAE(CVAE), Conditional Wasserstein GAN with
Gradient Penalty(CWGAN-GP), CWGAN-GP with L1 reconstruction loss, Adversarial
Generative Encoders(AGE) and Introspective VAE(IVAE). I trained these models
using CIFAR-10 images. To measure the performance, I use Inception Score(IS)
which measures how distinctive each image is and how diverse overall samples
are as well as human eyes for CIFAR-10 images. It turns out that CVAE with L1
reconstruction loss and IVAE achieve the highest score in IS. CWGAN-GP with L1
tends to learn faster than CWGAN-GP, but IS does not increase from CWGAN-GP.
CWGAN-GP tends to generate more diverse images than other models using
reconstruction loss. Also, I figured out that the proper regularization plays a
vital role in generative modeling.
"
1303,Rendu bas\'e image avec contraintes sur les gradients,"  Multi-view image-based rendering consists in generating a novel view of a
scene from a set of source views. In general, this works by first doing a
coarse 3D reconstruction of the scene, and then using this reconstruction to
establish correspondences between source and target views, followed by blending
the warped views to get the final image. Unfortunately, discontinuities in the
blending weights, due to scene geometry or camera placement, result in
artifacts in the target view. In this paper, we show how to avoid these
artifacts by imposing additional constraints on the image gradients of the
novel view. We propose a variational framework in which an energy functional is
derived and optimized by iteratively solving a linear system. We demonstrate
this method on several structured and unstructured multi-view datasets, and
show that it numerically outperforms state-of-the-art methods, and eliminates
artifacts that result from visibility discontinuities
"
1304,"Singularity Structure Simplification of Hexahedral Mesh via Weighted
  Ranking","  In this paper, we propose an improved singularity structure simplification
method for hexahedral (hex) meshes using a weighted ranking approach. In
previous work, the selection of to-be-collapsed base complex sheets/chords is
only based on their thickness, which will introduce a few closed-loops and
cause an early termination of simplification and a slow convergence rate. In
this paper, a new weighted ranking function is proposed by combining the
valence prediction function of local singularity structure, shape quality
metric of elements and the width of base complex sheets/chords together.
Adaptive refinement and local optimization are also introduced to improve the
uniformity and aspect ratio of mesh elements. Compared to thickness ranking
methods, our weighted ranking approach can yield a simpler singularity
structure with fewer base-complex components, while achieving comparable
Hausdorff distance ratio and better mesh quality. Comparisons on a hex-mesh
dataset are performed to demonstrate the effectiveness of the proposed method.
"
1305,High-order curvilinear hybrid mesh generation for CFD simulations,"  We describe a semi-structured method for the generation of high-order hybrid
meshes suited for the simulation of high Reynolds number flows. This is
achieved through the use of highly stretched elements in the viscous boundary
layers near the wall surfaces. CADfix is used to first repair any possible
defects in the CAD geometry and then generate a medial object based
decomposition of the domain that wraps the wall boundaries with partitions
suitable for the generation of either prismatic or hexahedral elements. The
latter is a novel distinctive feature of the method that permits to obtain
well-shaped hexahedral meshes at corners or junctions in the boundary layer.
The medial object approach allows greater control on the ""thickness"" of the
boundary-layer mesh than is generally achievable with advancing layer
techniques. CADfix subsequently generates a hybrid straight sided mesh of
prismatic and hexahedral elements in the near-field region modelling the
boundary layer, and tetrahedral elements in the far-field region covering the
rest of the domain. The mesh in the near-field region provides a framework that
facilitates the generation, via an isoparametric technique, of layers of highly
stretched elements with a distribution of points in the direction normal to the
wall tailored to efficiently and accurately capture the flow in the boundary
layer. The final step is the generation of a high-order mesh using NekMesh, a
high-order mesh generator within the Nektar++ framework. NekMesh uses the
CADfix API as a geometry engine that handles all the geometrical queries to the
CAD geometry required during the high-order mesh generation process. We will
describe in some detail the methodology using a simple geometry, a NACA wing
tip, for illustrative purposes. Finally, we will present two examples of
application to reasonably complex geometries proposed by NASA as CFD validation
cases.
"
1306,"PointCleanNet: Learning to Denoise and Remove Outliers from Dense Point
  Clouds","  Point clouds obtained with 3D scanners or by image-based reconstruction
techniques are often corrupted with significant amount of noise and outliers.
Traditional methods for point cloud denoising largely rely on local surface
fitting (e.g., jets or MLS surfaces), local or non-local averaging, or on
statistical assumptions about the underlying noise model. In contrast, we
develop a simple data-driven method for removing outliers and reducing noise in
unordered point clouds. We base our approach on a deep learning architecture
adapted from PCPNet, which was recently proposed for estimating local 3D shape
properties in point clouds. Our method first classifies and discards outlier
samples, and then estimates correction vectors that project noisy points onto
the original clean surfaces. The approach is efficient and robust to varying
amounts of noise and outliers, while being able to handle large densely-sampled
point clouds. In our extensive evaluation, both on synthesic and real data, we
show an increased robustness to strong noise levels compared to various
state-of-the-art methods, enabling accurate surface reconstruction from
extremely noisy real data obtained by range scans. Finally, the simplicity and
universality of our approach makes it very easy to integrate in any existing
geometry processing pipeline.
"
1307,"Generic Primitive Detection in Point Clouds Using Novel Minimal Quadric
  Fits","  We present a novel and effective method for detecting 3D primitives in
cluttered, unorganized point clouds, without axillary segmentation or type
specification. We consider the quadric surfaces for encapsulating the basic
building blocks of our environments - planes, spheres, ellipsoids, cones or
cylinders, in a unified fashion. Moreover, quadrics allow us to model higher
degree of freedom shapes, such as hyperboloids or paraboloids that could be
used in non-rigid settings.
  We begin by contributing two novel quadric fits targeting 3D point sets that
are endowed with tangent space information. Based upon the idea of aligning the
quadric gradients with the surface normals, our first formulation is exact and
requires as low as four oriented points. The second fit approximates the first,
and reduces the computational effort. We theoretically analyze these fits with
rigor, and give algebraic and geometric arguments. Next, by re-parameterizing
the solution, we devise a new local Hough voting scheme on the null-space
coefficients that is combined with RANSAC, reducing the complexity from
$O(N^4)$ to $O(N^3)$ (three points). To the best of our knowledge, this is the
first method capable of performing a generic cross-type multi-object primitive
detection in difficult scenes without segmentation. Our extensive qualitative
and quantitative results show that our method is efficient and flexible, as
well as being accurate.
"
1308,"Modeling Data-Driven Dominance Traits for Virtual Characters using Gait
  Analysis","  We present a data-driven algorithm for generating gaits of virtual characters
with varying dominance traits. Our formulation utilizes a user study to
establish a data-driven dominance mapping between gaits and dominance labels.
We use our dominance mapping to generate walking gaits for virtual characters
that exhibit a variety of dominance traits while interacting with the user.
Furthermore, we extract gait features based on known criteria in visual
perception and psychology literature that can be used to identify the dominance
levels of any walking gait. We validate our mapping and the perceived dominance
traits by a second user study in an immersive virtual environment. Our gait
dominance classification algorithm can classify the dominance traits of gaits
with ~73% accuracy. We also present an application of our approach that
simulates interpersonal relationships between virtual characters. To the best
of our knowledge, ours is the first practical approach to classifying gait
dominance and generate dominance traits in virtual characters.
"
1309,An Application of Manifold Learning in Global Shape Descriptors,"  With the rapid expansion of applied 3D computational vision, shape
descriptors have become increasingly important for a wide variety of
applications and objects from molecules to planets. Appropriate shape
descriptors are critical for accurate (and efficient) shape retrieval and 3D
model classification. Several spectral-based shape descriptors have been
introduced by solving various physical equations over a 3D surface model. In
this paper, for the first time, we incorporate a specific group of techniques
in statistics and machine learning, known as manifold learning, to develop a
global shape descriptor in the computer graphics domain. The proposed
descriptor utilizes the Laplacian Eigenmap technique in which the Laplacian
eigenvalue problem is discretized using an exponential weighting scheme. As a
result, our descriptor eliminates the limitations tied to the existing spectral
descriptors, namely dependency on triangular mesh representation and high
intra-class quality of 3D models. We also present a straightforward
normalization method to obtain a scale-invariant descriptor. The extensive
experiments performed in this study show that the present contribution provides
a highly discriminative and robust shape descriptor under the presence of a
high level of noise, random scale variations, and low sampling rate, in
addition to the known isometric-invariance property of the Laplace-Beltrami
operator. The proposed method significantly outperforms state-of-the-art
algorithms on several non-rigid shape retrieval benchmarks.
"
1310,Collaborative 3D modeling system based on blockchain,"  We propose a collaborative 3D modeling system, which is based on the
blockchain technology. Our approach uses the blockchain to communicate with
modeling tools and to provide them a decentralized database of the mesh
modification history. This approach also provides a server-less version control
system: users can commit their modifications to the blockchain and checkout
others' modifications from the blockchain. As a result, our system enables
users to do collaborative modeling without any central server.
"
1311,An Elastic Energy Minimization Framework for Mean Contour Calculation,"  In this paper we propose a contour mean calculation and interpolation method
designed for averaging manual delineations of objects performed by experts and
interpolate 3D layer stack images. The proposed method retains all visible
information of the input contour set: the relative positions, orientations and
size, but allows invisible quantities - parameterization and the centroid - to
be changed. The chosen representation space - the position vector rescaled by
square root velocity - is a real valued vector space on which the imposed L2
metric is used to define the distance function. With respect to this
representation the re-parameterization group acts by isometries and the
distance has well defined meaning: the sum of the central second moments of the
coordinate functions. To identify the optimal re-parameterization system and
proper centroid we use double energy minimization realized in a variational
framework.
"
1312,Learning to Infer and Execute 3D Shape Programs,"  Human perception of 3D shapes goes beyond reconstructing them as a set of
points or a composition of geometric primitives: we also effortlessly
understand higher-level shape structure such as the repetition and reflective
symmetry of object parts. In contrast, recent advances in 3D shape sensing
focus more on low-level geometry but less on these higher-level relationships.
In this paper, we propose 3D shape programs, integrating bottom-up recognition
systems with top-down, symbolic program structure to capture both low-level
geometry and high-level structural priors for 3D shapes. Because there are no
annotations of shape programs for real shapes, we develop neural modules that
not only learn to infer 3D shape programs from raw, unannotated shapes, but
also to execute these programs for shape reconstruction. After initial
bootstrapping, our end-to-end differentiable model learns 3D shape programs by
reconstructing shapes in a self-supervised manner. Experiments demonstrate that
our model accurately infers and executes 3D shape programs for highly complex
shapes from various categories. It can also be integrated with an
image-to-shape module to infer 3D shape programs directly from an RGB image,
leading to 3D shape reconstructions that are both more accurate and more
physically plausible.
"
1313,Stroke-based sketched symbol reconstruction and segmentation,"  Hand-drawn objects usually consist of multiple semantically meaningful parts.
For example, a stick figure consists of a head, a torso, and pairs of legs and
arms. Efficient and accurate identification of these subparts promises to
significantly improve algorithms for stylization, deformation, morphing and
animation of 2D drawings. In this paper, we propose a neural network model that
segments symbols into stroke-level components. Our segmentation framework has
two main elements: a fixed feature extractor and a Multilayer Perceptron (MLP)
network that identifies a component based on the feature. As the feature
extractor we utilize an encoder of a stroke-rnn, which is our newly proposed
generative Variational Auto-Encoder (VAE) model that reconstructs symbols on a
stroke by stroke basis. Experiments show that a single encoder could be reused
for segmenting multiple categories of sketched symbols with negligible effects
on segmentation accuracies. Our segmentation scores surpass existing
methodologies on an available small state of the art dataset. Moreover,
extensive evaluations on our newly annotated big dataset demonstrate that our
framework obtains significantly better accuracies as compared to baseline
models. We release the dataset to the community.
"
1314,"A Fully Bayesian Infinite Generative Model for Dynamic Texture
  Segmentation","  Generative dynamic texture models (GDTMs) are widely used for dynamic texture
(DT) segmentation in the video sequences. GDTMs represent DTs as a set of
linear dynamical systems (LDSs). A major limitation of these models concerns
the automatic selection of a proper number of DTs. Dirichlet process mixture
(DPM) models which have appeared recently as the cornerstone of the
non-parametric Bayesian statistics, is an optimistic candidate toward resolving
this issue. Under this motivation to resolve the aforementioned drawback, we
propose a novel non-parametric fully Bayesian approach for DT segmentation,
formulated on the basis of a joint DPM and GDTM construction. This interaction
causes the algorithm to overcome the problem of automatic segmentation
properly. We derive the Variational Bayesian Expectation-Maximization (VBEM)
inference for the proposed model. Moreover, in the E-step of inference, we
apply Rauch-Tung-Striebel smoother (RTSS) algorithm on Variational Bayesian
LDSs. Ultimately, experiments on different video sequences are performed.
Experiment results indicate that the proposed algorithm outperforms the
previous methods in efficiency and accuracy noticeably.
"
1315,Joint Stabilization and Direction of 360\deg Videos,"  360{\deg} video provides an immersive experience for viewers, allowing them
to freely explore the world by turning their head. However, creating
high-quality 360{\deg} video content can be challenging, as viewers may miss
important events by looking in the wrong direction, or they may see things that
ruin the immersion, such as stitching artifacts and the film crew. We take
advantage of the fact that not all directions are equally likely to be
observed; most viewers are more likely to see content located at ``true
north'', i.e. in front of them, due to ergonomic constraints. We therefore
propose 360{\deg} video direction, where the video is jointly optimized to
orient important events to the front of the viewer and visual clutter behind
them, while producing smooth camera motion. Unlike traditional video, viewers
can still explore the space as desired, but with the knowledge that the most
important content is likely to be in front of them. Constraints can be user
guided, either added directly on the equirectangular projection or by recording
``guidance'' viewing directions while watching the video in a VR headset, or
automatically computed, such as via visual saliency or forward motion
direction. To accomplish this, we propose a new motion estimation technique
specifically designed for 360{\deg} video which outperforms the commonly used
5-point algorithm on wide angle video. We additionally formulate the direction
problem as an optimization where a novel parametrization of spherical warping
allows us to correct for some degree of parallax effects. We compare our
approach to recent methods that address stabilization-only and converting
360{\deg} video to narrow field-of-view video.
"
1316,PointWise: An Unsupervised Point-wise Feature Learning Network,"  We present a novel approach to learning a point-wise, meaningful embedding
for point-clouds in an unsupervised manner, through the use of neural-networks.
The domain of point-cloud processing via neural-networks is rapidly evolving,
with novel architectures and applications frequently emerging. Within this
field of research, the availability and plethora of unlabeled point-clouds as
well as their possible applications make finding ways of characterizing this
type of data appealing. Though significant advancement was achieved in the
realm of unsupervised learning, its adaptation to the point-cloud
representation is not trivial. Previous research focuses on the embedding of
entire point-clouds representing an object in a meaningful manner. We present a
deep learning framework to learn point-wise description from a set of shapes
without supervision. Our approach leverages self-supervision to define a
relevant loss function to learn rich per-point features. We train a
neural-network with objectives based on context derived directly from the raw
data, with no added annotation. We use local structures of point-clouds to
incorporate geometric information into each point's latent representation. In
addition to using local geometric information, we encourage adjacent points to
have similar representations and vice-versa, creating a smoother, more
descriptive representation. We demonstrate the ability of our method to capture
meaningful point-wise features through three applications. By clustering the
learned embedding space, we perform unsupervised part-segmentation on point
clouds. By calculating euclidean distance in the latent space we derive
semantic point-analogies. Finally, by retrieving nearest-neighbors in our
learned latent space we present meaningful point-correspondence within and
among point-clouds.
"
1317,Image Synthesis and Style Transfer,"  Affine transformation, layer blending, and artistic filters are popular
processes that graphic designers employ to transform pixels of an image to
create a desired effect. Here, we examine various approaches that synthesize
new images: pixel-based compositing models and in particular, distributed
representations of deep neural network models. This paper focuses on
synthesizing new images from a learned representation model obtained from the
VGG network. This approach offers an interesting creative process from its
distributed representation of information in hidden layers of a deep VGG
network i.e., information such as contour, shape, etc. are effectively captured
in hidden layers of neural networks. Conceptually, if $\Phi$ is the function
that transforms input pixels into distributed representations of VGG layers
${\bf h}$, a new synthesized image $X$ can be generated from its inverse
function, $X = \Phi^{-1}({\bf h})$. We describe the concept behind the
approach, present some representative synthesized images and style-transferred
image examples.
"
1318,Computational Fluid Dynamics on 3D Point Set Surfaces,"  Computational fluid dynamics (CFD) in many cases requires designing 3D models
manually, which is a tedious task that requires specific skills. In this paper,
we present a novel method for performing CFD directly on scanned 3D point
clouds. The proposed method builds an anisotropic volumetric tetrahedral mesh
adapted around a point-sampled surface, without an explicit surface
reconstruction step. The surface is represented by a new extended implicit
moving least squares (EIMLS) scalar representation that extends the definition
of the function to the entire computational domain, which makes it possible for
use in immersed boundary flow simulations. The workflow we present allows us to
compute flows around point-sampled geometries automatically. It also gives a
better control of the precision around the surface with a limited number of
computational nodes, which is a critical issue in CFD.
"
1319,"A novel 3D display based on micro-volumetric scanning and real time
  reconstruction of holograms principle","  The present study proposes a novel 3D display contains a micro-volumetric
scanning system (MVS) and a real time reconstruction hologram system (RTRH).
"
1320,"Massively Parallel Construction of Radix Tree Forests for the Efficient
  Sampling of Discrete Probability Distributions","  We compare different methods for sampling from discrete probability
distributions and introduce a new algorithm which is especially efficient on
massively parallel processors, such as GPUs. The scheme preserves the
distribution properties of the input sequence, exposes constant time complexity
on the average, and significantly lowers the average number of operations for
certain distributions when sampling is performed in a parallel algorithm that
requires synchronization afterwards. Avoiding load balancing issues of na\""ive
approaches, a very efficient massively parallel construction algorithm for the
required auxiliary data structure is complemented.
"
1321,Computational Design of Lightweight Trusses,"  Trusses are load-carrying light-weight structures consisting of bars
connected at joints ubiquitously applied in a variety of engineering scenarios.
Designing optimal trusses that satisfy functional specifications with a minimal
amount of material has interested both theoreticians and practitioners for more
than a century. In this paper, we introduce two main ideas to improve upon the
state of the art. First, we formulate an alternating linear programming problem
for geometry optimization. Second, we introduce two sets of complementary
topological operations, including a novel subdivision scheme for global
topology refinement inspired by Michell's famed theoretical study. Based on
these two ideas, we build an efficient computational framework for the design
of lightweight trusses. \AD{We illustrate our framework with a variety of
functional specifications and extensions. We show that our method achieves
trusses with smaller volumes and is over two orders of magnitude faster
compared with recent state-of-the-art approaches.
"
1322,High-speed Video from Asynchronous Camera Array,"  This paper presents a method for capturing high-speed video using an
asynchronous camera array. Our method sequentially fires each sensor in a
camera array with a small time offset and assembles captured frames into a
high-speed video according to the time stamps. The resulting video, however,
suffers from parallax jittering caused by the viewpoint difference among
sensors in the camera array. To address this problem, we develop a dedicated
novel view synthesis algorithm that transforms the video frames as if they were
captured by a single reference sensor. Specifically, for any frame from a
non-reference sensor, we find the two temporally neighboring frames captured by
the reference sensor. Using these three frames, we render a new frame with the
same time stamp as the non-reference frame but from the viewpoint of the
reference sensor. Specifically, we segment these frames into super-pixels and
then apply local content-preserving warping to warp them to form the new frame.
We employ a multi-label Markov Random Field method to blend these warped
frames. Our experiments show that our method can produce high-quality and
high-speed video of a wide variety of scenes with large parallax, scene
dynamics, and camera motion and outperforms several baseline and
state-of-the-art approaches.
"
1323,Good Similar Patches for Image Denoising,"  Patch-based denoising algorithms like BM3D have achieved outstanding
performance. An important idea for the success of these methods is to exploit
the recurrence of similar patches in an input image to estimate the underlying
image structures. However, in these algorithms, the similar patches used for
denoising are obtained via Nearest Neighbour Search (NNS) and are sometimes not
optimal. First, due to the existence of noise, NNS can select similar patches
with similar noise patterns to the reference patch. Second, the unreliable
noisy pixels in digital images can bring a bias to the patch searching process
and result in a loss of color fidelity in the final denoising result. We
observe that given a set of good similar patches, their distribution is not
necessarily centered at the noisy reference patch and can be approximated by a
Gaussian component. Based on this observation, we present a patch searching
method that clusters similar patch candidates into patch groups using Gaussian
Mixture Model-based clustering, and selects the patch group that contains the
reference patch as the final patches for denoising. We also use an unreliable
pixel estimation algorithm to pre-process the input noisy images to further
improve the patch searching. Our experiments show that our approach can better
capture the underlying patch structures and can consistently enable the
state-of-the-art patch-based denoising algorithms, such as BM3D, LPCA and PLOW,
to better denoise images by providing them with patches found by our approach
while without modifying these algorithms.
"
1324,Metasurfaces for near-eye augmented reality,"  Augmented reality (AR) has the potential to revolutionize the way in which
information is presented by overlaying virtual information onto a person's
direct view of their real-time surroundings. By placing the display on the
surface of the eye, a contact lens display (CLD) provides a versatile solution
for compact AR. However, an unaided human eye cannot visualize patterns on the
CLD simply because of the limited accommodation of the eye. Here, we introduce
a holographic display technology that casts virtual information directly to the
retina so that the eye sees it while maintaining the visualization of the
real-world intact. The key to our design is to introduce metasurfaces to create
a phase distribution that projects virtual information in a pixel-by-pixel
manner. Unlike conventional holographic techniques, our metasurface-based
technique is able to display arbitrary patterns using a single passive
hologram. With a small form-factor, the designed metasurface empowers near-eye
AR excluding the need of extra optical elements, such as a spatial light
modulator, for dynamic image control.
"
1325,Automatic normal orientation in point clouds of building interiors,"  Orienting surface normals correctly and consistently is a fundamental problem
in geometry processing. Applications such as visualization, feature detection,
and geometry reconstruction often rely on the availability of correctly
oriented normals. Many existing approaches for automatic orientation of normals
on meshes or point clouds make severe assumptions on the input data or the
topology of the underlying object which are not applicable to real-world
measurements of urban scenes. In contrast, our approach is specifically
tailored to the challenging case of unstructured indoor point cloud scans of
multi-story, multi-room buildings. We evaluate the correctness and speed of our
approach on multiple real-world point cloud datasets.
"
1326,"A Monte Carlo Framework for Rendering Speckle Statistics in Scattering
  Media","  We present a Monte Carlo rendering framework for the physically-accurate
simulation of speckle patterns arising from volumetric scattering of coherent
waves. These noise-like patterns are characterized by strong statistical
properties, such as the so-called memory effect, which are at the core of
imaging techniques for applications as diverse as tissue imaging, motion
tracking, and non-line-of-sight imaging. Our framework allows for these
properties to be replicated computationally, in a way that is orders of
magnitude more efficient than alternatives based on directly solving the wave
equations. At the core of our framework is a path-space formulation for the
covariance of speckle patterns arising from a scattering volume, which we
derive from first principles. We use this formulation to develop two Monte
Carlo rendering algorithms, for computing speckle covariance as well as
directly speckle fields. While approaches based on wave equation solvers
require knowing the microscopic position of wavelength-sized scatterers, our
approach takes as input only bulk parameters describing the statistical
distribution of these scatterers inside a volume. We validate the accuracy of
our framework by comparing against speckle patterns simulated using wave
equation solvers, use it to simulate memory effect observations that were
previously only possible through lab measurements, and demonstrate its
applicability for computational imaging tasks.
"
1327,"Generation High resolution 3D model from natural language by Generative
  Adversarial Network","  We present a method of generating high resolution 3D shapes from natural
language descriptions. To achieve this goal, we propose two steps that
generating low resolution shapes which roughly reflect texts and generating
high resolution shapes which reflect the detail of texts. In a previous paper,
the authors have shown a method of generating low resolution shapes. We improve
it to generate 3D shapes more faithful to natural language and test the
effectiveness of the method. To generate high resolution 3D shapes, we use the
framework of Conditional Wasserstein GAN. We propose two roles of Critic
separately, which calculate the Wasserstein distance between two probability
distribution, so that we achieve generating high quality shapes or acceleration
of learning speed of model. To evaluate our approach, we performed quantitive
evaluation with several numerical metrics for Critic models. Our method is
first to realize the generation of high quality model by propagating text
embedding information to high resolution task when generating 3D model.
"
1328,"Periodic-corrected data driven coupling of blood flow and vessel wall
  for virtual surgery","  Fast and realistic coupling of blood flow and vessel wall is of great
importance to virtual surgery. In this paper, we propose a novel data-driven
coupling method that formulates physics-based blood flow simulation as a
regression problem, using an improved periodic-corrected neural network
(PcNet), estimating the acceleration of every particle at each frame to obtain
fast, stable and realistic simulation. We design a particle state feature
vector based on smoothed particle hydrodynamics (SPH), modeling the mixed
contribution of neighboring proxy particles on the blood vessel wall and
neighboring blood particles, giving the extrapolation ability to deal with more
complex couplings. We present a semi-supervised training strategy to improve
the traditional BP neural network, which corrects the error periodically to
ensure long term stability. Experimental results demonstrate that our method is
able to implement stable and vivid coupling of blood flow and vessel wall while
greatly improving computational efficiency.
"
1329,"Spherical sampling methods for the calculation of metamer mismatch
  volumes","  In this paper, we propose two methods of calculating theoretically maximal
metamer mismatch volumes. Unlike prior art techniques, our methods do not make
any assumptions on the shape of spectra on the boundary of the mismatch
volumes. Both methods utilize a spherical sampling approach, but they calculate
mismatch volumes in two different ways. The first method uses a linear
programming optimization, while the second is a computational geometry approach
based on half-space intersection. We show that under certain conditions the
theoretically maximal metamer mismatch volume is significantly larger than the
one approximated using a prior art method.
"
1330,Cross-Domain Image Manipulation by Demonstration,"  In this work we propose a model that can manipulate individual visual
attributes of objects in a real scene using examples of how respective
attribute manipulations affect the output of a simulation. As an example, we
train our model to manipulate the expression of a human face using
nonphotorealistic 3D renders of a face with varied expression. Our model
manages to preserve all other visual attributes of a real face, such as head
orientation, even though this and other attributes are not labeled in either
real or synthetic domain. Since our model learns to manipulate a specific
property in isolation using only ""synthetic demonstrations"" of such
manipulations without explicitly provided labels, it can be applied to shape,
texture, lighting, and other properties that are difficult to measure or
represent as real-valued vectors. We measure the degree to which our model
preserves other attributes of a real image when a single specific attribute is
manipulated. We use digit datasets to analyze how discrepancy in attribute
distributions affects the performance of our model, and demonstrate results in
a far more difficult setting: learning to manipulate real human faces using
nonphotorealistic 3D renders.
"
1331,Volumetric Spline Parameterization for Isogeometric Analysis,"  Given the spline representation of the boundary of a three dimensional
domain, constructing a volumetric spline parameterization of the domain (i.e.,
a map from a unit cube to the domain) with the given boundary is a fundamental
problem in isogeometric analysis. A good domain parameterization should satisfy
the following criteria: (1) the parameterization is a bijective map; and (2)
the map has lowest possible distortion. However, none of the state-of-the-art
volumetric parameterization methods has fully addressed the above issues. In
this paper, we propose a three-stage approach for constructing volumetric
parameterization satisfying the above criteria. Firstly, a harmonic map is
computed between a unit cube and the computational domain. Then a bijective map
modeled by a max-min optimization problem is computed in a coarse-to-fine way,
and an algorithm based on divide and conquer strategy is proposed to solve the
optimization problem efficiently. Finally, to ensure high quality of the
parameterization, the MIPS (Most Isometric Parameterizations) method is adopted
to reduce the conformal distortion of the bijective map. We provide several
examples to demonstrate the feasibility of our approach and to compare our
approach with some state-of-the-art methods. The results show that our
algorithm produces bijective parameterization with high quality even for
complex domains.
"
1332,A Robust Volume Conserving Method for Character-Water Interaction,"  We propose a novel volume conserving framework for character-water
interaction, using a novel volume-of-fluid solver on a skinned tetrahedral
mesh, enabling the high degree of the spatial adaptivity in order to capture
thin films and hair-water interactions. For efficiency, the bulk of the fluid
volume is simulated with a standard Eulerian solver which is two way coupled to
our skinned arbitrary Lagrangian-Eulerian mesh using a fast, robust, and
straightforward to implement partitioned approach. This allows for a
specialized and efficient treatment of the volume-of-fluid solver, since it is
only required in a subset of the domain. The combination of conservation of
fluid volume and a kinematically deforming skinned mesh allows us to robustly
implement interesting effects such as adhesion, and anisotropic porosity. We
illustrate the efficacy of our method by simulating various water effects with
solid objects and animated characters.
"
1333,"Advances in the Treatment of Trimmed CAD Models due to Isogeometric
  Analysis","  Trimming is a core technique in geometric modeling. Unfortunately, the
resulting objects do not take the requirements of numerical simulations into
account and yield various problems. This paper outlines principal issues of
trimmed models and highlights different analysis-suitable strategies to address
them. It is discussed that these concepts not only provide important
computational tools for isogeometric analysis, but can also improve the
treatment of trimmed models in a design context.
"
1334,Diffeomorphic Medial Modeling,"  Deformable shape modeling approaches that describe objects in terms of their
medial axis geometry (e.g., m-reps [Pizer et al., 2003]) yield rich geometrical
features that can be useful for analyzing the shape of sheet-like biological
structures, such as the myocardium. We present a novel shape analysis approach
that combines the benefits of medial shape modeling and diffeomorphometry. Our
algorithm is formulated as a problem of matching shapes using diffeomorphic
flows under constraints that approximately preserve medial axis geometry during
deformation. As the result, correspondence between the medial axes of similar
shapes is maintained. The approach is evaluated in the context of modeling the
shape of the left ventricular wall from 3D echocardiography images.
"
1335,Automated pebble mosaic stylization of images,"  Digital mosaics have usually used regular tiles, simulating the historical
""tessellated"" mosaics. In this paper, we present a method for synthesizing
pebble mosaics, a historical mosaic style in which the tiles are rounded
pebbles. We address both the tiling problem, where pebbles are distributed over
the image plane so as to approximate the input image content, and the problem
of geometry, creating a smooth rounded shape for each pebble. We adapt SLIC,
simple linear iterative clustering, to obtain elongated tiles conforming to
image content, and smooth the resulting irregular shapes into shapes resembling
pebble cross-sections. Then, we create an interior and exterior contour for
each pebble and solve a Laplace equation over the region between them to obtain
height-field geometry. The resulting pebble set approximates the input image
while presenting full geometry that can be rendered and textured for a highly
detailed representation of a pebble mosaic.
"
1336,X3D in Urban Planning - Savannah in 3D,"  Urban planning often raises complex issues that are difficult to visualize
and challenging to communicate. The increasing availability of 3D modeling
standards has provided the opportunity for many developers, engineers,
designers, planners, investors, and government officials to effectively
collaborate to bring projects to fruition. Because of its real-time
interactivity and widespread web-based content players, X3D proves to be a good
choice for developing and visualizing 3D city content on the Web for planning
purposes.
  Passenger rail is a viable and cost-effective transportation solution in many
areas, especially in view of rising energy costs. The Savannah in 3D (or S3D)
project is a multimedia tool for a feasibility study designed to bring
passenger rail to Savannah; thereby opening up the historic, tourist-friendly
city to a wider audience. The paper outlines the development process of an
interactive 3D train model as it journeys from Atlanta to Savannah, Georgia -
focusing on user interactivity and scene immersion to supplement the city and
transportation planning agenda.
"
1337,"Metric Curvatures and their Applications 2: Metric Ricci Curvature and
  Flow","  In this second part of our overview of the different metric curvatures and
their various applications, we concentrate on the Ricci curvature and flow for
polyhedral surfaces and higher dimensional manifolds, and we largely review our
previous studies on the subject, based upon Wald's curvature. In addition to
our previous metric approaches to the discretization of Ricci curvature, we
consider yet another one, based on the Haantjes curvature, interpreted as a
geodesic curvature. We also try to understand the mathematical reasons behind
the recent proliferation of discretizations of Ricci curvature. Furthermore, we
propose another approach to the metrization of Ricci curvature, based on
Forman's discretization, and in particular we propose on that uses our graph
version of Forman's Ricci curvature.
"
1338,Puppet Dubbing,"  Dubbing puppet videos to make the characters (e.g. Kermit the Frog)
convincingly speak a new speech track is a popular activity with many examples
of well-known puppets speaking lines from films or singing rap songs. But
manually aligning puppet mouth movements to match a new speech track is tedious
as each syllable of the speech must match a closed-open-closed segment of mouth
movement for the dub to be convincing. In this work, we present two methods to
align a new speech track with puppet video, one semi-automatic appearance-based
and the other fully-automatic audio-based. The methods offer complementary
advantages and disadvantages. Our appearance-based approach directly identifies
closed-open-closed segments in the puppet video and is robust to low-quality
audio as well as misalignments between the mouth movements and speech in the
original performance, but requires some manual annotation. Our audio-based
approach assumes the original performance matches a closed-open-closed mouth
segment to each syllable of the original speech. It is fully automatic, robust
to visual occlusions and fast puppet movements, but does not handle
misalignments in the original performance. We compare the methods and show that
both improve the credibility of the resulting video over simple baseline
techniques, via quantitative evaluation and user ratings.
"
1339,Task-based Augmented Contour Trees with Fibonacci Heaps,"  This paper presents a new algorithm for the fast, shared memory, multi-core
computation of augmented contour trees on triangulations. In contrast to most
existing parallel algorithms our technique computes augmented trees, enabling
the full extent of contour tree based applications including data segmentation.
Our approach completely revisits the traditional, sequential contour tree
algorithm to re-formulate all the steps of the computation as a set of
independent local tasks. This includes a new computation procedure based on
Fibonacci heaps for the join and split trees, two intermediate data structures
used to compute the contour tree, whose constructions are efficiently carried
out concurrently thanks to the dynamic scheduling of task parallelism. We also
introduce a new parallel algorithm for the combination of these two trees into
the output global contour tree. Overall, this results in superior time
performance in practice, both in sequential and in parallel thanks to the
OpenMP task runtime. We report performance numbers that compare our approach to
reference sequential and multi-threaded implementations for the computation of
augmented merge and contour trees. These experiments demonstrate the run-time
efficiency of our approach and its scalability on common workstations. We
demonstrate the utility of our approach in data segmentation applications.
"
1340,"Petascale Cloud Supercomputing for Terapixel Visualization of a Digital
  Twin","  Background: Photo-realistic terapixel visualization is computationally
intensive and to date there have been no such visualizations of urban digital
twins, the few terapixel visualizations that exist have looked towards space
rather than earth. Objective: our aims are: creating a scalable cloud
supercomputer software architecture for visualization; a photo-realistic
terapixel 3D visualization of urban IoT data supporting daily updates; a
rigorous evaluation of cloud supercomputing for our application. Method: we
migrated the Blender Cycles path tracer to the public cloud within a new
software framework designed to scale to petaFLOP performance. Results: we
demonstrate we can compute a terapixel visualization in under one hour, the
system scaling at 98% efficiency to use 1024 public cloud GPU nodes delivering
14 petaFLOPS. The resulting terapixel image supports interactive browsing of
the city and its data at a wide range of sensing scales. Conclusion: The GPU
compute resource available in the cloud is greater than anything available on
our national supercomputers providing access to globally competitive resources.
The direct financial cost of access, compared to procuring and running these
systems, was low. The indirect cost, in overcoming teething issues with cloud
software development, should reduce significantly over time.
"
1341,Proximity Queries for Absolutely Continuous Parametric Curves,"  In motion planning problems for autonomous robots, such as self-driving cars,
the robot must ensure that its planned path is not in close proximity to
obstacles in the environment. However, the problem of evaluating the proximity
is generally non-convex and serves as a significant computational bottleneck
for motion planning algorithms. In this paper, we present methods for a general
class of absolutely continuous parametric curves to compute: (i) the minimum
separating distance, (ii) tolerance verification, and (iii) collision
detection. Our methods efficiently compute bounds on obstacle proximity by
bounding the curve in a convex region. This bound is based on an upper bound on
the curve arc length that can be expressed in closed form for a useful class of
parametric curves including curves with trigonometric or polynomial bases. We
demonstrate the computational efficiency and accuracy of our approach through
numerical simulations of several proximity problems.
"
1342,Realistic Image Generation using Region-phrase Attention,"  The Generative Adversarial Network (GAN) has recently been applied to
generate synthetic images from text. Despite significant advances, most current
state-of-the-art algorithms are regular-grid region based; when attention is
used, it is mainly applied between individual regular-grid regions and a word.
These approaches are sufficient to generate images that contain a single object
in its foreground, such as a ""bird"" or ""flower"". However, natural languages
often involve complex foreground objects and the background may also constitute
a variable portion of the generated image. Therefore, the regular-grid based
image attention weights may not necessarily concentrate on the intended
foreground region(s), which in turn, results in an unnatural looking image.
Additionally, individual words such as ""a"", ""blue"" and ""shirt"" do not
necessarily provide a full visual context unless they are applied together. For
this reason, in our paper, we proposed a novel method in which we introduced an
additional set of attentions between true-grid regions and word phrases. The
true-grid region is derived using a set of auxiliary bounding boxes. These
auxiliary bounding boxes serve as superior location indicators to where the
alignment and attention should be drawn with the word phrases. Word phrases are
derived from analysing Part-of-Speech (POS) results. We perform experiments on
this novel network architecture using the Microsoft Common Objects in Context
(MSCOCO) dataset and the model generates $256 \times 256$ conditioned on a
short sentence description. Our proposed approach is capable of generating more
realistic images compared with the current state-of-the-art algorithms.
"
1343,"Breaking the Spatio-Angular Trade-off for Light Field Super-Resolution
  via LSTM Modelling on Epipolar Plane Images","  Light-field cameras (LFC) have received increasing attention due to their
wide-spread applications. However, current LFCs suffer from the well-known
spatio-angular trade-off, which is considered as an inherent and fundamental
limit for LFC designs. In this paper, by doing a detailed geometrical optical
analysis of the sampling process in an LFC, we show that the effective sampling
resolution is generally higher than the number of micro-lenses. This
contribution makes it theoretically possible to break the resolution trade-off.
Our second contribution is an epipolar plane image (EPI) based super-resolution
method, which can super-resolve the spatial and angular dimensions
simultaneously. We prove that the light field is a 2D series, thus, a
specifically designed CNN-LSTM network is proposed to capture the continuity
property of the EPI. Rather than leveraging semantic information, our network
focuses on extracting geometric continuity in the EPI. This gives our method an
improved generalization ability and makes it applicable to a wide range of
previously unseen scenes. Experiments on both synthetic and real light fields
demonstrate the improvements over state-of-the-art, especially in large
disparity areas.
"
1344,"Global Perturbation of Initial Geometry in a Biomechanical Model of
  Cortical Morphogenesis","  Cortical folding pattern is a main characteristic of the geometry of the
human brain which is formed by gyri (ridges) and sulci (grooves). Several
biological hypotheses have suggested different mechanisms that attempt to
explain the development of cortical folding and its abnormal evolutions. Based
on these hypotheses, biomechanical models of cortical folding have been
proposed. In this work, we compare biomechanical simulations for several
initial conditions by using an adaptive spherical parameterization approach.
Our approach allows us to study and explore one of the most potential sources
of reproducible cortical folding pattern: the specification of initial geometry
of the brain.
"
1345,Massively Parallel Path Space Filtering,"  Restricting path tracing to a small number of paths per pixel for performance
reasons rarely achieves a satisfactory image quality for scenes of interest.
However, path space filtering may dramatically improve the visual quality by
sharing information across vertices of paths classified as proximate. Unlike
screen space-based approaches, these paths neither need to be present on the
screen, nor is filtering restricted to the first intersection with the scene.
While searching proximate vertices had been more expensive than filtering in
screen space, we greatly improve over this performance penalty by storing and
looking up the required information in a hash table. The keys are constructed
from jittered and quantized information, such that only a single query very
likely replaces costly neighborhood searches. A massively parallel
implementation of the algorithm is demonstrated on a GPU.
"
1346,Local Fourier Slice Photography,"  Light field cameras provide intriguing possibilities, such as post-capture
refocus or the ability to synthesize images from novel viewpoints. This comes,
however, at the price of significant storage requirements. Compression
techniques can be used to reduce these but refocusing and reconstruction
require so far again a dense pixel representation. To avoid this, we introduce
local Fourier slice photography that allows for refocused image reconstruction
directly from a sparse wavelet representation of a light field, either to
obtain an image or a compressed representation of it. The result is made
possible by wavelets that respect the ""slicing's"" intrinsic structure and
enable us to derive exact reconstruction filters for the refocused image in
closed form. Image reconstruction then amounts to applying these filters to the
light field's wavelet coefficients, and hence no reconstruction of a dense
pixel representation is required. We demonstrate that this substantially
reduces storage requirements and also computation times. We furthermore analyze
the computational complexity of our algorithm and show that it scales linearly
with the size of the reconstructed region and the non-negligible wavelet
coefficients, i.e. with the visual complexity.
"
1347,"A Comprehensive Theory and Variational Framework for Anti-aliasing
  Sampling Patterns","  In this paper, we provide a comprehensive theory of anti-aliasing sampling
patterns that explains and revises known results, and show how patterns as
predicted by the theory can be generated via a variational optimization
framework. We start by deriving the exact spectral expression for expected
error in reconstructing an image in terms of power spectra of sampling
patterns, and analyzing how the shape of power spectra is related to
anti-aliasing properties. Based on this analysis, we then formulate the problem
of generating anti-aliasing sampling patterns as constrained variational
optimization on power spectra. This allows us to not rely on any parametric
form, and thus explore the whole space of realizable spectra. We show that the
resulting optimized sampling patterns lead to reconstructions with less visible
aliasing artifacts, while keeping low frequencies as clean as possible.
"
1348,Parallel Rendering and Large Data Visualization,"  We are living in the big data age: An ever increasing amount of data is being
produced through data acquisition and computer simulations. While large scale
analysis and simulations have received significant attention for cloud and
high-performance computing, software to efficiently visualise large data sets
is struggling to keep up.
  Visualization has proven to be an efficient tool for understanding data, in
particular visual analysis is a powerful tool to gain intuitive insight into
the spatial structure and relations of 3D data sets. Large-scale visualization
setups are becoming ever more affordable, and high-resolution tiled display
walls are in reach even for small institutions. Virtual reality has arrived in
the consumer space, making it accessible to a large audience.
  This thesis addresses these developments by advancing the field of parallel
rendering. We formalise the design of system software for large data
visualization through parallel rendering, provide a reference implementation of
a parallel rendering framework, introduce novel algorithms to accelerate the
rendering of large amounts of data, and validate this research and development
with new applications for large data visualization. Applications built using
our framework enable domain scientists and large data engineers to better
extract meaning from their data, making it feasible to explore more data and
enabling the use of high-fidelity visualization installations to see more
detail of the data.
"
1349,VoroCrust: Voronoi Meshing Without Clipping,"  Polyhedral meshes are increasingly becoming an attractive option with
particular advantages over traditional meshes for certain applications. What
has been missing is a robust polyhedral meshing algorithm that can handle broad
classes of domains exhibiting arbitrarily curved boundaries and sharp features.
In addition, the power of primal-dual mesh pairs, exemplified by
Voronoi-Delaunay meshes, has been recognized as an important ingredient in
numerous formulations. The VoroCrust algorithm is the first provably-correct
algorithm for conforming polyhedral Voronoi meshing for non-convex and
non-manifold domains with guarantees on the quality of both surface and volume
elements. A robust refinement process estimates a suitable sizing field that
enables the careful placement of Voronoi seeds across the surface circumventing
the need for clipping and avoiding its many drawbacks. The algorithm has the
flexibility of filling the interior by either structured or random samples,
while preserving all sharp features in the output mesh. We demonstrate the
capabilities of the algorithm on a variety of models and compare against
state-of-the-art polyhedral meshing methods based on clipped Voronoi cells
establishing the clear advantage of VoroCrust output.
"
1350,"HMLFC: Hierarchical Motion-Compensated Light Field Compression for
  Interactive Rendering","  We present a new motion-compensated hierarchical compression scheme (HMLFC)
for encoding light field images (LFI) that is suitable for interactive
rendering. Our method combines two different approaches, motion compensation
schemes and hierarchical compression methods, to exploit redundancies in LFI.
The motion compensation schemes capture the redundancies in local regions of
the LFI efficiently (local coherence) and hierarchical schemes capture the
redundancies present across the entire LFI (global coherence). Our hybrid
approach combines the two schemes effectively capturing both local as well as
global coherence to improve the overall compression rate. We compute a tree
from LFI using a hierarchical scheme and use phase shifted motion compensation
techniques at each level of the hierarchy. Our representation provides random
access to the pixel values of the light field, which makes it suitable for
interactive rendering applications using a small run-time memory footprint. Our
approach is GPU friendly and allows parallel decoding of LF pixel values. We
highlight the performance on the two-plane parameterized light fields and
obtain a compression ratio of 30-800X with a PSNR of 40-45 dB. Overall, we
observe a 2-5X improvement in compression rates using HMLFC over prior light
field compression schemes that provide random access capability. In practice,
our algorithm can render new views of resolution 512X512 on an NVIDIA GTX-980
at ~200 fps.
"
1351,Chromatic Adaptation Transform by Spectral Reconstruction (Preprint),"  A color appearance model (CAM) is an advanced colorimetric tool used to
predict color appearance under a wide variety of viewing conditions. A
chromatic adaptation transform (CAT) is an integral part of a CAM. Its role is
to predict ""corresponding colors,"" that is, a pair of colors that have the same
color appearance when viewed under different illuminants, after partial or full
adaptation to each illuminant. Modern CATs perform well when applied to a
limited range of illuminant pairs and a limited range of source (test) colors.
However, they can fail if operated outside these ranges. For imaging
applications, it is important to have a CAT that can operate on any real color
and illuminant pair without failure. This paper proposes a new CAT that does
not operate on the standard von Kries model of adaptation. Instead it relies on
spectral reconstruction and how these reconstructions behave with respect to
different illuminants. It is demonstrated that the proposed CAT is immune to
some of the limitations of existing CATs (such as producing colors with
negative tristimulus values). The proposed CAT does not use established
empirical corresponding-color datasets to optimize performance, as most modern
CATs do, yet it performs as well as or better than the most recent CATs when
tested against the corresponding-color datasets. This increase in robustness
comes at the expense of additional complexity and computational effort. If
robustness is of prime importance, then the proposed method may be justifiable.
"
1352,"Usage of analytic hierarchy process for steganographic inserts detection
  in images","  This article presents the method of steganography detection, which is formed
by replacing the least significant bit (LSB). Detection is performed by
dividing the image into layers and making an analysis of zero-layer of adjacent
bits for every bit. First-layer and second-layer are analyzed too. Hierarchies
analysis method is used for making decision if current bit is changed.
Weighting coefficients as part of the analytic hierarchy process are formed on
the values of bits. Then a matrix of corrupted pixels is generated.
Visualization of matrix with corrupted pixels allows to determine size,
location and presence of the embedded message. Computer experiment was
performed. Message was embedded in a bounded rectangular area of the image.
This method demonstrated efficiency even at low filling container, less than
10\%. Widespread statistical methods are unable to detect this steganographic
insert. The location and size of the embedded message can be determined with an
error which is not exceeding to five pixels.
"
1353,B-Script: Transcript-based B-roll Video Editing with Recommendations,"  In video production, inserting B-roll is a widely used technique to enrich
the story and make a video more engaging. However, determining the right
content and positions of B-roll and actually inserting it within the main
footage can be challenging, and novice producers often struggle to get both
timing and content right. We present B-Script, a system that supports B-roll
video editing via interactive transcripts. B-Script has a built-in
recommendation system trained on expert-annotated data, recommending users
B-roll position and content. To evaluate the system, we conducted a
within-subject user study with 110 participants, and compared three interface
variations: a timeline-based editor, a transcript-based editor, and a
transcript-based editor with recommendations. Users found it easier and were
faster to insert B-roll using the transcript-based interface, and they created
more engaging videos when recommendations were provided.
"
1354,"Web-Based 3D and Haptic Interactive Environments for e-Learning,
  Simulation, and Training","  Knowledge creation occurs in the process of social interaction. As our
service-based society is evolving into a knowledge-based society there is an
acute need for more effective collaboration and knowledge-sharing systems to be
used by geographically scattered people. We present the use of Web3D components
and standards, such as X3D, in combination with the haptic (tactile) paradigm,
for the development of new communication channels for e-Learning and
simulation.
"
1355,"Fine-Grained Semantic Segmentation of Motion Capture Data using Dilated
  Temporal Fully-Convolutional Networks","  Human motion capture data has been widely used in data-driven character
animation. In order to generate realistic, natural-looking motions, most
data-driven approaches require considerable efforts of pre-processing,
including motion segmentation and annotation. Existing (semi-) automatic
solutions either require hand-crafted features for motion segmentation or do
not produce the semantic annotations required for motion synthesis and building
large-scale motion databases. In addition, human labeled annotation data
suffers from inter- and intra-labeler inconsistencies by design. We propose a
semi-automatic framework for semantic segmentation of motion capture data based
on supervised machine learning techniques. It first transforms a motion capture
sequence into a ``motion image'' and applies a convolutional neural network for
image segmentation. Dilated temporal convolutions enable the extraction of
temporal information from a large receptive field. Our model outperforms two
state-of-the-art models for action segmentation, as well as a popular network
for sequence modeling. Most of all, our method is very robust under noisy and
inaccurate training labels and thus can handle human errors during the labeling
process.
"
1356,"Robust corner and tangent point detection for strokes with deep learning
  approach","  A robust corner and tangent point detection (CTPD) tool is critical for
sketch-based engineering modeling. This paper proposes a robust CTPD approach
for hand-drawn strokes with deep learning approach. Its robustness for users,
stroke shapes and biased datasets is improved due to multiscaled point contexts
and a vote scheme. Firstly, all stroke points are classified into segments by
two deep learning networks, based on scaled point contexts which mimic human's
perception. Then, a vote scheme is adopted to analyze the merge conditions and
operations for adjacent segments. If most points agree with a stroke's type,
this type is accepted. Finally, new corners and tangent points are inserted at
transition points. The algorithm's performance is experimented with 1500
strokes of 20 shapes. Results show that our algorithm can achieve 95.3% for
all-or-nothing accuracy and 88.6% accuracy for biased datasets, compared to
84.6% and 71% of the state-of-the-art CTPD technique, which is heuristic and
empirical-based.
"
1357,"Liver Pathology Simulation: Algorithm for Haptic Rendering and Force
  Maps for Palpation Assessment","  Preoperative gestures include tactile sampling of the mechanical properties
of biological tissue for both histological and pathological considerations.
Tactile properties used in conjunction with visual cues can provide useful
feedback to the surgeon. Development of novel cost effective haptic-based
simulators and their introduction in the minimally invasive surgery learning
cycle can absorb the learning curve for your residents. Receiving pre-training
in a core set of surgical skills can reduce skill acquisition time and risks.
We present the integration of a real-time surface stiffness adjustment
algorithm and a novel paradigm -- force maps -- in a visuo-haptic simulator
module designed to train internal organs disease diagnostics through palpation.
"
1358,"Computing Three-dimensional Constrained Delaunay Refinement Using the
  GPU","  We propose the first GPU algorithm for the 3D triangulation refinement
problem. For an input of a piecewise linear complex $\mathcal{G}$ and a
constant $B$, it produces, by adding Steiner points, a constrained Delaunay
triangulation conforming to $\mathcal{G}$ and containing tetrahedra mostly of
radius-edge ratios smaller than $B$. Our implementation of the algorithm shows
that it can be an order of magnitude faster than the best CPU algorithm while
using a similar amount of Steiner points to produce triangulations of
comparable quality.
"
1359,"Unsupervised Learning of Probabilistic Diffeomorphic Registration for
  Images and Surfaces","  Classical deformable registration techniques achieve impressive results and
offer a rigorous theoretical treatment, but are computationally intensive since
they solve an optimization problem for each image pair. Recently,
learning-based methods have facilitated fast registration by learning spatial
deformation functions. However, these approaches use restricted deformation
models, require supervised labels, or do not guarantee a diffeomorphic
(topology-preserving) registration. Furthermore, learning-based registration
tools have not been derived from a probabilistic framework that can offer
uncertainty estimates.
  In this paper, we build a connection between classical and learning-based
methods. We present a probabilistic generative model and derive an unsupervised
learning-based inference algorithm that uses insights from classical
registration methods and makes use of recent developments in convolutional
neural networks (CNNs). We demonstrate our method on a 3D brain registration
task for both images and anatomical surfaces, and provide extensive empirical
analyses. Our principled approach results in state of the art accuracy and very
fast runtimes, while providing diffeomorphic guarantees. Our implementation is
available at http://voxelmorph.csail.mit.edu.
"
1360,"LumiPath -- Towards Real-time Physically-based Rendering on Embedded
  Devices","  With the increasing computational power of today's workstations, real-time
physically-based rendering is within reach, rapidly gaining attention across a
variety of domains. These have expeditiously applied to medicine, where it is a
powerful tool for intuitive 3D data visualization. Embedded devices such as
optical see-through head-mounted displays (OST HMDs) have been a trend for
medical augmented reality. However, leveraging the obvious benefits of
physically-based rendering remains challenging on these devices because of
limited computational power, memory usage, and power consumption. We navigate
the compromise between device limitations and image quality to achieve
reasonable rendering results by introducing a novel light field that can be
sampled in real-time on embedded devices. We demonstrate its applications in
medicine and discuss limitations of the proposed method. An open-source version
of this project is available at https://github.com/lorafib/LumiPath which
provides full insight on implementation and exemplary demonstrational material.
"
1361,"Shape2Motion: Joint Analysis of Motion Parts and Attributes from 3D
  Shapes","  For the task of mobility analysis of 3D shapes, we propose joint analysis for
simultaneous motion part segmentation and motion attribute estimation, taking a
single 3D model as input. The problem is significantly different from those
tackled in the existing works which assume the availability of either a
pre-existing shape segmentation or multiple 3D models in different motion
states. To that end, we develop Shape2Motion which takes a single 3D point
cloud as input, and jointly computes a mobility-oriented segmentation and the
associated motion attributes. Shape2Motion is comprised of two deep neural
networks designed for mobility proposal generation and mobility optimization,
respectively. The key contribution of these networks is the novel motion-driven
features and losses used in both motion part segmentation and motion attribute
estimation. This is based on the observation that the movement of a functional
part preserves the shape structure. We evaluate Shape2Motion with a newly
proposed benchmark for mobility analysis of 3D shapes. Results demonstrate that
our method achieves the state-of-the-art performance both in terms of motion
part segmentation and motion attribute estimation.
"
1362,NormalNet: Learning-based Normal Filtering for Mesh Denoising,"  Mesh denoising is a critical technology in geometry processing that aims to
recover high-fidelity 3D mesh models of objects from their noise-corrupted
versions. In this work, we propose a learning-based normal filtering scheme for
mesh denoising called NormalNet, which maps the guided normal filtering (GNF)
into a deep network. The scheme follows the iterative framework of
filtering-based mesh denoising. During each iteration, first, the voxelization
strategy is applied on each face in a mesh to transform the irregular local
structure into the regular volumetric representation, therefore, both the
structure and face normal information are preserved and the convolution
operations in CNN(Convolutional Neural Network) can be easily performed.
Second, instead of the guidance normal generation and the guided filtering in
GNF, a deep CNN is designed, which takes the volumetric representation as
input, and outputs the learned filtered normals. At last, the vertex positions
are updated according to the filtered normals. Specifically, the iterative
training framework is proposed, in which the generation of training data and
the network training are alternately performed, whereas the ground truth
normals are taken as the guidance normals in GNF to get the target normals.
Compared to state-of-the-art works, NormalNet can effectively remove noise
while preserving the original features and avoiding pseudo-features.
"
1363,"Fast Registration for cross-source point clouds by using weak regional
  affinity and pixel-wise refinement","  Many types of 3D acquisition sensors have emerged in recent years and point
cloud has been widely used in many areas. Accurate and fast registration of
cross-source 3D point clouds from different sensors is an emerged research
problem in computer vision. This problem is extremely challenging because
cross-source point clouds contain a mixture of various variances, such as
density, partial overlap, large noise and outliers, viewpoint changing. In this
paper, an algorithm is proposed to align cross-source point clouds with both
high accuracy and high efficiency. There are two main contributions: firstly,
two components, the weak region affinity and pixel-wise refinement, are
proposed to maintain the global and local information of 3D point clouds. Then,
these two components are integrated into an iterative tensor-based registration
algorithm to solve the cross-source point cloud registration problem. We
conduct experiments on synthetic cross-source benchmark dataset and real
cross-source datasets. Comparison with six state-of-the-art methods, the
proposed method obtains both higher efficiency and accuracy.
"
1364,"A Visually Plausible Grasping System for Object Manipulation and
  Interaction in Virtual Reality Environments","  Interaction in virtual reality (VR) environments is essential to achieve a
pleasant and immersive experience. Most of the currently existing VR
applications, lack of robust object grasping and manipulation, which are the
cornerstone of interactive systems. Therefore, we propose a realistic, flexible
and robust grasping system that enables rich and real-time interactions in
virtual environments. It is visually realistic because it is completely
user-controlled, flexible because it can be used for different hand
configurations, and robust because it allows the manipulation of objects
regardless their geometry, i.e. hand is automatically fitted to the object
shape. In order to validate our proposal, an exhaustive qualitative and
quantitative performance analysis has been carried out. On the one hand,
qualitative evaluation was used in the assessment of the abstract aspects such
as: hand movement realism, interaction realism and motor control. On the other
hand, for the quantitative evaluation a novel error metric has been proposed to
visually analyze the performed grips. This metric is based on the computation
of the distance from the finger phalanges to the nearest contact point on the
object surface. These contact points can be used with different application
purposes, mainly in the field of robotics. As a conclusion, system evaluation
reports a similar performance between users with previous experience in virtual
reality applications and inexperienced users, referring to a steep learning
curve.
"
1365,colorspace: A Toolbox for Manipulating and Assessing Colors and Palettes,"  The R package colorspace provides a flexible toolbox for selecting individual
colors or color palettes, manipulating these colors, and employing them in
statistical graphics and data visualizations. In particular, the package
provides a broad range of color palettes based on the HCL
(Hue-Chroma-Luminance) color space. The three HCL dimensions have been shown to
match those of the human visual system very well, thus facilitating intuitive
selection of color palettes through trajectories in this space. Using the HCL
color model general strategies for three types of palettes are implemented: (1)
Qualitative for coding categorical information, i.e., where no particular
ordering of categories is available. (2) Sequential for coding ordered/numeric
information, i.e., going from high to low (or vice versa). (3) Diverging for
coding ordered/numeric information around a central neutral value, i.e., where
colors diverge from neutral to two extremes. To aid selection and application
of these palettes the package also contains scales for use with ggplot2, shiny
(and tcltk) apps for interactive exploration, visualizations of palette
properties, accompanying manipulation utilities (like desaturation and
lighten/darken), and emulation of color vision deficiencies.
"
1366,Effects of Self-Avatar and Gaze on Avoidance Movement Behavior,"  The present study investigates users' movement behavior in a virtual
environment when they attempted to avoid a virtual character. At each iteration
of the experiment, four conditions (Self-Avatar LookAt, No Self-Avatar LookAt,
Self-Avatar No LookAt, and No Self-Avatar No LookAt) were applied to examine
users' movement behavior based on kinematic measures. During the experiment, 52
participants were asked to walk from a starting position to a target position.
A virtual character was placed at the midpoint. Participants were asked to wear
a head-mounted display throughout the task, and their locomotion was captured
using a motion capture suit. We analyzed the captured trajectories of the
participants' routes on four kinematic measures to explore whether the four
experimental conditions influenced the paths they took. The results indicated
that the Self-Avatar LookAt condition affected the path the participants chose
more significantly than the other three conditions in terms of length,
duration, and deviation, but not in terms of speed. Overall, the length and
duration of the task, as well as the deviation of the trajectory from the
straight line, were greater when a self-avatar represented participants. An
additional effect on kinematic measures was found in the LookAt (Gaze)
conditions. Implications for future research are discussed.
"
1367,Surface Compression Using Dynamic Color Palettes,"  Off-chip memory traffic is a major source of power and energy consumption on
mobile platforms. A large amount of this off-chip traffic is used to manipulate
graphics framebuffer surfaces. To cut down the cost of accessing off-chip
memory, framebuffer surfaces are compressed to reduce the bandwidth consumed on
surface manipulation when rendering or displaying.
  In this work, we study the compression properties of framebuffer surfaces and
highlight the fact that surfaces from different applications have different
compression characteristics. We use the results of our analysis to propose a
scheme, Dynamic Color Palettes (DCP), which achieves higher compression rates
with UI and 2D surfaces.
  DCP is a hardware mechanism for exploiting inter-frame coherence in lossless
surface compression; it implements a scheme that dynamically constructs color
palettes, which are then used to efficiently compress framebuffer surfaces. To
evaluate DCP, we created an extensive set of OpenGL workload traces from 124
Android applications. We found that DCP improves compression rates by 91% for
UI and 20% for 2D applications compared to previous proposals. We also evaluate
a hybrid scheme that combines DCP with a generic compression scheme. We found
that compression rates improve over previous proposals by 161%, 124% and 83%
for UI, 2D and 3D applications, respectively.
"
1368,"Smart, Deep Copy-Paste","  In this work, we propose a novel system for smart copy-paste, enabling the
synthesis of high-quality results given a masked source image content and a
target image context as input. Our system naturally resolves both shading and
geometric inconsistencies between source and target image, resulting in a
merged result image that features the content from the pasted source image,
seamlessly pasted into the target context. Our framework is based on a novel
training image transformation procedure that allows to train a deep
convolutional neural network end-to-end to automatically learn a representation
that is suitable for copy-pasting. Our training procedure works with any image
dataset without additional information such as labels, and we demonstrate the
effectiveness of our system on two popular datasets, high-resolution face
images and the more complex Cityscapes dataset. Our technique outperforms the
current state of the art on face images, and we show promising results on the
Cityscapes dataset, demonstrating that our system generalizes to much higher
resolution than the training data.
"
1369,Semantic Image Synthesis with Spatially-Adaptive Normalization,"  We propose spatially-adaptive normalization, a simple but effective layer for
synthesizing photorealistic images given an input semantic layout. Previous
methods directly feed the semantic layout as input to the deep network, which
is then processed through stacks of convolution, normalization, and
nonlinearity layers. We show that this is suboptimal as the normalization
layers tend to ``wash away'' semantic information. To address the issue, we
propose using the input layout for modulating the activations in normalization
layers through a spatially-adaptive, learned transformation. Experiments on
several challenging datasets demonstrate the advantage of the proposed method
over existing approaches, regarding both visual fidelity and alignment with
input layouts. Finally, our model allows user control over both semantic and
style. Code is available at https://github.com/NVlabs/SPADE .
"
1370,"HexaShrink, an exact scalable framework for hexahedral meshes with
  attributes and discontinuities: multiresolution rendering and storage of
  geoscience models","  With huge data acquisition progresses realized in the past decades and
acquisition systems now able to produce high resolution grids and point clouds,
the digitization of physical terrains becomes increasingly more precise. Such
extreme quantities of generated and modeled data greatly impact computational
performances on many levels of high-performance computing (HPC): storage media,
memory requirements, transfer capability, and finally simulation interactivity,
necessary to exploit this instance of big data. Efficient representations and
storage are thus becoming ""enabling technologies'' in HPC experimental and
simulation science. We propose HexaShrink, an original decomposition scheme for
structured hexahedral volume meshes. The latter are used for instance in
biomedical engineering, materials science, or geosciences. HexaShrink provides
a comprehensive framework allowing efficient mesh visualization and storage.
Its exactly reversible multiresolution decomposition yields a hierarchy of
meshes of increasing levels of details, in terms of either geometry, continuous
or categorical properties of cells. Starting with an overview of volume meshes
compression techniques, our contribution blends coherently different
multiresolution wavelet schemes in different dimensions. It results in a global
framework preserving discontinuities (faults) across scales, implemented as a
fully reversible upscaling at different resolutions. Experimental results are
provided on meshes of varying size and complexity. They emphasize the
consistency of the proposed representation, in terms of visualization,
attribute downsampling and distribution at different resolutions. Finally,
HexaShrink yields gains in storage space when combined to lossless compression
techniques.
"
1371,"ReviewerNet: Visualizing Citation and Authorship Relations for Finding
  Reviewers","  We propose ReviewerNet, an online, interactive visualization system aimed to
improve the reviewer selection process in the academic domain. Given a paper
submitted for publication, we assume that good candidate reviewers can be
chosen among the authors of a small set of relevant and pertinent papers;
ReviewerNet supports the construction of such set of papers, by visualizing and
exploring a literature citation network. Then, the system helps to select
reviewers that are both well distributed in the scientific community and that
do not have any conflict-of-interest, by visualising the careers and
co-authorship relations of candidate reviewers. The system is publicly
available, and it has been evaluated by a set of experienced researchers in the
field of Computer Graphics.
"
1372,"Machine Learning for Data-Driven Movement Generation: a Review of the
  State of the Art","  The rise of non-linear and interactive media such as video games has
increased the need for automatic movement animation generation. In this survey,
we review and analyze different aspects of building automatic movement
generation systems using machine learning techniques and motion capture data.
We cover topics such as high-level movement characterization, training data,
features representation, machine learning models, and evaluation methods. We
conclude by presenting a discussion of the reviewed literature and outlining
the research gaps and remaining challenges for future work.
"
1373,Photometric Mesh Optimization for Video-Aligned 3D Object Reconstruction,"  In this paper, we address the problem of 3D object mesh reconstruction from
RGB videos. Our approach combines the best of multi-view geometric and
data-driven methods for 3D reconstruction by optimizing object meshes for
multi-view photometric consistency while constraining mesh deformations with a
shape prior. We pose this as a piecewise image alignment problem for each mesh
face projection. Our approach allows us to update shape parameters from the
photometric error without any depth or mask information. Moreover, we show how
to avoid a degeneracy of zero photometric gradients via rasterizing from a
virtual viewpoint. We demonstrate 3D object mesh reconstruction results from
both synthetic and real-world videos with our photometric mesh optimization,
which is unachievable with either na\""ive mesh generation networks or
traditional pipelines of surface reconstruction without heavy manual
post-processing.
"
1374,LOGAN: Unpaired Shape Transform in Latent Overcomplete Space,"  We introduce LOGAN, a deep neural network aimed at learning general-purpose
shape transforms from unpaired domains. The network is trained on two sets of
shapes, e.g., tables and chairs, while there is neither a pairing between
shapes from the domains as supervision nor any point-wise correspondence
between any shapes. Once trained, LOGAN takes a shape from one domain and
transforms it into the other. Our network consists of an autoencoder to encode
shapes from the two input domains into a common latent space, where the latent
codes concatenate multi-scale shape features, resulting in an overcomplete
representation. The translator is based on a generative adversarial network
(GAN), operating in the latent space, where an adversarial loss enforces
cross-domain translation while a feature preservation loss ensures that the
right shape features are preserved for a natural shape transform. We conduct
ablation studies to validate each of our key network designs and demonstrate
superior capabilities in unpaired shape transforms on a variety of examples
over baselines and state-of-the-art approaches. We show that LOGAN is able to
learn what shape features to preserve during shape translation, either local or
non-local, whether content or style, depending solely on the input domains for
training.
"
1375,"Robust Reference Frame Extraction from Unsteady 2D Vector Fields with
  Convolutional Neural Networks","  Robust feature extraction is an integral part of scientific visualization. In
unsteady vector field analysis, researchers recently directed their attention
towards the computation of near-steady reference frames for vortex extraction,
which is a numerically challenging endeavor. In this paper, we utilize a
convolutional neural network to combine two steps of the visualization pipeline
in an end-to-end manner: the filtering and the feature extraction. We use
neural networks for the extraction of a steady reference frame for a given
unsteady 2D vector field. By conditioning the neural network to noisy inputs
and resampling artifacts, we obtain numerically stabler results than existing
optimization-based approaches. Supervised deep learning typically requires a
large amount of training data. Thus, our second contribution is the creation of
a vector field benchmark data set, which is generally useful for any local deep
learning-based feature extraction. Based on Vatistas velocity profile, we
formulate a parametric vector field mixture model that we parameterize based on
numerically-computed example vector fields in near-steady reference frames.
Given the parametric model, we can efficiently synthesize thousands of vector
fields that serve as input to our deep learning architecture. The proposed
network is evaluated on an unseen numerical fluid flow simulation.
"
1376,AdaCoSeg: Adaptive Shape Co-Segmentation with Group Consistency Loss,"  We introduce AdaCoSeg, a deep neural network architecture for adaptive
co-segmentation of a set of 3D shapes represented as point clouds. Differently
from the familiar single-instance segmentation problem, co-segmentation is
intrinsically contextual: how a shape is segmented can vary depending on the
set it is in. Hence, our network features an adaptive learning module to
produce a consistent shape segmentation which adapts to a set. Specifically,
given an input set of unsegmented shapes, we first employ an offline
pre-trained part prior network to propose per-shape parts. Then, the
co-segmentation network iteratively and} jointly optimizes the part labelings
across the set subjected to a novel group consistency loss defined by matrix
ranks. While the part prior network can be trained with noisy and
inconsistently segmented shapes, the final output of AdaCoSeg is a consistent
part labeling for the input set, with each shape segmented into up to (a
user-specified) K parts. Overall, our method is weakly supervised, producing
segmentations tailored to the test set, without consistent ground-truth
segmentations. We show qualitative and quantitative results from AdaCoSeg and
evaluate it via ablation studies and comparisons to state-of-the-art
co-segmentation methods.
"
1377,Loopy Cuts: Surface-Field Aware Block Decomposition for Hex-Meshing,"  We present a new fully automatic block-decomposition hexahedral meshing
algorithm capable of producing high quality meshes that strictly preserve
feature curve networks on the input surface and align with an input surface
cross-field. We produce all-hex meshes on the vast majority of inputs, and
introduce localized non-hex elements only when the surface feature network
necessitates those. The input to our framework is a closed surface with a
collection of geometric or user-demarcated feature curves and a feature-aligned
surface cross-field. Its output is a compact set of blocks whose edges
interpolate these features and are loosely aligned with this cross-field. We
obtain this block decomposition by cutting the input model using a collection
of simple cutting surfaces bounded by closed surface loops. The set of cutting
loops spans the input feature curves, ensuring feature preservation, and is
obtained using a field-space sampling process. The computed loops are uniformly
distributed across the surface, cross orthogonally, and are loosely aligned
with the cross-field directions, inducing the desired block decomposition. We
validate our method by applying it to a large range of complex inputs and
comparing our results to those produced by state-of-the-art alternatives.
Contrary to prior approaches, our framework consistently produces high-quality
field aligned meshes while strictly preserving geometric or user-specified
surface features.
"
1378,BAE-NET: Branched Autoencoder for Shape Co-Segmentation,"  We treat shape co-segmentation as a representation learning problem and
introduce BAE-NET, a branched autoencoder network, for the task. The
unsupervised BAE-NET is trained with a collection of un-segmented shapes, using
a shape reconstruction loss, without any ground-truth labels. Specifically, the
network takes an input shape and encodes it using a convolutional neural
network, whereas the decoder concatenates the resulting feature code with a
point coordinate and outputs a value indicating whether the point is
inside/outside the shape. Importantly, the decoder is branched: each branch
learns a compact representation for one commonly recurring part of the shape
collection, e.g., airplane wings. By complementing the shape reconstruction
loss with a label loss, BAE-NET is easily tuned for one-shot learning. We show
unsupervised, weakly supervised, and one-shot learning results by BAE-NET,
demonstrating that using only a couple of exemplars, our network can generally
outperform state-of-the-art supervised methods trained on hundreds of segmented
shapes. Code is available at https://github.com/czq142857/BAE-NET.
"
1379,Implementing Noise with Hash functions for Graphics Processing Units,"  We propose a modification to Perlin noise which use computable hash functions
instead of textures as lookup tables. We implemented the FNV1, Jenkins and
Murmur hashes on Shader Model 4.0 Graphics Processing Units for noise
generation. Modified versions of the FNV1 and Jenkins hashes provide very close
performance compared to a texture based Perlin noise implementation. Our noise
modification enables noise function evaluation without any texture fetches,
trading computational power for memory bandwidth.
"
1380,"Parallelizable global conformal parameterization of simply-connected
  surfaces via partial welding","  Conformal surface parameterization is useful in graphics, imaging and
visualization, with applications to texture mapping, atlas construction,
registration, remeshing and so on. With the increasing capability in scanning
and storing data, dense 3D surface meshes are common nowadays. While meshes
with higher resolution better resemble smooth surfaces, they pose computational
difficulties for the existing parameterization algorithms. In this work, we
propose a novel parallelizable algorithm for computing the global conformal
parameterization of simply-connected surfaces via partial welding maps. A given
simply-connected surface is first partitioned into smaller subdomains. The
local conformal parameterizations of all subdomains are then computed in
parallel. The boundaries of the parameterized subdomains are subsequently
integrated consistently using a novel technique called partial welding, which
is developed based on conformal welding theory. Finally, by solving the Laplace
equation for each subdomain using the updated boundary conditions, we obtain a
global conformal parameterization of the given surface, with bijectivity
guaranteed by quasi-conformal theory. By including additional shape
constraints, our method can be easily extended to achieve disk conformal
parameterization for simply-connected open surfaces and spherical conformal
parameterization for genus-0 closed surfaces. Experimental results are
presented to demonstrate the effectiveness of our proposed algorithm. When
compared to the state-of-the-art conformal parameterization methods, our method
achieves a significant improvement in both computational time and accuracy.
"
1381,"Prediction Model for Semitransparent Watercolor Pigment Mixtures Using
  Deep Learning with a Dataset of Transmittance and Reflectance","  Learning color mixing is difficult for novice painters. In order to support
novice painters in learning color mixing, we propose a prediction model for
semitransparent pigment mixtures and use its prediction results to create a
Smart Palette system. Such a system is constructed by first building a
watercolor dataset with two types of color mixing data, indicated by
transmittance and reflectance: incrementation of the same primary pigment and a
mixture of two different pigments. Next, we apply the collected data to a deep
neural network to train a model for predicting the results of semitransparent
pigment mixtures. Finally, we constructed a Smart Palette that provides
easily-followable instructions on mixing a target color with two primary
pigments in real life: when users pick a pixel, an RGB color, from an image,
the system returns its mixing recipe which indicates the two primary pigments
being used and their quantities.
"
1382,Decomposition and Modeling in the Non-Manifold domain,"  The problem of decomposing non-manifold object has already been studied in
solid modeling. However, the few proposed solutions are limited to the problem
of decomposing solids described through their boundaries. In this thesis we
study the problem of decomposing an arbitrary non-manifold simplicial complex
into more regular components. A formal notion of decomposition is developed
using combinatorial topology. The proposed decomposition is unique, for a given
complex, and is computable for complexes of any dimension. A decomposition
algorithm is proposed that is linear w.r.t. the size of the input. In three or
higher dimensions a decomposition into manifold parts is not always possible.
Thus, in higher dimensions, we decompose a non-manifold into a decidable super
class of manifolds, that we call, Initial-Quasi-Manifolds. We also defined a
two-layered data structure, the Extended Winged data structure. This data
structure is a dimension independent data structure conceived to model
non-manifolds through their decomposition into initial-quasi-manifold parts.
Our two layered data structure describes the structure of the decomposition and
each component separately. In the second layer we encode the connectivity
structure of the decomposition. We analyze the space requirements of the
Extended Winged data structure and give algorithms to build and navigate it.
Finally, we discuss time requirements for the computation of topological
relations and show that, for surfaces and tetrahedralizations, embedded in real
3D space, all topological relations can be extracted in optimal time. This
approach offers a compact, dimension independent, representation for
non-manifolds that can be useful whenever the modeled object has few
non-manifold singularities.
"
1383,"Learning Soft Tissue Behavior of Organs for Surgical Navigation with
  Convolutional Neural Networks","  Purpose: In surgical navigation, pre-operative organ models are presented to
surgeons during the intervention to help them in efficiently finding their
target. In the case of soft tissue, these models need to be deformed and
adapted to the current situation by using intra-operative sensor data. A
promising method to realize this are real-time capable biomechanical models.
  Methods: We train a fully convolutional neural network to estimate a
displacement field of all points inside an organ when given only the
displacement of a part of the organ's surface. The network trains on entirely
synthetic data of random organ-like meshes, which allows us to generate much
more data than is otherwise available. The input and output data is discretized
into a regular grid, allowing us to fully utilize the capabilities of
convolutional operators and to train and infer in a highly parallelized manner.
  Results: The system is evaluated on in-silico liver models, phantom liver
data and human in-vivo breathing data. We test the performance with varying
material parameters, organ shapes and amount of visible surface. Even though
the network is only trained on synthetic data, it adapts well to the various
cases and gives a good estimation of the internal organ displacement. The
inference runs at over 50 frames per second.
  Conclusions: We present a novel method for training a data-driven, real-time
capable deformation model. The accuracy is comparable to other registration
methods, it adapts very well to previously unseen organs and does not need to
be re-trained for every patient. The high inferring speed makes this method
useful for many applications such as surgical navigation and real-time
simulation.
"
1384,"Training Object Detectors on Synthetic Images Containing Reflecting
  Materials","  One of the grand challenges of deep learning is the requirement to obtain
large labeled training data sets. While synthesized data sets can be used to
overcome this challenge, it is important that these data sets close the reality
gap, i.e., a model trained on synthetic image data is able to generalize to
real images. Whereas, the reality gap can be considered bridged in several
application scenarios, training on synthesized images containing reflecting
materials requires further research. Since the appearance of objects with
reflecting materials is dominated by the surrounding environment, this
interaction needs to be considered during training data generation. Therefore,
within this paper we examine the effect of reflecting materials in the context
of synthetic image generation for training object detectors. We investigate the
influence of rendering approach used for image synthesis, the effect of domain
randomization, as well as the amount of used training data. To be able to
compare our results to the state-of-the-art, we focus on indoor scenes as they
have been investigated extensively. Within this scenario, bathroom furniture is
a natural choice for objects with reflecting materials, for which we report our
findings on real and synthetic testing data.
"
1385,The Discrete Fourier Transform for Golden Angle Linogram Sampling,"  Estimation of the Discrete-Time Fourier Transform (DTFT) at points of a
finite domain arises in many imaging applications. A new approach to this task,
the Golden Angle Linogram Fourier Domain (GALFD), is presented, together with a
computationally fast and accurate tool, named Golden Angle Linogram Evaluation
(GALE), for approximating the DTFT at points of a GALFD. A GALFD resembles a
Linogram Fourier Domain (LFD), which is efficient and accurate. A limitation of
linograms is that embedding an LFD into a larger one requires many extra
points, at least doubling the domain's cardinality. The GALFD, on the other
hand, allows for incremental inclusion of relatively few data points.
Approximation error bounds and floating point operations counts are presented
to show that GALE computes accurately and efficiently the DTFT at the points of
a GALFD. The ability to extend the data collection in small increments is
beneficial in applications such as Magnetic Resonance Imaging. Experiments for
simulated and for real-world data are presented to substantiate the theoretical
claims. The mathematical analysis, algorithms, and software developed in the
paper are equally suitable to other angular distributions of rays and therefore
we bring the benefits of linograms to arbitrary radial patterns.
"
1386,DeepLight: Learning Illumination for Unconstrained Mobile Mixed Reality,"  We present a learning-based method to infer plausible high dynamic range
(HDR), omnidirectional illumination given an unconstrained, low dynamic range
(LDR) image from a mobile phone camera with a limited field of view (FOV). For
training data, we collect videos of various reflective spheres placed within
the camera's FOV, leaving most of the background unoccluded, leveraging that
materials with diverse reflectance functions reveal different lighting cues in
a single exposure. We train a deep neural network to regress from the LDR
background image to HDR lighting by matching the LDR ground truth sphere images
to those rendered with the predicted illumination using image-based relighting,
which is differentiable. Our inference runs at interactive frame rates on a
mobile device, enabling realistic rendering of virtual objects into real scenes
for mobile mixed reality. Training on automatically exposed and white-balanced
videos, we improve the realism of rendered objects compared to the state-of-the
art methods for both indoor and outdoor scenes.
"
1387,Non-Rigid Point Set Registration Networks,"  Point set registration is defined as a process to determine the spatial
transformation from the source point set to the target one. Existing methods
often iteratively search for the optimal geometric transformation to register a
given pair of point sets, driven by minimizing a predefined alignment loss
function. In contrast, the proposed point registration neural network (PR-Net)
actively learns the registration pattern as a parametric function from a
training dataset, consequently predict the desired geometric transformation to
align a pair of point sets. PR-Net can transfer the learned knowledge (i.e.
registration pattern) from registering training pairs to testing ones without
additional iterative optimization. Specifically, in this paper, we develop
novel techniques to learn shape descriptors from point sets that help formulate
a clear correlation between source and target point sets. With the defined
correlation, PR-Net tends to predict the transformation so that the source and
target point sets can be statistically aligned, which in turn leads to an
optimal spatial geometric registration. PR-Net achieves robust and superior
performance for non-rigid registration of point sets, even in presence of
Gaussian noise, outliers, and missing points, but requires much less time for
registering large number of pairs. More importantly, for a new pair of point
sets, PR-Net is able to directly predict the desired transformation using the
learned model without repetitive iterative optimization routine. Our code is
available at https://github.com/Lingjing324/PR-Net.
"
1388,"FEAFA: A Well-Annotated Dataset for Facial Expression Analysis and 3D
  Facial Animation","  Facial expression analysis based on machine learning requires large number of
well-annotated data to reflect different changes in facial motion. Publicly
available datasets truly help to accelerate research in this area by providing
a benchmark resource, but all of these datasets, to the best of our knowledge,
are limited to rough annotations for action units, including only their
absence, presence, or a five-level intensity according to the Facial Action
Coding System. To meet the need for videos labeled in great detail, we present
a well-annotated dataset named FEAFA for Facial Expression Analysis and 3D
Facial Animation. One hundred and twenty-two participants, including children,
young adults and elderly people, were recorded in real-world conditions. In
addition, 99,356 frames were manually labeled using Expression Quantitative
Tool developed by us to quantify 9 symmetrical FACS action units, 10
asymmetrical (unilateral) FACS action units, 2 symmetrical FACS action
descriptors and 2 asymmetrical FACS action descriptors, and each action unit or
action descriptor is well-annotated with a floating point number between 0 and
1. To provide a baseline for use in future research, a benchmark for the
regression of action unit values based on Convolutional Neural Networks are
presented. We also demonstrate the potential of our FEAFA dataset for 3D facial
animation. Almost all state-of-the-art algorithms for facial animation are
achieved based on 3D face reconstruction. We hence propose a novel method that
drives virtual characters only based on action unit value regression of the 2D
video frames of source actors.
"
1389,Orthogonal Voronoi Diagram and Treemap,"  In this paper, we propose a novel space partitioning strategy for implicit
hierarchy visualization such that the new plot not only has a tidy layout
similar to the treemap, but also is flexible to data changes similar to the
Voronoi treemap. To achieve this, we define a new distance function and
neighborhood relationship between sites so that space will be divided by
axis-aligned segments. Then a sweepline+skyline based heuristic algorithm is
proposed to allocate the partitioned spaces to form an orthogonal Voronoi
diagram with orthogonal rectangles. To the best of our knowledge, it is the
first time to use a sweepline-based strategy for the Voronoi treemap. Moreover,
we design a novel strategy to initialize the diagram status and modify the
status update procedure so that the generation of our plot is more effective
and efficient. We show that the proposed algorithm has an O(nlog(n)) complexity
which is the same as the state-of-the-art Voronoi treemap. To this end, we show
via experiments on the artificial dataset and real-world dataset the
performance of our algorithm in terms of computation time, converge rate, and
aspect ratio. Finally, we discuss the pros and cons of our method and make a
conclusion.
"
1390,x3ogre: Connecting X3D to a state of the art rendering engine,"  We connect X3D to the state of the art OGRE renderer using our prototypical
x3ogre implementation. At this we perform a comparison of both on a conceptual
level, highlighting similarities and differences. Our implementation allows
swapping X3D concepts for OGRE concepts and vice versa. We take advantage of
this to analyse current shortcomings in X3D and propose X3D extensions to
overcome those.
"
1391,"Constrained Generative Adversarial Networks for Interactive Image
  Generation","  Generative Adversarial Networks (GANs) have received a great deal of
attention due in part to recent success in generating original, high-quality
samples from visual domains. However, most current methods only allow for users
to guide this image generation process through limited interactions. In this
work we develop a novel GAN framework that allows humans to be ""in-the-loop"" of
the image generation process. Our technique iteratively accepts relative
constraints of the form ""Generate an image more like image A than image B"".
After each constraint is given, the user is presented with new outputs from the
GAN, informing the next round of feedback. This feedback is used to constrain
the output of the GAN with respect to an underlying semantic space that can be
designed to model a variety of different notions of similarity (e.g. classes,
attributes, object relationships, color, etc.). In our experiments, we show
that our GAN framework is able to generate images that are of comparable
quality to equivalent unsupervised GANs while satisfying a large number of the
constraints provided by users, effectively changing a GAN into one that allows
users interactive control over image generation without sacrificing image
quality.
"
1392,Blind Visual Motif Removal from a Single Image,"  Many images shared over the web include overlaid objects, or visual motifs,
such as text, symbols or drawings, which add a description or decoration to the
image. For example, decorative text that specifies where the image was taken,
repeatedly appears across a variety of different images. Often, the reoccurring
visual motif, is semantically similar, yet, differs in location, style and
content (e.g. text placement, font and letters). This work proposes a deep
learning based technique for blind removal of such objects. In the blind
setting, the location and exact geometry of the motif are unknown. Our approach
simultaneously estimates which pixels contain the visual motif, and synthesizes
the underlying latent image. It is applied to a single input image, without any
user assistance in specifying the location of the motif, achieving
state-of-the-art results for blind removal of both opaque and semi-transparent
visual motifs.
"
1393,Nutty-based Robot Animation -- Principles and Practices,"  Robot animation is a new form of character animation that extends the
traditional process by allowing the animated motion to become more interactive
and adaptable during interaction with users in real-world settings. This paper
reviews how this new type of character animation has evolved and been shaped
from character animation principles and practices. We outline some new
paradigms that aim at allowing character animators to become robot animators,
and to properly take part in the development of social robots. One such
paradigm consists of the 12 principles of robot animation, which describes
general concepts that both animators and robot developers should consider in
order to properly understand each other. We also introduce the concept of
Kinematronics, for specifying the controllable and programmable expressive
abilities of robots, and the Nutty Workflow and Pipeline. The Nutty Pipeline
introduces the concept of the Programmable Robot Animation Engine, which allows
to generate, compose and blend various types of animation sources into a final,
interaction-enabled motion that can be rendered on robots in real-time during
real-world interactions. The Nutty Motion Filter is described and exemplified
as a technique that allows an open-loop motion controller to apply physical
limits to the motion while still allowing to tweak the shape and expressivity
of the resulting motion. Additionally, we describe some types of tools that can
be developed and integrated into Nutty-based workflows and pipelines, which
allow animation artists to perform an integral part of the expressive behaviour
development within social robots, and thus to evolve from standard (3D)
character animators, towards a full-stack type of robot animators.
"
1394,"Manifold-based isogeometric analysis basis functions with prescribed
  sharp features","  We introduce manifold-based basis functions for isogeometric analysis of
surfaces with arbitrary smoothness, prescribed $C^0$ continuous creases and
boundaries. The utility of the manifold-based surface construction techniques
in isogeometric analysis was demonstrated in Majeed and Cirak (CMAME, 2017).
The respective basis functions are derived by combining differential-geometric
manifold techniques with conformal parametrisations and the partition of unity
method. The connectivity of a given unstructured quadrilateral control mesh in
$\mathbb R^3$ is used to define a set of overlapping charts. Each vertex with
its attached elements is assigned a corresponding conformally parametrised
planar chart domain in $\mathbb R^2$, so that a quadrilateral element is
present on four different charts. On the collection of unconnected chart
domains, the partition of unity method is used for approximation. The
transition functions required for navigating between the chart domains are
composed out of conformal maps. The necessary smooth partition of unity, or
blending, functions for the charts are assembled from tensor-product B-spline
pieces and require in contrast to earlier constructions no normalisation.
Creases are introduced across user tagged edges of the control mesh. Planar
chart domains that include creased edges or are adjacent to the domain boundary
require special local polynomial approximants. Three different types of chart
domain geometries are necessary to consider boundaries and arbitrary number and
arrangement of creases. The new chart domain geometries are chosen so that it
becomes trivial to establish local polynomial approximants that are always
$C^0$ continuous across tagged edges. The derived non-rational manifold-based
basis functions are particularly well suited for isogeometric analysis of
Kirchhoff-Love thin shells with kinks.
"
1395,AMASS: Archive of Motion Capture as Surface Shapes,"  Large datasets are the cornerstone of recent advances in computer vision
using deep learning. In contrast, existing human motion capture (mocap)
datasets are small and the motions limited, hampering progress on learning
models of human motion. While there are many different datasets available, they
each use a different parameterization of the body, making it difficult to
integrate them into a single meta dataset. To address this, we introduce AMASS,
a large and varied database of human motion that unifies 15 different optical
marker-based mocap datasets by representing them within a common framework and
parameterization. We achieve this using a new method, MoSh++, that converts
mocap data into realistic 3D human meshes represented by a rigged body model;
here we use SMPL [doi:10.1145/2816795.2818013], which is widely used and
provides a standard skeletal representation as well as a fully rigged surface
mesh. The method works for arbitrary marker sets, while recovering soft-tissue
dynamics and realistic hand motion. We evaluate MoSh++ and tune its
hyperparameters using a new dataset of 4D body scans that are jointly recorded
with marker-based mocap. The consistent representation of AMASS makes it
readily useful for animation, visualization, and generating training data for
deep learning. Our dataset is significantly richer than previous human motion
collections, having more than 40 hours of motion data, spanning over 300
subjects, more than 11,000 motions, and will be publicly available to the
research community.
"
1396,Teaching GANs to Sketch in Vector Format,"  Sketching is more fundamental to human cognition than speech. Deep Neural
Networks (DNNs) have achieved the state-of-the-art in speech-related tasks but
have not made significant development in generating stroke-based sketches a.k.a
sketches in vector format. Though there are Variational Auto Encoders (VAEs)
for generating sketches in vector format, there is no Generative Adversarial
Network (GAN) architecture for the same. In this paper, we propose a standalone
GAN architecture SkeGAN and a VAE-GAN architecture VASkeGAN, for sketch
generation in vector format. SkeGAN is a stochastic policy in Reinforcement
Learning (RL), capable of generating both multidimensional continuous and
discrete outputs. VASkeGAN hybridizes a VAE and a GAN, in order to couple the
efficient representation of data by VAE with the powerful generating
capabilities of a GAN, to produce visually appealing sketches. We also propose
a new metric called the Ske-score which quantifies the quality of vector
sketches. We have validated that SkeGAN and VASkeGAN generate visually
appealing sketches by using Human Turing Test and Ske-score.
"
1397,Neural Rerendering in the Wild,"  We explore total scene capture -- recording, modeling, and rerendering a
scene under varying appearance such as season and time of day. Starting from
internet photos of a tourist landmark, we apply traditional 3D reconstruction
to register the photos and approximate the scene as a point cloud. For each
photo, we render the scene points into a deep framebuffer, and train a neural
network to learn the mapping of these initial renderings to the actual photos.
This rerendering network also takes as input a latent appearance vector and a
semantic mask indicating the location of transient objects like pedestrians.
The model is evaluated on several datasets of publicly available images
spanning a broad range of illumination conditions. We create short videos
demonstrating realistic manipulation of the image viewpoint, appearance, and
semantic labeling. We also compare results with prior work on scene
reconstruction from internet photos.
"
1398,End-to-end Projector Photometric Compensation,"  Projector photometric compensation aims to modify a projector input image
such that it can compensate for disturbance from the appearance of projection
surface. In this paper, for the first time, we formulate the compensation
problem as an end-to-end learning problem and propose a convolutional neural
network, named CompenNet, to implicitly learn the complex compensation
function. CompenNet consists of a UNet-like backbone network and an autoencoder
subnet. Such architecture encourages rich multi-level interactions between the
camera-captured projection surface image and the input image, and thus captures
both photometric and environment information of the projection surface. In
addition, the visual details and interaction information are carried to deeper
layers along the multi-level skip convolution layers. The architecture is of
particular importance for the projector compensation task, for which only a
small training dataset is allowed in practice. Another contribution we make is
a novel evaluation benchmark, which is independent of system setup and thus
quantitatively verifiable. Such benchmark is not previously available, to our
best knowledge, due to the fact that conventional evaluation requests the
hardware system to actually project the final results. Our key idea, motivated
from our end-to-end problem formulation, is to use a reasonable surrogate to
avoid such projection process so as to be setup-independent. Our method is
evaluated carefully on the benchmark, and the results show that our end-to-end
learning solution outperforms state-of-the-arts both qualitatively and
quantitatively by a significant margin.
"
1399,Developable surface patches bounded by NURBS curves,"  In this paper we construct developable surface patches which are bounded by
two rational or NURBS curves, though the resulting patch is not a rational or
NURBS surface in general. This is accomplished by reparameterizing one of the
boundary curves. The reparameterization function is the solution of an
algebraic equation. For the relevant case of cubic or cubic spline curves, this
equation is quartic at most, quadratic if the curves are Bezier or splines and
lie on parallel planes, and hence it may be solved either by standard
analytical or numerical methods.
"
1400,Computational Parquetry: Fabricated Style Transfer with Wood Pixels,"  Parquetry is the art and craft of decorating a surface with a pattern of
differently colored veneers of wood, stone or other materials. Traditionally,
the process of designing and making parquetry has been driven by color, using
the texture found in real wood only for stylization or as a decorative effect.
Here, we introduce a computational pipeline that draws from the rich natural
structure of strongly textured real-world veneers as a source of detail in
order to approximate a target image as faithfully as possible using a
manageable number of parts. This challenge is closely related to the
established problems of patch-based image synthesis and stylization in some
ways, but fundamentally different in others. Most importantly, the limited
availability of resources (any piece of wood can only be used once) turns the
relatively simple problem of finding the right piece for the target location
into the combinatorial problem of finding optimal parts while avoiding resource
collisions. We introduce an algorithm that allows to efficiently solve an
approximation to the problem. It further addresses challenges like gamut
mapping, feature characterization and the search for fabricable cuts. We
demonstrate the effectiveness of the system by fabricating a selection of
""photo-realistic"" pieces of parquetry from different kinds of unstained wood
veneer.
"
1401,Unwind: Interactive Fish Straightening,"  The ScanAllFish project is a large-scale effort to scan all the world's
33,100 known species of fishes. It has already generated thousands of
volumetric CT scans of fish species which are available on open access
platforms such as the Open Science Framework. To achieve a scanning rate
required for a project of this magnitude, many specimens are grouped together
into a single tube and scanned all at once. The resulting data contain many
fish which are often bent and twisted to fit into the scanner. Our system,
Unwind, is a novel interactive visualization and processing tool which
extracts, unbends, and untwists volumetric images of fish with minimal user
interaction. Our approach enables scientists to interactively unwarp these
volumes to remove the undesired torque and bending using a piecewise-linear
skeleton extracted by averaging isosurfaces of a harmonic function connecting
the head and tail of each fish. The result is a volumetric dataset of a
individual, straight fish in a canonical pose defined by the marine biologist
expert user. We have developed Unwind in collaboration with a team of marine
biologists: Our system has been deployed in their labs, and is presently being
used for dataset construction, biomechanical analysis, and the generation of
figures for scientific publication.
"
1402,High Performance Reconfigurable Computing Systems,"  The rapid progress and advancement in electronic chips technology provide a
variety of new implementation options for system engineers. The choice varies
between the flexible programs running on a general-purpose processor (GPP) and
the fixed hardware implementation using an application specific integrated
circuit (ASIC). Many other implementation options present, for instance, a
system with a RISC processor and a DSP core. Other options include graphics
processors and microcontrollers. Specialist processors certainly improve
performance over general-purpose ones, but this comes as a quid pro quo for
flexibility. Combining the flexibility of GPPs and the high performance of
ASICs leads to the introduction of reconfigurable computing (RC) as a new
implementation option with a balance between versatility and speed. The focus
of this chapter is on introducing reconfigurable computers as modern super
computing architectures. The chapter also investigates the main reasons behind
the current advancement in the development of RC-systems. Furthermore, a
technical survey of various RC-systems is included laying common grounds for
comparisons. In addition, this chapter mainly presents case studies implemented
under the MorphoSys RC-system. The selected case studies belong to different
areas of application, such as, computer graphics and information coding.
Parallel versions of the studied algorithms are developed to match the
topologies supported by the MorphoSys. Performance evaluation and results
analyses are included for implementations with different characteristics.
"
1403,"Curve and surface construction based on the generalized toric-Bernstein
  basis functions","  The construction of parametric curve and surface plays important role in
computer aided geometric design (CAGD), computer aided design (CAD), and
geometric modeling. In this paper, we define a new kind of blending functions
associated with a real points set, called generalized toric-Bernstein
(GT-Bernstein) basis functions. Then the generalized toric-Bezier (GT-B\'ezier)
curves and surfaces are constructed based on the GT-Bernstein basis functions,
which are the projections of the (irrational) toric varieties in fact and the
generalizations of the classical rational B\'ezier curves and surfaces and
toric surface patches. Furthermore, we also study the properties of the
presented curves and surfaces, including the limiting properties of weights and
knots. Some representative examples verify the properties and results.
"
1404,"Depth from Videos in the Wild: Unsupervised Monocular Depth Learning
  from Unknown Cameras","  We present a novel method for simultaneous learning of depth, egomotion,
object motion, and camera intrinsics from monocular videos, using only
consistency across neighboring video frames as supervision signal. Similarly to
prior work, our method learns by applying differentiable warping to frames and
comparing the result to adjacent ones, but it provides several improvements: We
address occlusions geometrically and differentiably, directly using the depth
maps as predicted during training. We introduce randomized layer normalization,
a novel powerful regularizer, and we account for object motion relative to the
scene. To the best of our knowledge, our work is the first to learn the camera
intrinsic parameters, including lens distortion, from video in an unsupervised
manner, thereby allowing us to extract accurate depth and motion from arbitrary
videos of unknown origin at scale. We evaluate our results on the Cityscapes,
KITTI and EuRoC datasets, establishing new state of the art on depth prediction
and odometry, and demonstrate qualitatively that depth prediction can be
learned from a collection of YouTube videos.
"
1405,Predicting Novel Views Using Generative Adversarial Query Network,"  The problem of predicting a novel view of the scene using an arbitrary number
of observations is a challenging problem for computers as well as for humans.
This paper introduces the Generative Adversarial Query Network (GAQN), a
general learning framework for novel view synthesis that combines Generative
Query Network (GQN) and Generative Adversarial Networks (GANs). The
conventional GQN encodes input views into a latent representation that is used
to generate a new view through a recurrent variational decoder. The proposed
GAQN builds on this work by adding two novel aspects: First, we extend the
current GQN architecture with an adversarial loss function for improving the
visual quality and convergence speed. Second, we introduce a feature-matching
loss function for stabilizing the training procedure. The experiments
demonstrate that GAQN is able to produce high-quality results and faster
convergence compared to the conventional approach.
"
1406,Pixel-Adaptive Convolutional Neural Networks,"  Convolutions are the fundamental building block of CNNs. The fact that their
weights are spatially shared is one of the main reasons for their widespread
use, but it also is a major limitation, as it makes convolutions content
agnostic. We propose a pixel-adaptive convolution (PAC) operation, a simple yet
effective modification of standard convolutions, in which the filter weights
are multiplied with a spatially-varying kernel that depends on learnable, local
pixel features. PAC is a generalization of several popular filtering techniques
and thus can be used for a wide range of use cases. Specifically, we
demonstrate state-of-the-art performance when PAC is used for deep joint image
upsampling. PAC also offers an effective alternative to fully-connected CRF
(Full-CRF), called PAC-CRF, which performs competitively, while being
considerably faster. In addition, we also demonstrate that PAC can be used as a
drop-in replacement for convolution layers in pre-trained networks, resulting
in consistent performance improvements.
"
1407,Generating Animations from Screenplays,"  Automatically generating animation from natural language text finds
application in a number of areas e.g. movie script writing, instructional
videos, and public safety. However, translating natural language text into
animation is a challenging task. Existing text-to-animation systems can handle
only very simple sentences, which limits their applications. In this paper, we
develop a text-to-animation system which is capable of handling complex
sentences. We achieve this by introducing a text simplification step into the
process. Building on an existing animation generation system for screenwriting,
we create a robust NLP pipeline to extract information from screenplays and map
them to the system's knowledge base. We develop a set of linguistic
transformation rules that simplify complex sentences. Information extracted
from the simplified sentences is used to generate a rough storyboard and video
depicting the text. Our sentence simplification module outperforms existing
systems in terms of BLEU and SARI metrics.We further evaluated our system via a
user study: 68 % participants believe that our system generates reasonable
animation from input screenplays.
"
1408,"Predicting Future Pedestrian Motion in Video Sequences using Crowd
  Simulation","  While human and group analysis have become an important area in last decades,
some current and relevant applications involve to estimate future motion of
pedestrians in real video sequences. This paper presents a method to provide
motion estimation of real pedestrians in next seconds, using crowd simulation.
Our method is based on Physics and heuristics and use BioCrowds as crowd
simulation methodology to estimate future positions of people in video
sequences. Results show that our method for estimation works well even for
complex videos where events can happen. The maximum achieved average error is
$2.72$cm when estimating the future motion of 32 pedestrians with more than 2
seconds in advance. This paper discusses this and other results.
"
1409,Direct Fitting of Gaussian Mixture Models,"  When fitting Gaussian Mixture Models to 3D geometry, the model is typically
fit to point clouds, even when the shapes were obtained as 3D meshes. Here we
present a formulation for fitting Gaussian Mixture Models (GMMs) directly to a
triangular mesh instead of using points sampled from its surface. Part of this
work analyzes a general formulation for evaluating likelihood of geometric
objects. This modification enables fitting higher-quality GMMs under a wider
range of initialization conditions. Additionally, models obtained from this
fitting method are shown to produce an improvement in 3D registration for both
meshes and RGB-D frames. This result is general and applicable to arbitrary
geometric objects, including representing uncertainty from sensor measurements.
"
1410,"Probabilistic Permutation Synchronization using the Riemannian Structure
  of the Birkhoff Polytope","  We present an entirely new geometric and probabilistic approach to
synchronization of correspondences across multiple sets of objects or images.
In particular, we present two algorithms: (1) Birkhoff-Riemannian L-BFGS for
optimizing the relaxed version of the combinatorially intractable cycle
consistency loss in a principled manner, (2) Birkhoff-Riemannian Langevin Monte
Carlo for generating samples on the Birkhoff Polytope and estimating the
confidence of the found solutions. To this end, we first introduce the very
recently developed Riemannian geometry of the Birkhoff Polytope. Next, we
introduce a new probabilistic synchronization model in the form of a Markov
Random Field (MRF). Finally, based on the first order retraction operators, we
formulate our problem as simulating a stochastic differential equation and
devise new integrators. We show on both synthetic and real datasets that we
achieve high quality multi-graph matching results with faster convergence and
reliable confidence/uncertainty estimates.
"
1411,Learning Shape Templates with Structured Implicit Functions,"  Template 3D shapes are useful for many tasks in graphics and vision,
including fitting observation data, analyzing shape collections, and
transferring shape attributes. Because of the variety of geometry and topology
of real-world shapes, previous methods generally use a library of hand-made
templates. In this paper, we investigate learning a general shape template from
data. To allow for widely varying geometry and topology, we choose an implicit
surface representation based on composition of local shape elements. While long
known to computer graphics, this representation has not yet been explored in
the context of machine learning for vision. We show that structured implicit
functions are suitable for learning and allow a network to smoothly and
simultaneously fit multiple classes of shapes. The learned shape template
supports applications such as shape exploration, correspondence, abstraction,
interpolation, and semantic segmentation from an RGB image.
"
1412,Learning Deformable Kernels for Image and Video Denoising,"  Most of the classical denoising methods restore clear results by selecting
and averaging pixels in the noisy input. Instead of relying on hand-crafted
selecting and averaging strategies, we propose to explicitly learn this process
with deep neural networks. Specifically, we propose deformable 2D kernels for
image denoising where the sampling locations and kernel weights are both
learned. The proposed kernel naturally adapts to image structures and could
effectively reduce the oversmoothing artifacts. Furthermore, we develop 3D
deformable kernels for video denoising to more efficiently sample pixels across
the spatial-temporal space. Our method is able to solve the misalignment issues
of large motion from dynamic scenes. For better training our video denoising
model, we introduce the trilinear sampler and a new regularization term. We
demonstrate that the proposed method performs favorably against the
state-of-the-art image and video denoising approaches on both synthetic and
real-world data.
"
1413,Relation-Shape Convolutional Neural Network for Point Cloud Analysis,"  Point cloud analysis is very challenging, as the shape implied in irregular
points is difficult to capture. In this paper, we propose RS-CNN, namely,
Relation-Shape Convolutional Neural Network, which extends regular grid CNN to
irregular configuration for point cloud analysis. The key to RS-CNN is learning
from relation, i.e., the geometric topology constraint among points.
Specifically, the convolutional weight for local point set is forced to learn a
high-level relation expression from predefined geometric priors, between a
sampled point from this point set and the others. In this way, an inductive
local representation with explicit reasoning about the spatial layout of points
can be obtained, which leads to much shape awareness and robustness. With this
convolution as a basic operator, RS-CNN, a hierarchical architecture can be
developed to achieve contextual shape-aware learning for point cloud analysis.
Extensive experiments on challenging benchmarks across three tasks verify
RS-CNN achieves the state of the arts.
"
1414,Total Denoising: Unsupervised Learning of 3D Point Cloud Cleaning,"  We show that denoising of 3D point clouds can be learned unsupervised,
directly from noisy 3D point cloud data only. This is achieved by extending
recent ideas from learning of unsupervised image denoisers to unstructured 3D
point clouds. Unsupervised image denoisers operate under the assumption that a
noisy pixel observation is a random realization of a distribution around a
clean pixel value, which allows appropriate learning on this distribution to
eventually converge to the correct value. Regrettably, this assumption is not
valid for unstructured points: 3D point clouds are subject to total noise, i.
e., deviations in all coordinates, with no reliable pixel grid. Thus, an
observation can be the realization of an entire manifold of clean 3D points,
which makes a na\""ive extension of unsupervised image denoisers to 3D point
clouds impractical. Overcoming this, we introduce a spatial prior term, that
steers converges to the unique closest out of the many possible modes on a
manifold. Our results demonstrate unsupervised denoising performance similar to
that of supervised learning with clean data when given enough training examples
- whereby we do not need any pairs of noisy and clean training data.
"
1415,ZoomOut: Spectral Upsampling for Efficient Shape Correspondence,"  We present a simple and efficient method for refining maps or correspondences
by iterative upsampling in the spectral domain that can be implemented in a few
lines of code. Our main observation is that high quality maps can be obtained
even if the input correspondences are noisy or are encoded by a small number of
coefficients in a spectral basis. We show how this approach can be used in
conjunction with existing initialization techniques across a range of
application scenarios, including symmetry detection, map refinement across
complete shapes, non-rigid partial shape matching and function transfer. In
each application we demonstrate an improvement with respect to both the quality
of the results and the computational speed compared to the best competing
methods, with up to two orders of magnitude speed-up in some applications. We
also demonstrate that our method is both robust to noisy input and is scalable
with respect to shape complexity. Finally, we present a theoretical
justification for our approach, shedding light on structural properties of
functional maps.
"
1416,Rendering of Complex Heterogenous Scenes using Progressive Blue Surfels,"  We present a technique for rendering highly complex 3D scenes in real-time by
generating uniformly distributed points on the scene's visible surfaces. The
technique is applicable to a wide range of scene types, like scenes directly
based on complex and detailed CAD data consisting of billions of polygons (in
contrast to scenes handcrafted solely for visualization). This allows to
visualize such scenes smoothly even in VR on a HMD with good image quality,
while maintaining the necessary frame-rates. In contrast to other point based
rendering methods, we place points in an approximated blue noise distribution
only on visible surfaces and store them in a highly GPU efficient data
structure, allowing to progressively refine the number of rendered points to
maximize the image quality for a given target frame rate. Our evaluation shows
that scenes consisting of a high amount of polygons can be rendered with
interactive frame rates with good visual quality on standard hardware.
"
1417,Vid2Game: Controllable Characters Extracted from Real-World Videos,"  We are given a video of a person performing a certain activity, from which we
extract a controllable model. The model generates novel image sequences of that
person, according to arbitrary user-defined control signals, typically marking
the displacement of the moving body. The generated video can have an arbitrary
background, and effectively capture both the dynamics and appearance of the
person.
  The method is based on two networks. The first network maps a current pose,
and a single-instance control signal to the next pose. The second network maps
the current pose, the new pose, and a given background, to an output frame.
Both networks include multiple novelties that enable high-quality performance.
This is demonstrated on multiple characters extracted from various videos of
dancers and athletes.
"
1418,Deep Parametric Shape Predictions using Distance Fields,"  Many tasks in graphics and vision demand machinery for converting shapes into
consistent representations with sparse sets of parameters; these
representations facilitate rendering, editing, and storage. When the source
data is noisy or ambiguous, however, artists and engineers often manually
construct such representations, a tedious and potentially time-consuming
process. While advances in deep learning have been successfully applied to
noisy geometric data, the task of generating parametric shapes has so far been
difficult for these methods. Hence, we propose a new framework for predicting
parametric shape primitives using deep learning. We use distance fields to
transition between shape parameters like control points and input data on a
pixel grid. We demonstrate efficacy on 2D and 3D tasks, including font
vectorization and surface abstraction.
"
1419,Snaxels on a Plane,"  While many algorithms exist for tracing various contours for illustrating a
meshed object, few algorithms organize these contours into region-bounding
closed loops. Tracing closed-loop boundaries on a mesh can be problematic due
to switchbacks caused by subtle surface variation, and the organization of
these regions into a planar map can lead to many small region components due to
imprecision and noise. This paper adapts ""snaxels,"" an energy minimizing active
contour method designed for robust mesh processing, and repurposes it to
generate visual, shadow and shading contours, and a simplified visual-surface
planar map, useful for stylized vector art illustration of the mesh. The snaxel
active contours can also track contours as the mesh animates, and
frame-to-frame correspondences between snaxels lead to a new method to convert
the moving contours on a 3-D animated mesh into 2-D SVG curve animations for
efficient embedding in Flash, PowerPoint and other dynamic vector art
platforms.
"
1420,"Surface2Volume: Surface Segmentation Conforming Assemblable Volumetric
  Partition","  Users frequently seek to fabricate objects whose outer surfaces consist of
regions with different surface attributes, such as color or material.
Manufacturing such objects in a single piece is often challenging or even
impossible. The alternative is to partition them into single-attribute
volumetric parts that can be fabricated separately and then assembled to form
the target object. Facilitating this approach requires partitioning the input
model into parts that conform to the surface segmentation and that can be moved
apart with no collisions. We propose Surface2Volume, a partition algorithm
capable of producing such assemblable parts, each of which is affiliated with a
single attribute, the outer surface of whose assembly conforms to the input
surface geometry and segmentation. In computing the partition we strictly
enforce conformity with surface segmentation and assemblability, and optimize
for ease of fabrication by minimizing part count, promoting part simplicity,
and simplifying assembly sequencing. We note that computing the desired
partition requires solving for three types of variables: per-part assembly
trajectories, partition topology, i.e. the connectivity of the interface
surfaces separating the different parts, and the geometry, or location, of
these interfaces. We efficiently produce the desired partitions by addressing
one type of variables at a time: first computing the assembly trajectories,
then determining interface topology, and finally computing interface locations
that allow parts assemblability. We algorithmically identify inputs that
necessitate sequential assembly, and partition these inputs gradually by
computing and disassembling a subset of assemblable parts at a time. We
demonstrate our method....
"
1421,"Multi-modal 3D Shape Reconstruction Under Calibration Uncertainty using
  Parametric Level Set Methods","  We consider the problem of 3D shape reconstruction from multi-modal data,
given uncertain calibration parameters. Typically, 3D data modalities can be in
diverse forms such as sparse point sets, volumetric slices, 2D photos and so
on. To jointly process these data modalities, we exploit a parametric level set
method that utilizes ellipsoidal radial basis functions. This method not only
allows us to analytically and compactly represent the object, it also confers
on us the ability to overcome calibration related noise that originates from
inaccurate acquisition parameters. This essentially implicit regularization
leads to a highly robust and scalable reconstruction, surpassing other
traditional methods. In our results we first demonstrate the ability of the
method to compactly represent complex objects. We then show that our
reconstruction method is robust both to a small number of measurements and to
noise in the acquisition parameters. Finally, we demonstrate our reconstruction
abilities from diverse modalities such as volume slices obtained from liquid
displacement (similar to CTscans and XRays), and visual measurements obtained
from shape silhouettes.
"
1422,OperatorNet: Recovering 3D Shapes From Difference Operators,"  This paper proposes a learning-based framework for reconstructing 3D shapes
from functional operators, compactly encoded as small-sized matrices. To this
end we introduce a novel neural architecture, called OperatorNet, which takes
as input a set of linear operators representing a shape and produces its 3D
embedding. We demonstrate that this approach significantly outperforms previous
purely geometric methods for the same problem. Furthermore, we introduce a
novel functional operator, which encodes the extrinsic or pose-dependent shape
information, and thus complements purely intrinsic pose-oblivious operators,
such as the classical Laplacian. Coupled with this novel operator, our
reconstruction network achieves very high reconstruction accuracy, even in the
presence of incomplete information about a shape, given a soft or functional
map expressed in a reduced basis. Finally, we demonstrate that the
multiplicative functional algebra enjoyed by these operators can be used to
synthesize entirely new unseen shapes, in the context of shape interpolation
and shape analogy applications.
"
1423,3D Dynamic Point Cloud Inpainting via Temporal Consistency on Graphs,"  With the development of 3D laser scanning techniques and depth sensors, 3D
dynamic point clouds have attracted increasing attention as a representation of
3D objects in motion, enabling various applications such as 3D immersive
tele-presence, gaming and navigation. However, dynamic point clouds usually
exhibit holes of missing data, mainly due to the fast motion, the limitation of
acquisition and complicated structure. Leveraging on graph signal processing
tools, we represent irregular point clouds on graphs and propose a novel
inpainting method exploiting both intra-frame self-similarity and inter-frame
consistency in 3D dynamic point clouds. Specifically, for each missing region
in every frame of the point cloud sequence, we search for its self-similar
regions in the current frame and corresponding ones in adjacent frames as
references. Then we formulate dynamic point cloud inpainting as an optimization
problem based on the two types of references, which is regularized by a
graph-signal smoothness prior. Experimental results show the proposed approach
outperforms three competing methods significantly, both in objective and
subjective quality.
"
1424,"How much do you perceive this? An analysis on perceptions of geometric
  features, personalities and emotions in virtual humans (Extended Version)","  This work aims to evaluate people's perception regarding geometric features,
personalities and emotions characteristics in virtual humans. For this, we use
as a basis, a dataset containing the tracking files of pedestrians captured
from spontaneous videos and visualized them as identical virtual humans. The
goal is to focus on their behavior and not being distracted by other features.
In addition to tracking files containing their positions, the dataset also
contains pedestrian emotions and personalities detected using Computer Vision
and Pattern Recognition techniques. We proceed with our analysis in order to
answer the question if subjects can perceive geometric features as
distances/speeds as well as emotions and personalities in video sequences when
pedestrians are represented by virtual humans. Regarding the participants, an
amount of 73 people volunteered for the experiment. The analysis was divided in
two parts: i) evaluation on perception of geometric characteristics, such as
density, angular variation, distances and speeds, and ii) evaluation on
personality and emotion perceptions. Results indicate that, even without
explaining to the participants the concepts of each personality or emotion and
how they were calculated (considering geometric characteristics), in most of
the cases, participants perceived the personality and emotion expressed by the
virtual agents, in accordance with the available ground truth.
"
1425,Mechanics-Aware Modeling of Cloth Appearance,"  Micro-appearance models have brought unprecedented fidelity and details to
cloth rendering.
  Yet, these models neglect fabric mechanics: when a piece of cloth interacts
with the environment, its yarn and fiber arrangement usually changes in
response to external contact and tension forces.
  Since subtle changes of a fabric's microstructures can greatly affect its
macroscopic appearance, mechanics-driven appearance variation of fabrics has
been a phenomenon that remains to be captured.
  We introduce a mechanics-aware model that adapts the microstructures of cloth
yarns in a physics-based manner.
  Our technique works on two distinct physical scales: using physics-based
simulations of individual yarns, we capture the rearrangement of yarn-level
structures in response to external forces.
  These yarn structures are further enriched to obtain appearance-driving
fiber-level details.
  The cross-scale enrichment is made practical through a new parameter fitting
algorithm for simulation, an augmented procedural yarn model coupled with a
custom-design regression neural network.
  We train the network using a dataset generated by joint simulations at both
the yarn and the fiber levels.
  Through several examples, we demonstrate that our model is capable of
synthesizing photorealistic cloth appearance in a %dynamic and mechanically
plausible way.
"
1426,"A pressure field model for fast, robust approximation of net contact
  force and moment between nominally rigid objects","  We introduce an approximate model for predicting the net contact wrench
between nominally rigid objects for use in simulation, control, and state
estimation. The model combines and generalizes two ideas: a bed of springs (an
""elastic foundation"") and hydrostatic pressure. In this model, continuous
pressure fields are computed offline for the interior of each nominally rigid
object. Unlike hydrostatics or elastic foundations, the pressure fields need
not satisfy mechanical equilibrium conditions. When two objects nominally
overlap, a contact surface is defined where the two pressure fields are equal.
This static pressure is supplemented with a dissipative rate-dependent pressure
and friction to determine tractions on the contact surface. The contact wrench
between pairs of objects is an integral of traction contributions over this
surface. The model evaluates much faster than elasticity-theory models, while
showing the essential trends of force, moment, and stiffness increase with
contact load. It yields continuous wrenches even for non-convex objects and
coarse meshes. The method shows promise as sufficiently fast, accurate, and
robust for design-in-simulation of robot controllers.
"
1427,Meta-Sim: Learning to Generate Synthetic Datasets,"  Training models to high-end performance requires availability of large
labeled datasets, which are expensive to get. The goal of our work is to
automatically synthesize labeled datasets that are relevant for a downstream
task. We propose Meta-Sim, which learns a generative model of synthetic scenes,
and obtain images as well as its corresponding ground-truth via a graphics
engine. We parametrize our dataset generator with a neural network, which
learns to modify attributes of scene graphs obtained from probabilistic scene
grammars, so as to minimize the distribution gap between its rendered outputs
and target data. If the real dataset comes with a small labeled validation set,
we additionally aim to optimize a meta-objective, i.e. downstream task
performance. Experiments show that the proposed method can greatly improve
content generation quality over a human-engineered probabilistic scene grammar,
both qualitatively and quantitatively as measured by performance on a
downstream task.
"
1428,"XR: Enabling training mode in the human brain XR: Enabling training mode
  in the human brain","  The face of simulation-based training has greatly evolved, with the most
recent tools giving the ability to create virtual environments that rival
realism. At first glance, it might appear that what the training sector needs
is the most realistic simulators possible, but traditional simulators are not
necessarily the most efficient or practical training tools. With all that these
new technologies have to offer; the challenge is to go back to the core of
training needs and identify the right vector of sensory cues that will most
effectively enable training mode in the human brain. Bigger and Pricier doesn't
necessarily mean better. Simulation with cross-reality content (XR), which by
definition encompasses virtual reality (VR), mixed reality (MR), and augmented
reality (AR), is the most practical solution for deploying any kind of
simulation-based training. The authors of this paper (a teacher and a
technology expert) share their experiences and expose XR-specific best
practices to maximize learning transfer. ABOUT THE AUTHORS Sebastien Loze :
Starting his career in the modeling and simulation community more than 15 years
ago, S{\'e}bastien has focused on learning about the latest simulation
innovations and sharing information on how experts have solved their
challenges. He worked on the COTS integration at CAE and the Presagis focusing
on Simulation and Visualization products. More recently, Sebastien put together
simulation and training teams and strategies for emerging companies like CM
Labs and D-BOX. He is now the Simulations Industry Manager at Epic Games,
focusing on helping companies develop real-time solutions for simulation-based
training. Philippe Lepinard: Former military helicopter pilot and simulation
officer, Philippe L{\'e}pinard is now an associate professor at the University
of Paris-Est Cr{\'e}teil (UPEC). His research is focusing on playful learning
and training through simulation. He is one of the founding members of the
French simulation association.
"
1429,Automatic Support Removal for Additive Manufacturing Post Processing,"  An additive manufacturing (AM) process often produces a {\it near-net} shape
that closely conforms to the intended design to be manufactured. It sometimes
contains additional support structure (also called scaffolding), which has to
be removed in post-processing. We describe an approach to automatically
generate process plans for support removal using a multi-axis machining
instrument. The goal is to fracture the contact regions between each support
component and the part, and to do it in the most cost-effective order while
avoiding collisions with evolving near-net shape, including the remaining
support components. A recursive algorithm identifies a maximal collection of
support components whose connection regions to the part are accessible as well
as the orientations at which they can be removed at a given round. For every
such region, the accessible orientations appear as a 'fiber' in the
collision-free space of the evolving near-net shape and the tool assembly. To
order the removal of accessible supports, the algorithm constructs a search
graph whose edges are weighted by the Riemannian distance between the fibers.
The least expensive process plan is obtained by solving a traveling salesman
problem (TSP) over the search graph. The sequence of configurations obtained by
solving TSP is used as the input to a motion planner that finds collision free
paths to visit all accessible features. The resulting part without the support
structure can then be finished using traditional machining to produce the
intended design. The effectiveness of the method is demonstrated through
benchmark examples in 3D.
"
1430,A Deep Generative Model for Graph Layout,"  Different layouts can characterize different aspects of the same graph.
Finding a ""good"" layout of a graph is thus an important task for graph
visualization. In practice, users often visualize a graph in multiple layouts
by using different methods and varying parameter settings until they find a
layout that best suits the purpose of the visualization. However, this
trial-and-error process is often haphazard and time-consuming. To provide users
with an intuitive way to navigate the layout design space, we present a
technique to systematically visualize a graph in diverse layouts using deep
generative models. We design an encoder-decoder architecture to learn a model
from a collection of example layouts, where the encoder represents training
examples in a latent space and the decoder produces layouts from the latent
space. In particular, we train the model to construct a two-dimensional latent
space for users to easily explore and generate various layouts. We demonstrate
our approach through quantitative and qualitative evaluations of the generated
layouts. The results of our evaluations show that our model is capable of
learning and generalizing abstract concepts of graph layouts, not just
memorizing the training examples. In summary, this paper presents a
fundamentally new approach to graph visualization where a machine learning
model learns to visualize a graph from examples without manually-defined
heuristics.
"
1431,Differentiable Visual Computing,"  Derivatives of computer graphics, image processing, and deep learning
algorithms have tremendous use in guiding parameter space searches, or solving
inverse problems. As the algorithms become more sophisticated, we no longer
only need to differentiate simple mathematical functions, but have to deal with
general programs which encode complex transformations of data. This
dissertation introduces three tools for addressing the challenges that arise
when obtaining and applying the derivatives for complex graphics algorithms.
  Traditionally, practitioners have been constrained to composing programs with
a limited set of operators, or hand-deriving derivatives. We extend the image
processing language Halide with reverse-mode automatic differentiation, and the
ability to automatically optimize the gradient computations. This enables
automatic generation of the gradients of arbitrary Halide programs, at high
performance, with little programmer effort.
  In 3D rendering, the gradient is required with respect to variables such as
camera parameters, geometry, and appearance. However, computing the gradient is
challenging because the rendering integral includes visibility terms that are
not differentiable. We introduce, to our knowledge, the first general-purpose
differentiable ray tracer that solves the full rendering equation, while
correctly taking the geometric discontinuities into account.
  Finally, we demonstrate that the derivatives of light path throughput can
also be useful for guiding sampling in forward rendering. Simulating light
transport in the presence of multi-bounce glossy effects and motion in 3D
rendering is challenging due to the hard-to-sample high-contribution areas. We
present a Markov Chain Monte Carlo rendering algorithm that extends Metropolis
Light Transport by automatically and explicitly adapting to the local
integrand, thereby increasing sampling efficiency.
"
1432,Structurally optimized shells,"  Shells, i.e., objects made of a thin layer of material following a surface,
are among the most common structures in use. They are highly efficient, in
terms of material required to maintain strength, but also prone to deformation
and failure. We introduce an efficient method for reinforcing shells, that is,
adding material to the shell to increase its resilience to external loads. Our
goal is to produce a reinforcement structure of minimal weight. It has been
demonstrated that optimal reinforcement structures may be qualitatively
different, depending on external loads and surface shape. In some cases, it
naturally consists of discrete protruding ribs; in other cases, a smooth shell
thickness variation allows to save more material.
  Most previously proposed solutions, starting from classical Michell trusses,
are not able to handle a full range of shells (e.g., are restricted to
self-supporting structures) or are unable to reproduce this range of behaviors,
resulting in suboptimal structures.
  We propose a new method that works for any input surface with any load
configurations, taking into account both in-plane (tensile/compression) and
out-of-plane (bending) forces. By using a more precise volume model, we are
capable of producing optimized structures with the full range of qualitative
behaviors. Our method includes new algorithms for determining the layout of
reinforcement structure elements, and an efficient algorithm to optimize their
shape, minimizing a non-linear non-convex functional at a fraction of the cost
and with better optimality compared to standard solvers.
  We demonstrate the optimization results for a variety of shapes, and the
improvements it yields in the strength of 3D-printed objects.
"
1433,"Synthetic Data Generation and Adaption for Object Detection in Smart
  Vending Machines","  This paper presents an improved scheme for the generation and adaption of
synthetic images for the training of deep Convolutional Neural Networks(CNNs)
to perform the object detection task in smart vending machines. While
generating synthetic data has proved to be effective for complementing the
training data in supervised learning methods, challenges still exist for
generating virtual images which are similar to those of the complex real scenes
and minimizing redundant training data. To solve these problems, we consider
the simulation of cluttered objects placed in a virtual scene and the
wide-angle camera with distortions used to capture the whole scene in the data
generation process, and post-processed the generated images with a
elaborately-designed generative network to make them more similar to the real
images. Various experiments have been conducted to prove the efficiency of
using the generated virtual images to enhance the detection precision on
existing datasets with limited real training data and the generalization
ability of applying the trained network to datasets collected in new
environment.
"
1434,SurfaceBrush: From Virtual Reality Drawings to Manifold Surfaces,"  Popular Virtual Reality (VR) tools allow users to draw varying-width,
ribbon-like 3D brush strokes by moving a hand-held controller in 3D space.
Artists frequently use dense collections of such strokes to draw virtual 3D
shapes. We propose SurfaceBrush, a surfacing method that converts such VR
drawings into user-intended manifold free-form 3D surfaces, providing a novel
approach for modeling 3D shapes. The inputs to our method consist of dense
collections of artist-drawn stroke ribbons described by the positions and
normals of their central polylines, and ribbon widths. These inputs are highly
distinct from those handled by existing surfacing frameworks and exhibit
different sparsity and error patterns, necessitating a novel surfacing
approach. We surface the input stroke drawings by identifying and leveraging
local coherence between nearby artist strokes. In particular, we observe that
strokes intended to be adjacent on the artist imagined surface often have
similar tangent directions along their respective polylines. We leverage this
local stroke direction consistency by casting the computation of the
user-intended manifold surface as a constrained matching problem on stroke
polyline vertices and edges. We first detect and smoothly connect adjacent
similarly-directed sequences of stroke edges producing one or more manifold
partial surfaces. We then complete the surfacing process by identifying and
connecting adjacent similarly directed edges along the borders of these partial
surfaces. We confirm the usability of the SurfaceBrush interface and the
validity of our drawing analysis via an observational study. We validate our
stroke surfacing algorithm by demonstrating an array of manifold surfaces
computed by our framework starting from a range of inputs of varying
complexity, and by comparing our outputs to reconstructions computed using
alternative means.
"
1435,Deferred Neural Rendering: Image Synthesis using Neural Textures,"  The modern computer graphics pipeline can synthesize images at remarkable
visual quality; however, it requires well-defined, high-quality 3D content as
input. In this work, we explore the use of imperfect 3D content, for instance,
obtained from photo-metric reconstructions with noisy and incomplete surface
geometry, while still aiming to produce photo-realistic (re-)renderings. To
address this challenging problem, we introduce Deferred Neural Rendering, a new
paradigm for image synthesis that combines the traditional graphics pipeline
with learnable components. Specifically, we propose Neural Textures, which are
learned feature maps that are trained as part of the scene capture process.
Similar to traditional textures, neural textures are stored as maps on top of
3D mesh proxies; however, the high-dimensional feature maps contain
significantly more information, which can be interpreted by our new deferred
neural rendering pipeline. Both neural textures and deferred neural renderer
are trained end-to-end, enabling us to synthesize photo-realistic images even
when the original 3D content was imperfect. In contrast to traditional,
black-box 2D generative neural networks, our 3D representation gives us
explicit control over the generated output, and allows for a wide range of
application domains. For instance, we can synthesize temporally-consistent
video re-renderings of recorded 3D scenes as our representation is inherently
embedded in 3D space. This way, neural textures can be utilized to coherently
re-render or manipulate existing video content in both static and dynamic
environments at real-time rates. We show the effectiveness of our approach in
several experiments on novel view synthesis, scene editing, and facial
reenactment, and compare to state-of-the-art approaches that leverage the
standard graphics pipeline as well as conventional generative neural networks.
"
1436,TileGAN: Synthesis of Large-Scale Non-Homogeneous Textures,"  We tackle the problem of texture synthesis in the setting where many input
images are given and a large-scale output is required. We build on recent
generative adversarial networks and propose two extensions in this paper.
First, we propose an algorithm to combine outputs of GANs trained on a smaller
resolution to produce a large-scale plausible texture map with virtually no
boundary artifacts. Second, we propose a user interface to enable artistic
control. Our quantitative and qualitative results showcase the generation of
synthesized high-resolution maps consisting of up to hundreds of megapixels as
a case in point.
"
1437,"Synthesis of Biologically Realistic Human Motion Using Joint Torque
  Actuation","  Using joint actuators to drive the skeletal movements is a common practice in
character animation, but the resultant torque patterns are often unnatural or
infeasible for real humans to achieve. On the other hand, physiologically-based
models explicitly simulate muscles and tendons and thus produce more human-like
movements and torque patterns. This paper introduces a technique to transform
an optimal control problem formulated in the muscle-actuation space to an
equivalent problem in the joint-actuation space, such that the solutions to
both problems have the same optimal value. By solving the equivalent problem in
the joint-actuation space, we can generate human-like motions comparable to
those generated by musculotendon models, while retaining the benefit of simple
modeling and fast computation offered by joint-actuation models. Our method
transforms constant bounds on muscle activations to nonlinear, state-dependent
torque limits in the joint-actuation space. In addition, the metabolic energy
function on muscle activations is transformed to a nonlinear function of joint
torques, joint configuration and joint velocity. Our technique can also benefit
policy optimization using deep reinforcement learning approach, by providing a
more anatomically realistic action space for the agent to explore during the
learning process. We take the advantage of the physiologically-based simulator,
OpenSim, to provide training data for learning the torque limits and the
metabolic energy function. Once trained, the same torque limits and the energy
function can be applied to drastically different motor tasks formulated as
either trajectory optimization or policy learning. Codebase:
https://github.com/jyf588/lrle and https://github.com/jyf588/lrle-rl-examples
"
1438,A Classification of Topological Discrepancies in Additive Manufacturing,"  Additive manufacturing (AM) enables enormous freedom for design of complex
structures. However, the process-dependent limitations that result in
discrepancies between as-designed and as-manufactured shapes are not fully
understood. The tradeoffs between infinitely many different ways to approximate
a design by a manufacturable replica are even harder to characterize. To
support design for AM (DfAM), one has to quantify local discrepancies
introduced by AM processes, identify the detrimental deviations (if any) to the
original design intent, and prescribe modifications to the design and/or
process parameters to countervail their effects. Our focus in this work will be
on topological analysis. There is ample evidence in many applications that
preserving local topology (e.g., connectivity of beams in a lattice) is
important even when slight geometric deviations can be tolerated. We first
present a generic method to characterize local topological discrepancies due to
material under- and over-deposition in AM, and show how it captures various
types of defects in the as-manufactured structures. We use this information to
systematically modify the as-manufactured outcomes within the limitations of
available 3D printer resolution(s), which often comes at the expense of
introducing more geometric deviations (e.g., thickening a beam to avoid
disconnection). We validate the effectiveness of the method on 3D examples with
nontrivial topologies such as lattice structures and foams.
"
1439,"Inverse Halftoning Through Structure-Aware Deep Convolutional Neural
  Networks","  The primary issue in inverse halftoning is removing noisy dots on flat areas
and restoring image structures (e.g., lines, patterns) on textured areas.
Hence, a new structure-aware deep convolutional neural network that
incorporates two subnetworks is proposed in this paper. One subnetwork is for
image structure prediction while the other is for continuous-tone image
reconstruction. First, to predict image structures, patch pairs comprising
continuous-tone patches and the corresponding halftoned patches generated
through digital halftoning are trained. Subsequently, gradient patches are
generated by convolving gradient filters with the continuous-tone patches. The
subnetwork for the image structure prediction is trained using the mini-batch
gradient descent algorithm given the halftoned patches and gradient patches,
which are fed into the input and loss layers of the subnetwork, respectively.
Next, the predicted map including the image structures is stacked on the top of
the input halftoned image through a fusion layer and fed into the image
reconstruction subnetwork such that the entire network is trained adaptively to
the image structures. The experimental results confirm that the proposed
structure-aware network can remove noisy dot-patterns well on flat areas and
restore details clearly on textured areas. Furthermore, it is demonstrated that
the proposed method surpasses the conventional state-of-the-art methods based
on deep convolutional neural networks and locally learned dictionaries.
"
1440,Single Image Portrait Relighting,"  Lighting plays a central role in conveying the essence and depth of the
subject in a portrait photograph. Professional photographers will carefully
control the lighting in their studio to manipulate the appearance of their
subject, while consumer photographers are usually constrained to the
illumination of their environment. Though prior works have explored techniques
for relighting an image, their utility is usually limited due to requirements
of specialized hardware, multiple images of the subject under controlled or
known illuminations, or accurate models of geometry and reflectance. To this
end, we present a system for portrait relighting: a neural network that takes
as input a single RGB image of a portrait taken with a standard cellphone
camera in an unconstrained environment, and from that image produces a relit
image of that subject as though it were illuminated according to any provided
environment map. Our method is trained on a small database of 18 individuals
captured under different directional light sources in a controlled light stage
setup consisting of a densely sampled sphere of lights. Our proposed technique
produces quantitatively superior results on our dataset's validation set
compared to prior works, and produces convincing qualitative relighting results
on a dataset of hundreds of real-world cellphone portraits. Because our
technique can produce a 640 $\times$ 640 image in only 160 milliseconds, it may
enable interactive user-facing photographic applications in the future.
"
1441,"Local Light Field Fusion: Practical View Synthesis with Prescriptive
  Sampling Guidelines","  We present a practical and robust deep learning solution for capturing and
rendering novel views of complex real world scenes for virtual exploration.
Previous approaches either require intractably dense view sampling or provide
little to no guidance for how users should sample views of a scene to reliably
render high-quality novel views. Instead, we propose an algorithm for view
synthesis from an irregular grid of sampled views that first expands each
sampled view into a local light field via a multiplane image (MPI) scene
representation, then renders novel views by blending adjacent local light
fields. We extend traditional plenoptic sampling theory to derive a bound that
specifies precisely how densely users should sample views of a given scene when
using our algorithm. In practice, we apply this bound to capture and render
views of real world scenes that achieve the perceptual quality of Nyquist rate
view sampling while using up to 4000x fewer views. We demonstrate our
approach's practicality with an augmented reality smartphone app that guides
users to capture input images of a scene and viewers that enable realtime
virtual exploration on desktop and mobile platforms.
"
1442,Extending discrete exterior calculus to a fractional derivative,"  Fractional partial differential equations (FDEs) are used to describe
phenomena that involve a ""non-local"" or ""long-range"" interaction of some kind.
Accurate and practical numerical approximation of their solutions is
challenging due to the dense matrices arising from standard discretization
procedures. In this paper, we begin to extend the well-established
computational toolkit of Discrete Exterior Calculus (DEC) to the fractional
setting, focusing on proper discretization of the fractional derivative. We
define a Caputo-like fractional discrete derivative, in terms of the standard
discrete exterior derivative operator from DEC, weighted by a measure of
distance between $p$-simplices in a simplicial complex. We discuss key
theoretical properties of the fractional discrete derivative and compare it to
the continuous fractional derivative via a series of numerical experiments.
"
1443,A Similarity Measure for Material Appearance,"  We present a model to measure the similarity in appearance between different
materials, which correlates with human similarity judgments. We first create a
database of 9,000 rendered images depicting objects with varying materials,
shape and illumination. We then gather data on perceived similarity from
crowdsourced experiments; our analysis of over 114,840 answers suggests that
indeed a shared perception of appearance similarity exists. We feed this data
to a deep learning architecture with a novel loss function, which learns a
feature space for materials that correlates with such perceived appearance
similarity. Our evaluation shows that our model outperforms existing metrics.
Last, we demonstrate several applications enabled by our metric, including
appearance-based search for material suggestions, database visualization,
clustering and summarization, and gamut mapping.
"
1444,Unsupervised Detection of Distinctive Regions on 3D Shapes,"  This paper presents a novel approach to learn and detect distinctive regions
on 3D shapes. Unlike previous works, which require labeled data, our method is
unsupervised. We conduct the analysis on point sets sampled from 3D shapes,
then formulate and train a deep neural network for an unsupervised shape
clustering task to learn local and global features for distinguishing shapes
with respect to a given shape set. To drive the network to learn in an
unsupervised manner, we design a clustering-based nonparametric softmax
classifier with an iterative re-clustering of shapes, and an adapted
contrastive loss for enhancing the feature embedding quality and stabilizing
the learning process. By then, we encourage the network to learn the point
distinctiveness on the input shapes. We extensively evaluate various aspects of
our approach and present its applications for distinctiveness-guided shape
retrieval, sampling, and view selection in 3D scenes.
"
1445,Few-Shot Unsupervised Image-to-Image Translation,"  Unsupervised image-to-image translation methods learn to map images in a
given class to an analogous image in a different class, drawing on unstructured
(non-registered) datasets of images. While remarkably successful, current
methods require access to many images in both source and destination classes at
training time. We argue this greatly limits their use. Drawing inspiration from
the human capability of picking up the essence of a novel object from a small
number of examples and generalizing from there, we seek a few-shot,
unsupervised image-to-image translation algorithm that works on previously
unseen target classes that are specified, at test time, only by a few example
images. Our model achieves this few-shot generation capability by coupling an
adversarial training scheme with a novel network design. Through extensive
experimental validation and comparisons to several baseline methods on
benchmark datasets, we verify the effectiveness of the proposed framework. Our
implementation and datasets are available at https://github.com/NVlabs/FUNIT .
"
1446,"What Do People See in a Twenty-Second Glimpse of Bivariate Vector Field
  Visualizations?","  Little is known about how people learn from a brief glimpse of
three-dimensional (3D) bivariate vector field visualizations and about how well
visual features can guide behavior. Here we report empirical study results on
the use of color, texture, and length to guide viewing of bivariate glyphs:
these three visual features are mapped to the first integer variable (v1) and
length to the second quantitative variable (v2). Participants performed two
tasks within 20 seconds: (1) MAX: find the largest v2 when v1 is fixed; (2)
SEARCH: find a specific bivariate variable shown on the screen in a vector
field. Our first study with eighteen participants performing these tasks showed
that the randomized vector positions, although they lessened viewers' ability
to group vectors, did not reduce task accuracy compared to structured vector
fields. This result may support that these color, texture, and length can
provide to a certain degree, guide viewers' attention to task-relevant regions.
The second study measured eye movement to quantify viewers' behaviors with
three-errors (scanning, recognition, and decision errors) and one-behavior
(refixation) metrics. Our results showed two dominant search strategies:
drilling and scanning. Coloring tended to restrict eye movement to the
task-relevant regions of interest, enabling drilling. Length tended to support
scanners who quickly wandered around at different v1 levels. Drillers had
significantly less errors than scanners and the error rates for color and
texture were also lowest. And length had limited discrimination power than
color and texture as a 3D visual guidance. Our experiment results may suggest
that using categorical visual feature could help obtain the global structure of
a vector field visualization. We provide the first benchmark of the attention
cost of seeing a bivariate vector on average about 5 items per second.
"
1447,"Picturing Bivariate Separable-Features for Univariate Vector Magnitudes
  in Large-Magnitude-Range Quantum Physics Data","  We present study results from two experiments to empirically validate that
separable bivariate pairs for univariate representations of
large-magnitude-range vectors are more efficient than integral pairs. The first
experiment with 20 participants compared: one integral pair, three separable
pairs, and one redundant pair, which is a mix of the integral and separable
features. Participants performed three local tasks requiring reading numerical
values, estimating ratio, and comparing two points. The second 18-participant
study compared three separable pairs using three global tasks when participants
must look at the entire field to get an answer: find a specific target in 20
seconds, find the maximum magnitude in 20 seconds, and estimate the total
number of vector exponents within 2 seconds. Our results also reveal the
following: separable pairs led to the most accurate answers and the shortest
task execution time, while integral dimensions were among the least accurate;
it achieved high performance only when a pop-out separable feature (here color)
was added. To reconcile this finding with the existing literature, our second
experiment suggests that the higher the separability, the higher the accuracy;
the reason is probably that the emergent global scene created by the separable
pairs reduces the subsequent search space.
"
1448,"Neural 3D Morphable Models: Spiral Convolutional Networks for 3D Shape
  Representation Learning and Generation","  Generative models for 3D geometric data arise in many important applications
in 3D computer vision and graphics. In this paper, we focus on 3D deformable
shapes that share a common topological structure, such as human faces and
bodies. Morphable Models and their variants, despite their linear formulation,
have been widely used for shape representation, while most of the recently
proposed nonlinear approaches resort to intermediate representations, such as
3D voxel grids or 2D views. In this work, we introduce a novel graph
convolutional operator, acting directly on the 3D mesh, that explicitly models
the inductive bias of the fixed underlying graph. This is achieved by enforcing
consistent local orderings of the vertices of the graph, through the spiral
operator, thus breaking the permutation invariance property that is adopted by
all the prior work on Graph Neural Networks. Our operator comes by construction
with desirable properties (anisotropic, topology-aware, lightweight,
easy-to-optimise), and by using it as a building block for traditional deep
generative architectures, we demonstrate state-of-the-art results on a variety
of 3D shape datasets compared to the linear Morphable Model and other graph
convolutional operators.
"
1449,Design and Optimization of Conforming Lattice Structures,"  Inspired by natural cellular materials such as trabecular bone, lattice
structures have been developed as a new type of lightweight material. In this
paper we present a novel method to design lattice structures that conform with
both the principal stress directions and the boundary of the optimized shape.
Our method consists of two major steps: the first optimizes concurrently the
shape (including its topology) and the distribution of orthotropic lattice
materials inside the shape to maximize stiffness under application-specific
external loads; the second takes the optimized configuration (i.e.
locally-defined orientation, porosity, and anisotropy) of lattice materials
from the previous step, and extracts a globally consistent lattice structure by
field-aligned parameterization. Our approach is robust and works for both 2D
planar and 3D volumetric domains. Numerical results and physical verifications
demonstrate remarkable structural properties of conforming lattice structures
generated by our method.
"
1450,A note on 'A fully parallel 3D thinning algorithm and its applications',"  A 3D thinning algorithm erodes a 3D binary image layer by layer to extract
the skeletons. This paper presents a correction to Ma and Sonka's thinning
algorithm, A fully parallel 3D thinning algorithm and its applications, which
fails to preserve connectivity of 3D objects. We start with Ma and Sonka's
algorithm and examine its verification of connectivity preservation. Our
analysis leads to a group of different deleting templates, which can preserve
connectivity of 3D objects.
"
1451,DEMC: A Deep Dual-Encoder Network for Denoising Monte Carlo Rendering,"  In this paper, we present DEMC, a deep Dual-Encoder network to remove Monte
Carlo noise efficiently while preserving details. Denoising Monte Carlo
rendering is different from natural image denoising since inexpensive
by-products (feature buffers) can be extracted in the rendering stage. Most of
them are noise-free and can provide sufficient details for image
reconstruction. However, these feature buffers also contain redundant
information, which makes Monte Carlo denoising different from natural image
denoising. Hence, the main challenge of this topic is how to extract useful
information and reconstruct clean images. To address this problem, we propose a
novel network structure, Dual-Encoder network with a feature fusion
sub-network, to fuse feature buffers firstly, then encode the fused feature
buffers and a noisy image simultaneously, and finally reconstruct a clean image
by a decoder network. Compared with the state-of-the-art methods, our model is
more robust on a wide range of scenes and is able to generate satisfactory
results in a significantly faster way.
"
1452,"An Incremental Dimensionality Reduction Method for Visualizing Streaming
  Multidimensional Data","  Dimensionality reduction (DR) methods are commonly used for analyzing and
visualizing multidimensional data. However, when data is a live streaming feed,
conventional DR methods cannot be directly used because of their computational
complexity and inability to preserve the projected data positions at previous
time points. In addition, the problem becomes even more challenging when the
dynamic data records have a varying number of dimensions as often found in
real-world applications. This paper presents an incremental DR solution. We
enhance an existing incremental PCA method in several ways to ensure its
usability for visualizing streaming multidimensional data. First, we use
geometric transformation and animation methods to help preserve a viewer's
mental map when visualizing the incremental results. Second, to handle data
dimension variants, we use an optimization method to estimate the projected
data positions, and also convey the resulting uncertainty in the visualization.
We demonstrate the effectiveness of our design with two case studies using
real-world datasets.
"
1453,"DeepICP: An End-to-End Deep Neural Network for 3D Point Cloud
  Registration","  We present DeepICP - a novel end-to-end learning-based 3D point cloud
registration framework that achieves comparable registration accuracy to prior
state-of-the-art geometric methods. Different from other keypoint based methods
where a RANSAC procedure is usually needed, we implement the use of various
deep neural network structures to establish an end-to-end trainable network.
Our keypoint detector is trained through this end-to-end structure and enables
the system to avoid the inference of dynamic objects, leverages the help of
sufficiently salient features on stationary objects, and as a result, achieves
high robustness. Rather than searching the corresponding points among existing
points, the key contribution is that we innovatively generate them based on
learned matching probabilities among a group of candidates, which can boost the
registration accuracy. Our loss function incorporates both the local similarity
and the global geometric constraints to ensure all above network designs can
converge towards the right direction. We comprehensively validate the
effectiveness of our approach using both the KITTI dataset and the
Apollo-SouthBay dataset. Results demonstrate that our method achieves
comparable or better performance than the state-of-the-art geometry-based
methods. Detailed ablation and visualization analysis are included to further
illustrate the behavior and insights of our network. The low registration error
and high robustness of our method makes it attractive for substantial
applications relying on the point cloud registration task.
"
1454,HLO: Half-kernel Laplacian Operator for Surface Smoothing,"  This paper presents a simple yet effective method for feature-preserving
surface smoothing. Through analyzing the differential property of surfaces, we
show that the conventional discrete Laplacian operator with uniform weights is
not applicable to feature points at which the surface is non-differentiable and
the second order derivatives do not exist. To overcome this difficulty, we
propose a Half-kernel Laplacian Operator (HLO) as an alternative to the
conventional Laplacian. Given a vertex v, HLO first finds all pairs of its
neighboring vertices and divides each pair into two subsets (called half
windows); then computes the uniform Laplacians of all such subsets and
subsequently projects the computed Laplacians to the full-window uniform
Laplacian to alleviate flipping and degeneration. The half window with least
regularization energy is then chosen for v. We develop an iterative approach to
apply HLO for surface denoising. Our method is conceptually simple and easy to
use because it has a single parameter, i.e., the number of iterations for
updating vertices. We show that our method can preserve features better than
the popular uniform Laplacian-based denoising and it significantly alleviates
the shrinkage artifact. Extensive experimental results demonstrate that HLO is
better than or comparable to state-of-the-art techniques both qualitatively and
quantitatively and that it is particularly good at handling meshes with high
noise. We will make our source code publicly available.
"
1455,Spectral Coarsening of Geometric Operators,"  We introduce a novel approach to measure the behavior of a geometric operator
before and after coarsening. By comparing eigenvectors of the input operator
and its coarsened counterpart, we can quantitatively and visually analyze how
well the spectral properties of the operator are maintained. Using this
measure, we show that standard mesh simplification and algebraic coarsening
techniques fail to maintain spectral properties. In response, we introduce a
novel approach for spectral coarsening. We show that it is possible to
significantly reduce the sampling density of an operator derived from a 3D
shape without affecting the low-frequency eigenvectors. By marrying techniques
developed within the algebraic multigrid and the functional maps literatures,
we successfully coarsen a variety of isotropic and anisotropic operators while
maintaining sparsity and positive semi-definiteness. We demonstrate the utility
of this approach for applications including operator-sensitive sampling, shape
matching, and graph pooling for convolutional neural networks.
"
1456,"PIFu: Pixel-Aligned Implicit Function for High-Resolution Clothed Human
  Digitization","  We introduce Pixel-aligned Implicit Function (PIFu), a highly effective
implicit representation that locally aligns pixels of 2D images with the global
context of their corresponding 3D object. Using PIFu, we propose an end-to-end
deep learning method for digitizing highly detailed clothed humans that can
infer both 3D surface and texture from a single image, and optionally, multiple
input images. Highly intricate shapes, such as hairstyles, clothing, as well as
their variations and deformations can be digitized in a unified way. Compared
to existing representations used for 3D deep learning, PIFu can produce
high-resolution surfaces including largely unseen regions such as the back of a
person. In particular, it is memory efficient unlike the voxel representation,
can handle arbitrary topology, and the resulting surface is spatially aligned
with the input image. Furthermore, while previous techniques are designed to
process either a single image or multiple views, PIFu extends naturally to
arbitrary number of views. We demonstrate high-resolution and robust
reconstructions on real world images from the DeepFashion dataset, which
contains a variety of challenging clothing types. Our method achieves
state-of-the-art performance on a public benchmark and outperforms the prior
work for clothed human digitization from a single image.
"
1457,Can NetGAN be improved on short random walks?,"  Graphs are useful structures that can model several important real-world
problems. Recently, learning graphs have drawn considerable attention, leading
to the proposal of new methods for learning these data structures. One of these
studies produced NetGAN, a new approach for generating graphs via random walks.
Although NetGAN has shown promising results in terms of accuracy in the tasks
of generating graphs and link prediction, the choice of vertices from which it
starts random walks can lead to inconsistent and highly variable results,
especially when the length of walks is short. As an alternative to random
starting, this study aims to establish a new method for initializing random
walks from a set of dense vertices. We purpose estimating the importance of a
node based on the inverse of its influence over the whole vertices of its
neighborhood through random walks of different sizes. The proposed method
manages to achieve significantly better accuracy, less variance and lesser
outliers.
"
1458,Measuring and simulating latency in interactive remote rendering systems,"  Background: The computationally intensive task of real-time rendering can be
offloaded to remote cloud systems. However, due to network latency, interactive
remote rendering (IRR) introduces the challenge of interaction latency (IL),
which is the time between an action and response to that action. Objectives: to
model sources of latency, measure it in a real-world network and to use this
understanding to simulate latency so that we have a controlled platform for
experimental work in latency management. Method: we present a seven-parameter
model of latency for a typical IRR system; we describe new, minimally intrusive
software methods for measuring latency in a 3D graphics environment and create
a novel latency simulator tool in software. Results: We demonstrate our latency
simulator is comparable to real-world behavior and confirm that real-world
latency exceeds the interactive limit of 70ms over long distance connections.
We also find that current approaches to measuring IL are not general enough for
most situations and therefore propose a novel general-purpose solution.
Conclusion: to ameliorate latency in IRR systems we need controllable
simulation tools for experimentation. In addition to a new measurement
technique, we propose a new approach that will be of interest to IRR
researchers and developers when designing IL compensation techniques.
"
1459,"Disentangled Human Body Embedding Based on Deep Hierarchical Neural
  Network","  Human bodies exhibit various shapes for different identities or poses, but
the body shape has certain similarities in structure and thus can be embedded
in a low-dimensional space. This paper presents an autoencoder-like network
architecture to learn disentangled shape and pose embedding specifically for
the 3D human body. This is inspired by recent progress of deformation-based
latent representation learning. To improve the reconstruction accuracy, we
propose a hierarchical reconstruction pipeline for the disentangling process
and construct a large dataset of human body models with consistent connectivity
for the learning of the neural network. Our learned embedding can not only
achieve superior reconstruction accuracy but also provide great flexibility in
3D human body generation via interpolation, bilinear interpolation, and latent
space sampling. The results from extensive experiments demonstrate the
powerfulness of our learned 3D human body embedding in various applications.
"
1460,Toward Standardized Classification of Foveated Displays,"  Emergent in the field of head mounted display design is a desire to leverage
the limitations of the human visual system to reduce the computation,
communication, and display workload in power and form-factor constrained
systems. Fundamental to this reduced workload is the ability to match display
resolution to the acuity of the human visual system, along with a resulting
need to follow the gaze of the eye as it moves, a process referred to as
foveation. A display that moves its content along with the eye may be called a
Foveated Display, though this term is also commonly used to describe displays
with non-uniform resolution that attempt to mimic human visual acuity. We
therefore recommend a definition for the term Foveated Display that accepts
both of these interpretations. Furthermore, we include a simplified model for
human visual Acuity Distribution Functions (ADFs) at various levels of visual
acuity, across wide fields of view and propose comparison of this ADF with the
Resolution Distribution Function of a foveated display for evaluation of its
resolution at a particular gaze direction. We also provide a taxonomy to allow
the field to meaningfully compare and contrast various aspects of foveated
displays in a display and optical technology-agnostic manner.
"
1461,Synthetic Defocus and Look-Ahead Autofocus for Casual Videography,"  In cinema, large camera lenses create beautiful shallow depth of field (DOF),
but make focusing difficult and expensive. Accurate cinema focus usually relies
on a script and a person to control focus in realtime. Casual videographers
often crave cinematic focus, but fail to achieve it. We either sacrifice
shallow DOF, as in smartphone videos; or we struggle to deliver accurate focus,
as in videos from larger cameras. This paper is about a new approach in the
pursuit of cinematic focus for casual videography. We present a system that
synthetically renders refocusable video from a deep DOF video shot with a
smartphone, and analyzes future video frames to deliver context-aware autofocus
for the current frame. To create refocusable video, we extend recent machine
learning methods designed for still photography, contributing a new dataset for
machine training, a rendering model better suited to cinema focus, and a
filtering solution for temporal coherence. To choose focus accurately for each
frame, we demonstrate autofocus that looks at upcoming video frames and applies
AI-assist modules such as motion, face, audio and saliency detection. We also
show that autofocus benefits from machine learning and a large-scale video
dataset with focus annotation, where we use our RVR-LAAF GUI to create this
sizable dataset efficiently. We deliver, for example, a shallow DOF video where
the autofocus transitions onto each person before she begins to speak. This is
impossible for conventional camera autofocus because it would require seeing
into the future.
"
1462,"MoGlow: Probabilistic and controllable motion synthesis using
  normalising flows","  Data-driven modelling and synthesis of motion is an active research area with
applications that include animation, games, and social robotics. This paper
introduces a new class of probabilistic, generative, and controllable
motion-data models based on normalising flows. Models of this kind can describe
highly complex distributions, yet can be trained efficiently using exact
maximum likelihood, unlike GANs or VAEs. Our proposed model is autoregressive
and uses LSTMs to enable arbitrarily long time-dependencies. Importantly, is is
also causal, meaning that each pose in the output sequence is generated without
access to poses or control inputs from future time steps; this absence of
algorithmic latency is important for interactive applications with real-time
motion control. The approach can in principle be applied to any type of motion
since it does not make restrictive assumptions such as the motion being cyclic
in nature. We evaluate the models on motion-capture datasets of human and
quadruped locomotion. Objective and subjective results show that
randomly-sampled motion from the proposed method attains a motion quality close
to recorded motion capture for both humans and animals.
"
1463,"Statistical Analysis and Modeling of the Geometry and Topology of Plant
  Roots","  The root is an important organ of a plant since it is responsible for water
and nutrient uptake. Analyzing and modelling variabilities in the geometry and
topology of roots can help in assessing the plant's health, understanding its
growth patterns, and modeling relations between plant species and between
plants and their environment. In this article, we develop a framework for the
statistical analysis and modeling of the geometry and topology of plant roots.
We represent root structures as points in a tree-shape space equipped with a
metric that quantifies geometric and topological differences between pairs of
roots. We then use these building blocks to compute geodesics, i.e., optimal
deformations under the metric between root structures, and to perform
statistical analysis on root populations. We demonstrate the utility of the
proposed framework through an application to a dataset of wheat roots grown in
different environmental conditions. We also show that the framework can be used
in various applications including classification and regression.
"
1464,Evaluation of 4D Light Field Compression Methods,"  Light field data records the amount of light at multiple points in space,
captured e.g. by an array of cameras or by a light-field camera that uses
microlenses. Since the storage and transmission requirements for such data are
tremendous, compression techniques for light fields are gaining momentum in
recent years. Although plenty of efficient compression formats do exist for
still and moving images, only a little research on the impact of these methods
on light field imagery is performed. In this paper, we evaluate the impact of
state-of-the-art image and video compression methods on quality of images
rendered from light field data. The methods include recent video compression
standards, especially AV1 and XVC finalised in 2018. To fully exploit the
potential of common image compression methods on four-dimensional light field
imagery, we have extended these methods into three and four dimensions. In this
paper, we show that the four-dimensional light field data can be compressed
much more than independent still images while maintaining the same visual
quality of a perceived picture. We gradually compare the compression
performance of all image and video compression methods, and eventually answer
the question, ""What is the best compression method for light field data?"".
"
1465,Transport-Based Neural Style Transfer for Smoke Simulations,"  Artistically controlling fluids has always been a challenging task.
Optimization techniques rely on approximating simulation states towards target
velocity or density field configurations, which are often handcrafted by
artists to indirectly control smoke dynamics. Patch synthesis techniques
transfer image textures or simulation features to a target flow field. However,
these are either limited to adding structural patterns or augmenting coarse
flows with turbulent structures, and hence cannot capture the full spectrum of
different styles and semantically complex structures. In this paper, we propose
the first Transport-based Neural Style Transfer (TNST) algorithm for volumetric
smoke data. Our method is able to transfer features from natural images to
smoke simulations, enabling general content-aware manipulations ranging from
simple patterns to intricate motifs. The proposed algorithm is physically
inspired, since it computes the density transport from a source input smoke to
a desired target configuration. Our transport-based approach allows direct
control over the divergence of the stylization velocity field by optimizing
incompressible and irrotational potentials that transport smoke towards
stylization. Temporal consistency is ensured by transporting and aligning
subsequent stylized velocities, and 3D reconstructions are computed by
seamlessly merging stylizations from different camera viewpoints.
"
1466,Learning Perspective Undistortion of Portraits,"  Near-range portrait photographs often contain perspective distortion
artifacts that bias human perception and challenge both facial recognition and
reconstruction techniques. We present the first deep learning based approach to
remove such artifacts from unconstrained portraits. In contrast to the previous
state-of-the-art approach, our method handles even portraits with extreme
perspective distortion, as we avoid the inaccurate and error-prone step of
first fitting a 3D face model. Instead, we predict a distortion correction flow
map that encodes a per-pixel displacement that removes distortion artifacts
when applied to the input image. Our method also automatically infers missing
facial features, i.e. occluded ears caused by strong perspective distortion,
with coherent details. We demonstrate that our approach significantly
outperforms the previous state-of-the-art both qualitatively and
quantitatively, particularly for portraits with extreme perspective distortion
or facial expressions. We further show that our technique benefits a number of
fundamental tasks, significantly improving the accuracy of both face
recognition and 3D reconstruction and enables a novel camera calibration
technique from a single portrait. Moreover, we also build the first perspective
portrait database with a large diversity in identities, expression and poses,
which will benefit the related research in this area.
"
1467,Smooth quasi-developable surfaces bounded by smooth curves,"  Computing a quasi-developable strip surface bounded by design curves finds
wide industrial applications. Existing methods compute discrete surfaces
composed of developable lines connecting sampling points on input curves which
are not adequate for generating smooth quasi-developable surfaces. We propose
the first method which is capable of exploring the full solution space of
continuous input curves to compute a smooth quasi-developable ruled surface
with as large developability as possible. The resulting surface is exactly
bounded by the input smooth curves and is guaranteed to have no
self-intersections. The main contribution is a variational approach to compute
a continuous mapping of parameters of input curves by minimizing a function
evaluating surface developability. Moreover, we also present an algorithm to
represent a resulting surface as a B-spline surface when input curves are
B-spline curves.
"
1468,Few-Shot Adversarial Learning of Realistic Neural Talking Head Models,"  Several recent works have shown how highly realistic human head images can be
obtained by training convolutional neural networks to generate them. In order
to create a personalized talking head model, these works require training on a
large dataset of images of a single person. However, in many practical
scenarios, such personalized talking head models need to be learned from a few
image views of a person, potentially even a single image. Here, we present a
system with such few-shot capability. It performs lengthy meta-learning on a
large dataset of videos, and after that is able to frame few- and one-shot
learning of neural talking head models of previously unseen people as
adversarial training problems with high capacity generators and discriminators.
Crucially, the system is able to initialize the parameters of both the
generator and the discriminator in a person-specific way, so that training can
be based on just a few images and done quickly, despite the need to tune tens
of millions of parameters. We show that such an approach is able to learn
highly realistic and personalized talking head models of new people and even
portrait paintings.
"
1469,"BrainPainter: A software for the visualisation of brain structures,
  biomarkers and associated pathological processes","  We present BrainPainter, a software that automatically generates images of
highlighted brain structures given a list of numbers corresponding to the
output colours of each region. Compared to existing visualisation software
(i.e. Freesurfer, SPM, 3D Slicer), BrainPainter has three key advantages: (1)
it does not require the input data to be in a specialised format, allowing
BrainPainter to be used in combination with any neuroimaging analysis tools,
(2) it can visualise both cortical and subcortical structures and (3) it can be
used to generate movies showing dynamic processes, e.g. propagation of
pathology on the brain. We highlight three use cases where BrainPainter was
used in existing neuroimaging studies: (1) visualisation of the degree of
atrophy through interpolation along a user-defined gradient of colours, (2)
visualisation of the progression of pathology in Alzheimer's disease as well as
(3) visualisation of pathology in subcortical regions in Huntington's disease.
Moreover, through the design of BrainPainter we demonstrate the possibility of
using a powerful 3D computer graphics engine such as Blender to generate brain
visualisations for the neuroscience community. Blender's capabilities, e.g.
particle simulations, motion graphics, UV unwrapping, raster graphics editing,
raytracing and illumination effects, open a wealth of possibilities for brain
visualisation not available in current neuroimaging software. BrainPainter is
customisable, easy to use, and can run straight from the web browser:
https://brainpainter.csail.mit.edu , as well as from source-code packaged in a
docker container: https://github.com/mrazvan22/brain-coloring . It can be used
to visualise biomarker data from any brain imaging modality, or simply to
highlight a particular brain structure for e.g. anatomy courses.
"
1470,"Efficient Plane-Based Optimization of Geometry and Texture for Indoor
  RGB-D Reconstruction","  We propose a novel approach to reconstruct RGB-D indoor scene based on plane
primitives. Our approach takes as input a RGB-D sequence and a dense coarse
mesh reconstructed from it, and generates a lightweight, low-polygonal mesh
with clear face textures and sharp features without losing geometry details
from the original scene. Compared to existing methods which only cover large
planar regions in the scene, our method builds the entire scene by adaptive
planes without losing geometry details and also preserves sharp features in the
mesh. Experiments show that our method is more efficient to generate textured
mesh from RGB-D data than state-of-the-arts.
"
1471,"The Stabilized Explicit Variable-Load Solver with Machine Learning
  Acceleration for the Rapid Solution of Stiff Chemical Kinetics","  In this study, a fast and stable machine-learned hybrid algorithm implemented
in TensorFlow for the integration of stiff chemical kinetics is introduced.
Numerical solutions to differential equations are at the core of computational
fluid dynamics calculations. As the size and complexity of the simulations
grow, so does the need for computational power and time. Many efforts have been
made to implement stiff chemistry solvers on GPUs but have not been highly
successful because of the logical divergence in traditional stiff solver
algorithms. Because of these constrains, a novel Explicit Stabilized
Variable-load (STEV) solver has been developed. Overstepping due to the
relatively large time steps is prevented by introducing limits to the maximum
changes of chemical species per time step. To prevent oscillations, a discrete
Fourier transform is introduced to dampen ringing. In contrast to conventional
explicit approaches, a variable-load approach is used where each cell in the
computational domain is advanced with its unique time step. This approach
allows cells to be integrated simultaneously while maintaining warp convergence
but finish at different iterations and be removed from the workload. To improve
the computational performance of the introduced solver, specific thermodynamic
quantities of interest were estimated using shallow neural networks in place of
polynomial fits, leading to an additional 10% savings in clock time with
minimal training and implementation requirements. However ML specific hardware
could increase the time savings to as much as 28%. While the complexity of
these particular machine learning models is not high by modern standards, the
impact on computational efficiency should not be ignored. The results show a
dramatic decrease in total chemistry solution time (over 200 times) while
maintaining a similar degree of accuracy.
"
1472,Data-Driven Crowd Simulation with Generative Adversarial Networks,"  This paper presents a novel data-driven crowd simulation method that can
mimic the observed traffic of pedestrians in a given environment. Given a set
of observed trajectories, we use a recent form of neural networks, Generative
Adversarial Networks (GANs), to learn the properties of this set and generate
new trajectories with similar properties. We define a way for simulated
pedestrians (agents) to follow such a trajectory while handling local collision
avoidance. As such, the system can generate a crowd that behaves similarly to
observations, while still enabling real-time interactions between agents. Via
experiments with real-world data, we show that our simulated trajectories
preserve the statistical properties of their input. Our method simulates crowds
in real time that resemble existing crowds, while also allowing insertion of
extra agents, combination with other simulation methods, and user interaction.
"
1473,A Smoothness Energy without Boundary Distortion for Curved Surfaces,"  Current quadratic smoothness energies for curved surfaces either exhibit
distortions near the boundary due to zero Neumann boundary conditions, or they
do not correctly account for intrinsic curvature, which leads to
unnatural-looking behavior away from the boundary. This leads to an unfortunate
trade-off: one can either have natural behavior in the interior, or a
distortion-free result at the boundary, but not both. We introduce a
generalized Hessian energy for curved surfaces, expressed in terms of the
covariant one-form Dirichlet energy, the Gaussian curvature, and the exterior
derivative. Energy minimizers solve the Laplace-Beltrami biharmonic equation,
correctly accounting for intrinsic curvature, leading to natural-looking
isolines. On the boundary, minimizers are as-linear-as-possible, which reduces
the distortion of isolines at the boundary. We discretize the covariant
one-form Dirichlet energy using Crouzeix-Raviart finite elements, arriving at a
discrete formulation of the Hessian energy for applications on curved surfaces.
We observe convergence of the discretization in our experiments.
"
1474,Parallel Coordinate Order for High-Dimensional Data,"  Visualization of high-dimensional data is counter-intuitive using
conventional graphs. Parallel coordinates are proposed as an alternative to
explore multivariate data more effectively. However, it is difficult to extract
relevant information through the parallel coordinates when the data are
high-dimensional with thousands of lines overlapping. The order of the axes
determines the perception of information on parallel coordinates. Thus, the
information between attributes remain hidden if coordinates are improperly
ordered. Here we propose a general framework to reorder the coordinates. This
framework is general to cover a large range of data visualization objective. It
is also flexible to contain many conventional ordering measures. Consequently,
we present the coordinate ordering binary optimization problem and enhance
towards a computationally efficient greedy approach that suites
high-dimensional data. Our approach is applied on wine data and on genetic
data. The purpose of dimension reordering of wine data is highlighting
attributes dependence. Genetic data are reordered to enhance cluster detection.
The presented framework shows that it is able to adapt the measures and
criteria tested.
"
1475,DEMEA: Deep Mesh Autoencoders for Non-Rigidly Deforming Objects,"  Mesh autoencoders are commonly used for dimensionality reduction, sampling
and mesh modeling. We propose a general-purpose DEep MEsh Autoencoder (DEMEA)
which adds a novel embedded deformation layer to a graph-convolutional mesh
autoencoder. The embedded deformation layer (EDL) is a differentiable
deformable geometric proxy which explicitly models point displacements of
non-rigid deformations in a lower dimensional space and serves as a local
rigidity regularizer. DEMEA decouples the parameterization of the deformation
from the final mesh resolution since the deformation is defined over a lower
dimensional embedded deformation graph. We perform a large-scale study on four
different datasets of deformable objects. Reasoning about the local rigidity of
meshes using EDL allows us to achieve higher-quality results for highly
deformable objects, compared to directly regressing vertex positions. We
demonstrate multiple applications of DEMEA, including non-rigid 3D
reconstruction from depth and shading cues, non-rigid surface tracking, as well
as the transfer of deformations over different meshes.
"
1476,Overt visual attention on rendered 3D objects,"  This work covers multiple aspects of overt visual attention on 3D renders:
measurement, projection, visualization, and application to studying the
influence of material appearance on looking behaviour. In the scope of this
work, we ran an eye-tracking experiment in which the observers are presented
with animations of rotating 3D objects. The objects were rendered to simulate
different metallic appearance, particularly smooth (glossy), rough (matte), and
coated gold. The eye-tracking results illustrate how material appearance itself
influences the observer's attention, while all the other parameters remain
unchanged. In order to make visualization of the attention maps more natural
and also make the analysis more accurate, we develop a novel technique of
projection of gaze fixations on the 3D surface of the figure itself, instead of
the conventional 2D plane of the screen. The proposed methodology will be
useful for further studies of attention and saliency in the computer graphics
domain.
"
1477,ENIGMA: Evolutionary Non-Isometric Geometry Matching,"  In this paper we propose a fully automatic method for shape correspondence
that is widely applicable, and especially effective for non isometric shapes
and shapes of different topology. We observe that fully-automatic shape
correspondence can be decomposed as a hybrid discrete/continuous optimization
problem, and we find the best sparse landmark correspondence, whose
sparse-to-dense extension minimizes a local metric distortion. To tackle the
combinatorial task of landmark correspondence we use an evolutionary genetic
algorithm, where the local distortion of the sparse-to-dense extension is used
as the objective function. We design novel geometrically guided genetic
operators, which, when combined with our objective, are highly effective for
non isometric shape matching. Our method outperforms state of the art methods
for automatic shape correspondence both quantitatively and qualitatively on
challenging datasets.
"
1478,Unsupervised Intuitive Physics from Past Experiences,"  We are interested in learning models of intuitive physics similar to the ones
that animals use for navigation, manipulation and planning. In addition to
learning general physical principles, however, we are also interested in
learning ``on the fly'', from a few experiences, physical properties specific
to new environments. We do all this in an unsupervised manner, using a
meta-learning formulation where the goal is to predict videos containing
demonstrations of physical phenomena, such as objects moving and colliding with
a complex background. We introduce the idea of summarizing past experiences in
a very compact manner, in our case using dynamic images, and show that this can
be used to solve the problem well and efficiently. Empirically, we show via
extensive experiments and ablation studies, that our model learns to perform
physical predictions that generalize well in time and space, as well as to a
variable number of interacting physical objects.
"
1479,"EgoFace: Egocentric Face Performance Capture and Videorealistic
  Reenactment","  Face performance capture and reenactment techniques use multiple cameras and
sensors, positioned at a distance from the face or mounted on heavy wearable
devices. This limits their applications in mobile and outdoor environments. We
present EgoFace, a radically new lightweight setup for face performance capture
and front-view videorealistic reenactment using a single egocentric RGB camera.
Our lightweight setup allows operations in uncontrolled environments, and lends
itself to telepresence applications such as video-conferencing from dynamic
environments. The input image is projected into a low dimensional latent space
of the facial expression parameters. Through careful adversarial training of
the parameter-space synthetic rendering, a videorealistic animation is
produced. Our problem is challenging as the human visual system is sensitive to
the smallest face irregularities that could occur in the final results. This
sensitivity is even stronger for video results. Our solution is trained in a
pre-processing stage, through a supervised manner without manual annotations.
EgoFace captures a wide variety of facial expressions, including mouth
movements and asymmetrical expressions. It works under varying illuminations,
background, movements, handles people from different ethnicities and can
operate in real time.
"
1480,Smooth Shells: Multi-Scale Shape Registration with Functional Maps,"  We propose a novel 3D shape correspondence method based on the iterative
alignment of so-called smooth shells. Smooth shells define a series of
coarse-to-fine shape approximations designed to work well with multiscale
algorithms. The main idea is to first align rough approximations of the
geometry and then add more and more details to refine the correspondence. We
fuse classical shape registration with Functional Maps by embedding the input
shapes into an intrinsic-extrinsic product space. Moreover, we disambiguate
intrinsic symmetries by applying a surrogate based Markov chain Monte Carlo
initialization. Our method naturally handles various types of noise that
commonly occur in real scans, like non-isometry or incompatible meshing.
Finally, we demonstrate state-of-the-art quantitative results on several
datasets and show that our pipeline produces smoother, more realistic results
than other automatic matching methods in real world applications.
"
1481,The Art of Food: Meal Image Synthesis from Ingredients,"  In this work we propose a new computational framework, based on generative
deep models, for synthesis of photo-realistic food meal images from textual
descriptions of its ingredients. Previous works on synthesis of images from
text typically rely on pre-trained text models to extract text features,
followed by a generative neural networks (GANs) aimed to generate realistic
images conditioned on the text features. These works mainly focus on generating
spatially compact and well-defined categories of objects, such as birds or
flowers. In contrast, meal images are significantly more complex, consisting of
multiple ingredients whose appearance and spatial qualities are further
modified by cooking methods. We propose a method that first builds an
attention-based ingredients-image association model, which is then used to
condition a generative neural network tasked with synthesizing meal images.
Furthermore, a cycle-consistent constraint is added to further improve image
quality and control appearance. Extensive experiments show our model is able to
generate meal image corresponding to the ingredients, which could be used to
augment existing dataset for solving other computational food analysis
problems.
"
1482,Use of convexity in contour detection,"  In this paper, we formulate a simple algorithm that detects contours around a
region of interest in an image. After an initial smoothing, the method is based
on viewing an image as a topographic surface and finding convex and/or concave
regions using simple calculus-based testing. The algorithm can achieve
multi-scale contour detection by altering the initial smoothing. We show that
the method has promise by comparing results on several images with the
watershed transform performed on the gradient images.
"
1483,"3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework
  using Fully 3D Convolutional Neural Networks","  The capability to perform facial analysis from video sequences has
significant potential to positively impact in many areas of life. One such area
relates to the medical domain to specifically aid in the diagnosis and
rehabilitation of patients with facial palsy. With this application in mind,
this paper presents an end-to-end framework, named 3DPalsyNet, for the tasks of
mouth motion recognition and facial palsy grading. 3DPalsyNet utilizes a 3D CNN
architecture with a ResNet backbone for the prediction of these dynamic tasks.
Leveraging transfer learning from a 3D CNNs pre-trained on the Kinetics data
set for general action recognition, the model is modified to apply joint
supervised learning using center and softmax loss concepts. 3DPalsyNet is
evaluated on a test set consisting of individuals with varying ranges of facial
palsy and mouth motions and the results have shown an attractive level of
classification accuracy in these task of 82% and 86% respectively. The frame
duration and the loss function affect was studied in terms of the predictive
qualities of the proposed 3DPalsyNet, where it was found shorter frame
duration's of 8 performed best for this specific task. Centre loss and softmax
have shown improvements in spatio-temporal feature learning than softmax loss
alone, this is in agreement with earlier work involving the spatial domain.
"
1484,"Learning Patterns in Sample Distributions for Monte Carlo Variance
  Reduction","  This paper investigates a novel a-posteriori variance reduction approach in
Monte Carlo image synthesis. Unlike most established methods based on lateral
filtering in the image space, our proposition is to produce the best possible
estimate for each pixel separately, from all the samples drawn for it. To
enable this, we systematically study the per-pixel sample distributions for
diverse scene configurations. Noting that these are too complex to be
characterized by standard statistical distributions (e.g. Gaussians), we
identify patterns recurring in them and exploit those for training a
variance-reduction model based on neural nets. In result, we obtain numerically
better estimates compared to simple averaging of samples. This method is
compatible with existing image-space denoising methods, as the improved
estimates of our model can be used for further processing. We conclude by
discussing how the proposed model could in future be extended for fully
progressive rendering with constant memory footprint and scene-sensitive
output.
"
1485,"Temporally Coherent Full 3D Mesh Human Pose Recovery from Monocular
  Video","  Advances in Deep Learning have recently made it possible to recover full 3D
meshes of human poses from individual images. However, extension of this notion
to videos for recovering temporally coherent poses still remains unexplored. A
major challenge in this regard is the lack of appropriately annotated video
data for learning the desired deep models. Existing human pose datasets only
provide 2D or 3D skeleton joint annotations, whereas the datasets are also
recorded in constrained environments. We first contribute a technique to
synthesize monocular action videos with rich 3D annotations that are suitable
for learning computational models for full mesh 3D human pose recovery.
Compared to the existing methods which simply ""texture-map"" clothes onto the 3D
human pose models, our approach incorporates Physics based realistic cloth
deformations with the human body movements. The generated videos cover a large
variety of human actions, poses, and visual appearances, whereas the
annotations record accurate human pose dynamics and human body surface
information. Our second major contribution is an end-to-end trainable Recurrent
Neural Network for full pose mesh recovery from monocular video. Using the
proposed video data and LSTM based recurrent structure, our network explicitly
learns to model the temporal coherence in videos and imposes geometric
consistency over the recovered meshes. We establish the effectiveness of the
proposed model with quantitative and qualitative analysis using the proposed
and benchmark datasets.
"
1486,3D Magic Mirror: Automatic Video to 3D Caricature Translation,"  Caricature is an abstraction of a real person which distorts or exaggerates
certain features, but still retains a likeness. While most existing works focus
on 3D caricature reconstruction from 2D caricatures or translating 2D photos to
2D caricatures, this paper presents a real-time and automatic algorithm for
creating expressive 3D caricatures with caricature style texture map from 2D
photos or videos. To solve this challenging ill-posed reconstruction problem
and cross-domain translation problem, we first reconstruct the 3D face shape
for each frame, and then translate 3D face shape from normal style to
caricature style by a novel identity and expression preserving VAE-CycleGAN.
Based on a labeling formulation, the caricature texture map is constructed from
a set of multi-view caricature images generated by CariGANs. The effectiveness
and efficiency of our method are demonstrated by comparison with baseline
implementations. The perceptual study shows that the 3D caricatures generated
by our method meet people's expectations of 3D caricature style.
"
1487,"Sea of Genes: Combining Animation and Narrative Strategies to Visualize
  Metagenomic Data for Museums","  We examine the application of narrative strategies to present a complex and
unfamiliar metagenomics dataset to the public in a science museum. Our dataset
contains information about microbial gene expressions that scientists use to
infer the behavior of microbes. This exhibit had three goals: to inform (the)
public about microbes' behavior, cycles, and patterns; to link their behavior
to the concept of gene expression; and to highlight scientists' use of gene
expression data to understand the role of microbes. To address these three
goals, we created a visualization with three narrative layers, each layer
corresponding to a goal. This study presented us with an opportunity to assess
existing frameworks for narrative visualization in a naturalistic setting. We
present three successive rounds of design and evaluation of our attempts to
engage visitors with complex data through narrative visualization. We highlight
our design choices and their underlying rationale based on extant theories. We
conclude that a central animation based on a curated dataset could successfully
achieve our first goal, i.e., to communicate the aggregate behavior and
interactions of microbes. We failed to achieve our second goal and had limited
success with the third goal. Overall, this study highlights the challenges of
telling multi-layered stories and the need for new frameworks for communicating
layered stories in public settings.
"
1488,Text-based Editing of Talking-head Video,"  Editing talking-head video to change the speech content or to remove filler
words is challenging. We propose a novel method to edit talking-head video
based on its transcript to produce a realistic output video in which the
dialogue of the speaker has been modified, while maintaining a seamless
audio-visual flow (i.e. no jump cuts). Our method automatically annotates an
input talking-head video with phonemes, visemes, 3D face pose and geometry,
reflectance, expression and scene illumination per frame. To edit a video, the
user has to only edit the transcript, and an optimization strategy then chooses
segments of the input corpus as base material. The annotated parameters
corresponding to the selected segments are seamlessly stitched together and
used to produce an intermediate video representation in which the lower half of
the face is rendered with a parametric face model. Finally, a recurrent video
generation network transforms this representation to a photorealistic video
that matches the edited transcript. We demonstrate a large variety of edits,
such as the addition, removal, and alteration of words, as well as convincing
language translation and full sentence synthesis.
"
1489,Benchmark of Polygon Quality Metrics for Polytopal Element Methods,"  Polytopal Element Methods (PEM) allow to solve differential equations on
general polygonal and polyhedral grids, potentially offering great flexibility
to mesh generation algorithms. Differently from classical finite element
methods, where the relation between the geometric properties of the mesh and
the performances of the solver are well known, the characterization of a good
polytopal element is still subject to ongoing research. Current shape
regularity criteria are quite restrictive, and greatly limit the set of valid
meshes. Nevertheless, numerical experiments revealed that PEM solvers can
perform well on meshes that are far outside the strict boundaries imposed by
the current theory, suggesting that the real capabilities of these methods are
much higher. In this work, we propose a benchmark to study the correlation
between general 2D polygonal meshes and PEM solvers. The benchmark aims to
explore the space of 2D polygonal meshes and polygonal quality metrics, in
order to identify weaker shape-regularity criteria under which the considered
methods can reliably work. The proposed tool is quite general, and can be
potentially used to study any PEM solver. Besides discussing the basics of the
benchmark, in the second part of the paper we demonstrate its application on a
representative member of the PEM family, namely the Virtual Element Method,
also discussing our findings.
"
1490,A Multi-Pass GAN for Fluid Flow Super-Resolution,"  We propose a novel method to up-sample volumetric functions with generative
neural networks using several orthogonal passes. Our method decomposes
generative problems on Cartesian field functions into multiple smaller
sub-problems that can be learned more efficiently. Specifically, we utilize two
separate generative adversarial networks: the first one up-scales slices which
are parallel to the XY-plane, whereas the second one refines the whole volume
along the Z-axis working on slices in the YZ-plane. In this way, we obtain full
coverage for the 3D target function and can leverage spatio-temporal
supervision with a set of discriminators. Additionally, we demonstrate that our
method can be combined with curriculum learning and progressive growing
approaches. We arrive at a first method that can up-sample volumes by a factor
of eight along each dimension, i.e., increasing the number of degrees of
freedom by 512. Large volumetric up-scaling factors such as this one have
previously not been attainable as the required number of weights in the neural
networks renders adversarial training runs prohibitively difficult. We
demonstrate the generality of our trained networks with a series of comparisons
to previous work, a variety of complex 3D results, and an analysis of the
resulting performance.
"
1491,"Salient Building Outline Enhancement and Extraction Using Iterative L0
  Smoothing and Line Enhancing","  In this paper, our goal is salient building outline enhancement and
extraction from images taken from consumer cameras using L0 smoothing. We
address weak outlines and over-smoothing problem. Weak outlines are often
undetected by edge extractors or easily smoothed out. We propose an iterative
method, including the smoothing cell and sharpening cell. In the smoothing
cell, we iteratively enlarge the smoothing level of the L0 smoothing. In the
sharpening cell, we use Hough Transform to extract lines, based on the
assumption that salient outlines for buildings are usually straight, and
enhance those extracted lines. Our goal is to enhance line structures and do
the L0 smoothing simultaneously. Also, we propose to create building masks from
semantic segmentation using an encoder-decoder network. The masks filter out
irrelevant edges. We also provide an evaluation dataset on this task.
"
1492,"StyleNAS: An Empirical Study of Neural Architecture Search to Uncover
  Surprisingly Fast End-to-End Universal Style Transfer Networks","  Neural Architecture Search (NAS) has been widely studied for designing
discriminative deep learning models such as image classification, object
detection, and semantic segmentation. As a large number of priors have been
obtained through the manual design of architectures in the fields, NAS is
usually considered as a supplement approach. In this paper, we have
significantly expanded the application areas of NAS by performing an empirical
study of NAS to search generative models, or specifically, auto-encoder based
universal style transfer, which lacks systematic exploration, if any, from the
architecture search aspect. In our work, we first designed a search space where
common operators for image style transfer such as VGG-based encoders, whitening
and coloring transforms (WCT), convolution kernels, instance normalization
operators, and skip connections were searched in a combinatorial approach. With
a simple yet effective parallel evolutionary NAS algorithm with multiple
objectives, we derived the first group of end-to-end deep networks for
universal photorealistic style transfer. Comparing to random search, a NAS
method that is gaining popularity recently, we demonstrated that carefully
designed search strategy leads to much better architecture design. Finally
compared to existing universal style transfer networks for photorealistic
rendering such as PhotoWCT that stacks multiple well-trained auto-encoders and
WCT transforms in a non-end-to-end manner, the architectures designed by
StyleNAS produce better style-transferred images with details preserving, using
a tiny number of operators/parameters, and enjoying around 500x inference time
speed-up.
"
1493,"CrossFill: Foam Structures with Graded Density for Continuous Material
  Extrusion","  The fabrication flexibility of 3D printing has sparked a lot of interest in
designing structures with spatially graded material properties. In this paper,
we propose a new type of density graded structure that is particularly designed
for 3D printing systems based on filament extrusion. In order to ensure
high-quality fabrication results, extrusion-based 3D printing requires not only
that the structures are self-supporting, but also that extrusion toolpaths are
continuous and free of self-overlap. The structure proposed in this paper,
called CrossFill, complies with these requirements. In particular, CrossFill is
a self-supporting foam structure, for which each layer is fabricated by a
single, continuous and overlap-free path of material extrusion. Our method for
generating CrossFill is based on a space-filling surface that employs spatially
varying subdivision levels. Dithering of the subdivision levels is performed to
accurately reproduce a prescribed density distribution. We demonstrate the
effectiveness of CrossFill on a number of experimental tests and applications.
"
1494,"Coherent Point Drift Networks: Unsupervised Learning of Non-Rigid Point
  Set Registration","  Given new pairs of source and target point sets, standard point set
registration methods often repeatedly conduct the independent iterative search
of desired geometric transformation to align the source point set with the
target one. This limits their use in applications to handle the real-time point
set registration with large volume dataset. This paper presents a novel method,
named coherent point drift networks (CPD-Net), for the unsupervised learning of
geometric transformation towards real-time non-rigid point set registration. In
contrast to previous efforts (e.g. coherent point drift), CPD-Net can learn
displacement field function to estimate geometric transformation from a
training dataset, consequently, to predict the desired geometric transformation
for the alignment of previously unseen pairs without any additional iterative
optimization process. Furthermore, CPD-Net leverages the power of deep neural
networks to fit an arbitrary function, that adaptively accommodates different
levels of complexity of the desired geometric transformation. Particularly,
CPD-Net is proved with a theoretical guarantee to learn a continuous
displacement vector function that could further avoid imposing additional
parametric smoothness constraint as in previous works. Our experiments verify
the impressive performance of CPD-Net for non-rigid point set registration on
various 2D/3D datasets, even in the presence of significant displacement noise,
outliers, and missing points. Our code will be available at
https://github.com/nyummvc/CPD-Net.
"
1495,"PyramNet: Point Cloud Pyramid Attention Network and Graph Embedding
  Module for Classification and Segmentation","  With the tide of artificial intelligence, we try to apply deep learning to
understand 3D data. Point cloud is an important 3D data structure, which can
accurately and directly reflect the real world. In this paper, we propose a
simple and effective network, which is named PyramNet, suites for point cloud
object classification and semantic segmentation in 3D scene. We design two new
operators: Graph Embedding Module(GEM) and Pyramid Attention Network(PAN).
Specifically, GEM projects point cloud onto the graph and practices the
covariance matrix to explore the relationship between points, so as to improve
the local feature expression ability of the model. PAN assigns some strong
semantic features to each point to retain fine geometric features as much as
possible. Furthermore, we provide extensive evaluation and analysis for the
effectiveness of PyramNet. Empirically, we evaluate our model on ModelNet40,
ShapeNet and S3DIS.
"
1496,Learning Physics-guided Face Relighting under Directional Light,"  Relighting is an essential step in realistically transferring objects from a
captured image into another environment. For example, authentic telepresence in
Augmented Reality requires faces to be displayed and relit consistent with the
observer's scene lighting. We investigate end-to-end deep learning
architectures that both de-light and relight an image of a human face. Our
model decomposes the input image into intrinsic components according to a
diffuse physics-based image formation model. We enable non-diffuse effects
including cast shadows and specular highlights by predicting a residual
correction to the diffuse render. To train and evaluate our model, we collected
a portrait database of 21 subjects with various expressions and poses. Each
sample is captured in a controlled light stage setup with 32 individual light
sources. Our method creates precise and believable relighting results and
generalizes to complex illumination conditions and challenging poses, including
when the subject is not looking straight at the camera.
"
1497,"Scan-flood Fill(SCAFF): an Efficient Automatic Precise Region Filling
  Algorithm for Complicated Regions","  Recently, instant level labeling for supervised machine learning requires a
considerable number of filled masks. In this paper, we propose an efficient
automatic region filling algorithm for complicated regions. Distinguishing
between adjacent connected regions, the Main Filling Process scans through all
pixels and fills all the pixels except boundary ones with either exterior or
interior label color. In this way, we succeed in classifying all the pixels
inside the region except boundary ones in the given image to form two groups: a
background group and a mask group. We then set all exterior label pixels to
background color, and interior label pixels to mask color. With this algorithm,
we are able to generate output masks precisely and efficiently even for
complicated regions as long as boundary pixels are given. Experimental results
show that the proposed algorithm can generate precise masks that allow for
various machine learning tasks such as supervised training. This algorithm can
effectively handle multiple regions, complicated `holes' and regions whose
boundaries touch the image border. By testing the algorithm on both toy and
practical images, we show that the performance of Scan-flood Fill(SCAFF) has
achieved favorable results.
"
1498,"Synthesizing 3D Shapes from Silhouette Image Collections using
  Multi-projection Generative Adversarial Networks","  We present a new weakly supervised learning-based method for generating novel
category-specific 3D shapes from unoccluded image collections. Our method is
weakly supervised and only requires silhouette annotations from unoccluded,
category-specific objects. Our method does not require access to the object's
3D shape, multiple observations per object from different views, intra-image
pixel-correspondences, or any view annotations. Key to our method is a novel
multi-projection generative adversarial network (MP-GAN) that trains a 3D shape
generator to be consistent with multiple 2D projections of the 3D shapes, and
without direct access to these 3D shapes. This is achieved through multiple
discriminators that encode the distribution of 2D projections of the 3D shapes
seen from a different views. Additionally, to determine the view information
for each silhouette image, we also train a view prediction network on
visualizations of 3D shapes synthesized by the generator. We iteratively
alternate between training the generator and training the view prediction
network. We validate our multi-projection GAN on both synthetic and real image
datasets. Furthermore, we also show that multi-projection GANs can aid in
learning other high-dimensional distributions from lower dimensional training
datasets, such as material-class specific spatially varying reflectance
properties from images.
"
1499,Laplacian Spectral Basis Functions,"  Representing a signal as a linear combination of a set of basis functions is
central in a wide range of applications, such as approximation, de-noising,
compression, shape correspondence and comparison. In this context, our paper
addresses the main aspects of signal approximation, such as the definition,
computation, and comparison of basis functions on arbitrary 3D shapes. Focusing
on the class of basis functions induced by the Laplace-Beltrami operator and
its spectrum, we introduce the diffusion and Laplacian spectral basis
functions, which are then compared with the harmonic and Laplacian
eigenfunctions. As main properties of these basis functions, which are commonly
used for numerical geometry processing and shape analysis, we discuss the
partition of the unity and non-negativity; the intrinsic definition and
invariance with respect to shape transformations (e.g., translation, rotation,
uniform scaling); the locality, smoothness, and orthogonality; the numerical
stability with respect to the domain discretisation; the computational cost and
storage overhead. Finally, we consider geometric metrics, such as the area,
conformal, and kernel-based norms, for the comparison and characterisation of
the main properties of the Laplacian basis functions.
"
1500,"Data-driven quasi-interpolant spline surfaces for point cloud
  approximation","  In this paper we investigate a local surface approximation, the Weighted
Quasi Interpolant Spline Approximation (wQISA), specifically designed for large
and noisy point clouds. We briefly describe the properties of the wQISA
representation and introduce a novel data-driven implementation, which combines
prediction capability and complexity efficiency. We provide an extended
comparative analysis with other continuous approximations on real data,
including different types of surfaces and levels of noise, such as 3D models,
terrain data and digital environmental data.
"
1501,Differentiable Surface Splatting for Point-based Geometry Processing,"  We propose Differentiable Surface Splatting (DSS), a high-fidelity
differentiable renderer for point clouds. Gradients for point locations and
normals are carefully designed to handle discontinuities of the rendering
function. Regularization terms are introduced to ensure uniform distribution of
the points on the underlying surface. We demonstrate applications of DSS to
inverse rendering for geometry synthesis and denoising, where large scale
topological changes, as well as small scale detail modifications, are
accurately and robustly handled without requiring explicit connectivity,
outperforming state-of-the-art techniques. The data and code are at
https://github.com/yifita/DSS.
"
1502,"Multi-Resolution Rendering for Computationally Expensive Lighting
  Effects","  Many lighting methods used in computer graphics such as indirect illumination
can have very high computational costs and need to be approximated for
real-time applications. These costs can be reduced by means of upsampling
techniques which tend to introduce artifacts and affect the visual quality of
the rendered image. This paper suggests a versatile approach for accelerating
the rendering of screen space methods while maintaining the visual quality.
This is achieved by exploiting the low frequency nature of many of these
illumination methods and the geometrical continuity of the scene. First the
screen space is dynamically divided into separate sub-images, then the
illumination is rendered for each sub-image in an adequate resolution and
finally the sub-images are put together in order to compose the final image.
Therefore we identify edges in the scene and generate masks precisely
specifying which part of the image is included in which sub-image. The masks
therefore determine which part of the image is rendered in which resolution. A
step wise upsampling and merging process then allows optically soft transitions
between the different resolution levels. For this paper, the introduced
multi-resolution rendering method was implemented and tested on three commonly
used lighting methods. These are screen space ambient occlusion, soft shadow
mapping and screen space global illumination.
"
1503,"Estimating Homogeneous Data-driven BRDF Parameters from a Reflectance
  Map under Known Natural Lighting","  In this paper we demonstrate robust estimation of the model parameters of a
fully-linear data-driven BRDF model from a reflectance map under known natural
lighting. To regularize the estimation of the model parameters, we leverage the
reflectance similarities within a material class. We approximate the space of
homogeneous BRDFs using a Gaussian mixture model, and assign a material class
to each Gaussian in the mixture model. We formulate the estimation of the model
parameters as a non-linear maximum a-posteriori optimization, and introduce a
linear approximation that estimates a solution per material class from which
the best solution is selected. We demonstrate the efficacy and robustness of
our method using the MERL BRDF database under a variety of natural lighting
conditions, and we provide a proof-of-concept real-world experiment.
"
1504,Inferring 3D Shapes from Image Collections using Adversarial Networks,"  We investigate the problem of learning a probabilistic distribution over
three-dimensional shapes given two-dimensional views of multiple objects taken
from unknown viewpoints. Our approach called projective generative adversarial
network (PrGAN) trains a deep generative model of 3D shapes whose projections
(or renderings) match the distributions of the provided 2D distribution. The
addition of a differentiable projection module allows us to infer the
underlying 3D shape distribution without access to any explicit 3D or viewpoint
annotation during the learning phase. We show that our approach produces 3D
shapes of comparable quality to GANs trained directly on 3D data. %for a number
of shape categoriesincluding chairs, airplanes, and cars. Experiments also show
that the disentangled representation of 2D shapes into geometry and viewpoint
leads to a good generative model of 2D shapes. The key advantage of our model
is that it estimates 3D shape, viewpoint, and generates novel views from an
input image in a completely unsupervised manner. We further investigate how the
generative models can be improved if additional information such as depth,
viewpoint or part segmentations is available at training time. To this end, we
present new differentiable projection operators that can be used by PrGAN to
learn better 3D generative models. Our experiments show that our method can
successfully leverage extra visual cues to create more diverse and accurate
shapes.
"
1505,Blue-noise sampling for human retinal cone spatial distribution modeling,"  This paper proposes a novel method for modeling human retinal cone
distribution. It is based on Blue-noise sampling algorithms that share
interesting properties with the sampling performed by the mosaic formed by cone
photoreceptors in the retina. Here we present the method together with a series
of examples of various real retinal patches. The same samples have also been
created with alternative algorithms and compared with plots of the center of
the inner segments of cone photoreceptors from imaged retinas. Results are
evaluated with different distance measure used in the field, like
nearest-neighbor analysis and pair correlation function. The proposed method
can describe features of a human retinal cone distribution with a certain
degree of similarity to the available data and can be efficiently used for
modeling local patches of retina.
"
1506,VIPER: Volume Invariant Position-based Elastic Rods,"  We extend the formulation of position-based rods to include elastic
volumetric deformations. We achieve this by introducing an additional degree of
freedom per vertex -- isotropic scale (and its velocity). Including scale
enriches the space of possible deformations, allowing the simulation of
volumetric effects, such as a reduction in cross-sectional area when a rod is
stretched. We rigorously derive the continuous formulation of its elastic
energy potentials, and hence its associated position-based dynamics (PBD)
updates to realize this model, enabling the simulation of up to 26000 DOFs at
140 Hz in our GPU implementation. We further show how rods can provide a
compact alternative to tetrahedral meshes for the representation of complex
muscle deformations, as well as providing a convenient representation for
collision detection. This is achieved by modeling a muscle as a bundle of rods,
for which we also introduce a technique to automatically convert a muscle
surface mesh into a rods-bundle. Finally, we show how rods and/or bundles can
be skinned to a surface mesh to drive its deformation, resulting in an
alternative to cages for real-time volumetric deformation.
"
1507,"RodSteward: A Design-to-Assembly System for Fabrication using 3D-Printed
  Joints and Precision-Cut Rods","  We present RodSteward, a design-to-assembly system for creating
furniture-scale structures composed of 3D printed joints and precision-cut
rods. The RodSteward systems consists of: RSDesigner, a fabrication-aware
design interface that visualizes accurate geometries during edits and
identifies infeasible designs; physical fabrication of parts via novel fully
automatic construction of solid 3D-printable joint geometries and automatically
generated cutting plans for rods; and RSAssembler, a guided-assembly interface
that prompts the user to place parts in order while showing a focus+context
visualization of the assembly in progress. We demonstrate the effectiveness of
our tools with a number of example constructions of varying complexity, style
and parameter choices.
"
1508,The Replica Dataset: A Digital Replica of Indoor Spaces,"  We introduce Replica, a dataset of 18 highly photo-realistic 3D indoor scene
reconstructions at room and building scale. Each scene consists of a dense
mesh, high-resolution high-dynamic-range (HDR) textures, per-primitive semantic
class and instance information, and planar mirror and glass reflectors. The
goal of Replica is to enable machine learning (ML) research that relies on
visually, geometrically, and semantically realistic generative models of the
world - for instance, egocentric computer vision, semantic segmentation in 2D
and 3D, geometric inference, and the development of embodied agents (virtual
robots) performing navigation, instruction following, and question answering.
Due to the high level of realism of the renderings from Replica, there is hope
that ML systems trained on Replica may transfer directly to real world image
and video data. Together with the data, we are releasing a minimal C++ SDK as a
starting point for working with the Replica dataset. In addition, Replica is
`Habitat-compatible', i.e. can be natively used with AI Habitat for training
and testing embodied agents.
"
1509,Symmetric Algorithmic Components for Shape Analysis with Diffeomorphisms,"  In computational anatomy, the statistical analysis of temporal deformations
and inter-subject variability relies on shape registration. However, the
numerical integration and optimization required in diffeomorphic registration
often lead to important numerical errors. In many cases, it is well known that
the error can be drastically reduced in the presence of a symmetry. In this
work, the leading idea is to approximate the space of deformations and images
with a possibly non-metric symmetric space structure using an involution, with
the aim to perform parallel transport. Through basic properties of symmetries,
we investigate how the implementations of a midpoint and the involution compare
with the ones of the Riemannian exponential and logarithm on diffeomorphisms
and propose a modification of these maps using registration errors. This leads
us to identify transvections, the composition of two symmetries, as a mean to
measure how far from symmetric the underlying structure is. We test our method
on a set of 138 cardiac shapes and demonstrate improved numerical consistency
in the Pole Ladder scheme.
"
1510,"A Survey on Deep Learning Architectures for Image-based Depth
  Reconstruction","  Estimating depth from RGB images is a long-standing ill-posed problem, which
has been explored for decades by the computer vision, graphics, and machine
learning communities. In this article, we provide a comprehensive survey of the
recent developments in this field. We will focus on the works which use deep
learning techniques to estimate depth from one or multiple images. Deep
learning, coupled with the availability of large training datasets, have
revolutionized the way the depth reconstruction problem is being approached by
the research community. In this article, we survey more than 100 key
contributions that appeared in the past five years, summarize the most commonly
used pipelines, and discuss their benefits and limitations. In retrospect of
what has been achieved so far, we also conjecture what the future may hold for
learning-based depth reconstruction research.
"
1511,"Volumetric Isosurface Rendering with Deep Learning-Based
  Super-Resolution","  Rendering an accurate image of an isosurface in a volumetric field typically
requires large numbers of data samples. Reducing the number of required samples
lies at the core of research in volume rendering. With the advent of deep
learning networks, a number of architectures have been proposed recently to
infer missing samples in multi-dimensional fields, for applications such as
image super-resolution and scan completion. In this paper, we investigate the
use of such architectures for learning the upscaling of a low-resolution
sampling of an isosurface to a higher resolution, with high fidelity
reconstruction of spatial detail and shading. We introduce a fully
convolutional neural network, to learn a latent representation generating a
smooth, edge-aware normal field and ambient occlusions from a low-resolution
normal and depth field. By adding a frame-to-frame motion loss into the
learning stage, the upscaling can consider temporal variations and achieves
improved frame-to-frame coherence. We demonstrate the quality of the network
for isosurfaces which were never seen during training, and discuss remote and
in-situ visualization as well as focus+context visualization as potential
applications
"
1512,"Image-based 3D Object Reconstruction: State-of-the-Art and Trends in the
  Deep Learning Era","  3D reconstruction is a longstanding ill-posed problem, which has been
explored for decades by the computer vision, computer graphics, and machine
learning communities. Since 2015, image-based 3D reconstruction using
convolutional neural networks (CNN) has attracted increasing interest and
demonstrated an impressive performance. Given this new era of rapid evolution,
this article provides a comprehensive survey of the recent developments in this
field. We focus on the works which use deep learning techniques to estimate the
3D shape of generic objects either from a single or multiple RGB images. We
organize the literature based on the shape representations, the network
architectures, and the training mechanisms they use. While this survey is
intended for methods which reconstruct generic objects, we also review some of
the recent works which focus on specific object classes such as human body
shapes and faces. We provide an analysis and comparison of the performance of
some key papers, summarize some of the open problems in this field, and discuss
promising directions for future research.
"
1513,A Statistical View on Synthetic Aperture Imaging for Occlusion Removal,"  Synthetic apertures find applications in many fields, such as radar, radio
telescopes, microscopy, sonar, ultrasound, LiDAR, and optical imaging. They
approximate the signal of a single hypothetical wide aperture sensor with
either an array of static small aperture sensors or a single moving small
aperture sensor. Common sense in synthetic aperture sampling is that a dense
sampling pattern within a wide aperture is required to reconstruct a clear
signal. In this article we show that there exists practical limits to both,
synthetic aperture size and number of samples for the application of occlusion
removal. This leads to an understanding on how to design synthetic aperture
sampling patterns and sensors in a most optimal and practically efficient way.
We apply our findings to airborne optical sectioning which uses camera drones
and synthetic aperture imaging to computationally remove occluding vegetation
or trees for inspecting ground surfaces.
"
1514,"A Simple Local Minimal Intensity Prior and An Improved Algorithm for
  Blind Image Deblurring","  Blind image deblurring is a long standing challenging problem in image
processing and low-level vision. Recently, sophisticated priors such as dark
channel prior, extreme channel prior, and local maximum gradient prior, have
shown promising effectiveness. However, these methods are computationally
expensive. Meanwhile, since these priors involved subproblems cannot be solved
explicitly, approximate solution is commonly used, which limits the best
exploitation of their capability. To address these problems, this work firstly
proposes a simplified sparsity prior of local minimal pixels, namely patch-wise
minimal pixels (PMP). The PMP of clear images is much more sparse than that of
blurred ones, and hence is very effective in discriminating between clear and
blurred images. Then, a novel algorithm is designed to efficiently exploit the
sparsity of PMP in deblurring. The new algorithm flexibly imposes sparsity
inducing on the PMP under the MAP framework rather than directly uses the half
quadratic splitting algorithm. By this, it avoids non-rigorous approximation
solution in existing algorithms, while being much more computationally
efficient. Extensive experiments demonstrate that the proposed algorithm can
achieve better practical stability compared with state-of-the-arts. In terms of
deblurring quality, robustness and computational efficiency, the new algorithm
is superior to state-of-the-arts. Code for reproducing the results of the new
method is available at https://github.com/FWen/deblur-pmp.git.
"
1515,scenery: Flexible Virtual Reality Visualization on the Java VM,"  Life science today involves computational analysis of a large amount and
variety of data, such as volumetric data acquired by state-of-the-art
microscopes, or mesh data from analysis of such data or simulations.
Visualization is often the first step in making sense of data, and a crucial
part of building and debugging analysis pipelines. It is therefore important
that visualizations can be quickly prototyped, as well as developed or embedded
into full applications. In order to better judge spatiotemporal relationships,
immersive hardware, such as Virtual or Augmented Reality (VR/AR) headsets and
associated controllers are becoming invaluable tools. In this work we introduce
scenery, a flexible VR/AR visualization framework for the Java VM that can
handle mesh and large volumetric data, containing multiple views, timepoints,
and color channels. scenery is free and open-source software, works on all
major platforms, and uses the Vulkan or OpenGL rendering APIs. We introduce
scenery's main features and example applications, such as its use in VR for
microscopy, in the biomedical image analysis software Fiji, or for visualizing
agent-based simulations.
"
1516,"Pi-surfaces: products of implicit surfaces towards constructive
  composition of 3D objects","  Implicit functions provide a fundamental basis to model 3D objects, no matter
they are rigid or deformable, in computer graphics and geometric modeling. This
paper introduces a new constructive scheme of implicitly-defined 3D objects
based on products of implicit functions. This scheme is in contrast with
popular approaches like blobbies, meta balls and soft objects, which rely on
the sum of specific implicit functions to fit a 3D object to a set of spheres.
"
1517,DeepView: View Synthesis with Learned Gradient Descent,"  We present a novel approach to view synthesis using multiplane images (MPIs).
Building on recent advances in learned gradient descent, our algorithm
generates an MPI from a set of sparse camera viewpoints. The resulting method
incorporates occlusion reasoning, improving performance on challenging scene
features such as object boundaries, lighting reflections, thin structures, and
scenes with high depth complexity. We show that our method achieves
high-quality, state-of-the-art results on two datasets: the Kalantari light
field dataset, and a new camera array dataset, Spaces, which we make publicly
available.
"
1518,Active Scene Understanding via Online Semantic Reconstruction,"  We propose a novel approach to robot-operated active understanding of unknown
indoor scenes, based on online RGBD reconstruction with semantic segmentation.
In our method, the exploratory robot scanning is both driven by and targeting
at the recognition and segmentation of semantic objects from the scene. Our
algorithm is built on top of the volumetric depth fusion framework (e.g.,
KinectFusion) and performs real-time voxel-based semantic labeling over the
online reconstructed volume. The robot is guided by an online estimated
discrete viewing score field (VSF) parameterized over the 3D space of 2D
location and azimuth rotation. VSF stores for each grid the score of the
corresponding view, which measures how much it reduces the uncertainty
(entropy) of both geometric reconstruction and semantic labeling. Based on VSF,
we select the next best views (NBV) as the target for each time step. We then
jointly optimize the traverse path and camera trajectory between two adjacent
NBVs, through maximizing the integral viewing score (information gain) along
path and trajectory. Through extensive evaluation, we show that our method
achieves efficient and accurate online scene parsing during exploratory
scanning.
"
1519,Topologically robust CAD model generation for structural optimisation,"  Computer-aided design (CAD) models play a crucial role in the design,
manufacturing and maintenance of products. Therefore, the mesh-based finite
element descriptions common in structural optimisation must be first translated
into CAD models. Currently, this can at best be performed semi-manually. We
propose a fully automated and topologically accurate approach to synthesise a
structurally-sound parametric CAD model from topology optimised finite element
models. Our solution is to first convert the topology optimised structure into
a spatial frame structure and then to regenerate it in a CAD system using
standard constructive solid geometry (CSG) operations. The obtained parametric
CAD models are compact, that is, have as few as possible geometric parameters,
which makes them ideal for editing and further processing within a CAD system.
The critical task of converting the topology optimised structure into an
optimal spatial frame structure is accomplished in several steps. We first
generate from the topology optimised voxel model a one-voxel-wide voxel chain
model using a topology-preserving skeletonisation algorithm from digital
topology. The weighted undirected graph defined by the voxel chain model yields
a spatial frame structure after processing it with standard graph algorithms.
Subsequently, we optimise the cross-sections and layout of the frame members to
recover its optimality, which may have been compromised during the conversion
process. At last, we generate the obtained frame structure in a CAD system by
repeatedly combining primitive solids, like cylinders and spheres, using
boolean operations. The resulting solid model is a boundary representation
(B-Rep) consisting of trimmed non-uniform rational B-spline (NURBS) curves and
surfaces.
"
1520,3D Geometric salient patterns analysis on 3D meshes,"  Pattern analysis is a wide domain that has wide applicability in many fields.
In fact, texture analysis is one of those fields, since the texture is defined
as a set of repetitive or quasi-repetitive patterns. Despite its importance in
analyzing 3D meshes, geometric texture analysis is less studied by geometry
processing community. This paper presents a new efficient approach for
geometric texture analysis on 3D triangular meshes. The proposed method is a
scale-aware approach that takes as input a 3D mesh and a user-scale. It
provides, as a result, a similarity-based clustering of texels in meaningful
classes. Experimental results of the proposed algorithm are presented for both
real-world and synthetic meshes within various textures. Furthermore, the
efficiency of the proposed approach was experimentally demonstrated under mesh
simplification and noise addition on the mesh surface. In this paper, we
present a practical application for semantic annotation of 3D geometric salient
texels.
"
1521,Conditional Parallel Coordinates,"  Parallel Coordinates are a popular data visualization technique for
multivariate data. Dating back to as early as 1880 PC are nearly as old as John
Snow's famous cholera outbreak map of 1855, which is frequently regarded as a
historic landmark for modern data visualization. Numerous extensions have been
proposed to address integrity, scalability and readability. We make a new case
to employ PC on conditional data, where additional dimensions are only unfolded
if certain criteria are met in an observation. Compared to standard PC which
operate on a flat set of dimensions the ontology of our input to Conditional
Parallel Coordinates is of hierarchical nature. We therefore briefly review
related work around hierarchical PC using aggregation or nesting techniques.
Our contribution is a visualization to seamlessly adapt PC for conditional data
under preservation of intuitive interaction patterns to select or highlight
polylines. We conclude with intuitions on how to operate CPC on two data sets:
an AutoML hyperparameter search log, and session results from a conversational
agent.
"
1522,Neural Volumes: Learning Dynamic Renderable Volumes from Images,"  Modeling and rendering of dynamic scenes is challenging, as natural scenes
often contain complex phenomena such as thin structures, evolving topology,
translucency, scattering, occlusion, and biological motion. Mesh-based
reconstruction and tracking often fail in these cases, and other approaches
(e.g., light field video) typically rely on constrained viewing conditions,
which limit interactivity. We circumvent these difficulties by presenting a
learning-based approach to representing dynamic objects inspired by the
integral projection model used in tomographic imaging. The approach is
supervised directly from 2D images in a multi-view capture setting and does not
require explicit reconstruction or tracking of the object. Our method has two
primary components: an encoder-decoder network that transforms input images
into a 3D volume representation, and a differentiable ray-marching operation
that enables end-to-end training. By virtue of its 3D representation, our
construction extrapolates better to novel viewpoints compared to screen-space
rendering techniques. The encoder-decoder architecture learns a latent
representation of a dynamic scene that enables us to produce novel content
sequences not seen during training. To overcome memory limitations of
voxel-based representations, we learn a dynamic irregular grid structure
implemented with a warp field during ray-marching. This structure greatly
improves the apparent resolution and reduces grid-like artifacts and jagged
motion. Finally, we demonstrate how to incorporate surface-based
representations into our volumetric-learning framework for applications where
the highest resolution is required, using facial performance capture as a case
in point.
"
1523,"Analytical Derivatives for Differentiable Renderer: 3D Pose Estimation
  by Silhouette Consistency","  Differentiable render is widely used in optimization-based 3D reconstruction
which requires gradients from differentiable operations for gradient-based
optimization. The existing differentiable renderers obtain the gradients of
rendering via numerical technique which is of low accuracy and efficiency.
Motivated by this fact, a differentiable mesh renderer with analytical
gradients is proposed. The main obstacle of rasterization based rendering being
differentiable is the discrete sampling operation. To make the rasterization
differentiable, the pixel intensity is defined as a double integral over the
pixel area and the integral is approximated by anti-aliasing with an average
filter. Then the analytical gradients with respect to the vertices coordinates
can be derived from the continuous definition of pixel intensity. To
demonstrate the effectiveness and efficiency of the proposed differentiable
renderer, experiments of 3D pose estimation by only multi-viewpoint silhouettes
were conducted. The experimental results show that 3D pose estimation without
3D and 2D joints supervision is capable of producing competitive results both
qualitatively and quantitatively. The experimental results also show that the
proposed differentiable renderer is of higher accuracy and efficiency compared
with previous method of differentiable renderer.
"
1524,"Camouflage Design of Analysis Based on HSV Color Statistics and K-means
  Clustering","  Since ancient times, it has been essential to adopting camouflage on the
battlefield, whether it is in the forefront, in-depth or the rear. The
traditional evaluation method is made up of people opinion. By watching target
or looking at the pictures, and determine the effect of camouflage, so it can
be more influenced by man's subjective factors. And now, in order to
objectively reflect the camouflage effect, we set up a model through using
images similarity to evaluate camouflage effect. Image similarity comparison is
divided into two main image feature comparison: image color features and
texture features of images. We now using computer design camouflage, camouflage
pattern design is divided into two aspects of design color and design plaques.
For the design of the color, we based on HSV color model, and as for the design
of plague, the key steps are the background color edge extraction, we adopt
algorithm based on k-means clustering analysis of the method of background
color edge extraction.
"
1525,"A decision-support method for information inconsistency resolution in
  direct modeling of CAD models","  Direct modeling is a very recent CAD paradigm that can provide unprecedented
modeling flexibility. It, however, lacks the parametric capability, which is
indispensable to modern CAD systems. For direct modeling to have this
capability, an additional associativity information layer in the form of
geometric constraint systems needs to be incorporated into direct modeling.
This is no trivial matter due to the possible inconsistencies between the
associativity information and geometry information in a model after direct
edits. The major issue of resolving such inconsistencies is that there often
exist many resolution options. The challenge lies in avoiding invalid
resolution options and prioritizing valid ones. This paper presents an
effective method to support the user in making decisions among the resolution
options. In particular, the method can provide automatic information
inconsistency reasoning, avoid invalid resolution options completely, and guide
the choice among valid resolution options. Case studies and comparisons have
been conducted to demonstrate the effectiveness of the method.
"
1526,TopoLines: Topological Smoothing for Line Charts,"  Line charts are commonly used to visualize a series of data values. When the
data are noisy, smoothing is applied to make the signal more apparent.
Conventional methods used to smooth line charts, e.g., using subsampling or
filters, such as median, Gaussian, or low-pass, each optimize for different
properties of the data. The properties generally do not include retaining peaks
(i.e., local minima and maxima) in the data, which is an important feature for
certain visual analytics tasks. We present TopoLines, a method for smoothing
line charts using techniques from Topological Data Analysis. The design goal of
TopoLines is to maintain prominent peaks in the data while minimizing any
residual error. We evaluate TopoLines for 2 visual analytics tasks by comparing
to 5 popular line smoothing methods with data from 4 application domains.
"
1527,Gaze-Contingent Ocular Parallax Rendering for Virtual Reality,"  Immersive computer graphics systems strive to generate perceptually realistic
user experiences. Current-generation virtual reality (VR) displays are
successful in accurately rendering many perceptually important effects,
including perspective, disparity, motion parallax, and other depth cues. In
this article, we introduce ocular parallax rendering, a technology that
accurately renders small amounts of gaze-contingent parallax capable of
improving depth perception and realism in VR. Ocular parallax describes the
small amounts of depth-dependent image shifts on the retina that are created as
the eye rotates. The effect occurs because the centers of rotation and
projection of the eye are not the same. We study the perceptual implications of
ocular parallax rendering by designing and conducting a series of user
experiments. Specifically, we estimate perceptual detection and discrimination
thresholds for this effect and demonstrate that it is clearly visible in most
VR applications. Additionally, we show that ocular parallax rendering provides
an effective ordinal depth cue and it improves the impression of realistic
depth in VR.
"
1528,ZomeFab: Cost-effective Hybrid Fabrication with Zometools,"  In recent years, personalized fabrication has received considerable attention
because of the widespread use of consumer-level three-dimensional (3D)
printers. However, such 3D printers have drawbacks, such as long production
time and limited output size, which hinder large-scale rapid-prototyping. In
this paper, for the time- and cost-effective fabrication of large-scale
objects, we propose a hybrid 3D fabrication method that combines 3D printing
and the Zometool construction set, which is a compact, sturdy, and reusable
structure for infill fabrication. The proposed method significantly reduces
fabrication cost and time by printing only thin 3D outer shells. In addition,
we design an optimization framework to generate both a Zometool structure and
printed surface partitions by optimizing several criteria, including
printability, material cost, and Zometool structure complexity. Moreover, we
demonstrate the effectiveness of the proposed method by fabricating various
large-scale 3D models.
"
1529,"Interactive Optimization of Generative Image Modeling using Sequential
  Subspace Search and Content-based Guidance","  Generative image modeling techniques such as GAN demonstrate highly
convincing image generation result. However, user interaction is often
necessary to obtain the desired results. Existing attempts add interactivity
but require either tailored architectures or extra data. We present a
human-in-the-optimization method that allows users to directly explore and
search the latent vector space of generative image modeling. Our system
provides multiple candidates by sampling the latent vector space, and the user
selects the best blending weights within the subspace using multiple sliders.
In addition, the user can express their intention through image editing tools.
The system samples latent vectors based on inputs and presents new candidates
to the user iteratively. An advantage of our formulation is that one can apply
our method to arbitrary pre-trained model without developing specialized
architecture or data. We demonstrate our method with various generative image
modeling applications, and show superior performance in a comparative user
study with prior art iGAN.
"
1530,Structural Design Using Laplacian Shells,"  We introduce a method to design lightweight shell objects that are
structurally robust under the external forces they may experience during use.
Given an input 3D model and a general description of the external forces, our
algorithm generates a structurally-sound minimum weight shell object. Our
approach works by altering the local shell thickness repeatedly based on the
stresses that develop inside the object. A key issue in shell design is that
large thickness values might result in self-intersections on the inner boundary
creating a significant computational challenge during optimization. To address
this, we propose a shape parametrization based on the solution to the Laplace's
equation that guarantees smooth and intersection-free shell boundaries.
Combined with our gradient-free optimization algorithm, our method provides a
practical solution to the structural design of hollow objects with a single
inner cavity. We demonstrate our method on a variety of problems with arbitrary
3D models under complex force configurations and validate its performance with
physical experiments.
"
1531,Joint Multi-frame Detection and Segmentation for Multi-cell Tracking,"  Tracking living cells in video sequence is difficult, because of cell
morphology and high similarities between cells. Tracking-by-detection methods
are widely used in multi-cell tracking. We perform multi-cell tracking based on
the cell centroid detection, and the performance of the detector has high
impact on tracking performance. In this paper, UNet is utilized to extract
inter-frame and intra-frame spatio-temporal information of cells. Detection
performance of cells in mitotic phase is improved by multi-frame input. Good
detection results facilitate multi-cell tracking. A mitosis detection algorithm
is proposed to detect cell mitosis and the cell lineage is built up. Another
UNet is utilized to acquire primary segmentation. Jointly using detection and
primary segmentation, cells can be fine segmented in highly dense cell
population. Experiments are conducted to evaluate the effectiveness of our
method, and results show its state-of-the-art performance.
"
1532,"A Convolutional Decoder for Point Clouds using Adaptive Instance
  Normalization","  Automatic synthesis of high quality 3D shapes is an ongoing and challenging
area of research. While several data-driven methods have been proposed that
make use of neural networks to generate 3D shapes, none of them reach the level
of quality that deep learning synthesis approaches for images provide. In this
work we present a method for a convolutional point cloud decoder/generator that
makes use of recent advances in the domain of image synthesis. Namely, we use
Adaptive Instance Normalization and offer an intuition on why it can improve
training. Furthermore, we propose extensions to the minimization of the
commonly used Chamfer distance for auto-encoding point clouds. In addition, we
show that careful sampling is important both for the input geometry and in our
point cloud generation process to improve results. The results are evaluated in
an auto-encoding setup to offer both qualitative and quantitative analysis. The
proposed decoder is validated by an extensive ablation study and is able to
outperform current state of the art results in a number of experiments. We show
the applicability of our method in the fields of point cloud upsampling, single
view reconstruction, and shape synthesis.
"
1533,Flexible SVBRDF Capture with a Multi-Image Deep Network,"  Empowered by deep learning, recent methods for material capture can estimate
a spatially-varying reflectance from a single photograph. Such lightweight
capture is in stark contrast with the tens or hundreds of pictures required by
traditional optimization-based approaches. However, a single image is often
simply not enough to observe the rich appearance of real-world materials. We
present a deep-learning method capable of estimating material appearance from a
variable number of uncalibrated and unordered pictures captured with a handheld
camera and flash. Thanks to an order-independent fusing layer, this
architecture extracts the most useful information from each picture, while
benefiting from strong priors learned from data. The method can handle both
view and light direction variation without calibration. We show how our method
improves its prediction with the number of input pictures, and reaches high
quality reconstructions with as little as 1 to 10 images -- a sweet spot
between existing single-image and complex multi-image approaches.
"
1534,ORRB -- OpenAI Remote Rendering Backend,"  We present the OpenAI Remote Rendering Backend (ORRB), a system that allows
fast and customizable rendering of robotics environments. It is based on the
Unity3d game engine and interfaces with the MuJoCo physics simulation library.
ORRB was designed with visual domain randomization in mind. It is optimized for
cloud deployment and high throughput operation. We are releasing it to the
public under a liberal MIT license: https://github.com/openai/orrb .
"
1535,Optimizing for Aesthetically Pleasing Quadrotor Camera Motion,"  In this paper we first contribute a large scale online study (N=400) to
better understand aesthetic perception of aerial video. The results indicate
that it is paramount to optimize smoothness of trajectories across all
keyframes. However, for experts timing control remains an essential tool.
Satisfying this dual goal is technically challenging because it requires giving
up desirable properties in the optimization formulation. Second, informed by
this study we propose a method that optimizes positional and temporal reference
fit jointly. This allows to generate globally smooth trajectories, while
retaining user control over reference timings. The formulation is posed as a
variable, infinite horizon, contour-following algorithm. Finally, a comparative
lab study indicates that our optimization scheme outperforms the
state-of-the-art in terms of perceived usability and preference of resulting
videos. For novices our method produces smoother and better looking results and
also experts benefit from generated timings.
"
1536,DVP: Data Visualization Platform,"  We identify two major steps in data analysis, data exploration for
understanding and observing patterns/relationships in data; and construction,
design and assessment of various models to formalize these relationships. For
each step, there exists a large set of tools and software. For the first step,
many visualization tools exist, such as, GGobi, Parallax, and Crystal Vision,
and most recently tableau and plottly. For the second step, many Scientific
Computing Environments (SCEs) exist, such as, Matlab, Mathematica, R and
Python. However, there does not exist a tool which allows for seamless two-way
interaction between visualization tools and SCEs. We have designed and
implemented a data visualization platform (DVP) with an architecture and design
that attempts to bridge this gap. DVP connects seamlessly to SCEs to bring the
computational capabilities to the visualization methods in a single coherent
platform. DVP is designed with two interfaces, the desktop stand alone version
and the online interface. To illustrate the power of DVP design, a free demo
for the online interface of DVP is available \citep{DVP} and very low-level
design details are explained in this article. Since DVP was launched, circa
2012, the present manuscript was not published since today for
commercialization and patent considerations.
"
1537,HEMELB Acceleration and Visualization for Cerebral Aneurysms,"  A weakness in the wall of a cerebral artery causing a dilation or ballooning
of the blood vessel is known as a cerebral aneurysm. Optimal treatment requires
fast and accurate diagnosis of the aneurysm. HemeLB is a fluid dynamics solver
for complex geometries developed to provide neurosurgeons with information
related to the flow of blood in and around aneurysms. On a cost efficient
platform, HemeLB could be employed in hospitals to provide surgeons with the
simulation results in real-time. In this work, we developed an improved version
of HemeLB for GPU implementation and result visualization. A visualization
platform for smooth interaction with end users is also presented. Finally, a
comprehensive evaluation of this implementation is reported. The results
demonstrate that the proposed implementation achieves a maximum performance of
15,168,964 site updates per second, and is capable of speeding up HemeLB for
deployment in hospitals and clinical investigations.
"
1538,"Variational Shape Completion for Virtual Planning of Jaw Reconstructive
  Surgery","  The premorbid geometry of the mandible is of significant relevance in jaw
reconstructive surgeries and occasionally unknown to the surgical team. In this
paper, an optimization framework is introduced to train deep models for
completion (reconstruction) of the missing segments of the bone based on the
remaining healthy structure. To leverage the contextual information of the
surroundings of the dissected region, the voxel-weighted Dice loss is
introduced. To address the non-deterministic nature of the shape completion
problem, we leverage a weighted multi-target probabilistic solution which is an
extension to the conditional variational autoencoder (CVAE). This approach
considers multiple targets as acceptable reconstructions, each weighted
according to their conformity with the original shape. We quantify the
performance gain of the proposed method against similar algorithms, including
CVAE, where we report statistically significant improvements in both
deterministic and probabilistic paradigms. The probabilistic model is also
evaluated on its ability to generate anatomically relevant variations for the
missing bone. As a unique aspect of this work, the model is tested on real
surgical cases where the clinical relevancy of its reconstructions and their
compliance with surgeon's virtual plan are demonstrated as necessary steps
towards clinical adoption.
"
1539,Efficient Spatial Anti-Aliasing Rendering for Line Joins on Vector Maps,"  The spatial anti-aliasing technique for line joins (intersections of the road
segments) on vector maps is exclusively crucial to visual experience and system
performance. Due to limitations of OpenGL API, one common practice to achieve
the anti-aliased effect is splicing multiple triangles at varying scale levels
to approximate the fan-shaped line joins. However, this approximation
inevitably produces some unreality, and the system rendering performance is not
optimal. To circumvent these drawbacks, in this paper, we propose a simple but
efficient algorithm which uses only two triangles to substitute the multiple
triangles approximation and then renders a realistic fan-shaped curve with
alpha operation based on geometrical relation computing. Our experiment shows
it has advantages of a realistic anti-aliasing effect, less memory cost, higher
frame rate, and drawing line joins without overlapping rendering. Our proposed
spatial anti-aliasing technique has been widely used in Internet Maps such as
Tencent Mobile Maps and Tencent Automotive Maps.
"
1540,Learning Manifold Patch-Based Representations of Man-Made Shapes,"  Choosing the right shape representation for geometry is crucial for making 3D
models compatible with existing applications. Focusing on piecewise-smooth
man-made shapes, we propose a new representation that is usable in conventional
CAD modeling pipelines and can also be learned by deep neural networks. We
demonstrate the benefits of our representation by applying it to the task of
sketch-based modeling. Given a raster image, our system infers a set of
parametric surfaces that realize the input in 3D. To capture the piecewise
smooth geometry of man-made shapes, we learn a special shape representation: a
deformable parametric template composed of Coons patches. Naively training such
a system, however, would suffer from non-manifold artifacts of the parametric
shapes as well as from a lack of data. To address this, we introduce loss
functions that bias the network to output non-self-intersecting shapes and
implement them as part of a fully self-supervised system, automatically
generating both shape templates and synthetic training data. To test the
efficacy of our system, we develop a testbed for sketch-based modeling and show
results on a gallery of synthetic and real artist sketches. As additional
applications, we also demonstrate shape interpolation and provide comparison to
related work.
"
1541,"FVA: Modeling Perceived Friendliness of Virtual Agents Using Movement
  Characteristics","  We present a new approach for improving the friendliness and warmth of a
virtual agent in an AR environment by generating appropriate movement
characteristics. Our algorithm is based on a novel data-driven friendliness
model that is computed using a user-study and psychological characteristics. We
use our model to control the movements corresponding to the gaits, gestures,
and gazing of friendly virtual agents (FVAs) as they interact with the user's
avatar and other agents in the environment. We have integrated FVA agents with
an AR environment using with a Microsoft HoloLens. Our algorithm can generate
plausible movements at interactive rates to increase the social presence. We
also investigate the perception of a user in an AR setting and observe that an
FVA has a statistically significant improvement in terms of the perceived
friendliness and social presence of a user compared to an agent without the
friendliness modeling. We observe an increment of 5.71% in the mean responses
to a friendliness measure and an improvement of 4.03% in the mean responses to
a social presence measure.
"
1542,"Geodesic Centroidal Voronoi Tessellations: Theories, Algorithms and
  Applications","  Nowadays, big data of digital media (including images, videos and 3D
graphical models) are frequently modeled as low-dimensional manifold meshes
embedded in a high-dimensional feature space. In this paper, we summarized our
recent work on geodesic centroidal Voronoi tessellations(GCVTs), which are
intrinsic geometric structures on manifold meshes. We show that GCVT can find a
widely range of interesting applications in computer vision and graphics, due
to the efficiency of search, location and indexing inherent in these intrinsic
geometric structures. Then we present the challenging issues of how to build
the combinatorial structures of GCVTs and establish their time and space
complexities, including both theoretical and algorithmic results.
"
1543,Learning to Approximate Directional Fields Defined over 2D Planes,"  Reconstruction of directional fields is a need in many geometry processing
tasks, such as image tracing, extraction of 3D geometric features, and finding
principal surface directions. A common approach to the construction of
directional fields from data relies on complex optimization procedures, which
are usually poorly formalizable, require a considerable computational effort,
and do not transfer across applications. In this work, we propose a deep
learning-based approach and study the expressive power and generalization
ability.
"
1544,"Automatic reconstruction of fully volumetric 3D building models from
  point clouds","  We present a novel method for reconstructing parametric, volumetric,
multi-story building models from unstructured, unfiltered indoor point clouds
by means of solving an integer linear optimization problem. Our approach
overcomes limitations of previous methods in several ways: First, we drop
assumptions about the input data such as the availability of separate scans as
an initial room segmentation. Instead, a fully automatic room segmentation and
outlier removal is performed on the unstructured point clouds. Second,
restricting the solution space of our optimization approach to arrangements of
volumetric wall entities representing the structure of a building enforces a
consistent model of volumetric, interconnected walls fitted to the observed
data instead of unconnected, paper-thin surfaces. Third, we formulate the
optimization as an integer linear programming problem which allows for an exact
solution instead of the approximations achieved with most previous techniques.
Lastly, our optimization approach is designed to incorporate hard constraints
which were difficult or even impossible to integrate before. We evaluate and
demonstrate the capabilities of our proposed approach on a variety of complex
real-world point clouds.
"
1545,XNect: Real-time Multi-Person 3D Motion Capture with a Single RGB Camera,"  We present a real-time approach for multi-person 3D motion capture at over 30
fps using a single RGB camera. It operates successfully in generic scenes which
may contain occlusions by objects and by other people. Our method operates in
subsequent stages. The first stage is a convolutional neural network (CNN) that
estimates 2D and 3D pose features along with identity assignments for all
visible joints of all individuals.We contribute a new architecture for this
CNN, called SelecSLS Net, that uses novel selective long and short range skip
connections to improve the information flow allowing for a drastically faster
network without compromising accuracy. In the second stage, a fully connected
neural network turns the possibly partial (on account of occlusion) 2Dpose and
3Dpose features for each subject into a complete 3Dpose estimate per
individual. The third stage applies space-time skeletal model fitting to the
predicted 2D and 3D pose per subject to further reconcile the 2D and 3D pose,
and enforce temporal coherence. Our method returns the full skeletal pose in
joint angles for each subject. This is a further key distinction from previous
work that do not produce joint angle results of a coherent skeleton in real
time for multi-person scenes. The proposed system runs on consumer hardware at
a previously unseen speed of more than 30 fps given 512x320 images as input
while achieving state-of-the-art accuracy, which we will demonstrate on a range
of challenging real-world scenes.
"
1546,Computational Design of Skinned Quad-Robots,"  We present a computational design system that assists users to model,
optimize, and fabricate quad-robots with soft skins.Our system addresses the
challenging task of predicting their physical behavior by fully integrating the
multibody dynamics of the mechanical skeleton and the elastic behavior of the
soft skin. The developed motion control strategy uses an alternating
optimization scheme to avoid expensive full space time-optimization,
interleaving space-time optimization for the skeleton and frame-by-frame
optimization for the full dynamics. The output are motor torques to drive the
robot to achieve a user prescribed motion trajectory.We also provide a
collection of convenient engineering tools and empirical manufacturing guidance
to support the fabrication of the designed quad-robot. We validate the
feasibility of designs generated with our system through physics simulations
and with a physically-fabricated prototype.
"
1547,Going Deeper with Lean Point Networks,"  In this work we introduce Lean Point Networks (LPNs) to train deeper and more
accurate point processing networks by relying on three novel point processing
blocks that improve memory consumption, inference time, and accuracy: a
convolution-type block for point sets that blends neighborhood information in a
memory-efficient manner; a crosslink block that efficiently shares information
across low- and high-resolution processing branches; and a multiresolution
point cloud processing block for faster diffusion of information. By combining
these blocks, we design wider and deeper point-based architectures. We report
systematic accuracy and memory consumption improvements on multiple publicly
available segmentation tasks by using our generic modules as drop-in
replacements for the blocks of multiple architectures (PointNet++, DGCNN,
SpiderNet, PointCNN).
"
1548,"FastDVDnet: Towards Real-Time Deep Video Denoising Without Flow
  Estimation","  In this paper, we propose a state-of-the-art video denoising algorithm based
on a convolutional neural network architecture. Until recently, video denoising
with neural networks had been a largely under explored domain, and existing
methods could not compete with the performance of the best patch-based methods.
The approach we introduce in this paper, called FastDVDnet, shows similar or
better performance than other state-of-the-art competitors with significantly
lower computing times. In contrast to other existing neural network denoisers,
our algorithm exhibits several desirable properties such as fast runtimes, and
the ability to handle a wide range of noise levels with a single network model.
The characteristics of its architecture make it possible to avoid using a
costly motion compensation stage while achieving excellent performance. The
combination between its denoising performance and lower computational load
makes this algorithm attractive for practical denoising applications. We
compare our method with different state-of-art algorithms, both visually and
with respect to objective quality metrics.
"
1549,RadVR: A 6DOF Virtual Reality Daylighting Analysis Tool,"  This work introduces RadVR, a virtual reality daylighiting analysis tools,
that simultaneously allows the analysis of qualitative immersive renderings and
the assessment of quantitative data of physically correct daylighting
simulations in a 6DOF virtual environment. With an end-to-end workflow and
integration with commonly used modeling software, the system takes a 3D model
and material properties as input and allows user-designers to (1) perform
physically-based daylighting simulations powered by the Radiance engine (2)
study sunlight penetration in different hours of the year by navigating through
time (3) Interact with a 9-point-in-time matrix for the nine most
representative times of the year (4) Visualize, compare and analyze daylighting
simulation results using integrated tools in virtual reality. By conducting
user experiments and comparing the system with a conventional 2D-display
daylight analysis tool, Diva4Rhino, the results show that RadVR outperforms
Diva4Rhino in spatial understanding tasks, navigation and sun position
analysis.
"
1550,"EVA: Generating Emotional Behavior of Virtual Agents using Expressive
  Features of Gait and Gaze","  We present a novel, real-time algorithm, EVA, for generating virtual agents
with various perceived emotions. Our approach is based on using Expressive
Features of gaze and gait to convey emotions corresponding to happy, sad,
angry, or neutral. We precompute a data-driven mapping between gaits and their
perceived emotions. EVA uses this gait emotion association at runtime to
generate appropriate walking styles in terms of gaits and gaze. Using the EVA
algorithm, we can simulate gaits and gazing behaviors of hundreds of virtual
agents in real-time with known emotional characteristics. We have evaluated the
benefits in different multi-agent VR simulation environments. Our studies
suggest that the use of expressive features corresponding to gait and gaze can
considerably increase the sense of presence in scenarios with multiple virtual
agents.
"
1551,"CoAug-MR: An MR-based Interactive Office Workstation Design System via
  Augmented Multi-Person Collaboration","  Digital prototyping and evaluation using 3D modeling and digital human models
are becoming more practical for customizing products to the preference of a
user. However, the 3D modeling is less accessible to casual users, and digital
human models suffer from insufficient body data and less intuitive illustration
on how people use the product or how it accommodates to their body. Recently,
VR-supported 'Do It Yourself' design has achieved real-time ergonomic
evaluation with users themselves by capturing their poses, however, it lacks
reliability and quality of design. In this paper, we explore a multi-person
interactive design approach that enables designers, users, and even ergonomists
to collaborate to achieve effective and reliable design and prototyping tasks.
Mixed Reality that utilizes Hololens and motion tracking devices had been
developed to provide instant design feedback and evaluation and to experience
prototyping in physical space. We evaluate the system based on the usability
study, where casual users and designers are engaged in the interactive process
of designing items with respect to the body information, the preference, and
the environment.
"
1552,Fast Universal Style Transfer for Artistic and Photorealistic Rendering,"  Universal style transfer is an image editing task that renders an input
content image using the visual style of arbitrary reference images, including
both artistic and photorealistic stylization. Given a pair of images as the
source of content and the reference of style, existing solutions usually first
train an auto-encoder (AE) to reconstruct the image using deep features and
then embeds pre-defined style transfer modules into the AE reconstruction
procedure to transfer the style of the reconstructed image through modifying
the deep features. While existing methods typically need multiple rounds of
time-consuming AE reconstruction for better stylization, our work intends to
design novel neural network architectures on top of AE for fast style transfer
with fewer artifacts and distortions all in one pass of end-to-end inference.
To this end, we propose two network architectures named ArtNet and PhotoNet to
improve artistic and photo-realistic stylization, respectively. Extensive
experiments demonstrate that ArtNet generates images with fewer artifacts and
distortions against the state-of-the-art artistic transfer algorithms, while
PhotoNet improves the photorealistic stylization results by creating sharp
images faithfully preserving rich details of the input content. Moreover,
ArtNet and PhotoNet can achieve 3X to 100X speed-up over the state-of-the-art
algorithms, which is a major advantage for large content images.
"
1553,"Learning Structural Graph Layouts and 3D Shapes for Long Span Bridges 3D
  Reconstruction","  A learning-based 3D reconstruction method for long-span bridges is proposed
in this paper. 3D reconstruction generates a 3D computer model of a real object
or scene from images, it involves many stages and open problems. Existing
point-based methods focus on generating 3D point clouds and their reconstructed
polygonal mesh or fitting-based geometrical models in urban scenes civil
structures reconstruction within Manhattan world constrains and have made great
achievements. Difficulties arise when an attempt is made to transfer these
systems to structures with complex topology and part relations like steel
trusses and long-span bridges, this could be attributed to point clouds are
often unevenly distributed with noise and suffer from occlusions and
incompletion, recovering a satisfactory 3D model from these highly unstructured
point clouds in a bottom-up pattern while preserving the geometrical and
topological properties makes enormous challenge to existing algorithms.
Considering the prior human knowledge that these structures are in conformity
to regular spatial layouts in terms of components, a learning-based
topology-aware 3D reconstruction method which can obtain high-level structural
graph layouts and low-level 3D shapes from images is proposed in this paper. We
demonstrate the feasibility of this method by testing on two real long-span
steel truss cable-stayed bridges.
"
1554,"Barriers towards no-reference metrics application to compressed video
  quality analysis: on the example of no-reference metric NIQE","  This paper analyses the application of no-reference metric NIQE to the task
of video-codec comparison. A number of issues in the metric behaviour on videos
was detected and described. The metric has outlying scores on black and
solid-coloured frames. The proposed averaging technique for metric quality
scores helped to improve the results in some cases. Also, NIQE has low-quality
scores for videos with detailed textures and higher scores for videos of lower
bitrates due to the blurring of these textures after compression. Although NIQE
showed natural results for many tested videos, it is not universal and
currently can not be used for video-codec comparisons.
"
1555,"Efficient Cloth Simulation using Miniature Cloth and Upscaling Deep
  Neural Networks","  Cloth simulation requires a fast and stable method for interactively and
realistically visualizing fabric materials using computer graphics. We propose
an efficient cloth simulation method using miniature cloth simulation and
upscaling Deep Neural Networks (DNN). The upscaling DNNs generate the target
cloth simulation from the results of physically-based simulations of a
miniature cloth that has similar physical properties to those of the target
cloth. We have verified the utility of the proposed method through experiments,
and the results demonstrate that it is possible to generate fast and stable
cloth simulations under various conditions.
"
1556,Progressive Refinement Imaging,"  This paper presents a novel technique for progressive online integration of
uncalibrated image sequences with substantial geometric and/or photometric
discrepancies into a single, geometrically and photometrically consistent
image. Our approach can handle large sets of images, acquired from a nearly
planar or infinitely distant scene at different resolutions in object domain
and under variable local or global illumination conditions. It allows for
efficient user guidance as its progressive nature provides a valid and
consistent reconstruction at any moment during the online refinement process.
Our approach avoids global optimization techniques, as commonly used in the
field of image refinement, and progressively incorporates new imagery into a
dynamically extendable and memory-efficient Laplacian pyramid. Our image
registration process includes a coarse homography and a local refinement stage
using optical flow. Photometric consistency is achieved by retaining the
photometric intensities given in a reference image, while it is being refined.
Globally blurred imagery and local geometric inconsistencies due to, e.g.
motion are detected and removed prior to image fusion. We demonstrate the
quality and robustness of our approach using several image and video sequences,
including handheld acquisition with mobile phones and zooming sequences with
consumer cameras.
"
1557,"Prescription AR: A Fully-Customized Prescription-Embedded Augmented
  Reality Display","  In this paper, we present a fully-customized AR display design that considers
the user's prescription, interpupillary distance, and taste of fashion. A
free-form image combiner embedded inside the prescription lens provides
augmented images onto the vision-corrected real world. We establish a
prescription-embedded AR display optical design method as well as the
customization method for individual users. Our design can cover myopia,
hyperopia, astigmatism, and presbyopia, and allows the eye-contact interaction
with privacy protection. A 169$g$ dynamic prototype showed a 40$^\circ$
$\times$ 20 $^\circ$ virtual image with a 23 cpd resolution at center field and
6 mm $\times$ 4 mm eye box, with the vision-correction and varifocal (0.5-3$m$)
capability.
"
1558,"Shadow Accrual Maps: Efficient Accumulation of City-Scale Shadows Over
  Time","  Large scale shadows from buildings in a city play an important role in
determining the environmental quality of public spaces. They can be both
beneficial, such as for pedestrians during summer, and detrimental, by
impacting vegetation and by blocking direct sunlight. Determining the effects
of shadows requires the accumulation of shadows over time across different
periods in a year. In this paper, we propose a simple yet efficient class of
approach that uses the properties of sun movement to track the changing
position of shadows within a fixed time interval. We use this approach to
extend two commonly used shadowing techniques, shadow maps and ray tracing, and
demonstrate the efficiency of our approach. Our technique is used to develop an
interactive visual analysis system, Shadow Profiler, targeted at city planners
and architects that allows them to test the impact of shadows for different
development scenarios. We validate the usefulness of this system through case
studies set in Manhattan, a dense borough of New York City.
"
1559,Progressive Wasserstein Barycenters of Persistence Diagrams,"  This paper presents an efficient algorithm for the progressive approximation
of Wasserstein barycenters of persistence diagrams, with applications to the
visual analysis of ensemble data. Given a set of scalar fields, our approach
enables the computation of a persistence diagram which is representative of the
set, and which visually conveys the number, data ranges and saliences of the
main features of interest found in the set. Such representative diagrams are
obtained by computing explicitly the discrete Wasserstein barycenter of the set
of persistence diagrams, a notoriously computationally intensive task. In
particular, we revisit efficient algorithms for Wasserstein distance
approximation [12,51] to extend previous work on barycenter estimation [94]. We
present a new fast algorithm, which progressively approximates the barycenter
by iteratively increasing the computation accuracy as well as the number of
persistent features in the output diagram. Such a progressivity drastically
improves convergence in practice and allows to design an interruptible
algorithm, capable of respecting computation time constraints. This enables the
approximation of Wasserstein barycenters within interactive times. We present
an application to ensemble clustering where we revisit the k-means algorithm to
exploit our barycenters and compute, within execution time constraints,
meaningful clusters of ensemble data along with their barycenter diagram.
Extensive experiments on synthetic and real-life data sets report that our
algorithm converges to barycenters that are qualitatively meaningful with
regard to the applications, and quantitatively comparable to previous
techniques, while offering an order of magnitude speedup when run until
convergence (without time constraint). Our algorithm can be trivially
parallelized to provide additional speedups in practice on standard
workstations. [...]
"
1560,Non-Smooth Newton Methods for Deformable Multi-Body Dynamics,"  We present a framework for the simulation of rigid and deformable bodies in
the presence of contact and friction. Our method is based on a non-smooth
Newton iteration that solves the underlying nonlinear complementarity problems
(NCPs) directly. This approach allows us to support nonlinear dynamics models,
including hyperelastic deformable bodies and articulated rigid mechanisms,
coupled through a smooth isotropic friction model. The fixed-point nature of
our method means it requires only the solution of a symmetric linear system as
a building block. We propose a new complementarity preconditioner for NCP
functions that improves convergence, and we develop an efficient GPU-based
solver based on the conjugate residual (CR) method that is suitable for
interactive simulations. We show how to improve robustness using a new
geometric stiffness approximation and evaluate our method's performance on a
number of robotics simulation scenarios, including dexterous manipulation and
training using reinforcement learning.
"
1561,Hacking VMAF with Video Color and Contrast Distortion,"  Video quality measurement takes an important role in many applications.
Full-reference quality metrics which are usually used in video codecs
comparisons are expected to reflect any changes in videos. In this article, we
consider different color corrections of compressed videos which increase the
values of full-reference metric VMAF and almost don't decrease other
widely-used metric SSIM. The proposed video contrast enhancement approach shows
the metric inapplicability in some cases for video codecs comparisons, as it
may be used for cheating in the comparisons via tuning to improve this metric
values.
"
1562,Void-and-Cluster Sampling of Large Scattered Data and Trajectories,"  We propose a data reduction technique for scattered data based on statistical
sampling. Our void-and-cluster sampling technique finds a representative subset
that is optimally distributed in the spatial domain with respect to the blue
noise property. In addition, it can adapt to a given density function, which we
use to sample regions of high complexity in the multivariate value domain more
densely. Moreover, our sampling technique implicitly defines an ordering on the
samples that enables progressive data loading and a continuous level-of-detail
representation. We extend our technique to sample time-dependent trajectories,
for example pathlines in a time interval, using an efficient and iterative
approach. Furthermore, we introduce a local and continuous error measure to
quantify how well a set of samples represents the original dataset. We apply
this error measure during sampling to guide the number of samples that are
taken. Finally, we use this error measure and other quantities to evaluate the
quality, performance, and scalability of our algorithm.
"
1563,"Tranquil Clouds: Neural Networks for Learning Temporally Coherent
  Features in Point Clouds","  Point clouds, as a form of Lagrangian representation, allow for powerful and
flexible applications in a large number of computational disciplines. We
propose a novel deep-learning method to learn stable and temporally coherent
feature spaces for points clouds that change over time. We identify a set of
inherent problems with these approaches: without knowledge of the time
dimension, the inferred solutions can exhibit strong flickering, and easy
solutions to suppress this flickering can result in undesirable local minima
that manifest themselves as halo structures. We propose a novel temporal loss
function that takes into account higher time derivatives of the point
positions, and encourages mingling, i.e., to prevent the aforementioned halos.
We combine these techniques in a super-resolution method with a truncation
approach to flexibly adapt the size of the generated positions. We show that
our method works for large, deforming point sets from different sources to
demonstrate the flexibility of our approach.
"
1564,"City-GAN: Learning architectural styles using a custom Conditional GAN
  architecture","  Generative Adversarial Networks (GANs) are a well-known technique that is
trained on samples (e.g. pictures of fruits) and which after training is able
to generate realistic new samples. Conditional GANs (CGANs) additionally
provide label information for subclasses (e.g. apple, orange, pear) which
enables the GAN to learn more easily and increase the quality of its output
samples. We use GANs to learn architectural features of major cities and to
generate images of buildings which do not exist. We show that currently
available GAN and CGAN architectures are unsuited for this task and propose a
custom architecture and demonstrate that our architecture has superior
performance for this task and verify its capabilities with extensive
experiments.
"
1565,"Tiny-Inception-ResNet-v2: Using Deep Learning for Eliminating Bonded
  Labors of Brick Kilns in South Asia","  This paper proposes to employ a Inception-ResNet inspired deep learning
architecture called Tiny-Inception-ResNet-v2 to eliminate bonded labor by
identifying brick kilns within ""Brick-Kiln-Belt"" of South Asia. The framework
is developed by training a network on the satellite imagery consisting of 11
different classes of South Asian region. The dataset developed during the
process includes the geo-referenced images of brick kilns, houses, roads,
tennis courts, farms, sparse trees, dense trees, orchards, parking lots, parks
and barren lands. The dataset is made publicly available for further research.
Our proposed network architecture with very fewer learning parameters
outperforms all state-of-the-art architectures employed for recognition of
brick kilns. Our proposed solution would enable regional monitoring and
evaluation mechanisms for the Sustainable Development Goals.
"
1566,"Improving the Projection of Global Structures in Data through Spanning
  Trees","  The connection of edges in a graph generates a structure that is independent
of a coordinate system. This visual metaphor allows creating a more flexible
representation of data than a two-dimensional scatterplot. In this work, we
present STAD (Spanning Trees as Approximation of Data), a dimensionality
reduction method to approximate the high-dimensional structure into a graph
with or without formulating prior hypotheses. STAD generates an abstract
representation of high-dimensional data by giving each data point a location in
a graph which preserves the distances in the original high-dimensional space.
The STAD graph is built upon the Minimum Spanning Tree (MST) to which new edges
are added until the correlation between the distances from the graph and the
original dataset is maximized. Additionally, STAD supports the inclusion of
additional functions to focus the exploration and allow the analysis of data
from new perspectives, emphasizing traits in data which otherwise would remain
hidden. We demonstrate the effectiveness of our method by applying it to two
real-world datasets: traffic density in Barcelona and temporal measurements of
air quality in Castile and Le\'on in Spain.
"
1567,Towards Robust Direction Invariance in Character Animation,"  In character animation, direction invariance is a desirable property. That
is, a pose facing north and the same pose facing south are considered the same;
a character that can walk to the north is expected to be able to walk to the
south in a similar style. To achieve such direction invariance, the current
practice is to remove the facing direction's rotation around the vertical axis
before further processing. Such a scheme, however, is not robust for rotational
behaviors in the sagittal plane. In search of a smooth scheme to achieve
direction invariance, we prove that in general a singularity free scheme does
not exist. We further connect the problem with the hairy ball theorem, which is
better-known to the graphics community. Due to the nonexistence of a
singularity free scheme, a general solution does not exist and we propose a
remedy by using a properly-chosen motion direction that can avoid singularities
for specific motions at hand. We perform comparative studies using two
deep-learning based methods, one builds kinematic motion representations and
the other learns physics-based controls. The results show that with our robust
direction invariant features, both methods can achieve better results in terms
of learning speed and/or final quality. We hope this paper can not only boost
performance for character animation methods, but also help related communities
currently not fully aware of the direction invariance problem to achieve more
robust results.
"
1568,"RayTracer.jl: A Differentiable Renderer that supports Parameter
  Optimization for Scene Reconstruction","  In this paper, we present RayTracer.jl, a renderer in Julia that is fully
differentiable using source-to-source Automatic Differentiation (AD). This
means that RayTracer not only renders 2D images from 3D scene parameters, but
it can be used to optimize for model parameters that generate a target image in
a Differentiable Programming (DP) pipeline. We interface our renderer with the
deep learning library Flux for use in combination with neural networks. We
demonstrate the use of this differentiable renderer in rendering tasks and in
solving inverse graphics problems.
"
1569,"The Effect of Data Transformations on Scalar Field Topological Analysis
  of High-Order FEM Solutions","  High-order finite element methods (HO-FEM) are gaining popularity in the
simulation community due to their success in solving complex flow dynamics.
There is an increasing need to analyze the data produced as output by these
simulations. Simultaneously, topological analysis tools are emerging as
powerful methods for investigating simulation data. However, most of the
current approaches to topological analysis have had limited application to
HO-FEM simulation data for two reasons. First, the current topological tools
are designed for linear data (polynomial degree one), but the polynomial degree
of the data output by these simulations is typically higher (routinely up to
polynomial degree six). Second, the simulation data and derived quantities of
the simulation data have discontinuities at element boundaries, and these
discontinuities do not match the input requirements for the topological tools.
One solution to both issues is to transform the high-order data to achieve
low-order, continuous inputs for topological analysis. Nevertheless, there has
been little work evaluating the possible transformation choices and their
downstream effect on the topological analysis. We perform an empirical study to
evaluate two commonly used data transformation methodologies along with the
recently introduced L-SIAC filter for processing high-order simulation data.
Our results show diverse behaviors are possible. We offer some guidance about
how best to consider a pipeline of topological analysis of HO-FEM simulations
with the currently available implementations of topological analysis.
"
1570,"LightGuider: Guiding Interactive Lighting Design using Suggestions,
  Provenance, and Quality Visualization","  LightGuider is a novel guidance-based approach to interactive lighting
design, which typically consists of interleaved 3D modeling operations and
light transport simulations. Rather than having designers use a trial-and-error
approach to match their illumination constraints and aesthetic goals,
LightGuider supports the process by simulating potential next modeling steps
that can deliver the most significant improvements. LightGuider takes
predefined quality criteria and the current focus of the designer into account
to visualize suggestions for lighting-design improvements via a specialized
provenance tree. This provenance tree integrates snapshot visualizations of how
well a design meets the given quality criteria weighted by the designer's
preferences. This integration facilitates the analysis of quality improvements
over the course of a modeling workflow as well as the comparison of alternative
design solutions. We evaluate our approach with three lighting designers to
illustrate its usefulness.
"
1571,Human Extraction and Scene Transition utilizing Mask R-CNN,"  Object detection is a trendy branch of computer vision, especially on human
recognition and pedestrian detection. Recognizing the complete body of a person
has always been a difficult problem. Over the years, researchers proposed
various methods, and recently, Mask R-CNN has made a breakthrough for instance
segmentation. Based on Faster R-CNN, Mask R-CNN has been able to generate a
segmentation mask for each instance. We propose an application to extracts
multiple persons from images and videos for pleasant life scenes to grouping
happy moments of people such as family or friends and a community for QOL
(Quality Of Life). We likewise propose a methodology to put extracted images of
persons into the new background. This enables a user to make a pleasant
collection of happy facial expressions and actions of his/her family and
friends in his/her life. Mask R-CNN detects all types of object masks from
images. Then our algorithm considers only the target person and extracts a
person only without obstacles, such as dogs in front of the person, and the
user also can select multiple persons as their expectations. Our algorithm is
effective for both an image and a video irrespective of the length of it. Our
algorithm does not add any overhead to Mask R-CNN, running at 5 fps. We show
examples of yoga-person in an image and a dancer in a dance-video frame. We
hope our simple and effective approach would serve as a baseline for replacing
the image background and help ease future research.
"
1572,"Motion Browser: Visualizing and Understanding Complex Upper Limb
  Movement Under Obstetrical Brachial Plexus Injuries","  The brachial plexus is a complex network of peripheral nerves that enables
sensing from and control of the movements of the arms and hand. Nowadays, the
coordination between the muscles to generate simple movements is still not well
understood, hindering the knowledge of how to best treat patients with this
type of peripheral nerve injury. To acquire enough information for medical data
analysis, physicians conduct motion analysis assessments with patients to
produce a rich dataset of electromyographic signals from multiple muscles
recorded with joint movements during real-world tasks. However, tools for the
analysis and visualization of the data in a succinct and interpretable manner
are currently not available. Without the ability to integrate, compare, and
compute multiple data sources in one platform, physicians can only compute
simple statistical values to describe patient's behavior vaguely, which limits
the possibility to answer clinical questions and generate hypotheses for
research. To address this challenge, we have developed \systemname, an
interactive visual analytics system which provides an efficient framework to
extract and compare muscle activity patterns from the patient's limbs and
coordinated views to help users analyze muscle signals, motion data, and video
information to address different tasks. The system was developed as a result of
a collaborative endeavor between computer scientists and orthopedic surgery and
rehabilitation physicians. We present case studies showing physicians can
utilize the information displayed to understand how individuals coordinate
their muscles to initiate appropriate treatment and generate new hypotheses for
future research.
"
1573,"DeepOrganNet: On-the-Fly Reconstruction and Visualization of 3D / 4D
  Lung Models from Single-View Projections by Deep Deformation Network","  This paper introduces a deep neural network based method, i.e., DeepOrganNet,
to generate and visualize high-fidelity 3D / 4D organ geometric models from
single-view medical image in real time. Traditional 3D / 4D medical image
reconstruction requires near hundreds of projections, which cost insufferable
computational time and deliver undesirable high imaging / radiation dose to
human subjects. Moreover, it always needs further notorious processes to
extract the accurate 3D organ models subsequently. To our knowledge, there is
no method directly and explicitly reconstructing multiple 3D organ meshes from
a single 2D medical grayscale image on the fly. Given single-view 2D medical
images, e.g., 3D / 4D-CT projections or X-ray images, our end-to-end
DeepOrganNet framework can efficiently and effectively reconstruct 3D / 4D lung
models with a variety of geometric shapes by learning the smooth deformation
fields from multiple templates based on a trivariate tensor-product deformation
technique, leveraging an informative latent descriptor extracted from input 2D
images. The proposed method can guarantee to generate high-quality and
high-fidelity manifold meshes for 3D / 4D lung models. The major contributions
of this work are to accurately reconstruct the 3D organ shapes from 2D
single-view projection, significantly improve the procedure time to allow
on-the-fly visualization, and dramatically reduce the imaging dose for human
subjects. Experimental results are evaluated and compared with the traditional
reconstruction method and the state-of-the-art in deep learning, by using
extensive 3D and 4D examples from synthetic phantom and real patient datasets.
The proposed method only needs several milliseconds to generate organ meshes
with 10K vertices, which has a great potential to be used in real-time image
guided radiation therapy (IGRT).
"
1574,"A Generalized Framework for Edge-preserving and Structure-preserving
  Image Smoothing","  Image smoothing is a fundamental procedure in applications of both computer
vision and graphics. The required smoothing properties can be different or even
contradictive among different tasks. Nevertheless, the inherent smoothing
nature of one smoothing operator is usually fixed and thus cannot meet the
various requirements of different applications. In this paper, a non-convex
non-smooth optimization framework is proposed to achieve diverse smoothing
natures where even contradictive smoothing behaviors can be achieved. To this
end, we first introduce the truncated Huber penalty function which has seldom
been used in image smoothing. A robust framework is then proposed. When
combined with the strong flexibility of the truncated Huber penalty function,
our framework is capable of a range of applications and can outperform the
state-of-the-art approaches in several tasks. In addition, an efficient
numerical solution is provided and its convergence is theoretically guaranteed
even the optimization framework is non-convex and non-smooth. The effectiveness
and superior performance of our approach are validated through comprehensive
experimental results in a range of applications.
"
1575,A system for efficient 3D printed stop-motion face animation,"  Computer animation in conjunction with 3D printing has the potential to
positively impact traditional stop-motion animation. As 3D printing every frame
of a computer animation is prohibitively slow and expensive, 3D printed
stop-motion can only be viable if animations can be faithfully reproduced using
a compact library of 3D printed and efficiently assemblable parts. We thus
present the first system for processing computer animation sequences (typically
faces) to produce an optimal set of replacement parts for use in 3D printed
stop-motion animation. Given an input animation sequence of topology invariant
deforming meshes, our problem is to output a library of replacement parts and
per-animation-frame assignment of the parts, such that we maximally approximate
the input animation, while minimizing the amount of 3D printing and assembly.
Inspired by current stop-motion workflows, a user manually indicates which
parts of the model are preferred for segmentation; then, we find curves with
minimal deformation along which to segment the mesh. We then present a novel
algorithm to zero out deformations along the segment boundaries, so that
replacement sets for each part can be interchangeably and seamlessly assembled
together. The part boundaries are designed to ease 3D printing and
instrumentation for assembly. Each part is then independently optimized using a
graph-cut technique to find a set of replacements, whose size can be user
defined, or automatically computed to adhere to a printing budget or allowed
deviation from the original animation. Our evaluation is threefold: we show
results on a variety of facial animations, both digital and 3D printed,
critiqued by a professional animator; we show the impact of various algorithmic
parameters; and compare our results to naive solutions. Our approach can reduce
the printing time and cost significantly for stop-motion animated films.
"
1576,Spectral Visualization Sharpening,"  In this paper, we propose a perceptually-guided visualization sharpening
technique. We analyze the spectral behavior of an established comprehensive
perceptual model to arrive at our approximated model based on an adapted
weighting of the bandpass images from a Gaussian pyramid. The main benefit of
this approximated model is its controllability and predictability for
sharpening color-mapped visualizations. Our method can be integrated into any
visualization tool as it adopts generic image-based post-processing, and it is
intuitive and easy to use as viewing distance is the only parameter. Using
highly diverse datasets, we show the usefulness of our method across a wide
range of typical visualizations.
"
1577,Data-Driven Physical Face Inversion,"  Facial animation is one of the most challenging problems in computer
graphics, and it is often solved using linear heuristics like blend-shape
rigging. More expressive approaches like physical simulation have emerged, but
these methods are very difficult to tune, especially when simulating a real
actor's face. We propose to use a simple finite element simulation approach for
face animation, and present a novel method for recovering the required
simulation parameters in order to best match a real actor's face motion. Our
method involves reconstructing a very small number of head poses of the actor
in 3D, where the head poses span different configurations of force directions
due to gravity. Our algorithm can then automatically recover both the
gravity-free rest shape of the face as well as the spatially-varying physical
material stiffness such that a forward simulation will match the captured
targets as closely as possible. As a result, our system can produce
actor-specific, physical parameters that can be immediately used in recent
physical simulation methods for faces. Furthermore, as the simulation results
depend heavily on the chosen spatial layout of material clusters, we analyze
and compare different spatial layouts.
"
1578,Sketch-n-Sketch: Output-Directed Programming for SVG,"  For creative tasks, programmers face a choice: Use a GUI and sacrifice
flexibility, or write code and sacrifice ergonomics?
  To obtain both flexibility and ease of use, a number of systems have explored
a workflow that we call output-directed programming. In this paradigm, direct
manipulation of the program's graphical output corresponds to writing code in a
general-purpose programming language, and edits not possible with the mouse can
still be enacted through ordinary text edits to the program. Such capabilities
provide hope for integrating graphical user interfaces into what are currently
text-centric programming environments.
  To further advance this vision, we present a variety of new output-directed
techniques that extend the expressive power of Sketch-n-Sketch, an
output-directed programming system for creating programs that generate vector
graphics. To enable output-directed interaction at more stages of program
construction, we expose intermediate execution products for manipulation and we
present a mechanism for contextual drawing. Looking forward to output-directed
programming beyond vector graphics, we also offer generic refactorings through
the GUI, and our techniques employ a domain-agnostic provenance tracing scheme.
  To demonstrate the improved expressiveness, we implement a dozen new
parametric designs in Sketch-n-Sketch without text-based edits. Among these is
the first demonstration of building a recursive function in an output-directed
programming setting.
"
1579,"Real-time Deformation of Soft Tissue Internal Structure with Surface
  Profile Variations using Particle System","  Intraoperative observation of tissue internal structure is often difficult.
Hence, real-time soft tissue deformation is essential for the localization of
tumor and other internal structures. We propose a method to simulate the
internal structural deformations in a soft tissue with surface profile
variations. The deformation simulation utilizes virtual physical particles that
receive interaction forces from the surface and other particles and adjust
their positions accordingly. The proposed method involves two stages. In the
initialization stage, the three-dimensional internal structure of the surface
mesh is uniformly sampled using the particle expansion and attracting-repelling
force models whilst simultaneously building the internal particle connections.
In the simulation stage, under surface profile variations, we simulate the
internal structural deformation based on a deformation force model that uses
the internal particle connections. The main advantage of this method is that it
greatly reduces the computational burden as it only involves simplified
calculations and also does not require generating three-dimensional meshes.
Preliminary experimental results show that the proposed method can handle up to
10,000 particles in 0.3s.
"
1580,SceneGraphNet: Neural Message Passing for 3D Indoor Scene Augmentation,"  In this paper we propose a neural message passing approach to augment an
input 3D indoor scene with new objects matching their surroundings. Given an
input, potentially incomplete, 3D scene and a query location, our method
predicts a probability distribution over object types that fit well in that
location. Our distribution is predicted though passing learned messages in a
dense graph whose nodes represent objects in the input scene and edges
represent spatial and structural relationships. By weighting messages through
an attention mechanism, our method learns to focus on the most relevant
surrounding scene context to predict new scene objects. We found that our
method significantly outperforms state-of-the-art approaches in terms of
correctly predicting objects missing in a scene based on our experiments in the
SUNCG dataset. We also demonstrate other applications of our method, including
context-based 3D object recognition and iterative scene generation.
"
1581,"FAKIR: An algorithm for revealing the anatomy and pose of statues from
  raw point sets","  3D acquisition of archaeological artefacts has become an essential part of
cultural heritage research for preservation or restoration purpose. Statues, in
particular, have been at the center of many projects. In this paper, we
introduce a way to improve the understanding of acquired statues representing
real or imaginary creatures by registering a simple and pliable articulated
model to the raw point set data. Our approach performs a Forward And bacKward
Iterative Registration (FAKIR) which proceeds joint by joint, needing only a
few iterations to converge. We are thus able to detect the pose and elementary
anatomy of sculptures, with possibly non realistic body proportions. By
adapting our simple skeleton, our method can work on animals and imaginary
creatures.
"
1582,"Multivariate Pointwise Information-Driven Data Sampling and
  Visualization","  With increasing computing capabilities of modern supercomputers, the size of
the data generated from the scientific simulations is growing rapidly. As a
result, application scientists need effective data summarization techniques
that can reduce large-scale multivariate spatiotemporal data sets while
preserving the important data properties so that the reduced data can answer
domain-specific queries involving multiple variables with sufficient accuracy.
While analyzing complex scientific events, domain experts often analyze and
visualize two or more variables together to obtain a better understanding of
the characteristics of the data features. Therefore, data summarization
techniques are required to analyze multi-variable relationships in detail and
then perform data reduction such that the important features involving multiple
variables are preserved in the reduced data. To achieve this, in this work, we
propose a data sub-sampling algorithm for performing statistical data
summarization that leverages pointwise information theoretic measures to
quantify the statistical association of data points considering multiple
variables and generates a sub-sampled data that preserves the statistical
association among multi-variables. Using such reduced sampled data, we show
that multivariate feature query and analysis can be done effectively. The
efficacy of the proposed multivariate association driven sampling algorithm is
presented by applying it on several scientific data sets.
"
1583,"Self-Imitation Learning of Locomotion Movements through Termination
  Curriculum","  Animation and machine learning research have shown great advancements in the
past decade, leading to robust and powerful methods for learning complex
physically-based animations. However, learning can take hours or days,
especially if no reference movement data is available. In this paper, we
propose and evaluate a novel combination of techniques for accelerating the
learning of stable locomotion movements through self-imitation learning of
synthetic animations. First, we produce synthetic and cyclic reference movement
using a recent online tree search approach that can discover stable walking
gaits in a few minutes. This allows us to use reinforcement learning with
Reference State Initialization (RSI) to find a neural network controller for
imitating the synthesized reference motion. We further accelerate the learning
using a novel curriculum learning approach called Termination Curriculum (TC),
that adapts the episode termination threshold over time. The combination of the
RSI and TC ensures that simulation budget is not wasted in regions of the state
space not visited by the final policy. As a result, our agents can learn
locomotion skills in just a few hours on a modest 4-core computer. We
demonstrate this by producing locomotion movements for a variety of characters.
"
1584,MaskGAN: Towards Diverse and Interactive Facial Image Manipulation,"  Facial image manipulation has achieved great progress in recent years.
However, previous methods either operate on a predefined set of face attributes
or leave users little freedom to interactively manipulate images. To overcome
these drawbacks, we propose a novel framework termed MaskGAN, enabling diverse
and interactive face manipulation. Our key insight is that semantic masks serve
as a suitable intermediate representation for flexible face manipulation with
fidelity preservation. MaskGAN has two main components: 1) Dense Mapping
Network (DMN) and 2) Editing Behavior Simulated Training (EBST). Specifically,
DMN learns style mapping between a free-form user modified mask and a target
image, enabling diverse generation results. EBST models the user editing
behavior on the source mask, making the overall framework more robust to
various manipulated inputs. Specifically, it introduces dual-editing
consistency as the auxiliary supervision signal. To facilitate extensive
studies, we construct a large-scale high-resolution face dataset with
fine-grained mask annotations named CelebAMask-HQ. MaskGAN is comprehensively
evaluated on two challenging tasks: attribute transfer and style copy,
demonstrating superior performance over other state-of-the-art methods. The
code, models, and dataset are available at
https://github.com/switchablenorms/CelebAMask-HQ.
"
1585,Blue-Noise Dithered QMC Hierarchical Russian Roulette,"  In order to efficiently sample specular-diffuse-glossy and
glossy-diffuse-glossy transport phenomena, Tokuyoshi and Harada introduced
hierarchical Russian roulette, a smart algorithm that allows to compute the
minimum of the random numbers associated to leaves of a tree at each internal
node. The algorithm is used to efficiently cull the connections between the
product set of eye and light vertices belonging to large caches of eye and
light subpaths produced through bidirectional path tracing. The original
version of the algorithm is entirely based on the generation of semi-stratified
pseudo-random numbers. Our paper proposes a novel variant based on
deterministic blue-noise dithered Quasi Monte Carlo samples.
"
1586,ScaleTrotter: Illustrative Visual Travels Across Negative Scales,"  We present ScaleTrotter, a conceptual framework for an interactive,
multi-scale visualization of biological mesoscale data and, specifically,
genome data. ScaleTrotter allows viewers to smoothly transition from the
nucleus of a cell to the atomistic composition of the DNA, while bridging
several orders of magnitude in scale. The challenges in creating an interactive
visualization of genome data are fundamentally different in several ways from
those in other domains like astronomy that require a multi-scale representation
as well. First, genome data has intertwined scale levels---the DNA is an
extremely long, connected molecule that manifests itself at all scale levels.
Second, elements of the DNA do not disappear as one zooms out---instead the
scale levels at which they are observed group these elements differently.
Third, we have detailed information and thus geometry for the entire dataset
and for all scale levels, posing a challenge for interactive visual
exploration. Finally, the conceptual scale levels for genome data are close in
scale space, requiring us to find ways to visually embed a smaller scale into a
coarser one. We address these challenges by creating a new multi-scale
visualization concept. We use a scale-dependent camera model that controls the
visual embedding of the scales into their respective parents, the rendering of
a subset of the scale hierarchy, and the location, size, and scope of the view.
In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual
representations that are depicted in integrated visuals. We discuss,
specifically, how this form of multi-scale visualization follows from the
specific characteristics of the genome data and describe its implementation.
Finally, we discuss the implications of our work to the general illustrative
depiction of multi-scale data.
"
1587,"ICE: An Interactive Configuration Explorer for High Dimensional
  Categorical Parameter Spaces","  There are many applications where users seek to explore the impact of the
settings of several categorical variables with respect to one dependent
numerical variable. For example, a computer systems analyst might want to study
how the type of file system or storage device affects system performance. A
usual choice is the method of Parallel Sets designed to visualize multivariate
categorical variables. However, we found that the magnitude of the parameter
impacts on the numerical variable cannot be easily observed here. We also
attempted a dimension reduction approach based on Multiple Correspondence
Analysis but found that the SVD-generated 2D layout resulted in a loss of
information. We hence propose a novel approach, the Interactive Configuration
Explorer (ICE), which directly addresses the need of analysts to learn how the
dependent numerical variable is affected by the parameter settings given
multiple optimization objectives. No information is lost as ICE shows the
complete distribution and statistics of the dependent variable in context with
each categorical variable. Analysts can interactively filter the variables to
optimize for certain goals such as achieving a system with maximum performance,
low variance, etc. Our system was developed in tight collaboration with a group
of systems performance researchers and its final effectiveness was evaluated
with expert interviews, a comparative user study, and two case studies.
"
1588,"Overlap-free Drawing of Generalized Pythagoras Trees for Hierarchy
  Visualization","  Generalized Pythagoras trees were developed for visualizing hierarchical
data, producing organic, fractal-like representations. However, the drawback of
the original layout algorithm is visual overlap of tree branches. To avoid such
overlap, we introduce an adapted drawing algorithm using ellipses instead of
circles to recursively place tree nodes representing the subhierarchies. Our
technique is demonstrated by resolving overlap in diverse real-world and
generated datasets, while comparing the results to the original approach.
"
1589,Visual Entropy and the Visualization of Uncertainty,"  Background: It is possible to find many different visual representations of
data values in visualizations, it is less common to see visual representations
that include uncertainty, especially in visualizations intended for
non-technical audiences. Objective: our aim is to rigorously define and
evaluate the novel use of visual entropy as a measure of shape that allows us
to construct an ordered scale of glyphs for use in representing both
uncertainty and value in 2D and 3D environments. Method: We use sample entropy
as a numerical measure of visual entropy to construct a set of glyphs using R
and Blender which vary in their complexity. Results: A Bradley-Terry analysis
of a pairwise comparison of the glyphs shows participants (n=19) ordered the
glyphs as predicted by the visual entropy score (linear regression R2 >0.97,
p<0.001). We also evaluate whether the glyphs can effectively represent
uncertainty using a signal detection method, participants (n=15) were able to
search for glyphs representing uncertainty with high sensitivity and low error
rates. Conclusion: visual entropy is a novel cue for representing ordered data
and provides a channel that allows the uncertainty of a measure to be presented
alongside its mean value.
"
1590,"Artifact-Based Rendering: Harnessing Natural and Traditional Visual
  Media for More Expressive and Engaging 3D Visualizations","  We introduce Artifact-Based Rendering (ABR), a framework of tools,
algorithms, and processes that makes it possible to produce real, data-driven
3D scientific visualizations with a visual language derived entirely from
colors, lines, textures, and forms created using traditional physical media or
found in nature. A theory and process for ABR is presented to address three
current needs: (i) designing better visualizations by making it possible for
non-programmers to rapidly design and critique many alternative data-to-visual
mappings; (ii) expanding the visual vocabulary used in scientific
visualizations to depict increasingly complex multivariate data; (iii) bringing
a more engaging, natural, and human-relatable handcrafted aesthetic to data
visualization. New tools and algorithms to support ABR include front-end
applets for constructing artifact-based colormaps, optimizing 3D scanned meshes
for use in data visualization, and synthesizing textures from artifacts. These
are complemented by an interactive rendering engine with custom algorithms and
interfaces that demonstrate multiple new visual styles for depicting point,
line, surface, and volume data. A within-the-research-team design study
provides early evidence of the shift in visualization design processes that ABR
is believed to enable when compared to traditional scientific visualization
systems. Qualitative user feedback on applications to climate science and brain
imaging support the utility of ABR for scientific discovery and public
communication.
"
1591,A Comparison of Radial and Linear Charts for Visualizing Daily Pattern,"  Radial charts are generally considered less effective than linear charts.
Perhaps the only exception is in visualizing periodical time-dependent data,
which is believed to be naturally supported by the radial layout. It has been
demonstrated that the drawbacks of radial charts outweigh the benefits of this
natural mapping. Visualization of daily patterns, as a special case, has not
been systematically evaluated using radial charts. In contrast to yearly or
weekly recurrent trends, the analysis of daily patterns on a radial chart may
benefit from our trained skill on reading radial clocks that are ubiquitous in
our culture. In a crowd-sourced experiment with 92 non-expert users, we
evaluated the accuracy, efficiency, and subjective ratings of radial and linear
charts for visualizing daily traffic accident patterns. We systematically
compared juxtaposed 12-hours variants and single 24-hours variants for both
layouts in four low-level tasks and one high-level interpretation task. Our
results show that over all tasks, the most elementary 24-hours linear bar chart
is most accurate and efficient and is also preferred by the users. This
provides strong evidence for the use of linear layouts - even for visualizing
periodical daily patterns.
"
1592,LassoNet: Deep Lasso-Selection of 3D Point Clouds,"  Selection is a fundamental task in exploratory analysis and visualization of
3D point clouds. Prior researches on selection methods were developed mainly
based on heuristics such as local point density, thus limiting their
applicability in general data. Specific challenges root in the great
variabilities implied by point clouds (e.g., dense vs. sparse), viewpoint
(e.g., occluded vs. non-occluded), and lasso (e.g., small vs. large). In this
work, we introduce LassoNet, a new deep neural network for lasso selection of
3D point clouds, attempting to learn a latent mapping from viewpoint and lasso
to point cloud regions. To achieve this, we couple user-target points with
viewpoint and lasso information through 3D coordinate transform and naive
selection, and improve the method scalability via an intention filtering and
farthest point sampling. A hierarchical network is trained using a dataset with
over 30K lasso-selection records on two different point cloud data. We conduct
a formal user study to compare LassoNet with two state-of-the-art
lasso-selection methods. The evaluations confirm that our approach improves the
selection effectiveness and efficiency across different combinations of 3D
point clouds, viewpoints, and lasso selections. Project Website:
https://lassonet.github.io
"
1593,"Towards Automated Infographic Design: Deep Learning-based
  Auto-Extraction of Extensible Timeline","  Designers need to consider not only perceptual effectiveness but also visual
styles when creating an infographic. This process can be difficult and time
consuming for professional designers, not to mention non-expert users, leading
to the demand for automated infographics design. As a first step, we focus on
timeline infographics, which have been widely used for centuries. We contribute
an end-to-end approach that automatically extracts an extensible timeline
template from a bitmap image. Our approach adopts a deconstruction and
reconstruction paradigm. At the deconstruction stage, we propose a multi-task
deep neural network that simultaneously parses two kinds of information from a
bitmap timeline: 1) the global information, i.e., the representation, scale,
layout, and orientation of the timeline, and 2) the local information, i.e.,
the location, category, and pixels of each visual element on the timeline. At
the reconstruction stage, we propose a pipeline with three techniques, i.e.,
Non-Maximum Merging, Redundancy Recover, and DL GrabCut, to extract an
extensible template from the infographic, by utilizing the deconstruction
results. To evaluate the effectiveness of our approach, we synthesize a
timeline dataset (4296 images) and collect a real-world timeline dataset (393
images) from the Internet. We first report quantitative evaluation results of
our approach over the two datasets. Then, we present examples of automatically
extracted templates and timelines automatically generated based on these
templates to qualitatively demonstrate the performance. The results confirm
that our approach can effectively extract extensible templates from real-world
timeline infographics.
"
1594,Learning to Dress 3D People in Generative Clothing,"  Three-dimensional human body models are widely used in the analysis of human
pose and motion. Existing models, however, are learned from minimally-clothed
3D scans and thus do not generalize to the complexity of dressed people in
common images and videos. Additionally, current models lack the expressive
power needed to represent the complex non-linear geometry of pose-dependent
clothing shapes. To address this, we learn a generative 3D mesh model of
clothed people from 3D scans with varying pose and clothing. Specifically, we
train a conditional Mesh-VAE-GAN to learn the clothing deformation from the
SMPL body model, making clothing an additional term in SMPL. Our model is
conditioned on both pose and clothing type, giving the ability to draw samples
of clothing to dress different body shapes in a variety of styles and poses. To
preserve wrinkle detail, our Mesh-VAE-GAN extends patchwise discriminators to
3D meshes. Our model, named CAPE, represents global shape and fine local
structure, effectively extending the SMPL body model to clothing. To our
knowledge, this is the first generative model that directly dresses 3D human
body meshes and generalizes to different poses. The model, code and data are
available for research purposes at https://cape.is.tue.mpg.de.
"
1595,"Software-Enhanced Teaching and Visualization Capabilities of an
  Ultra-High-Resolution Video Wall","  This paper presents a modular approach to enhance the capabilities and
features of a visualization and teaching room using software. This approach was
applied to a room with a large, high resolution (7680$\times$4320 pixels),
tiled screen of 13 $\times$ 7.5 feet as its main display, and with a variety of
audio and video inputs, connected over a network. Many of the techniques
described are possible because of a software-enhanced setup, utilizing existing
hardware and a collection of mostly open-source tools, allowing to perform
collaborative, high-resolution visualizations as well as broadcasting and
recording workshops and lectures. The software approach is flexible and allows
one to add functionality without changing the hardware.
"
1596,"Biased Average Position Estimates in Line and Bar Graphs:
  Underestimation, Overestimation, and Perceptual Pull","  In visual depictions of data, position (i.e., the vertical height of a line
or a bar) is believed to be the most precise way to encode information compared
to other encodings (e.g., hue). Not only are other encodings less precise than
position, but they can also be prone to systematic biases (e.g., color category
boundaries can distort perceived differences between hues). By comparison,
position's high level of precision may seem to protect it from such biases. In
contrast, across three empirical studies, we show that while position may be a
precise form of data encoding, it can also produce systematic biases in how
values are visually encoded, at least for reports of average position across a
short delay. In displays with a single line or a single set of bars, reports of
average positions were significantly biased, such that line positions were
underestimated and bar positions were overestimated. In displays with multiple
data series (i.e., multiple lines and/or sets of bars), this systematic bias
still persisted. We also observed an effect of ""perceptual pull"", where the
average position estimate for each series was 'pulled' toward the other. These
findings suggest that, although position may still be the most precise form of
visual data encoding, it can also be systematically biased.
"
1597,"Extract and Merge: Merging extracted humans from different images
  utilizing Mask R-CNN","  Selecting human objects out of the various type of objects in images and
merging them with other scenes is manual and day-to-day work for photo editors.
Although recently Adobe photoshop released ""select subject"" tool which
automatically selects the foreground object in an image, but still requires
fine manual tweaking separately. In this work, we proposed an application
utilizing Mask R-CNN (for object detection and mask segmentation) that can
extract human instances from multiple images and merge them with a new
background. This application does not add any overhead to Mask R-CNN, running
at 5 frames per second. It can extract human instances from any number of
images or videos from merging them together. We also structured the code to
accept videos of different lengths as input and length of the output-video will
be equal to the longest input-video. We wanted to create a simple yet effective
application that can serve as a base for photo editing and do most
time-consuming work automatically, so, editors can focus more on the design
part. Other application could be to group people together in a single picture
with a new background from different images which could not be physically
together. We are showing single-person and multi-person extraction and
placement in two different backgrounds. Also, we are showing a video example
with single-person extraction.
"
1598,"InSituNet: Deep Image Synthesis for Parameter Space Exploration of
  Ensemble Simulations","  We propose InSituNet, a deep learning based surrogate model to support
parameter space exploration for ensemble simulations that are visualized in
situ. In situ visualization, generating visualizations at simulation time, is
becoming prevalent in handling large-scale simulations because of the I/O and
storage constraints. However, in situ visualization approaches limit the
flexibility of post-hoc exploration because the raw simulation data are no
longer available. Although multiple image-based approaches have been proposed
to mitigate this limitation, those approaches lack the ability to explore the
simulation parameters. Our approach allows flexible exploration of parameter
space for large-scale ensemble simulations by taking advantage of the recent
advances in deep learning. Specifically, we design InSituNet as a convolutional
regression model to learn the mapping from the simulation and visualization
parameters to the visualization results. With the trained model, users can
generate new images for different simulation parameters under various
visualization settings, which enables in-depth analysis of the underlying
ensemble simulations. We demonstrate the effectiveness of InSituNet in
combustion, cosmology, and ocean simulations through quantitative and
qualitative evaluations.
"
1599,"Slope-Dependent Rendering of Parallel Coordinates to Reduce Density
  Distortion and Ghost Clusters","  Parallel coordinates are a popular technique to visualize multi-dimensional
data. However, they face a significant problem influencing the perception and
interpretation of patterns. The distance between two parallel lines differs
based on their slope. Vertical lines are rendered longer and closer to each
other than horizontal lines. This problem is inherent in the technique and has
two main consequences: (1) clusters which have a steep slope between two axes
are visually more prominent than horizontal clusters. (2) Noise and clutter can
be perceived as clusters, as a few parallel vertical lines visually emerge as a
ghost cluster. Our paper makes two contributions: First, we formalize the
problem and show its impact. Second, we present a novel technique to reduce the
effects by rendering the polylines of the parallel coordinates based on their
slope: horizontal lines are rendered with the default width, lines with a steep
slope with a thinner line. Our technique avoids density distortions of
clusters, can be computed in linear time, and can be added on top of most
parallel coordinate variations. To demonstrate the usefulness, we show examples
and compare them to the classical rendering.
"
1600,"Design by Immersion: A Transdisciplinary Approach to Problem-Driven
  Visualizations","  While previous work exists on how to conduct and disseminate insights from
problem-driven visualization projects and design studies, the literature does
not address how to accomplish these goals in transdisciplinary teams in ways
that advance all disciplines involved. In this paper we introduce and define a
new methodological paradigm we call design by immersion, which provides an
alternative perspective on problem-driven visualization work. Design by
immersion embeds transdisciplinary experiences at the center of the
visualization process by having visualization researchers participate in the
work of the target domain (or domain experts participate in visualization
research). Based on our own combined experiences of working on
cross-disciplinary, problem-driven visualization projects, we present six case
studies that expose the opportunities that design by immersion enables,
including (1) exploring new domain-inspired visualization design spaces, (2)
enriching domain understanding through personal experiences, and (3) building
strong transdisciplinary relationships. Furthermore, we illustrate how the
process of design by immersion opens up a diverse set of design activities that
can be combined in different ways depending on the type of collaboration,
project, and goals. Finally, we discuss the challenges and potential pitfalls
of design by immersion.
"
1601,StructureNet: Hierarchical Graph Networks for 3D Shape Generation,"  The ability to generate novel, diverse, and realistic 3D shapes along with
associated part semantics and structure is central to many applications
requiring high-quality 3D assets or large volumes of realistic training data. A
key challenge towards this goal is how to accommodate diverse shape variations,
including both continuous deformations of parts as well as structural or
discrete alterations which add to, remove from, or modify the shape
constituents and compositional structure. Such object structure can typically
be organized into a hierarchy of constituent object parts and relationships,
represented as a hierarchy of n-ary graphs. We introduce StructureNet, a
hierarchical graph network which (i) can directly encode shapes represented as
such n-ary graphs; (ii) can be robustly trained on large and complex shape
families; and (iii) can be used to generate a great diversity of realistic
structured shape geometries. Technically, we accomplish this by drawing
inspiration from recent advances in graph neural networks to propose an
order-invariant encoding of n-ary graphs, considering jointly both part
geometry and inter-part relations during network training. We extensively
evaluate the quality of the learned latent spaces for various shape families
and show significant advantages over baseline and competing methods. The
learned latent spaces enable several structure-aware geometry processing
applications, including shape generation and interpolation, shape editing, or
shape structure discovery directly from un-annotated images, point clouds, or
partial scans.
"
1602,Evaluating Ordering Strategies of Star Glyph Axes,"  Star glyphs are a well-researched visualization technique to represent
multi-dimensional data. They are often used in small multiple settings for a
visual comparison of many data points. However, their overall visual appearance
is strongly influenced by the ordering of dimensions. To this end, two
orthogonal categories of layout strategies are proposed in the literature:
order dimensions by similarity to get homogeneously shaped glyphs vs. order by
dissimilarity to emphasize spikes and salient shapes. While there is evidence
that salient shapes support clustering tasks, evaluation, and direct comparison
of data-driven ordering strategies has not received much research attention. We
contribute an empirical user study to evaluate the efficiency, effectiveness,
and user confidence in visual clustering tasks using star glyphs. In comparison
to similarity-based ordering, our results indicate that dissimilarity-based
star glyph layouts support users better in clustering tasks, especially when
clutter is present.
"
1603,"Evaluating an Immersive Space-Time Cube Geovisualization for Intuitive
  Trajectory Data Exploration","  A Space-Time Cube enables analysts to clearly observe spatio-temporal
features in movement trajectory datasets in geovisualization. However, its
general usability is impacted by a lack of depth cues, a reported steep
learning curve, and the requirement for efficient 3D navigation. In this work,
we investigate a Space-Time Cube in the Immersive Analytics domain. Based on a
review of previous work and selecting an appropriate exploration metaphor, we
built a prototype environment where the cube is coupled to a virtual
representation of the analyst's real desk, and zooming and panning in space and
time are intuitively controlled using mid-air gestures. We compared our
immersive environment to a desktop-based implementation in a user study with 20
participants across 7 tasks of varying difficulty, which targeted different
user interface features. To investigate how performance is affected in the
presence of clutter, we explored two scenarios with different numbers of
trajectories. While the quantitative performance was similar for the majority
of tasks, large differences appear when we analyze the patterns of interaction
and consider subjective metrics. The immersive version of the Space-Time Cube
received higher usability scores, much higher user preference, and was rated to
have a lower mental workload, without causing participants discomfort in
25-minute-long VR sessions.
"
1604,Vis4Vis: Visualization for (Empirical) Visualization Research,"  Appropriate evaluation is a key component in visualization research. It is
typically based on empirical studies that assess visualization components or
complete systems. While such studies often include the user of the
visualization, empirical research is not necessarily restricted to user studies
but may also address the technical performance of a visualization system such
as its computational speed or memory consumption. Any such empirical experiment
faces the issue that the underlying visualization is becoming increasingly
sophisticated, leading to an increasingly difficult evaluation in complex
environments. Therefore, many of the established methods of empirical studies
can no longer capture the full complexity of the evaluation. One promising
solution is the use of data-rich observations that we can acquire during
studies to obtain more reliable interpretations of empirical research. For
example, we have been witnessing an increasing availability and use of
physiological sensor information from eye tracking, electrodermal activity
sensors, electroencephalography, etc. Other examples are various kinds of logs
of user activities such as mouse, keyboard, or touch interaction. Such
data-rich empirical studies promise to be especially useful for studies in the
wild and similar scenarios outside of the controlled laboratory environment.
However, with the growing availability of large, complex, time-dependent,
heterogeneous, and unstructured observational data, we are facing the new
challenge of how we can analyze such data. This challenge can be addressed by
establishing the subfield of visualization for visualization (Vis4Vis):
visualization as a means of analyzing and communicating data from empirical
studies to advance visualization research.
"
1605,"Color Crafting: Automating the Construction of Designer Quality Color
  Ramps","  Visualizations often encode numeric data using sequential and diverging color
ramps. Effective ramps use colors that are sufficiently discriminable, align
well with the data, and are aesthetically pleasing. Designers rely on years of
experience to create high-quality color ramps. However, it is challenging for
novice visualization developers that lack this experience to craft effective
ramps as most guidelines for constructing ramps are loosely defined qualitative
heuristics that are often difficult to apply. Our goal is to enable
visualization developers to readily create effective color encodings using a
single seed color. We do this using an algorithmic approach that models
designer practices by analyzing patterns in the structure of designer-crafted
color ramps. We construct these models from a corpus of 222 expert-designed
color ramps, and use the results to automatically generate ramps that mimic
designer practices. We evaluate our approach through an empirical study
comparing the outputs of our approach with designer-crafted color ramps. Our
models produce ramps that support accurate and aesthetically pleasing
visualizations at least as well as designer ramps and that outperform
conventional mathematical approaches.
"
1606,"Visualising Geographically-Embedded Origin-Destination Flows: in 2D and
  immersive environments","  This thesis develops and evaluates effective techniques for visualisation of
flows (e.g. of people, trade, knowledge) between places on geographic maps.
This geographically-embedded flow data contains information about geographic
locations, and flows from origin locations to destination locations. We
explored the design space of OD flow visualisation in both 2D and immersive
environments. We do so by creating novel OD flow visualisations in both
environments, and then conducting controlled user studies to evaluate different
designs.
"
1607,Effects of Illumination on the Categorization of Shiny Materials,"  The present research was designed to examine how patterns of illumination
influence the perceptual categorization of metal, shiny black, and shiny white
materials. The stimuli depicted three possible objects that were illuminated by
five possible HDRI light maps, which varied in their overall distributions of
illuminant directions and intensities. The surfaces included a low roughness
chrome material, a shiny black material, and a shiny white material with both
diffuse and specular components. Observers rated each stimulus by adjusting
four sliders to indicate their confidence that the depicted material was metal,
shiny black, shiny white or something else, and these adjustments were
constrained so that the sum of all four settings was always 100%. The results
revealed that the metal and shiny black categories are easily confused. For
example, metal materials with low intensity light maps or a narrow range of
illuminant directions are often judged as shiny black, whereas shiny black
materials with high intensity light maps or a wide range of illuminant
directions are often judged as metal. A spherical harmonic analysis was
performed on the different light maps in an effort to quantitatively predict
how they would bias observers' judgments of metal and shiny black surfaces.
"
1608,"Interactive Visualisation of Hierarchical Quantitative Data: An
  Evaluation","  We have compared three common visualisations for hierarchical quantitative
data, treemaps, icicle plots and sunburst charts as well as a semicircular
variant of sunburst charts we call the sundown chart. In a pilot study, we
found that the sunburst chart was least preferred. In a controlled study with
12 participants, we compared treemaps, icicle plots and sundown charts. Treemap
was the least preferred and had a slower performance on a basic navigation task
and slower performance and accuracy in hierarchy understanding tasks. The
icicle plot and sundown chart had similar performance with slight user
preference for the icicle plot.
"
1609,Another Simple but Faster Method for 2D Line Clipping,"  The majority of methods for line clipping make a rather large number of
comparisons and involve a lot of calculations compared to modern ones. Most of
the times, they are not so efficient as well as not so simple and applicable to
the majority of cases. Besides the most popular ones, namely, Cohen-Sutherland,
Liang-Barsky, Cyrus-Beck and Nicholl-Lee-Nicholl, other line-clipping methods
have been presented over the years, each one having its own advantages and
disadvantages. In this paper a new computation method for 2D line clipping
against a rectangular window is introduced. The proposed method has been
compared with the afore-mentioned ones as well as with two others; namely,
Skala and Kodituwakku-Wijeweera-Chamikara, with respect to the number of
operations performed and the computation time. The performance of the proposed
method has been found to be better than all of the above-mentioned methods and
it is found to be very fast, simple and can be implemented easily in any
programming language or integrated development environment.
"
1610,"Blind SAR Image Despeckling Using Self-Supervised Dense Dilated
  Convolutional Neural Network","  Despeckling is a key and indispensable step in SAR image preprocessing,
existing deep learning-based methods achieve SAR despeckling by learning some
mappings between speckled (different looks) and clean images. However, there
exist no clean SAR image in the real world. To this end, in this paper, we
propose a self-supervised dense dilated convolutional neural network (BDSS) for
blind SAR image despeckling. Proposed BDSS can still learn to suppress speckle
noise without clean ground truth by optimized for L2 loss. Besides, three
enhanced dense blocks with dilated convolution are employed to improve network
performance. The synthetic and real-data experiments demonstrate that proposed
BDSS can achieve despeckling effectively while maintaining well features such
as edges, point targets, and radiometric. At last, we demonstrate that our
proposed BDSS can achieve blind despeckling excellently, i.e., do not need to
care about the number of looks.
"
1611,"Rendering Non-Euclidean Geometry in Real-Time Using Spherical and
  Hyperbolic Trigonometry","  This paper introduces a method of calculating and rendering shapes in a
non-Euclidean 2D space. In order to achieve this, we developed a physics and
graphics engine that uses hyperbolic trigonometry to calculate and subsequently
render the shapes in a 2D space of constant negative or positive curvature in
real-time. We have chosen to use polar coordinates to record the parameters of
the objects as well as an azimuthal equidistant projection to render the space
onto the screen because of the multiple useful properties they have. For
example, polar coordinate system works well with trigonometric calculations,
due to the distance from the reference point (analogous to origin in Cartesian
coordinates) being one of the coordinates by definition. Azimuthal equidistant
projection is not a typical projection, used for neither spherical nor
hyperbolic space, however one of the main features of our engine relies on it:
changing the curvature of the world in real-time without stopping the execution
of the application in order to re-calculate the world. This is due to the
projection properties that work identically for both spherical and hyperbolic
space, as can be seen in the Figure 1 above. We will also be looking at the
complexity analysis of this method as well as renderings that the engine
produces. Finally we will be discussing the limitations and possible
applications of the created engine as well as potential improvements of the
described method.
"
1612,Geometric Sample Reweighting for Monte Carlo Integration,"  We present a general sample reweighting scheme and its underlying theory for
the integration of an unknown function with low dimensionality. Our method
produces better results than standard weighting schemes for common sampling
strategies, while avoiding bias. Our main insight is to link the weight
derivation to the function reconstruction process during integration. The
implementation of our solution is simple and results in an improved convergence
behavior. We illustrate its benefit by applying our method to multiple Monte
Carlo rendering problems.
"
1613,"Efficient Space Skipping and Adaptive Sampling of Unstructured Volumes
  Using Hardware Accelerated Ray Tracing","  Sample based ray marching is an effective method for direct volume rendering
of unstructured meshes. However, sampling such meshes remains expensive, and
strategies to reduce the number of samples taken have received relatively
little attention. In this paper, we introduce a method for rendering
unstructured meshes using a combination of a coarse spatial acceleration
structure and hardware-accelerated ray tracing. Our approach enables efficient
empty space skipping and adaptive sampling of unstructured meshes, and
outperforms a reference ray marcher by up to 7x.
"
1614,"Heterogeneous porous scaffold generation in trivariate B-spline solid
  with triply periodic minimal surface in the parametric domain","  A porous scaffold is a three-dimensional network structure composed of a
large number of pores, and triply periodic minimal surfaces (TPMSs) are one of
conventional tools for designing porous scaffolds. However, discontinuity,
incompleteness, and high storage space requirements are the three main
shortcomings of TPMSs for porous scaffold design. In this study, we developed
an effective method for heterogeneous porous scaffold generation to overcome
the abovementioned shortcomings of TPMSs. The input of the proposed method is a
trivariate B-spline solid (TBSS) with a cubic parameter domain. The proposed
method first constructs a threshold distribution field (TDF) in the cubic
parameter domain, and then produces a continuous and complete TPMS within it.
Moreover, by mapping the TPMS in the parametric domain to the TBSS, a
continuous and complete porous scaffold is generated in the TBSS. In addition,
if the TBSS does not satisfy engineering requirements, the TDF can be locally
modified in the parameter domain, and the porous scaffold in the TBSS can be
rebuilt. We also defined a new storage space-saving file format based on the
TDF to store porous scaffolds. The experimental results presented in this paper
demonstrate the effectiveness and efficiency of the method using a TBSS as well
as the superior space-saving of the proposed storage format.
"
1615,"Predictive Generalized Graph Fourier Transform for Attribute Compression
  of Dynamic Point Clouds","  As 3D scanning devices and depth sensors advance, dynamic point clouds have
attracted increasing attention as a format for 3D objects in motion, with
applications in various fields such as immersive telepresence, navigation for
autonomous driving and gaming. Nevertheless, the tremendous amount of data in
dynamic point clouds significantly burden transmission and storage. To this
end, we propose a complete compression framework for attributes of 3D dynamic
point clouds, focusing on optimal inter-coding. Firstly, we derive the optimal
inter-prediction and predictive transform coding assuming the Gaussian Markov
Random Field model with respect to a spatio-temporal graph underlying the
attributes of dynamic point clouds. The optimal predictive transform proves to
be the Generalized Graph Fourier Transform in terms of spatio-temporal
decorrelation. Secondly, we propose refined motion estimation via efficient
registration prior to inter-prediction, which searches the temporal
correspondence between adjacent frames of irregular point clouds. Finally, we
present a complete framework based on the optimal inter-coding and our
previously proposed intra-coding, where we determine the optimal coding mode
from rate-distortion optimization with the proposed offline-trained $\lambda$-Q
model. Experimental results show that we achieve around 17% bit rate reduction
on average over competitive dynamic point cloud compression methods.
"
1616,Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation,"  Showing flows of people and resources between multiple geographic locations
is a challenging visualisation problem. We conducted two quantitative user
studies to evaluate different visual representations for such dense
many-to-many flows. In our first study we compared a bundled node-link flow map
representation and OD Maps [37] with a new visualisation we call MapTrix. Like
OD Maps, MapTrix overcomes the clutter associated with a traditional flow map
while providing geographic embedding that is missing in standard OD matrix
representations. We found that OD Maps and MapTrix had similar performance
while bundled node-link flow map representations did not scale at all well. Our
second study compared participant performance with OD Maps and MapTrix on
larger data sets. Again performance was remarkably similar.
"
1617,Maps and Globes in Virtual Reality,"  This paper explores different ways to render world-wide geographic maps in
virtual reality (VR). We compare: (a) a 3D exocentric globe, where the user's
viewpoint is outside the globe; (b) a flat map (rendered to a plane in VR); (c)
an egocentric 3D globe, with the viewpoint inside the globe; and (d) a curved
map, created by projecting the map onto a section of a sphere which curves
around the user. In all four visualisations the geographic centre can be
smoothly adjusted with a standard handheld VR controller and the user, through
a head-tracked headset, can physically move around the visualisation. For
distance comparison, exocentric globe is more accurate than egocentric globe
and flat map. For area comparison, more time is required with exocentric and
egocentric globes than with flat and curved maps. For direction estimation, the
exocentric globe is more accurate and faster than the other visual
presentations. Our study participants had a weak preference for the exocentric
globe. Generally, the curved map had benefits over the flat map. In almost all
cases the egocentric globe was found to be the least effective visualisation.
Overall, our results provide support for the use of exocentric globes for
geographic visualisation in mixed-reality.
"
1618,Origin-Destination Flow Maps in Immersive Environments,"  Immersive virtual- and augmented-reality headsets can overlay a flat image
against any surface or hang virtual objects in the space around the user. The
technology is rapidly improving and may, in the long term, replace traditional
flat panel displays in many situations. When displays are no longer
intrinsically flat, how should we use the space around the user for abstract
data visualisation? In this paper, we ask this question with respect to
origin-destination flow data in a global geographic context. We report on the
findings of three studies exploring different spatial encodings for flow maps.
The first experiment focuses on different 2D and 3D encodings for flows on flat
maps. We find that participants are significantly more accurate with raised
flow paths whose height is proportional to flow distance but fastest with
traditional straight line 2D flows. In our second and third experiment, we
compared flat maps, 3D globes and a novel interactive design we call MapsLink,
involving a pair of linked flat maps. We find that participants took
significantly more time with MapsLink than other flow maps while the 3D globe
with raised flows was the fastest, most accurate, and most preferred method.
Our work suggests that careful use of the third spatial dimension can resolve
visual clutter in complex flow maps.
"
1619,Point Cloud Super Resolution with Adversarial Residual Graph Networks,"  Point cloud super-resolution is a fundamental problem for 3D reconstruction
and 3D data understanding. It takes a low-resolution (LR) point cloud as input
and generates a high-resolution (HR) point cloud with rich details. In this
paper, we present a data-driven method for point cloud super-resolution based
on graph networks and adversarial losses. The key idea of the proposed network
is to exploit the local similarity of point cloud and the analogy between LR
input and HR output. For the former, we design a deep network with graph
convolution. For the latter, we propose to add residual connections into graph
convolution and introduce a skip connection between input and output. The
proposed network is trained with a novel loss function, which combines Chamfer
Distance (CD) and graph adversarial loss. Such a loss function captures the
characteristics of HR point cloud automatically without manual design. We
conduct a series of experiments to evaluate our method and validate the
superiority over other methods. Results show that the proposed method achieves
the state-of-the-art performance and have a good generalization ability to
unseen data.
"
1620,"A Robust Billboard-based Free-viewpoint Video Synthesizing Algorithm for
  Sports Scenes","  We present a billboard-based free-viewpoint video synthesizing algorithm for
sports scenes that can robustly reconstruct and render a high-fidelity
billboard model for each object, including an occluded one, in each camera. Its
contributions are (1) applicable to a challenging shooting condition where a
high precision 3D model cannot be built because a small number of cameras
featuring wide-baseline are equipped; (2) capable of reproducing appearances of
occlusions, that is one of the most significant issues for billboard-based
approaches due to the ineffective detection of overlaps. To achieve
contributions above, the proposed method does not attempt to find a
high-quality 3D model but utilizes a raw 3D model that is obtained directly
from space carving. Although the model is insufficiently accurate for producing
an impressive visual effect, precise objects segmentation and occlusions
detection can be performed by back-projecting it onto each camera plane. The
billboard model of each object in each camera is rendered according to whether
it is occluded or not, and its location in the virtual stadium is determined
considering the location of its 3D model. We synthesized free-viewpoint videos
of two soccer sequences recorded by five cameras with the proposed and
state-of-art methods to demonstrate its performance.
"
1621,Mesh Variational Autoencoders with Edge Contraction Pooling,"  3D shape analysis is an important research topic in computer vision and
graphics. While existing methods have generalized image-based deep learning to
meshes using graph-based convolutions, the lack of an effective pooling
operation restricts the learning capability of their networks. In this paper,
we propose a novel pooling operation for mesh datasets with the same
connectivity but different geometry, by building a mesh hierarchy using mesh
simplification. For this purpose, we develop a modified mesh simplification
method to avoid generating highly irregularly sized triangles. Our pooling
operation effectively encodes the correspondence between coarser and finer
meshes in the hierarchy. We then present a variational auto-encoder structure
with the edge contraction pooling and graph-based convolutions, to explore
probability latent spaces of 3D surfaces. Our network requires far fewer
parameters than the original mesh VAE and thus can handle denser models thanks
to our new pooling operation and convolutional kernels. Our evaluation also
shows that our method has better generalization ability and is more reliable in
various applications, including shape generation, shape interpolation and shape
embedding.
"
1622,Rendering Point Clouds with Compute Shaders,"  We propose a compute shader based point cloud rasterizer with up to 10 times
higher performance than classic point-based rendering with the GL_POINT
primitive. In addition to that, our rasterizer offers 5 byte depth-buffer
precision with uniform or customizable distribution, and we show that it is
possible to implement a high-quality splatting method that blends together
overlapping fragments while still maintaining higher frame-rates than the
traditional approach.
"
1623,"Relighting Humans: Occlusion-Aware Inverse Rendering for Full-Body Human
  Images","  Relighting of human images has various applications in image synthesis. For
relighting, we must infer albedo, shape, and illumination from a human
portrait. Previous techniques rely on human faces for this inference, based on
spherical harmonics (SH) lighting. However, because they often ignore light
occlusion, inferred shapes are biased and relit images are unnaturally bright
particularly at hollowed regions such as armpits, crotches, or garment
wrinkles. This paper introduces the first attempt to infer light occlusion in
the SH formulation directly. Based on supervised learning using convolutional
neural networks (CNNs), we infer not only an albedo map, illumination but also
a light transport map that encodes occlusion as nine SH coefficients per pixel.
The main difficulty in this inference is the lack of training datasets compared
to unlimited variations of human portraits. Surprisingly, geometric information
including occlusion can be inferred plausibly even with a small dataset of
synthesized human figures, by carefully preparing the dataset so that the CNNs
can exploit the data coherency. Our method accomplishes more realistic
relighting than the occlusion-ignored formulation.
"
1624,"Efficient 3D Reconstruction and Streaming for Group-Scale Multi-Client
  Live Telepresence","  Sharing live telepresence experiences for teleconferencing or remote
collaboration receives increasing interest with the recent progress in
capturing and AR/VR technology. Whereas impressive telepresence systems have
been proposed on top of on-the-fly scene capture, data transmission and
visualization, these systems are restricted to the immersion of single or up to
a low number of users into the respective scenarios. In this paper, we direct
our attention on immersing significantly larger groups of people into
live-captured scenes as required in education, entertainment or collaboration
scenarios. For this purpose, rather than abandoning previous approaches, we
present a range of optimizations of the involved reconstruction and streaming
components that allow the immersion of a group of more than 24 users within the
same scene - which is about a factor of 6 higher than in previous work -
without introducing further latency or changing the involved consumer hardware
setup. We demonstrate that our optimized system is capable of generating
high-quality scene reconstructions as well as providing an immersive viewing
experience to a large group of people within these live-captured scenes.
"
1625,Committee Draft of JPEG XL Image Coding System,"  JPEG XL is a practical approach focused on scalable web distribution and
efficient compression of high-quality images. It provides various benefits
compared to existing image formats: 60% size reduction at equivalent subjective
quality; fast, parallelizable decoding and encoding configurations; features
such as progressive, lossless, animation, and reversible transcoding of
existing JPEG with 22% size reduction; support for high-quality applications
including wide gamut, higher resolution/bit depth/dynamic range, and visually
lossless coding. The JPEG XL architecture is traditional block-transform coding
with upgrades to each component.
"
1626,Fast Tetrahedral Meshing in the Wild,"  We propose a new tetrahedral meshing method, fTetWild, to convert triangle
soups into high-quality tetrahedral meshes. Our method builds on the TetWild
algorithm, replacing the rational triangle insertion with a new incremental
approach to construct and optimize the output mesh, interleaving triangle
insertion and mesh optimization. Our approach makes it possible to maintain a
valid floating-point tetrahedral mesh at all algorithmic stages, eliminating
the need for costly constructions with rational numbers used by TetWild, while
maintaining full robustness and similar output quality. This allows us to
improve on TetWild in two ways. First, our algorithm is significantly faster,
with running time comparable to less robust Delaunay-based tetrahedralization
algorithms. Second, our algorithm is guaranteed to produce a valid tetrahedral
mesh with floating-point vertex coordinates, while TetWild produces a valid
mesh with rational coordinates which is not guaranteed to be valid after
floating-point conversion. As a trade-off, our algorithm no longer guarantees
that all input triangles are present in the output mesh, but in practice, as
confirmed by our tests on the Thingi10k dataset, the algorithm always succeeds
in inserting all input triangles.
"
1627,Deep Tone Mapping Operator for High Dynamic Range Images,"  A computationally fast tone mapping operator (TMO) that can quickly adapt to
a wide spectrum of high dynamic range (HDR) content is quintessential for
visualization on varied low dynamic range (LDR) output devices such as movie
screens or standard displays. Existing TMOs can successfully tone-map only a
limited number of HDR content and require an extensive parameter tuning to
yield the best subjective-quality tone-mapped output. In this paper, we address
this problem by proposing a fast, parameter-free and scene-adaptable deep tone
mapping operator (DeepTMO) that yields a high-resolution and high-subjective
quality tone mapped output. Based on conditional generative adversarial network
(cGAN), DeepTMO not only learns to adapt to vast scenic-content (e.g., outdoor,
indoor, human, structures, etc.) but also tackles the HDR related
scene-specific challenges such as contrast and brightness, while preserving the
fine-grained details. We explore 4 possible combinations of
Generator-Discriminator architectural designs to specifically address some
prominent issues in HDR related deep-learning frameworks like blurring, tiling
patterns and saturation artifacts. By exploring different influences of scales,
loss-functions and normalization layers under a cGAN setting, we conclude with
adopting a multi-scale model for our task. To further leverage on the
large-scale availability of unlabeled HDR data, we train our network by
generating targets using an objective HDR quality metric, namely Tone Mapping
Image Quality Index (TMQI). We demonstrate results both quantitatively and
qualitatively, and showcase that our DeepTMO generates high-resolution,
high-quality output images over a large spectrum of real-world scenes. Finally,
we evaluate the perceived quality of our results by conducting a pair-wise
subjective study which confirms the versatility of our method.
"
1628,Convolutional Humanoid Animation via Deformation,"  In this paper we present a new deep learning-driven approach to image-based
synthesis of animations involving humanoid characters. Unlike previous deep
approaches to image-based animation our method makes no assumptions on the type
of motion to be animated nor does it require dense temporal input to produce
motion. Instead we generate new animations by interpolating between user chosen
keyframes, arranged sparsely in time. Utilizing a novel configuration manifold
learning approach we interpolate suitable motions between these keyframes. In
contrast to previous methods, ours requires less data (animations can be
generated from a single youtube video) and is broadly applicable to a wide
range of motions including facial motion, whole body motion and even scenes
with multiple characters. These improvements serve to significantly reduce the
difficulty in producing image-based animations of humanoid characters, allowing
even broader audiences to express their creativity.
"
1629,SDM-NET: Deep Generative Network for Structured Deformable Mesh,"  We introduce SDM-NET, a deep generative neural network which produces
structured deformable meshes. Specifically, the network is trained to generate
a spatial arrangement of closed, deformable mesh parts, which respect the
global part structure of a shape collection, e.g., chairs, airplanes, etc. Our
key observation is that while the overall structure of a 3D shape can be
complex, the shape can usually be decomposed into a set of parts, each
homeomorphic to a box, and the finer-scale geometry of the part can be
recovered by deforming the box. The architecture of SDM-NET is that of a
two-level variational autoencoder (VAE). At the part level, a PartVAE learns a
deformable model of part geometries. At the structural level, we train a
Structured Parts VAE (SP-VAE), which jointly learns the part structure of a
shape collection and the part geometries, ensuring a coherence between global
shape structure and surface details. Through extensive experiments and
comparisons with the state-of-the-art deep generative models of shapes, we
demonstrate the superiority of SDM-NET in generating meshes with visual
quality, flexible topology, and meaningful structures, which benefit shape
interpolation and other subsequently modeling tasks.
"
1630,Channel Decomposition into Painting Actions,"  This work presents a method to decompose a convolutional layer of the deep
neural network into painting actions. To behave like the human painter, these
actions are driven by the cost simulating the hand movement, the paint color
change, the stroke shape and the stroking style. To help planning, the Mask
R-CNN is applied to detect the object areas and decide the painting order. The
proposed painting system introduces a variety of extensions in artistic styles,
based on the chosen parameters. Further experiments are performed to evaluate
the channel penetration and the channel sensitivity on the strokes.
"
1631,Algebraic Representations for Volumetric Frame Fields,"  Field-guided parametrization methods have proven effective for quad meshing
of surfaces; these methods compute smooth cross fields to guide the meshing
process and then integrate the fields to construct a discrete mesh. A key
challenge in extending these methods to three dimensions, however, is
representation of field values. Whereas cross fields can be represented by
tangent vector fields that form a linear space, the 3D analog---an octahedral
frame field---takes values in a nonlinear manifold. In this work, we describe
the space of octahedral frames in the language of differential and algebraic
geometry. With this understanding, we develop geometry-aware tools for
optimization of octahedral fields, namely geodesic stepping and exact
projection via semidefinite relaxation. Our algebraic approach not only
provides an elegant and mathematically-sound description of the space of
octahedral frames but also suggests a generalization to frames whose three axes
scale independently, better capturing the singular behavior we expect to see in
volumetric frame fields. These new odeco frames, so-called as they are
represented by orthogonally decomposable tensors, also admit a semidefinite
program--based projection operator. Our description of the spaces of octahedral
and odeco frames suggests computing frame fields via manifold-based
optimization algorithms; we show that these algorithms efficiently produce
high-quality fields while maintaining stability and smoothness.
"
1632,FSGAN: Subject Agnostic Face Swapping and Reenactment,"  We present Face Swapping GAN (FSGAN) for face swapping and reenactment.
Unlike previous work, FSGAN is subject agnostic and can be applied to pairs of
faces without requiring training on those faces. To this end, we describe a
number of technical contributions. We derive a novel recurrent neural network
(RNN)-based approach for face reenactment which adjusts for both pose and
expression variations and can be applied to a single image or a video sequence.
For video sequences, we introduce continuous interpolation of the face views
based on reenactment, Delaunay Triangulation, and barycentric coordinates.
Occluded face regions are handled by a face completion network. Finally, we use
a face blending network for seamless blending of the two faces while preserving
target skin color and lighting conditions. This network uses a novel Poisson
blending loss which combines Poisson optimization with perceptual loss. We
compare our approach to existing state-of-the-art systems and show our results
to be both qualitatively and quantitatively superior.
"
1633,stdgpu: Efficient STL-like Data Structures on the GPU,"  Tremendous advances in parallel computing and graphics hardware opened up
several novel real-time GPU applications in the fields of computer vision,
computer graphics as well as augmented reality (AR) and virtual reality (VR).
Although these applications built upon established open-source frameworks that
provide highly optimized algorithms, they often come with custom self-written
data structures to manage the underlying data. In this work, we present stdgpu,
an open-source library which defines several generic GPU data structures for
fast and reliable data management. Rather than abandoning previous established
frameworks, our library aims to extend them, therefore bridging the gap between
CPU and GPU computing. This way, it provides clean and familiar interfaces and
integrates seamlessly into new as well as existing projects. We hope to foster
further developments towards unified CPU and GPU computing and welcome
contributions from the community.
"
1634,HOTVis: Higher-Order Time-Aware Visualisation of Dynamic Graphs,"  Network visualisation techniques are important tools for the exploratory
analysis of complex systems. While these methods are regularly applied to
visualise data on complex networks, we increasingly have access to time series
data that can be modelled as temporal networks or dynamic graphs. In dynamic
graphs, the temporal ordering of time-stamped edges determines the causal
topology of a system, i.e., which nodes can, directly and indirectly, influence
each other via a so-called causal path. This causal topology is crucial to
understand dynamical processes, assess the role of nodes, or detect clusters.
However, we lack graph drawing techniques that incorporate this information
into static visualisations. Addressing this gap, we present a novel dynamic
graph visualisation algorithm that utilises higher-order graphical models of
causal paths in time series data to compute time-aware static graph
visualisations. These visualisations combine the simplicity and
interpretability of static graphs with a time-aware layout algorithm that
highlights patterns in the causal topology that result from the temporal
dynamics of edges.
"
1635,"Extending editing capabilities of subdivision schemes by refinement of
  point-normal pairs","  In this paper we extend the 2D circle average of [11] to a 3D binary average
of point-normal pairs, and study its properties. We modify classical
surface-generating linear subdivision schemes with this average obtaining
surface-generating schemes refining point-normal pairs. The modified schemes
give the possibility to generate more geometries by editing the initial
normals. For the case of input data consisting of a mesh only, we present a
method for computing ""naive"" initial normals from the initial mesh. The
performance of several modified schemes is compared to their linear variants,
when operating on the same initial mesh, and examples of the editing
capabilities of the modified schemes are given. In addition we provide a link
to our repository, where we store the initial and refined mesh files, and the
implementation code. Several videos, demonstrating the editing capabilities of
the initial normals are provided in our Youtube channel.
"
1636,CompenNet++: End-to-end Full Projector Compensation,"  Full projector compensation aims to modify a projector input image such that
it can compensate for both geometric and photometric disturbance of the
projection surface. Traditional methods usually solve the two parts separately,
although they are known to correlate with each other. In this paper, we propose
the first end-to-end solution, named CompenNet++, to solve the two problems
jointly. Our work non-trivially extends CompenNet, which was recently proposed
for photometric compensation with promising performance. First, we propose a
novel geometric correction subnet, which is designed with a cascaded
coarse-to-fine structure to learn the sampling grid directly from photometric
sampling images. Second, by concatenating the geometric correction subset with
CompenNet, CompenNet++ accomplishes full projector compensation and is
end-to-end trainable. Third, after training, we significantly simplify both
geometric and photometric compensation parts, and hence largely improves the
running time efficiency. Moreover, we construct the first setup-independent
full compensation benchmark to facilitate the study on this topic. In our
thorough experiments, our method shows clear advantages over previous arts with
promising compensation quality and meanwhile being practically convenient.
"
1637,Thumbnails for Data Stories: A Survey of Current Practices,"  When people browse online news, small thumbnail images accompanying links to
articles attract their attention and help them to decide which articles to
read. As an increasing proportion of online news can be construed as data
journalism, we have witnessed a corresponding increase in the incorporation of
visualization in article thumbnails. However, there is little research to
support alternative design choices for visualization thumbnails, which include
resizing, cropping, simplifying, and embellishing charts appearing within the
body of the associated article. We therefore sought to better understand these
design choices and determine what makes a visualization thumbnail inviting and
interpretable. This paper presents our findings from a survey of visualization
thumbnails collected online and from conversations with data journalists and
news graphics designers. Our study reveals that there exists an uncharted
design space, one that is in need of further empirical study. Our work can thus
be seen as a first step toward providing structured guidance on how to design
thumbnails for data stories.
"
1638,Adding quadric fillets to quador lattice structures,"  Gupta et al. [1, 2] describe a very beautiful application of algebraic
geometry to lattice structures composed of quadric of revolution (quador)
implicit surfaces. However, the shapes created have concave edges where the
stubs meet, and such edges can be stress-raisers which can cause significant
problems with, for instance, fatigue under cyclic loading. This note describes
a way in which quadric fillets can be added to these models, thus relieving
this problem while retaining their computational simplicity and efficiency.
"
1639,The Topological Complexity of Spaces of Digital Jordan Curves,"  This research is motivated by studying image processing algorithms through a
topological lens. The images we focus on here are those that have been
segmented by digital Jordan curves as a means of image compression. The
algorithms of interest are those that continuously morph one digital image into
another digital image. Digital Jordan curves have been studied in a variety of
forms for decades now. Our contribution to this field is interpreting the set
of digital Jordan curves that can exist within a given digital plane as a
finite topological space. Computing the topological complexity of this space
determines the minimal number of continuous motion planning rules required to
transform one image into another, and determining the motion planners
associated to topological complexity provides the specific algorithms for doing
so. The main result of Section 3 is that our space of digital Jordan curves is
connected, hence, its topological complexity is finite. To build up to that, we
use Section 2 to prove some results about paths and distance functions that are
obvious in Hausdorff spaces, yet surprisingly elusive in $T_0$ spaces. We end
with Section 4, in which we study applications of these results. In particular,
we prove that our interpretation of the space of digital Jordan curves is the
only topologically correct interpretation. This article is an adaptation of the
author's Ph.D. dissertation.
"
1640,360-Degree Textures of People in Clothing from a Single Image,"  In this paper we predict a full 3D avatar of a person from a single image. We
infer texture and geometry in the UV-space of the SMPL model using an
image-to-image translation method. Given partial texture and segmentation
layout maps derived from the input view, our model predicts the complete
segmentation map, the complete texture map, and a displacement map. The
predicted maps can be applied to the SMPL model in order to naturally
generalize to novel poses, shapes, and even new clothing. In order to learn our
model in a common UV-space, we non-rigidly register the SMPL model to thousands
of 3D scans, effectively encoding textures and geometries as images in
correspondence. This turns a difficult 3D inference task into a simpler
image-to-image translation one. Results on rendered scans of people and images
from the DeepFashion dataset demonstrate that our method can reconstruct
plausible 3D avatars from a single image. We further use our model to digitally
change pose, shape, swap garments between people and edit clothing. To
encourage research in this direction we will make the source code available for
research purpose.
"
1641,DeepSketchHair: Deep Sketch-based 3D Hair Modeling,"  We present sketchhair, a deep learning based tool for interactive modeling of
3D hair from 2D sketches. Given a 3D bust model as reference, our sketching
system takes as input a user-drawn sketch (consisting of hair contour and a few
strokes indicating the hair growing direction within a hair region), and
automatically generates a 3D hair model, which matches the input sketch both
globally and locally. The key enablers of our system are two carefully designed
neural networks, namely, S2ONet, which converts an input sketch to a dense 2D
hair orientation field; and O2VNet, which maps the 2D orientation field to a 3D
vector field. Our system also supports hair editing with additional sketches in
new views. This is enabled by another deep neural network, V2VNet, which
updates the 3D vector field with respect to the new sketches. All the three
networks are trained with synthetic data generated from a 3D hairstyle
database. We demonstrate the effectiveness and expressiveness of our tool using
a variety of hairstyles and also compare our method with prior art.
"
1642,"Spatio-temporal Manifold Learning for Human Motions via Long-horizon
  Modeling","  Data-driven modeling of human motions is ubiquitous in computer graphics and
computer vision applications, such as synthesizing realistic motions or
recognizing actions. Recent research has shown that such problems can be
approached by learning a natural motion manifold using deep learning to address
the shortcomings of traditional data-driven approaches. However, previous
methods can be sub-optimal for two reasons. First, the skeletal information has
not been fully utilized for feature extraction. Unlike images, it is difficult
to define spatial proximity in skeletal motions in the way that deep networks
can be applied. Second, motion is time-series data with strong multi-modal
temporal correlations. A frame could be followed by several candidate frames
leading to different motions; long-range dependencies exist where a number of
frames in the beginning correlate to a number of frames later. Ineffective
modeling would either under-estimate the multi-modality and variance, resulting
in featureless mean motion or over-estimate them resulting in jittery motions.
In this paper, we propose a new deep network to tackle these challenges by
creating a natural motion manifold that is versatile for many applications. The
network has a new spatial component for feature extraction. It is also equipped
with a new batch prediction model that predicts a large number of frames at
once, such that long-term temporally-based objective functions can be employed
to correctly learn the motion multi-modality and variances. With our system,
long-duration motions can be predicted/synthesized using an open-loop setup
where the motion retains the dynamics accurately. It can also be used for
denoising corrupted motions and synthesizing new motions with given control
signals. We demonstrate that our system can create superior results comparing
to existing work in multiple applications.
"
1643,Continuous Toolpath Planning in Additive Manufacturing,"  We develop a framework that creates a new polygonal mesh representation of
the sparse infill domain of a layer-by-layer 3D printing job. We guarantee the
existence of a single, continuous tool path covering each connected piece of
the domain in every layer. We present a tool path algorithm that traverses each
such continuous tool path with no crossovers.
  The key construction at the heart of our framework is an Euler transformation
which converts a 2-dimensional cell complex K into a new 2-complex K^ such that
every vertex in the 1-skeleton G^ of K^ has even degree. Hence G^ is Eulerian,
and a Eulerian tour can be followed to print all edges in a continuous fashion.
  We start with a mesh K of the union of polygons obtained by projecting all
layers to the plane. We compute its Euler transformation K^. In the slicing
step, we clip K^ at each layer using its polygon to obtain a complex that may
not necessarily be Euler. We then patch this complex by adding edges such that
any odd-degree nodes created by slicing are transformed to have even degrees
again. We print extra support edges in place of any segments left out to ensure
there are no edges without support in the next layer. These support edges
maintain the Euler nature of the complex. Finally we describe a tree-based
search algorithm that builds the continuous tool path by traversing
""concentric"" cycles in the Euler complex. Our algorithm produces a tool path
that avoids material collisions and crossovers, and can be printed in a
continuous fashion irrespective of complex geometry or topology of the domain
(e.g., holes).
  We implement our test our framework on several 3D objects. Apart from
standard geometric shapes, we demonstrate the framework on the Stanford bunny.
"
1644,Developing Creative AI to Generate Sculptural Objects,"  We explore the intersection of human and machine creativity by generating
sculptural objects through machine learning. This research raises questions
about both the technical details of automatic art generation and the
interaction between AI and people, as both artists and the audience of art. We
introduce two algorithms for generating 3D point clouds and then discuss their
actualization as sculpture and incorporation into a holistic art installation.
Specifically, the Amalgamated DeepDream (ADD) algorithm solves the sparsity
problem caused by the naive DeepDream-inspired approach and generates creative
and printable point clouds. The Partitioned DeepDream (PDD) algorithm further
allows us to explore more diverse 3D object creation by combining point cloud
clustering algorithms and ADD.
"
1645,KeystoneDepth: Visualizing History in 3D,"  This paper introduces the largest and most diverse collection of rectified
stereo image pairs to the research community, KeystoneDepth, consisting of tens
of thousands of stereographs of historical people, events, objects, and scenes
between 1860 and 1963. Leveraging the Keystone-Mast raw scans from the
California Museum of Photography, we apply multiple processing steps to produce
clean stereo image pairs, complete with calibration data, rectification
transforms, and depthmaps. A second contribution is a novel approach for view
synthesis that runs at real-time rates on a mobile device, simulating the
experience of looking through an open window into these historical scenes. We
produce results for thousands of antique stereographs, capturing many important
historical moments.
"
1646,Multi-level Graph Drawing using Infomap Clustering,"  Infomap clustering finds the community structures that minimize the expected
description length of a random walk trajectory; algorithms for infomap
clustering run fast in practice for large graphs. In this paper we leverage the
effectiveness of Infomap clustering combined with the multi-level graph drawing
paradigm. Experiments show that our new Infomap based multi-level algorithm
produces good visualization of large and complex networks, with significant
improvement in quality metrics.
"
1647,"Pro-Cam SSfM: Projector-Camera System for Structure and Spectral
  Reflectance from Motion","  In this paper, we propose a novel projector-camera system for practical and
low-cost acquisition of a dense object 3D model with the spectral reflectance
property. In our system, we use a standard RGB camera and leverage an
off-the-shelf projector as active illumination for both the 3D reconstruction
and the spectral reflectance estimation. We first reconstruct the 3D points
while estimating the poses of the camera and the projector, which are
alternately moved around the object, by combining multi-view structured light
and structure-from-motion (SfM) techniques. We then exploit the projector for
multispectral imaging and estimate the spectral reflectance of each 3D point
based on a novel spectral reflectance estimation model considering the
geometric relationship between the reconstructed 3D points and the estimated
projector positions. Experimental results on several real objects demonstrate
that our system can precisely acquire a dense 3D model with the full spectral
reflectance property using off-the-shelf devices.
"
1648,ColorNet -- Estimating Colorfulness in Natural Images,"  Measuring the colorfulness of a natural or virtual scene is critical for many
applications in image processing field ranging from capturing to display. In
this paper, we propose the first deep learning-based colorfulness estimation
metric. For this purpose, we develop a color rating model which simultaneously
learns to extracts the pertinent characteristic color features and the mapping
from feature space to the ideal colorfulness scores for a variety of natural
colored images. Additionally, we propose to overcome the lack of adequate
annotated dataset problem by combining/aligning two publicly available
colorfulness databases using the results of a new subjective test which employs
a common subset of both databases. Using the obtained subjectively annotated
dataset with 180 colored images, we finally demonstrate the efficacy of our
proposed model over the traditional methods, both quantitatively and
qualitatively.
"
1649,"Predicting Animation Skeletons for 3D Articulated Models via Volumetric
  Nets","  We present a learning method for predicting animation skeletons for input 3D
models of articulated characters. In contrast to previous approaches that fit
pre-defined skeleton templates or predict fixed sets of joints, our method
produces an animation skeleton tailored for the structure and geometry of the
input 3D model. Our architecture is based on a stack of hourglass modules
trained on a large dataset of 3D rigged characters mined from the web. It
operates on the volumetric representation of the input 3D shapes augmented with
geometric shape features that provide additional cues for joint and bone
locations. Our method also enables intuitive user control of the
level-of-detail for the output skeleton. Our evaluation demonstrates that our
approach predicts animation skeletons that are much more similar to the ones
created by humans compared to several alternatives and baselines.
"
1650,"Design, Assembly, Calibration, and Measurement of an Augmented Reality
  Haploscope","  A haploscope is an optical system which produces a carefully controlled
virtual image. Since the development of Wheatstone's original stereoscope in
1838, haploscopes have been used to measure perceptual properties of human
stereoscopic vision. This paper presents an augmented reality (AR) haploscope,
which allows the viewing of virtual objects superimposed against the real
world. Our lab has used generations of this device to make a careful series of
perceptual measurements of AR phenomena, which have been described in
publications over the previous 8 years. This paper systematically describes the
design, assembly, calibration, and measurement of our AR haploscope. These
methods have been developed and improved in our lab over the past 10 years.
Despite the fact that 180 years have elapsed since the original report of
Wheatstone's stereoscope, we have not previously found a paper that describes
these kinds of details.
"
1651,"Sign Language Recognition, Generation, and Translation: An
  Interdisciplinary Perspective","  Developing successful sign language recognition, generation, and translation
systems requires expertise in a wide range of fields, including computer
vision, computer graphics, natural language processing, human-computer
interaction, linguistics, and Deaf culture. Despite the need for deep
interdisciplinary knowledge, existing research occurs in separate disciplinary
silos, and tackles separate portions of the sign language processing pipeline.
This leads to three key questions: 1) What does an interdisciplinary view of
the current landscape reveal? 2) What are the biggest challenges facing the
field? and 3) What are the calls to action for people working in the field? To
help answer these questions, we brought together a diverse group of experts for
a two-day workshop. This paper presents the results of that interdisciplinary
workshop, providing key background that is often overlooked by computer
scientists, a review of the state-of-the-art, a set of pressing challenges, and
a call to action for the research community.
"
1652,You Can't Publish Replication Studies (and How to Anyways),"  Reproducibility has been increasingly encouraged by communities of science in
order to validate experimental conclusions, and replication studies represent a
significant opportunity to vision scientists wishing contribute new perceptual
models, methods, or insights to the visualization community. Unfortunately, the
notion of replication of previous studies does not lend itself to how we
communicate research findings. Simple put, studies that re-conduct and confirm
earlier results do not hold any novelty, a key element to the modern research
publication system. Nevertheless, savvy researchers have discovered ways to
produce replication studies by embedding them into other sufficiently novel
studies. In this position paper, we define three methods -- re-evaluation,
expansion, and specialization -- for embedding a replication study into a novel
published work. Within this context, we provide a non-exhaustive case study on
replications of Cleveland and McGill's seminal work on graphical perception. As
it turns out, numerous replication studies have been carried out based on that
work, which have both confirmed prior findings and shined new light on our
understanding of human perception. Finally, we discuss how publishing a true
replication study should be avoided, while providing suggestions for how vision
scientists and others can still use replication studies as a vehicle to
producing visualization research publications.
"
1653,"Inconsistent Surface Registration via Optimization of Mapping
  Distortions","  We address the problem of registering two surfaces, of which a natural
bijection between them does not exist. More precisely, only a partial subset of
the source surface is assumed to be in correspondence with a subset of the
target surface. We call such a problem an {\it inconsistent surface
registration (ISR)} problem. This problem is challenging as the corresponding
regions on each surface and a meaningful bijection between them have to be
simultaneously determined. In this paper, we propose a variational model to
solve the ISR problem by minimizing mapping distortions. Mapping distortions
are described by the Beltrami coefficient as well as the differential of the
mapping. Registration is then guided by feature landmarks and/or intensities,
such as curvatures, defined on each surface. The key idea of the approach is to
control angle and scale distortions via quasiconformal theory as well as
minimizing landmark and/or intensity mismatch. A splitting method is proposed
to iteratively search for the optimal corresponding regions as well as the
optimal bijection between them. Bijectivity of the mapping is easily enforced
by a thresholding of the Beltrami coefficient. We test the proposed method on
both synthetic and real examples. Experimental results demonstrate the efficacy
of our proposed model.
"
1654,A Flexible Neural Renderer for Material Visualization,"  Photo realism in computer generated imagery is crucially dependent on how
well an artist is able to recreate real-world materials in the scene. The
workflow for material modeling and editing typically involves manual tweaking
of material parameters and uses a standard path tracing engine for visual
feedback. A lot of time may be spent in iterative selection and rendering of
materials at an appropriate quality. In this work, we propose a convolutional
neural network based workflow which quickly generates high-quality ray traced
material visualizations on a shaderball. Our novel architecture allows for
control over environment lighting and assists material selection along with the
ability to render spatially-varying materials. Additionally, our network
enables control over environment lighting which gives an artist more freedom
and provides better visualization of the rendered material. Comparison with
state-of-the-art denoising and neural rendering techniques suggests that our
neural renderer performs faster and better. We provide a interactive
visualization tool and release our training dataset to foster further research
in this area.
"
1655,Collision Detection for Agents in Multi-Agent Pathfinding,"  Recent work on the multi-agent pathfinding problem (MAPF) has begun to study
agents with motion that is more complex, for example, with non-unit action
durations and kinematic constraints. An important aspect of MAPF is collision
detection. Many collision detection approaches exist, but often suffer from
issues such as high computational cost or causing false negative or false
positive detections. In practice, these issues can result in problems that
range from inefficiency and annoyance to catastrophic. The main contribution of
this technical report is to provide a high-level overview of major categories
of collision detection, along with methods of collision detection and
anticipatory collision avoidance for agents that are both computationally
efficient and highly accurate.
"
1656,"Subdivision of point-normal pairs with application to smoothing feasible
  robot path","  In a previous paper [11] we introduced a weighted binary average of two 2D
point-normal pairs, termed circle average, and investigated subdivision schemes
based on it. These schemes refine point-normal pairs in 2D, and converge to
limit curves and limit normals. Such a scheme has the disadvantage that the
limit normals are not the normals of the limit curve. In this paper we solve
this problem by proposing a new averaging method, and obtaining a new family of
algorithms based on it. We demonstrate their new editing capabilities and apply
this subdivision technique to smooth a precomputed feasible polygonal point
robot path.
"
1657,Physics-Based Rendering for Improving Robustness to Rain,"  To improve the robustness to rain, we present a physically-based rain
rendering pipeline for realistically inserting rain into clear weather images.
Our rendering relies on a physical particle simulator, an estimation of the
scene lighting and an accurate rain photometric modeling to augment images with
arbitrary amount of realistic rain or fog. We validate our rendering with a
user study, proving our rain is judged 40% more realistic that
state-of-the-art. Using our generated weather augmented Kitti and Cityscapes
dataset, we conduct a thorough evaluation of deep object detection and semantic
segmentation algorithms and show that their performance decreases in degraded
weather, on the order of 15% for object detection and 60% for semantic
segmentation. Furthermore, we show refining existing networks with our
augmented images improves the robustness of both object detection and semantic
segmentation algorithms. We experiment on nuScenes and measure an improvement
of 15% for object detection and 35% for semantic segmentation compared to
original rainy performance. Augmented databases and code are available on the
project page.
"
1658,"Adversarial regression training for visualizing the progression of
  chronic obstructive pulmonary disease with chest x-rays","  Knowledge of what spatial elements of medical images deep learning methods
use as evidence is important for model interpretability, trustiness, and
validation. There is a lack of such techniques for models in regression tasks.
We propose a method, called visualization for regression with a generative
adversarial network (VR-GAN), for formulating adversarial training specifically
for datasets containing regression target values characterizing disease
severity. We use a conditional generative adversarial network where the
generator attempts to learn to shift the output of a regressor through creating
disease effect maps that are added to the original images. Meanwhile, the
regressor is trained to predict the original regression value for the modified
images. A model trained with this technique learns to provide visualization for
how the image would appear at different stages of the disease. We analyze our
method in a dataset of chest x-rays associated with pulmonary function tests,
used for diagnosing chronic obstructive pulmonary disease (COPD). For
validation, we compute the difference of two registered x-rays of the same
patient at different time points and correlate it to the generated disease
effect map. The proposed method outperforms a technique based on classification
and provides realistic-looking images, making modifications to images following
what radiologists usually observe for this disease. Implementation code is
available at https://github.com/ricbl/vrgan.
"
1659,"EventCap: Monocular 3D Capture of High-Speed Human Motions using an
  Event Camera","  The high frame rate is a critical requirement for capturing fast human
motions. In this setting, existing markerless image-based methods are
constrained by the lighting requirement, the high data bandwidth and the
consequent high computation overhead. In this paper, we propose EventCap ---
the first approach for 3D capturing of high-speed human motions using a single
event camera. Our method combines model-based optimization and CNN-based human
pose detection to capture high-frequency motion details and to reduce the
drifting in the tracking. As a result, we can capture fast motions at
millisecond resolution with significantly higher data efficiency than using
high frame rate videos. Experiments on our new event-based fast human motion
dataset demonstrate the effectiveness and accuracy of our method, as well as
its robustness to challenging lighting conditions.
"
1660,Geometric optimization using nonlinear rotation-invariant coordinates,"  Geometric optimization problems are at the core of many applications in
geometry processing. The choice of a representation fitting an optimization
problem can considerably simplify solving the problem. We consider the
Nonlinear Rotation-Invariant Coordinates (NRIC) that represent the nodal
positions of a discrete triangular surface with fixed combinatorics as a vector
that stacks all edge lengths and dihedral angles of the mesh. It is known that
this representation associates a unique vector to an equivalence class of nodal
positions that differ by a rigid body motion. Moreover, integrability
conditions that ensure the existence of nodal positions that match a given
vector of edge lengths and dihedral angles have been established. The goal of
this paper is to develop the machinery needed to use the NRIC for solving
geometric optimization problems. First, we use the integrability conditions to
derive an implicit description of the space of discrete surfaces as a
submanifold of an Euclidean space and a corresponding description of its
tangent spaces. Secondly, we reformulate the integrability conditions using
quaternions and provide explicit formulas for their first and second
derivatives facilitating the use of Hessians in NRIC-based optimization
problems. Lastly, we introduce a fast and robust algorithm that reconstructs
nodal positions from almost integrable NRIC. We demonstrate the benefits of
this approach on a collection of geometric optimization problems. Comparisons
to alternative approaches indicate that NRIC-based optimization is particularly
effective for problems involving near-isometric deformations.
"
1661,"Animated Stickies: Fast Video Projection Mapping onto a Markerless Plane
  through a Direct Closed-Loop Alignment","  This paper presents a fast projection mapping method for moving image content
projected onto a markerless planar surface using a low-latency Digital
Micromirror Device (DMD) projector. By adopting a closed-loop alignment
approach, in which not only the surface texture but also the projected image is
tracked by a camera, the proposed method is free from a calibration or position
adjustment between the camera and projector. We designed fiducial patterns to
be inserted into a fast flapping sequence of binary frames of the DMD
projector, which allows the simultaneous tracking of the surface texture and a
fiducial geometry separate from a single image captured by the camera. The
proposed method implemented on a CPU runs at 400 fps and enables arbitrary
video contents to be ""stuck"" onto a variety of textured surfaces.
"
1662,READ: Recursive Autoencoders for Document Layout Generation,"  Layout is a fundamental component of any graphic design. Creating large
varieties of plausible document layouts can be a tedious task, requiring
numerous constraints to be satisfied, including local ones relating different
semantic elements and global constraints on the general appearance and spacing.
In this paper, we present a novel framework, coined READ, for REcursive
Autoencoders for Document layout generation, to generate plausible 2D layouts
of documents in large quantities and varieties. First, we devise an exploratory
recursive method to extract a structural decomposition of a single document.
Leveraging a dataset of documents annotated with labeled bounding boxes, our
recursive neural network learns to map the structural representation, given in
the form of a simple hierarchy, to a compact code, the space of which is
approximated by a Gaussian distribution. Novel hierarchies can be sampled from
this space, obtaining new document layouts. Moreover, we introduce a
combinatorial metric to measure structural similarity among document layouts.
We deploy it to show that our method is able to generate highly variable and
realistic layouts. We further demonstrate the utility of our generated layouts
in the context of standard detection tasks on documents, showing that detection
performance improves when the training data is augmented with generated
documents whose layouts are produced by READ.
"
1663,Accelerating ADMM for Efficient Simulation and Optimization,"  The alternating direction method of multipliers (ADMM) is a popular approach
for solving optimization problems that are potentially non-smooth and with hard
constraints. It has been applied to various computer graphics applications,
including physical simulation, geometry processing, and image processing.
However, ADMM can take a long time to converge to a solution of high accuracy.
Moreover, many computer graphics tasks involve non-convex optimization, and
there is often no convergence guarantee for ADMM on such problems since it was
originally designed for convex optimization. In this paper, we propose a method
to speed up ADMM using Anderson acceleration, an established technique for
accelerating fixed-point iterations. We show that in the general case, ADMM is
a fixed-point iteration of the second primal variable and the dual variable,
and Anderson acceleration can be directly applied. Additionally, when the
problem has a separable target function and satisfies certain conditions, ADMM
becomes a fixed-point iteration of only one variable, which further reduces the
computational overhead of Anderson acceleration. Moreover, we analyze a
particular non-convex problem structure that is common in computer graphics,
and prove the convergence of ADMM on such problems under mild assumptions. We
apply our acceleration technique on a variety of optimization problems in
computer graphics, with notable improvement on their convergence speed.
"
1664,"Implicit Progressive-Iterative Approximation for Curve and Surface
  Reconstruction","  Implicit curve and surface reconstruction attracts the attention of many
researchers and gains a wide range of applications, due to its ability to
describe objects with complicated geometry and topology. However, extra
zero-level sets or spurious sheets arise in the reconstruction process makes
the reconstruction result challenging to be interpreted and damage the final
result. In this paper, we proposed an implicit curve and surface reconstruction
method based on the progressive-iterative approximation method, named implicit
progressive-iterative approximation (I-PIA). The proposed method elegantly
eliminates the spurious sheets naturally without requiring any explicit
minimization procedure, thus reducing the computational cost greatly and
providing high-quality reconstruction results. Numerical examples are provided
to demonstrate the efficiency and effectiveness of the proposed method.
"
1665,Next Event Backtracking,"  In light transport simulation, challenging situations are caused by the
variety of materials and the relative length of path segments. Path Tracing can
handle many situations and scales well to parallel hardware. However, it is not
able to produce paths which have a smooth surface in connection with a small
light source. Here, photon transports perform superior, which can be
ineffective if the smooth object is small compared to the scene size.
  We propose to use the last segment of a Path Tracer path as the first segment
of a photon path. As a result, the strengths of next event estimation are
inherited by the photon transport and photons are guided toward the regions
where they are most useful. To that end, we developed a lock-free sparse
octree, which we use for fast and robust density estimates. Summarizing, the
new method can outperform state of the art algorithms like Vertex Connection
and Merging in certain scenarios.
"
1666,Topologically-Guided Color Image Enhancement,"  Enhancement is an important step in post-processing digital images for
personal use, in medical imaging, and for object recognition. Most existing
manual techniques rely on region selection, similarity, and/or thresholding for
editing, never really considering the topological structure of the image. In
this paper, we leverage the contour tree to extract a hierarchical
representation of the topology of an image. We propose 4 topology-aware
transfer functions for editing features of the image using local topological
properties, instead of global image properties. Finally, we evaluate our
approach with grayscale and color images.
"
1667,"Propagate and Pair: A Single-Pass Approach to Critical Point Pairing in
  Reeb Graphs","  With the popularization of Topological Data Analysis, the Reeb graph has
found new applications as a summarization technique in the analysis and
visualization of large and complex data, whose usefulness extends beyond just
the graph itself. Pairing critical points enables forming topological
fingerprints, known as persistence diagrams, that provides insights into the
structure and noise in data. Although the body of work addressing the efficient
calculation of Reeb graphs is large, the literature on pairing is limited. In
this paper, we discuss two algorithmic approaches for pairing critical points
in Reeb graphs, first a multipass approach, followed by a new single-pass
algorithm, called Propagate and Pair.
"
1668,"3D Morphable Face Models -- Past, Present and Future","  In this paper, we provide a detailed survey of 3D Morphable Face Models over
the 20 years since they were first proposed. The challenges in building and
applying these models, namely capture, modeling, image formation, and image
analysis, are still active research topics, and we review the state-of-the-art
in each of these areas. We also look ahead, identifying unsolved challenges,
proposing directions for future research and highlighting the broad range of
current and future applications.
"
1669,Learning Elastic Constitutive Material and Damping Models,"  Commonly used linear and nonlinear constitutive material models in
deformation simulation contain many simplifications and only cover a tiny part
of possible material behavior. In this work we propose a framework for learning
customized models of deformable materials from example surface trajectories.
The key idea is to iteratively improve a correction to a nominal model of the
elastic and damping properties of the object, which allows new forward
simulations with the learned correction to more accurately predict the behavior
of a given soft object. Space-time optimization is employed to identify gentle
control forces with which we extract necessary data for model inference and to
finally encapsulate the material correction into a compact parametric form.
Furthermore, a patch based position constraint is proposed to tackle the
challenge of handling incomplete and noisy observations arising in real-world
examples. We demonstrate the effectiveness of our method with a set of
synthetic examples, as well with data captured from real world homogeneous
elastic objects.
"
1670,Poly-GAN: Multi-Conditioned GAN for Fashion Synthesis,"  We present Poly-GAN, a novel conditional GAN architecture that is motivated
by Fashion Synthesis, an application where garments are automatically placed on
images of human models at an arbitrary pose. Poly-GAN allows conditioning on
multiple inputs and is suitable for many tasks, including image alignment,
image stitching, and inpainting. Existing methods have a similar pipeline where
three different networks are used to first align garments with the human pose,
then perform stitching of the aligned garment and finally refine the results.
Poly-GAN is the first instance where a common architecture is used to perform
all three tasks. Our novel architecture enforces the conditions at all layers
of the encoder and utilizes skip connections from the coarse layers of the
encoder to the respective layers of the decoder. Poly-GAN is able to perform a
spatial transformation of the garment based on the RGB skeleton of the model at
an arbitrary pose. Additionally, Poly-GAN can perform image stitching,
regardless of the garment orientation, and inpainting on the garment mask when
it contains irregular holes. Our system achieves state-of-the-art quantitative
results on Structural Similarity Index metric and Inception Score metric using
the DeepFashion dataset.
"
1671,"Synthesizing Coupled 3D Face Modalities by Trunk-Branch Generative
  Adversarial Networks","  Generating realistic 3D faces is of high importance for computer graphics and
computer vision applications. Generally, research on 3D face generation
revolves around linear statistical models of the facial surface. Nevertheless,
these models cannot represent faithfully either the facial texture or the
normals of the face, which are very crucial for photo-realistic face synthesis.
Recently, it was demonstrated that Generative Adversarial Networks (GANs) can
be used for generating high-quality textures of faces. Nevertheless, the
generation process either omits the geometry and normals, or independent
processes are used to produce 3D shape information. In this paper, we present
the first methodology that generates high-quality texture, shape, and normals
jointly, which can be used for photo-realistic synthesis. To do so, we propose
a novel GAN that can generate data from different modalities while exploiting
their correlations. Furthermore, we demonstrate how we can condition the
generation on the expression and create faces with various facial expressions.
The qualitative results shown in this paper are compressed due to size
limitations, full-resolution results and the accompanying video can be found in
the supplementary documents. The code and models are available at the project
page: https://github.com/barisgecer/TBGAN.
"
1672,Neural Style-Preserving Visual Dubbing,"  Dubbing is a technique for translating video content from one language to
another. However, state-of-the-art visual dubbing techniques directly copy
facial expressions from source to target actors without considering
identity-specific idiosyncrasies such as a unique type of smile. We present a
style-preserving visual dubbing approach from single video inputs, which
maintains the signature style of target actors when modifying facial
expressions, including mouth motions, to match foreign languages. At the heart
of our approach is the concept of motion style, in particular for facial
expressions, i.e., the person-specific expression change that is yet another
essential factor beyond visual accuracy in face editing applications. Our
method is based on a recurrent generative adversarial network that captures the
spatiotemporal co-activation of facial expressions, and enables generating and
modifying the facial expressions of the target actor while preserving their
style. We train our model with unsynchronized source and target videos in an
unsupervised manner using cycle-consistency and mouth expression losses, and
synthesize photorealistic video frames using a layered neural face renderer.
Our approach generates temporally coherent results, and handles dynamic
backgrounds. Our results show that our dubbing approach maintains the
idiosyncratic style of the target actor better than previous approaches, even
for widely differing source and target actors.
"
1673,C3DPO: Canonical 3D Pose Networks for Non-Rigid Structure From Motion,"  We propose C3DPO, a method for extracting 3D models of deformable objects
from 2D keypoint annotations in unconstrained images. We do so by learning a
deep network that reconstructs a 3D object from a single view at a time,
accounting for partial occlusions, and explicitly factoring the effects of
viewpoint changes and object deformations. In order to achieve this
factorization, we introduce a novel regularization technique. We first show
that the factorization is successful if, and only if, there exists a certain
canonicalization function of the reconstructed shapes. Then, we learn the
canonicalization function together with the reconstruction one, which
constrains the result to be consistent. We demonstrate state-of-the-art
reconstruction results for methods that do not use ground-truth 3D supervision
for a number of benchmarks, including Up3D and PASCAL3D+. Source code has been
made available at https://github.com/facebookresearch/c3dpo_nrsfm.
"
1674,Deep Iterative Frame Interpolation for Full-frame Video Stabilization,"  Video stabilization is a fundamental and important technique for higher
quality videos. Prior works have extensively explored video stabilization, but
most of them involve cropping of the frame boundaries and introduce moderate
levels of distortion. We present a novel deep approach to video stabilization
which can generate video frames without cropping and low distortion. The
proposed framework utilizes frame interpolation techniques to generate in
between frames, leading to reduced inter-frame jitter. Once applied in an
iterative fashion, the stabilization effect becomes stronger. A major advantage
is that our framework is end-to-end trainable in an unsupervised manner. In
addition, our method is able to run in near real-time (15 fps). To the best of
our knowledge, this is the first work to propose an unsupervised deep approach
to full-frame video stabilization. We show the advantages of our method through
quantitative and qualitative evaluations comparing to the state-of-the-art
methods.
"
1675,Real-time Deformation with Coupled Cages and Skeletons,"  Skeleton-based and cage-based deformation techniques represent the two most
popular approaches to control real-time deformations of digital shapes and are,
to a vast extent, complementary to one another. Despite their complementary
roles, high-end modeling packages do not allow for seamless integration of such
control structures, thus inducing a considerable burden on the user to maintain
them synchronized. In this paper, we propose a framework that seamlessly
combines rigging skeletons and deformation cages, granting artists with a
real-time deformation system that operates using any smooth combination of the
two approaches. By coupling the deformation spaces of cages and skeletons, we
access a much larger space, containing poses that are impossible to obtain by
acting solely on a skeleton or a cage. Our method is oblivious to the specific
techniques used to perform skinning and cage-based deformation, securing it
compatible with pre-existing tools. We demonstrate the usefulness of our hybrid
approach on a variety of examples.
"
1676,"A Proposed Framework for Interactive Virtual Reality In Situ
  Visualization of Parallel Numerical Simulations","  As computer simulations progress to increasingly complex, non-linear, and
three-dimensional systems and phenomena, intuitive and immediate visualization
of their results is becoming crucial. While Virtual Reality (VR) and Natural
User Interfaces (NUIs) have been shown to improve understanding of complex 3D
data, their application to live in situ visualization and computational
steering is hampered by performance requirements. Here, we present the design
of a software framework for interactive VR in situ visualization of parallel
numerical simulations, as well as a working prototype implementation. Our
design is targeted towards meeting the performance requirements for VR, and our
work is packaged in a framework that allows for easy instrumentation of
simulations. Our preliminary results inform about the technical feasibility of
the architecture, as well as the challenges that remain.
"
1677,"DensePoint: Learning Densely Contextual Representation for Efficient
  Point Cloud Processing","  Point cloud processing is very challenging, as the diverse shapes formed by
irregular points are often indistinguishable. A thorough grasp of the elusive
shape requires sufficiently contextual semantic information, yet few works
devote to this. Here we propose DensePoint, a general architecture to learn
densely contextual representation for point cloud processing. Technically, it
extends regular grid CNN to irregular point configuration by generalizing a
convolution operator, which holds the permutation invariance of points, and
achieves efficient inductive learning of local patterns. Architecturally, it
finds inspiration from dense connection mode, to repeatedly aggregate
multi-level and multi-scale semantics in a deep hierarchy. As a result, densely
contextual information along with rich semantics, can be acquired by DensePoint
in an organic manner, making it highly effective. Extensive experiments on
challenging benchmarks across four tasks, as well as thorough model analysis,
verify DensePoint achieves the state of the arts.
"
1678,"GLoG: Laplacian of Gaussian for Spatial Pattern Detection in
  Spatio-Temporal Data","  Boundary detection has long been a fundamental tool for image processing and
computer vision, supporting the analysis of static and time-varying data. In
this work, we built upon the theory of Graph Signal Processing to propose a
novel boundary detection filter in the context of graphs, having as main
application scenario the visual analysis of spatio-temporal data. More
specifically, we propose the equivalent for graphs of the so-called Laplacian
of Gaussian edge detection filter, which is widely used in image processing.
The proposed filter is able to reveal interesting spatial patterns while still
enabling the definition of entropy of time slices. The entropy reveals the
degree of randomness of a time slice, helping users to identify expected and
unexpected phenomena over time. The effectiveness of our approach appears in
applications involving synthetic and real data sets, which show that the
proposed methodology is able to uncover interesting spatial and temporal
phenomena. The provided examples and case studies make clear the usefulness of
our approach as a mechanism to support visual analytic tasks involving
spatio-temporal data.
"
1679,PTRM: Perceived Terrain Realism Metrics,"  Terrains are visually important and commonly used in computer graphics. While
many algorithms for their generation exist, it is difficult to assess the
realism of a generated terrain. This paper presents a first step in the
direction of perceptual evaluation of terrain models. We gathered and
categorized several classes of real terrains and we generated synthetic
terrains by using methods from computer graphics. We then conducted two large
studies ranking the terrains perceptually and showing that the synthetic
terrains are perceived as lacking realism as compared to the real ones. Then we
provide insight into the features that affect the perceived realism by a
quantitative evaluation based on localized geomorphology-based landform
features (geomorphons) that categorize terrain structures such as valleys,
ridges, hollows, etc. We show that the presence or absence of certain features
have a significant perceptual effect. We then introduce Perceived Terrain
Realism Metrics (PTRM); a perceptual metrics that estimates perceived realism
of a terrain represented as a digital elevation map by relating distribution of
terrain features with their perceived realism. We validated PTRM on real and
synthetic data and compared it to the perceptual studies. To confirm the
importance of the presence of these features, we used a generative deep neural
network to transfer them between real terrains and synthetic ones and we
performed another perceptual experiment that further confirmed their importance
for perceived realism.
"
1680,Mathematical Foundations in Visualization,"  Mathematical concepts and tools have shaped the field of visualization in
fundamental ways and played a key role in the development of a large variety of
visualization techniques. In this chapter, we sample the visualization
literature to provide a taxonomy of the usage of mathematics in visualization,
and to identify a fundamental set of mathematics that should be taught to
students as part of an introduction to contemporary visualization research.
Within the scope of this chapter, we are unable to provide a full review of all
mathematical foundations of visualization; rather, we identify a number of
concepts that are useful in visualization, explain their significance, and
provide references for further reading.
"
1681,"Computer-Aided Automated Detection of Gene-Controlled Social Actions of
  Drosophila","  Gene expression of social actions in Drosophilae has been attracting wide
interest from biologists, medical scientists and psychologists. Gene-edited
Drosophilae have been used as a test platform for experimental investigation.
For example, Parkinson's genes can be embedded into a group of newly bred
Drosophilae for research purpose. However, human observation of numerous tiny
Drosophilae for a long term is an arduous work, and the dependence on human's
acute perception is highly unreliable. As a result, an automated system of
social action detection using machine learning has been highly demanded. In
this study, we propose to automate the detection and classification of two
innate aggressive actions demonstrated by Drosophilae. Robust keypoint
detection is achieved using selective spatio-temporal interest points (sSTIP)
which are then described using the 3D Scale Invariant Feature Transform
(3D-SIFT) descriptors. Dimensionality reduction is performed using Spectral
Regression Kernel Discriminant Analysis (SR-KDA) and classification is done
using the nearest centre rule. The classification accuracy shown demonstrates
the feasibility of the proposed system.
"
1682,Measures in Visualization Space,"  Measurement is an integral part of modern science, providing the fundamental
means for evaluation, comparison, and prediction. In the context of
visualization, several different types of measures have been proposed, ranging
from approaches that evaluate particular aspects of individual visualization
techniques, their perceptual characteristics, and even economic factors.
Furthermore, there are approaches that attempt to provide means for measuring
general properties of the visualization process as a whole. Measures can be
quantitative or qualitative, and one of the primary goals is to provide
objective means for reasoning about visualizations and their effectiveness. As
such, they play a central role in the development of scientific theories for
visualization. In this chapter, we provide an overview of the current state of
the art, survey and classify different types of visualization measures,
characterize their strengths and drawbacks, and provide an outline of open
challenges for future research.
"
1683,3D Ken Burns Effect from a Single Image,"  The Ken Burns effect allows animating still images with a virtual camera scan
and zoom. Adding parallax, which results in the 3D Ken Burns effect, enables
significantly more compelling results. Creating such effects manually is
time-consuming and demands sophisticated editing skills. Existing automatic
methods, however, require multiple input images from varying viewpoints. In
this paper, we introduce a framework that synthesizes the 3D Ken Burns effect
from a single image, supporting both a fully automatic mode and an interactive
mode with the user controlling the camera. Our framework first leverages a
depth prediction pipeline, which estimates scene depth that is suitable for
view synthesis tasks. To address the limitations of existing depth estimation
methods such as geometric distortions, semantic distortions, and inaccurate
depth boundaries, we develop a semantic-aware neural network for depth
prediction, couple its estimate with a segmentation-based depth adjustment
process, and employ a refinement neural network that facilitates accurate depth
predictions at object boundaries. According to this depth estimate, our
framework then maps the input image to a point cloud and synthesizes the
resulting video frames by rendering the point cloud from the corresponding
camera positions. To address disocclusions while maintaining geometrically and
temporally coherent synthesis results, we utilize context-aware color- and
depth-inpainting to fill in the missing information in the extreme views of the
camera path, thus extending the scene geometry of the point cloud. Experiments
with a wide variety of image content show that our method enables realistic
synthesis results. Our study demonstrates that our system allows users to
achieve better results while requiring little effort compared to existing
solutions for the 3D Ken Burns effect creation.
"
1684,"LOCALIS: Locally-adaptive Line Simplification for GPU-based Geographic
  Vector Data Visualization","  Visualization of large vector line data is a core task in geographic and
cartographic systems. Vector maps are often displayed at different cartographic
generalization levels, traditionally by using several discrete levels-of-detail
(LODs). This limits the generalization levels to a fixed and predefined set of
LODs, and generally does not support smooth LOD transitions. However, fast GPUs
and novel line rendering techniques can be exploited to integrate dynamic
vector map LOD management into GPU-based algorithms for locally-adaptive line
simplification and real-time rendering. We propose a new technique that
interactively visualizes large line vector datasets at variable LODs. It is
based on the Douglas-Peucker line simplification principle, generating an
exhaustive set of line segments whose specific subsets represent the lines at
any variable LOD. At run time, an appropriate and view-dependent error metric
supports screen-space adaptive LOD levels and the display of the correct subset
of line segments accordingly. Our implementation shows that we can simplify and
display large line datasets interactively. We can successfully apply line style
patterns, dynamic LOD selection lenses, and anti-aliasing techniques to our
line rendering.
"
1685,"Scenior: An Immersive Visual Scripting system based on VR Software
  Design Patterns for Experiential Training","  Virtual reality (VR) has re-emerged as a low-cost, highly accessible consumer
product, and training on simulators is rapidly becoming standard in many
industrial sectors. However, the available systems are either focusing on
gaming context, featuring limited capabilities or they support only content
creation of virtual environments without any rapid prototyping and
modification. In this project, we propose a code-free, visual scripting
platform to replicate gamified training scenarios through rapid prototyping and
VR software design patterns. We implemented and compared two authoring tools:
a) visual scripting and b) VR editor for the rapid reconstruction of VR
training scenarios. Our visual scripting module is capable to generate training
applications utilizing a node-based scripting system whereas the VR editor
gives user/developer the ability to customize and populate new VR training
scenarios directly from the virtual environment. We also introduce action
prototypes, a new software design pattern suitable to replicate behavioral
tasks for VR experiences. In addition, we present the training scenegraph
architecture as the main model to represent training scenarios on a modular,
dynamic and highly adaptive acyclic graph based on a structured educational
curriculum. Finally, a user-based evaluation of the proposed solution indicated
that users - regardless of their programming expertise - can effectively use
the tools to create and modify training scenarios in VR.
"
1686,CvxNet: Learnable Convex Decomposition,"  Any solid object can be decomposed into a collection of convex polytopes (in
short, convexes). When a small number of convexes are used, such a
decomposition can be thought of as a piece-wise approximation of the geometry.
This decomposition is fundamental in computer graphics, where it provides one
of the most common ways to approximate geometry, for example, in real-time
physics simulation. A convex object also has the property of being
simultaneously an explicit and implicit representation: one can interpret it
explicitly as a mesh derived by computing the vertices of a convex hull, or
implicitly as the collection of half-space constraints or support functions.
Their implicit representation makes them particularly well suited for neural
network training, as they abstract away from the topology of the geometry they
need to represent. However, at testing time, convexes can also generate
explicit representations -- polygonal meshes -- which can then be used in any
downstream application. We introduce a network architecture to represent a low
dimensional family of convexes. This family is automatically derived via an
auto-encoding process. We investigate the applications of this architecture
including automatic convex decomposition, image to 3D reconstruction, and
part-based shape retrieval.
"
1687,"A High-Fidelity Open Embodied Avatar with Lip Syncing and Expression
  Capabilities","  Embodied avatars as virtual agents have many applications and provide
benefits over disembodied agents, allowing non-verbal social and interactional
cues to be leveraged, in a similar manner to how humans interact with each
other. We present an open embodied avatar built upon the Unreal Engine that can
be controlled via a simple python programming interface. The avatar has lip
syncing (phoneme control), head gesture and facial expression (using either
facial action units or cardinal emotion categories) capabilities. We release
code and models to illustrate how the avatar can be controlled like a puppet or
used to create a simple conversational agent using public application
programming interfaces (APIs). GITHUB link:
https://github.com/danmcduff/AvatarSim
"
1688,"Learning to Think Outside the Box: Wide-Baseline Light Field Depth
  Estimation with EPI-Shift","  We propose a method for depth estimation from light field data, based on a
fully convolutional neural network architecture. Our goal is to design a
pipeline which achieves highly accurate results for small- and wide-baseline
light fields. Since light field training data is scarce, all learning-based
approaches use a small receptive field and operate on small disparity ranges.
In order to work with wide-baseline light fields, we introduce the idea of
EPI-Shift: To virtually shift the light field stack which enables to retain a
small receptive field, independent of the disparity range. In this way, our
approach ""learns to think outside the box of the receptive field"". Our network
performs joint classification of integer disparities and regression of
disparity-offsets. A U-Net component provides excellent long-range smoothing.
EPI-Shift considerably outperforms the state-of-the-art learning-based
approaches and is on par with hand-crafted methods. We demonstrate this on a
publicly available, synthetic, small-baseline benchmark and on large-baseline
real-world recordings.
"
1689,An Experimental Comparison of Map-like Visualisations and Treemaps,"  Treemaps have been used in information visualisation for over two decades.
They make use of nested filled areas to represent information hierarchies such
as file systems, library catalogues, etc. Recent years have witnessed the
emergence of visualisations that resemble geographic maps. In this paper we
present a study that compares the performance of one such map-like
visualisation with the original two forms of the treemap, namely nested and
non-nested treemaps. Our study employed a mixed-method evaluation of accuracy,
speed and usability (such as the ease-of-use and helpfulness of understanding
the information). We found that accuracy was highest for the map-like
visualisations, followed by nested treemaps and lastly non-nested treemaps.
Task performance was fastest for nested treemaps, followed by non-nested
treemaps, and then map-like visualisations. For usability, nested treemaps was
considered slightly more helpful than map-like visualisations while non-nested
performed poorly. We conclude that the results regarding accuracy are promising
for the use of map-like visualisations in tasks involving the visualisation of
hierarchical information, while non-nested treemap are favoured in tasks
requiring speed.
"
1690,A True AR Authoring Tool for Interactive Virtual Museums,"  In this work, a new and innovative way of spatial computing that appeared
recently in the bibliography called True Augmented Reality (AR), is employed in
cultural heritage preservation. This innovation could be adapted by the Virtual
Museums of the future to enhance the quality of experience. It emphasises, the
fact that a visitor will not be able to tell, at a first glance, if the
artefact that he/she is looking at is real or not and it is expected to draw
the visitors' interest. True AR is not limited to artefacts but extends even to
buildings or life-sized character simulations of statues. It provides the best
visual quality possible so that the users will not be able to tell the real
objects from the augmented ones. Such applications can be beneficial for future
museums, as with True AR, 3D models of various exhibits, monuments, statues,
characters and buildings can be reconstructed and presented to the visitors in
a realistic and innovative way. We also propose our Virtual Reality Sample
application, a True AR playground featuring basic components and tools for
generating interactive Virtual Museum applications, alongside a 3D
reconstructed character (the priest of Asinou church) facilitating the
storyteller of the augmented experience.
"
1691,Serious Educational Reinforcement Game in Preschool,"  In Education, is constant the searching of techniques to strengthen and
extend the educational strategies in order to achieve that students get
knowledge received in classroom, training personal courses and workshops.
Serious games are part of that set of educational strategies to reinforce or
extend the knowledge using a set of rules and policies in an interactive and
amuse way. Nowadays, using technology, it is possible to add images and sounds
into serious games under a digital platform. In this paper, we present a
solution based on serious games to reinforce the mathematical knowledge in the
preschool education following the study plan of the Bolivarian Republic of
Venezuela. Thus, we offer a tool with expectation of improving skills and
knowledge of children on a specific area, also allowing follow the student
track getting information of the activities performed. This compilation is made
performing reports which will be available for teachers and facilitators.
Reports allow adjust orientation and organization of topics imparted in
classroom, and to know the general overview of a preschool educational course.
Test performed determine the computational performance of solution, also the
impact on children and teachers. The wide attention of children was verified,
accomplishing the educational tasks in an indirect way.
"
1692,"Manufacturability Oriented Model Correction and Build Direction
  Optimization for Additive Manufacturing","  We introduce a method to analyze and modify a shape to make it manufacturable
for a given additive manufacturing (AM) process. Different AM technologies,
process parameters or materials introduce geometric constraints on what is
manufacturable or not. Given an input 3D model and minimum printable feature
size dictated by the manufacturing process characteristics and parameters, our
algorithm generates a corrected geometry that is printable with the intended AM
process. A key issue in model correction for manufacturability is the
identification of critical features that are affected by the printing process.
To address this challenge, we propose a topology aware approach to construct
the allowable space for a print head to traverse during the 3D printing
process. Combined with our build orientation optimization algorithm, the amount
of modifications performed on the shape is kept at minimum while providing an
accurate approximation of the as-manufactured part. We demonstrate our method
on a variety of 3D models and validate it by 3D printing the results.
"
1693,Photorealistic Material Editing Through Direct Image Manipulation,"  Creating photorealistic materials for light transport algorithms requires
carefully fine-tuning a set of material properties to achieve a desired
artistic effect. This is typically a lengthy process that involves a trained
artist with specialized knowledge. In this work, we present a technique that
aims to empower novice and intermediate-level users to synthesize high-quality
photorealistic materials by only requiring basic image processing knowledge. In
the proposed workflow, the user starts with an input image and applies a few
intuitive transforms (e.g., colorization, image inpainting) within a 2D image
editor of their choice, and in the next step, our technique produces a
photorealistic result that approximates this target image. Our method combines
the advantages of a neural network-augmented optimizer and an encoder neural
network to produce high-quality output results within 30 seconds. We also
demonstrate that it is resilient against poorly-edited target images and
propose a simple extension to predict image sequences with a strict time budget
of 1-2 seconds per image.
"
1694,"Realtime Simulation of Thin-Shell Deformable Materials using CNN-Based
  Mesh Embedding","  We address the problem of accelerating thin-shell deformable object
simulations by dimension reduction. We present a new algorithm to embed a
high-dimensional configuration space of deformable objects in a low-dimensional
feature space, where the configurations of objects and feature points have
approximate one-to-one mapping. Our key technique is a graph-based
convolutional neural network (CNN) defined on meshes with arbitrary topologies
and a new mesh embedding approach based on physics-inspired loss term. We have
applied our approach to accelerate high-resolution thin shell simulations
corresponding to cloth-like materials, where the configuration space has tens
of thousands of degrees of freedom. We show that our physics-inspired embedding
approach leads to higher accuracy compared with prior mesh embedding methods.
Finally, we show that the temporal evolution of the mesh in the feature space
can also be learned using a recurrent neural network (RNN) leading to fully
learnable physics simulators. After training our learned simulator runs
$500-10000\times$ faster and the accuracy is high enough for robot manipulation
tasks.
"
1695,Color continuity along the journey from ideas to objects,"  Human endeavor has involved making choices about color and looking for ways
to color objects since the dawn of civilization. While it has been the
exclusive domain of artists and craftspeople for millennia, the last century
has seen the introduction of a scientific basis to color communication. The
ultimate goal of this development is for color communication to happen
seamlessly and in a transparent way. There are however two categories of
challenges here: first, understanding and quantifying color needs and
expectation and second, developing control mechanisms that deliver the desired
color. In this paper a review will be presented of the color needs in
end-to-end color journeys, from initial concept to final colored object and an
overview of recent developments in color printing will follow. Topics like
imaging pipelines (including the recently-introduced HP Pixel Control), the
ease of use of color workflows (including HP Smart Color Tools), the handling
of brand or corporate identity colors (via HP Professional PANTONE Emulation)
and the measurement of color difference under specific viewing arrangements
(i.e., the dENS metric for viewing samples without separation) will be
addressed. Finally, a series of challenges for the future will be set out, so
that their solution can be approached by both academic and industrial
communities.
"
1696,Voting for Distortion Points in Geometric Processing,"  Low isometric distortion is often required for mesh parameterizations. A
configuration of some vertices, where the distortion is concentrated, provides
a way to mitigate isometric distortion, but determining the number and
placement of these vertices is non-trivial. We call these vertices distortion
points. We present a novel and automatic method to detect distortion points
using a voting strategy. Our method integrates two components: candidate
generation and candidate voting. Given a closed triangular mesh, we generate
candidate distortion points by executing a three-step procedure repeatedly: (1)
randomly cut an input to a disk topology; (2) compute a low conformal
distortion parameterization; and (3) detect the distortion points. Finally, we
count the candidate points and generate the final distortion points by voting.
We demonstrate that our algorithm succeeds when employed on various closed
meshes with a genus of zero or higher. The distortion points generated by our
method are utilized in three applications, including planar parameterization,
semi-automatic landmark correspondence, and isotropic remeshing. Compared to
other state-of-the-art methods, our method demonstrates stronger practical
robustness in distortion point detection.
"
1697,Shape Analysis via Functional Map Construction and Bases Pursuit,"  We propose a method to simultaneously compute scalar basis functions with an
associated functional map for a given pair of triangle meshes. Unlike previous
techniques that put emphasis on smoothness with respect to the
Laplace--Beltrami operator and thus favor low-frequency eigenfunctions, we aim
for a spectrum that allows for better feature matching. This change of
perspective introduces many degrees of freedom into the problem which we
exploit to improve the accuracy of our computed correspondences. To effectively
search in this high dimensional space of solutions, we incorporate into our
minimization state-of-the-art regularizers. We solve the resulting highly
non-linear and non-convex problem using an iterative scheme via the Alternating
Direction Method of Multipliers. At each step, our optimization involves simple
to solve linear or Sylvester-type equations. In practice, our method performs
well in terms of convergence, and we additionally show that it is similar to a
provably convergent problem. We show the advantages of our approach by
extensively testing it on multiple datasets in a few applications including
shape matching, consistent quadrangulation and scalar function transfer.
"
1698,"DSRGAN: Explicitly Learning Disentangled Representation of Underlying
  Structure and Rendering for Image Generation without Tuple Supervision","  We focus on explicitly learning disentangled representation for natural image
generation, where the underlying spatial structure and the rendering on the
structure can be independently controlled respectively, yet using no tuple
supervision. The setting is significant since tuple supervision is costly and
sometimes even unavailable. However, the task is highly unconstrained and thus
ill-posed. To address this problem, we propose to introduce an auxiliary domain
which shares a common underlying-structure space with the target domain, and we
make a partially shared latent space assumption. The key idea is to encourage
the partially shared latent variable to represent the similar underlying
spatial structures in both domains, while the two domain-specific latent
variables will be unavoidably arranged to present renderings of two domains
respectively. This is achieved by designing two parallel generative networks
with a common Progressive Rendering Architecture (PRA), which constrains both
generative networks' behaviors to model shared underlying structure and to
model spatially dependent relation between rendering and underlying structure.
Thus, we propose DSRGAN (GANs for Disentangling Underlying Structure and
Rendering) to instantiate our method. We also propose a quantitative criterion
(the Normalized Disentanglability) to quantify disentanglability. Comparison to
the state-of-the-art methods shows that DSRGAN can significantly outperform
them in disentanglability.
"
1699,"Vital Spreaders Identification in Complex Networks with Multi-Local
  Dimension","  The important nodes identification has been an interesting problem in this
issue. Several centrality measures have been proposed to solve this problem,
but most of previous methods have their own limitations. To address this
problem more effectively, multi-local dimension (MLD) which is based on the
fractal property is proposed to identify the vital spreaders in this paper.
This proposed method considers the information contained in the box and $q$
plays a weighting coefficient for this partition information. MLD would have
different expressions with different value of $q$, and it would degenerate to
local information dimension and variant of local dimension when $q = 1$ when $q
= 0$ respectively, both of which have been effective identification method for
influential nodes. Thus, MLD would be a more general method which can
degenerate to some exiting centrality measures. In addition, different with
classical methods, the node with low MLD would be more important in the
network. Some comparison methods and real-world complex networks are applied in
this paper to show the effectiveness and reasonableness of this proposed
method. The experiment results show the superiority of this proposed method.
"
1700,"Expressive Inverse Kinematics Solving in Real-time for Virtual and
  Robotic Interactive Characters","  With new advancements in interaction techniques, character animation also
requires new methods, to support fields such as robotics, and VR/AR.
Interactive characters in such fields are becoming driven by AI which opens up
the possibility of non-linear and open-ended narratives that may even include
interaction with the real, physical world. This paper presents and describes
ERIK, an expressive inverse kinematics technique aimed at such applications.
Our technique allows an arbitrary kinematic chain, such as an arm, snake, or
robotic manipulator, to exhibit an expressive posture while aiming its
end-point towards a given target orientation. The technique runs in
interactive-time and does not require any pre-processing step such as e.g.
training in machine learning techniques, in order to support new embodiments or
new postures. That allows it to be integrated in an artist-friendly workflow,
bringing artists closer to the development of such AI-driven expressive
characters, by allowing them to use their typical animation tools of choice,
and to properly pre-visualize the animation during design-time, even on a real
robot. The full algorithmic specification is presented and described so that it
can be implemented and used throughout the communities of the various fields we
address. We demonstrate ERIK on different virtual kinematic structures, and
also on a low-fidelity robot that was crafted using wood and hobby-grade
servos, to show how well the technique performs even on a low-grade robot. Our
evaluation shows how well the technique performs, i.e., how well the character
is able to point at the target orientation, while minimally disrupting its
target expressive posture, and respecting its mechanical rotation limits.
"
1701,pylustrator: Code generation for reproducible figures for publication,"  One major challenge in science is to make all results potentially
reproducible. Thus, along with the raw data, every step from basic processing
of the data, evaluation, to the generation of the figures, has to be documented
as clearly as possible. While there are many programming libraries that cover
the basic processing and plotting steps (e.g. Matplotlib in Python), no library
yet addresses the reproducible composing of single plots into meaningful
figures for publication. Thus, up to now it is still state-of-the-art to
generate publishable figures using image-processing or vector-drawing software
leading to unwanted alterations of the presented data in the worst case and to
figure quality reduction in the best case. Pylustrator a open source library
based on the Matplotlib aims to fill this gap and provides a tool to easily
generate the code necessary to compose publication figures from single plots.
It provides a graphical user interface where the user can interactively compose
the figures. All changes are tracked and converted to code that is
automatically integrated into the calling script file. Thus, this software
provides the missing link from raw data to the complete plot published in
scientific journals and thus contributes to the transparency of the complete
evaluation procedure.
"
1702,DiffTaichi: Differentiable Programming for Physical Simulation,"  We present DiffTaichi, a new differentiable programming language tailored for
building high-performance differentiable physical simulators. Based on an
imperative programming language, DiffTaichi generates gradients of simulation
steps using source code transformations that preserve arithmetic intensity and
parallelism. A light-weight tape is used to record the whole simulation program
structure and replay the gradient kernels in a reversed order, for end-to-end
backpropagation. We demonstrate the performance and productivity of our
language in gradient-based learning and optimization tasks on 10 different
physical simulators. For example, a differentiable elastic object simulator
written in our language is 4.2x shorter than the hand-engineered CUDA version
yet runs as fast, and is 188x faster than the TensorFlow implementation. Using
our differentiable programs, neural network controllers are typically optimized
within only tens of iterations.
"
1703,"Hash-Based Ray Path Prediction: Skipping BVH Traversal Computation by
  Exploiting Ray Locality","  State-of-the-art ray tracing techniques operate on hierarchical acceleration
structures such as BVH trees which wrap objects in a scene into bounding
volumes of decreasing sizes. Acceleration structures reduce the amount of
ray-scene intersections that a ray has to perform to find the intersecting
object. However, we observe a large amount of redundancy when rays are
traversing these acceleration structures. While modern acceleration structures
explore the spatial organization of the scene, they neglect similarities
between rays that traverse the structures and thereby cause redundant
traversals. This paper provides a limit study of a new promising technique,
Hash-Based Ray Path Prediction (HRPP), which exploits the similarity between
rays to predict leaf nodes to avoid redundant acceleration structure
traversals. Our data shows that acceleration structure traversal consumes a
significant proportion of the ray tracing rendering time regardless of the
platform or the target image quality. Our study quantifies unused ray locality
and evaluates the theoretical potential for improved ray traversal performance
for both coherent and seemingly incoherent rays. We show that HRPP is able to
skip, on average, 40% of all hit-all traversal computations.
"
1704,"iVRNote: Design, Creation and Evaluation of an Interactive Note-Taking
  Interface for Study and Reflection in VR Learning Environments","  In this contribution, we design, implement and evaluate the pedagogical
benefits of a novel interactive note taking interface (iVRNote) in VR for the
purpose of learning and reflection lectures. In future VR learning
environments, students would have challenges in taking notes when they wear a
head mounted display (HMD). To solve this problem, we installed a digital
tablet on the desk and provided several tools in VR to facilitate the learning
experience. Specifically, we track the stylus position and orientation in the
physical world and then render a virtual stylus in VR. In other words, when
students see a virtual stylus somewhere on the desk, they can reach out with
their hand for the physical stylus. The information provided will also enable
them to know where they will draw or write before the stylus touches the
tablet. Since the presented iVRNote featuring our note taking system is a
digital environment, we also enable students save efforts in taking extensive
notes by providing several functions, such as post-editing and picture taking,
so that they can pay more attention to lectures in VR. We also record the time
of each stroke on the note to help students review a lecture. They can select a
part of their note to revisit the corresponding segment in a virtual online
lecture. Figures and the accompanying video demonstrate the feasibility of the
presented iVRNote system. To evaluate the system, we conducted a user study
with 20 participants to assess the preference and pedagogical benefits of the
iVRNote interface.
"
1705,"Secondary Inputs for Measuring User Engagement in Immersive VR Education
  Environments","  This paper presents an experiment to assess the feasibility of using
secondary input data as a method of determining user engagement in immersive
virtual reality (VR). The work investigates whether secondary data (biosignals)
acquired from users are useful as a method of detecting levels of
concentration, stress, relaxation etc. in immersive environments, and if they
could be used to create an affective feedback loop in immersive VR
environments, including educational contexts. A VR Experience was developed in
the Unity game engine, with three different levels, each designed to expose the
user in one of three different states (relaxation, concentration, stress).
While in the VR Experience users physiological responses were measured using
ECG and EEG sensors. After the experience users completed questionnaires to
establish their perceived state during the levels, and to established the
usability of the system. Next a comparison between the reported levels of
emotion and the measured signals is presented, which show a strong
correspondence between the two measures indicating that biosignals are a useful
indicator of emotional state while in VR. Finally we make some recommendations
on the practicalities of using biosensors, and design considerations for their
incorporation in to a VR system, with particular focus on their integration in
to task-based training and educational virtual environments.
"
1706,"Sparse Surface Constraints for Combining Physics-based Elasticity
  Simulation and Correspondence-Free Object Reconstruction","  We address the problem to infer physical material parameters and boundary
conditions from the observed motion of a homogeneous deformable object via the
solution of an inverse problem. Parameters are estimated from potentially
unreliable real-world data sources such as sparse observations without
correspondences. We introduce a novel Lagrangian-Eulerian optimization
formulation, including a cost function that penalizes differences to
observations during an optimization run. This formulation matches
correspondence-free, sparse observations from a single-view depth sequence with
a finite element simulation of deformable bodies. In conjunction with an
efficient hexahedral discretization and a stable, implicit formulation of
collisions, our method can be used in demanding situation to recover a variety
of material parameters, ranging from Young's modulus and Poisson ratio to
gravity and stiffness damping, and even external boundaries. In a number of
tests using synthetic datasets and real-world measurements, we analyse the
robustness of our approach and the convergence behavior of the numerical
optimization scheme.
"
1707,Neural Turtle Graphics for Modeling City Road Layouts,"  We propose Neural Turtle Graphics (NTG), a novel generative model for spatial
graphs, and demonstrate its applications in modeling city road layouts.
Specifically, we represent the road layout using a graph where nodes in the
graph represent control points and edges in the graph represent road segments.
NTG is a sequential generative model parameterized by a neural network. It
iteratively generates a new node and an edge connecting to an existing node
conditioned on the current graph. We train NTG on Open Street Map data and show
that it outperforms existing approaches using a set of diverse performance
metrics. Moreover, our method allows users to control styles of generated road
layouts mimicking existing cities as well as to sketch parts of the city road
layout to be synthesized. In addition to synthesis, the proposed NTG finds uses
in an analytical task of aerial road parsing. Experimental results show that it
achieves state-of-the-art performance on the SpaceNet dataset.
"
1708,Neural Puppet: Generative Layered Cartoon Characters,"  We propose a learning based method for generating new animations of a cartoon
character given a few example images. Our method is designed to learn from a
traditionally animated sequence, where each frame is drawn by an artist, and
thus the input images lack any common structure, correspondences, or labels. We
express pose changes as a deformation of a layered 2.5D template mesh, and
devise a novel architecture that learns to predict mesh deformations matching
the template to a target image. This enables us to extract a common
low-dimensional structure from a diverse set of character poses. We combine
recent advances in differentiable rendering as well as mesh-aware models to
successfully align common template even if only a few character images are
available during training. In addition to coarse poses, character appearance
also varies due to shading, out-of-plane motions, and artistic effects. We
capture these subtle changes by applying an image translation network to refine
the mesh rendering, providing an end-to-end model to generate new animations of
a character with high visual quality. We demonstrate that our generative model
can be used to synthesize in-between frames and to create data-driven
deformation. Our template fitting procedure outperforms state-of-the-art
generic techniques for detecting image correspondences.
"
1709,Deep Radiance Caching: Convolutional Autoencoders Deeper in Ray Tracing,"  Rendering realistic images with global illumination is a computationally
demanding task and often requires dedicated hardware for feasible runtime.
Recent research uses Deep Neural Networks to predict indirect lighting on image
level, but such methods are commonly limited to diffuse materials and require
training on each scene.We present Deep Radiance Caching (DRC), an efficient
variant of Radiance Caching utilizing Convolutional Autoencoders for rendering
global illumination. DRC employs a denoising neural network with Radiance
Caching to support a wide range of material types, without the requirement of
offline pre-computation or training for each scene.This offers high performance
CPU rendering for maximum accessibility. Our method has been evaluated on
interior scenes, and is able to produce high-quality images within 180 seconds
on a single CPU.
"
1710,Cubic Stylization,"  We present a 3D stylization algorithm that can turn an input shape into the
style of a cube while maintaining the content of the original shape. The key
insight is that cubic style sculptures can be captured by the
as-rigid-as-possible energy with an l1-regularization on rotated surface
normals. Minimizing this energy naturally leads to a detail-preserving, cubic
geometry. Our optimization can be solved efficiently without any mesh surgery.
Our method serves as a non-realistic modeling tool where one can incorporate
many artistic controls to create stylized geometries.
"
1711,Visual Abstraction,"  In this article we revisit the concept of abstraction as it is used in
visualization and put it on a solid formal footing. While the term
\emph{abstraction} is utilized in many scientific disciplines, arts, as well as
everyday life, visualization inherits the notion of data abstraction or class
abstraction from computer science, topological abstraction from mathematics,
and visual abstraction from arts. All these notions have a lot in common, yet
there is a major discrepancy in the terminology and basic understanding about
visual abstraction in the context of visualization. We thus root the notion of
abstraction in the philosophy of science, clarify the basic terminology, and
provide crisp definitions of visual abstraction as a process. Furthermore, we
clarify how it relates to similar terms often used interchangeably in the field
of visualization. Visual abstraction is characterized by a conceptual space
where this process exists, by the purpose it should serve, and by the
perceptual and cognitive qualities of the beholder. These characteristics can
be used to control the process of visual abstraction to produce effective and
informative visual representations.
"
1712,"Triangle Mesh Slicing and Contour Construction for Three-Dimensional
  Printing on a Rotating Mandrel","  Three-dimensional (3D) printing is a powerful development tool both in
industry, as well as in biomedical research. Additive-lathe 3D printing is an
emerging sub-class of 3D printing whereby material is layered outward from the
surface of a rotating cylindrical mandrel. While established additive
manufacturing technologies have developed robust toolpath generation software,
additive-lathe publications to date have been relegated to the most basic of
proof-of-concept structures. This paper details the theory and implementation
of a method for slicing a triangulated surface with a series of concentric,
open, right circular cylinders that represents a crucial step in creating
toolpaths to print complex models with additive-lathe technology. Valid edge
cases are detailed which must be addressed when implementing a cylindrical
slicer to produce non-intersecting closed contours; two classes of resultant
closed contour are described. Methodologies for generating infill patterns,
support structures and other considerations for toolpath construction are
required prior to full implementation of a machine capable of printing complex
geometry from a digital model onto a rotating cylindrical surface. This work
represents the first thorough examination of the mathematics and algorithmic
implementation of triangle mesh slicing with concentric cylinders and offers
insights for future works in toolpath generation for the additive-lathe type 3D
printer.
"
1713,Dialog on a canvas with a machine,"  We propose a new form of human-machine interaction. It is a pictorial game
consisting of interactive rounds of creation between artists and a machine.
They repetitively paint one after the other. At its rounds, the computer
partially completes the drawing using machine learning algorithms, and projects
its additions directly on the canvas, which the artists are free to insert or
modify. Alongside fostering creativity, the process is designed to question the
growing interaction between humans and machines.
"
1714,Visual Indeterminacy in GAN Art,"  This paper explores visual indeterminacy as a description for artwork created
with Generative Adversarial Networks (GANs). Visual indeterminacy describes
images which appear to depict real scenes, but, on closer examination, defy
coherent spatial interpretation. GAN models seem to be predisposed to producing
indeterminate images, and indeterminacy is a key feature of much modern
representational art, as well as most GAN art. It is hypothesized that
indeterminacy is a consequence of a powerful-but-imperfect image synthesis
model that must combine general classes of objects, scenes, and textures.
"
1715,"Interactive Light Field Tilt-Shift Refocus with Generalized
  Shift-and-Sum","  Since their introduction more than two decades ago, light fields have gained
considerable interest in graphics and vision communities due to their ability
to provide the user with interactive visual content. One of the earliest and
most common light field operations is digital refocus, enabling the user to
choose the focus and depth-of-field for the image after capture. A common
interactive method for such an operation utilizes disparity estimations,
readily available from the light field, to allow the user to point-and-click on
the image to chose the location of the refocus plane.
  In this paper, we address the interactivity of a lesser-known light field
operation: refocus to a non-frontoparallel plane, simulating the result of
traditional tilt-shift photography. For this purpose we introduce a generalized
shift-and-sum framework. Further, we show that the inclusion of depth
information allows for intuitive interactive methods for placement of the
refocus plane. In addition to refocusing, light fields also enable the user to
interact with the viewpoint, which can be easily included in the proposed
generalized shift-and-sum framework.
"
1716,"Point cloud ridge-valley feature enhancement based on position and
  normal guidance","  Ridge-valley features are important elements of point clouds, as they contain
rich surface information. To recognize these features from point clouds, this
paper introduces an extreme point distance (EPD) criterion with scale
independence. Compared with traditional methods, the EPD greatly reduces the
number of potential feature points and improves the robustness of multiscale
feature point recognition. On this basis, a feature enhancement algorithm based
on user priori guidance is proposed that adjusts the coordinates of the feature
area by solving an objective equation containing the expected position and
normal constraints. Since the expected normal can be expressed as a function of
neighborhood point coordinates, the above objective equation can be converted
into linear sparse equations with enhanced feature positions as variables, and
thus, the closed solution can be obtained. In addition, a parameterization
method for scattered point clouds based on feature line guidance is proposed,
which reduces the number of unknowns by 2/3 and eliminates lateral sliding in
the direction perpendicular to feature lines. Finally, the application of the
algorithm in multiscale ridge-valley feature recognition, freeform surface
feature enhancement and computer-aided design (CAD) workpiece sharp feature
restoration verifies its effectiveness.
"
1717,Artistic Glyph Image Synthesis via One-Stage Few-Shot Learning,"  Automatic generation of artistic glyph images is a challenging task that
attracts many research interests. Previous methods either are specifically
designed for shape synthesis or focus on texture transfer. In this paper, we
propose a novel model, AGIS-Net, to transfer both shape and texture styles in
one-stage with only a few stylized samples. To achieve this goal, we first
disentangle the representations for content and style by using two encoders,
ensuring the multi-content and multi-style generation. Then we utilize two
collaboratively working decoders to generate the glyph shape image and its
texture image simultaneously. In addition, we introduce a local texture
refinement loss to further improve the quality of the synthesized textures. In
this manner, our one-stage model is much more efficient and effective than
other multi-stage stacked methods. We also propose a large-scale dataset with
Chinese glyph images in various shape and texture styles, rendered from 35
professional-designed artistic fonts with 7,326 characters and 2,460 synthetic
artistic fonts with 639 characters, to validate the effectiveness and
extendability of our method. Extensive experiments on both English and Chinese
artistic glyph image datasets demonstrate the superiority of our model in
generating high-quality stylized glyph images against other state-of-the-art
methods.
"
1718,"Single Image BRDF Parameter Estimation with a Conditional Adversarial
  Network","  Creating plausible surfaces is an essential component in achieving a high
degree of realism in rendering. To relieve artists, who create these surfaces
in a time-consuming, manual process, automated retrieval of the
spatially-varying Bidirectional Reflectance Distribution Function (SVBRDF) from
a single mobile phone image is desirable. By leveraging a deep neural network,
this casual capturing method can be achieved. The trained network can estimate
per pixel normal, base color, metallic and roughness parameters from the Disney
BRDF. The input image is taken with a mobile phone lit by the camera flash. The
network is trained to compensate for environment lighting and thus learned to
reduce artifacts introduced by other light sources. These losses contain a
multi-scale discriminator with an additional perceptual loss, a rendering loss
using a differentiable renderer, and a parameter loss. Besides the local
precision, this loss formulation generates material texture maps which are
globally more consistent. The network is set up as a generator network trained
in an adversarial fashion to ensure that only plausible maps are produced. The
estimated parameters not only reproduce the material faithfully in rendering
but capture the style of hand-authored materials due to the more global loss
terms compared to previous works without requiring additional post-processing.
Both the resolution and the quality is improved.
"
1719,Face Reflectance and Geometry Modeling via Differentiable Ray Tracing,"  We present a novel strategy to automatically reconstruct 3D faces from
monocular images with explicitly disentangled facial geometry (pose, identity
and expression), reflectance (diffuse and specular albedo), and self-shadows.
The scene lights are modeled as a virtual light stage with pre-oriented area
lights used in conjunction with differentiable Monte-Carlo ray tracing to
optimize the scene and face parameters. With correctly disentangled
self-shadows and specular reflection parameters, we can not only obtain robust
facial geometry reconstruction, but also gain explicit control over these
parameters, with several practical applications. We can change facial
expressions with accurate resultant self-shadows or relight the scene and
obtain accurate specular reflection and several other parameter combinations.
"
1720,"Adversarial Colorization Of Icons Based On Structure And Color
  Conditions","  We present a system to help designers create icons that are widely used in
banners, signboards, billboards, homepages, and mobile apps. Designers are
tasked with drawing contours, whereas our system colorizes contours in
different styles. This goal is achieved by training a dual conditional
generative adversarial network (GAN) on our collected icon dataset. One
condition requires the generated image and the drawn contour to possess a
similar contour, while the other anticipates the image and the referenced icon
to be similar in color style. Accordingly, the generator takes a contour image
and a man-made icon image to colorize the contour, and then the discriminators
determine whether the result fulfills the two conditions. The trained network
is able to colorize icons demanded by designers and greatly reduces their
workload. For the evaluation, we compared our dual conditional GAN to several
state-of-the-art techniques. Experiment results demonstrate that our network is
over the previous networks. Finally, we will provide the source code, icon
dataset, and trained network for public use.
"
1721,"Optimization and Manipulation of Contextual Mutual Spaces for Multi-User
  Virtual and Augmented Reality Interaction","  Spatial computing experiences are physically constrained by the geometry and
semantics of the local user environment. This limitation is elevated in remote
multi-user interaction scenarios, where finding a common virtual ground
physically accessible for all participants becomes challenging. Locating a
common accessible virtual ground is difficult for the users themselves,
particularly if they are not aware of the spatial properties of other
participants. In this paper, we introduce a framework to generate an optimal
mutual virtual space for a multi-user interaction setting where remote users'
room spaces can have different layout and sizes. The framework further
recommends movement of surrounding furniture objects that expand the size of
the mutual space with minimal physical effort. Finally, we demonstrate the
performance of our solution on real-world datasets and also a real HoloLens
application. Results show the proposed algorithm can effectively discover
optimal shareable space for multi-user virtual interaction and hence facilitate
remote spatial computing communication in various collaborative workflows.
"
1722,"Addressing Troubles with Double Bubbles: Convergence and Stability at
  Multi-Bubble Junctions","  In this report we discuss and propose a correction to a convergence and
stability issue occurring in the work of Da et al.[2015], in which they
proposed a numerical model to simulate soap bubbles.
"
1723,PRS-Net: Planar Reflective Symmetry Detection Net for 3D Models,"  In geometry processing, symmetry is a universal type of high-level structural
information of 3D models and benefits many geometry processing tasks including
shape segmentation, alignment, matching, and completion. Thus it is an
important problem to analyze various symmetry forms of 3D shapes. Planar
reflective symmetry is the most fundamental one. Traditional methods based on
spatial sampling can be time-consuming and may not be able to identify all the
symmetry planes. In this paper, we present a novel learning framework to
automatically discover global planar reflective symmetry of a 3D shape. Our
framework trains an unsupervised 3D convolutional neural network to extract
global model features and then outputs possible global symmetry parameters,
where input shapes are represented using voxels. We introduce a dedicated
symmetry distance loss along with a regularization loss to avoid generating
duplicated symmetry planes. Our network can also identify generalized cylinders
by predicting their rotation axes. We further provide a method to remove
invalid and duplicated planes and axes. We demonstrate that our method is able
to produce reliable and accurate results. Our neural network based method is
hundreds of times faster than the state-of-the-art methods, which are based on
sampling. Our method is also robust even with noisy or incomplete input
surfaces.
"
1724,"Analyzing symmetry and symmetry breaking by computational aesthetic
  measures","  We study creating and analyzing symmetry and broken symmetry in digital art.
Our focus is not so much on computer-generating artistic images, but rather on
analyzing concepts and templates for incorporating symmetry and symmetry
breaking into the creation process. Taking as a starting point patterns
generated algorithmically by emulating the collective feeding behavior of
sand-bubbler crabs, all four types of two-dimensional symmetry are used as
isometric maps. Apart from a geometric interpretation of symmetry, we also
consider color as an object of symmetric transformations. Color symmetry is
realized as a color permutation consistent with the isometries. Moreover, we
analyze the abilities of computational aesthetic measures to serve as a metric
that reflects design parameters, i.e. the type of symmetry and the degree of
symmetry breaking.
"
1725,"Animating Landscape: Self-Supervised Learning of Decoupled Motion and
  Appearance for Single-Image Video Synthesis","  Automatic generation of a high-quality video from a single image remains a
challenging task despite the recent advances in deep generative models. This
paper proposes a method that can create a high-resolution, long-term animation
using convolutional neural networks (CNNs) from a single landscape image where
we mainly focus on skies and waters. Our key observation is that the motion
(e.g., moving clouds) and appearance (e.g., time-varying colors in the sky) in
natural scenes have different time scales. We thus learn them separately and
predict them with decoupled control while handling future uncertainty in both
predictions by introducing latent codes. Unlike previous methods that infer
output frames directly, our CNNs predict spatially-smooth intermediate data,
i.e., for motion, flow fields for warping, and for appearance, color transfer
maps, via self-supervised learning, i.e., without explicitly-provided ground
truth. These intermediate data are applied not to each previous output frame,
but to the input image only once for each output frame. This design is crucial
to alleviate error accumulation in long-term predictions, which is the
essential problem in previous recurrent approaches. The output frames can be
looped like cinemagraph, and also be controlled directly by specifying latent
codes or indirectly via visual annotations. We demonstrate the effectiveness of
our method through comparisons with the state-of-the-arts on video prediction
as well as appearance manipulation.
"
1726,Statistical Parameter Selection for Clustering Persistence Diagrams,"  In urgent decision making applications, ensemble simulations are an important
way to determine different outcome scenarios based on currently available data.
In this paper, we will analyze the output of ensemble simulations by
considering so-called persistence diagrams, which are reduced representations
of the original data, motivated by the extraction of topological features.
Based on a recently published progressive algorithm for the clustering of
persistence diagrams, we determine the optimal number of clusters, and
therefore the number of significantly different outcome scenarios, by the
minimization of established statistical score functions. Furthermore, we
present a proof-of-concept prototype implementation of the statistical
selection of the number of clusters and provide the results of an experimental
study, where this implementation has been applied to real-world ensemble data
sets.
"
1727,Animation Synthesis Triggered by Vocal Mimics,"  We propose a method leveraging the naturally time-related expressivity of our
voice to control an animation composed of a set of short events. The user
records itself mimicking onomatopoeia sounds such as ""Tick"", ""Pop"", or ""Chhh""
which are associated with specific animation events. The recorded soundtrack is
automatically analyzed to extract every instant and types of sounds. We finally
synthesize an animation where each event type and timing correspond with the
soundtrack. In addition to being a natural way to control animation timing, we
demonstrate that multiple stories can be efficiently generated by recording
different voice sequences. Also, the use of more than one soundtrack allows us
to control different characters with overlapping actions.
"
1728,Illumination-Based Data Augmentation for Robust Background Subtraction,"  A core challenge in background subtraction (BGS) is handling videos with
sudden illumination changes in consecutive frames. In this paper, we tackle the
problem from a data point-of-view using data augmentation. Our method performs
data augmentation that not only creates endless data on the fly, but also
features semantic transformations of illumination which enhance the
generalisation of the model. It successfully simulates flashes and shadows by
applying the Euclidean distance transform over a binary mask that is randomly
generated. Such data allows us to effectively train an illumination-invariant
deep learning model for BGS. Experimental results demonstrate the contribution
of the synthetics in the ability of the models to perform BGS even when
significant illumination changes take place. The source code of the project is
made publicly available at
https://github.com/dksakkos/illumination_augmentation.
"
1729,"Normal Estimation for 3D Point Clouds via Local Plane Constraint and
  Multi-scale Selection","  In this paper, we propose a normal estimation method for unstructured 3D
point clouds. In this method, a feature constraint mechanism called Local Plane
Features Constraint (LPFC) is used and then a multi-scale selection strategy is
introduced. The LPEC can be used in a single-scale point network architecture
for a more stable normal estimation of the unstructured 3D point clouds. In
particular, it can partly overcome the influence of noise on a large sampling
scale compared to the other methods which only use regression loss for normal
estimation. For more details, a subnetwork is built after point-wise features
extracted layers of the network and it gives more constraints to each point of
the local patch via a binary classifier in the end. Then we use multi-task
optimization to train the normal estimation and local plane classification
tasks simultaneously.Also, to integrate the advantages of multi-scale results,
a scale selection strategy is adopted, which is a data-driven approach for
selecting the optimal scale around each point and encourages subnetwork
specialization. Specifically, we employed a subnetwork called Scale Estimation
Network to extract scale weight information from multi-scale features. More
analysis is given about the relations between noise levels, local boundary, and
scales in the experiment. These relationships can be a better guide to choosing
particular scales for a particular model. Besides, the experimental result
shows that our network can distinguish the points on the fitting plane
accurately and this can be used to guide the normal estimation and our
multi-scale method can improve the results well. Compared to some
state-of-the-art surface normal estimators, our method is robust to noise and
can achieve competitive results.
"
1730,Real-Time Lip Sync for Live 2D Animation,"  The emergence of commercial tools for real-time performance-based 2D
animation has enabled 2D characters to appear on live broadcasts and streaming
platforms. A key requirement for live animation is fast and accurate lip sync
that allows characters to respond naturally to other actors or the audience
through the voice of a human performer. In this work, we present a deep
learning based interactive system that automatically generates live lip sync
for layered 2D characters using a Long Short Term Memory (LSTM) model. Our
system takes streaming audio as input and produces viseme sequences with less
than 200ms of latency (including processing time). Our contributions include
specific design decisions for our feature definition and LSTM configuration
that provide a small but useful amount of lookahead to produce accurate lip
sync. We also describe a data augmentation procedure that allows us to achieve
good results with a very small amount of hand-animated training data (13-20
minutes). Extensive human judgement experiments show that our results are
preferred over several competing methods, including those that only support
offline (non-live) processing. Video summary and supplementary results at
GitHub link: https://github.com/deepalianeja/CharacterLipSync2D
"
1731,Deck.gl: Large-scale Web-based Visual Analytics Made Easy,"  In this paper, we demonstrate how deck.gl, an open-source project born out of
data-heavy visual analytics applications, has grown into the robust
visualization framework it is today. We begin by explaining why we built
another data visualization framework in the first place. Then, we summarize our
design goals (distilled from our interactions with users) and discuss how they
guided the development of the framework's main features. We use two real-world
applications of deck.gl to showcase how it can be applied to simplify the
creation of data-heavy visualizations. We also discuss our lessons learned as
we continue to improve the framework for the larger visualization community.
"
1732,Top-Down Shape Abstraction Based on Greedy Pole Selection,"  Motivated by the fact that the medial axis transform is able to encode nearly
the complete shape, we propose to use as few medial balls as possible to
approximate the original enclosed volume by the boundary surface. We
progressively select new medial balls, in a top-down style, to enlarge the
region spanned by the existing medial balls. The key spirit of the selection
strategy is to encourage large medial balls while imposing given geometric
constraints. We further propose a speedup technique based on a provable
observation that the intersection of medial balls implies the adjacency of
power cells (in the sense of the power crust). We further elaborate the
selection rules in combination with two closely related applications. One
application is to develop an easy-to-use ball-stick modeling system that helps
non-professional users to quickly build a shape with only balls and wires, but
any penetration between two medial balls must be suppressed. The other
application is to generate porous structures with convex, compact (with a high
isoperimetric quotient) and shape-aware pores where two adjacent spherical
pores may have penetration as long as the mechanical rigidity can be well
preserved.
"
1733,Dynamic Upsampling of Smoke through Dictionary-based Learning,"  Simulating turbulent smoke flows is computationally intensive due to their
intrinsic multiscale behavior, thus requiring relatively high resolution grids
to fully capture their complexity. For iterative editing or simply faster
generation of smoke flows, dynamic upsampling of an input low-resolution
numerical simulation is an attractive, yet currently unattainable goal. In this
paper, we propose a novel dictionary-based learning approach to the dynamic
upsampling of smoke flows. For each frame of an input coarse animation, we seek
a sparse representation of small, local velocity patches of the flow based on
an over-complete dictionary, and use the resulting sparse coefficients to
generate a high-resolution smoke animation sequence. We propose a novel
dictionary-based neural network which learns both a fast evaluation of sparse
patch encoding and a dictionary of corresponding coarse and fine patches from a
sequence of example simulations computed with any numerical solver. Our
upsampling network then injects into coarse input sequences physics-driven fine
details, unlike most previous approaches that only employed fast procedural
models to add high frequency to the input. We present a variety of upsampling
results for smoke flows and offer comparisons to their corresponding
high-resolution simulations to demonstrate the effectiveness of our approach.
"
1734,"A Survey and Taxonomy of Adversarial Neural Networks for Text-to-Image
  Synthesis","  Text-to-image synthesis refers to computational methods which translate human
written textual descriptions, in the form of keywords or sentences, into images
with similar semantic meaning to the text. In earlier research, image synthesis
relied mainly on word to image correlation analysis combined with supervised
methods to find best alignment of the visual content matching to the text.
Recent progress in deep learning (DL) has brought a new set of unsupervised
deep learning methods, particularly deep generative models which are able to
generate realistic visual images using suitably trained neural network models.
In this paper, we review the most recent development in the text-to-image
synthesis research domain. Our survey first introduces image synthesis and its
challenges, and then reviews key concepts such as generative adversarial
networks (GANs) and deep convolutional encoder-decoder neural networks (DCNN).
After that, we propose a taxonomy to summarize GAN based text-to-image
synthesis into four major categories: Semantic Enhancement GANs, Resolution
Enhancement GANs, Diversity Enhancement GANS, and Motion Enhancement GANs. We
elaborate the main objective of each group, and further review typical GAN
architectures in each group. The taxonomy and the review outline the techniques
and the evolution of different approaches, and eventually provide a clear
roadmap to summarize the list of contemporaneous solutions that utilize GANs
and DCNNs to generate enthralling results in categories such as human faces,
birds, flowers, room interiors, object reconstruction from edge maps (games)
etc. The survey will conclude with a comparison of the proposed solutions,
challenges that remain unresolved, and future developments in the text-to-image
synthesis domain.
"
1735,"Gloss, Color and Topography Scanning for Reproducing a Painting's
  Appearance using 3D printing","  High fidelity reproductions of paintings provide new opportunities to museums
in preserving and providing access to cultural heritage. This paper presents an
integrated system which is able to capture and fabricate color, topography and
gloss of a painting, of which gloss capturing forms the most important
contribution. A 3D imaging system, using fringe-encoded stereo imaging, is
extended to capture spatially-varying gloss, utilizing specular reflectance
polarization. The gloss is measured by sampling the specular reflection around
Brewster's angle, where these reflections are effectively polarized, and can be
separated from the unpolarized, diffuse reflectance. Off-center gloss
measurements are calibrated relative to the center measurement. Off-specular
gloss measurements, following from local variation of the surface normal, are
masked based on the height map and corrected. Shadowed regions, caused by the
3D relief, are treated similarly. The area of a single capture is approximately
180x90mm at a resolution of 25x25micron. Aligned color, height, and gloss tiles
are stitched together, registering overlapping color areas. These maps are
inputs for a 3D printer. Two paintings were reproduced to verify the
effectiveness and efficiency of the proposed system. One painting was scanned
four times, consecutively rotated by 90 degrees, to evaluate the influence of
the scanning system geometric configuration on the gloss measurement.
Experimental results show that the method is sufficiently fast for practical
application. The results can well be used for the purpose of physical
reproduction and other applications needing first-order estimates of the
appearance. Our method to extend appearance scanning with gloss measurements is
a valuable addition in the quest for realistic reproductions, in terms of its
practical applicability and its perceptual added value, when added to color and
topography.
"
1736,"A Robust Blind 3-D Mesh Watermarking technique based on SCS quantization
  and mesh Saliency for Copyright Protection","  Due to the recent demand of 3-D meshes in a wide range of applications such
as video games, medical imaging, film special effect making, computer-aided
design (CAD), among others, the necessity of implementing 3-D mesh watermarking
schemes aiming to protect copyright has increased in the last decade. Nowadays,
the majority of robust 3-D watermarking approaches have mainly focused on the
robustness against attacks while the imperceptibility of these techniques is
still a serious challenge. In this context, a blind robust 3-D mesh
watermarking method based on mesh saliency and scalar Costa scheme (SCS) for
Copyright protection is proposed. The watermark is embedded by quantifying the
vertex norms of the 3-D mesh by SCS scheme using the vertex normal norms as
synchronizing primitives. The choice of these vertices is based on 3-D mesh
saliency to achieve watermark robustness while ensuring high imperceptibility.
The experimental results show that in comparison with the alternative methods,
the proposed work can achieve a high imperceptibility performance while
ensuring a good robustness against several common attacks including similarity
transformations, noise addition, quantization, smoothing, elements reordering,
etc.
"
1737,Handheld Mobile Photography in Very Low Light,"  Taking photographs in low light using a mobile phone is challenging and
rarely produces pleasing results. Aside from the physical limits imposed by
read noise and photon shot noise, these cameras are typically handheld, have
small apertures and sensors, use mass-produced analog electronics that cannot
easily be cooled, and are commonly used to photograph subjects that move, like
children and pets. In this paper we describe a system for capturing clean,
sharp, colorful photographs in light as low as 0.3~lux, where human vision
becomes monochromatic and indistinct. To permit handheld photography without
flash illumination, we capture, align, and combine multiple frames. Our system
employs ""motion metering"", which uses an estimate of motion magnitudes (whether
due to handshake or moving objects) to identify the number of frames and the
per-frame exposure times that together minimize both noise and motion blur in a
captured burst. We combine these frames using robust alignment and merging
techniques that are specialized for high-noise imagery. To ensure accurate
colors in such low light, we employ a learning-based auto white balancing
algorithm. To prevent the photographs from looking like they were shot in
daylight, we use tone mapping techniques inspired by illusionistic painting:
increasing contrast, crushing shadows to black, and surrounding the scene with
darkness. All of these processes are performed using the limited computational
resources of a mobile device. Our system can be used by novice photographers to
produce shareable pictures in a few seconds based on a single shutter press,
even in environments so dim that humans cannot see clearly.
"
1738,Seeing What a GAN Cannot Generate,"  Despite the success of Generative Adversarial Networks (GANs), mode collapse
remains a serious issue during GAN training. To date, little work has focused
on understanding and quantifying which modes have been dropped by a model. In
this work, we visualize mode collapse at both the distribution level and the
instance level. First, we deploy a semantic segmentation network to compare the
distribution of segmented objects in the generated images with the target
distribution in the training set. Differences in statistics reveal object
classes that are omitted by a GAN. Second, given the identified omitted object
classes, we visualize the GAN's omissions directly. In particular, we compare
specific differences between individual photos and their approximate inversions
by a GAN. To this end, we relax the problem of inversion and solve the
tractable problem of inverting a GAN layer instead of the entire generator.
Finally, we use this framework to analyze several recent GANs trained on
multiple datasets and identify their typical failure cases.
"
1739,ETNet: Error Transition Network for Arbitrary Style Transfer,"  Numerous valuable efforts have been devoted to achieving arbitrary style
transfer since the seminal work of Gatys et al. However, existing
state-of-the-art approaches often generate insufficiently stylized results
under challenging cases. We believe a fundamental reason is that these
approaches try to generate the stylized result in a single shot and hence fail
to fully satisfy the constraints on semantic structures in the content images
and style patterns in the style images. Inspired by the works on
error-correction, instead, we propose a self-correcting model to predict what
is wrong with the current stylization and refine it accordingly in an iterative
manner. For each refinement, we transit the error features across both the
spatial and scale domain and invert the processed features into a residual
image, with a network we call Error Transition Network (ETNet). The proposed
model improves over the state-of-the-art methods with better semantic
structures and more adaptive style pattern details. Various qualitative and
quantitative experiments show that the key concept of both progressive strategy
and error-correction leads to better results. Code and models are available at
https://github.com/zhijieW94/ETNet.
"
1740,"Conflict and Cooperation: AI Research and Development in terms of the
  Economy of Conventions","  Artificial Intelligence (AI) and its relation with societies is increasingly
becoming an interesting object of study from the perspective of sociology and
other disciplines. Theories such as the Economy of Conventions (EC) are usually
applied in the context of interpersonal relations but there is still a clear
lack of studies around how this and other theories can shed light on
interactions between human an autonomous systems. This work is focused into
studying a preliminary step that is a key enabler for the subsequent
interaction between machines and humans: how the processes of researching,
designing and developing AI related systems reflect different moral registers,
represented by conventions within the EC. Having a better understanding of
those conventions guiding the advances in AI is considered as the first and
required advance to understand the conventions afterwards reflected by those
autonomous systems in the interactions with societies. For this purpose, we
develop an iterative tool based on active learning to label a data set from the
field of AI and Machine Learning (ML) research and present preliminary results
of a supervised classifier trained on these conventions. To further demonstrate
the feasibility of the approach, the results are contrasted with a classifier
trained on software conventions.
"
1741,Few-shot Video-to-Video Synthesis,"  Video-to-video synthesis (vid2vid) aims at converting an input semantic
video, such as videos of human poses or segmentation masks, to an output
photorealistic video. While the state-of-the-art of vid2vid has advanced
significantly, existing approaches share two major limitations. First, they are
data-hungry. Numerous images of a target human subject or a scene are required
for training. Second, a learned model has limited generalization capability. A
pose-to-human vid2vid model can only synthesize poses of the single person in
the training set. It does not generalize to other humans that are not in the
training set. To address the limitations, we propose a few-shot vid2vid
framework, which learns to synthesize videos of previously unseen subjects or
scenes by leveraging few example images of the target at test time. Our model
achieves this few-shot generalization capability via a novel network weight
generation module utilizing an attention mechanism. We conduct extensive
experimental validations with comparisons to strong baselines using several
large-scale video datasets including human-dancing videos, talking-head videos,
and street-scene videos. The experimental results verify the effectiveness of
the proposed framework in addressing the two limitations of existing vid2vid
approaches.
"
1742,Dual Illumination Estimation for Robust Exposure Correction,"  Exposure correction is one of the fundamental tasks in image processing and
computational photography. While various methods have been proposed, they
either fail to produce visually pleasing results, or only work well for limited
types of image (e.g., underexposed images). In this paper, we present a novel
automatic exposure correction method, which is able to robustly produce
high-quality results for images of various exposure conditions (e.g.,
underexposed, overexposed, and partially under- and over-exposed). At the core
of our approach is the proposed dual illumination estimation, where we
separately cast the under- and over-exposure correction as trivial illumination
estimation of the input image and the inverted input image. By performing dual
illumination estimation, we obtain two intermediate exposure correction results
for the input image, with one fixes the underexposed regions and the other one
restores the overexposed regions. A multi-exposure image fusion technique is
then employed to adaptively blend the visually best exposed parts in the two
intermediate exposure correction images and the input image into a globally
well-exposed image. Experiments on a number of challenging images demonstrate
the effectiveness of the proposed approach and its superiority over the
state-of-the-art methods and popular automatic exposure correction tools.
"
1743,Neural View-Interpolation for Sparse Light Field Video,"  We suggest representing light field (LF) videos as ""one-off"" neural networks
(NN), i.e., a learned mapping from view-plus-time coordinates to
high-resolution color values, trained on sparse views. Initially, this sounds
like a bad idea for three main reasons: First, a NN LF will likely have less
quality than a same-sized pixel basis representation. Second, only few training
data, e.g., 9 exemplars per frame are available for sparse LF videos. Third,
there is no generalization across LFs, but across view and time instead.
Consequently, a network needs to be trained for each LF video. Surprisingly,
these problems can turn into substantial advantages: Other than the linear
pixel basis, a NN has to come up with a compact, non-linear i.e., more
intelligent, explanation of color, conditioned on the sparse view and time
coordinates. As observed for many NN however, this representation now is
interpolatable: if the image output for sparse view coordinates is plausible,
it is for all intermediate, continuous coordinates as well. Our specific
network architecture involves a differentiable occlusion-aware warping step,
which leads to a compact set of trainable parameters and consequently fast
learning and fast execution.
"
1744,LaplacianNet: Learning on 3D Meshes with Laplacian Encoding and Pooling,"  3D models are commonly used in computer vision and graphics. With the wider
availability of mesh data, an efficient and intrinsic deep learning approach to
processing 3D meshes is in great need. Unlike images, 3D meshes have irregular
connectivity, requiring careful design to capture relations in the data. To
utilize the topology information while staying robust under different
triangulation, we propose to encode mesh connectivity using Laplacian spectral
analysis, along with Mesh Pooling Blocks (MPBs) that can split the surface
domain into local pooling patches and aggregate global information among them.
We build a mesh hierarchy from fine to coarse using Laplacian spectral
clustering, which is flexible under isometric transformation. Inside the MPBs
there are pooling layers to collect local information and multi-layer
perceptrons to compute vertex features with increasing complexity. To obtain
the relationships among different clusters, we introduce a Correlation Net to
compute a correlation matrix, which can aggregate the features globally by
matrix multiplication with cluster features. Our network architecture is
flexible enough to be used on meshes with different numbers of vertices. We
conduct several experiments including shape segmentation and classification,
and our LaplacianNet outperforms state-of-the-art algorithms for these tasks on
ShapeNet and COSEG datasets.
"
1745,Learning-based Real-time Detection of Intrinsic Reflectional Symmetry,"  Reflectional symmetry is ubiquitous in nature. While extrinsic reflectional
symmetry can be easily parametrized and detected, intrinsic symmetry is much
harder due to the high solution space. Previous works usually solve this
problem by voting or sampling, which suffer from high computational cost and
randomness. In this paper, we propose \YL{a} learning-based approach to
intrinsic reflectional symmetry detection. Instead of directly finding
symmetric point pairs, we parametrize this self-isometry using a functional map
matrix, which can be easily computed given the signs of Laplacian
eigenfunctions under the symmetric mapping. Therefore, we train a novel deep
neural network to predict the sign of each eigenfunction under symmetry, which
in addition takes the first few eigenfunctions as intrinsic features to
characterize the mesh while avoiding coping with the connectivity explicitly.
Our network aims at learning the global property of functions, and consequently
converts the problem defined on the manifold to the functional domain. By
disentangling the prediction of the matrix into separated basis, our method
generalizes well to new shapes and is invariant under perturbation of
eigenfunctions. Through extensive experiments, we demonstrate the robustness of
our method in challenging cases, including different topology and incomplete
shapes with holes. By avoiding random sampling, our learning-based algorithm is
over 100 times faster than state-of-the-art methods, and meanwhile, is more
robust, achieving higher correspondence accuracy in commonly used metrics.
"
1746,"Personality-Aware Probabilistic Map for Trajectory Prediction of
  Pedestrians","  We present a novel trajectory prediction algorithm for pedestrians based on a
personality-aware probabilistic feature map. This map is computed using a
spatial query structure and each value represents the probability of the
predicted pedestrian passing through various positions in the crowd space. We
update this map dynamically based on the agents in the environment and prior
trajectory of a pedestrian. Furthermore, we estimate the personality
characteristics of each pedestrian and use them to improve the prediction by
estimating the shortest path in this map. Our approach is general and works
well on crowd videos with low and high pedestrian density. We evaluate our
model on standard human-trajectory datasets. In practice, our prediction
algorithm improves the accuracy by 5-9% over prior algorithms.
"
1747,Learning to Infer Implicit Surfaces without 3D Supervision,"  Recent advances in 3D deep learning have shown that it is possible to train
highly effective deep models for 3D shape generation, directly from 2D images.
This is particularly interesting since the availability of 3D models is still
limited compared to the massive amount of accessible 2D images, which is
invaluable for training. The representation of 3D surfaces itself is a key
factor for the quality and resolution of the 3D output. While explicit
representations, such as point clouds and voxels, can span a wide range of
shape variations, their resolutions are often limited. Mesh-based
representations are more efficient but are limited by their ability to handle
varying topologies. Implicit surfaces, however, can robustly handle complex
shapes, topologies, and also provide flexible resolution control. We address
the fundamental problem of learning implicit surfaces for shape inference
without the need of 3D supervision. Despite their advantages, it remains
nontrivial to (1) formulate a differentiable connection between implicit
surfaces and their 2D renderings, which is needed for image-based supervision;
and (2) ensure precise geometric properties and control, such as local
smoothness. In particular, sampling implicit surfaces densely is also known to
be a computationally demanding and very slow operation. To this end, we propose
a novel ray-based field probing technique for efficient image-to-field
supervision, as well as a general geometric regularizer for implicit surfaces,
which provides natural shape priors in unconstrained regions. We demonstrate
the effectiveness of our framework on the task of single-view image-based 3D
shape digitization and show how we outperform state-of-the-art techniques both
quantitatively and qualitatively.
"
1748,BlenderProc,"  BlenderProc is a modular procedural pipeline, which helps in generating real
looking images for the training of convolutional neural networks. These can be
used in a variety of use cases including segmentation, depth, normal and pose
estimation and many others. A key feature of our extension of blender is the
simple to use modular pipeline, which was designed to be easily extendable. By
offering standard modules, which cover a variety of scenarios, we provide a
starting point on which new modules can be created.
"
1749,Ground Metric Learning on Graphs,"  Optimal transport (OT) distances between probability distributions are
parameterized by the ground metric they use between observations. Their
relevance for real-life applications strongly hinges on whether that ground
metric parameter is suitably chosen. Selecting it adaptively and
algorithmically from prior knowledge, the so-called ground metric learning GML)
problem, has therefore appeared in various settings. We consider it in this
paper when the learned metric is constrained to be a geodesic distance on a
graph that supports the measures of interest. This imposes a rich structure for
candidate metrics, but also enables far more efficient learning procedures when
compared to a direct optimization over the space of all metric matrices. We use
this setting to tackle an inverse problem stemming from the observation of a
density evolving with time: we seek a graph ground metric such that the OT
interpolation between the starting and ending densities that result from that
ground metric agrees with the observed evolution. This OT dynamic framework is
relevant to model natural phenomena exhibiting displacements of mass, such as
for instance the evolution of the color palette induced by the modification of
lighting and materials.
"
1750,"Enhancing User Experience in Virtual Reality with Radial Basis Function
  Interpolation Based Stereoscopic Camera Control","  Providing a depth-rich Virtual Reality (VR) experience to users without
causing discomfort remains to be a challenge with today's commercially
available head-mounted displays (HMDs), which enforce strict measures on
stereoscopic camera parameters for the sake of keeping visual discomfort to a
minimum. However, these measures often lead to an unimpressive VR experience
with shallow depth feeling. We propose the first method ready to be used with
existing consumer HMDs for automated stereoscopic camera control in virtual
environments (VEs). Using radial basis function interpolation and projection
matrix manipulations, our method makes it possible to significantly enhance
user experience in terms of overall perceived depth while maintaining visual
discomfort on a par with the default arrangement. In our implementation, we
also introduce the first immersive interface for authoring a unique 3D
stereoscopic cinematography for any VE to be experienced with consumer HMDs. We
conducted a user study that demonstrates the benefits of our approach in terms
of superior picture quality and perceived depth. We also investigated the
effects of using depth of field (DoF) in combination with our approach and
observed that the addition of our DoF implementation was seen as a degraded
experience, if not similar.
"
1751,Locking-free Simulation of Isometric Thin Plates,"  To efficiently simulate very thin, inextensible materials like cloth or
paper, it is tempting to replace force-based thin-plate dynamics with hard
isometry constraints. Unfortunately, naive formulations of the constraints
induce membrane locking---artificial stiffening of bending modes due to the
inability of discrete kinematics to reproduce exact isometries. We propose a
simple set of meshless isometry constraints, based on moving-least-squares
averaging of the strain tensor, which do not lock, and which can be easily
incorporated into standard constrained Lagrangian dynamics integration.
"
1752,Point Movement in a DSL for Higher-Order FEM Visualization,"  Scientific visualization tools tend to be flexible in some ways (e.g., for
exploring isovalues) while restricted in other ways, such as working only on
regular grids, or only on unstructured meshes (as used in the finite element
method, FEM). Our work seeks to expose the common structure of visualization
methods, apart from the specifics of how the fields being visualized are
formed. Recognizing that previous approaches to FEM visualization depend on
efficiently updating computed positions within a mesh, we took an existing
visualization domain-specific language, and added a mesh position type and
associated arithmetic operators. These are orthogonal to the visualization
method itself, so existing programs for visualizing regular grid data work,
with minimal changes, on higher-order FEM data. We reproduce the efficiency
gains of an earlier guided search method of mesh position update for computing
streamlines, and we demonstrate a novel ability to uniformly sample ridge
surfaces of higher-order FEM solutions defined on curved meshes.
"
1753,"Efficient Direct Slicing Of Dilated And Eroded 3d Models For Additive
  Manufacturing: Technical Report","  In the context of additive manufacturing we present a novel technique for
direct slicing of a dilated or eroded volume, where the input volume boundary
is a triangle mesh. Rather than computing a 3D model of the boundary of the
dilated or eroded volume, our technique directly produces its slices. This
leads to a computationally and memory efficient algorithm, which is
embarrassingly parallel. Contours can be extracted under an arbitrary chord
error, non-uniform dilation or erosion are also possible. Finally, the scheme
is simple and robust to implement.
"
1754,Efficient Animation of Sparse Voxel Octrees for Real-Time Ray Tracing,"  A considerable limitation of employing sparse voxels octrees (SVOs) as a
model format for ray tracing has been that the octree data structure is
inherently static. Due to traversal algorithms' dependence on the strict
hierarchical structure of octrees, it has been challenging to achieve real-time
performance of SVO model animation in ray tracing since the octree data
structure would typically have to be regenerated every frame. Presented in this
article is a novel method for animation of models specified on the SVO format.
The method distinguishes itself by permitting model transformations such as
rotation, translation, and anisotropic scaling, while preserving the
hierarchical structure of SVO models so that they may be efficiently traversed.
Due to its modest memory footprint and straightforward arithmetic operations,
the method is well-suited for implementation in hardware. A software ray
tracing implementation of animated SVO models demonstrates real-time
performance on current-generation desktop GPUs, and shows that the animation
method does not substantially slow down the rendering procedure compared to
rendering static SVOs.
"
1755,A Penetration Metric for Deforming Tetrahedra using Object Norm,"  In this paper, we propose a novel penetration metric, called deformable
penetration depth PDd, to define a measure of inter-penetration between two
linearly deforming tetrahedra using the object norm. First of all, we show that
a distance metric for a tetrahedron deforming between two configurations can be
found in closed form based on object norm. Then, we show that the PDd between
an intersecting pair of static and deforming tetrahedra can be found by solving
a quadratic programming (QP) problem in terms of the distance metric with
non-penetration constraints. We also show that the PDd between two,
intersected, deforming tetrahedra can be found by solving a similar QP problem
under some assumption on penetrating directions, and it can be also accelerated
by an order of magnitude using pre-calculated penetration direction. We have
implemented our algorithm on a standard PC platform using an off-the-shelf QP
optimizer, and experimentally show that both the static/deformable and
deformable/deformable tetrahedra cases can be solvable in from a few to tens of
milliseconds. Finally, we demonstrate that our penetration metric is
three-times smaller (or tighter) than the classical, rigid penetration depth
metric in our experiments.
"
1756,Scene-Aware Audio Rendering via Deep Acoustic Analysis,"  We present a new method to capture the acoustic characteristics of real-world
rooms using commodity devices, and use the captured characteristics to generate
similar sounding sources with virtual models. Given the captured audio and an
approximate geometric model of a real-world room, we present a novel
learning-based method to estimate its acoustic material properties. Our
approach is based on deep neural networks that estimate the reverberation time
and equalization of the room from recorded audio. These estimates are used to
compute material properties related to room reverberation using a novel
material optimization objective. We use the estimated acoustic material
characteristics for audio rendering using interactive geometric sound
propagation and highlight the performance on many real-world scenarios. We also
perform a user study to evaluate the perceptual similarity between the recorded
sounds and our rendered audio.
"
1757,Multiple Style-Transfer in Real-Time,"  Style transfer aims to combine the content of one image with the artistic
style of another. It was discovered that lower levels of convolutional networks
captured style information, while higher levels captures content information.
The original style transfer formulation used a weighted combination of VGG-16
layer activations to achieve this goal. Later, this was accomplished in
real-time using a feed-forward network to learn the optimal combination of
style and content features from the respective images. The first aim of our
project was to introduce a framework for capturing the style from several
images at once. We propose a method that extends the original real-time style
transfer formulation by combining the features of several style images. This
method successfully captures color information from the separate style images.
The other aim of our project was to improve the temporal style continuity from
frame to frame. Accordingly, we have experimented with the temporal stability
of the output images and discussed the various available techniques that could
be employed as alternatives.
"
1758,Exploring Configurations for Multi-user Communication in Virtual Reality,"  Virtual Reality (VR) enables users to collaborate while exploring scenarios
not realizable in the physical world. We propose CollabVR, a distributed
multi-user collaboration environment, to explore how digital content improves
expression and understanding of ideas among groups. To achieve this, we
designed and examined three possible configurations for participants and shared
manipulable objects. In configuration (1), participants stand side-by-side. In
(2), participants are positioned across from each other, mirrored face-to-face.
In (3), called ""eyes-free,"" participants stand side-by-side looking at a shared
display, and draw upon a horizontal surface. We also explored a ""telepathy""
mode, in which participants could see from each other's point of view. We
implemented ""3DSketch"" visual objects for participants to manipulate and move
between virtual content boards in the environment. To evaluate the system, we
conducted a study in which four people at a time used each of the three
configurations to cooperate and communicate ideas with each other. We have
provided experimental results and interview responses.
"
1759,Applying Rational Envelope curves for skinning purposes,"  Special curves in the Minkowski space such as Minkowski Pythagorean
hodographs play an important role in Computer Aided Geometric Design, and their
usages have been thoroughly studied in the recent years. Also, several papers
have been published which describe methods for interpolating Hermite data in
R2,1 by MPH curves. Bizzarri et al.introduced the class of RE curves and
presented an interpolation method for G1 Hermite data, where the resulting RE
curve yields a rational boundary for the represented domain. We now propose a
new application area for RE curves: skinning of a discrete set of input
circles. We find the appropriate Hermite data to interpolate so that the
obtained rational envelope curves touch each circle at previously defined
points of contact. This way we overcome the problematic scenarios when the
location of the touching points would not be appropriate for skinning purposes.
"
1760,BSP-Net: Generating Compact Meshes via Binary Space Partitioning,"  Polygonal meshes are ubiquitous in the digital 3D domain, yet they have only
played a minor role in the deep learning revolution. Leading methods for
learning generative models of shapes rely on implicit functions, and generate
meshes only after expensive iso-surfacing routines. To overcome these
challenges, we are inspired by a classical spatial data structure from computer
graphics, Binary Space Partitioning (BSP), to facilitate 3D learning. The core
ingredient of BSP is an operation for recursive subdivision of space to obtain
convex sets. By exploiting this property, we devise BSP-Net, a network that
learns to represent a 3D shape via convex decomposition. Importantly, BSP-Net
is unsupervised since no convex shape decompositions are needed for training.
The network is trained to reconstruct a shape using a set of convexes obtained
from a BSP-tree built on a set of planes. The convexes inferred by BSP-Net can
be easily extracted to form a polygon mesh, without any need for iso-surfacing.
The generated meshes are compact (i.e., low-poly) and well suited to represent
sharp geometry; they are guaranteed to be watertight and can be easily
parameterized. We also show that the reconstruction quality by BSP-Net is
competitive with state-of-the-art methods while using much fewer primitives.
Code is available at https://github.com/czq142857/BSP-NET-original.
"
1761,Hierarchical Optimization Time Integration for CFL-rate MPM Stepping,"  We propose Hierarchical Optimization Time Integration (HOT) for efficient
implicit time-stepping of the Material Point Method (MPM) irrespective of
simulated materials and conditions. HOT is an MPM-specialized hierarchical
optimization algorithm that solves nonlinear time step problems for large-scale
MPM systems near the CFL-limit. HOT provides convergent simulations
""out-of-the-box"" across widely varying materials and computational resolutions
without parameter tuning. As an implicit MPM time stepper accelerated by a
custom-designed Galerkin multigrid wrapped in a quasi-Newton solver, HOT is
both highly parallelizable and robustly convergent. As we show in our analysis,
HOT maintains consistent and efficient performance even as we grow stiffness,
increase deformation, and vary materials over a wide range of finite strain,
elastodynamic and plastic examples. Through careful benchmark ablation studies,
we compare the effectiveness of HOT against seemingly plausible alternative
combinations of MPM with standard multigrid and other Newton-Krylov models. We
show how these alternative designs result in severe issues and poor
performance. In contrast, HOT outperforms the existing state-of-the-art,
heavily optimized implicit MPM codes with an up to 10x performance speedup
across a wide range of challenging benchmark test simulations.
"
1762,Live Face De-Identification in Video,"  We propose a method for face de-identification that enables fully automatic
video modification at high frame rates. The goal is to maximally decorrelate
the identity, while having the perception (pose, illumination and expression)
fixed. We achieve this by a novel feed-forward encoder-decoder network
architecture that is conditioned on the high-level representation of a person's
facial image. The network is global, in the sense that it does not need to be
retrained for a given video or for a given identity, and it creates natural
looking image sequences with little distortion in time.
"
1763,Learning Stylized Character Expressions from Humans,"  We present DeepExpr, a novel expression transfer system from humans to
multiple stylized characters via deep learning. We developed : 1) a data-driven
perceptual model of facial expressions, 2) a novel stylized character data set
with cardinal expression annotations : FERG (Facial Expression Research Group)
- DB (added two new characters), and 3) . We evaluated our method on a set of
retrieval tasks on our collected stylized character dataset of expressions. We
have also shown that the ranking order predicted by the proposed features is
highly correlated with the ranking order provided by a facial expression expert
and Mechanical Turk (MT) experiments.
"
1764,Feature Extraction in Augmented Reality,"  Augmented Reality (AR) is used for various applications associated with the
real world. In this paper, first, describe characteristics and essential
services of AR. Brief history on Virtual Reality (VR) and AR is also mentioned
in the introductory section. Then, AR Technologies along with its workflow is
depicted, which includes the complete AR Process consisting of the stages of
Image Acquisition, Feature Extraction, Feature Matching, Geometric
Verification, and Associated Information Retrieval. Feature extraction is the
essence of AR hence its details are furnished in the paper.
"
1765,"DR-KFS: A Differentiable Visual Similarity Metric for 3D Shape
  Reconstruction","  We introduce a differential visual similarity metric to train deep neural
networks for 3D reconstruction, aimed at improving reconstruction quality. The
metric compares two 3D shapes by measuring distances between multi-view images
differentiably rendered from the shapes. Importantly, the image-space distance
is also differentiable and measures visual similarity, rather than pixel-wise
distortion. Specifically, the similarity is defined by mean-squared errors over
HardNet features computed from probabilistic keypoint maps of the compared
images. Our differential visual shape similarity metric can be easily plugged
into various 3D reconstruction networks, replacing their distortion-based
losses, such as Chamfer or Earth Mover distances, so as to optimize the network
weights to produce reconstructions with better structural fidelity and visual
quality. We demonstrate this both objectively, using well-known shape metrics
for retrieval and classification tasks that are independent from our new
metric, and subjectively through a perceptual study.
"
1766,"Semantic Hierarchy Emerges in Deep Generative Representations for Scene
  Synthesis","  Despite the success of Generative Adversarial Networks (GANs) in image
synthesis, there lacks enough understanding on what generative models have
learned inside the deep generative representations and how photo-realistic
images are able to be composed of the layer-wise stochasticity introduced in
recent GANs. In this work, we show that highly-structured semantic hierarchy
emerges as variation factors from synthesizing scenes from the generative
representations in state-of-the-art GAN models, like StyleGAN and BigGAN. By
probing the layer-wise representations with a broad set of semantics at
different abstraction levels, we are able to quantify the causality between the
activations and semantics occurring in the output image. Such a quantification
identifies the human-understandable variation factors learned by GANs to
compose scenes. The qualitative and quantitative results further suggest that
the generative representations learned by the GANs with layer-wise latent codes
are specialized to synthesize different hierarchical semantics: the early
layers tend to determine the spatial layout and configuration, the middle
layers control the categorical objects, and the later layers finally render the
scene attributes as well as color scheme. Identifying such a set of
manipulatable latent variation factors facilitates semantic scene manipulation.
"
1767,Virtual Lenses as Embodied Tools for Immersive Analytics,"  Interactive lenses are useful tools for supporting the analysis of data in
different ways. Most existing lenses are designed for 2D visualization and are
operated using standard mouse and keyboard interaction. On the other hand,
research on virtual lenses for novel 3D immersive visualization environments is
scarce. Our work aims to narrow this gap in the literature. We focus
particularly on the interaction with lenses. Inspired by natural interaction
with magnifying glasses in the real world, our lenses are designed as graspable
tools that can be created and removed as needed, manipulated and parameterized
depending on the task, and even combined to flexibly create new views on the
data. We implemented our ideas in a system for the visual analysis of 3D sonar
data. Informal user feedback from more than a hundred people suggests that the
designed lens interaction is easy to use for the task of finding a hidden wreck
in sonar data.
"
1768,Importance Sampling of Many Lights with Reinforcement Lightcuts Learning,"  In this manuscript, we introduce a novel technique for sampling and
integrating direct illumination in the presence of many lights. Unlike previous
work, the presented technique importance samples the product distribution of
radiance and visibility while using bounded memory footprint and very low
sampling overhead. This is achieved by learning a compact approximation of the
target distributions over both space and time, allowing to reuse and adapt the
learnt distributions both spatially, within a frame, and temporally, across
multiple frames. Finally, the technique is amenable to massive parallelization
on GPUs and suitable for both offline and real-time rendering.
"
1769,"Titan: A Parallel Asynchronous Library for Multi-Agent and Soft-Body
  Robotics using NVIDIA CUDA","  While most robotics simulation libraries are built for low-dimensional and
intrinsically serial tasks, soft-body and multi-agent robotics have created a
demand for simulation environments that can model many interacting bodies in
parallel. Despite the increasing interest in these fields, no existing
simulation library addresses the challenge of providing a unified,
highly-parallelized, GPU-accelerated interface for simulating large robotic
systems. Titan is a versatile CUDA-based C++ robotics simulation library that
employs a novel asynchronous computing model for GPU-accelerated simulations of
robotics primitives. The innovative GPU architecture design permits
simultaneous optimization and control on the CPU while the GPU runs
asynchronously, enabling rapid topology optimization and reinforcement learning
iterations. Kinematics are solved with a massively parallel integration scheme
that incorporates constraints and environmental forces. We report dramatically
improved performance over CPU-based baselines, simulating as many as 300
million primitive updates per second, while allowing flexibility for a wide
range of research applications. We present several applications of Titan to
high-performance simulations of soft-body and multi-agent robots.
"
1770,SAL: Sign Agnostic Learning of Shapes from Raw Data,"  Recently, neural networks have been used as implicit representations for
surface reconstruction, modelling, learning, and generation. So far, training
neural networks to be implicit representations of surfaces required training
data sampled from a ground-truth signed implicit functions such as signed
distance or occupancy functions, which are notoriously hard to compute.
  In this paper we introduce Sign Agnostic Learning (SAL), a deep learning
approach for learning implicit shape representations directly from raw,
unsigned geometric data, such as point clouds and triangle soups.
  We have tested SAL on the challenging problem of surface reconstruction from
an un-oriented point cloud, as well as end-to-end human shape space learning
directly from raw scans dataset, and achieved state of the art reconstructions
compared to current approaches. We believe SAL opens the door to many geometric
deep learning applications with real-world data, alleviating the usual
painstaking, often manual pre-process.
"
1771,"GAC-GAN: A General Method for Appearance-Controllable Human Video Motion
  Transfer","  Human video motion transfer has a wide range of applications in multimedia,
computer vision and graphics. Recently, due to the rapid development of
Generative Adversarial Networks (GANs), there has been significant progress in
the field. However, almost all existing GAN-based works are prone to address
the mapping from human motions to video scenes, with scene appearances are
encoded individually in the trained models. Therefore, each trained model can
only generate videos with a specific scene appearance, new models are required
to be trained to generate new appearances. Besides, existing works lack the
capability of appearance control. For example, users have to provide video
records of wearing new clothes or performing in new backgrounds to enable
clothes or background changing in their synthetic videos, which greatly limits
the application flexibility. In this paper, we propose GAC-GAN, a general
method for appearance-controllable human video motion transfer. To enable
general-purpose appearance synthesis, we propose to include appearance
information in the conditioning inputs. Thus, once trained, our model can
generate new appearances by altering the input appearance information. To
achieve appearance control, we first obtain the appearance-controllable
conditioning inputs and then utilize a two-stage GAC-GAN to generate the
corresponding appearance-controllable outputs, where we utilize an ACGAN loss
and a shadow extraction module for output foreground and background appearance
control respectively. We further build a solo dance dataset containing a large
number of dance videos for training and evaluation. Experimental results show
that, our proposed GAC-GAN can not only support appearance-controllable human
video motion transfer but also achieve higher video quality than state-of-art
methods.
"
1772,PQ-NET: A Generative Part Seq2Seq Network for 3D Shapes,"  We introduce PQ-NET, a deep neural network which represents and generates 3D
shapes via sequential part assembly. The input to our network is a 3D shape
segmented into parts, where each part is first encoded into a feature
representation using a part autoencoder. The core component of PQ-NET is a
sequence-to-sequence or Seq2Seq autoencoder which encodes a sequence of part
features into a latent vector of fixed size, and the decoder reconstructs the
3D shape, one part at a time, resulting in a sequential assembly. The latent
space formed by the Seq2Seq encoder encodes both part structure and fine part
geometry. The decoder can be adapted to perform several generative tasks
including shape autoencoding, interpolation, novel shape generation, and
single-view 3D reconstruction, where the generated shapes are all composed of
meaningful parts.
"
1773,StructEdit: Learning Structural Shape Variations,"  Learning to encode differences in the geometry and (topological) structure of
the shapes of ordinary objects is key to generating semantically plausible
variations of a given shape, transferring edits from one shape to another, and
many other applications in 3D content creation. The common approach of encoding
shapes as points in a high-dimensional latent feature space suggests treating
shape differences as vectors in that space. Instead, we treat shape differences
as primary objects in their own right and propose to encode them in their own
latent space. In a setting where the shapes themselves are encoded in terms of
fine-grained part hierarchies, we demonstrate that a separate encoding of shape
deltas or differences provides a principled way to deal with inhomogeneities in
the shape space due to different combinatorial part structures, while also
allowing for compactness in the representation, as well as edit abstraction and
transfer. Our approach is based on a conditional variational autoencoder for
encoding and decoding shape deltas, conditioned on a source shape. We
demonstrate the effectiveness and robustness of our approach in multiple shape
modification and generation tasks, and provide comparison and ablation studies
on the PartNet dataset, one of the largest publicly available 3D datasets.
"
1774,"Using Physics-Informed Super-Resolution Generative Adversarial Networks
  for Subgrid Modeling in Turbulent Reactive Flows","  Turbulence is still one of the main challenges for accurately predicting
reactive flows. Therefore, the development of new turbulence closures which can
be applied to combustion problems is essential. Data-driven modeling has become
very popular in many fields over the last years as large, often extensively
labeled, datasets became available and training of large neural networks became
possible on GPUs speeding up the learning process tremendously. However, the
successful application of deep neural networks in fluid dynamics, for example
for subgrid modeling in the context of large-eddy simulations (LESs), is still
challenging. Reasons for this are the large amount of degrees of freedom in
realistic flows, the high requirements with respect to accuracy and error
robustness, as well as open questions, such as the generalization capability of
trained neural networks in such high-dimensional, physics-constrained
scenarios. This work presents a novel subgrid modeling approach based on a
generative adversarial network (GAN), which is trained with unsupervised deep
learning (DL) using adversarial and physics-informed losses. A two-step
training method is used to improve the generalization capability, especially
extrapolation, of the network. The novel approach gives good results in a
priori as well as a posteriori tests with decaying turbulence including
turbulent mixing. The applicability of the network in complex combustion
scenarios is furthermore discussed by employing it to a reactive LES of the
Spray A case defined by the Engine Combustion Network (ECN).
"
1775,Image2StyleGAN++: How to Edit the Embedded Images?,"  We propose Image2StyleGAN++, a flexible image editing framework with many
applications. Our framework extends the recent Image2StyleGAN in three ways.
First, we introduce noise optimization as a complement to the $W^+$ latent
space embedding. Our noise optimization can restore high-frequency features in
images and thus significantly improves the quality of reconstructed images,
e.g. a big increase of PSNR from 20 dB to 45 dB. Second, we extend the global
$W^+$ latent space embedding to enable local embeddings. Third, we combine
embedding with activation tensor manipulation to perform high-quality local
edits along with global semantic edits on images. Such edits motivate various
high-quality image editing applications, e.g. image reconstruction, image
inpainting, image crossover, local style transfer, image editing using
scribbles, and attribute level feature transfer. Examples of the edited images
are shown across the paper for visual inspection.
"
1776,"MixNMatch: Multifactor Disentanglement and Encoding for Conditional
  Image Generation","  We present MixNMatch, a conditional generative model that learns to
disentangle and encode background, object pose, shape, and texture from real
images with minimal supervision, for mix-and-match image generation. We build
upon FineGAN, an unconditional generative model, to learn the desired
disentanglement and image generator, and leverage adversarial joint image-code
distribution matching to learn the latent factor encoders. MixNMatch requires
bounding boxes during training to model background, but requires no other
supervision. Through extensive experiments, we demonstrate MixNMatch's ability
to accurately disentangle, encode, and combine multiple factors for
mix-and-match image generation, including sketch2color, cartoon2img, and
img2gif applications. Our code/models/demo can be found at
https://github.com/Yuheng-Li/MixNMatch
"
1777,Recovering Facial Reflectance and Geometry from Multi-view Images,"  While the problem of estimating shapes and diffuse reflectances of human
faces from images has been extensively studied, there is relatively less work
done on recovering the specular albedo. This paper presents a lightweight
solution for inferring photorealistic facial reflectance and geometry. Our
system processes video streams from two views of a subject, and outputs two
reflectance maps for diffuse and specular albedos, as well as a vector map of
surface normals. A model-based optimization approach is used, consisting of the
three stages of multi-view face model fitting, facial reflectance inference and
facial geometry refinement. Our approach is based on a novel formulation built
upon the 3D morphable model (3DMM) for representing 3D textured faces in
conjunction with the Blinn-Phong reflection model. It has the advantage of
requiring only a simple setup with two video streams, and is able to exploit
the interaction between the diffuse and specular reflections across multiple
views as well as time frames. As a result, the method is able to reliably
recover high-fidelity facial reflectance and geometry, which facilitates
various applications such as generating photorealistic facial images under new
viewpoints or illumination conditions.
"
1778,"Vectorizing Quantum Turbulence Vortex-Core Lines for Real-Time
  Visualization","  Vectorizing vortex-core lines is crucial for high-quality visualization and
analysis of turbulence. While several techniques exist in the literature, they
can only be applied to classical fluids. Recently, quantum fluids with
turbulence get more and more attention in physics. It is thus desirable that
vortex-core lines can also be well extracted and visualized for quantum fluids.
In this paper, we aim for this goal and developed an efficient vortex-core line
vectorization method for quantum fluids, which enables real-time visualization
of high-resolution quantum turbulence structure. Given the datasets by
simulation, our technique is developed from the vortices identified by the
circulation-based method. To vectorize the vortex-core lines enclosed by those
vortices, we propose a novel graph-based data structure, with iterative graph
reduction and density-guided local optimization, to locate more precisely
sub-grid-scale vortex-core line samples, which are then vectorized by
continuous curves. This not only represents vortex-core line structures
continuously, but also naturally preserves complex topology, such as branching
during reconnection. By vectorization, the memory consumption can be largely
reduced by orders of magnitude, enabling real-time rendering performance.
Different types of interactive visualizations are demonstrated to show the
effectiveness of our technique, which could assist further research on quantum
turbulence.
"
1779,"Inattentional Blindness for Redirected Walking Using Dynamic Foveated
  Rendering","  Redirected walking is a Virtual Reality(VR) locomotion technique which
enables users to navigate virtual environments (VEs) that are spatially larger
than the available physical tracked space. In this work we present a novel
technique for redirected walking in VR based on the psychological phenomenon of
inattentional blindness. Based on the user's visual fixation points we divide
the user's view into zones. Spatially-varying rotations are applied according
to the zone's importance and are rendered using foveated rendering. Our
technique is real-time and applicable to small and large physical spaces.
Furthermore, the proposed technique does not require the use of stimulated
saccades but rather takes advantage of naturally occurring saccades and blinks
for a complete refresh of the framebuffer. We performed extensive testing and
present the analysis of the results of three user studies conducted for the
evaluation.
"
1780,"Geometry-Driven Detection, Tracking and Visual Analysis of Viscous and
  Gravitational Fingers","  Viscous and gravitational flow instabilities cause a displacement front to
break up into finger-like fluids. The detection and evolutionary analysis of
these fingering instabilities are critical in multiple scientific disciplines
such as fluid mechanics and hydrogeology. However, previous detection methods
of the viscous and gravitational fingers are based on density thresholding,
which provides limited geometric information of the fingers. The geometric
structures of fingers and their evolution are important yet little studied in
the literature. In this work, we explore the geometric detection and evolution
of the fingers in detail to elucidate the dynamics of the instability. We
propose a ridge voxel detection method to guide the extraction of finger cores
from three-dimensional (3D) scalar fields. After skeletonizing finger cores
into skeletons, we design a spanning tree based approach to capture how fingers
branch spatially from the finger skeletons. Finally, we devise a novel
geometric-glyph augmented tracking graph to study how the fingers and their
branches grow, merge, and split over time. Feedback from earth scientists
demonstrates the usefulness of our approach to performing spatio-temporal
geometric analyses of fingers.
"
1781,SEAN: Image Synthesis with Semantic Region-Adaptive Normalization,"  We propose semantic region-adaptive normalization (SEAN), a simple but
effective building block for Generative Adversarial Networks conditioned on
segmentation masks that describe the semantic regions in the desired output
image. Using SEAN normalization, we can build a network architecture that can
control the style of each semantic region individually, e.g., we can specify
one style reference image per region. SEAN is better suited to encode,
transfer, and synthesize style than the best previous method in terms of
reconstruction quality, variability, and visual quality. We evaluate SEAN on
multiple datasets and report better quantitative metrics (e.g. FID, PSNR) than
the current state of the art. SEAN also pushes the frontier of interactive
image editing. We can interactively edit images by changing segmentation masks
or the style for any given region. We can also interpolate styles from two
reference images per region.
"
1782,Safe Walking In VR using Augmented Virtuality,"  New technologies allow ordinary people to access Virtual Reality at
affordable prices in their homes. One of the most important tasks when
interacting with immersive Virtual Reality is to navigate the virtual
environments (VEs). Arguably, the best methods to accomplish this use of direct
control interfaces. Among those, natural walking (NW) makes for enjoyable user
experience. However, common techniques to support direct control interfaces in
VEs feature constraints that make it difficult to use those methods in cramped
home environments. Indeed, NW requires unobstructed and open space. To approach
this problem, we propose a new virtual locomotion technique, Combined Walking
in Place (CWIP). CWIP allows people to take advantage of the available physical
space and empowers them to use NW to navigate in the virtual world. For longer
distances, we adopt Walking in Place (WIP) to enable them to move in the
virtual world beyond the confines of a cramped real room. However, roaming in
immersive alternate reality, while moving in the confines of a cluttered
environment can lead people to stumble and fall. To approach these problems, we
developed Augmented Virtual Reality (AVR), to inform users about real-world
hazards, such as chairs, drawers, walls via proxies and signs placed in the
virtual world. We propose thus CWIP-AVR as a way to safely explore VR in the
cramped confines of your own home. To our knowledge, this is the first approach
to combined different locomotion modalities in a safe manner. We evaluated it
in a user study with 20 participants to validate their ability to navigate a
virtual world while walking in a confined and cluttered real space. Our results
show that CWIP-AVR allows people to navigate VR safely, switching between
locomotion modes flexibly while maintaining a good immersion.
"
1783,"DIST: Rendering Deep Implicit Signed Distance Function with
  Differentiable Sphere Tracing","  We propose a differentiable sphere tracing algorithm to bridge the gap
between inverse graphics methods and the recently proposed deep learning based
implicit signed distance function. Due to the nature of the implicit function,
the rendering process requires tremendous function queries, which is
particularly problematic when the function is represented as a neural network.
We optimize both the forward and backward passes of our rendering layer to make
it run efficiently with affordable memory consumption on a commodity graphics
card. Our rendering method is fully differentiable such that losses can be
directly computed on the rendered 2D observations, and the gradients can be
propagated backwards to optimize the 3D geometry. We show that our rendering
method can effectively reconstruct accurate 3D shapes from various inputs, such
as sparse depth and multi-view images, through inverse optimization. With the
geometry based reasoning, our 3D shape prediction methods show excellent
generalization capability and robustness against various noises.
"
1784,A SVBRDF Modeling Pipeline using Pixel Clustering,"  We present a pipeline for modeling spatially varying BRDFs (svBRDFs) of
planar materials which only requires a mobile phone for data acquisition. With
a minimum of two photos under the ambient and point light source, our pipeline
produces svBRDF parameters, a normal map and a tangent map for the material
sample. The BRDF fitting is achieved via a pixel clustering strategy and an
optimization based scheme. Our method is light-weight, easy-to-use and capable
of producing high-quality BRDF textures.
"
1785,"LatentFusion: End-to-End Differentiable Reconstruction and Rendering for
  Unseen Object Pose Estimation","  Current 6D object pose estimation methods usually require a 3D model for each
object. These methods also require additional training in order to incorporate
new objects. As a result, they are difficult to scale to a large number of
objects and cannot be directly applied to unseen objects.
  We propose a novel framework for 6D pose estimation of unseen objects. We
present a network that reconstructs a latent 3D representation of an object
using a small number of reference views at inference time. Our network is able
to render the latent 3D representation from arbitrary views. Using this neural
renderer, we directly optimize for pose given an input image. By training our
network with a large number of 3D shapes for reconstruction and rendering, our
network generalizes well to unseen objects. We present a new dataset for unseen
object pose estimation--MOPED. We evaluate the performance of our method for
unseen object pose estimation on MOPED as well as the ModelNet and LINEMOD
datasets. Our method performs competitively to supervised methods that are
trained on those objects. Code and data is available at
https://keunhong.com/publications/latentfusion/.
"
1786,"Continuous Histograms for Anisotropy of 2D Symmetric Piece-wise Linear
  Tensor Fields","  The analysis of contours of scalar fields plays an important role in
visualization. For example the contour tree and contour statistics can be used
as a means for interaction and filtering or as signatures. In the context of
tensor field analysis, such methods are also interesting for the analysis of
derived scalar invariants. While there are standard algorithms to compute and
analyze contours, they are not directly applicable to tensor invariants when
using component-wise tensor interpolation. In this chapter we present an
accurate derivation of the contour spectrum for invariants with quadratic
behavior computed from two-dimensional piece-wise linear tensor fields. For
this work, we are mostly motivated by a consistent treatment of the anisotropy
field, which plays an important role as stability measure for tensor field
topology. We show that it is possible to derive an analytical expression for
the distribution of the invariant values in this setting, which is exemplary
given for the anisotropy in all details. Our derivation is based on a
topological sub-division of the mesh in triangles that exhibit a monotonic
behavior. This triangulation can also directly be used to compute the accurate
contour tree with standard algorithms. We compare the results to a na\""ive
approach based on linear interpolation on the original mesh or the subdivision.
"
1787,"A Bayesian Inference Framework for Procedural Material Parameter
  Estimation","  Procedural material models have been gaining traction in many applications
thanks to their flexibility, compactness, and easy editability. We explore the
inverse rendering problem of procedural material parameter estimation from
photographs, presenting a unified view of the problem in a Bayesian framework.
In addition to computing point estimates of the parameters by optimization, our
framework uses a Markov Chain Monte Carlo approach to sample the space of
plausible material parameters, providing a collection of plausible matches that
a user can choose from, and efficiently handling both discrete and continuous
model parameters. To demonstrate the effectiveness of our framework, we fit
procedural models of a range of materials---wall plaster, leather, wood,
anisotropic brushed metals and layered metallic paints---to both synthetic and
real target images.
"
1788,Multiple Approaches to Frame Field Correction for CAD Models,"  Three-dimensional frame fields computed on CAD models often contain singular
curves that are not compatible with hexahedral meshing. In this paper, we show
how CAD feature curves can induce non meshable 3-5 singular curves and we study
four different approaches that aims at correcting the frame field topology. All
approaches consist in modifying the frame field computation, the two first ones
consisting in applying internal constraints and the two last ones consisting in
modifying the boundary conditions. Approaches based on internal constraints are
shown not to be very reliable because of their interactions with other
singularities. On the other hand, boundary condition modifications are more
promising as their impact is very localized. We eventually recommend the 3-5
singular curve boundary snapping strategy, which is simple to implement and
allows to generate topologically correct frame fields.
"
1789,"Accelerating Surface Tension Calculation in SPH via Particle
  Classification & Monte Carlo Integration","  Surface tension has a strong influence on the shape of fluid interfaces. We
propose a method to calculate the corresponding forces efficiently. In contrast
to several previous approaches, we discriminate to this end between surface and
non-surface SPH particles. Our method effectively smooths the fluid interface,
minimizing its curvature. We make use of an approach inspired by Monte Carlo
integration to estimate local normals as well as curvatures, based on which the
force can be calculated. The technique is applicable, but not limited to 2D and
3D simulations, and can be coupled with any common SPH formulation. It
outperforms prior approaches with regard to total computation time per time
step, while being stable and avoiding artifacts.
"
1790,"Towards Sustainable Architecture: 3D Convolutional Neural Networks for
  Computational Fluid Dynamics Simulation and Reverse DesignWorkflow","  We present a general and flexible approximation model for near real-time
prediction of steady turbulent flow in a 3D domain based on residual
Convolutional Neural Networks (CNNs). This approach can provide immediate
feedback for real-time iterations at the early stage of architectural design.
This work-flow is then reversed and offers a designer a tool that generates
building volumes based on target wind flow.
"
1791,NASA: Neural Articulated Shape Approximation,"  Efficient representation of articulated objects such as human bodies is an
important problem in computer vision and graphics. To efficiently simulate
deformation, existing approaches represent 3D objects using polygonal meshes
and deform them using skinning techniques. This paper introduces neural
articulated shape approximation (NASA), an alternative framework that enables
efficient representation of articulated deformable objects using neural
indicator functions that are conditioned on pose. Occupancy testing using NASA
is straightforward, circumventing the complexity of meshes and the issue of
water-tightness. We demonstrate the effectiveness of NASA for 3D tracking
applications, and discuss other potential extensions.
"
1792,Geometric Capsule Autoencoders for 3D Point Clouds,"  We propose a method to learn object representations from 3D point clouds
using bundles of geometrically interpretable hidden units, which we call
geometric capsules. Each geometric capsule represents a visual entity, such as
an object or a part, and consists of two components: a pose and a feature. The
pose encodes where the entity is, while the feature encodes what it is. We use
these capsules to construct a Geometric Capsule Autoencoder that learns to
group 3D points into parts (small local surfaces), and these parts into the
whole object, in an unsupervised manner. Our novel Multi-View Agreement voting
mechanism is used to discover an object's canonical pose and its pose-invariant
feature vector. Using the ShapeNet and ModelNet40 datasets, we analyze the
properties of the learned representations and show the benefits of having
multiple votes agree. We perform alignment and retrieval of arbitrarily rotated
objects -- tasks that evaluate our model's object identification and canonical
pose recovery capabilities -- and obtained insightful results.
"
1793,On the Optical Accuracy of the Salvator Mundi,"  A debate in the scientific literature has arisen regarding whether the orb
depicted in Salvator Mundi, which has been attributed by some experts to
Leonardo da Vinci, was rendered in a optically faithful manner or not. Some
hypothesize that it was solid crystal while others hypothesize that it was
hollow, with competing explanations for its apparent lack of background
distortion and its three white spots. In this paper, we study the optical
accuracy of the Salvator Mundi using physically based rendering, a
sophisticated computer graphics tool that produces optically accurate images by
simulating light transport in virtual scenes. We created a virtual model of the
composition centered on the translucent orb in the subject's hand. By
synthesizing images under configurations that vary illuminations and orb
material properties, we tested whether it is optically possible to produce an
image that renders the orb similarly to how it appears in the painting. Our
experiments show that an optically accurate rendering qualitatively matching
that of the painting is indeed possible using materials, light sources, and
scientific knowledge available to Leonardo da Vinci circa 1500. We additionally
tested alternative theories regarding the composition of the orb, such as that
it was a solid calcite ball, which provide empirical evidence that such
alternatives are unlikely to produce images similar to the painting, and that
the orb is instead hollow.
"
1794,VoronoiNet: General Functional Approximators with Local Support,"  Voronoi diagrams are highly compact representations that are used in various
Graphics applications. In this work, we show how to embed a differentiable
version of it -- via a novel deep architecture -- into a generative deep
network. By doing so, we achieve a highly compact latent embedding that is able
to provide much more detailed reconstructions, both in 2D and 3D, for various
shapes. In this tech report, we introduce our representation and present a set
of preliminary results comparing it with recently proposed implicit occupancy
networks.
"
1795,"Spectral domain decomposition method for physically-based rendering of
  Royaumont abbey","  In the context of a virtual reconstitution of the destroyed Royaumont abbey
church, this paper investigates computer sciences issues intrinsic to the
physically-based image rendering. First, a virtual model was designed from
historical sources and archaeological descriptions. Then some materials
physical properties were measured on remains of the church and on pieces from
similar ancient churches. We specify the properties of our lighting source
which is a representation of the sun, and present the rendering algorithm
implemented in our software Virtuelium. In order to accelerate the computation
of the interactions between light-rays and objects, this ray-tracing algorithm
is parallelized by means of domain decomposition techniques. Numerical
experiments show that the computational time saved by a classic parallelization
is much less significant than that gained with our approach.
"
1796,Learning a Neural 3D Texture Space from 2D Exemplars,"  We propose a generative model of 2D and 3D natural textures with diversity,
visual fidelity and at high computational efficiency. This is enabled by a
family of methods that extend ideas from classic stochastic procedural
texturing (Perlin noise) to learned, deep, non-linearities. The key idea is a
hard-coded, tunable and differentiable step that feeds multiple transformed
random 2D or 3D fields into an MLP that can be sampled over infinite domains.
Our model encodes all exemplars from a diverse set of textures without a need
to be re-trained for each exemplar. Applications include texture interpolation,
and learning 3D textures from 2D exemplars.
"
1797,"DeepDeform: Learning Non-rigid RGB-D Reconstruction with Semi-supervised
  Data","  Applying data-driven approaches to non-rigid 3D reconstruction has been
difficult, which we believe can be attributed to the lack of a large-scale
training corpus. Unfortunately, this method fails for important cases such as
highly non-rigid deformations. We first address this problem of lack of data by
introducing a novel semi-supervised strategy to obtain dense inter-frame
correspondences from a sparse set of annotations. This way, we obtain a large
dataset of 400 scenes, over 390,000 RGB-D frames, and 5,533 densely aligned
frame pairs; in addition, we provide a test set along with several metrics for
evaluation. Based on this corpus, we introduce a data-driven non-rigid feature
matching approach, which we integrate into an optimization-based reconstruction
pipeline. Here, we propose a new neural network that operates on RGB-D frames,
while maintaining robustness under large non-rigid deformations and producing
accurate predictions. Our approach significantly outperforms existing non-rigid
reconstruction methods that do not use learned data terms, as well as
learning-based approaches that only use self-supervision.
"
1798,"Interactive 3D fluid simulation: steering the simulation in progress
  using Lattice Boltzmann Method","  This paper describes a work in progress about software and hardware
architecture to steer and control an ongoing fluid simulation in a context of a
serious game application. We propose to use the Lattice Boltzmann Method as the
simulation approach considering that it can provide fully parallel algorithms
to reach interactive time and because it is easier to change parameters while
the simulation is in progress remaining physically relevant than more classical
simulation approaches. We describe which parameters we can modify and how we
solve technical issues of interactive steering and we finally show an
application of our interactive fluid simulation approach of water dam
phenomena.
"
1799,"RGB Point Cloud Manipulation with Triangular Structures for Artistic
  Image Recoloring","  Usual approaches for image recoloring, such as local filtering by transfer
functions and global histogram remapping, lack of accurate control or miss
small groups of important pixels. In this paper, we introduce a triangle-based
structuring of the colors of an image in the RGB space. We present an analysis
of image colors in the RGB space showing the theoretical motivation of our
triangular abstraction. We illustrate the usefulness of our structure to
recolor images.
"
1800,"Neural Voxel Renderer: Learning an Accurate and Controllable Rendering
  Tool","  We present a neural rendering framework that maps a voxelized scene into a
high quality image. Highly-textured objects and scene element interactions are
realistically rendered by our method, despite having a rough representation as
an input. Moreover, our approach allows controllable rendering: geometric and
appearance modifications in the input are accurately propagated to the output.
The user can move, rotate and scale an object, change its appearance and
texture or modify the position of the light and all these edits are represented
in the final rendering. We demonstrate the effectiveness of our approach by
rendering scenes with varying appearance, from single color per object to
complex, high-frequency textures. We show that our rerendering network can
generate very detailed images that represent precisely the appearance of the
input scene. Our experiments illustrate that our approach achieves more
accurate image synthesis results compared to alternatives and can also handle
low voxel grid resolutions. Finally, we show how our neural rendering framework
can capture and faithfully render objects from real images and from a diverse
set of classes.
"
1801,Modelling curvature of a bent paper leaf,"  In this article, we briefly describe various tools and approaches that
algebraic geometry has to offer to straighten bent objects. Throughout this
article we will consider a specific example of a bent or curved piece of paper
which in our case acts very much like an elastica curve. We conclude this
article with a suggestion to algebraic geometry as a viable and fast
performance alternative of neural networks in vision and machine learning. The
purpose of this article is not to build a full blown framework but to show
possibility of using algebraic geometry as an alternative to neural networks
for recognizing or extracting features on manifolds.
"
1802,SketchZooms: Deep multi-view descriptors for matching line drawings,"  Finding point-wise correspondences between images is a long-standing problem
in computer vision. Corresponding sketch images is particularly challenging due
to the varying nature of human style, projection distortions and viewport
changes. In this paper we present a feature descriptor targeting line drawings
learned from a 3D shape data set. Our descriptors are designed to locally match
image pairs where the object of interest belongs to the same semantic category,
yet still differ drastically in shape and projection angle. We build our
descriptors by means of a Convolutional Neural Network (CNN) trained in a
triplet fashion. The goal is to embed semantically similar anchor points close
to one another, and to pull the embeddings of different points far apart. To
learn the descriptors space, the network is fed with a succession of zoomed
views from the input sketches. We have specifically crafted a data set of
synthetic sketches using a non-photorealistic rendering algorithm over a large
collection of part-based registered 3D models. Once trained, our network can
generate descriptors for every pixel in an input image. Furthermore, our
network is able to generalize well to unseen sketches hand-drawn by humans,
outperforming state-of-the-art descriptors on the evaluated matching tasks. Our
descriptors can be used to obtain sparse and dense correspondences between
image pairs. We evaluate our method against a baseline of correspondences data
collected from expert designers, in addition to comparisons with descriptors
that have been proven effective in sketches. Finally, we demonstrate
applications showing the usefulness of our multi-view descriptors.
"
1803,"RoboCoDraw: Robotic Avatar Drawing with GAN-based Style Transfer and
  Time-efficient Path Optimization","  Robotic drawing has become increasingly popular as an entertainment and
interactive tool. In this paper we present RoboCoDraw, a real-time
collaborative robot-based drawing system that draws stylized human face
sketches interactively in front of human users, by using the Generative
Adversarial Network (GAN)-based style transfer and a Random-Key Genetic
Algorithm (RKGA)-based path optimization. The proposed RoboCoDraw system takes
a real human face image as input, converts it to a stylized avatar, then draws
it with a robotic arm. A core component in this system is the Avatar-GAN
proposed by us, which generates a cartoon avatar face image from a real human
face. AvatarGAN is trained with unpaired face and avatar images only and can
generate avatar images of much better likeness with human face images in
comparison with the vanilla CycleGAN. After the avatar image is generated, it
is fed to a line extraction algorithm and converted to sketches. An RKGA-based
path optimization algorithm is applied to find a time-efficient robotic drawing
path to be executed by the robotic arm. We demonstrate the capability of
RoboCoDraw on various face images using a lightweight, safe collaborative robot
UR5.
"
1804,"Spectral Domain Decomposition Method for Natural Lighting and Medieval
  Glass Rendering","  In this paper, we use an original ray-tracing domain decomposition method to
address image rendering of naturally lighted scenes. This new method allows to
particularly analyze rendering problems on parallel architectures, in the case
of interactions between light-rays and glass material. Numerical experiments,
for medieval glass rendering within the church of the Royaumont abbey,
illustrate the performance of the proposed ray-tracing domain decomposition
method (DDM) on multi-cores and multi-processors architectures. On one hand,
applying domain decomposition techniques increases speedups obtained by
parallelizing the computation. On the other hand, for a fixed number of
parallel processes, we notice that speedups increase as the number of
sub-domains do.
"
1805,Neural Voice Puppetry: Audio-driven Facial Reenactment,"  We present Neural Voice Puppetry, a novel approach for audio-driven facial
video synthesis. Given an audio sequence of a source person or digital
assistant, we generate a photo-realistic output video of a target person that
is in sync with the audio of the source input. This audio-driven facial
reenactment is driven by a deep neural network that employs a latent 3D face
model space. Through the underlying 3D representation, the model inherently
learns temporal stability while we leverage neural rendering to generate
photo-realistic output frames. Our approach generalizes across different
people, allowing us to synthesize videos of a target actor with the voice of
any unknown source actor or even synthetic voices that can be generated
utilizing standard text-to-speech approaches. Neural Voice Puppetry has a
variety of use-cases, including audio-driven video avatars, video dubbing, and
text-driven video synthesis of a talking head. We demonstrate the capabilities
of our method in a series of audio- and text-based puppetry examples, including
comparisons to state-of-the-art techniques and a user study.
"
1806,Local Deep Implicit Functions for 3D Shape,"  The goal of this project is to learn a 3D shape representation that enables
accurate surface reconstruction, compact storage, efficient computation,
consistency for similar shapes, generalization across diverse shape categories,
and inference from depth camera observations. Towards this end, we introduce
Local Deep Implicit Functions (LDIF), a 3D shape representation that decomposes
space into a structured set of learned implicit functions. We provide networks
that infer the space decomposition and local deep implicit functions from a 3D
mesh or posed depth image. During experiments, we find that it provides 10.3
points higher surface reconstruction accuracy (F-Score) than the
state-of-the-art (OccNet), while requiring fewer than 1 percent of the network
parameters. Experiments on posed depth image completion and generalization to
unseen classes show 15.8 and 17.8 point improvements over the state-of-the-art,
while producing a structured 3D representation for each input with consistency
across diverse shape collections.
"
1807,TopoAct: Visually Exploring the Shape of Activations in Deep Learning,"  Deep neural networks such as GoogLeNet, ResNet, and BERT have achieved
impressive performance in tasks like image and text classification. To
understand how such performance is achieved, we probe a trained deep neural
network by studying neuron activations, i.e., combinations of neuron firings,
at various layers of the network in response to a particular input. With a
large number of inputs, we aim to obtain a global view of what neurons detect
by studying their activations. In particular, we develop visualizations that
show the shape of the activation space, the organizational principle behind
neuron activations, and the relationships of these activations within a layer.
Applying tools from topological data analysis, we present TopoAct, a visual
exploration system to study topological summaries of activation vectors. We
present exploration scenarios using TopoAct that provide valuable insights into
learned representations of neural networks. We expect TopoAct to give a
topological perspective that enriches the current toolbox of neural network
analysis, and to provide a basis for network architecture diagnosis and data
anomaly detection.
"
1808,"Uncertainty Visualization of 2D Morse Complex Ensembles Using
  Statistical Summary Maps","  Morse complexes are gradient-based topological descriptors with close
connections to Morse theory. They are widely applicable in scientific
visualization as they serve as important abstractions for gaining insights into
the topology of scalar fields. Noise inherent to scalar field data due to
acquisitions and processing, however, limits our understanding of the Morse
complexes as structural abstractions. We, therefore, explore uncertainty
visualization of an ensemble of 2D Morse complexes that arise from scalar
fields coupled with data uncertainty. We propose statistical summary maps as
new entities for capturing structural variations and visualizing positional
uncertainties of Morse complexes in ensembles. Specifically, we introduce two
types of statistical summary maps -- the Probabilistic Map and the Survival Map
-- to characterize the uncertain behaviors of local extrema and local gradient
flows, respectively. We demonstrate the utility of our proposed approach using
synthetic and real-world datasets.
"
1809,Neural Cages for Detail-Preserving 3D Deformations,"  We propose a novel learnable representation for detail-preserving shape
deformation. The goal of our method is to warp a source shape to match the
general structure of a target shape, while preserving the surface details of
the source. Our method extends a traditional cage-based deformation technique,
where the source shape is enclosed by a coarse control mesh termed \emph{cage},
and translations prescribed on the cage vertices are interpolated to any point
on the source mesh via special weight functions. The use of this sparse cage
scaffolding enables preserving surface details regardless of the shape's
intricacy and topology. Our key contribution is a novel neural network
architecture for predicting deformations by controlling the cage. We
incorporate a differentiable cage-based deformation module in our architecture,
and train our network end-to-end. Our method can be trained with common
collections of 3D models in an unsupervised fashion, without any cage-specific
annotations. We demonstrate the utility of our method for synthesizing shape
variations and deformation transfer.
"
1810,"Spectral domain decomposition method for physically-based rendering of
  photochromic/electrochromic glass windows","  This paper covers the time consuming issues intrinsic to physically-based
image rendering algorithms. First, glass materials optical properties were
measured on samples of real glasses and other objects materials inside an hotel
room were characterized by deducing spectral data from multiple trichromatic
images. We then present the rendering model and ray-tracing algorithm
implemented in Virtuelium, an open source software. In order to accelerate the
computation of the interactions between light rays and objects, the ray-tracing
algorithm is parallelized by means of domain decomposition method techniques.
Numerical experiments show that the speedups obtained with classical
parallelization techniques are significantly less significant than those
achieved with parallel domain decomposition methods.
"
1811,"SDFDiff: Differentiable Rendering of Signed Distance Fields for 3D Shape
  Optimization","  We propose SDFDiff, a novel approach for image-based shape optimization using
differentiable rendering of 3D shapes represented by signed distance functions
(SDF). Compared to other representations, SDFs have the advantage that they can
represent shapes with arbitrary topology, and that they guarantee watertight
surfaces. We apply our approach to the problem of multi-view 3D reconstruction,
where we achieve high reconstruction quality and can capture complex topology
of 3D objects. In addition, we employ a multi-resolution strategy to obtain a
robust optimization algorithm. We further demonstrate that our SDF-based
differentiable renderer can be integrated with deep learning models, which
opens up options for learning approaches on 3D objects without 3D supervision.
In particular, we apply our method to single-view 3D reconstruction and achieve
state-of-the-art results.
"
1812,ORC Layout: Adaptive GUI Layout with OR-Constraints,"  We propose a novel approach for constraint-based graphical user interface
(GUI) layout based on OR-constraints (ORC) in standard soft/hard linear
constraint systems. ORC layout unifies grid layout and flow layout, supporting
both their features as well as cases where grid and flow layouts individually
fail. We describe ORC design patterns that enable designers to safely create
flexible layouts that work across different screen sizes and orientations. We
also present the ORC Editor, a GUI editor that enables designers to apply ORC
in a safe and effective manner, mixing grid, flow and new ORC layout features
as appropriate. We demonstrate that our prototype can adapt layouts to screens
with different aspect ratios with only a single layout specification, easing
the burden of GUI maintenance. Finally, we show that ORC specifications can be
modified interactively and solved efficiently at runtime.
"
1813,"A Comparison of Rendering Techniques for Large 3D Line Sets with
  Transparency","  This paper presents a comprehensive study of interactive rendering techniques
for large 3D line sets with transparency. The rendering of transparent lines is
widely used for visualizing trajectories of tracer particles in flow fields.
Transparency is then used to fade out lines deemed unimportant, based on, for
instance, geometric properties or attributes defined along them. Since accurate
blending of transparent lines requires rendering the lines in back-to-front or
front-to-back order, enforcing this order for 3D line sets with tens or even
hundreds of thousands of elements becomes challenging. In this paper, we study
CPU and GPU rendering techniques for large transparent 3D line sets. We compare
accurate and approximate techniques using optimized implementations and a
number of benchmark data sets. We discuss the effects of data size and
transparency on quality, performance and memory consumption. Based on our
study, we propose two improvements to per-pixel fragment lists and multi-layer
alpha blending. The first improves the rendering speed via an improved GPU
sorting operation, and the second improves rendering quality via a
transparency-based bucketing.
"
1814,"Multi-display Visual Analysis: Model, Interface, and Layout Computation","  Modern display environments offer great potential for involving multiple
users in presentations, discussions, and data analysis sessions. By showing
multiple views on multiple displays, information exchange can be improved,
several perspectives on the data can be combined, and different analysis
strategies can be pursued.
  In this report, we describe concepts to support display composition,
information distribution, and analysis coordination for visual data analysis in
multi-display environments. In particular, a basic model for layout modeling is
introduced, a graphical interface for interactive generation of the model is
presented, and a layout mechanism is described that arranges multiple views on
multiple displays automatically. Furthermore, approaches to meta-analysis will
be discussed. The developed approaches are demonstrated in a use case that
focuses on parameter space analysis for the segmentation of time series data.
"
1815,Neural Smoke Stylization with Color Transfer,"  Artistically controlling fluid simulations requires a large amount of manual
work by an artist. The recently presented transportbased neural style transfer
approach simplifies workflows as it transfers the style of arbitrary input
images onto 3D smoke simulations. However, the method only modifies the shape
of the fluid but omits color information. In this work, we therefore extend the
previous approach to obtain a complete pipeline for transferring shape and
color information onto 2D and 3D smoke simulations with neural networks. Our
results demonstrate that our method successfully transfers colored style
features consistently in space and time to smoke data for different input
textures.
"
1816,"Frequency-Aware Reconstruction of Fluid Simulations with Generative
  Networks","  Convolutional neural networks were recently employed to fully reconstruct
fluid simulation data from a set of reduced parameters. However, since
(de-)convolutions traditionally trained with supervised L1-loss functions do
not discriminate between low and high frequencies in the data, the error is not
minimized efficiently for higher bands. This directly correlates with the
quality of the perceived results, since missing high frequency details are
easily noticeable. In this paper, we analyze the reconstruction quality of
generative networks and present a frequency-aware loss function that is able to
focus on specific bands of the dataset during training time. We show that our
approach improves reconstruction quality of fluid simulation data in
mid-frequency bands, yielding perceptually better results while requiring
comparable training time.
"
1817,MVF Designer: Design and Visualization of Morse Vector Fields,"  Vector field design on surfaces was originally motivated by applications in
graphics such as texture synthesis and rendering. In this paper, we consider
the idea of vector field design with a new motivation from computational
topology. We are interested in designing and visualizing vector fields to aid
the study of Morse functions, Morse vector fields, and Morse-Smale complexes.
To achieve such a goal, we present MVF Designer, a new interactive design
system that provides fine-grained control over vector field geometry, enables
the editing of vector field topology, and supports a design process in a simple
and efficient way using elementary moves, which are actions that initiate or
advance our design process. Our system allows mathematicians to explore the
complex configuration spaces of Morse functions, their gradients, and their
associated Morse-Smale complexes. Understanding these spaces will help us
expand further their applicability in topological data analysis and
visualization.
"
1818,"Comparing Hierarchical Data Structures for Sparse Volume Rendering with
  Empty Space Skipping","  Empty space skipping can be efficiently implemented with hierarchical data
structures such as k-d trees and bounding volume hierarchies. This paper
compares several recently published hierarchical data structures with regard to
construction and rendering performance. The papers that form our prior work
have primarily focused on interactively building the data structures and only
showed that rendering performance is superior to using simple acceleration data
structures such as uniform grids with macro cells. In the area of surface ray
tracing, there exists a trade-off between construction and rendering
performance of hierarchical data structures. In this paper we present
performance comparisons for several empty space skipping data structures in
order to determine if such a trade-off also exists for volume rendering with
uniform data topologies.
"
1819,Anisotropic Mesh Filtering by Homogeneous MLS Fitting,"  In this paper we present a novel geometric filter, a homogeneous moving least
squares fitting-based filter (H-MLS filter), for anisotropic mesh filtering.
Instead of fitting the noisy data by a moving parametric surface and projecting
the noisy data onto the surface, we compute new positions of mesh vertices as
the solutions to homogeneous least squares fitting of moving constants to local
neighboring vertices and tangent planes that pass through the vertices. The
normals for defining the tangent planes need not be filtered beforehand but the
parameters for balancing the influences between neighboring vertices and
neighboring tangent planes are computed robustly from the original data under
the assumption of quadratic precision in each tangent direction. The weights
for respective neighboring points for the least squares fitting are computed
adaptively for anisotropic filtering. The filter is easy to implement and has
distinctive features for mesh filtering. (1) The filter is locally implemented
and has circular precision, spheres and cylinders can be recovered exactly by
the filter. (2) The filtered mesh has a high fidelity to the original data
without any position constraint and salient or sharp features can be preserved
well. (3) The filter can be used to filter meshes with various kinds of noise
as well as meshes with highly irregular triangulation.
"
1820,"Front2Back: Single View 3D Shape Reconstruction via Front to Back
  Prediction","  Reconstruction of a 3D shape from a single 2D image is a classical computer
vision problem, whose difficulty stems from the inherent ambiguity of
recovering occluded or only partially observed surfaces. Recent methods address
this challenge through the use of largely unstructured neural networks that
effectively distill conditional mapping and priors over 3D shape. In this work,
we induce structure and geometric constraints by leveraging three core
observations: (1) the surface of most everyday objects is often almost entirely
exposed from pairs of typical opposite views; (2) everyday objects often
exhibit global reflective symmetries which can be accurately predicted from
single views; (3) opposite orthographic views of a 3D shape share consistent
silhouettes. Following these observations, we first predict orthographic 2.5D
visible surface maps (depth, normal and silhouette) from perspective 2D images,
and detect global reflective symmetries in this data; second, we predict the
back facing depth and normal maps using as input the front maps and, when
available, the symmetric reflections of these maps; and finally, we reconstruct
a 3D mesh from the union of these maps using a surface reconstruction method
best suited for this data. Our experiments demonstrate that our framework
outperforms state-of-the art approaches for 3D shape reconstructions from 2D
and 2.5D data in terms of input fidelity and details preservation.
Specifically, we achieve 12% better performance on average in ShapeNet
benchmark dataset, and up to 19% for certain classes of objects (e.g., chairs
and vessels).
"
1821,GrabAR: Occlusion-aware Grabbing Virtual Objects in AR,"  Existing augmented reality (AR) applications often ignore occlusion between
real hands and virtual objects when incorporating virtual objects in our views.
The challenges come from the lack of accurate depth and mismatch between real
and virtual depth. This paper presents GrabAR, a new approach that directly
predicts the real-and-virtual occlusion, and bypasses the depth acquisition and
inference. Our goal is to enhance AR applications with interactions between
hand (real) and grabbable objects (virtual). With paired images of hand and
object as inputs, we formulate a neural network that learns to generate the
occlusion mask. To train the network, we compile a synthetic dataset to
pre-train it and a real dataset to fine-tune it, thus reducing the burden of
manual labels and addressing the domain difference. Then, we embed the trained
network in a prototyping AR system that supports hand grabbing of various
virtual objects, demonstrate the system performance, both quantitatively and
qualitatively, and showcase interaction scenarios, in which we can use bare
hand to grab virtual objects and directly manipulate them.
"
1822,Learned Interpolation for 3D Generation,"  In order to generate novel 3D shapes with machine learning, one must allow
for interpolation. The typical approach for incorporating this creative process
is to interpolate in a learned latent space so as to avoid the problem of
generating unrealistic instances by exploiting the model's learned structure.
The process of the interpolation is supposed to form a semantically smooth
morphing. While this approach is sound for synthesizing realistic media such as
lifelike portraits or new designs for everyday objects, it subjectively fails
to directly model the unexpected, unrealistic, or creative. In this work, we
present a method for learning how to interpolate point clouds. By encoding
prior knowledge about real-world objects, the intermediate forms are both
realistic and unlike any existing forms. We show not only how this method can
be used to generate ""creative"" point clouds, but how the method can also be
leveraged to generate 3D models suitable for sculpture.
"
1823,Rendering Synthetic Objects into Legacy Photographs,"  We propose a method to realistically insert synthetic objects into existing
photographs without requiring access to the scene or any additional scene
measurements. With a single image and a small amount of annotation, our method
creates a physical model of the scene that is suitable for realistically
rendering synthetic objects with diffuse, specular, and even glowing materials
while accounting for lighting interactions between the objects and the scene.
We demonstrate in a user study that synthetic images produced by our method are
confusable with real scenes, even for people who believe they are good at
telling the difference. Further, our study shows that our method is competitive
with other insertion methods while requiring less scene information. We also
collected new illumination and reflectance datasets; renderings produced by our
system compare well to ground truth. Our system has applications in the movie
and gaming industry, as well as home decorating and user content creation,
among others.
"
1824,"ConstructAide: Analyzing and Visualizing Construction Sites through
  Photographs and Building Models","  We describe a set of tools for analyzing, visualizing, and assessing
architectural/construction progress with unordered photo collections and 3D
building models. With our interface, a user guides the registration of the
model in one of the images, and our system automatically computes the alignment
for the rest of the photos using a novel Structure-from-Motion (SfM) technique;
images with nearby viewpoints are also brought into alignment with each other.
After aligning the photo(s) and model(s), our system allows a user, such as a
project manager or facility owner, to explore the construction site seamlessly
in time, monitor the progress of construction, assess errors and deviations,
and create photorealistic architectural visualizations. These interactions are
facilitated by automatic reasoning performed by our system: static and dynamic
occlusions are removed automatically, rendering information is collected, and
semantic selection tools help guide user input. We also demonstrate that our
user-assisted SfM method outperforms existing techniques on both real-world
construction data and established multi-view datasets.
"
1825,Blind Recovery of Spatially Varying Reflectance from a Single Image,"  We propose a new technique for estimating spatially varying parametric
materials from a single image of an object with unknown shape in unknown
illumination. Our method uses a low-order parametric reflectance model, and
incorporates strong assumptions about lighting and shape. We develop new priors
about how materials mix over space, and jointly infer all of these properties
from a single image. This produces a decomposition of an image which
corresponds, in one sense, to microscopic features (material reflectance) and
macroscopic features (weights defining the mixing properties of materials over
space). We have built a large dataset of real objects rendered with different
material models under different illumination fields for training and ground
truth evaluation. Extensive experiments on both our synthetic dataset images as
well as real images show that (a) our method recovers parameters with
reasonable accuracy; (b) material parameters recovered by our method give
accurate predictions of new renderings of the object; and (c) our low-order
reflectance model still provides a good fit to many real-world reflectances.
"
1826,"Concise and Effective Network for 3D Human Modeling from Orthogonal
  Silhouettes","  In this paper, we revisit the problem of 3D human modeling from two
orthogonal silhouettes of individuals (i.e., front and side views). Different
from our prior work {\cite{wang2003virtual}}, a supervised learning approach
based on \textit{convolutional neural network} (CNN) is investigated to solve
the problem by establishing a mapping function that can effectively extract
features from two silhouettes and fuse them into coefficients in the shape
space of human bodies. A new CNN structure is proposed in our work to exact not
only the discriminative features of front and side views and also their mixed
features for the mapping function. 3D human models with high accuracy are
synthesized from coefficients generated by the mapping function. Existing CNN
approaches for 3D human modeling usually learn a large number of parameters
(from {8.5M} to {355.4M}) from two binary images. Differently, we investigate a
new network architecture and conduct the samples on silhouettes as input. As a
consequence, more accurate models can be generated by our network with only
{2.4M} coefficients. The training of our network is conducted on samples
obtained by augmenting a publicly accessible dataset. Learning transfer by
using datasets with a smaller number of scanned models is applied to our
network to enable the function of generating results with gender-oriented (or
geographical) patterns.
"
1827,"Skeleton Extraction from 3D Point Clouds by Decomposing the Object into
  Parts","  Decomposing a point cloud into its components and extracting curve skeletons
from point clouds are two related problems. Decomposition of a shape into its
components is often obtained as a byproduct of skeleton extraction. In this
work, we propose to extract curve skeletons, from unorganized point clouds, by
decomposing the object into its parts, identifying part skeletons and then
linking these part skeletons together to obtain the complete skeleton. We
believe it is the most natural way to extract skeletons in the sense that this
would be the way a human would approach the problem. Our parts are generalized
cylinders (GCs). Since, the axis of a GC is an integral part of its definition,
the parts have natural skeletal representations. We use translational symmetry,
the fundamental property of GCs, to extract parts from point clouds. We
demonstrate how this method can handle a large variety of shapes. We compare
our method with state of the art methods and show how a part based approach can
deal with some of the limitations of other methods. We present an improved
version of an existing point set registration algorithm and demonstrate its
utility in extracting parts from point clouds. We also show how this method can
be used to extract skeletons from and identify parts of noisy point clouds. A
part based approach also provides a natural and intuitive interface for user
interaction. We demonstrate the ease with which mistakes, if any, can be fixed
with minimal user interaction with the help of a graphical user interface.
"
1828,Quaternion Equivariant Capsule Networks for 3D Point Clouds,"  We present a 3D capsule module for processing point clouds that is
equivariant to 3D rotations and translations, as well as invariant to
permutations of the input points. The operator receives a sparse set of local
reference frames, computed from an input point cloud and establishes end-to-end
transformation equivariance through a novel dynamic routing procedure on
quaternions. Further, we theoretically connect dynamic routing between capsules
to the well-known Weiszfeld algorithm, a scheme for solving \emph{iterative
re-weighted least squares} (IRLS) problems with provable convergence
properties. It is shown that such group dynamic routing can be interpreted as
robust IRLS rotation averaging on capsule votes, where information is routed
based on the final inlier scores. Based on our operator, we build a capsule
network that disentangles geometry from pose, paving the way for more
informative descriptors and a structured latent space. Our architecture allows
joint object classification and orientation estimation without explicit
supervision of rotations. We validate our algorithm empirically on common
benchmark datasets.
"
1829,Automatic Scene Inference for 3D Object Compositing,"  We present a user-friendly image editing system that supports a drag-and-drop
object insertion (where the user merely drags objects into the image, and the
system automatically places them in 3D and relights them appropriately),
post-process illumination editing, and depth-of-field manipulation. Underlying
our system is a fully automatic technique for recovering a comprehensive 3D
scene model (geometry, illumination, diffuse albedo and camera parameters) from
a single, low dynamic range photograph. This is made possible by two novel
contributions: an illumination inference algorithm that recovers a full
lighting model of the scene (including light sources that are not directly
visible in the photograph), and a depth estimation algorithm that combines
data-driven depth transfer with geometric reasoning about the scene layout. A
user study shows that our system produces perceptually convincing results, and
achieves the same level of realism as techniques that require significant user
interaction.
"
1830,Animals in Virtual Environments,"  The core idea in an XR (VR/MR/AR) application is to digitally stimulate one
or more sensory systems (e.g. visual, auditory, olfactory) of the human user in
an interactive way to achieve an immersive experience. Since the early 2000s
biologists have been using Virtual Environments (VE) to investigate the
mechanisms of behavior in non-human animals including insect, fish, and
mammals. VEs have become reliable tools for studying vision, cognition, and
sensory-motor control in animals. In turn, the knowledge gained from studying
such behaviors can be harnessed by researchers designing biologically inspired
robots, smart sensors, and multi-agent artificial intelligence. VE for animals
is becoming a widely used application of XR technology but such applications
have not previously been reported in the technical literature related to XR.
Biologists and computer scientists can benefit greatly from deepening
interdisciplinary research in this emerging field and together we can develop
new methods for conducting fundamental research in behavioral sciences and
engineering. To support our argument we present this review which provides an
overview of animal behavior experiments conducted in virtual environments.
"
1831,"Adding Custom Intersectors to the C++ Ray Tracing Template Library
  Visionaray","  Most ray tracing libraries allow the user to provide custom functionality
that is executed when a potential ray surface interaction was encountered to
determine if the interaction was valid or traversal should be continued. This
is e.g. useful for alpha mask validation and allows the user to reuse existing
ray object intersection routines rather than reimplementing them. Augmenting
ray traversal with custom intersection logic requires some kind of callback
mechanism that injects user code into existing library routines. With template
libraries, this injection can happen statically since the user compiles the
binary code herself. We present an implementation of this ""custom intersector""
approach and its integration into the C++ ray tracing template library
Visionaray.
"
1832,"Bas-relief Generation from Point Clouds Based on Normal Space
  Compression with Real-time Adjustment on CPU","  Bas-relief generation based on 3d models is a hot topic in computer graphics.
State-of-the-art algorithms take a mesh surface as input, but real-time
interaction via CPU cannot be realized. In this paper, a bas-relief generation
algorithm that takes a scattered point cloud as input is proposed. The
algorithm takes normal vectors as the operation object and the variation of the
local surface as the compression criterion. By constructing and solving linear
equations of bas-relief vertices, the closed-form solution can be obtained.
Since there is no need to compute discrete gradients on a point cloud lacking
topology information, it is easier to implement and more intuitive than
gradient domain methods. The algorithm provides parameters to adjust the
bas-relief height, saturation and detail richness. At the same time, through
the solution strategy based on the subspace, it realizes the real-time
adjustment of the bas-relief effect based on the computing power of a consumer
CPU. In addition, an iterative solution to generate a bas-relief model of a
specified height is presented to meet specific application requirements.
Experiments show that our algorithm provides a unified solution for various
types of bas-relief creation and can generate bas-reliefs with good saturation
and rich details.
"
1833,Learning to Infer User Interface Attributes from Images,"  We explore a new domain of learning to infer user interface attributes that
helps developers automate the process of user interface implementation.
Concretely, given an input image created by a designer, we learn to infer its
implementation which when rendered, looks visually the same as the input image.
To achieve this, we take a black box rendering engine and a set of attributes
it supports (e.g., colors, border radius, shadow or text properties), use it to
generate a suitable synthetic training dataset, and then train specialized
neural models to predict each of the attribute values. To improve pixel-level
accuracy, we additionally use imitation learning to train a neural policy that
refines the predicted attribute values by learning to compute the similarity of
the original and rendered images in their attribute space, rather than based on
the difference of pixel values. We instantiate our approach to the task of
inferring Android Button attribute values and achieve 92.5% accuracy on a
dataset consisting of real-world Google Play Store applications.
"
1834,Lightform: Procedural Effects for Projected AR,"  Projected augmented reality, also called projection mapping or video mapping,
is a form of augmented reality that uses projected light to directly augment 3D
surfaces, as opposed to using pass-through screens or headsets. The value of
projected AR is its ability to add a layer of digital content directly onto
physical objects or environments in a way that can be instantaneously viewed by
multiple people, unencumbered by a screen or additional setup.
  Because projected AR typically involves projecting onto non-flat, textured
objects (especially those that are conventionally not used as projection
surfaces), the digital content needs to be mapped and aligned to precisely fit
the physical scene to ensure a compelling experience. Current projected AR
techniques require extensive calibration at the time of installation, which is
not conducive to iteration or change, whether intentional (the scene is
reconfigured) or not (the projector is bumped or settles). The workflows are
undefined and fragmented, thus making it confusing and difficult for many to
approach projected AR. For example, a digital artist may have the software
expertise to create AR content, but could not complete an installation without
experience in mounting, blending, and realigning projector(s); the converse is
true for many A/V installation teams/professionals. Projection mapping has
therefore been limited to high-end event productions, concerts, and films,
because it requires expensive, complex tools, and skilled teams ($100K+
budgets).
  Lightform provides a technology that makes projected AR approachable,
practical, intelligent, and robust through integrated hardware and
computer-vision software. Lightform brings together and unites a currently
fragmented workflow into a single cohesive process that provides users with an
approachable and robust method to create and control projected AR experiences.
"
1835,Inverse Rendering Techniques for Physically Grounded Image Editing,"  From a single picture of a scene, people can typically grasp the spatial
layout immediately and even make good guesses at materials properties and where
light is coming from to illuminate the scene. For example, we can reliably tell
which objects occlude others, what an object is made of and its rough shape,
regions that are illuminated or in shadow, and so on. It is interesting how
little is known about our ability to make these determinations; as such, we are
still not able to robustly ""teach"" computers to make the same high-level
observations as people. This document presents algorithms for understanding
intrinsic scene properties from single images. The goal of these inverse
rendering techniques is to estimate the configurations of scene elements
(geometry, materials, luminaires, camera parameters, etc) using only
information visible in an image. Such algorithms have applications in robotics
and computer graphics. One such application is in physically grounded image
editing: photo editing made easier by leveraging knowledge of the physical
space. These applications allow sophisticated editing operations to be
performed in a matter of seconds, enabling seamless addition, removal, or
relocation of objects in images.
"
1836,Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings,"  We introduce a new video synthesis task: synthesizing time lapse videos
depicting how a given painting might have been created. Artists paint using
unique combinations of brushes, strokes, and colors. There are often many
possible ways to create a given painting. Our goal is to learn to capture this
rich range of possibilities.
  Creating distributions of long-term videos is a challenge for learning-based
video synthesis methods. We present a probabilistic model that, given a single
image of a completed painting, recurrently synthesizes steps of the painting
process. We implement this model as a convolutional neural network, and
introduce a novel training scheme to enable learning from a limited dataset of
painting time lapses. We demonstrate that this model can be used to sample many
time steps, enabling long-term stochastic video synthesis. We evaluate our
method on digital and watercolor paintings collected from video websites, and
show that human raters find our synthetic videos to be similar to time lapse
videos produced by real artists. Our code is available at
https://xamyzhao.github.io/timecraft.
"
1837,"TCM-ICP: Transformation Compatibility Measure for Registering Multiple
  LIDAR Scans","  Rigid registration of multi-view and multi-platform LiDAR scans is a
fundamental problem in 3D mapping, robotic navigation, and large-scale urban
modeling applications. Data acquisition with LiDAR sensors involves scanning
multiple areas from different points of view, thus generating partially
overlapping point clouds of the real world scenes. Traditionally, ICP
(Iterative Closest Point) algorithm is used to register the acquired point
clouds together to form a unique point cloud that captures the scanned real
world scene. Conventional ICP faces local minima issues and often needs a
coarse initial alignment to converge to the optimum. In this work, we present
an algorithm for registering multiple, overlapping LiDAR scans. We introduce a
geometric metric called Transformation Compatibility Measure (TCM) which aids
in choosing the most similar point clouds for registration in each iteration of
the algorithm. The LiDAR scan most similar to the reference LiDAR scan is then
transformed using simplex technique. An optimization of the transformation
using gradient descent and simulated annealing techniques are then applied to
improve the resulting registration. We evaluate the proposed algorithm on four
different real world scenes and experimental results shows that the
registration performance of the proposed method is comparable or superior to
the traditionally used registration methods. Further, the algorithm achieves
superior registration results even when dealing with outliers.
"
1838,"MW-GAN: Multi-Warping GAN for Caricature Generation with Multi-Style
  Geometric Exaggeration","  Given an input face photo, the goal of caricature generation is to produce
stylized, exaggerated caricatures that share the same identity as the photo. It
requires simultaneous style transfer and shape exaggeration with rich
diversity, and meanwhile preserving the identity of the input. To address this
challenging problem, we propose a novel framework called Multi-Warping GAN
(MW-GAN), including a style network and a geometric network that are designed
to conduct style transfer and geometric exaggeration respectively. We bridge
the gap between the style and landmarks of an image with corresponding latent
code spaces by a dual way design, so as to generate caricatures with arbitrary
styles and geometric exaggeration, which can be specified either through random
sampling of latent code or from a given caricature sample. Besides, we apply
identity preserving loss to both image space and landmark space, leading to a
great improvement in quality of generated caricatures. Experiments show that
caricatures generated by MW-GAN have better quality than existing methods.
"
1839,Deep Learning for Free-Hand Sketch: A Survey and A Toolbox,"  Free-hand sketches are highly illustrative, and have been widely used by
humans to depict objects or stories from ancient times to the present. The
recent prevalence of touchscreen devices has made sketch creation a much easier
task than ever and consequently made sketch-oriented applications increasingly
popular. The progress of deep learning has immensely benefited free-hand sketch
research and applications. This paper presents a comprehensive survey of the
deep learning techniques oriented at free-hand sketch data, and the
applications that they enable. The main contents of this survey include: (i) A
discussion of the intrinsic traits and unique challenges of free-hand sketch,
to highlight the essential differences between sketch data and other data
modalities, e.g., natural photos. (ii) A review of the developments of
free-hand sketch research in the deep learning era, by surveying existing
datasets, research topics, and the state-of-the-art methods through a detailed
taxonomy and experimental evaluation. (iii) Promotion of future work via a
discussion of bottlenecks, open problems, and potential research directions for
the community. Finally, to support future sketch research and applications, we
contribute TorchSketch -- the first sketch-oriented open-source deep learning
library, which is built on PyTorch and available at
https://github.com/PengBoXiangShang/torchsketch/.
"
1840,"Digesting the Elephant -- Experiences with Interactive Production
  Quality Path Tracing of the Moana Island Scene","  New algorithmic and hardware developments over the past two decades have
enabled interactive ray tracing of small to modest sized scenes, and are
finding growing popularity in scientific visualization and games. However,
interactive ray tracing has not been as widely explored in the context of
production film rendering, where challenges due to the complexity of the models
and, from a practical standpoint, their unavailability to the wider research
community, have posed significant challenges. The recent release of the Disney
Moana Island Scene has made one such model available to the community for
experimentation. In this paper, we detail the challenges posed by this scene to
an interactive ray tracer, and the solutions we have employed and developed to
enable interactive path tracing of the scene with full geometric and shading
detail, with the goal of providing insight and guidance to other researchers.
"
1841,"OO-VR: NUMA Friendly Object-Oriented VR Rendering Framework For Future
  NUMA-Based Multi-GPU Systems","  With the strong computation capability, NUMA-based multi-GPU system is a
promising candidate to provide sustainable and scalable performance for Virtual
Reality. However, the entire multi-GPU system is viewed as a single GPU which
ignores the data locality in VR rendering during the workload distribution,
leading to tremendous remote memory accesses among GPU models. By conducting
comprehensive characterizations on different kinds of parallel rendering
frameworks, we observe that distributing the rendering object along with its
required data per GPM can reduce the inter-GPM memory accesses. However, this
object-level rendering still faces two major challenges in NUMA-based multi-GPU
system: (1) the large data locality between the left and right views of the
same object and the data sharing among different objects and (2) the unbalanced
workloads induced by the software-level distribution and composition
mechanisms. To tackle these challenges, we propose object-oriented VR rendering
framework (OO-VR) that conducts the software and hardware co-optimization to
provide a NUMA friendly solution for VR multi-view rendering in NUMA-based
multi-GPU systems. We first propose an object-oriented VR programming model to
exploit the data sharing between two views of the same object and group objects
into batches based on their texture sharing levels. Then, we design an object
aware runtime batch distribution engine and distributed hardware composition
unit to achieve the balanced workloads among GPMs. Finally, evaluations on our
VR featured simulator show that OO-VR provides 1.58x overall performance
improvement and 76% inter-GPM memory traffic reduction over the
state-of-the-art multi-GPU systems. In addition, OO-VR provides NUMA friendly
performance scalability for the future larger multi-GPU scenarios with ever
increasing asymmetric bandwidth between local and remote memory.
"
1842,Unsupervised multi-modal Styled Content Generation,"  The emergence of deep generative models has recently enabled the automatic
generation of massive amounts of graphical content, both in 2D and in 3D.
Generative Adversarial Networks (GANs) and style control mechanisms, such as
Adaptive Instance Normalization (AdaIN), have proved particularly effective in
this context, culminating in the state-of-the-art StyleGAN architecture. While
such models are able to learn diverse distributions, provided a sufficiently
large training set, they are not well-suited for scenarios where the
distribution of the training data exhibits a multi-modal behavior. In such
cases, reshaping a uniform or normal distribution over the latent space into a
complex multi-modal distribution in the data domain is challenging, and the
generator might fail to sample the target distribution well. Furthermore,
existing unsupervised generative models are not able to control the mode of the
generated samples independently of the other visual attributes, despite the
fact that they are typically disentangled in the training data.
  In this paper, we introduce UMMGAN, a novel architecture designed to better
model multi-modal distributions, in an unsupervised fashion. Building upon the
StyleGAN architecture, our network learns multiple modes, in a completely
unsupervised manner, and combines them using a set of learned weights. We
demonstrate that this approach is capable of effectively approximating a
complex distribution as a superposition of multiple simple ones. We further
show that UMMGAN effectively disentangles between modes and style, thereby
providing an independent degree of control over the generated content.
"
1843,On Demand Solid Texture Synthesis Using Deep 3D Networks,"  This paper describes a novel approach for on demand volumetric texture
synthesis based on a deep learning framework that allows for the generation of
high quality 3D data at interactive rates. Based on a few example images of
textures, a generative network is trained to synthesize coherent portions of
solid textures of arbitrary sizes that reproduce the visual characteristics of
the examples along some directions. To cope with memory limitations and
computation complexity that are inherent to both high resolution and 3D
processing on the GPU, only 2D textures referred to as ""slices"" are generated
during the training stage. These synthetic textures are compared to exemplar
images via a perceptual loss function based on a pre-trained deep network. The
proposed network is very light (less than 100k parameters), therefore it only
requires sustainable training (i.e. few hours) and is capable of very fast
generation (around a second for $256^3$ voxels) on a single GPU. Integrated
with a spatially seeded PRNG the proposed generator network directly returns an
RGB value given a set of 3D coordinates. The synthesized volumes have good
visual results that are at least equivalent to the state-of-the-art patch based
approaches. They are naturally seamlessly tileable and can be fully generated
in parallel.
"
1844,"Neural Human Video Rendering by Learning Dynamic Textures and
  Rendering-to-Video Translation","  Synthesizing realistic videos of humans using neural networks has been a
popular alternative to the conventional graphics-based rendering pipeline due
to its high efficiency. Existing works typically formulate this as an
image-to-image translation problem in 2D screen space, which leads to artifacts
such as over-smoothing, missing body parts, and temporal instability of
fine-scale detail, such as pose-dependent wrinkles in the clothing. In this
paper, we propose a novel human video synthesis method that approaches these
limiting factors by explicitly disentangling the learning of time-coherent
fine-scale details from the embedding of the human in 2D screen space. More
specifically, our method relies on the combination of two convolutional neural
networks (CNNs). Given the pose information, the first CNN predicts a dynamic
texture map that contains time-coherent high-frequency details, and the second
CNN conditions the generation of the final video on the temporally coherent
output of the first CNN. We demonstrate several applications of our approach,
such as human reenactment and novel view synthesis from monocular video, where
we show significant improvement over the state of the art both qualitatively
and quantitatively.
"
1845,Everybody's Talkin': Let Me Talk as You Want,"  We present a method to edit a target portrait footage by taking a sequence of
audio as input to synthesize a photo-realistic video. This method is unique
because it is highly dynamic. It does not assume a person-specific rendering
network yet capable of translating arbitrary source audio into arbitrary video
output. Instead of learning a highly heterogeneous and nonlinear mapping from
audio to the video directly, we first factorize each target video frame into
orthogonal parameter spaces, i.e., expression, geometry, and pose, via
monocular 3D face reconstruction. Next, a recurrent network is introduced to
translate source audio into expression parameters that are primarily related to
the audio content. The audio-translated expression parameters are then used to
synthesize a photo-realistic human subject in each video frame, with the
movement of the mouth regions precisely mapped to the source audio. The
geometry and pose parameters of the target human portrait are retained,
therefore preserving the context of the original video footage. Finally, we
introduce a novel video rendering network and a dynamic programming method to
construct a temporally coherent and photo-realistic video. Extensive
experiments demonstrate the superiority of our method over existing approaches.
Our method is end-to-end learnable and robust to voice variations in the source
audio.
"
1846,Interoperable GPU Kernels as Latency Improver for MEC,"  Mixed reality (MR) applications are expected to become common when 5G goes
mainstream. However, the latency requirements are challenging to meet due to
the resources required by video-based remoting of graphics, that is, decoding
video codecs. We propose an approach towards tackling this challenge: a
client-server implementation for transacting intermediate representation (IR)
between a mobile UE and a MEC server instead of video codecs and this way
avoiding video decoding. We demonstrate the ability to address latency
bottlenecks on edge computing workloads that transact graphics. We select
SPIR-V compatible GPU kernels as the intermediate representation. Our approach
requires know-how in GPU architecture and GPU domain-specific languages (DSLs),
but compared to video-based edge graphics, it decreases UE device delay by
sevenfold. Further, we find that due to low cold-start times on both UEs and
MEC servers, application migration can happen in milliseconds. We imply that
graphics-based location-aware applications, such as MR, can benefit from this
kind of approach.
"
1847,"A Variational Staggered Particle Framework for Incompressible
  Free-Surface Flows","  Smoothed particle hydrodynamics (SPH) has been extensively studied in
computer graphics to animate fluids with versatile effects. However, SPH still
suffers from two numerical difficulties: the particle deficiency problem, which
will deteriorate the simulation accuracy, and the particle clumping problem,
which usually leads to poor stability of particle simulations. We propose to
solve these two problems by developing an approximate projection method for
incompressible free-surface flows under a variational staggered particle
framework. After particle discretization, we first categorize all fluid
particles into four subsets. Then according to the classification, we propose
to solve the particle deficiency problem by analytically imposing free surface
boundary conditions on both the Laplacian operator and the source term. To
address the particle clumping problem, we propose to extend the Taylor-series
consistent pressure gradient model with kernel function correction and
semi-analytical boundary conditions. Compared to previous approximate
projection method [1], our incompressibility solver is stable under both
compressive and tensile stress states, no pressure clumping or iterative
density correction (e.g., a density constrained pressure approach) is necessary
to stabilize the solver anymore. Motivated by the Helmholtz free energy
functional, we additionally introduce an iterative particle shifting algorithm
to improve the accuracy. It significantly reduces particle splashes near the
free surface. Therefore, high-fidelity simulations of the formation and
fragmentation of liquid jets and sheets are obtained for both the two-jets and
milk-crown examples.
"
1848,Running on Raygun,"  With the introduction of Nvidia RTX hardware, ray tracing is now viable as a
general real time rendering technique for complex 3D scenes. Leveraging this
new technology, we present Raygun, an open source rendering, simulation, and
game engine focusing on simplicity, expandability, and the topic of ray tracing
realized through Nvidia's Vulkan ray tracing extension.
"
1849,MGCN: Descriptor Learning using Multiscale GCNs,"  We propose a novel framework for computing descriptors for characterizing
points on three-dimensional surfaces. First, we present a new non-learned
feature that uses graph wavelets to decompose the Dirichlet energy on a
surface. We call this new feature wavelet energy decomposition signature
(WEDS). Second, we propose a new multiscale graph convolutional network (MGCN)
to transform a non-learned feature to a more discriminative descriptor. Our
results show that the new descriptor WEDS is more discriminative than the
current state-of-the-art non-learned descriptors and that the combination of
WEDS and MGCN is better than the state-of-the-art learned descriptors. An
important design criterion for our descriptor is the robustness to different
surface discretizations including triangulations with varying numbers of
vertices. Our results demonstrate that previous graph convolutional networks
significantly overfit to a particular resolution or even a particular
triangulation, but MGCN generalizes well to different surface discretizations.
In addition, MGCN is compatible with previous descriptors and it can also be
used to improve the performance of other descriptors, such as the heat kernel
signature, the wave kernel signature, or the local point signature.
"
1850,An Automated Approach for the Discovery of Interoperability,"  In this article, we present an automated approach that would test for and
discover the interoperability of CAD systems based on the
approximately-invariant shape properties of their models. We further show that
exchanging models in standard format does not guarantee the preservation of
shape properties. Our analysis is based on utilizing queries in deriving the
shape properties and constructing the proxy models of the given CAD models [1].
We generate template files to accommodate the information necessary for the
property computations and proxy model constructions, and implement an
interoperability discovery program called DTest to execute the interoperability
testing. We posit that our method could be extended to interoperability testing
on CAD-to-CAE and/or CAD-to-CAM interactions by modifying the set of property
checks and providing the additional requirements that may emerge in CAE or CAM
applications.
"
1851,"Developing an Augmented Reality Tourism App through User-Centred Design
  (Extended Version)","  Augmented Reality (AR) bridges the gap between the physical and virtual
world. Through overlaying graphics on natural environments, users can immerse
themselves in a tailored environment. This offers great benefits to mobile
tourism, where points of interest (POIs) can be annotated on a smartphone
screen. While a variety of apps currently exist, usability issues can
discourage users from embracing AR. Interfaces can become cluttered with icons,
with POI occlusion posing further challenges. In this paper, we use
user-centred design (UCD) to develop an AR tourism app. We solicit requirements
through a synthesis of domain analysis, tourist observation and semi-structured
interviews. Whereas previous user-centred work has designed mock-ups, we
iteratively develop a full Android app. This includes overhead maps and route
navigation, in addition to a detailed AR browser. The final product is
evaluated by 20 users, who participate in a tourism task in a UK city. Users
regard the system as usable and intuitive, and suggest the addition of further
customisation. We finish by critically analysing the challenges of a
user-centred methodology.
"
1852,Rigidity Properties of the Blum Medial Axis,"  We consider the Blum medial axis of a region in $\mathbb R^n$ with piecewise
smooth boundary and examine its ""rigidity properties"", by which we mean
properties preserved under diffeomorphisms of the regions preserving the medial
axis. There are several possible versions of rigidity depending on what
features of the Blum medial axis we wish to retain. We use a form of the cross
ratio from projective geometry to show that in the case of four smooth sheets
of the medial axis meeting along a branching submanifold, the cross ratio
defines a function on the branching sheet which must be preserved under any
diffeomorphism of the medial axis with another. Second, we show in the generic
case, along a Y-branching submanifold that there are three cross ratios
involving the three limiting tangent planes of the three smooth sheets and each
of the hyperplanes defined by one of the radial lines and the tangent space to
the Y-branching submanifold at the point, which again must be preserved.
Moreover, the triple of cross ratios then locally uniquely determines the
angles between the smooth sheets. Third, we observe that for a diffeomorphism
of the region preserving the Blum medial axis and the infinitesimal directions
of the radial lines, the second derivative of the diffeomorphism at points of
the medial axis must satisfy a condition relating the radial shape operators
and hence the differential geometry of the boundaries at corresponding boundary
points.
"
1853,"Fast 3D Indoor Scene Synthesis with Discrete and Exact Layout Pattern
  Extraction","  We present a fast framework for indoor scene synthesis, given a room geometry
and a list of objects with learnt priors. Unlike existing data-driven
solutions, which often extract priors by co-occurrence analysis and statistical
model fitting, our method measures the strengths of spatial relations by tests
for complete spatial randomness (CSR), and extracts complex priors based on
samples with the ability to accurately represent discrete layout patterns. With
the extracted priors, our method achieves both acceleration and plausibility by
partitioning input objects into disjoint groups, followed by layout
optimization based on the Hausdorff metric. Extensive experiments show that our
framework is capable of measuring more reasonable relations among objects and
simultaneously generating varied arrangements in seconds.
"
1854,Non-Euclidean Virtual Reality IV: Sol,"  This article presents virtual reality software designed to explore the Sol
geometry. The simulation is available on 3-dimensional.space/sol.html
"
1855,"FibAR: Embedding Optical Fibers in 3D Printed Objects for Active Markers
  in Dynamic Projection Mapping","  This paper presents a novel active marker for dynamic projection mapping (PM)
that emits a temporal blinking pattern of infrared (IR) light representing its
ID. We used a multi-material three dimensional (3D) printer to fabricate a
projection object with optical fibers that can guide IR light from LEDs
attached on the bottom of the object. The aperture of an optical fiber is
typically very small; thus, it is unnoticeable to human observers under
projection and can be placed on a strongly curved part of a projection surface.
In addition, the working range of our system can be larger than previous
marker-based methods as the blinking patterns can theoretically be recognized
by a camera placed at a wide range of distances from markers. We propose an
automatic marker placement algorithm to spread multiple active markers over the
surface of a projection object such that its pose can be robustly estimated
using captured images from arbitrary directions. We also propose an
optimization framework for determining the routes of the optical fibers in such
a way that collisions of the fibers can be avoided while minimizing the loss of
light intensity in the fibers. Through experiments conducted using three
fabricated objects containing strongly curved surfaces, we confirmed that the
proposed method can achieve accurate dynamic PMs in a significantly wide
working range.
"
1856,"IlluminatedFocus: Vision Augmentation using Spatial Defocusing via Focal
  Sweep Eyeglasses and High-Speed Projector","  Aiming at realizing novel vision augmentation experiences, this paper
proposes the IlluminatedFocus technique, which spatially defocuses real-world
appearances regardless of the distance from the user's eyes to observed real
objects. With the proposed technique, a part of a real object in an image
appears blurred, while the fine details of the other part at the same distance
remain visible. We apply Electrically Focus-Tunable Lenses (ETL) as eyeglasses
and a synchronized high-speed projector as illumination for a real scene. We
periodically modulate the focal lengths of the glasses (focal sweep) at more
than 60 Hz so that a wearer cannot perceive the modulation. A part of the scene
to appear focused is illuminated by the projector when it is in focus of the
user's eyes, while another part to appear blurred is illuminated when it is out
of the focus. As the basis of our spatial focus control, we build mathematical
models to predict the range of distance from the ETL within which real objects
become blurred on the retina of a user. Based on the blur range, we discuss a
design guideline for effective illumination timing and focal sweep range. We
also model the apparent size of a real scene altered by the focal length
modulation. This leads to an undesirable visible seam between focused and
blurred areas. We solve this unique problem by gradually blending the two
areas. Finally, we demonstrate the feasibility of our proposal by implementing
various vision augmentation applications.
"
1857,"A comparison of mobile VR display running on an ordinary smartphone with
  standard PC display for P300-BCI stimulus presentation","  A brain-computer interface (BCI) based on electroencephalography (EEG) is a
promising technology for enhancing virtual reality (VR) applications-in
particular, for gaming. We focus on the so-called P300-BCI, a stable and
accurate BCI paradigm relying on the recognition of a positive event-related
potential (ERP) occurring in the EEG about 300 ms post-stimulation. We
implemented a basic version of such a BCI displayed on an ordinary and
affordable smartphone-based head-mounted VR device: that is, a mobile and
passive VR system (with no electronic components beyond the smartphone). The
mobile phone performed the stimuli presentation, EEG synchronization (tagging)
and feedback display. We compared the ERPs and the accuracy of the BCI on the
VR device with a traditional BCI running on a personal computer (PC). We also
evaluated the impact of subjective factors on the accuracy. The study was
within-subjects, with 21 participants and one session in each modality. No
significant difference in BCI accuracy was found between the PC and VR systems,
although the P200 ERP was significantly wider and larger in the VR system as
compared to the PC system.
"
1858,"Audio-Visual-Olfactory Resource Allocation for Tri-modal Virtual
  Environments","  Virtual Environments (VEs) provide the opportunity to simulate a wide range
of applications, from training to entertainment, in a safe and controlled
manner. For applications which require realistic representations of real world
environments, the VEs need to provide multiple, physically accurate sensory
stimuli. However, simulating all the senses that comprise the human sensory
system (HSS) is a task that requires significant computational resources. Since
it is intractable to deliver all senses at the highest quality, we propose a
resource distribution scheme in order to achieve an optimal perceptual
experience within the given computational budgets. This paper investigates
resource balancing for multi-modal scenarios composed of aural, visual and
olfactory stimuli. Three experimental studies were conducted. The first
experiment identified perceptual boundaries for olfactory computation. In the
second experiment, participants (N=25) were asked, across a fixed number of
budgets (M=5), to identify what they perceived to be the best visual, acoustic
and olfactory stimulus quality for a given computational budget. Results
demonstrate that participants tend to prioritise visual quality compared to
other sensory stimuli. However, as the budget size is increased, users prefer a
balanced distribution of resources with an increased preference for having
smell impulses in the VE. Based on the collected data, a quality prediction
model is proposed and its accuracy is validated against previously unused
budgets and an untested scenario in a third and final experiment.
"
1859,AnimePose: Multi-person 3D pose estimation and animation,"  3D animation of humans in action is quite challenging as it involves using a
huge setup with several motion trackers all over the person's body to track the
movements of every limb. This is time-consuming and may cause the person
discomfort in wearing exoskeleton body suits with motion sensors. In this work,
we present a trivial yet effective solution to generate 3D animation of
multiple persons from a 2D video using deep learning. Although significant
improvement has been achieved recently in 3D human pose estimation, most of the
prior works work well in case of single person pose estimation and multi-person
pose estimation is still a challenging problem. In this work, we firstly
propose a supervised multi-person 3D pose estimation and animation framework
namely AnimePose for a given input RGB video sequence. The pipeline of the
proposed system consists of various modules: i) Person detection and
segmentation, ii) Depth Map estimation, iii) Lifting 2D to 3D information for
person localization iv) Person trajectory prediction and human pose tracking.
Our proposed system produces comparable results on previous state-of-the-art 3D
multi-person pose estimation methods on publicly available datasets MuCo-3DHP
and MuPoTS-3D datasets and it also outperforms previous state-of-the-art human
pose tracking methods by a significant margin of 11.7% performance gain on MOTA
score on Posetrack 2018 dataset.
"
1860,Deep No-reference Tone Mapped Image Quality Assessment,"  The process of rendering high dynamic range (HDR) images to be viewed on
conventional displays is called tone mapping. However, tone mapping introduces
distortions in the final image which may lead to visual displeasure. To
quantify these distortions, we introduce a novel no-reference quality
assessment technique for these tone mapped images. This technique is composed
of two stages. In the first stage, we employ a convolutional neural network
(CNN) to generate quality aware maps (also known as distortion maps) from tone
mapped images by training it with the ground truth distortion maps. In the
second stage, we model the normalized image and distortion maps using an
Asymmetric Generalized Gaussian Distribution (AGGD). The parameters of the AGGD
model are then used to estimate the quality score using support vector
regression (SVR). We show that the proposed technique delivers competitive
performance relative to the state-of-the-art techniques. The novelty of this
work is its ability to visualize various distortions as quality maps
(distortion maps), especially in the no-reference setting, and to use these
maps as features to estimate the quality score of tone mapped images.
"
1861,Correction of Chromatic Aberration from a Single Image Using Keypoints,"  In this paper, we propose a method to correct for chromatic aberration in a
single photograph. Our method replicates what a user would do in a photo
editing program to account for this defect. We find matching keypoints in each
colour channel then align them as a user would.
"
1862,Bilinear Graph Neural Network with Neighbor Interactions,"  Graph Neural Network (GNN) is a powerful model to learn representations and
make predictions on graph data. Existing efforts on GNN have largely defined
the graph convolution as a weighted sum of the features of the connected nodes
to form the representation of the target node. Nevertheless, the operation of
weighted sum assumes the neighbor nodes are independent of each other, and
ignores the possible interactions between them. When such interactions exist,
such as the co-occurrence of two neighbor nodes is a strong signal of the
target node's characteristics, existing GNN models may fail to capture the
signal. In this work, we argue the importance of modeling the interactions
between neighbor nodes in GNN. We propose a new graph convolution operator,
which augments the weighted sum with pairwise interactions of the
representations of neighbor nodes. We term this framework as Bilinear Graph
Neural Network (BGNN), which improves GNN representation ability with bilinear
interactions between neighbor nodes. In particular, we specify two BGNN models
named BGCN and BGAT, based on the well-known GCN and GAT, respectively.
Empirical results on three public benchmarks of semi-supervised node
classification verify the effectiveness of BGNN -- BGCN (BGAT) outperforms GCN
(GAT) by 1.6% (1.5%) in classification accuracy.Codes are available at:
https://github.com/zhuhm1996/bgnn.
"
1863,SplitStreams: A Visual Metaphor for Evolving Hierarchies,"  The visualization of hierarchically structured data over time is an ongoing
challenge and several approaches exist trying to solve it. Techniques such as
animated or juxtaposed tree visualizations are not capable of providing a good
overview of the time series and lack expressiveness in conveying changes over
time. Nested streamgraphs provide a better understanding of the data evolution,
but lack the clear outline of hierarchical structures at a given timestep.
Furthermore, these approaches are often limited to static hierarchies or
exclude complex hierarchical changes in the data, limiting their use cases. We
propose a novel visual metaphor capable of providing a static overview of all
hierarchical changes over time, as well as clearly outlining the hierarchical
structure at each individual time step. Our method allows for smooth
transitions between tree maps and nested streamgraphs, enabling the exploration
of the trade-off between dynamic behavior and hierarchical structure. As our
technique handles topological changes of all types, it is suitable for a wide
range of applications. We demonstrate the utility of our method on several use
cases, evaluate it with a user study, and provide its full source code.
"
1864,Folding-based compression of point cloud attributes,"  Existing techniques to compress point cloud attributes leverage either
geometric or video-based compression tools. We explore a radically different
approach inspired by recent advances in point cloud representation learning.
Point clouds can be interpreted as 2D manifolds in 3D space. Specifically, we
fold a 2D grid onto a point cloud and we map attributes from the point cloud
onto the folded 2D grid using a novel optimized mapping method. This mapping
results in an image, which opens a way to apply existing image processing
techniques on point cloud attributes. However, as this mapping process is lossy
in nature, we propose several strategies to refine it so that attributes can be
mapped to the 2D grid with minimal distortion. Moreover, this approach can be
flexibly applied to point cloud patches in order to better adapt to local
geometric complexity. In this work, we consider point cloud attribute
compression; thus, we compress this image with a conventional 2D image codec.
Our preliminary results show that the proposed folding-based coding scheme can
already reach performance similar to the latest MPEG Geometry-based PCC (G-PCC)
codec.
"
1865,"Course notes Geometric Algebra for Computer Graphics, SIGGRAPH 2019","  What is the best representation for doing euclidean geometry on computers?
These notes from a SIGGRAPH 2019 short course entitled ""Geometric algebra for
computer graphics"" introduce projective geometric algebra (PGA) as a modern
framework for this task. PGA features: uniform representation of points, lines,
and planes; robust, parallel-safe join and meet operations; compact,
polymorphic syntax for euclidean formulas and constructions; a single intuitive
sandwich form for isometries; native support for automatic differentiation; and
tight integration of kinematics and rigid body mechanics. PGA includes vector,
quaternion, dual quaternion, and exterior algebras as sub-algebras, simplifying
the learning curve and transition path for experienced practitioners. On the
practical side, it can be efficiently implemented, while its rich syntax
enhances programming productivity. The basic ideas are introduced in the 2D
context and developed selectively for 3D. Advantages to traditional approaches
are collected in a table at the end. The article aims to be a self-contained
introduction for practitioners of euclidean geometry and includes numerous
examples, formulas, figures, and tables.
"
1866,Visualizing modular forms,"  We examine several currently used techniques for visualizing complex-valued
functions applied to modular forms. We plot several examples and study the
benefits and limitations of each technique. We then introduce a method of
visualization that can take advantage of colormaps in Python's matplotlib
library, describe an implementation, and give more examples. Much of this
discussion applies to general visualizations of complex-valued functions in the
plane.
"
1867,A Bounded Measure for Estimating the Benefit of Visualization,"  Information theory can be used to analyze the cost-benefit of visualization
processes. However, the current measure of benefit contains an unbounded term
that is neither easy to estimate nor intuitive to interpret. In this work, we
propose to revise the existing cost-benefit measure by replacing the unbounded
term with a bounded one. We examine a number of bounded measures that include
the Jenson-Shannon divergence and a new divergence measure formulated as part
of this work. We use visual analysis to support the multi-criteria comparison,
narrowing the search down to those options with better mathematical properties.
We apply those remaining options to two visualization case studies to
instantiate their uses in practical scenarios, while the collected real world
data further informs the selection of a bounded measure, which can be used to
estimate the benefit of visualization.
"
1868,A User-centered Approach for Optimizing Information Visualizations,"  The optimization of information visualizations is time consuming and
expensive. To reduce this we propose an improvement of existing optimization
approaches based on user-centered design, focusing on readability,
comprehensibility, and user satisfaction as optimization goals. The changes
comprise (1) a separate optimization of user interface and representation, (2)
a fully automated evaluation of the representation, and (3) qualitative user
studies for simultaneously creating and evaluating interface variants. On the
basis of these results we are able to find a local optimum of an information
visualization in an efficient way.
"
1869,Replacing Mobile Camera ISP with a Single Deep Learning Model,"  As the popularity of mobile photography is growing constantly, lots of
efforts are being invested now into building complex hand-crafted camera ISP
solutions. In this work, we demonstrate that even the most sophisticated ISP
pipelines can be replaced with a single end-to-end deep learning model trained
without any prior knowledge about the sensor and optics used in a particular
device. For this, we present PyNET, a novel pyramidal CNN architecture designed
for fine-grained image restoration that implicitly learns to perform all ISP
steps such as image demosaicing, denoising, white balancing, color and contrast
correction, demoireing, etc. The model is trained to convert RAW Bayer data
obtained directly from mobile camera sensor into photos captured with a
professional high-end DSLR camera, making the solution independent of any
particular mobile ISP implementation. To validate the proposed approach on the
real data, we collected a large-scale dataset consisting of 10 thousand
full-resolution RAW-RGB image pairs captured in the wild with the Huawei P20
cameraphone (12.3 MP Sony Exmor IMX380 sensor) and Canon 5D Mark IV DSLR. The
experiments demonstrate that the proposed solution can easily get to the level
of the embedded P20's ISP pipeline that, unlike our approach, is combining the
data from two (RGB + B/W) camera sensors. The dataset, pre-trained models and
codes used in this paper are available on the project website.
"
1870,"A New Exocentric Metaphor for Complex Path Following to Control a UAV
  Using Mixed Reality","  Teleoperation of Unmanned Aerial Vehicles (UAVs) has recently become an
noteworthly research topic in the field of human robot interaction. Each year,
a variety of devices is being studied to design adapted interface for diverse
purpose such as view taking, search and rescue operation or suveillance. New
interfaces have to be precise, simple and intuitive even for complex path
planning. Moreover, when teleoperation involves long distance control, user
needs to get proper feedbacks and avoid motion sickness. In order to overcome
all these challenges, a new interaction metaphor named DrEAM (Drone Exocentric
Advanced Metaphor) was designed. User can see the UAV he is controlling in a
virtual environment mapped to the real world. He can interact with it as a
simple object in a classical virtual world. An experiment was lead in order to
evaluate the perfomances of this metaphor, comparing performance of novice user
using either a direct-view joystick control or using DrEAM.
"
1871,Pointfilter: Point Cloud Filtering via Encoder-Decoder Modeling,"  Point cloud filtering is a fundamental problem in geometry modeling and
processing. Despite of significant advancement in recent years, the existing
methods still suffer from two issues: 1) they are either designed without
preserving sharp features or less robust in feature preservation; and 2) they
usually have many parameters and require tedious parameter tuning. In this
paper, we propose a novel deep learning approach that automatically and
robustly filters point clouds by removing noise and preserving their sharp
features. Our point-wise learning architecture consists of an encoder and a
decoder. The encoder directly takes points (a point and its neighbors) as
input, and learns a latent representation vector which goes through the decoder
to relate the ground-truth position with a displacement vector. The trained
neural network can automatically generate a set of clean points from a noisy
input. Extensive experiments show that our approach outperforms the
state-of-the-art deep learning techniques in terms of both visual quality and
quantitative error metrics. The source code and dataset can be found at
https://github.com/dongbo-BUAA-VR/Pointfilter.
"
1872,Why Do Line Drawings Work? A Realism Hypothesis,"  Why is it that we can recognize object identity and 3D shape from line
drawings, even though they do not exist in the natural world? This paper
hypothesizes that the human visual system perceives line drawings as if they
were approximately realistic images. Moreover, the techniques of line drawing
are chosen to accurately convey shape to a human observer. Several implications
and variants of this hypothesis are explored.
"
1873,"Analytic Marching: An Analytic Meshing Solution from Deep Implicit
  Surface Networks","  This paper studies a problem of learning surface mesh via implicit functions
in an emerging field of deep learning surface reconstruction, where implicit
functions are popularly implemented as multi-layer perceptrons (MLPs) with
rectified linear units (ReLU). To achieve meshing from learned implicit
functions, existing methods adopt the de-facto standard algorithm of marching
cubes; while promising, they suffer from loss of precision learned in the MLPs,
due to the discretization nature of marching cubes. Motivated by the knowledge
that a ReLU based MLP partitions its input space into a number of linear
regions, we identify from these regions analytic cells and analytic faces that
are associated with zero-level isosurface of the implicit function, and
characterize the theoretical conditions under which the identified analytic
faces are guaranteed to connect and form a closed, piecewise planar surface.
Based on our theorem, we propose a naturally parallelizable algorithm of
analytic marching, which marches among analytic cells to exactly recover the
mesh captured by a learned MLP. Experiments on deep learning mesh
reconstruction verify the advantages of our algorithm over existing ones.
"
1874,"Large-Scale Evaluation of Shape-Aware Neighborhood Weights and
  Neighborhood Sizes","  In this paper, we define and evaluate a weighting scheme for neighborhoods in
point sets. Our weighting takes the shape of the geometry, i.e. the normal
information, into account. This causes the obtained neighborhoods to be more
reliable in the sense that connectivity also depends on the orientation of the
point set. We utilize a sigmoid to define the weights based on the normal
variation. For an evaluation of the weighting scheme, we turn to a Shannon
entropy model for feature separation and rigorously prove its non-degeneracy
for our family of weights. Based on this model, we evaluate our weighting terms
on a large scale of both clean and real-world models. This evaluation provides
results regarding the choice of optimal parameters within our weighting scheme.
Furthermore, the large-scale evaluation also reveals that neighborhood sizes
should not be fixed globally when processing models. This is in contrast to
current general practice in the field of geometry processing.
"
1875,Jittering Samples using a kd-Tree Stratification,"  Monte Carlo sampling techniques are used to estimate high-dimensional
integrals that model the physics of light transport in virtual scenes for
computer graphics applications. These methods rely on the law of large numbers
to estimate expectations via simulation, typically resulting in slow
convergence. Their errors usually manifest as undesirable grain in the pictures
generated by image synthesis algorithms. It is well known that these errors
diminish when the samples are chosen appropriately. A well known technique for
reducing error operates by subdividing the integration domain, estimating
integrals in each \emph{stratum} and aggregating these values into a stratified
sampling estimate. Na\""{i}ve methods for stratification, based on a lattice
(grid) are known to improve the convergence rate of Monte Carlo, but require
samples that grow exponentially with the dimensionality of the domain.
  We propose a simple stratification scheme for $d$ dimensional hypercubes
using the kd-tree data structure. Our scheme enables the generation of an
arbitrary number of equal volume partitions of the rectangular domain, and $n$
samples can be generated in $O(n)$ time. Since we do not always need to
explicitly build a kd-tree, we provide a simple procedure that allows the
sample set to be drawn fully in parallel without any precomputation or storage,
speeding up sampling to $O(\log n)$ time per sample when executed on $n$ cores.
If the tree is implicitly precomputed ($O(n)$ storage) the parallelised run
time reduces to $O(1)$ on $n$ cores. In addition to these benefits, we provide
an upper bound on the worst case star-discrepancy for $n$ samples matching that
of lattice-based sampling strategies, which occur as a special case of our
proposed method. We use a number of quantitative and qualitative tests to
compare our method against state of the art samplers for image synthesis.
"
1876,"Quantitative Evaluation of Time-Dependent Multidimensional Projection
  Techniques","  Dimensionality reduction methods are an essential tool for multidimensional
data analysis, and many interesting processes can be studied as time-dependent
multivariate datasets. There are, however, few studies and proposals that
leverage on the concise power of expression of projections in the context of
dynamic/temporal data. In this paper, we aim at providing an approach to assess
projection techniques for dynamic data and understand the relationship between
visual quality and stability. Our approach relies on an experimental setup that
consists of existing techniques designed for time-dependent data and new
variations of static methods. To support the evaluation of these techniques, we
provide a collection of datasets that has a wide variety of traits that encode
dynamic patterns, as well as a set of spatial and temporal stability metrics
that assess the quality of the layouts. We present an evaluation of 11 methods,
10 datasets, and 12 quality metrics, and elect the best-suited methods for
projecting time-dependent multivariate data, exploring the design choices and
characteristics of each method. All our results are documented and made
available in a public repository to allow reproducibility of results.
"
1877,A Survey on Deep Geometry Learning: From a Representation Perspective,"  Researchers have now achieved great success on dealing with 2D images using
deep learning. In recent years, 3D computer vision and Geometry Deep Learning
gain more and more attention. Many advanced techniques for 3D shapes have been
proposed for different applications. Unlike 2D images, which can be uniformly
represented by regular grids of pixels, 3D shapes have various representations,
such as depth and multi-view images, voxel-based representation, point-based
representation, mesh-based representation, implicit surface representation,
etc. However, the performance for different applications largely depends on the
representation used, and there is no unique representation that works well for
all applications. Therefore, in this survey, we review recent development in
deep learning for 3D geometry from a representation perspective, summarizing
the advantages and disadvantages of different representations in different
applications. We also present existing datasets in these representations and
further discuss future research directions.
"
1878,Computational Design with Crowds,"  Computational design is aimed at supporting or automating design processes
using computational techniques. However, some classes of design tasks involve
criteria that are difficult to handle only with computers. For example, visual
design tasks seeking to fulfill aesthetic goals are difficult to handle purely
with computers. One promising approach is to leverage human computation; that
is, to incorporate human input into the computation process. Crowdsourcing
platforms provide a convenient way to integrate such human computation into a
working system.
  In this chapter, we discuss such computational design with crowds in the
domain of parameter tweaking tasks in visual design. Parameter tweaking is
often performed to maximize the aesthetic quality of designed objects.
Computational design powered by crowds can solve this maximization problem by
leveraging human computation. We discuss the opportunities and challenges of
computational design with crowds with two illustrative examples: (1) estimating
the objective function (specifically, preference learning from crowds' pairwise
comparisons) to facilitate interactive design exploration by a designer and (2)
directly searching for the optimal parameter setting that maximizes the
objective function (specifically, crowds-in-the-loop Bayesian optimization).
"
1879,"STW and SPIHT Wavelet compression using MATLAB wavelet Tool for Color
  Image","  Images can be represented by mathematical function using wavelets. Wavelet
can be manipulated (shrink/expand) by applying some values to its function. It
helps to localize the signals. Application of wavelet in images processing has
larger scope as proved. Image compression is one of the dimension. There are
various wavelet image compression techniques. This research paper focused on
comparison of only two techniques i.e. STW and SPIHT for color JPEG images.
"
1880,Real-Time Visualization in Non-Isotropic Geometries,"  Non-isotropic geometries are of interest to low-dimensional topologists,
physicists and cosmologists. However, they are challenging to comprehend and
visualize. We present novel methods of computing real-time native geodesic
rendering of non-isotropic geometries. Our methods can be applied not only to
visualization, but also are essential for potential applications in machine
learning and video games.
"
1881,Implicit Geometric Regularization for Learning Shapes,"  Representing shapes as level sets of neural networks has been recently proved
to be useful for different shape analysis and reconstruction tasks. So far,
such representations were computed using either: (i) pre-computed implicit
shape representations; or (ii) loss functions explicitly defined over the
neural level sets. In this paper we offer a new paradigm for computing high
fidelity implicit neural representations directly from raw data (i.e., point
clouds, with or without normal information). We observe that a rather simple
loss function, encouraging the neural network to vanish on the input point
cloud and to have a unit norm gradient, possesses an implicit geometric
regularization property that favors smooth and natural zero level set surfaces,
avoiding bad zero-loss solutions. We provide a theoretical analysis of this
property for the linear case, and show that, in practice, our method leads to
state of the art implicit neural representations with higher level-of-details
and fidelity compared to previous methods.
"
1882,"Audio-driven Talking Face Video Generation with Learning-based
  Personalized Head Pose","  Real-world talking faces often accompany with natural head movement. However,
most existing talking face video generation methods only consider facial
animation with fixed head pose. In this paper, we address this problem by
proposing a deep neural network model that takes an audio signal A of a source
person and a very short video V of a target person as input, and outputs a
synthesized high-quality talking face video with personalized head pose (making
use of the visual information in V), expression and lip synchronization (by
considering both A and V). The most challenging issue in our work is that
natural poses often cause in-plane and out-of-plane head rotations, which makes
synthesized talking face video far from realistic. To address this challenge,
we reconstruct 3D face animation and re-render it into synthesized frames. To
fine tune these frames into realistic ones with smooth background transition,
we propose a novel memory-augmented GAN module. By first training a general
mapping based on a publicly available dataset and fine-tuning the mapping using
the input short video of target person, we develop an effective strategy that
only requires a small number of frames (about 300 frames) to learn personalized
talking behavior including head pose. Extensive experiments and two user
studies show that our method can generate high-quality (i.e., personalized head
movements, expressions and good lip synchronization) talking face videos, which
are naturally looking with more distinguishing head movement effects than the
state-of-the-art methods.
"
1883,PolyGen: An Autoregressive Generative Model of 3D Meshes,"  Polygon meshes are an efficient representation of 3D geometry, and are of
central importance in computer graphics, robotics and games development.
Existing learning-based approaches have avoided the challenges of working with
3D meshes, instead using alternative object representations that are more
compatible with neural architectures and training approaches. We present an
approach which models the mesh directly, predicting mesh vertices and faces
sequentially using a Transformer-based architecture. Our model can condition on
a range of inputs, including object classes, voxels, and images, and because
the model is probabilistic it can produce samples that capture uncertainty in
ambiguous scenarios. We show that the model is capable of producing
high-quality, usable meshes, and establish log-likelihood benchmarks for the
mesh-modelling task. We also evaluate the conditional models on surface
reconstruction metrics against alternative methods, and demonstrate competitive
performance despite not training directly on this task.
"
1884,Image Stylization: From Predefined to Personalized,"  We present a framework for interactive design of new image stylizations using
a wide range of predefined filter blocks. Both novel and off-the-shelf image
filtering and rendering techniques are extended and combined to allow the user
to unleash their creativity to intuitively invent, modify, and tune new styles
from a given set of filters. In parallel to this manual design, we propose a
novel procedural approach that automatically assembles sequences of filters,
leading to unique and novel styles. An important aim of our framework is to
allow for interactive exploration and design, as well as to enable videos and
camera streams to be stylized on the fly. In order to achieve this real-time
performance, we use the \textit{Best Linear Adaptive Enhancement} (BLADE)
framework -- an interpretable shallow machine learning method that simulates
complex filter blocks in real time. Our representative results include over a
dozen styles designed using our interactive tool, a set of styles created
procedurally, and new filters trained with our BLADE approach.
"
1885,$G^1$ hole filling with S-patches made easy,"  S-patches have been around for 30 years, but they are seldom used, and are
considered more of a mathematical curiosity than a practical surface
representation. In this article a method is presented for automatically
creating S-patches of any degree or any number of sides, suitable for inclusion
in a curve network with tangential continuity to the adjacent surfaces. The
presentation aims at making the implementation straightforward; a few examples
conclude the paper.
"
1886,On the CAD-compatible conversion of S-patches,"  S-patches have many nice mathematical properties. It is known since their
first appearance, that any regular S-patch can be exactly converted into a
trimmed rational B\'ezier surface. This is a big advantage compared to other
multi-sided surface representations that have to be approximated for exporting
them into CAD/CAM systems. The actual conversion process, however, remained at
a theoretical level, with bits and pieces scattered in multiple publications.
In this paper we review the entirety of the algorithm, and investigate it from
a practical aspect.
"
1887,Computationally efficient transfinite patches with fullness control,"  Transfinite patches provide a simple and elegant solution to the problem of
representing non-four-sided continuous surfaces, which are useful in a variety
of applications, such as curve network based design. Real-time responsiveness
is essential in this context, and thus reducing the computation cost is an
important concern. The Midpoint Coons (MC) patch presented in this paper is a
fusion of two previous transfinite schemes, combining the speed of one with the
superior control mechanism of the other. This is achieved using a new
constrained parameterization based on generalized barycentric coordinates and
transfinite blending functions.
"
1888,A multi-sided generalization of the $C^0$ Coons patch,"  Most multi-sided transfinite surfaces require cross-derivatives at the
boundaries. Here we show a general $n$-sided patch that interpolates all
boundaries based on only positional information. The surface is a weighted sum
of $n$ Coons patches, using a parameterization based on Wachspress coordinates.
"
1889,Learning to Shadow Hand-drawn Sketches,"  We present a fully automatic method to generate detailed and accurate
artistic shadows from pairs of line drawing sketches and lighting directions.
We also contribute a new dataset of one thousand examples of pairs of line
drawings and shadows that are tagged with lighting directions. Remarkably, the
generated shadows quickly communicate the underlying 3D structure of the
sketched scene. Consequently, the shadows generated by our approach can be used
directly or as an excellent starting point for artists. We demonstrate that the
deep learning network we propose takes a hand-drawn sketch, builds a 3D model
in latent space, and renders the resulting shadows. The generated shadows
respect the hand-drawn lines and underlying 3D space and contain sophisticated
and accurate details, such as self-shadowing effects. Moreover, the generated
shadows contain artistic effects, such as rim lighting or halos appearing from
back lighting, that would be achievable with traditional 3D rendering methods.
"
1890,Deep Slow Motion Video Reconstruction with Hybrid Imaging System,"  Slow motion videos are becoming increasingly popular, but capturing
high-resolution videos at extremely high frame rates requires professional
high-speed cameras. To mitigate this problem, current techniques increase the
frame rate of standard videos through frame interpolation by assuming linear
object motion which is not valid in challenging cases. In this paper, we
address this problem using two video streams as input; an auxiliary video with
high frame rate and low spatial resolution, providing temporal information, in
addition to the standard main video with low frame rate and high spatial
resolution. We propose a two-stage deep learning system consisting of alignment
and appearance estimation that reconstructs high resolution slow motion video
from the hybrid video input. For alignment, we propose to compute flows between
the missing frame and two existing frames of the main video by utilizing the
content of the auxiliary video frames. For appearance estimation, we propose to
combine the warped and auxiliary frames using a context and occlusion aware
network. We train our model on synthetically generated hybrid videos and show
high-quality results on a variety of test scenes. To demonstrate practicality,
we show the performance of our system on two real dual camera setups with small
baseline.
"
1891,Exploiting Colorimetry for Fidelity in Data Visualization,"  Advances in multimodal characterization methods fuel a generation of
increasing immense hyper-dimensional datasets. Color mapping is employed for
conveying higher dimensional data in two-dimensional (2D) representations for
human consumption without relying on multiple projections. How one constructs
these color maps, however, critically affects how accurately one perceives
data. For simple scalar fields, perceptually uniform color maps and color
selection have been shown to improve data readability and interpretation across
research fields. Here we review core concepts underlying the design of
perceptually uniform color map and extend the concepts from scalar fields to
two-dimensional vector fields and three-component composition fields frequently
found in materials-chemistry research to enable high-fidelity visualization. We
develop the software tools PAPUC and CMPUC to enable researchers to utilize
these colorimetry principles and employ perceptually uniform color spaces for
rigorously meaningful color mapping of higher dimensional data representations.
Last, we demonstrate how these approaches deliver immediate improvements in
data readability and interpretation in microscopies and spectroscopies
routinely used in discerning materials structure, chemistry, and properties.
"
1892,MINA: Convex Mixed-Integer Programming for Non-Rigid Shape Alignment,"  We present a convex mixed-integer programming formulation for non-rigid shape
matching. To this end, we propose a novel shape deformation model based on an
efficient low-dimensional discrete model, so that finding a globally optimal
solution is tractable in (most) practical cases. Our approach combines several
favourable properties: it is independent of the initialisation, it is much more
efficient to solve to global optimality compared to analogous quadratic
assignment problem formulations, and it is highly flexible in terms of the
variants of matching problems it can handle. Experimentally we demonstrate that
our approach outperforms existing methods for sparse shape matching, that it
can be used for initialising dense shape matching methods, and we showcase its
flexibility on several examples.
"
1893,PF-Net: Point Fractal Network for 3D Point Cloud Completion,"  In this paper, we propose a Point Fractal Network (PF-Net), a novel
learning-based approach for precise and high-fidelity point cloud completion.
Unlike existing point cloud completion networks, which generate the overall
shape of the point cloud from the incomplete point cloud and always change
existing points and encounter noise and geometrical loss, PF-Net preserves the
spatial arrangements of the incomplete point cloud and can figure out the
detailed geometrical structure of the missing region(s) in the prediction. To
succeed at this task, PF-Net estimates the missing point cloud hierarchically
by utilizing a feature-points-based multi-scale generating network. Further, we
add up multi-stage completion loss and adversarial loss to generate more
realistic missing region(s). The adversarial loss can better tackle multiple
modes in the prediction. Our experiments demonstrate the effectiveness of our
method for several challenging point cloud completion tasks.
"
1894,"Characterisation of rational and NURBS developable surfaces in Computer
  Aided Design","  In this paper we provide a characterisation of rational developable surfaces
in terms of the blossoms of the bounding curves and three rational functions
$\Lambda$, $M$, $\nu$. Properties of developable surfaces are revised in this
framework. In particular, a closed algebraic formula for the edge of regression
of the surface is obtained in terms of the functions $\Lambda$, $M$, $\nu$,
which are closely related to the ones that appear in the standard decomposition
of the derivative of the parametrisation of one of the bounding curves in terms
of the director vector of the rulings and its derivative. It is also shown that
all rational developable surfaces can be described as the set of developable
surfaces which can be constructed with a constant $\Lambda$, $M$, $\nu$ . The
results are readily extended to rational spline developable surfaces.
"
1895,Learning to See: You Are What You See,"  The authors present a visual instrument developed as part of the creation of
the artwork Learning to See. The artwork explores bias in artificial neural
networks and provides mechanisms for the manipulation of specifically trained
for real-world representations. The exploration of these representations acts
as a metaphor for the process of developing a visual understanding and/or
visual vocabulary of the world. These representations can be explored and
manipulated in real time, and have been produced in such a way so as to reflect
specific creative perspectives that call into question the relationship between
how both artificial neural networks and humans may construct meaning.
"
1896,A Feature-aware SPH for Isotropic Unstructured Mesh Generation,"  In this paper, we present a feature-aware SPH method for the concurrent and
automated isotropic unstructured mesh generation. Two additional objectives are
achieved with the proposed method compared to the original SPH-based mesh
generator (Fu et al., 2019). First, a feature boundary correction term is
introduced to address the issue of incomplete kernel support at the boundary
vicinity. The mesh generation of feature curves, feature surfaces and volumes
can be handled concurrently without explicitly following a dimensional
sequence. Second, a two-phase model is proposed to characterize the
mesh-generation procedure by a feature-size-adaptation phase and a
mesh-quality-optimization phase. By proposing a new error measurement criterion
and an adaptive control system with two sets of simulation parameters, the
objectives of faster feature-size adaptation and local mesh-quality improvement
are merged into a consistent framework. The proposed method is validated with a
set of 2D and 3D numerical tests with different complexities and scales. The
results demonstrate that high-quality meshes are generated with a significant
speedup of convergence.
"
1897,A Hybrid Lagrangian-Eulerian Method for Topology Optimization,"  We propose LETO, a new hybrid Lagrangian-Eulerian method for topology
optimization. At the heart of LETO lies in a hybrid particle-grid Material
Point Method (MPM) to solve for elastic force equilibrium. LETO transfers
density information from freely movable Lagrangian carrier particles to a fixed
set of Eulerian quadrature points. The quadrature points act as MPM particles
embedded in a lower-resolution grid and enable sub-cell resolution of intricate
structures with a reduced computational cost. By treating both densities and
positions of the carrier particles as optimization variables, LETO
reparameterizes the Eulerian solution space of topology optimization in a
Lagrangian view. LETO also unifies the treatment for both linear and non-linear
elastic materials. In the non-linear deformation regime, the resulting scheme
naturally permits large deformation and buckling behaviors. Additionally, LETO
explores contact-awareness during optimization by incorporating a fictitious
domain-based contact model into the static equilibrium solver, resulting in the
discovery of novel structures. We conduct an extensive set of experiments. By
comparing against a representative Eulerian scheme, LETO's objective achieves
an average quantitative improvement of 20% (up to 40%) in 3D and 2% in 2D (up
to 12%). Qualitatively, LETO also discovers novel non-linear functional
structures and conducts self-contact-aware structural explorations.
"
1898,Optimizing JPEG Quantization for Classification Networks,"  Deep learning for computer vision depends on lossy image compression: it
reduces the storage required for training and test data and lowers transfer
costs in deployment. Mainstream datasets and imaging pipelines all rely on
standard JPEG compression. In JPEG, the degree of quantization of frequency
coefficients controls the lossiness: an 8 by 8 quantization table (Q-table)
decides both the quality of the encoded image and the compression ratio. While
a long history of work has sought better Q-tables, existing work either seeks
to minimize image distortion or to optimize for models of the human visual
system. This work asks whether JPEG Q-tables exist that are ""better"" for
specific vision networks and can offer better quality--size trade-offs than
ones designed for human perception or minimal distortion. We reconstruct an
ImageNet test set with higher resolution to explore the effect of JPEG
compression under novel Q-tables. We attempt several approaches to tune a
Q-table for a vision task. We find that a simple sorted random sampling method
can exceed the performance of the standard JPEG Q-table. We also use
hyper-parameter tuning techniques including bounded random search, Bayesian
optimization, and composite heuristic optimization methods. The new Q-tables we
obtained can improve the compression rate by 10% to 200% when the accuracy is
fixed, or improve accuracy up to $2\%$ at the same compression rate.
"
1899,DeLTra: Deep Light Transport for Projector-Camera Systems,"  In projector-camera systems, light transport models the propagation from
projector emitted radiance to camera-captured irradiance. In this paper, we
propose the first end-to-end trainable solution named Deep Light Transport
(DeLTra) that estimates radiometrically uncalibrated projector-camera light
transport. DeLTra is designed to have two modules: DepthToAtrribute and
ShadingNet. DepthToAtrribute explicitly learns rays, depth and normal, and then
estimates rough Phong illuminations. Afterwards, the CNN-based ShadingNet
renders photorealistic camera-captured image using estimated shading attributes
and rough Phong illuminations. A particular challenge addressed by DeLTra is
occlusion, for which we exploit epipolar constraint and propose a novel
differentiable direct light mask. Thus, it can be learned end-to-end along with
the other DeLTra modules. Once trained, DeLTra can be applied simultaneously to
three projector-camera tasks: image-based relighting, projector compensation
and depth/normal reconstruction. In our experiments, DeLTra shows clear
advantages over previous arts with promising quality and meanwhile being
practically convenient.
"
1900,"PoseNet3D: Learning Temporally Consistent 3D Human Pose via Knowledge
  Distillation","  Recovering 3D human pose from 2D joints is a highly unconstrained problem. We
propose a novel neural network framework, PoseNet3D, that takes 2D joints as
input and outputs 3D skeletons and SMPL body model parameters. By casting our
learning approach in a student-teacher framework, we avoid using any 3D data
such as paired/unpaired 3D data, motion capture sequences, depth images or
multi-view images during training. We first train a teacher network that
outputs 3D skeletons, using only 2D poses for training. The teacher network
distills its knowledge to a student network that predicts 3D pose in SMPL
representation. Finally, both the teacher and the student networks are jointly
fine-tuned in an end-to-end manner using temporal, self-consistency and
adversarial losses, improving the accuracy of each individual network. Results
on Human3.6M dataset for 3D human pose estimation demonstrate that our approach
reduces the 3D joint prediction error by 18% compared to previous unsupervised
methods. Qualitative results on in-the-wild datasets show that the recovered 3D
poses and meshes are natural, realistic, and flow smoothly over consecutive
frames.
"
1901,"STD-Net: Structure-preserving and Topology-adaptive Deformation Network
  for 3D Reconstruction from a Single Image","  3D reconstruction from a single view image is a long-standing prob-lem in
computer vision. Various methods based on different shape representations(such
as point cloud or volumetric representations) have been proposed. However,the
3D shape reconstruction with fine details and complex structures are still
chal-lenging and have not yet be solved. Thanks to the recent advance of the
deepshape representations, it becomes promising to learn the structure and
detail rep-resentation using deep neural networks. In this paper, we propose a
novel methodcalled STD-Net to reconstruct the 3D models utilizing the mesh
representationthat is well suitable for characterizing complex structure and
geometry details.To reconstruct complex 3D mesh models with fine details, our
method consists of(1) an auto-encoder network for recovering the structure of
an object with bound-ing box representation from a single image, (2) a
topology-adaptive graph CNNfor updating vertex position for meshes of complex
topology, and (3) an unifiedmesh deformation block that deforms the structural
boxes into structure-awaremeshed models. Experimental results on the images
from ShapeNet show that ourproposed STD-Net has better performance than other
state-of-the-art methods onreconstructing 3D objects with complex structures
and fine geometric details.
"
1902,"Style-compatible Object Recommendation for Multi-room Indoor Scene
  Synthesis","  Traditional indoor scene synthesis methods often take a two-step approach:
object selection and object arrangement. Current state-of-the-art object
selection approaches are based on convolutional neural networks (CNNs) and can
produce realistic scenes for a single room. However, they cannot be directly
extended to synthesize style-compatible scenes for multiple rooms with
different functions. To address this issue, we treat the object selection
problem as combinatorial optimization based on a Labeled LDA (L-LDA) model. We
first calculate occurrence probability distribution of object categories
according to a topic model, and then sample objects from each category
considering their function diversity along with style compatibility, while
regarding not only separate rooms, but also associations among rooms. User
study shows that our method outperforms the baselines by incorporating
multi-function and multi-room settings with style constraints, and sometimes
even produces plausible scenes comparable to those produced by professional
designers.
"
1903,"TailorNet: Predicting Clothing in 3D as a Function of Human Pose, Shape
  and Garment Style","  In this paper, we present TailorNet, a neural model which predicts clothing
deformation in 3D as a function of three factors: pose, shape and style
(garment geometry), while retaining wrinkle detail. This goes beyond prior
models, which are either specific to one style and shape, or generalize to
different shapes producing smooth results, despite being style specific. Our
hypothesis is that (even non-linear) combinations of examples smooth out high
frequency components such as fine-wrinkles, which makes learning the three
factors jointly hard. At the heart of our technique is a decomposition of
deformation into a high frequency and a low frequency component. While the
low-frequency component is predicted from pose, shape and style parameters with
an MLP, the high-frequency component is predicted with a mixture of shape-style
specific pose models. The weights of the mixture are computed with a narrow
bandwidth kernel to guarantee that only predictions with similar high-frequency
patterns are combined. The style variation is obtained by computing, in a
canonical pose, a subspace of deformation, which satisfies physical constraints
such as inter-penetration, and draping on the body. TailorNet delivers 3D
garments which retain the wrinkles from the physics based simulations (PBS) it
is learned from, while running more than 1000 times faster. In contrast to PBS,
TailorNet is easy to use and fully differentiable, which is crucial for
computer vision algorithms. Several experiments demonstrate TailorNet produces
more realistic results than prior work, and even generates temporally coherent
deformations on sequences of the AMASS dataset, despite being trained on static
poses from a different dataset. To stimulate further research in this
direction, we will make a dataset consisting of 55800 frames, as well as our
model publicly available at https://virtualhumans.mpi-inf.mpg.de/tailornet.
"
1904,Enabling Viewpoint Learning through Dynamic Label Generation,"  Optimal viewpoint prediction is an essential task in many computer
graphicsapplications. Unfortunately, common viewpoint qualities suffer from
majordrawbacks: dependency on clean surface meshes, which are not
alwaysavailable, insensitivity to upright orientation, and the lack of
closed-formexpressions, which requires a costly sampling process involving
rendering.We overcome these limitations through a 3D deep learning approach,
whichsolely exploits vertex coordinate information to predict optimal
viewpointsunder upright orientation, while reflecting both informational
content andhuman preference analysis. To enable this approach we propose a
dynamiclabel generation strategy, which resolves inherent label ambiguities
dur-ing training. In contrast to previous viewpoint prediction methods,
whichevaluate many rendered views, we directly learn on the 3D mesh, and
arethus independent from rendering. Furthermore, by exploiting
unstructuredlearning, we are independent of mesh discretization. We show how
the pro-posed technology enables learned prediction from model to viewpoints
fordifferent object categories and viewpoint qualities. Additionally, we
showthat prediction times are reduced from several minutes to a fraction of
asecond, as compared to viewpoint quality evaluation. We will release thecode
and training data, which will to our knowledge be the biggest viewpointquality
dataset available.
"
1905,Deep Vectorization of Technical Drawings,"  We present a new method for vectorization of technical line drawings, such as
floor plans, architectural drawings, and 2D CAD images. Our method includes (1)
a deep learning-based cleaning stage to eliminate the background and
imperfections in the image and fill in missing parts, (2) a transformer-based
network to estimate vector primitives, and (3) optimization procedure to obtain
the final primitive configurations. We train the networks on synthetic data,
renderings of vector line drawings, and manually vectorized scans of line
drawings. Our method quantitatively and qualitatively outperforms a number of
existing techniques on a collection of representative technical drawings.
"
1906,"Towards Photo-Realistic Virtual Try-On by Adaptively
  Generating$\leftrightarrow$Preserving Image Content","  Image visual try-on aims at transferring a target clothing image onto a
reference person, and has become a hot topic in recent years. Prior arts
usually focus on preserving the character of a clothing image (e.g. texture,
logo, embroidery) when warping it to arbitrary human pose. However, it remains
a big challenge to generate photo-realistic try-on images when large occlusions
and human poses are presented in the reference person. To address this issue,
we propose a novel visual try-on network, namely Adaptive Content Generating
and Preserving Network (ACGPN). In particular, ACGPN first predicts semantic
layout of the reference image that will be changed after try-on (e.g. long
sleeve shirt$\rightarrow$arm, arm$\rightarrow$jacket), and then determines
whether its image content needs to be generated or preserved according to the
predicted semantic layout, leading to photo-realistic try-on and rich clothing
details. ACGPN generally involves three major modules. First, a semantic layout
generation module utilizes semantic segmentation of the reference image to
progressively predict the desired semantic layout after try-on. Second, a
clothes warping module warps clothing images according to the generated
semantic layout, where a second-order difference constraint is introduced to
stabilize the warping process during training. Third, an inpainting module for
content fusion integrates all information (e.g. reference image, semantic
layout, warped clothes) to adaptively produce each semantic part of human body.
In comparison to the state-of-the-art methods, ACGPN can generate
photo-realistic images with much better perceptual quality and richer
fine-details.
"
1907,"Geodesic Distance Field-based Curved Layer Volume Decomposition for
  Multi-Axis Support-free Printing","  This paper presents a new curved layer volume decomposition method for
multi-axis support-free printing of freeform solid parts. Given a solid model
to be printed that is represented as a tetrahedral mesh, we first establish a
geodesic distance field embedded on the mesh, whose value at any vertex is the
geodesic distance to the base of the model. Next, the model is naturally
decomposed into curved layers by interpolating a number of iso-geodesic
distance surfaces (IGDSs). These IGDSs morph from bottom-up in an intrinsic and
smooth way owing to the nature of geodesics, which will be used as the curved
printing layers that are friendly to multi-axis printing. In addition, to cater
to the collision-free requirement and to improve the printing efficiency, we
also propose a printing sequence optimization algorithm for determining the
printing order of the IGDSs, which helps reduce the air-move path length. Ample
experiments in both computer simulation and physical printing are performed,
and the experimental results confirm the advantages of our method.
"
1908,Fusion-Aware Point Convolution for Online Semantic 3D Scene Segmentation,"  Online semantic 3D segmentation in company with real-time RGB-D
reconstruction poses special challenges such as how to perform 3D convolution
directly over the progressively fused 3D geometric data, and how to smartly
fuse information from frame to frame. We propose a novel fusion-aware 3D point
convolution which operates directly on the geometric surface being
reconstructed and exploits effectively the inter-frame correlation for high
quality 3D feature learning. This is enabled by a dedicated dynamic data
structure which organizes the online acquired point cloud with global-local
trees. Globally, we compile the online reconstructed 3D points into an
incrementally growing coordinate interval tree, enabling fast point insertion
and neighborhood query. Locally, we maintain the neighborhood information for
each point using an octree whose construction benefits from the fast query of
the global tree.Both levels of trees update dynamically and help the 3D
convolution effectively exploits the temporal coherence for effective
information fusion across RGB-D frames.
"
1909,Symmetry Detection of Occluded Point Cloud Using Deep Learning,"  Symmetry detection has been a classical problem in computer graphics, many of
which using traditional geometric methods. In recent years, however, we have
witnessed the arising deep learning changed the landscape of computer graphics.
In this paper, we aim to solve the symmetry detection of the occluded point
cloud in a deep-learning fashion. To the best of our knowledge, we are the
first to utilize deep learning to tackle such a problem. In such a deep
learning framework, double supervisions: points on the symmetry plane and
normal vectors are employed to help us pinpoint the symmetry plane. We
conducted experiments on the YCB- video dataset and demonstrate the efficacy of
our method.
"
1910,Interactive Neural Style Transfer with Artists,"  We present interactive painting processes in which a painter and various
neural style transfer algorithms interact on a real canvas. Understanding what
these algorithms' outputs achieve is then paramount to describe the creative
agency in our interactive experiments. We gather a set of paired
painting-pictures images and present a new evaluation methodology based on the
predictivity of neural style transfer algorithms. We point some algorithms'
instabilities and show that they can be used to enlarge the diversity and
pleasing oddity of the images synthesized by the numerous existing neural style
transfer algorithms. This diversity of images was perceived as a source of
inspiration for human painters, portraying the machine as a computational
catalyst.
"
1911,"Complexity of Shapes Embedded in ${\mathbb Z^n}$ with a Bias Towards
  Squares","  Shape complexity is a hard-to-quantify quality, mainly due to its relative
nature. Biased by Euclidean thinking, circles are commonly considered as the
simplest. However, their constructions as digital images are only
approximations to the ideal form. Consequently, complexity orders computed in
reference to circle are unstable. Unlike circles which lose their circleness in
digital images, squares retain their qualities. Hence, we consider squares
(hypercubes in $\mathbb Z^n$) to be the simplest shapes relative to which
complexity orders are constructed. Using the connection between $L^\infty$ norm
and squares we effectively encode squareness-adapted simplification through
which we obtain multi-scale complexity measure, where scale determines the
level of interest to the boundary. The emergent scale above which the effect of
a boundary feature (appendage) disappears is related to the ratio of the
contacting width of the appendage to that of the main body. We discuss what
zero complexity implies in terms of information repetition and constructibility
and what kind of shapes in addition to squares have zero complexity.
"
1912,Real-time Image Smoothing via Iterative Least Squares,"  Edge-preserving image smoothing is a fundamental procedure for many computer
vision and graphic applications. There is a tradeoff between the smoothing
quality and the processing speed: the high smoothing quality usually requires a
high computational cost which leads to the low processing speed. In this paper,
we propose a new global optimization based method, named iterative least
squares (ILS), for efficient edge-preserving image smoothing. Our approach can
produce high-quality results but at a much lower computational cost.
Comprehensive experiments demonstrate that the propose method can produce
results with little visible artifacts. Moreover, the computation of ILS can be
highly parallel, which can be easily accelerated through either multi-thread
computing or the GPU hardware. With the acceleration of a GTX 1080 GPU, it is
able to process images of 1080p resolution ($1920\times1080$) at the rate of
20fps for color images and 47fps for gray images. In addition, the ILS is
flexible and can be modified to handle more applications that require different
smoothing properties. Experimental results of several applications show the
effectiveness and efficiency of the proposed method. The code is available at
\url{https://github.com/wliusjtu/Real-time-Image-Smoothing-via-Iterative-Least-Squares}
"
1913,Inferring the Material Properties of Granular Media for Robotic Tasks,"  Granular media (e.g., cereal grains, plastic resin pellets, and pills) are
ubiquitous in robotics-integrated industries, such as agriculture,
manufacturing, and pharmaceutical development. This prevalence mandates the
accurate and efficient simulation of these materials. This work presents a
software and hardware framework that automatically calibrates a fast physics
simulator to accurately simulate granular materials by inferring material
properties from real-world depth images of granular formations (i.e., piles and
rings). Specifically, coefficients of sliding friction, rolling friction, and
restitution of grains are estimated from summary statistics of grain formations
using likelihood-free Bayesian inference. The calibrated simulator accurately
predicts unseen granular formations in both simulation and experiment;
furthermore, simulator predictions are shown to generalize to more complex
tasks, including using a robot to pour grains into a bowl, as well as to create
a desired pattern of piles and rings. Visualizations of the framework and
experiments can be viewed at https://youtu.be/OBvV5h2NMKA
"
1914,"Rotate-and-Render: Unsupervised Photorealistic Face Rotation from
  Single-View Images","  Though face rotation has achieved rapid progress in recent years, the lack of
high-quality paired training data remains a great hurdle for existing methods.
The current generative models heavily rely on datasets with multi-view images
of the same person. Thus, their generated results are restricted by the scale
and domain of the data source. To overcome these challenges, we propose a novel
unsupervised framework that can synthesize photo-realistic rotated faces using
only single-view image collections in the wild. Our key insight is that
rotating faces in the 3D space back and forth, and re-rendering them to the 2D
plane can serve as a strong self-supervision. We leverage the recent advances
in 3D face modeling and high-resolution GAN to constitute our building blocks.
Since the 3D rotation-and-render on faces can be applied to arbitrary angles
without losing details, our approach is extremely suitable for in-the-wild
scenarios (i.e. no paired data are available), where existing methods fall
short. Extensive experiments demonstrate that our approach has superior
synthesis quality as well as identity preservation over the state-of-the-art
methods, across a wide range of poses and domains. Furthermore, we validate
that our rotate-and-render framework naturally can act as an effective data
augmentation engine for boosting modern face recognition systems even on strong
baseline models.
"
1915,"Lighthouse: Predicting Lighting Volumes for Spatially-Coherent
  Illumination","  We present a deep learning solution for estimating the incident illumination
at any 3D location within a scene from an input narrow-baseline stereo image
pair. Previous approaches for predicting global illumination from images either
predict just a single illumination for the entire scene, or separately estimate
the illumination at each 3D location without enforcing that the predictions are
consistent with the same 3D scene. Instead, we propose a deep learning model
that estimates a 3D volumetric RGBA model of a scene, including content outside
the observed field of view, and then uses standard volume rendering to estimate
the incident illumination at any 3D location within that volume. Our model is
trained without any ground truth 3D data and only requires a held-out
perspective view near the input stereo pair and a spherical panorama taken
within each scene as supervision, as opposed to prior methods for
spatially-varying lighting estimation, which require ground truth scene
geometry for training. We demonstrate that our method can predict consistent
spatially-varying lighting that is convincing enough to plausibly relight and
insert highly specular virtual objects into real images.
"
1916,"PT2PC: Learning to Generate 3D Point Cloud Shapes from Part Tree
  Conditions","  3D generative shape modeling is a fundamental research area in computer
vision and interactive computer graphics, with many real-world applications.
This paper investigates the novel problem of generating 3D shape point cloud
geometry from a symbolic part tree representation. In order to learn such a
conditional shape generation procedure in an end-to-end fashion, we propose a
conditional GAN ""part tree""-to-""point cloud"" model (PT2PC) that disentangles
the structural and geometric factors. The proposed model incorporates the part
tree condition into the architecture design by passing messages top-down and
bottom-up along the part tree hierarchy. Experimental results and user study
demonstrate the strengths of our method in generating perceptually plausible
and diverse 3D point clouds, given the part tree condition. We also propose a
novel structural measure for evaluating if the generated shape point clouds
satisfy the part tree conditions.
"
1917,"Latent Space Subdivision: Stable and Controllable Time Predictions for
  Fluid Flow","  We propose an end-to-end trained neural networkarchitecture to robustly
predict the complex dynamics of fluid flows with high temporal stability. We
focus on single-phase smoke simulations in 2D and 3D based on the
incompressible Navier-Stokes (NS) equations, which are relevant for a wide
range of practical problems. To achieve stable predictions for long-term flow
sequences, a convolutional neural network (CNN) is trained for spatial
compression in combination with a temporal prediction network that consists of
stacked Long Short-Term Memory (LSTM) layers. Our core contribution is a novel
latent space subdivision (LSS) to separate the respective input quantities into
individual parts of the encoded latent space domain. This allows to
distinctively alter the encoded quantities without interfering with the
remaining latent space values and hence maximizes external control. By
selectively overwriting parts of the predicted latent space points, our
proposed method is capable to robustly predict long-term sequences of complex
physics problems. In addition, we highlight the benefits of a recurrent
training on the latent space creation, which is performed by the spatial
compression network.
"
1918,A Compact Spectral Descriptor for Shape Deformations,"  Modern product design in the engineering domain is increasingly driven by
computational analysis including finite-element based simulation, computational
optimization, and modern data analysis techniques such as machine learning. To
apply these methods, suitable data representations for components under
development as well as for related design criteria have to be found. While a
component's geometry is typically represented by a polygon surface mesh, it is
often not clear how to parametrize critical design properties in order to
enable efficient computational analysis. In the present work, we propose a
novel methodology to obtain a parameterization of a component's plastic
deformation behavior under stress, which is an important design criterion in
many application domains, for example, when optimizing the crash behavior in
the automotive context. Existing parameterizations limit computational analysis
to relatively simple deformations and typically require extensive input by an
expert, making the design process time intensive and costly. Hence, we propose
a way to derive a compact descriptor of deformation behavior that is based on
spectral mesh processing and enables a low-dimensional representation of also
complex deformations.We demonstrate the descriptor's ability to represent
relevant deformation behavior by applying it in a nearest-neighbor search to
identify similar simulation results in a filtering task. The proposed
descriptor provides a novel approach to the parametrization of geometric
deformation behavior and enables the use of state-of-the-art data analysis
techniques such as machine learning to engineering tasks concerned with plastic
deformation behavior.
"
1919,NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis,"  We present a method that achieves state-of-the-art results for synthesizing
novel views of complex scenes by optimizing an underlying continuous volumetric
scene function using a sparse set of input views. Our algorithm represents a
scene using a fully-connected (non-convolutional) deep network, whose input is
a single continuous 5D coordinate (spatial location $(x,y,z)$ and viewing
direction $(\theta, \phi)$) and whose output is the volume density and
view-dependent emitted radiance at that spatial location. We synthesize views
by querying 5D coordinates along camera rays and use classic volume rendering
techniques to project the output colors and densities into an image. Because
volume rendering is naturally differentiable, the only input required to
optimize our representation is a set of images with known camera poses. We
describe how to effectively optimize neural radiance fields to render
photorealistic novel views of scenes with complicated geometry and appearance,
and demonstrate results that outperform prior work on neural rendering and view
synthesis. View synthesis results are best viewed as videos, so we urge readers
to view our supplementary video for convincing comparisons.
"
1920,Cross-Shape Graph Convolutional Networks,"  We present a method that processes 3D point clouds by performing graph
convolution operations across shapes. In this manner, point descriptors are
learned by allowing interaction and propagation of feature representations
within a shape collection. To enable this form of non-local, cross-shape graph
convolution, our method learns a pairwise point attention mechanism indicating
the degree of interaction between points on different shapes. Our method also
learns to create a graph over shapes of an input collection whose edges connect
shapes deemed as useful for performing cross-shape convolution. The edges are
also equipped with learned weights indicating the compatibility of each shape
pair for cross-shape convolution. Our experiments demonstrate that this
interaction and propagation of point representations across shapes make them
more discriminative. In particular, our results show significantly improved
performance for 3D point cloud semantic segmentation compared to conventional
approaches, especially in cases with the limited number of training examples.
"
1921,Gaussian Curvature Filter on 3D Mesh,"  Minimizing Gaussian curvature of meshes is fundamentally important for
obtaining smooth and developable surfaces. However, there is a lack of
computationally efficient and robust Gaussian curvature optimization method. In
this paper, we present a simple yet effective method that can efficiently
reduce Gaussian curvature for 3D meshes. We first present the mathematical
foundation of our method, which states that for any point on a developable
surface there must be another point that lives on its tangent plane. Then,
based on this theoretical insight, we introduce a simple and robust implicit
Gaussian curvature optimization method named Gaussian Curvature Filter (GCF).
GCF implicitly minimizes Gaussian curvature without the need to explicitly
calculate the Gaussian curvature itself. GCF is highly efficient and is 20
times faster than the classical standard Gaussian curvature flow method. We
present extensive experiments to demonstrate that GCF significantly outperforms
state-of-the-art methods in minimizing Gaussian curvature, geometric feature
preserving smoothing and mesh noise removal. This method can be used in a large
range of applications that involve Gaussian curvature.
"
1922,Volumetric density-equalizing reference map with applications,"  The density-equalizing map, a technique developed for cartogram creation, has
been widely applied to data visualization but only for 2D applications. In this
work, we propose a novel method called the volumetric density-equalizing
reference map (VDERM) for computing density-equalizing map for volumetric
domains. Given a prescribed density distribution in a volumetric domain in
$\mathbb{R}^3$, the proposed method continuously deforms the domain, with
different volume elements enlarged or shrunk according to the density
distribution. With the aid of the proposed method, medical and sociological
data can be visualized via deformations of 3D objects. The method can also be
applied to adaptive remeshing and shape modeling. Furthermore, by exploiting
the time-dependent nature of the proposed method, applications to shape
morphing can be easily achieved. Experimental results are presented to
demonstrate the effectiveness of the proposed method.
"
1923,Rig-space Neural Rendering,"  Movie productions use high resolution 3d characters with complex proprietary
rigs to create the highest quality images possible for large displays.
Unfortunately, these 3d assets are typically not compatible with real-time
graphics engines used for games, mixed reality and real-time pre-visualization.
Consequently, the 3d characters need to be re-modeled and re-rigged for these
new applications, requiring weeks of work and artistic approval. Our solution
to this problem is to learn a compact image-based rendering of the original 3d
character, conditioned directly on the rig parameters. Our idea is to render
the character in many different poses and views, and to train a deep neural
network to render high resolution images, from the rig parameters directly.
Many neural rendering techniques have been proposed to render from 2d
skeletons, or geometry and UV maps. However these require manual work, and to
do not remain compatible with the animator workflow of manipulating rig
widgets, as well as the real-time game engine pipeline of interpolating rig
parameters. We extend our architecture to support dynamic re-lighting and
composition with other 3d objects in the scene. We designed a network that
efficiently generates multiple scene feature maps such as normals, depth,
albedo and mask, which are composed with other scene objects to form the final
image.
"
1924,"Multiview Neural Surface Reconstruction by Disentangling Geometry and
  Appearance","  In this work we address the challenging problem of multiview 3D surface
reconstruction. We introduce a neural network architecture that simultaneously
learns the unknown geometry, camera parameters, and a neural renderer that
approximates the light reflected from the surface towards the camera. The
geometry is represented as a zero level-set of a neural network, while the
neural renderer, derived from the rendering equation, is capable of
(implicitly) modeling a wide set of lighting conditions and materials. We
trained our network on real world 2D images of objects with different material
properties, lighting conditions, and noisy camera initializations from the DTU
MVS dataset. We found our model to produce state of the art 3D surface
reconstructions with high fidelity, resolution and detail.
"
1925,Neural Contours: Learning to Draw Lines from 3D Shapes,"  This paper introduces a method for learning to generate line drawings from 3D
models. Our architecture incorporates a differentiable module operating on
geometric features of the 3D model, and an image-based module operating on
view-based shape representations. At test time, geometric and view-based
reasoning are combined with the help of a neural module to create a line
drawing. The model is trained on a large number of crowdsourced comparisons of
line drawings. Experiments demonstrate that our method achieves significant
improvements in line drawing over the state-of-the-art when evaluated on
standard benchmarks, resulting in drawings that are comparable to those
produced by experienced human artists.
"
1926,Pose to Seat: Automated Design of Body-Supporting Surfaces,"  The design of functional seating furniture is a complicated process which
often requires extensive manual design effort and empirical evaluation. We
propose a computational design framework for pose-driven automated generation
of body-supports which are optimized for comfort of sitting. Given a human body
in a specified pose as input, our method computes an approximate pressure
distribution that also takes frictional forces and body torques into
consideration which serves as an objective measure of comfort. Utilizing this
information to find out where the body needs to be supported in order to
maintain comfort of sitting, our algorithm can create a supporting mesh suited
for a person in that specific pose. This is done in an automated fitting
process, using a template model capable of supporting a large variety of
sitting poses. The results can be used directly or can be considered as a
starting point for further interactive design.
"
1927,"Perspective picture from Visual Sphere: a new approach to image
  rasterization","  In this paper alternative method for real-time 3D model rasterization is
given. Surfaces are drawn in perspective-map space which acts as a virtual
camera lens. It can render single-pass 360{\deg} angle of view (AOV) image of
unlimited shape, view-directions count and unrestrained projection geometry
(e.g. direct lens distortion, projection mapping, curvilinear perspective),
natively aliasing-free. In conjunction to perspective vector map, visual-sphere
perspective model is proposed. A model capable of combining pictures from
sources previously incompatible, like fish-eye camera and wide-angle lens
picture. More so, method is proposed for measurement and simulation of a real
optical system variable no-parallax point (NPP). This study also explores
philosophical and historical aspects of picture perception and presents a guide
for perspective design.
"
1928,"Automatic Modelling of Human Musculoskeletal Ligaments -- Framework
  Overview and Model Quality Evaluation","  Accurate segmentation of connective soft tissues is still a challenging task,
which hinders the generation of corresponding geometric models for
biomechanical computations. Alternatively, one could predict ligament insertion
sites and then approximate the shapes, based on anatomical knowledge and
morphological studies. Here, we describe a corresponding integrated framework
for the automatic modelling of human musculoskeletal ligaments. We combine
statistical shape modelling with geometric algorithms to automatically identify
insertion sites, based on which geometric surface and volume meshes are
created. For demonstrating a clinical use case, the framework has been applied
to generate models of the interosseous membrane in the forearm. For the
adoption to the forearm anatomy, ligament insertion sites in the statistical
model were defined according to anatomical predictions following an approach
proposed in prior work. For evaluation we compared the generated sites, as well
as the ligament shapes, to data obtained from a cadaveric study, involving five
forearms with a total of 15 ligaments. Our framework permitted the creation of
3D models approximating ligaments' shapes with good fidelity. However, we found
that the statistical model trained with the state-of-the-art prediction of the
insertion sites was not always reliable. Using that model, average mean square
errors as well as Hausdorff distances of the meshes increased by more than one
order of magnitude, as compared to employing the known insertion locations of
the cadaveric study. Using the latter an average mean square error of 0.59 mm
and an average Hausdorff distance of less than 7 mm resulted, for the complete
set of ligaments. In conclusion, the presented approach for generating ligament
shapes from insertion points appears to be feasible but the detection of the
insertion sites with a SSM is too inaccurate.
"
1929,Deformable Style Transfer,"  Both geometry and texture are fundamental aspects of visual style. Existing
style transfer methods, however, primarily focus on texture, almost entirely
ignoring geometry. We propose deformable style transfer (DST), an
optimization-based approach that jointly stylizes the texture and geometry of a
content image to better match a style image. Unlike previous geometry-aware
stylization methods, our approach is neither restricted to a particular domain
(such as human faces), nor does it require training sets of matching
style/content pairs. We demonstrate our method on a diverse set of content and
style images including portraits, animals, objects, scenes, and paintings. Code
has been made publicly available at https://github.com/sunniesuhyoung/DST.
"
1930,Global Illumination of non-Euclidean spaces,"  This paper presents a path tracer algorithm to compute the global
illumination of non-Euclidean manifolds. We use the 3D torus as an example.
"
1931,"Virtual reality for 3D histology: multi-scale visualization of organs
  with interactive feature exploration","  Virtual reality (VR) enables data visualization in an immersive and engaging
manner, and it can be used for creating ways to explore scientific data. Here,
we use VR for visualization of 3D histology data, creating a novel interface
for digital pathology. Our contribution includes 3D modeling of a whole organ
and embedded objects of interest, fusing the models with associated
quantitative features and full resolution serial section patches, and
implementing the virtual reality application. Our VR application is multi-scale
in nature, covering two object levels representing different ranges of detail,
namely organ level and sub-organ level. In addition, the application includes
several data layers, including the measured histology image layer and multiple
representations of quantitative features computed from the histology. In this
interactive VR application, the user can set visualization properties, select
different samples and features, and interact with various objects. In this
work, we used whole mouse prostates (organ level) with prostate cancer tumors
(sub-organ objects of interest) as example cases, and included quantitative
histological features relevant for tumor biology in the VR model. Due to
automated processing of the histology data, our application can be easily
adopted to visualize other organs and pathologies from various origins. Our
application enables a novel way for exploration of high-resolution,
multidimensional data for biomedical research purposes, and can also be used in
teaching and researcher training.
"
1932,"A Hybrid Lagrangian/Eulerian Collocated Advection and Projection Method
  for Fluid Simulation","  We present a hybrid particle/grid approach for simulating incompressible
fluids on collocated velocity grids. We interchangeably use particle and grid
representations of transported quantities to balance efficiency and accuracy. A
novel Backward Semi-Lagrangian method is derived to improve accuracy of grid
based advection. Our approach utilizes the implicit formula associated with
solutions of Burgers' equation. We solve this equation using Newton's method
enabled by $C^1$ continuous grid interpolation. We enforce incompressibility
over collocated, rather than staggered grids. Our projection technique is
variational and designed for B-spline interpolation over regular grids where
multiquadratic interpolation is used for velocity and multilinear interpolation
for pressure. Despite our use of regular grids, we extend the variational
technique to allow for cut-cell definition of irregular flow domains for both
Dirichlet and free surface boundary conditions.
"
1933,"LIMP: Learning Latent Shape Representations with Metric Preservation
  Priors","  In this paper, we advocate the adoption of metric preservation as a powerful
prior for learning latent representations of deformable 3D shapes. Key to our
construction is the introduction of a geometric distortion criterion, defined
directly on the decoded shapes, translating the preservation of the metric on
the decoding to the formation of linear paths in the underlying latent space.
Our rationale lies in the observation that training samples alone are often
insufficient to endow generative models with high fidelity, motivating the need
for large training datasets. In contrast, metric preservation provides a
rigorous way to control the amount of geometric distortion incurring in the
construction of the latent space, leading in turn to synthetic samples of
higher quality. We further demonstrate, for the first time, the adoption of
differentiable intrinsic distances in the backpropagation of a geodesic loss.
Our geometric priors are particularly relevant in the presence of scarce
training data, where learning any meaningful latent structure can be especially
challenging. The effectiveness and potential of our generative model is
showcased in applications of style transfer, content generation, and shape
completion.
"
1934,Deep 3D Capture: Geometry and Reflectance from Sparse Multi-View Images,"  We introduce a novel learning-based method to reconstruct the high-quality
geometry and complex, spatially-varying BRDF of an arbitrary object from a
sparse set of only six images captured by wide-baseline cameras under
collocated point lighting. We first estimate per-view depth maps using a deep
multi-view stereo network; these depth maps are used to coarsely align the
different views. We propose a novel multi-view reflectance estimation network
architecture that is trained to pool features from these coarsely aligned
images and predict per-view spatially-varying diffuse albedo, surface normals,
specular roughness and specular albedo. We do this by jointly optimizing the
latent space of our multi-view reflectance network to minimize the photometric
error between images rendered with our predictions and the input images. While
previous state-of-the-art methods fail on such sparse acquisition setups, we
demonstrate, via extensive experiments on synthetic and real data, that our
method produces high-quality reconstructions that can be used to render
photorealistic images.
"
1935,PointGMM: a Neural GMM Network for Point Clouds,"  Point clouds are a popular representation for 3D shapes. However, they encode
a particular sampling without accounting for shape priors or non-local
information. We advocate for the use of a hierarchical Gaussian mixture model
(hGMM), which is a compact, adaptive and lightweight representation that
probabilistically defines the underlying 3D surface. We present PointGMM, a
neural network that learns to generate hGMMs which are characteristic of the
shape class, and also coincide with the input point cloud. PointGMM is trained
over a collection of shapes to learn a class-specific prior. The hierarchical
representation has two main advantages: (i) coarse-to-fine learning, which
avoids converging to poor local-minima; and (ii) (an unsupervised) consistent
partitioning of the input shape. We show that as a generative model, PointGMM
learns a meaningful latent space which enables generating consistent
interpolations between existing shapes, as well as synthesizing novel shapes.
We also present a novel framework for rigid registration using PointGMM, that
learns to disentangle orientation from structure of an input shape.
"
1936,Human Motion Transfer with 3D Constraints and Detail Enhancement,"  We propose a new method for realistic human motion transfer using a
generative adversarial network (GAN), which generates a motion video of a
target character imitating actions of a source character, while maintaining
high authenticity of the generated results. We tackle the problem by decoupling
and recombining the posture information and appearance information of both the
source and target characters. The innovation of our approach lies in the use of
the projection of a reconstructed 3D human model as the condition of GAN to
better maintain the structural integrity of transfer results in different
poses. We further introduce a detail enhancement net to enhance the details of
transfer results by exploiting the details in real source frames. Extensive
experiments show that our approach yields better results both qualitatively and
quantitatively than the state-of-the-art methods.
"
1937,"Label-Efficient Learning on Point Clouds using Approximate Convex
  Decompositions","  The problems of shape classification and part segmentation from 3D point
clouds have garnered increasing attention in the last few years. Both of these
problems, however, suffer from relatively small training sets, creating the
need for statistically efficient methods to learn 3D shape representations. In
this paper, we investigate the use of Approximate Convex Decompositions (ACD)
as a self-supervisory signal for label-efficient learning of point cloud
representations. We show that using ACD to approximate ground truth
segmentation provides excellent self-supervision for learning 3D point cloud
representations that are highly effective on downstream tasks. We report
improvements over the state-of-the-art for unsupervised representation learning
on the ModelNet40 shape classification dataset and significant gains in
few-shot part segmentation on the ShapeNetPart dataset.Code available at
https://github.com/matheusgadelha/PointCloudLearningACD
"
1938,"AvatarMe: Realistically Renderable 3D Facial Reconstruction
  ""in-the-wild""","  Over the last years, with the advent of Generative Adversarial Networks
(GANs), many face analysis tasks have accomplished astounding performance, with
applications including, but not limited to, face generation and 3D face
reconstruction from a single ""in-the-wild"" image. Nevertheless, to the best of
our knowledge, there is no method which can produce high-resolution
photorealistic 3D faces from ""in-the-wild"" images and this can be attributed to
the: (a) scarcity of available data for training, and (b) lack of robust
methodologies that can successfully be applied on very high-resolution data. In
this paper, we introduce AvatarMe, the first method that is able to reconstruct
photorealistic 3D faces from a single ""in-the-wild"" image with an increasing
level of detail. To achieve this, we capture a large dataset of facial shape
and reflectance and build on a state-of-the-art 3D texture and shape
reconstruction method and successively refine its results, while generating the
per-pixel diffuse and specular components that are required for realistic
rendering. As we demonstrate in a series of qualitative and quantitative
experiments, AvatarMe outperforms the existing arts by a significant margin and
reconstructs authentic, 4K by 6K-resolution 3D faces from a single
low-resolution image that, for the first time, bridges the uncanny valley.
"
1939,"Y-net: Multi-scale feature aggregation network with wavelet structure
  similarity loss function for single image dehazing","  Single image dehazing is the ill-posed two-dimensional signal reconstruction
problem. Recently, deep convolutional neural networks (CNN) have been
successfully used in many computer vision problems. In this paper, we propose a
Y-net that is named for its structure. This network reconstructs clear images
by aggregating multi-scale features maps. Additionally, we propose a Wavelet
Structure SIMilarity (W-SSIM) loss function in the training step. In the
proposed loss function, discrete wavelet transforms are applied repeatedly to
divide the image into differently sized patches with different frequencies and
scales. The proposed loss function is the accumulation of SSIM loss of various
patches with respective ratios. Extensive experimental results demonstrate that
the proposed Y-net with the W-SSIM loss function restores high-quality clear
images and outperforms state-of-the-art algorithms. Code and models are
available at https://github.com/dectrfov/Y-net.
"
1940,StyleRig: Rigging StyleGAN for 3D Control over Portrait Images,"  StyleGAN generates photorealistic portrait images of faces with eyes, teeth,
hair and context (neck, shoulders, background), but lacks a rig-like control
over semantic face parameters that are interpretable in 3D, such as face pose,
expressions, and scene illumination. Three-dimensional morphable face models
(3DMMs) on the other hand offer control over the semantic parameters, but lack
photorealism when rendered and only model the face interior, not other parts of
a portrait image (hair, mouth interior, background). We present the first
method to provide a face rig-like control over a pretrained and fixed StyleGAN
via a 3DMM. A new rigging network, RigNet is trained between the 3DMM's
semantic parameters and StyleGAN's input. The network is trained in a
self-supervised manner, without the need for manual annotations. At test time,
our method generates portrait images with the photorealism of StyleGAN and
provides explicit control over the 3D semantic parameters of the face.
"
1941,BCNet: Learning Body and Cloth Shape from A Single Image,"  In this paper, we consider the problem to automatically reconstruct garment
and body shapes from a single near-front view RGB image. To this end, we
propose a layered garment representation on top of SMPL and novelly make the
skinning weight of garment independent of the body mesh, which significantly
improves the expression ability of our garment model. Compared with existing
methods, our method can support more garment categories and recover more
accurate geometry. To train our model, we construct two large scale datasets
with ground truth body and garment geometries as well as paired color images.
Compared with single mesh or non-parametric representation, our method can
achieve more flexible control with separate meshes, makes applications like
re-pose, garment transfer, and garment texture mapping possible. Code and some
data is available at https://github.com/jby1993/BCNet.
"
1942,"SoftSMPL: Data-driven Modeling of Nonlinear Soft-tissue Dynamics for
  Parametric Humans","  We present SoftSMPL, a learning-based method to model realistic soft-tissue
dynamics as a function of body shape and motion. Datasets to learn such task
are scarce and expensive to generate, which makes training models prone to
overfitting. At the core of our method there are three key contributions that
enable us to model highly realistic dynamics and better generalization
capabilities than state-of-the-art methods, while training on the same data.
First, a novel motion descriptor that disentangles the standard pose
representation by removing subject-specific features; second, a
neural-network-based recurrent regressor that generalizes to unseen shapes and
motions; and third, a highly efficient nonlinear deformation subspace capable
of representing soft-tissue deformations of arbitrary shapes. We demonstrate
qualitative and quantitative improvements over existing methods and,
additionally, we show the robustness of our method on a variety of motion
capture databases.
"
1943,Two-shot Spatially-varying BRDF and Shape Estimation,"  Capturing the shape and spatially-varying appearance (SVBRDF) of an object
from images is a challenging task that has applications in both computer vision
and graphics. Traditional optimization-based approaches often need a large
number of images taken from multiple views in a controlled environment. Newer
deep learning-based approaches require only a few input images, but the
reconstruction quality is not on par with optimization techniques. We propose a
novel deep learning architecture with a stage-wise estimation of shape and
SVBRDF. The previous predictions guide each estimation, and a joint refinement
network later refines both SVBRDF and shape. We follow a practical mobile image
capture setting and use unaligned two-shot flash and no-flash images as input.
Both our two-shot image capture and network inference can run on mobile
hardware. We also create a large-scale synthetic training dataset with
domain-randomized geometry and realistic materials. Extensive experiments on
both synthetic and real-world datasets show that our network trained on a
synthetic dataset can generalize well to real-world images. Comparisons with
recent approaches demonstrate the superior performance of the proposed
approach.
"
1944,"PIFuHD: Multi-Level Pixel-Aligned Implicit Function for High-Resolution
  3D Human Digitization","  Recent advances in image-based 3D human shape estimation have been driven by
the significant improvement in representation power afforded by deep neural
networks. Although current approaches have demonstrated the potential in real
world settings, they still fail to produce reconstructions with the level of
detail often present in the input images. We argue that this limitation stems
primarily form two conflicting requirements; accurate predictions require large
context, but precise predictions require high resolution. Due to memory
limitations in current hardware, previous approaches tend to take low
resolution images as input to cover large spatial context, and produce less
precise (or low resolution) 3D estimates as a result. We address this
limitation by formulating a multi-level architecture that is end-to-end
trainable. A coarse level observes the whole image at lower resolution and
focuses on holistic reasoning. This provides context to an fine level which
estimates highly detailed geometry by observing higher-resolution images. We
demonstrate that our approach significantly outperforms existing
state-of-the-art techniques on single image human shape reconstruction by fully
leveraging 1k-resolution input images.
"
1945,Synchronizing Probability Measures on Rotations via Optimal Transport,"  We introduce a new paradigm, $\textit{measure synchronization}$, for
synchronizing graphs with measure-valued edges. We formulate this problem as
maximization of the cycle-consistency in the space of probability measures over
relative rotations. In particular, we aim at estimating marginal distributions
of absolute orientations by synchronizing the $\textit{conditional}$ ones,
which are defined on the Riemannian manifold of quaternions. Such graph
optimization on distributions-on-manifolds enables a natural treatment of
multimodal hypotheses, ambiguities and uncertainties arising in many computer
vision applications such as SLAM, SfM, and object pose estimation. We first
formally define the problem as a generalization of the classical rotation graph
synchronization, where in our case the vertices denote probability measures
over rotations. We then measure the quality of the synchronization by using
Sinkhorn divergences, which reduces to other popular metrics such as
Wasserstein distance or the maximum mean discrepancy as limit cases. We propose
a nonparametric Riemannian particle optimization approach to solve the problem.
Even though the problem is non-convex, by drawing a connection to the recently
proposed sparse optimization methods, we show that the proposed algorithm
converges to the global optimum in a special case of the problem under certain
conditions. Our qualitative and quantitative experiments show the validity of
our approach and we bring in new perspectives to the study of synchronization.
"
1946,Deformation-Aware 3D Model Embedding and Retrieval,"  We introduce a new problem of retrieving 3D models that are deformable to a
given query shape and present a novel deep deformation-aware embedding to solve
this retrieval task. 3D model retrieval is a fundamental operation for
recovering a clean and complete 3D model from a noisy and partial 3D scan.
However, given a finite collection of 3D shapes, even the closest model to a
query may not be satisfactory. This motivates us to apply 3D model deformation
techniques to adapt the retrieved model so as to better fit the query. Yet,
certain restrictions are enforced in most 3D deformation techniques to preserve
important features of the original model that prevent a perfect fitting of the
deformed model to the query. This gap between the deformed model and the query
induces asymmetric relationships among the models, which cannot be handled by
typical metric learning techniques. Thus, to retrieve the best models for
fitting, we propose a novel deep embedding approach that learns the asymmetric
relationships by leveraging location-dependent egocentric distance fields. We
also propose two strategies for training the embedding network. We demonstrate
that both of these approaches outperform other baselines in our experiments
with both synthetic and real data. Our project page can be found at
https://deformscan2cad.github.io/.
"
1947,Intrinsic Point Cloud Interpolation via Dual Latent Space Navigation,"  We present a learning-based method for interpolating and manipulating 3D
shapes represented as point clouds, that is explicitly designed to preserve
intrinsic shape properties. Our approach is based on constructing a dual
encoding space that enables shape synthesis and, at the same time, provides
links to the intrinsic shape information, which is typically not available on
point cloud data. Our method works in a single pass and avoids expensive
optimization, employed by existing techniques. Furthermore, the strong
regularization provided by our dual latent space approach also helps to improve
shape recovery in challenging settings from noisy point clouds across different
datasets. Extensive experiments show that our method results in more realistic
and smoother interpolations compared to baselines.
"
1948,Robust 3D Self-portraits in Seconds,"  In this paper, we propose an efficient method for robust 3D self-portraits
using a single RGBD camera. Benefiting from the proposed PIFusion and
lightweight bundle adjustment algorithm, our method can generate detailed 3D
self-portraits in seconds and shows the ability to handle subjects wearing
extremely loose clothes. To achieve highly efficient and robust reconstruction,
we propose PIFusion, which combines learning-based 3D recovery with volumetric
non-rigid fusion to generate accurate sparse partial scans of the subject.
Moreover, a non-rigid volumetric deformation method is proposed to continuously
refine the learned shape prior. Finally, a lightweight bundle adjustment
algorithm is proposed to guarantee that all the partial scans can not only
""loop"" with each other but also remain consistent with the selected live key
observations. The results and experiments show that the proposed method
achieves more robust and efficient 3D self-portraits compared with
state-of-the-art methods.
"
1949,GANSpace: Discovering Interpretable GAN Controls,"  This paper describes a simple technique to analyze Generative Adversarial
Networks (GANs) and create interpretable controls for image synthesis, such as
change of viewpoint, aging, lighting, and time of day. We identify important
latent directions based on Principal Components Analysis (PCA) applied either
in latent space or feature space. Then, we show that a large number of
interpretable controls can be defined by layer-wise perturbation along the
principal directions. Moreover, we show that BigGAN can be controlled with
layer-wise inputs in a StyleGAN-like manner. We show results on different GANs
trained on various datasets, and demonstrate good qualitative matches to edit
directions found through earlier supervised approaches.
"
1950,A Morphable Face Albedo Model,"  In this paper, we bring together two divergent strands of research:
photometric face capture and statistical 3D face appearance modelling. We
propose a novel lightstage capture and processing pipeline for acquiring
ear-to-ear, truly intrinsic diffuse and specular albedo maps that fully factor
out the effects of illumination, camera and geometry. Using this pipeline, we
capture a dataset of 50 scans and combine them with the only existing publicly
available albedo dataset (3DRFE) of 23 scans. This allows us to build the first
morphable face albedo model. We believe this is the first statistical analysis
of the variability of facial specular albedo maps. This model can be used as a
plug in replacement for the texture model of the Basel Face Model (BFM) or
FLAME and we make the model publicly available. We ensure careful spectral
calibration such that our model is built in a linear sRGB space, suitable for
inverse rendering of images taken by typical cameras. We demonstrate our model
in a state of the art analysis-by-synthesis 3DMM fitting pipeline, are the
first to integrate specular map estimation and outperform the BFM in albedo
reconstruction.
"
1951,Rethinking Spatially-Adaptive Normalization,"  Spatially-adaptive normalization is remarkably successful recently in
conditional semantic image synthesis, which modulates the normalized activation
with spatially-varying transformations learned from semantic layouts, to
preserve the semantic information from being washed away. Despite its
impressive performance, a more thorough understanding of the true advantages
inside the box is still highly demanded, to help reduce the significant
computation and parameter overheads introduced by these new structures. In this
paper, from a return-on-investment point of view, we present a deep analysis of
the effectiveness of SPADE and observe that its advantages actually come mainly
from its semantic-awareness rather than the spatial-adaptiveness. Inspired by
this point, we propose class-adaptive normalization (CLADE), a lightweight
variant that is not adaptive to spatial positions or layouts. Benefited from
this design, CLADE greatly reduces the computation cost while still being able
to preserve the semantic information during the generation. Extensive
experiments on multiple challenging datasets demonstrate that while the
resulting fidelity is on par with SPADE, its overhead is much cheaper than
SPADE. Take the generator for ADE20k dataset as an example, the extra parameter
and computation cost introduced by CLADE are only 4.57% and 0.07% while that of
SPADE are 39.21% and 234.73% respectively.
"
1952,Learning Generative Models of Shape Handles,"  We present a generative model to synthesize 3D shapes as sets of handles --
lightweight proxies that approximate the original 3D shape -- for applications
in interactive editing, shape parsing, and building compact 3D representations.
Our model can generate handle sets with varying cardinality and different types
of handles (Figure 1). Key to our approach is a deep architecture that predicts
both the parameters and existence of shape handles, and a novel similarity
measure that can easily accommodate different types of handles, such as cuboids
or sphere-meshes. We leverage the recent advances in semantic 3D annotation as
well as automatic shape summarizing techniques to supervise our approach. We
show that the resulting shape representations are intuitive and achieve
superior quality than previous state-of-the-art. Finally, we demonstrate how
our method can be used in applications such as interactive shape editing,
completion, and interpolation, leveraging the latent space learned by our model
to guide these tasks. Project page: http://mgadelha.me/shapehandles.
"
1953,Iconify: Converting Photographs into Icons,"  In this paper, we tackle a challenging domain conversion task between photo
and icon images. Although icons often originate from real object images (i.e.,
photographs), severe abstractions and simplifications are applied to generate
icon images by professional graphic designers. Moreover, there is no one-to-one
correspondence between the two domains, for this reason we cannot use it as the
ground-truth for learning a direct conversion function. Since generative
adversarial networks (GAN) can undertake the problem of domain conversion
without any correspondence, we test CycleGAN and UNIT to generate icons from
objects segmented from photo images. Our experiments with several image
datasets prove that CycleGAN learns sufficient abstraction and simplification
ability to generate icon-like images.
"
1954,Learning to Accelerate Decomposition for Multi-Directional 3D Printing,"  Multi-directional 3D printing has the capability of decreasing or eliminating
the need for support structures. Recent work proposed a beam-guided search
algorithm to find an optimized sequence of plane-clipping, which gives volume
decomposition of a given 3D model. Different printing directions are employed
in different regions to fabricate a model with tremendously less support (or
even no support in many cases).To obtain optimized decomposition, a large beam
width needs to be used in the search algorithm, leading to a very
time-consuming computation. In this paper, we propose a learning framework that
can accelerate the beam-guided search by using a smaller number of the original
beam width to obtain results with similar quality. Specifically, we use the
results of beam-guided search with large beam width to train a scoring function
for candidate clipping planes based on six newly proposed feature metrics. With
the help of these feature metrics, both the current and the sequence-dependent
information are captured by the neural network to score candidates of clipping.
As a result, we can achieve around 3x computational speed. We test and
demonstrate our accelerated decomposition on a large dataset of models for 3D
printing.
"
1955,"Multimodal Image Synthesis with Conditional Implicit Maximum Likelihood
  Estimation","  Many tasks in computer vision and graphics fall within the framework of
conditional image synthesis. In recent years, generative adversarial nets
(GANs) have delivered impressive advances in quality of synthesized images.
However, it remains a challenge to generate both diverse and plausible images
for the same input, due to the problem of mode collapse. In this paper, we
develop a new generic multimodal conditional image synthesis method based on
Implicit Maximum Likelihood Estimation (IMLE) and demonstrate improved
multimodal image synthesis performance on two tasks, single image
super-resolution and image synthesis from scene layouts. We make our
implementation publicly available.
"
1956,State of the Art on Neural Rendering,"  Efficient rendering of photo-realistic virtual worlds is a long standing
effort of computer graphics. Modern graphics techniques have succeeded in
synthesizing photo-realistic images from hand-crafted scene representations.
However, the automatic generation of shape, materials, lighting, and other
aspects of scenes remains a challenging problem that, if solved, would make
photo-realistic computer graphics more widely accessible. Concurrently,
progress in computer vision and machine learning have given rise to a new
approach to image synthesis and editing, namely deep generative models. Neural
rendering is a new and rapidly emerging field that combines generative machine
learning techniques with physical knowledge from computer graphics, e.g., by
the integration of differentiable rendering into network training. With a
plethora of applications in computer graphics and vision, neural rendering is
poised to become a new area in the graphics community, yet no survey of this
emerging field exists. This state-of-the-art report summarizes the recent
trends and applications of neural rendering. We focus on approaches that
combine classic computer graphics techniques with deep generative models to
obtain controllable and photo-realistic outputs. Starting with an overview of
the underlying computer graphics and machine learning concepts, we discuss
critical aspects of neural rendering approaches. This state-of-the-art report
is focused on the many important use cases for the described algorithms such as
novel view synthesis, semantic photo manipulation, facial and body reenactment,
relighting, free-viewpoint video, and the creation of photo-realistic avatars
for virtual and augmented reality telepresence. Finally, we conclude with a
discussion of the social implications of such technology and investigate open
research problems.
"
1957,Deep Manifold Prior,"  We present a prior for manifold structured data, such as surfaces of 3D
shapes, where deep neural networks are adopted to reconstruct a target shape
using gradient descent starting from a random initialization. We show that
surfaces generated this way are smooth, with limiting behavior characterized by
Gaussian processes, and we mathematically derive such properties for
fully-connected as well as convolutional networks. We demonstrate our method in
a variety of manifold reconstruction applications, such as point cloud
denoising and interpolation, achieving considerably better results against
competitive baselines while requiring no training data. We also show that when
training data is available, our method allows developing alternate
parametrizations of surfaces under the framework of AtlasNet, leading to a
compact network architecture and better reconstruction results on standard
image to shape reconstruction benchmarks.
"
1958,Multi-feature super-resolution network for cloth wrinkle synthesis,"  Existing physical cloth simulators suffer from expensive computation and
difficulties in tuning mechanical parameters to get desired wrinkling
behaviors. Data-driven methods provide an alternative solution. It typically
synthesizes cloth animation at a much lower computational cost, and also
creates wrinkling effects that highly resemble the much controllable training
data. In this paper we propose a deep learning based method for synthesizing
cloth animation with high resolution meshes. To do this we first create a
dataset for training: a pair of low and high resolution meshes are simulated
and their motions are synchronized. As a result the two meshes exhibit similar
large-scale deformation but different small wrinkles. Each simulated mesh pair
are then converted into a pair of low and high resolution ""images"" (a 2D array
of samples), with each sample can be interpreted as any of three features: the
displacement, the normal and the velocity. With these image pairs, we design a
multi-feature super-resolution (MFSR) network that jointly train an upsampling
synthesizer for the three features. The MFSR architecture consists of two key
components: a sharing module that takes multiple features as input to learn
low-level representations from corresponding super-resolution tasks
simultaneously; and task-specific modules focusing on various high-level
semantics. Frame-to-frame consistency is well maintained thanks to the proposed
kinematics-based loss function. Our method achieves realistic results at high
frame rates: 12-14 times faster than traditional physical simulation. We
demonstrate the performance of our method with various experimental scenes,
including a dressed character with sophisticated collisions.
"
1959,ARCH: Animatable Reconstruction of Clothed Humans,"  In this paper, we propose ARCH (Animatable Reconstruction of Clothed Humans),
a novel end-to-end framework for accurate reconstruction of animation-ready 3D
clothed humans from a monocular image. Existing approaches to digitize 3D
humans struggle to handle pose variations and recover details. Also, they do
not produce models that are animation ready. In contrast, ARCH is a learned
pose-aware model that produces detailed 3D rigged full-body human avatars from
a single unconstrained RGB image. A Semantic Space and a Semantic Deformation
Field are created using a parametric 3D body estimator. They allow the
transformation of 2D/3D clothed humans into a canonical space, reducing
ambiguities in geometry caused by pose variations and occlusions in training
data. Detailed surface geometry and appearance are learned using an implicit
function representation with spatial local features. Furthermore, we propose
additional per-pixel supervision on the 3D reconstruction using opacity-aware
differentiable rendering. Our experiments indicate that ARCH increases the
fidelity of the reconstructed humans. We obtain more than 50% lower
reconstruction errors for standard metrics compared to state-of-the-art methods
on public datasets. We also show numerous qualitative examples of animated,
high-quality reconstructed avatars unseen in the literature so far.
"
1960,"SESAME: Semantic Editing of Scenes by Adding, Manipulating or Erasing
  Objects","  Recent advances in image generation gave rise to powerful tools for semantic
image editing. However, existing approaches can either operate on a single
image or require an abundance of additional information. They are not capable
of handling the complete set of editing operations, that is addition,
manipulation or removal of semantic concepts. To address these limitations, we
propose SESAME, a novel generator-discriminator pair for Semantic Editing of
Scenes by Adding, Manipulating or Erasing objects. In our setup, the user
provides the semantic labels of the areas to be edited and the generator
synthesizes the corresponding pixels. In contrast to previous methods that
employ a discriminator that trivially concatenates semantics and image as an
input, the SESAME discriminator is composed of two input streams that
independently process the image and its semantics, using the latter to
manipulate the results of the former. We evaluate our model on a diverse set of
datasets and report state-of-the-art performance on two tasks: (a) image
manipulation and (b) image generation conditioned on semantic labels.
"
1961,"Cross-domain Correspondence Learning for Exemplar-based Image
  Translation","  We present a general framework for exemplar-based image translation, which
synthesizes a photo-realistic image from the input in a distinct domain (e.g.,
semantic segmentation mask, or edge map, or pose keypoints), given an exemplar
image. The output has the style (e.g., color, texture) in consistency with the
semantically corresponding objects in the exemplar. We propose to jointly learn
the crossdomain correspondence and the image translation, where both tasks
facilitate each other and thus can be learned with weak supervision. The images
from distinct domains are first aligned to an intermediate domain where dense
correspondence is established. Then, the network synthesizes images based on
the appearance of semantically corresponding patches in the exemplar. We
demonstrate the effectiveness of our approach in several image translation
tasks. Our method is superior to state-of-the-art methods in terms of image
quality significantly, with the image style faithful to the exemplar with
semantic consistency. Moreover, we show the utility of our method for several
applications
"
1962,MLCVNet: Multi-Level Context VoteNet for 3D Object Detection,"  In this paper, we address the 3D object detection task by capturing
multi-level contextual information with the self-attention mechanism and
multi-scale feature fusion. Most existing 3D object detection methods recognize
objects individually, without giving any consideration on contextual
information between these objects. Comparatively, we propose Multi-Level
Context VoteNet (MLCVNet) to recognize 3D objects correlatively, building on
the state-of-the-art VoteNet. We introduce three context modules into the
voting and classifying stages of VoteNet to encode contextual information at
different levels. Specifically, a Patch-to-Patch Context (PPC) module is
employed to capture contextual information between the point patches, before
voting for their corresponding object centroid points. Subsequently, an
Object-to-Object Context (OOC) module is incorporated before the proposal and
classification stage, to capture the contextual information between object
candidates. Finally, a Global Scene Context (GSC) module is designed to learn
the global scene context. We demonstrate these by capturing contextual
information at patch, object and scene levels. Our method is an effective way
to promote detection accuracy, achieving new state-of-the-art detection
performance on challenging 3D object detection datasets, i.e., SUN RGBD and
ScanNet. We also release our code at https://github.com/NUAAXQ/MLCVNet.
"
1963,NiLBS: Neural Inverse Linear Blend Skinning,"  In this technical report, we investigate efficient representations of
articulated objects (e.g. human bodies), which is an important problem in
computer vision and graphics. To deform articulated geometry, existing
approaches represent objects as meshes and deform them using ""skinning""
techniques. The skinning operation allows a wide range of deformations to be
achieved with a small number of control parameters. This paper introduces a
method to invert the deformations undergone via traditional skinning techniques
via a neural network parameterized by pose. The ability to invert these
deformations allows values (e.g., distance function, signed distance function,
occupancy) to be pre-computed at rest pose, and then efficiently queried when
the character is deformed. We leave empirical evaluation of our approach to
future work.
"
1964,"Line Art Correlation Matching Feature Transfer Network for Automatic
  Animation Colorization","  Automatic animation line art colorization is a challenging computer vision
problem, since the information of the line art is highly sparse and abstracted
and there exists a strict requirement for the color and style consistency
between frames. Recently, a lot of Generative Adversarial Network (GAN) based
image-to-image translation methods for single line art colorization have
emerged. They can generate perceptually appealing results conditioned on line
art images. However, these methods can not be adopted for the purpose of
animation colorization because there is a lack of consideration of the
in-between frame consistency. Existing methods simply input the previous
colored frame as a reference to color the next line art, which will mislead the
colorization due to the spatial misalignment of the previous colored frame and
the next line art especially at positions where apparent changes happen. To
address these challenges, we design a kind of correlation matching feature
transfer model (called CMFT) to align the colored reference feature in a
learnable way and integrate the model into an U-Net based generator in a
coarse-to-fine manner. This enables the generator to transfer the layer-wise
synchronized features from the deep semantic code to the content progressively.
Extension evaluation shows that CMFT model can effectively improve the
in-between consistency and the quality of colored frames especially when the
motion is intense and diverse.
"
1965,"Intuitive, Interactive Beard and Hair Synthesis with Generative Models","  We present an interactive approach to synthesizing realistic variations in
facial hair in images, ranging from subtle edits to existing hair to the
addition of complex and challenging hair in images of clean-shaven subjects. To
circumvent the tedious and computationally expensive tasks of modeling,
rendering and compositing the 3D geometry of the target hairstyle using the
traditional graphics pipeline, we employ a neural network pipeline that
synthesizes realistic and detailed images of facial hair directly in the target
image in under one second. The synthesis is controlled by simple and sparse
guide strokes from the user defining the general structural and color
properties of the target hairstyle. We qualitatively and quantitatively
evaluate our chosen method compared to several alternative approaches. We show
compelling interactive editing results with a prototype user interface that
allows novice users to progressively refine the generated image to match their
desired hairstyle, and demonstrate that our approach also allows for flexible
and high-fidelity scalp hair synthesis.
"
1966,MeshingNet: A New Mesh Generation Method based on Deep Learning,"  We introduce a novel approach to automatic unstructured mesh generation using
machine learning to predict an optimal finite element mesh for a previously
unseen problem. The framework that we have developed is based around training
an artificial neural network (ANN) to guide standard mesh generation software,
based upon a prediction of the required local mesh density throughout the
domain. We describe the training regime that is proposed, based upon the use of
\emph{a posteriori} error estimation, and discuss the topologies of the ANNs
that we have considered. We then illustrate performance using two standard test
problems, a single elliptic partial differential equation (PDE) and a system of
PDEs associated with linear elasticity. We demonstrate the effective generation
of high quality meshes for arbitrary polygonal geometries and a range of
material parameters, using a variety of user-selected error norms.
"
1967,Combinatorial 3D Shape Generation via Sequential Assembly,"  3D shape generation has drawn attention in computer vision and machine
learning since it opens an inspiring way to designing or creating new objects.
Existing methods, however, do not reflect an important aspect of human
generation processes in real life -- we often create a 3D shape by sequentially
assembling geometric primitives into a combinatorial configuration. In this
work, we propose a new 3D shape generation algorithm that aims to create such a
combinatorial configuration from a set of volumetric primitives. To tackle the
exponential growth of feasible combinations in terms of the number of
primitives, we adopt sequential model-based optimization. Our method
sequentially assembles primitives by exploiting and exploring adequate regions
that are constrained by the current primitive placements. The evaluation
function conveys global structure guidance for the assembling process to
follow. Experimental results demonstrate that our method successfully generates
combinatorial objects and simulates more realistic generation processes. We
also introduce a new dataset for combinatorial 3D shape generation.
"
1968,"Fast Differentiable Raycasting for Neural Rendering using Sphere-based
  Representations","  Differentiable rendering in combination with deep learning promises great
advantages: deep learning models can produce realistic scenes rapidly, while
differentiable rendering offers consistent scene representations and respective
gradients. However, gradient based optimization of classical mesh
representations is cumbersome because of the explicit topology encoding.
Moreover, complex scenes may need detailed geometric representation, requiring
many geometric primitives and a fast rendering operation. We propose to break
up the rendering process into multiple parts: (1) the scene representation, (2)
a differentiable geometry projection and (3) neural shading. While mature,
off-the-shelf models for scene representation and neural shading are widely
available, we propose pulsar as a general purpose differentiable geometry
engine tightly integrated with PyTorch. By replacing mesh representations with
sphere clouds for the scene representation, the operation is fast compared to
existing differentiable renderers and avoids problems with surface topology. It
provides gradients for the full scene parameterization, i.e., sphere positions,
colors, radiuses, opacity and the camera parameters. pulsar can execute many
times, up to orders of magnitudes faster than existing renderers and allows
real-time rendering and optimization of scenes with millions of spheres. It can
be used for 3D reconstruction, rendering and volumetric scene optimization.
"
1969,"A Simple, General, and GPU Friendly Method for Computing Dual Mesh and
  Iso-Surfaces of Adaptive Mesh Refinement (AMR) Data","  We propose a novel approach to extracting crack-free iso-surfaces from
Structured AMR data that is more general than previous techniques, is trivially
simple to implement, requires no information other than the list of AMR cells,
and works, in particular, for different AMR formats including octree AMR,
block-structured AMR with arbitrary level differences at level boundaries, and
AMR data that consist of individual cells without any existing grid structure.
We describe both the technique itself and a CUDA-based GPU implementation of
this technique, and evaluate it on several non-trivial AMR data sets.
"
1970,Developable B-spline surface generation from control rulings,"  An intuitive design method is proposed for generating developable ruled
B-spline surfaces from a sequence of straight line segments indicating the
surface shape. The first and last line segments are enforced to be the head and
tail ruling lines of the resulting surface while the interior lines are
required to approximate rulings on the resulting surface as much as possible.
This manner of developable surface design is conceptually similar to the
popular way of the freeform curve and surface design in the CAD community,
observing that a developable ruled surface is a single parameter family of
straight lines. This new design mode of the developable surface also provides
more flexibility than the widely employed way of developable surface design
from two boundary curves of the surface. The problem is treated by numerical
optimization methods with which a particular level of distance error is
allowed. We thus provide an effective tool for creating surfaces with a high
degree of developability when the input control rulings do not lie in exact
developable surfaces. We consider this ability as the superiority over
analytical methods in that it can deal with arbitrary design inputs and find
practically useful results.
"
1971,"Robust and efficient tool path generation for poor-quality triangular
  mesh surface machining","  This paper presents a new method to generate iso-scallop tool paths for
triangular mesh surfaces. With the popularity of 3D scanning techniques,
scanning-derived mesh surfaces have seen a significant increase in their
application to machining. Quite often, such mesh surfaces exhibit defects such
as noises, which differentiate them from the good-quality mesh surfaces
previous research work focuses on. To generate tool paths for such poor-quality
mesh surfaces, the primary challenge lies in robustness against the defects. In
this work, a robust tool path generation method is proposed for poor-quality
mesh surfaces. In addition to robustness, the method is quite efficient,
providing the benefit of faster iterations and improved integration between
scanning and machining. The fundamental principle of the method is to convert
the tool path generation problem to the heat diffusion problem that has robust
and efficient algorithms available. The effectiveness of the method will be
demonstrated by a series of case studies and comparisons.
"
1972,Pose Manipulation with Identity Preservation,"  This paper describes a new model which generates images in novel poses e.g.
by altering face expression and orientation, from just a few instances of a
human subject. Unlike previous approaches which require large datasets of a
specific person for training, our approach may start from a scarce set of
images, even from a single image. To this end, we introduce Character Adaptive
Identity Normalization GAN (CainGAN) which uses spatial characteristic features
extracted by an embedder and combined across source images. The identity
information is propagated throughout the network by applying conditional
normalization. After extensive adversarial training, CainGAN receives figures
of faces from a certain individual and produces new ones while preserving the
person's identity. Experimental results show that the quality of generated
images scales with the size of the input set used during inference.
Furthermore, quantitative measurements indicate that CainGAN performs better
compared to other methods when training data is limited.
"
1973,"Landmark Detection and 3D Face Reconstruction for Caricature using a
  Nonlinear Parametric Model","  Caricature is an artistic abstraction of the human face by distorting or
exaggerating certain facial features, while still retains a likeness with the
given face. Due to the large diversity of geometric and texture variations,
automatic landmark detection and 3D face reconstruction for caricature is a
challenging problem and has rarely been studied before. In this paper, we
propose the first automatic method for this task by a novel 3D approach. To
this end, we first build a dataset with various styles of 2D caricatures and
their corresponding 3D shapes, and then build a parametric model on vertex
based deformation space for 3D caricature face. Based on the constructed
dataset and the nonlinear parametric model, we propose a neural network based
method to regress the 3D face shape and orientation from the input 2D
caricature image. Ablation studies and comparison with baseline methods
demonstrate the effectiveness of our algorithm design, and extensive
experimental results demonstrate that our method works well for various
caricatures. Our constructed dataset, source code and trained model are
available at https://github.com/Juyong/CaricatureFace.
"
1974,Bringing Old Photos Back to Life,"  We propose to restore old photos that suffer from severe degradation through
a deep learning approach. Unlike conventional restoration tasks that can be
solved through supervised learning, the degradation in real photos is complex
and the domain gap between synthetic images and real old photos makes the
network fail to generalize. Therefore, we propose a novel triplet domain
translation network by leveraging real photos along with massive synthetic
image pairs. Specifically, we train two variational autoencoders (VAEs) to
respectively transform old photos and clean photos into two latent spaces. And
the translation between these two latent spaces is learned with synthetic
paired data. This translation generalizes well to real photos because the
domain gap is closed in the compact latent space. Besides, to address multiple
degradations mixed in one old photo, we design a global branch with a partial
nonlocal block targeting to the structured defects, such as scratches and dust
spots, and a local branch targeting to the unstructured defects, such as noises
and blurriness. Two branches are fused in the latent space, leading to improved
capability to restore old photos from multiple defects. The proposed method
outperforms state-of-the-art methods in terms of visual quality for old photos
restoration.
"
1975,"A scriptable, generative modelling system for dynamic 3D meshes","  We describe a flexible, script-based system for the procedural generation and
animation of 3D geometry. Dynamic triangular meshes are generated through the
real-time execution of scripts written in the Lua programming language. Tight
integration between the programming environment, runtime engine and graphics
visualisation enables a workflow between coding and visual results that
encourages experimentation and rapid prototyping. The system has been used
successfully to generate a variety of complex, dynamic organic forms including
complex branching structures, scalable symmetric manifolds and abstract organic
forms. We use examples in each of these areas to detail the main features of
the system, which include a set of flexible 3D mesh operations integrated with
a Lua-based L-system interpreter that creates geometry using generalised
cylinders.
"
1976,Spectrally Consistent UNet for High Fidelity Image Transformations,"  Convolutional Neural Networks (CNNs) are the current de-facto models used for
many imaging tasks due to their high learning capacity as well as their
architectural qualities. The ubiquitous UNet architecture provides an efficient
and multi-scale solution that combines local and global information. Despite
the success of UNet architectures, the use of upsampling layers can cause
artefacts. In this work, a method for assessing the structural biases of UNets
and the effects these have on the outputs is presented, characterising their
impact in the Fourier domain. A new upsampling module is proposed, based on a
novel use of the Guided Image Filter, that provides spectrally consistent
outputs when used in a UNet architecture, forming the Guided UNet (GUNet). The
GUNet architecture is applied and evaluated for example applications of inverse
tone mapping/dynamic range expansion and colourisation from grey-scale images
and is shown to provide higher fidelity outputs.
"
1977,"Through the Looking Glass: Neural 3D Reconstruction of Transparent
  Shapes","  Recovering the 3D shape of transparent objects using a small number of
unconstrained natural images is an ill-posed problem. Complex light paths
induced by refraction and reflection have prevented both traditional and deep
multiview stereo from solving this challenge. We propose a physically-based
network to recover 3D shape of transparent objects using a few images acquired
with a mobile phone camera, under a known but arbitrary environment map. Our
novel contributions include a normal representation that enables the network to
model complex light transport through local computation, a rendering layer that
models refractions and reflections, a cost volume specifically designed for
normal refinement of transparent shapes and a feature mapping based on
predicted normals for 3D point cloud reconstruction. We render a synthetic
dataset to encourage the model to learn refractive light transport across
different views. Our experiments show successful recovery of high-quality 3D
geometry for complex transparent shapes using as few as 5-12 natural images.
Code and data are publicly released.
"
1978,Single-View View Synthesis with Multiplane Images,"  A recent strand of work in view synthesis uses deep learning to generate
multiplane images (a camera-centric, layered 3D representation) given two or
more input images at known viewpoints. We apply this representation to
single-view view synthesis, a problem which is more challenging but has
potentially much wider application. Our method learns to predict a multiplane
image directly from a single image input, and we introduce scale-invariant view
synthesis for supervision, enabling us to train on online video. We show this
approach is applicable to several different datasets, that it additionally
generates reasonable depth maps, and that it learns to fill in content behind
the edges of foreground objects in background layers.
  Project page at https://single-view-mpi.github.io/.
"
1979,Deep Feature-preserving Normal Estimation for Point Cloud Filtering,"  Point cloud filtering, the main bottleneck of which is removing noise
(outliers) while preserving geometric features, is a fundamental problem in 3D
field. The two-step schemes involving normal estimation and position update
have been shown to produce promising results. Nevertheless, the current normal
estimation methods including optimization ones and deep learning ones, often
either have limited automation or cannot preserve sharp features. In this
paper, we propose a novel feature-preserving normal estimation method for point
cloud filtering with preserving geometric features. It is a learning method and
thus achieves automatic prediction for normals. For training phase, we first
generate patch based samples which are then fed to a classification network to
classify feature and non-feature points. We finally train the samples of
feature and non-feature points separately, to achieve decent results. Regarding
testing, given a noisy point cloud, its normals can be automatically estimated.
For further point cloud filtering, we iterate the above normal estimation and a
current position update algorithm for a few times. Various experiments
demonstrate that our method outperforms state-of-the-art normal estimation
methods and point cloud filtering techniques, in terms of both quality and
quantity.
"
1980,Multimodal Medical Volume Colorization from 2D Style,"  Colorization involves the synthesis of colors on a target image while
preserving structural content as well as the semantics of the target image.
This is a well-explored problem in 2D with many state-of-the-art solutions. We
propose a novel deep learning-based approach for the colorization of 3D medical
volumes. Our system is capable of directly mapping the colors of a 2D
photograph to a 3D MRI volume in real-time, producing a high-fidelity color
volume suitable for photo-realistic visualization. Since this work is first of
its kind, we discuss the full pipeline in detail and the challenges that it
brings for 3D medical data. The colorization of medical MRI volume also entails
modality conversion that highlights the robustness of our approach in handling
multi-modal data.
"
1981,"Tales from the Trenches: Developing sciview, a new 3D viewer for the
  ImageJ community","  ImageJ/Fiji is a widely-used tool in the biomedical community for performing
everyday image analysis tasks. However, its 3D viewer component (aptly named 3D
Viewer) has become dated and is no longer actively maintained. We set out to
create an alternative tool that not only brings modern concepts and APIs from
computer graphics to ImageJ, but is designed to be robust to long-term,
open-source development. To achieve this we divided the visualization logic
into two parts: the rendering framework, scenery, and the user-facing
application, sciview. In this paper we describe the development process and
design decisions made, putting an emphasis on sustainable development,
community building, and software engineering best practises. We highlight the
motivation for the Java Virtual Machine (JVM) as a target platform for
visualisation applications. We conclude by discussing the remaining milestones
and strategy for long-term sustainability.
"
1982,Deep Photon Mapping,"  Recently, deep learning-based denoising approaches have led to dramatic
improvements in low sample-count Monte Carlo rendering. These approaches are
aimed at path tracing, which is not ideal for simulating challenging light
transport effects like caustics, where photon mapping is the method of choice.
However, photon mapping requires very large numbers of traced photons to
achieve high-quality reconstructions. In this paper, we develop the first deep
learning-based method for particle-based rendering, and specifically focus on
photon density estimation, the core of all particle-based methods. We train a
novel deep neural network to predict a kernel function to aggregate photon
contributions at shading points. Our network encodes individual photons into
per-photon features, aggregates them in the neighborhood of a shading point to
construct a photon local context vector, and infers a kernel function from the
per-photon and photon local context features. This network is easy to
incorporate in many previous photon mapping methods (by simply swapping the
kernel density estimator) and can produce high-quality reconstructions of
complex global illumination effects like caustics with an order of magnitude
fewer photons compared to previous photon mapping methods.
"
1983,MakeItTalk: Speaker-Aware Talking-Head Animation,"  We present a method that generates expressive talking heads from a single
facial image with audio as the only input. In contrast to previous approaches
that attempt to learn direct mappings from audio to raw pixels or points for
creating talking faces, our method first disentangles the content and speaker
information in the input audio signal. The audio content robustly controls the
motion of lips and nearby facial regions, while the speaker information
determines the specifics of facial expressions and the rest of the talking head
dynamics. Another key component of our method is the prediction of facial
landmarks reflecting speaker-aware dynamics. Based on this intermediate
representation, our method is able to synthesize photorealistic videos of
entire talking heads with full range of motion and also animate artistic
paintings, sketches, 2D cartoon characters, Japanese mangas, stylized
caricatures in a single unified framework. We present extensive quantitative
and qualitative evaluation of our method, in addition to user studies,
demonstrating generated talking heads of significantly higher quality compared
to prior state-of-the-art.
"
1984,Graph2Plan: Learning Floorplan Generation from Layout Graphs,"  We introduce a learning framework for automated floorplan generation which
combines generative modeling using deep neural networks and user-in-the-loop
designs to enable human users to provide sparse design constraints. Such
constraints are represented by a layout graph. The core component of our
learning framework is a deep neural network, Graph2Plan, which converts a
layout graph, along with a building boundary, into a floorplan that fulfills
both the layout and boundary constraints. Given an input building boundary, we
allow a user to specify room counts and other layout constraints, which are
used to retrieve a set of floorplans, with their associated layout graphs, from
a database. For each retrieved layout graph, along with the input boundary,
Graph2Plan first generates a corresponding raster floorplan image, and then a
refined set of boxes representing the rooms. Graph2Plan is trained on RPLAN, a
large-scale dataset consisting of 80K annotated floorplans. The network is
mainly based on convolutional processing over both the layout graph, via a
graph neural network (GNN), and the input building boundary, as well as the
raster floorplan images, via conventional image convolution.
"
1985,"How the deprecation of Java applets affected online visualization
  frameworks -- a case study","  The JavaView visualization framework was designed at the end of the 1990s as
a software that provides - among other services - easy, interactive geometry
visualizations on web pages. We discuss how this and other design goals were
met and present several applications to highlight the contemporary use-cases of
the framework. However, as JavaView's easy web exports was based on Java
Applets, the deprecation of this technology disabled one main functionality of
the software. The remainder of the article uses JavaView as an example to
highlight the effects of changes in the underlying programming language on a
visualization toolkit. We discuss possible reactions of software to such
challenges, where the JavaView framework serves as an example to illustrate
development decisions. These discussions are guided by the broader, underlying
question as to how long it is sensible to maintain a software.
"
1986,"A framework for adaptive width control of dense contour-parallel
  toolpaths in fused deposition modeling","  3D printing techniques such as Fused Deposition Modeling (FDM) have enabled
the fabrication of complex geometry quickly and cheaply. High stiffness parts
are produced by filling the 2D polygons of consecutive layers with
contour-parallel extrusion toolpaths. Uniform width toolpaths consisting of
inward offsets from the outline polygons produce over- and underfill regions in
the center of the shape, which are especially detrimental to the mechanical
performance of thin parts. In order to fill shapes with arbitrary diameter
densely the toolpaths require adaptive width. Existing approaches for
generating toolpaths with adaptive width result in a large variation in widths,
which for some hardware systems is difficult to realize accurately. In this
paper we present a framework which supports multiple schemes to generate
toolpaths with adaptive width, by employing a function to decide the number of
beads and their widths. Furthermore, we propose a novel scheme which reduces
extreme bead widths, while limiting the number of altered toolpaths. We
statistically validate the effectiveness of our framework and this novel scheme
on a data set of representative 3D models, and physically validate it by
developing a technique, called back pressure compensation, for off-the-shelf
FDM systems to effectively realize adaptive width.
"
1987,TRAKO: Efficient Transmission of Tractography Data for Visualization,"  Fiber tracking produces large tractography datasets that are tens of
gigabytes in size consisting of millions of streamlines. Such vast amounts of
data require formats that allow for efficient storage, transfer, and
visualization. We present TRAKO, a new data format based on the Graphics Layer
Transmission Format (glTF) that enables immediate graphical and
hardware-accelerated processing. We integrate a state-of-the-art compression
technique for vertices, streamlines, and attached scalar and property data. We
then compare TRAKO to existing tractography storage methods and provide a
detailed evaluation on eight datasets. TRAKO can achieve data reductions of
over 28x without loss of statistical significance when used to replicate
analysis from previously published studies.
"
1988,"A First Principles Approach for Data-Efficient System Identification of
  Spring-Rod Systems via Differentiable Physics Engines","  We propose a novel differentiable physics engine for system identification of
complex spring-rod assemblies. Unlike black-box data-driven methods for
learning the evolution of a dynamical system and its parameters, we modularize
the design of our engine using a discrete form of the governing equations of
motion, similar to a traditional physics engine. We further reduce the
dimension from 3D to 1D for each module, which allows efficient learning of
system parameters using linear regression. As a side benefit, the regression
parameters correspond to physical quantities, such as spring stiffness or the
mass of the rod, making the pipeline explainable. The approach significantly
reduces the amount of training data required, and also avoids iterative
identification of data sampling and model training. We compare the performance
of the proposed engine with previous solutions, and demonstrate its efficacy on
tensegrity systems, such as NASA's icosahedron.
"
1989,Organic Narrative Charts,"  Storyline visualizations display the interactions of groups and entities and
their development over time. Existing approaches have successfully adopted the
general layout from hand-drawn illustrations to automatically create similar
depictions. Ward Shelley is the author of several diagrammatic paintings that
show the timeline of art-related subjects, such as Downtown Body, a history of
art scenes. His drawings include many stylistic elements that are not covered
by existing storyline visualizations, like links between entities, splits and
merges of streams, and tags or labels to describe the individual elements. We
present a visualization method that provides a visual mapping for the complex
relationships in the data, creates a layout for their display, and adopts a
similar styling of elements to imitate the artistic appeal of such
illustrations. We compare our results to the original drawings and provide an
open-source authoring tool prototype.
"
1990,Image Morphing with Perceptual Constraints and STN Alignment,"  In image morphing, a sequence of plausible frames are synthesized and
composited together to form a smooth transformation between given instances.
Intermediates must remain faithful to the input, stand on their own as members
of the set, and maintain a well-paced visual transition from one to the next.
In this paper, we propose a conditional GAN morphing framework operating on a
pair of input images. The network is trained to synthesize frames corresponding
to temporal samples along the transformation, and learns a proper shape prior
that enhances the plausibility of intermediate frames. While individual frame
plausibility is boosted by the adversarial setup, a special training protocol
producing sequences of frames, combined with a perceptual similarity loss,
promote smooth transformation over time. Explicit stating of correspondences is
replaced with a grid-based freeform deformation spatial transformer that
predicts the geometric warp between the inputs, instituting the smooth
geometric effect by bringing the shapes into an initial alignment. We provide
comparisons to classic as well as latent space morphing techniques, and
demonstrate that, given a set of images for self-supervision, our network
learns to generate visually pleasing morphing effects featuring believable
in-betweens, with robustness to changes in shape and texture, requiring no
correspondence annotation.
"
1991,"Informative Scene Decomposition for Crowd Analysis, Comparison and
  Simulation Guidance","  Crowd simulation is a central topic in several fields including graphics. To
achieve high-fidelity simulations, data has been increasingly relied upon for
analysis and simulation guidance. However, the information in real-world data
is often noisy, mixed and unstructured, making it difficult for effective
analysis, therefore has not been fully utilized. With the fast-growing volume
of crowd data, such a bottleneck needs to be addressed. In this paper, we
propose a new framework which comprehensively tackles this problem. It centers
at an unsupervised method for analysis. The method takes as input raw and noisy
data with highly mixed multi-dimensional (space, time and dynamics)
information, and automatically structure it by learning the correlations among
these dimensions. The dimensions together with their correlations fully
describe the scene semantics which consists of recurring activity patterns in a
scene, manifested as space flows with temporal and dynamics profiles. The
effectiveness and robustness of the analysis have been tested on datasets with
great variations in volume, duration, environment and crowd dynamics. Based on
the analysis, new methods for data visualization, simulation evaluation and
simulation guidance are also proposed. Together, our framework establishes a
highly automated pipeline from raw data to crowd analysis, comparison and
simulation guidance. Extensive experiments and evaluations have been conducted
to show the flexibility, versatility and intuitiveness of our framework.
"
1992,Visualization of Unsteady Flow Using Heat Kernel Signatures,"  We introduce a new technique to visualize complex flowing phenomena by using
concepts from shape analysis. Our approach uses techniques that examine the
intrinsic geometry of manifolds through their heat kernel, to obtain
representations of such manifolds that are isometry-invariant and multi-scale.
These representations permit us to compute heat kernel signatures of each point
on that manifold, and we can use these signatures as features for
classification and segmentation that identify points that have similar
structural properties.
  Our approach adapts heat kernel signatures to unsteady flows by formulating a
notion of shape where pathlines are observations of a manifold living in a
high-dimensional space.
  We use this space to compute and visualize heat kernel signatures associated
with each pathline.
  Besides being able to capture the structural features of a pathline, heat
kernel signatures allow the comparison of pathlines from different flow
datasets through a shape matching pipeline. We demonstrate the analytic power
of heat kernel signatures by comparing both (1) different timesteps from the
same unsteady flow as well as (2) flow datasets taken from ensemble simulations
with varying simulation parameters. Our analysis only requires the pathlines
themselves, and thus it does not utilize the underlying vector field directly.
We make minimal assumptions on the pathlines: while we assume they are sampled
from a continuous, unsteady flow, our computations can tolerate pathlines that
have varying density and potential unknown boundaries. We evaluate our approach
through visualizations of a variety of two-dimensional unsteady flows.
"
1993,Interactive Video Stylization Using Few-Shot Patch-Based Training,"  In this paper, we present a learning-based method to the keyframe-based video
stylization that allows an artist to propagate the style from a few selected
keyframes to the rest of the sequence. Its key advantage is that the resulting
stylization is semantically meaningful, i.e., specific parts of moving objects
are stylized according to the artist's intention. In contrast to previous style
transfer techniques, our approach does not require any lengthy pre-training
process nor a large training dataset. We demonstrate how to train an appearance
translation network from scratch using only a few stylized exemplars while
implicitly preserving temporal consistency. This leads to a video stylization
framework that supports real-time inference, parallel processing, and random
access to an arbitrary output frame. It can also merge the content from
multiple keyframes without the need to perform an explicit blending operation.
We demonstrate its practical utility in various interactive scenarios, where
the user paints over a selected keyframe and sees her style transferred to an
existing recorded sequence or a live video stream.
"
1994,"Real-World Textured Things: a Repository of Textured Models Generated
  with Modern Photo-Reconstruction Tools","  We are witnessing a proliferation of textured 3D models captured from the
real world with automatic photo-reconstruction tools. Digital 3D models of this
class come with a unique set of characteristics and defects -- especially
concerning their parametrization -- setting them starkly apart from 3D models
originating from other, more traditional, sources. We study this class of 3D
models by collecting a significant number of representatives and quantitatively
evaluating their quality according to several metrics. These include a new
invariant metric we design to assess the fragmentation of the UV map, one of
the main weaknesses hindering the usability of these models. Our results back
the widely shared notion that such models are not fit for direct use in
downstream applications (such as videogames), and require challenging
processing steps. Regrettably, existing automatic geometry processing tools are
not always up to the task: for example, we verify that available tools for UV
optimization often fail due mesh inconsistencies, geometric and topological
noise, excessive resolution, or other factors; moreover, even when an output is
produced, it is rarely a significant improvement over the input (according to
the aforementioned measures). Therefore, we argue that further advancements are
required specifically targeted at this class of models. Towards this goal, we
share the models we collected in the form of a new public repository,
Real-World Textured Things (RWTT), a benchmark to systematic field-test and
compare algorithms. RWTT consists of 568 carefully selected textured 3D models
representative of all the main modern off-the-shelf photo-reconstruction tools.
The repository is available at http://texturedmesh.isti.cnr.it/ and is
browsable by metadata collected during experiments, and comes with a tool,
TexMetro, providing the same set of measures for generic UV mapped datasets.
"
1995,Levitating Rigid Objects with Hidden Support Structures,"  We propose a novel algorithm to efficiently generate hidden structures to
support arrangements of floating rigid objects. Our optimization finds a small
set of rods and wires between objects and each other or a supporting surface
(e.g., wall or ceiling) that hold all objects in force and torque equilibrium.
Our objective function includes a sparsity inducing total volume term and a
linear visibility term based on efficiently pre-computed Monte-Carlo
integration, to encourage solutions that are as-hidden-as-possible. The
resulting optimization is convex and the global optimum can be efficiently
recovered via a linear program. Our representation allows for a
user-controllable mixture of tension-, compression-, and bending-resistant rods
or tension-only wires. We explore applications to theatre set design, museum
exhibit curation, and other artistic endeavours.
"
1996,Computational Steering of Geometrically Sensitive Simulations,"  In the context of high-performance finite element analysis, the cost of
iteratively modifying a computational domain via re-meshing and restarting the
analysis becomes time prohibitive as the size of simulations increases. In this
paper, we demonstrate a new interactive simulation pipeline targeting
high-performance fluid dynamics simulations where the computational domain is
modified in situ, that is, while the simulation is ongoing. This pipeline is
designed to be modular so that it may interface with any existing finite
element simulation framework. A server-client architecture is employed to
manage simulation mesh data existing on a high performance computing resource
while user-prescribed geometric modifications take place on a separate
workstation. We employ existing in situ visualization techniques to rapidly
inform the user of simulation progression, enabling computational steering. By
expressing the simulation domain in a reduced fashion on the client
application, this pipeline manages highly refined finite element simulation
domains on the server while maintaining good performance on the client
application.
"
1997,"Bionic Tracking: Using Eye Tracking to Track Biological Cells in Virtual
  Reality","  We present Bionic Tracking, a novel method for solving biological cell
tracking problems with eye tracking in virtual reality using commodity
hardware. Using gaze data, and especially smooth pursuit eye movements, we are
able to track cells in time series of 3D volumetric datasets. The problem of
tracking cells is ubiquitous in developmental biology, where large volumetric
microscopy datasets are acquired on a daily basis, often comprising hundreds or
thousands of time points that span hours or days. The image data, however, is
only a means to an end, and scientists are often interested in the
reconstruction of cell trajectories and cell lineage trees. Reliably tracking
cells in crowded three-dimensional space over many timepoints remains an open
problem, and many current approaches rely on tedious manual annotation and
curation. In our Bionic Tracking approach, we substitute the usual 2D
point-and-click annotation to track cells with eye tracking in a virtual
reality headset, where users simply have to follow a cell with their eyes in 3D
space in order to track it. We detail the interaction design of our approach
and explain the graph-based algorithm used to connect different time points,
also taking occlusion and user distraction into account. We demonstrate our
cell tracking method using the example of two different biological datasets.
Finally, we report on a user study with seven cell tracking experts,
demonstrating the benefits of our approach over manual point-and-click
tracking.
"
1998,Code Replicability in Computer Graphics,"  Being able to duplicate published research results is an important process of
conducting research whether to build upon these findings or to compare with
them. This process is called ""replicability"" when using the original authors'
artifacts (e.g., code), or ""reproducibility"" otherwise (e.g., re-implementing
algorithms). Reproducibility and replicability of research results have gained
a lot of interest recently with assessment studies being led in various fields,
and they are often seen as a trigger for better result diffusion and
transparency. In this work, we assess replicability in Computer Graphics, by
evaluating whether the code is available and whether it works properly. As a
proxy for this field we compiled, ran and analyzed 151 codes out of 374 papers
from 2014, 2016 and 2018 SIGGRAPH conferences. This analysis shows a clear
increase in the number of papers with available and operational research codes
with a dependency on the subfields, and indicates a correlation between code
replicability and citation count. We further provide an interactive tool to
explore our results and evaluation data.
"
1999,RigNet: Neural Rigging for Articulated Characters,"  We present RigNet, an end-to-end automated method for producing animation
rigs from input character models. Given an input 3D model representing an
articulated character, RigNet predicts a skeleton that matches the animator
expectations in joint placement and topology. It also estimates surface skin
weights based on the predicted skeleton. Our method is based on a deep
architecture that directly operates on the mesh representation without making
assumptions on shape class and structure. The architecture is trained on a
large and diverse collection of rigged models, including their mesh, skeletons
and corresponding skin weights. Our evaluation is three-fold: we show better
results than prior art when quantitatively compared to animator rigs;
qualitatively we show that our rigs can be expressively posed and animated at
multiple levels of detail; and finally, we evaluate the impact of various
algorithm choices on our output rigs.
"
2000,Lagrangian Neural Style Transfer for Fluids,"  Artistically controlling the shape, motion and appearance of fluid
simulations pose major challenges in visual effects production. In this paper,
we present a neural style transfer approach from images to 3D fluids formulated
in a Lagrangian viewpoint. Using particles for style transfer has unique
benefits compared to grid-based techniques. Attributes are stored on the
particles and hence are trivially transported by the particle motion. This
intrinsically ensures temporal consistency of the optimized stylized structure
and notably improves the resulting quality. Simultaneously, the expensive,
recursive alignment of stylization velocity fields of grid approaches is
unnecessary, reducing the computation time to less than an hour and rendering
neural flow stylization practical in production settings. Moreover, the
Lagrangian representation improves artistic control as it allows for
multi-fluid stylization and consistent color transfer from images, and the
generality of the method enables stylization of smoke and liquids likewise.
"
2001,Variational Shape Approximation of Point Set Surfaces,"  In this work, we present a translation of the complete pipeline for
variational shape approximation (VSA) to the setting of point sets. First, we
describe an explicit example for the theoretically known non-convergence of the
currently available VSA approaches. The example motivates us to introduce an
alternate version of VSA based on a switch operation for which we prove
convergence. Second, we discuss how two operations - split and merge - can be
included in a fully automatic pipeline that is in turn independent of the
placement and number of initial seeds. Third and finally, we present two
approaches how to obtain a simplified mesh from the output of the VSA
procedure. This simplification is either based on simple plane intersection or
based on a variational optimization problem. Several qualitative and
quantitative results prove the relevance of our approach.
"
2002,Neural Subdivision,"  This paper introduces Neural Subdivision, a novel framework for data-driven
coarse-to-fine geometry modeling. During inference, our method takes a coarse
triangle mesh as input and recursively subdivides it to a finer geometry by
applying the fixed topological updates of Loop Subdivision, but predicting
vertex positions using a neural network conditioned on the local geometry of a
patch. This approach enables us to learn complex non-linear subdivision
schemes, beyond simple linear averaging used in classical techniques. One of
our key contributions is a novel self-supervised training setup that only
requires a set of high-resolution meshes for learning network weights. For any
training shape, we stochastically generate diverse low-resolution
discretizations of coarse counterparts, while maintaining a bijective mapping
that prescribes the exact target position of every new vertex during the
subdivision process. This leads to a very efficient and accurate loss function
for conditional mesh generation, and enables us to train a method that
generalizes across discretizations and favors preserving the manifold structure
of the output. During training we optimize for the same set of network weights
across all local mesh patches, thus providing an architecture that is not
constrained to a specific input mesh, fixed genus, or category. Our network
encodes patch geometry in a local frame in a rotation- and
translation-invariant manner. Jointly, these design choices enable our method
to generalize well, and we demonstrate that even when trained on a single
high-resolution mesh our method generates reasonable subdivisions for novel
shapes.
"
2003,"Illumination-Invariant Image from 4-Channel Images: The Effect of
  Near-Infrared Data in Shadow Removal","  Removing the effect of illumination variation in images has been proved to be
beneficial in many computer vision applications such as object recognition and
semantic segmentation. Although generating illumination-invariant images has
been studied in the literature before, it has not been investigated on real
4-channel (4D) data. In this study, we examine the quality of
illumination-invariant images generated from red, green, blue, and
near-infrared (RGBN) data. Our experiments show that the near-infrared channel
substantively contributes toward removing illumination. As shown in our
numerical and visual results, the illumination-invariant image obtained by RGBN
data is superior compared to that obtained by RGB alone.
"
2004,"Augmented Semantic Signatures of Airborne LiDAR Point Clouds for
  Comparison","  LiDAR point clouds provide rich geometric information, which is particularly
useful for the analysis of complex scenes of urban regions. Finding structural
and semantic differences between two different three-dimensional point clouds,
say, of the same region but acquired at different time instances is an
important problem. A comparison of point clouds involves computationally
expensive registration and segmentation. We are interested in capturing the
relative differences in the geometric uncertainty and semantic content of the
point cloud without the registration process. Hence, we propose an
orientation-invariant geometric signature of the point cloud, which integrates
its probabilistic geometric and semantic classifications. We study different
properties of the geometric signature, which are an image-based encoding of
geometric uncertainty and semantic content. We explore different metrics to
determine differences between these signatures, which in turn compare point
clouds without performing point-to-point registration. Our results show that
the differences in the signatures corroborate with the geometric and semantic
differences of the point clouds.
"
2005,"An Information-theoretic Visual Analysis Framework for Convolutional
  Neural Networks","  Despite the great success of Convolutional Neural Networks (CNNs) in Computer
Vision and Natural Language Processing, the working mechanism behind CNNs is
still under extensive discussions and research. Driven by a strong demand for
the theoretical explanation of neural networks, some researchers utilize
information theory to provide insight into the black box model. However, to the
best of our knowledge, employing information theory to quantitatively analyze
and qualitatively visualize neural networks has not been extensively studied in
the visualization community. In this paper, we combine information entropies
and visualization techniques to shed light on how CNN works. Specifically, we
first introduce a data model to organize the data that can be extracted from
CNN models. Then we propose two ways to calculate entropy under different
circumstances. To provide a fundamental understanding of the basic building
blocks of CNNs (e.g., convolutional layers, pooling layers, normalization
layers) from an information-theoretic perspective, we develop a visual analysis
system, CNNSlicer. CNNSlicer allows users to interactively explore the amount
of information changes inside the model. With case studies on the widely used
benchmark datasets (MNIST and CIFAR-10), we demonstrate the effectiveness of
our system in opening the blackbox of CNNs.
"
2006,"AR-Therapist: Design and Simulation of an AR-Game Environment as a CBT
  for Patients with ADHD","  Attention Deficit Hyperactivity Disorder is one of the most common
neurodevelopmental disorders in which patients have difficulties related to
inattention, hyperactivity, and impulsivity. Those patients are in need of a
psychological therapy use Cognitive Behavioral Therapy (CBT) to enhance the way
they think and behave. This type of therapy is mostly common in treating
patients with anxiety and depression but also is useful in treating autism,
obsessive compulsive disorder and post-traumatic stress disorder. A major
limitation of traditional CBT is that therapists may face difficulty in
optimizing patients' neuropsychological stimulus following a specified
treatment plan. Other limitations include availability, accessibility and
level-of-experience of the therapists. Hence, this paper aims to design and
simulate a generic cognitive model that can be used as an appropriate
alternative treatment to traditional CBT, we term as ""AR-Therapist."" This model
takes advantage of the current developments of augmented reality to engage
patients in both real and virtual game-based environments.
"
2007,Overview of Surgical Simulation,"  Motivated by the current demand of clinical governance, surgical simulation
is now a well-established modality for basic skills training and assessment.
The practical deployment of the technique is a multi-disciplinary venture
encompassing areas in engineering, medicine and psychology. This paper provides
an overview of the key topics involved in surgical simulation and associated
technical challenges. The paper discusses the clinical motivation for surgical
simulation, the use of virtual environments for surgical training, model
acquisition and simplification, deformable models, collision detection, tissue
property measurement, haptic rendering and image synthesis. Additional topics
include surgical skill training and assessment metrics as well as challenges
facing the incorporation of surgical simulation into medical education
curricula.
"
2008,"CARL: Controllable Agent with Reinforcement Learning for Quadruped
  Locomotion","  Motion synthesis in a dynamic environment has been a long-standing problem
for character animation. Methods using motion capture data tend to scale poorly
in complex environments because of their larger capturing and labeling
requirement. Physics-based controllers are effective in this regard, albeit
less controllable. In this paper, we present CARL, a quadruped agent that can
be controlled with high-level directives and react naturally to dynamic
environments. Starting with an agent that can imitate individual animation
clips, we use Generative Adversarial Networks to adapt high-level controls,
such as speed and heading, to action distributions that correspond to the
original animations. Further fine-tuning through the deep reinforcement
learning enables the agent to recover from unseen external perturbations while
producing smooth transitions. It then becomes straightforward to create
autonomous agents in dynamic environments by adding navigation modules over the
entire process. We evaluate our approach by measuring the agent's ability to
follow user control and provide a visual analysis of the generated motion to
show its effectiveness.
"
2009,"Vid2Curve: Simultaneous Camera Motion Estimation and Thin Structure
  Reconstruction from an RGB Video","  Thin structures, such as wire-frame sculptures, fences, cables, power lines,
and tree branches, are common in the real world. It is extremely challenging to
acquire their 3D digital models using traditional image-based or depth-based
reconstruction methods because thin structures often lack distinct point
features and have severe self-occlusion. We propose the first approach that
simultaneously estimates camera motion and reconstructs the geometry of complex
3D thin structures in high quality from a color video captured by a handheld
camera. Specifically, we present a new curve-based approach to estimate
accurate camera poses by establishing correspondences between featureless thin
objects in the foreground in consecutive video frames, without requiring visual
texture in the background scene to lock on. Enabled by this effective
curve-based camera pose estimation strategy, we develop an iterative
optimization method with tailored measures on geometry, topology as well as
self-occlusion handling for reconstructing 3D thin structures. Extensive
validations on a variety of thin structures show that our method achieves
accurate camera pose estimation and faithful reconstruction of 3D thin
structures with complex shape and topology at a level that has not been
attained by other existing reconstruction methods.
"
2010,"Fast Automatic Visibility Optimization for Thermal Synthetic Aperture
  Visualization","  In this article, we describe and validate the first fully automatic parameter
optimization for thermal synthetic aperture visualization. It replaces previous
manual exploration of the parameter space, which is time consuming and error
prone. We prove that the visibility of targets in thermal integral images is
proportional to the variance of the targets' image. Since this is invariant to
occlusion it represents a suitable objective function for optimization. Our
findings have the potential to enable fully autonomous search and recuse
operations with camera drones.
"
2011,Sequential Gallery for Interactive Visual Design Optimization,"  Visual design tasks often involve tuning many design parameters. For example,
color grading of a photograph involves many parameters, some of which
non-expert users might be unfamiliar with. We propose a novel user-in-the-loop
optimization method that allows users to efficiently find an appropriate
parameter set by exploring such a high-dimensional design space through much
easier two-dimensional search subtasks. This method, called sequential plane
search, is based on Bayesian optimization to keep necessary queries to users as
few as possible. To help users respond to plane-search queries, we also propose
using a gallery-based interface that provides options in the two-dimensional
subspace arranged in an adaptive grid view. We call this interactive framework
Sequential Gallery since users sequentially select the best option from the
options provided by the interface. Our experiment with synthetic functions
shows that our sequential plane search can find satisfactory solutions in fewer
iterations than baselines. We also conducted a preliminary user study, results
of which suggest that novices can effectively complete search tasks with
Sequential Gallery in a photo-enhancement scenario.
"
2012,ALLSTEPS: Curriculum-driven Learning of Stepping Stone Skills,"  Humans are highly adept at walking in environments with foot placement
constraints, including stepping-stone scenarios where the footstep locations
are fully constrained. Finding good solutions to stepping-stone locomotion is a
longstanding and fundamental challenge for animation and robotics. We present
fully learned solutions to this difficult problem using reinforcement learning.
We demonstrate the importance of a curriculum for efficient learning and
evaluate four possible curriculum choices compared to a non-curriculum
baseline. Results are presented for a simulated human character, a realistic
bipedal robot simulation and a monster character, in each case producing
robust, plausible motions for challenging stepping stone sequences and
terrains.
"
2013,FAME: 3D Shape Generation via Functionality-Aware Model Evolution,"  We introduce a modeling tool which can evolve a set of 3D objects in a
functionality-aware manner. Our goal is for the evolution to generate large and
diverse sets of plausible 3D objects for data augmentation, constrained
modeling, as well as open-ended exploration to possibly inspire new designs.
Starting with an initial population of 3D objects belonging to one or more
functional categories, we evolve the shapes through part recombination to
produce generations of hybrids or crossbreeds between parents from the
heterogeneous shape collection. Evolutionary selection of offsprings is guided
both by a functional plausibility score derived from functionality analysis of
shapes in the initial population and user preference, as in a design gallery.
Since cross-category hybridization may result in offsprings not belonging to
any of the known functional categories, we develop a means for functionality
partial matching to evaluate functional plausibility on partial shapes. We show
a variety of plausible hybrid shapes generated by our functionality-aware model
evolution, which can complement existing datasets as training data and boost
the performance of contemporary data-driven segmentation schemes, especially in
challenging cases. Our tool supports constrained modeling, allowing users to
restrict or steer the model evolution with functionality labels. At the same
time, unexpected yet functional object prototypes can emerge during open-ended
exploration owing to structure breaking when evolving a heterogeneous
collection.
"
2014,Design and visualization of Riemannian metrics,"  Local and global illumination were recently defined in Riemannian manifolds
to visualize classical Non-Euclidean spaces. This work focuses on Riemannian
metric construction in $\mathbb{R}^3$ to explore special effects like warping,
mirages, and deformations. We investigate the possibility of using graphs of
functions and diffeomorphism to produce such effects. For these, their
Riemannian metrics and geodesics derivations are provided, and ways of
accumulating such metrics. We visualize, in ""real-time"", the resulting
Riemannian manifolds using a ray tracing implemented on top of Nvidia RTX GPUs.
"
2015,"SpectralWeight: a spectral graph wavelet framework for weight prediction
  of pork cuts","  In this paper, we propose a novel approach for the quality assessment of pork
carcasses using 3D shape analysis. First, we make a 3D model of a pork
half-carcass using a 3D scanner and then we take advantage of spectral graph
wavelet signature (SGWS) to build a local spectral descriptor. Next, we
aggregate the extracted features using the bag-of-geometric-words paradigm to
globally represent the half-carcass shape. We then employ partial least-squares
regression to predict the weight of pork cuts for the quality assessment of
carcasses. Our results demonstrate that SpectralWeight can predict the weight
of different pork cuts and tissues with high accuracy. Although in this study
we evaluate the performance of SGWS for the weight prediction of pork
dissection, our framework is fairly general and enables new ways to estimate
the quality and economical value of carcasses of different animals.
"
2016,Skeleton-Aware Networks for Deep Motion Retargeting,"  We introduce a novel deep learning framework for data-driven motion
retargeting between skeletons, which may have different structure, yet
corresponding to homeomorphic graphs. Importantly, our approach learns how to
retarget without requiring any explicit pairing between the motions in the
training set. We leverage the fact that different homeomorphic skeletons may be
reduced to a common primal skeleton by a sequence of edge merging operations,
which we refer to as skeletal pooling. Thus, our main technical contribution is
the introduction of novel differentiable convolution, pooling, and unpooling
operators. These operators are skeleton-aware, meaning that they explicitly
account for the skeleton's hierarchical structure and joint adjacency, and
together they serve to transform the original motion into a collection of deep
temporal features associated with the joints of the primal skeleton. In other
words, our operators form the building blocks of a new deep motion processing
framework that embeds the motion into a common latent space, shared by a
collection of homeomorphic skeletons. Thus, retargeting can be achieved simply
by encoding to, and decoding from this latent space. Our experiments show the
effectiveness of our framework for motion retargeting, as well as motion
processing in general, compared to existing approaches. Our approach is also
quantitatively evaluated on a synthetic dataset that contains pairs of motions
applied to different skeletons. To the best of our knowledge, our method is the
first to perform retargeting between skeletons with differently sampled
kinematic chains, without any paired examples.
"
2017,Unpaired Motion Style Transfer from Video to Animation,"  Transferring the motion style from one animation clip to another, while
preserving the motion content of the latter, has been a long-standing problem
in character animation. Most existing data-driven approaches are supervised and
rely on paired data, where motions with the same content are performed in
different styles. In addition, these approaches are limited to transfer of
styles that were seen during training. In this paper, we present a novel
data-driven framework for motion style transfer, which learns from an unpaired
collection of motions with style labels, and enables transferring motion styles
not observed during training. Furthermore, our framework is able to extract
motion styles directly from videos, bypassing 3D reconstruction, and apply them
to the 3D input motion. Our style transfer network encodes motions into two
latent codes, for content and for style, each of which plays a different role
in the decoding (synthesis) process. While the content code is decoded into the
output motion by several temporal convolutional layers, the style code modifies
deep features via temporally invariant adaptive instance normalization (AdaIN).
Moreover, while the content code is encoded from 3D joint rotations, we learn a
common embedding for style from either 3D or 2D joint positions, enabling style
extraction from videos. Our results are comparable to the state-of-the-art,
despite not requiring paired training data, and outperform other methods when
transferring previously unseen styles. To our knowledge, we are the first to
demonstrate style transfer directly from videos to 3D animations - an ability
which enables one to extend the set of style examples far beyond motions
captured by MoCap systems.
"
2018,A Survey on Patch-based Synthesis: GPU Implementation and Optimization,"  This thesis surveys the research in patch-based synthesis and algorithms for
finding correspondences between small local regions of images. We additionally
explore a large kind of applications of this new fast randomized matching
technique. One of the algorithms we have studied in particular is PatchMatch,
can find similar regions or ""patches"" of an image one to two orders of
magnitude faster than previous techniques. The algorithmic program is driven by
applying mathematical properties of nearest neighbors in natural images. It is
observed that neighboring correspondences tend to be similar or ""coherent"" and
use this observation in algorithm in order to quickly converge to an
approximate solution. The algorithm is the most general form can find k-nearest
neighbor matching, using patches that translate, rotate, or scale, using
arbitrary descriptors, and between two or more images. Speed-ups are obtained
over various techniques in an exceeding range of those areas. We have explored
many applications of PatchMatch matching algorithm. In computer graphics, we
have explored removing unwanted objects from images, seamlessly moving objects
in images, changing image aspect ratios, and video summarization. In computer
vision we have explored denoising images, object detection, detecting image
forgeries, and detecting symmetries. We conclude by discussing the restrictions
of our algorithmic program, GPU implementation and areas for future analysis.
"
2019,Representing Whole Slide Cancer Image Features with Hilbert Curves,"  Regions of Interest (ROI) contain morphological features in pathology whole
slide images (WSI) are delimited with polygons[1]. These polygons are often
represented in either a textual notation (with the array of edges) or in a
binary mask form. Textual notations have an advantage of human readability and
portability, whereas, binary mask representations are more useful as the input
and output of feature-extraction pipelines that employ deep learning
methodologies. For any given whole slide image, more than a million cellular
features can be segmented generating a corresponding number of polygons. The
corpus of these segmentations for all processed whole slide images creates
various challenges for filtering specific areas of data for use in interactive
real-time and multi-scale displays and analysis. Simple range queries of image
locations do not scale and, instead, spatial indexing schemes are required. In
this paper we propose using Hilbert Curves simultaneously for spatial indexing
and as a polygonal ROI representation. This is achieved by using a series of
Hilbert Curves[2] creating an efficient and inherently spatially-indexed
machine-usable form. The distinctive property of Hilbert curves that enables
both mask and polygon delimitation of ROIs is that the elements of the vector
extracted ro describe morphological features maintain their relative positions
for different scales of the same image.
"
2020,"Optimally Fast Soft Shadows on Curved Terrain with Dynamic Programming
  and Maximum Mipmaps","  We present a simple, novel method of efficiently rendering ray cast soft
shadows on curved terrain by using dynamic programming and maximum mipmaps to
rapidly find a global minimum shadow cost in constant runtime complexity.
Additionally, we apply a new method of reducing view ray computation times that
pre-displaces the terrain mesh to bootstrap ray starting positions. Combining
these two methods, our ray casting engine runs in real-time with more than 200%
speed up over uniform ray stepping with comparable image quality and without
hardware ray tracing acceleration. To add support for accurate planetary
ephemerides and interactive features, we integrated the engine into
celestia.Sci, a general space simulation software. We demonstrate the ability
of our engine to accurately handle a large range of distance scales by using it
to generate videos of lunar landing trajectories. The numerical error when
compared with real lunar mission imagery is small, demonstrating the accuracy
and efficiency of our approach.
"
2021,Plane-Activated Mapped Microstructure,"  Querying and interacting with models of massive material micro-structure
requires localized on-demand generation of the micro-structure since the
full-scale storing and retrieving is cost prohibitive. When the micro-structure
is efficiently represented as the image of a canonical structure under a
non-linear space deformation to allow it to conform to curved shape, the
additional challenge is to relate the query of the mapped micro-structure back
to its canonical structure. This paper presents an efficient algorithm to pull
back a mapped micro-structure to a partition of the canonical domain structure
into boxes and only activates boxes whose image is likely intersected by a
plane. The active boxes are organized into a forest whose trees are traversed
depth first to generate mapped micro-structure only of the active boxes. The
traversal supports, for example, 3D print slice generation in additive
manufacturing.
"
2022,"Single Image HDR Reconstruction Using a CNN with Masked Features and
  Perceptual Loss","  Digital cameras can only capture a limited range of real-world scenes'
luminance, producing images with saturated pixels. Existing single image high
dynamic range (HDR) reconstruction methods attempt to expand the range of
luminance, but are not able to hallucinate plausible textures, producing
results with artifacts in the saturated areas. In this paper, we present a
novel learning-based approach to reconstruct an HDR image by recovering the
saturated pixels of an input LDR image in a visually pleasing way. Previous
deep learning-based methods apply the same convolutional filters on
well-exposed and saturated pixels, creating ambiguity during training and
leading to checkerboard and halo artifacts. To overcome this problem, we
propose a feature masking mechanism that reduces the contribution of the
features from the saturated areas. Moreover, we adapt the VGG-based perceptual
loss function to our application to be able to synthesize visually pleasing
textures. Since the number of HDR images for training is limited, we propose to
train our system in two stages. Specifically, we first train our system on a
large number of images for image inpainting task and then fine-tune it on HDR
reconstruction. Since most of the HDR examples contain smooth regions that are
simple to reconstruct, we propose a sampling strategy to select challenging
training patches during the HDR fine-tuning stage. We demonstrate through
experimental results that our approach can reconstruct visually pleasing HDR
results, better than the current state of the art on a wide range of scenes.
"
2023,Online path sampling control with progressive spatio-temporal filtering,"  This work introduces progressive spatio-temporal filtering, an efficient
method to build all-frequency approximations to the light transport
distribution into a scene by filtering individual samples produced by an
underlying path sampler, using online, iterative algorithms and data-structures
that exploit both the spatial and temporal coherence of the approximated light
field. Unlike previous approaches, the proposed method is both more efficient,
due to its use of an iterative temporal feedback loop that massively improves
convergence to a noise-free approximant, and more flexible, due to its
introduction of a spatio-directional hashing representation that allows to
encode directional variations like those due to glossy reflections. We then
introduce four different methods to employ the resulting approximations to
control the underlying path sampler and/or modify its associated estimator,
greatly reducing its variance and enhancing its robustness to complex lighting
scenarios. The core algorithms are highly scalable and low-overhead, requiring
only minor modifications to an existing path tracer.
"
2024,"Generative Adversarial Networks for photo to Hayao Miyazaki style
  cartoons","  This paper takes on the problem of transferring the style of cartoon images
to real-life photographic images by implementing previous work done by
CartoonGAN. We trained a Generative Adversial Network(GAN) on over 60 000
images from works by Hayao Miyazaki at Studio Ghibli. To evaluate our results,
we conducted a qualitative survey comparing our results with two
state-of-the-art methods. 117 survey results indicated that our model on
average outranked state-of-the-art methods on cartoon-likeness.
"
2025,Semantic Photo Manipulation with a Generative Image Prior,"  Despite the recent success of GANs in synthesizing images conditioned on
inputs such as a user sketch, text, or semantic labels, manipulating the
high-level attributes of an existing natural photograph with GANs is
challenging for two reasons. First, it is hard for GANs to precisely reproduce
an input image. Second, after manipulation, the newly synthesized pixels often
do not fit the original image. In this paper, we address these issues by
adapting the image prior learned by GANs to image statistics of an individual
image. Our method can accurately reconstruct the input image and synthesize new
content, consistent with the appearance of the input image. We demonstrate our
interactive system on several semantic image editing tasks, including
synthesizing new objects consistent with background, removing unwanted objects,
and changing the appearance of an object. Quantitative and qualitative
comparisons against several existing methods demonstrate the effectiveness of
our method.
"
2026,Face Identity Disentanglement via Latent Space Mapping,"  Learning disentangled representations of data is a fundamental problem in
artificial intelligence. Specifically, disentangled latent representations
allow generative models to control and compose the disentangled factors in the
synthesis process. Current methods, however, require extensive supervision and
training, or instead, noticeably compromise quality. In this paper, we present
a method that learns how to represent data in a disentangled way, with minimal
supervision, manifested solely using available pre-trained networks. Our key
insight is to decouple the processes of disentanglement and synthesis, by
employing a leading pre-trained unconditional image generator, such as
StyleGAN. By learning to map into its latent space, we leverage both its
state-of-the-art quality, and its rich and expressive latent space, without the
burden of training it. We demonstrate our approach on the complex and high
dimensional domain of human heads. We evaluate our method qualitatively and
quantitatively, and exhibit its success with de-identification operations and
with temporal identity coherency in image sequences. Through extensive
experimentation, we show that our method successfully disentangles identity
from other facial attributes, surpassing existing methods, even though they
require more training and supervision.
"
2027,Attribute2Font: Creating Fonts You Want From Attributes,"  Font design is now still considered as an exclusive privilege of professional
designers, whose creativity is not possessed by existing software systems.
Nevertheless, we also notice that most commercial font products are in fact
manually designed by following specific requirements on some attributes of
glyphs, such as italic, serif, cursive, width, angularity, etc. Inspired by
this fact, we propose a novel model, Attribute2Font, to automatically create
fonts by synthesizing visually-pleasing glyph images according to
user-specified attributes and their corresponding values. To the best of our
knowledge, our model is the first one in the literature which is capable of
generating glyph images in new font styles, instead of retrieving existing
fonts, according to given values of specified font attributes. Specifically,
Attribute2Font is trained to perform font style transfer between any two fonts
conditioned on their attribute values. After training, our model can generate
glyph images in accordance with an arbitrary set of font attribute values.
Furthermore, a novel unit named Attribute Attention Module is designed to make
those generated glyph images better embody the prominent font attributes.
Considering that the annotations of font attribute values are extremely
expensive to obtain, a semi-supervised learning scheme is also introduced to
exploit a large number of unlabeled fonts. Experimental results demonstrate
that our model achieves impressive performance on many tasks, such as creating
glyph images in new font styles, editing existing fonts, interpolation among
different fonts, etc.
"
2028,Deep Lighting Environment Map Estimation from Spherical Panoramas,"  Estimating a scene's lighting is a very important task when compositing
synthetic content within real environments, with applications in mixed reality
and post-production. In this work we present a data-driven model that estimates
an HDR lighting environment map from a single LDR monocular spherical panorama.
In addition to being a challenging and ill-posed problem, the lighting
estimation task also suffers from a lack of facile illumination ground truth
data, a fact that hinders the applicability of data-driven methods. We approach
this problem differently, exploiting the availability of surface geometry to
employ image-based relighting as a data generator and supervision mechanism.
This relies on a global Lambertian assumption that helps us overcome issues
related to pre-baked lighting. We relight our training data and complement the
model's supervision with a photometric loss, enabled by a differentiable
image-based relighting technique. Finally, since we predict spherical spectral
coefficients, we show that by imposing a distribution prior on the predicted
coefficients, we can greatly boost performance. Code and models available at
https://vcl3d.github.io/DeepPanoramaLighting.
"
2029,"An error reduced and uniform parameter approximation in fitting of
  B-spline curves to data points","  Approximating data points in three or higher dimension space based on cubic
B-spline curve is presented. Representations for planar curves, are merged and
extended to the higher dimension. The curve is fitted to the order of data
points, or uniform parameter values are assumed for the points. Tangents are
assumed at the data points, corresponding to the property used in cardinal
splines, for shape preserving and visually pleasing fit. Control points of
piecewise continuous cubic bezier curves, meeting the boundary conditions of
cardinal spline segments, are used for b-spline curve in corresponding
coordinate planes. Approximation using error computed in the least square
sense, based on a fraction of data points, is also presented.
"
2030,Knot Morphing Algorithm for Quantum `Fragile Topology',"  A knot theoretic algorithm is proposed to model `fragile topology' of quantum
physics.
"
2031,Generative Tweening: Long-term Inbetweening of 3D Human Motions,"  The ability to generate complex and realistic human body animations at scale,
while following specific artistic constraints, has been a fundamental goal for
the game and animation industry for decades. Popular techniques include
key-framing, physics-based simulation, and database methods via motion graphs.
Recently, motion generators based on deep learning have been introduced.
Although these learning models can automatically generate highly intricate
stylized motions of arbitrary length, they still lack user control. To this
end, we introduce the problem of long-term inbetweening, which involves
automatically synthesizing complex motions over a long time interval given very
sparse keyframes by users. We identify a number of challenges related to this
problem, including maintaining biomechanical and keyframe constraints,
preserving natural motions, and designing the entire motion sequence
holistically while considering all constraints. We introduce a biomechanically
constrained generative adversarial network that performs long-term inbetweening
of human motions, conditioned on keyframe constraints. This network uses a
novel two-stage approach where it first predicts local motion in the form of
joint angles, and then predicts global motion, i.e. the global path that the
character follows. Since there are typically a number of possible motions that
could satisfy the given user constraints, we also enable our network to
generate a variety of outputs with a scheme that we call Motion DNA. This
approach allows the user to manipulate and influence the output content by
feeding seed motions (DNA) to the network. Trained with 79 classes of captured
motion data, our network performs robustly on a variety of highly complex
motion styles.
"
2032,Portrait Shadow Manipulation,"  Casually-taken portrait photographs often suffer from unflattering lighting
and shadowing because of suboptimal conditions in the environment. Aesthetic
qualities such as the position and softness of shadows and the lighting ratio
between the bright and dark parts of the face are frequently determined by the
constraints of the environment rather than by the photographer. Professionals
address this issue by adding light shaping tools such as scrims, bounce cards,
and flashes. In this paper, we present a computational approach that gives
casual photographers some of this control, thereby allowing poorly-lit
portraits to be relit post-capture in a realistic and easily-controllable way.
Our approach relies on a pair of neural networks---one to remove foreign
shadows cast by external objects, and another to soften facial shadows cast by
the features of the subject and to add a synthetic fill light to improve the
lighting ratio. To train our first network we construct a dataset of real-world
portraits wherein synthetic foreign shadows are rendered onto the face, and we
show that our network learns to remove those unwanted shadows. To train our
second network we use a dataset of Light Stage scans of human subjects to
construct input/output pairs of input images harshly lit by a small light
source, and variably softened and fill-lit output images of each face. We
propose a way to explicitly encode facial symmetry and show that our dataset
and training procedure enable the model to generalize to images taken in the
wild. Together, these networks enable the realistic and aesthetically pleasing
enhancement of shadows and lights in real-world portrait images
"
2033,"Saving the Sonorine: Photovisual Audio Recovery Using Image Processing
  and Computer Vision Techniques","  This paper presents a novel technique to recover audio from sonorines, an
early 20th century form of analogue sound storage. Our method uses high
resolution photographs of sonorines under different lighting conditions to
observe the change in reflection behavior of the physical surface features and
create a three-dimensional height map of the surface. Sound can then be
extracted using height information within the surface's grooves, mimicking a
physical stylus on a phonograph. Unlike traditional playback methods, our
method has the advantage of being contactless: the medium will not incur damage
and wear from being played repeatedly. We compare the results of our technique
to a previously successful contactless method using flatbed scans of the
sonorines, and conclude with future research that can be applied to this
photovisual approach to audio recovery.
"
2034,Holistic Parameteric Reconstruction of Building Models from Point Clouds,"  Building models are conventionally reconstructed by building roof points
planar segmentation and then using a topology graph to group the planes
together. Roof edges and vertices are then mathematically represented by
intersecting segmented planes. Technically, such solution is based on
sequential local fitting, i.e., the entire data of one building are not
simultaneously participating in determining the building model. As a
consequence, the solution is lack of topological integrity and geometric rigor.
Fundamentally different from this traditional approach, we propose a holistic
parametric reconstruction method which means taking into consideration the
entire point clouds of one building simultaneously. In our work, building
models are reconstructed from predefined parametric (roof) primitives. We first
use a well-designed deep neural network to segment and identify primitives in
the given building point clouds. A holistic optimization strategy is then
introduced to simultaneously determine the parameters of a segmented primitive.
In the last step, the optimal parameters are used to generate a watertight
building model in CityGML format. The airborne LiDAR dataset RoofN3D with
predefined roof types is used for our test. It is shown that PointNet++ applied
to the entire dataset can achieve an accuracy of 83% for primitive
classification. For a subset of 910 buildings in RoofN3D, the holistic approach
is then used to determine the parameters of primitives and reconstruct the
buildings. The achieved overall quality of reconstruction is 0.08 meters for
point-surface-distance or 0.7 times RMSE of the input LiDAR points. The study
demonstrates the efficiency and capability of the proposed approach and its
potential to handle large scale urban point clouds.
"
2035,"Contextual Residual Aggregation for Ultra High-Resolution Image
  Inpainting","  Recently data-driven image inpainting methods have made inspiring progress,
impacting fundamental image editing tasks such as object removal and damaged
image repairing. These methods are more effective than classic approaches,
however, due to memory limitations they can only handle low-resolution inputs,
typically smaller than 1K. Meanwhile, the resolution of photos captured with
mobile devices increases up to 8K. Naive up-sampling of the low-resolution
inpainted result can merely yield a large yet blurry result. Whereas, adding a
high-frequency residual image onto the large blurry image can generate a sharp
result, rich in details and textures. Motivated by this, we propose a
Contextual Residual Aggregation (CRA) mechanism that can produce high-frequency
residuals for missing contents by weighted aggregating residuals from
contextual patches, thus only requiring a low-resolution prediction from the
network. Since convolutional layers of the neural network only need to operate
on low-resolution inputs and outputs, the cost of memory and computing power is
thus well suppressed. Moreover, the need for high-resolution training datasets
is alleviated. In our experiments, we train the proposed model on small images
with resolutions 512x512 and perform inference on high-resolution images,
achieving compelling inpainting quality. Our model can inpaint images as large
as 8K with considerable hole sizes, which is intractable with previous
learning-based approaches. We further elaborate on the light-weight design of
the network architecture, achieving real-time performance on 2K images on a GTX
1080 Ti GPU. Codes are available at: Atlas200dk/sample-imageinpainting-HiFill.
"
2036,Non-Uniform Gaussian Blur of Hexagonal Bins in Cartesian Coordinates,"  In a recent application of the Bokeh Python library for visualizing
physico-chemical properties of chemical entities text-mined from the scientific
literature, we found ourselves facing the task of smoothing hexagonally binned
data in Cartesian coordinates. To the best of our knowledge, no documentation
for how to do this exist in the public domain. This short paper shows how to
accomplish this in general and for Bokeh in particular. We illustrate the
method with a real-world example and discuss some potential advantages of using
hexagonal bins in these and similar applications.
"
2037,Few-shot Compositional Font Generation with Dual Memory,"  Generating a new font library is a very labor-intensive and time-consuming
job for glyph-rich scripts. Despite the remarkable success of existing font
generation methods, they have significant drawbacks; they require a large
number of reference images to generate a new font set, or they fail to capture
detailed styles with only a few samples. In this paper, we focus on
compositional scripts, a widely used letter system in the world, where each
glyph can be decomposed by several components. By utilizing the
compositionality of compositional scripts, we propose a novel font generation
framework, named Dual Memory-augmented Font Generation Network (DM-Font), which
enables us to generate a high-quality font library with only a few samples. We
employ memory components and global-context awareness in the generator to take
advantage of the compositionality. In the experiments on Korean-handwriting
fonts and Thai-printing fonts, we observe that our method generates a
significantly better quality of samples with faithful stylization compared to
the state-of-the-art generation methods quantitatively and qualitatively.
Source code is available at https://github.com/clovaai/dmfont.
"
2038,Wish You Were Here: Context-Aware Human Generation,"  We present a novel method for inserting objects, specifically humans, into
existing images, such that they blend in a photorealistic manner, while
respecting the semantic context of the scene. Our method involves three
subnetworks: the first generates the semantic map of the new person, given the
pose of the other persons in the scene and an optional bounding box
specification. The second network renders the pixels of the novel person and
its blending mask, based on specifications in the form of multiple appearance
components. A third network refines the generated face in order to match those
of the target person. Our experiments present convincing high-resolution
outputs in this novel and challenging application domain. In addition, the
three networks are evaluated individually, demonstrating for example, state of
the art results in pose transfer benchmarks.
"
2039,Point2Mesh: A Self-Prior for Deformable Meshes,"  In this paper, we introduce Point2Mesh, a technique for reconstructing a
surface mesh from an input point cloud. Instead of explicitly specifying a
prior that encodes the expected shape properties, the prior is defined
automatically using the input point cloud, which we refer to as a self-prior.
The self-prior encapsulates reoccurring geometric repetitions from a single
shape within the weights of a deep neural network. We optimize the network
weights to deform an initial mesh to shrink-wrap a single input point cloud.
This explicitly considers the entire reconstructed shape, since shared local
kernels are calculated to fit the overall object. The convolutional kernels are
optimized globally across the entire shape, which inherently encourages
local-scale geometric self-similarity across the shape surface. We show that
shrink-wrapping a point cloud with a self-prior converges to a desirable
solution; compared to a prescribed smoothness prior, which often becomes
trapped in undesirable local minima. While the performance of traditional
reconstruction approaches degrades in non-ideal conditions that are often
present in real world scanning, i.e., unoriented normals, noise and missing
(low density) parts, Point2Mesh is robust to non-ideal conditions. We
demonstrate the performance of Point2Mesh on a large variety of shapes with
varying complexity.
"
2040,"Software Implementation of Optimized Bicubic Interpolated Scan
  Conversion in Echocardiography","  This paper presents the image-quality-guided strategy for optimization of
bicubic interpolation and interpolated scan conversion algorithms. This
strategy uses feature selection through line chart data visualization technique
and first index of the minimum absolute difference between computed scores and
ideal scores to determine the image quality guided coefficient k that changes
all sixteen BIC coefficients to new coefficients on which the OBIC
interpolation algorithm is based. Perceptual evaluations of cropped sectored
images from Matlab software implementation of interpolated scan conversion
algorithms are presented. Also, IQA metrics-based evaluation is presented and
demonstrates that the overall performance of the OBIC algorithm is 92.22% when
compared with BIC alone, but becomes 57.22% with all other methods mentioned.
"
2041,MeshODE: A Robust and Scalable Framework for Mesh Deformation,"  We present MeshODE, a scalable and robust framework for pairwise CAD model
deformation without prespecified correspondences. Given a pair of shapes, our
framework provides a novel shape feature-preserving mapping function that
continuously deforms one model to the other by minimizing fitting and rigidity
losses based on the non-rigid iterative-closest-point (ICP) algorithm. We
address two challenges in this problem, namely the design of a powerful
deformation function and obtaining a feature-preserving CAD deformation. While
traditional deformation directly optimizes for the coordinates of the mesh
vertices or the vertices of a control cage, we introduce a deep bijective
mapping that utilizes a flow model parameterized as a neural network. Our
function has the capacity to handle complex deformations, produces deformations
that are guaranteed free of self-intersections, and requires low rigidity
constraining for geometry preservation, which leads to a better fitting quality
compared with existing methods. It additionally enables continuous deformation
between two arbitrary shapes without supervision for intermediate shapes.
Furthermore, we propose a robust preprocessing pipeline for raw CAD meshes
using feature-aware subdivision and a uniform graph template representation to
address artifacts in raw CAD models including self-intersections, irregular
triangles, topologically disconnected components, non-manifold edges, and
nonuniformly distributed vertices. This facilitates a fast deformation
optimization process that preserves global and local details. Our code is
publicly available.
"
2042,"ManifoldPlus: A Robust and Scalable Watertight Manifold Surface
  Generation Method for Triangle Soups","  We present ManifoldPlus, a method for robust and scalable conversion of
triangle soups to watertight manifolds. While many algorithms in computer
graphics require the input mesh to be a watertight manifold, in practice many
meshes designed by artists are often for visualization purposes, and thus have
non-manifold structures such as incorrect connectivity, ambiguous face
orientation, double surfaces, open boundaries, self-intersections, etc.
Existing methods suffer from problems in the inputs with face orientation and
zero-volume structures. Additionally most methods do not scale to meshes of
high complexity. In this paper, we propose a method that extracts exterior
faces between occupied voxels and empty voxels, and uses a projection-based
optimization method to accurately recover a watertight manifold that resembles
the reference mesh. Compared to previous methods, our methodology is simpler.
It does not rely on face normals of the input triangle soups and can accurately
recover zero-volume structures. Our algorithm is scalable, because it employs
an adaptive Gauss-Seidel method for shape optimization, in which each step is
an easy-to-solve convex problem. We test ManifoldPlus on ModelNet10 and
AccuCity datasets to verify that our methods can generate watertight meshes
ranging from object-level shapes to city-level models. Furthermore, through our
experimental evaluations, we show that our method is more robust, efficient and
accurate than the state-of-the-art. Our implementation is publicly available.
"
2043,Unsupervised Geometric Disentanglement for Surfaces via CFAN-VAE,"  For non-Euclidean data such as meshes of humans, a prominent task for
generative models is geometric disentanglement; the separation of latent codes
for intrinsic (i.e. identity) and extrinsic (i.e. pose) geometry. This work
introduces a novel mesh feature, the conformal factor and normal feature
(CFAN), for use in mesh convolutional autoencoders. We further propose
CFAN-VAE, a novel architecture that disentangles identity and pose using the
CFAN feature and parallel transport convolution. CFAN-VAE achieves this
geometric disentanglement in an unsupervised way, as it does not require label
information on the identity or pose during training. Our comprehensive
experiments, including reconstruction, interpolation, generation, and canonical
correlation analysis, validate the effectiveness of the unsupervised geometric
disentanglement. We also successfully detect and recover geometric
disentanglement in mesh convolutional autoencoders that encode xyz-coordinates
directly by registering its latent space to that of CFAN-VAE.
"
2044,"Haptic Rendering of Thin, Deformable Objects with Spatially Varying
  Stiffness","  In the real world, we often come across soft objects having spatially varying
stiffness, such as human palm or a wart on the skin. In this paper, we propose
a novel approach to render thin, deformable objects having spatially varying
stiffness (inhomogeneous material). We use the classical Kirchhoff thin plate
theory to compute the deformation. In general, the physics-based rendering of
an arbitrary 3D surface is complex and time-consuming. Therefore, we
approximate the 3D surface locally by a 2D plane using an area-preserving
mapping technique - Gall-Peters mapping. Once the deformation is computed by
solving a fourth-order partial differential equation, we project the points
back onto the original object for proper haptic rendering. The method was
validated through user experiments and was found to be realistic.
"
2045,HiVision: Rapid Visualization of Large-Scale Spatial Vector Data,"  Rapid visualization of large-scale spatial vector data is a long-standing
challenge in Geographic Information Science. In existing methods, the
computation overheads grow rapidly with data volumes, leading to the
incapability of providing real-time visualization for large-scale spatial
vector data, even with parallel acceleration technologies. To fill the gap, we
present HiVision, a display-driven visualization model for large-scale spatial
vector data. Different from traditional data-driven methods, the computing
units in HiVision are pixels rather than spatial objects to achieve real-time
performance, and efficient spatial-index-based strategies are introduced to
estimate the topological relationships between pixels and spatial objects.
HiVision can maintain exceedingly good performance regardless of the data
volume due to the stable pixel number for display. In addition, an optimized
parallel computing architecture is proposed in HiVision to ensure the ability
of real-time visualization. Experiments show that our approach outperforms
traditional methods in rendering speed and visual effects while dealing with
large-scale spatial vector data, and can provide interactive visualization of
datasets with billion-scale points/segments/edges in real-time with flexible
rendering styles. The HiVision code is open-sourced at
https://github.com/MemoryMmy/HiVision with an online demonstration.
"
2046,Survey: Machine Learning in Production Rendering,"  In the past few years, machine learning-based approaches have had some great
success for rendering animated feature films. This survey summarizes several of
the most dramatic improvements in using deep neural networks over traditional
rendering methods, such as better image quality and lower computational
overhead. More specifically, this survey covers the fundamental principles of
machine learning and its applications, such as denoising, path guiding,
rendering participating media, and other notoriously difficult light transport
situations. Some of these techniques have already been used in the latest
released animations while others are still in the continuing development by
researchers in both academia and movie studios. Although learning-based
rendering methods still have some open issues, they have already demonstrated
promising performance in multiple parts of the rendering pipeline, and people
are continuously making new attempts.
"
2047,A Deep Learning based Fast Signed Distance Map Generation,"  Signed distance map (SDM) is a common representation of surfaces in medical
image analysis and machine learning. The computational complexity of SDM for 3D
parametric shapes is often a bottleneck in many applications, thus limiting
their interest. In this paper, we propose a learning based SDM generation
neural network which is demonstrated on a tridimensional cochlea shape model
parameterized by 4 shape parameters. The proposed SDM Neural Network generates
a cochlea signed distance map depending on four input parameters and we show
that the deep learning approach leads to a 60 fold improvement in the time of
computation compared to more classical SDM generation methods. Therefore, the
proposed approach achieves a good trade-off between accuracy and efficiency.
"
2048,How to see the eight Thurston geometries,"  A manifold is a topological space that is locally Euclidean. Manifolds are
important because they arise naturally in a variety of mathematical and
physical applications as global objects with simpler local structure. In this
paper we propose a technique for immersive visualization of relevant
three-dimensional manifolds in the context of the Geometrization conjecture.
The algorithm generalizes traditional computer graphics ray tracing. To do so
we use several related definitions and results dating back to the works of
Poincar\'e, Thurston, and Perelman.
"
2049,4D Visualization of Dynamic Events from Unconstrained Multi-View Videos,"  We present a data-driven approach for 4D space-time visualization of dynamic
events from videos captured by hand-held multiple cameras. Key to our approach
is the use of self-supervised neural networks specific to the scene to compose
static and dynamic aspects of an event. Though captured from discrete
viewpoints, this model enables us to move around the space-time of the event
continuously. This model allows us to create virtual cameras that facilitate:
(1) freezing the time and exploring views; (2) freezing a view and moving
through time; and (3) simultaneously changing both time and view. We can also
edit the videos and reveal occluded objects for a given view if it is visible
in any of the other views. We validate our approach on challenging in-the-wild
events captured using up to 15 mobile cameras.
"
2050,Constructing Human Motion Manifold with Sequential Networks,"  This paper presents a novel recurrent neural network-based method to
construct a latent motion manifold that can represent a wide range of human
motions in a long sequence. We introduce several new components to increase the
spatial and temporal coverage in motion space while retaining the details of
motion capture data. These include new regularization terms for the motion
manifold, combination of two complementary decoders for predicting joint
rotations and joint velocities, and the addition of the forward kinematics
layer to consider both joint rotation and position errors. In addition, we
propose a set of loss terms that improve the overall quality of the motion
manifold from various aspects, such as the capability of reconstructing not
only the motion but also the latent manifold vector, and the naturalness of the
motion through adversarial loss. These components contribute to creating
compact and versatile motion manifold that allows for creating new motions by
performing random sampling and algebraic operations, such as interpolation and
analogy, in the latent motion manifold.
"
2051,"Non-Rigid Volume to Surface Registration using a Data-Driven
  Biomechanical Model","  Non-rigid registration is a key component in soft-tissue navigation. We focus
on laparoscopic liver surgery, where we register the organ model obtained from
a preoperative CT scan to the intraoperative partial organ surface,
reconstructed from the laparoscopic video. This is a challenging task due to
sparse and noisy intraoperative data, real-time requirements and many unknowns
- such as tissue properties and boundary conditions. Furthermore, establishing
correspondences between pre- and intraoperative data can be extremely difficult
since the liver usually lacks distinct surface features and the used imaging
modalities suffer from very different types of noise. In this work, we train a
convolutional neural network to perform both the search for surface
correspondences as well as the non-rigid registration in one step. The network
is trained on physically accurate biomechanical simulations of randomly
generated, deforming organ-like structures. This enables the network to
immediately generalize to a new patient organ without the need to re-train. We
add various amounts of noise to the intraoperative surfaces during training,
making the network robust to noisy intraoperative data. During inference, the
network outputs the displacement field which matches the preoperative volume to
the partial intraoperative surface. In multiple experiments, we show that the
network translates well to real data while maintaining a high inference speed.
Our code is made available online.
"
2052,"Clustering-informed Cinematic Astrophysical Data Visualization with
  Application to the Moon-forming Terrestrial Synestia","  Scientific visualization tools are currently not optimized to create
cinematic, production-quality representations of numerical data for the purpose
of science communication. In our pipeline \texttt{Estra}, we outline a
step-by-step process from a raw simulation into a finished render as a way to
teach non-experts in the field of visualization how to achieve
production-quality outputs on their own. We demonstrate feasibility of using
the visual effects software Houdini for cinematic astrophysical data
visualization, informed by machine learning clustering algorithms. To
demonstrate the capabilities of this pipeline, we used a post-impact,
thermally-equilibrated Moon-forming synestia from \cite{Lock18}. Our approach
aims to identify ""physically interpretable"" clusters, where clusters identified
in an appropriate phase space (e.g. here we use a temperature-entropy
phase-space) correspond to physically meaningful structures within the
simulation data. Clustering results can then be used to highlight these
structures by informing the color-mapping process in a simplified Houdini
software shading network, where dissimilar phase-space clusters are mapped to
different color values for easier visual identification. Cluster information
can also be used in 3D position space, via Houdini's Scene View, to aid in
physical cluster finding, simulation prototyping, and data exploration. Our
clustering-based renders are compared to those created by the Advanced
Visualization Lab (AVL) team for the full dome show ""Imagine the Moon"" as proof
of concept. With \texttt{Estra}, scientists have a tool to create their own
production-quality, data-driven visualizations.
"
2053,"Design and Implementation of a Virtual 3D Educational Environment to
  improve Deaf Education","  Advances in NLP, knowledge representation and computer graphic technologies
can provide us insights into the development of educational tool for Deaf
people. Actual education materials and tools for deaf pupils present several
problems, since textbooks are designed to support normal students in the
classroom and most of them are not suitable for people with hearing
disabilities. Virtual Reality (VR) technologies appear to be a good tool and a
promising framework in the education of pupils with hearing disabilities. In
this paper, we present a current research tasks surrounding the design and
implementation of a virtual 3D educational environment based on X3D and H-Anim
standards. The system generates and animates automatically Sign language
sentence from a semantic representation that encode the whole meaning of the
Arabic input text. Some aspects and issues in Sign language generation will be
discussed, including the model of Sign representation that facilitate reuse and
reduces the time of Sign generation, conversion of semantic components to sign
features representation with regard to Sign language linguistics
characteristics and how to generate realistic smooth gestural sequences using
X3D content to performs transition between signs for natural-looking of
animated avatar. Sign language sentences were evaluated by Algerian native Deaf
people. The goal of the project is the development of a machine translation
system from Arabic to Algerian Sign Language that can be used as educational
tool for Deaf children in algerian primary schools.
"
2054,OPAL-Net: A Generative Model for Part-based Object Layout Generation,"  We propose OPAL-Net, a novel hierarchical architecture for part-based layout
generation of objects from multiple categories using a single unified model. We
adopt a coarse-to-fine strategy involving semantically conditioned
autoregressive generation of bounding box layouts and pixel-level part layouts
for objects. We use Graph Convolutional Networks, Deep Recurrent Networks along
with custom-designed Conditional Variational Autoencoders to enable flexible,
diverse and category-aware generation of object layouts. We train OPAL-Net on
PASCAL-Parts dataset. The generated samples and corresponding evaluation scores
demonstrate the versatility of OPAL-Net compared to ablative variants and
baselines.
"
2055,Deep Generation of Face Images from Sketches,"  Recent deep image-to-image translation techniques allow fast generation of
face images from freehand sketches. However, existing solutions tend to overfit
to sketches, thus requiring professional sketches or even edge maps as input.
To address this issue, our key idea is to implicitly model the shape space of
plausible face images and synthesize a face image in this space to approximate
an input sketch. We take a local-to-global approach. We first learn feature
embeddings of key face components, and push corresponding parts of input
sketches towards underlying component manifolds defined by the feature vectors
of face component samples. We also propose another deep neural network to learn
the mapping from the embedded component features to realistic images with
multi-channel feature maps as intermediate results to improve the information
flow. Our method essentially uses input sketches as soft constraints and is
thus able to produce high-quality face images even from rough and/or incomplete
sketches. Our tool is easy to use even for non-artists, while still supporting
fine-grained control of shape details. Both qualitative and quantitative
evaluations show the superior generation ability of our system to existing and
alternative solutions. The usability and expressiveness of our system are
confirmed by a user study.
"
2056,"High-quality Panorama Stitching based on Asymmetric Bidirectional
  Optical Flow","  In this paper, we propose a panorama stitching algorithm based on asymmetric
bidirectional optical flow. This algorithm expects multiple photos captured by
fisheye lens cameras as input, and then, through the proposed algorithm, these
photos can be merged into a high-quality 360-degree spherical panoramic image.
For photos taken from a distant perspective, the parallax among them is
relatively small, and the obtained panoramic image can be nearly seamless and
undistorted. For photos taken from a close perspective or with a relatively
large parallax, a seamless though partially distorted panoramic image can also
be obtained. Besides, with the help of Graphics Processing Unit (GPU), this
algorithm can complete the whole stitching process at a very fast speed:
typically, it only takes less than 30s to obtain a panoramic image of
9000-by-4000 pixels, which means our panorama stitching algorithm is of high
value in many real-time applications. Our code is available at
https://github.com/MungoMeng/Panorama-OpticalFlow.
"
2057,Neural Control Variates,"  We propose neural control variates (NCV) for unbiased variance reduction in
parametric Monte Carlo integration. So far, the core challenge of applying the
method of control variates has been finding a good approximation of the
integrand that is cheap to integrate. We show that a set of neural networks can
face that challenge: a normalizing flow that approximates the shape of the
integrand and another neural network that infers the solution of the integral
equation. We also propose to leverage a neural importance sampler to estimate
the difference between the original integrand and the learned control variate.
To optimize the resulting parametric estimator, we derive a theoretically
optimal, variance-minimizing loss function, and propose an alternative,
composite loss for stable online training in practice. When applied to light
transport simulation, neural control variates are capable of matching the
state-of-the-art performance of other unbiased approaches, while providing
means to develop more performant, practical solutions. Specifically, we show
that the learned light-field approximation is of sufficient quality for
high-order bounces, allowing us to omit the error correction and thereby
dramatically reduce the noise at the cost of negligible visible bias.
"
2058,"Accurate Face Rig Approximation with Deep Differential Subspace
  Reconstruction","  To be suitable for film-quality animation, rigs for character deformation
must fulfill a broad set of requirements. They must be able to create highly
stylized deformation, allow a wide variety of controls to permit artistic
freedom, and accurately reflect the design intent. Facial deformation is
especially challenging due to its nonlinearity with respect to the animation
controls and its additional precision requirements, which often leads to highly
complex face rigs that are not generalizable to other characters. This lack of
generality creates a need for approximation methods that encode the deformation
in simpler structures. We propose a rig approximation method that addresses
these issues by learning localized shape information in differential
coordinates and, separately, a subspace for mesh reconstruction. The use of
differential coordinates produces a smooth distribution of errors in the
resulting deformed surface, while the learned subspace provides constraints
that reduce the low frequency error in the reconstruction. Our method can
reconstruct both face and body deformations with high fidelity and does not
require a set of well-posed animation examples, as we demonstrate with a
variety of production characters.
"
2059,"Integrating Deep Learning into CAD/CAE System: Case Study on Road Wheel
  Design Automation","  Research regarding design automation that integrates artificial intelligence
(AI) into computer-aided design (CAD) and computer-aided engineering (CAE) is
actively being conducted. This study proposes a deep learning-based CAD/CAE
framework that automatically generates three-dimensional (3D) CAD models,
predicts CAE results immediately, explains the results, and verifies the
reliability. The proposed framework comprises seven stages: (1) two-dimensional
(2D) generative design, (2) dimensionality reduction, (3) design of experiment
in latent space, (4) CAD automation, (5) CAE automation, (6) transfer learning,
and (7) visualization and analysis. The proposed framework is demonstrated
through a road wheel design case study and indicates that AI can be practically
incorporated into end-use product design. Using this framework, it is expected
that industrial designers and engineers can jointly review feasible engineering
3D CAD models created by AI and select the best design for the market in the
early stages of product development. In addition, because the proposed deep
learning model can predict CAE results based on 2D disc-view design, industrial
designers can obtain instant feedback regarding the engineering performance of
2D concept sketches.
"
2060,MapTree: Recovering Multiple Solutions in the Space of Maps,"  In this paper we propose an approach for computing multiple high-quality
near-isometric dense correspondences between a pair of 3D shapes. Our method is
fully automatic and does not rely on user-provided landmarks or descriptors.
This allows us to analyze the full space of maps and extract multiple diverse
and accurate solutions, rather than optimizing for a single optimal
correspondence as done in most previous approaches. To achieve this, we propose
a compact tree structure based on the spectral map representation for encoding
and enumerating possible rough initializations, and a novel efficient approach
for refining them to dense pointwise maps. This leads to a new method capable
of both producing multiple high-quality correspondences across shapes and
revealing the symmetry structure of a shape without a priori information. In
addition, we demonstrate through extensive experiments that our method is
robust and results in more accurate correspondences than state-of-the-art for
shape matching and symmetry detection.
"
2061,A Survey on Deep Learning Techniques for Stereo-based Depth Estimation,"  Estimating depth from RGB images is a long-standing ill-posed problem, which
has been explored for decades by the computer vision, graphics, and machine
learning communities. Among the existing techniques, stereo matching remains
one of the most widely used in the literature due to its strong connection to
the human binocular system. Traditionally, stereo-based depth estimation has
been addressed through matching hand-crafted features across multiple images.
Despite the extensive amount of research, these traditional techniques still
suffer in the presence of highly textured areas, large uniform regions, and
occlusions. Motivated by their growing success in solving various 2D and 3D
vision problems, deep learning for stereo-based depth estimation has attracted
growing interest from the community, with more than 150 papers published in
this area between 2014 and 2019. This new generation of methods has
demonstrated a significant leap in performance, enabling applications such as
autonomous driving and augmented reality. In this article, we provide a
comprehensive survey of this new and continuously growing field of research,
summarize the most commonly used pipelines, and discuss their benefits and
limitations. In retrospect of what has been achieved so far, we also conjecture
what the future may hold for deep learning-based stereo for depth estimation
research.
"
2062,"Boosting I/O and visualization for exascale era using Hercule: test case
  on RAMSES","  It has been clearly identified that I/O is one of the bottleneck to extend
application for the exascale era. New concepts such as 'in transit' and 'in
situ' visualization and analysis have been identified as key technologies to
circumvent this particular issue. A new parallel I/O and data management
library called Hercule, developed at CEA-DAM, has been integrated to Ramses, an
AMR simulation code for self-gravitating fluids. Splitting the original Ramses
output format in Hercule database formats dedicated to either
checkpoints/restarts (HProt format) or post-processing (HDep format) not only
improved I/O performance and scalability of the Ramses code but also introduced
much more flexibility in the simulation outputs to help astrophysicists prepare
their DMP (Data Management Plan). Furthermore, the very lightweight and
purpose-specific post-processing format (HDep) will significantly improve the
overall performance of analysis and visualization tools such as PyMSES 5. An
introduction to the Hercule parallel I/O library as well as I/O benchmark
results will be discussed.
"
2063,Simple Primary Colour Editing for Consumer Product Images,"  We present a simple primary colour editing method for consumer product
images. We show that by using colour correction and colour blending, we can
automate the pain-staking colour editing task and save time for consumer colour
preference researchers. To improve the colour harmony between the primary
colour and its complementary colours, our algorithm also tunes the other
colours in the image. Preliminary experiment has shown some promising results
compared with a state-of-the-art method and human editing.
"
2064,"Deep Octree-based CNNs with Output-Guided Skip Connections for 3D Shape
  and Scene Completion","  Acquiring complete and clean 3D shape and scene data is challenging due to
geometric occlusion and insufficient views during 3D capturing. We present a
simple yet effective deep learning approach for completing the input noisy and
incomplete shapes or scenes. Our network is built upon the octree-based CNNs
(O-CNN) with U-Net like structures, which enjoys high computational and memory
efficiency and supports to construct a very deep network structure for 3D CNNs.
A novel output-guided skip-connection is introduced to the network structure
for better preserving the input geometry and learning geometry prior from data
effectively. We show that with these simple adaptions -- output-guided
skip-connection and deeper O-CNN (up to 70 layers), our network achieves
state-of-the-art results in 3D shape completion and semantic scene computation.
"
2065,Robust Learning Through Cross-Task Consistency,"  Visual perception entails solving a wide set of tasks, e.g., object
detection, depth estimation, etc. The predictions made for multiple tasks from
the same image are not independent, and therefore, are expected to be
consistent. We propose a broadly applicable and fully computational method for
augmenting learning with Cross-Task Consistency. The proposed formulation is
based on inference-path invariance over a graph of arbitrary tasks. We observe
that learning with cross-task consistency leads to more accurate predictions
and better generalization to out-of-distribution inputs. This framework also
leads to an informative unsupervised quantity, called Consistency Energy, based
on measuring the intrinsic consistency of the system. Consistency Energy
correlates well with the supervised error (r=0.67), thus it can be employed as
an unsupervised confidence metric as well as for detection of
out-of-distribution inputs (ROC-AUC=0.95). The evaluations are performed on
multiple datasets, including Taskonomy, Replica, CocoDoom, and ApolloScape, and
they benchmark cross-task consistency versus various baselines including
conventional multi-task learning, cycle consistency, and analytical
consistency.
"
2066,"DiffGCN: Graph Convolutional Networks via Differential Operators and
  Algebraic Multigrid Pooling","  Graph Convolutional Networks (GCNs) have shown to be effective in handling
unordered data like point clouds and meshes. In this work we propose novel
approaches for graph convolution, pooling and unpooling, inspired from finite
differences and algebraic multigrid frameworks. We form a parameterized
convolution kernel based on discretized differential operators, leveraging the
graph mass, gradient and Laplacian. This way, the parameterization does not
depend on the graph structure, only on the meaning of the network convolutions
as differential operators. To allow hierarchical representations of the input,
we propose pooling and unpooling operations that are based on algebraic
multigrid methods, which are mainly used to solve partial differential
equations on unstructured grids. To motivate and explain our method, we compare
it to standard convolutional neural networks, and show their similarities and
relations in the case of a regular grid. Our proposed method is demonstrated in
various experiments like classification and part-segmentation, achieving on par
or better than state of the art results. We also analyze the computational cost
of our method compared to other GCNs.
"
2067,RBF Solver for Quaternions Interpolation,"  In this paper we adapt the RBF Solver to work with quaternions by taking
advantage of their Lie Algebra and exponential map. This will allow to work
with quaternions as if they were normal vectors in R^3 and blend them in a very
efficient way.
"
2068,"Approximate learning of high dimensional Bayesian network structures via
  pruning of Candidate Parent Sets","  Score-based algorithms that learn Bayesian Network (BN) structures provide
solutions ranging from different levels of approximate learning to exact
learning. Approximate solutions exist because exact learning is generally not
applicable to networks of moderate or higher complexity. In general,
approximate solutions tend to sacrifice accuracy for speed, where the aim is to
minimise the loss in accuracy and maximise the gain in speed. While some
approximate algorithms are optimised to handle thousands of variables, these
algorithms may still be unable to learn such high dimensional structures. Some
of the most efficient score-based algorithms cast the structure learning
problem as a combinatorial optimisation of candidate parent sets. This paper
explores a strategy towards pruning the size of candidate parent sets, aimed at
high dimensionality problems. The results illustrate how different levels of
pruning affect the learning speed relative to the loss in accuracy in terms of
model fitting, and show that aggressive pruning may be required to produce
approximate solutions for high complexity problems.
"
2069,Network visualizations with Pyvis and VisJS,"  Pyvis is a Python module that enables visualizing and interactively
manipulating network graphs in the Jupyter notebook, or as a standalone web
application. Pyvis is built on top of the powerful and mature VisJS JavaScript
library, which allows for fast and responsive interactions while also
abstracting away the low-level JavaScript and HTML. This means that elements of
the rendered graph visualization, such as node/edge attributes can be specified
within Python and shipped to the JavaScript layer for VisJS to render. This
declarative approach makes it easy to quickly explore graph visualizations and
investigate data relationships. In addition, Pyvis is highly customizable so
that colors, sizes, and hover tooltips can be assigned to the rendered graph.
The network graph layout is controlled by a front-end physics engine that is
configurable from a Python interface, allowing for the detailed placement of
the graph elements. In this paper, we outline use cases for Pyvis with specific
examples to highlight key features for any analysis workflow. A brief overview
of Pyvis' implementation describes how the Python front-end binding uses simple
Pyvis calls.
"
2070,SALD: Sign Agnostic Learning with Derivatives,"  Learning 3D geometry directly from raw data, such as point clouds, triangle
soups, or unoriented meshes is still a challenging task that feeds many
downstream computer vision and graphics applications.
  In this paper, we introduce SALD: a method for learning implicit neural
representations of shapes directly from raw data. We generalize sign agnostic
learning (SAL) to include derivatives: given an unsigned distance function to
the input raw data, we advocate a novel sign agnostic regression loss,
incorporating both pointwise values and gradients of the unsigned distance
function. Optimizing this loss leads to a signed implicit function solution,
the zero level set of which is a high quality and valid manifold approximation
to the input 3D data. The motivation behind SALD is that incorporating
derivatives in a regression loss leads to a lower sample complexity, and
consequently better fitting. In addition, we prove that SAL enjoys a minimal
length property in 2D, favoring minimal length solutions. More importantly, we
are able to show that this property still holds for SALD, i.e., with
derivatives included.
  We demonstrate the efficacy of SALD for shape space learning on two
challenging datasets: ShapeNet that contains inconsistent orientation and
non-manifold meshes, and D-Faust that contains raw 3D scans (triangle soups).
On both these datasets, we present state-of-the-art results.
"
2071,"Real-time single image depth perception in the wild with handheld
  devices","  Depth perception is paramount to tackle real-world problems, ranging from
autonomous driving to consumer applications. For the latter, depth estimation
from a single image represents the most versatile solution, since a standard
camera is available on almost any handheld device. Nonetheless, two main issues
limit its practical deployment: i) the low reliability when deployed
in-the-wild and ii) the demanding resource requirements to achieve real-time
performance, often not compatible with such devices. Therefore, in this paper,
we deeply investigate these issues showing how they are both addressable
adopting appropriate network design and training strategies -- also outlining
how to map the resulting networks on handheld devices to achieve real-time
performance. Our thorough evaluation highlights the ability of such fast
networks to generalize well to new environments, a crucial feature required to
tackle the extremely varied contexts faced in real applications. Indeed, to
further support this evidence, we report experimental results concerning
real-time depth-aware augmented reality and image blurring with smartphones
in-the-wild.
"
2072,Towards 3D Dance Motion Synthesis and Control,"  3D human dance motion is a cooperative and elegant social movement. Unlike
regular simple locomotion, it is challenging to synthesize artistic dance
motions due to the irregularity, kinematic complexity and diversity. It
requires the synthesized dance is realistic, diverse and controllable. In this
paper, we propose a novel generative motion model based on temporal convolution
and LSTM,TC-LSTM, to synthesize realistic and diverse dance motion. We
introduce a unique control signal, dance melody line, to heighten
controllability. Hence, our model, and its switch for control signals, promote
a variety of applications: random dance synthesis, music-to-dance, user
control, and more. Our experiments demonstrate that our model can synthesize
artistic dance motion in various dance types. Compared with existing methods,
our method achieved start-of-the-art results.
"
2073,"Computational Design and Evaluation Methods for Empowering Non-Experts
  in Digital Fabrication","  Despite the increasing availability of personal fabrication hardware and
services, the true potential of digital fabrication remains unrealized due to
lack of computational techniques that can support 3D shape design by
non-experts. This work develops computational methods that address two key
aspects of content creation:(1) Function-driven design synthesis, (2) Design
assessment.
  For design synthesis, a generative shape modeling algorithm that facilitates
automatic geometry synthesis and user-driven modification for non-experts is
introduced. A critical observation that arises from this study is that the most
geometrical specifications are dictated by functional requirements. To support
design by high-level functional prescriptions, a physics based shape
optimization method for compliant coupling behavior design has been developed.
In line with this idea, producing complex 3D surfaces from flat 2D sheets by
exploiting the concept of buckling beams has also been explored. Effective
design assessment, the second key aspect, becomes critical for problems in
which computational solutions do not exist. For these problems, this work
proposes crowdsourcing as a way to empower non-experts in esoteric design
domains that traditionally require expertise and specialized knowledge.
"
2074,"Affective Movement Generation using Laban Effort and Shape and Hidden
  Markov Models","  Body movements are an important communication medium through which affective
states can be discerned. Movements that convey affect can also give machines
life-like attributes and help to create a more engaging human-machine
interaction. This paper presents an approach for automatic affective movement
generation that makes use of two movement abstractions: 1) Laban movement
analysis (LMA), and 2) hidden Markov modeling. The LMA provides a systematic
tool for an abstract representation of the kinematic and expressive
characteristics of movements. Given a desired motion path on which a target
emotion is to be overlaid, the proposed approach searches a labeled dataset in
the LMA Effort and Shape space for similar movements to the desired motion path
that convey the target emotion. An HMM abstraction of the identified movements
is obtained and used with the desired motion path to generate a novel movement
that is a modulated version of the desired motion path that conveys the target
emotion. The extent of modulation can be varied, trading-off between kinematic
and affective constraints in the generated movement. The proposed approach is
tested using a full-body movement dataset. The efficacy of the proposed
approach in generating movements with recognizable target emotions is assessed
using a validated automatic recognition model and a user study. The target
emotions were correctly recognized from the generated movements at a rate of
72% using the recognition model. Furthermore, participants in the user study
were able to correctly perceive the target emotions from a sample of generated
movements, although some cases of confusion were also observed.
"
2075,Least-Squares Affine Reflection Using Eigen Decomposition,"  This note summarizes the steps to computing the best-fitting affine
reflection that aligns two sets of corresponding points.
"
2076,Curvature of planar aesthetic curves,"  Farin proposed a method for designing Bezier curves with monotonic curvature
and torsion. Such curves are relevant in design due to their aesthetic shape.
The method relies on applying a matrix M to the first edge of the control
polygon of the curve in order to obtain by iteration the remaining edges. With
this method, sufficient conditions on the matrix $M$ are provided, which lead
to the definition of Class A curves, generalising a previous result by Mineur
et al for plane curves with M being the composition of a dilatation and a
rotation. However, Cao and Wang have shown counterexamples for such conditions.
In this paper, we revisit Farin's idea of using the subdivision algorithm to
relate the curvature at every point of the curve to the curvature at the
initial point in order to produce a closed formula for the curvature of planar
curves in terms of the eigenvalues of the matrix M and the seed vector for the
curve, the first edge of the control polygon. Moreover, we give new conditions
in order to produce planar curves with monotonic curvature. The main difference
is that we do not require our conditions on the eigenvalues to be preserved
under subdivision of the curve. This facilitates giving a unified derivation of
the existing results and obtain more general results in the planar case.
"
2077,"Residual Force Control for Agile Human Behavior Imitation and Extended
  Motion Synthesis","  Reinforcement learning has shown great promise for synthesizing realistic
human behaviors by learning humanoid control policies from motion capture data.
However, it is still very challenging to reproduce sophisticated human skills
like ballet dance, or to stably imitate long-term human behaviors with complex
transitions. The main difficulty lies in the dynamics mismatch between the
humanoid model and real humans. That is, motions of real humans may not be
physically possible for the humanoid model. To overcome the dynamics mismatch,
we propose a novel approach, residual force control (RFC), that augments a
humanoid control policy by adding external residual forces into the action
space. During training, the RFC-based policy learns to apply residual forces to
the humanoid to compensate for the dynamics mismatch and better imitate the
reference motion. Experiments on a wide range of dynamic motions demonstrate
that our approach outperforms state-of-the-art methods in terms of convergence
speed and the quality of learned motions. Notably, we showcase a physics-based
virtual character empowered by RFC that can perform highly agile ballet dance
moves such as pirouette, arabesque and jet\'e. Furthermore, we propose a
dual-policy control framework, where a kinematic policy and an RFC-based policy
work in tandem to synthesize multi-modal infinite-horizon human motions without
any task guidance or user input. Our approach is the first humanoid control
method that successfully learns from a large-scale human motion dataset
(Human3.6M) and generates diverse long-term motions. Code and videos are
available at https://www.ye-yuan.com/rfc.
"
2078,Convolutional Generation of Textured 3D Meshes,"  While recent generative models for 2D images achieve impressive visual
results, they clearly lack the ability to perform 3D reasoning. This heavily
restricts the degree of control over generated objects as well as the possible
applications of such models. In this work, we bridge this gap by leveraging
recent advances in differentiable rendering. We design a framework that can
generate triangle meshes and associated high-resolution texture maps, using
only 2D supervision from single-view natural images. A key contribution of our
work is the encoding of the mesh and texture as 2D representations, which are
semantically aligned and can be easily modeled by a 2D convolutional GAN. We
demonstrate the efficacy of our method on Pascal3D+ Cars and CUB, both in an
unconditional setting and in settings where the model is conditioned on class
labels, attributes, and text. Finally, we propose an evaluation methodology
that assesses the mesh and texture quality separately.
"
2079,"Alternating ConvLSTM: Learning Force Propagation with Alternate State
  Updates","  Data-driven simulation is an important step-forward in computational physics
when traditional numerical methods meet their limits. Learning-based simulators
have been widely studied in past years; however, most previous works view
simulation as a general spatial-temporal prediction problem and take little
physical guidance in designing their neural network architectures. In this
paper, we introduce the alternating convolutional Long Short-Term Memory
(Alt-ConvLSTM) that models the force propagation mechanisms in a deformable
object with near-uniform material properties. Specifically, we propose an
accumulation state, and let the network update its cell state and the
accumulation state alternately. We demonstrate how this novel scheme imitates
the alternate updates of the first and second-order terms in the forward Euler
method of numerical PDE solvers. Benefiting from this, our network only
requires a small number of parameters, independent of the number of the
simulated particles, and also retains the essential features in ConvLSTM,
making it naturally applicable to sequential data with spatial inputs and
outputs. We validate our Alt-ConvLSTM on human soft tissue simulation with
thousands of particles and consistent body pose changes. Experimental results
show that Alt-ConvLSTM efficiently models the material kinetic features and
greatly outperforms vanilla ConvLSTM with only the single state update.
"
2080,Repulsive Curves,"  Curves play a fundamental role across computer graphics, physical simulation,
and mathematical visualization, yet most tools for curve design do nothing to
prevent crossings or self-intersections. This paper develops efficient
algorithms for (self-)repulsion of plane and space curves that are well-suited
to problems in computational design. Our starting point is the so-called
tangent-point energy, which provides an infinite barrier to self-intersection.
In contrast to local collision detection strategies used in, e.g., physical
simulation, this energy considers interactions between all pairs of points, and
is hence useful for global shape optimization: local minima tend to be
aesthetically pleasing, physically valid, and nicely distributed in space. A
reformulation of gradient descent, based on a Sobolev-Slobodeckij inner product
enables us to make rapid progress toward local minima---independent of curve
resolution. We also develop a hierarchical multigrid scheme that significantly
reduces the per-step cost of optimization. The energy is easily integrated with
a variety of constraints and penalties (e.g., inextensibility, or obstacle
avoidance), which we use for applications including curve packing, knot
untangling, graph embedding, non-crossing spline interpolation, flow
visualization, and robotic path planning.
"
2081,ShapeFlow: Learnable Deformations Among 3D Shapes,"  We present ShapeFlow, a flow-based model for learning a deformation space for
entire classes of 3D shapes with large intra-class variations. ShapeFlow allows
learning a multi-template deformation space that is agnostic to shape topology,
yet preserves fine geometric details. Different from a generative space where a
latent vector is directly decoded into a shape, a deformation space decodes a
vector into a continuous flow that can advect a source shape towards a target.
Such a space naturally allows the disentanglement of geometric style (coming
from the source) and structural pose (conforming to the target). We parametrize
the deformation between geometries as a learned continuous flow field via a
neural network and show that such deformations can be guaranteed to have
desirable properties, such as be bijectivity, freedom from self-intersections,
or volume preservation. We illustrate the effectiveness of this learned
deformation space for various downstream applications, including shape
generation via deformation, geometric style transfer, unsupervised learning of
a consistent parameterization for entire classes of shapes, and shape
interpolation.
"
2082,"Geo-PIFu: Geometry and Pixel Aligned Implicit Functions for Single-view
  Human Reconstruction","  We propose Geo-PIFu, a method to recover a 3D mesh from a monocular color
image of a clothed person. Our method is based on a deep implicit
function-based representation to learn latent voxel features using a
structure-aware 3D U-Net, to constrain the model in two ways: first, to resolve
feature ambiguities in query point encoding, second, to serve as a coarse human
shape proxy to regularize the high-resolution mesh and encourage global shape
regularity. We show that, by both encoding query points and constraining global
shape using latent voxel features, the reconstruction we obtain for clothed
human meshes exhibits less shape distortion and improved surface details
compared to competing methods. We evaluate Geo-PIFu on a recent human mesh
public dataset that is $10 \times$ larger than the private commercial dataset
used in PIFu and previous derivative work. On average, we exceed the state of
the art by $42.7\%$ reduction in Chamfer and Point-to-Surface Distances, and
$19.4\%$ reduction in normal estimation errors.
"
2083,"A study of the effect of the illumination model on the generation of
  synthetic training datasets","  The use of computer generated images to train Deep Neural Networks is a
viable alternative to real images when the latter are scarce or expensive. In
this paper, we study how the illumination model used by the rendering software
affects the quality of the generated images. We created eight training sets,
each one with a different illumination model, and tested them on three
different network architectures, ResNet, U-Net and a combined architecture
developed by us. The test set consisted of photos of 3D printed objects
produced from the same CAD models used to generate the training set. The effect
of the other parameters of the rendering process, such as textures and camera
position, was randomized.
  Our results show that the effect of the illumination model is important,
comparable in significance to the network architecture. We also show that both
light probes capturing natural environmental light, and modelled lighting
environments, can give good results. In the case of light probes, we identified
as two significant factors affecting performance the similarity between the
light probe and the test environment, as well as the light probe's resolution.
Regarding modelled lighting environment, similarity with the test environment
was again identified as a significant factor.
"
2084,EMU: Efficient Muscle Simulation In Deformation Space,"  EMU is an efficient and scalable model to simulate bulk musculoskeletal
motion with heterogenous materials. First, EMU requires no model reductions, or
geometric coarsening, thereby producing results visually accurate when compared
to an FEM simulation. Second, EMU is efficient and scales much better than
state-of-the-art FEM with the number of elements in the mesh, and is more
easily parallelizable. Third, EMU can handle heterogeneously stiff meshes with
an arbitrary constitutive model, thus allowing it to simulate soft muscles,
stiff tendons and even stiffer bones all within one unified system. These three
key characteristics of EMU enable us to efficiently orchestrate muscle
activated skeletal movements. We demonstrate the efficacy of our approach via a
number of examples with tendons, muscles, bones and joints.
"
2085,MetaSDF: Meta-learning Signed Distance Functions,"  Neural implicit shape representations are an emerging paradigm that offers
many potential benefits over conventional discrete representations, including
memory efficiency at a high spatial resolution. Generalizing across shapes with
such neural implicit representations amounts to learning priors over the
respective function space and enables geometry reconstruction from partial or
noisy observations. Existing generalization methods rely on conditioning a
neural network on a low-dimensional latent code that is either regressed by an
encoder or jointly optimized in the auto-decoder framework. Here, we formalize
learning of a shape space as a meta-learning problem and leverage
gradient-based meta-learning algorithms to solve this task. We demonstrate that
this approach performs on par with auto-decoder based approaches while being an
order of magnitude faster at test-time inference. We further demonstrate that
the proposed gradient-based method outperforms encoder-decoder based methods
that leverage pooling-based set encoders.
"
2086,"An Evolutional Algorithm for Automatic 2D Layer Segmentation in
  Laser-aided Additive Manufacturing","  Toolpath planning is an important task in laser aided additive manufacturing
(LAAM) and other direct energy deposition (DED) processes. The deposition
toolpaths for complex geometries with slender structures can be further
optimized by partitioning the sliced 2D layers into sub-regions, and enable the
design of appropriate infill toolpaths for different sub-regions. However,
reported approaches for 2D layer segmentation generally require manual
operations that are tedious and time-consuming. To increase segmentation
efficiency, this paper proposes an autonomous approach based on evolutional
computation for 2D layer segmentation. The algorithm works in an
identify-and-segment manner. Specifically, the largest quasi-quadrilateral is
identified and segmented from the target layer iteratively. Results from case
studies have validated the effectiveness and efficacy of the developed
algorithm. To further improve its performance, a roughing-finishing strategy is
proposed. Via multi-processing, the strategy can remarkably increase the
solution variety without affecting solution quality and search time, thus
providing great application potential in LAAM toolpath planning. To the best of
the authors knowledge, this work is the first to address automatic 2D layer
segmentation problem in LAAM process. Therefore, it may be a valuable
supplement to the state of the art in this area.
"
2087,"Sky Optimization: Semantically aware image processing of skies in
  low-light photography","  The sky is a major component of the appearance of a photograph, and its color
and tone can strongly influence the mood of a picture. In nighttime
photography, the sky can also suffer from noise and color artifacts. For this
reason, there is a strong desire to process the sky in isolation from the rest
of the scene to achieve an optimal look. In this work, we propose an automated
method, which can run as a part of a camera pipeline, for creating accurate sky
alpha-masks and using them to improve the appearance of the sky. Our method
performs end-to-end sky optimization in less than half a second per image on a
mobile device. We introduce a method for creating an accurate sky-mask dataset
that is based on partially annotated images that are inpainted and refined by
our modified weighted guided filter. We use this dataset to train a neural
network for semantic sky segmentation. Due to the compute and power constraints
of mobile devices, sky segmentation is performed at a low image resolution. Our
modified weighted guided filter is used for edge-aware upsampling to resize the
alpha-mask to a higher resolution. With this detailed mask we automatically
apply post-processing steps to the sky in isolation, such as automatic
spatially varying white-balance, brightness adjustments, contrast enhancement,
and noise reduction.
"
2088,Structure and Design of HoloGen,"  Increasing popularity of augmented and mixed reality systems has seen a
similar increase of interest in 2D and 3D computer generated holography (CGH).
Unlike stereoscopic approaches, CGH can fully represent a light field including
depth of focus, accommodation and vergence. Along with existing
telecommunications, imaging, projection, lithography, beam shaping and optical
tweezing applications, CGH is an exciting technique applicable to a wide array
of photonic problems including full 3D representation. Traditionally, the
primary roadblock to acceptance has been the significant numerical processing
required to generate holograms requiring both significant expertise and
significant computational power. This article discusses the structure and
design of HoloGen. HoloGen is an MIT licensed application that may be used to
generate holograms using a wide array of algorithms without expert guidance.
HoloGen uses a Cuda C and C++ backend with a C# and Windows Presentation
Framework graphical user interface. The article begins by introducing HoloGen
before providing an in-depth discussion of its design and structure. Particular
focus is given to the communication, data transfer and algorithmic aspects.
"
2089,Differentiable Augmentation for Data-Efficient GAN Training,"  The performance of generative adversarial networks (GANs) heavily
deteriorates given a limited amount of training data. This is mainly because
the discriminator is memorizing the exact training set. To combat it, we
propose Differentiable Augmentation (DiffAugment), a simple method that
improves the data efficiency of GANs by imposing various types of
differentiable augmentations on both real and fake samples. Previous attempts
to directly augment the training data manipulate the distribution of real
images, yielding little benefit; DiffAugment enables us to adopt the
differentiable augmentation for the generated samples, effectively stabilizes
training, and leads to better convergence. Experiments demonstrate consistent
gains of our method over a variety of GAN architectures and loss functions for
both unconditional and class-conditional generation. With DiffAugment, we
achieve a state-of-the-art FID of 6.80 with an IS of 100.8 on ImageNet 128x128
and 2-4x reductions of FID given 1,000 images on FFHQ and LSUN. Furthermore,
with only 20% training data, we can match the top performance on CIFAR-10 and
CIFAR-100. Finally, our method can generate high-fidelity images using only 100
images without pre-training, while being on par with existing transfer learning
algorithms. Code is available at
https://github.com/mit-han-lab/data-efficient-gans.
"
2090,Ray-VR: Ray Tracing Virtual Reality in Falcor,"  NVidia RTX platform has been changing and extending the possibilities for
real time Computer Graphics applications. It is the first time in history that
retail graphics cards have full hardware support for ray tracing primitives. It
still a long way to fully understand and optimize its use and this task itself
is a fertile field for scientific progression. However, another path is to
explore the platform as an expansion of paradigms for other problems. For
example, the integration of real time Ray Tracing and Virtual Reality can
result in interesting applications for visualization of Non-Euclidean Geometry
and 3D Manifolds. In this paper we present Ray-VR, a novel algorithm for real
time stereo ray tracing, constructed on top of Falcor, NVidia's scientific
prototyping framework.
"
2091,Technical Note: Generating Realistic Fighting Scenes by Game Tree,"  Recently, there have been a lot of researches to synthesize / edit the motion
of a single avatar in the virtual environment. However, there has not been so
much work of simulating continuous interactions of multiple avatars such as
fighting. In this paper, we propose a new method to generate a realistic
fighting scene based on motion capture data. We propose a new algorithm called
the temporal expansion approach which maps the continuous time action plan to a
discrete causality space such that turn-based evaluation methods can be used.
As a result, it is possible to use many mature algorithms available in strategy
games such as the Minimax algorithm and $\alpha-\beta$ pruning. We also propose
a method to generate and use an offense/defense table, which illustrates the
spatial-temporal relationship of attacks and dodges, to incorporate tactical
maneuvers of defense into the scene. Using our method, avatars will plan their
strategies taking into account the reaction of the opponent. Fighting scenes
with multiple avatars are generated to demonstrate the effectiveness of our
algorithm. The proposed method can also be applied to other kinds of continuous
activities that require strategy planning such as sport games.
"
2092,Quanta Burst Photography,"  Single-photon avalanche diodes (SPADs) are an emerging sensor technology
capable of detecting individual incident photons, and capturing their
time-of-arrival with high timing precision. While these sensors were limited to
single-pixel or low-resolution devices in the past, recently, large (up to 1
MPixel) SPAD arrays have been developed. These single-photon cameras (SPCs) are
capable of capturing high-speed sequences of binary single-photon images with
no read noise. We present quanta burst photography, a computational photography
technique that leverages SPCs as passive imaging devices for photography in
challenging conditions, including ultra low-light and fast motion. Inspired by
recent success of conventional burst photography, we design algorithms that
align and merge binary sequences captured by SPCs into intensity images with
minimal motion blur and artifacts, high signal-to-noise ratio (SNR), and high
dynamic range. We theoretically analyze the SNR and dynamic range of quanta
burst photography, and identify the imaging regimes where it provides
significant benefits. We demonstrate, via a recently developed SPAD array, that
the proposed method is able to generate high-quality images for scenes with
challenging lighting, complex geometries, high dynamic range and moving
objects. With the ongoing development of SPAD arrays, we envision quanta burst
photography finding applications in both consumer and scientific photography.
"
2093,Perspective Texture Synthesis Based on Improved Energy Optimization,"  Perspective texture synthesis has great significance in many fields like
video editing, scene capturing etc., due to its ability to read and control
global feature information. In this paper, we present a novel example-based,
specifically energy optimization-based algorithm, to synthesize perspective
textures. Energy optimization technique is a pixel-based approach, so it is
time-consuming. We improve it from two aspects with the purpose of achieving
faster synthesis and high quality. Firstly, we change this pixel-based
technique by replacing the pixel computation with a little patch. Secondly, we
present a novel technique to accelerate searching nearest neighborhoods in
energy optimization. Using k- means clustering technique to build a search tree
to accelerate the search. Hence, we make use of principal component analysis
(PCA) technique to reduce dimensions of input vectors. The high quality results
prove that our approach is feasible. Besides, our proposed algorithm needs
shorter time relative to other similar methods.
"
2094,Differentiable Rendering: A Survey,"  Deep neural networks (DNNs) have shown remarkable performance improvements on
vision-related tasks such as object detection or image segmentation. Despite
their success, they generally lack the understanding of 3D objects which form
the image, as it is not always possible to collect 3D information about the
scene or to easily annotate it. Differentiable rendering is a novel field which
allows the gradients of 3D objects to be calculated and propagated through
images. It also reduces the requirement of 3D data collection and annotation,
while enabling higher success rate in various applications. This paper reviews
existing literature and discusses the current state of differentiable
rendering, its applications and open research problems.
"
2095,"MotioNet: 3D Human Motion Reconstruction from Monocular Video with
  Skeleton Consistency","  We introduce MotioNet, a deep neural network that directly reconstructs the
motion of a 3D human skeleton from monocular video.While previous methods rely
on either rigging or inverse kinematics (IK) to associate a consistent skeleton
with temporally coherent joint rotations, our method is the first data-driven
approach that directly outputs a kinematic skeleton, which is a complete,
commonly used, motion representation. At the crux of our approach lies a deep
neural network with embedded kinematic priors, which decomposes sequences of 2D
joint positions into two separate attributes: a single, symmetric, skeleton,
encoded by bone lengths, and a sequence of 3D joint rotations associated with
global root positions and foot contact labels. These attributes are fed into an
integrated forward kinematics (FK) layer that outputs 3D positions, which are
compared to a ground truth. In addition, an adversarial loss is applied to the
velocities of the recovered rotations, to ensure that they lie on the manifold
of natural joint rotations. The key advantage of our approach is that it learns
to infer natural joint rotations directly from the training data, rather than
assuming an underlying model, or inferring them from joint positions using a
data-agnostic IK solver. We show that enforcing a single consistent skeleton
along with temporally coherent joint rotations constrains the solution space,
leading to a more robust handling of self-occlusions and depth ambiguities.
"
2096,"A Baseline Approach for AutoImplant: the MICCAI 2020 Cranial Implant
  Design Challenge","  In this study, we present a baseline approach for AutoImplant
(https://autoimplant.grand-challenge.org/) - the cranial implant design
challenge, which, as suggested by the organizers, can be formulated as a
volumetric shape learning task. In this task, the defective skull, the complete
skull and the cranial implant are represented as binary voxel grids. To
accomplish this task, the implant can be either reconstructed directly from the
defective skull or obtained by taking the difference between a defective skull
and a complete skull. In the latter case, a complete skull has to be
reconstructed given a defective skull, which defines a volumetric shape
completion problem. Our baseline approach for this task is based on the former
formulation, i.e., a deep neural network is trained to predict the implants
directly from the defective skulls. The approach generates high-quality
implants in two steps: First, an encoder-decoder network learns a coarse
representation of the implant from down-sampled, defective skulls; The coarse
implant is only used to generate the bounding box of the defected region in the
original high-resolution skull. Second, another encoder-decoder network is
trained to generate a fine implant from the bounded area. On the test set, the
proposed approach achieves an average dice similarity score (DSC) of 0.8555 and
Hausdorff distance (HD) of 5.1825 mm. The code is publicly available at
https://github.com/Jianningli/autoimplant.
"
2097,"SN-Engine, a Scale-free Geometric Modelling Environment","  We present a new scale-free geometric modelling environment designed by the
author of the paper. It allows one to consistently treat geometric objects of
arbitrary size and offers extensive analytic and computational support for
visualization of both real and artificial sceneries.
"
2098,Steiner's Hat: a Constant-Area Deltoid Associated with the Ellipse,"  The Negative Pedal Curve (NPC) of the Ellipse with respect to a boundary
point M is a 3-cusp closed-curve which is the affine image of the Steiner
Deltoid. Over all M the family has invariant area and displays an array of
interesting properties.
"
2099,Efficient Spatially Adaptive Convolution and Correlation,"  Fast methods for convolution and correlation underlie a variety of
applications in computer vision and graphics, including efficient filtering,
analysis, and simulation. However, standard convolution and correlation are
inherently limited to fixed filters: spatial adaptation is impossible without
sacrificing efficient computation. In early work, Freeman and Adelson have
shown how steerable filters can address this limitation, providing a way for
rotating the filter as it is passed over the signal. In this work, we provide a
general, representation-theoretic, framework that allows for spatially varying
linear transformations to be applied to the filter. This framework allows for
efficient implementation of extended convolution and correlation for
transformation groups such as rotation (in 2D and 3D) and scale, and provides a
new interpretation for previous methods including steerable filters and the
generalized Hough transform. We present applications to pattern matching, image
feature description, vector field visualization, and adaptive image filtering.
"
2100,Neural Non-Rigid Tracking,"  We introduce a novel, end-to-end learnable, differentiable non-rigid tracker
that enables state-of-the-art non-rigid reconstruction. Given two input RGB-D
frames of a non-rigidly moving object, we employ a convolutional neural network
to predict dense correspondences. These correspondences are used as constraints
in an as-rigid-as-possible (ARAP) optimization problem. By enabling gradient
back-propagation through the non-rigid optimization solver, we are able to
learn correspondences in an end-to-end manner such that they are optimal for
the task of non-rigid tracking. Furthermore, this formulation allows for
learning correspondence weights in a self-supervised manner. Thus, outliers and
wrong correspondences are down-weighted to enable robust tracking. Compared to
state-of-the-art approaches, our algorithm shows improved reconstruction
performance, while simultaneously achieving 85 times faster correspondence
prediction than comparable deep-learning based methods.
"
2101,OMiCroN -- Oblique Multipass Hierarchy Creation while Navigating,"  Rendering large point clouds ordinarily requires building a hierarchical data
structure for accessing the points that best represent the object for a given
viewing frustum and level-of-detail. The building of such data structures
frequently represents a large portion of the cost of the rendering pipeline
both in terms of time and space complexity, especially when rendering is done
for inspection purposes only. This problem has been addressed in the past by
incremental construction approaches, but these either result in low quality
hierarchies or in longer construction times. In this work we present OMiCroN --
Oblique Multipass Hierarchy Creation while Navigating -- which is the first
algorithm capable of immediately displaying partial renders of the geometry,
provided the cloud is made available sorted in Morton order. OMiCroN is fast,
being capable of building the entire data structure in memory spending an
amount of time that is comparable to that of just reading the cloud from disk.
Thus, there is no need for storing an expensive hierarchy, nor for delaying the
rendering until the whole hierarchy is read from disk. In fact, a pipeline
coupling OMiCroN with an incremental sorting algorithm running in parallel can
start rendering as soon as the first sorted prefix is produced, making this
setup very convenient for streamed viewing.
"
2102,A Benchmarking Framework for Interactive 3D Applications in the Cloud,"  With the growing popularity of cloud gaming and cloud virtual reality (VR),
interactive 3D applications have become a major type of workloads for the
cloud. However, despite their growing importance, there is limited public
research on how to design cloud systems to efficiently support these
applications, due to the lack of an open and reliable research infrastructure,
including benchmarks and performance analysis tools. The challenges of
generating human-like inputs under various system/application randomness and
dissecting the performance of complex graphics systems make it very difficult
to design such an infrastructure. In this paper, we present the design of a
novel cloud graphics rendering research infrastructure, Pictor. Pictor employs
AI to mimic human interactions with complex 3D applications. It can also
provide in-depth performance measurements for the complex software and hardware
stack used for cloud 3D graphics rendering. With Pictor, we designed a
benchmark suite with six interactive 3D applications. Performance analyses were
conducted with these benchmarks to characterize 3D applications in the cloud
and reveal new performance bottlenecks. To demonstrate the effectiveness of
Pictor, we also implemented two optimizations to address two performance
bottlenecks discovered in a state-of-the-art cloud 3D-graphics rendering
system, which improved the frame rate by 57.7% on average.
"
2103,Neural Splines: Fitting 3D Surfaces with Infinitely-Wide Neural Networks,"  We present Neural Splines, a technique for 3D surface reconstruction that is
based on random feature kernels arising from infinitely-wide shallow ReLU
networks. Our method achieves state-of-the-art results, outperforming Screened
Poisson Surface Reconstruction and modern neural network based techniques.
Because our approach is based on a simple kernel formulation, it is fast to run
and easy to analyze. We provide explicit analytical expressions for our kernel
and argue that our formulation can be seen as a generalization of cubic spline
interpolation to higher dimensions. In particular, the RKHS norm associated
with our kernel biases toward smooth interpolants. Finally, we formulate
Screened Poisson Surface Reconstruction as a kernel method and derive an
analytic expression for its norm in the corresponding RKHS.
"
2104,Understanding SSIM,"  The use of the structural similarity index (SSIM) is widespread. For almost
two decades, it has played a major role in image quality assessment in many
different research disciplines. Clearly, its merits are indisputable in the
research community. However, little deep scrutiny of this index has been
performed. Contrary to popular belief, there are some interesting properties of
SSIM that merit such scrutiny. In this paper, we analyze the mathematical
factors of SSIM and show that it can generate results, in both synthetic and
realistic use cases, that are unexpected, sometimes undefined, and
nonintuitive. As a consequence, assessing image quality based on SSIM can lead
to incorrect conclusions and using SSIM as a loss function for deep learning
can guide neural network training in the wrong direction.
"
2105,"Tilt Map: Interactive Transitions Between Choropleth Map, Prism Map and
  Bar Chart in Immersive Environments","  We introduce Tilt Map, a novel interaction technique for intuitively
transitioning between 2D and 3D map visualisations in immersive environments.
Our focus is visualising data associated with areal features on maps, for
example, population density by state. Tilt Map transitions from 2D choropleth
maps to 3D prism maps to 2D bar charts to overcome the limitations of each. Our
paper includes two user studies. The first study compares subjects' task
performance interpreting population density data using 2D choropleth maps and
3D prism maps in virtual reality (VR). We observed greater task accuracy with
prism maps, but faster response times with choropleth maps. The complementarity
of these views inspired our hybrid Tilt Map design. Our second study compares
Tilt Map to: a side-by-side arrangement of the various views; and interactive
toggling between views. The results indicate benefits for Tilt Map in user
preference; and accuracy (versus side-by-side) and time (versus toggle).
"
2106,"Anderson Acceleration for Nonconvex ADMM Based on Douglas-Rachford
  Splitting","  The alternating direction multiplier method (ADMM) is widely used in computer
graphics for solving optimization problems that can be nonsmooth and nonconvex.
It converges quickly to an approximate solution, but can take a long time to
converge to a solution of high-accuracy. Previously, Anderson acceleration has
been applied to ADMM, by treating it as a fixed-point iteration for the
concatenation of the dual variables and a subset of the primal variables. In
this paper, we note that the equivalence between ADMM and Douglas-Rachford
splitting reveals that ADMM is in fact a fixed-point iteration in a
lower-dimensional space. By applying Anderson acceleration to such
lower-dimensional fixed-point iteration, we obtain a more effective approach
for accelerating ADMM. We analyze the convergence of the proposed acceleration
method on nonconvex problems, and verify its effectiveness on a variety of
computer graphics problems including geometry processing and physical
simulation.
"
2107,Augmenting Image Warping-Based Remote Volume Rendering with Ray Tracing,"  We propose an image warping-based remote rendering technique for volumes that
decouples the rendering and display phases. Our work builds on prior work that
samples the volume on the client using ray casting and reconstructs a z-value
based on some heuristic. The color and depth buffer are then sent to the client
that reuses this depth image as a stand-in for subsequent frames by warping it
according to the current camera position until new data was received from the
server. We augment that method by implementing the client renderer using ray
tracing. By representing the pixel contributions as spheres, this allows us to
effectively vary their footprint based on the distance to the viewer, which we
find to give better results than point-based rasterization when applied to
volumetric data sets.
"
2108,RPM-Net: Recurrent Prediction of Motion and Parts from Point Cloud,"  We introduce RPM-Net, a deep learning-based approach which simultaneously
infers movable parts and hallucinates their motions from a single,
un-segmented, and possibly partial, 3D point cloud shape. RPM-Net is a novel
Recurrent Neural Network (RNN), composed of an encoder-decoder pair with
interleaved Long Short-Term Memory (LSTM) components, which together predict a
temporal sequence of pointwise displacements for the input point cloud. At the
same time, the displacements allow the network to learn movable parts,
resulting in a motion-based shape segmentation. Recursive applications of
RPM-Net on the obtained parts can predict finer-level part motions, resulting
in a hierarchical object segmentation. Furthermore, we develop a separate
network to estimate part mobilities, e.g., per-part motion parameters, from the
segmented motion sequence. Both networks learn deep predictive models from a
training set that exemplifies a variety of mobilities for diverse objects. We
show results of simultaneous motion and part predictions from synthetic and
real scans of 3D objects exhibiting a variety of part mobilities, possibly
involving multiple movable parts.
"
2109,Computing Light Transport Gradients using the Adjoint Method,"  This paper proposes a new equation from continuous adjoint theory to compute
the gradient of quantities governed by the Transport Theory of light. Unlike
discrete gradients ala autograd, which work at the code level, we first
formulate the continuous theory and then discretize it. The key insight of this
paper is that computing gradients in Transport Theory is akin to computing the
importance, a quantity adjoint to radiance that satisfies an adjoint equation.
Importance tells us where to look for light that matters. This is one of the
key insights of this paper. In fact, this mathematical journey started from a
whimsical thought that these adjoints might be related. Computing gradients is
therefore no more complicated than computing the importance field. This insight
and the following paper hopefully will shed some light on this complicated
problem and ease the implementations of gradient computations in existing path
tracers.
"
2110,"Automatic Recommendation of Strategies for Minimizing Discomfort in
  Virtual Environments","  Virtual reality (VR) is an imminent trend in games, education, entertainment,
military, and health applications, as the use of head-mounted displays is
becoming accessible to the mass market. Virtual reality provides immersive
experiences but still does not offer an entirely perfect situation, mainly due
to Cybersickness (CS) issues. In this work, we first present a detailed review
about possible causes of CS. Following, we propose a novel CS prediction
solution. Our system is able to suggest if the user may be entering in the next
moments of the application into an illness situation. We use Random Forest
classifiers, based on a dataset we have produced. The CSPQ (Cybersickness
Profile Questionnaire) is also proposed, which is used to identify the player's
susceptibility to CS and the dataset construction. In addition, we designed two
immersive environments for empirical studies where participants are asked to
complete the questionnaire and describe (orally) the degree of discomfort
during their gaming experience. Our data was achieved through 84 individuals on
different days, using VR devices. Our proposal also allows us to identify which
are the most frequent attributes (causes) in the observed discomfort
situations.
"
2111,DNF-Net: a Deep Normal Filtering Network for Mesh Denoising,"  This paper presents a deep normal filtering network, called DNF-Net, for mesh
denoising. To better capture local geometry, our network processes the mesh in
terms of local patches extracted from the mesh. Overall, DNF-Net is an
end-to-end network that takes patches of facet normals as inputs and directly
outputs the corresponding denoised facet normals of the patches. In this way,
we can reconstruct the geometry from the denoised normals with feature
preservation. Besides the overall network architecture, our contributions
include a novel multi-scale feature embedding unit, a residual learning
strategy to remove noise, and a deeply-supervised joint loss function. Compared
with the recent data-driven works on mesh denoising, DNF-Net does not require
manual input to extract features and better utilizes the training data to
enhance its denoising performance. Finally, we present comprehensive
experiments to evaluate our method and demonstrate its superiority over the
state of the art on both synthetic and real-scanned meshes.
"
2112,Predictive and Generative Neural Networks for Object Functionality,"  Humans can predict the functionality of an object even without any
surroundings, since their knowledge and experience would allow them to
""hallucinate"" the interaction or usage scenarios involving the object. We
develop predictive and generative deep convolutional neural networks to
replicate this feat. Specifically, our work focuses on functionalities of
man-made 3D objects characterized by human-object or object-object
interactions. Our networks are trained on a database of scene contexts, called
interaction contexts, each consisting of a central object and one or more
surrounding objects, that represent object functionalities. Given a 3D object
in isolation, our functional similarity network (fSIM-NET), a variation of the
triplet network, is trained to predict the functionality of the object by
inferring functionality-revealing interaction contexts. fSIM-NET is
complemented by a generative network (iGEN-NET) and a segmentation network
(iSEG-NET). iGEN-NET takes a single voxelized 3D object with a functionality
label and synthesizes a voxelized surround, i.e., the interaction context which
visually demonstrates the corresponding functionality. iSEG-NET further
separates the interacting objects into different groups according to their
interaction types.
"
2113,"Intrinsic Autoencoders for Joint Neural Rendering and Intrinsic Image
  Decomposition","  Neural rendering techniques promise efficient photo-realistic image synthesis
while at the same time providing rich control over scene parameters by learning
the physical image formation process. While several supervised methods have
been proposed for this task, acquiring a dataset of images with accurately
aligned 3D models is very difficult. The main contribution of this work is to
lift this restriction by training a neural rendering algorithm from unpaired
data. More specifically, we propose an autoencoder for joint generation of
realistic images from synthetic 3D models while simultaneously decomposing real
images into their intrinsic shape and appearance properties. In contrast to a
traditional graphics pipeline, our approach does not require to specify all
scene properties, such as material parameters and lighting by hand. Instead, we
learn photo-realistic deferred rendering from a small set of 3D models and a
larger set of unaligned real images, both of which are easy to acquire in
practice. Simultaneously, we obtain accurate intrinsic decompositions of real
images while not requiring paired ground truth. Our experiments confirm that a
joint treatment of rendering and decomposition is indeed beneficial and that
our approach outperforms state-of-the-art image-to-image translation baselines
both qualitatively and quantitatively.
"
2114,GramGAN: Deep 3D Texture Synthesis From 2D Exemplars,"  We present a novel texture synthesis framework, enabling the generation of
infinite, high-quality 3D textures given a 2D exemplar image. Inspired by
recent advances in natural texture synthesis, we train deep neural models to
generate textures by non-linearly combining learned noise frequencies. To
achieve a highly realistic output conditioned on an exemplar patch, we propose
a novel loss function that combines ideas from both style transfer and
generative adversarial networks. In particular, we train the synthesis network
to match the Gram matrices of deep features from a discriminator network. In
addition, we propose two architectural concepts and an extrapolation strategy
that significantly improve generalization performance. In particular, we inject
both model input and condition into hidden network layers by learning to scale
and bias hidden activations. Quantitative and qualitative evaluations on a
diverse set of exemplars motivate our design decisions and show that our system
performs superior to previous state of the art. Finally, we conduct a user
study that confirms the benefits of our framework.
"
2115,Deep Geometric Texture Synthesis,"  Recently, deep generative adversarial networks for image generation have
advanced rapidly; yet, only a small amount of research has focused on
generative models for irregular structures, particularly meshes. Nonetheless,
mesh generation and synthesis remains a fundamental topic in computer graphics.
In this work, we propose a novel framework for synthesizing geometric textures.
It learns geometric texture statistics from local neighborhoods (i.e., local
triangular patches) of a single reference 3D model. It learns deep features on
the faces of the input triangulation, which is used to subdivide and generate
offsets across multiple scales, without parameterization of the reference or
target mesh. Our network displaces mesh vertices in any direction (i.e., in the
normal and tangential direction), enabling synthesis of geometric textures,
which cannot be expressed by a simple 2D displacement map. Learning and
synthesizing on local geometric patches enables a genus-oblivious framework,
facilitating texture transfer between shapes of different genus.
"
2116,On Elastic Geodesic Grids and Their Planar to Spatial Deployment,"  We propose a novel type of planar-to-spatial deployable structures that we
call elastic geodesic grids. Our approach aims at the approximation of freeform
surfaces with spatial grids of bent lamellas which can be deployed from a
planar configuration using a simple kinematic mechanism. Such elastic
structures are easy-to-fabricate and easy-to-deploy and approximate shapes
which combine physics and aesthetics. We propose a solution based on networks
of geodesic curves on target surfaces and we introduce a set of conditions and
assumptions which can be closely met in practice. Our formulation allows for a
purely geometric approach which avoids the necessity of numerical shape
optimization by building on top of theoretical insights from differential
geometry. We propose a solution for the design, computation, and physical
simulation of elastic geodesic grids, and present several fabricated
small-scale examples with varying complexity. Moreover, we provide an empirical
proof of our method by comparing the results to laser-scans of the fabricated
models. Our method is intended as a form-finding tool for elastic gridshells in
architecture and other creative disciplines and should give the designer an
easy-to-handle way for the exploration of such structures.
"
2117,Polar Stroking: New Theory and Methods for Stroking Paths,"  Stroking and filling are the two basic rendering operations on paths in
vector graphics. The theory of filling a path is well-understood in terms of
contour integrals and winding numbers, but when path rendering standards
specify stroking, they resort to the analogy of painting pixels with a brush
that traces the outline of the path. This means important standards such as
PDF, SVG, and PostScript lack a rigorous way to say what samples are inside or
outside a stroked path. Our work fills this gap with a principled theory of
stroking.
  Guided by our theory, we develop a novel polar stroking method to render
stroked paths robustly with an intuitive way to bound the tessellation error
without needing recursion. Because polar stroking guarantees small uniform
steps in tangent angle, it provides an efficient way to accumulate arc length
along a path for texturing or dashing. While this paper focuses on developing
the theory of our polar stroking method, we have successfully implemented our
methods on modern programmable GPUs.
"
2118,On Designing GPU Algorithms with Applications to Mesh Refinement,"  We present a set of rules to guide the design of GPU algorithms. These rules
are grounded on the principle of reducing waste in GPU utility to achieve good
speed up. In accordance to these rules, we propose GPU algorithms for 2D
constrained, 3D constrained and 3D Restricted Delaunay refinement problems
respectively. Our algorithms take a 2D planar straight line graph (PSLG) or 3D
piecewise linear complex (PLC) $\mathcal{G}$ as input, and generate quality
meshes conforming or approximating to $\mathcal{G}$. The implementation of our
algorithms shows that they are the first to run an order of magnitude faster
than current state-of-the-art counterparts in sequential and parallel manners
while using similar numbers of Steiner points to produce triangulations of
comparable qualities. It thus reduces the computing time of mesh refinement
from possibly hours to a few seconds or minutes for possible use in interactive
graphics applications.
"
2119,"Multi-Axis Support-Free Printing of Freeform Parts with Lattice Infill
  Structures","  In additive manufacturing, infill structures are commonly used to reduce the
weight and cost of a solid part. Currently, most infill structure generation
methods are based on the conventional 2.5-axis printing configuration, which,
although able to satisfy the self-supporting condition on the infills, suffer
from the well-known stair-case effect on the finished surface and the need of
extensive support for overhang features. In this paper, based on the emerging
continuous multi-axis printing configuration, we present a new lattice infill
structure generation algorithm, which is able to achieve both the
self-supporting condition for the infills and the support-free requirement at
the boundary surface of the part. The algorithm critically relies on the use of
three mutually orthogonal geodesic distance fields that are embedded in the
tetrahedral mesh of the solid model. The intersection between the iso-geodesic
distance surfaces of these three geodesic distance fields naturally forms the
desired lattice of infill structure, while the density of the infills can be
conveniently controlled by adjusting the iso-values. The lattice infill pattern
in each curved slicing layer is trimmed to conform to an Eulerian graph so to
generate a continuous printing path, which can effectively reduce the nozzle
retractions during the printing process. In addition, to cater to the
collision-free requirement and to improve the printing efficiency, we also
propose a printing sequence optimization algorithm for determining a
collision-free order of printing of the connected lattice infills, which seeks
to reduce the air-move length of the nozzle. Ample experiments in both computer
simulation and physical printing are performed, and the results give a
preliminary confirmation of the advantages of our methodology.
"
2120,Swapping Autoencoder for Deep Image Manipulation,"  Deep generative models have become increasingly effective at producing
realistic images from randomly sampled seeds, but using such models for
controllable manipulation of existing images remains challenging. We propose
the Swapping Autoencoder, a deep model designed specifically for image
manipulation, rather than random sampling. The key idea is to encode an image
with two independent components and enforce that any swapped combination maps
to a realistic image. In particular, we encourage the components to represent
structure and texture, by enforcing one component to encode co-occurrent patch
statistics across different parts of an image. As our method is trained with an
encoder, finding the latent codes for a new input image becomes trivial, rather
than cumbersome. As a result, it can be used to manipulate real input images in
various ways, including texture swapping, local and global editing, and latent
code vector arithmetic. Experiments on multiple datasets show that our model
produces better results and is substantially more efficient compared to recent
generative models.
"
2121,"Surface Denoising based on Normal Filtering in a Robust Statistics
  Framework","  During a surface acquisition process using 3D scanners, noise is inevitable
and an important step in geometry processing is to remove these noise
components from these surfaces (given as points-set or triangulated mesh). The
noise-removal process (denoising) can be performed by filtering the surface
normals first and by adjusting the vertex positions according to filtered
normals afterwards. Therefore, in many available denoising algorithms, the
computation of noise-free normals is a key factor. A variety of filters have
been introduced for noise-removal from normals, with different focus points
like robustness against outliers or large amplitude of noise. Although these
filters are performing well in different aspects, a unified framework is
missing to establish the relation between them and to provide a theoretical
analysis beyond the performance of each method.
  In this paper, we introduce such a framework to establish relations between a
number of widely-used nonlinear filters for face normals in mesh denoising and
vertex normals in point set denoising. We cover robust statistical estimation
with M-smoothers and their application to linear and non-linear normal
filtering. Although these methods originate in different mathematical theories
- which include diffusion-, bilateral-, and directional curvature-based
algorithms - we demonstrate that all of them can be cast into a unified
framework of robust statistics using robust error norms and their corresponding
influence functions. This unification contributes to a better understanding of
the individual methods and their relations with each other. Furthermore, the
presented framework provides a platform for new techniques to combine the
advantages of known filters and to compare them with available methods.
"
2122,"PerceptionGAN: Real-world Image Construction from Provided Text through
  Perceptual Understanding","  Generating an image from a provided descriptive text is quite a challenging
task because of the difficulty in incorporating perceptual information (object
shapes, colors, and their interactions) along with providing high relevancy
related to the provided text. Current methods first generate an initial
low-resolution image, which typically has irregular object shapes, colors, and
interaction between objects. This initial image is then improved by
conditioning on the text. However, these methods mainly address the problem of
using text representation efficiently in the refinement of the initially
generated image, while the success of this refinement process depends heavily
on the quality of the initially generated image, as pointed out in the DM-GAN
paper. Hence, we propose a method to provide good initialized images by
incorporating perceptual understanding in the discriminator module. We improve
the perceptual information at the first stage itself, which results in
significant improvement in the final generated image. In this paper, we have
applied our approach to the novel StackGAN architecture. We then show that the
perceptual information included in the initial image is improved while modeling
image distribution at multiple stages. Finally, we generated realistic
multi-colored images conditioned by text. These images have good quality along
with containing improved basic perceptual information. More importantly, the
proposed method can be integrated into the pipeline of other state-of-the-art
text-based-image-generation models to generate initial low-resolution images.
We also worked on improving the refinement process in StackGAN by augmenting
the third stage of the generator-discriminator pair in the StackGAN
architecture. Our experimental analysis and comparison with the
state-of-the-art on a large but sparse dataset MS COCO further validate the
usefulness of our proposed approach.
"
2123,"ADD: Analytically Differentiable Dynamics for Multi-Body Systems with
  Frictional Contact","  We present a differentiable dynamics solver that is able to handle frictional
contact for rigid and deformable objects within a unified framework. Through a
principled mollification of normal and tangential contact forces, our method
circumvents the main difficulties inherent to the non-smooth nature of
frictional contact. We combine this new contact model with fully-implicit time
integration to obtain a robust and efficient dynamics solver that is
analytically differentiable. In conjunction with adjoint sensitivity analysis,
our formulation enables gradient-based optimization with adaptive trade-offs
between simulation accuracy and smoothness of objective function landscapes. We
thoroughly analyse our approach on a set of simulation examples involving rigid
bodies, visco-elastic materials, and coupled multi-body systems. We furthermore
showcase applications of our differentiable simulator to parameter estimation
for deformable objects, motion planning for robotic manipulation, trajectory
optimization for compliant walking robots, as well as efficient self-supervised
learning of control policies.
"
2124,"Ordinary Facet Angles of a Stroked Path Tessellated by Uniform Tangent
  Angle Steps Are Bounded by Twice the Step Angle","  We explain geometrically why ordinary facet angles of a stroked path
tessellated from uniform tangent angle steps are bounded by twice the step
angle. This fact means---excluding a small number of extraordinary facet angles
straddling offset cusps---our polar stroking method bounds the facet angle size
to less than $2 \theta$ where $\theta$ is the tangent step angle.
"
2125,A Discrete Probabilistic Approach to Dense Flow Visualization,"  Dense flow visualization is a popular visualization paradigm. Traditionally,
the various models and methods in this area use a continuous formulation,
resting upon the solid foundation of functional analysis. In this work, we
examine a discrete formulation of dense flow visualization. From probability
theory, we derive a similarity matrix that measures the similarity between
different points in the flow domain, leading to the discovery of a whole new
class of visualization models. Using this matrix, we propose a novel
visualization approach consisting of the computation of spectral embeddings,
i.e., characteristic domain maps, defined by particle mixture probabilities.
These embeddings are scalar fields that give insight into the mixing processes
of the flow on different scales. The approach of spectral embeddings is already
well studied in image segmentation, and we see that spectral embeddings are
connected to Fourier expansions and frequencies. We showcase the utility of our
method using different 2D and 3D flows.
"
2126,Structure-Aware Human-Action Generation,"  Generating long-range skeleton-based human actions has been a challenging
problem since small deviations of one frame can cause a malformed action
sequence. Most existing methods borrow ideas from video generation, which
naively treat skeleton nodes/joints as pixels of images without considering the
rich inter-frame and intra-frame structure information, leading to potential
distorted actions. Graph convolutional networks (GCNs) is a promising way to
leverage structure information to learn structure representations. However,
directly adopting GCNs to tackle such continuous action sequences both in
spatial and temporal spaces is challenging as the action graph could be huge.
To overcome this issue, we propose a variant of GCNs to leverage the powerful
self-attention mechanism to adaptively sparsify a complete action graph in the
temporal space. Our method could dynamically attend to important past frames
and construct a sparse graph to apply in the GCN framework, well-capturing the
structure information in action sequences. Extensive experimental results
demonstrate the superiority of our method on two standard human action datasets
compared with existing methods.
"
2127,"Interpretation of Disease Evidence for Medical Images Using Adversarial
  Deformation Fields","  The high complexity of deep learning models is associated with the difficulty
of explaining what evidence they recognize as correlating with specific disease
labels. This information is critical for building trust in models and finding
their biases. Until now, automated deep learning visualization solutions have
identified regions of images used by classifiers, but these solutions are too
coarse, too noisy, or have a limited representation of the way images can
change. We propose a novel method for formulating and presenting spatial
explanations of disease evidence, called deformation field interpretation with
generative adversarial networks (DeFI-GAN). An adversarially trained generator
produces deformation fields that modify images of diseased patients to resemble
images of healthy patients. We validate the method studying chronic obstructive
pulmonary disease (COPD) evidence in chest x-rays (CXRs) and Alzheimer's
disease (AD) evidence in brain MRIs. When extracting disease evidence in
longitudinal data, we show compelling results against a baseline producing
difference maps. DeFI-GAN also highlights disease biomarkers not found by
previous methods and potential biases that may help in investigations of the
dataset and of the adopted learning methods.
"
2128,"Quo Vadis, Skeleton Action Recognition ?","  In this paper, we study current and upcoming frontiers across the landscape
of skeleton-based human action recognition. To begin with, we benchmark
state-of-the-art models on the NTU-120 dataset and provide multi-layered
assessment of the results. To examine skeleton action recognition 'in the
wild', we introduce Skeletics-152, a curated and 3-D pose-annotated subset of
RGB videos sourced from Kinetics-700, a large-scale action dataset. The results
from benchmarking the top performers of NTU-120 on Skeletics-152 reveal the
challenges and domain gap induced by actions 'in the wild'. We extend our study
to include out-of-context actions by introducing Skeleton-Mimetics, a dataset
derived from the recently introduced Mimetics dataset. Finally, as a new
frontier for action recognition, we introduce Metaphorics, a dataset with
caption-style annotated YouTube videos of the popular social game Dumb Charades
and interpretative dance performances. Overall, our work characterizes the
strengths and limitations of existing approaches and datasets. It also provides
an assessment of top-performing approaches across a spectrum of activity
settings and via the introduced datasets, proposes new frontiers for human
action recognition.
"
2129,Scalable Differentiable Physics for Learning and Control,"  Differentiable physics is a powerful approach to learning and control
problems that involve physical objects and environments. While notable progress
has been made, the capabilities of differentiable physics solvers remain
limited. We develop a scalable framework for differentiable physics that can
support a large number of objects and their interactions. To accommodate
objects with arbitrary geometry and topology, we adopt meshes as our
representation and leverage the sparsity of contacts for scalable
differentiable collision handling. Collisions are resolved in localized regions
to minimize the number of optimization variables even when the number of
simulated objects is high. We further accelerate implicit differentiation of
optimization with nonlinear constraints. Experiments demonstrate that the
presented framework requires up to two orders of magnitude less memory and
computation in comparison to recent particle-based methods. We further validate
the approach on inverse problems and control scenarios, where it outperforms
derivative-free and model-free baselines by at least an order of magnitude.
"
2130,Computational LEGO Technic Design,"  We introduce a method to automatically compute LEGO Technic models from user
input sketches, optionally with motion annotations. The generated models
resemble the input sketches with coherently-connected bricks and simple
layouts, while respecting the intended symmetry and mechanical properties
expressed in the inputs. This complex computational assembly problem involves
an immense search space, and a much richer brick set and connection mechanisms
than regular LEGO. To address it, we first comprehensively model the brick
properties and connection mechanisms, then formulate the construction
requirements into an objective function, accounting for faithfulness to input
sketch, model simplicity, and structural integrity. Next, we model the problem
as a sketch cover, where we iteratively refine a random initial layout to cover
the input sketch, while guided by the objective. At last, we provide a working
system to analyze the balance, stress, and assemblability of the generated
model. To evaluate our method, we compared it with four baselines and
professional designs by a LEGO expert, demonstrating the superiority of our
automatic designs. Also, we recruited several users to try our system, employed
it to create models of varying forms and complexities, and physically built
most of them.
"
2131,TilinGNN: Learning to Tile with Self-Supervised Graph Neural Network,"  We introduce the first neural optimization framework to solve a classical
instance of the tiling problem. Namely, we seek a non-periodic tiling of an
arbitrary 2D shape using one or more types of tiles: the tiles maximally fill
the shape's interior without overlaps or holes. To start, we reformulate tiling
as a graph problem by modeling candidate tile locations in the target shape as
graph nodes and connectivity between tile locations as edges. Further, we build
a graph convolutional neural network, coined TilinGNN, to progressively
propagate and aggregate features over graph edges and predict tile placements.
TilinGNN is trained by maximizing the tiling coverage on target shapes, while
avoiding overlaps and holes between the tiles. Importantly, our network is
self-supervised, as we articulate these criteria as loss terms defined on the
network outputs, without the need of ground-truth tiling solutions. After
training, the runtime of TilinGNN is roughly linear to the number of candidate
tile locations, significantly outperforming traditional combinatorial search.
We conducted various experiments on a variety of shapes to showcase the speed
and versatility of TilinGNN. We also present comparisons to alternative methods
and manual solutions, robustness analysis, and ablation studies to demonstrate
the quality of our approach.
"
2132,Learning Graph-Convolutional Representations for Point Cloud Denoising,"  Point clouds are an increasingly relevant data type but they are often
corrupted by noise. We propose a deep neural network based on
graph-convolutional layers that can elegantly deal with the
permutation-invariance problem encountered by learning-based point cloud
processing methods. The network is fully-convolutional and can build complex
hierarchies of features by dynamically constructing neighborhood graphs from
similarity among the high-dimensional feature representations of the points.
When coupled with a loss promoting proximity to the ideal surface, the proposed
approach significantly outperforms state-of-the-art methods on a variety of
metrics. In particular, it is able to improve in terms of Chamfer measure and
of quality of the surface normals that can be estimated from the denoised data.
We also show that it is especially robust both at high noise levels and in
presence of structured noise such as the one encountered in real LiDAR scans.
"
2133,Guided Fine-Tuning for Large-Scale Material Transfer,"  We present a method to transfer the appearance of one or a few exemplar
SVBRDFs to a target image representing similar materials. Our solution is
extremely simple: we fine-tune a deep appearance-capture network on the
provided exemplars, such that it learns to extract similar SVBRDF values from
the target image. We introduce two novel material capture and design workflows
that demonstrate the strength of this simple approach. Our first workflow
allows to produce plausible SVBRDFs of large-scale objects from only a few
pictures. Specifically, users only need take a single picture of a large
surface and a few close-up flash pictures of some of its details. We use
existing methods to extract SVBRDF parameters from the close-ups, and our
method to transfer these parameters to the entire surface, enabling the
lightweight capture of surfaces several meters wide such as murals, floors and
furniture. In our second workflow, we provide a powerful way for users to
create large SVBRDFs from internet pictures by transferring the appearance of
existing, pre-designed SVBRDFs. By selecting different exemplars, users can
control the materials assigned to the target image, greatly enhancing the
creative possibilities offered by deep appearance capture.
"
2134,Skeletonization via Local Separators,"  We propose a new algorithm for curve skeleton computation which differs from
previous algorithms by being based on the notion of local separators. The main
benefits of this approach are that it is able to capture relatively fine
details and that it works robustly on a range of shape representations.
Specifically, our method works on shape representations that can be construed
as a spatially embedded graphs. Such representations include meshes, volumetric
shapes, and graphs computed from point clouds. We describe a simple pipeline
where geometric data is initially converted to a graph, optionally simplified,
local separators are computed and selected, and finally a skeleton is
constructed. We test our pipeline on polygonal meshes, volumetric shapes, and
point clouds. Finally, we compare our results to other methods for
skeletonization according to performance and quality.
"
2135,A Free Viewpoint Portrait Generator with Dynamic Styling,"  Generating portrait images from a single latent space facing the problem of
entangled attributes, making it difficult to explicitly adjust the generation
on specific attributes, e.g., contour and viewpoint control or dynamic styling.
Therefore, we propose to decompose the generation space into two subspaces:
geometric and texture space. We first encode portrait scans with a semantic
occupancy field (SOF), which represents semantic-embedded geometry structure
and output free-viewpoint semantic segmentation maps. Then we design a semantic
instance wised(SIW) StyleGAN to regionally styling the segmentation map. We
capture 664 3D portrait scans for our SOF training and use real capture
photos(FFHQ and CelebA-HQ) for SIW StyleGAN training. Adequate experiments show
that our representations enable appearance consistent shape, pose, regional
styles controlling, achieve state-of-the-art results, and generalize well in
various application scenarios.
"
2136,"Deform, Cut and Tear a skinned model using Conformal Geometric Algebra","  In this work, we present a novel, integrated rigged character simulation
framework in Conformal Geometric Algebra (CGA) that supports, for the first
time, real-time cuts and tears, before and/or after the animation, while
maintaining deformation topology. The purpose of using CGA is to lift several
restrictions posed by current state-of-the-art character animation &
deformation methods. Previous implementations originally required weighted
matrices to perform deformations, whereas, in the current state-of-the-art,
dual-quaternions handle both rotations and translations, but cannot handle
dilations. CGA is a suitable extension of dual-quaternion algebra that amends
these two major previous shortcomings: the need to constantly transmute between
matrices and dual-quaternions as well as the inability to properly dilate a
model during animation. Our CGA algorithm also provides easy interpolation and
application of all deformations in each intermediate steps, all within the same
geometric framework. Furthermore we also present two novel algorithms that
enable cutting and tearing of the input rigged, animated model, while the
output model can be further re-deformed. These interactive, real-time cut and
tear operations can enable a new suite of applications, especially under the
scope of a medical surgical simulation.
"
2137,ThreeDWorld: A Platform for Interactive Multi-Modal Physical Simulation,"  We introduce ThreeDWorld (TDW), a platform for interactive multi-modal
physical simulation. With TDW, users can simulate high-fidelity sensory data
and physical interactions between mobile agents and objects in a wide variety
of rich 3D environments. TDW has several unique properties: 1) realtime near
photo-realistic image rendering quality; 2) a library of objects and
environments with materials for high-quality rendering, and routines enabling
user customization of the asset library; 3) generative procedures for
efficiently building classes of new environments 4) high-fidelity audio
rendering; 5) believable and realistic physical interactions for a wide variety
of material types, including cloths, liquid, and deformable objects; 6) a range
of ""avatar"" types that serve as embodiments of AI agents, with the option for
user avatar customization; and 7) support for human interactions with VR
devices. TDW also provides a rich API enabling multiple agents to interact
within a simulation and return a range of sensor and physics data representing
the state of the world. We present initial experiments enabled by the platform
around emerging research directions in computer vision, machine learning, and
cognitive science, including multi-modal physical scene understanding,
multi-agent interactions, models that ""learn like a child"", and attention
studies in humans and neural networks. The simulation platform will be made
publicly available.
"
2138,Deep Patch-based Human Segmentation,"  3D human segmentation has seen noticeable progress in re-cent years. It,
however, still remains a challenge to date. In this paper, weintroduce a deep
patch-based method for 3D human segmentation. Wefirst extract a local surface
patch for each vertex and then parameterizeit into a 2D grid (or image). We
then embed identified shape descriptorsinto the 2D grids which are further fed
into the powerful 2D Convolu-tional Neural Network for regressing corresponding
semantic labels (e.g.,head, torso). Experiments demonstrate that our method is
effective inhuman segmentation, and achieves state-of-the-art accuracy.
"
2139,LSQT: Low-Stretch Quasi-Trees for Bundling and Layout,"  We introduce low-stretch trees to the visualization community with LSQT, our
novel technique that uses quasi-trees for both layout and edge bundling. Our
method offers strong computational speed and complexity guarantees by
leveraging the convenient properties of low-stretch trees, which accurately
reflect the topological structure of arbitrary graphs with superior fidelity
compared to arbitrary spanning trees. Low-stretch quasi-trees also have
provable sparseness guarantees, providing algorithmic support for aggressive
de-cluttering of hairball graphs. LSQT does not rely on previously computed
vertex positions and computes bundles based on topological structure before any
geometric layout occurs. Edge bundles are computed efficiently and stored in an
explicit data structure that supports sophisticated visual encoding and
interaction techniques, including dynamic layout adjustment and interactive
bundle querying. Our unoptimized implementation handles graphs of over 100,000
edges in eight seconds, providing substantially higher performance than
previous approaches.
"
2140,Conditional Image Retrieval,"  This work introduces Conditional Image Retrieval (CIR) systems: IR methods
that can efficiently specialize to specific subsets of images on the fly. These
systems broaden the class of queries IR systems support, and eliminate the need
for expensive re-fitting to specific subsets of data. Specifically, we adapt
tree-based K-Nearest Neighbor (KNN) data-structures to the conditional setting
by introducing additional inverted-index data-structures. This speeds
conditional queries and does not slow queries without conditioning. We present
two new datasets for evaluating the performance of CIR systems and evaluate a
variety of design choices. As a motivating application, we present an algorithm
that can explore shared semantic content between works of art of vastly
different media and cultural origin. Finally, we demonstrate that CIR
data-structures can identify Generative Adversarial Network (GAN) ""blind
spots"": areas where GANs fail to properly model the true data distribution.
"
2141,"Transposer: Universal Texture Synthesis Using Feature Maps as Transposed
  Convolution Filter","  Conventional CNNs for texture synthesis consist of a sequence of
(de)-convolution and up/down-sampling layers, where each layer operates locally
and lacks the ability to capture the long-term structural dependency required
by texture synthesis. Thus, they often simply enlarge the input texture, rather
than perform reasonable synthesis. As a compromise, many recent methods
sacrifice generalizability by training and testing on the same single (or fixed
set of) texture image(s), resulting in huge re-training time costs for unseen
images. In this work, based on the discovery that the assembling/stitching
operation in traditional texture synthesis is analogous to a transposed
convolution operation, we propose a novel way of using transposed convolution
operation. Specifically, we directly treat the whole encoded feature map of the
input texture as transposed convolution filters and the features'
self-similarity map, which captures the auto-correlation information, as input
to the transposed convolution. Such a design allows our framework, once
trained, to be generalizable to perform synthesis of unseen textures with a
single forward pass in nearly real-time. Our method achieves state-of-the-art
texture synthesis quality based on various metrics. While self-similarity helps
preserve the input textures' regular structural patterns, our framework can
also take random noise maps for irregular input textures instead of
self-similarity maps as transposed convolution inputs. It allows to get more
diverse results as well as generate arbitrarily large texture outputs by
directly sampling large noise maps in a single pass as well.
"
2142,Fast and Robust Iterative Closet Point,"  The Iterative Closest Point (ICP) algorithm and its variants are a
fundamental technique for rigid registration between two point sets, with wide
applications in different areas from robotics to 3D reconstruction. The main
drawbacks for ICP are its slow convergence as well as its sensitivity to
outliers, missing data, and partial overlaps. Recent work such as Sparse ICP
achieves robustness via sparsity optimization at the cost of computational
speed. In this paper, we propose a new method for robust registration with fast
convergence. First, we show that the classical point-to-point ICP can be
treated as a majorization-minimization (MM) algorithm, and propose an Anderson
acceleration approach to improve its convergence. In addition, we introduce a
robust error metric based on the Welsch's function, which is minimized
efficiently using the MM algorithm with Anderson acceleration. On challenging
datasets with noises and partial overlaps, we achieve similar or better
accuracy than Sparse ICP while being at least an order of magnitude faster.
Finally, we extend the robust formulation to point-to-plane ICP, and solve the
resulting problem using a similar Anderson-accelerated MM strategy. Our robust
ICP methods improve the registration accuracy on benchmark datasets while being
competitive in computational time.
"
2143,SSN: Soft Shadow Network for Image Compositing,"  In image compositing tasks, objects from different sources are put together
to form a new image. Artists often increase realism by adding object shadows to
match the scene geometry and lighting. However, creating realistic soft shadows
requires skill and is time-consuming. We introduce a Soft Shadow Network to
generate convincing soft shadows for 2D object cutouts automatically. SSN takes
an object cutout mask as input and thus is agnostic to image types such as
painting and vector art. Although inferring the 3D shape of an object from its
silhouette can be ambiguous, it is easy for humans to get the 3D geometry from
a 2D projection when it is in an iconic view. We follow this intuition and
train the SSN to render soft shadows for objects' iconic views. To train our
model, we design an efficient pipeline to produce diverse soft shadow training
data using 3D object models. Our pipeline first computes a set of soft shadow
bases by sampling hard shadows. During training, environment lighting maps that
cover a wide spectrum of possible configurations are used to calculate the soft
shadow ground truth using the shadow bases. This enables our model to see a
complex lighting pattern and to learn the interaction between the lights and 3D
geometries. In addition, we propose an inverse shadow map representation, which
makes the training focused on the shadow area and leads to much faster
convergence and better performance. We show that our model produces realistic
soft shadow details for objects of different shapes. A user study shows that
SSN generated shadows are often indistinguishable from shadows calculated by
physics-based rendering. Our SSN can produce a shadow in real-time and it
allows real-time interactive shadow manipulation. We develop a simple user
interface and a second user study shows that amateur users can easily use our
tool to generate soft shadows matching a reference shadow.
"
2144,"Artificial GAN Fingerprints: Rooting Deepfake Attribution in Training
  Data","  Photorealistic image generation is progressing rapidly and has reached a new
level of quality, thanks to the invention and breakthroughs of generative
adversarial networks (GANs). Yet the dark side of such deepfakes, the malicious
use of generated media, never stops raising concerns of visual misinformation.
Existing research works on deepfake detection demonstrate impressive accuracy,
while it is accompanied by adversarial iterations on detection countermeasure
techniques. In order to lead this arms race to the end, we investigate a
fundamental solution on deepfake detection, agnostic to the evolution of GANs
in order to enable a responsible disclosure or regulation of such double-edged
techniques. We propose to embed artificial fingerprints into GAN training data,
and show a surprising discovery on the transferability of such fingerprints
from training data to GAN models, which in turn enables reliable detection and
attribution of deepfakes. Our empirical study shows that our fingerprinting
technique (1) holds for different state-of-the-art GAN configurations, (2)
turns more effective along with the development of GAN techniques, (3) has a
negligible side effect on the generation quality, and (4) stays robust against
image-level and model-level perturbations. When we allocate each GAN publisher
a unique artificial fingerprint, the margins between real data and deepfakes,
and the margins among different deepfake sources are fundamentally guaranteed.
As a result, we are able to evidence accurate deepfake detection/attribution
using our fingerprint decoder, which makes this solution stand out from the
current arms race.
"
2145,Accelerating 3D Deep Learning with PyTorch3D,"  Deep learning has significantly improved 2D image recognition. Extending into
3D may advance many new applications including autonomous vehicles, virtual and
augmented reality, authoring 3D content, and even improving 2D recognition.
However despite growing interest, 3D deep learning remains relatively
underexplored. We believe that some of this disparity is due to the engineering
challenges involved in 3D deep learning, such as efficiently processing
heterogeneous data and reframing graphics operations to be differentiable. We
address these challenges by introducing PyTorch3D, a library of modular,
efficient, and differentiable operators for 3D deep learning. It includes a
fast, modular differentiable renderer for meshes and point clouds, enabling
analysis-by-synthesis approaches. Compared with other differentiable renderers,
PyTorch3D is more modular and efficient, allowing users to more easily extend
it while also gracefully scaling to large meshes and images. We compare the
PyTorch3D operators and renderer with other implementations and demonstrate
significant speed and memory improvements. We also use PyTorch3D to improve the
state-of-the-art for unsupervised 3D mesh and point cloud prediction from 2D
images on ShapeNet. PyTorch3D is open-source and we hope it will help
accelerate research in 3D deep learning.
"
2146,Talking-head Generation with Rhythmic Head Motion,"  When people deliver a speech, they naturally move heads, and this rhythmic
head motion conveys prosodic information. However, generating a lip-synced
video while moving head naturally is challenging. While remarkably successful,
existing works either generate still talkingface videos or rely on
landmark/video frames as sparse/dense mapping guidance to generate head
movements, which leads to unrealistic or uncontrollable video synthesis. To
overcome the limitations, we propose a 3D-aware generative network along with a
hybrid embedding module and a non-linear composition module. Through modeling
the head motion and facial expressions1 explicitly, manipulating 3D animation
carefully, and embedding reference images dynamically, our approach achieves
controllable, photo-realistic, and temporally coherent talking-head videos with
natural head movements. Thoughtful experiments on several standard benchmarks
demonstrate that our method achieves significantly better results than the
state-of-the-art methods in both quantitative and qualitative comparisons. The
code is available on https://github.com/
lelechen63/Talking-head-Generation-with-Rhythmic-Head-Motion.
"
2147,Generating Person Images with Appearance-aware Pose Stylizer,"  Generation of high-quality person images is challenging, due to the
sophisticated entanglements among image factors, e.g., appearance, pose,
foreground, background, local details, global structures, etc. In this paper,
we present a novel end-to-end framework to generate realistic person images
based on given person poses and appearances. The core of our framework is a
novel generator called Appearance-aware Pose Stylizer (APS) which generates
human images by coupling the target pose with the conditioned person appearance
progressively. The framework is highly flexible and controllable by effectively
decoupling various complex person image factors in the encoding phase, followed
by re-coupling them in the decoding phase. In addition, we present a new
normalization method named adaptive patch normalization, which enables
region-specific normalization and shows a good performance when adopted in
person image generation model. Experiments on two benchmark datasets show that
our method is capable of generating visually appealing and realistic-looking
results using arbitrary image and pose inputs.
"
2148,"Moving fast and slow: Analysis of representations and post-processing in
  speech-driven automatic gesture generation","  This paper presents a novel framework for speech-driven gesture production,
applicable to virtual agents to enhance human-computer interaction.
Specifically, we extend recent deep-learning-based, data-driven methods for
speech-driven gesture generation by incorporating representation learning. Our
model takes speech as input and produces gestures as output, in the form of a
sequence of 3D coordinates. We provide an analysis of different representations
for the input (speech) and the output (motion) of the network by both objective
and subjective evaluations. We also analyse the importance of smoothing of the
produced motion. Our results indicated that the proposed method improved on our
baseline in terms of objective measures. For example, it better captured the
motion dynamics and better matched the motion-speed distribution. Moreover, we
performed user studies on two different datasets. The studies confirmed that
our proposed method is perceived as more natural than the baseline, although
the difference in the studies was eliminated by appropriate post-processing:
hip-centering and smoothing. We conclude that it is important to take both
feature representation, model architecture and post-processing into account
when designing an automatic gesture-production method.
"
2149,Meshing Point Clouds with Predicted Intrinsic-Extrinsic Ratio Guidance,"  We are interested in reconstructing the mesh representation of object
surfaces from point clouds. Surface reconstruction is a prerequisite for
downstream applications such as rendering, collision avoidance for planning,
animation, etc. However, the task is challenging if the input point cloud has a
low resolution, which is common in real-world scenarios (e.g., from LiDAR or
Kinect sensors). Existing learning-based mesh generative methods mostly predict
the surface by first building a shape embedding that is at the whole object
level, a design that causes issues in generating fine-grained details and
generalizing to unseen categories. Instead, we propose to leverage the input
point cloud as much as possible, by only adding connectivity information to
existing points. Particularly, we predict which triplets of points should form
faces. Our key innovation is a surrogate of local connectivity, calculated by
comparing the intrinsic/extrinsic metrics. We learn to predict this surrogate
using a deep point cloud network and then feed it to an efficient
post-processing module for high-quality mesh generation. We demonstrate that
our method can not only preserve details, handle ambiguous structures, but also
possess strong generalizability to unseen categories by experiments on
synthetic and real data. The code is available at
https://github.com/Colin97/Point2Mesh.
"
2150,A Robust Interactive Facial Animation Editing System,"  Over the past few years, the automatic generation of facial animation for
virtual characters has garnered interest among the animation research and
industry communities. Recent research contributions leverage machine-learning
approaches to enable impressive capabilities at generating plausible facial
animation from audio and/or video signals. However, these approaches do not
address the problem of animation edition, meaning the need for correcting an
unsatisfactory baseline animation or modifying the animation content itself. In
facial animation pipelines, the process of editing an existing animation is
just as important and time-consuming as producing a baseline. In this work, we
propose a new learning-based approach to easily edit a facial animation from a
set of intuitive control parameters. To cope with high-frequency components in
facial movements and preserve a temporal coherency in the animation, we use a
resolution-preserving fully convolutional neural network that maps control
parameters to blendshapes coefficients sequences. We stack an additional
resolution-preserving animation autoencoder after the regressor to ensure that
the system outputs natural-looking animation. The proposed system is robust and
can handle coarse, exaggerated edits from non-specialist users. It also retains
the high-frequency motion of the facial animation.
"
2151,Octahedral Frames for Feature-Aligned Cross-Fields,"  We present a method for designing smooth cross fields on surfaces that
automatically align to sharp features of an underlying geometry. Our approach
introduces a novel class of energies based on a representation of cross fields
in the spherical harmonic basis. We provide theoretical analysis of these
energies in the smooth setting, showing that they penalize deviations from
surface creases while otherwise promoting intrinsically smooth fields. We
demonstrate the applicability of our method to quad-meshing and include an
extensive benchmark comparing our fields to other automatic approaches for
generating feature-aligned cross fields on triangle meshes.
"
2152,"Deep Reflectance Volumes: Relightable Reconstructions from Multi-View
  Photometric Images","  We present a deep learning approach to reconstruct scene appearance from
unstructured images captured under collocated point lighting. At the heart of
Deep Reflectance Volumes is a novel volumetric scene representation consisting
of opacity, surface normal and reflectance voxel grids. We present a novel
physically-based differentiable volume ray marching framework to render these
scene volumes under arbitrary viewpoint and lighting. This allows us to
optimize the scene volumes to minimize the error between their rendered images
and the captured images. Our method is able to reconstruct real scenes with
challenging non-Lambertian reflectance and complex geometry with occlusions and
shadowing. Moreover, it accurately generalizes to novel viewpoints and
lighting, including non-collocated lighting, rendering photorealistic images
that are significantly better than state-of-the-art mesh-based methods. We also
show that our learned reflectance volumes are editable, allowing for modifying
the materials of the captured scenes.
"
2153,Learning Adaptive Sampling and Reconstruction for Volume Visualization,"  A central challenge in data visualization is to understand which data samples
are required to generate an image of a data set in which the relevant
information is encoded. In this work, we make a first step towards answering
the question of whether an artificial neural network can predict where to
sample the data with higher or lower density, by learning of correspondences
between the data, the sampling patterns and the generated images. We introduce
a novel neural rendering pipeline, which is trained end-to-end to generate a
sparse adaptive sampling structure from a given low-resolution input image, and
reconstructs a high-resolution image from the sparse set of samples. For the
first time, to the best of our knowledge, we demonstrate that the selection of
structures that are relevant for the final visual representation can be jointly
learned together with the reconstruction of this representation from these
structures. Therefore, we introduce differentiable sampling and reconstruction
stages, which can leverage back-propagation based on supervised losses solely
on the final image. We shed light on the adaptive sampling patterns generated
by the network pipeline and analyze its use for volume visualization including
isosurface and direct volume rendering.
"
2154,"Coupling Explicit and Implicit Surface Representations for Generative 3D
  Modeling","  We propose a novel neural architecture for representing 3D surfaces, which
harnesses two complementary shape representations: (i) an explicit
representation via an atlas, i.e., embeddings of 2D domains into 3D; (ii) an
implicit-function representation, i.e., a scalar function over the 3D volume,
with its levels denoting surfaces. We make these two representations
synergistic by introducing novel consistency losses that ensure that the
surface created from the atlas aligns with the level-set of the implicit
function. Our hybrid architecture outputs results which are superior to the
output of the two equivalent single-representation networks, yielding smoother
explicit surfaces with more accurate normals, and a more accurate implicit
occupancy function. Additionally, our surface reconstruction step can directly
leverage the explicit atlas-based representation. This process is
computationally efficient, and can be directly used by differentiable
rasterizers, enabling training our hybrid representation with image-based
losses.
"
2155,A Survey of Algorithms for Geodesic Paths and Distances,"  Numerical computation of shortest paths or geodesics on curved domains, as
well as the associated geodesic distance, arises in a broad range of
applications across digital geometry processing, scientific computing, computer
graphics, and computer vision. Relative to Euclidean distance computation,
these tasks are complicated by the influence of curvature on the behavior of
shortest paths, as well as the fact that the representation of the domain may
itself be approximate. In spite of the difficulty of this problem, recent
literature has developed a wide variety of sophisticated methods that enable
rapid queries of geodesic information, even on relatively large models. This
survey reviews the major categories of approaches to the computation of
geodesic paths and distances, highlighting common themes and opportunities for
future improvement.
"
2156,Deep Preset: Blending and Retouching Photos with Color Style Transfer,"  End-users, without knowledge in photography, desire to beautify their photos
to have a similar color style as a well-retouched reference. However, recent
works in image style transfer are overused. They usually synthesize undesirable
results due to transferring exact colors to the wrong destination. It becomes
even worse in sensitive cases such as portraits. In this work, we concentrate
on learning low-level image transformation, especially color-shifting methods,
rather than mixing contextual features, then present a novel scheme to train
color style transfer with ground-truth. Furthermore, we propose a color style
transfer named Deep Preset. It is designed to 1) generalize the features
representing the color transformation from content with natural colors to
retouched reference, then blend it into the contextual features of content, 2)
predict hyper-parameters (settings or preset) of the applied low-level color
transformation methods, 3) stylize content to have a similar color style as
reference. We script Lightroom, a powerful tool in editing photos, to generate
600,000 training samples using 1,200 images from the Flick2K dataset and 500
user-generated presets with 69 settings. Experimental results show that our
Deep Preset outperforms the previous works in color style transfer
quantitatively and qualitatively.
"
2157,DecoSurf: Recursive Geodesic Patterns on Triangle Meshes,"  In this paper, we show that many complex patterns, which characterize the
decorative style of many artisanal objects, can be generated by the recursive
application of only four operators. Each operator is derived from tracing the
isolines or the integral curves of geodesics fields generated from selected
seeds on the surface. Based on this formulation, we present an interactive
application that lets designers model complex recursive patterns directly on
the object surface, without relying on parametrization. We support interaction
on commodity hardware on meshes of a few million triangles, by combining light
data structures together with an efficient approximate graph-based geodesic
solver. We validate our approach by matching decoration styles from real-world
photos, by analyzing the speed and accuracy of our geodesic solver, and by
validating the interface with a user study.
"
2158,"FASTSWARM: A Data-driven FrAmework for Real-time Flying InSecT SWARM
  Simulation","  Insect swarms are common phenomena in nature and therefore have been actively
pursued in computer animation. Realistic insect swarm simulation is difficult
due to two challenges: high-fidelity behaviors and large scales, which make the
simulation practice subject to laborious manual work and excessive
trial-and-error processes. To address both challenges, we present a novel
data-driven framework, FASTSWARM, to model complex behaviors of flying insects
based on real-world data and simulate plausible animations of flying insect
swarms. FASTSWARM has a linear time complexity and achieves real-time
performance for large swarms. The high-fidelity behavior model of FASTSWARM
explicitly takes into consideration the most common behaviors of flying
insects, including the interactions among insects such as repulsion and
attraction, the self-propelled behaviors such as target following and obstacle
avoidance, and other characteristics such as the random movements. To achieve
scalability, an energy minimization problem is formed with different behaviors
modelled as energy terms, where the minimizer is the desired behavior. The
minimizer is computed from the real-world data, which ensures the plausibility
of the simulation results. Extensive simulation results and evaluations show
that FASTSWARM is versatile in simulating various swarm behaviors, high
fidelity measured by various metrics, easily controllable in inducing user
controls and highly scalable.
"
2159,"InCorr: Interactive Data-Driven Correlation Panels for Digital Outcrop
  Analysis","  Geological analysis of 3D Digital Outcrop Models (DOMs) for reconstruction of
ancient habitable environments is a key aspect of the upcoming ESA ExoMars 2022
Rosalind Franklin Rover and the NASA 2020 Rover Perseverance missions in
seeking signs of past life on Mars. Geologists measure and interpret 3D DOMs,
create sedimentary logs and combine them in `correlation panels' to map the
extents of key geological horizons, and build a stratigraphic model to
understand their position in the ancient landscape. Currently, the creation of
correlation panels is completely manual and therefore time-consuming, and
inflexible. With InCorr we present a visualization solution that encompasses a
3D logging tool and an interactive data-driven correlation panel that evolves
with the stratigraphic analysis. For the creation of InCorr we closely
cooperated with leading planetary geologists in the form of a design study. We
verify our results by recreating an existing correlation analysis with InCorr
and validate our correlation panel against a manually created illustration.
Further, we conducted a user-study with a wider circle of geologists. Our
evaluation shows that InCorr efficiently supports the domain experts in
tackling their research questions and that it has the potential to
significantly impact how geologists work with digital outcrop representations
in general.
"
2160,Neural Sparse Voxel Fields,"  Photo-realistic free-viewpoint rendering of real-world scenes using classical
computer graphics techniques is challenging, because it requires the difficult
step of capturing detailed appearance and geometry models. Recent studies have
demonstrated promising results by learning scene representations that
implicitly encode both geometry and appearance without 3D supervision. However,
existing approaches in practice often show blurry renderings caused by the
limited network capacity or the difficulty in finding accurate intersections of
camera rays with the scene geometry. Synthesizing high-resolution imagery from
these representations often requires time-consuming optical ray marching. In
this work, we introduce Neural Sparse Voxel Fields (NSVF), a new neural scene
representation for fast and high-quality free-viewpoint rendering. NSVF defines
a set of voxel-bounded implicit fields organized in a sparse voxel octree to
model local properties in each cell. We progressively learn the underlying
voxel structures with a diffentiable ray-marching operation from only a set of
posed RGB images. With the sparse voxel octree structure, rendering novel views
can be accelerated by skipping the voxels containing no relevant scene content.
Our method is over 10 times faster than the state-of-the-art (namely, NeRF) at
inference time while achieving higher quality results. Furthermore, by
utilizing an explicit sparse voxel representation, our method can easily be
applied to scene editing and scene composition. We also demonstrate several
challenging tasks, including multi-scene learning, free-viewpoint rendering of
a moving human, and large-scale scene rendering.
"
2161,"Wavelet-based Heat Kernel Derivatives: Towards Informative Localized
  Shape Analysis","  In this paper, we propose a new construction for the Mexican hat wavelets on
shapes with applications to partial shape matching. Our approach takes its main
inspiration from the well-established methodology of diffusion wavelets. This
novel construction allows us to rapidly compute a multiscale family of Mexican
hat wavelet functions, by approximating the derivative of the heat kernel. We
demonstrate that it leads to a family of functions that inherit many attractive
properties of the heat kernel (e.g., a local support, ability to recover
isometries from a single point, efficient computation). Due to its natural
ability to encode high-frequency details on a shape, the proposed method
reconstructs and transfers $\delta$-functions more accurately than the
Laplace-Beltrami eigenfunction basis and other related bases. Finally, we apply
our method to the challenging problems of partial and large-scale shape
matching. An extensive comparison to the state-of-the-art shows that it is
comparable in performance, while both simpler and much faster than competing
approaches.
"
2162,Silhouette Vectorization by Affine Scale-space,"  Silhouettes or 2D planar shapes are extremely important in human
communication, which involves many logos, graphics symbols and fonts in vector
form. Many more shapes can be extracted from image by binarization or
segmentation, thus in raster form that requires a vectorization. There is a
need for disposing of a mathematically well defined and justified shape
vectorization process, which in addition provides a minimal set of control
points with geometric meaning. In this paper we propose a silhouette
vectorization method which extracts the outline of a 2D shape from a raster
binary image, and converts it to a combination of cubic B\'{e}zier polygons and
perfect circles. Starting from the boundary curvature extrema computed at
sub-pixel level, we identify a set of control points based on the affine
scale-space induced by the outline. These control points capture similarity
invariant geometric features of the given silhouette and give precise locations
of the shape's corners.of the given silhouette. Then, piecewise B\'{e}zier
cubics are computed by least-square fitting combined with an adaptive splitting
to guarantee a predefined accuracy. When there are no curvature extrema
identified, either the outline is recognized as a circle using the
isoperimetric inequality, or a pair of the most distant outline points are
chosen to initiate the fitting. Given their construction, most of our control
points are geometrically stable under affine transformations. By comparing with
other feature detectors, we show that our method can be used as a reliable
feature point detector for silhouettes. Compared to state-of-the-art image
vectorization software, our algorithm demonstrates superior reduction on the
number of control points, while maintaining high accuracy.
"
2163,"Anecdotal Survey of Variations in Path Stroking among Real-world
  Implementations","  Stroking a path is one of the two basic rendering operations in vector
graphics standards (e.g., PostScript, PDF, SVG). We survey path stroking
rendering results from real-world software implementations of path stroking for
anecdotal evidence that such implementations are prone to rendering variances.
While our survey is limited and informal, the rendering results we gathered
indicate widespread rendering variations for simple-but-problematic stroked
paths first identified decades ago. We conclude that creators of vector
graphics content would benefit from a mathematically grounded standardization
for how a stroked path should be rasterized.
"
2164,"Self-Prediction for Joint Instance and Semantic Segmentation of Point
  Clouds","  We develop a novel learning scheme named Self-Prediction for 3D instance and
semantic segmentation of point clouds. Distinct from most existing methods that
focus on designing convolutional operators, our method designs a new learning
scheme to enhance point relation exploring for better segmentation. More
specifically, we divide a point cloud sample into two subsets and construct a
complete graph based on their representations. Then we use label propagation
algorithm to predict labels of one subset when given labels of the other
subset. By training with this Self-Prediction task, the backbone network is
constrained to fully explore relational context/geometric/shape information and
learn more discriminative features for segmentation. Moreover, a general
associated framework equipped with our Self-Prediction scheme is designed for
enhancing instance and semantic segmentation simultaneously, where instance and
semantic representations are combined to perform Self-Prediction. Through this
way, instance and semantic segmentation are collaborated and mutually
reinforced. Significant performance improvements on instance and semantic
segmentation compared with baseline are achieved on S3DIS and ShapeNet. Our
method achieves state-of-the-art instance segmentation results on S3DIS and
comparable semantic segmentation results compared with state-of-the-arts on
S3DIS and ShapeNet when we only take PointNet++ as the backbone network.
"
2165,"Building Trust in Autonomous Vehicles: Role of Virtual Reality Driving
  Simulators in HMI Design","  The investigation of factors contributing at making humans trust Autonomous
Vehicles (AVs) will play a fundamental role in the adoption of such technology.
The user's ability to form a mental model of the AV, which is crucial to
establish trust, depends on effective user-vehicle communication; thus, the
importance of Human-Machine Interaction (HMI) is poised to increase. In this
work, we propose a methodology to validate the user experience in AVs based on
continuous, objective information gathered from physiological signals, while
the user is immersed in a Virtual Reality-based driving simulation. We applied
this methodology to the design of a head-up display interface delivering visual
cues about the vehicle' sensory and planning systems. Through this approach, we
obtained qualitative and quantitative evidence that a complete picture of the
vehicle's surrounding, despite the higher cognitive load, is conducive to a
less stressful experience. Moreover, after having been exposed to a more
informative interface, users involved in the study were also more willing to
test a real AV. The proposed methodology could be extended by adjusting the
simulation environment, the HMI and/or the vehicle's Artificial Intelligence
modules to dig into other aspects of the user experience.
"
2166,Continuous Fuzzy Transform as Integral Operator,"  The Fuzzy transform is ubiquitous in different research fields and
applications, such as image and data compression, data mining, knowledge
discovery, and the analysis of linguistic expressions. As a generalisation of
the Fuzzy transform, we introduce the continuous Fuzzy transform and its
inverse, as an integral operator induced by a kernel function. Through the
relation between membership functions and integral kernels, we show that the
main properties (e.g., continuity, symmetry) of the membership functions are
inherited by the continuous Fuzzy transform. Then, the relation between the
continuous Fuzzy transform and integral operators is used to introduce a
data-driven Fuzzy transform, which encodes intrinsic information (e.g.,
structure, geometry, sampling density) about the input data. In this way, we
avoid coarse fuzzy partitions, which group data into large clusters that do not
adapt to their local behaviour, or a too dense fuzzy partition, which generally
has cells that are not covered by the data, thus being redundant and resulting
in a higher computational cost. To this end, the data-driven membership
functions are defined by properly filtering the spectrum of the
Laplace-Beltrami operator associated with the input data. Finally, we introduce
the space of continuous Fuzzy transforms, which is useful for the comparison of
different continuous Fuzzy transforms and for their efficient computation.
"
2167,"se(3)-TrackNet: Data-driven 6D Pose Tracking by Calibrating Image
  Residuals in Synthetic Domains","  Tracking the 6D pose of objects in video sequences is important for robot
manipulation. This task, however, introduces multiple challenges: (i) robot
manipulation involves significant occlusions; (ii) data and annotations are
troublesome and difficult to collect for 6D poses, which complicates machine
learning solutions, and (iii) incremental error drift often accumulates in long
term tracking to necessitate re-initialization of the object's pose. This work
proposes a data-driven optimization approach for long-term, 6D pose tracking.
It aims to identify the optimal relative pose given the current RGB-D
observation and a synthetic image conditioned on the previous best estimate and
the object's model. The key contribution in this context is a novel neural
network architecture, which appropriately disentangles the feature encoding to
help reduce domain shift, and an effective 3D orientation representation via
Lie Algebra. Consequently, even when the network is trained only with synthetic
data can work effectively over real images. Comprehensive experiments over
benchmarks - existing ones as well as a new dataset with significant occlusions
related to object manipulation - show that the proposed approach achieves
consistently robust estimates and outperforms alternatives, even though they
have been trained with real images. The approach is also the most
computationally efficient among the alternatives and achieves a tracking
frequency of 90.9Hz.
"
2168,Monocular Real-Time Volumetric Performance Capture,"  We present the first approach to volumetric performance capture and
novel-view rendering at real-time speed from monocular video, eliminating the
need for expensive multi-view systems or cumbersome pre-acquisition of a
personalized template model. Our system reconstructs a fully textured 3D human
from each frame by leveraging Pixel-Aligned Implicit Function (PIFu). While
PIFu achieves high-resolution reconstruction in a memory-efficient manner, its
computationally expensive inference prevents us from deploying such a system
for real-time applications. To this end, we propose a novel hierarchical
surface localization algorithm and a direct rendering method without explicitly
extracting surface meshes. By culling unnecessary regions for evaluation in a
coarse-to-fine manner, we successfully accelerate the reconstruction by two
orders of magnitude from the baseline without compromising the quality.
Furthermore, we introduce an Online Hard Example Mining (OHEM) technique that
effectively suppresses failure modes due to the rare occurrence of challenging
examples. We adaptively update the sampling probability of the training data
based on the current reconstruction accuracy, which effectively alleviates
reconstruction artifacts. Our experiments and evaluations demonstrate the
robustness of our system to various challenging angles, illuminations, poses,
and clothing styles. We also show that our approach compares favorably with the
state-of-the-art monocular performance capture. Our proposed approach removes
the need for multi-view studio settings and enables a consumer-accessible
solution for volumetric capture.
"
2169,Signed Distance Fields Dynamic Diffuse Global Illumination,"  Global Illumination (GI) is of utmost importance in the field of
photo-realistic rendering. However, its computation has always been very
complex, especially diffuse GI. State of the art real-time GI methods have
limitations of different nature, such as light leaking, performance issues,
special hardware requirements, noise corruption, bounce number limitations,
among others. To overcome these limitations, we propose a novel approach of
computing dynamic diffuse GI with a signed distance fields approximation of the
scene and discretizing the space domain of the irradiance function. With this
approach, we are able to estimate real-time diffuse GI for dynamic lighting and
geometry, without any precomputations and supporting multi-bounce GI, providing
good quality lighting and high performance at the same time. Our algorithm is
also able to achieve better scalability, and manage both large open scenes and
indoor high-detailed scenes without being corrupted by noise.
"
2170,Enhancement of Retinal Fundus Images via Pixel Color Amplification,"  We propose a pixel color amplification theory and family of enhancement
methods to facilitate segmentation tasks on retinal images. Our novel
re-interpretation of the image distortion model underlying dehazing theory
shows how three existing priors commonly used by the dehazing community and a
novel fourth prior are related. We utilize the theory to develop a family of
enhancement methods for retinal images, including novel methods for whole image
brightening and darkening. We show a novel derivation of the Unsharp Masking
algorithm. We evaluate the enhancement methods as a pre-processing step to a
challenging multi-task segmentation problem and show large increases in
performance on all tasks, with Dice score increases over a no-enhancement
baseline by as much as 0.491. We provide evidence that our enhancement
preprocessing is useful for unbalanced and difficult data. We show that the
enhancements can perform class balancing by composing them together.
"
2171,A Progressive Approach to Scalar Field Topology,"  This paper introduces progressive algorithms for the topological analysis of
scalar data. Our approach is based on a hierarchical representation of the
input data and the fast identification of topologically invariant vertices, for
which we show that no computation is required as they are introduced in the
hierarchy. This enables the definition of efficient coarse-to-fine topological
algorithms, which leverage fast update mechanisms for ordinary vertices and
avoid computation for the topologically invariant ones. We instantiate our
approach with two examples of topological algorithms (critical point extraction
and persistence diagram computation), which generate exploitable outputs upon
interruption requests and which progressively refine them otherwise.
Experiments on real-life datasets illustrate that our progressive strategy, in
addition to the continuous visual feedback it provides, even improves run time
performances with regard to non-progressive algorithms and we describe further
accelerations with shared-memory parallelism. We illustrate the utility of our
approach in (i) batch-mode and (ii) interactive setups, where it respectively
enables (i) the control of the execution time of complete topological pipelines
as well as (ii) previews of the topological features found in a dataset, with
progressive updates delivered within interactive times.
"
2172,AMM: Adaptive Multilinear Meshes,"  We present Adaptive Multilinear Meshes (AMM), a new framework that
significantly reduces the memory footprint compared to existing data
structures. AMM uses a hierarchy of cuboidal cells to create continuous,
piecewise multilinear representation of uniformly sampled data. Furthermore,
AMM can selectively relax or enforce constraints on conformity, continuity, and
coverage, creating a highly adaptive and flexible representation to support a
wide range of use cases. AMM supports incremental updates in both spatial
resolution and numerical precision establishing the first practical data
structure that can seamlessly explore the tradeoff between resolution and
precision. We use tensor products of linear B-spline wavelets to create an
adaptive representation and illustrate the advantages of our framework. AMM
provides a simple interface for evaluating the function defined on the adaptive
mesh, efficiently traversing the mesh, and manipulating the mesh, including
incremental, partial updates. Our framework is easy to adopt for standard
visualization and analysis tasks. As an example, we provide a VTK interface,
through efficient on-demand conversion, which can be used directly by
corresponding tools, such as VisIt, disseminating the advantages of faster
processing and a smaller memory footprint to a wider audience. We demonstrate
the advantages of our approach for simplifying scalar-valued data for commonly
used visualization and analysis tasks using incremental construction, according
to mixed resolution and precision data streams.
"
2173,"Federated Visualization: A Privacy-preserving Strategy for Decentralized
  Visualization","  We present a novel privacy preservation strategy for decentralized
visualization. The key idea is to imitate the flowchart of the federated
learning framework, and reformulate the visualization process within a
federated infrastructure. The federation of visualization is fulfilled by
leveraging a shared global module that composes the encrypted externalizations
of transformed visual features of data pieces in local modules. We design two
implementations of federated visualization: a prediction-based scheme, and a
query-based scheme. We demonstrate the effectiveness of our approach with a set
of visual forms, and verify its robustness with evaluations. We report the
value of federated visualization in real scenarios with an expert review.
"
2174,"Understanding the Stability of Deep Control Policies for Biped
  Locomotion","  Achieving stability and robustness is the primary goal of biped locomotion
control. Recently, deep reinforce learning (DRL) has attracted great attention
as a general methodology for constructing biped control policies and
demonstrated significant improvements over the previous state-of-the-art.
Although deep control policies have advantages over previous controller design
approaches, many questions remain unanswered. Are deep control policies as
robust as human walking? Does simulated walking use similar strategies as human
walking to maintain balance? Does a particular gait pattern similarly affect
human and simulated walking? What do deep policies learn to achieve improved
gait stability? The goal of this study is to answer these questions by
evaluating the push-recovery stability of deep policies compared to human
subjects and a previous feedback controller. We also conducted experiments to
evaluate the effectiveness of variants of DRL algorithms.
"
2175,"ConceptExplorer: Visual Analysis of Concept Driftsin Multi-source
  Time-series Data","  Time-series data is widely studied in various scenarios, like weather
forecast, stock market, customer behavior analysis. To comprehensively learn
about the dynamic environments, it is necessary to comprehend features from
multiple data sources. This paper proposes a novel visual analysis approach for
detecting and analyzing concept drifts from multi-sourced time-series. We
propose a visual detection scheme for discovering concept drifts from multiple
sourced time-series based on prediction models. We design a drift level index
to depict the dynamics, and a consistency judgment model to justify whether the
concept drifts from various sources are consistent. Our integrated visual
interface, ConceptExplorer, facilitates visual exploration, extraction,
understanding, and comparison of concepts and concept drifts from multi-source
time-series data. We conduct three case studies and expert interviews to verify
the effectiveness of our approach.
"
2176,Functionality-Driven Musculature Retargeting,"  We present a novel retargeting algorithm that transfers the musculature of a
reference anatomical model to new bodies with different sizes, body
proportions, muscle capability, and joint range of motion while preserving the
functionality of the original musculature as closely as possible. The geometric
configuration and physiological parameters of musculotendon units are estimated
and optimized to adapt to new bodies. The range of motion around joints is
estimated from a motion capture dataset and edited further for individual
models. The retargeted model is simulation-ready, so we can physically simulate
muscle-actuated motor skills with the model. Our system is capable of
generating a wide variety of anatomical bodies that can be simulated to walk,
run, jump and dance while maintaining balance under gravity. We will also
demonstrate the construction of individualized musculoskeletal models from
bi-planar X-ray images and medical examinations.
"
2177,Visual Analysis of Multi-Parameter Distributions across Ensembles,"  For an ensemble of data points in a multi-parameter space, we present a
visual analytics technique to select a representative distribution of parameter
values, and analyse how representative this distribution is in all ensemble
members. A multi-parameter cluster in a representative ensemble member is
visualized via a parallel coordinates plot, to provide initial distributions
and let domain experts interactively select relevant parameters and value
ranges. Since unions of value ranges select hyper-cubes in parameter space,
data points in these unions are not necessarily contained in the cluster. By
using a multi-parameter kD-tree to further refine the selected parameter
ranges, in combination with a covariance analysis of refined sets of data
points, a tight partition in multi-parameter space with reduced number of
falsely selected points is obtained. To assess the representativeness of the
selected multi-parameter distribution across the ensemble, a linked
side-by-side view of per-member violin plots is provided. We propose
modifications of violin plots to show multi-parameter distributions
simultaneously, and investigate the visual design that effectively conveys
(dis-)similarities in multi-parameter distributions. In a linked spatial view,
users can analyse and compare the spatial distribution of selected points in
different ensemble members via interval-based isosurface raycasting. In two
real-world application cases we show how our approach is used to analyse the
multi-parameter distributions across an ensemble of 3D fields.
"
2178,"Mixed-Reality Robotic Games: Design Guidelines for Effective
  Entertainment with Consumer Robots","  In recent years, there has been an increasing interest in the use of robotic
technology at home. A number of service robots appeared on the market,
supporting customers in the execution of everyday tasks. Roughly at the same
time, consumer level robots started to be used also as toys or gaming
companions. However, gaming possibilities provided by current off-the-shelf
robotic products are generally quite limited, and this fact makes them quickly
loose their attractiveness. A way that has been proven capable to boost robotic
gaming and related devices consists in creating playful experiences in which
physical and digital elements are combined together using Mixed Reality
technologies. However, these games differ significantly from digital- or
physical only experiences, and new design principles are required to support
developers in their creative work. This papers addresses such need, by drafting
a set of guidelines which summarize developments carried out by the research
community and their findings.
"
2179,Rewriting a Deep Generative Model,"  A deep generative model such as a GAN learns to model a rich set of semantic
and physical rules about the target distribution, but up to now, it has been
obscure how such rules are encoded in the network, or how a rule could be
changed. In this paper, we introduce a new problem setting: manipulation of
specific rules encoded by a deep generative model. To address the problem, we
propose a formulation in which the desired rule is changed by manipulating a
layer of a deep network as a linear associative memory. We derive an algorithm
for modifying one entry of the associative memory, and we demonstrate that
several interesting structural rules can be located and modified within the
layers of state-of-the-art generative models. We present a user interface to
enable users to interactively change the rules of a generative model to achieve
desired effects, and we show several proof-of-concept applications. Finally,
results on multiple datasets demonstrate the advantage of our method against
standard fine-tuning methods and edit transfer algorithms.
"
2180,"Blending Generative Adversarial Image Synthesis with Rendering for
  Computer Graphics","  Conventional computer graphics pipelines require detailed 3D models, meshes,
textures, and rendering engines to generate 2D images from 3D scenes. These
processes are labor-intensive. We introduce Hybrid Neural Computer Graphics
(HNCG) as an alternative. The contribution is a novel image formation strategy
to reduce the 3D model and texture complexity of computer graphics pipelines.
Our main idea is straightforward: Given a 3D scene, render only important
objects of interest and use generative adversarial processes for synthesizing
the rest of the image. To this end, we propose a novel image formation strategy
to form 2D semantic images from 3D scenery consisting of simple object models
without textures. These semantic images are then converted into photo-realistic
RGB images with a state-of-the-art conditional Generative Adversarial Network
(cGAN) based image synthesizer trained on real-world data. Meanwhile, objects
of interest are rendered using a physics-based graphics engine. This is
necessary as we want to have full control over the appearance of objects of
interest. Finally, the partially-rendered and cGAN synthesized images are
blended with a blending GAN. We show that the proposed framework outperforms
conventional rendering with ablation and comparison studies. Semantic retention
and Fr\'echet Inception Distance (FID) measurements were used as the main
performance metrics.
"
2181,A Visual Analytics Framework for Contrastive Network Analysis,"  A common network analysis task is comparison of two networks to identify
unique characteristics in one network with respect to the other. For example,
when comparing protein interaction networks derived from normal and cancer
tissues, one essential task is to discover protein-protein interactions unique
to cancer tissues. However, this task is challenging when the networks contain
complex structural (and semantic) relations. To address this problem, we design
ContraNA, a visual analytics framework leveraging both the power of machine
learning for uncovering unique characteristics in networks and also the
effectiveness of visualization for understanding such uniqueness. The basis of
ContraNA is cNRL, which integrates two machine learning schemes, network
representation learning (NRL) and contrastive learning (CL), to generate a
low-dimensional embedding that reveals the uniqueness of one network when
compared to another. ContraNA provides an interactive visualization interface
to help analyze the uniqueness by relating embedding results and network
structures as well as explaining the learned features by cNRL. We demonstrate
the usefulness of ContraNA with two case studies using real-world datasets. We
also evaluate through a controlled user study with 12 participants on network
comparison tasks. The results show that participants were able to both
effectively identify unique characteristics from complex networks and interpret
the results obtained from cNRL.
"
2182,Self-supervised Learning of Point Clouds via Orientation Estimation,"  Point clouds provide a compact and efficient representation of 3D shapes.
While deep neural networks have achieved impressive results on point cloud
learning tasks, they require massive amounts of manually labeled data, which
can be costly and time-consuming to collect. In this paper, we leverage 3D
self-supervision for learning downstream tasks on point clouds with fewer
labels. A point cloud can be rotated in infinitely many ways, which provides a
rich label-free source for self-supervision. We consider the auxiliary task of
predicting rotations that in turn leads to useful features for other tasks such
as shape classification and 3D keypoint prediction. Using experiments on
ShapeNet and ModelNet, we demonstrate that our approach outperforms the
state-of-the-art. Moreover, features learned by our model are complementary to
other self-supervised methods and combining them leads to further performance
improvement.
"
2183,"P-Cloth: Interactive Complex Cloth Simulation on Multi-GPU Systems using
  Dynamic Matrix Assembly and Pipelined Implicit Integrators","  We present a novel parallel algorithm for cloth simulation that exploits
multiple GPUs for fast computation and the handling of very high resolution
meshes. To accelerate implicit integration, we describe new parallel algorithms
for sparse matrix-vector multiplication (SpMV) and for dynamic matrix assembly
on a multi-GPU workstation. Our algorithms use a novel work queue generation
scheme for a fat-tree GPU interconnect topology. Furthermore, we present a
novel collision handling scheme that uses spatial hashing for discrete and
continuous collision detection along with a non-linear impact zone solver. Our
parallel schemes can distribute the computation and storage overhead among
multiple GPUs and enable us to perform almost interactive simulation on complex
cloth meshes, which can hardly be handled on a single GPU due to memory
limitations. We have evaluated the performance with two multi-GPU workstations
(with 4 and 8 GPUs, respectively) on cloth meshes with 0.5-1.65M triangles. Our
approach can reliably handle the collisions and generate vivid wrinkles and
folds at 2-5 fps, which is significantly faster than prior cloth simulation
systems. We observe almost linear speedups with respect to the number of GPUs.
"
2184,"SymmetryNet: Learning to Predict Reflectional and Rotational Symmetries
  of 3D Shapes from Single-View RGB-D Images","  We study the problem of symmetry detection of 3D shapes from single-view
RGB-D images, where severely missing data renders geometric detection approach
infeasible. We propose an end-to-end deep neural network which is able to
predict both reflectional and rotational symmetries of 3D objects present in
the input RGB-D image. Directly training a deep model for symmetry prediction,
however, can quickly run into the issue of overfitting. We adopt a multi-task
learning approach. Aside from symmetry axis prediction, our network is also
trained to predict symmetry correspondences. In particular, given the 3D points
present in the RGB-D image, our network outputs for each 3D point its symmetric
counterpart corresponding to a specific predicted symmetry. In addition, our
network is able to detect for a given shape multiple symmetries of different
types. We also contribute a benchmark of 3D symmetry detection based on
single-view RGB-D images. Extensive evaluation on the benchmark demonstrates
the strong generalization ability of our method, in terms of high accuracy of
both symmetry axis prediction and counterpart estimation. In particular, our
method is robust in handling unseen object instances with large variation in
shape, multi-symmetry composition, as well as novel object categories.
"
2185,Modeling of Personalized Anatomy using Plastic Strains,"  We give a method for modeling solid objects undergoing large spatially
varying and/or anisotropic strains, and use it to reconstruct human anatomy
from medical images. Our novel shape deformation method uses plastic strains
and the Finite Element Method to successfully model shapes undergoing large
and/or anisotropic strains, specified by sparse point constraints on the
boundary of the object. We extensively compare our method to standard
second-order shape deformation methods, variational methods and surface-based
methods and demonstrate that our method avoids the spikiness, wiggliness and
other artefacts of previous methods. We demonstrate how to perform such shape
deformation both for attached and un-attached (""free flying"") objects, using a
novel method to solve linear systems with singular matrices with a known
nullspace. While our method is applicable to general large-strain shape
deformation modeling, we use it to create personalized 3D triangle and
volumetric meshes of human organs, based on MRI or CT scans. Given a medically
accurate anatomy template of a generic individual, we optimize the geometry of
the organ to match the MRI or CT scan of a specific individual. Our examples
include human hand muscles, a liver, a hip bone, and a gluteus medius muscle
(""hip abductor"").
"
2186,Exemplar-based Layout Fine-tuning for Node-link Diagrams,"  We design and evaluate a novel layout fine-tuning technique for node-link
diagrams that facilitates exemplar-based adjustment of a group of substructures
in batching mode. The key idea is to transfer user modifications on a local
substructure to other substructures in the whole graph that are topologically
similar to the exemplar. We first precompute a canonical representation for
each substructure with node embedding techniques and then use it for on-the-fly
substructure retrieval. We design and develop a light-weight interactive system
to enable intuitive adjustment, modification transfer, and visual graph
exploration. We also report some results of quantitative comparisons, three
case studies, and a within-participant user study.
"
2187,Rethinking Image Deraining via Rain Streaks and Vapors,"  Single image deraining regards an input image as a fusion of a background
image, a transmission map, rain streaks, and atmosphere light. While advanced
models are proposed for image restoration (i.e., background image generation),
they regard rain streaks with the same properties as background rather than
transmission medium. As vapors (i.e., rain streaks accumulation or fog-like
rain) are conveyed in the transmission map to model the veiling effect, the
fusion of rain streaks and vapors do not naturally reflect the rain image
formation. In this work, we reformulate rain streaks as transmission medium
together with vapors to model rain imaging. We propose an encoder-decoder CNN
named as SNet to learn the transmission map of rain streaks. As rain streaks
appear with various shapes and directions, we use ShuffleNet units within SNet
to capture their anisotropic representations. As vapors are brought by rain
streaks, we propose a VNet containing spatial pyramid pooling (SSP) to predict
the transmission map of vapors in multi-scales based on that of rain streaks.
Meanwhile, we use an encoder CNN named ANet to estimate atmosphere light. The
SNet, VNet, and ANet are jointly trained to predict transmission maps and
atmosphere light for rain image restoration. Extensive experiments on the
benchmark datasets demonstrate the effectiveness of the proposed visual model
to predict rain streaks and vapors. The proposed deraining method performs
favorably against state-of-the-art deraining approaches.
"
2188,"Unsupervised 3D Learning for Shape Analysis via Multiresolution Instance
  Discrimination","  Although unsupervised feature learning has demonstrated its advantages to
reducing the workload of data labeling and network design in many fields,
existing unsupervised 3D learning methods still cannot offer a generic network
for various shape analysis tasks with competitive performance to supervised
methods. In this paper, we propose an unsupervised method for learning a
generic and efficient shape encoding network for different shape analysis
tasks. The key idea of our method is to jointly encode and learn shape and
point features from unlabeled 3D point clouds. For this purpose, we adapt
HR-Net to octree-based convolutional neural networks for jointly encoding shape
and point features with fused multiresolution subnetworks and design a
simple-yet-efficient \emph{Multiresolution Instance Discrimination} (MID) loss
for jointly learning the shape and point features. Our network takes a 3D point
cloud as input and output both shape and point features. After training, the
network is concatenated with simple task-specific back-end layers and
fine-tuned for different shape analysis tasks. We evaluate the efficacy and
generality of our method and validate our network and loss design with a set of
shape analysis tasks, including shape classification, semantic shape
segmentation, as well as shape registration tasks. With simple back-ends, our
network demonstrates the best performance among all unsupervised methods and
achieves competitive performance to supervised methods, especially in tasks
with a small labeled dataset. For fine-grained shape segmentation, our method
even surpasses existing supervised methods by a large margin.
"
2189,"Mesh Processing Strategies and Fractals for Three Dimensional
  Morphological Analysis of a Granitic Terrain using IRS LISS IV and Carto DEM","  Virtual Reality (VR) enabled applications are becoming very important to
visualize the terrain features in 3D. In general 3D datasets generated from
high-resolution satellites and DEM occupy large volumes of data. However,
lightweight datasets are required to create better user experiences on VR
platforms. So, the present study develops a methodology to generate datasets
compatible with VR using Indian Remote Sensing satellite (IRS) sensors. A
Linear Imaging Self-Scanning System - IV (LISS IV) with 5.8 m spatial
resolution and Carto DEM are used for generating the 3D view using the Arc
environment and then converted into virtual reality modeling language (VRML)
format. In order to reduce the volume of the VRML dataset a quadratic edge
collapse decimation method is applied which reduces the number of faces in the
mesh while preserving the boundary and/or normal. A granitic terrain in the
south-west part of Hyderabad comprising of dyke intrusion is considered for the
generation of 3D VR dataset, as it has high elevation differences thus
rendering it most suitable for the present study. Further, the enhanced
geomorphological features such as hills and valleys, geological structures such
as fractures, intrusive (dykes) are studied and found suitable for better
interpretation.
"
2190,"Design and Deployment of Photo2Building: A Cloud-based Procedural
  Modeling Tool as a Service","  We present a Photo2Building tool to create a plausible 3D model of a building
from only a single photograph. Our tool is based on a prior desktop version
which, as described in this paper, is converted into a client-server model,
with job queuing, web-page support, and support of concurrent usage. The
reported cloud-based web-accessible tool can reconstruct a building in 40
seconds on average and costing only 0.60 USD with current pricing. This
provides for an extremely scalable and possibly widespread tool for creating
building models for use in urban design and planning applications. With the
growing impact of rapid urbanization on weather and climate and resource
availability, access to such a service is expected to help a wide variety of
users such as city planners, urban meteorologists worldwide in the quest to
improved prediction of urban weather and designing climate-resilient cities of
the future.
"
2191,Real-Time Cleaning and Refinement of Facial Animation Signals,"  With the increasing demand for real-time animated 3D content in the
entertainment industry and beyond, performance-based animation has garnered
interest among both academic and industrial communities. While recent solutions
for motion-capture animation have achieved impressive results, handmade
post-processing is often needed, as the generated animations often contain
artifacts. Existing real-time motion capture solutions have opted for standard
signal processing methods to strengthen temporal coherence of the resulting
animations and remove inaccuracies. While these methods produce smooth results,
they inherently filter-out part of the dynamics of facial motion, such as high
frequency transient movements. In this work, we propose a real-time animation
refining system that preserves -- or even restores -- the natural dynamics of
facial motions. To do so, we leverage an off-the-shelf recurrent neural network
architecture that learns proper facial dynamics patterns on clean animation
data. We parametrize our system using the temporal derivatives of the signal,
enabling our network to process animations at any framerate. Qualitative
results show that our system is able to retrieve natural motion signals from
noisy or degraded input animation.
"
2192,Segmentation Based Mesh Denoising,"  Feature-preserving mesh denoising has received noticeable attention recently.
Many methods often design great weighting for anisotropic surfaces and small
weighting for isotropic surfaces, to preserve sharp features. However, they
often disregard the fact that small weights still pose negative impacts to the
denoising outcomes. Furthermore, it may increase the difficulty in parameter
tuning, especially for users without any background knowledge. In this paper,
we propose a novel clustering method for mesh denoising, which can avoid the
disturbance of anisotropic information and be easily embedded into
commonly-used mesh denoising frameworks. Extensive experiments have been
conducted to validate our method, and demonstrate that it can enhance the
denoising results of some existing methods remarkably both visually and
quantitatively. It also largely relaxes the parameter tuning procedure for
users, in terms of increasing stability for existing mesh denoising methods.
"
2193,Illustrations of non-Euclidean geometry in virtual reality,"  Mathematical objects are generally abstract and not very approachable.
Illustrations and interactive visualizations help both students and
professionals to comprehend mathematical material and to work with it. This
approach lends itself particularly well to geometrical objects. An example for
this category of mathematical objects are hyperbolic geometric spaces. When
Euclid lay down the foundations of mathematics, his formulation of geometry
reflected the surrounding space, as humans perceive it. For about two
millennia, it remained unclear whether there are alternative geometric spaces
that carry their own, unique mathematical properties and that do not reflect
human every-day perceptions. Finally, in the early 19th century, several
mathematicians described such geometries, which do not follow Euclid's rules
and which were at first interesting solely from a pure mathematical point of
view. These descriptions were not very accessible as mathematicians approached
the geometries via complicated collections of formulae. Within the following
decades, visualization aided the new concepts and two-dimensional versions of
these illustrations even appeared in artistic works. Furthermore, certain
aspects of Einstein's theory of relativity provided applications for
non-Euclidean geometric spaces. With the rise of computer graphics towards the
end of the twentieth century, three-dimensional illustrations became available
to explore these geometries and their non-intuitive properties. However, just
as the canvas confines the two-dimensional depictions, the computer monitor
confines these three-dimensional visualizations. Only virtual reality recently
made it possible to present immersive experiences of non-Euclidean geometries.
In virtual reality, users have completely new opportunities to encounter
geometric properties and effects that are not present in their surrounding
Euclidean world.
"
2194,Optimized Processing of Localized Collisions in Projective Dynamics,"  We present a method for the efficient processing of contact and collision in
volumetric elastic models simulated using the Projective Dynamics paradigm. Our
approach enables interactive simulation of tetrahedral meshes with more than
half a million elements, provided that the model satisfies two fundamental
properties: the region of the model's surface that is susceptible to collision
events needs to be known in advance, and the simulation degrees of freedom
associated with that surface region should be limited to a small fraction (e.g.
5\%) of the total simulation nodes. Despite this conscious delineation of
scope, our hypotheses hold true for common animation subjects, such as
simulated models of the human face and parts of the body. In such scenarios, a
partial Cholesky factorization can abstract away the behavior of the
collision-safe subset of the face into the Schur Complement matrix with respect
to the collision-prone region. We demonstrate how fast and accurate updates of
penalty-based collision terms can be incorporated into this representation, and
solved with high efficiency on the GPU. We also demonstrate the opportunity to
iterate a partial update of the element rotations, akin to a selective
application of the local step, specifically on the smaller collision-prone
region without explicitly paying the cost associated with the rest of the
simulation mesh. We demonstrate efficient and robust interactive simulation in
detailed models from animation and medical applications.
"
2195,"PatchNets: Patch-Based Generalizable Deep Implicit 3D Shape
  Representations","  Implicit surface representations, such as signed-distance functions, combined
with deep learning have led to impressive models which can represent detailed
shapes of objects with arbitrary topology. Since a continuous function is
learned, the reconstructions can also be extracted at any arbitrary resolution.
However, large datasets such as ShapeNet are required to train such models. In
this paper, we present a new mid-level patch-based surface representation. At
the level of patches, objects across different categories share similarities,
which leads to more generalizable models. We then introduce a novel method to
learn this patch-based representation in a canonical space, such that it is as
object-agnostic as possible. We show that our representation trained on one
category of objects from ShapeNet can also well represent detailed shapes from
any other category. In addition, it can be trained using much fewer shapes,
compared to existing approaches. We show several applications of our new
representation, including shape interpolation and partial point cloud
completion. Due to explicit control over positions, orientations and scales of
patches, our representation is also more controllable compared to object-level
representations, which enables us to deform encoded shapes non-rigidly.
"
2196,"A Visual Analytics Framework for Reviewing Multivariate Time-Series Data
  with Dimensionality Reduction","  Data-driven problem solving in many real-world applications involves analysis
of time-dependent multivariate data, for which dimensionality reduction (DR)
methods are often used to uncover the intrinsic structure and features of the
data. However, DR is usually applied to a subset of data that is either
single-time-point multivariate or univariate time-series, resulting in the need
to manually examine and correlate the DR results out of different data subsets.
When the number of dimensions is large either in terms of the number of time
points or attributes, this manual task becomes too tedious and infeasible. In
this paper, we present MulTiDR, a new DR framework that enables processing of
time-dependent multivariate data as a whole to provide a comprehensive overview
of the data. With the framework, we employ DR in two steps. When treating the
instances, time points, and attributes of the data as a 3D array, the first DR
step reduces the three axes of the array to two, and the second DR step
visualizes the data in a lower-dimensional space. In addition, by coupling with
a contrastive learning method and interactive visualizations, our framework
enhances analysts' ability to interpret DR results. We demonstrate the
effectiveness of our framework with four case studies using real-world
datasets.
"
2197,Deep Multi Depth Panoramas for View Synthesis,"  We propose a learning-based approach for novel view synthesis for
multi-camera 360$^{\circ}$ panorama capture rigs. Previous work constructs RGBD
panoramas from such data, allowing for view synthesis with small amounts of
translation, but cannot handle the disocclusions and view-dependent effects
that are caused by large translations. To address this issue, we present a
novel scene representation - Multi Depth Panorama (MDP) - that consists of
multiple RGBD$\alpha$ panoramas that represent both scene geometry and
appearance. We demonstrate a deep neural network-based method to reconstruct
MDPs from multi-camera 360$^{\circ}$ images. MDPs are more compact than
previous 3D scene representations and enable high-quality, efficient new view
rendering. We demonstrate this via experiments on both synthetic and real data
and comparisons with previous state-of-the-art methods spanning both
learning-based approaches and classical RGBD-based methods.
"
2198,COALESCE: Component Assembly by Learning to Synthesize Connections,"  We introduce COALESCE, the first data-driven framework for component-based
shape assembly which employs deep learning to synthesize part connections. To
handle geometric and topological mismatches between parts, we remove the
mismatched portions via erosion, and rely on a joint synthesis step, which is
learned from data, to fill the gap and arrive at a natural and plausible part
joint. Given a set of input parts extracted from different objects, COALESCE
automatically aligns them and synthesizes plausible joints to connect the parts
into a coherent 3D object represented by a mesh. The joint synthesis network,
designed to focus on joint regions, reconstructs the surface between the parts
by predicting an implicit shape representation that agrees with existing parts,
while generating a smooth and topologically meaningful connection. We employ
test-time optimization to further ensure that the synthesized joint region
closely aligns with the input parts to create realistic component assemblies
from diverse input parts. We demonstrate that our method significantly
outperforms prior approaches including baseline deep models for 3D shape
synthesis, as well as state-of-the-art methods for shape completion.
"
2199,"NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo
  Collections","  We present a learning-based method for synthesizing novel views of complex
outdoor scenes using only unstructured collections of in-the-wild photographs.
We build on neural radiance fields (NeRF), which uses the weights of a
multilayer perceptron to implicitly model the volumetric density and color of a
scene. While NeRF works well on images of static subjects captured under
controlled settings, it is incapable of modeling many ubiquitous, real-world
phenomena in uncontrolled images, such as variable illumination or transient
occluders. In this work, we introduce a series of extensions to NeRF to address
these issues, thereby allowing for accurate reconstructions from unstructured
image collections taken from the internet. We apply our system, which we dub
NeRF-W, to internet photo collections of famous landmarks, thereby producing
photorealistic, spatially consistent scene representations despite unknown and
confounding factors, resulting in significant improvement over the state of the
art.
"
2200,Learning Illumination from Diverse Portraits,"  We present a learning-based technique for estimating high dynamic range
(HDR), omnidirectional illumination from a single low dynamic range (LDR)
portrait image captured under arbitrary indoor or outdoor lighting conditions.
We train our model using portrait photos paired with their ground truth
environmental illumination. We generate a rich set of such photos by using a
light stage to record the reflectance field and alpha matte of 70 diverse
subjects in various expressions. We then relight the subjects using image-based
relighting with a database of one million HDR lighting environments,
compositing the relit subjects onto paired high-resolution background imagery
recorded during the lighting acquisition. We train the lighting estimation
model using rendering-based loss functions and add a multi-scale adversarial
loss to estimate plausible high frequency lighting detail. We show that our
technique outperforms the state-of-the-art technique for portrait-based
lighting estimation, and we also show that our method reliably handles the
inherent ambiguity between overall lighting strength and surface albedo,
recovering a similar scale of illumination for subjects with diverse skin
tones. We demonstrate that our method allows virtual objects and digital
characters to be added to a portrait photograph with consistent illumination.
Our lighting inference runs in real-time on a smartphone, enabling realistic
rendering and compositing of virtual objects into live video for augmented
reality applications.
"
2201,"StyleFlow: Attribute-conditioned Exploration of StyleGAN-Generated
  Images using Conditional Continuous Normalizing Flows","  High-quality, diverse, and photorealistic images can now be generated by
unconditional GANs (e.g., StyleGAN). However, limited options exist to control
the generation process using (semantic) attributes, while still preserving the
quality of the output. Further, due to the entangled nature of the GAN latent
space, performing edits along one attribute can easily result in unwanted
changes along other attributes. In this paper, in the context of conditional
exploration of entangled latent spaces, we investigate the two sub-problems of
attribute-conditioned sampling and attribute-controlled editing. We present
StyleFlow as a simple, effective, and robust solution to both the sub-problems
by formulating conditional exploration as an instance of conditional continuous
normalizing flows in the GAN latent space conditioned by attribute features. We
evaluate our method using the face and the car latent space of StyleGAN, and
demonstrate fine-grained disentangled edits along various attributes on both
real photographs and StyleGAN generated images. For example, for faces, we vary
camera pose, illumination variation, expression, facial hair, gender, and age.
Finally, via extensive qualitative and quantitative comparisons, we demonstrate
the superiority of StyleFlow to other concurrent works.
"
2202,Efficient Non-Line-of-Sight Imaging from Transient Sinograms,"  Non-line-of-sight (NLOS) imaging techniques use light that diffusely reflects
off of visible surfaces (e.g., walls) to see around corners. One approach
involves using pulsed lasers and ultrafast sensors to measure the travel time
of multiply scattered light. Unlike existing NLOS techniques that generally
require densely raster scanning points across the entirety of a relay wall, we
explore a more efficient form of NLOS scanning that reduces both acquisition
times and computational requirements. We propose a circular and confocal
non-line-of-sight (C2NLOS) scan that involves illuminating and imaging a common
point, and scanning this point in a circular path along a wall. We observe that
(1) these C2NLOS measurements consist of a superposition of sinusoids, which we
refer to as a transient sinogram, (2) there exists computationally efficient
reconstruction procedures that transform these sinusoidal measurements into 3D
positions of hidden scatterers or NLOS images of hidden objects, and (3)
despite operating on an order of magnitude fewer measurements than previous
approaches, these C2NLOS scans provide sufficient information about the hidden
scene to solve these different NLOS imaging tasks. We show results from both
simulated and real C2NLOS scans.
"
2203,Learning to Factorize and Relight a City,"  We propose a learning-based framework for disentangling outdoor scenes into
temporally-varying illumination and permanent scene factors. Inspired by the
classic intrinsic image decomposition, our learning signal builds upon two
insights: 1) combining the disentangled factors should reconstruct the original
image, and 2) the permanent factors should stay constant across multiple
temporal samples of the same scene. To facilitate training, we assemble a
city-scale dataset of outdoor timelapse imagery from Google Street View, where
the same locations are captured repeatedly through time. This data represents
an unprecedented scale of spatio-temporal outdoor imagery. We show that our
learned disentangled factors can be used to manipulate novel images in
realistic ways, such as changing lighting effects and scene geometry. Please
visit factorize-a-city.github.io for animated results.
"
2204,Predicting Visual Importance Across Graphic Design Types,"  This paper introduces a Unified Model of Saliency and Importance (UMSI),
which learns to predict visual importance in input graphic designs, and
saliency in natural images, along with a new dataset and applications. Previous
methods for predicting saliency or visual importance are trained individually
on specialized datasets, making them limited in application and leading to poor
generalization on novel image classes, while requiring a user to know which
model to apply to which input. UMSI is a deep learning-based model
simultaneously trained on images from different design classes, including
posters, infographics, mobile UIs, as well as natural images, and includes an
automatic classification module to classify the input. This allows the model to
work more effectively without requiring a user to label the input. We also
introduce Imp1k, a new dataset of designs annotated with importance
information. We demonstrate two new design interfaces that use importance
prediction, including a tool for adjusting the relative importance of design
elements, and a tool for reflowing designs to new aspect ratios while
preserving visual importance. The model, code, and importance dataset are
available at https://predimportance.mit.edu .
"
2205,SimPatch: A Nearest Neighbor Similarity Match between Image Patches,"  Measuring the similarity between patches in images is a fundamental building
block in various tasks. Naturally, the patch-size has a major impact on the
matching quality, and on the consequent application performance. We try to use
large patches instead of relatively small patches so that each patch contains
more information. We use different feature extraction mechanisms to extract the
features of each individual image patches which forms a feature matrix and find
out the nearest neighbor patches in the image. The nearest patches are
calculated using two different nearest neighbor algorithms in this paper for a
query patch for a given image and the results have been demonstrated in this
paper.
"
2206,LPMNet: Latent Part Modification and Generation for 3D Point Clouds,"  In this paper, we focus on latent modification and generation of 3D point
cloud object models with respect to their semantic parts. Different to the
existing methods which use separate networks for part generation and assembly,
we propose a single end-to-end Autoencoder model that can handle generation and
modification of both semantic parts, and global shapes. The proposed method
supports part exchange between 3D point cloud models and composition by
different parts to form new models by directly editing latent representations.
This holistic approach does not need part-based training to learn part
representations and does not introduce any extra loss besides the standard
reconstruction loss. The experiments demonstrate the robustness of the proposed
method with different object categories and varying number of points. The
method can generate new models by integration of generative models such as GANs
and VAEs and can work with unannotated point clouds by integration of a
segmentation module.
"
2207,"Accelerating Evolutionary Construction Tree Extraction via Graph
  Partitioning","  Extracting a Construction Tree from potentially noisy point clouds is an
important aspect of Reverse Engineering tasks in Computer Aided Design.
Solutions based on algorithmic geometry impose constraints on usable model
representations (e.g. quadric surfaces only) and noise robustness.
Re-formulating the problem as a combinatorial optimization problem and solving
it with an Evolutionary Algorithm can mitigate some of these constraints at the
cost of increased computational complexity. This paper proposes a graph-based
search space partitioning scheme that is able to accelerate Evolutionary
Construction Tree extraction while exploiting parallelization capabilities of
modern CPUs. The evaluation indicates a speed-up up to a factor of $46.6$
compared to the baseline approach while resulting tree sizes increased by
$25.2\%$ to $88.6\%$.
"
2208,A Flexible Pipeline for the Optimization of CSG Trees,"  CSG trees are an intuitive, yet powerful technique for the representation of
geometry using a combination of Boolean set-operations and geometric
primitives. In general, there exists an infinite number of trees all describing
the same 3D solid. However, some trees are optimal regarding the number of used
operations, their shape or other attributes, like their suitability for
intuitive, human-controlled editing. In this paper, we present a systematic
comparison of newly developed and existing tree optimization methods and
propose a flexible processing pipeline with a focus on tree editability. The
pipeline uses a redundancy removal and decomposition stage for complexity
reduction and different (meta-)heuristics for remaining tree optimization. We
also introduce a new quantitative measure for CSG tree editability and show how
it can be used as a constraint in the optimization process.
"
2209,Neural Light Transport for Relighting and View Synthesis,"  The light transport (LT) of a scene describes how it appears under different
lighting and viewing directions, and complete knowledge of a scene's LT enables
the synthesis of novel views under arbitrary lighting. In this paper, we focus
on image-based LT acquisition, primarily for human bodies within a light stage
setup. We propose a semi-parametric approach to learn a neural representation
of LT that is embedded in the space of a texture atlas of known geometric
properties, and model all non-diffuse and global LT as residuals added to a
physically-accurate diffuse base rendering. In particular, we show how to fuse
previously seen observations of illuminants and views to synthesize a new image
of the same scene under a desired lighting condition from a chosen viewpoint.
This strategy allows the network to learn complex material effects (such as
subsurface scattering) and global illumination, while guaranteeing the physical
correctness of the diffuse LT (such as hard shadows). With this learned LT, one
can relight the scene photorealistically with a directional light or an HDRI
map, synthesize novel views with view-dependent effects, or do both
simultaneously, all in a unified framework using a set of sparse, previously
seen observations. Qualitative and quantitative experiments demonstrate that
our neural LT (NLT) outperforms state-of-the-art solutions for relighting and
view synthesis, without separate treatment for both problems that prior work
requires.
"
2210,Neural Reflectance Fields for Appearance Acquisition,"  We present Neural Reflectance Fields, a novel deep scene representation that
encodes volume density, normal and reflectance properties at any 3D point in a
scene using a fully-connected neural network. We combine this representation
with a physically-based differentiable ray marching framework that can render
images from a neural reflectance field under any viewpoint and light. We
demonstrate that neural reflectance fields can be estimated from images
captured with a simple collocated camera-light setup, and accurately model the
appearance of real-world scenes with complex geometry and reflectance. Once
estimated, they can be used to render photo-realistic images under novel
viewpoint and (non-collocated) lighting conditions and accurately reproduce
challenging effects like specularities, shadows and occlusions. This allows us
to perform high-quality view synthesis and relighting that is significantly
better than previous methods. We also demonstrate that we can compose the
estimated neural reflectance field of a real scene with traditional scene
models and render them using standard Monte Carlo rendering engines. Our work
thus enables a complete pipeline from high-quality and practical appearance
acquisition to 3D scene composition and rendering.
"
2211,"Dual In-painting Model for Unsupervised Gaze Correction and Animation in
  the Wild","  In this paper we address the problem of unsupervised gaze correction in the
wild, presenting a solution that works without the need for precise annotations
of the gaze angle and the head pose. We have created a new dataset called
CelebAGaze, which consists of two domains X, Y, where the eyes are either
staring at the camera or somewhere else. Our method consists of three novel
modules: the Gaze Correction module (GCM), the Gaze Animation module (GAM), and
the Pretrained Autoencoder module (PAM). Specifically, GCM and GAM separately
train a dual in-painting network using data from the domain $X$ for gaze
correction and data from the domain $Y$ for gaze animation. Additionally, a
Synthesis-As-Training method is proposed when training GAM to encourage the
features encoded from the eye region to be correlated with the angle
information, resulting in a gaze animation which can be achieved by
interpolation in the latent space. To further preserve the identity
information~(e.g., eye shape, iris color), we propose the PAM with an
Autoencoder, which is based on Self-Supervised mirror learning where the
bottleneck features are angle-invariant and which works as an extra input to
the dual in-painting models. Extensive experiments validate the effectiveness
of the proposed method for gaze correction and gaze animation in the wild and
demonstrate the superiority of our approach in producing more compelling
results than state-of-the-art baselines. Our code, the pretrained models and
the supplementary material are available at:
https://github.com/zhangqianhui/GazeAnimation.
"
2212,RocNet: Recursive Octree Network for Efficient 3D Deep Representation,"  We introduce a deep recursive octree network for the compression of 3D voxel
data. Our network compresses a voxel grid of any size down to a very small
latent space in an autoencoder-like network. We show results for compressing
32, 64 and 128 grids down to just 80 floats in the latent space. We demonstrate
the effectiveness and efficiency of our proposed method on several publicly
available datasets with three experiments: 3D shape classification, 3D shape
reconstruction, and shape generation. Experimental results show that our
algorithm maintains accuracy while consuming less memory with shorter training
times compared to existing methods, especially in 3D reconstruction tasks.
"
2213,Deep Detail Enhancement for Any Garment,"  Creating fine garment details requires significant efforts and huge
computational resources. In contrast, a coarse shape may be easy to acquire in
many scenarios (e.g., via low-resolution physically-based simulation, linear
blend skinning driven by skeletal motion, portable scanners). In this paper, we
show how to enhance, in a data-driven manner, rich yet plausible details
starting from a coarse garment geometry. Once the parameterization of the
garment is given, we formulate the task as a style transfer problem over the
space of associated normal maps. In order to facilitate generalization across
garment types and character motions, we introduce a patch-based formulation,
that produces high-resolution details by matching a Gram matrix based style
loss, to hallucinate geometric details (i.e., wrinkle density and shape). We
extensively evaluate our method on a variety of production scenarios and show
that our method is simple, light-weight, efficient, and generalizes across
underlying garment types, sewing patterns, and body motion.
"
2214,"Meshless Approximation and Helmholtz-Hodge Decomposition of Vector
  Fields","  The analysis of vector fields is crucial for the understanding of several
physical phenomena, such as natural events (e.g., analysis of waves), diffusive
processes, electric and electromagnetic fields. While previous work has been
focused mainly on the analysis of 2D or 3D vector fields on volumes or
surfaces, we address the meshless analysis of a vector field defined on an
arbitrary domain, without assumptions on its dimension and discretisation. The
meshless approximation of the Helmholtz-Hodge decomposition of a vector field
is achieved by expressing the potential of its components as a linear
combination of radial basis functions and by computing the corresponding
conservative, irrotational, and harmonic components as solution to a
least-squares or to a differential problem. To this end, we identify the
conditions on the kernel of the radial basis functions that guarantee the
existence of their derivatives. Finally, we demonstrate our approach on 2D and
3D vector fields measured by sensors or generated through simulation.
"
2215,"Vid2Player: Controllable Video Sprites that Behave and Appear like
  Professional Tennis Players","  We present a system that converts annotated broadcast video of tennis matches
into interactively controllable video sprites that behave and appear like
professional tennis players. Our approach is based on controllable video
textures, and utilizes domain knowledge of the cyclic structure of tennis
rallies to place clip transitions and accept control inputs at key
decision-making moments of point play. Most importantly, we use points from the
video collection to model a player's court positioning and shot selection
decisions during points. We use these behavioral models to select video clips
that reflect actions the real-life player is likely to take in a given match
play situation, yielding sprites that behave realistically at the macro level
of full points, not just individual tennis motions. Our system can generate
novel points between professional tennis players that resemble Wimbledon
broadcasts, enabling new experiences such as the creation of matchups between
players that have not competed in real life, or interactive control of players
in the Wimbledon final. According to expert tennis players, the rallies
generated using our approach are significantly more realistic in terms of
player behavior than video sprite methods that only consider the quality of
motion transitions during video synthesis.
"
2216,GeLaTO: Generative Latent Textured Objects,"  Accurate modeling of 3D objects exhibiting transparency, reflections and thin
structures is an extremely challenging problem. Inspired by billboards and
geometric proxies used in computer graphics, this paper proposes Generative
Latent Textured Objects (GeLaTO), a compact representation that combines a set
of coarse shape proxies defining low frequency geometry with learned neural
textures, to encode both medium and fine scale geometry as well as
view-dependent appearance. To generate the proxies' textures, we learn a joint
latent space allowing category-level appearance and geometry interpolation. The
proxies are independently rasterized with their corresponding neural texture
and composited using a U-Net, which generates an output photorealistic image
including an alpha map. We demonstrate the effectiveness of our approach by
reconstructing complex objects from a sparse set of views. We show results on a
dataset of real images of eyeglasses frames, which are particularly challenging
to reconstruct using classical methods. We also demonstrate that these coarse
proxies can be handcrafted when the underlying object geometry is easy to
model, like eyeglasses, or generated using a neural network for more complex
categories, such as cars.
"
2217,Facial Expression Retargeting from Human to Avatar Made Easy,"  Facial expression retargeting from humans to virtual characters is a useful
technique in computer graphics and animation. Traditional methods use markers
or blendshapes to construct a mapping between the human and avatar faces.
However, these approaches require a tedious 3D modeling process, and the
performance relies on the modelers' experience. In this paper, we propose a
brand-new solution to this cross-domain expression transfer problem via
nonlinear expression embedding and expression domain translation. We first
build low-dimensional latent spaces for the human and avatar facial expressions
with variational autoencoder. Then we construct correspondences between the two
latent spaces guided by geometric and perceptual constraints. Specifically, we
design geometric correspondences to reflect geometric matching and utilize a
triplet data structure to express users' perceptual preference of avatar
expressions. A user-friendly method is proposed to automatically generate
triplets for a system allowing users to easily and efficiently annotate the
correspondences. Using both geometric and perceptual correspondences, we
trained a network for expression domain translation from human to avatar.
Extensive experimental results and user studies demonstrate that even
nonprofessional users can apply our method to generate high-quality facial
expression retargeting results with less time and effort.
"
2218,Towards Geometry Guided Neural Relighting with Flash Photography,"  Previous image based relighting methods require capturing multiple images to
acquire high frequency lighting effect under different lighting conditions,
which needs nontrivial effort and may be unrealistic in certain practical use
scenarios. While such approaches rely entirely on cleverly sampling the color
images under different lighting conditions, little has been done to utilize
geometric information that crucially influences the high-frequency features in
the images, such as glossy highlight and cast shadow. We therefore propose a
framework for image relighting from a single flash photograph with its
corresponding depth map using deep learning. By incorporating the depth map,
our approach is able to extrapolate realistic high-frequency effects under
novel lighting via geometry guided image decomposition from the flashlight
image, and predict the cast shadow map from the shadow-encoding transformed
depth map. Moreover, the single-image based setup greatly simplifies the data
capture process. We experimentally validate the advantage of our geometry
guided approach over state-of-the-art image-based approaches in intrinsic image
decomposition and image relighting, and also demonstrate our performance on
real mobile phone photo examples.
"
2219,The Topology of Shapes Made with Points,"  In architecture, city planning, visual arts, and other design areas, shapes
are often made with points, or with structural representations based on
point-sets. Shapes made with points can be understood more generally as finite
arrangements formed with elements (i.e. points) of the algebra of shapes $U_i$,
for $i = 0$. This paper examines the kind of topology that is applicable to
such shapes. From a mathematical standpoint, any ""shape made with points"" is
equivalent to a finite space, so that topology on a shape made with points is
no different than topology on a finite space: the study of topological
structure naturally coincides with the study of preorder relations on the
points of the shape. After establishing this fact, some connections between the
topology of shapes made with points and the topology of ""point-free"" pictorial
shapes (when $i > 0$) are discussed and the main differences between the two
are summarized.
"
2220,"DSM-Net: Disentangled Structured Mesh Net for Controllable Generation of
  Fine Geometry","  3D shape generation is a fundamental operation in computer graphics. While
significant progress has been made, especially with recent deep generative
models, it remains a challenge to synthesize high-quality geometric shapes with
rich detail and complex structure, in a controllable manner. To tackle this, we
introduce DSM-Net, a deep neural network that learns a disentangled structured
mesh representation for 3D shapes, where two key aspects of shapes, geometry
and structure, are encoded in a synergistic manner to ensure plausibility of
the generated shapes, while also being disentangled as much as possible. This
supports a range of novel shape generation applications with intuitive control,
such as interpolation of structure (geometry) while keeping geometry
(structure) unchanged. To achieve this, we simultaneously learn structure and
geometry through variational autoencoders (VAEs) in a hierarchical manner for
both, with bijective mappings at each level. In this manner we effectively
encode geometry and structure in separate latent spaces, while ensuring their
compatibility: the structure is used to guide the geometry and vice versa. At
the leaf level, the part geometry is represented using a conditional part VAE,
to encode high-quality geometric details, guided by the structure context as
the condition. Our method not only supports controllable generation
applications, but also produces high-quality synthesized shapes, outperforming
state-of-the-art methods.
"
2221,Procedural Urban Forestry,"  The placement of vegetation plays a central role in the realism of virtual
scenes. We introduce procedural placement models (PPMs) for vegetation in urban
layouts. PPMs are environmentally sensitive to city geometry and allow
identifying plausible plant positions based on structural and functional zones
in an urban layout. PPMs can either be directly used by defining their
parameters or can be learned from satellite images and land register data.
Together with approaches for generating buildings and trees, this allows us to
populate urban landscapes with complex 3D vegetation. The effectiveness of our
framework is shown through examples of large-scale city scenes and close-ups of
individually grown tree models; we also validate it by a perceptual user study.
"
2222,Motion Similarity Modeling -- A State of the Art Report,"  The analysis of human motion opens up a wide range of possibilities, such as
realistic training simulations or authentic motions in robotics or animation.
One of the problems underlying motion analysis is the meaningful comparison of
actions based on similarity measures. Since the motion analysis is
application-dependent, it is essential to find the appropriate motion
similarity method for the particular use case. This state of the art report
provides an overview of human motion analysis and different similarity modeling
methods, while mainly focusing on approaches that work with 3D motion data. The
survey summarizes various similarity aspects and features of motion and
describes approaches to measuring the similarity between two actions.
"
2223,"SIDOD: A Synthetic Image Dataset for 3D Object Pose Recognition with
  Distractors","  We present a new, publicly-available image dataset generated by the NVIDIA
Deep Learning Data Synthesizer intended for use in object detection, pose
estimation, and tracking applications. This dataset contains 144k stereo image
pairs that synthetically combine 18 camera viewpoints of three photorealistic
virtual environments with up to 10 objects (chosen randomly from the 21 object
models of the YCB dataset [1]) and flying distractors. Object and camera pose,
scene lighting, and quantity of objects and distractors were randomized. Each
provided view includes RGB, depth, segmentation, and surface normal images, all
pixel level. We describe our approach for domain randomization and provide
insight into the decisions that produced the dataset.
"
2224,Interactive volume illumination of slice-based ray casting,"  Volume rendering always plays an important role in the field of medical
imaging and industrial design. In recent years, the realistic and interactive
volume rendering of the global illumination can improve the perception of shape
and depth of volumetric datasets. In this paper, a novel and flexible
performance method of slice-based ray casting is proposed to implement the
volume illumination effects, such as volume shadow and other scattering
effects. This benefits from the slice-based illumination attenuation buffers of
the whole geometry slices at the viewpoint of the light source and the
high-efficiency shadow or scattering coefficient calculation per sample in ray
casting. These tests show the method can obtain much better volume illumination
effects and more scalable performance in contrast to the local volume
illumination in ray casting volume rendering or other similar slice-based
global volume illumination.
"
2225,Self-Sampling for Neural Point Cloud Consolidation,"  In this paper, we introduce a deep learning technique for consolidating and
sharp feature generation of point clouds using only the input point cloud
itself. Rather than explicitly define a prior that describes typical shape
characteristics (i.e., piecewise-smoothness), or a heuristic policy for
generating novel sharp points, we opt to learn both using a neural network with
shared-weights. Instead of relying on a large collection of manually annotated
data, we use the self-supervision present within a single shape, i.e.,
self-prior, to train the network, and learn the underlying distribution of
sharp features specific to the given input point cloud. By learning to map a
low-curvature subset of the input point cloud to a disjoint high-curvature
subset, the network formalizes the shape-specific characteristics and infers
how to generate sharp points. During test time, the network is repeatedly fed a
random subset of points from the input and displaces them to generate an
arbitrarily large set of novel sharp feature points. The local shared weights
are optimized over the entire shape, learning non-local statistics and
exploiting the recurrence of local-scale geometries. We demonstrate the ability
to generate coherent sets of sharp feature points on a variety of shapes, while
eliminating outliers and noise.
"
2226,"MobileVisFixer: Tailoring Web Visualizations for Mobile Phones
  Leveraging an Explainable Reinforcement Learning Framework","  We contribute MobileVisFixer, a new method to make visualizations more
mobile-friendly. Although mobile devices have become the primary means of
accessing information on the web, many existing visualizations are not
optimized for small screens and can lead to a frustrating user experience.
Currently, practitioners and researchers have to engage in a tedious and
time-consuming process to ensure that their designs scale to screens of
different sizes, and existing toolkits and libraries provide little support in
diagnosing and repairing issues. To address this challenge, MobileVisFixer
automates a mobile-friendly visualization re-design process with a novel
reinforcement learning framework. To inform the design of MobileVisFixer, we
first collected and analyzed SVG-based visualizations on the web, and
identified five common mobile-friendly issues. MobileVisFixer addresses four of
these issues on single-view Cartesian visualizations with linear or discrete
scales by a Markov Decision Process model that is both generalizable across
various visualizations and fully explainable. MobileVisFixer deconstructs
charts into declarative formats, and uses a greedy heuristic based on Policy
Gradient methods to find solutions to this difficult, multi-criteria
optimization problem in reasonable time. In addition, MobileVisFixer can be
easily extended with the incorporation of optimization algorithms for data
visualizations. Quantitative evaluation on two real-world datasets demonstrates
the effectiveness and generalizability of our method.
"
2227,"Primary-Space Adaptive Control Variates using Piecewise-Polynomial
  Approximations","  We present an unbiased numerical integration algorithm that handles both
low-frequency regions and high frequency details of multidimensional integrals.
It combines quadrature and Monte Carlo integration, by using a quadrature-base
approximation as a control variate of the signal. We adaptively build the
control variate constructed as a piecewise polynomial, which can be
analytically integrated, and accurately reconstructs the low frequency regions
of the integrand. We then recover the high-frequency details missed by the
control variate by using Monte Carlo integration of the residual. Our work
leverages importance sampling techniques by working in primary space, allowing
the combination of multiple mappings; this enables multiple importance sampling
in quadrature-based integration. Our algorithm is generic, and can be applied
to any complex multidimensional integral. We demonstrate its effectiveness with
four applications with low dimensionality: transmittance estimation in
heterogeneous participating media, low-order scattering in homogeneous media,
direct illumination computation, and rendering of distributed effects. Finally,
we show how our technique is extensible to integrands of higher dimensionality,
by computing the control variate on Monte Carlo estimates of the
high-dimensional signal, and accounting for such additional dimensionality on
the residual as well. In all cases, we show accurate results and faster
convergence compared to previous approaches.
"
2228,Soft Multicopter Control using Neural Dynamics Identification,"  Dynamic control of a soft-body robot to deliver complex behaviors with
low-dimensional actuation inputs is challenging. In this paper, we present a
computational approach to automatically generate versatile, underactuated
control policies that drives soft-bodied machines with complicated structures
and nonlinear dynamics. Our target application is focused on the autonomous
control of a soft multicopter, featured by its elastic material components,
non-conventional shapes, and asymmetric rotor layouts, to precisely deliver
compliant deformation and agile locomotion. The central piece of our approach
lies in a lightweight neural surrogate model to identify and predict the
temporal evolution of a set of geometric variables characterizing an elastic
soft body. This physics-based learning model is further integrated into a
Linear Quadratic Regulator (LQR) control loop enhanced by a novel online
fixed-point relinearization scheme to accommodate the dynamic body balance,
allowing an aggressive reduction of the computational overhead caused by the
conventional full-scale sensing-simulation-control workflow. We demonstrate the
efficacy of our approach by generating controllers for a broad spectrum of
customized soft multicopter designs and testing them in a high-fidelity physics
simulation environment. The control algorithm enables the multicopters to
perform a variety of tasks, including hovering, trajectory tracking, cruising
and active deforming.
"
2229,Scalability of Network Visualisation from a Cognitive Load Perspective,"  Node-link diagrams are widely used to visualise networks. However, even the
best network layout algorithms ultimately result in 'hairball' visualisations
when the graph reaches a certain degree of complexity, requiring simplification
through aggregation or interaction (such as filtering) to remain usable. Until
now, there has been little data to indicate at what level of complexity
node-link diagrams become ineffective or how visual complexity affects
cognitive load. To this end, we conducted a controlled study to understand
workload limits for a task that requires a detailed understanding of the
network topology---finding the shortest path between two nodes. We tested
performance on graphs with 25 to 175 nodes with varying density. We collected
performance measures (accuracy and response time), subjective feedback, and
physiological measures (EEG, pupil dilation, and heart rate variability). To
the best of our knowledge, this is the first network visualisation study to
include physiological measures. Our results show that people have significant
difficulty finding the shortest path in high-density node-link diagrams with
more than 50 nodes and even low-density graphs with more than 100 nodes. From
our collected EEG data we observe functional differences in brain activity
between hard and easy tasks. We found that cognitive load increased up to a
certain level of difficulty after which it decreased, likely because
participants had given up. We also explored the effects of global network
layout features such as size or number of crossings, and features of the
shortest path such as length or straightness on task difficulty. We found that
global features generally had a greater impact than those of the shortest path.
"
2230,Learning to Generate Diverse Dance Motions with Transformer,"  With the ongoing pandemic, virtual concerts and live events using digitized
performances of musicians are getting traction on massive multiplayer online
worlds. However, well choreographed dance movements are extremely complex to
animate and would involve an expensive and tedious production process. In
addition to the use of complex motion capture systems, it typically requires a
collaborative effort between animators, dancers, and choreographers. We
introduce a complete system for dance motion synthesis, which can generate
complex and highly diverse dance sequences given an input music sequence. As
motion capture data is limited for the range of dance motions and styles, we
introduce a massive dance motion data set that is created from YouTube videos.
We also present a novel two-stream motion transformer generative model, which
can generate motion sequences with high flexibility. We also introduce new
evaluation metrics for the quality of synthesized dance motions, and
demonstrate that our system can outperform state-of-the-art methods. Our system
provides high-quality animations suitable for large crowds for virtual concerts
and can also be used as reference for professional animation pipelines. Most
importantly, we show that vast online videos can be effective in training dance
motion models.
"
2231,Deep Volumetric Ambient Occlusion,"  We present a novel deep learning based technique for volumetric ambient
occlusion in the context of direct volume rendering. Our proposed Deep
Volumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient
occlusion in volumetric data sets, while considering global information
provided through the transfer function. The proposed neural network only needs
to be executed upon change of this global information, and thus supports
real-time volume interaction. Accordingly, we demonstrate DVAOs ability to
predict volumetric ambient occlusion, such that it can be applied interactively
within direct volume rendering. To achieve the best possible results, we
propose and analyze a variety of transfer function representations and
injection strategies for deep neural networks. Based on the obtained results we
also give recommendations applicable in similar volume learning scenarios.
Lastly, we show that DVAO generalizes to a variety of modalities, despite being
trained on computed tomography data only.
"
2232,AutoSimulate: (Quickly) Learning Synthetic Data Generation,"  Simulation is increasingly being used for generating large labelled datasets
in many machine learning problems. Recent methods have focused on adjusting
simulator parameters with the goal of maximising accuracy on a validation task,
usually relying on REINFORCE-like gradient estimators. However these approaches
are very expensive as they treat the entire data generation, model training,
and validation pipeline as a black-box and require multiple costly objective
evaluations at each iteration. We propose an efficient alternative for optimal
synthetic data generation, based on a novel differentiable approximation of the
objective. This allows us to optimize the simulator, which may be
non-differentiable, requiring only one objective evaluation at each iteration
with a little overhead. We demonstrate on a state-of-the-art photorealistic
renderer that the proposed method finds the optimal data distribution faster
(up to $50\times$), with significantly reduced training data generation (up to
$30\times$) and better accuracy ($+8.7\%$) on real-world test datasets than
previous methods.
"
2233,"RealitySketch: Embedding Responsive Graphics and Visualizations in AR
  through Dynamic Sketching","  We present RealitySketch, an augmented reality interface for sketching
interactive graphics and visualizations. In recent years, an increasing number
of AR sketching tools enable users to draw and embed sketches in the real
world. However, with the current tools, sketched contents are inherently
static, floating in mid air without responding to the real world. This paper
introduces a new way to embed dynamic and responsive graphics in the real
world. In RealitySketch, the user draws graphical elements on a mobile AR
screen and binds them with physical objects in real-time and improvisational
ways, so that the sketched elements dynamically move with the corresponding
physical motion. The user can also quickly visualize and analyze real-world
phenomena through responsive graph plots or interactive visualizations. This
paper contributes to a set of interaction techniques that enable capturing,
parameterizing, and visualizing real-world motion without pre-defined programs
and configurations. Finally, we demonstrate our tool with several application
scenarios, including physics education, sports training, and in-situ tangible
interfaces.
"
2234,"DronePose: Photorealistic UAV-Assistant Dataset Synthesis for 3D Pose
  Estimation via a Smooth Silhouette Loss","  In this work we consider UAVs as cooperative agents supporting human users in
their operations. In this context, the 3D localisation of the UAV assistant is
an important task that can facilitate the exchange of spatial information
between the user and the UAV. To address this in a data-driven manner, we
design a data synthesis pipeline to create a realistic multimodal dataset that
includes both the exocentric user view, and the egocentric UAV view. We then
exploit the joint availability of photorealistic and synthesized inputs to
train a single-shot monocular pose estimation model. During training we
leverage differentiable rendering to supplement a state-of-the-art direct
regression objective with a novel smooth silhouette loss. Our results
demonstrate its qualitative and quantitative performance gains over traditional
silhouette objectives. Our data and code are available at
https://vcl3d.github.io/DronePose
"
2235,PhysCap: Physically Plausible Monocular 3D Motion Capture in Real Time,"  Marker-less 3D human motion capture from a single colour camera has seen
significant progress. However, it is a very challenging and severely ill-posed
problem. In consequence, even the most accurate state-of-the-art approaches
have significant limitations. Purely kinematic formulations on the basis of
individual joints or skeletons, and the frequent frame-wise reconstruction in
state-of-the-art methods greatly limit 3D accuracy and temporal stability
compared to multi-view or marker-based motion capture. Further, captured 3D
poses are often physically incorrect and biomechanically implausible, or
exhibit implausible environment interactions (floor penetration, foot skating,
unnatural body leaning and strong shifting in depth), which is problematic for
any use case in computer graphics. We, therefore, present PhysCap, the first
algorithm for physically plausible, real-time and marker-less human 3D motion
capture with a single colour camera at 25 fps. Our algorithm first captures 3D
human poses purely kinematically. To this end, a CNN infers 2D and 3D joint
positions, and subsequently, an inverse kinematics step finds space-time
coherent joint angles and global 3D pose. Next, these kinematic reconstructions
are used as constraints in a real-time physics-based pose optimiser that
accounts for environment constraints (e.g., collision handling and floor
placement), gravity, and biophysical plausibility of human postures. Our
approach employs a combination of ground reaction force and residual force for
plausible root control, and uses a trained neural network to detect foot
contact events in images. Our method captures physically plausible and
temporally stable global 3D human motion, without physically implausible
postures, floor penetrations or foot skating, from video in real time and in
general scenes. The video is available at
http://gvv.mpi-inf.mpg.de/projects/PhysCap
"
2236,A Special Conic Associated with the Reuleaux Negative Pedal Curve,"  The Negative Pedal Curve of the Reuleaux Triangle w.r. to a point $M$ on its
boundary consists of two elliptic arcs and a point $P_0$. Interestingly, the
conic passing through the four arc endpoints and by $P_0$ has a remarkable
property: one of its foci is $M$. We provide a synthetic proof based on
Poncelet's polar duality and inversive techniques. Additional intriguing
properties of Reuleaux negative pedal are proved using straightforward
techniques.
"
2237,"Object Properties Inferring from and Transfer for Human Interaction
  Motions","  Humans regularly interact with their surrounding objects. Such interactions
often result in strongly correlated motion between humans and the interacting
objects. We thus ask: ""Is it possible to infer object properties from skeletal
motion alone, even without seeing the interacting object itself?"" In this
paper, we present a fine-grained action recognition method that learns to infer
such latent object properties from human interaction motion alone. This
inference allows us to disentangle the motion from the object property and
transfer object properties to a given motion. We collected a large number of
videos and 3D skeletal motions of the performing actors using an inertial
motion capture device. We analyze similar actions and learn subtle differences
among them to reveal latent properties of the interacting objects. In
particular, we learn to identify the interacting object, by estimating its
weight, or its fragility or delicacy. Our results clearly demonstrate that the
interaction motions and interacting objects are highly correlated and indeed
relative object latent properties can be inferred from the 3D skeleton
sequences alone, leading to new synthesis possibilities for human interaction
motions. Dataset will be available at http://vcc.szu.edu.cn/research/2020/IT.
"
2238,Monocular Expressive Body Regression through Body-Driven Attention,"  To understand how people look, interact, or perform tasks, we need to quickly
and accurately capture their 3D body, face, and hands together from an RGB
image. Most existing methods focus only on parts of the body. A few recent
approaches reconstruct full expressive 3D humans from images using 3D body
models that include the face and hands. These methods are optimization-based
and thus slow, prone to local optima, and require 2D keypoints as input. We
address these limitations by introducing ExPose (EXpressive POse and Shape
rEgression), which directly regresses the body, face, and hands, in SMPL-X
format, from an RGB image. This is a hard problem due to the high
dimensionality of the body and the lack of expressive training data.
Additionally, hands and faces are much smaller than the body, occupying very
few image pixels. This makes hand and face estimation hard when body images are
downscaled for neural networks. We make three main contributions. First, we
account for the lack of training data by curating a dataset of SMPL-X fits on
in-the-wild images. Second, we observe that body estimation localizes the face
and hands reasonably well. We introduce body-driven attention for face and hand
regions in the original image to extract higher-resolution crops that are fed
to dedicated refinement modules. Third, these modules exploit part-specific
knowledge from existing face- and hand-only datasets. ExPose estimates
expressive 3D humans more accurately than existing optimization methods at a
small fraction of the computational cost. Our data, model and code are
available for research at https://expose.is.tue.mpg.de .
"
2239,"Meta-Sim2: Unsupervised Learning of Scene Structure for Synthetic Data
  Generation","  Procedural models are being widely used to synthesize scenes for graphics,
gaming, and to create (labeled) synthetic datasets for ML. In order to produce
realistic and diverse scenes, a number of parameters governing the procedural
models have to be carefully tuned by experts. These parameters control both the
structure of scenes being generated (e.g. how many cars in the scene), as well
as parameters which place objects in valid configurations. Meta-Sim aimed at
automatically tuning parameters given a target collection of real images in an
unsupervised way. In Meta-Sim2, we aim to learn the scene structure in addition
to parameters, which is a challenging problem due to its discrete nature.
Meta-Sim2 proceeds by learning to sequentially sample rule expansions from a
given probabilistic scene grammar. Due to the discrete nature of the problem,
we use Reinforcement Learning to train our model, and design a feature space
divergence between our synthesized and target images that is key to successful
training. Experiments on a real driving dataset show that, without any
supervision, we can successfully learn to generate data that captures discrete
structural statistics of objects, such as their frequency, in real images. We
also show that this leads to downstream improvement in the performance of an
object detector trained on our generated dataset as opposed to other baseline
simulation methods. Project page:
https://nv-tlabs.github.io/meta-sim-structure/.
"
2240,MetroSets: Visualizing Sets as Metro Maps,"  We propose MetroSets, a new, flexible online tool for visualizing set systems
using the metro map metaphor. We model a given set system as a hypergraph
$\mathcal{H} = (V, \mathcal{S})$, consisting of a set $V$ of vertices and a set
$\mathcal{S}$, which contains subsets of $V$ called hyperedges. Our system then
computes a metro map representation of $\mathcal{H}$, where each hyperedge $E$
in $\mathcal{S}$ corresponds to a metro line and each vertex corresponds to a
metro station. Vertices that appear in two or more hyperedges are drawn as
interchanges in the metro map, connecting the different sets. MetroSets is
based on a modular 4-step pipeline which constructs and optimizes a path-based
hypergraph support, which is then drawn and schematized using metro map layout
algorithms. We propose and implement multiple algorithms for each step of the
MetroSet pipeline and provide a functional prototype with \new{easy-to-use
preset configurations.} % many real-world datasets. Furthermore, \new{using
several real-world datasets}, we perform an extensive quantitative evaluation
of the impact of different pipeline stages on desirable properties of the
generated maps, such as octolinearity, monotonicity, and edge uniformity.
"
2241,"Visual Analysis of Large Multivariate Scattered Data using Clustering
  and Probabilistic Summaries","  Rapidly growing data sizes of scientific simulations pose significant
challenges for interactive visualization and analysis techniques. In this work,
we propose a compact probabilistic representation to interactively visualize
large scattered datasets. In contrast to previous approaches that represent
blocks of volumetric data using probability distributions, we model clusters of
arbitrarily structured multivariate data. In detail, we discuss how to
efficiently represent and store a high-dimensional distribution for each
cluster. We observe that it suffices to consider low-dimensional marginal
distributions for two or three data dimensions at a time to employ common
visual analysis techniques. Based on this observation, we represent
high-dimensional distributions by combinations of low-dimensional Gaussian
mixture models. We discuss the application of common interactive visual
analysis techniques to this representation. In particular, we investigate
several frequency-based views, such as density plots in 1D and 2D,
density-based parallel coordinates, and a time histogram. We visualize the
uncertainty introduced by the representation, discuss a level-of-detail
mechanism, and explicitly visualize outliers. Furthermore, we propose a spatial
visualization by splatting anisotropic 3D Gaussians for which we derive a
closed-form solution. Lastly, we describe the application of brushing and
linking to this clustered representation. Our evaluation on several large,
real-world datasets demonstrates the scaling of our approach.
"
2242,DeepLandscape: Adversarial Modeling of Landscape Video,"  We build a new model of landscape videos that can be trained on a mixture of
static landscape images as well as landscape animations. Our architecture
extends StyleGAN model by augmenting it with parts that allow to model dynamic
changes in a scene. Once trained, our model can be used to generate realistic
time-lapse landscape videos with moving objects and time-of-the-day changes.
Furthermore, by fitting the learned models to a static landscape image, the
latter can be reenacted in a realistic way. We propose simple but necessary
modifications to StyleGAN inversion procedure, which lead to in-domain latent
codes and allow to manipulate real images. Quantitative comparisons and user
studies suggest that our model produces more compelling animations of given
photographs than previously proposed methods. The results of our approach
including comparisons with prior art can be seen in supplementary materials and
on the project page https://saic-mdal.github.io/deep-landscape
"
2243,Toward Quantifying Ambiguities in Artistic Images,"  It has long been hypothesized that perceptual ambiguities play an important
role in aesthetic experience: a work with some ambiguity engages a viewer more
than one that does not. However, current frameworks for testing this theory are
limited by the availability of stimuli and data collection methods. This paper
presents an approach to measuring the perceptual ambiguity of a collection of
images. Crowdworkers are asked to describe image content, after different
viewing durations. Experiments are performed using images created with
Generative Adversarial Networks, using the Artbreeder website. We show that
text processing of viewer responses can provide a fine-grained way to measure
and describe image ambiguities.
"
2244,"Embodied Navigation in Immersive Abstract Data Visualization: Is
  Overview+Detail or Zooming Better for 3D Scatterplots?","  Abstract data has no natural scale and so interactive data visualizations
must provide techniques to allow the user to choose their viewpoint and scale.
Such techniques are well established in desktop visualization tools. The two
most common techniques are zoom+pan and overview+detail. However, how best to
enable the analyst to navigate and view abstract data at different levels of
scale in immersive environments has not previously been studied. We report the
findings of the first systematic study of immersive navigation techniques for
3D scatterplots. We tested four conditions that represent our best attempt to
adapt standard 2D navigation techniques to data visualization in an immersive
environment while still providing standard immersive navigation techniques
through physical movement and teleportation. We compared room-sized
visualization versus a zooming interface, each with and without an overview. We
find significant differences in participants' response times and accuracy for a
number of standard visual analysis tasks. Both zoom and overview provide
benefits over standard locomotion support alone (i.e., physical movement and
pointer teleportation). However, which variation is superior, depends on the
task. We obtain a more nuanced understanding of the results by analyzing them
in terms of a time-cost model for the different components of navigation:
way-finding, travel, number of travel steps, and context switching.
"
2245,"Geometry-guided Dense Perspective Network for Speech-Driven Facial
  Animation","  Realistic speech-driven 3D facial animation is a challenging problem due to
the complex relationship between speech and face. In this paper, we propose a
deep architecture, called Geometry-guided Dense Perspective Network (GDPnet),
to achieve speaker-independent realistic 3D facial animation. The encoder is
designed with dense connections to strengthen feature propagation and encourage
the re-use of audio features, and the decoder is integrated with an attention
mechanism to adaptively recalibrate point-wise feature responses by explicitly
modeling interdependencies between different neuron units. We also introduce a
non-linear face reconstruction representation as a guidance of latent space to
obtain more accurate deformation, which helps solve the geometry-related
deformation and is good for generalization across subjects. Huber and HSIC
(Hilbert-Schmidt Independence Criterion) constraints are adopted to promote the
robustness of our model and to better exploit the non-linear and high-order
correlations. Experimental results on the public dataset and real scanned
dataset validate the superiority of our proposed GDPnet compared with
state-of-the-art model.
"
2246,Fast Bi-layer Neural Synthesis of One-Shot Realistic Head Avatars,"  We propose a neural rendering-based system that creates head avatars from a
single photograph. Our approach models a person's appearance by decomposing it
into two layers. The first layer is a pose-dependent coarse image that is
synthesized by a small neural network. The second layer is defined by a
pose-independent texture image that contains high-frequency details. The
texture image is generated offline, warped and added to the coarse image to
ensure a high effective resolution of synthesized head views. We compare our
system to analogous state-of-the-art systems in terms of visual quality and
speed. The experiments show significant inference speedup over previous neural
head avatar models for a given visual quality. We also report on a real-time
smartphone-based implementation of our system.
"
2247,Monocular Reconstruction of Neural Face Reflectance Fields,"  The reflectance field of a face describes the reflectance properties
responsible for complex lighting effects including diffuse, specular,
inter-reflection and self shadowing. Most existing methods for estimating the
face reflectance from a monocular image assume faces to be diffuse with very
few approaches adding a specular component. This still leaves out important
perceptual aspects of reflectance as higher-order global illumination effects
and self-shadowing are not modeled. We present a new neural representation for
face reflectance where we can estimate all components of the reflectance
responsible for the final appearance from a single monocular image. Instead of
modeling each component of the reflectance separately using parametric models,
our neural representation allows us to generate a basis set of faces in a
geometric deformation-invariant space, parameterized by the input light
direction, viewpoint and face geometry. We learn to reconstruct this
reflectance field of a face just from a monocular image, which can be used to
render the face from any viewpoint in any light condition. Our method is
trained on a light-stage training dataset, which captures 300 people
illuminated with 150 light conditions from 8 viewpoints. We show that our
method outperforms existing monocular reflectance reconstruction methods, in
terms of photorealism due to better capturing of physical premitives, such as
sub-surface scattering, specularities, self-shadows and other higher-order
effects.
"
2248,The Hessian Penalty: A Weak Prior for Unsupervised Disentanglement,"  Existing disentanglement methods for deep generative models rely on
hand-picked priors and complex encoder-based architectures. In this paper, we
propose the Hessian Penalty, a simple regularization term that encourages the
Hessian of a generative model with respect to its input to be diagonal. We
introduce a model-agnostic, unbiased stochastic approximation of this term
based on Hutchinson's estimator to compute it efficiently during training. Our
method can be applied to a wide range of deep generators with just a few lines
of code. We show that training with the Hessian Penalty often causes
axis-aligned disentanglement to emerge in latent space when applied to ProGAN
on several datasets. Additionally, we use our regularization term to identify
interpretable directions in BigGAN's latent space in an unsupervised fashion.
Finally, we provide empirical evidence that the Hessian Penalty encourages
substantial shrinkage when applied to over-parameterized latent spaces.
"
2249,A Critical Analysis of Patch Similarity Based Image Denoising Algorithms,"  Image denoising is a classical signal processing problem that has received
significant interest within the image processing community during the past two
decades. Most of the algorithms for image denoising has focused on the paradigm
of non-local similarity, where image blocks in the neighborhood that are
similar, are collected to build a basis for reconstruction. Through rigorous
experimentation, this paper reviews multiple aspects of image denoising
algorithm development based on non-local similarity. Firstly, the concept of
non-local similarity as a foundational quality that exists in natural images
has not received adequate attention. Secondly, the image denoising algorithms
that are developed are a combination of multiple building blocks, making
comparison among them a tedious task. Finally, most of the work surrounding
image denoising presents performance results based on Peak-Signal-to-Noise
Ratio (PSNR) between a denoised image and a reference image (which is perturbed
with Additive White Gaussian Noise). This paper starts with a statistical
analysis on non-local similarity and its effectiveness under various noise
levels, followed by a theoretical comparison of different state-of-the-art
image denoising algorithms. Finally, we argue for a methodological overhaul to
incorporate no-reference image quality measures and unprocessed images (raw)
during performance evaluation of image denoising algorithms.
"
2250,Differentiating a Tensor Language,"  How does one compile derivatives of tensor programs, such that the resulting
code is purely functional (hence easier to optimize and parallelize) and
provably efficient relative to the original program? We show that naively
differentiating tensor code---as done in popular systems like Tensorflow and
PyTorch---can cause asymptotic slowdowns in pathological cases, violating the
Cheap Gradients Principle. However, all existing automatic differentiation
methods that guarantee this principle (for variable size data) do so by relying
on += mutation through aliases/pointers---which complicates downstream
optimization. We provide the first purely functional, provably efficient,
adjoint/reverse-mode derivatives of array/tensor code by explicitly accounting
for sparsity. We do this by focusing on the indicator function from Iverson's
APL. We also introduce a new ""Tensor SSA"" normal form and a new derivation of
reverse-mode automatic differentiation based on the universal property of
inner-products.
"
2251,Test Scene Design for Physically Based Rendering,"  Physically based rendering is a discipline in computer graphics which aims at
reproducing certain light and material appearances that occur in the real
world. Complex scenes can be difficult to compute for rendering algorithms.
This paper introduces a new comprehensive test database of scenes that treat
different light setups in conjunction with diverse materials and discusses its
design principles. A lot of research is focused on the development of new
algorithms that can deal with difficult light conditions and materials
efficiently. This database delivers a comprehensive foundation for evaluating
existing and newly developed rendering techniques. A final evaluation compares
different results of different rendering algorithms for all scenes.
"
2252,GraphFederator: Federated Visual Analysis for Multi-party Graphs,"  This paper presents GraphFederator, a novel approach to construct joint
representations of multi-party graphs and supports privacy-preserving visual
analysis of graphs. Inspired by the concept of federated learning, we
reformulate the analysis of multi-party graphs into a decentralization process.
The new federation framework consists of a shared module that is responsible
for joint modeling and analysis, and a set of local modules that run on
respective graph data. Specifically, we propose a federated graph
representation model (FGRM) that is learned from encrypted characteristics of
multi-party graphs in local modules. We also design multiple visualization
views for joint visualization, exploration, and analysis of multi-party graphs.
Experimental results with two datasets demonstrate the effectiveness of our
approach.
"
2253,One Shot 3D Photography,"  3D photography is a new medium that allows viewers to more fully experience a
captured moment. In this work, we refer to a 3D photo as one that displays
parallax induced by moving the viewpoint (as opposed to a stereo pair with a
fixed viewpoint). 3D photos are static in time, like traditional photos, but
are displayed with interactive parallax on mobile or desktop screens, as well
as on Virtual Reality devices, where viewing it also includes stereo. We
present an end-to-end system for creating and viewing 3D photos, and the
algorithmic and design choices therein. Our 3D photos are captured in a single
shot and processed directly on a mobile device. The method starts by estimating
depth from the 2D input image using a new monocular depth estimation network
that is optimized for mobile devices. It performs competitively to the
state-of-the-art, but has lower latency and peak memory consumption and uses an
order of magnitude fewer parameters. The resulting depth is lifted to a layered
depth image, and new geometry is synthesized in parallax regions. We synthesize
color texture and structures in the parallax regions as well, using an
inpainting network, also optimized for mobile devices, on the LDI directly.
Finally, we convert the result into a mesh-based representation that can be
efficiently transmitted and rendered even on low-end devices and over poor
network connections. Altogether, the processing takes just a few seconds on a
mobile device, and the result can be instantly viewed and shared. We perform
extensive quantitative evaluation to validate our system and compare its new
components against the current state-of-the-art.
"
2254,ClipFlip : Multi-view Clipart Design,"  We present an assistive system for clipart design by providing visual
scaffolds from the unseen viewpoints. Inspired by the artists' creation
process, our system constructs the visual scaffold by first synthesizing the
reference 3D shape of the input clipart and rendering it from the desired
viewpoint. The critical challenge of constructing this visual scaffold is to
generate a reference 3Dshape that matches the user's expectation in terms of
object sizing and positioning while preserving the geometric style of the input
clipart. To address this challenge, we propose a user-assisted curve extrusion
method to obtain the reference 3D shape.We render the synthesized reference 3D
shape with consistent style into the visual scaffold. By following the
generated visual scaffold, the users can efficiently design clipart with their
desired viewpoints. The user study conducted by an intuitive user interface and
our generated visual scaffold suggests that the users are able to design
clipart from different viewpoints while preserving the original geometric style
without losing its original shape.
"
2255,"ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in
  Virtual Screening","  In the modern drug discovery process, medicinal chemists deal with the
complexity of analysis of large ensembles of candidate molecules. Computational
tools, such as dimensionality reduction (DR) and classification, are commonly
used to efficiently process the multidimensional space of features. These
underlying calculations often hinder interpretability of results and prevent
experts from assessing the impact of individual molecular features on the
resulting representations. To provide a solution for scrutinizing such complex
data, we introduce ChemVA, an interactive application for the visual
exploration of large molecular ensembles and their features. Our tool consists
of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table
view, and a newly proposed Difference view designed for the comparison of DR
projections. These views display DR projections combined with biological
activity, selected molecular features, and confidence scores for each of these
projections. This conjunction of views allows the user to drill down through
the dataset and to efficiently select candidate compounds. Our approach was
evaluated on two case studies of finding structurally similar ligands with
similar binding affinity to a target protein, as well as on an external
qualitative evaluation. The results suggest that our system allows effective
visual inspection and comparison of different high-dimensional molecular
representations. Furthermore, ChemVA assists in the identification of candidate
compounds while providing information on the certainty behind different
molecular representations.
"
2256,Discrete Curvature and Torsion from Cross-Ratios,"  Motivated by a M\""obius invariant subdivision scheme for polygons, we study a
curvature notion for discrete curves where the cross-ratio plays an important
role in all our key definitions. Using a particular M\""obius invariant
point-insertion-rule, comparable to the classical four-point-scheme, we
construct circles along discrete curves. Asymptotic analysis shows that these
circles defined on a sampled curve converge to the smooth curvature circles as
the sampling density increases. We express our discrete torsion for space
curves, which is not a M\""obius invariant notion, using the cross-ratio and
show its asymptotic behavior in analogy to the curvature.
"
2257,"Relationship-aware Multivariate Sampling Strategy for Scientific
  Simulation Data","  With the increasing computational power of current supercomputers, the size
of data produced by scientific simulations is rapidly growing. To reduce the
storage footprint and facilitate scalable post-hoc analyses of such scientific
data sets, various data reduction/summarization methods have been proposed over
the years. Different flavors of sampling algorithms exist to sample the
high-resolution scientific data, while preserving important data properties
required for subsequent analyses. However, most of these sampling algorithms
are designed for univariate data and cater to post-hoc analyses of single
variables. In this work, we propose a multivariate sampling strategy which
preserves the original variable relationships and enables different
multivariate analyses directly on the sampled data. Our proposed strategy
utilizes principal component analysis to capture the variance of multivariate
data and can be built on top of any existing state-of-the-art sampling
algorithms for single variables. In addition, we also propose variants of
different data partitioning schemes (regular and irregular) to efficiently
model the local multivariate relationships. Using two real-world multivariate
data sets, we demonstrate the efficacy of our proposed multivariate sampling
strategy with respect to its data reduction capabilities as well as the ease of
performing efficient post-hoc multivariate analyses.
"
2258,Direct Volume Rendering with Nonparametric Models of Uncertainty,"  We present a nonparametric statistical framework for the quantification,
analysis, and propagation of data uncertainty in direct volume rendering (DVR).
The state-of-the-art statistical DVR framework allows for preserving the
transfer function (TF) of the ground truth function when visualizing uncertain
data; however, the existing framework is restricted to parametric models of
uncertainty. In this paper, we address the limitations of the existing DVR
framework by extending the DVR framework for nonparametric distributions. We
exploit the quantile interpolation technique to derive probability
distributions representing uncertainty in viewing-ray sample intensities in
closed form, which allows for accurate and efficient computation. We evaluate
our proposed nonparametric statistical models through qualitative and
quantitative comparisons with the mean-field and parametric statistical models,
such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we
present an extension of the state-of-the-art rendering parametric framework to
2D TFs for improved DVR classifications. We show the applicability of our
uncertainty quantification framework to ensemble, downsampled, and bivariate
versions of scalar field datasets.
"
2259,A Square Equal-area Map Projection,"  A novel square equal-area map projection is proposed. The projection combines
closed-form forward and inverse solutions with relatively low angular
distortion and minimal cusps, a combination of properties not manifested by any
previously published square equal-area projection. Thus, the new projection has
lower angular distortion than any previously published square equal-area
projection with a closed-form solution. Utilizing a quincuncial arrangement,
the new projection places the north pole at the center of the square and
divides the south pole between its four corners; the projection can be
seamlessly tiled. The existence of closed-form solutions makes the projection
suitable for real-time visualization applications, both in cartography and in
other areas, such as for the display of panoramic images.
"
2260,Localized Topological Simplification of Scalar Data,"  This paper describes a localized algorithm for the topological simplification
of scalar data, an essential pre-processing step of topological data analysis
(TDA). Given a scalar field f and a selection of extrema to preserve, the
proposed localized topological simplification (LTS) derives a function g that
is close to f and only exhibits the selected set of extrema. Specifically, sub-
and superlevel set components associated with undesired extrema are first
locally flattened and then correctly embedded into the global scalar field,
such that these regions are guaranteed -- from a combinatorial perspective --
to no longer contain any undesired extrema. In contrast to previous global
approaches, LTS only and independently processes regions of the domain that
actually need to be simplified, which already results in a noticeable speedup.
Moreover, due to the localized nature of the algorithm, LTS can utilize
shared-memory parallelism to simplify regions simultaneously with a high
parallel efficiency (70%). Hence, LTS significantly improves interactivity for
the exploration of simplification parameters and their effect on subsequent
topological analysis. For such exploration tasks, LTS brings the overall
execution time of a plethora of TDA pipelines from minutes down to seconds,
with an average observed speedup over state-of-the-art techniques of up to x36.
Furthermore, in the special case where preserved extrema are selected based on
topological persistence, an adapted version of LTS partially computes the
persistence diagram and simultaneously simplifies features below a predefined
persistence threshold. The effectiveness of LTS, its parallel efficiency, and
its resulting benefits for TDA are demonstrated on several simulated and
acquired datasets from different application domains, including physics,
chemistry, and biomedical imaging.
"
2261,GIF: Generative Interpretable Faces,"  Photo-realistic visualization and animation of expressive human faces have
been a long standing challenge. On one end of the spectrum, 3D face modeling
methods provide parametric control but tend to generate unrealistic images,
while on the other end, generative 2D models like GANs (Generative Adversarial
Networks) output photo-realistic face images, but lack explicit control. Recent
methods gain partial control, either by attempting to disentangle different
factors in an unsupervised manner, or by adding control post hoc to a
pre-trained model. Trained GANs without pre-defined control, however, may
entangle factors that are hard to undo later. To guarantee some disentanglement
that provides us with desired kinds of control, we train our generative model
conditioned on pre-defined control parameters. Specifically, we condition
StyleGAN2 on FLAME, a generative 3D face model. However, we found out that a
naive conditioning on FLAME parameters yields rather unsatisfactory results.
Instead we render out geometry and photo-metric details of the FLAME mesh and
use these for conditioning instead. This gives us a generative 2D face model
named GIF (Generative Interpretable Faces) that shares FLAME's parametric
control. Given FLAME parameters for shape, pose, and expressions, parameters
for appearance and lighting, and an additional style vector, GIF outputs
photo-realistic face images. To evaluate how well GIF follows its conditioning
and the impact of different design choices, we perform a perceptual study. The
code and trained model are publicly available for research purposes at
https://github.com/ParthaEth/GIF.
"
2262,Efficient 2D Simulation on Moving 3D Surfaces,"  We present a method to simulate fluid flow on evolving surfaces, e.g., an oil
film on a water surface. Given an animated surface (e.g., extracted from a
particle-based fluid simulation) in three-dimensional space, we add a second
simulation on this base animation. In general, we solve a partial differential
equation (PDE) on a level set surface obtained from the animated input surface.
The properties of the input surface are transferred to a sparse volume data
structure that is then used for the simulation. We introduce one-way coupling
strategies from input properties to our simulation and we add conservation of
mass and momentum to existing methods that solve a PDE in a narrow-band using
the Closest Point Method. In this way, we efficiently compute high-resolution
2D simulations on coarse input surfaces. Our approach helps visual effects
creators easily integrate a workflow to simulate material flow on evolving
surfaces into their existing production pipeline.
"
2263,Inspection of histological 3D reconstructions in virtual reality,"  3D reconstruction is a challenging current topic in medical research. We
perform 3D reconstructions from serial sections stained by immunohistological
methods. This paper presents an immersive visualisation solution to quality
control (QC), inspect, and analyse such reconstructions. QC is essential to
establish correct digital processing methodologies. Visual analytics, such as
annotation placement, mesh painting, and classification utility, facilitates
medical research insights. We propose a visualisation in virtual reality (VR)
for these purposes. In this manner, we advance the microanatomical research of
human bone marrow and spleen. Both 3D reconstructions and original data are
available in VR. Data inspection is streamlined by subtle implementation
details and general immersion in VR.
"
2264,Neural Crossbreed: Neural Based Image Metamorphosis,"  We propose Neural Crossbreed, a feed-forward neural network that can learn a
semantic change of input images in a latent space to create the morphing
effect. Because the network learns a semantic change, a sequence of meaningful
intermediate images can be generated without requiring the user to specify
explicit correspondences. In addition, the semantic change learning makes it
possible to perform the morphing between the images that contain objects with
significantly different poses or camera views. Furthermore, just as in
conventional morphing techniques, our morphing network can handle shape and
appearance transitions separately by disentangling the content and the style
transfer for rich usability. We prepare a training dataset for morphing using a
pre-trained BigGAN, which generates an intermediate image by interpolating two
latent vectors at an intended morphing value. This is the first attempt to
address image morphing using a pre-trained generative model in order to learn
semantic transformation. The experiments show that Neural Crossbreed produces
high quality morphed images, overcoming various limitations associated with
conventional approaches. In addition, Neural Crossbreed can be further extended
for diverse applications such as multi-image morphing, appearance transfer, and
video frame interpolation.
"
2265,A Study of Opacity Ranges for Transparent Overlays in 3D Landscapes,"  {When visualizing data in a realistically rendered 3D virtual environment, it
is often important to represent not only the 3D scene but also overlaid
information about additional, abstract data. These overlays must be usefully
visible, i.e. be readable enough to convey the information they represent, but
remain unobtrusive to avoid cluttering the view. We take a step toward
establishing guidelines for designing such overlays by studying the
relationship between three different patterns (filled, striped and dotted
patterns), two pattern densities, the presence or not of a solid outline, two
types of background (blank and with trees), and the opacity of the overlay. For
each combination of factors, participants set the faintest and the strongest
acceptable opacity values. Results from this first study suggest that i) ranges
of acceptable opacities are around 20-70%, that ii) ranges can be extended by
5% by using an outline, and that iii) ranges shift based on features like
pattern and density.
"
2266,Mononizing Binocular Videos,"  This paper presents the idea ofmono-nizingbinocular videos and a frame-work
to effectively realize it. Mono-nize means we purposely convert abinocular
video into a regular monocular video with the stereo informationimplicitly
encoded in a visual but nearly-imperceptible form. Hence, wecan impartially
distribute and show the mononized video as an ordinarymonocular video. Unlike
ordinary monocular videos, we can restore from itthe original binocular video
and show it on a stereoscopic display. To start,we formulate an
encoding-and-decoding framework with the pyramidal de-formable fusion module to
exploit long-range correspondences between theleft and right views, a
quantization layer to suppress the restoring artifacts,and the compression
noise simulation module to resist the compressionnoise introduced by modern
video codecs. Our framework is self-supervised,as we articulate our objective
function with loss terms defined on the input:a monocular term for creating the
mononized video, an invertibility termfor restoring the original video, and a
temporal term for frame-to-framecoherence. Further, we conducted extensive
experiments to evaluate ourgenerated mononized videos and restored binocular
videos for diverse typesof images and 3D movies. Quantitative results on both
standard metrics anduser perception studies show the effectiveness of our
method.
"
2267,"DeformSyncNet: Deformation Transfer via Synchronized Shape Deformation
  Spaces","  Shape deformation is an important component in any geometry processing
toolbox. The goal is to enable intuitive deformations of single or multiple
shapes or to transfer example deformations to new shapes while preserving the
plausibility of the deformed shape(s). Existing approaches assume access to
point-level or part-level correspondence or establish them in a preprocessing
phase, thus limiting the scope and generality of such approaches. We propose
DeformSyncNet, a new approach that allows consistent and synchronized shape
deformations without requiring explicit correspondence information.
Technically, we achieve this by encoding deformations into a class-specific
idealized latent space while decoding them into an individual, model-specific
linear deformation action space, operating directly in 3D. The underlying
encoding and decoding are performed by specialized (jointly trained) neural
networks. By design, the inductive bias of our networks results in a
deformation space with several desirable properties, such as path invariance
across different deformation pathways, which are then also approximately
preserved in real space. We qualitatively and quantitatively evaluate our
framework against multiple alternative approaches and demonstrate improved
performance.
"
2268,TAP-Net: Transport-and-Pack using Reinforcement Learning,"  We introduce the transport-and-pack(TAP) problem, a frequently encountered
instance of real-world packing, and develop a neural optimization solution
based on reinforcement learning. Given an initial spatial configuration of
boxes, we seek an efficient method to iteratively transport and pack the boxes
compactly into a target container. Due to obstruction and accessibility
constraints, our problem has to add a new search dimension, i.e., finding an
optimal transport sequence, to the already immense search space for packing
alone. Using a learning-based approach, a trained network can learn and encode
solution patterns to guide the solution of new problem instances instead of
executing an expensive online search. In our work, we represent the transport
constraints using a precedence graph and train a neural network, coined
TAP-Net, using reinforcement learning to reward efficient and stable packing.
The network is built on an encoder-decoder architecture, where the encoder
employs convolution layers to encode the box geometry and precedence graph and
the decoder is a recurrent neural network (RNN) which inputs the current
encoder output, as well as the current box packing state of the target
container, and outputs the next box to pack, as well as its orientation. We
train our network on randomly generated initial box configurations, without
supervision, via policy gradients to learn optimal TAP policies to maximize
packing efficiency and stability. We demonstrate the performance of TAP-Net on
a variety of examples, evaluating the network through ablation studies and
comparisons to baselines and alternative network designs. We also show that our
network generalizes well to larger problem instances, when trained on
small-sized inputs.
"
2269,"TopoMap: A 0-dimensional Homology Preserving Projection of
  High-Dimensional Data","  Multidimensional Projection is a fundamental tool for high-dimensional data
analytics and visualization. With very few exceptions, projection techniques
are designed to map data from a high-dimensional space to a visual space so as
to preserve some dissimilarity (similarity) measure, such as the Euclidean
distance for example. In fact, although adopting distinct mathematical
formulations designed to favor different aspects of the data, most
multidimensional projection methods strive to preserve dissimilarity measures
that encapsulate geometric properties such as distances or the proximity
relation between data objects. However, geometric relations are not the only
interesting property to be preserved in a projection. For instance, the
analysis of particular structures such as clusters and outliers could be more
reliably performed if the mapping process gives some guarantee as to
topological invariants such as connected components and loops. This paper
introduces TopoMap, a novel projection technique which provides topological
guarantees during the mapping process. In particular, the proposed method
performs the mapping from a high-dimensional space to a visual space, while
preserving the 0-dimensional persistence diagram of the Rips filtration of the
high-dimensional data, ensuring that the filtrations generate the same
connected components when applied to the original as well as projected data.
The presented case studies show that the topological guarantee provided by
TopoMap not only brings confidence to the visual analytic process but also can
be used to assist in the assessment of other projection methods.
"
2270,"Symmetry and scaling limits for matching of implicit surfaces based on
  thin shell energies","  In a recent paper by Iglesias, Rumpf and Scherzer (Found. Comput. Math.
18(4), 2018) a variational model for deformations matching a pair of shapes
given as level set functions was proposed. Its main feature is the presence of
anisotropic energies active only in a narrow band around the hypersurfaces that
resemble the behavior of elastic shells. In this work we consider some
extensions and further analysis of that model. First, we present a symmetric
energy functional such that given two particular shapes, it assigns the same
energy to any given deformation as to its inverse when the roles of the shapes
are interchanged, and introduce the adequate parameter scaling to recover a
surface problem when the width of the narrow band vanishes. Then, we obtain
existence of minimizing deformations for the symmetric energy in classes of
bi-Sobolev homeomorphisms for small enough widths, and prove a
$\Gamma$-convergence result for the corresponding non-symmetric energies as the
width tends to zero. Finally, numerical results on realistic shape matching
applications demonstrating the effect of the symmetric energy are presented.
"
2271,"Improving the Usability of Virtual Reality Neuron Tracing with
  Topological Elements","  Researchers in the field of connectomics are working to reconstruct a map of
neural connections in the brain in order to understand at a fundamental level
how the brain processes information. Constructing this wiring diagram is done
by tracing neurons through high-resolution image stacks acquired with
fluorescence microscopy imaging techniques. While a large number of automatic
tracing algorithms have been proposed, these frequently rely on local features
in the data and fail on noisy data or ambiguous cases, requiring time-consuming
manual correction. As a result, manual and semi-automatic tracing methods
remain the state-of-the-art for creating accurate neuron reconstructions. We
propose a new semi-automatic method that uses topological features to guide
users in tracing neurons and integrate this method within a virtual reality
(VR) framework previously used for manual tracing. Our approach augments both
visualization and interaction with topological elements, allowing rapid
understanding and tracing of complex morphologies. In our pilot study,
neuroscientists demonstrated a strong preference for using our tool over prior
approaches, reported less fatigue during tracing, and commended the ability to
better understand possible paths and alternatives. Quantitative evaluation of
the traces reveals that users' tracing speed increased, while retaining similar
accuracy compared to a fully manual approach.
"
2272,Staged Animation Strategies for Online Dynamic Networks,"  Dynamic networks -- networks that change over time -- can be categorized into
two types: offline dynamic networks, where all states of the network are known,
and online dynamic networks, where only the past states of the network are
known. Research on staging animated transitions in dynamic networks has focused
more on offline data, where rendering strategies can take into account past and
future states of the network. Rendering online dynamic networks is a more
challenging problem since it requires a balance between timeliness for
monitoring tasks -- so that the animations do not lag too far behind the events
-- and clarity for comprehension tasks -- to minimize simultaneous changes that
may be difficult to follow. To illustrate the challenges placed by these
requirements, we explore three strategies to stage animations for online
dynamic networks: time-based, event-based, and a new hybrid approach that we
introduce by combining the advantages of the first two. We illustrate the
advantages and disadvantages of each strategy in representing low- and
high-throughput data and conduct a user study involving monitoring and
comprehension of dynamic networks. We also conduct a follow-up, a think-aloud
study combining monitoring and comprehension with experts in dynamic network
visualization. Our findings show that animation staging strategies that
emphasize comprehension do better for participant response times and accuracy.
However, the notion of ``comprehension'' is not always clear when it comes to
complex changes in highly dynamic networks, requiring some iteration in staging
that the hybrid approach affords. Based on our results, we make recommendations
for balancing event-based and time-based parameters for our hybrid approach.
"
2273,"Speech Gesture Generation from the Trimodal Context of Text, Audio, and
  Speaker Identity","  For human-like agents, including virtual avatars and social robots, making
proper gestures while speaking is crucial in human--agent interaction.
Co-speech gestures enhance interaction experiences and make the agents look
alive. However, it is difficult to generate human-like gestures due to the lack
of understanding of how people gesture. Data-driven approaches attempt to learn
gesticulation skills from human demonstrations, but the ambiguous and
individual nature of gestures hinders learning. In this paper, we present an
automatic gesture generation model that uses the multimodal context of speech
text, audio, and speaker identity to reliably generate gestures. By
incorporating a multimodal context and an adversarial training scheme, the
proposed model outputs gestures that are human-like and that match with speech
content and rhythm. We also introduce a new quantitative evaluation metric for
gesture generation models. Experiments with the introduced metric and
subjective human evaluation showed that the proposed gesture generation model
is better than existing end-to-end generation models. We further confirm that
our model is able to work with synthesized audio in a scenario where contexts
are constrained, and show that different gesture styles can be generated for
the same speech by specifying different speaker identities in the style
embedding space that is learned from videos of various speakers. All the code
and data is available at
https://github.com/ai4r/Gesture-Generation-from-Trimodal-Context.
"
2274,Homomorphic-Encrypted Volume Rendering,"  Computationally demanding tasks are typically calculated in dedicated data
centers, and real-time visualizations also follow this trend. Some rendering
tasks, however, require the highest level of confidentiality so that no other
party, besides the owner, can read or see the sensitive data. Here we present a
direct volume rendering approach that performs volume rendering directly on
encrypted volume data by using the homomorphic Paillier encryption algorithm.
This approach ensures that the volume data and rendered image are
uninterpretable to the rendering server. Our volume rendering pipeline
introduces novel approaches for encrypted-data compositing, interpolation, and
opacity modulation, as well as simple transfer function design, where each of
these routines maintains the highest level of privacy. We present performance
and memory overhead analysis that is associated with our privacy-preserving
scheme. Our approach is open and secure by design, as opposed to secure through
obscurity. Owners of the data only have to keep their secure key confidential
to guarantee the privacy of their volume data and the rendered images. Our work
is, to our knowledge, the first privacy-preserving remote volume-rendering
approach that does not require that any server involved be trustworthy; even in
cases when the server is compromised, no sensitive data will be leaked to a
foreign party.
"
2275,SketchPatch: Sketch Stylization via Seamless Patch-level Synthesis,"  The paradigm of image-to-image translation is leveraged for the benefit of
sketch stylization via transfer of geometric textural details. Lacking the
necessary volumes of data for standard training of translation systems, we
advocate for operation at the patch level, where a handful of stylized sketches
provide ample mining potential for patches featuring basic geometric
primitives. Operating at the patch level necessitates special consideration of
full sketch translation, as individual translation of patches with no regard to
neighbors is likely to produce visible seams and artifacts at patch borders.
Aligned pairs of styled and plain primitives are combined to form input hybrids
containing styled elements around the border and plain elements within, and
given as input to a seamless translation (ST) generator, whose output patches
are expected to reconstruct the fully styled patch. An adversarial addition
promotes generalization and robustness to diverse geometries at inference time,
forming a simple and effective system for arbitrary sketch stylization, as
demonstrated upon a variety of styles and sketches.
"
2276,"Interactive Visual Study of Multiple Attributes Learning Model of X-Ray
  Scattering Images","  Existing interactive visualization tools for deep learning are mostly applied
to the training, debugging, and refinement of neural network models working on
natural images. However, visual analytics tools are lacking for the specific
application of x-ray image classification with multiple structural attributes.
In this paper, we present an interactive system for domain scientists to
visually study the multiple attributes learning models applied to x-ray
scattering images. It allows domain scientists to interactively explore this
important type of scientific images in embedded spaces that are defined on the
model prediction output, the actual labels, and the discovered feature space of
neural networks. Users are allowed to flexibly select instance images, their
clusters, and compare them regarding the specified visual representation of
attributes. The exploration is guided by the manifestation of model performance
related to mutual relationships among attributes, which often affect the
learning accuracy and effectiveness. The system thus supports domain scientists
to improve the training dataset and model, find questionable attributes labels,
and identify outlier images or spurious data clusters. Case studies and
scientists feedback demonstrate its functionalities and usefulness.
"
2277,Chordal Decomposition for Spectral Coarsening,"  We introduce a novel solver to significantly reduce the size of a geometric
operator while preserving its spectral properties at the lowest frequencies. We
use chordal decomposition to formulate a convex optimization problem which
allows the user to control the operator sparsity pattern. This allows for a
trade-off between the spectral accuracy of the operator and the cost of its
application. We efficiently minimize the energy with a change of variables and
achieve state-of-the-art results on spectral coarsening. Our solver further
enables novel applications including volume-to-surface approximation and
detaching the operator from the mesh, i.e., one can produce a mesh tailormade
for visualization and optimize an operator separately for computation.
"
2278,Complementary Dynamics,"  We present a novel approach to enrich arbitrary rig animations with
elastodynamic secondary effects. Unlike previous methods which pit rig
displacements and physical forces as adversaries against each other, we
advocate that physics should complement artists intentions. We propose
optimizing for elastodynamic displacements in the subspace orthogonal to
displacements that can be created by the rig. This ensures that the additional
dynamic motions do not undo the rig animation. The complementary space is high
dimensional, algebraically constructed without manual oversight, and capable of
rich high-frequency dynamics. Unlike prior tracking methods, we do not require
extra painted weights, segmentation into fixed and free regions or tracking
clusters. Our method is agnostic to the physical model and plugs into
non-linear FEM simulations, geometric as-rigid-as-possible energies, or
mass-spring models. Our method does not require a particular type of rig and
adds secondary effects to skeletal animations, cage-based deformations, wire
deformers, motion capture data, and rigid-body simulations.
"
2279,Trimmed Spline Surfaces with Accurate Boundary Control,"  We introduce trimmed NURBS surfaces with accurate boundary control, briefly
called ABC-surfaces, as a solution to the notorious problem of constructing
watertight or smooth ($G^1$ and $G^2)$ multi-patch surfaces within the function
range of standard CAD/CAM systems and the associated file exchange formats. Our
construction is based on the appropriate blend of a base surface, which traces
out the intended global shape, and a series of reparametrized ribbons, which
dominate the shape near the boundary.
"
2280,A curvature and density-based generative representation of shapes,"  This paper introduces a generative model for 3D surfaces based on a
representation of shapes with mean curvature and metric, which are invariant
under rigid transformation. Hence, compared with existing 3D machine learning
frameworks, our model substantially reduces the influence of translation and
rotation. In addition, the local structure of shapes will be more precisely
captured, since the curvature is explicitly encoded in our model. Specifically,
every surface is first conformally mapped to a canonical domain, such as a unit
disk or a unit sphere. Then, it is represented by two functions: the mean
curvature half-density and the vertex density, over this canonical domain.
Assuming that input shapes follow a certain distribution in a latent space, we
use the variational autoencoder to learn the latent space representation. After
the learning, we can generate variations of shapes by randomly sampling the
distribution in the latent space. Surfaces with triangular meshes can be
reconstructed from the generated data by applying isotropic remeshing and spin
transformation, which is given by Dirac equation. We demonstrate the
effectiveness of our model on datasets of man-made and biological shapes and
compare the results with other methods.
"
2281,Area-Invariant Pedal-Like Curves Derived from the Ellipse,"  We study six pedal-like curves associated with the ellipse which are
area-invariant for pedal points lying on one of two shapes: (i) a circle
concentric with the ellipse, or (ii) the ellipse boundary itself. Case (i) is a
corollary to properties of the Curvature Centroid (Kr\""ummungs-Schwerpunkt) of
a curve, proved by Steiner in 1825. For case (ii) we prove area invariance
algebraically. Explicit expressions for all invariant areas are also provided.
"
2282,"Length-optimal tool path planning for freeform surfaces with preferred
  feed directions","  This paper presents a new method to generate tool paths for machining
freeform surfaces represented either as parametric surfaces or as triangular
meshes. This method allows for the optimal tradeoff between the preferred feed
direction field and the constant scallop height, and yields a minimized overall
path length. The optimality is achieved by formulating tool path planning as a
Poisson problem that minimizes a simple, quadratic energy. This Poisson
formulation considers all tool paths at once, without resorting to any
heuristic sampling or initial tool path choosing as in existing methods, and is
thus a globally optimal solution. Finding the optimal tool paths amounts to
solving a well-conditioned sparse linear system, which is computationally
convenient and efficient. Tool paths are represented with an implicit scheme
that can completely avoid the challenging topological issues of path
singularities and self-intersections seen in previous methods. The presented
method has been validated with a series of examples and comparisons.
"
2283,"The Mixture Graph-A Data Structure for Compressing, Rendering, and
  Querying Segmentation Histograms","  In this paper, we present a novel data structure, called the Mixture Graph.
This data structure allows us to compress, render, and query segmentation
histograms. Such histograms arise when building a mipmap of a volume containing
segmentation IDs. Each voxel in the histogram mipmap contains a convex
combination (mixture) of segmentation IDs. Each mixture represents the
distribution of IDs in the respective voxel's children. Our method factorizes
these mixtures into a series of linear interpolations between exactly two
segmentation IDs. The result is represented as a directed acyclic graph (DAG)
whose nodes are topologically ordered. Pruning replicate nodes in the tree
followed by compression allows us to store the resulting data structure
efficiently. During rendering, transfer functions are propagated from sources
(leafs) through the DAG to allow for efficient, pre-filtered rendering at
interactive frame rates. Assembly of histogram contributions across the
footprint of a given volume allows us to efficiently query partial histograms,
achieving up to 178$\times$ speed-up over na$\mathrm{\""{i}}$ve parallelized
range queries. Additionally, we apply the Mixture Graph to compute correctly
pre-filtered volume lighting and to interactively explore segments based on
shape, geometry, and orientation using multi-dimensional transfer functions.
"
2284,Palettailor: Discriminable Colorization for Categorical Data,"  We present an integrated approach for creating and assigning color palettes
to different visualizations such as multi-class scatterplots, line, and bar
charts. While other methods separate the creation of colors from their
assignment, our approach takes data characteristics into account to produce
color palettes, which are then assigned in a way that fosters better visual
discrimination of classes. To do so, we use a customized optimization based on
simulated annealing to maximize the combination of three carefully designed
color scoring functions: point distinctness, name difference, and color
discrimination. We compare our approach to state-ofthe-art palettes with a
controlled user study for scatterplots and line charts, furthermore we
performed a case study. Our results show that Palettailor, as a fully-automated
approach, generates color palettes with a higher discrimination quality than
existing approaches. The efficiency of our optimization allows us also to
incorporate user modifications into the color selection process.
"
2285,Nonlinear Spectral Geometry Processing via the TV Transform,"  We introduce a novel computational framework for digital geometry processing,
based upon the derivation of a nonlinear operator associated to the total
variation functional. Such operator admits a generalized notion of spectral
decomposition, yielding a sparse multiscale representation akin to
Laplacian-based methods, while at the same time avoiding undesirable
over-smoothing effects typical of such techniques. Our approach entails
accurate, detail-preserving decomposition and manipulation of 3D shape geometry
while taking an especially intuitive form: non-local semantic details are well
separated into different bands, which can then be filtered and re-synthesized
with a straightforward linear step. Our computational framework is flexible,
can be applied to a variety of signals, and is easily adapted to different
geometry representations, including triangle meshes and point clouds. We
showcase our method throughout multiple applications in graphics, ranging from
surface and signal denoising to detail transfer and cubic stylization.
"
2286,Ray Tracing Structured AMR Data Using ExaBricks,"  Structured Adaptive Mesh Refinement (Structured AMR) enables simulations to
adapt the domain resolution to save computation and storage, and has become one
of the dominant data representations used by scientific simulations; however,
efficiently rendering such data remains a challenge. We present an efficient
approach for volume- and iso-surface ray tracing of Structured AMR data on
GPU-equipped workstations, using a combination of two different data
structures. Together, these data structures allow a ray tracing based renderer
to quickly determine which segments along the ray need to be integrated and at
what frequency, while also providing quick access to all data values required
for a smooth sample reconstruction kernel. Our method makes use of the RTX ray
tracing hardware for surface rendering, ray marching, space skipping, and
adaptive sampling; and allows for interactive changes to the transfer function
and implicit iso-surfacing thresholds. We demonstrate that our method achieves
high performance with little memory overhead, enabling interactive high quality
rendering of complex AMR data sets on individual GPU workstations.
"
2287,"Interactive Visualization of Terascale Data in the Browser: Fact or
  Fiction?","  Information visualization applications have become ubiquitous, in no small
part thanks to the ease of wide distribution and deployment to users enabled by
the web browser. Scientific visualization applications, relying on native code
libraries and parallel processing, have been less suited to such widespread
distribution, as browsers do not provide the required libraries or compute
capabilities. In this paper, we revisit this gap in visualization technologies
and explore how new web technologies, WebAssembly and WebGPU, can be used to
deploy powerful visualization solutions for large-scale scientific data in the
browser. In particular, we evaluate the programming effort required to bring
scientific visualization applications to the browser through these technologies
and assess their competitiveness against classic native solutions. As a main
example, we present a new GPU-driven isosurface extraction method for
block-compressed data sets, that is suitable for interactive isosurface
computation on large volumes in resource-constrained environments, such as the
browser. We conclude that web browsers are on the verge of becoming a
competitive platform for even the most demanding scientific visualization
tasks, such as interactive visualization of isosurfaces from a 1TB DNS
simulation. We call on researchers and developers to consider investing in a
community software stack to ease use of these upcoming browser features to
bring accessible scientific visualization to the browser.
"
2288,Implicit Multidimensional Projection of Local Subspaces,"  We propose a visualization method to understand the effect of
multidimensional projection on local subspaces, using implicit function
differentiation. Here, we understand the local subspace as the multidimensional
local neighborhood of data points. Existing methods focus on the projection of
multidimensional data points, and the neighborhood information is ignored. Our
method is able to analyze the shape and directional information of the local
subspace to gain more insights into the global structure of the data through
the perception of local structures. Local subspaces are fitted by
multidimensional ellipses that are spanned by basis vectors. An accurate and
efficient vector transformation method is proposed based on analytical
differentiation of multidimensional projections formulated as implicit
functions. The results are visualized as glyphs and analyzed using a full set
of specifically-designed interactions supported in our efficient web-based
visualization tool. The usefulness of our method is demonstrated using various
multi- and high-dimensional benchmark datasets. Our implicit differentiation
vector transformation is evaluated through numerical comparisons; the overall
method is evaluated through exploration examples and use cases.
"
2289,Improved Modeling of 3D Shapes with Multi-view Depth Maps,"  We present a simple yet effective general-purpose framework for modeling 3D
shapes by leveraging recent advances in 2D image generation using CNNs. Using
just a single depth image of the object, we can output a dense multi-view depth
map representation of 3D objects. Our simple encoder-decoder framework,
comprised of a novel identity encoder and class-conditional viewpoint
generator, generates 3D consistent depth maps. Our experimental results
demonstrate the two-fold advantage of our approach. First, we can directly
borrow architectures that work well in the 2D image domain to 3D. Second, we
can effectively generate high-resolution 3D shapes with low computational
memory. Our quantitative evaluations show that our method is superior to
existing depth map methods for reconstructing and synthesizing 3D objects and
is competitive with other representations, such as point clouds, voxel grids,
and implicit functions.
"
2290,"Responsive Matrix Cells: A Focus+Context Approach for Exploring and
  Editing Multivariate Graphs","  Matrix visualizations are a useful tool to provide a general overview of a
graph's structure. For multivariate graphs, a remaining challenge is to cope
with the attributes that are associated with nodes and edges. Addressing this
challenge, we propose responsive matrix cells as a focus+context approach for
embedding additional interactive views into a matrix. Responsive matrix cells
are local zoomable regions of interest that provide auxiliary data exploration
and editing facilities for multivariate graphs. They behave responsively by
adapting their visual contents to the cell location, the available display
space, and the user task. Responsive matrix cells enable users to reveal
details about the graph, compare node and edge attributes, and edit data values
directly in a matrix without resorting to external views or tools. We report
the general design considerations for responsive matrix cells covering the
visual and interactive means necessary to support a seamless data exploration
and editing. Responsive matrix cells have been implemented in a web-based
prototype based on which we demonstrate the utility of our approach. We
describe a walk-through for the use case of analyzing a graph of soccer players
and report on insights from a preliminary user feedback session.
"
2291,A Fast Parametric Ellipse Algorithm,"  This paper describes a 2-D graphics algorithm that uses shifts and adds to
precisely plot a series of points on an ellipse of any shape and orientation.
The algorithm can also plot an elliptic arc that starts and ends at arbitrary
angles. The ellipse algorithm described here is largely based on earlier papers
by Van Aken and Simar [1,2], which extend Marvin Minsky's well-known circle
algorithm [3,4,5] to ellipses, and show how to cancel out the sources of error
in Minsky's original algorithm. A new flatness test is presented for
automatically controlling the spacing between points plotted on an ellipse or
elliptic arc. Most of the calculations performed by the ellipse algorithm and
flatness test use fixed-point addition and shift operations, and thus are
well-suited to run on less-powerful processors. C++ source code listings are
included.
  Keywords: parametric ellipse algorithm, rotated ellipse, Minsky circle
algorithm, flatness, elliptic arc, conjugate diameters, affine invariance
"
2292,Computational Design of Cold Bent Glass Fa\c{c}ades,"  Cold bent glass is a promising and cost-efficient method for realizing doubly
curved glass fa\c{c}ades. They are produced by attaching planar glass sheets to
curved frames and require keeping the occurring stress within safe limits.
However, it is very challenging to navigate the design space of cold bent glass
panels due to the fragility of the material, which impedes the form-finding for
practically feasible and aesthetically pleasing cold bent glass fa\c{c}ades. We
propose an interactive, data-driven approach for designing cold bent glass
fa\c{c}ades that can be seamlessly integrated into a typical architectural
design pipeline. Our method allows non-expert users to interactively edit a
parametric surface while providing real-time feedback on the deformed shape and
maximum stress of cold bent glass panels. Designs are automatically refined to
minimize several fairness criteria while maximal stresses are kept within glass
limits. We achieve interactive frame rates by using a differentiable Mixture
Density Network trained from more than a million simulations. Given a curved
boundary, our regression model is capable of handling multistable
configurations and accurately predicting the equilibrium shape of the panel and
its corresponding maximal stress. We show predictions are highly accurate and
validate our results with a physical realization of a cold bent glass surface.
"
2293,GPU Parallel Computation of Morse-Smale Complexes,"  The Morse-Smale complex is a well studied topological structure that
represents the gradient flow behavior of a scalar function. It supports
multi-scale topological analysis and visualization of large scientific data.
Its computation poses significant algorithmic challenges when considering large
scale data and increased feature complexity. Several parallel algorithms have
been proposed towards the fast computation of the 3D Morse-Smale complex. The
non-trivial structure of the saddle-saddle connections are not amenable to
parallel computation. This paper describes a fine grained parallel method for
computing the Morse-Smale complex that is implemented on a GPU. The
saddle-saddle reachability is first determined via a transformation into a
sequence of vector operations followed by the path traversal, which is achieved
via a sequence of matrix operations. Computational experiments show that the
method achieves up to 7x speedup over current shared memory implementations.
"
2294,Improving Engagement of Animated Visualization with Visual Foreshadowing,"  Animated visualization is becoming increasingly popular as a compelling way
to illustrate changes in time series data. However, maintaining the viewer's
focus throughout the entire animation is difficult because of its
time-consuming nature. Viewers are likely to become bored and distracted during
the ever-changing animated visualization. Informed by the role of foreshadowing
that builds the expectation in film and literature, we introduce visual
foreshadowing to improve the engagement of animated visualizations. In
specific, we propose designs of visual foreshadowing that engage the audience
while watching the animation. To demonstrate our approach, we built a
proof-of-concept animated visualization authoring tool that incorporates visual
foreshadowing techniques with various styles. Our user study indicates the
effectiveness of our foreshadowing techniques on improving engagement for
animated visualization.
"
2295,MU-GAN: Facial Attribute Editing based on Multi-attention Mechanism,"  Facial attribute editing has mainly two objectives: 1) translating image from
a source domain to a target one, and 2) only changing the facial regions
related to a target attribute and preserving the attribute-excluding details.
In this work, we propose a Multi-attention U-Net-based Generative Adversarial
Network (MU-GAN). First, we replace a classic convolutional encoder-decoder
with a symmetric U-Net-like structure in a generator, and then apply an
additive attention mechanism to build attention-based U-Net connections for
adaptively transferring encoder representations to complement a decoder with
attribute-excluding detail and enhance attribute editing ability. Second, a
self-attention mechanism is incorporated into convolutional layers for modeling
long-range and multi-level dependencies across image regions. experimental
results indicate that our method is capable of balancing attribute editing
ability and details preservation ability, and can decouple the correlation
among attributes. It outperforms the state-of-the-art methods in terms of
attribute manipulation accuracy and image quality.
"
2296,"Deterministic Linear Time Constrained Triangulation using Simplified
  Earcut","  Triangulation algorithms that conform to a set of non-intersecting input
segments typically proceed in an incremental fashion, by inserting points
first, and then segments. Inserting a segment amounts to delete all the
triangles it intersects, define two polygons that fill the so generated hole
and have the segment as shared basis, and then re-triangulate each polygon
separately. In this paper we prove that the polygons generated evacuating the
triangles that intersect a constrained segment are such that all their convex
vertices but two can be used to form triangles in an earcut fashion, without
the need to check whether other polygon points are located within each ear. The
fact that any simple polygon contains at least three convex vertices guarantees
the existence of a valid ear to cut, ensuring convergence. Not only this
translates to an optimal deterministic linear time triangulation algorithm, but
such algorithm is also trivial to implement. In this paper we formally prove
the correctness of our approach, also validating it in practical applications
and comparing it with prior art.
"
2297,Uncertain Transport in Unsteady Flows,"  We study uncertainty in the dynamics of time-dependent flows by identifying
barriers and enhancers to stochastic transport. This topological segmentation
is closely related to the theory of Lagrangian coherent structures and is based
on a recently introduced quantity, the diffusion barrier strength (DBS). The
DBS is defined similar to the finite-time Lyapunov exponent (FTLE), but
incorporates diffusion during flow integration. Height ridges of the DBS
indicate stochastic transport barriers and enhancers, i.e. material surfaces
that are minimally or maximally diffusive. To apply these concepts to
real-world data, we represent uncertainty in a flow by a stochastic
differential equation that consists of a deterministic and a stochastic
component modeled by a Gaussian. With this formulation we identify barriers and
enhancers to stochastic transport, without performing expensive Monte Carlo
simulation and with a computational complexity comparable to FTLE. In addition,
we propose a complementary visualization to convey the absolute scale of
uncertainties in the Lagrangian frame of reference. This enables us to study
uncertainty in real-world datasets, for example due to small deviations, data
reduction, or estimated from multiple ensemble runs.
"
2298,Fully Convolutional Graph Neural Networks for Parametric Virtual Try-On,"  We present a learning-based approach for virtual try-on applications based on
a fully convolutional graph neural network. In contrast to existing data-driven
models, which are trained for a specific garment or mesh topology, our fully
convolutional model can cope with a large family of garments, represented as
parametric predefined 2D panels with arbitrary mesh topology, including long
dresses, shirts, and tight tops. Under the hood, our novel geometric deep
learning approach learns to drape 3D garments by decoupling the three different
sources of deformations that condition the fit of clothing: garment type,
target body shape, and material. Specifically, we first learn a regressor that
predicts the 3D drape of the input parametric garment when worn by a mean body
shape. Then, after a mesh topology optimization step where we generate a
sufficient level of detail for the input garment type, we further deform the
mesh to reproduce deformations caused by the target body shape. Finally, we
predict fine-scale details such as wrinkles that depend mostly on the garment
material. We qualitatively and quantitatively demonstrate that our fully
convolutional approach outperforms existing methods in terms of generalization
capabilities and memory requirements, and therefore it opens the door to more
general learning-based models for virtual try-on applications.
"
2299,"Mode Surfaces of Symmetric Tensor Fields: Topological Analysis and
  Seamless Extraction","  Mode surfaces are the generalization of degenerate curves and neutral
surfaces, which constitute 3D symmetric tensor field topology. Efficient
analysis and visualization of mode surfaces can provide additional insight into
not only degenerate curves and neutral surfaces, but also how these features
transition into each other. Moreover, the geometry and topology of mode
surfaces can help domain scientists better understand the tensor fields in
their applications. Existing mode surface extraction methods can miss features
in the surfaces. Moreover, the mode surfaces extracted from neighboring cells
have gaps, which make their subsequent analysis difficult. In this paper, we
provide novel analysis on the topological structures of mode surfaces,
including a common parameterization of all mode surfaces of a tensor field
using 2D asymmetric tensors. This allows us to not only better understand the
structures in mode surfaces and their interactions with degenerate curves and
neutral surfaces, but also develop an efficient algorithm to seamlessly extract
mode surfaces, including neutral surfaces. The seamless mode surfaces enable
efficient analysis of their geometric structures, such as the principal
curvature directions. We apply our analysis and visualization to a number of
solid mechanics data sets.
"
2300,A Framework for Evaluating Dashboards in Healthcare,"  In the era of ""information overload"", effective information provision is
essential for enabling rapid response and critical decision making. In making
sense of diverse information sources, data dashboards have become an
indispensable tool, providing fast, effective, adaptable, and personalized
access to information for professionals and the general public alike. However,
these objectives place a heavy requirement on dashboards as information
systems, resulting in poor usability and ineffective design. Understanding
these shortfalls is a challenge given the absence of a consistent and
comprehensive approach to dashboard evaluation. In this paper we systematically
review literature on dashboard implementation in the healthcare domain, a field
where dashboards have been employed widely, and in which there is widespread
interest for improving the current state of the art, and subsequently analyse
approaches taken towards evaluation. We draw upon consolidated dashboard
literature and our own observations to introduce a general definition of
dashboards which is more relevant to current trends, together with a dashboard
task-based classification, which underpin our subsequent analysis. From a total
of 81 papers we derive seven evaluation scenarios - task performance, behaviour
change, interaction workflow, perceived engagement, potential utility,
algorithm performance and system implementation. These scenarios distinguish
different evaluation purposes which we illustrate through measurements, example
studies, and common challenges in evaluation study design. We provide a
breakdown of each evaluation scenario, and highlight some of the subtle and
less well posed questions. We conclude by outlining a number of active
discussion points and a set of dashboard evaluation best practices for the
academic, clinical and software development communities alike.
"
2301,Sketch2CAD: Sequential CAD Modeling by Sketching in Context,"  We present a sketch-based CAD modeling system, where users create objects
incrementally by sketching the desired shape edits, which our system
automatically translates to CAD operations. Our approach is motivated by the
close similarities between the steps industrial designers follow to draw 3D
shapes, and the operations CAD modeling systems offer to create similar shapes.
To overcome the strong ambiguity with parsing 2D sketches, we observe that in a
sketching sequence, each step makes sense and can be interpreted in the
\emph{context} of what has been drawn before. In our system, this context
corresponds to a partial CAD model, inferred in the previous steps, which we
feed along with the input sketch to a deep neural network in charge of
interpreting how the model should be modified by that sketch. Our deep network
architecture then recognizes the intended CAD operation and segments the sketch
accordingly, such that a subsequent optimization estimates the parameters of
the operation that best fit the segmented sketch strokes. Since there exists no
datasets of paired sketching and CAD modeling sequences, we train our system by
generating synthetic sequences of CAD operations that we render as line
drawings. We present a proof of concept realization of our algorithm supporting
four frequently used CAD operations. Using our system, participants are able to
quickly model a large and diverse set of objects, demonstrating Sketch2CAD to
be an alternate way of interacting with current CAD modeling systems.
"
2302,Attribute-conditioned Layout GAN for Automatic Graphic Design,"  Modeling layout is an important first step for graphic design. Recently,
methods for generating graphic layouts have progressed, particularly with
Generative Adversarial Networks (GANs). However, the problem of specifying the
locations and sizes of design elements usually involves constraints with
respect to element attributes, such as area, aspect ratio and reading-order.
Automating attribute conditional graphic layouts remains a complex and unsolved
problem. In this paper, we introduce Attribute-conditioned Layout GAN to
incorporate the attributes of design elements for graphic layout generation by
forcing both the generator and the discriminator to meet attribute conditions.
Due to the complexity of graphic designs, we further propose an element dropout
method to make the discriminator look at partial lists of elements and learn
their local patterns. In addition, we introduce various loss designs following
different design principles for layout optimization. We demonstrate that the
proposed method can synthesize graphic layouts conditioned on different element
attributes. It can also adjust well-designed layouts to new sizes while
retaining elements' original reading-orders. The effectiveness of our method is
validated through a user study.
"
2303,"VC-Net: Deep Volume-Composition Networks for Segmentation and
  Visualization of Highly Sparse and Noisy Image Data","  The motivation of our work is to present a new visualization-guided computing
paradigm to combine direct 3D volume processing and volume rendered clues for
effective 3D exploration such as extracting and visualizing microstructures
in-vivo. However, it is still challenging to extract and visualize high
fidelity 3D vessel structure due to its high sparseness, noisiness, and complex
topology variations. In this paper, we present an end-to-end deep learning
method, VC-Net, for robust extraction of 3D microvasculature through embedding
the image composition, generated by maximum intensity projection (MIP), into 3D
volume image learning to enhance the performance. The core novelty is to
automatically leverage the volume visualization technique (MIP) to enhance the
3D data exploration at deep learning level. The MIP embedding features can
enhance the local vessel signal and are adaptive to the geometric variability
and scalability of vessels, which is crucial in microvascular tracking. A
multi-stream convolutional neural network is proposed to learn the 3D volume
and 2D MIP features respectively and then explore their inter-dependencies in a
joint volume-composition embedding space by unprojecting the MIP features into
3D volume embedding space. The proposed framework can better capture small /
micro vessels and improve vessel connectivity. To our knowledge, this is the
first deep learning framework to construct a joint convolutional embedding
space, where the computed vessel probabilities from volume rendering based 2D
projection and 3D volume can be explored and integrated synergistically.
Experimental results are compared with the traditional 3D vessel segmentation
methods and the deep learning state-of-the-art on public and real patient
(micro-)cerebrovascular image datasets. Our method demonstrates the potential
in a powerful MR arteriogram and venogram diagnosis of vascular diseases.
"
2304,"Deep intrinsic decomposition trained on surreal scenes yet with
  realistic light effects","  Estimation of intrinsic images still remains a challenging task due to
weaknesses of ground-truth datasets, which either are too small or present
non-realistic issues. On the other hand, end-to-end deep learning architectures
start to achieve interesting results that we believe could be improved if
important physical hints were not ignored. In this work, we present a twofold
framework: (a) a flexible generation of images overcoming some classical
dataset problems such as larger size jointly with coherent lighting appearance;
and (b) a flexible architecture tying physical properties through intrinsic
losses. Our proposal is versatile, presents low computation time, and achieves
state-of-the-art results.
"
2305,Data-Driven Space-Filling Curves,"  We propose a data-driven space-filling curve method for 2D and 3D
visualization. Our flexible curve traverses the data elements in the spatial
domain in a way that the resulting linearization better preserves features in
space compared to existing methods. We achieve such data coherency by
calculating a Hamiltonian path that approximately minimizes an objective
function that describes the similarity of data values and location coherency in
a neighborhood. Our extended variant even supports multiscale data via
quadtrees and octrees. Our method is useful in many areas of visualization,
including multivariate or comparative visualization, ensemble visualization of
2D and 3D data on regular grids, or multiscale visual analysis of particle
simulations. The effectiveness of our method is evaluated with numerical
comparisons to existing techniques and through examples of ensemble and
multivariate datasets.
"
2306,Interactive Focus+Context Rendering for Hexahedral Mesh Inspection,"  The visual inspection of a hexahedral mesh with respect to element quality is
difficult due to clutter and occlusions that are produced when rendering all
element faces or their edges simultaneously. Current approaches overcome this
problem by using focus on specific elements that are then rendered opaque, and
carving away all elements occluding their view. In this work, we make use of
advanced GPU shader functionality to generate a focus+context rendering that
highlights the elements in a selected region and simultaneously conveys the
global mesh structure in the surrounding. To achieve this, we propose a gradual
transition from edge-based focus rendering to volumetric context rendering, by
combining fragment shader-based edge and face rendering with per-pixel fragment
lists. A fragment shader smoothly transitions between wireframe and face-based
rendering, including focus-dependent rendering style and depth-dependent edge
thickness and halos, and per-pixel fragment lists are used to blend fragments
in correct visibility order. To maintain the global mesh structure in the
context regions, we propose a new method to construct a sheet-based
level-of-detail hierarchy and smoothly blend it with volumetric information.
The user guides the exploration process by moving a lens-like hotspot. Since
all operations are performed on the GPU, interactive frame rates are achieved
even for large meshes.
"
2307,"Smoothed Particle Hydrodynamics Techniques for the Physics Based
  Simulation of Fluids and Solids","  Graphics research on Smoothed Particle Hydrodynamics (SPH) has produced
fantastic visual results that are unique across the board of research
communities concerned with SPH simulations. Generally, the SPH formalism serves
as a spatial discretization technique, commonly used for the numerical
simulation of continuum mechanical problems such as the simulation of fluids,
highly viscous materials, and deformable solids. Recent advances in the field
have made it possible to efficiently simulate massive scenes with highly
complex boundary geometries on a single PC [Com16b, Com16a]. Moreover, novel
techniques allow to robustly handle interactions among various materials
[Com18,Com17]. As of today, graphics-inspired pressure solvers, neighborhood
search algorithms, boundary formulations, and other contributions often serve
as core components in commercial software for animation purposes [Nex17] as
well as in computer-aided engineering software [FIF16].
  This tutorial covers various aspects of SPH simulations. Governing equations
for mechanical phenomena and their SPH discretizations are discussed. Concepts
and implementations of core components such as neighborhood search algorithms,
pressure solvers, and boundary handling techniques are presented.
Implementation hints for the realization of SPH solvers for fluids, elastic
solids, and rigid bodies are given. The tutorial combines the introduction of
theoretical concepts with the presentation of actual implementations.
"
2308,Old Photo Restoration via Deep Latent Space Translation,"  We propose to restore old photos that suffer from severe degradation through
a deep learning approach. Unlike conventional restoration tasks that can be
solved through supervised learning, the degradation in real photos is complex
and the domain gap between synthetic images and real old photos makes the
network fail to generalize. Therefore, we propose a novel triplet domain
translation network by leveraging real photos along with massive synthetic
image pairs. Specifically, we train two variational autoencoders (VAEs) to
respectively transform old photos and clean photos into two latent spaces. And
the translation between these two latent spaces is learned with synthetic
paired data. This translation generalizes well to real photos because the
domain gap is closed in the compact latent space. Besides, to address multiple
degradations mixed in one old photo, we design a global branch with apartial
nonlocal block targeting to the structured defects, such as scratches and dust
spots, and a local branch targeting to the unstructured defects, such as noises
and blurriness. Two branches are fused in the latent space, leading to improved
capability to restore old photos from multiple defects. Furthermore, we apply
another face refinement network to recover fine details of faces in the old
photos, thus ultimately generating photos with enhanced perceptual quality.
With comprehensive experiments, the proposed pipeline demonstrates superior
performance over state-of-the-art methods as well as existing commercial tools
in terms of visual quality for old photos restoration.
"
2309,BOP Challenge 2020 on 6D Object Localization,"  This paper presents the evaluation methodology, datasets, and results of the
BOP Challenge 2020, the third in a series of public competitions organized with
the goal to capture the status quo in the field of 6D object pose estimation
from an RGB-D image. In 2020, to reduce the domain gap between synthetic
training and real test RGB images, the participants were provided 350K
photorealistic training images generated by BlenderProc4BOP, a new open-source
and light-weight physically-based renderer (PBR) and procedural data generator.
Methods based on deep neural networks have finally caught up with methods based
on point pair features, which were dominating previous editions of the
challenge. Although the top-performing methods rely on RGB-D image channels,
strong results were achieved when only RGB channels were used at both training
and test time - out of the 26 evaluated methods, the third method was trained
on RGB channels of PBR and real images, while the fifth on RGB channels of PBR
images only. Strong data augmentation was identified as a key component of the
top-performing CosyPose method, and the photorealism of PBR images was
demonstrated effective despite the augmentation. The online evaluation system
stays open and is available on the project website: bop.felk.cvut.cz.
"
2310,"Related by Similarity II: Poncelet 3-Periodics in the Homothetic Pair
  and the Brocard Porism","  Previously we showed the family of 3-periodics in the elliptic billiard
(confocal pair) is the image under a variable similarity transform of poristic
triangles (those with non-concentric, fixed incircle and circumcircle). Both
families conserve the ratio of inradius to circumradius and therefore also the
sum of cosines. This is consisten with the fact that a similarity preserves
angles. Here we study two new Poncelet 3-periodic families also tied to each
other via a variable similarity: (i) a first one interscribed in a pair of
concentric, homothetic ellipses, and (ii) a second non-concentric one known as
the Brocard porism: fixed circumcircle and Brocard inellipse. The Brocard
points of this family are stationary at the foci of the inellipse. A key common
invariant is the Brocard angle, and therefore the sum of cotangents. This
raises an interesting question: given a non-concentric Poncelet family (limited
or not to the outer conic being a circle), can a similar doppelg\""anger always
be found interscribed in a concentric, axis-aligned ellipse and/or conic pair?
"
2311,Layered Neural Rendering for Retiming People in Video,"  We present a method for retiming people in an ordinary, natural
video---manipulating and editing the time in which different motions of
individuals in the video occur. We can temporally align different motions,
change the speed of certain actions (speeding up/slowing down, or entirely
""freezing"" people), or ""erase"" selected people from the video altogether. We
achieve these effects computationally via a dedicated learning-based layered
video representation, where each frame in the video is decomposed into separate
RGBA layers, representing the appearance of different people in the video. A
key property of our model is that it not only disentangles the direct motions
of each person in the input video, but also correlates each person
automatically with the scene changes they generate---e.g., shadows,
reflections, and motion of loose clothing. The layers can be individually
retimed and recombined into a new video, allowing us to achieve realistic,
high-quality renderings of retiming effects for real-world videos depicting
complex actions and involving multiple individuals, including dancing,
trampoline jumping, or group running.
"
2312,"ShapeAssembly: Learning to Generate Programs for 3D Shape Structure
  Synthesis","  Manually authoring 3D shapes is difficult and time consuming; generative
models of 3D shapes offer compelling alternatives. Procedural representations
are one such possibility: they offer high-quality and editable results but are
difficult to author and often produce outputs with limited diversity. On the
other extreme are deep generative models: given enough data, they can learn to
generate any class of shape but their outputs have artifacts and the
representation is not editable. In this paper, we take a step towards achieving
the best of both worlds for novel 3D shape synthesis. We propose ShapeAssembly,
a domain-specific ""assembly-language"" for 3D shape structures. ShapeAssembly
programs construct shapes by declaring cuboid part proxies and attaching them
to one another, in a hierarchical and symmetrical fashion. Its functions are
parameterized with free variables, so that one program structure is able to
capture a family of related shapes. We show how to extract ShapeAssembly
programs from existing shape structures in the PartNet dataset. Then we train a
deep generative model, a hierarchical sequence VAE, that learns to write novel
ShapeAssembly programs. The program captures the subset of variability that is
interpretable and editable. The deep model captures correlations across shape
collections that are hard to express procedurally. We evaluate our approach by
comparing shapes output by our generated programs to those from other recent
shape structure synthesis models. We find that our generated shapes are more
plausible and physically-valid than those of other methods. Additionally, we
assess the latent spaces of these models, and find that ours is better
structured and produces smoother interpolations. As an application, we use our
generative model and differentiable program interpreter to infer and fit shape
programs to unstructured geometry, such as point clouds.
"
2313,"Efficient conformal parameterization of multiply-connected surfaces
  using quasi-conformal theory","  Conformal mapping, a classical topic in complex analysis and differential
geometry, has become a subject of great interest in the area of surface
parameterization in recent decades with various applications in science and
engineering. However, most of the existing conformal parameterization
algorithms only focus on simply-connected surfaces and cannot be directly
applied to surfaces with holes. In this work, we propose two novel algorithms
for computing the conformal parameterization of multiply-connected surfaces. We
first develop an efficient method for conformally parameterizing an open
surface with one hole to an annulus on the plane. Based on this method, we then
develop an efficient method for conformally parameterizing an open surface with
$k$ holes onto a unit disk with $k$ circular holes. The conformality and
bijectivity of the mappings are ensured by quasi-conformal theory. Numerical
experiments and applications are presented to demonstrate the effectiveness of
the proposed methods.
"
2314,"DeepRemaster: Temporal Source-Reference Attention Networks for
  Comprehensive Video Enhancement","  The remastering of vintage film comprises of a diversity of sub-tasks
including super-resolution, noise removal, and contrast enhancement which aim
to restore the deteriorated film medium to its original state. Additionally,
due to the technical limitations of the time, most vintage film is either
recorded in black and white, or has low quality colors, for which colorization
becomes necessary. In this work, we propose a single framework to tackle the
entire remastering task semi-interactively. Our work is based on temporal
convolutional neural networks with attention mechanisms trained on videos with
data-driven deterioration simulation. Our proposed source-reference attention
allows the model to handle an arbitrary number of reference color images to
colorize long videos without the need for segmentation while maintaining
temporal consistency. Quantitative analysis shows that our framework
outperforms existing approaches, and that, in contrast to existing approaches,
the performance of our framework increases with longer videos and more
reference color images.
"
2315,"Light Direction and Color Estimation from Single Image with Deep
  Regression","  We present a method to estimate the direction and color of the scene light
source from a single image. Our method is based on two main ideas: (a) we use a
new synthetic dataset with strong shadow effects with similar constraints to
the SID dataset; (b) we define a deep architecture trained on the mentioned
dataset to estimate the direction and color of the scene light source. Apart
from showing good performance on synthetic images, we additionally propose a
preliminary procedure to obtain light positions of the Multi-Illumination
dataset, and, in this way, we also prove that our trained model achieves good
performance when it is applied to real scenes.
"
2316,Mid-Air Drawing of Curves on 3D Surfaces in AR/VR,"  Complex 3D curves can be created by directly drawing mid-air in immersive
environments (AR/VR). Drawing mid-air strokes precisely on the surface of a 3D
virtual object however, is difficult; necessitating a projection of the mid-air
stroke onto the user ""intended"" surface curve. We present the first detailed
investigation of the fundamental problem of 3D stroke projection in AR/VR. An
assessment of the design requirements of real-time drawing of curves on 3D
objects in AR/VR is followed by the definition and classification of multiple
techniques for 3D stroke projection. We analyze the advantages and shortcomings
of these approaches both theoretically and via practical pilot testing. We then
formally evaluate the two most promising techniques spraycan and mimicry with
20 users in VR. The study shows a strong qualitative and quantitative user
preference for our novel stroke mimicry projection algorithm. We further
illustrate the effectiveness and utility of stroke mimicry, to draw complex 3D
curves on surfaces for various artistic and functional design applications.
"
2317,"Differentiable Refraction-Tracing for Mesh Reconstruction of Transparent
  Objects","  Capturing the 3D geometry of transparent objects is a challenging task,
ill-suited for general-purpose scanning and reconstruction techniques, since
these cannot handle specular light transport phenomena. Existing
state-of-the-art methods, designed specifically for this task, either involve a
complex setup to reconstruct complete refractive ray paths, or leverage a
data-driven approach based on synthetic training data. In either case, the
reconstructed 3D models suffer from over-smoothing and loss of fine detail.
This paper introduces a novel, high precision, 3D acquisition and
reconstruction method for solid transparent objects. Using a static background
with a coded pattern, we establish a mapping between the camera view rays and
locations on the background. Differentiable tracing of refractive ray paths is
then used to directly optimize a 3D mesh approximation of the object, while
simultaneously ensuring silhouette consistency and smoothness. Extensive
experiments and comparisons demonstrate the superior accuracy of our method.
"
2318,"Michelson Holography: Dual-SLM Holography with Camera-in-the-loop
  Optimization","  We introduce Michelson Holography (MH), a holographic display technology that
optimizes image quality for emerging holographic near-eye displays. Using two
spatial light modulators, MH is capable of leveraging destructive interference
to optically cancel out undiffracted light corrupting the observed image. We
calibrate this system using emerging camera-in-the-loop holography techniques
and demonstrate state-of-the-art holographic 2D image quality.
"
2319,"3D Modeling and WebVR Implementation using Azure Kinect, Open3D, and
  Three.js","  This paper proposes a method of extracting an RGB-D image usingAzure Kinect,
a depth camera, creating afragment,i.e., 6D images (RGBXYZ), usingOpen3D,
creatingit as a point cloud object, and implementing webVR usingthree.js.
Furthermore, it presents limitations and potentials for development.
"
2320,PIE: Portrait Image Embedding for Semantic Control,"  Editing of portrait images is a very popular and important research topic
with a large variety of applications. For ease of use, control should be
provided via a semantically meaningful parameterization that is akin to
computer animation controls. The vast majority of existing techniques do not
provide such intuitive and fine-grained control, or only enable coarse editing
of a single isolated control parameter. Very recently, high-quality
semantically controlled editing has been demonstrated, however only on
synthetically created StyleGAN images. We present the first approach for
embedding real portrait images in the latent space of StyleGAN, which allows
for intuitive editing of the head pose, facial expression, and scene
illumination in the image. Semantic editing in parameter space is achieved
based on StyleRig, a pretrained neural network that maps the control space of a
3D morphable face model to the latent space of the GAN. We design a novel
hierarchical non-linear optimization problem to obtain the embedding. An
identity preservation energy term allows spatially coherent edits while
maintaining facial integrity. Our approach runs at interactive frame rates and
thus allows the user to explore the space of possible edits. We evaluate our
approach on a wide set of portrait photos, compare it to the current state of
the art, and validate the effectiveness of its components in an ablation study.
"
2321,"3D Primitives Gpgpu Generation for Volume Visualization in 3D Graphics
  Systems","  This article discusses the study of 3D graphic volume primitive computer
system generation (3D segments) based on General Purpose Graphics Processing
Unit (GPGPU) technology for 3D volume visualization systems. It is based on the
general method of Volume 3D primitive generation and an algorithm for the
voxelization of 3D lines, previously proposed and studied by the authors. We
considered the Compute Unified Device Architect (CUDA) implementation of a
parametric method for generating 3D line segments and characteristics of
generation on modern Graphics Processing Units. Experiments on the test bench
showed the relative inefficiency of generating a single 3D line segment and the
efficiency of generating both fixed and arbitrary length of 3D segments on a
Graphics Processing Unit (GPU). Experimental studies have proven the
effectiveness and the quality of produced solutions by our method, when
compared to existing state-of-the-art approaches.
"
2322,3D Pseudo Stereo Visualization with Gpgpu Support,"  This article discusses the study of a computer system for creating 3D
pseudo-stereo images and videos using hardware and software support for
accelerating a synthesis process based on General Purpose Graphics Processing
Unit (GPGPU) technology. Based on the general strategy of 3D pseudo-stereo
synthesis previously proposed by the authors, Compute Unified Device Architect
(CUDA) method considers the main implementation stages of 3D pseudo-stereo
synthesis: (i) the practical implementation study; (ii) the synthesis
characteristics for obtaining images; (iii) the video in Ultra-High Definition
(UHD) 4K resolution using the Graphics Processing Unit (GPU). Respectively with
these results of 4K content test on evaluation systems with a GPU the
acceleration average of 60.6 and 6.9 times is obtained for images and videos.
The research results show consistency with previously identified forecasts for
processing 4K image frames. They are confirming the possibility of synthesizing
3D pseudo-stereo algorithms in real time using powerful support for modern
Graphics Processing Unit/Graphics Processing Clusters (GPU/GPC).
"
2323,Overfit Neural Networks as a Compact Shape Representation,"  Neural networks have proven to be effective approximators of signed distance
fields (SDFs) for solid 3D objects. While prior work has focused on the
generalization power of such approximations, we instead explore their
suitability as a compact - if purposefully overfit - SDF representation of
individual shapes. Specifically, we ask whether neural networks can serve as
first-class implicit shape representations in computer graphics. We call such
overfit networks Neural Implicits. Similar to SDFs stored on a regular grid,
Neural Implicits have fixed storage profiles and memory layout, but afford far
greater accuracy. At equal storage cost, Neural Implicits consistently match or
exceed the accuracy of irregularly-sampled triangle meshes. We achieve this
with a combination of a novel loss function, sampling strategy and supervision
protocol designed to facilitate robust shape overfitting. We demonstrate the
flexibility of our representation on a variety of standard rendering and
modelling tasks.
"
2324,Deep Neural Network Approach for Annual Luminance Simulations,"  Annual luminance maps provide meaningful evaluations for occupants' visual
comfort, preferences, and perception. However, acquiring long-term luminance
maps require labor-intensive and time-consuming simulations or impracticable
long-term field measurements. This paper presents a novel data-driven machine
learning approach that makes annual luminance-based evaluations more efficient
and accessible. The methodology is based on predicting the annual luminance
maps from a limited number of point-in-time high dynamic range imagery by
utilizing a deep neural network (DNN). Panoramic views are utilized, as they
can be post-processed to study multiple view directions. The proposed DNN model
can faithfully predict high-quality annual panoramic luminance maps from one of
the three options within 30 minutes training time: a) point-in-time luminance
imagery spanning 5% of the year, when evenly distributed during daylight hours,
b) one-month hourly imagery generated or collected continuously during daylight
hours around the equinoxes (8% of the year); or c) 9 days of hourly data
collected around the spring equinox, summer and winter solstices (2.5% of the
year) all suffice to predict the luminance maps for the rest of the year. The
DNN predicted high-quality panoramas are validated against Radiance (RPICT)
renderings using a series of quantitative and qualitative metrics. The most
efficient predictions are achieved with 9 days of hourly data collected around
the spring equinox, summer and winter solstices. The results clearly show that
practitioners and researchers can efficiently incorporate long-term
luminance-based metrics over multiple view directions into the design and
research processes using the proposed DNN workflow.
"
2325,CNNPruner: Pruning Convolutional Neural Networks with Visual Analytics,"  Convolutional neural networks (CNNs) have demonstrated extraordinarily good
performance in many computer vision tasks. The increasing size of CNN models,
however, prevents them from being widely deployed to devices with limited
computational resources, e.g., mobile/embedded devices. The emerging topic of
model pruning strives to address this problem by removing less important
neurons and fine-tuning the pruned networks to minimize the accuracy loss.
Nevertheless, existing automated pruning solutions often rely on a numerical
threshold of the pruning criteria, lacking the flexibility to optimally balance
the trade-off between model size and accuracy. Moreover, the complicated
interplay between the stages of neuron pruning and model fine-tuning makes this
process opaque, and therefore becomes difficult to optimize. In this paper, we
address these challenges through a visual analytics approach, named CNNPruner.
It considers the importance of convolutional filters through both instability
and sensitivity, and allows users to interactively create pruning plans
according to a desired goal on model size or accuracy. Also, CNNPruner
integrates state-of-the-art filter visualization techniques to help users
understand the roles that different filters played and refine their pruning
plans. Through comprehensive case studies on CNNs with real-world sizes, we
validate the effectiveness of CNNPruner.
"
2326,"MonoClothCap: Towards Temporally Coherent Clothing Capture from
  Monocular RGB Video","  We present a method to capture temporally coherent dynamic clothing
deformation from a monocular RGB video input. In contrast to the existing
literature, our method does not require a pre-scanned personalized mesh
template, and thus can be applied to in-the-wild videos. To constrain the
output to a valid deformation space, we build statistical deformation models
for three types of clothing: T-shirt, short pants and long pants. A
differentiable renderer is utilized to align our captured shapes to the input
frames by minimizing the difference in both silhouette and texture. We develop
a UV texture growing method which expands the visible texture region of the
clothing sequentially in order to minimize drift in deformation tracking. We
also extract fine-grained wrinkle detail from the input videos by fitting the
clothed surface to the normal maps estimated by a convolutional neural network.
Our method produces temporally coherent reconstruction of body and clothing
from monocular video. We demonstrate successful clothing capture results from a
variety of challenging videos. Extensive quantitative experiments demonstrate
the effectiveness of our method on metrics including body pose error and
surface reconstruction error of the clothing.
"
2327,Scaling Probe-Based Real-Time Dynamic Global Illumination for Production,"  We contribute several practical extensions to the probe based
irradiance-field-with-visibility representation to improve image quality,
constant and asymptotic performance, memory efficiency, and artist control. We
developed these extensions in the process of incorporating the previous work
into the global illumination solutions of the NVIDIA RTXGI SDK, the Unity and
Unreal Engine 4 game engines, and proprietary engines for several commercial
games. These extensions include: a single, intuitive tuning parameter (the
""self-shadow"" bias); heuristics to speed transitions in the global
illumination; reuse of irradiance data as prefiltered radiance for recursive
glossy reflection; a probe state machine to prune work that will not affect the
final image; and multiresolution cascaded volumes for large worlds.
"
2328,Visualization of Human Spine Biomechanics for Spinal Surgery,"  We propose a visualization application, designed for the exploration of human
spine simulation data. Our goal is to support research in biomechanical spine
simulation and advance efforts to implement simulation-backed analysis in
surgical applications. Biomechanical simulation is a state-of-the-art technique
for analyzing load distributions of spinal structures. Through the inclusion of
patient-specific data, such simulations may facilitate personalized treatment
and customized surgical interventions. Difficulties in spine modelling and
simulation can be partly attributed to poor result representation, which may
also be a hindrance when introducing such techniques into a clinical
environment. Comparisons of measurements across multiple similar anatomical
structures and the integration of temporal data make commonly available
diagrams and charts insufficient for an intuitive and systematic display of
results. Therefore, we facilitate methods such as multiple coordinated views,
abstraction and focus and context to display simulation outcomes in a dedicated
tool. By linking the result data with patient-specific anatomy, we make
relevant parameters tangible for clinicians. Furthermore, we introduce new
concepts to show the directions of impact force vectors, which were not
accessible before. We integrated our toolset into a spine segmentation and
simulation pipeline and evaluated our methods with both surgeons and
biomechanical researchers. When comparing our methods against standard
representations that are currently in use, we found increases in accuracy and
speed in data exploration tasks. In a qualitative review, domain experts deemed
the tool highly useful when dealing with simulation result data, which
typically combines time-dependent patient movement and the resulting force
distributions on spinal structures.
"
2329,An Online and Nonuniform Timeslicing Method for Network Visualisation,"  Visual analysis of temporal networks comprises an effective way to understand
the network dynamics, facilitating the identification of patterns, anomalies,
and other network properties, thus resulting in fast decision making. The
amount of data in real-world networks, however, may result in a layout with
high visual clutter due to edge overlapping. This is particularly relevant in
the so-called streaming networks, in which edges are continuously arriving
(online) and in non-stationary distribution. All three network dimensions,
namely node, edge, and time, can be manipulated to reduce such clutter and
improve readability. This paper presents an online and nonuniform timeslicing
method, thus considering the underlying network structure and addressing
streaming network analyses. We conducted experiments using two real-world
networks to compare our method against uniform and nonuniform timeslicing
strategies. The results show that our method automatically selects timeslices
that effectively reduce visual clutter in periods with bursts of events. As a
consequence, decision making based on the identification of global temporal
patterns becomes faster and more reliable.
"
2330,Deep Learning of Individual Aesthetics,"  Accurate evaluation of human aesthetic preferences represents a major
challenge for creative evolutionary and generative systems research. Prior work
has tended to focus on feature measures of the artefact, such as symmetry,
complexity and coherence. However, research models from Psychology suggest that
human aesthetic experiences encapsulate factors beyond the artefact, making
accurate computational models very difficult to design. The interactive genetic
algorithm (IGA) circumvents the problem through human-in-the-loop, subjective
evaluation of aesthetics, but is limited due to user fatigue and small
population sizes. In this paper we look at how recent advances in deep learning
can assist in automating personal aesthetic judgement. Using a leading artist's
computer art dataset, we investigate the relationship between image measures,
such as complexity, and human aesthetic evaluation. We use dimension reduction
methods to visualise both genotype and phenotype space in order to support the
exploration of new territory in a generative system. Convolutional Neural
Networks trained on the artist's prior aesthetic evaluations are used to
suggest new possibilities similar or between known high quality
genotype-phenotype mappings. We integrate this classification and discovery
system into a software tool for evolving complex generative art and design.
"
2331,"SceneGen: Generative Contextual Scene Augmentation using Scene Graph
  Priors","  Spatial computing experiences are constrained by the real-world surroundings
of the user. In such experiences, augmenting virtual objects to existing scenes
require a contextual approach, where geometrical conflicts are avoided, and
functional and plausible relationships to other objects are maintained in the
target environment. Yet, due to the complexity and diversity of user
environments, automatically calculating ideal positions of virtual content that
is adaptive to the context of the scene is considered a challenging task.
Motivated by this problem, in this paper we introduce SceneGen, a generative
contextual augmentation framework that predicts virtual object positions and
orientations within existing scenes. SceneGen takes a semantically segmented
scene as input, and outputs positional and orientational probability maps for
placing virtual content. We formulate a novel spatial Scene Graph
representation, which encapsulates explicit topological properties between
objects, object groups, and the room. We believe providing explicit and
intuitive features plays an important role in informative content creation and
user interaction of spatial computing settings, a quality that is not captured
in implicit models. We use kernel density estimation (KDE) to build a
multivariate conditional knowledge model trained using prior spatial Scene
Graphs extracted from real-world 3D scanned data. To further capture
orientational properties, we develop a fast pose annotation tool to extend
current real-world datasets with orientational labels. Finally, to demonstrate
our system in action, we develop an Augmented Reality application, in which
objects can be contextually augmented in real-time.
"
2332,"A grammar of graphics framework for generalized parallel coordinate
  plots","  Parallel coordinate plots (PCP) are a useful tool in exploratory data
analysis of high-dimensional numerical data. The use of PCPs is limited when
working with categorical variables or a mix of categorical and continuous
variables. In this paper, we propose generalized parallel coordinate plots
(GPCP) to extend the ability of PCPs from just numeric variables to dealing
seamlessly with a mix of categorical and numeric variables in a single plot. In
this process we find that existing solutions for categorical values only, such
as hammock plots or parsets become edge cases in the new framework. By focusing
on individual observation rather a marginal frequency we gain additional
flexibility. The resulting approach is implemented in the R package ggpcp.
"
2333,Recognition and Synthesis of Object Transport Motion,"  Deep learning typically requires vast numbers of training examples in order
to be used successfully. Conversely, motion capture data is often expensive to
generate, requiring specialist equipment, along with actors to generate the
prescribed motions, meaning that motion capture datasets tend to be relatively
small. Motion capture data does however provide a rich source of information
that is becoming increasingly useful in a wide variety of applications, from
gesture recognition in human-robot interaction, to data driven animation.
  This project illustrates how deep convolutional networks can be used,
alongside specialized data augmentation techniques, on a small motion capture
dataset to learn detailed information from sequences of a specific type of
motion (object transport). The project shows how these same augmentation
techniques can be scaled up for use in the more complex task of motion
synthesis.
  By exploring recent developments in the concept of Generative Adversarial
Models (GANs), specifically the Wasserstein GAN, this project outlines a model
that is able to successfully generate lifelike object transportation motions,
with the generated samples displaying varying styles and transport strategies.
"
2334,A Testing Environment for Continuous Colormaps,"  Many computer science disciplines (e.g., combinatorial optimization, natural
language processing, and information retrieval) use standard or established
test suites for evaluating algorithms. In visualization, similar approaches
have been adopted in some areas (e.g., volume visualization), while user
testimonies and empirical studies have been the dominant means of evaluation in
most other areas, such as designing colormaps. In this paper, we propose to
establish a test suite for evaluating the design of colormaps. With such a
suite, the users can observe the effects when different continuous colormaps
are applied to planar scalar fields that may exhibit various characteristic
features, such as jumps, local extrema, ridge or valley lines, different
distributions of scalar values, different gradients, different signal
frequencies, different levels of noise, and so on. The suite also includes an
expansible collection of real-world data sets including the most popular data
for colormap testing in the visualization literature. The test suite has been
integrated into a web-based application for creating continuous colormaps
(https://ccctool.com/), facilitating close inter-operation between design and
evaluation processes. This new facility complements traditional evaluation
methods such as user testimonies and empirical studies.
"
2335,Weakly Supervised Deep Functional Map for Shape Matching,"  A variety of deep functional maps have been proposed recently, from fully
supervised to totally unsupervised, with a range of loss functions as well as
different regularization terms. However, it is still not clear what are minimum
ingredients of a deep functional map pipeline and whether such ingredients
unify or generalize all recent work on deep functional maps. We show
empirically minimum components for obtaining state of the art results with
different loss functions, supervised as well as unsupervised. Furthermore, we
propose a novel framework designed for both full-to-full as well as partial to
full shape matching that achieves state of the art results on several benchmark
datasets outperforming even the fully supervised methods by a significant
margin. Our code is publicly available at
https://github.com/Not-IITian/Weakly-supervised-Functional-map
"
2336,"A Large Scale Benchmark and an Inclusion-Based Algorithm for Continuous
  Collision Detection","  We introduce a large scale benchmark for continuous collision detection (CCD)
algorithms, composed of queries manually constructed to highlight challenging
degenerate cases and automatically generated using existing simulators to cover
common cases. We use the benchmark to evaluate the accuracy, correctness, and
efficiency of state-of-the-art continuous collision detection algorithms, both
with and without minimal separation. We discover that, despite the widespread
use of CCD algorithms, existing algorithms are either: (1) correct but
impractically slow, (2) efficient but incorrect, introducing false negatives
which will lead to interpenetration, or (3) correct but over conservative,
reporting a large number of false positives which might lead to inaccuracies
when integrated in a simulator. By combining the seminal interval root finding
algorithm introduced by Snyder in 1992 with modern predicate design techniques,
we propose a simple and efficient CCD algorithm. This algorithm is competitive
with state of the art methods in terms of runtime while conservatively
reporting the time of impact and allowing explicit trade off between runtime
efficiency and number of false positives reported.
"
2337,Neural Alignment for Face De-pixelization,"  We present a simple method to reconstruct a high-resolution video from a
face-video, where the identity of a person is obscured by pixelization. This
concealment method is popular because the viewer can still perceive a human
face figure and the overall head motion. However, we show in our experiments
that a fairly good approximation of the original video can be reconstructed in
a way that compromises anonymity. Our system exploits the simultaneous
similarity and small disparity between close-by video frames depicting a human
face, and employs a spatial transformation component that learns the alignment
between the pixelated frames. Each frame, supported by its aligned surrounding
frames, is first encoded, then decoded to a higher resolution. Reconstruction
and perceptual losses promote adherence to the ground-truth, and an adversarial
loss assists in maintaining domain faithfulness. There is no need for explicit
temporal coherency loss as it is maintained implicitly by the alignment of
neighboring frames and reconstruction. Although simple, our framework
synthesizes high-quality face reconstructions, demonstrating that given the
statistical prior of a human face, multiple aligned pixelated frames contain
sufficient information to reconstruct a high-quality approximation of the
original signal.
"
2338,Asynchronous Liquids: Regional Time Stepping for Faster SPH and PCISPH,"  This paper presents novel and efficient strategies to spatially adapt the
amount of computational effort applied based on the local dynamics of a free
surface flow, for both classic weakly compressible SPH (WCSPH) and
predictive-corrective incompressible SPH (PCISPH). Using a convenient and
readily parallelizable block-based approach, different regions of the fluid are
assigned differing time steps and solved at different rates to minimize
computational cost. Our approach for WCSPH scheme extends an asynchronous SPH
technique from compressible flow of astrophysical phenomena to the
incompressible free surface setting, and further accelerates it by entirely
decoupling the time steps of widely spaced particles. Similarly, our approach
to PCISPH adjusts the the number of iterations of density correction applied to
different regions, and asynchronously updates the neighborhood regions used to
perform these corrections; this sharply reduces the computational cost of
slowly deforming regions while preserving the standard density invariant. We
demonstrate our approaches on a number of highly dynamic scenarios,
demonstrating that they can typically double the speed of a simulation compared
to standard methods while achieving visually consistent results.
"
2339,Turbulent Details Simulation for SPH Fluids via Vorticity Refinement,"  A major issue in Smoothed Particle Hydrodynamics (SPH) approaches is the
numerical dissipation during the projection process, especially under coarse
discretizations. High-frequency details, such as turbulence and vortices, are
smoothed out, leading to unrealistic results. To address this issue, we
introduce a Vorticity Refinement (VR) solver for SPH fluids with negligible
computational overhead. In this method, the numerical dissipation of the
vorticity field is recovered by the difference between the theoretical and the
actual vorticity, so as to enhance turbulence details. Instead of solving the
Biot-Savart integrals, a stream function, which is easier and more efficient to
solve, is used to relate the vorticity field to the velocity field. We obtain
turbulence effects of different intensity levels by changing an adjustable
parameter. Since the vorticity field is enhanced according to the curl field,
our method can not only amplify existing vortices, but also capture additional
turbulence. Our VR solver is straightforward to implement and can be easily
integrated into existing SPH methods.
"
2340,Structured Regularization of Functional Map Computations,"  We consider the problem of non-rigid shape matching using the functional map
framework. Specifically, we analyze a commonly used approach for regularizing
functional maps, which consists in penalizing the failure of the unknown map to
commute with the Laplace-Beltrami operators on the source and target shapes. We
show that this approach has certain undesirable fundamental theoretical
limitations, and can be undefined even for trivial maps in the smooth setting.
Instead we propose a novel, theoretically well-justified approach for
regularizing functional maps, by using the notion of the resolvent of the
Laplacian operator. In addition, we provide a natural one-parameter family of
regularizers, that can be easily tuned depending on the expected approximate
isometry of the input shape pair. We show on a wide range of shape
correspondence scenarios that our novel regularization leads to an improvement
in the quality of the estimated functional, and ultimately pointwise
correspondences before and after commonly-used refinement techniques.
"
2341,"CrowdEst: A Method for Estimating (and not Simulating) Crowd Evacuation
  Parameters in Generic Environments","  Evacuation plans have been historically used as a safety measure for the
construction of buildings. The existing crowd simulators require fully-modeled
3D environments and enough time to prepare and simulate scenarios, where the
distribution and behavior of the crowd needs to be controlled. In addition, its
population, routes or even doors and passages may change, so the 3D model and
configurations have to be updated accordingly. This is a time-consuming task
that commonly has to be addressed within the crowd simulators. With that in
mind, we present a novel approach to estimate the resulting data of a given
evacuation scenario without actually simulating it. For such, we divide the
environment into smaller modular rooms with different configurations, in a
divide-and-conquer fashion. Next, we train an artificial neural network to
estimate all required data regarding the evacuation of a single room. After
collecting the estimated data from each room, we develop a heuristic capable of
aggregating per-room information so the full environment can be properly
evaluated. Our method presents an average error of 5% when compared to
evacuation time in a real-life environment. Our crowd estimator approach has
several advantages, such as not requiring to model the 3D environment, nor
learning how to use and configure a crowd simulator, which means any user can
easily use it. Furthermore, the computational time to estimate evacuation data
(inference time) is virtually zero, which is much better even when compared to
the best-case scenario in a real-time crowd simulator.
"
2342,"X-Fields: Implicit Neural View-, Light- and Time-Image Interpolation","  We suggest to represent an X-Field -a set of 2D images taken across different
view, time or illumination conditions, i.e., video, light field, reflectance
fields or combinations thereof-by learning a neural network (NN) to map their
view, time or light coordinates to 2D images. Executing this NN at new
coordinates results in joint view, time or light interpolation. The key idea to
make this workable is a NN that already knows the ""basic tricks"" of graphics
(lighting, 3D projection, occlusion) in a hard-coded and differentiable form.
The NN represents the input to that rendering as an implicit map, that for any
view, time, or light coordinate and for any pixel can quantify how it will move
if view, time or light coordinates change (Jacobian of pixel position with
respect to view, time, illumination, etc.). Our X-Field representation is
trained for one scene within minutes, leading to a compact set of trainable
parameters and hence real-time navigation in view, time and illumination.
"
2343,Dynamic Facial Asset and Rig Generation from a Single Scan,"  The creation of high-fidelity computer-generated (CG) characters used in film
and gaming requires intensive manual labor and a comprehensive set of facial
assets to be captured with complex hardware, resulting in high cost and long
production cycles. In order to simplify and accelerate this digitization
process, we propose a framework for the automatic generation of high-quality
dynamic facial assets, including rigs which can be readily deployed for artists
to polish. Our framework takes a single scan as input to generate a set of
personalized blendshapes, dynamic and physically-based textures, as well as
secondary facial components (e.g., teeth and eyeballs). Built upon a facial
database consisting of pore-level details, with over $4,000$ scans of varying
expressions and identities, we adopt a self-supervised neural network to learn
personalized blendshapes from a set of template expressions. We also model the
joint distribution between identities and expressions, enabling the inference
of the full set of personalized blendshapes with dynamic appearances from a
single neutral input scan. Our generated personalized face rig assets are
seamlessly compatible with cutting-edge industry pipelines for facial animation
and rendering. We demonstrate that our framework is robust and effective by
inferring on a wide range of novel subjects, and illustrate compelling
rendering results while animating faces with generated customized
physically-based dynamic textures.
"
2344,Cartographic Relief Shading with Neural Networks,"  Shaded relief is an effective method for visualising terrain on topographic
maps, especially when the direction of illumination is adapted locally to
emphasise individual terrain features. However, digital shading algorithms are
unable to fully match the expressiveness of hand-crafted masterpieces, which
are created through a laborious process by highly specialised cartographers. We
replicate hand-drawn relief shading using U-Net neural networks. The deep
neural networks are trained with manual shaded relief images of the Swiss
topographic map series and terrain models of the same area. The networks
generate shaded relief that closely resemble hand-drawn shaded relief art. The
networks learn essential design principles from manual relief shading such as
removing unnecessary terrain details, locally adjusting the illumination
direction to accentuate individual terrain features, and varying brightness to
emphasise larger landforms. Neural network shadings are generated from digital
elevation models in a few seconds, and a study with 18 relief shading experts
found that they are of high quality.
"
2345,"An Infinite, Converging, Sequence of Brocard Porisms","  The Brocard porism is a known 1d family of triangles inscribed in a circle
and circumscribed about an ellipse. Remarkably, the Brocard angle is invariant
and the Brocard points are stationary at the foci of the ellipse. In this paper
we show that a certain derived triangle spawns off a second, smaller, Brocard
porism so that repeating this calculation produces an infinite, converging
sequence of porisms. We also show that this sequence is embedded in a
continuous family of porisms.
"
2346,"Generating Emotive Gaits for Virtual Agents Using Affect-Based
  Autoregression","  We present a novel autoregression network to generate virtual agents that
convey various emotions through their walking styles or gaits. Given the 3D
pose sequences of a gait, our network extracts pertinent movement features and
affective features from the gait. We use these features to synthesize
subsequent gaits such that the virtual agents can express and transition
between emotions represented as combinations of happy, sad, angry, and neutral.
We incorporate multiple regularizations in the training of our network to
simultaneously enforce plausible movements and noticeable emotions on the
virtual agents. We also integrate our approach with an AR environment using a
Microsoft HoloLens and can generate emotive gaits at interactive rates to
increase the social presence. We evaluate how human observers perceive both the
naturalness and the emotions from the generated gaits of the virtual agents in
a web-based study. Our results indicate around 89% of the users found the
naturalness of the gaits satisfactory on a five-point Likert scale, and the
emotions they perceived from the virtual agents are statistically similar to
the intended emotions of the virtual agents. We also use our network to augment
existing gait datasets with emotive gaits and will release this augmented
dataset for future research in emotion prediction and emotive gait synthesis.
Our project website is available at https://gamma.umd.edu/gen_emotive_gaits/.
"
2347,Learning Complete 3D Morphable Face Models from Images and Videos,"  Most 3D face reconstruction methods rely on 3D morphable models, which
disentangle the space of facial deformations into identity geometry,
expressions and skin reflectance. These models are typically learned from a
limited number of 3D scans and thus do not generalize well across different
identities and expressions. We present the first approach to learn complete 3D
models of face identity geometry, albedo and expression just from images and
videos. The virtually endless collection of such data, in combination with our
self-supervised learning-based approach allows for learning face models that
generalize beyond the span of existing approaches. Our network design and loss
functions ensure a disentangled parameterization of not only identity and
albedo, but also, for the first time, an expression basis. Our method also
allows for in-the-wild monocular reconstruction at test time. We show that our
learned models better generalize and lead to higher quality image-based
reconstructions than existing approaches.
"
2348,Photon-Driven Neural Path Guiding,"  Although Monte Carlo path tracing is a simple and effective algorithm to
synthesize photo-realistic images, it is often very slow to converge to
noise-free results when involving complex global illumination. One of the most
successful variance-reduction techniques is path guiding, which can learn
better distributions for importance sampling to reduce pixel noise. However,
previous methods require a large number of path samples to achieve reliable
path guiding. We present a novel neural path guiding approach that can
reconstruct high-quality sampling distributions for path guiding from a sparse
set of samples, using an offline trained neural network. We leverage photons
traced from light sources as the input for sampling density reconstruction,
which is highly effective for challenging scenes with strong global
illumination. To fully make use of our deep neural network, we partition the
scene space into an adaptive hierarchical grid, in which we apply our network
to reconstruct high-quality sampling distributions for any local region in the
scene. This allows for highly efficient path guiding for any path bounce at any
location in path tracing. We demonstrate that our photon-driven neural path
guiding method can generalize well on diverse challenging testing scenes that
are not seen in training. Our approach achieves significantly better rendering
results of testing scenes than previous state-of-the-art path guiding methods.
"
2349,Actors in VR storytelling,"  Virtual Reality (VR) storytelling enhances the immersion of users into
virtual environments (VE). Its use in virtual cultural heritage presentations
helps the revival of the genius loci (the spirit of the place) of cultural
monuments. This paper aims to show that the use of actors in VR storytelling
adds to the quality of user experience and improves the edutainment value of
virtual cultural heritage applications. We will describe the Baiae dry visit
application which takes us to a time travel in the city considered by the Roman
elite as ""Little Rome (Pusilla Roma)"" and presently is only partially preserved
under the sea.
"
2350,"Topological Analysis of Magnetic Reconnection in Kinetic Plasma
  Simulations","  Magnetic reconnection is a ubiquitous plasma process in which oppositely
directed magnetic field lines break and rejoin, resulting in a change of the
magnetic field topology. Reconnection generates magnetic islands: regions
enclosed by magnetic field lines and separated by reconnection points. Proper
identification of these features is important to understand particle
acceleration and overall behavior of plasma. We present a contour-tree based
visualization for robust and objective identification of islands and
reconnection points in two-dimensional (2D) magnetic reconnection simulations.
The application of this visualization to a simple simulation has revealed a
physical phenomenon previously not reported, resulting in a more comprehensive
understanding of magnetic reconnection.
"
2351,"Combined Hapto-Visual and Auditory Rendering of Cultural Heritage
  Objects","  In this work, we develop a multi-modal rendering framework comprising of
hapto-visual and auditory data. The prime focus is to haptically render point
cloud data representing virtual 3-D models of cultural significance and also to
handle their affine transformations. Cultural heritage objects could
potentially be very large and one may be required to render the object at
various scales of details. Further, surface effects such as texture and
friction are incorporated in order to provide a realistic haptic perception to
the users. Moreover, the proposed framework includes an appropriate sound
synthesis to bring out the acoustic properties of the object. It also includes
a graphical user interface with varied options such as choosing the desired
orientation of 3-D objects and selecting the desired level of spatial
resolution adaptively at runtime. A fast, point proxy-based haptic rendering
technique is proposed with proxy update loop running 100 times faster than the
required haptic update frequency of 1 kHz. The surface properties are
integrated in the system by applying a bilateral filter on the depth data of
the virtual 3-D models. Position dependent sound synthesis is incorporated with
the incorporation of appropriate audio clips.
"
2352,"Tensor Fields for Data Extraction from Chart Images: Bar Charts and
  Scatter Plots","  Charts are an essential part of both graphicacy (graphical literacy), and
statistical literacy. As chart understanding has become increasingly relevant
in data science, automating chart analysis by processing raster images of the
charts has become a significant problem. Automated chart reading involves data
extraction and contextual understanding of the data from chart images. In this
paper, we perform the first step of determining the computational model of
chart images for data extraction for selected chart types, namely, bar charts,
and scatter plots. We demonstrate the use of positive semidefinite second-order
tensor fields as an effective model. We identify an appropriate tensor field as
the model and propose a methodology for the use of its degenerate point
extraction for data extraction from chart images. Our results show that tensor
voting is effective for data extraction from bar charts and scatter plots, and
histograms, as a special case of bar charts.
"
2353,"Fusion 360 Gallery: A Dataset and Environment for Programmatic CAD
  Reconstruction","  Parametric computer-aided design (CAD) is a standard paradigm used for the
design of manufactured objects. CAD designers perform modeling operations, such
as sketch and extrude, to form a construction sequence that makes up a final
design. Despite the pervasiveness of parametric CAD and growing interest from
the research community, a dataset of human designed 3D CAD construction
sequences has not been available to-date. In this paper we present the Fusion
360 Gallery reconstruction dataset and environment for learning CAD
reconstruction. We provide a dataset of 8,625 designs, comprising sequential
sketch and extrude modeling operations, together with a complementary
environment called the Fusion 360 Gym, to assist with performing CAD
reconstruction. We outline a standard CAD reconstruction task, together with
evaluation metrics, and present results from a novel method using neurally
guided search to recover a construction sequence from raw geometry.
"
2354,Scalable Rendering of Variable Density Point Cloud Data,"  In this paper, we present a novel proxy-based method of the adaptive haptic
rendering of a variable density 3D point cloud data at different levels of
detail without pre-computing the mesh structure. We also incorporate features
like rotation, translation, and friction to provide a better realistic
experience to the user. A proxy-based rendering technique is used to avoid the
pop-through problem while rendering thin parts of the object. Instead of a
point proxy, a spherical proxy of a variable radius is used, which avoids the
sinking of proxy during the haptic interaction of sparse data. The radius of
the proxy is adaptively varied depending upon the local density of the point
data using kernel bandwidth estimation. During the interaction, the proxy moves
in small steps tangentially over the point cloud such that the new position
always minimizes the distance between the proxy and the haptic interaction
point (HIP). The raw point cloud data re-sampled in a regular 3D lattice of
voxels are loaded to the haptic space after proper smoothing to avoid aliasing
effects. The rendering technique is validated with several subjects, and it is
observed that this functionality supplements the user's experience by allowing
the user to interact with an object at multiple resolutions.
"
2355,Haptic Rendering of Cultural Heritage Objects at Different Scales,"  In this work, we address the issue of a virtual representation of objects of
cultural heritage for haptic interaction. Our main focus is to provide haptic
access to artistic objects of any physical scale to the differently-abled
people. This is a low-cost system and, in conjunction with a stereoscopic
visual display, gives a better immersive experience even to the sighted
persons. To achieve this, we propose a simple multilevel, proxy-based
hapto-visual rendering technique for point cloud data, which includes the
much-desired scalability feature which enables the users to change the scale of
the objects adaptively during the haptic interaction. For the proposed haptic
rendering technique, the proxy updation loop runs at a rate 100 times faster
than the required haptic updation frequency of 1KHz. We observe that this
functionality augments very well with the realism of the experience.
"
2356,Cinema Darkroom: A Deferred Rendering Framework for Large-Scale Datasets,"  This paper presents a framework that fully leverages the advantages of a
deferred rendering approach for the interactive visualization of large-scale
datasets. Geometry buffers (G-Buffers) are generated and stored in situ, and
shading is performed post hoc in an interactive image-based rendering front
end. This decoupled framework has two major advantages. First, the G-Buffers
only need to be computed and stored once---which corresponds to the most
expensive part of the rendering pipeline. Second, the stored G-Buffers can
later be consumed in an image-based rendering front end that enables users to
interactively adjust various visualization parameters---such as the applied
color map or the strength of ambient occlusion---where suitable choices are
often not known a priori. This paper demonstrates the use of Cinema Darkroom on
several real-world datasets, highlighting CD's ability to effectively decouple
the complexity and size of the dataset from its visualization.
"
2357,"Temporally-smooth Antialiasing and Lens Distortion with Rasterization
  Map","  Current GPU rasterization procedure is limited to narrow views in rectilinear
perspective. While industries demand curvilinear perspective in wide-angle
views, like Virtual Reality and Virtual Film Production industry. This paper
delivers new rasterization method using industry-standard STMaps. Additionally
new antialiasing rasterization method is proposed, which outperforms MSAA in
both quality and performance. It is an improvement upon previous solutions
found in paper Perspective picture from Visual Sphere by yours truly.
"
2358,Refinement of Predicted Missing Parts Enhance Point Cloud Completion,"  Point cloud completion is the task of predicting complete geometry from
partial observations using a point set representation for a 3D shape. Previous
approaches propose neural networks to directly estimate the whole point cloud
through encoder-decoder models fed by the incomplete point set. By predicting
the complete model, the current methods compute redundant information because
the output also contains the known incomplete input geometry. This paper
proposes an end-to-end neural network architecture that focuses on computing
the missing geometry and merging the known input and the predicted point cloud.
Our method is composed of two neural networks: the missing part prediction
network and the merging-refinement network. The first module focuses on
extracting information from the incomplete input to infer the missing geometry.
The second module merges both point clouds and improves the distribution of the
points. Our experiments on ShapeNet dataset show that our method outperforms
the state-of-the-art methods in point cloud completion. The code of our methods
and experiments is available in
\url{https://github.com/ivansipiran/Refinement-Point-Cloud-Completion}.
"
2359,"GRF: Learning a General Radiance Field for 3D Scene Representation and
  Rendering","  We present a simple yet powerful implicit neural function that can represent
and render arbitrarily complex 3D scenes in a single network only from 2D
observations. The function models 3D scenes as a general radiance field, which
takes a set of posed 2D images as input, constructs an internal representation
for each 3D point of the scene, and renders the corresponding appearance and
geometry of any 3D point viewing from an arbitrary angle. The key to our
approach is to explicitly integrate the principle of multi-view geometry to
obtain the internal representations from observed 2D views, guaranteeing the
learned implicit representations meaningful and multi-view consistent. In
addition, we introduce an effective neural module to learn general features for
each pixel in 2D images, allowing the constructed internal 3D representations
to be remarkably general as well. Extensive experiments demonstrate the
superiority of our approach.
"
2360,MPEG Media Enablers For Richer XR Experiences,"  With the advent of immersive media applications, the requirements for the
representation and the consumption of such content has dramatically increased.
The ever-increasing size of the media asset combined with the stringent
motion-to-photon latency requirement makes the equation of a high quality of
experience for XR streaming services difficult to solve. The MPEG-I standards
aim at facilitating the wide deployment of immersive applications. This paper
describes part 13, Video Decoding Interface, and part 14, Scene Description for
MPEG Media of MPEG-I which address decoder management and the virtual scene
composition, respectively. These new parts intend to make complex media
rendering operations and hardware resources management hidden from the
application, hence lowering the barrier for XR application to become mainstream
and accessible to XR experience developers and designers. Both parts are
expected to be published by ISO at the end of 2021.
"
2361,"Learning Acoustic Scattering Fields for Highly Dynamic Interactive Sound
  Propagation","  We present a novel hybrid sound propagation algorithm for interactive
applications. Our approach is designed for general dynamic scenes and uses a
neural network-based learned scattered field representation along with ray
tracing to generate specular, diffuse, diffraction, and occlusion effects
efficiently. To handle general objects, we exploit properties of the acoustic
scattering field and use geometric deep learning to approximate the field using
spherical harmonics. We use a large dataset for training, and compare its
accuracy with the ground truth generated using an accurate wave-based solver.
The additional overhead of computing the learned scattered field at runtime is
small and we highlight the interactive performance by generating plausible
sound effects in dynamic scenes with diffraction and occlusion effects. We
demonstrate the perceptual benefits of our approach based on an audio-visual
user study.
"
2362,LSMAT Least Squares Medial Axis Transform,"  The medial axis transform has applications in numerous fields including
visualization, computer graphics, and computer vision. Unfortunately,
traditional medial axis transformations are usually brittle in the presence of
outliers, perturbations and/or noise along the boundary of objects. To overcome
this limitation, we introduce a new formulation of the medial axis transform
which is naturally robust in the presence of these artifacts. Unlike previous
work which has approached the medial axis from a computational geometry angle,
we consider it from a numerical optimization perspective. In this work, we
follow the definition of the medial axis transform as ""the set of maximally
inscribed spheres"". We show how this definition can be formulated as a least
squares relaxation where the transform is obtained by minimizing a continuous
optimization problem. The proposed approach is inherently parallelizable by
performing independant optimization of each sphere using Gauss-Newton, and its
least-squares form allows it to be significantly more robust compared to
traditional computational geometry approaches. Extensive experiments on 2D and
3D objects demonstrate that our method provides superior results to the state
of the art on both synthetic and real-data.
"
2363,Fat Pad Cages for Facial Posing,"  We introduce Fat Pad cages for posing facial meshes. It combines cage
representation and facial anatomical elements, and enables users with no
artistic skill to quickly sketch realistic facial expressions. The model relies
on one or several cage(s) that deform(s) the mesh following the human fat pads
map. We propose a new function to filter Green Coordinates using geodesic
distances preventing global deformation while ensuring smooth deformations at
the borders. Lips, nostrils and eyelids are processed slightly differently to
allow folding up and opening. Cages are automatically created and fit any new
unknown facial mesh. To validate our approach, we present a user study
comparing our Fat Pad cages to regular Green Coordinates. Results show that Fat
Pad cages bring a significant improvement in reproducing existing facial
expressions.
"
2364,High-Fidelity 3D Digital Human Creation from RGB-D Selfies,"  We present a fully automatic system that can produce high-fidelity,
photo-realistic 3D digital human characters with a consumer RGB-D selfie
camera. The system only needs the user to take a short selfie RGB-D video while
rotating his/her head, and can produce a high quality reconstruction in less
than 30 seconds. Our main contribution is a new facial geometry modeling and
reflectance synthesis procedure that significantly improves the
state-of-the-art. Specifically, given the input video a two-stage frame
selection algorithm is first employed to select a few high-quality frames for
reconstruction. A novel, differentiable renderer based 3D Morphable Model
(3DMM) fitting method is then applied to recover facial geometries from
multiview RGB-D data, which takes advantages of extensive data generation and
perturbation. Our 3DMM has much larger expressive capacities than conventional
3DMM, allowing us to recover more accurate facial geometry using merely linear
bases. For reflectance synthesis, we present a hybrid approach that combines
parametric fitting and CNNs to synthesize high-resolution albedo/normal maps
with realistic hair/pore/wrinkle details. Results show that our system can
produce faithful 3D characters with extremely realistic details. Code and the
constructed 3DMM is publicly available.
"
2365,Intuitive Facial Animation Editing Based On A Generative RNN Framework,"  For the last decades, the concern of producing convincing facial animation
has garnered great interest, that has only been accelerating with the recent
explosion of 3D content in both entertainment and professional activities. The
use of motion capture and retargeting has arguably become the dominant solution
to address this demand. Yet, despite high level of quality and automation
performance-based animation pipelines still require manual cleaning and editing
to refine raw results, which is a time- and skill-demanding process. In this
paper, we look to leverage machine learning to make facial animation editing
faster and more accessible to non-experts. Inspired by recent image inpainting
methods, we design a generative recurrent neural network that generates
realistic motion into designated segments of an existing facial animation,
optionally following user-provided guiding constraints. Our system handles
different supervised or unsupervised editing scenarios such as motion filling
during occlusions, expression corrections, semantic content modifications, and
noise filtering. We demonstrate the usability of our system on several
animation editing use cases.
"
2366,Cut-and-Paste Neural Rendering,"  Cut-and-paste methods take an object from one image and insert it into
another. Doing so often results in unrealistic looking images because the
inserted object's shading is inconsistent with the target scene's shading.
Existing reshading methods require a geometric and physical model of the
inserted object, which is then rendered using environment parameters.
Accurately constructing such a model only from a single image is beyond the
current understanding of computer vision. We describe an alternative procedure
-- cut-and-paste neural rendering, to render the inserted fragment's shading
field consistent with the target scene. We use a Deep Image Prior (DIP) as a
neural renderer trained to render an image with consistent image decomposition
inferences. The resulting rendering from DIP should have an albedo consistent
with composite albedo; it should have a shading field that, outside the
inserted fragment, is the same as the target scene's shading field; and
composite surface normals are consistent with the final rendering's shading
field. The result is a simple procedure that produces convincing and realistic
shading. Moreover, our procedure does not require rendered images or
image-decomposition from real images in the training or labeled annotations. In
fact, our only use of simulated ground truth is our use of a pre-trained normal
estimator. Qualitative results are strong, supported by a user study comparing
against the state-of-the-art image harmonization baseline.
"
2367,TM-NET: Deep Generative Networks for Textured Meshes,"  We introduce TM-NET, a novel deep generative model capable of generating
meshes with detailed textures, as well as synthesizing plausible textures for a
given shape. To cope with complex geometry and structure, inspired by the
recently proposed SDM-NET, our method produces texture maps for individual
parts, each as a deformed box, which further leads to a natural UV map with
minimum distortions. To provide a generic framework for different application
scenarios, we encode geometry and texture separately and learn the texture
probability distribution conditioned on the geometry. We address challenges for
textured mesh generation by sampling textures on the conditional probability
distribution. Textures also often contain high-frequency details (e.g. wooden
texture), and we encode them effectively with a variational autoencoder (VAE)
using dictionary-based vector quantization. We also exploit the transparency in
the texture as an effective approach to modeling highly complicated topology
and geometry. This work is the first to synthesize high-quality textured meshes
for shapes with complex structures. Extensive experiments show that our method
produces high-quality textures, and avoids the inconsistency issue common for
novel view synthesis methods where textured shapes from different views are
generated separately.
"
2368,"Bayesian Spatio-Temporal Graph Convolutional Network for Traffic
  Forecasting","  In traffic forecasting, graph convolutional networks (GCNs), which model
traffic flows as spatio-temporal graphs, have achieved remarkable performance.
However, existing GCN-based methods heuristically define the graph structure as
the physical topology of the road network, ignoring potential dependence of the
graph structure over traffic data. And the defined graph structure is
deterministic, which lacks investigation of uncertainty. In this paper, we
propose a Bayesian Spatio-Temporal Graph Convolutional Network (BSTGCN) for
traffic prediction. The graph structure in our network is learned from the
physical topology of the road network and traffic data in an end-to-end manner,
which discovers a more accurate description of the relationship among traffic
flows. Moreover, a parametric generative model is proposed to represent the
graph structure, which enhances the generalization capability of GCNs. We
verify the effectiveness of our method on two real-world datasets, and the
experimental results demonstrate that BSTGCN attains superior performance
compared with state-of-the-art methods.
"
2369,Design and Fabrication of Elastic Geodesic Grid Structures,"  Elastic geodesic grids (EGG) are lightweight structures that can be easily
deployed to approximate designer provided free-form surfaces. In the initial
configuration the grids are perfectly flat, during deployment, though,
curvature is induced to the structure, as grid elements bend and twist. Their
layout is found geometrically, it is based on networks of geodesic curves on
free-form design-surfaces. Generating a layout with this approach encodes an
elasto-kinematic mechanism to the grid that creates the curved shape during
deployment. In the final state the grid can be fixed to supports and serve for
all kinds of purposes like free-form sub-structures, paneling, sun and rain
protectors, pavilions, etc. However, so far these structures have only been
investigated using small-scale desktop models. We investigate the scalability
of such structures, presenting a medium sized model. It was designed by an
architecture student without expert knowledge on elastic structures or
differential geometry, just using the elastic geodesic grids design-pipeline.
We further present a fabrication-process for EGG-models. They can be built
quickly and with a small budget.
"
2370,Reduced-Order Simulation of Flexible Meta-Materials,"  We propose a reduced-order simulation and optimization technique for a type
of digital materials which we denote as geometric meta-materials. They are
planar cellular structures, which can be fabricated in 2d and folded in 3d
space and thus well shaped into sophisticated 3d surfaces. They obtain their
elasticity attributes mainly from the geometry of their cellular elements and
their connections. While the physical properties of the base material (i.e.,
the physical substance) of course influence the behavior as well, our goal is
to factor them out. However, the simulation of such complex structures still
comes with a high computational cost. We propose an approach to reduce this
computational cost by abstracting the meso-structures and encoding the
properties of their elastic deformation behavior into a different set of
material parameters. We can thus obtain an approximation of the deformed
pattern by simulating a simplified version of the pattern using the computed
material parameters.
"
2371,"Training Data Generating Networks: Linking 3D Shapes and Few-Shot
  Classification","  We propose a novel 3d shape representation for 3d shape reconstruction from a
single image. Rather than predicting a shape directly, we train a network to
generate a training set which will be feed into another learning algorithm to
define the shape. Training data generating networks establish a link between
few-shot learning and 3d shape analysis. We propose a novel meta-learning
framework to jointly train the data generating network and other components. We
improve upon recent work on standard benchmarks for 3d shape reconstruction,
but our novel shape representation has many applications.
"
2372,Real-time High-Quality Rendering of Non-Rotating Black Holes,"  We propose a real-time method to render high-quality images of a non-rotating
black hole with an accretion disc and background stars. Our method is based on
beam tracing, but uses precomputed tables to find the intersections of each
curved light beam with the scene in constant time per pixel. It also uses a
specific texture filtering scheme to integrate the contribution of the light
sources to each beam. Our method is simple to implement and achieves high frame
rates.
"
2373,Discovering Pattern Structure Using Differentiable Compositing,"  Patterns, which are collections of elements arranged in regular or
near-regular arrangements, are an important graphic art form and widely used
due to their elegant simplicity and aesthetic appeal. When a pattern is encoded
as a flat image without the underlying structure, manually editing the pattern
is tedious and challenging as one has to both preserve the individual element
shapes and their original relative arrangements. State-of-the-art deep learning
frameworks that operate at the pixel level are unsuitable for manipulating such
patterns. Specifically, these methods can easily disturb the shapes of the
individual elements or their arrangement, and thus fail to preserve the latent
structures of the input patterns. We present a novel differentiable compositing
operator using pattern elements and use it to discover structures, in the form
of a layered representation of graphical objects, directly from raw pattern
images. This operator allows us to adapt current deep learning based image
methods to effectively handle patterns. We evaluate our method on a range of
patterns and demonstrate superiority in the context of pattern manipulations
when compared against state-of-the-art
"
2374,Light Stage Super-Resolution: Continuous High-Frequency Relighting,"  The light stage has been widely used in computer graphics for the past two
decades, primarily to enable the relighting of human faces. By capturing the
appearance of the human subject under different light sources, one obtains the
light transport matrix of that subject, which enables image-based relighting in
novel environments. However, due to the finite number of lights in the stage,
the light transport matrix only represents a sparse sampling on the entire
sphere. As a consequence, relighting the subject with a point light or a
directional source that does not coincide exactly with one of the lights in the
stage requires interpolation and resampling the images corresponding to nearby
lights, and this leads to ghosting shadows, aliased specularities, and other
artifacts. To ameliorate these artifacts and produce better results under
arbitrary high-frequency lighting, this paper proposes a learning-based
solution for the ""super-resolution"" of scans of human faces taken from a light
stage. Given an arbitrary ""query"" light direction, our method aggregates the
captured images corresponding to neighboring lights in the stage, and uses a
neural network to synthesize a rendering of the face that appears to be
illuminated by a ""virtual"" light source at the query location. This neural
network must circumvent the inherent aliasing and regularity of the light stage
data that was used for training, which we accomplish through the use of
regularized traditional interpolation methods within our network. Our learned
model is able to produce renderings for arbitrary light directions that exhibit
realistic shadows and specular highlights, and is able to generalize across a
wide variety of subjects.
"
2375,Studying Visualization Guidelines According to Grounded Theory,"  Visualization guidelines, if defined properly, are invaluable to both
practical applications and the theoretical foundation of visualization. In this
paper, we present a collection of research activities for studying
visualization guidelines according to Grounded Theory (GT). We used the
discourses at VisGuides, which is an online discussion forum for visualization
guidelines, as the main data source for enabling data-driven research processes
as advocated by the grounded theory methodology. We devised a categorization
scheme focusing on observing how visualization guidelines were featured in
different threads and posts at VisGuides, and coded all 248 posts between
September 27, 2017 (when VisGuides was first launched) and March 13, 2019. To
complement manual categorization and coding, we used text analysis and
visualization to help reveal patterns that may have been missed by the manual
effort and summary statistics. To facilitate theoretical sampling and negative
case analysis, we made an in-depth analysis of the 148 posts (with both
questions and replies) related to a student assignment of a visualization
course. Inspired by two discussion threads at VisGuides, we conducted two
controlled empirical studies to collect further data to validate specific
visualization guidelines. Through these activities guided by grounded theory,
we have obtained some new findings about visualization guidelines.
"
2376,A Convenient Generalization of Schlick's Bias and Gain Functions,"  We present a generalization of Schlick's bias and gain functions -- simple
parametric curve-shaped functions for inputs in [0, 1]. Our single function
includes both bias and gain as special cases, and is able to describe other
smooth and monotonic curves with variable degrees of asymmetry.
"
2377,GAMesh: Guided and Augmented Meshing for Deep Point Networks,"  We present a new meshing algorithm called guided and augmented meshing,
GAMesh, which uses a mesh prior to generate a surface for the output points of
a point network. By projecting the output points onto this prior and
simplifying the resulting mesh, GAMesh ensures a surface with the same topology
as the mesh prior but whose geometric fidelity is controlled by the point
network. This makes GAMesh independent of both the density and distribution of
the output points, a common artifact in traditional surface reconstruction
algorithms. We show that such a separation of geometry from topology can have
several advantages especially in single-view shape prediction, fair evaluation
of point networks and reconstructing surfaces for networks which output sparse
point clouds. We further show that by training point networks with GAMesh, we
can directly optimize the vertex positions to generate adaptive meshes with
arbitrary topologies.
"
2378,The Anatomical Edutainer,"  Physical visualizations (i.e., data representations by means of physical
objects) have been used for many centuries in medical and anatomical education.
Recently, 3D printing techniques started also to emerge. Still, other medical
physicalizations that rely on affordable and easy-to-find materials are
limited, while smart strategies that take advantage of the optical properties
of our physical world have not been thoroughly investigated. We propose the
Anatomical Edutainer, a workflow to guide the easy, accessible, and affordable
generation of physicalizations for tangible, interactive anatomical
edutainment. The Anatomical Edutainer supports 2D printable and 3D foldable
physicalizations that change their visual properties (i.e., hues of the visible
spectrum) under colored lenses or colored lights, to reveal distinct anatomical
structures through user interaction.
"
2379,"Probabilistic Character Motion Synthesis using a Hierarchical Deep
  Latent Variable Model","  We present a probabilistic framework to generate character animations based
on weak control signals, such that the synthesized motions are realistic while
retaining the stochastic nature of human movement. The proposed architecture,
which is designed as a hierarchical recurrent model, maps each sub-sequence of
motions into a stochastic latent code using a variational autoencoder extended
over the temporal domain. We also propose an objective function which respects
the impact of each joint on the pose and compares the joint angles based on
angular distance. We use two novel quantitative protocols and human qualitative
assessment to demonstrate the ability of our model to generate convincing and
diverse periodic and non-periodic motion sequences without the need for strong
control signals.
"
2380,An Evaluation Testbed for Locomotion in Virtual Reality,"  A common operation performed in Virtual Reality (VR) environments is
locomotion. Although real walking can represent a natural and intuitive way to
manage displacements in such environments, its use is generally limited by the
size of the area tracked by the VR system (typically, the size of a room) or
requires expensive technologies to cover particularly extended settings. A
number of approaches have been proposed to enable effective explorations in VR,
each characterized by different hardware requirements and costs, and capable to
provide different levels of usability and performance. However, the lack of a
well-defined methodology for assessing and comparing available approaches makes
it difficult to identify, among the various alternatives, the best solutions
for selected application domains. To deal with this issue, this paper
introduces a novel evaluation testbed which, by building on the outcomes of
many separate works reported in the literature, aims to support a comprehensive
analysis of the considered design space. An experimental protocol for
collecting objective and subjective measures is proposed, together with a
scoring system able to rank locomotion approaches based on a weighted set of
requirements. Testbed usage is illustrated in a use case requesting to select
the technique to adopt in a given application scenario.
"
2381,Image-Driven Furniture Style for Interactive 3D Scene Modeling,"  Creating realistic styled spaces is a complex task, which involves design
know-how for what furniture pieces go well together. Interior style follows
abstract rules involving color, geometry and other visual elements. Following
such rules, users manually select similar-style items from large repositories
of 3D furniture models, a process which is both laborious and time-consuming.
We propose a method for fast-tracking style-similarity tasks, by learning a
furniture's style-compatibility from interior scene images. Such images contain
more style information than images depicting single furniture. To understand
style, we train a deep learning network on a classification task. Based on
image embeddings extracted from our network, we measure stylistic compatibility
of furniture. We demonstrate our method with several 3D model
style-compatibility results, and with an interactive system for modeling
style-consistent scenes.
"
2382,"MINVO Basis: Finding Simplexes with Minimum Volume Enclosing Polynomial
  Curves","  Outer polyhedral representations of a given polynomial curve are extensively
exploited in computer graphics rendering, computer gaming, path planning for
robots, and finite element simulations. B\'ezier curves (which use the
Bernstein basis) or B-Splines are a very common choice for these polyhedral
representations because their non-negativity and partition-of-unity properties
guarantee that each interval of the curve is contained inside the convex hull
of its control points. However, the convex hull provided by these bases is not
the one with smallest volume, producing therefore undesirable levels of
conservatism in all of the applications mentioned above. This paper presents
the MINVO basis, a polynomial basis that generates the smallest $n$-simplex
that encloses any given $n^\text{th}$-order polynomial curve. The results
obtained for $n=3$ show that, for any given $3^{\text{rd}}$-order polynomial
curve, the MINVO basis is able to obtain an enclosing simplex whose volume is
$2.36$ and $254.9$ times smaller than the ones obtained by the Bernstein and
B-Spline bases, respectively. When $n=7$, these ratios increase to $902.7$ and
$2.997\cdot10^{21}$, respectively.
"
2383,SEG-MAT: 3D Shape Segmentation Using Medial Axis Transform,"  Segmenting arbitrary 3D objects into constituent parts that are structurally
meaningful is a fundamental problem encountered in a wide range of computer
graphics applications. Existing methods for 3D shape segmentation suffer from
complex geometry processing and heavy computation caused by using low-level
features and fragmented segmentation results due to the lack of global
consideration. We present an efficient method, called SEG-MAT, based on the
medial axis transform (MAT) of the input shape. Specifically, with the rich
geometrical and structural information encoded in the MAT, we are able to
develop a simple and principled approach to effectively identify the various
types of junctions between different parts of a 3D shape. Extensive evaluations
and comparisons show that our method outperforms the state-of-the-art methods
in terms of segmentation quality and is also one order of magnitude faster.
"
2384,Tackling problems of marker-based augmented reality under water,"  Underwater sites are a harsh environment for augmented reality applications.
Obstacles that must be battled include poor visibility conditions, difficult
navigation, and hard manipulation with devices under water. This chapter
focuses on the problem of localizing a device under water using markers. It
discusses various filters that enhance and improve images recorded under water,
and their impact on marker-based tracking. It presents various combinations of
10 image improving algorithms and 4 marker detecting algorithms, and tests
their performance in real situations. All solutions are designed to run
real-time on mobile devices to provide a solid basis for augmented reality.
Usability of this solution is evaluated on locations in Mediterranean Sea. It
is shown that image improving algorithms with carefully chosen parameters can
reduce the problems with visibility under water and improve the detection of
markers. The best results are obtained with marker detecting algorithms that
are specifically designed for underwater environments.
"
2385,"Investigating Cultural Aspects in the Fundamental Diagram using
  Convolutional Neural Networks and Simulation","  This paper presents a study regarding group behavior in a controlled
experiment focused on differences in an important attribute that vary across
cultures -- the personal spaces -- in two Countries: Brazil and Germany. In
order to coherently compare Germany and Brazil evolutions with same population
applying same task, we performed the pedestrian Fundamental Diagram experiment
in Brazil, as performed in Germany. We use CNNs to detect and track people in
video sequences. With this data, we use Voronoi Diagrams to find out the
neighbor relation among people and then compute the walking distances to find
out the personal spaces. Based on personal spaces analyses, we found out that
people behavior is more similar, in terms of their behaviours, in high dense
populations and vary more in low and medium densities. So, we focused our study
on cultural differences between the two Countries in low and medium densities.
Results indicate that personal space analyses can be a relevant feature in
order to understand cultural aspects in video sequences. In addition to the
cultural differences, we also investigate the personality model in crowds,
using OCEAN. We also proposed a way to simulate the FD experiment from other
countries using the OCEAN psychological traits model as input. The simulated
countries were consistent with the literature.
"
2386,A Characterization of 3D Printability,"  Additive manufacturing technologies are positioned to provide an
unprecedented innovative transformation in how products are designed and
manufactured. Due to differences in the technical specifications of AM
technologies, the final fabricated parts can vary significantly from the
original CAD models, therefore raising issues regarding accuracy, surface
finish, robustness, mechanical properties, functional and geometrical
constraints. Various researchers have studied the correlation between AM
technologies and design rules.
  In this work we propose a novel approach to assessing the capability of a 3D
model to be printed successfully (a.k.a printability) on a specific AM machine.
This is utilized by taking into consideration the model mesh complexity and
certain part characteristics. A printability score is derived for a model in
reference to a specific 3D printing technology, expressing the probability of
obtaining a robust and accurate end result for 3D printing on a specific AM
machine. The printability score can be used either to determine which 3D
technology is more suitable for manufacturing a specific model or as a guide to
redesign the model to ensure printability. We verify this framework by
conducting 3D printing experiments for benchmark models which are printed on
three AM machines employing different technologies: Fused Deposition Modeling
(FDM), Binder Jetting (3DP), and Material Jetting (Polyjet).
"
2387,Diptychs of human and machine perceptions,"  We propose visual creations that put differences in algorithms and humans
\emph{perceptions} into perspective. We exploit saliency maps of neural
networks and visual focus of humans to create diptychs that are
reinterpretations of an original image according to both machine and human
attentions. Using those diptychs as a qualitative evaluation of perception, we
discuss some crucial issues of current \textit{task-oriented} artificial
intelligence.
"
2388,"Optimal Textures: Fast and Robust Texture Synthesis and Style Transfer
  through Optimal Transport","  This paper presents a light-weight, high-quality texture synthesis algorithm
that easily generalizes to other applications such as style transfer and
texture mixing. We represent texture features through the deep neural
activation vectors within the bottleneck layer of an auto-encoder and frame the
texture synthesis problem as optimal transport between the activation values of
the image being synthesized and those of an exemplar texture. To find this
optimal transport mapping, we utilize an N-dimensional probability density
function (PDF) transfer process that iterates over multiple random rotations of
the PDF basis and matches the 1D marginal distributions across each dimension.
This achieves quality and flexibility on par with expensive back-propagation
based neural texture synthesis methods, but with the potential of achieving
interactive rates. We demonstrate that first order statistics offer a more
robust representation for texture than the second order statistics that are
used today. We propose an extension of this algorithm that reduces the
dimensionality of the neural feature space. We utilize a multi-scale
coarse-to-fine synthesis pyramid to capture and preserve larger image features;
unify color and style transfer under one framework; and further augment this
system with a novel masking scheme that re-samples and re-weights the feature
distribution for user-guided texture painting and targeted style transfer.
"
2389,papaya2: 2D Irreducible Minkowski Tensor computation,"  A common challenge in scientific and technical domains is the quantitative
description of geometries and shapes, e.g. in the analysis of microscope
imagery or astronomical observation data. Frequently, it is desirable to go
beyond scalar shape metrics such as porosity and surface to volume ratios
because the samples are anisotropic or because direction-dependent quantities
such as conductances or elasticity are of interest. Minkowski Tensors are a
systematic family of versatile and robust higher-order shape descriptors that
allow for shape characterization of arbitrary order and promise a path to
systematic structure-function relationships for direction-dependent properties.
Papaya2 is a software to calculate 2D higher-order shape metrics with a library
interface, support for Irreducible Minkowski Tensors and interpolated marching
squares. Extensions to Matlab, JavaScript and Python are provided as well.
While the tensor of inertia is computed by many tools, we are not aware of
other open-source software which provides higher-rank shape characterization in
2D.
"
2390,Free-boundary conformal parameterization of point clouds,"  With the advancement in 3D scanning technology, there has been a surge of
interest in the use of point clouds in science and engineering. To facilitate
the computations and analyses of point clouds, prior works have considered
parameterizing them onto some simple planar domains with a fixed boundary shape
such as a unit circle or a rectangle. However, the geometry of the fixed shape
may lead to some undesirable distortion in the parameterization. It is
therefore more natural to consider free-boundary conformal parameterizations of
point clouds, which minimize the local geometric distortion of the mapping
without constraining the overall shape. In this work, we propose a novel
approximation scheme of the Laplace--Beltrami operator on point clouds and
utilize it for developing a free-boundary conformal parameterization method for
disk-type point clouds. With the aid of the free-boundary conformal
parameterization, high-quality point cloud meshing can be easily achieved.
Furthermore, we show that using the idea of conformal welding in complex
analysis, the point cloud conformal parameterization can be computed in a
divide-and-conquer manner. Experimental results are presented to demonstrate
the effectiveness of the proposed method.
"
2391,Ray-marching Thurston geometries,"  We describe algorithms that produce accurate real-time interactive in-space
views of the eight Thurston geometries using ray-marching. We give a
theoretical framework for our algorithms, independent of the geometry involved.
In addition to scenes within a geometry $X$, we also consider scenes within
quotient manifolds and orbifolds $X / \Gamma$. We adapt the Phong lighting
model to non-euclidean geometries. The most difficult part of this is the
calculation of light intensity, which relates to the area density of geodesic
spheres. We also give extensive practical details for each geometry.
"
2392,Unsupervised Monocular Depth Learning in Dynamic Scenes,"  We present a method for jointly training the estimation of depth, ego-motion,
and a dense 3D translation field of objects relative to the scene, with
monocular photometric consistency being the sole source of supervision. We show
that this apparently heavily underdetermined problem can be regularized by
imposing the following prior knowledge about 3D translation fields: they are
sparse, since most of the scene is static, and they tend to be constant for
rigid moving objects. We show that this regularization alone is sufficient to
train monocular depth prediction models that exceed the accuracy achieved in
prior work for dynamic scenes, including methods that require semantic input.
Code is at
https://github.com/google-research/google-research/tree/master/depth_and_motion_learning .
"
2393,Virtual reality simulations of curved spaces,"  Previous virtual-reality simulations of curved space, which typically present
honeycombs or other periodic structures, have proven effective in letting
mathematicians experience curved space directly. By contrast, for students and
other non-mathematicians, a game like Non-Euclidean Billiards is more effective
because it gives students not just something to see, but also something to do
in the curved space. However, such simulations encounter a geometrical problem:
they must track the player's hands as well as her head, and in curved space the
effects of holonomy would quickly lead to violations of body coherence. This
is, what the player sees with her eyes would disagree with what she feels with
her hands. The present article presents a solution to the body coherence
problem, as well as several other questions that arise in interactive VR
simulations in curved space.
"
2394,Visualization of Technical and Tactical Characteristics in Fencing,"  Fencing is a sport that relies heavily on the use of tactics. However, most
existing methods for analyzing fencing data are based on statistical models in
which hidden patterns are difficult to discover. Unlike sequential games, such
as tennis and table tennis, fencing is a type of simultaneous game. Thus, the
existing methods on the sports visualization do not operate well for fencing
matches. In this study, we cooperated with experts to analyze the technical and
tactical characteristics of fencing competitions. To meet the requirements of
the fencing experts, we designed and implemented FencingVis, an interactive
visualization system for fencing competition data.The action sequences in the
bout are first visualized by modified bar charts to reveal the actions of
footworks and bladeworks of both fencers. Then an interactive technique is
provided for exploring the patterns of behavior of fencers. The different
combinations of tactical behavior patterns are further mapped to the graph
model and visualized by a tactical flow graph. This graph can reveal the
different strategies adopted by both fencers and their mutual influence in one
bout. We also provided a number of well-coordinated views to supplement the
tactical flow graph and display the information of the fencing competition from
different perspectives. The well-coordinated views are meant to organically
integrate with the tactical flow graph through consistent visual style and view
coordination. We demonstrated the usability and effectiveness of the proposed
system with three case studies. On the basis of expert feedback, FencingVis can
help analysts find not only the tactical patterns hidden in fencing bouts, but
also the technical and tactical characteristics of the contestant.
"
2395,"Uncertainty-Oriented Ensemble Data Visualization and Exploration using
  Variable Spatial Spreading","  As an important method of handling potential uncertainties in numerical
simulations, ensemble simulation has been widely applied in many disciplines.
Visualization is a promising and powerful ensemble simulation analysis method.
However, conventional visualization methods mainly aim at data simplification
and highlighting important information based on domain expertise instead of
providing a flexible data exploration and intervention mechanism.
Trial-and-error procedures have to be repeatedly conducted by such approaches.
To resolve this issue, we propose a new perspective of ensemble data analysis
using the attribute variable dimension as the primary analysis dimension.
Particularly, we propose a variable uncertainty calculation method based on
variable spatial spreading. Based on this method, we design an interactive
ensemble analysis framework that provides a flexible interactive exploration of
the ensemble data. Particularly, the proposed spreading curve view, the region
stability heat map view, and the temporal analysis view, together with the
commonly used 2D map view, jointly support uncertainty distribution perception,
region selection, and temporal analysis, as well as other analysis
requirements. We verify our approach by analyzing a real-world ensemble
simulation dataset. Feedback collected from domain experts confirms the
efficacy of our framework.
"
2396,"PCEDNet : A Neural Network for Fast and Efficient Edge Detection in 3D
  Point Clouds","  In recent years, Convolutional Neural Networks (CNN) have proven to be
efficient analysis tools for processing point clouds, e.g., for reconstruction,
segmentation and classification. In this paper, we focus on the classification
of edges in point clouds, where both edges and their surrounding are described.
We propose a new parameterization adding to each point a set of differential
information on its surrounding shape reconstructed at different scales. These
parameters, stored in a Scale-Space Matrix (SSM), provide a well suited
information from which an adequate neural network can learn the description of
edges and use it to efficiently detect them in acquired point clouds. After
successfully applying a multi-scale CNN on SSMs for the efficient
classification of edges and their neighborhood, we propose a new neural network
architecture outperforming the CNN in learning time, processing time and
classification capabilities. Our architecture is compact, requires small
learning sets, is very fast to train and classifies millions of points in
seconds.
"
2397,"Palette diagram: A Python package for visualization of collective
  categorical data","  Categorical data, wherein a numerical quantity is assigned to each category
(nominal variable), are ubiquitous in data science. A palette diagram is a
visualization tool for a large number of categorical datasets, each comprising
several categories.
"
2398,"An Empirical-cum-Statistical Approach to Power-Performance
  Characterization of Concurrent GPU Kernels","  Growing deployment of power and energy efficient throughput accelerators
(GPU) in data centers demands enhancement of power-performance co-optimization
capabilities of GPUs. Realization of exascale computing using accelerators
requires further improvements in power efficiency. With hardwired kernel
concurrency enablement in accelerators, inter- and intra-workload simultaneous
kernels computation predicts increased throughput at lower energy budget. To
improve Performance-per-Watt metric of the architectures, a systematic
empirical study of real-world throughput workloads (with concurrent kernel
execution) is required. To this end, we propose a multi-kernel throughput
workload generation framework that will facilitate aggressive energy and
performance management of exascale data centers and will stimulate synergistic
power-performance co-optimization of throughput architectures. Also, we
demonstrate a multi-kernel throughput benchmark suite based on the framework
that encapsulates symmetric, asymmetric and co-existing (often appears
together) kernel based workloads. On average, our analysis reveals that spatial
and temporal concurrency within kernel execution in throughput architectures
saves energy consumption by 32%, 26% and 33% in GTX470, Tesla M2050 and Tesla
K20 across 12 benchmarks. Concurrency and enhanced utilization are often
correlated but do not imply significant deviation in power dissipation.
Diversity analysis of proposed multi-kernels confirms characteristic variation
and power-profile diversity within the suite. Besides, we explain several
findings regarding power-performance co-optimization of concurrent throughput
workloads.
"
2399,"Hypersim: A Photorealistic Synthetic Dataset for Holistic Indoor Scene
  Understanding","  For many fundamental scene understanding tasks, it is difficult or impossible
to obtain per-pixel ground truth labels from real images. We address this
challenge by introducing Hypersim, a photorealistic synthetic dataset for
holistic indoor scene understanding. To create our dataset, we leverage a large
repository of synthetic scenes created by professional artists, and we generate
77,400 images of 461 indoor scenes with detailed per-pixel labels and
corresponding ground truth geometry. Our dataset: (1) relies exclusively on
publicly available 3D assets; (2) includes complete scene geometry, material
information, and lighting information for every scene; (3) includes dense
per-pixel semantic instance segmentations for every image; and (4) factors
every image into diffuse reflectance, diffuse illumination, and a non-diffuse
residual term that captures view-dependent lighting effects. Together, these
features make our dataset well-suited for geometric learning problems that
require direct 3D supervision, multi-task learning problems that require
reasoning jointly over multiple input and output modalities, and inverse
rendering problems. We analyze our dataset at the level of scenes, objects, and
pixels, and we analyze costs in terms of money, annotation effort, and
computation time. Remarkably, we find that it is possible to generate our
entire dataset from scratch, for roughly half the cost of training a
state-of-the-art natural language processing model. All the code we used to
generate our dataset is available online.
"
2400,"Learning Multiple-Scattering Solutions for Sphere-Tracing of Volumetric
  Subsurface Effects","  Accurate subsurface scattering solutions require the integration of optical
material properties along many complicated light paths. We present a method
that learns a simple geometric approximation of random paths in a homogeneous
volume of translucent material. The generated representation allows determining
the absorption along the path as well as a direct lighting contribution, which
is representative of all scattering events along the path. A sequence of
conditional variational auto-encoders (CVAEs) is trained to model the
statistical distribution of the photon paths inside a spherical region in
presence of multiple scattering events. A first CVAE learns to sample the
number of scattering events, occurring on a ray path inside the sphere, which
effectively determines the probability of the ray being absorbed. Conditioned
on this, a second model predicts the exit position and direction of the light
particle. Finally, a third model generates a representative sample of photon
position and direction along the path, which is used to approximate the
contribution of direct illumination due to in-scattering. To accelerate the
tracing of the light path through the volumetric medium toward the solid
boundary, we employ a sphere-tracing strategy that considers the light
absorption and is able to perform statistically accurate next-event estimation.
We demonstrate efficient learning using shallow networks of only three layers
and no more than 16 nodes. In combination with a GPU shader that evaluates the
CVAEs' predictions, performance gains can be demonstrated for a variety of
different scenarios. A quality evaluation analyzes the approximation error that
is introduced by the data-driven scattering simulation and sheds light on the
major sources of error in the accelerated path tracing process.
"
2401,"Mapper Interactive: A Scalable, Extendable, and Interactive Toolbox for
  the Visual Exploration of High-Dimensional Data","  Mapper algorithm is a popular tool from topological data analysis for
extracting topological summaries of high-dimensional datasets. It has enjoyed
great success in data science, from shape classification to cancer research and
sports analytics. In this paper, we present Mapper Interactive, a web-based
framework for the interactive analysis and visualization of high-dimensional
point cloud data built upon the mapper algorithm. Different from existing
implementations, Mapper Interactive implements the mapper algorithm in an
interactive, scalable, and easily extendable way, thus supporting practical
data analysis. In particular, its command-line API can compute mapper graphs
for 1 million points of 512 dimensions in about 3 minutes (6 times faster than
the vanilla implementation). Its visual interface allows on-the-fly computation
and manipulation of the mapper graph based on user-specified parameters and
supports the addition of new analysis modules with a few lines of code. Mapper
Interactive makes the mapper algorithm accessible to nonspecialists and
accelerates topological analysis workflows.
"
2402,Modular Primitives for High-Performance Differentiable Rendering,"  We present a modular differentiable renderer design that yields performance
superior to previous methods by leveraging existing, highly optimized hardware
graphics pipelines. Our design supports all crucial operations in a modern
graphics pipeline: rasterizing large numbers of triangles, attribute
interpolation, filtered texture lookups, as well as user-programmable shading
and geometry processing, all in high resolutions. Our modular primitives allow
custom, high-performance graphics pipelines to be built directly within
automatic differentiation frameworks such as PyTorch or TensorFlow. As a
motivating application, we formulate facial performance capture as an inverse
rendering problem and show that it can be solved efficiently using our tools.
Our results indicate that this simple and straightforward approach achieves
excellent geometric correspondence between rendered results and reference
imagery.
"
2403,"Flexible Virtual Reality System for Neurorehabilitation and Quality of
  Life Improvement","  As life expectancy is mostly increasing, the incidence of many neurological
disorders is also constantly growing. For improving the physical functions
affected by a neurological disorder, rehabilitation procedures are mandatory,
and they must be performed regularly. Unfortunately, neurorehabilitation
procedures have disadvantages in terms of costs, accessibility and a lack of
therapists. This paper presents Immersive Neurorehabilitation Exercises Using
Virtual Reality (INREX-VR), our innovative immersive neurorehabilitation system
using virtual reality. The system is based on a thorough research methodology
and is able to capture real-time user movements and evaluate joint mobility for
both upper and lower limbs, record training sessions and save electromyography
data. The use of the first-person perspective increases immersion, and the
joint range of motion is calculated with the help of both the HTC Vive system
and inverse kinematics principles applied on skeleton rigs. Tutorial exercises
are demonstrated by a virtual therapist, as they were recorded with real-life
physicians, and sessions can be monitored and configured through tele-medicine.
Complex movements are practiced in gamified settings, encouraging
self-improvement and competition. Finally, we proposed a training plan and
preliminary tests which show promising results in terms of accuracy and user
feedback. As future developments, we plan to improve the system's accuracy and
investigate a wireless alternative based on neural networks.
"
2404,Learning Human Search Behavior from Egocentric Visual Inputs,"  ""Looking for things"" is a mundane but critical task we repeatedly carry on in
our daily life. We introduce a method to develop a human character capable of
searching for a randomly located target object in a detailed 3D scene using its
locomotion capability and egocentric vision perception represented as RGBD
images. By depriving the privileged 3D information from the human character, it
is forced to move and look around simultaneously to account for the restricted
sensing capability, resulting in natural navigation and search behaviors. Our
method consists of two components: 1) a search control policy based on an
abstract character model, and 2) an online replanning control module for
synthesizing detailed kinematic motion based on the trajectories planned by the
search policy. We demonstrate that the combined techniques enable the character
to effectively find often occluded household items in indoor environments. The
same search policy can be applied to different full-body characters without the
need for retraining. We evaluate our method quantitatively by testing it on
randomly generated scenarios. Our work is a first step toward creating
intelligent virtual agents with humanlike behaviors driven by onboard sensors,
paving the road toward future robotic applications.
"
2405,"Unmasking Communication Partners: A Low-Cost AI Solution for Digitally
  Removing Head-Mounted Displays in VR-Based Telepresence","  Face-to-face conversation in Virtual Reality (VR) is a challenge when
participants wear head-mounted displays (HMD). A significant portion of a
participant's face is hidden and facial expressions are difficult to perceive.
Past research has shown that high-fidelity face reconstruction with personal
avatars in VR is possible under laboratory conditions with high-cost hardware.
In this paper, we propose one of the first low-cost systems for this task which
uses only open source, free software and affordable hardware. Our approach is
to track the user's face underneath the HMD utilizing a Convolutional Neural
Network (CNN) and generate corresponding expressions with Generative
Adversarial Networks (GAN) for producing RGBD images of the person's face. We
use commodity hardware with low-cost extensions such as 3D-printed mounts and
miniature cameras. Our approach learns end-to-end without manual intervention,
runs in real time, and can be trained and executed on an ordinary gaming
computer. We report evaluation results showing that our low-cost system does
not achieve the same fidelity of research prototypes using high-end hardware
and closed source software, but it is capable of creating individual facial
avatars with person-specific characteristics in movements and expressions.
"
2406,"LCollision: Fast Generation of Collision-Free Human Poses using Learned
  Non-Penetration Constraints","  We present a learning-based method (LCollision) that synthesizes
collision-free 3D human poses. At the crux of our approach is a novel deep
architecture that simultaneously decodes new human poses from the latent space
and classifies the collision status. These two components of our architecture
are used as the objective function and surrogate hard-constraints in a
constrained-optimization algorithm for collision-free human pose generation. A
novel aspect of our approach is the use of a bilevel autoencoder that
decomposes whole-body collisions into groups of collisions between localized
body parts. We show that solving our constrained optimization formulation can
resolve significantly more collision artifacts than prior learning algorithms.
Furthermore, in a large test set of $2.5\times 10^6$ randomized poses from
three major datasets, our architecture achieves a collision-prediction accuracy
of $94.1\%$ with $80\times$ speedup over exact collision detection algorithms.
To the best of our knowledge, LCollision is the first approach that can obtain
high accuracy in terms of handling non-penetration and collision constraints in
a learning framework.
"
2407,"Interactive digital storytelling: bringing cultural heritage in a
  classroom","  Interactive digital storytelling becomes a popular choice for information
presentation in many fields. Its application spans from media industry and
business information visualization, through digital cultural heritage, serious
games, education, to contemporary theater and visual arts. The benefits of this
form of multimedia presentation in education are generally recognized, and
several studies exploring and supporting the opinion are conducted. In addition
to discussing the benefits, we wanted to address the challenges in introducing
interactive digital storytelling and serious games in the classroom. The
challenge of inherent ambiguity of edutainment, due to opposing features of
education and entertainment is augmented with different viewpoints of
multidisciplinary team members. We specifically address the opposing views on
artistic liberty, at one side, and technical constraints and historic facts, on
the other side. In this paper we present the first findings related to these
questions and to initiate furthering discussions in this area.
"
2408,Fourier-based and Rational Graph Filters for Spectral Processing,"  Data are represented as graphs in a wide range of applications, such as
Computer Vision (e.g., images) and Graphics (e.g., 3D meshes), network analysis
(e.g., social networks), and bio-informatics (e.g., molecules). In this
context, our overall goal is the definition of novel Fourier-based and graph
filters induced by rational polynomials for graph processing, which generalise
polynomial filters and the Fourier transform to non-Euclidean domains. For the
efficient evaluation of discrete spectral Fourier-based and wavelet operators,
we introduce a spectrum-free approach, which requires the solution of a small
set of sparse, symmetric, well-conditioned linear systems and is oblivious of
the evaluation of the Laplacian or kernel spectrum. Approximating arbitrary
graph filters with rational polynomials provides a more accurate and
numerically stable alternative with respect to polynomials. To achieve these
goals, we also study the link between spectral operators, wavelets, and
filtered convolution with integral operators induced by spectral kernels.
According to our tests, main advantages of the proposed approach are (i) its
generality with respect to the input data (e.g., graphs, 3D shapes),
applications (e.g., signal reconstruction and smoothing, shape correspondence),
and filters (e.g., polynomial, rational polynomial), and (ii) a spectrum-free
computation with a generally low computational cost and storage overhead.
"
2409,Fast Fourier Intrinsic Network,"  We address the problem of decomposing an image into albedo and shading. We
propose the Fast Fourier Intrinsic Network, FFI-Net in short, that operates in
the spectral domain, splitting the input into several spectral bands. Weights
in FFI-Net are optimized in the spectral domain, allowing faster convergence to
a lower error. FFI-Net is lightweight and does not need auxiliary networks for
training. The network is trained end-to-end with a novel spectral loss which
measures the global distance between the network prediction and corresponding
ground truth. FFI-Net achieves state-of-the-art performance on MPI-Sintel, MIT
Intrinsic, and IIW datasets.
"
2410,"Similarity-Based Clustering for Enhancing Image Classification
  Architectures","  Convolutional networks are at the center of best in class computer vision
applications for a wide assortment of undertakings. Since 2014, profound amount
of work began to make better convolutional architectures, yielding generous
additions in different benchmarks. Albeit expanded model size and computational
cost will, in general, mean prompt quality increases for most undertakings but,
the architectures now need to have some additional information to increase the
performance. We show empirical evidence that with the amalgamation of
content-based image similarity and deep learning models, we can provide the
flow of information which can be used in making clustered learning possible. We
show how parallel training of sub-dataset clusters not only reduces the cost of
computation but also increases the benchmark accuracies by 5-11 percent.
"
2411,Spring-Rod System Identification via Differentiable Physics Engine,"  We propose a novel differentiable physics engine for system identification of
complex spring-rod assemblies. Unlike black-box data-driven methods for
learning the evolution of a dynamical system \emph{and} its parameters, we
modularize the design of our engine using a discrete form of the governing
equations of motion, similar to a traditional physics engine. We further reduce
the dimension from 3D to 1D for each module, which allows efficient learning of
system parameters using linear regression. The regression parameters correspond
to physical quantities, such as spring stiffness or the mass of the rod, making
the pipeline explainable. The approach significantly reduces the amount of
training data required, and also avoids iterative identification of data
sampling and model training. We compare the performance of the proposed engine
with previous solutions, and demonstrate its efficacy on tensegrity systems,
such as NASA's icosahedron.
"
2412,"An End-to-End Differentiable but Explainable Physics Engine for
  Tensegrity Robots: Modeling and Control","  This work proposes an end-to-end differentiable physics engine for tensegrity
robots, which introduces a data-efficient linear contact model for accurately
predicting collision responses that arise due to contacting surfaces, and a
linear actuator model that can drive these robots by expanding and contracting
their flexible cables. To the best of the authors' knowledge, this is the
\emph{first} differentiable physics engine for tensegrity robots that supports
cable modeling, contact, and actuation. This engine can be used inside an
off-the-shelf, RL-based locomotion controller in order to provide training
examples. This paper proposes a progressive training pipeline for the
differentiable physics engine that helps avoid local optima during the training
phase and reduces data requirements. It demonstrates the data-efficiency
benefits of using the differentiable engine for learning locomotion policies
for NASA's icosahedron SUPERballBot. In particular, after the engine has been
trained with few trajectories to match a ground truth simulated model, then a
policy learned on the differentiable engine is shown to be transferable back to
the ground-truth model. Training the controller requires orders of magnitude
more data than training the differential engine.
"
2413,Topology of Frame Field Design for Hex Meshing,"  In the past decade frame fields have emerged as a promising approach for
generating hexahedral meshes for CFD and CAE applications. One important
problem asks for construction of a boundary-aligned frame field with prescribed
singularity constraints over a volume that corresponds to a valid hexahedral
mesh. We give a necessary and sufficient condition in terms of solutions to a
system of monomial equations with variables in the binary octahedral group when
a boundary frame field and singularity graph have been fixed. This is phrased
with respect to general $CW$-decompositions of the volume, which allows some
flexibility in simplifying these systems. Along the way we look at frame field
design from an algebraic topological perspective, proving various results, some
known, some new.
"
2414,"Sound Synthesis, Propagation, and Rendering: A Survey","  Sound, as a crucial sensory channel, plays a vital role in improving the
reality and immersiveness of a virtual environment, following only vision in
importance. Sound can provide important clues such as sound directionality and
spatial size. This paper gives a broad overview of research works on sound
simulation in virtual reality, games, multimedia, computer-aided design. We
first survey various sound synthesis methods, including harmonic synthesis,
texture synthesis, spectral analysis, and physics-based synthesis. Then, we
summarize popular sound propagation techniques, namely wave-based methods,
geometric-based methods, and hybrid methods. Next, the sound rendering methods
are reviewed. We further demonstrate the latest deep learning based sound
simulation approaches. Finally, we point to some future directions of this
field. To the best of our knowledge, this is the first attempt to provide a
comprehensive summary of sound research in the field of computer graphics.
"
2415,Diffusion Structures for Architectural Stripe Pattern Generation,"  We present Diffusion Structures, a family of resilient shell structures from
the eigenfunctions of a pair of novel diffusion operators. This approach is
based on Michell's theorem but avoids expensive non-linear optimization with
computation that amounts to constructing and solving two generalized eigenvalue
problems to generate two sets of stripe patterns. This structure family can be
generated quickly, and navigated in real-time using a small number of tuneable
parameters.
"
2416,Slice and Dice: A Physicalization Workflow for Anatomical Edutainment,"  During the last decades, anatomy has become an interesting topic in
education---even for laymen or schoolchildren. As medical imaging techniques
become increasingly sophisticated, virtual anatomical education applications
have emerged. Still, anatomical models are often preferred, as they facilitate
3D localization of anatomical structures. Recently, data physicalizations
(i.e., physical visualizations) have proven to be effective and
engaging---sometimes, even more than their virtual counterparts. So far,
medical data physicalizations involve mainly 3D printing, which is still
expensive and cumbersome. We investigate alternative forms of physicalizations,
which use readily available technologies (home printers) and inexpensive
materials (paper or semi-transparent films) to generate crafts for anatomical
edutainment. To the best of our knowledge, this is the first computer-generated
crafting approach within an anatomical edutainment context. Our approach
follows a cost-effective, simple, and easy-to-employ workflow, resulting in
assemblable data sculptures (i.e., semi-transparent sliceforms). It primarily
supports volumetric data (such as CT or MRI), but mesh data can also be
imported. An octree slices the imported volume and an optimization step
simplifies the slice configuration, proposing the optimal order for easy
assembly. A packing algorithm places the resulting slices with their labels,
annotations, and assembly instructions on a paper or transparent film of
user-selected size, to be printed, assembled into a sliceform, and explored. We
conducted two user studies to assess our approach, demonstrating that it is an
initial positive step towards the successful creation of interactive and
engaging anatomical physicalizations.
"
2417,"SHAD3S: A model to Sketch, Shade and Shadow","  Hatching is a common method used by artists to accentuate the third dimension
of a sketch, and to illuminate the scene. Our system SHAD3S attempts to compete
with a human at hatching generic three-dimensional (3D) shapes, and also tries
to assist her in a form exploration exercise. The novelty of our approach lies
in the fact that we make no assumptions about the input other than that it
represents a 3D shape, and yet, given a contextual information of illumination
and texture, we synthesise an accurate hatch pattern over the sketch, without
access to 3D or pseudo 3D. In the process, we contribute towards a) a cheap yet
effective method to synthesise a sufficiently large high fidelity dataset,
pertinent to task; b) creating a pipeline with conditional generative
adversarial network (CGAN); and c) creating an interactive utility with GIMP,
that is a tool for artists to engage with automated hatching or a
form-exploration exercise. User evaluation of the tool suggests that the model
performance does generalise satisfactorily over diverse input, both in terms of
style as well as shape. A simple comparison of inception scores suggest that
the generated distribution is as diverse as the ground truth.
"
2418,Designing Human-Robot Coexistence Space,"  When the human-robot interactions become ubiquitous, the environment
surrounding these interactions will have significant impact on the safety and
comfort of the human and the effectiveness and efficiency of the robot.
Although most robots are designed to work in the spaces created for humans,
many environments, such as living rooms and offices, can be and should be
redesigned to enhance and improve human-robot collaboration and interactions.
This work uses autonomous wheelchair as an example and investigates the
computational design in the human-robot coexistence spaces. Given the room size
and the objects $O$ in the room, the proposed framework computes the optimal
layouts of $O$ that satisfy both human preferences and navigation constraints
of the wheelchair. The key enabling technique is a motion planner that can
efficiently evaluate hundreds of similar motion planning problems. Our
implementation shows that the proposed framework can produce a design around
three to five minutes on average comparing to 10 to 20 minutes without the
proposed motion planner. Our results also show that the proposed method
produces reasonable designs even for tight spaces and for users with different
preferences.
"
2419,"Aquanims -- Area-Preserving Animated Transitions based on a Hydraulic
  Metaphor","  We propose ""Aquanims"" as new design metaphors for animated transitions that
preserve displayed areas during the transformation. As liquids are
incompressible fluids, we use a hydraulic metaphor to convey the sense of area
preservation during animated transitions. We study the design space of Aquanims
for rectangle-based charts.
"
2420,Conversion Between Bezier and Catmull-Rom Splines,"  Splines are one of the main methods of mathematically representing
complicated shapes, which have become the primary technique in computer
graphics for modeling complex surfaces. Among all, Bezier and Catmull-Rom
splines are of the most used in the subfields of engineering. In this document,
we focus on conversion of splines rather than going through the properties of
them, i.e, converting the control points of a spline to the control points of
another spline, which results in approximately the same curve, as the spline
before conversion represents.
"
2421,Normalized Weighting Schemes for Image Interpolation Algorithms,"  This paper presents and evaluates four weighting schemes for image
interpolation algorithms. The first scheme is based on the normalized area of
the circle, whose diameter is equal to the minimum side of a tetragon. The
second scheme is based on the normalized area of the circle, whose radius is
equal to the hypotenuse. The third scheme is based on the normalized area of
the triangle, whose base and height are equal to the hypotenuse and virtual
pixel length, respectively. The fourth weighting scheme is based on the
normalized area of the circle, whose radius is equal to the virtual pixel
length-based hypotenuse. Experiments demonstrated debatable algorithm
performances and the need for further research.
"
2422,Topology-Based Feature Design and Tracking for Multi-Center Cyclones,"  In this paper, we propose a concept to design, track, and compare
application-specific feature definitions expressed as sets of critical points.
Our work has been inspired by the observation that in many applications a large
variety of different feature definitions for the same concept are used. Often,
these definitions compete with each other and it is unclear which definition
should be used in which context. A prominent example is the definition of
cyclones in climate research. Despite the differences, frequently these feature
definitions can be related to topological concepts.
  In our approach, we provide a cyclone tracking framework that supports
interactive feature definition and comparison based on a precomputed tracking
graph that stores all extremal points as well as their temporal correspondents.
The framework combines a set of independent building blocks: critical point
extraction, critical point tracking, feature definition, and track exploration.
One of the major advantages of such an approach is the flexibility it provides,
that is, each block is exchangeable. Moreover, it also enables us to perform
the most expensive analysis, the construction of a full tracking graph, as a
prepossessing step, while keeping the feature definition interactive. Different
feature definitions can be explored and compared interactively based on this
tracking graph. Features are specified by rules for grouping critical points,
while feature tracking corresponds to filtering and querying the full tracking
graph by specific requests. We demonstrate this method for cyclone
identification and tracking in the context of climate research.
"
2423,"FTK: A High-Dimensional Simplicial Meshing Framework for Robust and
  Scalable Feature Tracking","  We present the Feature Tracking Kit (FTK), a framework that simplifies,
scales, and delivers various feature-tracking algorithms for scientific data.
The key of FTK is our high-dimensional simplicial meshing scheme that
generalizes both regular and unstructured spatial meshes to spacetime while
tessellating spacetime mesh elements into simplices. The benefits of using
simplicial spacetime meshes include (1) reducing ambiguity cases for feature
extraction and tracking, (2) simplifying the handling of degeneracies using
symbolic perturbations, and (3) enabling scalable and parallel processing. The
use of simplicial spacetime meshing simplifies and improves the implementation
of several feature-tracking algorithms for critical points, quantum vortices,
and isosurfaces. As a software framework, FTK provides end users with
VTK/ParaView filters, Python bindings, a command line interface, and
programming interfaces for feature-tracking applications. We demonstrate use
cases as well as scalability studies through both synthetic data and scientific
applications including Tokamak, fluid dynamics, and superconductivity
simulations. We also conduct end-to-end performance studies on the Summit
supercomputer. FTK is open-sourced under the MIT license:
https://github.com/hguo/ftk
"
2424,Deep Active Surface Models,"  Active Surface Models have a long history of being useful to model complex 3D
surfaces but only Active Contours have been used in conjunction with deep
networks, and then only to produce the data term as well as meta-parameter maps
controlling them. In this paper, we advocate a much tighter integration. We
introduce layers that implement them that can be integrated seamlessly into
Graph Convolutional Networks to enforce sophisticated smoothness priors at an
acceptable computational cost. We will show that the resulting Deep Active
Surface Models outperform equivalent architectures that use traditional
regularization loss terms to impose smoothness priors for 3D surface
reconstruction from 2D images and for 3D volume segmentation.
"
2425,Designing Game Feel. A Survey,"  Game feel design is the intentional design of the affective impact of
moment-to-moment interaction with games. In this paper we survey academic
research and publications by practitioners to give a complete overview of the
state of research concerning this aspect of game design, including context from
related areas. We analysed over 200 sources and categorised their content
according to the design purpose presented. This resulted in three different
domains of intended player experiences: physicality, amplification, and
support. In these domains, the act of polishing that determines game feel,
takes the shape of tuning, juicing, and streamlining respectively. Tuning the
physicality of game objects creates cohesion, predictability, and the resulting
movement informs many other design aspects. Juicing is the act of polishing
amplification and it results in empowerment and provides clarity of feedback by
communicating the importance of game events. Streamlining allows a game to act
on the intention of the player, supporting the execution of actions in the
game. These three design intents are the main means through which designers
control minute details of interactivity and inform the player's reaction. This
framework and its nuanced vocabulary can lead to an understanding of game feel
that is shared between practitioners and researchers as highlighted in the
concluding future research section.
"
2426,Assembling a Pipeline for 3D Face Interpolation,"  This paper describes a pipeline built with open source tools for
interpolating 3D facial expressions taken from images. The presented approach
allows anyone to create 3D face animations from 2 input photos: one from the
start face expression, and the other from the final face expression. Given the
input photos, corresponding 3D face models are constructed and texture-mapped
using the photos as textures aligned with facial features. Animations are then
generated by morphing the models by interpolation of the geometries and
textures of the models. This work was performed as a MS project at the
University of California, Merced.
"
2427,Bezier Curves Intersection Using Relief Perspective,"  Presented paper describes the method for finding the intersection of class
space rational Bezier curves. The problem curve/curve intersection belongs
among basic geometric problems and the aim of this article is to describe the
new technique to solve the problem using relief perspective and Bezier
clipping.
"
2428,Connectivity Compression for Irregular Quadrilateral Meshes,"  Applications that require Internet access to remote 3D datasets are often
limited by the storage costs of 3D models. Several compression methods are
available to address these limits for objects represented by triangle meshes.
Many CAD and VRML models, however, are represented as quadrilateral meshes or
mixed triangle/quadrilateral meshes, and these models may also require
compression. We present an algorithm for encoding the connectivity of such
quadrilateral meshes, and we demonstrate that by preserving and exploiting the
original quad structure, our approach achieves encodings 30 - 80% smaller than
an approach based on randomly splitting quads into triangles. We present both a
code with a proven worst-case cost of 3 bits per vertex (or 2.75 bits per
vertex for meshes without valence-two vertices) and entropy-coding results for
typical meshes ranging from 0.3 to 0.9 bits per vertex, depending on the
regularity of the mesh. Our method may be implemented by a rule for a
particular splitting of quads into triangles and by using the compression and
decompression algorithms introduced in [Rossignac99] and
[Rossignac&Szymczak99]. We also present extensions to the algorithm to compress
meshes with holes and handles and meshes containing triangles and other
polygons as well as quads.
"
2429,"A Fast General Methodology for Information-Theoretically Optimal
  Encodings of Graphs","  We propose a fast methodology for encoding graphs with
information-theoretically minimum numbers of bits. Specifically, a graph with
property pi is called a pi-graph. If pi satisfies certain properties, then an
n-node m-edge pi-graph G can be encoded by a binary string X such that (1) G
and X can be obtained from each other in O(n log n) time, and (2) X has at most
beta(n)+o(beta(n)) bits for any continuous super-additive function beta(n) so
that there are at most 2^{beta(n)+o(beta(n))} distinct n-node pi-graphs. The
methodology is applicable to general classes of graphs; this paper focuses on
planar graphs. Examples of such pi include all conjunctions over the following
groups of properties: (1) G is a planar graph or a plane graph; (2) G is
directed or undirected; (3) G is triangulated, triconnected, biconnected,
merely connected, or not required to be connected; (4) the nodes of G are
labeled with labels from {1, ..., ell_1} for ell_1 <= n; (5) the edges of G are
labeled with labels from {1, ..., ell_2} for ell_2 <= m; and (6) each node
(respectively, edge) of G has at most ell_3 = O(1) self-loops (respectively,
ell_4 = O(1) multiple edges). Moreover, ell_3 and ell_4 are not required to be
O(1) for the cases of pi being a plane triangulation. These examples are novel
applications of small cycle separators of planar graphs and are the only
nontrivial classes of graphs, other than rooted trees, with known
polynomial-time information-theoretically optimal coding schemes.
"
2430,Linear-Time Succinct Encodings of Planar Graphs via Canonical Orderings,"  Let G be an embedded planar undirected graph that has n vertices, m edges,
and f faces but has no self-loop or multiple edge. If G is triangulated, we can
encode it using {4/3}m-1 bits, improving on the best previous bound of about
1.53m bits. In case exponential time is acceptable, roughly 1.08m bits have
been known to suffice. If G is triconnected, we use at most
(2.5+2\log{3})\min\{n,f\}-7 bits, which is at most 2.835m bits and smaller than
the best previous bound of 3m bits. Both of our schemes take O(n) time for
encoding and decoding.
"
2431,Digital Color Imaging,"  This paper surveys current technology and research in the area of digital
color imaging. In order to establish the background and lay down terminology,
fundamental concepts of color perception and measurement are first presented
us-ing vector-space notation and terminology. Present-day color recording and
reproduction systems are reviewed along with the common mathematical models
used for representing these devices. Algorithms for processing color images for
display and communication are surveyed, and a forecast of research trends is
attempted. An extensive bibliography is provided.
"
2432,"Conformal Geometry, Euclidean Space and Geometric Algebra","  Projective geometry provides the preferred framework for most implementations
of Euclidean space in graphics applications. Translations and rotations are
both linear transformations in projective geometry, which helps when it comes
to programming complicated geometrical operations. But there is a fundamental
weakness in this approach - the Euclidean distance between points is not
handled in a straightforward manner. Here we discuss a solution to this
problem, based on conformal geometry. The language of geometric algebra is best
suited to exploiting this geometry, as it handles the interior and exterior
products in a single, unified framework. A number of applications are
discussed, including a compact formula for reflecting a line off a general
spherical surface.
"
2433,Computer-Generated Photorealistic Hair,"  This paper presents an efficient method for generating and rendering
photorealistic hair in two dimensional pictures. The method consists of three
major steps. Simulating an artist drawing is used to design the rough hair
shape. A convolution based filter is then used to generate photorealistic hair
patches. A refine procedure is finally used to blend the boundaries of the
patches with surrounding areas. This method can be used to create all types of
photorealistic human hair (head hair, facial hair and body hair). It is also
suitable for fur and grass generation. Applications of this method include:
hairstyle designing/editing, damaged hair image restoration, human hair
animation, virtual makeover of a human, and landscape creation.
"
2434,Optimally cutting a surface into a disk,"  We consider the problem of cutting a set of edges on a polyhedral manifold
surface, possibly with boundary, to obtain a single topological disk,
minimizing either the total number of cut edges or their total length. We show
that this problem is NP-hard, even for manifolds without boundary and for
punctured spheres. We also describe an algorithm with running time n^{O(g+k)},
where n is the combinatorial complexity, g is the genus, and k is the number of
boundary components of the input surface. Finally, we describe a greedy
algorithm that outputs a O(log^2 g)-approximation of the minimum cut graph in
O(g^2 n log n) time.
"
2435,User software for the next generation,"  New generations of neutron scattering sources and instrumentation are
providing challenges in data handling for user software. Time-of-Flight
instruments used at pulsed sources typically produce hundreds or thousands of
channels of data for each detector segment. New instruments are being designed
with thousands to hundreds of thousands of detector segments. High intensity
neutron sources make possible parametric studies and texture studies which
further increase data handling requirements. The Integrated Spectral Analysis
Workbench (ISAW) software developed at Argonne handles large numbers of spectra
simultaneously while providing operations to reduce, sort, combine and export
the data. It includes viewers to inspect the data in detail in real time. ISAW
uses existing software components and packages where feasible and takes
advantage of the excellent support for user interface design and network
communication in Java. The included scripting language simplifies repetitive
operations for analyzing many files related to a given experiment. Recent
additions to ISAW include a contour view, a time-slice table view, routines for
finding and fitting peaks in data, and support for data from other facilities
using the NeXus format. In this paper, I give an overview of features and
planned improvements of ISAW. Details of some of the improvements are covered
in other presentations at this conference.
"
2436,Optimized Color Gamuts for Tiled Displays,"  We consider the problem of finding a large color space that can be generated
by all units in multi-projector tiled display systems. Viewing the problem
geometrically as one of finding a large parallelepiped within the intersection
of multiple parallelepipeds, and using colorimetric principles to define a
volume-based objective function for comparing feasible solutions, we develop an
algorithm for finding the optimal gamut in time O(n^3), where n denotes the
number of projectors in the system. We also discuss more efficient quasiconvex
programming algorithms for alternative objective functions based on maximizing
the quality of the color space extrema.
"
2437,Computing Conformal Structure of Surfaces,"  This paper solves the problem of computing conformal structures of general
2-manifolds represented as triangle meshes. We compute conformal structures in
the following way: first compute homology bases from simplicial complex
structures, then construct dual cohomology bases and diffuse them to harmonic
1-forms. Next, we construct bases of holomorphic differentials. We then obtain
period matrices by integrating holomorphic differentials along homology bases.
We also study the global conformal mapping between genus zero surfaces and
spheres, and between general meshes and planes. Our method of computing
conformal structures can be applied to tackle fundamental problems in computer
aid design and computer graphics, such as geometry classification and
identification, and surface global parametrization.
"
2438,"Practical and Robust Stenciled Shadow Volumes for Hardware-Accelerated
  Rendering","  Twenty-five years ago, Crow published the shadow volume approach for
determining shadowed regions in a scene. A decade ago, Heidmann described a
hardware-accelerated stencil buffer-based shadow volume algorithm.
  Unfortunately hardware-accelerated stenciled shadow volume techniques have
not been widely adopted by 3D games and applications due in large part to the
lack of robustness of described techniques. This situation persists despite
widely available hardware support. Specifically what has been lacking is a
technique that robustly handles various ""hard"" situations created by near or
far plane clipping of shadow volumes.
  We describe a robust, artifact-free technique for hardware-accelerated
rendering of stenciled shadow volumes. Assuming existing hardware, we resolve
the issues otherwise caused by shadow volume near and far plane clipping
through a combination of (1) placing the conventional far clip plane ""at
infinity"", (2) rasterization with infinite shadow volume polygons via
homogeneous coordinates, and (3) adopting a zfail stencil-testing scheme. Depth
clamping, a new rasterization feature provided by NVIDIA's GeForce3, preserves
existing depth precision by not requiring the far plane to be placed at
infinity. We also propose two-sided stencil testing to improve the efficiency
of rendering stenciled shadow volumes.
"
2439,Cg in Two Pages,"  Cg is a language for programming GPUs. This paper describes Cg briefly.
"
2440,Embedded Reflection Mapping,"  Environment maps are used to simulate reflections off curved objects. We
present a technique to reflect a user, or a group of users, in a real
environment, onto a virtual object, in a virtual reality application, using the
live video feeds from a set of cameras, in real-time. Our setup can be used in
a variety of environments ranging from outdoor or indoor scenes.
"
2441,The Persint visualization program for the ATLAS experiment,"  The Persint program is designed for the three-dimensional representation of
objects and for the interfacing and access to a variety of independent
applications, in a fully interactive way. Facilities are provided for the
spatial navigation and the definition of the visualization properties, in order
to interactively set the viewing and viewed points, and to obtain the desired
perspective. In parallel, applications may be launched through the use of
dedicated interfaces, such as the interactive reconstruction and display of
physics events. Recent developments have focalized on the interfacing to the
XML ATLAS General Detector Description AGDD, making it a widely used tool for
XML developers. The graphics capabilities of this program were exploited in the
context of the ATLAS 2002 Muon Testbeam where it was used as an online event
display, integrated in the online software framework and participating in the
commissioning and debug of the detector system.
"
2442,"On multiple connectedness of regions visible due to multiple diffuse
  reflections","  It is known that the region $V(s)$ of a simple polygon $P$, directly visible
(illuminable) from an internal point $s$, is simply connected. Aronov et al.
\cite{addpp981} established that the region $V_1(s)$ of a simple polygon
visible from an internal point $s$ due to at most one diffuse reflection on the
boundary of the polygon $P$, is also simply connected. In this paper we
establish that the region $V_2(s)$, visible from $s$ due to at most two diffuse
reflections may be multiply connected; we demonstrate the construction of an
$n$-sided simple polygon with a point $s$ inside it so that and the region of
$P$ visible from $s$ after at most two diffuse reflections is multiple
connected.
"
2443,GraXML - Modular Geometric Modeler,"  Many entities managed by HEP Software Frameworks represent spatial
(3-dimensional) real objects. Effective definition, manipulation and
visualization of such objects is an indispensable functionality.
  GraXML is a modular Geometric Modeling toolkit capable of processing
geometric data of various kinds (detector geometry, event geometry) from
different sources and delivering them in ways suitable for further use.
Geometric data are first modeled in one of the Generic Models. Those Models are
then used to populate powerful Geometric Model based on the Java3D technology.
While Java3D has been originally created just to provide visualization of 3D
objects, its light weight and high functionality allow an effective reuse as a
general geometric component. This is possible also thanks to a large overlap
between graphical and general geometric functionality and modular design of
Java3D itself. Its graphical functionalities also allow a natural visualization
of all manipulated elements.
  All these techniques have been developed primarily (or only) for the Java
environment. It is, however, possible to interface them transparently to
Frameworks built in other languages, like for example C++.
  The GraXML toolkit has been tested with data from several sources, as for
example ATLAS and ALICE detector description and ATLAS event data. Prototypes
for other sources, like Geometry Description Markup Language (GDML) exist too
and interface to any other source is easy to add.
"
2444,The FRED Event Display: an Extensible HepRep Client for GLAST,"  A new graphics client prototype for the HepRep protocol is presented. Based
on modern toolkits and high level languages (C++ and Ruby), Fred is an
experiment to test applicability of scripting facilities to the high energy
physics event display domain. Its flexible structure, extensibility and the use
of the HepRep protocol are key features for its use in the astroparticle
experiment GLAST.
"
2445,"IGUANA Architecture, Framework and Toolkit for Interactive Graphics","  IGUANA is a generic interactive visualisation framework based on a C++
component model. It provides powerful user interface and visualisation
primitives in a way that is not tied to any particular physics experiment or
detector design. The article describes interactive visualisation tools built
using IGUANA for the CMS and D0 experiments, as well as generic GEANT4 and
GEANT3 applications. It covers features of the graphical user interfaces, 3D
and 2D graphics, high-quality vector graphics output for print media, various
textual, tabular and hierarchical data views, and integration with the
application through control panels, a command line and different
multi-threading models.
"
2446,The Use of HepRep in GLAST,"  HepRep is a generic, hierarchical format for description of graphics
representables that can be augmented by physics information and relational
properties. It was developed for high energy physics event display applications
and is especially suited to client/server or component frameworks. The GLAST
experiment, an international effort led by NASA for a gamma-ray telescope to
launch in 2006, chose HepRep to provide a flexible, extensible and maintainable
framework for their event display without tying their users to any one graphics
application. To support HepRep in their GUADI infrastructure, GLAST developed a
HepRep filler and builder architecture. The architecture hides the details of
XML and CORBA in a set of base and helper classes allowing physics experts to
focus on what data they want to represent. GLAST has two GAUDI services:
HepRepSvc, which registers HepRep fillers in a global registry and allows the
HepRep to be exported to XML, and CorbaSvc, which allows the HepRep to be
published through a CORBA interface and which allows the client application to
feed commands back to GAUDI (such as start next event, or run some GAUDI
algorithm). GLAST's HepRep solution gives users a choice of client
applications, WIRED (written in Java) or FRED (written in C++ and Ruby), and
leaves them free to move to any future HepRep-compliant event display.
"
2447,"OO Model of the STAR offline production ""Event Display"" and its
  implementation based on Qt-ROOT","  The paper presents the ""Event Display"" package for the STAR offline
production as a special visualization tool to debug the reconstruction code.
This can be achieved if an author of the algorithm / code may build his/her own
custom Event Display alone from the base software blocks and re-used some
well-designed, easy to learn user-friendly patterns. For STAR offline
production Event Display ROOT with Qt lower level interface was chosen as the
base tools.
"
2448,"Application of interactive parallel visualization for commodity-based
  clusters using visualization APIs","  We present an efficient and inexpensive to develop application for
interactive high-performance parallel visualization. We extend popular APIs
such as Open Inventor and VTK to support commodity-based cluster visualization.
Our implementation follows a standard master/slave concept: the general idea is
to have a ``Master'' node, which will intercept a sequential graphical user
interface (GUI) and broadcast it to the ``Slave'' nodes. The interactions
between the nodes are implemented using MPI. The parallel remote rendering uses
Chromium. This paper is mainly the report of our implementation experiences. We
present in detail the proposed model and key aspects of its implementation.
Also, we present performance measurements, we benchmark and quantitatively
demonstrate the dependence of the visualization speed on the data size and the
network bandwidth, and we identify the singularities and draw conclusions on
Chromium's sort-first rendering architecture. The most original part of this
work is the combined use of Open Inventor and Chromium.
"
2449,The Graphics Card as a Streaming Computer,"  Massive data sets have radically changed our understanding of how to design
efficient algorithms; the streaming paradigm, whether it in terms of number of
passes of an external memory algorithm, or the single pass and limited memory
of a stream algorithm, appears to be the dominant method for coping with large
data.
  A very different kind of massive computation has had the same effect at the
level of the CPU. The most prominent example is that of the computations
performed by a graphics card. The operations themselves are very simple, and
require very little memory, but require the ability to perform many
computations extremely fast and in parallel to whatever degree possible. What
has resulted is a stream processor that is highly optimized for stream
computations. An intriguing side effect of this is the growing use of a
graphics card as a general purpose stream processing engine. In an
ever-increasing array of applications, researchers are discovering that
performing a computation on a graphics card is far faster than performing it on
a CPU, and so are using a GPU as a stream co-processor.
"
2450,Poster on MPI application in Computational Fluid Dynamics,"  Poster-presentation of the paper ""Message Passing Fluids: molecules as
processes in parallel computational fluids"" held at ""EURO PVMMPI 2003""
Congress; the paper is on the proceedings ""Recent Advances in Parallel Virtual
Machine and Message Passing Interface"", 10th European PVM/MPI User's Group
Meeting, LNCS 2840, Springer-Verlag, Dongarra-Laforenza-Orlando editors, pp.
550-554.
"
2451,Circle and sphere blending with conformal geometric algebra,"  Blending schemes based on circles provide smooth `fair' interpolations
between series of points. Here we demonstrate a simple, robust set of
algorithms for performing circle blends for a range of cases. An arbitrary
level of G-continuity can be achieved by simple alterations to the underlying
parameterisation. Our method exploits the computational framework provided by
conformal geometric algebra. This employs a five-dimensional representation of
points in space, in contrast to the four-dimensional representation typically
used in projective geometry. The advantage of the conformal scheme is that
straight lines and circles are treated in a single, unified framework. As a
further illustration of the power of the conformal framework, the basic idea is
extended to the case of sphere blending to interpolate over a surface.
"
2452,"Visualization of variations in human brain morphology using
  differentiating reflection functions","  Conventional visualization media such as MRI prints and computer screens are
inherently two dimensional, making them incapable of displaying true 3D volume
data sets. By applying only transparency or intensity projection, and ignoring
light-matter interaction, results will likely fail to give optimal results.
Little research has been done on using reflectance functions to visually
separate the various segments of a MRI volume. We will explore if applying
specific reflectance functions to individual anatomical structures can help in
building an intuitive 2D image from a 3D dataset. We will test our hypothesis
by visualizing a statistical analysis of the genetic influences on variations
in human brain morphology because it inherently contains complex and many
different types of data making it a good candidate for our approach
"
2453,"Benchmarking and Implementation of Probability-Based Simulations on
  Programmable Graphics Cards","  The latest Graphics Processing Units (GPUs) are reported to reach up to
  200 billion floating point operations per second (200 Gflops) and to have
price performance of 0.1 cents per M flop. These facts raise great interest in
the plausibility of extending the GPUs' use to non-graphics applications, in
particular numerical simulations on structured grids (lattice).
  We review previous work on using GPUs for non-graphics applications,
implement probability-based simulations on the GPU, namely the
  Ising and percolation models, implement vector operation benchmarks for the
GPU, and finally compare the CPU's and GPU's performance.
  A general conclusion from the results obtained is that moving computations
from the CPU to the GPU is feasible, yielding good time and price performance,
for certain lattice computations.
  Preliminary results also show that it is feasible to use them in parallel
"
2454,Surface Triangulation -- The Metric Approach,"  We embark in a program of studying the problem of better approximating
surfaces by triangulations(triangular meshes) by considering the approximating
triangulations as finite metric spaces and the target smooth surface as their
Haussdorff-Gromov limit. This allows us to define in a more natural way the
relevant elements, constants and invariants s.a. principal directions and
principal values, Gaussian and Mean curvature, etc. By a ""natural way"" we mean
an intrinsic, discrete, metric definitions as opposed to approximating or
paraphrasing the differentiable notions. In this way we hope to circumvent
computational errors and, indeed, conceptual ones, that are often inherent to
the classical, ""numerical"" approach. In this first study we consider the
problem of determining the Gaussian curvature of a polyhedral surface, by using
the {\em embedding curvature} in the sense of Wald (and Menger). We present two
modalities of employing these definitions for the computation of Gaussian
curvature.
"
2455,An Algorithm for Transforming Color Images into Tactile Graphics,"  This paper presents an algorithm that transforms color visual images, like
photographs or paintings, into tactile graphics. In the algorithm, the edges of
objects are detected and colors of the objects are estimated. Then, the edges
and the colors are encoded into lines and textures in the output tactile image.
Design of the method is substantiated by various qualities of haptic
recognizing of images. Also, means of presentation of the tactile images in
printouts are discussed. Example translated images are shown.
"
2456,Single-Strip Triangulation of Manifolds with Arbitrary Topology,"  Triangle strips have been widely used for efficient rendering. It is
NP-complete to test whether a given triangulated model can be represented as a
single triangle strip, so many heuristics have been proposed to partition
models into few long strips. In this paper, we present a new algorithm for
creating a single triangle loop or strip from a triangulated model. Our method
applies a dual graph matching algorithm to partition the mesh into cycles, and
then merges pairs of cycles by splitting adjacent triangles when necessary. New
vertices are introduced at midpoints of edges and the new triangles thus formed
are coplanar with their parent triangles, hence the visual fidelity of the
geometry is not changed. We prove that the increase in the number of triangles
due to this splitting is 50% in the worst case, however for all models we
tested the increase was less than 2%. We also prove tight bounds on the number
of triangles needed for a single-strip representation of a model with holes on
its boundary. Our strips can be used not only for efficient rendering, but also
for other applications including the generation of space filling curves on a
manifold of any arbitrary topology.
"
2457,"Interactive visualization of higher dimensional data in a multiview
  environment","  We develop multiple view visualization of higher dimensional data. Our work
was chiefly motivated by the need to extract insight from four dimensional
Quantum Chromodynamic (QCD) data. We develop visualization where multiple
views, generally views of 3D projections or slices of a higher dimensional
data, are tightly coupled not only by their specific order but also by a view
synchronizing interaction style, and an internally defined interaction
language. The tight coupling of the different views allows a fast and
well-coordinated exploration of the data. In particular, the visualization
allowed us to easily make consistency checks of the 4D QCD data and to infer
the correctness of particle properties calculations. The software developed was
also successfully applied in material studies, in particular studies of
meteorite properties. Our implementation uses the VTK API. To handle a large
number of views (slices/projections) and to still maintain good resolution, we
use IBM T221 display (3840 X 2400 pixels).
"
2458,An Example of Clifford Algebras Calculations with GiNaC,"  This example of Clifford algebras calculations uses GiNaC
(http://www.ginac.de/) library, which includes a support for generic Clifford
algebra starting from version~1.3.0. Both symbolic and numeric calculation are
possible and can be blended with other functions of GiNaC. This calculations
was made for the paper math.CV/0410399.
  Described features of GiNaC are already available at PyGiNaC
(http://sourceforge.net/projects/pyginac/) and due to course should propagate
into other software like GNU Octave (http://www.octave.org/), gTybalt
(http://www.fis.unipr.it/~stefanw/gtybalt.html), which use GiNaC library as
their back-end.
"
2459,Analytic Definition of Curves and Surfaces by Parabolic Blending,"  A procedure for interpolating between specified points of a curve or surface
is described. The method guarantees slope continuity at all junctions. A
surface panel divided into p x q contiguous patches is completely specified by
the coordinates of (p+1) x (q+1) points. Each individual patch, however,
depends parametrically on the coordinates of 16 points, allowing shape
flexibility and global conformity.
"
2460,Convexity Analysis of Snake Models Based on Hamiltonian Formulation,"  This paper presents a convexity analysis for the dynamic snake model based on
the Potential Energy functional and the Hamiltonian formulation of the
classical mechanics. First we see the snake model as a dynamical system whose
singular points are the borders we seek. Next we show that a necessary
condition for a singular point to be an attractor is that the energy functional
is strictly convex in a neighborhood of it, that means, if the singular point
is a local minimum of the potential energy. As a consequence of this analysis,
a local expression relating the dynamic parameters and the rate of convergence
arises. Such results link the convexity analysis of the potential energy and
the dynamic snake model and point forward to the necessity of a physical
quantity whose convexity analysis is related to the dynamic and which
incorporate the velocity space. Such a quantity is exactly the (conservative)
Hamiltonian of the system.
"
2461,"k-core decomposition: a tool for the visualization of large scale
  networks","  We use the k-core decomposition to visualize large scale complex networks in
two dimensions. This decomposition, based on a recursive pruning of the least
connected vertices, allows to disentangle the hierarchical structure of
networks by progressively focusing on their central cores. By using this
strategy we develop a general visualization algorithm that can be used to
compare the structural properties of various networks and highlight their
hierarchical structure. The low computational complexity of the algorithm,
O(n+e), where 'n' is the size of the network, and 'e' is the number of edges,
makes it suitable for the visualization of very large sparse networks. We apply
the proposed visualization tool to several real and synthetic graphs, showing
its utility in finding specific structural fingerprints of computer generated
and real world networks.
"
2462,"Estimacao Temporal da Deformacao entre Objectos utilizando uma
  Metodologia Fisica","  In this paper, it is presented a methodology to estimate the deformation
involved between two objects attending to its physical properties. This
methodology can be used, for example, in Computational Vision or Computer
Graphics applications, and consists in physically modeling the objects, by
means of the Finite Elements Method, establishing correspondences between some
of its data points, by using Modal Matching, and finally, determining the
displacement field, that is the intermediate shapes, through the resolution of
the Lagrange Dynamic Equilibrium Equation. As in many of the possible
applications of the methodology to present, it is necessary to quantify the
existing deformation, as well as to estimate only the non rigid component of
the involved global deformation. The solutions adopted to satisfy such
intentions will be also presented.
"
2463,Lattice Gas Cellular Automata for Computational Fluid Animation,"  The past two decades showed a rapid growing of physically-based modeling of
fluids for computer graphics applications. In this area, a common top down
approach is to model the fluid dynamics by Navier-Stokes equations and apply a
numerical techniques such as Finite Differences or Finite Elements for the
simulation. In this paper we focus on fluid modeling through Lattice Gas
Cellular Automata (LGCA) for computer graphics applications. LGCA are discrete
models based on point particles that move on a lattice, according to suitable
and simple rules in order to mimic a fully molecular dynamics. By
Chapman-Enskog expansion, a known multiscale technique in this area, it can be
demonstrated that the Navier-Stokes model can be reproduced by the LGCA
technique. Thus, with LGCA we get a fluid model that does not require solution
of complicated equations. Therefore, we combine the advantage of the low
computational cost of LGCA and its ability to mimic the realistic fluid
dynamics to develop a new animating framework for computer graphics
applications. In this work, we discuss the theoretical elements of our proposal
and show experimental results.
"
2464,"Methods for Analytical Understanding of Agent-Based Modeling of Complex
  Systems","  Von Neuman's work on universal machines and the hardware development have
allowed the simulation of dynamical systems through a large set of interacting
agents. This is a bottom-up approach which tries to derive global properties of
a complex system through local interaction rules and agent behaviour.
Traditionally, such systems are modeled and simulated through top-down methods
based on differential equations. Agent-Based Modeling has the advantage of
simplicity and low computational cost. However, unlike differential equations,
there is no standard way to express agent behaviour. Besides, it is not clear
how to analytically predict the results obtained by the simulation. In this
paper we survey some of these methods. For expressing agent behaviour formal
methods, like Stochastic Process Algebras have been used. Such approach is
useful if the global properties of interest can be expressed as a function of
stochastic time series. However, if space variables must be considered, we
shall change the focus. In this case, multiscale techniques, based on
Chapman-Enskog expansion, was used to establish the connection between the
microscopic dynamics and the macroscopic observables. Also, we use data mining
techniques,like Principal Component Analysis (PCA), to study agent systems like
Cellular Automata. With the help of these tools we will discuss a simple
society model, a Lattice Gas Automaton for fluid modeling, and knowledge
discovery in CA databases. Besides, we show the capabilities of the NetLogo, a
software for agent simulation of complex system and show our experience about.
"
2465,MathPSfrag: Creating Publication-Quality Labels in Mathematica Plots,"  This article introduces a Mathematica package providing a graphics export
function that automatically replaces Mathematica expressions in a graphic by
the corresponding LaTeX constructs and positions them correctly. It thus
facilitates the creation of publication-quality Enscapulated PostScript (EPS)
graphics.
"
2466,"Spatiotemporal sensistivity and visual attention for efficient rendering
  of dynamic environments","  We present a method to accelerate global illumination computation in dynamic
environments by taking advantage of limitations of the human visual system. A
model of visual attention is used to locate regions of interest in a scene and
to modulate spatiotemporal sensitivity. The method is applied in the form of a
spatiotemporal error tolerance map. Perceptual acceleration combined with good
sampling protocols provide a global illumination solution feasible for use in
animation. Results indicate an order of magnitude improvement in computational
speed. The method is adaptable and can also be used in image-based rendering,
geometry level of detail selection, realistic image synthesis, video telephony
and video compression.
"
2467,"A geometry of information, I: Nerves, posets and differential forms","  The main theme of this workshop (Dagstuhl seminar 04351) is `Spatial
Representation: Continuous vs. Discrete'. Spatial representation has two
contrasting but interacting aspects (i) representation of spaces' and (ii)
representation by spaces. In this paper, we will examine two aspects that are
common to both interpretations of the theme, namely nerve constructions and
refinement. Representations change, data changes, spaces change. We will
examine the possibility of a `differential geometry' of spatial representations
of both types, and in the sequel give an algebra of differential forms that has
the potential to handle the dynamical aspect of such a geometry. We will
discuss briefly a conjectured class of spaces, generalising the Cantor set
which would seem ideal as a test-bed for the set of tools we are developing.
"
2468,Incremental and Transitive Discrete Rotations,"  A discrete rotation algorithm can be apprehended as a parametric application
$f\_\alpha$ from $\ZZ[i]$ to $\ZZ[i]$, whose resulting permutation ``looks
like'' the map induced by an Euclidean rotation. For this kind of algorithm, to
be incremental means to compute successively all the intermediate rotate d
copies of an image for angles in-between 0 and a destination angle. The di
scretized rotation consists in the composition of an Euclidean rotation with a
discretization; the aim of this article is to describe an algorithm whic h
computes incrementally a discretized rotation. The suggested method uses o nly
integer arithmetic and does not compute any sine nor any cosine. More pr
ecisely, its design relies on the analysis of the discretized rotation as a
step function: the precise description of the discontinuities turns to be th e
key ingredient that will make the resulting procedure optimally fast and e
xact. A complete description of the incremental rotation process is provided,
also this result may be useful in the specification of a consistent set of
defin itions for discrete geometry.
"
2469,"Mathematical models of the complex surfaces in simulation and
  visualization systems","  Modeling, simulation and visualization of three-dimension complex bodies
widely use mathematical model of curves and surfaces. The most important curves
and surfaces for these purposes are curves and surfaces in Hermite and Bezier
forms, splines and NURBS. Article is devoted to survey this way to use
geometrical data in various computer graphics systems and adjacent fields.
"
2470,Implementation of float-float operators on graphics hardware,"  The Graphic Processing Unit (GPU) has evolved into a powerful and flexible
processor. The latest graphic processors provide fully programmable vertex and
pixel processing units that support vector operations up to single
floating-point precision. This computational power is now being used for
general-purpose computations. However, some applications require higher
precision than single precision. This paper describes the emulation of a 44-bit
floating-point number format and its corresponding operations. An
implementation is presented along with performance and accuracy results.
"
2471,Graphics Turing Test,"  We define a Graphics Turing Test to measure graphics performance in a similar
manner to the definition of the traditional Turing Test. To pass the test one
needs to reach a computational scale, the Graphics Turing Scale, for which
Computer Generated Imagery becomes comparatively indistinguishable from real
images while also being interactive. We derive an estimate for this
computational scale which, although large, is within reach of todays
supercomputers. We consider advantages and disadvantages of various computer
systems designed to pass the Graphics Turing Test. Finally we discuss
commercial applications from the creation of such a system, in particular
Interactive Cinema.
"
2472,"A parent-centered radial layout algorithm for interactive graph
  visualization and animation","  We have developed (1) a graph visualization system that allows users to
explore graphs by viewing them as a succession of spanning trees selected
interactively, (2) a radial graph layout algorithm, and (3) an animation
algorithm that generates meaningful visualizations and smooth transitions
between graphs while minimizing edge crossings during transitions and in static
layouts.
  Our system is similar to the radial layout system of Yee et al. (2001), but
differs primarily in that each node is positioned on a coordinate system
centered on its own parent rather than on a single coordinate system for all
nodes. Our system is thus easy to define recursively and lends itself to
parallelization. It also guarantees that layouts have many nice properties,
such as: it guarantees certain edges never cross during an animation.
  We compared the layouts and transitions produced by our algorithms to those
produced by Yee et al. Results from several experiments indicate that our
system produces fewer edge crossings during transitions between graph drawings,
and that the transitions more often involve changes in local scaling rather
than structure.
  These findings suggest the system has promise as an interactive graph
exploration tool in a variety of settings.
"
2473,"Simple Methods For Drawing Rational Surfaces as Four or Six Bezier
  Patches","  In this paper, we give several simple methods for drawing a whole rational
surface (without base points) as several Bezier patches. The first two methods
apply to surfaces specified by triangular control nets and partition the real
projective plane RP2 into four and six triangles respectively. The third method
applies to surfaces specified by rectangular control nets and partitions the
torus RP1 X RP1 into four rectangular regions. In all cases, the new control
nets are obtained by sign flipping and permutation of indices from the original
control net. The proofs that these formulae are correct involve very little
computations and instead exploit the geometry of the parameter space (RP2 or
RP1 X RP1). We illustrate our method on some classical examples. We also
propose a new method for resolving base points using a simple ``blowing up''
technique involving the computation of ``resolved'' control nets.
"
2474,Fast and Simple Methods For Computing Control Points,"  The purpose of this paper is to present simple and fast methods for computing
control points for polynomial curves and polynomial surfaces given explicitly
in terms of polynomials (written as sums of monomials). We give recurrence
formulae w.r.t. arbitrary affine frames. As a corollary, it is amusing that we
can also give closed-form expressions in the case of the frame (r, s) for
curves, and the frame ((1, 0, 0), (0, 1, 0), (0, 0, 1) for surfaces. Our
methods have the same low polynomial (time and space) complexity as the other
best known algorithms, and are very easy to implement.
"
2475,"On the Efficiency of Strategies for Subdividing Polynomial Triangular
  Surface Patches","  In this paper, we investigate the efficiency of various strategies for
subdividing polynomial triangular surface patches. We give a simple algorithm
performing a regular subdivision in four calls to the standard de Casteljau
algorithm (in its subdivision version). A naive version uses twelve calls. We
also show that any method for obtaining a regular subdivision using the
standard de Casteljau algorithm requires at least 4 calls. Thus, our method is
optimal. We give another subdivision algorithm using only three calls to the de
Casteljau algorithm. Instead of being regular, the subdivision pattern is
diamond-like. Finally, we present a ``spider-like'' subdivision scheme
producing six subtriangles in four calls to the de Casteljau algorithm.
"
2476,Outlier Robust ICP for Minimizing Fractional RMSD,"  We describe a variation of the iterative closest point (ICP) algorithm for
aligning two point sets under a set of transformations. Our algorithm is
superior to previous algorithms because (1) in determining the optimal
alignment, it identifies and discards likely outliers in a statistically robust
manner, and (2) it is guaranteed to converge to a locally optimal solution. To
this end, we formalize a new distance measure, fractional root mean squared
distance (frmsd), which incorporates the fraction of inliers into the distance
function. We lay out a specific implementation, but our framework can easily
incorporate most techniques and heuristics from modern registration algorithms.
We experimentally validate our algorithm against previous techniques on 2 and 3
dimensional data exposed to a variety of outlier types.
"
2477,Interactive Hatching and Stippling by Example,"  We describe a system that lets a designer interactively draw patterns of
strokes in the picture plane, then guide the synthesis of similar patterns over
new picture regions. Synthesis is based on an initial user-assisted analysis
phase in which the system recognizes distinct types of strokes (hatching and
stippling) and organizes them according to perceptual grouping criteria. The
synthesized strokes are produced by combining properties (eg. length,
orientation, parallelism, proximity) of the stroke groups extracted from the
input examples. We illustrate our technique with a drawing application that
allows the control of attributes and scale-dependent reproduction of the
synthesized patterns.
"
2478,On a solution to display non-filled-in quaternionic Julia sets,"  During early 1980s, the so-called `escape time' method, developed to display
the Julia sets for complex dynamical systems, was exported to quaternions in
order to draw analogous pictures in this wider numerical field. Despite of the
fine results in the complex plane, where all topological configurations of
Julia sets have been successfully displayed, the `escape time' method fails to
render properly the non-filled-in variety of quaternionic Julia sets. So their
digital visualisation remained an open problem for several years. Both the
solution for extending this old method to non-filled-in quaternionic Julia sets
and its implementation into a program are explained here.
"
2479,Non-photorealistic image rendering with a labyrinthine tiling,"  The paper describes a new image processing for a non-photorealistic
rendering. The algorithm is based on a random generation of gray tones and
competing statistical requirements. The gray tone value of each pixel in the
starting image is replaced selecting among randomly generated tone values,
according to the statistics of nearest-neighbor and next-nearest-neighbor
pixels. Two competing conditions for replacing the tone values - one position
on the local mean value the other on the local variance - produce a peculiar
pattern on the image. This pattern has a labyrinthine tiling aspect. For
certain subjects, the pattern enhances the look of the image.
"
2480,Vector field visualization with streamlines,"  We have recently developed an algorithm for vector field visualization with
oriented streamlines, able to depict the flow directions everywhere in a dense
vector field and the sense of the local orientations. The algorithm has useful
applications in the visualization of the director field in nematic liquid
crystals. Here we propose an improvement of the algorithm able to enhance the
visualization of the local magnitude of the field. This new approach of the
algorithm is compared with the same procedure applied to the Line Integral
Convolution (LIC) visualization.
"
2481,Shape preservation behavior of spline curves,"  Shape preservation behavior of a spline consists of criterial conditions for
preserving convexity, inflection, collinearity, torsion and coplanarity shapes
of data polgonal arc. We present our results which acts as an improvement in
the definitions of and provide geometrical insight into each of the above shape
preservation criteria. We also investigate the effect of various results from
the literature on various shape preservation criteria. These results have not
been earlier refered in the context of shape preservation behaviour of splines.
We point out that each curve segment need to satisfy more than one shape
preservation criteria. We investigate the conflict between different shape
preservation criteria 1)on each curve segment and 2)of adjacent curve segments.
We derive simplified formula for shape preservation criteria for cubic curve
segments. We study the shape preservation behavior of cubic Catmull-Rom splines
and see that, though being very simple spline curve, it indeed satisfy all the
shape preservation criteria.
"
2482,Plot 94 in ambiance X-Window,"  <PLOT > is a collection of routines to draw surfaces, contours and so on. In
this work we are presenting a version, that functions over work stations with
the operative system UNIX, that count with the graphic ambiance X-WINDOW with
the tools XLIB and OSF/MOTIF. This implant was realized for the work stations
DEC 5000-200, DEC IPX, and DEC ALFA of the CINVESTAV (Center of Investigation
and Advanced Studies). Also implanted in SILICON GRAPHICS of the CENAC
(National Center of Calculation of the Polytechnic National Institute
"
2483,A note on digitized angles,"  We study the configurations of pixels that occur when two digitized straight
lines meet each other.
"
2484,Separation-Sensitive Collision Detection for Convex Objects,"  We develop a class of new kinetic data structures for collision detection
between moving convex polytopes; the performance of these structures is
sensitive to the separation of the polytopes during their motion. For two
convex polygons in the plane, let $D$ be the maximum diameter of the polygons,
and let $s$ be the minimum distance between them during their motion. Our
separation certificate changes $O(\log(D/s))$ times when the relative motion of
the two polygons is a translation along a straight line or convex curve,
$O(\sqrt{D/s})$ for translation along an algebraic trajectory, and $O(D/s)$ for
algebraic rigid motion (translation and rotation). Each certificate update is
performed in $O(\log(D/s))$ time. Variants of these data structures are also
shown that exhibit \emph{hysteresis}---after a separation certificate fails,
the new certificate cannot fail again until the objects have moved by some
constant fraction of their current separation. We can then bound the number of
events by the combinatorial size of a certain cover of the motion path by
balls.
"
2485,"Droems: experimental mathematics, informatics and infinite dimensional
  geometry","  The article is devoted to a problem of elaboration of the real-time
interactive videosystems for accelerated nonverbal cognitive computer and
telecommunications. The proposed approach is based on the using of droems
(dynamically reconstructed objects of experimental mathematics) and
interpretational figures as pointers to them. Four paragraphs of the article
are devoted to (1) an exposition of basic notions of the interpretational
geometry, (2) the operator methods in the theory of interactive dynamical
videosystems, (3) the general concept of organization of the integrated
interactive real-time videocognitive systems, (4) the droems and processes of
their dynamical reconstruction, where the general notions are illustrated by a
concrete example related to the infinite dimensional geometry. The exposition
is presumably heuristic and conceptual (the first and the third paragraphs)
though some particular aspects such as content of the second and the fourth
paragraphs, which allow deeper formalization and detailing in present, are
exposed on the mathematical level of rigor.
"
2486,"The Design of EzWindows: A Graphics API for an Introductory Programming
  Course","  Teaching object-oriented programming in an introductory programming course
poses considerable challenges to the instructor. An often advocated approach to
meeting this challenge is the use of a simple, object-oriented graphics
library. We have developed a simple, portable graphics library for teaching
object-oriented programming using C++. The library, EzWindows, allows beginning
programmers to design and write programs that use the graphical display found
on all modern desktop computers. In addition to providing simple graphical
objects such as windows, geometric shapes, and bitmaps, EzWindows provides
facilities for introducing event-based programming using the mouse and timers.
EzWindows has proven to be extremely popular; it is currently in use at over
200 universities, colleges, and high schools. This paper describes the
rationale for EzWindows and its high-level design.
"
2487,Computational Geometry Column 33,"  Several recent SIGGRAPH papers on surface simplification are described.
"
2488,Computational Geometry Column 32,"  The proof of Dey's new k-set bound is illustrated.
"
2489,Geometric compression for progressive transmission,"  The compression of geometric structures is a relatively new field of data
compression. Since about 1995, several articles have dealt with the coding of
meshes, using for most of them the following approach: the vertices of the mesh
are coded in an order such that it contains partially the topology of the mesh.
In the same time, some simple rules attempt to predict the position of the
current vertex from the positions of its neighbours that have been previously
coded. In this article, we describe a compression algorithm whose principle is
completely different: the order of the vertices is used to compress their
coordinates, and then the topology of the mesh is reconstructed from the
vertices. This algorithm, particularly suited for terrain models, achieves
compression factors that are slightly greater than those of the currently
available algorithms, and moreover, it allows progressive and interactive
transmission of the meshes.
"
2490,Finite-resolution hidden surface removal,"  We propose a hybrid image-space/object-space solution to the classical hidden
surface removal problem: Given n disjoint triangles in Real^3 and p sample
points (``pixels'') in the xy-plane, determine the first triangle directly
behind each pixel. Our algorithm constructs the sampled visibility map of the
triangles with respect to the pixels, which is the subset of the trapezoids in
a trapezoidal decomposition of the analytic visibility map that contain at
least one pixel. The sampled visibility map adapts to local changes in image
complexity, and its complexity is bounded both by the number of pixels and by
the complexity of the analytic visibility map. Our algorithm runs in time
O(n^{1+e} + n^{2/3+e}t^{2/3} + p), where t is the output size and e is any
positive constant. This is nearly optimal in the worst case and compares
favorably with the best output-sensitive algorithms for both ray casting and
analytic hidden surface removal. In the special case where the pixels form a
regular grid, a sweepline variant of our algorithm runs in time O(n^{1+e} +
n^{2/3+e}t^{2/3} + t log p), which is usually sublinear in the number of
pixels.
"
2491,A Vortex Method for Bi-phasic Fluids Interacting with Rigid Bodies,"  We present an accurate Lagrangian method based on vortex particles,
level-sets, and immersed boundary methods, for animating the interplay between
two fluids and rigid solids. We show that a vortex method is a good choice for
simulating bi-phase flow, such as liquid and gas, with a good level of realism.
Vortex particles are localized at the interfaces between the two fluids and
within the regions of high turbulence. We gain local precision and efficiency
from the stable advection permitted by the vorticity formulation. Moreover, our
numerical method straightforwardly solves the two-way coupling problem between
the fluids and animated rigid solids. This new approach is validated through
numerical comparisons with reference experiments from the computational fluid
community. We also show that the visually appealing results obtained in the CG
community can be reproduced with increased efficiency and an easier
implementation.
"
2492,One method for proving inequalities by computer,"  In this article we consider a method for proving a class of analytical
inequalities via minimax rational approximations. All numerical calculations in
this paper are given by Maple computer program.
"
2493,Topological Quantum Error Correction with Optimal Encoding Rate,"  We prove the existence of topological quantum error correcting codes with
encoding rates $k/n$ asymptotically approaching the maximum possible value.
Explicit constructions of these topological codes are presented using surfaces
of arbitrary genus. We find a class of regular toric codes that are optimal.
For physical implementations, we present planar topological codes.
"
