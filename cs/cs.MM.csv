,title,abstract
0,Characterization of P2P IPTV Traffic: Scaling Analysis,"  P2P IPTV applications arise on the Internet and will be massively used in the
future. It is expected that P2P IPTV will contribute to increase the overall
Internet traffic. In this context, it is important to measure the impact of P2P
IPTV on the networks and to characterize this traffic. Dur- ing the 2006 FIFA
World Cup, we performed an extensive measurement campaign. We measured network
traffic generated by broadcasting soc- cer games by the most popular P2P IPTV
applications, namely PPLive, PPStream, SOPCast and TVAnts. From the collected
data, we charac- terized the P2P IPTV traffic structure at different time
scales by using wavelet based transform method. To the best of our knowledge,
this is the first work, which presents a complete multiscale analysis of the
P2P IPTV traffic. Our results show that the scaling properties of the TCP
traffic present periodic behavior whereas the UDP traffic is stationary and
lead to long- range depedency characteristics. For all the applications, the
download traffic has different characteristics than the upload traffic. The
signaling traffic has a significant impact on the download traffic but it has
negligible impact on the upload. Both sides of the traffic and its granularity
has to be taken into account to design accurate P2P IPTV traffic models.
"
1,Double Sided Watermark Embedding and Detection with Perceptual Analysis,"  In our previous work, we introduced a double-sided technique that utilizes
but not reject the host interference. Due to its nice property of utilizing but
not rejecting the host interference, it has a big advantage over the host
interference schemes in that the perceptual analysis can be easily implemented
for our scheme to achieve the locally bounded maximum embedding strength. Thus,
in this work, we detail how to implement the perceptual analysis in our
double-sided schemes since the perceptual analysis is very important for
improving the fidelity of watermarked contents. Through the extensive
performance comparisons, we can further validate the performance advantage of
our double-sided schemes.
"
2,Watermark Embedding and Detection,"  The embedder and the detector (or decoder) are the two most important
components of the digital watermarking systems. Thus in this work, we discuss
how to design a better embedder and detector (or decoder). I first give a
summary of the prospective applications of watermarking technology and major
watermarking schemes in the literature. My review on the literature closely
centers upon how the side information is exploited at both embedders and
detectors. In Chapter 3, I explore the optimum detector or decoder according to
a particular probability distribution of the host signals. We found that the
performance of both multiplicative and additive spread spectrum schemes depends
on the shape parameter of the host signals. For spread spectrum schemes, the
performance of the detector or the decoder is reduced by the host interference.
Thus I present a new host-interference rejection technique for the
multiplicative spread spectrum schemes. Its embedding rule is tailored to the
optimum detection or decoding rule. Though the host interference rejection
schemes enjoy a big performance gain over the traditional spread spectrum
schemes, their drawbacks that it is difficult for them to be implemented with
the perceptual analysis to achieve the maximum allowable embedding level
discourage their use in real scenarios. Thus, in the last chapters of this
work, I introduce a double-sided technique to tackle this drawback. It differs
from the host interference rejection schemes in that it utilizes but does not
reject the host interference at its embedder. The perceptual analysis can be
easily implemented in our scheme to achieve the maximum allowable level of
embedding strength.
"
3,"Multimedia Content Distribution in Hybrid Wireless Networks using
  Weighted Clustering","  Fixed infrastructured networks naturally support centralized approaches for
group management and information provisioning. Contrary to infrastructured
networks, in multi-hop ad-hoc networks each node acts as a router as well as
sender and receiver. Some applications, however, requires hierarchical
arrangements that-for practical reasons-has to be done locally and
self-organized. An additional challenge is to deal with mobility that causes
permanent network partitioning and re-organizations. Technically, these
problems can be tackled by providing additional uplinks to a backbone network,
which can be used to access resources in the Internet as well as to inter-link
multiple ad-hoc network partitions, creating a hybrid wireless network. In this
paper, we present a prototypically implemented hybrid wireless network system
optimized for multimedia content distribution. To efficiently manage the ad-hoc
communicating devices a weighted clustering algorithm is introduced. The
proposed localized algorithm deals with mobility, but does not require
geographical information or distances.
"
4,On the Performance of Joint Fingerprint Embedding and Decryption Scheme,"  Till now, few work has been done to analyze the performances of joint
fingerprint embedding and decryption schemes. In this paper, the security of
the joint fingerprint embedding and decryption scheme proposed by Kundur et al.
is analyzed and improved. The analyses include the security against
unauthorized customer, the security against authorized customer, the
relationship between security and robustness, the relationship between
secu-rity and imperceptibility and the perceptual security. Based these
analyses, some means are proposed to strengthen the system, such as multi-key
encryp-tion and DC coefficient encryption. The method can be used to analyze
other JFD schemes. It is expected to provide valuable information to design JFD
schemes.
"
5,Robust Audio Watermarking Against the D/A and A/D conversions,"  Audio watermarking has played an important role in multimedia security. In
many applications using audio watermarking, D/A and A/D conversions (denoted by
DA/AD in this paper) are often involved. In previous works, however, the
robustness issue of audio watermarking against the DA/AD conversions has not
drawn sufficient attention yet. In our extensive investigation, it has been
found that the degradation of a watermarked audio signal caused by the DA/AD
conversions manifests itself mainly in terms of wave magnitude distortion and
linear temporal scaling, making the watermark extraction failed. Accordingly, a
DWT-based audio watermarking algorithm robust against the DA/AD conversions is
proposed in this paper. To resist the magnitude distortion, the relative energy
relationships among different groups of the DWT coefficients in the
low-frequency sub-band are utilized in watermark embedding by adaptively
controlling the embedding strength. Furthermore, the resynchronization is
designed to cope with the linear temporal scaling. The time-frequency
localization characteristics of DWT are exploited to save the computational
load in the resynchronization. Consequently, the proposed audio watermarking
algorithm is robust against the DA/AD conversions, other common audio
processing manipulations, and the attacks in StirMark Benchmark for Audio,
which has been verified by experiments.
"
6,Very fast watermarking by reversible contrast mapping,"  Reversible contrast mapping (RCM) is a simple integer transform that applies
to pairs of pixels. For some pairs of pixels, RCM is invertible, even if the
least significant bits (LSBs) of the transformed pixels are lost. The data
space occupied by the LSBs is suitable for data hiding. The embedded
information bit-rates of the proposed spatial domain reversible watermarking
scheme are close to the highest bit-rates reported so far. The scheme does not
need additional data compression, and, in terms of mathematical complexity, it
appears to be the lowest complexity one proposed up to now. A very fast lookup
table implementation is proposed. Robustness against cropping can be ensured as
well.
"
7,"Multimedia Capacity Analysis of the IEEE 802.11e Contention-based
  Infrastructure Basic Service Set","  We first propose a simple mathematical analysis framework for the Enhanced
Distributed Channel Access (EDCA) function of the recently ratified IEEE
802.11e standard. Our analysis considers the fact that the distributed random
access systems exhibit cyclic behavior. The proposed model is valid for
arbitrary assignments of AC-specific Arbitration Interframe Space (AIFS) values
and Contention Window (CW) sizes and is the first that considers an arbitrary
distribution of active Access Categories (ACs) at the stations. Validating the
theoretical results via extensive simulations, we show that the proposed
analysis accurately captures the EDCA saturation performance. Next, we propose
a framework for multimedia capacity analysis of the EDCA function. We calculate
an accurate station- and AC-specific queue utilization ratio by appropriately
weighing the service time predictions of the cycle time model for different
number of active stations. Based on the calculated queue utilization ratio, we
design a simple model-based admission control scheme. We show that the proposed
call admission control algorithm maintains satisfactory user-perceived quality
for coexisting voice and video connections in an infrastructure BSS and does
not present over- or under-admission problems of previously proposed models in
the literature.
"
8,"Understanding the Characteristics of Internet Short Video Sharing:
  YouTube as a Case Study","  Established in 2005, YouTube has become the most successful Internet site
providing a new generation of short video sharing service. Today, YouTube alone
comprises approximately 20% of all HTTP traffic, or nearly 10% of all traffic
on the Internet. Understanding the features of YouTube and similar video
sharing sites is thus crucial to their sustainable development and to network
traffic engineering. In this paper, using traces crawled in a 3-month period,
we present an in-depth and systematic measurement study on the characteristics
of YouTube videos. We find that YouTube videos have noticeably different
statistics compared to traditional streaming videos, ranging from length and
access pattern, to their active life span, ratings, and comments. The series of
datasets also allows us to identify the growth trend of this fast evolving
Internet site in various aspects, which has seldom been explored before. We
also look closely at the social networking aspect of YouTube, as this is a key
driving force toward its success. In particular, we find that the links to
related videos generated by uploaders' choices form a small-world network. This
suggests that the videos have strong correlations with each other, and creates
opportunities for developing novel caching or peer-to-peer distribution schemes
to efficiently deliver videos to end users.
"
9,Image Authentication Based on Neural Networks,"  Neural network has been attracting more and more researchers since the past
decades. The properties, such as parameter sensitivity, random similarity,
learning ability, etc., make it suitable for information protection, such as
data encryption, data authentication, intrusion detection, etc. In this paper,
by investigating neural networks' properties, the low-cost authentication
method based on neural networks is proposed and used to authenticate images or
videos. The authentication method can detect whether the images or videos are
modified maliciously. Firstly, this chapter introduces neural networks'
properties, such as parameter sensitivity, random similarity, diffusion
property, confusion property, one-way property, etc. Secondly, the chapter
gives an introduction to neural network based protection methods. Thirdly, an
image or video authentication scheme based on neural networks is presented, and
its performances, including security, robustness and efficiency, are analyzed.
Finally, conclusions are drawn, and some open issues in this field are
presented.
"
10,An Application of Chromatic Prototypes,"  This paper has been withdrawn.
"
11,"A quick search method for audio signals based on a piecewise linear
  representation of feature trajectories","  This paper presents a new method for a quick similarity-based search through
long unlabeled audio streams to detect and locate audio clips provided by
users. The method involves feature-dimension reduction based on a piecewise
linear representation of a sequential feature trajectory extracted from a long
audio stream. Two techniques enable us to obtain a piecewise linear
representation: the dynamic segmentation of feature trajectories and the
segment-based Karhunen-L\'{o}eve (KL) transform. The proposed search method
guarantees the same search results as the search method without the proposed
feature-dimension reduction method in principle. Experiment results indicate
significant improvements in search speed. For example the proposed method
reduced the total search time to approximately 1/12 that of previous methods
and detected queries in approximately 0.3 seconds from a 200-hour audio
database.
"
12,Compositional Memory Systems for Multimedia Communicating Tasks,"  Conventional cache models are not suited for real-time parallel processing
because tasks may flush each other's data out of the cache in an unpredictable
manner. In this way the system is not compositional so the overall performance
is difficult to predict and the integration of new tasks expensive. This paper
proposes a new method that imposes compositionality to the system?s performance
and makes different memory hierarchy optimizations possible for multimedia
communicating tasks when running on embedded multiprocessor architectures. The
method is based on a cache allocation strategy that assigns sets of the unified
cache exclusively to tasks and to the communication buffers. We also
analytically formulate the problem and describe a method to compute the cache
partitioning ratio for optimizing the throughput and the consumed power. When
applied to a multiprocessor with memory hierarchy our technique delivers also
performance gain. Compared to the shared cache case, for an application
consisting of two jpeg decoders and one edge detection algorithm 5 times less
misses are experienced and for an mpeg2 decoder 6.5 times less misses are
experienced.
"
13,"Integration, Verification and Layout of a Complex Multimedia SOC","  We present our experience of designing a single-chip controller for advanced
digital still camera from specification all the way to mass production. The
process involves collaboration with camera system designer, IP vendors, EDA
vendors, silicon wafer foundry, package and testing houses, and camera maker.
We also co-work with academic research groups to develop a JPEG codec IP and
memory BIST and SOC testing methodology. In this presentation, we cover the
problems encountered, our solutions, and lessons learned.
"
14,"A High Quality/Low Computational Cost Technique for Block Matching
  Motion Estimation","  Motion estimation is the most critical process in video coding systems. First
of all, it has a definitive impact on the rate-distortion performance given by
the video encoder. Secondly, it is the most computationally intensive process
within the encoding loop. For these reasons, the design of high-performance
low-cost motion estimators is a crucial task in the video compression field. An
adaptive cost block matching (ACBM) motion estimation technique is presented in
this paper, featuring an excellent tradeoff between the quality of the
reconstructed video sequences and the computational effort. Simulation results
demonstrate that the ACBM algorithm achieves a slight better rate-distortion
performance than the one given by the well-known full search algorithm block
matching algorithm with reductions of up to 95% in the computational load.
"
15,Multimedia Applications of Multiprocessor Systems-on-Chips,"  This paper surveys the characteristics of multimedia systems. Multimedia
applications today are dominated by compression and decompression, but
multimedia devices must also implement many other functions such as security
and file management. We introduce some basic concepts of multimedia algorithms
and the larger set of functions that multimedia systems-on-chips must
implement.
"
16,A Coprocessor for Accelerating Visual Information Processing,"  Visual information processing will play an increasingly important role in
future electronics systems. In many applications, e.g. video surveillance
cameras, data throughput of microprocessors is not sufficient and power
consumption is too high. Instruction profiling on a typical test algorithm has
shown that pixel address calculations are the dominant operations to be
optimized. Therefore AddressLib, a structured scheme for pixel addressing was
developed, that can be accelerated by AddressEngine, a coprocessor for visual
information processing. In this paper, the architectural design of
AddressEngine is described, which in the first step supports a subset of the
AddressLib. Dataflow and memory organization are optimized during architectural
design. AddressEngine was implemented in a FPGA and was tested with MPEG-7
Global Motion Estimation algorithm. Results on processing speed and circuit
complexity are given and compared to a pure software implementation. The next
step will be the support for the full AddressLib, including segment addressing.
An outlook on further investigations on dynamic reconfiguration capabilities is
given.
"
17,"An Integrated Design and Verification Methodology for Reconfigurable
  Multimedia Systems","  Recently a lot of multimedia applications are emerging on portable
appliances. They require both the flexibility of upgradeable devices
(traditionally software based) and a powerful computing engine (typically
hardware). In this context, programmable HW and dynamic reconfiguration allow
novel approaches to the migration of algorithms from SW to HW. Thus, in the
frame of the Symbad project, we propose an industrial design flow for
reconfigurable SoC's. The goal of Symbad consists of developing a system level
design platform for hardware and software SoC systems including formal and
semi-formal verification techniques.
"
18,"Cryptanalysis of an image encryption scheme based on a new total
  shuffling algorithm","  Chaotic systems have been broadly exploited through the last two decades to
build encryption methods. Recently, two new image encryption schemes have been
proposed, where the encryption process involves a permutation operation and an
XOR-like transformation of the shuffled pixels, which are controlled by three
chaotic systems. This paper discusses some defects of the schemes and how to
break them with a chosen-plaintext attack.
"
19,Secure Fractal Image Coding,"  In recent work, various fractal image coding methods are reported, which
adopt the self-similarity of images to compress the size of images. However,
till now, no solutions for the security of fractal encoded images have been
provided. In this paper, a secure fractal image coding scheme is proposed and
evaluated, which encrypts some of the fractal parameters during fractal
encoding, and thus, produces the encrypted and encoded image. The encrypted
image can only be recovered by the correct key. To keep secure and efficient,
only the suitable parameters are selected and encrypted through in-vestigating
the properties of various fractal parameters, including parameter space,
parameter distribu-tion and parameter sensitivity. The encryption process does
not change the file format, keeps secure in perception, and costs little time
or computational resources. These properties make it suitable for secure image
encoding or transmission.
"
20,"Cryptanalysis of an Image Encryption Scheme Based on a Compound Chaotic
  Sequence","  Recently, an image encryption scheme based on a compound chaotic sequence was
proposed. In this paper, the security of the scheme is studied and the
following problems are found: (1) a differential chosen-plaintext attack can
break the scheme with only three chosen plain-images; (2) there is a number of
weak keys and some equivalent keys for encryption; (3) the scheme is not
sensitive to the changes of plain-images; and (4) the compound chaotic sequence
does not work as a good random number resource.
"
21,On the Robustness of the Delay-Based Fingerprint Embedding Scheme,"  The delay-based fingerprint embedding was recently proposed to support more
users in secure media distribution scenario. In this embedding scheme, some
users are assigned the same fingerprint code with only different embedding
delay. The algorithm's robustness against collusion attacks is investigated.
However, its robustness against common desynchronization attacks, e.g.,
cropping and time shifting, is not considered. In this paper, desynchronization
attacks are used to break the delay-based fingerprint embedding algorithm. To
improve the robustness, two means are proposed to keep the embedded fingerprint
codes synchronized, i.e., adding a synchronization fingerprint and adopting the
relative delay to detect users. Analyses and experiments are given to show the
improvements.
"
22,On the Capacity and Design of Limited Feedback Multiuser MIMO Uplinks,"  The theory of multiple-input multiple-output (MIMO) technology has been
well-developed to increase fading channel capacity over single-input
single-output (SISO) systems. This capacity gain can often be leveraged by
utilizing channel state information at the transmitter and the receiver. Users
make use of this channel state information for transmit signal adaptation. In
this correspondence, we derive the capacity region for the MIMO multiple access
channel (MIMO MAC) when partial channel state information is available at the
transmitters, where we assume a synchronous MIMO multiuser uplink. The partial
channel state information feedback has a cardinality constraint and is fed back
from the basestation to the users using a limited rate feedback channel. Using
this feedback information, we propose a finite codebook design method to
maximize sum-rate. In this correspondence, the codebook is a set of transmit
signal covariance matrices. We also derive the capacity region and codebook
design methods in the case that the covariance matrix is rank-one (i.e.,
beamforming). This is motivated by the fact that beamforming is optimal in
certain conditions. The simulation results show that when the number of
feedback bits increases, the capacity also increases. Even with a small number
of feedback bits, the performance of the proposed system is close to an optimal
solution with the full feedback.
"
23,"Some Aspects of Testing Process for Transport Streams in Digital Video
  Broadcasting","  This paper presents some aspects related to the DVB (Digital Video
Broadcasting) investigation. The basic aspects of DVB are presented, with an
emphasis on DVB-T version of standard. The main purpose of this research is to
analyze the way that the transmission of the transport streams is realized in
case of the Terrestrial Digital Video Broadcasting (DVB-T). To accomplish this,
first, Digital Video Broadcasting standard is presented, and then the main
aspects of DVB testing and analysis of the transport streams are investigated.
The paper presents also the results obtained using two programs designed for
DVB analysis: Mosalina and TSA.
"
24,"Implementing a Test Strategy for an Advanced Video Acquisition and
  Processing Architecture","  This paper presents some aspects related to test process of an advanced video
system used in remote IP surveillance. The system is based on a Pentium
compatible architecture using the industrial standard PC104+. First the overall
architecture of the system is presented, involving both hardware or software
aspects. The acquisition board which is developed in a special, nonstandard
architecture, is also briefly presented. The main purpose of this research was
to set a coherent set of procedures in order to test all the aspects of the
video acquisition board. To accomplish this, it was necessary to set-up a
procedure in two steps: stand alone video board test (functional test) and an
in-system test procedure verifying the compatibility with both OS: Linux and
Windows. The paper presents also the results obtained using this procedure.
"
25,"Acquisition Accuracy Evaluation in Visual Inspection Systems - a
  Practical Approach","  This paper draws a proposal of a set of parameters and methods for accuracy
evaluation of visual inspection systems. The case of a monochrome board is
treated, but practically all conclusions and methods may be extended for colour
acquisition. Basically, the proposed parameters are grouped in five sets as
follows:Internal noise;Video ADC cuantisation parameters;Analogue processing
section parameters;Dominant frequencies;Synchronisation (lock-in) accuracy. On
basis of this set of parameters was developed a software environment, in
conjunction with a test signal generator that allows the ""test"" images. The
paper also presents conclusions of evaluation for two types of video
acquisition boards
"
26,Multi-dimensional sparse time series: feature extraction,"  We show an analysis of multi-dimensional time series via entropy and
statistical linguistic techniques. We define three markers encoding the
behavior of the series, after it has been translated into a multi-dimensional
symbolic sequence. The leading component and the trend of the series with
respect to a mobile window analysis result from the entropy analysis and label
the dynamical evolution of the series. The diversification formalizes the
differentiation in the use of recurrent patterns, from a Zipf law point of
view. These markers are the starting point of further analysis such as
classification or clustering of large database of multi-dimensional time
series, prediction of future behavior and attribution of new data. We also
present an application to economic data. We deal with measurements of money
investments of some business companies in advertising market for different
media sources.
"
27,SecMon: End-to-End Quality and Security Monitoring System,"  The Voice over Internet Protocol (VoIP) is becoming a more available and
popular way of communicating for Internet users. This also applies to
Peer-to-Peer (P2P) systems and merging these two have already proven to be
successful (e.g. Skype). Even the existing standards of VoIP provide an
assurance of security and Quality of Service (QoS), however, these features are
usually optional and supported by limited number of implementations. As a
result, the lack of mandatory and widely applicable QoS and security guaranties
makes the contemporary VoIP systems vulnerable to attacks and network
disturbances. In this paper we are facing these issues and propose the SecMon
system, which simultaneously provides a lightweight security mechanism and
improves quality parameters of the call. SecMon is intended specially for VoIP
service over P2P networks and its main advantage is that it provides
authentication, data integrity services, adaptive QoS and (D)DoS attack
detection. Moreover, the SecMon approach represents a low-bandwidth consumption
solution that is transparent to the users and possesses a self-organizing
capability. The above-mentioned features are accomplished mainly by utilizing
two information hiding techniques: digital audio watermarking and network
steganography. These techniques are used to create covert channels that serve
as transport channels for lightweight QoS measurement's results. Furthermore,
these metrics are aggregated in a reputation system that enables best route
path selection in the P2P network. The reputation system helps also to mitigate
(D)DoS attacks, maximize performance and increase transmission efficiency in
the network.
"
28,Characterizing Video Responses in Social Networks,"  Video sharing sites, such as YouTube, use video responses to enhance the
social interactions among their users. The video response feature allows users
to interact and converse through video, by creating a video sequence that
begins with an opening video and followed by video responses from other users.
Our characterization is over 3.4 million videos and 400,000 video responses
collected from YouTube during a 7-day period. We first analyze the
characteristics of the video responses, such as popularity, duration, and
geography. We then examine the social networks that emerge from the video
response interactions.
"
29,Steganography of VoIP Streams,"  The paper concerns available steganographic techniques that can be used for
creating covert channels for VoIP (Voice over Internet Protocol) streams. Apart
from characterizing existing steganographic methods we provide new insights by
presenting two new techniques. The first one is network steganography solution
which exploits free/unused protocols' fields and is known for IP, UDP or TCP
protocols but has never been applied to RTP (Real-Time Transport Protocol) and
RTCP (Real-Time Control Protocol) which are characteristic for VoIP. The second
method, called LACK (Lost Audio Packets Steganography), provides hybrid
storage-timing covert channel by utilizing delayed audio packets. The results
of the experiment, that was performed to estimate a total amount of data that
can be covertly transferred during typical VoIP conversation phase, regardless
of steganalysis, are also included in this paper.
"
30,Covert Channels in SIP for VoIP signalling,"  In this paper, we evaluate available steganographic techniques for SIP
(Session Initiation Protocol) that can be used for creating covert channels
during signaling phase of VoIP (Voice over IP) call. Apart from characterizing
existing steganographic methods we provide new insights by introducing new
techniques. We also estimate amount of data that can be transferred in
signalling messages for typical IP telephony call.
"
31,On the Superdistribution of Digital Goods,"  Business models involving buyers of digital goods in the distribution process
are called superdistribution schemes. We review the state-of-the art of
research and application of superdistribution and propose systematic approach
to market mechanisms using super-distribution and technical system
architectures supporting it. The limiting conditions on such markets are of
economic, legal, technical, and psychological nature.
"
32,Scalar Quantization for Audio Data Coding,"  This paper is concerned with scalar quantization of transform coefficients in
an audio codec. The generalized Gaussian distribution (GGD) is used as an
approximation of one-dimensional probability density function for transform
coefficients obtained by modulated lapped transform (MLT) or modified cosine
transform (MDCT) filterbank. The rationale of the model is provided in
comparison with theoretically achievable rate-distortion function. The
rate-distortion function computed for the random sequence obtained from a real
sequence of samples from a large database is compared with that computed for
random sequence obtained by a GGD random generator. A simple algorithm of
constructing the Extended Zero Zone (EZZ) quantizer is proposed. Simulation
results show that the EZZ quantizer yields a negligible loss in terms of coding
efficiency compared to optimal scalar quantizers. Furthermore, we describe an
adaptive version of the EZZ quantizer which works efficiently with low bitrate
requirements for transmitting side information
"
33,"Avatar Mobility in Networked Virtual Environments: Measurements,
  Analysis, and Implications","  We collected mobility traces of 84,208 avatars spanning 22 regions over two
months in Second Life, a popular networked virtual environment. We analyzed the
traces to characterize the dynamics of the avatars mobility and behavior, both
temporally and spatially. We discuss the implications of the our findings to
the design of peer-to-peer networked virtual environments, interest management,
mobility modeling of avatars, server load balancing and zone partitioning,
client-side caching, and prefetching.
"
34,A Reliable SVD based Watermarking Schem,"  We propose a novel scheme for watermarking of digital images based on
singular value decomposition (SVD), which makes use of the fact that the SVD
subspace preserves significant amount of information of an image, as compared
to its singular value matrix, Zhang and Li (2005). The principal components of
the watermark are embedded in the original image, leaving the detector with a
complimentary set of singular vectors for watermark extraction. The above step
invariably ensures that watermark extraction from the embedded watermark image,
using a modified matrix, is not possible, thereby removing a major drawback of
an earlier proposed algorithm by Liu and Tan (2002).
"
35,Computer Art in the Former Soviet Bloc,"  Documents early computer art in the Soviet bloc and describes Marxist art
theory.
"
36,A First Step to Convolutive Sparse Representation,"  In this paper an extension of the sparse decomposition problem is considered
and an algorithm for solving it is presented. In this extension, it is known
that one of the shifted versions of a signal s (not necessarily the original
signal itself) has a sparse representation on an overcomplete dictionary, and
we are looking for the sparsest representation among the representations of all
the shifted versions of s. Then, the proposed algorithm finds simultaneously
the amount of the required shift, and the sparse representation. Experimental
results emphasize on the performance of our algorithm.
"
37,An Export Architecture for a Multimedia Authoring Environment,"  In this paper, we propose an export architecture that provides a clear
separation of authoring services from publication services. We illustrate this
architecture with the LimSee3 authoring tool and several standard publication
formats: Timesheets, SMIL, and XHTML.
"
38,Initial Offset Placement in p2p Live Streaming Systems,"  Initial offset placement in p2p streaming systems is studied in this paper.
Proportional placement (PP) scheme is proposed. In this scheme, peer places the
initial offset as the offset reported by other reference peer with a shift
proportional to the buffer width or offset lag of this reference peer. This
will introduce a stable placement that supports larger buffer width for peers
and small buffer width for tracker. Real deployed placement method in PPLive is
studied through measurement. It shows that, instead of based on offset lag, the
placement is based on buffer width of the reference peer to facilitate the
initial chunk fetching. We will prove that, such a PP scheme may not be stable
under arbitrary buffer occupation in the reference peer. The required average
buffer width then is derived. A simple good peer selection mechanism to check
the buffer occupation of reference peer is proposed for a stable PP scheme
based on buffer width
"
39,"Optimization of automatically generated multi-core code for the LTE
  RACH-PD algorithm","  Embedded real-time applications in communication systems require high
processing power. Manual scheduling devel-oped for single-processor
applications is not suited to multi-core architectures. The Algorithm
Architecture Matching (AAM) methodology optimizes static application
implementation on multi-core architectures. The Random Access Channel Preamble
Detection (RACH-PD) is an algorithm for non-synchronized access of Long Term
Evolu-tion (LTE) wireless networks. LTE aims to improve the spectral efficiency
of the next generation cellular system. This paper de-scribes a complete
methodology for implementing the RACH-PD. AAM prototyping is applied to the
RACH-PD which is modelled as a Synchronous DataFlow graph (SDF). An efficient
implemen-tation of the algorithm onto a multi-core DSP, the TI C6487, is then
explained. Benchmarks for the solution are given.
"
40,"Characterization and collection of information from heterogeneous
  multimedia sources with users' parameters for decision support","  No single information source can be good enough to satisfy the divergent and
dynamic needs of users all the time. Integrating information from divergent
sources can be a solution to deficiencies in information content. We present
how Information from multimedia document can be collected based on associating
a generic database to a federated database. Information collected in this way
is brought into relevance by integrating the parameters of usage and user's
parameter for decision making. We identified seven different classifications of
multimedia document.
"
41,Approximate Sparse Decomposition Based on Smoothed L0-Norm,"  In this paper, we propose a method to address the problem of source
estimation for Sparse Component Analysis (SCA) in the presence of additive
noise. Our method is a generalization of a recently proposed method (SL0),
which has the advantage of directly minimizing the L0-norm instead of L1-norm,
while being very fast. SL0 is based on minimization of the smoothed L0-norm
subject to As=x. In order to better estimate the source vector for noisy
mixtures, we suggest then to remove the constraint As=x, by relaxing exact
equality to an approximation (we call our method Smoothed L0-norm Denoising or
SL0DN). The final result can then be obtained by minimization of a proper
linear combination of the smoothed L0-norm and a cost function for the
approximation. Experimental results emphasize on the significant enhancement of
the modified method in noisy cases.
"
42,LACK - a VoIP Steganographic Method,"  The paper presents a new steganographic method called LACK (Lost Audio
PaCKets Steganography) which is intended mainly for VoIP. The method is
presented in a broader context of network steganography and of VoIP
steganography in particular. The analytical results presented in the paper
concern the influence of LACK's hidden data insertion procedure on the method's
impact on quality of voice transmission and its resistance to steganalysis.
"
43,"Wide spread spectrum watermarking with side information and interference
  cancellation","  Nowadays, a popular method used for additive watermarking is wide spread
spectrum. It consists in adding a spread signal into the host document. This
signal is obtained by the sum of a set of carrier vectors, which are modulated
by the bits to be embedded. To extract these embedded bits, weighted
correlations between the watermarked document and the carriers are computed.
Unfortunately, even without any attack, the obtained set of bits can be
corrupted due to the interference with the host signal (host interference) and
also due to the interference with the others carriers (inter-symbols
interference (ISI) due to the non-orthogonality of the carriers). Some recent
watermarking algorithms deal with host interference using side informed
methods, but inter-symbols interference problem is still open. In this paper,
we deal with interference cancellation methods, and we propose to consider ISI
as side information and to integrate it into the host signal. This leads to a
great improvement of extraction performance in term of signal-to-noise ratio
and/or watermark robustness.
"
44,"Fast and Quality-Guaranteed Data Streaming in Resource-Constrained
  Sensor Networks","  In many emerging applications, data streams are monitored in a network
environment. Due to limited communication bandwidth and other resource
constraints, a critical and practical demand is to online compress data streams
continuously with quality guarantee. Although many data compression and digital
signal processing methods have been developed to reduce data volume, their
super-linear time and more-than-constant space complexity prevents them from
being applied directly on data streams, particularly over resource-constrained
sensor networks. In this paper, we tackle the problem of online quality
guaranteed compression of data streams using fast linear approximation (i.e.,
using line segments to approximate a time series). Technically, we address two
versions of the problem which explore quality guarantees in different forms. We
develop online algorithms with linear time complexity and constant cost in
space. Our algorithms are optimal in the sense they generate the minimum number
of segments that approximate a time series with the required quality guarantee.
To meet the resource constraints in sensor networks, we also develop a fast
algorithm which creates connecting segments with very simple computation. The
low cost nature of our methods leads to a unique edge on the applications of
massive and fast streaming environment, low bandwidth networks, and heavily
constrained nodes in computational power. We implement and evaluate our methods
in the application of an acoustic wireless sensor network.
"
45,"The Good, the Bad, and the Ugly: three different approaches to break
  their watermarking system","  The Good is Blondie, a wandering gunman with a strong personal sense of
honor. The Bad is Angel Eyes, a sadistic hitman who always hits his mark. The
Ugly is Tuco, a Mexican bandit who's always only looking out for himself.
Against the backdrop of the BOWS contest, they search for a watermark in gold
buried in three images. Each knows only a portion of the gold's exact location,
so for the moment they're dependent on each other. However, none are
particularly inclined to share...
"
46,"Informed stego-systems in active warden context: statistical
  undetectability and capacity","  Several authors have studied stego-systems based on Costa scheme, but just a
few ones gave both theoretical and experimental justifications of these schemes
performance in an active warden context. We provide in this paper a
steganographic and comparative study of three informed stego-systems in active
warden context: scalar Costa scheme, trellis-coded quantization and spread
transform scalar Costa scheme. By leading on analytical formulations and on
experimental evaluations, we show the advantages and limits of each scheme in
term of statistical undetectability and capacity in the case of active warden.
Such as the undetectability is given by the distance between the stego-signal
and the cover distance. It is measured by the Kullback-Leibler distance.
"
47,Trellis-coded quantization for public-key steganography,"  This paper deals with public-key steganography in the presence of a passive
warden. The aim is to hide secret messages within cover-documents without
making the warden suspicious, and without any preliminar secret key sharing.
Whereas a practical attempt has been already done to provide a solution to this
problem, it suffers of poor flexibility (since embedding and decoding steps
highly depend on cover-signals statistics) and of little capacity compared to
recent data hiding techniques. Using the same framework, this paper explores
the use of trellis-coded quantization techniques (TCQ and turbo TCQ) to design
a more efficient public-key scheme. Experiments on audio signals show great
improvements considering Cachin's security criterion.
"
48,"Information-theoretic resolution of perceptual WSS watermarking of non
  i.i.d. Gaussian signals","  The theoretical foundations of data hiding have been revealed by formulating
the problem as message communication over a noisy channel. We revisit the
problem in light of a more general characterization of the watermark channel
and of weighted distortion measures. Considering spread spectrum based
information hiding, we release the usual assumption of an i.i.d. cover signal.
The game-theoretic resolution of the problem reveals a generalized
characterization of optimum attacks. The paper then derives closed-form
expressions for the different parameters exhibiting a practical embedding and
extraction technique.
"
49,A new Contrast Based Image Fusion using Wavelet Packets,"  Image Fusion, a technique which combines complimentary information from
different images of the same scene so that the fused image is more suitable for
segmentation, feature extraction, object recognition and Human Visual System.
In this paper, a simple yet efficient algorithm is presented based on contrast
using wavelet packet decomposition. First, all the source images are decomposed
into low and high frequency sub-bands and then fusion of high frequency
sub-bands is done by the means of Directive Contrast. Now, inverse wavelet
packet transform is performed to reconstruct the fused image. The performance
of the algorithm is carried out by the comparison made between proposed and
existing algorithm.
"
50,"Decomposition Principles and Online Learning in Cross-Layer Optimization
  for Delay-Sensitive Applications","  In this paper, we propose a general cross-layer optimization framework in
which we explicitly consider both the heterogeneous and dynamically changing
characteristics of delay-sensitive applications and the underlying time-varying
network conditions. We consider both the independently decodable data units
(DUs, e.g. packets) and the interdependent DUs whose dependencies are captured
by a directed acyclic graph (DAG). We first formulate the cross-layer design as
a non-linear constrained optimization problem by assuming complete knowledge of
the application characteristics and the underlying network conditions. The
constrained cross-layer optimization is decomposed into several cross-layer
optimization subproblems for each DU and two master problems. The proposed
decomposition method determines the necessary message exchanges between layers
for achieving the optimal cross-layer solution. However, the attributes (e.g.
distortion impact, delay deadline etc) of future DUs as well as the network
conditions are often unknown in the considered real-time applications. The
impact of current cross-layer actions on the future DUs can be characterized by
a state-value function in the Markov decision process (MDP) framework. Based on
the dynamic programming solution to the MDP, we develop a low-complexity
cross-layer optimization algorithm using online learning for each DU
transmission. This online algorithm can be implemented in real-time in order to
cope with unknown source characteristics, network dynamics and resource
constraints. Our numerical results demonstrate the efficiency of the proposed
online algorithm.
"
51,"A New Trend in Optimization on Multi Overcomplete Dictionary toward
  Inpainting","  Recently, great attention was intended toward overcomplete dictionaries and
the sparse representations they can provide. In a wide variety of signal
processing problems, sparsity serves a crucial property leading to high
performance. Inpainting, the process of reconstructing lost or deteriorated
parts of images or videos, is an interesting application which can be handled
by suitably decomposition of an image through combination of overcomplete
dictionaries. This paper addresses a novel technique of such a decomposition
and investigate that through inpainting of images. Simulations are presented to
demonstrate the validation of our approach.
"
52,"Probabilistic SVM/GMM Classifier for Speaker-Independent Vowel
  Recognition in Continues Speech","  In this paper, we discuss the issues in automatic recognition of vowels in
Persian language. The present work focuses on new statistical method of
recognition of vowels as a basic unit of syllables. First we describe a vowel
detection system then briefly discuss how the detected vowels can feed to
recognition unit. According to pattern recognition, Support Vector Machines
(SVM) as a discriminative classifier and Gaussian mixture model (GMM) as a
generative model classifier are two most popular techniques. Current
state-ofthe- art systems try to combine them together for achieving more power
of classification and improving the performance of the recognition systems. The
main idea of the study is to combine probabilistic SVM and traditional GMM
pattern classification with some characteristic of speech like band-pass energy
to achieve better classification rate. This idea has been analytically
formulated and tested on a FarsDat based vowel recognition system. The results
show inconceivable increases in recognition accuracy. The tests have been
carried out by various proposed vowel recognition algorithms and the results
have been compared.
"
53,"Kalinahia: Considering Quality of Service to Design and Execute
  Distributed Multimedia Applications","  One of the current challenges of Information Systems is to ensure
semi-structured data transmission, such as multimedia data, in a distributed
and pervasive environment. Information Sytems must then guarantee users a
quality of service ensuring data accessibility whatever the hardware and
network conditions may be. They must also guarantee information coherence and
particularly intelligibility that imposes a personalization of the service.
Within this framework, we propose a design method based on original models of
multimedia applications and quality of service. We also define a supervision
platform Kalinahia using a user centered heuristic allowing us to define at any
moment which configuration of software components constitutes the best answers
to users' wishes in terms of service.
"
54,The Korrontea Data Modeling,"  Needs of multimedia systems evolved due to the evolution of their
architecture which is now distributed into heterogeneous contexts. A critical
issue lies in the fact that they handle, process, and transmit multimedia data.
This data integrates several properties which should be considered since it
holds a considerable part of its semantics, for instance the lips
synchronization in a video. In this paper, we focus on the definition of a
model as a basic abstraction for describing and modeling media in multimedia
systems by taking into account their properties. This model will be used in
software architecture in order to handle data in efficient way. The provided
model is an interesting solution for the integration of media into
applications; we propose to consider and to handle them in a uniform way. This
model is proposed with synchronization policies to ensure synchronous transport
of media. Therefore, we use it in a component model that we develop for the
design and deployment of distributed multimedia systems.
"
55,"Heterogeneous component interactions: Sensors integration into
  multimedia applications","  Resource-constrained embedded and mobile devices are becoming increasingly
common. Since few years, some mobile and ubiquitous devices such as wireless
sensor, able to be aware of their physical environment, appeared. Such devices
enable proposing applications which adapt to user's need according the context
evolution. It implies the collaboration of sensors and software components
which differ on their nature and their communication mechanisms. This paper
proposes a unified component model in order to easily design applications based
on software components and sensors without taking care of their nature. Then it
presents a state of the art of communication problems linked to heterogeneous
components and proposes an interaction mechanism which ensures information
exchanges between wireless sensors and software components.
"
56,Exact Histogram Specification Optimized for Structural Similarity,"  An exact histogram specification (EHS) method modifies its input image to
have a specified histogram. Applications of EHS include image (contrast)
enhancement (e.g., by histogram equalization) and histogram watermarking.
Performing EHS on an image, however, reduces its visual quality. Starting from
the output of a generic EHS method, we maximize the structural similarity index
(SSIM) between the original image (before EHS) and the result of EHS
iteratively. Essential in this process is the computationally simple and
accurate formula we derive for SSIM gradient. As it is based on gradient
ascent, the proposed EHS always converges. Experimental results confirm that
while obtaining the histogram exactly as specified, the proposed method
invariably outperforms the existing methods in terms of visual quality of the
result. The computational complexity of the proposed method is shown to be of
the same order as that of the existing methods.
  Index terms: histogram modification, histogram equalization, optimization for
perceptual visual quality, structural similarity gradient ascent, histogram
watermarking, contrast enhancement.
"
57,"Condition for Energy Efficient Watermarking with Random Vector Model
  without WSS Assumption","  Energy efficient watermarking preserves the watermark energy after linear
attack as much as possible. We consider in this letter non-stationary signal
models and derive conditions for energy efficient watermarking under random
vector model without WSS assumption. We find that the covariance matrix of the
energy efficient watermark should be proportional to host covariance matrix to
best resist the optimal linear removal attacks. In WSS process our result
reduces to the well known power spectrum condition. Intuitive geometric
interpretation of the results are also discussed which in turn also provide
more simpler proof of the main results.
"
58,"Over-enhancement Reduction in Local Histogram Equalization using its
  Degrees of Freedom","  A well-known issue of local (adaptive) histogram equalization (LHE) is
over-enhancement (i.e., generation of spurious details) in homogenous areas of
the image. In this paper, we show that the LHE problem has many solutions due
to the ambiguity in ranking pixels with the same intensity. The LHE solution
space can be searched for the images having the maximum PSNR or structural
similarity (SSIM) with the input image. As compared to the results of the prior
art, these solutions are more similar to the input image while offering the
same local contrast.
  Index Terms: histogram modification or specification, contrast enhancement
"
59,"Fundamental delay bounds in peer-to-peer chunk-based real-time streaming
  systems","  This paper addresses the following foundational question: what is the maximum
theoretical delay performance achievable by an overlay peer-to-peer streaming
system where the streamed content is subdivided into chunks? As shown in this
paper, when posed for chunk-based systems, and as a consequence of the
store-and-forward way in which chunks are delivered across the network, this
question has a fundamentally different answer with respect to the case of
systems where the streamed content is distributed through one or more flows
(sub-streams). To circumvent the complexity emerging when directly dealing with
delay, we express performance in term of a convenient metric, called ""stream
diffusion metric"". We show that it is directly related to the end-to-end
minimum delay achievable in a P2P streaming network. In a homogeneous scenario,
we derive a performance bound for such metric, and we show how this bound
relates to two fundamental parameters: the upload bandwidth available at each
node, and the number of neighbors a node may deliver chunks to. In this bound,
k-step Fibonacci sequences do emerge, and appear to set the fundamental laws
that characterize the optimal operation of chunk-based systems.
"
60,A Standalone Markerless 3D Tracker for Handheld Augmented Reality,"  This paper presents an implementation of a markerless tracking technique
targeted to the Windows Mobile Pocket PC platform. The primary aim of this work
is to allow the development of standalone augmented reality applications for
handheld devices based on natural feature tracking. In order to achieve this
goal, a subset of two computer vision libraries was ported to the Pocket PC
platform. They were also adapted to use fixed point math, with the purpose of
improving the overall performance of the routines. The port of these libraries
opens up the possibility of having other computer vision tasks being executed
on mobile platforms. A model based tracking approach that relies on edge
information was adopted. Since it does not require a high processing power, it
is suitable for constrained devices such as handhelds. The OpenGL ES graphics
library was used to perform computer vision tasks, taking advantage of existing
graphics hardware acceleration. An augmented reality application was created
using the implemented technique and evaluations were done regarding tracking
performance and accuracy
"
61,ImageSpace: An Environment for Image Ontology Management,"  More and more researchers have realized that ontologies will play a critical
role in the development of the Semantic Web, the next generation Web in which
content is not only consumable by humans, but also by software agents. The
development of tools to support ontology management including creation,
visualization, annotation, database storage, and retrieval is thus extremely
important. We have developed ImageSpace, an image ontology creation and
annotation tool that features (1) full support for the standard web ontology
language DAML+OIL; (2) image ontology creation, visualization, image annotation
and display in one integrated framework; (3) ontology consistency assurance;
and (4) storing ontologies and annotations in relational databases. It is
expected that the availability of such a tool will greatly facilitate the
creation of image repositories as islands of the Semantic Web.
"
62,OntoELAN: An Ontology-based Linguistic Multimedia Annotator,"  Despite its scientific, political, and practical value, comprehensive
information about human languages, in all their variety and complexity, is not
readily obtainable and searchable. One reason is that many language data are
collected as audio and video recordings which imposes a challenge to document
indexing and retrieval. Annotation of multimedia data provides an opportunity
for making the semantics explicit and facilitates the searching of multimedia
documents. We have developed OntoELAN, an ontology-based linguistic multimedia
annotator that features: (1) support for loading and displaying ontologies
specified in OWL; (2) creation of a language profile, which allows a user to
choose a subset of terms from an ontology and conveniently rename them if
needed; (3) creation of ontological tiers, which can be annotated with profile
terms and, therefore, corresponding ontological terms; and (4) saving
annotations in the XML format as Multimedia Ontology class instances and,
linked to them, class instances of other ontologies used in ontological tiers.
To our best knowledge, OntoELAN is the first audio/video annotation tool in
linguistic domain that provides support for ontology-based annotation.
"
63,"Ontology-Based Annotation of Multimedia Language Data for the Semantic
  Web","  There is an increasing interest and effort in preserving and documenting
endangered languages. Language data are valuable only when they are
well-cataloged, indexed and searchable. Many language data, particularly those
of lesser-spoken languages, are collected as audio and video recordings. While
multimedia data provide more channels and dimensions to describe a language's
function, and gives a better presentation of the cultural system associated
with the language of that community, they are not text-based or structured (in
binary format), and their semantics is implicit in their content. The content
is thus easy for a human being to understand, but difficult for computers to
interpret. Hence, there is a great need for a powerful and user-friendly system
to annotate multimedia data with text-based, well-structured and searchable
metadata. This chapter describes an ontology-based multimedia annotation tool,
OntoELAN, that enables annotation of language multimedia data with a linguistic
ontology.
"
64,"Optimal Control of a Single Queue with Retransmissions: Delay-Dropping
  Tradeoffs","  A single queue incorporating a retransmission protocol is investigated,
assuming that the sequence of per effort success probabilities in the Automatic
Retransmission reQuest (ARQ) chain is a priori defined and no channel state
information at the transmitter is available. A Markov Decision Problem with an
average cost criterion is formulated where the possible actions are to either
continue the retransmission process of an erroneous packet at the next time
slot or to drop the packet and move on to the next packet awaiting for
transmission. The cost per slot is a linear combination of the current queue
length and a penalty term in case dropping is chosen as action. The
investigation seeks policies that provide the best possible average packet
delay-dropping trade-off for Quality of Service guarantees. An optimal
deterministic stationary policy is shown to exist, several structural
properties of which are obtained. Based on that, a class of suboptimal
<L,K>-policies is introduced. These suggest that it is almost optimal to use a
K-truncated ARQ protocol as long as the queue length is lower than L, else send
all packets in one shot. The work concludes with an evaluation of the optimal
delay-dropping tradeoff using dynamic programming and a comparison between the
optimal and suboptimal policies.
"
65,"A Systematic Framework for Dynamically Optimizing Multi-User Wireless
  Video Transmission","  In this paper, we formulate the collaborative multi-user wireless video
transmission problem as a multi-user Markov decision process (MUMDP) by
explicitly considering the users' heterogeneous video traffic characteristics,
time-varying network conditions and the resulting dynamic coupling between the
wireless users. These environment dynamics are often ignored in existing
multi-user video transmission solutions. To comply with the decentralized
nature of wireless networks, we propose to decompose the MUMDP into local MDPs
using Lagrangian relaxation. Unlike in conventional multi-user video
transmission solutions stemming from the network utility maximization
framework, the proposed decomposition enables each wireless user to
individually solve its own dynamic cross-layer optimization (i.e. the local
MDP) and the network coordinator to update the Lagrangian multipliers (i.e.
resource prices) based on not only current, but also future resource needs of
all users, such that the long-term video quality of all users is maximized.
However, solving the MUMDP requires statistical knowledge of the experienced
environment dynamics, which is often unavailable before transmission time. To
overcome this obstacle, we then propose a novel online learning algorithm,
which allows the wireless users to update their policies in multiple states
during one time slot. This is different from conventional learning solutions,
which often update one state per time slot. The proposed learning algorithm can
significantly improve the learning performance, thereby dramatically improving
the video quality experienced by the wireless users over time. Our simulation
results demonstrate the efficiency of the proposed MUMDP framework as compared
to conventional multi-user video transmission solutions.
"
66,"A Novel Approach for Compression of Images Captured using Bayer Color
  Filter Arrays","  We propose a new approach for image compression in digital cameras, where the
goal is to achieve better quality at a given rate by using the characteristics
of a Bayer color filter array. Most digital cameras produce color images by
using a single CCD plate, so that each pixel in an image has only one color
component and therefore an interpolation method is needed to produce a full
color image. After the image processing stage, in order to reduce the memory
requirements of the camera, a lossless or lossy compression stage often
follows. But in this scheme, before decreasing redundancy through compression,
redundancy is increased in an interpolation stage. In order to avoid increasing
the redundancy before compression, we propose algorithms for image compression
in which the order of the compression and interpolation stages is reversed. We
introduce image transform algorithms, since non interpolated images cannot be
directly compressed with general image coders. The simulation results show that
our algorithm outperforms conventional methods with various color interpolation
methods in a wide range of compression ratios. Our proposed algorithm provides
not only better quality but also lower encoding complexity because the amount
of luminance data used is only half of that in conventional methods.
"
67,Efficiently Learning a Detection Cascade with Sparse Eigenvectors,"  In this work, we first show that feature selection methods other than
boosting can also be used for training an efficient object detector. In
particular, we introduce Greedy Sparse Linear Discriminant Analysis (GSLDA)
\cite{Moghaddam2007Fast} for its conceptual simplicity and computational
efficiency; and slightly better detection performance is achieved compared with
\cite{Viola2004Robust}. Moreover, we propose a new technique, termed Boosted
Greedy Sparse Linear Discriminant Analysis (BGSLDA), to efficiently train a
detection cascade. BGSLDA exploits the sample re-weighting property of boosting
and the class-separability criterion of GSLDA.
"
68,"Gradient-based adaptive interpolation in super-resolution image
  restoration","  This paper presents a super-resolution method based on gradient-based
adaptive interpolation. In this method, in addition to considering the distance
between the interpolated pixel and the neighboring valid pixel, the
interpolation coefficients take the local gradient of the original image into
account. The smaller the local gradient of a pixel is, the more influence it
should have on the interpolated pixel. And the interpolated high resolution
image is finally deblurred by the application of wiener filter. Experimental
results show that our proposed method not only substantially improves the
subjective and objective quality of restored images, especially enhances edges,
but also is robust to the registration error and has low computational
complexity.
"
69,"Overlay Structure for Large Scale Content Sharing: Leveraging Geography
  as the Basis for Routing Locality","  In this paper we place our arguments on two related issues in the design of
generalized structured peer-to-peer overlays. First, we argue that for the
large-scale content-sharing applications, lookup and content transport
functions need to be treated separately. Second, to create a location-based
routing overlay suitable for content sharing and other applications, we argue
that off-the-shelf geographic coordinates of Internet-connected hosts can be
used as a basis. We then outline the design principles and present a design for
the generalized routing overlay based on adaptive hierarchical partitioning of
the geographical space.
"
70,Virtual Reality,"  This paper is focused on the presentation of Virtual Reality principles
together with the main implementation methods and techniques. An overview of
the main development directions is included.
"
71,"CliqueStream: an efficient and fault-resilient live streaming network on
  a clustered peer-to-peer overlay","  Several overlay-based live multimedia streaming platforms have been proposed
in the recent peer-to-peer streaming literature. In most of the cases, the
overlay neighbors are chosen randomly for robustness of the overlay. However,
this causes nodes that are distant in terms of proximity in the underlying
physical network to become neighbors, and thus data travels unnecessary
distances before reaching the destination. For efficiency of bulk data
transmission like multimedia streaming, the overlay neighborhood should
resemble the proximity in the underlying network. In this paper, we exploit the
proximity and redundancy properties of a recently proposed clique-based
clustered overlay network, named eQuus, to build efficient as well as robust
overlays for multimedia stream dissemination. To combine the efficiency of
content pushing over tree structured overlays and the robustness of data-driven
mesh overlays, higher capacity stable nodes are organized in tree structure to
carry the long haul traffic and less stable nodes with intermittent presence
are organized in localized meshes. The overlay construction and fault-recovery
procedures are explained in details. Simulation study demonstrates the good
locality properties of the platform. The outage time and control overhead
induced by the failure recovery mechanism are minimal as demonstrated by the
analysis.
"
72,"A Distributed Software Architecture for Collaborative Teleoperation
  based on a VR Platform and Web Application Interoperability","  Augmented Reality and Virtual Reality can provide to a Human Operator (HO) a
real help to complete complex tasks, such as robot teleoperation and
cooperative teleassistance. Using appropriate augmentations, the HO can
interact faster, safer and easier with the remote real world. In this paper, we
present an extension of an existing distributed software and network
architecture for collaborative teleoperation based on networked human-scaled
mixed reality and mobile platform. The first teleoperation system was composed
by a VR application and a Web application. However the 2 systems cannot be used
together and it is impossible to control a distant robot simultaneously. Our
goal is to update the teleoperation system to permit a heterogeneous
collaborative teleoperation between the 2 platforms. An important feature of
this interface is based on different Mobile platforms to control one or many
robots.
"
73,"The Multimedia Product - between Design and Information, Design and
  Utility and Design and Entertainment","  The paper investigates the possible coherent and effective alternatives to
solve the problems related to the communication needs of any multimedia
product. In essence, the presentation will focus on identifying the issues and
principles governing three types of the design - in fact, the multimedia design
in a broader sense - namely the information design - precisely aiming at ways
of organization and presentation of information in a useful and significant
form, the graphical user interface design, whose sub-domain consists of the
information displayed on the monitor screen and of interactivity between user,
computer and electronic devices, meaning, in fact, everything the user sees,
touches, hears and all the elements with which he interacts, the graphic
design, whose main concern is to create an aesthetic layout arrangement (from
the visual and perceptive) information.
"
74,"The new multimedia educational technologies, used in open and distance
  learning","  This paper reviews and refers to the latest telematics technology that has
turned the open system learning and helped it to become an institutional
alternative to the face-to-face traditional one. Most technologies, briefly
presented here, will be implemented in the ""ARTeFACt"" project - telematic
system for vocational education system of open system learning, system which
will be officially launched at the end of 2006, in the institutional offer of
the Faculty of Arts of the University West of Timisoara. The scientific
coordination of the doctoral project ""ARTeFACt"" is done by Mr. Prof. Dr. Eng.
Savi G. George, representing the Department of Mechatronics Faculty of
Mechanical Engineering from the University ""Politehnica"" of Timisoara, Romania
"
75,On-the-fly erasure coding for real-time video applications,"  This paper introduces a robust point-to-point transmission scheme: Tetrys,
that relies on a novel on-the-fly erasure coding concept which reduces the
delay for recovering lost data at the receiver side. In current erasure coding
schemes, the packets that are not rebuilt at the receiver side are either lost
or delayed by at least one RTT before transmission to the application. The
present contribution aims at demonstrating that Tetrys coding scheme can fill
the gap between real-time applications requirements and full reliability.
Indeed, we show that in several cases, Tetrys can recover lost packets below
one RTT over lossy and best-effort networks. We also show that Tetrys allows to
enable full reliability without delay compromise and as a result: significantly
improves the performance of time constrained applications. For instance, our
evaluations present that video-conferencing applications obtain a PSNR gain up
to 7dB compared to classic block-based erasure codes.
"
76,"The Modular Audio Recognition Framework (MARF) and its Applications:
  Scientific and Software Engineering Notes","  MARF is an open-source research platform and a collection of
voice/sound/speech/text and natural language processing (NLP) algorithms
written in Java and arranged into a modular and extensible framework
facilitating addition of new algorithms. MARF can run distributively over the
network and may act as a library in applications or be used as a source for
learning and extension. A few example applications are provided to show how to
use the framework. There is an API reference in the Javadoc format as well as
this set of accompanying notes with the detailed description of the
architectural design, algorithms, and applications. MARF and its applications
are released under a BSD-style license and is hosted at SourceForge.net. This
document provides the details and the insight on the internals of MARF and some
of the mentioned applications.
"
77,"On Design and Implementation of the Distributed Modular Audio
  Recognition Framework: Requirements and Specification Design Document","  We present the requirements and design specification of the open-source
Distributed Modular Audio Recognition Framework (DMARF), a distributed
extension of MARF. The distributed version aggregates a number of distributed
technologies (e.g. Java RMI, CORBA, Web Services) in a pluggable and modular
model along with the provision of advanced distributed systems algorithms. We
outline the associated challenges incurred during the design and implementation
as well as overall specification of the project and its advantages and
limitations.
"
78,Generalized Kernel-based Visual Tracking,"  In this work we generalize the plain MS trackers and attempt to overcome
standard mean shift trackers' two limitations.
  It is well known that modeling and maintaining a representation of a target
object is an important component of a successful visual tracker.
  However, little work has been done on building a robust template model for
kernel-based MS tracking. In contrast to building a template from a single
frame, we train a robust object representation model from a large amount of
data. Tracking is viewed as a binary classification problem, and a
discriminative classification rule is learned to distinguish between the object
and background. We adopt a support vector machine (SVM) for training. The
tracker is then implemented by maximizing the classification score. An
iterative optimization scheme very similar to MS is derived for this purpose.
"
79,"Structural Solutions for Cross-Layer Optimization of Wireless Multimedia
  Transmission","  In this paper, we propose a systematic solution to the problem of cross-layer
optimization for delay-sensitive media transmission over time-varying wireless
channels as well as investigate the structures and properties of this solution,
such that it can be easily implemented in various multimedia systems and
applications. Specifically, we formulate this problem as a finite-horizon
Markov decision process (MDP) by explicitly considering the users'
heterogeneous multimedia traffic characteristics (e.g. delay deadlines,
distortion impacts and dependencies etc.), time-varying network conditions as
well as, importantly, their ability to adapt their cross-layer transmission
strategies in response to these dynamics. Based on the heterogeneous
characteristics of the media packets, we are able to express the transmission
priorities between packets as a new type of directed acyclic graph (DAG). This
DAG provides the necessary structure for determining the optimal cross-layer
actions in each time slot: the root packet in the DAG will always be selected
for transmission since it has the highest positive marginal utility; and the
complexity of the proposed cross-layer solution is demonstrated to linearly
increase w.r.t. the number of disconnected packet pairs in the DAG and
exponentially increase w.r.t. the number of packets on which the current
packets depend on. The simulation results demonstrate that the proposed
solution significantly outperforms existing state-of-the-art cross-layer
solutions. Moreover, we show that our solution provides the upper bound
performance for the cross-layer optimization solutions with delayed feedback
such as the well-known RaDiO framework.
"
80,Development and Optimization of a Multimedia Product,"  This article presents a new concept of a multimedia interactive product. It
is a multiuser versatile platform that can be used for different purposes. The
first implementation of the platform is a multiplayer game called Texas Hold
'em, which is a very popular community card game. The paper shows the product's
multimedia structure where Hardware and Software work together in creating a
realistic feeling for the users.
"
81,CoPhIR: a Test Collection for Content-Based Image Retrieval,"  The scalability, as well as the effectiveness, of the different Content-based
Image Retrieval (CBIR) approaches proposed in literature, is today an important
research issue. Given the wealth of images on the Web, CBIR systems must in
fact leap towards Web-scale datasets. In this paper, we report on our
experience in building a test collection of 100 million images, with the
corresponding descriptive features, to be used in experimenting new scalable
techniques for similarity searching, and comparing their results. In the
context of the SAPIR (Search on Audio-visual content using Peer-to-peer
Information Retrieval) European project, we had to experiment our distributed
similarity searching technology on a realistic data set. Therefore, since no
large-scale collection was available for research purposes, we had to tackle
the non-trivial process of image crawling and descriptive feature extraction
(we used five MPEG-7 features) using the European EGEE computer GRID. The
result of this effort is CoPhIR, the first CBIR test collection of such scale.
CoPhIR is now open to the research community for experiments and comparisons,
and access to the collection was already granted to more than 50 research
groups worldwide.
"
82,Quality assessment of the MPEG-4 scalable video CODEC,"  In this paper, the performance of the emerging MPEG-4 SVC CODEC is evaluated.
In the first part, a brief introduction on the subject of quality assessment
and the development of the MPEG-4 SVC CODEC is given. After that, the used test
methodologies are described in detail, followed by an explanation of the actual
test scenarios. The main part of this work concentrates on the performance
analysis of the MPEG-4 SVC CODEC - both objective and subjective.
"
83,Web Publishing of the Files Obtained by Flash,"  The aim of this article is to familiarize the user with the Web publishing of
the files obtained by Flash. The article contains an overview of Macromedia
Flash 5, as well as the running of a Playing Flash movie, information on Flash
and Generator, the publishing of Flash movies, a HTLM publishing for Flash
Player files and publishing by Generator templates.
"
84,Robust Watermarking in Multiresolution Walsh-Hadamard Transform,"  In this paper, a newer version of Walsh-Hadamard Transform namely
multiresolution Walsh-Hadamard Transform (MR-WHT) is proposed for images.
Further, a robust watermarking scheme is proposed for copyright protection
using MRWHT and singular value decomposition. The core idea of the proposed
scheme is to decompose an image using MR-WHT and then middle singular values of
high frequency sub-band at the coarsest and the finest level are modified with
the singular values of the watermark. Finally, a reliable watermark extraction
scheme is developed for the extraction of the watermark from the distorted
image. The experimental results show better visual imperceptibility and
resiliency of the proposed scheme against intentional or un-intentional variety
of attacks.
"
85,A Bandwidth Characterization Tool For MPEG-2 File,"  This paper proposes the design and development of MPEG 2 Video Decoder to
offer flexible and effective utilization of bandwidth services. The decoder is
capable of decoding the MPEG 2 bit stream on a single host machine. The present
decoder is designed to be simple, but yet effectively reconstruct the video
from MPEG 2 bit stream.
"
86,A New Approach to Manage QoS in Distributed Multimedia Systems,"  Dealing with network congestion is a criterion used to enhance quality of
service (QoS) in distributed multimedia systems. The existing solutions for the
problem of network congestion ignore scalability considerations because they
maintain a separate classification for each video stream. In this paper, we
propose a new method allowing to control QoS provided to clients according to
the network congestion, by discarding some frames when needed. The technique
proposed, called (m,k)-frame, is scalable with little degradation in
application performances. (m,k)-frame method is issued from the notion of
(m,k)-firm realtime constraints which means that among k invocations of a task,
m invocations must meet their deadline. Our simulation studies show the
usefulness of (m,k)-frame method to adapt the QoS to the real conditions in a
multimedia application, according to the current system load. Notably, the
system must adjust the QoS provided to active clients1 when their number
varies, i.e. dynamic arrival of clients.
"
87,"TTSS Packet Classification Algorithm to enhance Multimedia Applications
  in Network Processor based Router","  The objective of this paper is to implement the Trie based Tuple Space
Search(TTSS) packet classification algorithm for Network Processor(NP) based
router to enhance multimedia applications. The performance is evaluated using
Intel IXP2400 NP Simulator. The results demonstrate that, TTSS has better
performance than Tuple Space Search algorithm and is well suited to achieve
high speed packet classification to support multimedia applications.
"
88,Online Reinforcement Learning for Dynamic Multimedia Systems,"  In our previous work, we proposed a systematic cross-layer framework for
dynamic multimedia systems, which allows each layer to make autonomous and
foresighted decisions that maximize the system's long-term performance, while
meeting the application's real-time delay constraints. The proposed solution
solved the cross-layer optimization offline, under the assumption that the
multimedia system's probabilistic dynamics were known a priori. In practice,
however, these dynamics are unknown a priori and therefore must be learned
online. In this paper, we address this problem by allowing the multimedia
system layers to learn, through repeated interactions with each other, to
autonomously optimize the system's long-term performance at run-time. We
propose two reinforcement learning algorithms for optimizing the system under
different design constraints: the first algorithm solves the cross-layer
optimization in a centralized manner, and the second solves it in a
decentralized manner. We analyze both algorithms in terms of their required
computation, memory, and inter-layer communication overheads. After noting that
the proposed reinforcement learning algorithms learn too slowly, we introduce a
complementary accelerated learning algorithm that exploits partial knowledge
about the system's dynamics in order to dramatically improve the system's
performance. In our experiments, we demonstrate that decentralized learning can
perform as well as centralized learning, while enabling the layers to act
autonomously. Additionally, we show that existing application-independent
reinforcement learning algorithms, and existing myopic learning algorithms
deployed in multimedia systems, perform significantly worse than our proposed
application-aware and foresighted learning methods.
"
89,"Interworking Scheme Using Optimized SIP Mobility for MultiHomed Mobile
  Nodes in Wireless Heterogeneous Networks","  Nowadays, mobile users wish to use their multi-interface mobile devices to
access the Internet through network points of attachment (PoA) based on
heterogeneous wireless technologies. They also wish to seamlessly change the
PoAs during their ongoing sessions to improve service quality and/or reduce
monetary cost. If appropriately handled, multihomed mobile nodes offer a
potential solution to this issue. In this sense, the management of multihomed
mobile nodes in heterogeneous environment is a key research topic. In this
paper, we present an improvement of SIP mobility (pre-call plus mid-call
mobility) to support seamless mobility of multihomed mobile nodes in
heterogeneous wireless networks. Pre-call mobility is extended to associate
user identifier (i.e. SIP URI) and interface identifiers (i.e. IP addresses).
The multiple addresses of a mobile device are weighted by the user to create a
priority list in the SIP server so as to guarantee resilient reachability of
mobile nodes and to avoid unnecessary signaling through wireless links, thus
saving radio resources. Then, three variations of mid-call mobility, called
hard, hybrid and soft procedures, are also proposed. Their main aim is to
minimize, or even avoid, packet losses during interface switching at the mobile
node. The proposed solutions have been implemented in a wireless heterogeneous
testbed composed of 802.11 WLAN plus 3.5 cellular network, which are fully
controlled and configurable. The testbed has been used to study the performance
and the robustness of the three proposed mid-call mobility procedures.
"
90,Component based platform for multimedia applications,"  We propose a platform for distributed multimedia applications which
simplifies the development process and at the same time ensures application
portability, flexibility and performance. The platform is implemented using the
Netscape Portable Runtime (NSPR) and the Cross-Platform Component Object Model
(XPCOM).
"
91,"Optimization of Bit Plane Combination for Efficient Digital Image
  Watermarking","  In view of the frequent multimedia data transfer authentication and
protection of images has gained importance in todays world. In this paper we
propose a new watermarking technique, based on bit plane, which enhances
robustness and capacity of the watermark, as well as maintains transparency of
the watermark and fidelity of the image. In the proposed technique, higher
strength bit plane of digital signature watermark is embedded in to a
significant bit plane of the original image. The combination of bit planes
(image and watermark) selection is an important issue. Therefore, a mechanism
is developed for appropriate bit plane selection. Ten different attacks are
selected to test different alternatives. These attacks are given different
weightings as appropriate to user requirement. A weighted correlation
coefficient for retrieved watermark is estimated for each of the alternatives.
Based on these estimated values optimal bit plane combination is identified for
a given user requirement. The proposed method is found to be useful for
authentication and to prove legal ownership. We observed better results by our
proposed method in comparison with the previously reported work on pseudorandom
watermark embedded in least significant bit (LSB) plane.
"
92,Retrieval of Remote Sensing Images Using Colour and Texture Attribute,"  Grouping images into semantically meaningful categories using low-level
visual feature is a challenging and important problem in content-based image
retrieval. The groupings can be used to build effective indices for an image
database. Digital image analysis techniques are being used widely in remote
sensing assuming that each terrain surface category is characterized with
spectral signature observed by remote sensors. Even with the remote sensing
images of IRS data, integration of spatial information is expected to assist
and to improve the image analysis of remote sensing data. In this paper we
present a satellite image retrieval based on a mixture of old fashioned ideas
and state of the art learning tools. We have developed a methodology to
classify remote sensing images using HSV color features and Haar wavelet
texture features and then grouping them on the basis of particular threshold
value. The experimental results indicate that the use of color and texture
feature extraction is very useful for image retrieval.
"
93,Dynamic Multimedia Content Retrieval System in Distributed Environment,"  WiCoM enables remote management of web resources. Our application Mobile
reporter is aimed at Journalist, who will be able to capture the events in
real-time using their mobile phones and update their web server on the latest
event. WiCoM has been developed using J2ME technology on the client side and
PHP on the server side. The communication between the client and the server is
established through GPRS. Mobile reporter will be able to upload, edit and
remove both textual as well as multimedia contents in the server.
"
94,"Enhanced Mode Selection Algorithm for H.264 encoder for Application in
  Low Computational power devices","  The intent of the H.264 AVC project was to create a standard capable of
providing good video quality at substantially lower bit rates than previous
standards without increasing the complexity of design so much that it would be
impractical or excessively expensive to implement. An additional goal was to
provide enough flexibility to allow the standard to be applied to a wide
variety of applications. To achieve better coding efficiency, H.264 AVC uses
several techniques such as inter mode and intra mode prediction with variable
size motion compensation, which adopts Rate Distortion Optimization (RDO). This
increases the computational complexity of the encoder especially for devices
with lower processing capabilities such as mobile and other handheld devices.
In this paper, we propose an algorithm to reduce the number of mode and sub
mode evaluations in inter mode prediction. Experimental results show that this
fast intra mode selection algorithm can lessen about 75 percent encoding time
with little loss of bit rate and visual quality.
"
95,Efficient Quality-Based Playout Buffer Algorithm,"  Playout buffers are used in VoIP systems to compensate for network delay
jitter by making a trade-off between delay and loss. In this work we propose a
playout buffer algorithm that makes the trade-off based on maximization of
conversational speech quality, aiming to keep the computational complexity
lowest possible. We model the network delay using a Pareto distribution and
show that it is a good compromise between providing an appropriate fit to the
network delay characteristics and yielding a low arithmetical complexity. We
use the ITU-T E-Model as the quality model and simplify its delay impairment
function. The proposed playout buffer algorithm finds the optimum playout delay
using a closed-form solution that minimizes the sum of the simplified delay
impairment factor and the loss-dependent equipment impairment factor of the
E-model. The simulation results show that our proposed algorithm outperforms
existing state-of-the-art algorithms with a reduced complexity for a
quality-based algorithm.
"
96,"Robustness of the Digital Image Watermarking Techniques against
  Brightness and Rotation Attack","  The recent advent in the field of multimedia proposed a many facilities in
transport, transmission and manipulation of data. Along with this advancement
of facilities there are larger threats in authentication of data, its licensed
use and protection against illegal use of data. A lot of digital image
watermarking techniques have been designed and implemented to stop the illegal
use of the digital multimedia images. This paper compares the robustness of
three different watermarking schemes against brightness and rotation attacks.
The robustness of the watermarked images has been verified on the parameters of
PSNR (Peak Signal to Noise Ratio), RMSE (Root Mean Square Error) and MAE (Mean
Absolute Error).
"
97,"Analysis, Design and Simulation of a New System for Internet Multimedia
  Transmission Guarantee","  QoS is a very important issue for multimedia communication systems. In this
paper, a new system that reinstalls the relation between the QoS elements
(RSVP, routing protocol, sender, and receiver) during the multimedia
transmission is proposed, then an alternative path is created in case of
original multimedia path failure. The suggested system considers the resulting
problems that may be faced within and after the creation of rerouting path.
Finally, the proposed system is simulated using OPNET 11.5 simulation package.
Simulation results show that our proposed system outperforms the old one in
terms of QoS parameters like packet loss and delay jitter.
"
98,On Metric Skyline Processing by PM-tree,"  The task of similarity search in multimedia databases is usually accomplished
by range or k nearest neighbor queries. However, the expressing power of these
""single-example"" queries fails when the user's delicate query intent is not
available as a single example. Recently, the well-known skyline operator was
reused in metric similarity search as a ""multi-example"" query type. When
applied on a multi-dimensional database (i.e., on a multi-attribute table), the
traditional skyline operator selects all database objects that are not
dominated by other objects. The metric skyline query adopts the skyline
operator such that the multiple attributes are represented by distances
(similarities) to multiple query examples. Hence, we can view the metric
skyline as a set of representative database objects which are as similar to all
the examples as possible and, simultaneously, are semantically distinct. In
this paper we propose a technique of processing the metric skyline query by use
of PM-tree, while we show that our technique significantly outperforms the
original M-tree based implementation in both time and space costs. In
experiments we also evaluate the partial metric skyline processing, where only
a controlled number of skyline objects is retrieved.
"
99,Prefetching of VoD Programs Based On ART1 Requesting Clustering,"  In this paper, we propose a novel approach to group users according to the
VoD user request pattern. We cluster the user requests based on ART1 neural
network algorithm. The knowledge extracted from the cluster is used to prefetch
the multimedia object from each cluster before the users request. We have
developed an algorithm to cluster users according to the users request patterns
based on ART1 neural network algorithm that offers an unsupervised clustering.
This approach adapts to changes in user request patterns over period without
losing previous information. Each cluster is represented as prototype vector by
generalizing the most frequently used URLs that are accessed by all the cluster
members. The simulation results of our proposed clustering and prefetching
algorithm, shows enormous increase in the performance of streaming server. Our
algorithm helps the servers agent to learn user preferences and discover the
information about the corresponding sources and other similar interested
individuals.
"
100,"Prefix based Chaining Scheme for Streaming Popular Videos using Proxy
  servers in VoD","  Streaming high quality videos consumes significantly large amount of network
resources. In this context request to service delay, network traffic,
congestion and server overloading are the main parameters to be considered in
video streaming over the internet that effect the quality of service (QoS). In
this paper, we propose an efficient architecture as a cluster of proxy servers
and clients that uses a peer to peer (P2P) approach to cooperatively stream the
video using chaining technique. We consider the following two key issues in the
proposed architecture (1) Prefix caching technique to accommodate more number
of videos close to client (2) Cooperative client and proxy chaining to achieve
the network efficiency. Our simulation results shows that the proposed approach
yields a prefix caching close to the optimal solution minimizing WAN bandwidth
usage on server-proxy path by utilizing the proxy-client and client-client path
bandwidth, which is much cheaper than the expensive server proxy path
bandwidth, server load, and client rejection ratio significantly using
chaining.
"
101,"Media-TCP: A Quality-Centric TCP-Friendly Congestion Control for
  Multimedia Transmission","  In this paper, we propose a quality-centric congestion control for multimedia
streaming over IP networks, which we refer to as media-TCP. Unlike existing
congestion control schemes that adapt a user's sending rate merely to the
network condition, our solution adapts the sending rate to both the network
condition and the application characteristics by explicitly considering the
distortion impacts, delay deadlines, and interdependencies of different video
packet classes. Hence, our media-aware solution is able to provide differential
services for transmitting various packet classes and thereby, further improves
the multimedia streaming quality. We model this problem using a Finite-Horizon
Markov Decision Process (FHMDP) and determine the optimal congestion control
policy that maximizes the long-term multimedia quality, while adhering to the
horizon- TCP-friendliness constraint, which ensures long-term fairness with
existing TCP applications. We show that the FHMDP problem can be decomposed
into multiple optimal stopping problems, which admit a low-complexity
threshold-based solution. Moreover, unlike existing congestion control
approaches, which focus on maintaining throughput-based fairness among users,
the proposed media-TCP aims to achieve quality-based fairness among multimedia
users. We also derive sufficient conditions for multiple multimedia users to
achieve quality-based fairness using media-TCP congestion control. Our
simulation results show that the proposed media-TCP achieves more than 3dB
improvement in terms of PSNR over the conventional TCP congestion control
approaches, with the largest improvements observed for real-time streaming
applications requiring stringent playback delays.
"
102,A Wavelet-Based Digital Watermarking for Video,"  A novel video watermarking system operating in the three dimensional wavelet
transform is here presented. Specifically the video sequence is partitioned
into spatio temporal units and the single shots are projected onto the 3D
wavelet domain. First a grayscale watermark image is decomposed into a series
of bitplanes that are preprocessed with a random location matrix. After that
the preprocessed bitplanes are adaptively spread spectrum and added in 3D
wavelet coefficients of the video shot. Our video watermarking algorithm is
robust against the attacks of frame dropping, averaging and swapping.
Furthermore, it allows blind retrieval of embedded watermark which does not
need the original video and the watermark is perceptually invisible. The
algorithm design, evaluation, and experimentation of the proposed scheme are
described in this paper.
"
103,"An Innovative Scheme For Effectual Fingerprint Data Compression Using
  Bezier Curve Representations","  Naturally, with the mounting application of biometric systems, there arises a
difficulty in storing and handling those acquired biometric data. Fingerprint
recognition has been recognized as one of the most mature and established
technique among all the biometrics systems. In recent times, with fingerprint
recognition receiving increasingly more attention the amount of fingerprints
collected has been constantly creating enormous problems in storage and
transmission. Henceforth, the compression of fingerprints has emerged as an
indispensable step in automated fingerprint recognition systems. Several
researchers have presented approaches for fingerprint image compression. In
this paper, we propose a novel and efficient scheme for fingerprint image
compression. The presented scheme utilizes the Bezier curve representations for
effective compression of fingerprint images. Initially, the ridges present in
the fingerprint image are extracted along with their coordinate values using
the approach presented. Subsequently, the control points are determined for all
the ridges by visualizing each ridge as a Bezier curve. The control points of
all the ridges determined are stored and are used to represent the fingerprint
image. When needed, the fingerprint image is reconstructed from the stored
control points using Bezier curves. The quality of the reconstructed
fingerprint is determined by a formal evaluation. The proposed scheme achieves
considerable memory reduction in storing the fingerprint.
"
104,G3 : GENESIS software envrionment update,"  GENESIS3 is the new version of the GENESIS software environment for musical
creation by means of mass-interaction physics network modeling. It was
designed, and developed from scratch, in hindsight of more than 10 years
working on and using the previous version. We take the opportunity of this
birth to provide in this article (1) an analysis of the peculiarities in
GENESIS, aiming at highlighting its core ?software paradigm?; and (2) an update
on the features of the new version as compared to the last.
"
105,"Performance analysis of Non Linear Filtering Algorithms for underwater
  images","  Image filtering algorithms are applied on images to remove the different
types of noise that are either present in the image during capturing or
injected in to the image during transmission. Underwater images when captured
usually have Gaussian noise, speckle noise and salt and pepper noise. In this
work, five different image filtering algorithms are compared for the three
different noise types. The performances of the filters are compared using the
Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE). The modified
spatial median filter gives desirable results in terms of the above two
parameters for the three different noise. Forty underwater images are taken for
study.
"
106,A Reliable Replication Strategy for VoD System using Markov Chain,"  In this paper we have investigated on the reliability of streams for a VoD
system. The objective of the paper is to maximize the availability of streams
for the peers in the VoD system. We have achieved this by using data
replication technique in the peers. Hence, we proposed a new data replication
technique to optimally store the videos in the peers. The new data replication
technique generates more number of replicas than the existing techniques such
as random, minimum request and maximize hit. We have also investigated by
applying the CTMC model for the reliability of replications during the peer
failures. Our result shows that the mean lifetime of replicas are more under
various circumstances. We have addressed the practical issues of efficient
utilization of overall bandwidth and buffer in the VoD system. We achieved
greater success playback probability of videos than the existing techniques.
"
107,Genetic Programming Framework for Fingerprint Matching,"  A fingerprint matching is a very difficult problem. Minutiae based matching
is the most popular and widely used technique for fingerprint matching. The
minutiae points considered in automatic identification systems are based
normally on termination and bifurcation points. In this paper we propose a new
technique for fingerprint matching using minutiae points and genetic
programming. The goal of this paper is extracting the mathematical formula that
defines the minutiae points.
"
108,"Breaking a modified substitution-diffusion image cipher based on chaotic
  standard and logistic maps","  Recently, an image encryption scheme based on chaotic standard and logistic
maps was proposed by Patidar et al. It was later reported by Rhouma et al. that
an equivalent secret key can be reconstructed with only one
known/chosen-plaintext and the corresponding ciphertext. Patidar et al. soon
modified the original scheme and claimed that the modified scheme is secure
against Rhouma et al.'s attack. In this paper, we point out that the modified
scheme is still insecure against the same known/chosen-plaintext attack. In
addition, some other security defects existing in both the original and the
modified schemes are also reported.
"
109,"Speech Recognition Oriented Vowel Classification Using Temporal Radial
  Basis Functions","  The recent resurgence of interest in spatio-temporal neural network as speech
recognition tool motivates the present investigation. In this paper an approach
was developed based on temporal radial basis function ""TRBF"" looking to many
advantages: few parameters, speed convergence and time invariance. This
application aims to identify vowels taken from natural speech samples from the
Timit corpus of American speech. We report a recognition accuracy of 98.06
percent in training and 90.13 in test on a subset of 6 vowel phonemes, with the
possibility to expend the vowel sets in future.
"
110,"How Do Interactive Virtual Operas Shift Relationships between Music,
  Text and Image?","  In this paper we present the new genre of interactive operas implemented on
personal computers. They differ from traditional ones not only because they are
virtual, but mainly because they offer to composers and listeners new
perspectives of combinations and interactions between music, text and visual
aspects.
"
111,Music-ripping: des pratiques qui provoquent la musicologie,"  Out of the scope of the usual positions of computing in the field of music
and musicology, one notices the emergence of human-computer systems that do
exist by breaking off. Though these singular systems take effect in the usual
fields of expansion of music, they do not make any systematic reference to
known musicological categories. On the contrary, they make possible experiments
that open uses where listening, composition and musical transmission get merged
in a gesture sometimes named as ?music-ripping?. We will show in which way the
music-ripping practices provoke traditional musicology, whose canonical
categories happen to be ineffectual to explain here. To achieve that purpose,
we shall need: - to make explicit a minimal set of categories that is
sufficient to underlie the usual models of computer assisted music;- to do the
same for human-computer systems (anti-musicological?) that disturb us; - to
examine the possibility conditions of reduction of the second set to the first;
- to conclude on the nature of music-ripping.
"
112,Tutoring System for Dance Learning,"  Recent advances in hardware sophistication related to graphics display, audio
and video devices made available a large number of multimedia and hypermedia
applications. These multimedia applications need to store and retrieve the
different forms of media like text, hypertext, graphics, still images,
animations, audio and video. Dance is one of the important cultural forms of a
nation and dance video is one such multimedia types. Archiving and retrieving
the required semantics from these dance media collections is a crucial and
demanding multimedia application. This paper summarizes the difference dance
video archival techniques and systems. Keywords: Multimedia, Culture Media,
Metadata archival and retrieval systems, MPEG-7, XML.
"
113,Semantic Modeling and Retrieval of Dance Video Annotations,"  Dance video is one of the important types of narrative videos with semantic
rich content. This paper proposes a new meta model, Dance Video Content Model
(DVCM) to represent the expressive semantics of the dance videos at multiple
granularity levels. The DVCM is designed based on the concepts such as video,
shot, segment, event and object, which are the components of MPEG-7 MDS. This
paper introduces a new relationship type called Temporal Semantic Relationship
to infer the semantic relationships between the dance video objects. Inverted
file based index is created to reduce the search time of the dance queries. The
effectiveness of containment queries using precision and recall is depicted.
Keywords: Dance Video Annotations, Effectiveness Metrics, Metamodeling,
Temporal Semantic Relationships.
"
114,Modeling and Annotating the Expressive Semantics of Dance Videos,"  Dance videos are interesting and semantics-intensive. At the same time, they
are the complex type of videos compared to all other types such as sports, news
and movie videos. In fact, dance video is the one which is less explored by the
researchers across the globe. Dance videos exhibit rich semantics such as macro
features and micro features and can be classified into several types. Hence,
the conceptual modeling of the expressive semantics of the dance videos is very
crucial and complex. This paper presents a generic Dance Video Semantics Model
(DVSM) in order to represent the semantics of the dance videos at different
granularity levels, identified by the components of the accompanying song. This
model incorporates both syntactic and semantic features of the videos and
introduces a new entity type called, Agent, to specify the micro features of
the dance videos. The instantiations of the model are expressed as graphs. The
model is implemented as a tool using J2SE and JMF to annotate the macro and
micro features of the dance videos. Finally examples and evaluation results are
provided to depict the effectiveness of the proposed dance video model.
Keywords: Agents, Dance videos, Macro features, Micro features, Video
annotation, Video semantics.
"
115,Discovering Knowledge from Multi-modal Lecture Recordings,"  Educational media mining is the process of converting raw media data from
educational systems to useful information that can be used to design learning
systems, answer research questions and allow personalized learning experiences.
Knowledge discovery encompasses a wide range of techniques ranging from
database queries to more recent developments in machine learning and language
technology. Educational media mining techniques are now being used in IT
Services research worldwide. Multi-modal Lecture Recordings is one of the
important types of educational media and this paper explores the research
challenges for mining lecture recordings for the efficient personalized
learning experiences. Keywords: Educational Media Mining; Lecture Recordings,
Multimodal Information System, Personalized Learning; Online Course Ware;
Skills and Competences;
"
116,"Distributed Rate Allocation Policies for Multi-Homed Video Streaming
  over Heterogeneous Access Networks","  We consider the problem of rate allocation among multiple simultaneous video
streams sharing multiple heterogeneous access networks. We develop and evaluate
an analytical framework for optimal rate allocation based on observed available
bit rate (ABR) and round-trip time (RTT) over each access network and video
distortion-rate (DR) characteristics. The rate allocation is formulated as a
convex optimization problem that minimizes the total expected distortion of all
video streams. We present a distributed approximation of its solution and
compare its performance against H-infinity optimal control and two heuristic
schemes based on TCP-style additive-increase-multiplicative decrease (AIMD)
principles. The various rate allocation schemes are evaluated in simulations of
multiple high-definition (HD) video streams sharing multiple access networks.
Our results demonstrate that, in comparison with heuristic AIMD-based schemes,
both media-aware allocation and H-infinity optimal control benefit from
proactive congestion avoidance and reduce the average packet loss rate from 45%
to below 2%. Improvement in average received video quality ranges between 1.5
to 10.7 dB in PSNR for various background traffic loads and video playout
deadlines. Media-aware allocation further exploits its knowledge of the video
DR characteristics to achieve a more balanced video quality among all streams.
"
117,"Designing a Truly Integrated (Onsite and Online) Conference: Concept,
  Processes, Solutions","  Web conferencing tools have entered the mainstream of business applications.
Using web conferencing for IEEE conferences has a good potential of adding
value to both organizers and participants. Authors propose a concept of Truly
Integrated Conference (TIC) according to which a multi-point
worldwide-distributed network of conference online authors/participants will
enhance the standard (centralized) IEEE conference model, which requires
attendance of the participants in person at the main conference location. The
concept entails seamless integration of the onsite and online conference
systems, including data/presentation, video, audio channels. Benefits and
challenges of the TIC concept are analyzed. Requirements to the web
conferencing system capable of supporting the TIC conference are presented and
reviewed against commercial web conferencing tools. Case study of the IEEE
Toronto International Conference ? Science and Technology for Humanity, which
was the first realization of TIC, is presented which analyzes various aspects
(organizational, technological, and financial) of the integrated conference.
"
118,"Avoiding Interruptions - QoE Trade-offs in Block-coded Streaming Media
  Applications","  We take an analytical approach to study Quality of user Experience (QoE) for
video streaming applications. First, we show that random linear network coding
applied to blocks of video frames can significantly simplify the packet
requests at the network layer and save resources by avoiding duplicate packet
reception. Network coding allows us to model the receiver's buffer as a queue
with Poisson arrivals and deterministic departures. We consider the probability
of interruption in video playback as well as the number of initially buffered
packets (initial waiting time) as the QoE metrics. We characterize the optimal
trade-off between these metrics by providing upper and lower bounds on the
minimum initial buffer size, required to achieve certain level of interruption
probability for different regimes of the system parameters. Our bounds are
asymptotically tight as the file size goes to infinity.
"
119,A New Image Steganography Based On First Component Alteration Technique,"  In this paper, A new image steganography scheme is proposed which is a kind
of spatial domain technique. In order to hide secret data in cover-image, the
first component alteration technique is used. Techniques used so far focuses
only on the two or four bits of a pixel in a image (at the most five bits at
the edge of an image) which results in less peak to signal noise ratio and high
root mean square error. In this technique, 8 bits of blue components of pixels
are replaced with secret data bits. Proposed scheme can embed more data than
previous schemes and shows better image quality. To prove this scheme, several
experiments are performed, and are compared the experimental results with the
related previous works.
"
120,"Evaluating Effectiveness of Tamper Proofing on Dynamic Graph Software
  Watermarks","  For enhancing the protection level of dynamic graph software watermarks and
for the purpose of conducting the analysis which evaluates the effect of
integrating two software protection techniques such as software watermarking
and tamper proofing, constant encoding technique along with the enhancement
through the idea of constant splitting is proposed. In this paper Thomborson
technique has been implemented with the scheme of breaking constants which
enables to encode all constants without having any consideration about their
values with respect to the value of watermark tree. Experimental analysis which
have been conducted and provided in this paper concludes that the constant
encoding process significantly increases the code size, heap space usage, and
execution time, while making the tamper proofed code resilient to variety of
semantic preserving program transformation attacks.
"
121,Comparative Evaluation and Analysis of IAX and RSW,"  Voice over IP (VoIP) is a technology to transport media over IP networks such
as the Internet. VoIP has the capability of connecting people over packet
switched networks instead of traditional circuit switched networks. Recently,
the InterAsterisk Exchange Protocol (IAX) has emerged as a new VoIP which is
gaining popularity among VoIP products. IAX is known for its simplicity, NAT
friendliness, efficiency, and robustness. More recently, the Real time
Switching (RSW) control criterion has emerged as a multimedia conferencing
protocol. In this paper, we made a comparative evaluation and analysis of IAX
and RSW using Mean Opinion Score rating (MOS) and found that they both perform
well under different network packet delays in ms.
"
122,"Multicast Transmission Prefix and Popularity Aware Interval Caching
  Based Admission Control Policy","  Admission control is a key component in multimedia servers, which will allow
the resources to be used by the client only when they are available. A problem
faced by numerous content serving machines is overload, when there are too many
clients who need to be served, the server tends to slow down. An admission
control algorithm for a multimedia server is responsible for determining if a
new request can be accepted without violating the QoS requirements of the
existing requests in the system. By caching and streaming only the data in the
interval between two successive requests on the same object, the following
request can be serviced directly from the buffer cache without disk operations
and within the deadline of the request. An admission control strategy based on
Popularity-aware interval caching for Prefix [3] scheme extends the interval
caching by considering different popularity of multimedia objects. The method
of Prefix caching with multicast transmission of popular objects utilizes the
hard disk and network bandwidth efficiently and increases the number of
requests being served.
"
123,"Cooperative Proxy Servers Architecture for VoD to Achieve High QoS with
  Reduced Transmission Time and Cost","  - The aim of this paper is to propose a novel Voice On Demand (VoD)
architecture and implementation of an efficient load sharing algorithm to
achieve Quality of Service (QoS). This scheme reduces the transmission cost
from the Centralized Multimedia Sever (CMS) to Proxy Servers (PS) by sharing
the videos among the proxy servers of the Local Proxy Servers Group [LPSG] and
among the neighboring LPSGs, which are interconnected in a ring fashion. This
results in very low request rejection ratio, reduction in transmission time and
cost, reduction of load on the CMS and high QoS for the users. Simulation
results indicate acceptable initial startup latency, reduced transmission cost
and time, load sharing among the proxy servers, among the LPSGs and between the
CMS and the PS.
"
124,"An Adaptive Dynamic Replacement Approach for a Multicast based
  Popularity Aware Prefix Cache Memory System","  In this paper we have proposed an adaptive dynamic cache replacement
algorithm for a multimedia servers cache system. The goal is to achieve an
effective utilization of the cache memory which stores the prefix of popular
videos. A replacement policy is usually evaluated using hit ratio, the
frequency with which any video is requested. Usually discarding the least
recently used page is the policy of choice in cache management. The adaptive
dynamic replacement approach for prefix cache is a self tuning, low overhead
algorithm that responds online to changing access patterns. It constantly
balances between lru and lfu to improve combined result. It automatically
adapts to evolving workloads. Since in our algorithm we have considered a
prefix caching with multicast transmission of popular objects it utilizes the
hard disk and network bandwidth efficiently and increases the number of
requests being served.
"
125,"A Strategy to enable Prefix of Multicast VoD through dynamic buffer
  allocation","  In this paper we have proposed a dynamic buffer allocation algorithm for the
prefix, based on the popularity of the videos. More cache blocks are allocated
for most popular videos and a few cache blocks are allocated for less popular
videos. Buffer utilization is also maximized irrespective of the load on the
Video-on-Demand system. Overload can lead the server getting slowed down. By
storing the first few seconds of popular video clips, a multimedia local server
can shield the users from the delay, throughput, and loss properties of the
path between the local server and the central server. The key idea of
controlled multicast is used to allow clients to share a segment of a video
stream even when the requests arrive at different times. This dynamic buffer
allocation algorithm is simulated and its performance is evaluated based on the
buffer utilization by multimedia servers and average buffer allocation for the
most popular videos. Our simulation results shows efficient utilization of
network bandwidth and reduced hard disk utilization hence resulting in increase
in the number of requests being served.
"
126,Shape-Adaptive Motion Estimation Algorithm for MPEG-4 Video Coding,"  This paper presents a gradient based motion estimation algorithm based on
shape-motion prediction, which takes advantage of the correlation between
neighboring Binary Alpha Blocks (BABs), to match with the Mpeg-4 shape coding
case and speed up the estimation process. The PSNR and computation time
achieved by the proposed algorithm seem to be better than those obtained by
most popular motion estimation techniques.
"
127,"Stochastic Model Based Proxy Servers Architecture for VoD to Achieve
  Reduced Client Waiting Time","  In a video on demand system, the main video repository may be far away from
the user and generally has limited streaming capacities. Since a high quality
video's size is huge, it requires high bandwidth for streaming over the
internet. In order to achieve a higher video hit ratio, reduced client waiting
time, distributed server's architecture can be used, in which multiple local
servers are placed close to clients and, based on their regional demands video
contents are cached dynamically from the main server. As the cost of proxy
server is decreasing and demand for reduced waiting time is increasing day by
day, newer architectures are explored, innovative schemes are arrived at. In
this paper we present novel 3 layer architecture, includes main multimedia
server, a Tracker and Proxy servers. This architecture targets to optimize the
client waiting time. We also propose an efficient prefix caching and load
sharing algorithm at the proxy server to allocate the cache according to
regional popularity of the video. The simulation results demonstrate that it
achieves significantly lower client's waiting time, when compared to the other
existing algorithms.
"
128,"An Improved DC Recovery Method from AC Coefficients of DCT-Transformed
  Images","  Motivated by the work of Uehara et al. [1], an improved method to recover DC
coefficients from AC coefficients of DCT-transformed images is investigated in
this work, which finds applications in cryptanalysis of selective multimedia
encryption. The proposed under/over-flow rate minimization (FRM) method employs
an optimization process to get a statistically more accurate estimation of
unknown DC coefficients, thus achieving a better recovery performance. It was
shown by experimental results based on 200 test images that the proposed DC
recovery method significantly improves the quality of most recovered images in
terms of the PSNR values and several state-of-the-art objective image quality
assessment (IQA) metrics such as SSIM and MS-SSIM.
"
129,"Image Retrieval Techniques based on Image Features, A State of Art
  approach for CBIR","  The purpose of this Paper is to describe our research on different feature
extraction and matching techniques in designing a Content Based Image Retrieval
(CBIR) system. Due to the enormous increase in image database sizes, as well as
its vast deployment in various applications, the need for CBIR development
arose. Firstly, this paper outlines a description of the primitive feature
extraction techniques like, texture, colour, and shape. Once these features are
extracted and used as the basis for a similarity check between images, the
various matching techniques are discussed. Furthermore, the results of its
performance are illustrated by a detailed example.
"
130,The Fast Haar Wavelet Transform for Signal & Image Processing,"  A method for the design of Fast Haar wavelet for signal processing and image
processing has been proposed. In the proposed work, the analysis bank and
synthesis bank of Haar wavelet is modified by using polyphase structure.
Finally, the Fast Haar wavelet was designed and it satisfies alias free and
perfect reconstruction condition. Computational time and computational
complexity is reduced in Fast Haar wavelet transform.
"
131,Vision Based Game Development Using Human Computer Interaction,"  A Human Computer Interface (HCI) System for playing games is designed here
for more natural communication with the machines. The system presented here is
a vision-based system for detection of long voluntary eye blinks and
interpretation of blink patterns for communication between man and machine.
This system replaces the mouse with the human face as a new way to interact
with the computer. Facial features (nose tip and eyes) are detected and tracked
in realtime to use their actions as mouse events. The coordinates and movement
of the nose tip in the live video feed are translated to become the coordinates
and movement of the mouse pointer on the application. The left or right eye
blinks fire left or right mouse click events. The system works with inexpensive
USB cameras and runs at a frame rate of 30 frames per second.
"
132,Using Statistical Moment Invariants and Entropy in Image Retrieval,"  Although content-based image retrieval (CBIR) is not a new subject, it keeps
attracting more and more attention, as the amount of images grow tremendously
due to internet, inexpensive hardware and automation of image acquisition. One
of the applications of CBIR is fetching images from a database. This paper
presents a new method for automatic image retrieval using moment invariants and
image entropy, our technique could be used to find semi or perfect matches
based on query by example manner, experimental results demonstrate that the
purposed technique is scalable and efficient.
"
133,Dual Watermarking Scheme with Encryption,"  Digital Watermarking is used for copyright protection and authentication. In
the proposed system, a Dual Watermarking Scheme based on DWT SVD with chaos
encryption algorithm, will be developed to improve the robustness and
protection along with security. DWT and SVD have been used as a mathematical
tool to embed watermark in the image. Two watermarks are embedded in the host
image. The secondary is embedded into primary watermark and the resultant
watermarked image is encrypted using chaos based logistic map. This provides an
efficient and secure way for image encryption and transmission. The watermarked
image is decrypted and a reliable watermark extraction scheme is developed for
the extraction of the primary as well as secondary watermark from the distorted
image.
"
134,"New System for Secure Cover File of Hidden Data in the Image Page within
  Executable File Using Statistical Steganography Techniques","  A Previously traditional methods were sufficient to protect the information,
since it is simplicity in the past does not need complicated methods but with
the progress of information technology, it become easy to attack systems, and
detection of encryption methods became necessary to find ways parallel with the
differing methods used by hackers, so the embedding methods could be under
surveillance from system managers in an organization that requires the high
level of security. This fact requires researches on new hiding methods and
cover objects which hidden information is embedded in. It is the result from
the researches to embed information in executable files, but when will use the
executable file for cover they have many challenges must be taken into
consideration which is any changes made to the file will be firstly detected by
untie viruses, secondly the functionality of the file is not still functioning.
In this paper, a new information hiding system is presented. The aim of the
proposed system is to hide information (data file) within image page of
execution file (EXEfile) to make sure changes made to the file will not be
detected by universe and the functionality of the exe.file is still functioning
after hiding process. Meanwhile, since the cover file might be used to identify
hiding information, the proposed system considers overcoming this dilemma by
using the execution file as a cover file.
"
135,"Iterative exact global histogram specification and SSIM gradient ascent:
  a proof of convergence, step size and parameter selection","  The SSIM-optimized exact global histogram specification (EGHS) is shown to
converge in the sense that the first order approximation of the result's
quality (i.e., its structural similarity with input) does not decrease in an
iteration, when the step size is small. Each iteration is composed of SSIM
gradient ascent and basic EGHS with the specified target histogram. Selection
of step size and other parameters is also discussed.
"
136,Effect of Embedding Watermark on Compression of the Digital Images,"  Image Compression plays a very important role in image processing especially
when we are to send the image on the internet. The threat to the information on
the internet increases and image is no exception. Generally the image is sent
on the internet as the compressed image to optimally use the bandwidth of the
network. But as we are on the network, at any intermediate level the image can
be changed intentionally or unintentionally. To make sure that the correct
image is being delivered at the other end we embed the water mark to the image.
The watermarked image is then compressed and sent on the network. When the
image is decompressed at the other end we can extract the watermark and make
sure that the image is the same that was sent by the other end. Though
watermarking the image increases the size of the uncompressed image but that
has to done to achieve the high degree of robustness i.e. how an image sustains
the attacks on it. The present paper is an attempt to make transmission of the
images secure from the intermediate attacks by applying the generally used
compression transforms.
"
137,Optimization Digital Image Watermarking Technique for Patent Protection,"  The rapid development of multimedia and internet allows for wide distribution
of digital media data. It becomes much easier to edit, modify and duplicate
digital information besides that, digital documents are also easy to copy and
distribute, therefore it will be faced by many threats. It is a big security
and privacy issue. Another problem with digital document and video is that
undetectable modifications can be made with very simple and widely available
equipment, which put the digital material for evidential purposes under
question With the large flood of information and the development of the digital
format, it become necessary to find appropriate protection because of the
significance, accuracy and sensitivity of the information, therefore multimedia
technology and popularity of internet communications they have great interest
in using digital watermarks for the purpose of copy protection and content
authentication. Digital watermarking is a technique used to embed a known piece
of digital data within another piece of digital data .A digital data may
represent a digital signature or digital watermark that is embedded in the host
media. The signature or watermark is hidden such that it's perceptually and
statistically undetectable. Then this signature or watermark can be extracted
from the host media and used to identify the owner of the media.
"
138,What are suspicious VoIP delays?,"  Voice over IP (VoIP) is unquestionably the most popular real-time service in
IP networks today. Recent studies have shown that it is also a suitable carrier
for information hiding. Hidden communication may pose security concerns as it
can lead to confidential information leakage. In VoIP, RTP (Real-time Transport
Protocol) in particular, which provides the means for the successful transport
of voice packets through IP networks, is suitable for steganographic purposes.
It is characterised by a high packet rate compared to other protocols used in
IP telephony, resulting in a potentially high steganographic bandwidth. The
modification of an RTP packet stream provides many opportunities for hidden
communication as the packets may be delayed, reordered or intentionally lost.
In this paper, to enable the detection of steganographic exchanges in VoIP, we
examined real RTP traffic traces to answer the questions, what do the ""normal""
delays in RTP packet streams look like? and, is it possible to detect the use
of known RTP steganographic methods based on this knowledge?
"
139,Structure-Aware Stochastic Control for Transmission Scheduling,"  In this paper, we consider the problem of real-time transmission scheduling
over time-varying channels. We first formulate the transmission scheduling
problem as a Markov decision process (MDP) and systematically unravel the
structural properties (e.g. concavity in the state-value function and
monotonicity in the optimal scheduling policy) exhibited by the optimal
solutions. We then propose an online learning algorithm which preserves these
structural properties and achieves -optimal solutions for an arbitrarily small
. The advantages of the proposed online method are that: (i) it does not
require a priori knowledge of the traffic arrival and channel statistics and
(ii) it adaptively approximates the state-value functions using piece-wise
linear functions and has low storage and computation complexity. We also extend
the proposed low-complexity online learning solution to the prioritized data
transmission. The simulation results demonstrate that the proposed method
achieves significantly better utility (or delay)-energy trade-offs when
comparing to existing state-of-art online optimization methods.
"
140,"An Algorithm for Index Multimedia Data (Video) using the Movement
  Oriented Method for Real-time Online Services","  Multimedia data is a form of data that can represent all types of data
(images, sound and text). The use of multimedia data for the online application
requires a more comprehensive database in the use of storage media, Sorting /
indexing, search and system / data searching. This is necessary in order to
help providers and users to access multimedia data online. Systems that use of
the index image as a reference requires storage media so that the rules and
require special expertise to obtain the desired file. Changes in multimedia
data into a series of stories / storyboard in the form of a text will help
reduce the consumption of media storage, system index / sorting and search
applications. Oriented Movement is one method that is being developed to change
the form of multimedia data into a storyboard.
"
141,"Towards Automated Lecture Capture, Navigation and Delivery System for
  Web-Lecture on Demand","  Institutions all over the world are continuously exploring ways to use ICT in
improving teaching and learning effectiveness. The use of course web pages,
discussion groups, bulletin boards, and e-mails have shown considerable impact
on teaching and learning in significant ways, across all disciplines. ELearning
has emerged as an alternative to traditional classroom-based education and
training and web lectures can be a powerful addition to traditional lectures.
They can even serve as a main content source for learning, provided users can
quickly navigate and locate relevant pages in a web lecture. A web lecture
consists of video and audio of the presenter and slides complemented with
screen capturing. In this paper, an automated approach for recording live
lectures and for browsing available web lectures for on-demand applications by
end users is presented.
"
142,An Optimal Prefix Replication Strategy for VoD Services,"  In this paper we propose scalable proxy servers cluster architecture of
interconnected proxy servers for high quality and high availability services.
We also propose an optimal regional popularity based video prefix replication
strategy and a scene change based replica caching algorithm that utilizes the
zipf-like video popularity distribution to maximize the availability of videos
closer to the client and request-servicing rate thereby reducing the client
rejection ratio and the response time for the client. The simulation results of
our proposed architecture and algorithm show the greater achievement in
maximizing the availability of videos, client request-servicing rate and in
reduction of initial start-up latency and client rejection ratio.
"
143,"Voice Recognition Algorithms using Mel Frequency Cepstral Coefficient
  (MFCC) and Dynamic Time Warping (DTW) Techniques","  Digital processing of speech signal and voice recognition algorithm is very
important for fast and accurate automatic voice recognition technology. The
voice is a signal of infinite information. A direct analysis and synthesizing
the complex voice signal is due to too much information contained in the
signal. Therefore the digital signal processes such as Feature Extraction and
Feature Matching are introduced to represent the voice signal. Several methods
such as Liner Predictive Predictive Coding (LPC), Hidden Markov Model (HMM),
Artificial Neural Network (ANN) and etc are evaluated with a view to identify a
straight forward and effective method for voice signal. The extraction and
matching process is implemented right after the Pre Processing or filtering
signal is performed. The non-parametric method for modelling the human auditory
perception system, Mel Frequency Cepstral Coefficients (MFCCs) are utilize as
extraction techniques. The non linear sequence alignment known as Dynamic Time
Warping (DTW) introduced by Sakoe Chiba has been used as features matching
techniques. Since it's obvious that the voice signal tends to have different
temporal rate, the alignment is important to produce the better
performance.This paper present the viability of MFCC to extract features and
DTW to compare the test patterns.
"
144,"New Classification Methods for Hiding Information into Two Parts:
  Multimedia Files and Non Multimedia Files","  With the rapid development of various multimedia technologies, more and more
multimedia data are generated and transmitted in the medical, commercial, and
military fields, which may include some sensitive information which should not
be accessed by or can only be partially exposed to the general users.
Therefore, security and privacy has become an important, Another problem with
digital document and video is that undetectable modifications can be made with
very simple and widely available equipment, which put the digital material for
evidential purposes under question .With the large flood of information and the
development of the digital format Information hiding considers one of the
techniques which used to protect the important information. The main goals for
this paper, provides a general overview of the New Classification Methods for
Hiding Information into Two Parts: Multimedia Files and Non Multimedia Files.
"
145,Overview: Main Fundamentals for Steganography,"  The rapid development of multimedia and internet allows for wide distribution
of digital media data. It becomes much easier to edit, modify and duplicate
digital information .Besides that, digital documents are also easy to copy and
distribute, therefore it will be faced by many threats. It is a big security
and privacy issue, it become necessary to find appropriate protection because
of the significance, accuracy and sensitivity of the information. Steganography
considers one of the techniques which used to protect the important
information. The main goals for this paper, to recognize the researchers for
the main fundamentals of steganography. In this paper provides a general
overview of the following subject areas: Steganography types, General
Steganography system, Characterization of Steganography Systems and
Classification of Steganography Techniques.
"
146,Context-Oriented Web Video Tag Recommendation,"  Tag recommendation is a common way to enrich the textual annotation of
multimedia contents. However, state-of-the-art recommendation methods are built
upon the pair-wised tag relevance, which hardly capture the context of the web
video, i.e., when who are doing what at where. In this paper we propose the
context-oriented tag recommendation (CtextR) approach, which expands tags for
web videos under the context-consistent constraint. Given a web video, CtextR
first collects the multi-form WWW resources describing the same event with the
video, which produce an informative and consistent context; and then, the tag
recommendation is conducted based on the obtained context. Experiments on an
80,031 web video collection show CtextR recommends various relevant tags to web
videos. Moreover, the enriched tags improve the performance of web video
categorization.
"
147,Image Compression and Watermarking scheme using Scalar Quantization,"  This paper presents a new compression technique and image watermarking
algorithm based on Contourlet Transform (CT). For image compression, an energy
based quantization is used. Scalar quantization is explored for image
watermarking. Double filter bank structure is used in CT. The Laplacian Pyramid
(LP) is used to capture the point discontinuities, and then followed by a
Directional Filter Bank (DFB) to link point discontinuities. The coefficients
of down sampled low pass version of LP decomposed image are re-ordered in a
pre-determined manner and prediction algorithm is used to reduce entropy
(bits/pixel). In addition, the coefficients of CT are quantized based on the
energy in the particular band. The superiority of proposed algorithm to JPEG is
observed in terms of reduced blocking artifacts. The results are also compared
with wavelet transform (WT). Superiority of CT to WT is observed when the image
contains more contours. The watermark image is embedded in the low pass image
of contourlet decomposition. The watermark can be extracted with minimum error.
In terms of PSNR, the visual quality of the watermarked image is exceptional.
The proposed algorithm is robust to many image attacks and suitable for
copyright protection applications.
"
148,"A stochastic model of human visual attention with a dynamic Bayesian
  network","  Recent studies in the field of human vision science suggest that the human
responses to the stimuli on a visual display are non-deterministic. People may
attend to different locations on the same visual input at the same time. Based
on this knowledge, we propose a new stochastic model of visual attention by
introducing a dynamic Bayesian network to predict the likelihood of where
humans typically focus on a video scene. The proposed model is composed of a
dynamic Bayesian network with 4 layers. Our model provides a framework that
simulates and combines the visual saliency response and the cognitive state of
a person to estimate the most probable attended regions. Sample-based inference
with Markov chain Monte-Carlo based particle filter and stream processing with
multi-core processors enable us to estimate human visual attention in near real
time. Experimental results have demonstrated that our model performs
significantly better in predicting human visual attention compared to the
previous deterministic models.
"
149,Psychophysiological Correlations with Gameplay Experience Dimensions,"  In this paper, we report a case study using two easy-to-deploy
psychophysiological measures - electrodermal activity (EDA) and heart rate (HR)
- and correlating them with a gameplay experience questionnaire (GEQ) in an
attempt to establish this mixed-methods approach for rapid application in a
commercial game development context. Results indicate that there is a
statistically significant correlation (p < 0.01) between measures of
psychophysiological arousal (HR, EDA) and self-reported UX in games (GEQ), with
some variation between the EDA and HR measures. Results are consistent across
three major commercial First-Person Shooter (FPS) games.
"
150,"Affective Ludology, Flow and Immersion in a First- Person Shooter:
  Measurement of Player Experience","  Gameplay research about experiential phenomena is a challenging undertaking,
given the variety of experiences that gamers encounter when playing and which
currently do not have a formal taxonomy, such as flow, immersion, boredom, and
fun. These informal terms require a scientific explanation. Ludologists also
acknowledge the need to understand cognition, emotion, and goal- oriented
behavior of players from a psychological perspective by establishing rigorous
methodologies. This paper builds upon and extends prior work in an area for
which we would like to coin the term ""affective ludology."" The area is
concerned with the affective measurement of player-game interaction. The
experimental study reported here investigated different traits of gameplay
experience using subjective (i.e., questionnaires) and objective (i.e.,
psychophysiological) measures. Participants played three Half-Life 2 game level
design modifications while measures such as electromyography (EMG),
electrodermal activity (EDA) were taken and questionnaire responses were
collected. A level designed for combat-oriented flow experience demonstrated
significant high-arousal positive affect emotions. This method shows that
emotional patterns emerge from different level designs, which has great
potential for providing real-time emotional profiles of gameplay that may be
generated together with self- reported subjective player experience
descriptions.
"
151,From Playability to a Hierarchical Game Usability Model,"  This paper presents a brief review of current game usability models. This
leads to the conception of a high-level game development-centered usability
model that integrates current usability approaches in game industry and game
research.
"
152,Trends and Techniques in Visual Gaze Analysis,"  Visualizing gaze data is an effective way for the quick interpretation of eye
tracking results. This paper presents a study investigation benefits and
limitations of visual gaze analysis among eye tracking professionals and
researchers. The results were used to create a tool for visual gaze analysis
within a Master's project.
"
153,Gameplay experience in a gaze interaction game,"  Assessing gameplay experience for gaze interaction games is a challenging
task. For this study, a gaze interaction Half-Life 2 game modification was
created that allowed eye tracking control. The mod was deployed during an
experiment at Dreamhack 2007, where participants had to play with gaze
navigation and afterwards rate their gameplay experience. The results show low
tension and negative affects scores on the gameplay experience questionnaire as
well as high positive challenge, immersion and flow ratings. The correlation
between spatial presence and immersion for gaze interaction was high and yields
further investigation. It is concluded that gameplay experience can be
correctly assessed with the methodology presented in this paper.
"
154,Integrating identity-based cryptography in IMS service authentication,"  Nowadays, the IP Multimedia Subsystem (IMS) is a promising research field.
Many ongoing works related to the security and the performances of its
employment are presented to the research community. Although, the security and
data privacy aspects are very important in the IMS global objectives, they
observe little attention so far. Secure access to multimedia services is based
on SIP and HTTP digest on top of IMS architecture. The standard deploys AKA-MD5
for the terminal authentication. The third Generation Partnership Project
(3GPP) provided Generic Bootstrapping Architecture (GBA) to authenticate the
subscriber before accessing multimedia services over HTTP. In this paper, we
propose a new IMS Service Authentication scheme using Identity Based
cryptography (IBC). This new scheme will lead to better performances when there
are simultaneous authentication requests using Identity-based Batch
Verification. We analyzed the security of our new protocol and we presented a
performance evaluation of its cryptographic operations
"
155,"Feature-Based Adaptive Tolerance Tree (FATT): An Efficient Indexing
  Technique for Content-Based Image Retrieval Using Wavelet Transform","  This paper introduces a novel indexing and access method, called Feature-
Based Adaptive Tolerance Tree (FATT), using wavelet transform is proposed to
organize large image data sets efficiently and to support popular image access
mechanisms like Content Based Image Retrieval (CBIR).Conventional database
systems are designed for managing textual and numerical data and retrieving
such data is often based on simple comparisons of text or numerical values.
However, this method is no longer adequate for images, since the digital
presentation of images does not convey the reality of images. Retrieval of
images become difficult when the database is very large. This paper addresses
such problems and presents a novel indexing technique, Feature Based Adaptive
Tolerance Tree (FATT), which is designed to bring an effective solution
especially for indexing large databases. The proposed indexing scheme is then
used along with a query by image content, in order to achieve the ultimate goal
from the user point of view that is retrieval of all relevant images. FATT
indexing technique, features of the image is extracted using 2-dimensional
discrete wavelet transform (2DDWT) and index code is generated from the
determinant value of the features. Multiresolution analysis technique using
2D-DWT can decompose the image into components at different scales, so that the
coarest scale components carry the global approximation information while the
finer scale components contain the detailed information. Experimental results
show that the FATT outperforms M-tree upto 200%, Slim-tree up to 120% and HCT
upto 89%. FATT indexing technique is adopted to increase the efficiently of
data storage and retrieval.
"
156,"A reversible high embedding capacity data hiding technique for hiding
  secret data in images","  As the multimedia and internet technologies are growing fast, the
transmission of digital media plays an important role in communication. The
various digital media like audio, video and images are being transferred
through internet. There are a lot of threats for the digital data that are
transferred through internet. Also, a number of security techniques have been
employed to protect the data that is transferred through internet. This paper
proposes a new technique for sending secret messages securely, using
steganographic technique. Since the proposed system uses multiple level of
security for data hiding, where the data is hidden in an image file and the
stego file is again concealed in another image. Previously, the secret message
is being encrypted with the encryption algorithm which ensures the achievement
of high security enabled data transfer through internet.
"
157,"Design And Implementation Of Multilevel Access Control In Medical Image
  Transmission Using Symmetric Polynomial Based Audio Steganography","  ...The steganography scheme makes it possible to hide the medical image in
different bit locations of host media without inviting suspicion. The Secret
file is embedded in a cover media with a key. At the receiving end the key can
be derived by all the classes which are higher in the hierarchy using symmetric
polynomial and the medical image file can be retrieved. The system is
implemented and found to be secure, fast and scalable. Simulation results show
that the system is dynamic in nature and allows any type of hierarchy. The
proposed approach performs better even during frequent member joins and leaves.
The computation cost is reduced as the same algorithm is used for key
computation and descendant key derivation. Steganographic technique used in
this paper does not use the conventional LSB's and uses two bit positions and
the hidden data occurs only from a frame which is dictated by the key that is
used. Hence the quality of stego data is improved.
"
158,"Processor Based Active Queue Management for providing QoS in Multimedia
  Application","  The objective of this paper is to implement the Active Network based Active
Queue Management Technique for providing Quality of Service (QoS) using Network
Processor(NP) based router to enhance multimedia applications. The performance
is evaluated using Intel IXP2400 NP Simulator. The results demonstrate that,
Active Network based Active Queue Management has better performance than RED
algorithm in case of congestion and is well suited to achieve high speed packet
classification to support multimedia applications with minimum delay and Queue
loss. Using simulation, we show that the proposed system can provide assurance
for prioritized flows with improved network utilization where bandwidth is
shared among the flows according to the levels of priority. We first analyze
the feasibility and optimality of the load distribution schemes and then
present separate solutions for non-delay sensitive streams and delay-sensitive
streams. Rigorous simulations and experiments have been carried out to evaluate
the performance.
"
159,Review of Robust Video Watermarking Algorithms,"  There has been a remarkable increase in the data exchange over web and the
widespread use of digital media. As a result, multimedia data transfers also
had a boost up. The mounting interest with reference to digital watermarking
throughout the last decade is certainly due to the increase in the need of
copyright protection of digital content. This is also enhanced due to
commercial prospective. Applications of video watermarking in copy control,
broadcast monitoring, fingerprinting, video authentication, copyright
protection etc is immensely rising. The main aspects of information hiding are
capacity, security and robustness. Capacity deals with the amount of
information that can be hidden. The skill of anyone detecting the information
is security and robustness refers to the resistance to modification of the
cover content before concealed information is destroyed. Video watermarking
algorithms normally prefers robustness. In a robust algorithm it is not
possible to eliminate the watermark without rigorous degradation of the cover
content. In this paper, we introduce the notion of Video Watermarking and the
features required to design a robust watermarked video for a valuable
application. We review several algorithms, and introduce frequently used key
techniques. The aim of this paper is to focus on the various domains of video
watermarking techniques. The majority of the reviewed methods based on video
watermarking emphasize on the notion of robustness of the algorithm.
"
160,"SAR Image Segmentation using Vector Quantization Technique on Entropy
  Images","  The development and application of various remote sensing platforms result in
the production of huge amounts of satellite image data. Therefore, there is an
increasing need for effective querying and browsing in these image databases.
In order to take advantage and make good use of satellite images data, we must
be able to extract meaningful information from the imagery. Hence we proposed a
new algorithm for SAR image segmentation. In this paper we propose segmentation
using vector quantization technique on entropy image. Initially, we obtain
entropy image and in second step we use Kekre's Fast Codebook Generation (KFCG)
algorithm for segmentation of the entropy image. Thereafter, a codebook of size
128 was generated for the Entropy image. These code vectors were further
clustered in 8 clusters using same KFCG algorithm and converted into 8 images.
These 8 images were displayed as a result. This approach does not lead to over
segmentation or under segmentation. We compared these results with well known
Gray Level Co-occurrence Matrix. The proposed algorithm gives better
segmentation with less complexity.
"
161,"Reversible Image data Hiding using Lifting wavelet Transform and
  Histogram Shifting","  A method of lossless data hiding in images using integer wavelet transform
and histogram shifting for gray scale images is proposed. The method shifts
part of the histogram, to create space for embedding the watermark information
bits. The method embeds watermark while maintaining the visual quality well.
The method is completely reversible. The original image and the watermark data
can be recovered without any loss.
"
162,"C Implementation & comparison of companding & silence audio compression
  techniques","  Just about all the newest living room audio-video electronics and PC
multimedia products being designed today will incorporate some form of
compressed digitized-audio processing capability. Audio compression reduces the
bit rate required to represent an analog audio signal while maintaining the
perceived audio quality. Discarding inaudible data reduces the storage,
transmission and compute requirements of handling high-quality audio files.
This paper covers wave audio file format & algorithm of silence compression
method and companding method to compress and decompress wave audio file. Then
it compares the result of these two methods.
"
163,"Access-Network Association Policies for Media Streaming in Heterogeneous
  Environments","  We study the design of media streaming applications in the presence of
multiple heterogeneous wireless access methods with different throughputs and
costs. Our objective is to analytically characterize the trade-off between the
usage cost and the Quality of user Experience (QoE), which is represented by
the probability of interruption in media playback and the initial waiting time.
We model each access network as a server that provides packets to the user
according to a Poisson process with a certain rate and cost. Blocks are coded
using random linear codes to alleviate the duplicate packet reception problem.
Users must take decisions on how many packets to buffer before playout, and
which networks to access during playout. We design, analyze and compare several
control policies with a threshold structure. We formulate the problem of
finding the optimal control policy as an MDP with a probabilistic constraint.
We present the HJB equation for this problem by expanding the state space, and
exploit it as a verification method for optimality of the proposed control law.
"
164,Policies and Economics of Digital Multimedia Transmission,"  There are different Standards of digital multimedia transmission, for example
DVB in Europe and ISDB in Japan and DMB in Korea, with different delivery
system (example MPEG-2, MPEG-4).This paper describe an overview of Digital
Multimedia Transmission (DMT) technologies. The economic aspects of digital
content & software solution industry as a strategic key in the future will be
discussed. The study then focuses on some important policy and technology
issues, such S-DMB, T-DMB, Digital Video Broadcasting Handheld (DVB-H) and
concludes DMT policies for convergence of telecommunications and broadcasting.
"
165,"Error Concealment in Image Communication Using Edge Map Watermarking and
  Spatial Smoothing","  We propose a novel error concealment algorithm to be used at the receiver
side of a lossy image transmission system. Our algorithm involves hiding the
edge map of the original image at the transmitter within itself using a robust
watermarking scheme. At the receiver, wherever a lost block is detected, the
extracted edge information is used as border constraint for the spatial
smoothing employing the intact neighboring blocks in order to conceal errors.
Simulation results show the superiority of our technique over existing methods
even in case of high packet loss ratios in the communication network.
"
166,"Combination of Subtractive Clustering and Radial Basis Function in
  Speaker Identification","  Speaker identification is the process of determining which registered speaker
provides a given utterance. Speaker identification required to make a claim on
the identity of speaker from the Ns trained speaker in its user database. In
this study, we propose the combination of clustering algorithm and the
classification technique - subtractive and Radial Basis Function (RBF). The
proposed technique is chosen because RBF is a simpler network structures and
faster learning algorithm. RBF finds the input to output map using the local
approximators which will combine the linear of the approximators and cause the
linear combiner have few weights. Besides that, RBF neural network model using
subtractive clustering algorithm for selecting the hidden node centers, which
can achieve faster training speed. In the meantime, the RBF network was trained
with a regularization term so as to minimize the variances of the nodes in the
hidden layer and perform more accu-rate prediction.
"
167,"Visual Infrared Video Fusion for Night Vision using Background
  Estimation","  Video fusion is a process that combines visual data from different sensors to
obtain a single composite video preserving the information of the sources. The
availability of a system, enhancing human ability to perceive the observed
scenario, is crucial to improve the performance of a surveillance system. The
infrared (IR) camera captures thermal image of object in night-time
environment, when only limited visual information can be captured by RGB
camera. The fusion of data recorded by an IR sensor and a visible RGB camera
can produce information otherwise not obtainable by viewing the sensor outputs
separately. In this paper we consider the problem of fusing two video streams
acquired by an RGB camera and an IR sensor. The pedestrians, distinctly
captured by IR video, are separated and fused with the RGB video. The
algorithms implemented involve estimation of the background, followed by
detection of object from the IR Video, after necessary denoising. Finally a
suitable fusion algorithm is employed to combine the extracted pedestrians with
the visual output. The obtained results clearly demonstrate the effectiveness
of the proposed video fusion scheme, for night vision.
"
168,"Audio enabled information extraction system for cricket and hockey
  domains","  The proposed system aims at the retrieval of the summarized information from
the documents collected from web based search engine as per the user query
related to cricket and hockey domain. The system is designed in a manner that
it takes the voice commands as keywords for search. The parts of speech in the
query are extracted using the natural language extractor for English. Based on
the keywords the search is categorized into 2 types: - 1.Concept wise -
information retrieved to the query is retrieved based on the keywords and the
concept words related to it. The retrieved information is summarized using the
probabilistic approach and weighted means algorithm.2.Keyword search - extracts
the result relevant to the query from the highly ranked document retrieved from
the search by the search engine. The relevant search results are retrieved and
then keywords are used for summarizing part. During summarization it follows
the weighted and probabilistic approaches in order to identify the data
comparable to the keywords extracted. The extracted information is then refined
repeatedly through the aggregation process to reduce redundancy. Finally the
resultant data is submitted to the user in the form of audio output.
"
169,"Influence of distortions of key frames on video transfer in wireless
  networks","  In this paper it is shown that for substantial increase of video quality in
wireless network it is necessary to execute two obligatory points on
modernization of the communication scheme. The player on the received part
should throw back automatically duplicated RTP packets, server of streaming
video should duplicate the packets containing the information of key frames.
Coefficients of the mathematical model describing video quality in wireless
network have been found for WiFi and 3G standards and codecs MPEG-2 and MPEG-4
(DivX). The special experimental technique which has allowed collecting and
processing the data has been developed for calculation of values of factors.
"
170,"Towards Hardware implementation of video applications in new
  telecommunications devices","  Among the areas, most demanding in terms of calculation is the
telecommunication and video applications are now included in several
telecommunication devices such as set-top boxes, mobile phones. Embedded videos
applications in new generations of telecommunication devices need a processing
capacity that can not be achieved by the conventional processor, to work around
this problem the use of programmable technology has a lot of interest. First,
Field Programmable Gate Arrays (FPGAs) present many performance benefits for
real-time image processing applications. The FPGA structure is able to exploit
spatial and temporal parallelism. In this paper, we present a new method for
implementation of the Color Structure Descriptor (CSD) using the FPGA circuit.
In fact the (CSD) provides satisfactory image indexing and retrieval results
among all colorbased descriptors in MPEG-7. But the real time implementation of
this descriptor is still having problems. In this paper we propose a method for
adapting this descriptor for possible implementation under the constraints of
the video processing in real time. We have verified the real-time
implementation of the (CSD) with an image size of 120*80 pixels.
"
171,On Macroscopic Complexity and Perceptual Coding,"  The theoretical limits of 'lossy' data compression algorithms are considered.
The complexity of an object as seen by a macroscopic observer is the size of
the perceptual code which discards all information that can be lost without
altering the perception of the specified observer. The complexity of this
macroscopically observed state is the simplest description of any microstate
comprising that macrostate. Inference and pattern recognition based on
macrostate rather than microstate complexities will take advantage of the
complexity of the macroscopic observer to ignore irrelevant noise.
"
172,Architecture for Cooperative Prefetching in P2P Video-on- Demand System,"  Most P2P VoD schemes focused on service architectures and overlays
optimization without considering segments rarity and the performance of
prefetching strategies. As a result, they cannot better support VCRoriented
service in heterogeneous environment having clients using free VCR controls.
Despite the remarkable popularity in VoD systems, there exist no prior work
that studies the performance gap between different prefetching strategies. In
this paper, we analyze and understand the performance of different prefetching
strategies. Our analytical characterization brings us not only a better
understanding of several fundamental tradeoffs in prefetching strategies, but
also important insights on the design of P2P VoD system. On the basis of this
analysis, we finally proposed a cooperative prefetching strategy called
""cooching"". In this strategy, the requested segments in VCR interactivities are
prefetched into session beforehand using the information collected through
gossips. We evaluate our strategy through extensive simulations. The results
indicate that the proposed strategy outperforms the existing prefetching
mechanisms.
"
173,Proviola: A Tool for Proof Re-animation,"  To improve on existing models of interaction with a proof assistant (PA), in
particular for storage and replay of proofs, we in- troduce three related
concepts, those of: a proof movie, consisting of frames which record both user
input and the corresponding PA response; a camera, which films a user's
interactive session with a PA as a movie; and a proviola, which replays a movie
frame-by-frame to a third party. In this paper we describe the movie data
structure and we discuss a proto- type implementation of the camera and
proviola based on the ProofWeb system. ProofWeb uncouples the interaction with
a PA via a web- interface (the client) from the actual PA that resides on the
server. Our camera films a movie by ""listening"" to the ProofWeb communication.
The first reason for developing movies is to uncouple the reviewing of a formal
proof from the PA used to develop it: the movie concept enables users to
discuss small code fragments without the need to install the PA or to load a
whole library into it. Other advantages include the possibility to develop a
separate com- mentary track to discuss or explain the PA interaction. We assert
that a combined camera+proviola provides a generic layer between a client
(user) and a server (PA). Finally we claim that movies are the right type of
data to be stored in an encyclopedia of formalized mathematics, based on our
experience in filming the Coq standard library.
"
174,"A Study on Potential of Integrating Multimodal Interaction into Musical
  Conducting Education","  With the rapid development of computer technology, computer music has begun
to appear in the laboratory. Many potential utility of computer music is
gradually increasing. The purpose of this paper is attempted to analyze the
possibility of integrating multimodal interaction such as vision-based hand
gesture and speech interaction into musical conducting education. To achieve
this purpose, this paper is focus on discuss some related research and the
traditional musical conducting education. To do so, six musical conductors had
been interviewed to share their musical conducting learning/ teaching
experience. These interviews had been analyzed in this paper to show the
syllabus and the focus of musical conducting education for beginners.
"
175,Content Base Image Retrieval Using Phong Shading,"  The digital image data is rapidly expanding in quantity and heterogeneity.
The traditional information retrieval techniques does not meet the user's
demand, so there is need to develop an efficient system for content based image
retrieval. Content based image retrieval means retrieval of images from
database on the basis of visual features of image like as color, texture etc.
In our proposed method feature are extracted after applying Phong shading on
input image. Phong shading, flattering out the dull surfaces of the image The
features are extracted using color, texture & edge density methods. Feature
extracted values are used to find the similarity between input query image and
the data base image. It can be measure by the Euclidean distance formula. The
experimental result shows that the proposed approach has a better retrieval
results with phong shading.
"
176,"A basic gesture and motion format for virtual reality multisensory
  applications","  The question of encoding movements such as those produced by human gestures
may become central in the coming years, given the growing importance of
movement data exchanges between heterogeneous systems and applications (musical
applications, 3D motion control, virtual reality interaction, etc.). For the
past 20 years, various formats have been proposed for encoding movement,
especially gestures. Though, these formats, at different degrees, were designed
in the context of quite specific applications (character animation, motion
capture, musical gesture, biomechanical concerns...). The article introduce a
new file format, called GMS (for 'Gesture and Motion Signal'), with the aim of
being more low-level and generic, by defining the minimal features a format
carrying movement/gesture information needs, rather than by gathering all the
information generally given by the existing formats. The article argues that,
given its growing presence in virtual reality situations, the ""gesture signal""
itself must be encoded, and that a specific format is needed. The proposed
format features the inner properties of such signals: dimensionality,
structural features, types of variables, and spatial and temporal properties.
The article first reviews the various situations with multisensory virtual
objects in which gesture controls intervene. The proposed format is then
deduced, as a mean to encode such versatile and variable ""gestural and animated
scene"".
"
177,Client-to-Client Streaming Scheme for VOD Applications,"  In this paper, we propose an efficient client-to-client streaming approach to
cooperatively stream the video using chaining technique with unicast
communication among the clients. This approach considers two major issues of
VoD 1) Prefix caching scheme to accommodate more number of videos closer to
client, so that the request-service delay for the user can be minimized. 2)
Cooperative proxy and client chaining scheme for streaming the videos using
unicasting. This approach minimizes the client rejection rate and bandwidth
requirement on server to proxy and proxy to client path. Our simulation results
show that the proposed approach achieves reduced client waiting time and
optimal prefix caching of videos minimizing server to proxy path bandwidth
usage by utilizing the client to client bandwidth, which is occasionally used
when compared to busy server to proxy path bandwidth.
"
178,"An Automated Algorithm for Approximation of Temporal Video Data Using
  Linear B'EZIER Fitting","  This paper presents an efficient method for approximation of temporal video
data using linear Bezier fitting. For a given sequence of frames, the proposed
method estimates the intensity variations of each pixel in temporal dimension
using linear Bezier fitting in Euclidean space. Fitting of each segment ensures
upper bound of specified mean squared error. Break and fit criteria is employed
to minimize the number of segments required to fit the data. The proposed
method is well suitable for lossy compression of temporal video data and
automates the fitting process of each pixel. Experimental results show that the
proposed method yields good results both in terms of objective and subjective
quality measurement parameters without causing any blocking artifacts.
"
179,"A novel technique for image steganography based on Block-DCT and Huffman
  Encoding","  Image steganography is the art of hiding information into a cover image. This
paper presents a novel technique for Image steganography based on Block-DCT,
where DCT is used to transform original image (cover image) blocks from spatial
domain to frequency domain. Firstly a gray level image of size M x N is divided
into no joint 8 x 8 blocks and a two dimensional Discrete Cosine Transform (2-d
DCT) is performed on each of the P = MN / 64 blocks. Then Huffman encoding is
also performed on the secret messages/images before embedding and each bit of
Huffman code of secret message/image is embedded in the frequency domain by
altering the least significant bit of each of the DCT coefficients of cover
image blocks. The experimental results show that the algorithm has a high
capacity and a good invisibility. Moreover PSNR of cover image with stego-image
shows the better results in comparison with other existing steganography
approaches. Furthermore, satisfactory security is maintained since the secret
message/image cannot be extracted without knowing decoding rules and Huffman
table.
"
180,An Alternative Approach of Steganography using Reference Image,"  This paper is to create a practical steganographic implementation for 4-bit
images.The proposed technique converts 4 bit image into 4 shaded Gray Scale
image. This image will be act as reference image to hide the text. Using this
grey scale reference image any text can be hidden. Single character of a text
can be represented by 8-bit. The 8-bit character can be split into 4X2 bit
information. If the reference image and the data file are transmitted through
network separately, we can achieve the effect of Steganography. Here the image
is not at all distorted because said image is only used for referencing. Any
huge mount of text material can be hidden using a very small image. Decipher
the text is not possible intercepting the image or data file separately. So, it
is more secure.
"
181,"Human Daily Activities Indexing in Videos from Wearable Cameras for
  Monitoring of Patients with Dementia Diseases","  Our research focuses on analysing human activities according to a known
behaviorist scenario, in case of noisy and high dimensional collected data. The
data come from the monitoring of patients with dementia diseases by wearable
cameras. We define a structural model of video recordings based on a Hidden
Markov Model. New spatio-temporal features, color features and localization
features are proposed as observations. First results in recognition of
activities are promising.
"
182,"Perceptual Copyright Protection Using Multiresolution Wavelet-Based
  Watermarking And Fuzzy Logic","  In this paper, an efficiently DWT-based watermarking technique is proposed to
embed signatures in images to attest the owner identification and discourage
the unauthorized copying. This paper deals with a fuzzy inference filter to
choose the larger entropy of coefficients to embed watermarks. Unlike most
previous watermarking frameworks which embedded watermarks in the larger
coefficients of inner coarser subbands, the proposed technique is based on
utilizing a context model and fuzzy inference filter by embedding watermarks in
the larger-entropy coefficients of coarser DWT subbands. The proposed
approaches allow us to embed adaptive casting degree of watermarks for
transparency and robustness to the general image-processing attacks such as
smoothing, sharpening, and JPEG compression. The approach has no need the
original host image to extract watermarks. Our schemes have been shown to
provide very good results in both image transparency and robustness.
"
183,"Fully automatic extraction of salient objects from videos in near
  real-time","  Automatic video segmentation plays an important role in a wide range of
computer vision and image processing applications. Recently, various methods
have been proposed for this purpose. The problem is that most of these methods
are far from real-time processing even for low-resolution videos due to the
complex procedures. To this end, we propose a new and quite fast method for
automatic video segmentation with the help of 1) efficient optimization of
Markov random fields with polynomial time of number of pixels by introducing
graph cuts, 2) automatic, computationally efficient but stable derivation of
segmentation priors using visual saliency and sequential update mechanism, and
3) an implementation strategy in the principle of stream processing with
graphics processor units (GPUs). Test results indicates that our method
extracts appropriate regions from videos as precisely as and much faster than
previous semi-automatic methods even though any supervisions have not been
incorporated.
"
184,"Web Video Categorization based on Wikipedia Categories and
  Content-Duplicated Open Resources","  This paper presents a novel approach for web video categorization by
leveraging Wikipedia categories (WikiCs) and open resources describing the same
content as the video, i.e., content-duplicated open resources (CDORs). Note
that current approaches only col-lect CDORs within one or a few media forms and
ignore CDORs of other forms. We explore all these resources by utilizing WikiCs
and commercial search engines. Given a web video, its discrimin-ative Wikipedia
concepts are first identified and classified. Then a textual query is
constructed and from which CDORs are collected. Based on these CDORs, we
propose to categorize web videos in the space spanned by WikiCs rather than
that spanned by raw tags. Experimental results demonstrate the effectiveness of
both the proposed CDOR collection method and the WikiC voting catego-rization
algorithm. In addition, the categorization model built based on both WikiCs and
CDORs achieves better performance compared with the models built based on only
one of them as well as state-of-the-art approach.
"
185,Optimized Image Steganalysis through Feature Selection using MBEGA,"  Feature based steganalysis, an emerging branch in information forensics, aims
at identifying the presence of a covert communication by employing the
statistical features of the cover and stego image as clues/evidences. Due to
the large volumes of security audit data as well as complex and dynamic
properties of steganogram behaviours, optimizing the performance of
steganalysers becomes an important open problem. This paper is focussed at fine
tuning the performance of six promising steganalysers in this field, through
feature selection. We propose to employ Markov Blanket-Embedded Genetic
Algorithm (MBEGA) for stego sensitive feature selection process. In particular,
the embedded Markov blanket based memetic operators add or delete features (or
genes) from a genetic algorithm (GA) solution so as to quickly improve the
solution and fine-tune the search. Empirical results suggest that MBEGA is
effective and efficient in eliminating irrelevant and redundant features based
on both Markov blanket and predictive power in classifier model. Observations
show that the proposed method is superior in terms of number of selected
features, classification accuracy and computational cost than their existing
counterparts.
"
186,"Reliable Multicasting for Device-to-Device Radio Underlaying Cellular
  Networks","  This paper proposes Leader in Charge (LiC), a reliable multicast architecture
for device-to-device (D2D) radio underlaying cellular networks. The
multicast-requesting user equipments (UEs) in close proximity form a D2D
cluster to receive the multicast packets through cooperation. In addition to
receiving the multicast packets from the eNB, UEs share what they received from
the multicast on short-range links among UEs, namely the D2D links, to exploit
the wireless resources a more efficient way. Consequently, we show that
utilizing the D2D links in cellular networks increases the throughput of a
multicast session by means of simulation. We also discuss some practical issues
facing the integration of LiC into the current cellular networks. In
particular, we propose efficient delay control mechanism to reduce the average
and maximum delay experienced by LiC users, which is further confirmed by the
simulation results.
"
187,"Structural Solutions to Dynamic Scheduling for Multimedia Transmission
  in Unknown Wireless Environments","  In this paper, we propose a systematic solution to the problem of scheduling
delay-sensitive media data for transmission over time-varying wireless
channels. We first formulate the dynamic scheduling problem as a Markov
decision process (MDP) that explicitly considers the users' heterogeneous
multimedia data characteristics (e.g. delay deadlines, distortion impacts and
dependencies etc.) and time-varying channel conditions, which are not
simultaneously considered in state-of-the-art packet scheduling algorithms.
This formulation allows us to perform foresighted decisions to schedule
multiple data units for transmission at each time in order to optimize the
long-term utilities of the multimedia applications. The heterogeneity of the
media data enables us to express the transmission priorities between the
different data units as a priority graph, which is a directed acyclic graph
(DAG). This priority graph provides us with an elegant structure to decompose
the multi-data unit foresighted decision at each time into multiple single-data
unit foresighted decisions which can be performed sequentially, from the high
priority data units to the low priority data units, thereby significantly
reducing the computation complexity. When the statistical knowledge of the
multimedia data characteristics and channel conditions is unknown a priori, we
develop a low-complexity online learning algorithm to update the value
functions which capture the impact of the current decision on the future
utility. The simulation results show that the proposed solution significantly
outperforms existing state-of-the-art scheduling solutions.
"
188,M-Learning: A New Paradigm of Learning Mathematics in Malaysia,"  M-Learning is a new learning paradigm of the new social structure with mobile
and wireless technologies.Smart school is one of the four flagship applications
for Multimedia Super Corridor (MSC) under Malaysian government initiative to
improve education standard in the country. With the advances of mobile devices
technologies, mobile learning could help the government in realizing the
initiative. This paper discusses the prospect of implementing mobile learning
for primary school students. It indicates significant and challenges and
analysis of user perceptions on potential mobile applications through a survey
done in primary school context. The authors propose the m-Learning for
mathematics by allowing the extension of technology in the traditional
classroom in term of learning and teaching.
"
189,A Block Based Scheme for Enhancing Low Luminated Images,"  In this paper the background detection in images in poor lighting can be done
by the use of morphological filters. Lately contrast image enhancement
technique is used to detect the background in image which uses Weber's Law. The
proposed technique is more effective one in which the background detection in
image can be done in color images. The given image obtained in this method is
very effective one. More enhancement can be obtained while comparing the
results. In this technique compressed domain enhancement has been used for
better result.
"
190,"Network evolution and QOS provisioning for integrated
  femtocell/macrocell networks","  Integrated femtocell/macrocell networks, comprising a conventional cellular
network overlaid with femtocells, offer an economically appealing way to
improve coverage, quality of service, and access network capacity. The key
element to successful femtocells/macrocell integration lies in its
self-organizing capability. Provisioning of quality of service is the main
technical challenge of the femtocell/macrocell integrated networks, while the
main administrative challenge is the choice of the proper evolutionary path
from the existing macrocellular networks to the integrated network. In this
article, we introduce three integrated network architectures which, while
increasing the access capacity, they also reduce the deployment and operational
costs. Then, we discuss a number of technical issues, which are key to making
such integration a reality, and we offer possible approaches to their solution.
These issues include efficient frequency and interference management, quality
of service provisioning of the xDSL-based backhaul networks, and intelligent
handover control.
"
191,Handover Control for WCDMA Femtocell Networks,"  The ability to seamlessly switch between the macro networks and femtocell
networks is a key driver for femtocell network deployment. The handover
procedures for the integrated femtocell/macrocell networks differ from the
existing handovers. Some modifications of existing network and protocol
architecture for the integration of femtocell networks with the existing
macrocell networks are also essential. These modifications change the signal
flow for handover procedures due to different 2-tier cell (macrocell and
femtocell) environment. The handover between two networks should be performed
with minimum signaling. A frequent and unnecessary handover is another problem
for hierarchical femtocell/macrocell network environment that must be
minimized. This work studies the details mobility management schemes for small
and medium scale femtocell network deployment. To do that, firstly we present
two different network architectures for small scale and medium scale WCDMA
femtocell deployment. The details handover call flow for these two network
architectures and CAC scheme to minimize the unnecessary handovers are proposed
for the integrated femtocell/macrocell networks. The numerical analysis for the
proposed M/M/N/N queuing scheme and the simulation results of the proposed CAC
scheme demonstrate the handover call control performances for femtocell
environment.
"
192,"Improved Iterative Techniques to Compensate for Interpolation
  Distortions","  In this paper a novel hybrid approach for compensating the distortion of any
interpolation has been proposed. In this hybrid method, a modular approach was
incorporated in an iterative fashion. By using this approach we can get drastic
improvement with less computational complexity. The extension of the proposed
approach to two dimensions was also studied. Both the simulation results and
mathematical analyses confirmed the superiority of the hybrid method. The
proposed method was also shown to be robust against additive noise.
"
193,"A Gossip-based optimistic replication for efficient delay-sensitive
  streaming using an interactive middleware support system","  While sharing resources the efficiency is substantially degraded as a result
of the scarceness of availability of the requested resources in a multiclient
support manner. These resources are often aggravated by many factors like the
temporal constraints for availability or node flooding by the requested
replicated file chunks. Thus replicated file chunks should be efficiently
disseminated in order to enable resource availability on-demand by the mobile
users. This work considers a cross layered middleware support system for
efficient delay-sensitive streaming by using each device's connectivity and
social interactions in a cross layered manner. The collaborative streaming is
achieved through the epidemically replicated file chunk policy which uses a
transition-based approach of a chained model of an infectious disease with
susceptible, infected, recovered and death states. The Gossip-based stateful
model enforces the mobile nodes whether to host a file chunk or not or, when no
longer a chunk is needed, to purge it. The proposed model is thoroughly
evaluated through experimental simulation taking measures for the effective
throughput Eff as a function of the packet loss parameter in contrast with the
effectiveness of the replication Gossip-based policy.
"
194,Morphological dilation image coding with context weights prediction,"  This paper proposes an adaptive morphological dilation image coding with
context weights prediction. The new dilation method is not to use fixed models,
but to decide whether a coefficient needs to be dilated or not according to the
coefficient's predicted significance degree. It includes two key dilation
technologies: 1) controlling dilation process with context weights to reduce
the output of insignificant coefficients, and 2) using variable-length group
test coding with context weights to adjust the coding order and cost as few
bits as possible to present the events with large probability. Moreover, we
also propose a novel context weight strategy to predict coefficient's
significance degree more accurately, which serves for two dilation
technologies. Experimental results show that our proposed method outperforms
the state of the art image coding algorithms available today.
"
195,Profile Based Sub-Image Search in Image Databases,"  Sub-image search with high accuracy in natural images still remains a
challenging problem. This paper proposes a new feature vector called profile
for a keypoint in a bag of visual words model of an image. The profile of a
keypoint captures the spatial geometry of all the other keypoints in an image
with respect to itself, and is very effective in discriminating true matches
from false matches. Sub-image search using profiles is a single-phase process
requiring no geometric validation, yields high precision on natural images, and
works well on small visual codebook. The proposed search technique differs from
traditional methods that first generate a set of candidates disregarding
spatial information and then verify them geometrically. Conventional methods
also use large codebooks. We achieve a precision of 81% on a combined data set
of synthetic and real natural images using a codebook size of 500 for top-10
queries; that is 31% higher than the conventional candidate generation
approach.
"
196,Transmitting Video-on-Demand Effectively,"  Now-a-days internet has become a vast source of entertainment & new services
are available in quick succession which provides entertainment to the users.
One of this service i.e. Video-on-Demand is most hyped service in this context.
Transferring the video over the network with less error is the main objective
of the service providers. In this paper we present an algorithm for routing the
video to the user in an effective manner along with a method that ensures less
error rate than others.
"
197,Alternatives to speech in low bit rate communication systems,"  This paper describes a framework and a method with which speech communication
can be analyzed. The framework consists of a set of low bit rate, short-range
acoustic communication systems, such as speech, but that are quite different
from speech. The method is to systematically compare these systems according to
different objective functions such as data rate, computational overhead,
psychoacoustic effects and semantics. One goal of this study is to better
understand the nature of human communication. Another goal is to identify
acoustic communication systems that are more efficient than human speech for
some specific purposes.
"
198,Colour Guided Colour Image Steganography,"  Information security has become a cause of concern because of the electronic
eavesdropping. Capacity, robustness and invisibility are important parameters
in information hiding and are quite difficult to achieve in a single algorithm.
This paper proposes a novel steganography technique for digital color image
which achieves the purported targets. The professed methodology employs a
complete random scheme for pixel selection and embedding of data. Of the three
colour channels (Red, Green, Blue) in a given colour image, the least two
significant bits of any one of the channels of the color image is used to
channelize the embedding capacity of the remaining two channels. We have
devised three approaches to achieve various levels of our desired targets. In
the first approach, Red is the default guide but it results in localization of
MSE in the remaining two channels, which makes it slightly vulnerable. In the
second approach, user gets the liberty to select the guiding channel (Red,
Green or Blue) to guide the remaining two channels. It will increase the
robustness and imperceptibility of the embedded image however the MSE factor
will still remain as a drawback. The third approach improves the performance
factor as a cyclic methodology is employed and the guiding channel is selected
in a cyclic fashion. This ensures the uniform distribution of MSE, which gives
better robustness and imperceptibility along with enhanced embedding capacity.
The imperceptibility has been enhanced by suitably adapting optimal pixel
adjustment process (OPAP) on the stego covers.
"
199,"Haar Wavelet Based Approach for Image Compression and Quality Assessment
  of Compressed Image","  With the increasing growth of technology and the entrance into the digital
age, we have to handle a vast amount of information every time which often
presents difficulties. So, the digital information must be stored and retrieved
in an efficient and effective manner, in order for it to be put to practical
use. Wavelets provide a mathematical way of encoding information in such a way
that it is layered according to level of detail. This layering facilitates
approximations at various intermediate stages. These approximations can be
stored using a lot less space than the original data. Here a low complex 2D
image compression method using wavelets as the basis functions and the approach
to measure the quality of the compressed image are presented. The particular
wavelet chosen and used here is the simplest wavelet form namely the Haar
Wavelet. The 2D discret wavelet transform (DWT) has been applied and the detail
matrices from the information matrix of the image have been estimated. The
reconstructed image is synthesized using the estimated detail matrices and
information matrix provided by the Wavelet transform. The quality of the
compressed images has been evaluated using some factors like Compression Ratio
(CR), Peak Signal to Noise Ratio (PSNR), Mean Opinion Score (MOS), Picture
Quality Scale (PQS) etc.
"
200,Compensating Interpolation Distortion by New Optimized Modular Method,"  A modular method was suggested before to recover a band limited signal from
the sample and hold and linearly interpolated (or, in general, an
nth-order-hold) version of the regular samples. In this paper a novel approach
for compensating the distortion of any interpolation based on modular method
has been proposed. In this method the performance of the modular method is
optimized by adding only some simply calculated coefficients. This approach
causes drastic improvement in terms of SNRs with fewer modules compared to the
classical modular method. Simulation results clearly confirm the improvement of
the proposed method and also its superior robustness against additive noise.
"
201,Web Conferencing Traffic - An Analysis using DimDim as Example,"  In this paper, we present an evaluation of the Ethernet traffic for host and
attendees of the popular opensource web conferencing system DimDim. While
traditional Internet-centric approaches such as the MBONE have been used over
the past decades, current trends for web-based conference systems make
exclusive use of application-layer multicast. To allow for network dimensioning
and QoS provisioning, an understanding of the underlying traffic
characteristics is required. We find in our exemplary evaluations that the host
of a web conference session produces a large amount of Ethernet traffic,
largely due to the required control of the conference session, that is
heavily-tailed distributed and exhibits additionally long-range dependence. For
different groups of activities within a web conference session, we find
distinctive characteristics of the generated traffic.
"
202,Image Inpainting Using Sparsity of the Transform Domain,"  In this paper, we propose a new image inpainting method based on the property
that much of the image information in the transform domain is sparse. We add a
redundancy to the original image by mapping the transform coefficients with
small amplitudes to zero and the resultant sparsity pattern is used as the side
information in the recovery stage. If the side information is not available,
the receiver has to estimate the sparsity pattern. At the end, the recovery is
done by consecutive projecting between two spatial and transform sets.
Experimental results show that our method works well for both structural and
texture images and outperforms other techniques in objective and subjective
performance measures.
"
203,An Effective Method of Image Retrieval using Image Mining Techniques,"  The present research scholars are having keen interest in doing their
research activities in the area of Data mining all over the world. Especially,
[13]Mining Image data is the one of the essential features in this present
scenario since image data plays vital role in every aspect of the system such
as business for marketing, hospital for surgery, engineering for construction,
Web for publication and so on. The other area in the Image mining system is the
Content-Based Image Retrieval (CBIR) which performs retrieval based on the
similarity defined in terms of extracted features with more objectiveness. The
drawback in CBIR is the features of the query image alone are considered.
Hence, a new technique called Image retrieval based on optimum clusters is
proposed for improving user interaction with image retrieval systems by fully
exploiting the similarity information. The index is created by describing the
images according to their color characteristics, with compact feature vectors,
that represent typical color distributions [12].
"
204,A proposed Optimized Spline Interpolation,"  The goal of this paper is to design compact support basis spline functions
that best approximate a given filter (e.g., an ideal Lowpass filter). The
optimum function is found by minimizing the least square problem ($\ell$2 norm
of the difference between the desired and the approximated filters) by means of
the calculus of variation; more precisely, the introduced splines give optimal
filtering properties with respect to their time support interval. Both
mathematical analysis and simulation results confirm the superiority of these
splines.
"
205,"Image Deblurring and Super-resolution by Adaptive Sparse Domain
  Selection and Adaptive Regularization","  As a powerful statistical image modeling technique, sparse representation has
been successfully used in various image restoration applications. The success
of sparse representation owes to the development of l1-norm optimization
techniques, and the fact that natural images are intrinsically sparse in some
domain. The image restoration quality largely depends on whether the employed
sparse domain can represent well the underlying image. Considering that the
contents can vary significantly across different images or different patches in
a single image, we propose to learn various sets of bases from a pre-collected
dataset of example image patches, and then for a given patch to be processed,
one set of bases are adaptively selected to characterize the local sparse
domain. We further introduce two adaptive regularization terms into the sparse
representation framework. First, a set of autoregressive (AR) models are
learned from the dataset of example image patches. The best fitted AR models to
a given patch are adaptively selected to regularize the image local structures.
Second, the image non-local self-similarity is introduced as another
regularization term. In addition, the sparsity regularization parameter is
adaptively estimated for better image restoration performance. Extensive
experiments on image deblurring and super-resolution validate that by using
adaptive sparse domain selection and adaptive regularization, the proposed
method achieves much better results than many state-of-the-art algorithms in
terms of both PSNR and visual perception.
"
206,Evaluating Modelling Approaches for Medical Image Annotations,"  Information system designers face many challenges w.r.t. selecting
appropriate semantic technologies and deciding on a modelling approach for
their system. However, there is no clear methodology yet to evaluate
""semantically enriched"" information systems. In this paper we present a case
study on different modelling approaches for annotating medical images and
introduce a conceptual framework that can be used to analyse the fitness of
information systems and help designers to spot the strengths and weaknesses of
various modelling approaches as well as managing trade-offs between modelling
effort and their potential benefits.
"
207,"A Survey on Cross-Layer Design Frameworks for Multimedia Applications
  over Wireless Networks","  In the last few years, the Internet throughput, usage and reliability have
increased almost exponentially. The introduction of broadband wireless mobile
ad hoc networks (MANETs) and cellular networks together with increased
computational power have opened the door for a new breed of applications to be
created, namely real-time multimedia applications. Delivering real-time
multimedia traffic over a complex network like the Internet is a particularly
challenging task since these applications have strict quality -of-service (QoS)
requirements on bandwidth, delay, and delay jitter. Traditional IP-based best
effort service will not be able to meet these stringent requirements. The
time-varying nature of wireless channels and resource constrained wireless
devices make the problem even more difficult. To improve perceived media
quality by end users over wireless Internet, QoS supports can be addressed in
different layers, including application layer, transport layer and link layer.
Cross layer design is a well-known approach to achieve this adaptation. In
cross-layer design, the challenges from the physical wireless medium and the
QoS-demands from the applications are taken into account so that the rate,
power, and coding at the physical layer can adapted to meet the requirements of
the applications given the current channel and network conditions. A number of
propositions for cross-layer designs exist in the literature. In this paper, an
extensive review has been made on these cross-layer architectures that combine
the application-layer, transport layer and the link layer controls.
Particularly the issues like channel estimation techniques, adaptive controls
at the application and link layers for energy efficiency, priority based
scheduling, transmission rate control at the transport layer, and adaptive
automatic repeat request (ARQ) are discussed in detail.
"
208,Digital watermarking : An approach based on Hilbert transform,"  Most of the well known algorithms for watermarking of digital images involve
transformation of the image data to Fourier or singular vector space. In this
paper, we introduce watermarking in Hilbert transform domain for digital media.
Generally, if the image is a matrix of order $m$ by $n$, then the transformed
space is also an image of the same order. However, with Hilbert transforms, the
transformed space is of order $2m$ by $2n$. This allows for more latitude in
storing the watermark in the host image. Based on this idea, we propose an
algorithm for embedding and extracting watermark in a host image and
analytically obtain a parameter related to this procedure. Using extensive
simulations, we show that the algorithm performs well even if the host image is
corrupted by various attacks.
"
209,"Texture feature extraction in the spatial-frequency domain for
  content-based image retrieval","  The advent of large scale multimedia databases has led to great challenges in
content-based image retrieval (CBIR). Even though CBIR is considered an
emerging field of research, however it constitutes a strong background for new
methodologies and systems implementations. Therefore, many research
contributions are focusing on techniques enabling higher image retrieval
accuracy while preserving low level of computational complexity. Image
retrieval based on texture features is receiving special attention because of
the omnipresence of this visual feature in most real-world images. This paper
highlights the state-of-the-art and current progress relevant to texture-based
image retrieval and spatial-frequency image representations. In particular, it
gives an overview of statistical methodologies and techniques employed for
texture feature extraction using most popular spatial-frequency image
transforms, namely discrete wavelets, Gabor wavelets, dual-tree complex wavelet
and contourlets. Indications are also given about used similarity measurement
functions and most important achieved results.
"
210,Image Sterilization to Prevent LSB-based Steganographic Transmission,"  Sterilization is a very popular word used in biomedical testing (like removal
of all microorganisms on surface of an article or in fluid using appropriate
chemical products). Motivated by this biological analogy, we, for the first
time, introduce the concept of sterilization of an image, i.e., removing any
steganographic information embedded in the image. Experimental results show
that our technique succeeded in sterilizing around 76% to 91% of stego pixels
in an image on average, where data is embedded using LSB-based steganography.
"
211,Packet Scheduling in Switches with Target Outflow Profiles,"  The problem of packet scheduling for traffic streams with target outflow
profiles traversing input queued switches is formulated in this paper. Target
outflow profiles specify the desirable inter-departure times of packets leaving
the switch from each traffic stream. The goal of the switch scheduler is to
dynamically select service configurations of the switch, so that actual outflow
streams (""pulled"" through the switch) adhere to their desired target profiles
as accurately as possible. Dynamic service controls (schedules) are developed
to minimize deviation of actual outflow streams from their targets and suppress
stream ""distortion"". Using appropriately selected subsets of service
configurations of the switch, efficient schedules are designed, which deliver
high performance at relatively low complexity. Some of these schedules are
provably shown to achieve 100% pull-throughput. Moreover, simulations
demonstrate that for even substantial contention of streams through the switch,
due to stringent/intense target outflow profiles, the proposed schedules
achieve closely their target profiles and suppress stream distortion. The
switch model investigated here deviates from the classical switching paradigm.
In the latter, the goal of packet scheduling is primarily to ""push"" as much
traffic load through the switch as possible, while controlling delay to
traverse the switch and keeping congestion/backlogs from exploding. In the
model presented here, however, the goal of packet scheduling is to ""pull""
traffic streams through the switch, maintaining desirable (target) outflow
profiles.
"
212,"Alchymical Mirror: Real-time Interactive Sound- and Simple
  Motion-Tracking Set of Jitter/Max/MSP Patches","  This document supplements an experimental Jitter / Max/MSP collection of
implementation patches that set its goal to simulate an alchemical process for
a person standing in front of a mirror-like screen while interacting with it.
The work involved takes some patience and has three stages to go through. At
the final stage the ""alchemist"" in the mirror wearing sharp-colored gloves (for
motion tracking) is to extract the final ultimate shining sparkle (FFT-based
visualization) in the nexus of the hands. The more the hands are apart, the
large the sparkle should be. Moving hands around should make the sparkle
follow. To achieve the desired visual effect and the feedback mechanism, the
Jitter lattice-based intensional programming model is used to work on
4-dimensional (A+R+G+B) video matrices and sound signals in order to apply some
well-known alchemical techniques to the video at real-time to get a mirror
effect and accompanying transmutation and transformation stages of the video
based on the stability of the sound produced for some duration of time in
real-time. There is an accompanying video of the result with the interaction
with the tool and the corresponding programming patches.
"
213,"Selection of network coding nodes for minimal playback delay in
  streaming overlays","  Network coding permits to deploy distributed packet delivery algorithms that
locally adapt to the network availability in media streaming applications.
However, it may also increase delay and computational complexity if it is not
implemented efficiently. We address here the effective placement of nodes that
implement randomized network coding in overlay networks, so that the goodput is
kept high while the delay for decoding stays small in streaming applications.
We first estimate the decoding delay at each client, which depends on the
innovative rate in the network. This estimation permits to identify the nodes
that have to perform coding for a reduced decoding delay. We then propose two
iterative algorithms for selecting the nodes that should perform network
coding. The first algorithm relies on the knowledge of the full network
statistics. The second algorithm uses only local network statistics at each
node. Simulation results show that large performance gains can be achieved with
the selection of only a few network coding nodes. Moreover, the second
algorithm performs very closely to the central estimation strategy, which
demonstrates that the network coding nodes can be selected efficiently in a
distributed manner. Our scheme shows large gains in terms of achieved
throughput, delay and video quality in realistic overlay networks when compared
to methods that employ traditional streaming strategies as well as random
network nodes selection algorithms.
"
214,Multi-Level Steganography: Improving Hidden Communication in Networks,"  The paper presents Multi-Level Steganography (MLS), which defines a new
concept for hidden communication in telecommunication networks. In MLS, at
least two steganographic methods are utilised simultaneously, in such a way
that one method (called the upper-level) serves as a carrier for the second one
(called the lower-level). Such a relationship between two (or more) information
hiding solutions has several potential benefits. The most important is that the
lower-level method steganographic bandwidth can be utilised to make the
steganogram unreadable even after the detection of the upper-level method:
e.g., it can carry a cryptographic key that deciphers the steganogram carried
by the upper-level one. It can also be used to provide the steganogram with
integrity. Another important benefit is that the lower-layer method may be used
as a signalling channel in which to exchange information that affects the way
that the upper-level method functions, thus possibly making the steganographic
communication harder to detect. The prototype of MLS for IP networks was also
developed, and the experimental results are included in this paper.
"
215,A Color Image Digital Watermarking Scheme Based on SOFM,"  Digital watermarking technique has been presented and widely researched to
solve some important issues in the digital world, such as copyright protection,
copy protection and content authentication. Several robust watermarking schemes
based on vector quantization (VQ) have been presented. In this paper, we
present a new digital image watermarking method based on SOFM vector quantizer
for color images. This method utilizes the codebook partition technique in
which the watermark bit is embedded into the selected VQ encoded block. The
main feature of this scheme is that the watermark exists both in VQ compressed
image and in the reconstructed image. The watermark extraction can be performed
without the original image. The watermark is hidden inside the compressed
image, so much transmission time and storage space can be saved when the
compressed data are transmitted over the Internet. Simulation results
demonstrate that the proposed method has robustness against various image
processing operations without sacrificing compression performance and the
computational speed.
"
216,2D Sparse Signal Recovery via 2D Orthogonal Matching Pursuit,"  Recovery algorithms play a key role in compressive sampling (CS). Most of
current CS recovery algorithms are originally designed for one-dimensional (1D)
signal, while many practical signals are two-dimensional (2D). By utilizing 2D
separable sampling, 2D signal recovery problem can be converted into 1D signal
recovery problem so that ordinary 1D recovery algorithms, e.g. orthogonal
matching pursuit (OMP), can be applied directly. However, even with 2D
separable sampling, the memory usage and complexity at the decoder is still
high. This paper develops a novel recovery algorithm called 2D-OMP, which is an
extension of 1D-OMP. In the 2D-OMP, each atom in the dictionary is a matrix. At
each iteration, the decoder projects the sample matrix onto 2D atoms to select
the best matched atom, and then renews the weights for all the already selected
atoms via the least squares. We show that 2D-OMP is in fact equivalent to
1D-OMP, but it reduces recovery complexity and memory usage significantly.
What's more important, by utilizing the same methodology used in this paper,
one can even obtain higher dimensional OMP (say 3D-OMP, etc.) with ease.
"
217,Using Planetlab to Implement Multicast at the Application Level,"  Application-layer multicast implements the multicast functionality at the
application layer. The main goal of application-layer multicast is to construct
and maintain efficient distribution structures between endhosts. In this paper
we focus on the implementation of an application-layer multicast network using
PlanetLab. We observe that the total time required to measure network latency
over TCP is influenced dramatically by the TCP connection time. We argue that
end-host distribution is not only influenced by the quality of network links
but also by the time required to make connections between nodes. We provide
several solutions to decrease the total end-host distribution time.
"
218,On Steganography in Lost Audio Packets,"  The paper presents a new hidden data insertion procedure based on estimated
probability of the remaining time of the call for steganographic method called
LACK (Lost Audio PaCKets steganography). LACK provides hidden communication for
real-time services like Voice over IP. The analytical results presented in this
paper concern the influence of LACK's hidden data insertion procedures on the
method's impact on quality of voice transmission and its resistance to
steganalysis. The proposed hidden data insertion procedure is also compared to
previous steganogram insertion approach based on estimated remaining average
call duration.
"
219,Peer-to-Peer Multimedia Sharing based on Social Norms,"  Empirical data shows that in the absence of incentives, a peer participating
in a Peer-to-Peer (P2P) network wishes to free-riding. Most solutions for
providing incentives in P2P networks are based on direct reciprocity, which are
not appropriate for most P2P multimedia sharing networks due to the unique
features exhibited by such networks: large populations of anonymous agents
interacting infrequently, asymmetric interests of peers, network errors, and
multiple concurrent transactions. In this paper, we design and rigorously
analyze a new family of incentive protocols that utilizes indirect reciprocity
which is based on the design of efficient social norms. In the proposed P2P
protocols, the social norms consist of a social strategy, which represents the
rule prescribing to the peers when they should or should not provide content to
other peers, and a reputation scheme, which rewards or punishes peers depending
on whether they comply or not with the social strategy. We first define the
concept of a sustainable social norm, under which no peer has an incentive to
deviate. We then formulate the problem of designing optimal social norms, which
selects the social norm that maximizes the network performance among all
sustainable social norms. Hence, we prove that it becomes in the self-interest
of peers to contribute their content to the network rather than to free-ride.
We also investigate the impact of various punishment schemes on the social
welfare as well as how should the optimal social norms be designed if
altruistic and malicious peers are active in the network. Our results show that
optimal social norms are capable of providing significant improvements in the
sharing efficiency of multimedia P2P networks.
"
220,"A Study on Digital Video Broadcasting to a Handheld Device (DVB-H),
  Operating in UHF Band","  In this paper, we will understand that the development of the Digital Video
Broadcasting to a Handheld (DVB-H) standard makes it possible to deliver live
broadcast television to a mobile handheld device. Building upon the strengths
of the Digital Video Broadcasting - Terrestrial (DVB-T) standard in use in
millions of homes, DVB-H recognizes the trend towards the personal consumption
of media.
"
221,Quasi-Optimal Network Utility Maximization for Scalable Video Streaming,"  This paper addresses rate control for transmission of scalable video streams
via Network Utility Maximization (NUM) formulation. Due to stringent QoS
requirements of video streams and specific characterization of utility
experienced by end-users, one has to solve nonconvex and even nonsmooth NUM
formulation for such streams, where dual methods often prove incompetent.
Convexification plays an important role in this work as it permits the use of
existing dual methods to solve an approximate to the NUM problem iteratively
and distributively. Hence, to tackle the nonsmoothness and nonconvexity, we aim
at reformulating the NUM problem through approximation and transformation of
the ideal discretely adaptive utility function for scalable video streams. The
reformulated problem is shown to be a D.C. (Difference of Convex) problem. We
leveraged Sequential Convex Programming (SCP) approach to replace the nonconvex
D.C. problem by a sequence of convex problems that aim to approximate the
original D.C. problem. We then solve each convex problem produced by SCP
approach using existing dual methods. This procedure is the essence of two
distributed iterative rate control algorithms proposed in this paper, for which
one can show the convergence to a locally optimal point of the nonconvex D.C.
problem and equivalently to a locally optimal point of an approximate to the
original nonconvex problem. Our experimental results show that the proposed
rate control algorithms converge with tractable convergence behavior.
"
222,On the Capacity of p2p Multipoint Video Conference,"  In this paper, The structure of video conference is formulated and the
peer-assisted distribution scheme is constructed to achieve optimal video
delivery rate in each sub-conference. The capacity of conference is proposed to
referee the video rate that can be supported in every possible scenario. We
have proved that, in case of one user watching only one video, 5/6 is a lower
bound of the capacity which is much larger than 1/2, the achievable rate of
chained approach in [2]. Almost all proofs in this paper are constructive. They
can be applied into real implementation directly with a few modifications.
"
223,"Transmitting important bits and sailing high radio waves: a
  decentralized cross-layer approach to cooperative video transmission","  We investigate the impact of cooperative relaying on uplink and downlink
multi-user (MU) wireless video transmissions. The objective is to maximize the
long-term sum of utilities across the video terminals in a decentralized
fashion, by jointly optimizing the packet scheduling, the resource allocation,
and the cooperation decisions, under the assumption that some nodes are willing
to act as cooperative relays. A pricing-based distributed resource allocation
framework is adopted, where the price reflects the expected future congestion
in the network. Specifically, we formulate the wireless video transmission
problem as an MU Markov decision process (MDP) that explicitly considers the
cooperation at the physical layer and the medium access control sublayer, the
video users' heterogeneous traffic characteristics, the dynamically varying
network conditions, and the coupling among the users' transmission strategies
across time due to the shared wireless resource. Although MDPs notoriously
suffer from the curse of dimensionality, our study shows that, with appropriate
simplications and approximations, the complexity of the MU-MDP can be
significantly mitigated. Our simulation results demonstrate that integrating
cooperative decisions into the MU-MDP optimization can increase the resource
price in networks that only support low transmission rates and can decrease the
price in networks that support high transmission rates. Additionally, our
results show that cooperation allows users with feeble direct signals to
achieve improvements in video quality on the order of 5-10 dB peak
signal-to-noise ratio (PSNR), with less than 0.8 dB quality loss by users with
strong direct signals, and with a moderate increase in total network energy
consumption that is significantly less than the energy that a distant node
would require to achieve an equivalent PSNR without exploiting cooperative
diversity.
"
224,Ontology based approach for video transmission over the network,"  With the increase in the bandwidth & the transmission speed over the
internet, transmission of multimedia objects like video, audio, images has
become an easier work. In this paper we provide an approach that can be useful
for transmission of video objects over the internet without much fuzz. The
approach provides a ontology based framework that is used to establish an
automatic deployment of video transmission system. Further the video is
compressed using the structural flow mechanism that uses the wavelet principle
for compression of video frames. Finally the video transmission algorithm known
as RRDBFSF algorithm is provided that makes use of the concept of restrictive
flooding to avoid redundancy thereby increasing the efficiency.
"
225,"Multimedia Database Applications: Issues and Concerns for Classroom
  Teaching","  The abundance of multimedia data and information is challenging educators to
effectively search, browse, access, use, and store the data for their classroom
teaching. However, many educators could still be accustomed to teaching or
searching for information using conventional methods, but often the
conventional methods may not function well with multimedia data. Educators need
to efficiently interact and manage a variety of digital media files too. The
purpose of this study is to review current multimedia database applications in
teaching and learning, and further discuss some of the issues or concerns that
educators may have while incorporating multimedia data into their classrooms.
Some strategies and recommendations are also provided in order for educators to
be able to use multimedia data more effectively in their teaching environments.
"
226,"Interdisciplinary Collaboration through Designing 3D Simulation Case
  Studies","  Interdisciplinary collaboration is essential for the advance of research. As
domain subjects become more and more specialized, researchers need to cross
disciplines for insights from peers in other areas to have a broader and deeper
understand of a topic at micro- and macro-levels. We developed a 3D virtual
learning environment that served as a platform for faculty to plan curriculum,
share educational beliefs, and conduct cross-discipline research for effective
learning. Based upon the scripts designed by faculty from five disciplines,
virtual doctors, nurses, or patients interact in a 3D virtual hospital. The
teaching vignettes were then converted to video clips, allowing users to view,
pause, replay, or comment on the videos individually or in groups. Unlike many
existing platforms, we anticipated a value-added by adding a social networking
capacity to this virtual environment. The focus of this paper is on the
cost-efficiency and system design of the virtual learning environment.
"
227,"An Algorithm for Repairing Low-Quality Video Enhancement Techniques
  Based on Trained Filter","  Multifarious image enhancement algorithms have been used in different
applications. Still, some algorithms or modules are imperfect for practical
use. When the image enhancement modules have been fixed or combined by a series
of algorithms, we need to repair them as a whole part without changing the
inside. This report aims to find an algorithm based on trained filters to
repair low-quality image enhancement modules. A brief review on basic image
enhancement techniques and pixel classification methods will be presented, and
the procedure of trained filters will be described step by step. The
experiments and result comparisons for this algorithm will be described in
detail.
"
228,Hiding Secret Information in Movie Clip: A Steganographic Approach,"  Establishing hidden communication is an important subject of discussion that
has gained increasing importance nowadays with the development of the internet.
One of the key methods for establishing hidden communication is steganography.
Modern day steganography mainly deals with hiding information within files like
image, text, html, binary files etc. These file contains small irrelevant
information that can be substituted for small secret data. To store a high
capacity secret data these carrier files are not very supportive. To overcome
the problem of storing the high capacity secret data with the utmost security
fence, we have proposed a novel methodology for concealing a voluminous data
with high levels of security wall by using movie clip as a carrier file.
"
229,Priority based Interface Selection for Overlaying Heterogeneous Networks,"  Offering of different attractive opportunities by different wireless
technologies trends the convergence of heterogeneous networks for the future
wireless communication system. To make a seamless handover among the
heterogeneous networks, the optimization of the power consumption, and optimal
selection of interface are the challenging issues for convergence networks. The
access of multi interfaces simultaneously reduces the handover latency and data
loss in heterogeneous handover. The mobile node (MN) maintains one interface
connection while other interface is used for handover process. However, it
causes much battery power consumption. In this paper we propose an efficient
interface selection scheme including interface selection algorithms, interface
selection procedures considering battery power consumption and user mobility
with other existing parameters for overlaying networks. We also propose a
priority based network selection scheme according to the service types. MN's
battery power level, provision of QoS/QoE in the target network and our
proposed priority parameters are considered as more important parameters for
our interface selection algorithm. The performances of the proposed scheme are
verified using numerical analysis.
"
230,Sparse Transfer Learning for Interactive Video Search Reranking,"  Visual reranking is effective to improve the performance of the text-based
video search. However, existing reranking algorithms can only achieve limited
improvement because of the well-known semantic gap between low level visual
features and high level semantic concepts. In this paper, we adopt interactive
video search reranking to bridge the semantic gap by introducing user's
labeling effort. We propose a novel dimension reduction tool, termed sparse
transfer learning (STL), to effectively and efficiently encode user's labeling
information. STL is particularly designed for interactive video search
reranking. Technically, it a) considers the pair-wise discriminative
information to maximally separate labeled query relevant samples from labeled
query irrelevant ones, b) achieves a sparse representation for the subspace to
encodes user's intention by applying the elastic net penalty, and c) propagates
user's labeling information from labeled samples to unlabeled samples by using
the data distribution knowledge. We conducted extensive experiments on the
TRECVID 2005, 2006 and 2007 benchmark datasets and compared STL with popular
dimension reduction algorithms. We report superior performance by using the
proposed STL based interactive video search reranking.
"
231,Stage Staffing Scheme for Copyright Protection in Multimedia,"  Copyright protection has become a need in today's world. To achieve a secure
copyright protection we embedded some information in images and videos and that
image or video is called copyright protected. The embedded information can't be
detected by human eye but some attacks and operations can tamper that
information to breach protection. So in order to find a secure technique of
copyright protection, we have analyzed image processing techniques i.e. Spatial
Domain (Least Significant Bit (LSB)), Transform Domain (Discrete Cosine
Transform (DCT)), Discrete Wavelet Transform (DWT) and there are numerous
algorithm for watermarking using them. After having a good understanding of the
same we have proposed a novel algorithm named as Stage Staffing Algorithm that
generates results with high effectiveness, additionally we can use self
extracted-watermark technique to increase the security and automate the process
of watermark image. The proposed algorithm provides protection in three stages.
We have implemented the algorithm and results of the simulations are shown. The
various factors affecting spatial domain watermarking are also discussed.
"
232,Rendering of 3D Dynamic Virtual Environments,"  In this paper we present a framework for the rendering of dynamic 3D virtual
environments which can be integrated in the development of videogames. It
includes methods to manage sounds and particle effects, paged static
geometries, the support of a physics engine and various input systems. It has
been designed with a modular structure to allow future expansions. We exploited
some open-source state-of-the-art components such as OGRE, PhysX,
ParticleUniverse, etc.; all of them have been properly integrated to obtain
peculiar physical and environmental effects. The stand-alone version of the
application is fully compatible with Direct3D and OpenGL APIs and adopts OpenAL
APIs to manage audio cards. Concluding, we devised a showcase demo which
reproduces a dynamic 3D environment, including some particular effects: the
alternation of day and night infuencing the lighting of the scene, the
rendering of terrain, water and vegetation, the reproduction of sounds and
atmospheric agents.
"
233,Distributed Video Coding: Codec Architecture and Implementation,"  Distributed Video Coding (DVC) is a new coding paradigm for video
compression, based on Slepian- Wolf (lossless coding) and Wyner-Ziv (lossy
coding) information theoretic results. DVC is useful for emerging applications
such as wireless video cameras, wireless low-power surveillance networks and
disposable video cameras for medical applications etc. The primary objective of
DVC is low-complexity video encoding, where bulk of computation is shifted to
the decoder, as opposed to low-complexity decoder in conventional video
compression standards such as H.264 and MPEG etc. There are couple of early
architectures and implementations of DVC from Stanford University[2][3] in
2002, Berkeley University PRISM (Power-efficient, Robust, hIgh-compression,
Syndrome-based Multimedia coding)[4][5] in 2002 and European project DISCOVER
(DIStributed COding for Video SERvices)[6] in 2007. Primarily there are two
types of DVC techniques namely pixel domain and transform domain based.
Transform domain design will have better rate-distortion (RD) performance as it
exploits spatial correlation between neighbouring samples and compacts the
block energy into as few transform coefficients as possible (aka energy
compaction). In this paper, architecture, implementation details and ""C"" model
results of our transform domain DVC are presented.
"
234,"SLDs for Visualizing Multicolor Elevation Contour Lines in Geo-Spatial
  Web Applications","  This paper addresses the need for geospatial consumers (either humans or
machines) to visualize multicolored elevation contour poly lines with respect
their different contour intervals and control the visual portrayal of the data
with which they work. The current OpenGIS Web Map Service (WMS) specification
supports the ability for an information provider to specify very basic styling
options by advertising a preset collection of visual portrayals for each
available data set. However, while a WMS currently can provide the user with a
choice of style options, the WMS can only tell the user the name of each style.
It cannot tell the user what portrayal will look like on the map. More
importantly, the user has no way of defining their own styling rules. The
ability for a human or machine client to define these rules requires a styling
language that the client and server can both understand. Defining this
language, called the StyledLayerDescriptor (SLD), is the main focus of this
paper, and it can be used to portray the output of Web Map Servers, Web Feature
Servers and Web Coverage Servers.
"
235,Liquidsoap: a High-Level Programming Language for Multimedia Streaming,"  Generating multimedia streams, such as in a netradio, is a task which is
complex and difficult to adapt to every users' needs. We introduce a novel
approach in order to achieve it, based on a dedicated high-level functional
programming language, called Liquidsoap, for generating, manipulating and
broadcasting multimedia streams. Unlike traditional approaches, which are based
on configuration files or static graphical interfaces, it also allows the user
to build complex and highly customized systems. This language is based on a
model for streams and contains operators and constructions, which make it
adapted to the generation of streams. The interpreter of the language also
ensures many properties concerning the good execution of the stream generation.
"
236,Duplication of Key Frames of Video Streams in Wireless Networks,"  In this paper technological solutions for improving the quality of video
transfer along wireless networks are investigated. Tools have been developed to
allow packets to be duplicated with key frames data. In the paper we tested
video streams with duplication of all frames, with duplication of key frames,
and without duplication. The experiments showed that the best results are
obtained by duplication of packages which contain key frames. The paper also
provides an overview of the coefficients describing the dependence of video
quality on packet loss and delay variation (network jitter).
"
237,Content-Based Spam Filtering on Video Sharing Social Networks,"  In this work we are concerned with the detection of spam in video sharing
social networks. Specifically, we investigate how much visual content-based
analysis can aid in detecting spam in videos. This is a very challenging task,
because of the high-level semantic concepts involved; of the assorted nature of
social networks, preventing the use of constrained a priori information; and,
what is paramount, of the context dependent nature of spam. Content filtering
for social networks is an increasingly demanded task: due to their popularity,
the number of abuses also tends to increase, annoying the user base and
disrupting their services. We systematically evaluate several approaches for
processing the visual information: using static and dynamic (motionaware)
features, with and without considering the context, and with or without latent
semantic analysis (LSA). Our experiments show that LSA is helpful, but taking
the context into consideration is paramount. The whole scheme shows good
results, showing the feasibility of the concept.
"
238,Optimized Spline Interpolation,"  In this paper, we investigate the problem of designing compact support
interpolation kernels for a given class of signals. By using calculus of
variations, we simplify the optimization problem from an infinite nonlinear
problem to a finite dimensional linear case, and then find the optimum compact
support function that best approximates a given filter in the least square
sense (l2 norm). The benefit of compact support interpolants is the low
computational complexity in the interpolation process while the optimum compact
support interpolant gaurantees the highest achivable Signal to Noise Ratio
(SNR). Our simulation results confirm the superior performance of the proposed
splines compared to other conventional compact support interpolants such as
cubic spline.
"
239,Survey of Cognitive Radio Techniques in Wireless Network,"  In this report, I surveyed the cognitive radio technique in wireless
networks. Researched several kinds of cognitive techniques about their
advantages and disadvantages.
"
240,Robust Sign Language Recognition System Using ToF Depth Cameras,"  Sign language recognition is a difficult task, yet required for many
applications in real-time speed. Using RGB cameras for recognition of sign
languages is not very successful in practical situations and accurate 3D
imaging requires expensive and complex instruments. With introduction of
Time-of-Flight (ToF) depth cameras in recent years, it has become easier to
scan the environment for accurate, yet fast depth images of the objects without
the need of any extra calibrating object. In this paper, a robust system for
sign language recognition using ToF depth cameras is presented for converting
the recorded signs to a standard and portable XML sign language named SiGML for
easy transferring and converting to real-time 3D virtual characters animations.
Feature extraction using moments and classification using nearest neighbor
classifier are used to track hand gestures and significant result of 100% is
achieved for the proposed approach.
"
241,"Using Logistic Regression to Analyze the Balance of a Game: The Case of
  StarCraft II","  Recently, the market size of online game has been increasing astonishingly
fast, and so does the importance of good game design. In online games, usually
a human user competes with others, so the fairness of the game system to all
users is of great importance not to lose interests of users on the game.
Furthermore, the emergence and success of electronic sports (e-sports) and
professional gaming which specially talented gamers compete with others draws
more attention on whether they are competing in the fair environment. No matter
how fierce the debates are in the game-design community, it is rarely the case
that one employs statistical analysis to answer this question seriously. But
considering the fact that we can easily gather large amount of user behavior
data on games, it seems potentially beneficial to make use of this data to aid
making decisions on design problems of games. Actually, modern games do not aim
to perfectly design the game at once: rather, they first release the game, and
then monitor users' behavior to better balance the game. In such a scenario,
statistical analysis can be particularly helpful. Specifically, we chose to
analyze the balance of StarCraft II, which is a very successful
recently-released real-time strategy (RTS) game. It is a central icon in
current e-Sports and professional gaming community: from April 1st to 15th,
there were 18 tournaments of StarCraft II. However, there is endless debate on
whether the winner of the tournament is actually superior to others, or it is
largely due to certain design flaws of the game. In this paper, we aim to
answer such a question using traditional statistical tool, logistic regression.
"
242,Streaming Multimedia Information Using the Features of the DVB-S Card,"  This paper presents a study of audio-video streaming using the additional
possibilities of a DVB-S card. The board used for experiments (Technisat
SkyStar 2) is one of the most frequently used cards for this purpose. Using the
main blocks of the board's software support it is possible the implement a
really useful and full functional system for audio-video streaming. The
streaming is possible to be implemented either for decoded MPEG stream or for
transport stream. In this last case it is possible to view not only a program,
but any program from the same multiplex. This allows us to implement
"
243,Efficient Image Transmission Through Analog Error Correction,"  This paper presents a new paradigm for image transmission through analog
error correction codes. Conventional schemes rely on digitizing images through
quantization (which inevitably causes significant bandwidth expansion) and
transmitting binary bit-streams through digital error correction codes (which
do not automatically differentiate the different levels of significance among
the bits). To strike a better overall performance in terms of transmission
efficiency and quality, we propose to use a single analog error correction code
in lieu of digital quantization, digital code and digital modulation. The key
is to get analog coding right. We show that this can be achieved by cleverly
exploiting an elegant ""butterfly"" property of chaotic systems. Specifically, we
demonstrate a tail-biting triple-branch baker's map code and its
maximum-likelihood decoding algorithm. Simulations show that the proposed
analog code can actually outperform digital turbo code, one of the best codes
known to date. The results and findings discussed in this paper speak volume
for the promising potential of analog codes, in spite of their rather short
history.
"
244,"Analytical Classification of Multimedia Index Structures by Using a
  Partitioning Method-Based Framework","  Due to the advances in hardware technology and increase in production of
multimedia data in many applications, during the last decades, multimedia
databases have become increasingly important. Contentbased multimedia retrieval
is one of an important research area in the field of multimedia databases. Lots
of research on this field has led to proposition of different kinds of index
structures to support fast and efficient similarity search to retrieve
multimedia data from these databases. Due to variety and plenty of proposed
index structures, we suggest a systematic framework based on partitioning
method used in these structures to classify multimedia index structures, and
then we evaluated these structures based on important functional measures. We
hope this proposed framework will lead to empirical and technical comparison of
multimedia index structures and development of more efficient structures at
future.
"
245,Learning content similarity for music recommendation,"  Many tasks in music information retrieval, such as recommendation, and
playlist generation for online radio, fall naturally into the query-by-example
setting, wherein a user queries the system by providing a song, and the system
responds with a list of relevant or similar song recommendations. Such
applications ultimately depend on the notion of similarity between items to
produce high-quality results. Current state-of-the-art systems employ
collaborative filter methods to represent musical items, effectively comparing
items in terms of their constituent users. While collaborative filter
techniques perform well when historical data is available for each item, their
reliance on historical data impedes performance on novel or unpopular items. To
combat this problem, practitioners rely on content-based similarity, which
naturally extends to novel items, but is typically out-performed by
collaborative filter methods.
  In this article, we propose a method for optimizing contentbased similarity
by learning from a sample of collaborative filter data. The optimized
content-based similarity metric can then be applied to answer queries on novel
and unpopular items, while still maintaining high recommendation accuracy. The
proposed system yields accurate and efficient representations of audio content,
and experimental results show significant improvements in accuracy over
competing content-based recommendation techniques.
"
246,"Improving Performance of Speaker Identification System Using
  Complementary Information Fusion","  Feature extraction plays an important role as a front-end processing block in
speaker identification (SI) process. Most of the SI systems utilize like
Mel-Frequency Cepstral Coefficients (MFCC), Perceptual Linear Prediction (PLP),
Linear Predictive Cepstral Coefficients (LPCC), as a feature for representing
speech signal. Their derivations are based on short term processing of speech
signal and they try to capture the vocal tract information ignoring the
contribution from the vocal cord. Vocal cord cues are equally important in SI
context, as the information like pitch frequency, phase in the residual signal,
etc could convey important speaker specific attributes and are complementary to
the information contained in spectral feature sets. In this paper we propose a
novel feature set extracted from the residual signal of LP modeling.
Higher-order statistical moments are used here to find the nonlinear
relationship in residual signal. To get the advantages of complementarity vocal
cord based decision score is fused with the vocal tract based score. The
experimental results on two public databases show that fused mode system
outperforms single spectral features.
"
247,View subspaces for indexing and retrieval of 3D models,"  View-based indexing schemes for 3D object retrieval are gaining popularity
since they provide good retrieval results. These schemes are coherent with the
theory that humans recognize objects based on their 2D appearances. The
viewbased techniques also allow users to search with various queries such as
binary images, range images and even 2D sketches. The previous view-based
techniques use classical 2D shape descriptors such as Fourier invariants,
Zernike moments, Scale Invariant Feature Transform-based local features and 2D
Digital Fourier Transform coefficients. These methods describe each object
independent of others. In this work, we explore data driven subspace models,
such as Principal Component Analysis, Independent Component Analysis and
Nonnegative Matrix Factorization to describe the shape information of the
views. We treat the depth images obtained from various points of the view
sphere as 2D intensity images and train a subspace to extract the inherent
structure of the views within a database. We also show the benefit of
categorizing shapes according to their eigenvalue spread. Both the shape
categorization and data-driven feature set conjectures are tested on the PSB
database and compared with the competitor view-based 3D shape retrieval
algorithms
"
248,Salient Local 3D Features for 3D Shape Retrieval,"  In this paper we describe a new formulation for the 3D salient local features
based on the voxel grid inspired by the Scale Invariant Feature Transform
(SIFT). We use it to identify the salient keypoints (invariant points) on a 3D
voxelized model and calculate invariant 3D local feature descriptors at these
keypoints. We then use the bag of words approach on the 3D local features to
represent the 3D models for shape retrieval. The advantages of the method are
that it can be applied to rigid as well as to articulated and deformable 3D
models. Finally, this approach is applied for 3D Shape Retrieval on the McGill
articulated shape benchmark and then the retrieval results are presented and
compared to other methods.
"
249,"Fast restoration of natural images corrupted by high-density impulse
  noise","  In this paper, we suggest a general model for the fixed-valued impulse noise
and propose a two-stage method for high density noise suppression while
preserving the image details. In the first stage, we apply an iterative impulse
detector, exploiting the image entropy, to identify the corrupted pixels and
then employ an Adaptive Iterative Mean filter to restore them. The filter is
adaptive in terms of the number of iterations, which is different for each
noisy pixel, according to the Euclidean distance from the nearest uncorrupted
pixel. Experimental results show that the proposed filter is fast and
outperforms the best existing techniques in both objective and subjective
performance measures.
"
250,"Service Level Agreement for the QoS Guaranteed Mobile IPTV Services over
  Mobile WiMAX Networks","  While mobile IPTV services are supported through the mobile WiMAX networks,
there must need some guaranteed bandwidth for the IPTV services especially if
IPTV and non-IPTV services are simultaneously supported by the mobile WiMAX
networks. The quality of an IPTV service definitely depends on the allocated
bandwidth for that channel. However, due to the high quality IPTV services and
to support of huge non-IPTV traffic over mobile WiMAX networks, it is not
possible to guarantee the sufficient amount of the limited mobile WiMAX
bandwidth for the mobile IPTV services every time. A Service Level Agreement
(SLA) between the mobile IPTV service provider and mobile WiMAX network
operator to reserve sufficient bandwidth for the IPTV calls can increase the
satisfaction level of the mobile IPTV users. In this paper, we propose a SLA
negotiation procedure for mobile IPTV users over mobile WiMAX networks. The
Bandwidth Broker controls the allocated bandwidth for IPTV and non-IPTV users.
The proposed dynamically reserved bandwidth for the IPTV services increases the
IPTV user's satisfaction level. The simulation results state that, our proposed
scheme is able to provide better user satisfaction level for the IPTV users.
"
251,"A Frequency-domain Compensation Scheme for IQ-Imbalance in OFDM
  Receivers","  A pilot pattern across two OFDM symbols with special structure is devised for
channel estimation in OFDM systems with IQ imbalance at receiver. Based on this
pilot pattern, a high-efficiency time-domain (TD) least square (LS) channel
estimator is proposed to significantly suppress channel noise by a factor
N/(L+1) in comparison with the frequency-domain LS one in [1] where N and L+1
are the total number of subcarriers and the length of cyclic prefix,
respectively. Following this, a low-complexity frequency-domain (FD) Gaussian
elimination (GE) equalizer is proposed to eliminate IQ distortion by using only
2N complex multiplications per OFDM symbol. From simulation, the proposed
scheme TD-LS/FD-GE using only two pilot OFDM symbols achieves the same bit
error rate (BER) performance under ideal channel knowledge and no IQ imbalances
at low and medium signal-to-noise ratio (SNR) regions whereas these
compensation schemes including FD-LS/Post-FFT LS, FD-LS/Pre-FFT Corr, and
SPP/Pre-FFT Corr in [1] require about twenty OFDM training symbols to reach the
same performance where A/B denotes compensation scheme with A being channel
estimator and B being equalizer.
"
252,High Quality of Service on Video Streaming in P2P Networks using FST-MDC,"  Video streaming applications have newly attracted a large number of
participants in a distribution network. Traditional client-server based video
streaming solutions sustain precious bandwidth provision rate on the server.
Recently, several P2P streaming systems have been organized to provide
on-demand and live video streaming services on the wireless network at reduced
server cost. Peer-to-Peer (P2P) computing is a new pattern to construct
disseminated network applications. Typical error control techniques are not
very well matched and on the other hand error prone channels has increased
greatly for video transmission e.g., over wireless networks and IP. These two
facts united together provided the essential motivation for the development of
a new set of techniques (error concealment) capable of dealing with
transmission errors in video systems. In this paper, we propose an flexible
multiple description coding method named as Flexible Spatial-Temporal (FST)
which improves error resilience in the sense of frame loss possibilities over
independent paths. It introduces combination of both spatial and temporal
concealment technique at the receiver and to conceal the lost frames more
effectively. Experimental results show that, proposed approach attains
reasonable quality of video performance over P2P wireless network.
"
253,"Scale-Invariant Local Descriptor for Event Recognition in 1D Sensor
  Signals","  In this paper, we introduce a shape-based, time-scale invariant feature
descriptor for 1-D sensor signals. The time-scale invariance of the feature
allows us to use feature from one training event to describe events of the same
semantic class which may take place over varying time scales such as walking
slow and walking fast. Therefore it requires less training set. The descriptor
takes advantage of the invariant location detection in the scale space theory
and employs a high level shape encoding scheme to capture invariant local
features of events. Based on this descriptor, a scale-invariant classifier with
""R"" metric (SIC-R) is designed to recognize multi-scale events of human
activities. The R metric combines the number of matches of keypoint in scale
space with the Dynamic Time Warping score. SICR is tested on various types of
1-D sensors data from passive infrared, accelerometer and seismic sensors with
more than 90% classification accuracy.
"
254,"Simulating the Electroweak Phase Transition: Sonification of Bubble
  Nucleation","  As an applicaton of sonification, a simulation of the early universe was
developed to portray a phase transition that occurred shortly after the Big
Bang. The Standard Model of particle physics postulates that a hypothetical
particle, the Higgs boson, is responsible for the breaking of the symmetry
between the electromagnetic force and the weak force. This phase transition may
have been responsible for triggering Baryogenesis, the generation of an
abundance of matter over anti-matter. This hypothesis is known as Electroweak
Baryogenesis. In this simulation, aspects of bubble nucleation in Standard
Model Electroweak Baryogenesis were examined and modeled using Mathematica, and
sonified using SuperCollider3. The resulting simulation, which has been used
for pedagogical purposes by one of the authors, suggests interesting
possibilities for the integration of science and aesthetics as well as auditory
perception. The sonification component in particular also had the unexpected
benefit of being useful in debugging the Mathematica code.
"
255,"Bits from Photons: Oversampled Image Acquisition Using Binary Poisson
  Statistics","  We study a new image sensor that is reminiscent of traditional photographic
film. Each pixel in the sensor has a binary response, giving only a one-bit
quantized measurement of the local light intensity. To analyze its performance,
we formulate the oversampled binary sensing scheme as a parameter estimation
problem based on quantized Poisson statistics. We show that, with a
single-photon quantization threshold and large oversampling factors, the
Cram\'er-Rao lower bound (CRLB) of the estimation variance approaches that of
an ideal unquantized sensor, that is, as if there were no quantization in the
sensor measurements. Furthermore, the CRLB is shown to be asymptotically
achievable by the maximum likelihood estimator (MLE). By showing that the
log-likelihood function of our problem is concave, we guarantee the global
optimality of iterative algorithms in finding the MLE. Numerical results on
both synthetic data and images taken by a prototype sensor verify our
theoretical analysis and demonstrate the effectiveness of our image
reconstruction algorithm. They also suggest the potential application of the
oversampled binary sensing scheme in high dynamic range photography.
"
256,Nested Graph Words for Object Recognition,"  In this paper, we propose a new, scalable approach for the task of object
based image search or object recognition. Despite the very large literature
existing on the scalability issues in CBIR in the sense of retrieval
approaches, the scalability of media and scalability of features remain an
issue. In our work we tackle the problem of scalability and structural
organization of features. The proposed features are nested local graphs built
upon sets of SURF feature points with Delaunay triangulation. A
Bag-of-Visual-Words (BoVW) framework is applied on these graphs, giving birth
to a Bag-of-Graph-Words representation. The nested nature of the descriptors
consists in scaling from trivial Delaunay graphs - isolated feature points - by
increasing the number of nodes layer by layer up to graphs with maximal number
of nodes. For each layer of graphs its proper visual dictionary is built. The
experiments conducted on the SIVAL data set reveal that the graph features at
different layers exhibit complementary performances on the same content. The
nested approach, the combination of all existing layers, yields significant
improvement of the object recognition performance compared to single level
approaches.
"
257,"Activities of Daily Living Indexing by Hierarchical HMM for Dementia
  Diagnostics","  This paper presents a method for indexing human ac- tivities in videos
captured from a wearable camera being worn by patients, for studies of
progression of the dementia diseases. Our method aims to produce indexes to
facilitate the navigation throughout the individual video recordings, which
could help doctors search for early signs of the dis- ease in the activities of
daily living. The recorded videos have strong motion and sharp lighting
changes, inducing noise for the analysis. The proposed approach is based on a
two steps analysis. First, we propose a new approach to segment this type of
video, based on apparent motion. Each segment is characterized by two original
motion de- scriptors, as well as color, and audio descriptors. Second, a
Hidden-Markov Model formulation is used to merge the multimodal audio and video
features, and classify the test segments. Experiments show the good properties
of the ap- proach on real data.
"
258,SIP APIs for Voice and Video Communications on the Web,"  Existing standard protocols for the web and Internet telephony fail to
deliver real-time interactive communication from within a web browser. In
particular, the client-server web protocol over reliable TCP is not always
suitable for end-to-end low latency media path needed for interactive voice and
video communication. To solve this, we compare the available platform options
using the existing technologies such as modifying the web programming language
and protocol, using an existing web browser plugin, and a separate host
resident application that the web browser can talk to. We argue that using a
separate application as an adaptor is a promising short term as well as
long-term strategy for voice and video communications on the web. Our project
aims at developing the open technology and sample implementations for web-based
real-time voice and video communication applications. We describe the
architecture of our project including (1) a RESTful web communication API over
HTTP inspired by SIP message flows, (2) a web-friendly set of metadata for
session description, and (3) an UDP-based end-to-end media path. All other
telephony functions reside in the web application itself and/or in web feature
servers. The adaptor approach allows us to easily add new voice and video
codecs and NAT traversal technologies such as Host Identity Protocol. We want
to make web-based communication accessible to millions of web developers,
maximize the end user experience and security, and preserve the huge global
investment in and experience from SIP systems while adhering to web standards
and development tools as much as possible. We have created an open source
prototype that allows you to freely use the conference application by directing
a browser to the conference URL.
"
259,Flash-based Audio and Video Communication in the Cloud,"  Internet telephony and multimedia communication protocols have matured over
the last fifteen years. Recently, the web is evolving as a popular platform for
everything we do on the Internet including email, text chat, voice calls,
discussions, enterprise apps and multi-party collaboration. Unfortunately,
there is a disconnect between web and traditional Internet telephony protocols
as they have ignored the constraints and requirements of each other.
Consequently, the Flash Player is being used as a web browser plugin by many
developers for web-based voice and video calls. We describe the challenges of
video communication using a web browser, present a simple API using a Flash
Player application, show how it supports wide range of web communication
scenarios in the cloud, and describe how it can interoperate with Session
Initiation Protocol (SIP)-based systems. We describe both the advantages and
challenges of Flash Player based communication applications. The presented API
could guide future work on communication-related web protocol extensions.
"
260,A Framework for Designing 3D Virtual Environments,"  The process of design and development of virtual environments can be
supported by tools and frameworks, to save time in technical aspects and
focusing on the content. In this paper we present an academic framework which
provides several levels of abstraction to ease this work. It includes
state-of-the-art components we devised or integrated adopting open-source
solutions in order to face specific problems. Its architecture is modular and
customizable, the code is open-source.
"
261,Celerity: A Low-Delay Multi-Party Conferencing Solution,"  In this paper, we attempt to revisit the problem of multi-party conferencing
from a practical perspective, and to rethink the design space involved in this
problem. We believe that an emphasis on low end-to-end delays between any two
parties in the conference is a must, and the source sending rate in a session
should adapt to bandwidth availability and congestion. We present Celerity, a
multi-party conferencing solution specifically designed to achieve our
objectives. It is entirely Peer-to-Peer (P2P), and as such eliminating the cost
of maintaining centrally administered servers. It is designed to deliver video
with low end-to-end delays, at quality levels commensurate with available
network resources over arbitrary network topologies where bottlenecks can be
anywhere in the network. This is in contrast to commonly assumed P2P scenarios
where bandwidth bottlenecks reside only at the edge of the network. The
highlight in our design is a distributed and adaptive rate control protocol,
that can discover and adapt to arbitrary topologies and network conditions
quickly, converging to efficient link rate allocations allowed by the
underlying network. In accordance with adaptive link rate control, source video
encoding rates are also dynamically controlled to optimize video quality in
arbitrary and unpredictable network conditions. We have implemented Celerity in
a prototype system, and demonstrate its superior performance over existing
solutions in a local experimental testbed and over the Internet.
"
262,"Study of a Hybrid - Analog TV and Ethernet- Home Data Link using a
  Coaxial Cable","  The paper presents an implementation and compatibility tests of a simple home
network implemented in a nonconventional manner using a CATV coaxial cable.
Reusing the cable, normally designated to supply RF modulated TV signals from
cable TV networks, makes possible to add data services as well. A short
presentation of the technology is given with an investigation of the main
performances obtained using this technique. The measurements revealed that this
simple solution makes possible to have both TV and data services with
performances close to traditional home data services: cable modems or ADSL,
with minimal investments. This technology keeps also open the possibility for
future improvements of the network: DVB-C or Data via Cable Modems.
"
263,Aspects of Entertainment Distribution in an Intelligent Home Environment,"  The paper presents an implementation and tests of a simple home entertainment
distribution architecture (server + multiple clients) implemented using two
conventional cabling architectures: CATV coaxial cable and conventional
Ethernet. This architecture is created taking into account the ""Home gateway""
concept present in most attempts to solve the problem of the ""Intelligent
home"". A short presentation of the experimental is given with an investigation
of the main performances obtained using this architecture. The experiments
revealed that this simple solution makes possible to have entertainment and
data services with performances close to traditional data services in a
cost-effective architecture
"
264,"Label-Specific Training Set Construction from Web Resource for Image
  Annotation","  Recently many research efforts have been devoted to image annotation by
leveraging on the associated tags/keywords of web images as training labels. A
key issue to resolve is the relatively low accuracy of the tags. In this paper,
we propose a novel semi-automatic framework to construct a more accurate and
effective training set from these web media resources for each label that we
want to learn. Experiments conducted on a real-world dataset demonstrate that
the constructed training set can result in higher accuracy for image
annotation.
"
265,Lost Audio Packets Steganography: The First Practical Evaluation,"  This paper presents first experimental results for an IP telephony-based
steganographic method called LACK (Lost Audio PaCKets steganography). This
method utilizes the fact that in typical multimedia communication protocols
like RTP (Real-Time Transport Protocol), excessively delayed packets are not
used for the reconstruction of transmitted data at the receiver, i.e. these
packets are considered useless and discarded. The results presented in this
paper were obtained basing on a functional LACK prototype and show the method's
impact on the quality of voice transmission. Achievable steganographic
bandwidth for the different IP telephony codecs is also calculated.
"
266,MediaWiki Grammar Recovery,"  The paper describes in detail the recovery effort of one of the official
MediaWiki grammars. Over two hundred grammar transformation steps are reported
and annotated, leading to delivery of a level 2 grammar, semi-automatically
extracted from a community created semi-formal text using at least five
different syntactic notations, several non-enforced naming conventions,
multiple misspellings, obsolete parsing technology idiosyncrasies and other
problems commonly encountered in grammars that were not engineered properly.
Having a quality grammar will allow to test and validate it further, without
alienating the community with a separately developed grammar.
"
267,Mobile Cloud Computing: A Comparison of Application Models,"  Cloud computing is an emerging concept combining many fields of computing.
The foundation of cloud computing is the delivery of services, software and
processing capacity over the Internet, reducing cost, increasing storage,
automating systems, decoupling of service delivery from underlying technology,
and providing flexibility and mobility of information. However, the actual
realization of these benefits is far from being achieved for mobile
applications and open many new research questions. In order to better
understand how to facilitate the building of mobile cloud-based applications,
we have surveyed existing work in mobile computing through the prism of cloud
computing principles. We give a definition of mobile cloud coputing and provide
an overview of the results from this review, in particular, models of mobile
cloud applications. We also highlight research challenges in the area of mobile
cloud computing. We conclude with recommendations for how this better
understanding of mobile cloud computing can help building more powerful mobile
applications.
"
268,An end-to-end machine learning system for harmonic analysis of music,"  We present a new system for simultaneous estimation of keys, chords, and bass
notes from music audio. It makes use of a novel chromagram representation of
audio that takes perception of loudness into account. Furthermore, it is fully
based on machine learning (instead of expert knowledge), such that it is
potentially applicable to a wider range of genres as long as training data is
available. As compared to other models, the proposed system is fast and memory
efficient, while achieving state-of-the-art performance.
"
269,"Analysis of Buffer Starvation with Application to Objective QoE
  Optimization of Streaming Services","  Our purpose in this paper is to characterize buffer starvations for streaming
services. The buffer is modeled as an M/M/1 queue, plus the consideration of
bursty arrivals. When the buffer is empty, the service restarts after a certain
amount of packets are \emph{prefetched}. With this goal, we propose two
approaches to obtain the \emph{exact distribution} of the number of buffer
starvations, one of which is based on \emph{Ballot theorem}, and the other uses
recursive equations. The Ballot theorem approach gives an explicit result. We
extend this approach to the scenario with a constant playback rate using
T\`{a}kacs Ballot theorem. The recursive approach, though not offering an
explicit result, can obtain the distribution of starvations with
non-independent and identically distributed (i.i.d.) arrival process in which
an ON/OFF bursty arrival process is considered in this work. We further compute
the starvation probability as a function of the amount of prefetched packets
for a large number of files via a fluid analysis. Among many potential
applications of starvation analysis, we show how to apply it to optimize the
objective quality of experience (QoE) of media streaming, by exploiting the
tradeoff between startup/rebuffering delay and starvations.
"
270,An Efficient Real Time Method of Fingertip Detection,"  Fingertips detection has been used in many applications, and it is very
popular and commonly used in the area of Human Computer Interaction these days.
This paper presents a novel time efficient method that will lead to fingertip
detection after cropping the irrelevant parts of input image. Binary silhouette
of the input image is generated using HSV color space based skin filter and
hand cropping done based on histogram of the hand image. The cropped image will
be used to figure out the fingertips.
"
271,"Characterization and exploitation of community structure in cover song
  networks","  The use of community detection algorithms is explored within the framework of
cover song identification, i.e. the automatic detection of different audio
renditions of the same underlying musical piece. Until now, this task has been
posed as a typical query-by-example task, where one submits a query song and
the system retrieves a list of possible matches ranked by their similarity to
the query. In this work, we propose a new approach which uses song communities
to provide more relevant answers to a given query. Starting from the output of
a state-of-the-art system, songs are embedded in a complex weighted network
whose links represent similarity (related musical content). Communities inside
the network are then recognized as groups of covers and this information is
used to enhance the results of the system. In particular, we show that this
approach increases both the coherence and the accuracy of the system.
Furthermore, we provide insight into the internal organization of individual
cover song communities, showing that there is a tendency for the original song
to be central within the community. We postulate that the methods and results
presented here could be relevant to other query-by-example tasks.
"
272,"Compression and Quantitative Analysis of Buffer Map Message in P2P
  Streaming System","  BM compression is a straightforward and operable way to reduce buffer message
length as well as to improve system performance. In this paper, we thoroughly
discuss the principles and protocol progress of different compression schemes,
and for the first time present an original compression scheme which can nearly
remove all redundant information from buffer message. Theoretical limit of
compression rates are deduced in the theory of information. Through the
analysis of information content and simulation with our measured BM trace of
UUSee, the validity and superiority of our compression scheme are validated in
term of compression ratio.
"
273,"Buffer Map Message Compression Based on Relevant Window in P2P Streaming
  Media System","  Popular peer to peer streaming media systems such as PPLive and UUSee rely on
periodic buffer-map exchange between peers for proper operation. The buffer-map
exchange contains redundant information which causes non-negligible overhead.
In this paper we present a theoretical framework to study how the overhead can
be lowered. Differentiating from the traditional data compression approach, we
do not treat each buffer-map as an isolated data block, but consider the
correlations between the sequentially exchanged buffer-maps. Under this
framework, two buffer-map compression schemes are proposed and the correctness
of the schemes is proved mathematically. Moreover, we derive the theoretical
limit of compression gain based on probability theory and information theory.
Based on the system parameters of UUSee (a popular P2P streaming platform), our
simulations show that the buffer-map sizes are reduced by 86% and 90% (from 456
bits down to only 66 bits and 46 bits) respectively after applying our schemes.
Furthermore, by combining with the traditional compression methods (on
individual blocks), the sizes are decreased by 91% and 95% (to 42 bits and 24
bits) respectively. Our study provides a guideline for developing practical
compression algorithms.
"
274,"Evaluation of Huffman and Arithmetic Algorithms for Multimedia
  Compression Standards","  Compression is a technique to reduce the quantity of data without excessively
reducing the quality of the multimedia data. The transition and storing of
compressed multimedia data is much faster and more efficient than original
uncompressed multimedia data. There are various techniques and standards for
multimedia data compression, especially for image compression such as the JPEG
and JPEG2000 standards. These standards consist of different functions such as
color space conversion and entropy coding. Arithmetic and Huffman coding are
normally used in the entropy coding phase. In this paper we try to answer the
following question. Which entropy coding, arithmetic or Huffman, is more
suitable compared to other from the compression ratio, performance, and
implementation points of view? We have implemented and tested Huffman and
arithmetic algorithms. Our implemented results show that compression ratio of
arithmetic coding is better than Huffman coding, while the performance of the
Huffman coding is higher than Arithmetic coding. In addition, implementation of
Huffman coding is much easier than the Arithmetic coding.
"
275,"Transmission of Successful Route Error Message(RERR) in Routing Aware
  Multiple Description Video Coding over Mobile Ad-Hoc Network","  Video transmission over mobile ad-hoc networks is becoming important as these
networks become more widely used in the wireless networks. We propose a
routing-aware multiple description video coding approach to support video
transmission over mobile ad-hoc networks with single and multiple path
transport. We build a model to estimate the packet loss probability of each
packet transmitted over the network based on the standard ad-hoc routing
messages and network parameters without losing the RERR message. We then
calculate the frame loss probability in order to eliminate error without any
loss of data.
"
276,SAGA: A DSL for Story Management,"  Video game development is currently a very labour-intensive endeavour.
Furthermore it involves multi-disciplinary teams of artistic content creators
and programmers, whose typical working patterns are not easily meshed. SAGA is
our first effort at augmenting the productivity of such teams.
  Already convinced of the benefits of DSLs, we set out to analyze the domains
present in games in order to find out which would be most amenable to the DSL
approach. Based on previous work, we thus sought those sub-parts that already
had a partially established vocabulary and at the same time could be well
modeled using classical computer science structures. We settled on the 'story'
aspect of video games as the best candidate domain, which can be modeled using
state transition systems.
  As we are working with a specific company as the ultimate customer for this
work, an additional requirement was that our DSL should produce code that can
be used within a pre-existing framework. We developed a full system (SAGA)
comprised of a parser for a human-friendly language for 'story events', an
internal representation of design patterns for implementing object-oriented
state-transitions systems, an instantiator for these patterns for a specific
'story', and three renderers (for C++, C# and Java) for the instantiated
abstract code.
"
277,A Survey on Web Multimedia Mining,"  Modern developments in digital media technologies has made transmitting and
storing large amounts of multi/rich media data (e.g. text, images, music, video
and their combination) more feasible and affordable than ever before. However,
the state of the art techniques to process, mining and manage those rich media
are still in their infancy. Advances developments in multimedia acquisition and
storage technology the rapid progress has led to the fast growing incredible
amount of data stored in databases. Useful information to users can be revealed
if these multimedia files are analyzed. Multimedia mining deals with the
extraction of implicit knowledge, multimedia data relationships, or other
patterns not explicitly stored in multimedia files. Also in retrieval, indexing
and classification of multimedia data with efficient information fusion of the
different modalities is essential for the system's overall performance. The
purpose of this paper is to provide a systematic overview of multimedia mining.
This article is also represents the issues in the application process component
for multimedia mining followed by the multimedia mining models.
"
278,"FEBER: Feedback Based Erasure Recovery for Real-Time Multicast over
  802.11 Networks","  We consider the problem of broadcasting data streams over a wireless network
for multiple receivers with reliability and timely delivery guarantees. In our
framework, we consider packets that need to be delivered within a given time
interval, after which the packet is no longer useful at the application layer.
We set the notion of critical packet and, based on periodic feedback from the
receivers, we propose a retransmission scheme that will guarantee timely
delivery of such packets, as well as packets that are innovative for other
receivers. Our solution provides a trade-off between packet delivery ratio and
bandwidth use, which contrasts with existing approaches such as FEC and ARQ,
where the focus is on ensuring reliability first, offering no guarantees of
timely delivery of data. We evaluate the performance of our proposal in a
802.11 wireless network testbed.
"
279,"Optimization and Evaluation of a Multimedia Streaming Service on Hybrid
  Telco cloud","  With recent developments in cloud computing, a paradigm shift from rather
static deployment of resources to more dynamic, on-demand practices means more
flexibility and better utilization of resources. This demands new ways to
efficiently configure networks.
  In this paper, we will characterize a class of competitive cloud services
that telecom operators could provide based on the characteristics of telecom
infrastructure through an applicable streaming service architecture. Then, we
will model this architecture as a cost-based mathematic model. This model
provides a tool to evaluate and compare the cost of software services for
different telecom network topologies and deployment strategies. Additionally,
with each topology it acts as a means to characterize the deployment solution
that yields the lowest resource usage over the entire network. These
applications are illustrated through numerical analysis. Finally, a
proof-of-concept prototype is deployed to shows dynamic properties of the
service in the architecture and the model above.
"
280,Secured color image watermarking technique in DWT-DCT domain,"  The multilayer secured DWT-DCT and YIQ color space based image watermarking
technique with robustness and better correlation is presented here. The
security levels are increased by using multiple pn sequences, Arnold
scrambling, DWT domain, DCT domain and color space conversions. Peak signal to
noise ratio and Normalized correlations are used as measurement metrics. The
512x512 sized color images with different histograms are used for testing and
watermark of size 64x64 is embedded in HL region of DWT and 4x4 DCT is used.
'Haar' wavelet is used for decomposition and direct flexing factor is used. We
got PSNR value is 63.9988 for flexing factor k=1 for Lena image and the maximum
NC 0.9781 for flexing factor k=4 in Q color space. The comparative performance
in Y, I and Q color space is presented. The technique is robust for different
attacks like scaling, compression, rotation etc.
"
281,"Latent Semantic Learning with Structured Sparse Representation for Human
  Action Recognition","  This paper proposes a novel latent semantic learning method for extracting
high-level features (i.e. latent semantics) from a large vocabulary of abundant
mid-level features (i.e. visual keywords) with structured sparse
representation, which can help to bridge the semantic gap in the challenging
task of human action recognition. To discover the manifold structure of
midlevel features, we develop a spectral embedding approach to latent semantic
learning based on L1-graph, without the need to tune any parameter for graph
construction as a key step of manifold learning. More importantly, we construct
the L1-graph with structured sparse representation, which can be obtained by
structured sparse coding with its structured sparsity ensured by novel L1-norm
hypergraph regularization over mid-level features. In the new embedding space,
we learn latent semantics automatically from abundant mid-level features
through spectral clustering. The learnt latent semantics can be readily used
for human action recognition with SVM by defining a histogram intersection
kernel. Different from the traditional latent semantic analysis based on topic
models, our latent semantic learning method can explore the manifold structure
of mid-level features in both L1-graph construction and spectral embedding,
which results in compact but discriminative high-level features. The
experimental results on the commonly used KTH action dataset and unconstrained
YouTube action dataset show the superior performance of our method.
"
282,Low-rank data modeling via the Minimum Description Length principle,"  Robust low-rank matrix estimation is a topic of increasing interest, with
promising applications in a variety of fields, from computer vision to data
mining and recommender systems. Recent theoretical results establish the
ability of such data models to recover the true underlying low-rank matrix when
a large portion of the measured matrix is either missing or arbitrarily
corrupted. However, if low rank is not a hypothesis about the true nature of
the data, but a device for extracting regularity from it, no current guidelines
exist for choosing the rank of the estimated matrix. In this work we address
this problem by means of the Minimum Description Length (MDL) principle -- a
well established information-theoretic approach to statistical inference -- as
a guideline for selecting a model for the data at hand. We demonstrate the
practical usefulness of our formal approach with results for complex background
extraction in video sequences.
"
283,"Content-Aware Rate Control for Video Transmission with Buffer
  Constraints in Multipath Networks","  Being an integral part of the network traffic, nowadays it's vital to design
robust mechanisms to provide QoS for multimedia applications. The main goal of
this paper is to provide an efficient solution to support content-aware video
transmission mechanism with buffer underflow avoidance at the receiver in
multipath networks. Towards this, we introduce a content-aware time-varying
utility function, where the quality impacts of video content is incorporated
into its definition. Using the proposed utility function, we formulate a
multipath Dynamic Network Utility Maximization (DNUM) problem for the rate
allocation of video streams, where it takes into account QoS demand of video
streams in terms of buffer underflow avoidance. Finally, using primal-dual
method, we propose a distributed solution that optimally allocates the shared
bandwidth to video streams. The numerical examples demonstrate the efficacy of
the proposed content-aware rate allocation algorithm for video sources in both
single and multiple path network models.
"
284,Video OCR for Video Indexing,"  Video OCR is a technique that can greatly help to locate the topics of
interest in video via the automatic extraction and reading of captions and
annotations. Text in video can provide key indexing information. Recognizing
such text for search application is critical. Major difficult problem for
character recognition for videos is degraded and deformated characters, low
resolution characters or very complex background. To tackle the problem
preprocessing on text image plays vital role. Most of the OCR engines are
working on the binary image so to find a better binarization procedure for
image to get a desired result is important.Accurate binarization process
minimizes the error rate of video OCR.
"
285,"Cross-Layer Protocols for Multimedia Communications over Wireless
  Networks","  In the last few years, the Internet throughput, usage and reliability have
increased almost exponentially. The introduction of broadband wireless mobile
ad hoc networks (MANETs) and cellular networks together with increased
computational power have opened the door for a new breed of applications to be
created, namely real-time multimedia applications. Delivering real-time
multimedia traffic over a complex network like the Internet is a particularly
challenging task since these applications have strict quality-of-service (QoS)
requirements on bandwidth, delay, and delay jitter. Traditional Internet
protocol (IP)-based best effort service is not able to meet these stringent
requirements. The time-varying nature of wireless channels and resource
constrained wireless devices make the problem even more difficult. To improve
perceived media quality by end users over wireless Internet, QoS supports can
be addressed in different layers, including application layer, transport layer
and link layer. Cross layer design is a well-known approach to achieve this
adaptation. In cross-layer design, the challenges from the physical wireless
medium and the QoS-demands from the applications are taken into account so that
the rate, power, and coding at the physical (PHY) layer can adapted to meet the
requirements of the applications given the current channel and network
conditions. A number of propositions for cross-layer designs exist in the
literature. In this chapter, an extensive review has been made on these
cross-layer architectures that combine the application-layer, transport layer
and the link layer controls. Particularly, the issues like channel estimation
techniques, adaptive controls at the application and link layers for energy
efficiency, priority based scheduling, transmission rate control at the
transport layer, and adaptive automatic repeat request (ARQ) are discussed in
detail.
"
286,"Rotation, Scaling and Translation Analysis of Biometric Signature
  Templates","  Biometric authentication systems that make use of signature verification
methods often render optimum performance only under limited and restricted
conditions. Such methods utilize several training samples so as to achieve high
accuracy. Moreover, several constraints are imposed on the end-user so that the
system may work optimally, and as expected. For example, the user is made to
sign within a small box, in order to limit their signature to a predefined set
of dimensions, thus eliminating scaling. Moreover, the angular rotation with
respect to the referenced signature that will be inadvertently introduced as
human error, hampers performance of biometric signature verification systems.
To eliminate this, traditionally, a user is asked to sign exactly on top of a
reference line. In this paper, we propose a robust system that optimizes the
signature obtained from the user for a large range of variation in
Rotation-Scaling-Translation (RST) and resolves these error parameters in the
user signature according to the reference signature stored in the database.
"
287,Audio Watermarking with Error Correction,"  In recent times, communication through the internet has tremendously
facilitated the distribution of multimedia data. Although this is indubitably a
boon, one of its repercussions is that it has also given impetus to the
notorious issue of online music piracy. Unethical attempts can also be made to
deliberately alter such copyrighted data and thus, misuse it. Copyright
violation by means of unauthorized distribution, as well as unauthorized
tampering of copyrighted audio data is an important technological and research
issue. Audio watermarking has been proposed as a solution to tackle this issue.
The main purpose of audio watermarking is to protect against possible threats
to the audio data and in case of copyright violation or unauthorized tampering,
authenticity of such data can be disputed by virtue of audio watermarking.
"
288,Multi-Layer Local Graph Words for Object Recognition,"  In this paper, we propose a new multi-layer structural approach for the task
of object based image retrieval. In our work we tackle the problem of
structural organization of local features. The structural features we propose
are nested multi-layered local graphs built upon sets of SURF feature points
with Delaunay triangulation. A Bag-of-Visual-Words (BoVW) framework is applied
on these graphs, giving birth to a Bag-of-Graph-Words representation. The
multi-layer nature of the descriptors consists in scaling from trivial Delaunay
graphs - isolated feature points - by increasing the number of nodes layer by
layer up to graphs with maximal number of nodes. For each layer of graphs its
own visual dictionary is built. The experiments conducted on the SIVAL and
Caltech-101 data sets reveal that the graph features at different layers
exhibit complementary performances on the same content and perform better than
baseline BoVW approach. The combination of all existing layers, yields
significant improvement of the object recognition performance compared to
single level approaches.
"
289,Storage Balancing in Self-organizing Multimedia Delivery Systems,"  Many of the current bio-inspired delivery networks set their focus on search,
e.g., by using artificial ants. If the network size and, therefore, the search
space gets too large, the users experience high delays until the requested
content can be consumed. In previous work, we proposed different replication
strategies to reduce the search space. In this report we further evaluate
measures for storage load balancing, because peers are most likely limited in
space. We periodically apply clean-ups if a certain storage level is reached.
For our evaluations we combine the already introduced replication measures with
least recently used (LRU), least frequently used (LFU) and a hormone-based
clean-up. The goal is to elaborate a combination that leads to low delays while
the replica utilization is high.
"
290,Network Characteristics of Video Streaming Traffic,"  Video streaming represents a large fraction of Internet traffic.
Surprisingly, little is known about the network characteristics of this
traffic. In this paper, we study the network characteristics of the two most
popular video streaming services, Netflix and YouTube. We show that the
streaming strategies vary with the type of the application (Web browser or
native mobile application), and the type of container (Silverlight, Flash, or
HTML5) used for video streaming. In particular, we identify three different
streaming strategies that produce traffic patterns from non-ack clocked ON-OFF
cycles to bulk TCP transfer. We then present an analytical model to study the
potential impact of these streaming strategies on the aggregate traffic and
make recommendations accordingly.
"
291,Using Transcoding for Hidden Communication in IP Telephony,"  The paper presents a new steganographic method for IP telephony called
TranSteg (Transcoding Steganography). Typically, in steganographic
communication it is advised for covert data to be compressed in order to limit
its size. In TranSteg it is the overt data that is compressed to make space for
the steganogram. The main innovation of TranSteg is to, for a chosen voice
stream, find a codec that will result in a similar voice quality but smaller
voice payload size than the originally selected. Then, the voice stream is
transcoded. At this step the original voice payload size is intentionally
unaltered and the change of the codec is not indicated. Instead, after placing
the transcoded voice payload, the remaining free space is filled with hidden
data. TranSteg proof of concept implementation was designed and developed. The
obtained experimental results are enclosed in this paper. They prove that the
proposed method is feasible and offers a high steganographic bandwidth.
TranSteg detection is difficult to perform when performing inspection in a
single network localisation.
"
292,"Hierarchical Hidden Markov Model in Detecting Activities of Daily Living
  in Wearable Videos for Studies of Dementia","  This paper presents a method for indexing activities of daily living in
videos obtained from wearable cameras. In the context of dementia diagnosis by
doctors, the videos are recorded at patients' houses and later visualized by
the medical practitioners. The videos may last up to two hours, therefore a
tool for an efficient navigation in terms of activities of interest is crucial
for the doctors. The specific recording mode provides video data which are
really difficult, being a single sequence shot where strong motion and sharp
lighting changes often appear. Our work introduces an automatic motion based
segmentation of the video and a video structuring approach in terms of
activities by a hierarchical two-level Hidden Markov Model. We define our
description space over motion and visual characteristics of video and audio
channels. Experiments on real data obtained from the recording at home of
several patients show the difficulty of the task and the promising results of
our approach.
"
293,The UWB Solution for Multimedia Traffic in Wireless Sensor Networks,"  Several researches are focused on the QoS (Quality of Service) and Energy
consumption in wireless Multimedia Sensor Networks. Those research projects
invest in theory and practice in order to extend the spectrum of use of norms,
standards and technologies which are emerged in wireless communications. The
performance of these technologies is strongly related to domains of use and
limitations of their characteristics. In this paper, we give a comparison of
ZigBee technology, most widely used in sensor networks, and UWB (Ultra Wide
Band) which presents itself as competitor that present in these work better
results for audiovisual applications with medium-range and high throughput.
"
294,A Survey on Web-based AR Applications,"  Due to the increase of interest in Augmented Reality (AR), the potential uses
of AR are increasing also. It can benefit the user in various fields such as
education, business, medicine, and other. Augmented Reality supports the real
environment with synthetic environment to give more details and meaning to the
objects in the real word. AR refers to a situation in which the goal is to
supplement a user's perception of the real-world through the addition of
virtual objects. This paper is an attempt to make a survey of web-based
Augmented Reality applications and make a comparison among them.
"
295,Fingerprinting with Equiangular Tight Frames,"  Digital fingerprinting is a framework for marking media files, such as
images, music, or movies, with user-specific signatures to deter illegal
distribution. Multiple users can collude to produce a forgery that can
potentially overcome a fingerprinting system. This paper proposes an
equiangular tight frame fingerprint design which is robust to such collusion
attacks. We motivate this design by considering digital fingerprinting in terms
of compressed sensing. The attack is modeled as linear averaging of multiple
marked copies before adding a Gaussian noise vector. The content owner can then
determine guilt by exploiting correlation between each user's fingerprint and
the forged copy. The worst-case error probability of this detection scheme is
analyzed and bounded. Simulation results demonstrate the average-case
performance is similar to the performance of orthogonal and simplex fingerprint
designs, while accommodating several times as many users.
"
296,"Channel Reordering with Time-shifted Streams to Improve Channel Change
  Latency in IPTV Networks","  In IPTV networks, channel change latency is considered as a major obstacle in
achieving broadcast-level quality video delivery. Because of the bandwidth
limitations observed at the client side, users typically have access to a
limited number of channels. As a result, channel change requests oftentimes
need to go through the network, thereby leading to significant delays. In this
paper, we address this problem by proposing a resource-efficient time-shifted
channel reordering mechanism to minimize the channel change latency. The
proposed framework exploits the differing key-frame delivery times for the
adjacent sessions to dynamically arrange the switching order during the surfing
periods. The simulation results show that, with the proposed framework, more
than 50% improvement can be achieved in channel change latency without
introducing any overhead in the network.
"
297,Enhancement of Image Resolution by Binarization,"  Image segmentation is one of the principal approaches of image processing.
The choice of the most appropriate Binarization algorithm for each case proved
to be a very interesting procedure itself. In this paper, we have done the
comparison study between the various algorithms based on Binarization
algorithms and propose a methodologies for the validation of Binarization
algorithms. In this work we have developed two novel algorithms to determine
threshold values for the pixels value of the gray scale image. The performance
estimation of the algorithm utilizes test images with, the evaluation metrics
for Binarization of textual and synthetic images. We have achieved better
resolution of the image by using the Binarization method of optimum
thresholding techniques.
"
298,"A Frame Rate Optimization Framework For Improving Continuity In Video
  Streaming","  This paper aims to reduce the prebuffering requirements, while maintaining
continuity, for video streaming. Current approaches do this by making use of
adaptive media playout (AMP) to reduce the playout rate. However, this
introduces playout distortion to the viewers and increases the viewing latency.
We approach this by proposing a frame rate optimization framework that adjusts
both the encoder frame generation rate and the decoder playout frame rate.
Firstly, we model this problem as the joint adjustment of the encoder frame
generation interval and the decoder playout frame interval. This model is used
with a discontinuity penalty virtual buffer to track the accumulated difference
between the receiving frame interval and the playout frame interval. We then
apply Lyapunov optimization to the model to systematically derive a pair of
decoupled optimization policies. We show that the occupancy of the
discontinuity penalty virtual buffer is correlated to the video discontinuity
and that this framework produces a very low playout distortion in addition to a
significant reduction in the prebuffering requirements compared to existing
approaches. Secondly, we introduced a delay constraint into the framework by
using a delay accumulator virtual buffer. Simulation results show that the the
delay constrained framework provides a superior tradeoff between the video
quality and the delay introduced compared to the existing approach. Finally, we
analyzed the impact of delayed feedback between the receiver and the sender on
the optimization policies. We show that the delayed feedbacks have a minimal
impact on the optimization policies.
"
299,"Distributed Representation of Geometrically Correlated Images with
  Compressed Linear Measurements","  This paper addresses the problem of distributed coding of images whose
correlation is driven by the motion of objects or positioning of the vision
sensors. It concentrates on the problem where images are encoded with
compressed linear measurements. We propose a geometry-based correlation model
in order to describe the common information in pairs of images. We assume that
the constitutive components of natural images can be captured by visual
features that undergo local transformations (e.g., translation) in different
images. We first identify prominent visual features by computing a sparse
approximation of a reference image with a dictionary of geometric basis
functions. We then pose a regularized optimization problem to estimate the
corresponding features in correlated images given by quantized linear
measurements. The estimated features have to comply with the compressed
information and to represent consistent transformation between images. The
correlation model is given by the relative geometric transformations between
corresponding features. We then propose an efficient joint decoding algorithm
that estimates the compressed images such that they stay consistent with both
the quantized measurements and the correlation model. Experimental results show
that the proposed algorithm effectively estimates the correlation between
images in multi-view datasets. In addition, the proposed algorithm provides
effective decoding performance that compares advantageously to independent
coding solutions as well as state-of-the-art distributed coding schemes based
on disparity learning.
"
300,"Estimation of the Embedding Capacity in Pixel-pair based Watermarking
  Schemes","  Estimation of the Embedding capacity is an important problem specifically in
reversible multi-pass watermarking and is required for analysis before any
image can be watermarked. In this paper, we propose an efficient method for
estimating the embedding capacity of a given cover image under multi-pass
embedding, without actually embedding the watermark. We demonstrate this for a
class of reversible watermarking schemes which operate on a disjoint group of
pixels, specifically for pixel pairs. The proposed algorithm iteratively
updates the co-occurrence matrix at every stage, to estimate the multi-pass
embedding capacity, and is much more efficient vis-a-vis actual watermarking.
We also suggest an extremely efficient, pre-computable tree based
implementation which is conceptually similar to the co-occurrence based method,
but provides the estimates in a single iteration, requiring a complexity akin
to that of single pass capacity estimation. We also provide bounds on the
embedding capacity. We finally show how our method can be easily used on a
number of watermarking algorithms and specifically evaluate the performance of
our algorithms on the benchmark watermarking schemes of Tian [11] and Coltuc
[6].
"
301,"A Scalable Video Search Engine Based on Audio Content Indexing and Topic
  Segmentation","  One important class of online videos is that of news broadcasts. Most news
organisations provide near-immediate access to topical news broadcasts over the
Internet, through RSS streams or podcasts. Until lately, technology has not
made it possible for a user to automatically go to the smaller parts, within a
longer broadcast, that might interest them. Recent advances in both speech
recognition systems and natural language processing have led to a number of
robust tools that allow us to provide users with quicker, more focussed access
to relevant segments of one or more news broadcast videos. Here we present our
new interface for browsing or searching news broadcasts (video/audio) that
exploits these new language processing tools to (i) provide immediate access to
topical passages within news broadcasts, (ii) browse news broadcasts by events
as well as by people, places and organisations, (iii) perform cross lingual
search of news broadcasts, (iv) search for news through a map interface, (v)
browse news by trending topics, and (vi) see automatically-generated textual
clues for news segments, before listening. Our publicly searchable demonstrator
currently indexes daily broadcast news content from 50 sources in English,
French, Chinese, Arabic, Spanish, Dutch and Russian.
"
302,"A New Digital Watermarking Algorithm Using Combination of Least
  Significant Bit (LSB) and Inverse Bit","  In this paper, we introduce a new digital watermarking algorithm using least
significant bit (LSB). LSB is used because of its little effect on the image.
This new algorithm is using LSB by inversing the binary values of the watermark
text and shifting the watermark according to the odd or even number of pixel
coordinates of image before embedding the watermark. The proposed algorithm is
flexible depending on the length of the watermark text. If the length of the
watermark text is more than ((MxN)/8)-2 the proposed algorithm will also embed
the extra of the watermark text in the second LSB. We compare our proposed
algorithm with the 1-LSB algorithm and Lee's algorithm using Peak
signal-to-noise ratio (PSNR). This new algorithm improved its quality of the
watermarked image. We also attack the watermarked image by using cropping and
adding noise and we got good results as well.
"
303,"Peer-to-Peer Live Streaming and Video On Demand Design Issues and its
  Challenges","  Peer-to-Peer Live streaming and Video on Demand is the most popular media
applications over the Internet in recent years. These systems reduce the load
on the server and provide a scalable content distribution. A new paradigm of
P2P network collaborates to build large distributed video applications on
existing networks .But, the problem of designing the system are at par with the
P2P media streaming, live and Video on demand systems. Hence a comprehensive
design comparison is needed to build such kind of system architecture.
Therefore, in this paper we elaborately studied the traditional approaches for
P2P streaming architectures, and its critical design issues, as well as
practicable challenges. Thus, our studies in this paper clearly point the
tangible design issues and its challenges, and other intangible issues for
providing P2P VoD services.
"
304,"Automatic Classification of X-rated Videos using Obscene Sound Analysis
  based on a Repeated Curve-like Spectrum Feature","  This paper addresses the automatic classification of X-rated videos by
analyzing its obscene sounds. In this paper, obscene sounds refer to audio
signals generated from sexual moans and screams during sexual scenes. By
analyzing various sound samples, we determined the distinguishable
characteristics of obscene sounds and propose a repeated curve-like spectrum
feature that represents the characteristics of such sounds. We constructed
6,269 audio clips to evaluate the proposed feature, and separately constructed
1,200 X-rated and general videos for classification. The proposed feature has
an F1-score, precision, and recall rate of 96.6%, 98.2%, and 95.2%,
respectively, for the original dataset, and 92.6%, 97.6%, and 88.0% for a noisy
dataset of 5dB SNR. And, in classifying videos, the feature has more than a 90%
F1-score, 97% precision, and an 84% recall rate. From the measured performance,
X-rated videos can be classified with only the audio features and the repeated
curve-like spectrum feature is suitable to detect obscene sounds.
"
305,Recent Trends and Research Issues in Video Association Mining,"  With the ever-growing digital libraries and video databases, it is
increasingly important to understand and mine the knowledge from video database
automatically. Discovering association rules between items in a large video
database plays a considerable role in the video data mining research areas.
Based on the research and development in the past years, application of
association rule mining is growing in different domains such as surveillance,
meetings, broadcast news, sports, archives, movies, medical data, as well as
personal and online media collections. The purpose of this paper is to provide
general framework of mining the association rules from video database. This
article is also represents the research issues in video association mining
followed by the recent trends.
"
306,"Statistical Information of the Increased Demand for Watch the VOD with
  the Increased Sophistication in the Mobile Devices,Communications and
  Internet Penetration in Asia","  As the rapid progress of the media streaming applications such as video
streaming can be classified into two types of streaming, Live video streaming,
Video on Demand (VoD). Live video streaming is a service which allows the
clients to watch many TV channels over the internet and the clients able to use
one operation to perform is to switch the channels. Video on Demand (VoD) is
one of the most important applications for the internet of the future and has
become an interactive multimedia service which allows the users to start
watching the video of their choice at anytime and anywhere, especially after
the rapid deployment of the wireless networks and mobile devices. In this paper
provide statistical information about the Internet, communications and mobile
devices etc. This has led to an increased demand for the development,
communication and computational powers of many of the mobile wireless
subscribers/mobile devices such as laptops, PDAs, smart phones and notebook.
These techniques are utilized to obtain a video on demand service with higher
resolution and quality. Another objective in this paper is to see Malaysia
ranked as a fully developed country by the year 2020.
"
307,Modelling Gesture Based Ubiquitous Applications,"  A cost effective, gesture based modelling technique called Virtual
Interactive Prototyping (VIP) is described in this paper. Prototyping is
implemented by projecting a virtual model of the equipment to be prototyped.
Users can interact with the virtual model like the original working equipment.
For capturing and tracking the user interactions with the model image and sound
processing techniques are used. VIP is a flexible and interactive prototyping
method that has much application in ubiquitous computing environments.
Different commercial as well as socio-economic applications and extension to
interactive advertising of VIP are also discussed.
"
308,Lossless Digital Image Compression Method for Bitmap Images,"  In this research paper, the authors propose a new approach to digital image
compression using crack coding This method starts with the original image and
develop crack codes in a recursive manner, marking the pixels visited earlier
and expanding the entropy in four directions. The proposed method is
experimented with sample bitmap images and results are tabulated. The method is
implemented in uni-processor machine using C language source code.
"
309,Steganography Algorithm to Hide Secret Message inside an Image,"  In this paper, the authors propose a new algorithm to hide data inside image
using steganography technique. The proposed algorithm uses binary codes and
pixels inside an image. The zipped file is used before it is converted to
binary codes to maximize the storage of data inside the image. By applying the
proposed algorithm, a system called Steganography Imaging System (SIS) is
developed. The system is then tested to see the viability of the proposed
algorithm. Various sizes of data are stored inside the images and the PSNR
(Peak signal-to-noise ratio) is also captured for each of the images tested.
Based on the PSNR value of each images, the stego image has a higher PSNR
value. Hence this new steganography algorithm is very efficient to hide the
data inside the image.
"
310,"Chaotic iterations for steganography: Stego-security and
  topological-security","  In this paper is proposed a novel steganographic scheme based on chaotic
iterations. This research work takes place into the information hiding security
fields. We show that the proposed scheme is stego-secure, which is the highest
level of security in a well defined and studied category of attack called
""watermark-only attack"". Additionally, we prove that this scheme presents
topological properties so that it is one of the firsts able to face, at least
partially, an adversary when considering the others categories of attacks
defined in the literature.
"
311,"Chaotic iterations versus Spread-spectrum: topological-security and
  stego-security","  A new framework for information hiding security, called topological-security,
has been proposed in a previous study. It is based on the evaluation of
unpredictability of the scheme, whereas existing notions of security, as
stego-security, are more linked to information leaks. It has been proven that
spread-spectrum techniques, a well-known stego-secure scheme, are
topologically-secure too. In this paper, the links between the two notions of
security is deepened and the usability of topological-security is clarified, by
presenting a novel data hiding scheme that is twice stego and
topological-secure. This last scheme has better scores than spread-spectrum
when evaluating qualitative and quantitative topological-security properties.
Incidentally, this result shows that the new framework for security tends to
improve the ability to compare data hiding scheme.
"
312,"Markov Decision Process Based Energy-Efficient On-Line Scheduling for
  Slice-Parallel Video Decoders on Multicore Systems","  We consider the problem of energy-efficient on-line scheduling for
slice-parallel video decoders on multicore systems. We assume that each of the
processors are Dynamic Voltage Frequency Scaling (DVFS) enabled such that they
can independently trade off performance for power, while taking the video
decoding workload into account. In the past, scheduling and DVFS policies in
multi-core systems have been formulated heuristically due to the inherent
complexity of the on-line multicore scheduling problem. The key contribution of
this report is that we rigorously formulate the problem as a Markov decision
process (MDP), which simultaneously takes into account the on-line scheduling
and per-core DVFS capabilities; the power consumption of the processor cores
and caches; and the loss tolerant and dynamic nature of the video decoder's
traffic. In particular, we model the video traffic using a Direct Acyclic Graph
(DAG) to capture the precedence constraints among frames in a Group of Pictures
(GOP) structure, while also accounting for the fact that frames have different
display/decoding deadlines and non-deterministic decoding complexities. The
objective of the MDP is to minimize long-term power consumption subject to a
minimum Quality of Service (QoS) constraint related to the decoder's
throughput. Although MDPs notoriously suffer from the curse of dimensionality,
we show that, with appropriate simplifications and approximations, the
complexity of the MDP can be mitigated. We implement a slice-parallel version
of H.264 on a multiprocessor ARM (MPARM) virtual platform simulator, which
provides cycle-accurate and bus signal-accurate simulation for different
processors. We use this platform to generate realistic video decoding traces
with which we evaluate the proposed on-line scheduling algorithm in Matlab.
"
313,"Online Learning for Classification of Low-rank Representation Features
  and Its Applications in Audio Segment Classification","  In this paper, a novel framework based on trace norm minimization for audio
segment is proposed. In this framework, both the feature extraction and
classification are obtained by solving corresponding convex optimization
problem with trace norm regularization. For feature extraction, robust
principle component analysis (robust PCA) via minimization a combination of the
nuclear norm and the $\ell_1$-norm is used to extract low-rank features which
are robust to white noise and gross corruption for audio segments. These
low-rank features are fed to a linear classifier where the weight and bias are
learned by solving similar trace norm constrained problems. For this
classifier, most methods find the weight and bias in batch-mode learning, which
makes them inefficient for large-scale problems. In this paper, we propose an
online framework using accelerated proximal gradient method. This framework has
a main advantage in memory cost. In addition, as a result of the regularization
formulation of matrix classification, the Lipschitz constant was given
explicitly, and hence the step size estimation of general proximal gradient
method was omitted in our approach. Experiments on real data sets for
laugh/non-laugh and applause/non-applause classification indicate that this
novel framework is effective and noise robust.
"
314,Critical Data Compression,"  A new approach to data compression is developed and applied to multimedia
content. This method separates messages into components suitable for both
lossless coding and 'lossy' or statistical coding techniques, compressing
complex objects by separately encoding signals and noise. This is demonstrated
by compressing the most significant bits of data exactly, since they are
typically redundant and compressible, and either fitting a maximally likely
noise function to the residual bits or compressing them using lossy methods.
Upon decompression, the significant bits are decoded and added to a noise
function, whether sampled from a noise model or decompressed from a lossy code.
This results in compressed data similar to the original. For many test images,
a two-part image code using JPEG2000 for lossy coding and PAQ8l for lossless
coding produces less mean-squared error than an equal length of JPEG2000.
Computer-generated images typically compress better using this method than
through direct lossy coding, as do many black and white photographs and most
color photographs at sufficiently high quality levels. Examples applying the
method to audio and video coding are also demonstrated. Since two-part codes
are efficient for both periodic and chaotic data, concatenations of roughly
similar objects may be encoded efficiently, which leads to improved inference.
Applications to artificial intelligence are demonstrated, showing that signals
using an economical lossless code have a critical level of redundancy which
leads to better description-based inference than signals which encode either
insufficient data or too much detail.
"
315,"Interactive multiview video system with non-complex navigation at the
  decoder","  Multiview video with interactive and smooth view switching at the receiver is
a challenging application with several issues in terms of effective use of
storage and bandwidth resources, reactivity of the system, quality of the
viewing experience and system complexity. The classical decoding system for
generating virtual views first projects a reference or encoded frame to a given
viewpoint and then fills in the holes due to potential occlusions. This last
step still constitutes a complex operation with specific software or hardware
at the receiver and requires a certain quantity of information from the
neighboring frames for insuring consistency between the virtual images. In this
work we propose a new approach that shifts most of the burden due to
interactivity from the decoder to the encoder, by anticipating the navigation
of the decoder and sending auxiliary information that guarantees temporal and
interview consistency. This leads to an additional cost in terms of
transmission rate and storage, which we minimize by using optimization
techniques based on the user behavior modeling. We show by experiments that the
proposed system represents a valid solution for interactive multiview systems
with classical decoders.
"
316,Stereo image Transference & Retrieval over SMS,"  Paper presents the way of transferring stereo images using SMS over GSM
network. Generally, Stereo image is composed of two stereoscopic images in such
way that gives three dimensional affect when viewed. GSM have two short
messaging services, which can transfer images and sounds etc. Such services are
known as; MMS (Multimedia Messaging Service) and EMS (Extended Messaging
Service). EMS can send Predefined sounds, animation and images but have
limitation that it does not support widely. MMS can send much higher contents
than EMS but need 3G and other network capability in order to send large size
data up to 1000 bytes. Other limitations are Portability, content adaption etc.
Our major aim in this paper is to provide an alternative way of sending stereo
images over SMS which is widely supported than EMS. We develop an application
using J2ME Platform.
"
317,"Identifying and Analysis of Scene Mining Methods Beased on Scenes
  Extracted Features","  Scene mining is a subset of image mining in which scenes are classified to a
distinct set of classes based on analysis of their content. In other word in
scene mining, a label is given to visual content of scene, for example,
mountain, beach. Scene mining is used in applications such as medicine, movie,
information retrieval, computer vision, recognition of traffic scene. Reviewing
of represented methods shows there are various methods in scene mining. Scene
mining applications extension and existence of various scenes, make comparison
of methods hard. Scene mining can be followed by identifying scene mining
components and representing a framework to analyzing and evaluating methods. In
this paper, at first, components of scene mining are introduced, then a
framework based on extracted features of scene is represented to classify scene
mining methods. Finally, these methods are analyzed and evaluated via a
proposal framework.
"
318,"Throughput Scaling Of Convolution For Error-Tolerant Multimedia
  Applications","  Convolution and cross-correlation are the basis of filtering and pattern or
template matching in multimedia signal processing. We propose two throughput
scaling options for any one-dimensional convolution kernel in programmable
processors by adjusting the imprecision (distortion) of computation. Our
approach is based on scalar quantization, followed by two forms of tight
packing in floating-point (one of which is proposed in this paper) that allow
for concurrent calculation of multiple results. We illustrate how our approach
can operate as an optional pre- and post-processing layer for off-the-shelf
optimized convolution routines. This is useful for multimedia applications that
are tolerant to processing imprecision and for cases where the input signals
are inherently noisy (error tolerant multimedia applications). Indicative
experimental results with a digital music matching system and an MPEG-7 audio
descriptor system demonstrate that the proposed approach offers up to 175%
increase in processing throughput against optimized (full-precision)
convolution with virtually no effect in the accuracy of the results. Based on
marginal statistics of the input data, it is also shown how the throughput and
distortion can be adjusted per input block of samples under constraints on the
signal-to-noise ratio against the full-precision convolution.
"
319,"A New Color Feature Extraction Method Based on Dynamic Color
  Distribution Entropy of Neighborhoods","  One of the important requirements in image retrieval, indexing,
classification, clustering and etc. is extracting efficient features from
images. The color feature is one of the most widely used visual features. Use
of color histogram is the most common way for representing color feature. One
of disadvantage of the color histogram is that it does not take the color
spatial distribution into consideration. In this paper dynamic color
distribution entropy of neighborhoods method based on color distribution
entropy is presented, which effectively describes the spatial information of
colors. The image retrieval results in compare to improved color distribution
entropy show the acceptable efficiency of this approach.
"
320,An Authoring System for Editing Lessons in Phonetic English in SMIL3.0,"  One of the difficulties of teaching English is the prosody, including the
stress. French learners have difficulties to encode this information about the
word because it is irrelevant for them. Therefore, they have difficulty to
produce this stress when they speak that language. Studies in this area have
concluded that the dual-coding approach (auditory and visual) of a phonetic
phenomenon helps a lot to improve its perception and memorization for novice
learners. The aim of our work is to provide English teachers with an authoring
named SaCoPh for editing multimedia courses that support this approach. This
course is based on a template that fits the educational aspects of phonetics,
exploiting the features of version 3.0 of the standard SMIL (Synchronized
Multimedia Integration Language) for the publication of this course on the web.
"
321,Influence of Speech Codecs Selection on Transcoding Steganography,"  The typical approach to steganography is to compress the covert data in order
to limit its size, which is reasonable in the context of a limited
steganographic bandwidth. TranSteg (Trancoding Steganography) is a new IP
telephony steganographic method that was recently proposed that offers high
steganographic bandwidth while retaining good voice quality. In TranSteg,
compression of the overt data is used to make space for the steganogram. In
this paper we focus on analyzing the influence of the selection of speech
codecs on hidden transmission performance, that is, which codecs would be the
most advantageous ones for TranSteg. Therefore, by considering the codecs which
are currently most popular for IP telephony we aim to find out which codecs
should be chosen for transcoding to minimize the negative influence on voice
quality while maximizing the obtained steganographic bandwidth.
"
322,Personalised product design using virtual interactive techniques,"  Use of Virtual Interactive Techniques for personalized product design is
described in this paper. Usually products are designed and built by considering
general usage patterns and Prototyping is used to mimic the static or working
behaviour of an actual product before manufacturing the product. The user does
not have any control on the design of the product. Personalized design
postpones design to a later stage. It allows for personalized selection of
individual components by the user. This is implemented by displaying the
individual components over a physical model constructed using Cardboard or
Thermocol in the actual size and shape of the original product. The components
of the equipment or product such as screen, buttons etc. are then projected
using a projector connected to the computer into the physical model. Users can
interact with the prototype like the original working equipment and they can
select, shape, position the individual components displayed on the interaction
panel using simple hand gestures. Computer Vision techniques as well as sound
processing techniques are used to detect and recognize the user gestures
captured using a web camera and microphone.
"
323,An evaluation of local shape descriptors for 3D shape retrieval,"  As the usage of 3D models increases, so does the importance of developing
accurate 3D shape retrieval algorithms. A common approach is to calculate a
shape descriptor for each object, which can then be compared to determine two
objects' similarity. However, these descriptors are often evaluated
independently and on different datasets, making them difficult to compare.
Using the SHREC 2011 Shape Retrieval Contest of Non-rigid 3D Watertight Meshes
dataset, we systematically evaluate a collection of local shape descriptors. We
apply each descriptor to the bag-of-words paradigm and assess the effects of
varying the dictionary's size and the number of sample points. In addition,
several salient point detection methods are used to choose sample points; these
methods are compared to each other and to random selection. Finally,
information from two local descriptors is combined in two ways and changes in
performance are investigated. This paper presents results of these experiment
"
324,A Frequency Domain Steganography using Z Transform (FDSZT),"  Image steganography is art of hiding information onto the cover image. In
this proposal a transformed domain based gray scale image authentication/data
hiding technique using Z transform (ZT) termed as FDSZT, has been proposed.
ZTransform is applied on 2x2 masks of the source image in row major order to
transform original sub image (cover image) block to its corresponding frequency
domain. One bit of the hidden image is embedded in each mask of the source
image onto the fourth LSB of transformed coefficient based on median value of
the mask. A delicate handle has also been performed as post embedding operation
for proper decoding. Stego sub image is obtained through a reverse transform as
final step of embedding in a mask. During the process of embedding, dimension
of the hidden image followed by the content of the message/hidden image are
embedded. Reverse process is followed during decoding. High PSNR obtained for
various images conform the quality of invisible watermark of FDSZT.
"
325,"Real-time detection and tracking of multiple objects with partial
  decoding in H.264/AVC bitstream domain","  In this paper, we show that we can apply probabilistic spatiotemporal
macroblock filtering (PSMF) and partial decoding processes to effectively
detect and track multiple objects in real time in H.264|AVC bitstreams with
stationary background. Our contribution is that our method cannot only show
fast processing time but also handle multiple moving objects that are
articulated, changing in size or internally have monotonous color, even though
they contain a chaotic set of non-homogeneous motion vectors inside. In
addition, our partial decoding process for H.264|AVC bitstreams enables to
improve the accuracy of object trajectories and overcome long occlusion by
using extracted color information.
"
326,"A new hybrid jpeg image compression scheme using symbol reduction
  technique","  Lossy JPEG compression is a widely used compression technique. Normally the
JPEG standard technique uses three process mapping reduces interpixel
redundancy, quantization, which is lossy process and entropy encoding, which is
considered lossless process. In this paper, a new technique has been proposed
by combining the JPEG algorithm and Symbol Reduction Huffman technique for
achieving more compression ratio. The symbols reduction technique reduces the
number of symbols by combining together to form a new symbol. As a result of
this technique the number of Huffman code to be generated also reduced. It is
simple fast and easy to implement. The result shows that the performance of
standard JPEG method can be improved by proposed method. This hybrid approach
achieves about 20% more compression ratio than the Standard JPEG.
"
327,Analysis and implementation of the Large Scale Video-on-Demand System,"  Next Generation Network (NGN) provides multimedia services over broadband
based networks, which supports high definition TV (HDTV), and DVD quality
video-on-demand content. The video services are thus seen as merging mainly
three areas such as computing, communication, and broadcasting. It has numerous
advantages and more exploration for the large-scale deployment of
video-on-demand system is still needed. This is due to its economic and design
constraints. It's need significant initial investments for full service
provision. This paper presents different estimation for the different
topologies and it require efficient planning for a VOD system network. The
methodology investigates the network bandwidth requirements of a VOD system
based on centralized servers, and distributed local proxies. Network traffic
models are developed to evaluate the VOD system's operational bandwidth
requirements for these two network architectures. This paper present an
efficient estimation of the of the bandwidth requirement for the different
architectures.
"
328,Development Trends in Steganography,"  Steganography is a general term referring to all methods for the embedding of
additional secret content into some form of carrier, with the aim of
concealment of the introduced alterations. The choice of the carrier is nearly
unlimited, it may be an ancient piece of parchment, as well as a network
protocol header. Inspired by biological phenomena, adopted by man in the
ancient times, it has been developed over the ages. Present day steganographic
methods are far more sophisticated than their ancient predecessors, but the
main principles have remained unchanged. They typically rely on the utilization
of digital media files or network protocols as a carrier, in which secret data
is embedded. This paper presents the evolution of the hidden data carrier from
the ancient times till the present day and pinpoints the observed development
trends, with special emphasis on network steganography.
"
329,"Lyapunov exponent evaluation of a digital watermarking scheme proven to
  be secure","  In our previous researches, a new digital watermarking scheme based on
chaotic iterations has been introduced. This scheme was both stego-secure and
topologically secure. The stego-security is to face an attacker in the
""watermark only attack"" category, whereas the topological security concerns
other categories of attacks. Its Lyapunov exponent is evaluated here, to
quantify the chaos generated by this scheme.
  Keywords : Lyapunov exponent; Information hiding; Security; Chaotic
iterations; Digital Watermarking.
"
330,"Enhancement Techniques for Local Content Preservation and Contrast
  Improvement in Images","  There are several images that do not have uniform brightness which pose a
challenging problem for image enhancement systems. As histogram equalization
has been successfully used to correct for uniform brightness problems, a
histogram equalization method that utilizes human visual system based
thresholding(human vision thresholding) as well as logarithmic processing
techniques were introduced later . But these methods are not good for
preserving the local content of the image which is a major factor for various
images like medical and aerial images. Therefore new method is proposed here.
This method is referred as ""Human vision thresholding with enhancement
technique for dark blurred images for local content preservation"". It uses
human vision thresholding together with an existing enhancement method for dark
blurred images. Furthermore a comparative study with another method for local
content preservation is done which is further extended to make it suitable for
contrast improvement. Experimental results shows that the proposed methods
outperforms the former existing methods in preserving the local content for
standard images, medical and aerial images.
"
331,A Hybrid Image Cryptosystem Based On OMFLIP Permutation Cipher,"  The protection of confidential image data from unauthorized access is an
important area of research in network communication. This paper presents a
high-level security encryption scheme for gray scale images. The gray level
image is first decomposed into binary images using bit scale decomposition.
Each binary image is then compressed by selecting a good scanning path that
minimizes the total number of bits needed to encode the bit sequence along the
scanning path using two dimensional run encoding. The compressed bit string is
then scrambled iteratively using a pseudo-random number generator and finally
encrypted using a bit level permutation OMFLIP. The performance is tested,
illustrated and discussed.
"
332,"Blind 3D Model Watermarking Based on Multi-Resolution Representation and
  Fuzzy Logic","  Insertion of a text message, audio data or/and an image into another image or
3D model is called as a watermarking process. Watermarking has variety of
applications like: Copyright Protection, Owner Identification, Copy Protection
and Data Hiding etc., depending upon the type of watermark insertion algorithm.
Watermark remains in the content after applying various attacks without any
distortions. The blind watermarking method used in the system is based on a
wavelet transform, a fuzzy inference system and a multi-resolution
representation (MRR) of the 3d model. The watermark scrambled by Arnold
Transform is embedded in the wavelet coefficients at third resolution level of
the MRR. Fuzzy logic approach used in the method makes it to approximate the
best possible gain with an accurate scaling factor so that the watermark
remains invisible. The fuzzy input variables are computed for each wavelet
coefficient in the 3D model. The output of the fuzzy system is a single value
which is a perceptual value for each corresponding wavelet coefficient. Thus,
the fuzzy perceptual mask combines all these non-linear variables to build a
simple, easy to use HVS model. Results shows that the system is robust against
affine transformations, smoothing, cropping and noise attacks.
"
333,QoE-aware Media Streaming in Technology and Cost Heterogeneous Networks,"  We present a framework for studying the problem of media streaming in
technology and cost heterogeneous environments. We first address the problem of
efficient streaming in a technology-heterogeneous setting. We employ random
linear network coding to simplify the packet selection strategies and alleviate
issues such as duplicate packet reception. Then, we study the problem of media
streaming from multiple cost-heterogeneous access networks. Our objective is to
characterize analytically the trade-off between access cost and user
experience. We model the Quality of user Experience (QoE) as the probability of
interruption in playback as well as the initial waiting time. We design and
characterize various control policies, and formulate the optimal control
problem using a Markov Decision Process (MDP) with a probabilistic constraint.
We present a characterization of the optimal policy using the
Hamilton-Jacobi-Bellman (HJB) equation. For a fluid approximation model, we
provide an exact and explicit characterization of a threshold policy and prove
its optimality using the HJB equation.
  Our simulation results show that under properly designed control policy, the
existence of alternative access technology as a complement for a primary access
network can significantly improve the user experience without any bandwidth
over-provisioning.
"
334,Experimenting with the Novel Approaches in Text Steganography,"  As is commonly known, the steganographic algorithms employ images, audio,
video or text files as the medium to ensure hidden exchange of information
between multiple contenders to protect the data from the prying eyes. However,
using text as the target medium is relatively difficult as compared to the
other target media, because of the lack of available redundant information in a
text file. In this paper, in the backdrop of the limitations in the prevalent
text based steganographic approaches, we propose simple, yet novel approaches
that overcome the same. Our approaches are based on combining the random
character sequence and feature coding methods to hide a character. We also
analytically evaluate the approaches based on metrics viz. hiding strength,
time overhead and memory overhead entailed. As compared to other methods, we
believe the approaches proposed impart increased randomness and thus aid higher
security at lower overhead.
"
335,"Quantitative Multiscale Analysis using Different Wavelets in 1D Voice
  Signal and 2D Image","  Mutiscale analysis represents multiresolution scrutiny of a signal to improve
its signal quality. Multiresolution analysis of 1D voice signal and 2D image is
conducted using DCT, FFT and different wavelets such as Haar, Deubachies,
Morlet, Cauchy, Shannon, Biorthogonal, Symmlet and Coiflet deploying the
cascaded filter banks based decomposition and reconstruction. The outstanding
quantitative analysis of the specified wavelets is done to investigate the
signal quality, mean square error, entropy and peak-to-peak SNR at multiscale
stage-4 for both 1D voice signal and 2D image. In addition, the 2D image
compression performance is significantly found 93.00% in DB-4, 93.68% in
bior-4.4, 93.18% in Sym-4 and 92.20% in Coif-2 during the multiscale analysis.
"
336,VoIP Steganography and Its Detection - A Survey,"  Steganography is an ancient art that encompasses various techniques of
information hiding, the aim of which is to secret information into a carrier
message. Steganographic methods are usually aimed at hiding the very existence
of the communication. Due to the rise in popularity of IP telephony, together
with the large volume of data and variety of protocols involved, it is
currently attracting the attention of the research community as a perfect
carrier for steganographic purposes. This paper is a survey of the existing
VoIP steganography (steganophony) methods and their countermeasures.
"
337,Compressed Sensing for Moving Imagery in Medical Imaging,"  Numerous applications in signal processing have benefited from the theory of
compressed sensing which shows that it is possible to reconstruct signals
sampled below the Nyquist rate when certain conditions are satisfied. One of
these conditions is that there exists a known transform that represents the
signal with a sufficiently small number of non-zero coefficients. However when
the signal to be reconstructed is composed of moving images or volumes, it is
challenging to form such regularization constraints with traditional transforms
such as wavelets. In this paper, we present a motion compensating prior for
such signals that is derived directly from the optical flow constraint and can
utilize the motion information during compressed sensing reconstruction.
Proposed regularization method can be used in a wide variety of applications
involving compressed sensing and images or volumes of moving and deforming
objects. It is also shown that it is possible to estimate the signal and the
motion jointly or separately. Practical examples from magnetic resonance
imaging has been presented to demonstrate the benefit of the proposed method.
"
338,"I-SolFramework: An Integrated Solution Framework Six Layers Assessment
  on Multimedia Information Security Architecture Policy Compliance","  Multimedia Information security becomes a important part for the
organization's intangible assets. Level of confidence and stakeholder trusted
are performance indicator as successes organization, it is imperative for
organizations to use Information Security Management System (ISMS) to
effectively manage their multimedia information assets. The main objective of
this paper is to Provide a novel practical framework approach to the
development of ISMS, Called by the I-SolFramework, implemented in multimedia
information security architecture (MISA), it divides a problem into six object
domains or six layers, namely organization,stakeholders, tool & technology,
policy, knowledge, and culture. In addition, this framework also introduced
novelty algorithm and mathematic models as measurement and assessment tools of
MISA parameters.
"
339,Query Language for Complex Similarity Queries,"  For complex data types such as multimedia, traditional data management
methods are not suitable. Instead of attribute matching approaches, access
methods based on object similarity are becoming popular. Recently, this
resulted in an intensive research of indexing and searching methods for the
similarity-based retrieval. Nowadays, many efficient methods are already
available, but using them to build an actual search system still requires
specialists that tune the methods and build the system manually. Several
attempts have already been made to provide a more convenient high-level
interface in a form of query languages for such systems, but these are limited
to support only basic similarity queries. In this paper, we propose a new
language that allows to formulate content-based queries in a flexible way,
taking into account the functionality offered by a particular search engine in
use. To ensure this, the language is based on a general data model with an
abstract set of operations. Consequently, the language supports various
advanced query operations such as similarity joins, reverse nearest neighbor
queries, or distinct kNN queries, as well as multi-object and multi-modal
queries. The language is primarily designed to be used with the MESSIF
framework for content-based searching but can be employed by other retrieval
systems as well.
"
340,Online multipath convolutional coding for real-time transmission,"  Most of multipath multimedia streaming proposals use Forward Error Correction
(FEC) approach to protect from packet losses. However, FEC does not sustain
well burst of losses even when packets from a given FEC block are spread over
multiple paths. In this article, we propose an online multipath convolutional
coding for real-time multipath streaming based on an on-the-fly coding scheme
called Tetrys. We evaluate the benefits brought out by this coding scheme
inside an existing FEC multipath load splitting proposal known as Encoded
Multipath Streaming (EMS). We demonstrate that Tetrys consistently outperforms
FEC in both uniform and burst losses with EMS scheme. We also propose a
modification of the standard EMS algorithm that greatly improves the
performance in terms of packet recovery. Finally, we analyze different
spreading policies of the Tetrys redundancy traffic between available paths and
observe that the longer propagation delay path should be preferably used to
carry repair packets.
"
341,User-based key frame detection in social web video,"  Video search results and suggested videos on web sites are represented with a
video thumbnail, which is manually selected by the video up-loader among three
randomly generated ones (e.g., YouTube). In contrast, we present a grounded
user-based approach for automatically detecting interesting key-frames within a
video through aggregated users' replay interactions with the video player.
Previous research has focused on content-based systems that have the benefit of
analyzing a video without user interactions, but they are monolithic, because
the resulting video thumbnails are the same regardless of the user preferences.
We constructed a user interest function, which is based on aggregate video
replays, and analyzed hundreds of user interactions. We found that the local
maximum of the replaying activity stands for the semantics of information rich
videos, such as lecture, and how-to. The concept of user-based key-frame
detection could be applied to any video on the web, in order to generate a
user-based and dynamic video thumbnail in search results.
"
342,"Simplification Resilient LDPC-Coded Sparse-QIM Watermarking for
  3D-Meshes","  We propose a blind watermarking scheme for 3-D meshes which combines sparse
quantization index modulation (QIM) with deletion correction codes. The QIM
operates on the vertices in rough concave regions of the surface thus ensuring
impeccability, while the deletion correction code recovers the data hidden in
the vertices which is removed by mesh optimization and/or simplification. The
proposed scheme offers two orders of magnitude better performance in terms of
recovered watermark bit error rate compared to the existing schemes of similar
payloads and fidelity constraints.
"
343,"An Overview of Video Allocation Algorithms for Flash-based SSD Storage
  Systems","  Despite the fact that Solid State Disk (SSD) data storage media had offered a
revolutionary property storages community, but the unavailability of a
comprehensive allocation strategy in SSDs storage media, leads to consuming the
available space, random writing processes, time-consuming reading processes,
and system resources consumption. In order to overcome these challenges, an
efficient allocation algorithm is a desirable option. In this paper, we had
executed an intensive investigation on the SSD-based allocation algorithms that
had been proposed by the knowledge community. An explanatory comparison had
been made between these algorithms. We reviewed these algorithms in order to
building advanced knowledge armature that would help in inventing new
allocation algorithms for this type of storage media.
"
344,"Genetic Algorithm to Make Persistent Security and Quality of Image in
  Steganography from RS Analysis","  Retention of secrecy is one of the significant features during communication
activity. Steganography is one of the popular methods to achieve secret
communication between sender and receiver by hiding message in any form of
cover media such as an audio, video, text, images etc. Least significant bit
encoding is the simplest encoding method used by many steganography programs to
hide secret message in 24bit, 8bit colour images and grayscale images.
Steganalysis is a method of detecting secret message hidden in a cover media
using steganography. RS steganalysis is one of the most reliable steganalysis
which performs statistical analysis of the pixels to successfully detect the
hidden message in an image. However, existing steganography method protects the
information against RS steganalysis in grey scale images. This paper presents a
steganography method using genetic algorithm to protect against the RS attack
in colour images. Stego image is divided into number of blocks. Subsequently,
with the implementation of natural evolution on the stego image using genetic
algorithm enables to achieve optimized security and image quality.
"
345,Rateless Codes with Progressive Recovery for Layered Multimedia Delivery,"  This paper proposes a novel approach, based on unequal error protection, to
enhance rateless codes with progressive recovery for layered multimedia
delivery. With a parallel encoding structure, the proposed Progressive Rateless
codes (PRC) assign unequal redundancy to each layer in accordance with their
importance. Each output symbol contains information from all layers, and thus
the stream layers can be recovered progressively at the expected received
ratios of output symbols. Furthermore, the dependency between layers is
naturally considered. The performance of the PRC is evaluated and compared with
some related UEP approaches. Results show that our PRC approach provides better
recovery performance with lower overhead both theoretically and numerically.
"
346,"Compensating Interpolation Distortion by Using New Optimized Modular
  Method","  A modular method was suggested before to recover a band limited signal from
the sample and hold and linearly interpolated (or, in general, an
nth-order-hold) version of the regular samples. In this paper a novel approach
for compensating the distortion of any interpolation based on modular method
has been proposed. In this method the performance of the modular method is
optimized by adding only some simply calculated coefficients. This approach
causes drastic improvement in terms of signal-to-noise ratios with fewer
modules compared to the classical modular method. Simulation results clearly
confirm the improvement of the proposed method and also its superior robustness
against additive noise.
"
347,"Efficient Video Indexing on the Web: A System that Leverages User
  Interactions with a Video Player","  In this paper, we propose a user-based video indexing method, that
automatically generates thumbnails of the most important scenes of an online
video stream, by analyzing users' interactions with a web video player. As a
test bench to verify our idea we have extended the YouTube video player into
the VideoSkip system. In addition, VideoSkip uses a web-database (Google
Application Engine) to keep a record of some important parameters, such as the
timing of basic user actions (play, pause, skip). Moreover, we implemented an
algorithm that selects representative thumbnails. Finally, we populated the
system with data from an experiment with nine users. We found that the
VideoSkip system indexes video content by leveraging implicit users
interactions, such as pause and thirty seconds skip. Our early findings point
toward improvements of the web video player and its thumbnail generation
technique. The VideSkip system could compliment content-based algorithms, in
order to achieve efficient video-indexing in difficult videos, such as lectures
or sports.
"
348,Image Enhancement with Statistical Estimation,"  Contrast enhancement is an important area of research for the image analysis.
Over the decade, the researcher worked on this domain to develop an efficient
and adequate algorithm. The proposed method will enhance the contrast of image
using Binarization method with the help of Maximum Likelihood Estimation (MLE).
The paper aims to enhance the image contrast of bimodal and multi-modal images.
The proposed methodology use to collect mathematical information retrieves from
the image. In this paper, we are using binarization method that generates the
desired histogram by separating image nodes. It generates the enhanced image
using histogram specification with binarization method. The proposed method has
showed an improvement in the image contrast enhancement compare with the other
image.
"
349,Content based video retrieval systems,"  With the development of multimedia data types and available bandwidth there
is huge demand of video retrieval systems, as users shift from text based
retrieval systems to content based retrieval systems. Selection of extracted
features play an important role in content based video retrieval regardless of
video attributes being under consideration. These features are intended for
selecting, indexing and ranking according to their potential interest to the
user. Good features selection also allows the time and space costs of the
retrieval process to be reduced. This survey reviews the interesting features
that can be extracted from video data for indexing and retrieval along with
similarity measurement methods. We also identify present research issues in
area of content based video retrieval systems.
"
350,Text Steganography using LSB insertion method along with Chaos Theory,"  The art of information hiding has been around nearly as long as the need for
covert communication. Steganography, the concealing of information, arose early
on as an extremely useful method for covert information transmission.
Steganography is the art of hiding secret message within a larger image or
message such that the hidden message or an image is undetectable; this is in
contrast to cryptography, where the existence of the message itself is not
disguised, but the content is obscure. The goal of a steganographic method is
to minimize the visually apparent and statistical differences between the cover
data and a steganogram while maximizing the size of the payload. Current
digital image steganography presents the challenge of hiding message in a
digital image in a way that is robust to image manipulation and attack. This
paper explains about how a secret message can be hidden into an image using
least significant bit insertion method along with chaos.
"
351,"An Adaptive Watermarking Technique for the copyright of digital images
  and Digital Image Protection","  The Internet as a whole does not use secure links, thus information in
transit may be vulnerable to interruption as well. The important of reducing a
chance of the information being detected during the transmission is being an
issue in the real world now days. The Digital watermarking method provides for
the quick and inexpensive distribution of digital information over the
Internet. This method provides new ways of ensuring the sufficient protection
of copyright holders in the intellectual property dispersion process. The
property of digital watermarking images allows insertion of additional data in
the image without altering the value of the image.In this paper investigate the
following relevant concepts and terminology, history of watermarks and the
properties of a watermarking system and applications. We are proposing edge
detection using Gabor Filters. In this paper we are proposed least significant
bit (LSB) substitution method to encrypt the message in the watermark image
file. The benefits of the LSB are its simplicity to embed the bits of the
message directly into the LSB plane of cover-image and many techniques using
these methods. The LSB does not result in a human perceptible difference
because the amplitude of the change is little therefore the human eye the
resulting stego image will look identical to the cover image and this allows
high perceptual transparency of the LSB. The spatial domain technique LSB
substitution it would be able to use a pseudo-random number generator to
determine the pixels to be used for embedding based on a given key. We are
using DCT transform watermark algorithms based on robustness. The watermarking
robustness have been calculated by the Peak Signal to Noise Ratio (PSNR) and
Normalized cross correlation (NC) is used to quantify by the similarity between
the real watermark and after extracting watermark.
"
352,"Transference & Retrieval of Pulse-code modulation Audio over Short
  Messaging Service","  The paper presents the method of transferring PCM (Pulse-Code Modulation)
based audio messages through SMS (Short Message Service) over GSM (Global
System for Mobile Communications) network. As SMS is text based service, and
could not send voice. Our method enables voice transferring through SMS, by
converting PCM audio into characters. Than Huffman coding compression technique
is applied in order to reduce numbers of characters which will latterly set as
payload text of SMS. Testing the said method we develop an application using
J2me platform
"
353,ISWAR: An Imaging System with Watermarking and Attack Resilience,"  With the explosive growth of internet technology, easy transfer of digital
multimedia is feasible. However, this kind of convenience with which authorized
users can access information, turns out to be a mixed blessing due to
information piracy. The emerging field of Digital Rights Management (DRM)
systems addresses issues related to the intellectual property rights of digital
content. In this paper, an object-oriented (OO) DRM system, called ""Imaging
System with Watermarking and Attack Resilience"" (ISWAR), is presented that
generates and authenticates color images with embedded mechanisms for
protection against infringement of ownership rights as well as security
attacks. In addition to the methods, in the object-oriented sense, for
performing traditional encryption and decryption, the system implements methods
for visible and invisible watermarking. This paper presents one visible and one
invisible watermarking algorithm that have been integrated in the system. The
qualitative and quantitative results obtained for these two watermarking
algorithms with several benchmark images indicate that high-quality watermarked
images are produced by the algorithms. With the help of experimental results it
is demonstrated that the presented invisible watermarking techniques are
resilient to the well known benchmark attacks and hence a fail-safe method for
providing constant protection to ownership rights.
"
354,"A Novel Video Compression Approach Based on Underdetermined Blind Source
  Separation","  This paper develops a new video compression approach based on underdetermined
blind source separation. Underdetermined blind source separation, which can be
used to efficiently enhance the video compression ratio, is combined with
various off-the-shelf codecs in this paper. Combining with MPEG-2, video
compression ratio could be improved slightly more than 33%. As for combing with
H.264, 4X~12X more compression ratio could be achieved with acceptable PSNR,
according to different kinds of video sequences.
"
355,Measuring the evolution of contemporary western popular music,"  Popular music is a key cultural expression that has captured listeners'
attention for ages. Many of the structural regularities underlying musical
discourse are yet to be discovered and, accordingly, their historical evolution
remains formally unknown. Here we unveil a number of patterns and metrics
characterizing the generic usage of primary musical facets such as pitch,
timbre, and loudness in contemporary western popular music. Many of these
patterns and metrics have been consistently stable for a period of more than
fifty years, thus pointing towards a great degree of conventionalism.
Nonetheless, we prove important changes or trends related to the restriction of
pitch transitions, the homogenization of the timbral palette, and the growing
loudness levels. This suggests that our perception of the new would be rooted
on these changing characteristics. Hence, an old tune could perfectly sound
novel and fashionable, provided that it consisted of common harmonic
progressions, changed the instrumentation, and increased the average loudness.
"
356,Signal and Image Processing with Sinlets,"  This paper presents a new family of localized orthonormal bases - sinlets -
which are well suited for both signal and image processing and analysis.
One-dimensional sinlets are related to specific solutions of the time-dependent
harmonic oscillator equation. By construction, each sinlet is infinitely
differentiable and has a well-defined and smooth instantaneous frequency known
in analytical form. For square-integrable transient signals with infinite
support, one-dimensional sinlet basis provides an advantageous alternative to
the Fourier transform by rendering accurate signal representation via a
countable set of real-valued coefficients. The properties of sinlets make them
suitable for analyzing many real-world signals whose frequency content changes
with time including radar and sonar waveforms, music, speech, biological
echolocation sounds, biomedical signals, seismic acoustic waves, and signals
employed in wireless communication systems. One-dimensional sinlet bases can be
used to construct two- and higher-dimensional bases with variety of potential
applications including image analysis and representation.
"
357,"Perceptual quality comparison between single-layer and scalable videos
  at the same spatial, temporal and amplitude resolutions","  In this paper, the perceptual quality difference between scalable and
single-layer videos coded at the same spatial, temporal and amplitude
resolution (STAR) is investigated through a subjective test using a mobile
platform. Three source videos are considered and for each source video
single-layer and scalable video are compared at 9 different STARs. We utilize
paired comparison methods with and without tie option. Results collected from
10 subjects in the without ""tie"" option and 6 subjects in the with ""tie"" option
show that there is no significant quality difference between scalable and
singlelayer video when coded at the same STAR. An analysis of variance (ANOVA)
test is also performed to further confirm the finding.
"
358,MediaWise - Designing a Smart Media Cloud,"  The MediaWise project aims to expand the scope of existing media delivery
systems with novel cloud, personalization and collaboration capabilities that
can serve the needs of more users, communities, and businesses. The project
develops a MediaWise Cloud platform that supports do-it-yourself creation,
search, management, and consumption of multimedia content. The MediaWise Cloud
supports pay-as-you-go models and elasticity that are similar to those offered
by commercially available cloud services. However, unlike existing commercial
CDN services providers such as Limelight Networks and Akamai the MediaWise
Cloud require no ownerships of computing infrastructure and instead rely on the
public Internet and public cloud services (e.g., commercial cloud storage to
store its content). In addition to integrating such public cloud services into
a public cloud-based Content Delivery Network, the MediaWise Cloud also
provides advanced Quality of Service (QoS) management as required for the
delivery of streamed and interactive high resolution multimedia content. In
this paper, we give a brief overview of MediaWise Cloud architecture and
present a comprehensive discussion on research objectives related to its
service components. Finally, we also compare the features supported by the
existing CDN services against the envisioned objectives of MediaWise Cloud.
"
359,"Q-STAR:A Perceptual Video Quality Model Considering Impact of Spatial,
  Temporal, and Amplitude Resolutions","  In this paper, we investigate the impact of spatial, temporal and amplitude
resolution (STAR) on the perceptual quality of a compressed video. Subjective
quality tests were carried out on a mobile device. Seven source sequences are
included in the tests and for each source sequence we have 27 test
configurations generated by JSVM encoder (3 QP levels, 3 spatial resolutions,
and 3 temporal resolutions), resulting a total of 189 processed video sequences
(PVSs). Videos coded at different spatial resolutions are displayed at the full
screen size of the mobile platform. Subjective data reveal that the impact of
spatial resolution (SR), temporal resolution (TR) and quantization stepsize
(QS) can each be captured by a function with a single content-dependent
parameter. The joint impact of SR, TR and QS can be accurately modeled by the
product of these three functions with only three parameters. We further find
that the quality decay rates with SR and QS, respectively are independent of
TR, and likewise, the decay rate with TR is independent of SR and QS,
respectively. However, there is a significant interaction between the effects
of SR and QS. The overall quality model is further validated on five other
datasets with very high accuracy. The complete model correlates well with the
subjective ratings with a Pearson Correlation Coefficient (PCC) of 0.991.
"
360,"Architecture for Automated Tagging and Clustering of Song Files
  According to Mood","  Music is one of the basic human needs for recreation and entertainment. As
song files are digitalized now a days, and digital libraries are expanding
continuously, which makes it difficult to recall a song. Thus need of a new
classification system other than genre is very obvious and mood based
classification system serves the purpose very well. In this paper we will
present a well-defined architecture to classify songs into different mood-based
categories, using audio content analysis, affective value of song lyrics to map
a song onto a psychological-based emotion space and information from online
sources. In audio content analysis we will use music features such as
intensity, timbre and rhythm including their subfeatures to map music in a
2-Dimensional emotional space. In lyric based classification 1-Dimensional
emotional space is used. Both the results are merged onto a 2-Dimensional
emotional space, which will classify song into a particular mood category.
Finally clusters of mood based song files are formed and arranged according to
data acquired from various Internet sources.
"
361,"Generic Subsequence Matching Framework: Modularity, Flexibility,
  Efficiency","  Subsequence matching has appeared to be an ideal approach for solving many
problems related to the fields of data mining and similarity retrieval. It has
been shown that almost any data class (audio, image, biometrics, signals) is or
can be represented by some kind of time series or string of symbols, which can
be seen as an input for various subsequence matching approaches. The variety of
data types, specific tasks and their partial or full solutions is so wide that
the choice, implementation and parametrization of a suitable solution for a
given task might be complicated and time-consuming; a possibly fruitful
combination of fragments from different research areas may not be obvious nor
easy to realize. The leading authors of this field also mention the
implementation bias that makes difficult a proper comparison of competing
approaches. Therefore we present a new generic Subsequence Matching Framework
(SMF) that tries to overcome the aforementioned problems by a uniform frame
that simplifies and speeds up the design, development and evaluation of
subsequence matching related systems. We identify several relatively separate
subtasks solved differently over the literature and SMF enables to combine them
in straightforward manner achieving new quality and efficiency. This framework
can be used in many application domains and its components can be reused
effectively. Its strictly modular architecture and openness enables also
involvement of efficient solutions from different fields, for instance
efficient metric-based indexes. This is an extended version of a paper
published on DEXA 2012.
"
362,"Rate Model for Compressed Video Considering Impacts Of Spatial, Temporal
  and Amplitude Resolutions and Its Applications for Video Coding and
  Adaptation","  In this paper, we investigate the impacts of spatial, temporal and amplitude
resolution (STAR) on the bit rate of a compressed video. We propose an
analytical rate model in terms of the quantization stepsize, frame size and
frame rate. Experimental results reveal that the increase of the video rate as
the individual resolution increases follows a power function. Hence, the
proposed model expresses the rate as the product of power functions of the
quantization stepsize, frame size and frame rate, respectively. The proposed
rate model is analytically tractable, requiring only four content dependent
parameters. We also propose methods for predicting the model parameters from
content features that can be computed from original video. Simulation results
show that model predicted rates fit the measured data very well with high
Pearson correlation (PC) and small relative root mean square error (RRMSE). The
same model function works for different coding scenarios (including scalable
and non-scalable video, temporal prediction using either hierarchical B or IPPP
structure, etc.) with very high accuracy (average PC $>$ 0.99), but the values
of model parameters differ. Using the proposed rate model and the quality model
introduced in a separate work, we show how to optimize the STAR for a given
rate constraint, which is important for both encoder rate control and scalable
video adaptation. Furthermore, we demonstrate how to order the spatial,
temporal and amplitude layers of a scalable video in a rate-quality optimized
way.
"
363,"Topological study and Lyapunov exponent of a secure steganographic
  scheme","  CIS2 is a steganographic scheme proposed in the information hiding
literature, belonging into the small category of algorithms being both stego
and topologically secure. Due to its stego-security, this scheme is able to
face attacks that take place into the ""watermark only attack"" framework. Its
topological security reinforce its capability to face attacks in other
frameworks as ""known message attack"" or ""known original attack"", in the
Simmons' prisoner problem. In this research work, the study of topological
properties of C I S 2 is enlarged by describing this scheme as iterations over
the real line, and investigating other security properties of topological
nature as the Lyapunov exponent. Results show that this scheme is able to
withdraw a malicious attacker in the ""estimated original attack"" context too.
"
364,"A Novel Effective, Secure and Robust CDMA Digital Image Watermarking in
  YUV Color Space Using DWT2","  This paper is allocated to CDMA digital images watermarking for ownership
verification and image authentication applications, which for more security,
watermark W is converted to a sequence and then a random binary sequence R of
size n is adopted to encrypt the watermark; where n is the size of the
watermark. This adopting process uses a pseudo-random number generator to
determine the pixel to be used on a given key. After converting the host image
to YUV color space and then wavelet decomposition of Y channel, this adopted
watermark is embedded into the selected subbands coefficients of Y channel
using the correlation properties of additive pseudo- random noise patterns. The
experimental results show that the proposed approach provides extra
imperceptibility, security and robustness against JPEG compression and
different noises attacks compared to the similar proposed methods. Moreover,
the proposed approach has no need of the original image to extract watermarks.
"
365,Joint Reconstruction of Multi-view Compressed Images,"  The distributed representation of correlated multi-view images is an
important problem that arise in vision sensor networks. This paper concentrates
on the joint reconstruction problem where the distributively compressed
correlated images are jointly decoded in order to improve the reconstruction
quality of all the compressed images. We consider a scenario where the images
captured at different viewpoints are encoded independently using common coding
solutions (e.g., JPEG, H.264 intra) with a balanced rate distribution among
different cameras. A central decoder first estimates the underlying correlation
model from the independently compressed images which will be used for the joint
signal recovery. The joint reconstruction is then cast as a constrained convex
optimization problem that reconstructs total-variation (TV) smooth images that
comply with the estimated correlation model. At the same time, we add
constraints that force the reconstructed images to be consistent with their
compressed versions. We show by experiments that the proposed joint
reconstruction scheme outperforms independent reconstruction in terms of image
quality, for a given target bit rate. In addition, the decoding performance of
our proposed algorithm compares advantageously to state-of-the-art distributed
coding schemes based on disparity learning and on the DISCOVER.
"
366,Improved DWT Based Watermarking Using JPEG-YCbCr,"  In this paper a blind, Secure, imperceptible and robust watermarking
algorithm based on wavelet transform domain is proposed in which for more
security, the watermark W is converted to a sequence and then a random binary
sequence R of size n is adopted to encrypt the watermark, where n is the size
of the watermark image. Afterwards, the encrypted watermark sequence W1 is
generated by executing exclusive-OR operation on W and R. This generated
watermark embeds into low frequency selected coefficients of Y channel wavelet
decomposition of JPEG-YCbCr using LSB insertion technique. The experimental
results show that the proposed algorithm increases the security and
imperceptibility of watermark and has better robustness against wavelet
compression and cropping attacks compared to the earlier work in [1].
"
367,"Effective Digital Image Watermarking in YCbCr Color Space Accompanied by
  Presenting a Novel Technique Using DWT","  In this paper, a quantization based watermark casting and blind watermark
retrieval algorithm operating in YCbCr color space using discrete wavelet
transform (DWT), for ownership verification and image authentication
applications is implemented. This method uses implicit visual masking by
inserting watermark bits into only the wavelet coefficients of high magnitude,
in Y channel of YCbCr color space. A blind watermark retrieval technique that
can detect the embedded watermark without the help from the original
uncorrupted image is devised which is computationally efficient. The new
watermarking algorithm combines and adapts various aspects from existing
watermarking methods. Experimental results show that the proposed technique to
embed watermark provides extra imperceptibility and robustness against various
signal processing attacks in comparison with the same technique in RGB color
space.
"
368,"A Comparison between Digital Image Watermarking in Tow Different Color
  Spaces Using DWT2","  A novel digital watermarking for ownership verification and image
authentication applications using discrete wavelet transform (DWT) is proposed
in this paper. Most previous proposed watermarking algorithms embed sequences
of random numbers as watermarks. Here binary images are taken as watermark for
embedding. In the proposed approach, the host image is converted into the YCbCr
color space and then its Y channel decomposed into wavelet coefficients. The
selected approximation coefficients are quantized and then their four least
significant bits of the quantized coefficients are replaced by the watermark
using LSB insertion technique. At last, the watermarked image is synthesized
from the changed and unchanged DWT coefficients. The experiments show that the
proposed approach provides extra imperceptibility and robustness against
wavelet compression compared to the traditional embedding methods in RGB color
space. Moreover, the proposed approach has no need of the original image to
extract watermarks.
"
369,Bayesian Watermark Attacks,"  This paper presents an application of statistical machine learning to the
field of watermarking. We propose a new attack model on additive
spread-spectrum watermarking systems. The proposed attack is based on Bayesian
statistics. We consider the scenario in which a watermark signal is repeatedly
embedded in specific, possibly chosen based on a secret message bitstream,
segments (signals) of the host data. The host signal can represent a patch of
pixels from an image or a video frame. We propose a probabilistic model that
infers the embedded message bitstream and watermark signal, directly from the
watermarked data, without access to the decoder. We develop an efficient Markov
chain Monte Carlo sampler for updating the model parameters from their
conjugate full conditional posteriors. We also provide a variational Bayesian
solution, which further increases the convergence speed of the algorithm.
Experiments with synthetic and real image signals demonstrate that the attack
model is able to correctly infer a large part of the message bitstream and
obtain a very accurate estimate of the watermark signal.
"
370,PAC-Bayesian Majority Vote for Late Classifier Fusion,"  A lot of attention has been devoted to multimedia indexing over the past few
years. In the literature, we often consider two kinds of fusion schemes: The
early fusion and the late fusion. In this paper we focus on late classifier
fusion, where one combines the scores of each modality at the decision level.
To tackle this problem, we investigate a recent and elegant well-founded
quadratic program named MinCq coming from the Machine Learning PAC-Bayes
theory. MinCq looks for the weighted combination, over a set of real-valued
functions seen as voters, leading to the lowest misclassification rate, while
making use of the voters' diversity. We provide evidence that this method is
naturally adapted to late fusion procedure. We propose an extension of MinCq by
adding an order- preserving pairwise loss for ranking, helping to improve Mean
Averaged Precision measure. We confirm the good behavior of the MinCq-based
fusion approaches with experiments on a real image benchmark.
"
371,Improvement of ISOM by using filter,"  Image compression helps in storing the transmitted data in proficient way by
decreasing its redundancy. This technique helps in transferring more digital or
multimedia data over internet as it increases the storage space. It is
important to maintain the image quality even if it is compressed to certain
extent. Depend upon this the image compression is classified into two
categories : lossy and lossless image compression. There are many lossy digital
image compression techniques exists. Among this Incremental Self Organizing Map
is a familiar one. The good pictures quality can be retrieved if image
denoising technique is used for compression and also provides better
compression ratio. Image denoising is an important pre-processing step for many
image analysis and computer vision system. It refers to the task of recovering
a good estimate of the true image from a degraded observation without altering
and changing useful structure in the image such as discontinuities and edges.
Many approaches have been proposed to remove the noise effectively while
preserving the original image details and features as much as possible. This
paper proposes a technique for image compression using Incremental Self
Organizing Map (ISOM) with Discret Wavelet Transform (DWT) by applying
filtering techniques which play a crucial role in enhancing the quality of a
reconstructed image. The experimental result shows that the proposed technique
obtained better compression ratio value.
"
372,"Erasure Coding and Congestion Control for Interactive Real-Time
  Communication","  The use of real-time applications over the Internet is a challenging problem
that the QoS epoch attempted to solve by proposing the DiffServ architecture.
Today, the only existing service provided by the Internet is still best-effort.
As a result, multimedia applications often perform on top of a transport layer
that provides a variable sending rate. In an obvious manner, this variable
sending rate is an issue for these applications with strong delay constraint.
In a real-time context where retransmission can not be used to ensure
reliability, video quality suffers from any packet losses. In this position
paper, we discuss this problem and motivate why we want to bring out a certain
class of erasure coding scheme inside multimedia congestion control protocols
such as TFRC.
"
373,Real-Time Peer-to-Peer Streaming Over Multiple Random Hamiltonian Cycles,"  We are motivated by the problem of designing a simple distributed algorithm
for Peer-to-Peer streaming applications that can achieve high throughput and
low delay, while allowing the neighbor set maintained by each peer to be small.
While previous works have mostly used tree structures, our algorithm constructs
multiple random directed Hamiltonian cycles and disseminates content over the
superposed graph of the cycles. We show that it is possible to achieve the
maximum streaming capacity even when each peer only transmits to and receives
from Theta(1) neighbors. Further, we show that the proposed algorithm achieves
the streaming delay of Theta(log N) when the streaming rate is less than
(1-1/K) of the maximum capacity for any fixed integer K>1, where N denotes the
number of peers in the network. The key theoretical contribution is to
characterize the distance between peers in a graph formed by the superposition
of directed random Hamiltonian cycles, in which edges from one of the cycles
may be dropped at random. We use Doob martingales and graph expansion ideas to
characterize this distance as a function of N, with high probability.
"
374,"Usability, Design and Content Issues of Mobile Apps for Cultural
  Heritage Promotion: The Malta Culture Guide Experience","  The paper discusses the experience of producing and distributing an iPhone
app for promotion of the Maltese Cultural Heritage on behalf of the Malta
Tourism Authority. Thanks to its position at the heart of the Mediterranean
Sea, Malta has been a crossroads of civilisations whose traces are still
visible today, leaving a particularly rich and varied cultural heritage, from
megalithic temples to baroque palaces and Caravaggio masterpieces. Conveying
all these different aspects within a single application, using textual, visual,
and audio means, has raised many different issues about the planning and
production of cultural content for mobile usage, together with usability
aspects regarding design and distribution of a mobile app. In this paper, we
outline all of these aspects, focusing on the design and planning strategies
for a long-term user commitment and how to evaluate results for cultural mobile
applications. We include experience of all the steps of developing a mobile
app, information that is of possible benefit to other app developers in the
cultural sector.
"
375,Streaming Codes for Channels with Burst and Isolated Erasures,"  We study low-delay error correction codes for streaming recovery over a class
of packet-erasure channels that introduce both burst-erasures and isolated
erasures. We propose a simple, yet effective class of codes whose parameters
can be tuned to obtain a tradeoff between the capability to correct burst and
isolated erasures. Our construction generalizes previously proposed low-delay
codes which are effective only against burst erasures. We establish an
information theoretic upper bound on the capability of any code to
simultaneously correct burst and isolated erasures and show that our proposed
constructions meet the upper bound in some special cases. We discuss the
operational significance of column-distance and column-span metrics and
establish that the rate 1/2 codes discovered by Martinian and Sundberg [IT
Trans.\, 2004] through a computer search indeed attain the optimal
column-distance and column-span tradeoff. Numerical simulations over a
Gilbert-Elliott channel model and a Fritchman model show significant
performance gains over previously proposed low-delay codes and random linear
codes for certain range of channel parameters.
"
376,A Session based Multiple Image Hiding Technique using DWT and DCT,"  This work proposes Steganographic technique for hiding multiple images in a
color image based on DWT and DCT. The cover image is decomposed into three
separate color planes namely R, G and B. Individual planes are decomposed into
subbands using DWT. DCT is applied in HH component of each plane. Secret images
are dispersed among the selected DCT coefficients using a pseudo random
sequence and a Session key. Secret images are extracted using the session key
and the size of the images from the planer decomposed stego image. In this
approach the stego image generated is of acceptable level of imperceptibility
and distortion compared to the cover image and the overall security is high.
"
377,"Analysis of a Modern Voice Morphing Approach using Gaussian Mixture
  Models for Laryngectomees","  This paper proposes a voice morphing system for people suffering from
Laryngectomy, which is the surgical removal of all or part of the larynx or the
voice box, particularly performed in cases of laryngeal cancer. A primitive
method of achieving voice morphing is by extracting the source's vocal
coefficients and then converting them into the target speaker's vocal
parameters. In this paper, we deploy Gaussian Mixture Models (GMM) for mapping
the coefficients from source to destination. However, the use of the
traditional/conventional GMM-based mapping approach results in the problem of
over-smoothening of the converted voice. Thus, we hereby propose a unique
method to perform efficient voice morphing and conversion based on GMM,which
overcomes the traditional-method effects of over-smoothening. It uses a
technique of glottal waveform separation and prediction of excitations and
hence the result shows that not only over-smoothening is eliminated but also
the transformed vocal tract parameters match with the target. Moreover, the
synthesized speech thus obtained is found to be of a sufficiently high quality.
Thus, voice morphing based on a unique GMM approach has been proposed and also
critically evaluated based on various subjective and objective evaluation
parameters. Further, an application of voice morphing for Laryngectomees which
deploys this unique approach has been recommended by this paper.
"
378,"Stereo Acoustic Perception based on Real Time Video Acquisition for
  Navigational Assistance","  A smart navigation system (an Electronic Travel Aid) based on an object
detection mechanism has been designed to detect the presence of obstacles that
immediately impede the path, by means of real time video processing. The
algorithm can be used for any general purpose navigational aid. This paper is
discussed, keeping in mind the navigation of the visually impaired, and is not
limited to the same. A video camera feeds images of the surroundings to a Da-
Vinci Digital Media Processor, DM642, which works on the video, frame by frame.
The processor carries out image processing techniques whose result contains
information about the object in terms of image pixels. The algorithm aims to
select the object which, among all others, poses maximum threat to the
navigation. A database containing a total of three sounds is constructed.
Hence, each image translates to a beep, where every beep informs the navigator
of the obstacles directly in front of him. This paper implements an algorithm
that is more efficient as compared to its predecessors.
"
379,Social Event Detection with Interaction Graph Modeling,"  This paper focuses on detecting social, physical-world events from photos
posted on social media sites. The problem is important: cheap media capture
devices have significantly increased the number of photos shared on these
sites. The main contribution of this paper is to incorporate online social
interaction features in the detection of physical events. We believe that
online social interaction reflect important signals among the participants on
the ""social affinity"" of two photos, thereby helping event detection. We
compute social affinity via a random-walk on a social interaction graph to
determine similarity between two photos on the graph. We train a support vector
machine classifier to combine the social affinity between photos and
photo-centric metadata including time, location, tags and description.
Incremental clustering is then used to group photos to event clusters. We have
very good results on two large scale real-world datasets: Upcoming and
MediaEval. We show an improvement between 0.06-0.10 in F1 on these datasets.
"
380,"Anthropomorphic User Interface Feedback in a Sewing Context and
  Affordances","  The aim of the authors' research is to gain better insights into the
effectiveness and user satisfaction of anthropomorphism at the user interface.
Therefore, this paper presents a between users experiment and the results in
the context of anthropomorphism at the user interface and the giving of
instruction for learning sewing stitches. Two experimental conditions were
used, where the information for learning sewing stitches was the same. However
the manner of presentation was varied. Therefore one condition was
anthropomorphic and the other was non-anthropomorphic. Also the work is closely
linked with Hartson's theory of affordances applied to user interfaces. The
results suggest that facilitation of the affordances in an anthropomorphic user
interface lead to statistically significant results in terms of effectiveness
and user satisfaction in the sewing context. Further some violation of the
affordances leads to an interface being less usable in terms of effectiveness
and user satisfaction.
"
381,"Exploiting Image Local And Nonlocal Consistency For Mixed
  Gaussian-Impulse Noise Removal","  Most existing image denoising algorithms can only deal with a single type of
noise, which violates the fact that the noisy observed images in practice are
often suffered from more than one type of noise during the process of
acquisition and transmission. In this paper, we propose a new variational
algorithm for mixed Gaussian-impulse noise removal by exploiting image local
consistency and nonlocal consistency simultaneously. Specifically, the local
consistency is measured by a hyper-Laplace prior, enforcing the local
smoothness of images, while the nonlocal consistency is measured by
three-dimensional sparsity of similar blocks, enforcing the nonlocal
self-similarity of natural images. Moreover, a Split-Bregman based technique is
developed to solve the above optimization problem efficiently. Extensive
experiments for mixed Gaussian plus impulse noise show that significant
performance improvements over the current state-of-the-art schemes have been
achieved, which substantiates the effectiveness of the proposed algorithm.
"
382,"Comparative Study and Optimization of Feature-Extraction Techniques for
  Content based Image Retrieval","  The aim of a Content-Based Image Retrieval (CBIR) system, also known as Query
by Image Content (QBIC), is to help users to retrieve relevant images based on
their contents. CBIR technologies provide a method to find images in large
databases by using unique descriptors from a trained image. The image
descriptors include texture, color, intensity and shape of the object inside an
image. Several feature-extraction techniques viz., Average RGB, Color Moments,
Co-occurrence, Local Color Histogram, Global Color Histogram and Geometric
Moment have been critically compared in this paper. However, individually these
techniques result in poor performance. So, combinations of these techniques
have also been evaluated and results for the most efficient combination of
techniques have been presented and optimized for each class of image query. We
also propose an improvement in image retrieval performance by introducing the
idea of Query modification through image cropping. It enables the user to
identify a region of interest and modify the initial query to refine and
personalize the image retrieval results.
"
383,"Behavioral Systel Level Power Consumption Modeling of Mobile Video
  Streaming applications","  Nowadays, the use of mobile applications and terminals faces fundamental
challenges related to energy constraint. This is due to the limited battery
lifetime as compared to the increasing hardware evolution. Video streaming is
one of the most energy consuming applications in a mobile system because of its
intensive use of bandwidth, memory and processing power. In this work, we aim
to propose a methodology for building and validating a high level global power
consumption model including a hardware and software elements. Our approach is
based on exploiting the interactions between power consumption sub-models of
standalone systems in the perspective to build more accurate global model. The
interactions are studied within the exclusive context of video streaming
applications that are one of the most used mobile applications.
"
384,"Approximate Similarity Search for Online Multimedia Services on
  Distributed CPU-GPU Platforms","  Similarity search in high-dimentional spaces is a pivotal operation found a
variety of database applications. Recently, there has been an increase interest
in similarity search for online content-based multimedia services. Those
services, however, introduce new challenges with respect to the very large
volumes of data that have to be indexed/searched, and the need to minimize
response times observed by the end-users. Additionally, those users dynamically
interact with the systems creating fluctuating query request rates, requiring
the search algorithm to adapt in order to better utilize the underline hardware
to reduce response times. In order to address these challenges, we introduce
hypercurves, a flexible framework for answering approximate k-nearest neighbor
(kNN) queries for very large multimedia databases, aiming at online
content-based multimedia services. Hypercurves executes on hybrid CPU--GPU
environments, and is able to employ those devices cooperatively to support
massive query request rates. In order to keep the response times optimal as the
request rates vary, it employs a novel dynamic scheduler to partition the work
between CPU and GPU. Hypercurves was throughly evaluated using a large database
of multimedia descriptors. Its cooperative CPU--GPU execution achieved
performance improvements of up to 30x when compared to the single CPU-core
version. The dynamic work partition mechanism reduces the observed query
response times in about 50% when compared to the best static CPU--GPU task
partition configuration. In addition, Hypercurves achieves superlinear
scalability in distributed (multi-node) executions, while keeping a high
guarantee of equivalence with its sequential version --- thanks to the proof of
probabilistic equivalence, which supported its aggressive parallelization
design.
"
385,Alternative Astronomical FITS imaging,"  Astronomical radio maps are presented mainly in FITS format. Astronomical
Image Processing Software (AIPS) uses a set of tables attached to the output
map to include all sorts of information concerning the production of the image.
However this information together with information on the flux and noise of the
map is lost as soon as the image of the radio source in fits or other format is
extracted from AIPS. This information would have been valuable to another
astronomer who just uses NED, for example, to download the map. In the current
work, we show a method of data hiding inside the radio map, which can be
preserved under transformations, even for example while the format of the map
is changed from fits to other lossless available image formats.
"
386,"Constructing the L2-Graph for Robust Subspace Learning and Subspace
  Clustering","  Under the framework of graph-based learning, the key to robust subspace
clustering and subspace learning is to obtain a good similarity graph that
eliminates the effects of errors and retains only connections between the data
points from the same subspace (i.e., intra-subspace data points). Recent works
achieve good performance by modeling errors into their objective functions to
remove the errors from the inputs. However, these approaches face the
limitations that the structure of errors should be known prior and a complex
convex problem must be solved. In this paper, we present a novel method to
eliminate the effects of the errors from the projection space (representation)
rather than from the input space. We first prove that $\ell_1$-, $\ell_2$-,
$\ell_{\infty}$-, and nuclear-norm based linear projection spaces share the
property of Intra-subspace Projection Dominance (IPD), i.e., the coefficients
over intra-subspace data points are larger than those over inter-subspace data
points. Based on this property, we introduce a method to construct a sparse
similarity graph, called L2-Graph. The subspace clustering and subspace
learning algorithms are developed upon L2-Graph. Experiments show that L2-Graph
algorithms outperform the state-of-the-art methods for feature extraction,
image clustering, and motion segmentation in terms of accuracy, robustness, and
time efficiency.
"
387,"Video Data Visualization System: Semantic Classification And
  Personalization","  We present in this paper an intelligent video data visualization tool, based
on semantic classification, for retrieving and exploring a large scale corpus
of videos. Our work is based on semantic classification resulting from semantic
analysis of video. The obtained classes will be projected in the visualization
space. The graph is represented by nodes and edges, the nodes are the keyframes
of video documents and the edges are the relation between documents and the
classes of documents. Finally, we construct the user's profile, based on the
interaction with the system, to render the system more adequate to its
references.
"
388,Video Chat with Multiple Cameras,"  The dominant paradigm for video chat employs a single camera at each end of
the conversation, but some conversations can be greatly enhanced by using
multiple cameras at one or both ends. This paper provides the first rigorous
investigation of multi-camera video chat, concentrating especially on the
ability of users to switch between views at either end of the conversation. A
user study of 23 individuals analyzes the advantages and disadvantages of
permitting a user to switch between views at a remote location. Benchmark
experiments employing up to four webcams simultaneously demonstrate that
multi-camera video chat is feasible on consumer hardware. The paper also
presents the design of MultiCam, a software package permitting multi-camera
video chat. Some important trade-offs in the design of MultiCam are discussed,
and typical usage scenarios are analyzed.
"
389,Recovering Missing Coefficients in DCT-Transformed Images,"  A general method for recovering missing DCT coefficients in DCT-transformed
images is presented in this work. We model the DCT coefficients recovery
problem as an optimization problem and recover all missing DCT coefficients via
linear programming. The visual quality of the recovered image gradually
decreases as the number of missing DCT coefficients increases. For some images,
the quality is surprisingly good even when more than 10 most significant DCT
coefficients are missing. When only the DC coefficient is missing, the proposed
algorithm outperforms existing methods according to experimental results
conducted on 200 test images. The proposed recovery method can be used for
cryptanalysis of DCT based selective encryption schemes and other applications.
"
390,Improved Robust DWT-Watermarking in YCbCr Color Space,"  Digital watermarking is an effective way to protect copyright. In this paper,
a robust watermarking algorithm based on wavelet transformation is proposed
which can confirm the copyright without original image. The wavelet
transformation technique is effective in image analyzing and processing. Thus
the color-image watermark algorithm based on discrete wavelet transformation
(DWT) begins to draw an increasing attention. In the proposed approach, the
watermark Encrypt by Arnold transform and the host image is converted into the
YCbCr color space. Then its Y channel decomposed into wavelet coefficients and
the selected approximation coefficients are quantized and then their least
significant bit of the quantized coefficients is replaced by the Encrypted
watermark using LSB insertion technique. The experimental results show that
watermark embedded by this algorithm is of better robustness and extra
imperceptibility and robustness against wavelet compression compared to the
traditional embedding methods in RGB color space.
"
391,"A Markov Decision Model for Adaptive Scheduling of Stored Scalable
  Videos","  We propose two scheduling algorithms that seek to optimize the quality of
scalably coded videos that have been stored at a video server before
transmission.} The first scheduling algorithm is derived from a Markov Decision
Process (MDP) formulation developed here. We model the dynamics of the channel
as a Markov chain and reduce the problem of dynamic video scheduling to a
tractable Markov decision problem over a finite state space. Based on the MDP
formulation, a near-optimal scheduling policy is computed that minimize the
mean square error. Using insights taken from the development of the optimal
MDP-based scheduling policy, the second proposed scheduling algorithm is an
online scheduling method that only requires easily measurable knowledge of the
channel dynamics, and is thus viable in practice. Simulation results show that
the performance of both scheduling algorithms is close to a performance upper
bound also derived in this paper.
"
392,Content-based Multi-media Retrieval Technology,"  This paper gives a summary of the content-based Image Retrieval and
Content-based Audio Retrieval, which are two parts of the Content-based
Retrieval. Content-based Retrieval is the retrieval based on the features of
the content. Generally, it is a way to extract features of the media data and
find other data with the similar features from the database automatically.
Content-based Retrieval can not only work on discrete media like texts, but
also can be used on continuous media, such as video and audio.
"
393,"Investigating Streaming Techniques and Energy Efficiency of Mobile Video
  Services","  We report results from a measurement study of three video streaming services,
YouTube, Dailymotion and Vimeo on six different smartphones. We measure and
analyze the traffic and energy consumption when streaming different quality
videos over Wi-Fi and 3G. We identify five different techniques to deliver the
video and show that the use of a particular technique depends on the device,
player, quality, and service. The energy consumption varies dramatically
between devices, services, and video qualities depending on the streaming
technique used. As a consequence, we come up with suggestions on how to improve
the energy efficiency of mobile video streaming services.
"
394,"Surveying the Social, Smart and Converged TV Landscape: Where is
  Television Research Headed?","  The TV is dead motto of just a few years ago has been replaced by the
prospect of Internet Protocol (IP) television experiences over converged
networks to become one of the great technology opportunities in the next few
years. As an introduction to the Special Issue on Smart, Social and Converged
Television, this extended editorial intends to review the current IP television
landscape in its many realizations: operator-based, over-the-top, and user
generated. We will address new services like social TV and recommendation
engines, dissemination including new paradigms built on peer to peer and
content centric networks, as well as the all important quality of experience
that challenges services and networks alike. But we intend to go further than
just review the existing work by proposing areas for the future of television
research. These include strategies to provide services that are more efficient
in network and energy usage while being socially engaging, novel services that
will provide consumers with a broader choice of content and devices, and
metrics that will enable operators and users alike to define the level of
service they require or that they are ready to provide. These topics are
addressed in this survey paper that attempts to create a unifying framework to
link them all together. Not only is television not dead, it is well alive,
thriving and fostering innovation and this paper will hopefully prove it.
"
395,"A Simultaneous-Movement Mobile Multiplayer Game Design based on Adaptive
  Background Partitioning Technique","  Implementations of mobile games have become prevalent industrial technology
due to the ubiquitous nature of mobile devices. However, simultaneous-movement
multiplayer games, games that a player competes simultaneously with other
players, are usually affected by such parameters as latency, type of game
architecture and type of communication technology. This paper makes a review of
the above parameters, considering the pros and cons of the various techniques
used in addressing each parameter. It then goes ahead to propose an enhanced
mechanism for dealing with packet delays based on partitioning the game
background into grids. The proposed design is implemented and tested using
Bluetooth and Wi-Fi communication technologies. The efficiency and
effectiveness of the design are also analyzed.
"
396,"Decision-Theoretic Coordination and Control for Active Multi-Camera
  Surveillance in Uncertain, Partially Observable Environments","  A central problem of surveillance is to monitor multiple targets moving in a
large-scale, obstacle-ridden environment with occlusions. This paper presents a
novel principled Partially Observable Markov Decision Process-based approach to
coordinating and controlling a network of active cameras for tracking and
observing multiple mobile targets at high resolution in such surveillance
environments. Our proposed approach is capable of (a) maintaining a belief over
the targets' states (i.e., locations, directions, and velocities) to track
them, even when they may not be observed directly by the cameras at all times,
(b) coordinating the cameras' actions to simultaneously improve the belief over
the targets' states and maximize the expected number of targets observed with a
guaranteed resolution, and (c) exploiting the inherent structure of our
surveillance problem to improve its scalability (i.e., linear time) in the
number of targets to be observed. Quantitative comparisons with
state-of-the-art multi-camera coordination and control techniques show that our
approach can achieve higher surveillance quality in real time. The practical
feasibility of our approach is also demonstrated using real AXIS 214 PTZ
cameras
"
397,"Comparison of Speech Activity Detection Techniques for Speaker
  Recognition","  Speech activity detection (SAD) is an essential component for a variety of
speech processing applications. It has been observed that performances of
various speech based tasks are very much dependent on the efficiency of the
SAD. In this paper, we have systematically reviewed some popular SAD techniques
and their applications in speaker recognition. Speaker verification system
using different SAD technique are experimentally evaluated on NIST speech
corpora using Gaussian mixture model- universal background model (GMM-UBM)
based classifier for clean and noisy conditions. It has been found that two
Gaussian modeling based SAD is comparatively better than other SAD techniques
for different types of noises.
"
398,Tracking Large-Scale Video Remix in Real-World Events,"  Social information networks, such as YouTube, contains traces of both
explicit online interaction (such as ""like"", leaving a comment, or subscribing
to video feed), and latent interactions (such as quoting, or remixing parts of
a video). We propose visual memes, or frequently re-posted short video
segments, for tracking such latent video interactions at scale. Visual memes
are extracted by scalable detection algorithms that we develop, with high
accuracy. We further augment visual memes with text, via a statistical model of
latent topics. We model content interactions on YouTube with visual memes,
defining several measures of influence and building predictive models for meme
popularity. Experiments are carried out on with over 2 million video shots from
more than 40,000 videos on two prominent news events in 2009: the election in
Iran and the swine flu epidemic. In these two events, a high percentage of
videos contain remixed content, and it is apparent that traditional news media
and citizen journalists have different roles in disseminating remixed content.
We perform two quantitative evaluations for annotating visual memes and
predicting their popularity. The joint statistical model of visual memes and
words outperform a concurrence model, and the average error is ~2% for
predicting meme volume and ~17% for their lifespan.
"
399,Reduction of Blocking Artifacts In JPEG Compressed Image,"  In JPEG (DCT based) compresses image data by representing the original image
with a small number of transform coefficients. It exploits the fact that for
typical images a large amount of signal energy is concentrated in a small
number of coefficients. The goal of DCT transform coding is to minimize the
number of retained transform coefficients while keeping distortion at an
acceptable level.In JPEG, it is done in 8X8 non overlapping blocks. It divides
an image into blocks of equal size and processes each block independently.
Block processing allows the coder to adapt to the local image statistics,
exploit the correlation present among neighboring image pixels, and to reduce
computational and storage requirements. One of the most degradation of the
block transform coding is the blocking artifact. These artifacts appear as a
regular pattern of visible block boundaries. This degradation is a direct
result of the coarse quantization of the coefficients and the independent
processing of the blocks which does not take into account the existing
correlations among adjacent block pixels. In this paper attempt is being made
to reduce the blocking artifact introduced by the Block DCT Transform in JPEG.
"
400,Video De-fencing,"  This paper describes and provides an initial solution to a novel video
editing task, i.e., video de-fencing. It targets automatic restoration of the
video clips that are corrupted by fence-like occlusions during capture. Our key
observation lies in the visual parallax between fences and background scenes,
which is caused by the fact that the former are typically closer to the camera.
Unlike in traditional image inpainting, fence-occluded pixels in the videos
tend to appear later in the temporal dimension and are therefore recoverable
via optimized pixel selection from relevant frames. To eventually produce
fence-free videos, major challenges include cross-frame sub-pixel image
alignment under diverse scene depth, and ""correct"" pixel selection that is
robust to dominating fence pixels. Several novel tools are developed in this
paper, including soft fence detection, weighted truncated optical flow method
and robust temporal median filter. The proposed algorithm is validated on
several real-world video clips with fences.
"
401,"Minimum Distortion Variance Concatenated Block Codes for Embedded Source
  Transmission","  Some state-of-art multimedia source encoders produce embedded source bit
streams that upon the reliable reception of only a fraction of the total bit
stream, the decoder is able reconstruct the source up to a basic quality.
Reliable reception of later source bits gradually improve the reconstruction
quality. Examples include scalable extensions of H.264/AVC and progressive
image coders such as JPEG2000. To provide an efficient protection for embedded
source bit streams, a concatenated block coding scheme using a minimum mean
distortion criterion was considered in the past. Although, the original design
was shown to achieve better mean distortion characteristics than previous
studies, the proposed coding structure was leading to dramatic quality
fluctuations. In this paper, a modification of the original design is first
presented and then the second order statistics of the distortion is taken into
account in the optimization. More specifically, an extension scheme is proposed
using a minimum distortion variance optimization criterion. This robust system
design is tested for an image transmission scenario. Numerical results show
that the proposed extension achieves significantly lower variance than the
original design, while showing similar mean distortion performance using both
convolutional codes and low density parity check codes.
"
402,Epitome for Automatic Image Colorization,"  Image colorization adds color to grayscale images. It not only increases the
visual appeal of grayscale images, but also enriches the information contained
in scientific images that lack color information. Most existing methods of
colorization require laborious user interaction for scribbles or image
segmentation. To eliminate the need for human labor, we develop an automatic
image colorization method using epitome. Built upon a generative graphical
model, epitome is a condensed image appearance and shape model which also
proves to be an effective summary of color information for the colorization
task. We train the epitome from the reference images and perform inference in
the epitome to colorize grayscale images, rendering better colorization results
than previous method in our experiments.
"
403,Navigation domain representation for interactive multiview imaging,"  Enabling users to interactively navigate through different viewpoints of a
static scene is a new interesting functionality in 3D streaming systems. While
it opens exciting perspectives towards rich multimedia applications, it
requires the design of novel representations and coding techniques in order to
solve the new challenges imposed by interactive navigation. Interactivity
clearly brings new design constraints: the encoder is unaware of the exact
decoding process, while the decoder has to reconstruct information from
incomplete subsets of data since the server can generally not transmit images
for all possible viewpoints due to resource constrains. In this paper, we
propose a novel multiview data representation that permits to satisfy bandwidth
and storage constraints in an interactive multiview streaming system. In
particular, we partition the multiview navigation domain into segments, each of
which is described by a reference image and some auxiliary information. The
auxiliary information enables the client to recreate any viewpoint in the
navigation segment via view synthesis. The decoder is then able to navigate
freely in the segment without further data request to the server; it requests
additional data only when it moves to a different segment. We discuss the
benefits of this novel representation in interactive navigation systems and
further propose a method to optimize the partitioning of the navigation domain
into independent segments, under bandwidth and storage constraints.
Experimental results confirm the potential of the proposed representation;
namely, our system leads to similar compression performance as classical
inter-view coding, while it provides the high level of flexibility that is
required for interactive streaming. Hence, our new framework represents a
promising solution for 3D data representation in novel interactive multimedia
services.
"
404,Steganalysis of Transcoding Steganography,"  TranSteg (Trancoding Steganography) is a fairly new IP telephony
steganographic method that functions by compressing overt (voice) data to make
space for the steganogram by means of transcoding. It offers high
steganographic bandwidth, retains good voice quality and is generally harder to
detect than other existing VoIP steganographic methods. In TranSteg, after the
steganogram reaches the receiver, the hidden information is extracted and the
speech data is practically restored to what was originally sent. This is a huge
advantage compared with other existing VoIP steganographic methods, where the
hidden data can be extracted and removed but the original data cannot be
restored because it was previously erased due to a hidden data insertion
process. In this paper we address the issue of steganalysis of TranSteg.
Various TranSteg scenarios and possibilities of warden(s) localization are
analyzed with regards to the TranSteg detection. A steganalysis method based on
MFCC (Mel-Frequency Cepstral Coefficients) parameters and GMMs (Gaussian
Mixture Models) was developed and tested for various overt/covert codec pairs
in a single warden scenario with double transcoding. The proposed method
allowed for efficient detection of some codec pairs (e.g., G.711/G.729), whilst
some others remained more resistant to detection (e.g., iLBC/AMR).
"
405,Multilayer image watermarking scheme for providing high security,"  The main theme of this application is to provide an algorithm color image
watermark to manage the attacks such as rotation, scaling and translation. In
the existing watermarking algorithms, those exploited robust features are more
or less related to the pixel position, so they cannot be more robust against
the attacks. In order to solve this problem this application focus on certain
parameters rather than the pixel position for watermarking. Two statistical
features such as the histogram shape and the mean of Gaussian filtered
low-frequency component of images are taken for this proposed application to
make the watermarking algorithm robust to attacks and also AES technique is
used to provide higher security.
"
406,Convolutional Compressed Sensing Using Deterministic Sequences,"  In this paper, a new class of circulant matrices built from deterministic
sequences is proposed for convolution-based compressed sensing (CS). In
contrast to random convolution, the coefficients of the underlying filter are
given by the discrete Fourier transform of a deterministic sequence with good
autocorrelation. Both uniform recovery and non-uniform recovery of sparse
signals are investigated, based on the coherence parameter of the proposed
sensing matrices. Many examples of the sequences are investigated, particularly
the Frank-Zadoff-Chu (FZC) sequence, the \textit{m}-sequence and the Golay
sequence. A salient feature of the proposed sensing matrices is that they can
not only handle sparse signals in the time domain, but also those in the
frequency and/or or discrete-cosine transform (DCT) domain.
"
407,"Beltrami Representation and its applications to texture map and video
  compression","  Surface parameterizations and registrations are important in computer
graphics and imaging, where 1-1 correspondences between meshes are computed. In
practice, surface maps are usually represented and stored as 3D coordinates
each vertex is mapped to, which often requires lots of storage memory. This
causes inconvenience in data transmission and data storage. To tackle this
problem, we propose an effective algorithm for compressing surface
homeomorphisms using Fourier approximation of the Beltrami representation. The
Beltrami representation is a complex-valued function defined on triangular
faces of the surface mesh with supreme norm strictly less than 1. Under
suitable normalization, there is a 1-1 correspondence between the set of
surface homeomorphisms and the set of Beltrami representations. Hence, every
bijective surface map is associated with a unique Beltrami representation.
Conversely, given a Beltrami representation, the corresponding bijective
surface map can be exactly reconstructed using the Linear Beltrami Solver
introduced in this paper. Using the Beltrami representation, the surface
homeomorphism can be easily compressed by Fourier approximation, without
distorting the bijectivity of the map. The storage memory can be effectively
reduced, which is useful for many practical problems in computer graphics and
imaging. In this paper, we proposed to apply the algorithm to texture map
compression and video compression. With our proposed algorithm, the storage
requirement for the texture properties of a textured surface can be
significantly reduced. Our algorithm can further be applied to compressing
motion vector fields for video compression, which effectively improve the
compression ratio.
"
408,"Non-uniform Quantization of Detail Components in Wavelet Transformed
  Image for Lossy JPEG2000 Compression","  The paper introduces the idea of non-uniform quantization in the detail
components of wavelet transformed image. It argues that most of the
coefficients of horizontal, vertical and diagonal components lie near to zeros
and the coefficients representing large differences are few at the extreme ends
of histogram. Therefore, this paper advocates need for variable step size
quantization scheme which preserves the edge information at the edge of
histogram and removes redundancy with the minimal number of quantized values.
To support the idea, preliminary results are provided using a non-uniform
quantization algorithm. We believe that successful implementation of
non-uniform quantization in detail components in JPEG-2000 still image standard
will improve image quality and compression efficiency with lesser number of
quantized values.
"
409,Mugshot Identification from Manipulated Facial Images,"  Editing on digital images is ubiquitous. Identification of deliberately
modified facial images is a new challenge for face identification system. In
this paper, we address the problem of identification of a face or person from
heavily altered facial images. In this face identification problem, the input
to the system is a manipulated or transformed face image and the system reports
back the determined identity from a database of known individuals. Such a
system can be useful in mugshot identification in which mugshot database
contains two views (frontal and profile) of each criminal. We considered only
frontal view from the available database for face identification and the query
image is a manipulated face generated by face transformation software tool
available online. We propose SIFT features for efficient face identification in
this scenario. Further comparative analysis has been given with well known
eigenface approach. Experiments have been conducted with real case images to
evaluate the performance of both methods.
"
410,Public key Steganography Using Discrete Cross-Coupled Chaotic Maps,"  By cross-coupling two logistic maps a novel method is proposed for the public
key steganography in JPEG image. Chaotic maps entail high complexity in the
used algorithm for embedding secret data in a medium. In this paper, discrete
cross- coupled chaotic maps are used to specifying the location of the
different parts of the secret data in the image. Modifying JPEG format during
compressing and decompressing, and also using public key enhanced difficulty of
the algorithm. Simulation results show that in addition to excessive capacity,
this method has high robustness and resistance against hackers and can be
applicable in secret communication. Also the PSNR value is high compared to the
other works.
"
411,Sampling and Reconstruction of Spatial Fields using Mobile Sensors,"  Spatial sampling is traditionally studied in a static setting where static
sensors scattered around space take measurements of the spatial field at their
locations. In this paper we study the emerging paradigm of sampling and
reconstructing spatial fields using sensors that move through space. We show
that mobile sensing offers some unique advantages over static sensing in
sensing time-invariant bandlimited spatial fields. Since a moving sensor
encounters such a spatial field along its path as a time-domain signal, a
time-domain anti-aliasing filter can be employed prior to sampling the signal
received at the sensor. Such a filtering procedure, when used by a
configuration of sensors moving at constant speeds along equispaced parallel
lines, leads to a complete suppression of spatial aliasing in the direction of
motion of the sensors. We analytically quantify the advantage of using such a
sampling scheme over a static sampling scheme by computing the reduction in
sampling noise due to the filter. We also analyze the effects of non-uniform
sensor speeds on the reconstruction accuracy. Using simulation examples we
demonstrate the advantages of mobile sampling over static sampling in practical
problems.
  We extend our analysis to sampling and reconstruction schemes for monitoring
time-varying bandlimited fields using mobile sensors. We demonstrate that in
some situations we require a lower density of sensors when using a mobile
sensing scheme instead of the conventional static sensing scheme. The exact
advantage is quantified for a problem of sampling and reconstructing an audio
field.
"
412,Some New Methodologies for Image Hiding using Steganographic Techniques,"  Security and memory management are the major demands for electronics devices
like ipods, cell phones, pmps, iphones and digital cameras. In this paper, we
have suggested a high level of security mechanism by considering the concept of
steganography along with the principle of cryptography. Four different methods
that can save a considerable amount of memory space have been discussed. Based
on these methods, we have constructed secured stego image creator and secured
multi image viewer in Microsoft platform so as to provide high level of
security and using less memory space for storage of image files in the above
said electronic devices
"
413,Ordered Statistics Vertex Extraction and Tracing Algorithm (OSVETA),"  We propose an algorithm for identifying vertices from three dimensional (3D)
meshes that are most important for a geometric shape creation. Extracting such
a set of vertices from a 3D mesh is important in applications such as digital
watermarking, but also as a component of optimization and triangulation. In the
first step, the Ordered Statistics Vertex Extraction and Tracing Algorithm
(OSVETA) estimates precisely the local curvature, and most important
topological features of mesh geometry. Using the vertex geometric importance
ranking, the algorithm traces and extracts a vector of vertices, ordered by
decreasing index of importance.
"
414,Embedding grayscale halftone pictures in QR Codes using Correction Trees,"  Barcodes like QR Codes have made that encoded messages have entered our
everyday life, what suggests to attach them a second layer of information:
directly available to human receiver for informational or marketing purposes.
We will discuss a general problem of using codes with chosen statistical
constrains, for example reproducing given grayscale picture using halftone
technique. If both sender and receiver know these constrains, the optimal
capacity can be easily approached by entropy coder. The problem is that this
time only the sender knows them - we will refer to these scenarios as
constrained coding. Kuznetsov and Tsybakov problem in which only the sender
knows which bits are fixed can be seen as a special case, surprisingly
approaching the same capacity as if both sides would know the constrains. We
will analyze Correction Trees to approach analogous capacity in the general
case - use weaker: statistical constrains, what allows to apply them to all
bits. Finding satisfying coding is similar to finding the proper correction in
error correction problem, but instead of single ensured possibility, there are
now statistically expected some. While in standard steganography we hide
information in the least important bits, this time we create codes resembling
given picture - hide information in the freedom of realizing grayness by black
and white pixels using halftone technique. We will also discuss combining with
error correction and application to rate distortion problem.
"
415,"Teichm\""uller extremal mapping and its applications to landmark matching
  registration","  Registration, which aims to find an optimal 1-1 correspondence between
shapes, is an important process in different research areas. Conformal mappings
have been widely used to obtain a diffeomorphism between shapes that minimizes
angular distortion. Conformal registrations are beneficial since it preserves
the local geometry well. However, when landmark constraints are enforced,
conformal mappings generally do not exist. This motivates us to look for a
unique landmark matching quasi-conformal registration, which minimizes the
conformality distortion. Under suitable condition on the landmark constraints,
a unique diffeomporphism, called the Teichm\""uller extremal mapping between two
surfaces can be obtained, which minimizes the maximal conformality distortion.
In this paper, we propose an efficient iterative algorithm, called the
Quasi-conformal (QC) iterations, to compute the Teichm\""uller mapping. The
basic idea is to represent the set of diffeomorphisms using Beltrami
coefficients (BCs), and look for an optimal BC associated to the desired
Teichm\""uller mapping. The associated diffeomorphism can be efficiently
reconstructed from the optimal BC using the Linear Beltrami Solver(LBS). Using
BCs to represent diffeomorphisms guarantees the diffeomorphic property of the
registration. Using our proposed method, the Teichm\""uller mapping can be
accurately and efficiently computed within 10 seconds. The obtained
registration is guaranteed to be bijective. The proposed algorithm can also be
extended to compute Teichm\""uller mapping with soft landmark constraints. We
applied the proposed algorithm to real applications, such as brain landmark
matching registration, constrained texture mapping and human face registration.
Experimental results shows that our method is both effective and efficient in
computing a non-overlap landmark matching registration with least amount of
conformality distortion.
"
416,"A Non-Blind Watermarking Scheme for Gray Scale Images in Discrete
  Wavelet Transform Domain using Two Subbands","  Digital watermarking is the process to hide digital pattern directly into a
digital content. Digital watermarking techniques are used to address digital
rights management, protect information and conceal secrets. An invisible
non-blind watermarking approach for gray scale images is proposed in this
paper. The host image is decomposed into 3-levels using Discrete Wavelet
Transform. Based on the parent-child relationship between the wavelet
coefficients the Set Partitioning in Hierarchical Trees (SPIHT) compression
algorithm is performed on the LH3, LH2, HL3 and HL2 subbands to find out the
significant coefficients. The most significant coefficients of LH2 and HL2
bands are selected to embed a binary watermark image. The selected significant
coefficients are modulated using Noise Visibility Function, which is considered
as the best strength to ensure better imperceptibility. The approach is tested
against various image processing attacks such as addition of noise, filtering,
cropping, JPEG compression, histogram equalization and contrast adjustment. The
experimental results reveal the high effectiveness of the method.
"
417,Intermediate Performance Analysis of Growth Codes,"  Growth codes are a subclass of Rateless codes that have found interesting
applications in data dissemination problems. Compared to other Rateless and
conventional channel codes, Growth codes show improved intermediate performance
which is particularly useful in applications where performance increases with
the number of decoded data units. In this paper, we provide a generic
analytical framework for studying the asymptotic performance of Growth codes in
different settings. Our analysis based on Wormald method applies to any class
of Rateless codes that does not include a precoding step. We evaluate the
decoding probability model for short codeblocks and validate our findings by
experiments. We then exploit the decoding probability model in an illustrative
application of Growth codes to error resilient video transmission. The video
transmission problem is cast as a joint source and channel rate allocation
problem that is shown to be convex with respect to the channel rate. This
application permits to highlight the main advantage of Growth codes that is
improved performance (hence distortion in video) in the intermediate loss
region.
"
418,Network Coding Meets Multimedia: a Review,"  While every network node only relays messages in a traditional communication
system, the recent network coding (NC) paradigm proposes to implement simple
in-network processing with packet combinations in the nodes. NC extends the
concept of ""encoding"" a message beyond source coding (for compression) and
channel coding (for protection against errors and losses). It has been shown to
increase network throughput compared to traditional networks implementation, to
reduce delay and to provide robustness to transmission errors and network
dynamics. These features are so appealing for multimedia applications that they
have spurred a large research effort towards the development of
multimedia-specific NC techniques. This paper reviews the recent work in NC for
multimedia applications and focuses on the techniques that fill the gap between
NC theory and practical applications. It outlines the benefits of NC and
presents the open challenges in this area. The paper initially focuses on
multimedia-specific aspects of network coding, in particular delay, in-network
error control, and media-specific error control. These aspects permit to handle
varying network conditions as well as client heterogeneity, which are critical
to the design and deployment of multimedia systems. After introducing these
general concepts, the paper reviews in detail two applications that lend
themselves naturally to NC via the cooperation and broadcast models, namely
peer-to-peer multimedia streaming and wireless networking.
"
419,Five Modulus Method For Image Compression,"  Data is compressed by reducing its redundancy, but this also makes the data
less reliable, more prone to errors. In this paper a novel approach of image
compression based on a new method that has been created for image compression
which is called Five Modulus Method (FMM). The new method consists of
converting each pixel value in an 8-by-8 block into a multiple of 5 for each of
the R, G and B arrays. After that, the new values could be divided by 5 to get
new values which are 6-bit length for each pixel and it is less in storage
space than the original value which is 8-bits. Also, a new protocol for
compression of the new values as a stream of bits has been presented that gives
the opportunity to store and transfer the new compressed image easily.
"
420,Content based video retrieval,"  Content based video retrieval is an approach for facilitating the searching
and browsing of large image collections over World Wide Web. In this approach,
video analysis is conducted on low level visual properties extracted from video
frame. We believed that in order to create an effective video retrieval system,
visual perception must be taken into account. We conjectured that a technique
which employs multiple features for indexing and retrieval would be more
effective in the discrimination and search tasks of videos. In order to
validate this claim, content based indexing and retrieval systems were
implemented using color histogram, various texture features and other
approaches. Videos were stored in Oracle 9i Database and a user study measured
correctness of response.
"
421,Collaborative P2P Streaming of Interactive Live Free Viewpoint Video,"  We study an interactive live streaming scenario where multiple peers pull
streams of the same free viewpoint video that are synchronized in time but not
necessarily in view. In free viewpoint video, each user can periodically select
a virtual view between two anchor camera views for display. The virtual view is
synthesized using texture and depth videos of the anchor views via
depth-image-based rendering (DIBR). In general, the distortion of the virtual
view increases with the distance to the anchor views, and hence it is
beneficial for a peer to select the closest anchor views for synthesis. On the
other hand, if peers interested in different virtual views are willing to
tolerate larger distortion in using more distant anchor views, they can
collectively share the access cost of common anchor views.
  Given anchor view access cost and synthesized distortion of virtual views
between anchor views, we study the optimization of anchor view allocation for
collaborative peers. We first show that, if the network reconfiguration costs
due to view-switching are negligible, the problem can be optimally solved in
polynomial time using dynamic programming. We then consider the case of
non-negligible reconfiguration costs (e.g., large or frequent view-switching
leading to anchor-view changes). In this case, the view allocation problem
becomes NP-hard. We thus present a locally optimal and centralized allocation
algorithm inspired by Lloyd's algorithm in non-uniform scalar quantization. We
also propose a distributed algorithm with guaranteed convergence where each
peer group independently make merge-and-split decisions with a well-defined
fairness criteria. The results show that depending on the problem settings, our
proposed algorithms achieve respective optimal and close-to-optimal performance
in terms of total cost, and outperform a P2P scheme without collaborative
anchor selection.
"
422,Corpus Development for Affective Video Indexing,"  Affective video indexing is the area of research that develops techniques to
automatically generate descriptions of video content that encode the emotional
reactions which the video content evokes in viewers. This paper provides a set
of corpus development guidelines based on state-of-the-art practice intended to
support researchers in this field. Affective descriptions can be used for video
search and browsing systems offering users affective perspectives. The paper is
motivated by the observation that affective video indexing has yet to fully
profit from the standard corpora (data sets) that have benefited conventional
forms of video indexing. Affective video indexing faces unique challenges,
since viewer-reported affective reactions are difficult to assess. Moreover
affect assessment efforts must be carefully designed in order to both cover the
types of affective responses that video content evokes in viewers and also
capture the stable and consistent aspects of these responses. We first present
background information on affect and multimedia and related work on affective
multimedia indexing, including existing corpora. Three dimensions emerge as
critical for affective video corpora, and form the basis for our proposed
guidelines: the context of viewer response, personal variation among viewers,
and the effectiveness and efficiency of corpus creation. Finally, we present
examples of three recent corpora and discuss how these corpora make progressive
steps towards fulfilling the guidelines.
"
423,"A Hash based Approach for Secure Keyless Steganography in Lossless RGB
  Images","  This paper proposes an improved steganography approach for hiding text
messages in lossless RGB images. The objective of this work is to increase the
security level and to improve the storage capacity with compression techniques.
The security level is increased by randomly distributing the text message over
the entire image instead of clustering within specific image portions. Storage
capacity is increased by utilizing all the color channels for storing
information and providing the source text message compression. The degradation
of the images can be minimized by changing only one least significant bit per
color channel for hiding the message, incurring a very little change in the
original image. Using steganography alone with simple LSB has a potential
problem that the secret message is easily detectable from the histogram
analysis method. To improve the security as well as the image embedding
capacity indirectly, a compression based scheme is introduced. Various tests
have been done to check the storage capacity and message distribution. These
testes show the superiority of the proposed approach with respect to other
existing approaches.
"
424,"SVD Based Image Processing Applications: State of The Art, Contributions
  and Research Challenges","  Singular Value Decomposition (SVD) has recently emerged as a new paradigm for
processing different types of images. SVD is an attractive algebraic transform
for image processing applications. The paper proposes an experimental survey
for the SVD as an efficient transform in image processing applications. Despite
the well-known fact that SVD offers attractive properties in imaging, the
exploring of using its properties in various image applications is currently at
its infancy. Since the SVD has many attractive properties have not been
utilized, this paper contributes in using these generous properties in newly
image applications and gives a highly recommendation for more research
challenges. In this paper, the SVD properties for images are experimentally
presented to be utilized in developing new SVD-based image processing
applications. The paper offers survey on the developed SVD based image
applications. The paper also proposes some new contributions that were
originated from SVD properties analysis in different image processing. The aim
of this paper is to provide a better understanding of the SVD in image
processing and identify important various applications and open research
directions in this increasingly important area; SVD based image processing in
the future research.
"
425,"Towards semantic and affective coupling in emotionally annotated
  databases","  Emotionally annotated databases are repositories of multimedia documents with
annotated affective content that elicit emotional responses in exposed human
subjects. They are primarily used in research of human emotions, attention and
development of stress-related mental disorders. This can be successfully
exploited in larger processes like selection, evaluation and training of
personnel for occupations involving high stress levels. Emotionally annotated
databases are also used in multimodal affective user interfaces to facilitate
richer and more intuitive human-computer interaction. Multimedia documents in
emotionally annotated databases must have maximum personal ego relevance to be
the most effective in all these applications. For this reason flexible
construction of subject-specific of emotionally annotated databases is
imperative. But current construction process is lengthy and labor intensive
because it inherently includes an elaborate tagging experiment involving a team
of human experts. This is unacceptable since the creation of new databases or
modification of the existing ones becomes slow and difficult. We identify a
positive correlation between the affect and semantics in the existing
emotionally annotated databases and propose to exploit this feature with an
interactive relevance feedback for a more efficient construction of emotionally
annotated databases. Automatic estimation of affective annotations from
existing semantics enhanced with information refinement processes may lead to
an efficient construction of high-quality emotionally annotated databases.
"
426,A Conformal Approach for Surface Inpainting,"  We address the problem of surface inpainting, which aims to fill in holes or
missing regions on a Riemann surface based on its surface geometry. In
practical situation, surfaces obtained from range scanners often have holes
where the 3D models are incomplete. In order to analyze the 3D shapes
effectively, restoring the incomplete shape by filling in the surface holes is
necessary. In this paper, we propose a novel conformal approach to inpaint
surface holes on a Riemann surface based on its surface geometry. The basic
idea is to represent the Riemann surface using its conformal factor and mean
curvature. According to Riemann surface theory, a Riemann surface can be
uniquely determined by its conformal factor and mean curvature up to a rigid
motion. Given a Riemann surface $S$, its mean curvature $H$ and conformal
factor $\lambda$ can be computed easily through its conformal parameterization.
Conversely, given $\lambda$ and $H$, a Riemann surface can be uniquely
reconstructed by solving the Gauss-Codazzi equation on the conformal parameter
domain. Hence, the conformal factor and the mean curvature are two geometric
quantities fully describing the surface. With this $\lambda$-$H$ representation
of the surface, the problem of surface inpainting can be reduced to the problem
of image inpainting of $\lambda$ and $H$ on the conformal parameter domain.
Once $\lambda$ and $H$ are inpainted, a Riemann surface can be reconstructed
which effectively restores the 3D surface with missing holes. Since the
inpainting model is based on the geometric quantities $\lambda$ and $H$, the
restored surface follows the surface geometric pattern. We test the proposed
algorithm on synthetic data as well as real surface data. Experimental results
show that our proposed method is an effective surface inpainting algorithm to
fill in surface holes on an incomplete 3D models based their surface geometry.
"
427,"An Image Steganography Scheme using Randomized Algorithm and
  Context-Free Grammar","  Currently, cryptography is in wide use as it is being exploited in various
domains from data confidentiality to data integrity and message authentication.
Basically, cryptography shuffles data so that they become unreadable by
unauthorized parties. However, clearly visible encrypted messages, no matter
how unbreakable, will arouse suspicions. A better approach would be to hide the
very existence of the message using steganography. Fundamentally, steganography
conceals secret data into innocent-looking mediums called carriers which can
then travel from the sender to the receiver safe and unnoticed. This paper
proposes a novel steganography scheme for hiding digital data into uncompressed
image files using a randomized algorithm and a context-free grammar. Besides,
the proposed scheme uses two mediums to deliver the secret data: a carrier
image into which the secret data are hidden into random pixels, and a
well-structured English text that encodes the location of the random carrier
pixels. The English text is generated at runtime using a context-free grammar
coupled with a lexicon of English words. The proposed scheme is stealthy, and
hard to be noticed, detected, and recovered. Experiments conducted showed how
the covering and the uncovering processes of the proposed scheme work. As
future work, a semantic analyzer is to be developed so as to make the English
text medium semantically correct, and consequently safer to be transmitted
without drawing any attention.
"
428,"Enhanced Mobile Digital Video Broadcasting with Distributed Space-Time
  Coding","  This paper investigates the distributed space-time (ST) coding proposals for
the future Digital Video Broadcasting--Next Generation Handheld (DVB-NGH)
standard. We first theoretically show that the distributed MIMO scheme is the
best broadcasting scenario in terms of channel capacity. Consequently we
evaluate the performance of several ST coding proposals for DVB-NGH with
practical system specifications and channel conditions. Simulation results
demonstrate that the 3D code is the best ST coding solution for broadcasting in
the distributed MIMO scenario.
"
429,"Self Authentication of color image through Wavelet Transformation
  Technique (SAWT)","  In this paper a self organized legal document/content authentication,
copyright protection in composite domain has been proposed without using any
external information. Average values of transformed red and green components in
frequency domain generated through wavelet transform are embedded into the blue
component of the color image matrix in spatial domain. A reverse transformation
is made in RG matrix to obtain embedded image in association with blue
component in spatial domain. Reverse procedure is done during decoding where
transformed average values are obtained from red and green components and
compared with the same from blue component for authentication. Results are
compared with existing technique which shows better performance interns of
PSNR, MSE & IF.
"
430,Multi-View Video Packet Scheduling,"  In multiview applications, multiple cameras acquire the same scene from
different viewpoints and generally produce correlated video streams. This
results in large amounts of highly redundant data. In order to save resources,
it is critical to handle properly this correlation during encoding and
transmission of the multiview data. In this work, we propose a
correlation-aware packet scheduling algorithm for multi-camera networks, where
information from all cameras are transmitted over a bottleneck channel to
clients that reconstruct the multiview images. The scheduling algorithm relies
on a new rate-distortion model that captures the importance of each view in the
scene reconstruction. We propose a problem formulation for the optimization of
the packet scheduling policies, which adapt to variations in the scene content.
Then, we design a low complexity scheduling algorithm based on a trellis search
that selects the subset of candidate packets to be transmitted towards
effective multiview reconstruction at clients. Extensive simulation results
confirm the gain of our scheduling algorithm when inter-source correlation
information is used in the scheduler, compared to scheduling policies with no
information about the correlation or non-adaptive scheduling policies. We
finally show that increasing the optimization horizon in the packet scheduling
algorithm improves the transmission performance, especially in scenarios where
the level of correlation rapidly varies with time.
"
431,"A Multi-View Embedding Space for Modeling Internet Images, Tags, and
  their Semantics","  This paper investigates the problem of modeling Internet images and
associated text or tags for tasks such as image-to-image search, tag-to-image
search, and image-to-tag search (image annotation). We start with canonical
correlation analysis (CCA), a popular and successful approach for mapping
visual and textual features to the same latent space, and incorporate a third
view capturing high-level image semantics, represented either by a single
category or multiple non-mutually-exclusive concepts. We present two ways to
train the three-view embedding: supervised, with the third view coming from
ground-truth labels or search keywords; and unsupervised, with semantic themes
automatically obtained by clustering the tags. To ensure high accuracy for
retrieval tasks while keeping the learning process scalable, we combine
multiple strong visual features and use explicit nonlinear kernel mappings to
efficiently approximate kernel CCA. To perform retrieval, we use a specially
designed similarity function in the embedded space, which substantially
outperforms the Euclidean distance. The resulting system produces compelling
qualitative results and outperforms a number of two-view baselines on retrieval
tasks on three large-scale Internet image datasets.
"
432,Image Steganography Method Based on Brightness Adjustment,"  Steganography is an information hiding technique in which secret data are
secured by covering them into a computer carrier file without damaging the file
or changing its size. The difference between steganography and cryptography is
that steganography is a stealthy method of communication that only the
communicating parties are aware of; while, cryptography is an overt method of
communication that anyone is aware of, despite its payload is scribbled.
Typically, an irrecoverable steganography algorithm is the algorithm that makes
it hard for malicious third parties to discover how it works and how to recover
the secret data out of the carrier file. One popular way to achieve
irrecoverability is to digitally process the carrier file after hiding the
secret data into it. However, such process is irreversible as it would destroy
the concealed data. This paper proposes a new image steganography method for
textual data, as well as for any form of digital data, based on adjusting the
brightness of the carrier image after covering the secret data into it. The
algorithm used is parameterized as it can be configured using three different
parameters defined by the communicating parties. They include the amount of
brightness to apply on the carrier image after the completion of the covering
process, the color channels whose brightness should be adjusted, and the bytes
that should carry in the secret data. The novelty of the proposed method is
that it embeds bits of the secret data into the three LSBs of the bytes that
compose the carrier image in such a way that does not destroy the secret data
when restoring back the original brightness of the carrier image. The
simulation conducted proved that the proposed algorithm is valid and correct.
"
433,"High Quality Image Interpolation via Local Autoregressive and Nonlocal
  3-D Sparse Regularization","  In this paper, we propose a novel image interpolation algorithm, which is
formulated via combining both the local autoregressive (AR) model and the
nonlocal adaptive 3-D sparse model as regularized constraints under the
regularization framework. Estimating the high-resolution image by the local AR
regularization is different from these conventional AR models, which weighted
calculates the interpolation coefficients without considering the rough
structural similarity between the low-resolution (LR) and high-resolution (HR)
images. Then the nonlocal adaptive 3-D sparse model is formulated to regularize
the interpolated HR image, which provides a way to modify these pixels with the
problem of numerical stability caused by AR model. In addition, a new
Split-Bregman based iterative algorithm is developed to solve the above
optimization problem iteratively. Experiment results demonstrate that the
proposed algorithm achieves significant performance improvements over the
traditional algorithms in terms of both objective quality and visual perception
"
434,"Computer-Assisted Interactive Documentary and Performance Arts in
  Illimitable Space","  This major component of the research described in this thesis is 3D computer
graphics, specifically the realistic physics-based softbody simulation and
haptic responsive environments. Minor components include advanced
human-computer interaction environments, non-linear documentary storytelling,
and theatre performance. The journey of this research has been unusual because
it requires a researcher with solid knowledge and background in multiple
disciplines; who also has to be creative and sensitive in order to combine the
possible areas into a new research direction. [...] It focuses on the advanced
computer graphics and emerges from experimental cinematic works and theatrical
artistic practices. Some development content and installations are completed to
prove and evaluate the described concepts and to be convincing. [...] To
summarize, the resulting work involves not only artistic creativity, but
solving or combining technological hurdles in motion tracking, pattern
recognition, force feedback control, etc., with the available documentary
footage on film, video, or images, and text via a variety of devices [....] and
programming, and installing all the needed interfaces such that it all works in
real-time. Thus, the contribution to the knowledge advancement is in solving
these interfacing problems and the real-time aspects of the interaction that
have uses in film industry, fashion industry, new age interactive theatre,
computer games, and web-based technologies and services for entertainment and
education. It also includes building up on this experience to integrate Kinect-
and haptic-based interaction, artistic scenery rendering, and other forms of
control. This research work connects all the research disciplines, seemingly
disjoint fields of research, such as computer graphics, documentary film,
interactive media, and theatre performance together.
"
435,Single-sided Real-time PESQ Score Estimation,"  For several years now, the ITU-T's Perceptual Evaluation of Speech Quality
(PESQ) has been the reference for objective speech quality assessment. It is
widely deployed in commercial QoE measurement products, and it has been well
studied in the literature. While PESQ does provide reasonably good correlation
with subjective scores for VoIP applications, the algorithm itself is not
usable in a real-time context, since it requires a reference signal, which is
usually not available in normal conditions. In this paper we provide an
alternative technique for estimating PESQ scores in a single-sided fashion,
based on the Pseudo Subjective Quality Assessment (PSQA) technique.
"
436,Bounding Lossy Compression using Lossless Codes at Reduced Precision,"  An alternative approach to two-part 'critical compression' is presented.
Whereas previous results were based on summing a lossless code at reduced
precision with a lossy-compressed error or noise term, the present approach
uses a similar lossless code at reduced precision to establish absolute bounds
which constrain an arbitrary lossy data compression algorithm applied to the
original data.
"
437,A Poisson Hidden Markov Model for Multiview Video Traffic,"  Multiview video has recently emerged as a means to improve user experience in
novel multimedia services. We propose a new stochastic model to characterize
the traffic generated by a Multiview Video Coding (MVC) variable bit rate
source. To this aim, we resort to a Poisson Hidden Markov Model (P-HMM), in
which the first (hidden) layer represents the evolution of the video activity
and the second layer represents the frame sizes of the multiple encoded views.
We propose a method for estimating the model parameters in long MVC sequences.
We then present extensive numerical simulations assessing the model's ability
to produce traffic with realistic characteristics for a general class of MVC
sequences. We then extend our framework to network applications where we show
that our model is able to accurately describe the sender and receiver buffers
behavior in MVC transmission. Finally, we derive a model of user behavior for
interactive view selection, which, in conjunction with our traffic model, is
able to accurately predict actual network load in interactive multiview
services.
"
438,"An Extensive Analysis of Query by Singing/Humming System Through Query
  Proportion","  Query by Singing/Humming (QBSH) is a Music Information Retrieval (MIR) system
with small audio excerpt as query. The rising availability of digital music
stipulates effective music retrieval methods. Further, MIR systems support
content based searching for music and requires no musical acquaintance. Current
work on QBSH focuses mainly on melody features such as pitch, rhythm, note
etc., size of databases, response time, score matching and search algorithms.
Even though a variety of QBSH techniques are proposed, there is a dearth of
work to analyze QBSH through query excerption. Here, we present an analysis
that works on QBSH through query excerpt. To substantiate a series of
experiments are conducted with the help of Mel-Frequency Cepstral Coefficients
(MFCC), Linear Predictive Coefficients (LPC) and Linear Predictive Cepstral
Coefficients (LPCC) to portray the robustness of the knowledge representation.
Proposed experiments attempt to reveal that retrieval performance as well as
precision diminishes in the snail phase with the growing database size.
"
439,"Content-Based Video Browsing by Text Region Localization and
  Classification","  The amount of digital video data is increasing over the world. It highlights
the need for efficient algorithms that can index, retrieve and browse this data
by content. This can be achieved by identifying semantic description captured
automatically from video structure. Among these descriptions, text within video
is considered as rich features that enable a good way for video indexing and
browsing. Unlike most video text detection and extraction methods that treat
video sequences as collections of still images, we propose in this paper
spatiotemporal. video-text localization and identification approach which
proceeds in two main steps: text region localization and text region
classification. In the first step we detect the significant appearance of the
new objects in a frame by a split and merge processes applied on binarized edge
frame pair differences. Detected objects are, a priori, considered as text.
They are then filtered according to both local contrast variation and texture
criteria in order to get the effective ones. The resulted text regions are
classified based on a visual grammar descriptor containing a set of semantic
text class regions characterized by visual features. A visual table of content
is then generated based on extracted text regions occurring within video
sequence enriched by a semantic identification. The experimentation performed
on a variety of video sequences shows the efficiency of our approach.
"
440,"AViTExt: Automatic Video Text Extraction, A new Approach for video
  content indexing Application","  In this paper, we propose a spatial temporal video-text detection technique
which proceed in two principal steps:potential text region detection and a
filtering process. In the first step we divide dynamically each pair of
consecutive video frames into sub block in order to detect change. A
significant difference between homologous blocks implies the appearance of an
important object which may be a text region. The temporal redundancy is then
used to filter these regions and forms an effective text region. The
experimentation driven on a variety of video sequences shows the effectiveness
of our approach by obtaining a 89,39% as precision rate and 90,19 as recall.
"
441,A Visual Grammar Approach for TV Program Identification,"  Automatic identification of TV programs within TV streams is an important
task for archive exploitation. This paper proposes a new spatial-temporal
approach to identify programs in TV streams in two main steps: First, a
reference catalogue for video grammars of visual jingles is constructed. We
exploit visual grammars characterizing instances of the same program type in
order to identify the various program types in the TV stream. The role of video
grammar is to represent the visual invariants for each visual jingle using a
set of descriptors appropriate for each TV program. Secondly, programs in TV
streams are identified by examining the similarity of the video signal to the
visual grammars in the catalogue. The main idea of identification process
consists in comparing the visual similarity of the video signal signature in TV
stream to the catalogue elements. After presenting the proposed approach, the
paper overviews the encouraging experimental results on several streams
extracted from different channels and composed of several programs.
"
442,Loss Visibility Optimized Real-time Video Transmission over MIMO Systems,"  The structured nature of video data motivates introducing video-aware
decisions that make use of this structure for improved video transmission over
wireless networks. In this paper, we introduce an architecture for real-time
video transmission over multiple-input multiple-output (MIMO) wireless
communication systems using loss visibility side information. We quantify the
perceptual importance of a packet through the packet loss visibility and use
the loss visibility distribution to provide a notion of relative packet
importance. To jointly achieve video quality and low latency, we define the
optimization objective function as the throughput weighted by the loss
visibility of each packet, a proxy for the total perceptual value of successful
packets per unit time. We solve the problem of mapping video packets to MIMO
subchannels and adapting per-stream rates to maximize the proposed objective.
We show that the solution enables jointly reaping gains in terms of improved
video quality and lower latency. Optimized packet-stream mapping enables
transmission of more relevant packets over more reliable streams while unequal
modulation opportunistically increases the transmission rate on the stronger
streams to enable low latency delivery of high priority packets. We extend the
solution to capture codebook-based limited feedback and MIMO mode adaptation.
Results show that the composite quality and throughput gains are significant
under full channel state information as well as limited feedback. Tested on
H.264-encoded video sequences, for a 4x4 MIMO with 3 spatial streams, the
proposed architecture achieves 8 dB power reduction for the same video quality
and supports 2.4x higher throughput due to unequal modulation. Furthermore, the
gains are achieved at the expense of few bits of cross-layer overhead rather
than a complex cross-layer design.
"
443,SkyDe: a Skype-based Steganographic Method,"  This paper introduces SkyDe (Skype Hide), a new steganographic method that
utilizes Skype encrypted packets with silence to provide the means for
clandestine communication. It is possible to reuse packets that do not carry
voice signals for steganographic purposes because Skype does not use any
silence suppression mechanism. The method's proof-of-concept implementation and
first experimental results are presented. They prove that the method is
feasible and offers steganographic bandwidth as high as 2.8 kbps.
"
444,A Novel Digital Watermarking Algorithm using Random Matrix Image,"  The availability of bandwidth for internet access is sufficient enough to
communicate digital assets. These digital assets are subjected to various types
of threats. [19] As a result of this, protection mechanism required for the
protection of digital assets is of priority in research. The threat of current
focus is unauthorized copying of digital assets which give boost to piracy.
This under the copyright act is illegal and a robust mechanism is required to
curb this kind of unauthorized copy. To safeguard the copyright digital assets,
a robust digital watermarking technique is needed. The existing digital
watermarking techniques protect digital assets by embedding a digital watermark
into a host digital image. This embedding does induce slight distortion in the
host image but the distortion is usually too small to be noticed. At the same
time the embedded watermark must be robust enough to with stand deliberate
attacks. There are various techniques of digital watermarking but researchers
are making constant efforts to increase the robustness of the watermark image.
The layered approach of watermarking based on Huffman coding [5] can soon
increase the robustness of digital watermark.[11] Ultimately, increasing the
security of copyright of protection. The proposed work is in similar direction
where in RMI (Random Matrix Image) is used in place of Huffman coding. This
innovative algorithm has considerably increased the robustness in digital
watermark while also enhancing security of production
"
445,"Video Tester -- A multiple-metric framework for video quality assessment
  over IP networks","  This paper presents an extensible and reusable framework which addresses the
problem of video quality assessment over IP networks. The proposed tool
(referred to as Video-Tester) supports raw uncompressed video encoding and
decoding. It also includes different video over IP transmission methods (i.e.:
RTP over UDP unicast and multicast, as well as RTP over TCP). In addition, it
is furnished with a rich set of offline analysis capabilities. Video-Tester
analysis includes QoS and bitstream parameters estimation (i.e.: bandwidth,
packet inter-arrival time, jitter and loss rate, as well as GOP size and
I-frame loss rate). Our design facilitates the integration of virtually any
existing video quality metric thanks to the adopted Python-based modular
approach. Video-Tester currently provides PSNR, SSIM, ITU-T G.1070 video
quality metric, DIV and PSNR-based MOS estimations. In order to promote its use
and extension, Video-Tester is open and publicly available.
"
446,A new compressive video sensing framework for mobile broadcast,"  A new video coding method based on compressive sampling is proposed. In this
method, a video is coded using compressive measurements on video cubes. Video
reconstruction is performed by minimization of total variation (TV) of the
pixelwise DCT coefficients along the temporal direction. A new reconstruction
algorithm is developed from TVAL3, an efficient TV minimization algorithm based
on the alternating minimization and augmented Lagrangian methods. Video coding
with this method is inherently scalable, and has applications in mobile
broadcast.
"
447,"WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical
  Ontologies","  Ever growing number of image documents available on the Internet continuously
motivates research in better annotation models and more efficient retrieval
methods. Formal knowledge representation of objects and events in pictures,
their interaction as well as context complexity becomes no longer an option for
a quality image repository, but a necessity. We present an ontology-based
online image annotation tool WNtags and demonstrate its usefulness in several
typical multimedia retrieval tasks using International Affective Picture System
emotionally annotated image database. WNtags is built around WordNet lexical
ontology but considers Suggested Upper Merged Ontology as the preferred
labeling formalism. WNtags uses sets of weighted WordNet synsets as high-level
image semantic descriptors and query matching is performed with word stemming
and node distance metrics. We also elaborate our near future plans to expand
image content description with induced affect as in stimuli for research of
human emotion and attention.
"
448,Comparision and analysis of photo image forgery detection techniques,"  Digital Photo images are everywhere, on the covers of magazines, in
newspapers, in courtrooms, and all over the Internet. We are exposed to them
throughout the day and most of the time. Ease with which images can be
manipulated; we need to be aware that seeing does not always imply believing.
We propose methodologies to identify such unbelievable photo images and
succeeded to identify forged region by given only the forged image. Formats are
additive tag for every file system and contents are relatively expressed with
extension based on most popular digital camera uses JPEG and Other image
formats like png, bmp etc. We have designed algorithm running behind with the
concept of abnormal anomalies and identify the forgery regions.
"
449,Adaptive Temporal Compressive Sensing for Video,"  This paper introduces the concept of adaptive temporal compressive sensing
(CS) for video. We propose a CS algorithm to adapt the compression ratio based
on the scene's temporal complexity, computed from the compressed data, without
compromising the quality of the reconstructed video. The temporal adaptivity is
manifested by manipulating the integration time of the camera, opening the
possibility to real-time implementation. The proposed algorithm is a
generalized temporal CS approach that can be incorporated with a diverse set of
existing hardware systems.
"
450,"The Robust Digital Image Watermarking using Quantization and Fuzzy Logic
  Approach in DWT Domain","  In this paper a novel approach to embed watermark into the host image using
quantization with the help of Dynamic Fuzzy Inference System (DFIS) is
proposed. The cover image is decomposed up to 3- levels using quantization and
Discrete Wavelet Transform (DWT). A bitmap of size 64x64 pixels is embedded
into the host image using DFIS rule base. The DFIS is utilized to generate the
watermark weighting function to embed the imperceptible watermark. The
implemented watermarking algorithm is imperceptible and robust to some normal
attacks such as JPEG Compression, salt&pepper noise, median filtering, rotation
and cropping.
  Keywords: Watermark, Quantization, Dynamic Fuzzy Inference System,
Imperceptible, Robust, JPEG Compression, Cropping.
"
451,"An Optical Watermarking Solution for Color Personal Identification
  Pictures","  This paper presents a new approach for embedding authentication information
into image on printed materials based on optical projection technique. Our
experimental setup consists of two parts, one is a common camera, and the other
is a LCD projector, which project a pattern on personnel's body (especially on
the face). The pattern, generated by a computer, act as the illumination light
source with sinusoidal distribution and it is also the watermark signal. For a
color image, the watermark is embedded into the blue channel. While we take
pictures (256 *256 and 512*512, 567*390 pixels, respectively), an invisible
mark is embedded directly into magnitude oefficients of Discrete Fourier
transform (DFT) at exposure moment. Both optical an d digital correlation is
suitable for detection of this type of watermark. The decoded watermark is a
set of concentric circles or sectors in the DFT domain (middle frequencies
region) which is robust to photographing, printing and scanning. The unlawful
people modify or replace the original photograph, and make fake passport
(drivers' license and so on). Experiments show, it is difficult to forge
certificates in which a watermark was embedded by our projector-camera
combination based on analogue watermark method rather than classical digital
method.
"
452,P3: Toward Privacy-Preserving Photo Sharing,"  With increasing use of mobile devices, photo sharing services are
experiencing greater popularity. Aside from providing storage, photo sharing
services enable bandwidth-efficient downloads to mobile devices by performing
server-side image transformations (resizing, cropping). On the flip side, photo
sharing services have raised privacy concerns such as leakage of photos to
unauthorized viewers and the use of algorithmic recognition technologies by
providers. To address these concerns, we propose a privacy-preserving photo
encoding algorithm that extracts and encrypts a small, but significant,
component of the photo, while preserving the remainder in a public,
standards-compatible, part. These two components can be separately stored. This
technique significantly reduces the signal-to-noise ratio and the accuracy of
automated detection and recognition on the public part, while preserving the
ability of the provider to perform server-side transformations to conserve
download bandwidth usage. Our prototype privacy-preserving photo sharing
system, P3, works with Facebook, and can be extended to other services as well.
P3 requires no changes to existing services or mobile application software, and
adds minimal photo storage overhead.
"
453,"The impact of teaching two courses (electronic curriculum design,
  multimedia) on the acquisition of electronic content design skills","  The use of Multimedia applications in Learning provides useful concepts for
Instructional Content Design. This study aimed to investigate the effect of
design electronic curriculum and multimedia applications on acquiring e-content
design skills, and improving their attitudes towards e-learning. To achieve the
objective of the study, the researchers developed a test to measure the
efficiencies of designing electronic content and the measure of attitudes
towards e-learning, The results showed that study of both courses contributed
positively to the acquisition of design skills of e-content, The results
revealed that there are statistical significant differences between the scores
of the students in the two applications (pre and post) on the total score of
the attitude measure and three areas of it.
"
454,Towards a provably resilient scheme for graph-based watermarking,"  Digital watermarks have been considered a promising way to fight software
piracy. Graph-based watermarking schemes encode authorship/ownership data as
control-flow graph of dummy code. In 2012, Chroni and Nikolopoulos developed an
ingenious such scheme which was claimed to withstand attacks in the form of a
single edge removal. We extend the work of those authors in various aspects.
First, we give a formal characterization of the class of graphs generated by
their encoding function. Then, we formulate a linear-time algorithm which
recovers from ill-intentioned removals of $k \leq 2$ edges, therefore proving
their claim. Furthermore, we provide a simpler decoding function and an
algorithm to restore watermarks with an arbitrary number of missing edges
whenever at all possible. By disclosing and improving upon the resilience of
Chroni and Nikolopoulos's watermark, our results reinforce the interest in
regarding it as a possible solution to numerous applications.
"
455,Secure Video Streaming Plug-In,"  Video sharing sites like YouTube, Metacafe, Dailymotion, Vimeo, etc. provide
a platform for media content sharing among its users. Some of these videos are
copyright protected and restricted from being downloaded and saved. But users
can use various download managers or application programs to download and save
these videos. This affects the incoming traffic on these websites reducing
their hit rate and consequently reducing their revenue. Adobe Flash Player is
the most commonly used player for watching online videos. It uses RTMP (Real
Time Messaging Protocol) to stream audio, video and data over the Internet,
between a Flash Player and Adobe Flash Media Server.Here, we propose a plug-in
that enables the site owner control over downloading of videos from such
website. The plug-in will be installed at the client side with the consent of
the user. When the video is being played this plug-in will send unique keys to
the media server. The server will continue streaming the video after verifying
the keys. Download managers or application programs will not be able to
download the videos as they wont be able to create the unique keys that need to
be sent to the server.
"
456,"Medical Information Embedding in Compressed Watermarked Intravascular
  Ultrasound Video","  In medical field, intravascular ultrasound (IVUS) is a tomographic imaging
modality, which can identify the boundaries of different layers of blood
vessels. IVUS can detect myocardial infarction (heart attack) that remains
ignored and unattended when only angioplasty is done. During the past decade,
it became easier for some individuals or groups to copy and transmits digital
information without the permission of the owner. For increasing authentication
and security of copyrights, digital watermarking, an information hiding
technique, was introduced. Achieving watermarking technique with lesser amount
of distortion in biomedical data is a challenging task. Watermark can be
embedded into an image or in a video. As video data is a huge amount of
information, therefore a large storage area is needed which is not feasible. In
this case motion vector based video compression is done to reduce size. In this
present paper, an Electronic Patient Record (EPR) is embedded as watermark
within an IVUS video and then motion vector is calculated. This proposed method
proves robustness as the extracted watermark has good PSNR value and less MSE.
"
457,Image compression using anti-forensics method,"  A large number of image forensics methods are available which are capable of
identifying image tampering. But these techniques are not capable of addressing
the anti-forensics method which is able to hide the trace of image tampering.
In this paper anti-forensics method for digital image compression has been
proposed. This anti-forensics method is capable of removing the traces of image
compression. Additionally, technique is also able to remove the traces of
blocking artifact that are left by image compression algorithms that divide an
image into segments during compression process. This method is targeted to
remove the compression fingerprints of JPEG compression.
"
458,"Proposed Video Encryption Algorithm v/s Other Existing Algorithms: A
  Comparative Study","  Securing multimedia data has become of utmost importance especially in the
applications related to military purposes. With the rise in development in
computer and internet technology, multimedia data has become the most
convenient method for military training. An innovative encryption algorithm for
videos compressed using H.264 was proposed to safely exchange highly
confidential videos. To maintain a balance between security and computational
time, the proposed algorithm shuffles the video frames along with the audio,
and then AES is used to selectively encrypt the sensitive video codewords.
Using this approach unauthorized viewing of the video file can be prevented and
hence this algorithm provides a high level of security. A comparative study of
the proposed algorithm with other existing algorithms has been put forward in
this paper to prove the effectiveness of the proposed algorithm.
"
459,StegTorrent: a Steganographic Method for the P2P File Sharing Service,"  The paper proposes StegTorrent a new network steganographic method for the
popular P2P file transfer service-BitTorrent. It is based on modifying the
order of data packets in the peer-peer data exchange protocol. Unlike other
existing steganographic methods that modify the packets' order it does not
require any synchronization. Experimental results acquired from prototype
implementation proved that it provides high steganographic bandwidth of up to
270 b/s while introducing little transmission distortion and providing
difficult detectability.
"
460,Multimedia stimuli databases usage patterns: a survey report,"  Multimedia documents such as images, sounds or videos can be used to elicit
emotional responses in exposed human subjects. These stimuli are stored in
affective multimedia databases and successfully used for a wide variety of
research in affective computing, human-computer interaction and cognitive
sciences. Affective multimedia databases are simple repositories of multimedia
documents with annotated high-level semantics and affective content. Although
important all affective multimedia databases have numerous deficiencies which
impair their applicability. To establish a better understanding of how experts
use affective multimedia databases an online survey was conducted into the
subject. The survey results are statistically significant and indicate that
contemporary databases lack stimuli with rich semantic and emotional content.
73.33% of survey participants find the databases lacking at least some
important semantic or emotion content. Most of the participants consider
stimuli descriptions to be inadequate. Overall, 1-2h or more than 24h are
generally needed to construct a single stimulation sequence. Almost 84% of the
survey participants would like to use real-life videos in their research.
Experts unequivocally recognize the need for an intelligent stimuli retrieval
application that would assist them in experimentation. Almost all experts agree
such applications could be useful in their work.
"
461,"Odd-Even Embedding Scheme Based Modified Reversible Watermarking
  Technique using Blueprint","  Digital watermarking is a technique of information adding or information
hiding in order to identify the owner of the data in multimedia content. It
seems that a signal or digital image can permanently embed over another digital
data providing a good way to protect intellectual property from illegal
replication. The cover data that is transmitted through the internet hides the
watermark in a computer aided assertion method such that it becomes
undetectable. Finally it stands as a hindrance over many operations without
harming the embedded host document. Unfortunately, many owners of the digital
materials such as images, text, audio and video are reluctant to the spreading
of their documents on the web or other networked environment, because the ease
of duplicating digital materials facilitates copyright violation. Digital media
distribution occurs through various channels. The cover data may or may not
hold any relation with the watermark information. In the last two decades, a
considerable amount of research has been done on the digital watermarking of
multimedia files such as audio, video, images and text. Different type of
watermarking algorithms has been proposed by the researchers to achieve high
level of security and authenticity. In our proposed method, a modified
reversible watermarking technique is introduced, which employs a blueprint
generation of original image based on odd-even embedding methodology to yield
large data hiding capacity, security as well as high watermarked quality. The
experimental results demonstrate that, no matter how much secret data is
embedded, the watermarked quality is about 51dB in this proposed scheme.
"
462,A Modified LSB Technique of Digital Watermarking in Spatial Domain,"  Digital watermarking is a technique of embedding pieces of information into
digital data such as text, audio, video, and still images that can be detected
or extracted later to show authentication about the data. Watermark is hidden
information in the image(s) and is so designed that it does not degrade/distort
the quality of the image and still keeps the information. Digital watermarking
is basically to protect ownership rights and to control of making illicit
copies of digital data. In this paper, we have discussed various watermarking
techniques and properties and have proposed a modified LSB technique. We have
implemented the proposed technique by following: 2-bits of 8-bit gray image is
replaced by luminance part, next 2-bits by red component, next 2-bits by green
component and next 2-bits by blue component of 32-bit image using secret key.
The advantage is that watermarking capacity has been increased and unaffected
by various attacks e.g. zero out LSB bits, cropping etc. Watermark image is
imperceptible in resultant image. We have tested this technique on several
images and found that it is quite satisfactory. This technique is secured as
unauthorized user can not extract the watermarked contents easily from the
original image and works well in adverse situations. We have implemented this
technique on platform java 1.5.0.
"
463,A local fingerprinting approach for audio copy detection,"  This study proposes an audio copy detection system that is robust to various
attacks. These include the severe pitch shift and tempo change attacks which
existing systems fail to detect. First, we propose a novel two dimensional
representation for audio signals called the time-chroma image. This image is
based on a modification of the concept of chroma in the music literature and is
shown to achieve better performance in song identification. Then, we propose a
novel fingerprinting algorithm that extracts local fingerprints from the
time-chroma image. The proposed local fingerprinting algorithm is invariant to
time/frequency scale changes in audio signals. It also outperforms existing
methods like SIFT by a great extent. Finally, we introduce a song
identification algorithm that uses the proposed fingerprints. The resulting
copy detection system is shown to significantly outperform existing methods.
Besides being able to detect whether a song (or a part of it) has been copied,
the proposed system can accurately estimate the amount of pitch shift and/or
tempo change that might have been applied to a song.
"
464,A Review on P2P Video Streaming,"  The main objective of this article is to provide an overview of P2P based
Video-on-Demand and live streaming services. The article starts with an
introduction to media streaming and its simplified architecture. Various
solutions offering video streaming in the context of widespread usage of
Internet are discussed. This is followed by a short introduction to P2P
networks and its applications. A broad discussion on various P2P streaming
schemes and P2P streaming applications are the main focus of this chapter.
Finally, the security issues and solutions for P2P video streaming are
discussed briefly.
"
465,Hiding Image in Image by Five Modulus Method for Image Steganography,"  This paper is to create a practical steganographic implementation to hide
color image (stego) inside another color image (cover). The proposed technique
uses Five Modulus Method to convert the whole pixels within both the cover and
the stego images into multiples of five. Since each pixels inside the stego
image is divisible by five then the whole stego image could be divided by five
to get new range of pixels 0..51. Basically, the reminder of each number that
is not divisible by five is either 1,2,3 or 4 when divided by 5. Subsequently,
then a 4-by-4 window size has been implemented to accommodate the proposed
technique. For each 4-by-4 window inside the cover image, a number from 1 to 4
could be embedded secretly from the stego image. The previous discussion must
be applied separately for each of the R, G, and B arrays. Moreover, a stego-key
could be combined with the proposed algorithm to make it difficult for any
adversary to extract the secret image from the cover image. Based on the PSNR
value, the extracted stego image has high PSNR value. Hence this new
steganography algorithm is very efficient to hide color images.
"
466,Multi-Resolution Video Streaming in Peer-to-peer Networks,"  We consider multi-resolution streaming in fully-connected peer-to-peer
networks, where transmission rates are constrained by arbitrarily specified
upload capacities of the source and peers. We fully characterize the capacity
region of rate vectors achievable with arbitrary coding, where an achievable
rate vector describes a vector of throughputs of the different resolutions that
can be supported by the network. We then prove that all rate vectors in the
capacity region can be achieved using pure routing strategies. This shows that
coding has no capacity advantage over routing in this scenario.
"
467,Genetic Soundtracks: Creative Matching of Audio to Video,"  The matching of the soundtrack in a movie or a video can have an enormous
influence in the message being conveyed and its impact, in the sense of
involvement and engagement, and ultimately in their aesthetic and entertainment
qualities. Art is often associated with creativity, implying the presence of
inspiration, originality and appropriateness. Evolutionary systems provides us
with the novelty, showing us new and subtly different solutions in every
generation, possibly stimulating the creativity of the human using the system.
In this paper, we present Genetic Soundtracks, an evolutionary approach to the
creative matching of audio to a video. It analyzes both media to extract
features based on their content, and adopts genetic algorithms, with the
purpose of truncating, combining and adjusting audio clips, to align and match
them with the video scenes.
"
468,"Anticipatory Buffer Control and Resource Allocation for Wireless Video
  Streaming","  This paper describes a new approach for allocating resources to video
streaming traffic. Assuming that the future channel state can be predicted for
a certain time, we minimize the fraction of the bandwidth consumed for smooth
streaming by jointly allocating wireless channel resources and play-out buffer
size. To formalize this idea, we introduce a new model to capture the dynamic
of a video streaming buffer and the allocated spectrum in an optimization
problem. The result is a Linear Program that allows to trade off buffer size
and allocated bandwidth. Based on this tractable model, our simulation results
show that anticipating poor channel states and pre-loading the buffer
accordingly allows to serve more users at perfect video quality.
"
469,A Secure And High Capacity Image Steganography Technique,"  Steganography is the science of invisible communication. The purpose of
Steganography is to maintain secret communication between two parties. The
secret information can be concealed in content such as image, audio, or video.
This paper provides a novel image steganography technique to hide multiple
secret images and keys in color cover image using Integer Wavelet Transform
(IWT). There is no visual difference between the stego image and the cover
image. The extracted secret images are also similar to the original secret
images. Very good PSNR (Peak Signal to Noise Ratio) values are obtained for
both stego and extracted secret images. The results are compared with the
results of other techniques, where single image is hidden and it is found that
the proposed technique is simple and gives better PSNR values than others.
"
470,Metrics for Video Quality Assessment in Mobile Scenarios,"  With exponential increase in the volumes of video traffic in cellular
net-works, there is an increasing need for optimizing the quality of video
delivery. 4G networks (Long Term Evolution Advanced or LTE A) are being
introduced in many countries worldwide, which allow a downlink speed of upto 1
Gbps and uplink of 100 Mbps over a single base station. This makes a strong
push towards video broadcasting over LTE networks, characterizing its
performance and developing metrics which can be deployed to provide user
feedback of video quality and feed-back them to network operators to fine tune
the network. In this paper, we characterize the performance of video
transmission over LTE A physical layer using popular video quality metrics such
as SSIM, Blocking, Blurring, NIQE and BRISQUE. We conduct experiments to find a
suitable no-reference metrics for mobile scenario and find that Blocking
Metrics is most promising in case of channel or modulation variations but it
does not perform well to quantize variations in compression ratios. The metrics
BRISQUE is very efficient in quantizing this distortion and performs well in
case of network variations also.
"
471,"Combinaison d'information visuelle, conceptuelle, et contextuelle pour
  la construction automatique de hierarchies semantiques adaptees a
  l'annotation d'images","  This paper proposes a new methodology to automatically build semantic
hierarchies suitable for image annotation and classification. The building of
the hierarchy is based on a new measure of semantic similarity. The proposed
measure incorporates several sources of information: visual, conceptual and
contextual as we defined in this paper. The aim is to provide a measure that
best represents image semantics. We then propose rules based on this measure,
for the building of the final hierarchy, and which explicitly encode
hierarchical relationships between different concepts. Therefore, the built
hierarchy is used in a semantic hierarchical classification framework for image
annotation. Our experiments and results show that the hierarchy built improves
classification results.
  Ce papier propose une nouvelle methode pour la construction automatique de
hierarchies semantiques adaptees a la classification et a l'annotation
d'images. La construction de la hierarchie est basee sur une nouvelle mesure de
similarite semantique qui integre plusieurs sources d'informations: visuelle,
conceptuelle et contextuelle que nous definissons dans ce papier. L'objectif
est de fournir une mesure qui est plus proche de la semantique des images. Nous
proposons ensuite des regles, basees sur cette mesure, pour la construction de
la hierarchie finale qui encode explicitement les relations hierarchiques entre
les differents concepts. La hierarchie construite est ensuite utilisee dans un
cadre de classification semantique hierarchique d'images en concepts visuels.
Nos experiences et resultats montrent que la hierarchie construite permet
d'ameliorer les resultats de la classification.
"
472,"Joint On-the-Fly Network Coding/Video Quality Adaptation for Real-Time
  Delivery","  This paper introduces a redundancy adaptation algorithm for an on-the-fly
erasure network coding scheme called Tetrys in the context of real-time video
transmission. The algorithm exploits the relationship between the redundancy
ratio used by Tetrys and the gain or loss in encoding bit rate from changing a
video quality parameter called the Quantization Parameter (QP). Our evaluations
show that with equal or less bandwidth occupation, the video protected by
Tetrys with redundancy adaptation algorithm obtains a PSNR gain up to or more 4
dB compared to the video without Tetrys protection. We demonstrate that the
Tetrys redundancy adaptation algorithm performs well with the variations of
both loss pattern and delay induced by the networks. We also show that Tetrys
with the redundancy adaptation algorithm outperforms FEC with and without
redundancy adaptation.
"
473,Security Issues In Speech Watermarking for Information Transmission,"  The secure transmission of speech information is a significant issue faced by
many security professionals and individuals. By applying voice-encryption
technique any kind of encrypted sensitive speech data such as password can be
transmitted. But this has the serious disadvantage that by means of
cryptanalysis attack encrypted data can be compromised. Increasing the strength
of encryption/decryption results in an associated increased in the cost.
Additional techniques like stenography and digital watermarking can be used to
conceal information in an undetectable way in audio data. However this
watermarked audio data has to be send through unreliable media and an
eavesdropper might get hold of secret message and can also determine the
identity of a speaker who is sending the information since human voice contains
information based on its characteristics such as frequency, pitch, and energy.
This paper proposes Normalized Speech Watermarking technique. Speech signal is
normalized to hide the identity of the speaker who is sending the information
and then speech watermarking technique is applied on this normalized signal
that contains the message (password) so that what information is transmitted
should not be unauthorizedly revealed.
"
474,A new Watermarking Technique for Secure Database,"  Digital multimedia watermarking technology was suggested in the last decade
to embed copyright information in digital objects such images, audio and video.
However, the increasing use of relational database systems in many real-life
applications created an ever increasing need for watermarking database systems.
As a result, watermarking relational database systems is now merging as a
research area that deals with the legal issue of copyright protection of
database systems. Approach: In this study, we proposed an efficient database
watermarking algorithm based on inserting binary image watermarks in
non-numeric mutli-word attributes of selected database tuples. Results: The
algorithm is robust as it resists attempts to remove or degrade the embedded
watermark and it is blind as it does not require the original database in order
to extract the embedded watermark. Conclusion: Experimental results
demonstrated blindness and the robustness of the algorithm against common
database attacks.
"
475,A Novel approach for Hybrid Database,"  In the current world of economic crises, the cost control is one of the chief
concerns for all types of industries, especially for the small venders. The
small vendors are suppose to minimize their budget on Information Technology by
reducing the initial investment in hardware and costly database servers like
ORACLE, SQL Server, SYBASE, etc. for the purpose of data processing and
storing. In other divisions, the electronic devices manufacturing companies
want to increase the demand and reduce the manufacturing cost by introducing
the low cost technologies. The new small devices like ipods, iphones, palm top
etc. are now-a-days used as data computation and storing tools. For both the
cases mentioned above, instead of going for the costly database servers which
additionally requires extra hardware as well as the extra expenses in training
and handling, the flat file may be considered as a candidate due to its easy
handling nature, fast accessing, and of course free of cost. But the main
hurdle is the security aspects which are not up to the optimum level. In this
paper, we propose a methodology that combines all the merit of the flat file
and with the help of a novel steganographic technique we can maintain the
utmost security fence. The new proposed methodology will undoubtedly be highly
beneficial for small vendors as well as for the above said electronic devices
manufacturer
"
476,Adaptive Software Radio Steganography,"  This paper presents an adaptable steganography (information hiding) method
for digital radio communication. Many radio steganography methods exist, but
most are defined at higher levels of the protocol stack and are thus protocol
dependent. In contrast, this method is defined at the physical layer, which
makes it widely applicable regardless of the protocols used at higher layers.
This approach is also adaptive; the covertness of the hidden channel is simple
to control via a single continuous parameter either manually or automatically.
Several variations are introduced, each with performance evaluated by
simulation. Results show this to be a feasible method with a reasonable
trade-off between performance and covertness.
"
477,Secure Transmission of Password Using Speech Watermarking,"  Internet is one of the most valuable resources for information communication
and retrievals. Most multimedia signals today are in digital formats. The
digital data can be duplicated and edited with great ease which has led to a
need for data integrity and protection of digital data. The security
requirements such as integrity or data authentication can be met by
implementing security measures using digital watermarking techniques. In this
paper a blind speech watermarking algorithm that embeds the watermark signal
data in the musical (sequence) host signal by using frequency masking is used.
A different logarithmic approach is proposed. In this regard a logarithmic
function is first applied to watermark data. Then the transformed signal is
embedded to the converted version of host signal which is obtained by applying
Fast Fourier transform method. Finally using inverse Fast Fourier Transform and
antilogarithmic function watermark signal is retrieved.
"
478,Image Compression By Embedding Five Modulus Method Into JPEG,"  The standard JPEG format is almost the optimum format in image compression.
The compression ratio in JPEG sometimes reaches 30:1. The compression ratio of
JPEG could be increased by embedding the Five Modulus Method (FMM) into the
JPEG algorithm. The novel algorithm gives twice the time as the standard JPEG
algorithm or more. The novel algorithm was called FJPEG (Five-JPEG). The
quality of the reconstructed image after compression is approximately
approaches the JPEG. Standard test images have been used to support and
implement the suggested idea in this paper and the error metrics have been
computed and compared with JPEG.
"
479,Video Segmentation via Diffusion Bases,"  Identifying moving objects in a video sequence, which is produced by a static
camera, is a fundamental and critical task in many computer-vision
applications. A common approach performs background subtraction, which
identifies moving objects as the portion of a video frame that differs
significantly from a background model. A good background subtraction algorithm
has to be robust to changes in the illumination and it should avoid detecting
non-stationary background objects such as moving leaves, rain, snow, and
shadows. In addition, the internal background model should quickly respond to
changes in background such as objects that start to move or stop. We present a
new algorithm for video segmentation that processes the input video sequence as
a 3D matrix where the third axis is the time domain. Our approach identifies
the background by reducing the input dimension using the \emph{diffusion bases}
methodology. Furthermore, we describe an iterative method for extracting and
deleting the background. The algorithm has two versions and thus covers the
complete range of backgrounds: one for scenes with static backgrounds and the
other for scenes with dynamic (moving) backgrounds.
"
480,"Computing a k-sparse n-length Discrete Fourier Transform using at most
  4k samples and O(k log k) complexity","  Given an $n$-length input signal $\mbf{x}$, it is well known that its
Discrete Fourier Transform (DFT), $\mbf{X}$, can be computed in $O(n \log n)$
complexity using a Fast Fourier Transform (FFT). If the spectrum $\mbf{X}$ is
exactly $k$-sparse (where $k<<n$), can we do better? We show that
asymptotically in $k$ and $n$, when $k$ is sub-linear in $n$ (precisely, $k
\propto n^{\delta}$ where $0 < \delta <1$), and the support of the non-zero DFT
coefficients is uniformly random, we can exploit this sparsity in two
fundamental ways (i) {\bf {sample complexity}}: we need only $M=rk$
deterministically chosen samples of the input signal $\mbf{x}$ (where $r < 4$
when $0 < \delta < 0.99$); and (ii) {\bf {computational complexity}}: we can
reliably compute the DFT $\mbf{X}$ using $O(k \log k)$ operations, where the
constants in the big Oh are small and are related to the constants involved in
computing a small number of DFTs of length approximately equal to the sparsity
parameter $k$. Our algorithm succeeds with high probability, with the
probability of failure vanishing to zero asymptotically in the number of
samples acquired, $M$.
"
481,Performance Evaluation of Video Communications over 4G Network,"  With exponential increase in the volumes of video traffic in cellular
net-works, there is an increasing need for optimizing the quality of video
delivery. 4G networks (Long Term Evolution Advanced or LTE A) are being
introduced in many countries worldwide, which allow a downlink speed of upto 1
Gbps and uplink of 100 Mbps over a single base station. In this paper, we
characterize the performance of LTE A physical layer in terms of transmitted
video quality when the channel condi-tions and LTE settings are varied. We test
the performance achieved as the channel quality is changed and HARQ features
are enabled in physical layer. Blocking and blurring metrics were used to model
image quality.
"
482,"An Adaptive Statistical Non-uniform Quantizer for Detail Wavelet
  Components in Lossy JPEG2000 Image Compression","  The paper presents a non-uniform quantization method for the Detail
components in the JPEG2000 standard. Incorporating the fact that the
coefficients lying towards the ends of the histogram plot of each Detail
component represent the structural information of an image, the quantization
step sizes become smaller at they approach the ends of the histogram plot. The
variable quantization step sizes are determined by the actual statistics of the
wavelet coefficients. Mean and standard deviation are the two statistical
parameters used iteratively to obtain the variable step sizes. Moreover, the
mean of the coefficients lying within the step size is chosen as the quantized
value, contrary to the deadzone uniform quantizer which selects the midpoint of
the quantization step size as the quantized value. The experimental results of
the deadzone uniform quantizer and the proposed non-uniform quantizer are
objectively compared by using Mean-Squared Error (MSE) and Mean Structural
Similarity Index Measure (MSSIM), to evaluate the quantization error and
reconstructed image quality, respectively. Subjective analysis of the
reconstructed images is also carried out. Through the objective and subjective
assessments, it is shown that the non-uniform quantizer performs better than
the deadzone uniform quantizer in the perceptual quality of the reconstructed
image, especially at low bitrates. More importantly, unlike the deadzone
uniform quantizer, the non-uniform quantizer accomplishes better visual quality
with a few quantized values.
"
483,"Quantum Image Representation Through Two-Dimensional Quantum States and
  Normalized Amplitude","  We propose a novel method for image representation in quantum computers,
which uses the two-dimensional (2-D) quantum states to locate each pixel in an
image through row-location and column-location vectors for identifying each
pixel location. The quantum state of an image is the linear superposition of
the tensor product of the m-qubits row-location vector and the n-qubits
column-location vector of each pixel. It enables the natural quantum
representation of rectangular images that other methods lack. The
amplitude/intensity of each pixel is incorporated into the coefficient values
of the pixel's quantum state, without using any qubits. Due to the fact that
linear superposition, tensor product and qubits form the fundamental basis of
quantum computing, the proposed method presents the machine level
representation of images on quantum computers. Unlike other methods, this
method is a pure quantum representation without any classical components.
"
484,Wave Atom Based Watermarking,"  Watermarking helps in ensuring originality, ownership and copyrights of a
digital image. This paper aims at embedding a Watermark in an image using Wave
Atom Transform. Preference of Wave Atoms on other transformations has been due
to its sparser expansion, adaptability to the direction of local pattern, and
sharp frequency localization. In this scheme, we had tried to spread the
watermark in an image so that the information at one place is very small and
undetectable. In order to extract the watermark and verify ownership of an
image, one would have the advantage of prior knowledge of embedded locations. A
noise of high amplitude will be needed to be added to the image for watermark
distortion. Furthermore, the information spread will ensure the robustness of
the watermark data. The proposed scheme has the ability to withstand malicious
operations and attacks.
"
485,"Utility Optimal Scheduling and Admission Control for Adaptive Video
  Streaming in Small Cell Networks","  We consider the jointly optimal design of a transmission scheduling and
admission control policy for adaptive video streaming over small cell networks.
We formulate the problem as a dynamic network utility maximization and observe
that it naturally decomposes into two subproblems: admission control and
transmission scheduling. The resulting algorithms are simple and suitable for
distributed implementation. The admission control decisions involve each user
choosing the quality of the video chunk asked for download, based on the
network congestion in its neighborhood. This form of admission control is
compatible with the current video streaming technology based on the DASH
protocol over TCP connections. Through simulations, we evaluate the performance
of the proposed algorithm under realistic assumptions for a small-cell network.
"
486,Sparse Norm Filtering,"  Optimization-based filtering smoothes an image by minimizing a fidelity
function and simultaneously preserves edges by exploiting a sparse norm penalty
over gradients. It has obtained promising performance in practical problems,
such as detail manipulation, HDR compression and deblurring, and thus has
received increasing attentions in fields of graphics, computer vision and image
processing. This paper derives a new type of image filter called sparse norm
filter (SNF) from optimization-based filtering. SNF has a very simple form,
introduces a general class of filtering techniques, and explains several
classic filters as special implementations of SNF, e.g. the averaging filter
and the median filter. It has advantages of being halo free, easy to implement,
and low time and memory costs (comparable to those of the bilateral filter).
Thus, it is more generic than a smoothing operator and can better adapt to
different tasks. We validate the proposed SNF by a wide variety of applications
including edge-preserving smoothing, outlier tolerant filtering, detail
manipulation, HDR compression, non-blind deconvolution, image segmentation, and
colorization.
"
487,"Using Bias Optimization for Reversible Data Hiding Using Image
  Interpolation","  In this paper, we propose a reversible data hiding method in the spatial
domain for compressed grayscale images. The proposed method embeds secret bits
into a compressed thumbnail of the original image by using a novel
interpolation method and the Neighbour Mean Interpolation (NMI) technique as
scaling up to the original image occurs. Experimental results presented in this
paper show that the proposed method has significantly improved embedding
capacities over the approach proposed by Jung and Yoo.
"
488,"Optimal Frame Transmission for Scalable Video with Hierarchical
  Prediction Structure","  An optimal frame transmission scheme is presented for streaming scalable
video over a link with limited capacity. The objective is to select a
transmission sequence of frames and their transmission schedule such that the
overall video quality is maximized. The problem is solved for two general
classes of hierarchical prediction structures, which include as a special case
the popular dyadic structure. Based on a new characterization of the
interdependence among frames in terms of trees, structural properties of an
optimal transmission schedule are derived. These properties lead to the
development of a jointly optimal frame selection and scheduling algorithm,
which has computational complexity that is quadratic in the number of frames.
Simulation results show that the optimal scheme substantially outperforms three
existing alternatives.
"
489,"Wireless Device-to-Device Caching Networks: Basic Principles and System
  Performance","  As wireless video transmission is the fastest-growing form of data traffic,
methods for spectrally efficient video on-demand wireless streaming are
essential to service providers and users alike. A key property of video
on-demand is the asynchronous content reuse, such that a few dominant videos
account for a large part of the traffic, but are viewed by users at different
times. Caching of content on devices in conjunction with D2D communications
allows to exploit this property, and provide a network throughput that is
significantly in excess of both the conventional approach of unicasting from
the base station and the traditional D2D networks for regular data traffic.
This paper presents in a semi-tutorial concise form some recent results on the
throughput scaling laws of wireless networks with caching and asynchronous
content reuse, contrasting the D2D approach with a competing approach based on
combinatorial cache design and network coded transmission from the base station
(BS) only, referred to as coded multicasting. Interestingly, the spatial reuse
gain of the former and the coded multicasting gain of the latter yield, somehow
surprisingly, the same near-optimal throughput behavior in the relevant regime
where the number of video files in the library is smaller than the number of
streaming users. Based on our recent theoretical results, we propose a holistic
D2D system design that incorporates traditional microwave (2 GHz) as well as
millimeter-wave D2D links; the direct connections to the base station can be
used to provide those rare video requests that cannot be found in local caches.
We provide extensive simulations under a variety of system settings, and
compare our scheme with other existing schemes by the BS. We show that, despite
the similar behavior of the scaling laws, the proposed D2D approach offers very
significant throughput gains with respect to the BS-only schemes.
"
490,"Loss-resilient Coding of Texture and Depth for Free-viewpoint Video
  Conferencing","  Free-viewpoint video conferencing allows a participant to observe the remote
3D scene from any freely chosen viewpoint. An intermediate virtual viewpoint
image is commonly synthesized using two pairs of transmitted texture and depth
maps from two neighboring captured viewpoints via depth-image-based rendering
(DIBR). To maintain high quality of synthesized images, it is imperative to
contain the adverse effects of network packet losses that may arise during
texture and depth video transmission. Towards this end, we develop an
integrated approach that exploits the representation redundancy inherent in the
multiple streamed videos a voxel in the 3D scene visible to two captured views
is sampled and coded twice in the two views. In particular, at the receiver we
first develop an error concealment strategy that adaptively blends
corresponding pixels in the two captured views during DIBR, so that pixels from
the more reliable transmitted view are weighted more heavily. We then couple it
with a sender-side optimization of reference picture selection (RPS) during
real-time video coding, so that blocks containing samples of voxels that are
visible in both views are more error-resiliently coded in one view only, given
adaptive blending will erase errors in the other view. Further, synthesized
view distortion sensitivities to texture versus depth errors are analyzed, so
that relative importance of texture and depth code blocks can be computed for
system-wide RPS optimization. Experimental results show that the proposed
scheme can outperform the use of a traditional feedback channel by up to 0.82
dB on average at 8% packet loss rate, and by as much as 3 dB for particular
frames.
"
491,Fast Autocorrelated Context Models for Data Compression,"  A method is presented to automatically generate context models of data by
calculating the data's autocorrelation function. The largest values of the
autocorrelation function occur at the offsets or lags in the bitstream which
tend to be the most highly correlated to any particular location. These offsets
are ideal for use in predictive coding, such as predictive partial match (PPM)
or context-mixing algorithms for data compression, making such algorithms more
efficient and more general by reducing or eliminating the need for ad-hoc
models based on particular types of data. Instead of using the definition of
the autocorrelation function, which considers the pairwise correlations of data
requiring O(n^2) time, the Weiner-Khinchin theorem is applied, quickly
obtaining the autocorrelation as the inverse Fast Fourier transform of the
data's power spectrum in O(n log n) time, making the technique practical for
the compression of large data objects. The method is shown to produce the
highest levels of performance obtained to date on a lossless image compression
benchmark.
"
492,Resource Efficient LDPC Decoders for Multimedia Communication,"  Achieving high image quality is an important aspect in an increasing number
of wireless multimedia applications. These applications require resource
efficient error correction hardware to detect and correct errors introduced by
the communication channel. This paper presents an innovative flexible
architecture for error correction using Low-Density Parity-Check (LDPC) codes.
The proposed partially-parallel decoder architecture utilizes a novel code
construction technique based on multi-level Hierarchical Quasi-Cyclic (HQC)
matrix with innovative layering of random sub-matrices. Simulation of a
high-level MATLAB model shows that the proposed HQC matrices have bit error
rate (BER) performance close to that of unstructured random matrices. The
proposed decoder has been implemented on FPGA. It is very resource efficient
and provides very high throughput compared to other decoders reported to date.
Performance evaluation of the decoder has been carried out by transmitting JPEG
images over an AWGN channel and comparing the quality of the reconstructed
images with those from other decoders.
"
493,"The Story of Telebrain: A multi-performer telematic platform for
  performatization","  This paper presents Telebrain, a browser-based performatization platform
invented for organizing real-time telematic performances. Performatization is
the human performance of algorithms. When computers and humans performatize
cooperatively, the human-computer interaction (HCI) becomes the location of
computation. Novel modes of machine-human communication are necessary for
organizing performatizations. Telebrain is designed to facilitate machine-human
languages. Capitalizing on the ubiquity and cross-platform compatibility of the
Internet, Telebrain is an open-source web application supporting PerPL
(Performer Programming Language), a human-interpreted configurable language of
multi-media instructions used to program performers. Telebrain facilitates a
variety of performance disciplines such as music, theater, dance, computational
performance, networked scoring (image and audio), prompted improvisation,
real-space multi-player gaming, collaborative transdisciplinary karaoke and
quantum square-dancing. (http://telebrain.org)
"
494,Survey on QoE\QoS Correlation Models For Multimedia Services,"  This paper presents a brief review of some existing correlation models which
attempt to map Quality of Service (QoS) to Quality of Experience (QoE) for
multimedia services. The term QoS refers to deterministic network behaviour, so
that data can be transported with a minimum of packet loss, delay and maximum
bandwidth. QoE is a subjective measure that involves human dimensions; it ties
together user perception, expectations, and experience of the application and
network performance. The Holy Grail of subjective measurement is to predict it
from the objective measurements; in other words predict QoE from a given set of
QoS parameters or vice versa. Whilst there are many quality models for
multimedia, most of them are only partial solutions to predicting QoE from a
given QoS. This contribution analyses a number of previous attempts and
optimisation techniquesthat can reliably compute the weighting coefficients for
the QoS/QoE mapping.
"
495,"CUDA Based Performance Evaluation of the Computational Efficiency of the
  DCT Image Compression Technique on Both the CPU and GPU","  Recent advances in computing such as the massively parallel GPUs (Graphical
Processing Units),coupled with the need to store and deliver large quantities
of digital data especially images, has brought a number of challenges for
Computer Scientists, the research community and other stakeholders. These
challenges, such as prohibitively large costs to manipulate the digital data
amongst others, have been the focus of the research community in recent years
and has led to the investigation of image compression techniques that can
achieve excellent results. One such technique is the Discrete Cosine Transform,
which helps separate an image into parts of differing frequencies and has the
advantage of excellent energy-compaction.
  This paper investigates the use of the Compute Unified Device Architecture
(CUDA) programming model to implement the DCT based Cordic based Loeffler
algorithm for efficient image compression. The computational efficiency is
analyzed and evaluated under both the CPU and GPU. The PSNR (Peak Signal to
Noise Ratio) is used to evaluate image reconstruction quality in this paper.
The results are presented and discussed.
"
496,"Cache-Enabled Opportunistic Cooperative MIMO for Video Streaming in
  Wireless Systems","  We propose a cache-enabled opportunistic cooperative MIMO (CoMP) framework
for wireless video streaming. By caching a portion of the video files at the
relays (RS) using a novel MDS-coded random cache scheme, the base station (BS)
and RSs opportunistically employ CoMP to achieve spatial multiplexing gain
without expensive payload backhaul. We study a two timescale joint optimization
of power and cache control to support real-time video streaming. The cache
control is to create more CoMP opportunities and is adaptive to the long-term
popularity of the video files. The power control is to guarantee the QoS
requirements and is adaptive to the channel state information (CSI), the cache
state at the RS and the queue state information (QSI) at the users. The joint
problem is decomposed into an inner power control problem and an outer cache
control problem. We first derive a closed-form power control policy from an
approximated Bellman equation. Based on this, we transform the outer problem
into a convex stochastic optimization problem and propose a stochastic
subgradient algorithm to solve it. Finally, the proposed solution is shown to
be asymptotically optimal for high SNR and small timeslot duration. Its
superior performance over various baselines is verified by simulations.
"
497,Sparse Representation-based Image Quality Assessment,"  A successful approach to image quality assessment involves comparing the
structural information between a distorted and its reference image. However,
extracting structural information that is perceptually important to our visual
system is a challenging task. This paper addresses this issue by employing a
sparse representation-based approach and proposes a new metric called the
\emph{sparse representation-based quality} (SPARQ) \emph{index}. The proposed
method learns the inherent structures of the reference image as a set of basis
vectors, such that any structure in the image can be represented by a linear
combination of only a few of those basis vectors. This sparse strategy is
employed because it is known to generate basis vectors that are qualitatively
similar to the receptive field of the simple cells present in the mammalian
primary visual cortex. The visual quality of the distorted image is estimated
by comparing the structures of the reference and the distorted images in terms
of the learnt basis vectors resembling cortical cells. Our approach is
evaluated on six publicly available subject-rated image quality assessment
datasets. The proposed SPARQ index consistently exhibits high correlation with
the subjective ratings on all datasets and performs better or at par with the
state-of-the-art.
"
498,Document watermarking based on digital holographic principle,"  A new method for document watermarking based on the digital Fourier hologram
is proposed. It applies the methods of digital image watermarking based on
holographic principle presented previously in several papers into printed
documents. Experimental results show that the proposed method can not only meet
the demand on invisibility, robustness and non-reproducibility of the document
watermark, and but also has other advantages compared with the conventional
methods for document securities such as embossed hologram, Lippmann photograph
and halftone modulation.
"
499,Enhanced Tiny Encryption Algorithm with Embedding (ETEA),"  As computer systems become more pervasive and complex, security is
increasingly important. Secure Transmission refers to the transfer of data such
as confidential or proprietary information over a secure channel. Many secure
transmission methods require a type of encryption. Secure transmissions are put
in place to prevent attacks such as ARP spoofing and general data loss. Hence,
in order to provide a better security mechanism, in this paper we propose
Enhanced Tiny Encryption Algorithm with Embedding (ETEA), a data hiding
technique called steganography along with the technique of encryption
(Cryptography). The advantage of ETEA is that it incorporates cryptography and
steganography. The advantage proposed algorithm is that it hides the messages.
"
500,"Increasing Compression Ratio in PNG Images by k-Modulus Method for Image
  Transformation","  Image compression is an important filed in image processing. The science
welcomes any tinny contribution that may increase the compression ratio by
whichever insignificant percentage. Therefore, the essential contribution in
this paper is to increase the compression ratio for the well known Portable
Network Graphics (PNG) image file format. The contribution starts with
converting the original PNG image into k-Modulus Method (k-MM). Practically,
taking k equals to ten, and then the pixels in the constructed image will be
integers divisible by ten. Since PNG uses Lempel-Ziv compression algorithm,
then the ability to reduce file size will increase according to the repetition
in pixels in each k-by-k window according to the transformation done by k-MM.
Experimental results show that the proposed technique (k-PNG) produces high
compression ratio with smaller file size in comparison to the original PNG
file.
"
501,"A Novel Steganography Algorithm for Hiding Text in Image using Five
  Modulus Method","  The needs for steganographic techniques for hiding secret message inside
images have been arise. This paper is to create a practical steganographic
implementation to hide text inside grey scale images. The secret message is
hidden inside the cover image using Five Modulus Method. The novel algorithm is
called (ST-FMM. FMM which consists of transforming all the pixels within the
5X5 window size into its corresponding multiples of 5. After that, the secret
message is hidden inside the 5X5 window as a non-multiples of 5. Since the
modulus of non-multiples of 5 are 1,2,3 and 4, therefore; if the reminder is
one of these, then this pixel represents a secret character. The secret key
that has to be sent is the window size. The main advantage of this novel
algorithm is to keep the size of the cover image constant while the secret
message increased in size. Peak signal-to-noise ratio is captured for each of
the images tested. Based on the PSNR value of each images, the stego image has
high PSNR value. Hence this new steganography algorithm is very efficient to
hide the data inside the image.
"
502,Single Video Performance Analysis for Video-on-Demand Systems,"  We study the content placement problem for cache delivery video-on-demand
systems under static random network topologies with fixed heavy-tailed video
demand. The performance measure is the amount of server load; we wish to
minimize the total download rate for all users from the server and maximize the
rate from caches. Our approach reduces the analysis for multiple videos to
consideration of decoupled systems with a single video each. For each placement
policy, insights gained from the single video analysis carry back to the
original multiple video content placement problem. Finally, we propose a hybrid
placement technique that achieves near optimal performance with low complexity.
"
503,"A Novel Robust Method to Add Watermarks to Bitmap Images by Fading
  Technique","  Digital water marking is one of the essential fields in image security and
copyright protection. The proposed technique in this paper was based on the
principle of protecting images by hide an invisible watermark in the image. The
technique starts with merging the cover image and the watermark image with
suitable ratios, i.e., 99% from the cover image will be merged with 1% from the
watermark image. Technically, the fading process is irreversible but with the
proposed technique, the probability to reconstruct the original watermark image
is great. There is no perceptible difference between the original and
watermarked image by human eye. The experimental results show that the proposed
technique proven its ability to hide images that have the same size of the
cover image. Three performance measures were implemented to support the
proposed techniques which are MSE, PSNR, and SSIM. Fortunately, all the three
measures have excellent values.
"
504,"Anisotropic Diffusion for Details Enhancement in Multi-Exposure Image
  Fusion","  We develop a multiexposure image fusion method based on texture features,
which exploits the edge preserving and intraregion smoothing property of
nonlinear diffusion filters based on partial differential equations (PDE). With
the captured multiexposure image series, we first decompose images into base
layers and detail layers to extract sharp details and fine details,
respectively. The magnitude of the gradient of the image intensity is utilized
to encourage smoothness at homogeneous regions in preference to inhomogeneous
regions. Then, we have considered texture features of the base layer to
generate a mask (i.e., decision mask) that guides the fusion of base layers in
multiresolution fashion. Finally, well-exposed fused image is obtained that
combines fused base layer and the detail layers at each scale across all the
input exposures. Proposed algorithm skipping complex High Dynamic Range Image
(HDRI) generation and tone mapping steps to produce detail preserving image for
display on standard dynamic range display devices. Moreover, our technique is
effective for blending flash/no-flash image pair and multifocus images, that
is, images focused on different targets.
"
505,"Comparison of secure and high capacity color image steganography
  techniques in RGB and YCbCr domains","  Steganography is one of the methods used for secret communication.
Steganography attempts to hide the existence of the information. The object
used to hide the secret information is called as cover object. Images are the
most popular cover objects used for steganography. Different techniques have to
be used for color image steganography and grey scale image steganography since
they are stored in different ways. Color image are normally stored with 24 bit
depth and grey scale images are stored with 8 bit depth. Color images can hold
large amount of secret information since they have three color components.
Different color spaces namely RGB (Red Green Blue), HSV (Hue, Saturation,
Value), YUV, YIQ, YCbCr (Luminance, Chrominance) etc. are used to represent
color images. Color image steganography can be done in any color space domain.
In this paper color image steganography in RGB and YCbCr domain are compared.
The secret information considered is grey scale image. Since RGB is the common
method of representation, hiding secret information in this format is not
secure.
"
506,"A dwt, dct and svd based watermarking technique to protect the image
  piracy","  With the rapid development of information technology and multimedia, the use
of digital data is increasing day by day. So it becomes very essential to
protect multimedia information from piracy and also it is challenging. A great
deal of Copyright owners is worried about protecting any kind of illegal
repetition of their information. Hence, facing all these kinds of problems
development of the techniques is very important. Digital watermarking
considered as a solution to prevent the multimedia data. In this paper, an idea
of watermarking is proposed and implemented. In proposed watermarking method,
the original image is rearranged using zigzag sequence and DWT is applied on
rearranged image. Then DCT and SVD are applied on all high bands LH, HL and HH.
Watermark is then embedded by modifying the singular values of these bands.
Extraction of watermark is performed by the inversion of watermark embedding
process. For choosing of these three bands it gives facility of mid-band and
pure high band that ensures good imperceptibility and more robustness against
different kinds of attacks.
"
507,Multiview Hessian Discriminative Sparse Coding for Image Annotation,"  Sparse coding represents a signal sparsely by using an overcomplete
dictionary, and obtains promising performance in practical computer vision
applications, especially for signal restoration tasks such as image denoising
and image inpainting. In recent years, many discriminative sparse coding
algorithms have been developed for classification problems, but they cannot
naturally handle visual data represented by multiview features. In addition,
existing sparse coding algorithms use graph Laplacian to model the local
geometry of the data distribution. It has been identified that Laplacian
regularization biases the solution towards a constant function which possibly
leads to poor extrapolating power. In this paper, we present multiview Hessian
discriminative sparse coding (mHDSC) which seamlessly integrates Hessian
regularization with discriminative sparse coding for multiview learning
problems. In particular, mHDSC exploits Hessian regularization to steer the
solution which varies smoothly along geodesics in the manifold, and treats the
label information as an additional view of feature for incorporating the
discriminative power for image annotation. We conduct extensive experiments on
PASCAL VOC'07 dataset and demonstrate the effectiveness of mHDSC for image
annotation.
"
508,Smart Streaming for Online Video Services,"  Bandwidth consumption is a significant concern for online video service
providers. Practical video streaming systems usually use some form of HTTP
streaming (progressive download) to let users download the video at a faster
rate than the video bitrate. Since users may quit before viewing the complete
video, however, much of the downloaded video will be ""wasted"". To the extent
that users' departure behavior can be predicted, we develop smart streaming
that can be used to improve user QoE with limited server bandwidth or save
bandwidth cost with unlimited server bandwidth. Through measurement, we extract
certain user behavior properties for implementing such smart streaming, and
demonstrate its advantage using prototype implementation as well as
simulations.
"
509,"Digital Watermarking for Image AuthenticationBased on Combined DCT, DWT
  and SVD Transformation","  This paper presents a hybrid digital image watermarking based on Discrete
Wavelet Transform (DWT), Discrete Cosine Transform (DCT) and Singular Value
Decomposition (SVD) in a zigzag order. From DWT we choose the high band to
embed the watermark that facilities to add more information, gives more
invisibility and robustness against some attacks. Such as geometric attack.
Zigzag method is applied to map DCT coefficients into four quadrants that
represent low, mid and high bands. Finally, SVD is applied to each quadrant.
"
510,Study of Encryption and Decryption of Wave File in Image Formats,"  This paper describes a novel method of encrypting wave files in popular image
formats like JPEG, TIF and PNG along with retrieving them from these image
files. MATLAB software is used to perform matrix manipulation to encrypt and
decrypt sound files into and from image files. This method is not only a
stenographic means but also a data compression technique.
"
511,NOVA: QoE-driven Optimization of DASH-based Video Delivery in Networks,"  We consider the problem of optimizing video delivery for a network supporting
video clients streaming stored video. Specifically, we consider the problem of
jointly optimizing network resource allocation and video quality adaptation.
Our objective is to fairly maximize video clients' Quality of Experience (QoE)
realizing tradeoffs among the mean quality, temporal variability in quality,
and fairness, incorporating user preferences on rebuffering and cost of video
delivery. We present a simple asymptotically optimal online algorithm, NOVA, to
solve the problem. NOVA is asynchronous, and using minimal communication,
distributes the tasks of resource allocation to network controller, and quality
adaptation to respective video clients. Video quality adaptation in NOVA is
also optimal for standalone video clients, and is well suited for use with DASH
framework. Further, we extend NOVA for use with more general QoE models,
networks shared with other traffic loads and networks using fixed/legacy
resource allocation.
"
512,A simple technique for steganography,"  A new technique for data hiding in digital image is proposed in this paper.
Steganography is a well known technique for hiding data in an image, but
generally the format of image plays a pivotal role in it, and the scheme is
format dependent. In this paper we will discuss a new technique where
irrespective of the format of image, we can easily hide a large amount of data
without deteriorating the quality of the image. The data to be hidden is
enciphered with the help of a secret key. This enciphered data is then embedded
at the end of the image. The enciphered data bits are extracted and then
deciphered with the help of same key used for encryption. Simulation results
show that Image Quality Measures of this proposed scheme are better than the
conventional LSB replacing technique. The proposed method is simple and is easy
to implement.
"
513,"MAS for video objects segmentation and tracking based on active contours
  and SURF descriptor","  In computer vision, video segmentation and tracking is an important
challenging issue. In this paper, we describe a new video sequences
segmentation and tracking algorithm based on MAS ""multi-agent systems"" and SURF
""Speeded Up Robust Features"". Our approach consists in modelling a multi-agent
system for segmenting the first image from a video sequence and tracking
objects in the video sequences. The used agents are supervisor and explorator
agents, they are communicating between them and they inspire in their behavior
from active contours approaches. The tracking of objects is based on SURF
descriptors ""Speed Up Robust Features"". We used the DIMA platform and ""API
Ateji PX"" (an extension of the Java language to facilitate parallel programming
on heterogeneous architectures) to implement this algorithm. The experimental
results indicate that the proposed algorithm is more robust and faster than
previous approaches.
"
514,"Improved Watermarking Scheme Using Discrete Cosine Transform and Schur
  Decomposition","  Watermarking is a technique which consists in introducing a brand, the name
or the logo of the author, in an image in order to protect it against illegal
copy. The capacity of the existing watermark channel is often limited. We
propose in this paper a new robust method which consists in adding the
triangular matrix of the mark obtained after the Schur decomposition to the DCT
transform of the host image. The unitary matrix acts as secret key for the
extraction of the mark. Unlike most watermarking algorithms, the host image and
the mark have the same size. The results show that our method is robust against
attack techniques as : JPEG compression, colors reducing, adding noise,
filtering, cropping, low rotations, and histogram spreading.
"
515,Image Integrity Authentication Scheme Based On Fixed Point Theory,"  Based on fixed point theory, this paper proposes a new scheme for image
integrity authentication, which is different from Digital Signature and Fragile
Watermarking. A realization of the new scheme is given based on Gaussian
Convolution and Deconvolution (GCD) functions. For a given image, if it is
invariant under a GCD function, we call it GCD fixed point image. An existence
theorem of fixed points for GCD functions is proved and an iterative algorithm
is presented for finding fixed points. Experiments show that GCD fixed point
images perform well in transparence, fragility, security and tampering
localization.
"
516,Multimodal Approach for Video Surveillance Indexing and Retrieval,"  In this paper, we present an overview of a multimodal system to indexing and
searching video sequence by the content that has been developed within the
REGIMVid project. A large part of our system has been developed as part of
TRECVideo evaluation. The MAVSIR platform provides High-level feature
extraction from audio-visual content and concept/event-based video retrieval.
We illustrate the architecture of the system as well as provide an overview of
the descriptors supported to date. Then we demonstrate the usefulness of the
toolbox in the context of feature extraction, concepts/events learning and
retrieval in large collections of video surveillance dataset. The results are
encouraging as we are able to get good results on several event categories,
while for all events we have gained valuable insights and experience.
"
517,Benchmarking Soundtrack Recommendation Systems with SRBench,"  In this work, a benchmark to evaluate the retrieval performance of soundtrack
recommendation systems is proposed. Such systems aim at finding songs that are
played as background music for a given set of images. The proposed benchmark is
based on preference judgments, where relevance is considered a continuous
ordinal variable and judgments are collected for pairs of songs with respect to
a query (i.e., set of images). To capture a wide variety of songs and images,
we use a large space of possible music genres, different emotions expressed
through music, and various query-image themes. The benchmark consists of two
types of relevance assessments: (i) judgments obtained from a user study, that
serve as a ""gold standard"" for (ii) relevance judgments gathered through
Amazon's Mechanical Turk. We report on an analysis of relevance judgments based
on different levels of user agreement and investigate the performance of two
state-of-the-art soundtrack recommendation systems using the proposed
benchmark.
"
518,A Latent Social Approach to YouTube Popularity Prediction,"  Current works on Information Centric Networking assume the spectrum of
caching strategies under the Least Recently/ Frequently Used (LRFU) scheme as
the de-facto standard, due to the ease of implementation and easier analysis of
such strategies. In this paper we predict the popularity distribution of
YouTube videos within a campus network. We explore two broad approaches in
predicting the popularity of videos in the network: consensus approaches based
on aggregate behavior in the network, and social approaches based on the
information diffusion over an implicit network. We measure the performance of
our approaches under a simple caching framework by picking the k most popular
videos according to our predicted distribution and calculating the hit rate on
the cache. We develop our approach by first incorporating video inter-arrival
time (based on the power-law distribution governing the transmission time
between two receivers of the same message in scale-free networks) to the
baseline (LRFU), then combining with an information diffusion model over the
inferred latent social graph that governs diffusion of videos in the network.
We apply techniques from latent social network inference to learn the sharing
probabilities between users in the network and apply a virus propagation model
borrowed from mathematical epidemiology to estimate the number of times a video
will be accessed in the future. Our approach gives rise to a 14% hit rate
improvement over the baseline.
"
519,Semantic Computing of Moods Based on Tags in Social Media of Music,"  Social tags inherent in online music services such as Last.fm provide a rich
source of information on musical moods. The abundance of social tags makes this
data highly beneficial for developing techniques to manage and retrieve mood
information, and enables study of the relationships between music content and
mood representations with data substantially larger than that available for
conventional emotion research. However, no systematic assessment has been done
on the accuracy of social tags and derived semantic models at capturing mood
information in music. We propose a novel technique called Affective Circumplex
Transformation (ACT) for representing the moods of music tracks in an
interpretable and robust fashion based on semantic computing of social tags and
research in emotion modeling. We validate the technique by predicting listener
ratings of moods in music tracks, and compare the results to prediction with
the Vector Space Model (VSM), Singular Value Decomposition (SVD), Nonnegative
Matrix Factorization (NMF), and Probabilistic Latent Semantic Analysis (PLSA).
The results show that ACT consistently outperforms the baseline techniques, and
its performance is robust against a low number of track-level mood tags. The
results give validity and analytical insights for harnessing millions of music
tracks and associated mood data available through social tags in application
development.
"
520,"Model and Performance of a No-Reference Quality Assessment Metric for
  Video Streaming","  Video streaming via TCP networks has become a popular and highly demanded
service, but its quality assessment in both objective and subjective terms has
not been properly addressed. In this paper, based on statistical analysis a
full analytic model of a no-reference objective metric, namely Pause Intensity,
for video quality assessment is presented. The model characterizes the video
playout buffer behavior in connection with the network performance (throughput)
and the video playout rate. This allows for instant quality measurement and
control without requiring a reference video. Pause intensity specifically
addresses the need for assessing the quality issue in terms of the continuity
in the playout of TCP streaming videos, which cannot be properly measured by
other objective metrics such as PSNR, SSIM and buffer underrun or pause
frequency. The performance of the analytical model is rigidly verified by
simulation results and subjective tests using a range of video clips. It is
demonstrated that pause intensity is closely correlated with viewer opinion
scores regardless of the vastly different composition of individual elements,
such as pause duration and pause frequency which jointly constitute this new
quality metric. It is also shown that the correlation performance of pause
intensity is consistent and content independent.
"
521,"An Efficient Transport Protocol for delivery of Multimedia An Efficient
  Transport Protocol for delivery of Multimedia Content in Wireless Grids","  A grid computing system is designed for solving complicated scientific and
commercial problems effectively,whereas mobile computing is a traditional
distributed system having computing capability with mobility and adopting
wireless communications. Media and Entertainment fields can take advantage from
both paradigms by applying its usage in gaming applications and multimedia data
management. Multimedia data has to be stored and retrieved in an efficient and
effective manner to put it in use. In this paper, we proposed an application
layer protocol for delivery of multimedia data in wireless girds i.e.
multimedia grid protocol (MMGP). To make streaming efficient a new video
compression algorithm called dWave is designed and embedded in the proposed
protocol. This protocol will provide faster, reliable access and render an
imperceptible QoS in delivering multimedia in wireless grid environment and
tackles the challenging issues such as i) intermittent connectivity, ii) device
heterogeneity, iii) weak security and iv) device mobility.
"
522,"An Enhanced Time Space Priority Scheme to Manage QoS for Multimedia
  Flows transmitted to an end user in HSDPA Network","  When different type of packets with different needs of Quality of Service
(QoS) requirements share the same network resources, it became important to use
queue management and scheduling schemes in order to maintain perceived quality
at the end users at an acceptable level. Many schemes have been studied in the
literature, these schemes use time priority (to maintain QoS for Real Time (RT)
packets) and/or space priority (to maintain QoS for Non Real Time (NRT)
packets). In this paper, we study and show the drawback of a combined time and
space priority (TSP) scheme used to manage QoS for RT and NRT packets intended
for an end user in High Speed Downlink Packet Access (HSDPA) cell, and we
propose an enhanced scheme (Enhanced Basic-TSP scheme) to improve QoS
relatively to the RT packets, and to exploit efficiently the network resources.
A mathematical model for the EB-TSP scheme is done, and numerical results show
the positive impact of this scheme.
"
523,"An interactive engine for multilingual video browsing using semantic
  content","  The amount of audio-visual information has increased dramatically with the
advent of High Speed Internet. Furthermore, technological advances in recent
years in the field of information technology, have simplified the use of video
data in various fields by the general public. This made it possible to store
large collections of video documents into computer systems. To enable efficient
use of these collections, it is necessary to develop tools to facilitate access
to these documents and handling them. In this paper we propose a method for
indexing and retrieval of video sequences in a video database of large
dimension, based on a weighting technique to calculate the degree of membership
of a concept in a video also a structuring of the data of the audio-visual
(context / concept / video) and a relevance feedback mechanism.
"
524,Arabic Text Recognition in Video Sequences,"  In this paper, we propose a robust approach for text extraction and
recognition from Arabic news video sequence. The text included in video
sequences is an important needful for indexing and searching system. However,
this text is difficult to detect and recognize because of the variability of
its size, their low resolution characters and the complexity of the
backgrounds. To solve these problems, we propose a system performing in two
main tasks: extraction and recognition of text. Our system is tested on a
varied database composed of different Arabic news programs and the obtained
results are encouraging and show the merits of our approach.
"
525,"Compressive Sampling for the Packet Loss Recovery in Audio Multimedia
  Streaming","  The aim of this paper is to introduce a new schema, based on a Compressive
Sampling technique, for the recovery of lost data in multimedia streaming. The
audio streaming data are encapsuled in different packets by using an
interleaving technique. The Compressive Sampling technique is used to recover
audio information in case of lost packets. Experimental results are presented
on speech and musical audio signals to illustrate the performances and the
capabilities of the proposed methodology.
"
526,Coded Acquisition of High Frame Rate Video,"  High frame video (HFV) is an important investigational tool in sciences,
engineering and military. In ultra-high speed imaging, the obtainable temporal,
spatial and spectral resolutions are limited by the sustainable throughput of
in-camera mass memory, the lower bound of exposure time, and illumination
conditions. In order to break these bottlenecks, we propose a new coded video
acquisition framework that employs K > 2 conventional cameras, each of which
makes random measurements of the 3D video signal in both temporal and spatial
domains. For each of the K cameras, this multi-camera strategy greatly relaxes
the stringent requirements in memory speed, shutter speed, and illumination
strength. The recovery of HFV from these random measurements is posed and
solved as a large scale l1 minimization problem by exploiting joint temporal
and spatial sparsities of the 3D signal. Three coded video acquisition
techniques of varied trade offs between performance and hardware complexity are
developed: frame-wise coded acquisition, pixel-wise coded acquisition, and
column-row-wise coded acquisition. The performances of these techniques are
analyzed in relation to the sparsity of the underlying video signal.
Simulations of these new HFV capture techniques are carried out and
experimental results are reported.
"
527,A Unified Framework for Multi-Sensor HDR Video Reconstruction,"  One of the most successful approaches to modern high quality HDR-video
capture is to use camera setups with multiple sensors imaging the scene through
a common optical system. However, such systems pose several challenges for HDR
reconstruction algorithms. Previous reconstruction techniques have considered
debayering, denoising, resampling (align- ment) and exposure fusion as separate
problems. In contrast, in this paper we present a unifying approach, performing
HDR assembly directly from raw sensor data. Our framework includes a camera
noise model adapted to HDR video and an algorithm for spatially adaptive HDR
reconstruction based on fitting of local polynomial approximations to observed
sensor data. The method is easy to implement and allows reconstruction to an
arbitrary resolution and output mapping. We present an implementation in CUDA
and show real-time performance for an experimental 4 Mpixel multi-sensor HDR
video system. We further show that our algorithm has clear advantages over
existing methods, both in terms of flexibility and reconstruction quality.
"
528,"A Novel Method for Image Integrity Authentication Based on Fixed Point
  Theory","  Based on fixed point theory, this paper proposes a simple but efficient
method for image integrity authentication, which is different from Digital
Signature and Fragile Watermarking. By this method, any given image can be
transformed into a fixed point of a well-chosen function, which can be
constructed with periodic functions. The authentication can be realized due to
the fragility of the fixed points. The experiments show that 'Fixed Point
Image' performs well in security, transparence, fragility and tampering
localization.
"
529,"Joint Video and Text Parsing for Understanding Events and Answering
  Queries","  We propose a framework for parsing video and text jointly for understanding
events and answering user queries. Our framework produces a parse graph that
represents the compositional structures of spatial information (objects and
scenes), temporal information (actions and events) and causal information
(causalities between events and fluents) in the video and text. The knowledge
representation of our framework is based on a spatial-temporal-causal And-Or
graph (S/T/C-AOG), which jointly models possible hierarchical compositions of
objects, scenes and events as well as their interactions and mutual contexts,
and specifies the prior probabilistic distribution of the parse graphs. We
present a probabilistic generative model for joint parsing that captures the
relations between the input video/text, their corresponding parse graphs and
the joint parse graph. Based on the probabilistic model, we propose a joint
parsing system consisting of three modules: video parsing, text parsing and
joint inference. Video parsing and text parsing produce two parse graphs from
the input video and text respectively. The joint inference module produces a
joint parse graph by performing matching, deduction and revision on the video
and text parse graphs. The proposed framework has the following objectives:
Firstly, we aim at deep semantic parsing of video and text that goes beyond the
traditional bag-of-words approaches; Secondly, we perform parsing and reasoning
across the spatial, temporal and causal dimensions based on the joint S/T/C-AOG
representation; Thirdly, we show that deep joint parsing facilitates subsequent
applications such as generating narrative text descriptions and answering
queries in the forms of who, what, when, where and why. We empirically
evaluated our system based on comparison against ground-truth as well as
accuracy of query answering and obtained satisfactory results.
"
530,"Achieving the Optimal Steaming Capacity and Delay Using Random Regular
  Digraphs in P2P Networks","  In earlier work, we showed that it is possible to achieve $O(\log N)$
streaming delay with high probability in a peer-to-peer network, where each
peer has as little as four neighbors, while achieving any arbitrary fraction of
the maximum possible streaming rate. However, the constant in the $O(log N)$
delay term becomes rather large as we get closer to the maximum streaming rate.
In this paper, we design an alternative pairing and chunk dissemination
algorithm that allows us to transmit at the maximum streaming rate while
ensuring that all, but a negligible fraction of the peers, receive the data
stream with $O(\log N)$ delay with high probability. The result is established
by examining the properties of graph formed by the union of two or more random
1-regular digraphs, i.e., directed graphs in which each node has an incoming
and an outgoing node degree both equal to one.
"
531,"Band Codes for Energy-Efficient Network Coding with Application to P2P
  Mobile Streaming","  A key problem in random network coding (NC) lies in the complexity and energy
consumption associated with the packet decoding processes, which hinder its
application in mobile environments. Controlling and hence limiting such factors
has always been an important but elusive research goal, since the packet degree
distribution, which is the main factor driving the complexity, is altered in a
non-deterministic way by the random recombinations at the network nodes. In
this paper we tackle this problem proposing Band Codes (BC), a novel class of
network codes specifically designed to preserve the packet degree distribution
during packet encoding, ecombination and decoding. BC are random codes over
GF(2) that exhibit low decoding complexity, feature limited and controlled
degree distribution by construction, and hence allow to effectively apply NC
even in energy-constrained scenarios. In particular, in this paper we motivate
and describe our new design and provide a thorough analysis of its performance.
We provide numerical simulations of the performance of BC in order to validate
the analysis and assess the overhead of BC with respect to a onventional NC
scheme. Moreover, peer-to-peer media streaming experiments with a random-push
protocol show that BC reduce the decoding complexity by a factor of two, to a
point where NC-based mobile streaming to mobile devices becomes practically
feasible.
"
532,"Speech Enhancement using Kernel and Normalized Kernel Affine Projection
  Algorithm","  The goal of this paper is to investigate the speech signal enhancement using
Kernel Affine Projection Algorithm (KAPA) and Normalized KAPA. The removal of
background noise is very important in many applications like speech
recognition, telephone conversations, hearing aids, forensic, etc. Kernel
adaptive filters shown good performance for removal of noise. If the evaluation
of background noise is more slowly than the speech, i.e., noise signal is more
stationary than the speech, we can easily estimate the noise during the pauses
in speech. Otherwise it is more difficult to estimate the noise which results
in degradation of speech. In order to improve the quality and intelligibility
of speech, unlike time and frequency domains, we can process the signal in new
domain like Reproducing Kernel Hilbert Space (RKHS) for high dimensional to
yield more powerful nonlinear extensions. For experiments, we have used the
database of noisy speech corpus (NOIZEUS). From the results, we observed the
removal noise in RKHS has great performance in signal to noise ratio values in
comparison with conventional adaptive filters.
"
533,Robust watermarking based on DWT SVD,"  Digital information revolution has brought about many advantages and new
issues. The protection of ownership and the prevention of unauthorized
manipulation of digital audio, image, and video materials has become an
important concern due to the ease of editing and perfect reproduction.
Watermarking is identified as a major means to achieve copyright protection. It
is a branch of information hiding which is used to hide proprietary information
in digital media like photographs, digital music, digital video etc. In this
paper, a new image watermarking algorithm that is robust against various
attacks is presented. DWT (Discrete Wavelet Transform) and SVD (Singular Value
Decomposition) have been used to embed two watermarks in the HL and LH bands of
the host image. Simulation evaluation demonstrates that the proposed technique
withstand various attacks.
"
534,"Evaluation of the Performance/Energy Overhead in DSP Video Decoding and
  its Implications","  Video decoding is considered as one of the most compute and energy intensive
application in energy constrained mobile devices. Some specific processing
units, such as DSPs, are added to those devices in order to optimize the
performance and the energy consumption. However, in DSP video decoding, the
inter-processor communication overhead may have a considerable impact on the
performance and the energy consumption. In this paper, we propose to evaluate
this overhead and analyse its impact on the performance and the energy
consumption as compared to the GPP decoding. Our work revealed that the GPP can
be the best choice in many cases due to the a significant overhead in DSP
decoding which may represents 30% of the total decoding energy.
"
535,Progressive Compression of 3D Objects with an Adaptive Quantization,"  This paper presents a new progressive compression method for triangular
meshes. This method, in fact, is based on a schema of irregular
multi-resolution analysis and is centered on the optimization of the
rate-distortion trade-off. The quantization precision is adapted to each vertex
during the encoding / decoding process to optimize the rate-distortion
compromise. The Optimization of the treated mesh geometry improves the
approximation quality and the compression ratio at each level of resolution.
The experimental results show that the proposed algorithm gives competitive
results compared to the previous works dealing with the rate-distortion
compromise.
"
536,Exploring Image Virality in Google Plus,"  Reactions to posts in an online social network show different dynamics
depending on several textual features of the corresponding content. Do similar
dynamics exist when images are posted? Exploiting a novel dataset of posts,
gathered from the most popular Google+ users, we try to give an answer to such
a question. We describe several virality phenomena that emerge when taking into
account visual characteristics of images (such as orientation, mean saturation,
etc.). We also provide hypotheses and potential explanations for the dynamics
behind them, and include cases for which common-sense expectations do not hold
true in our experiments.
"
537,"Anticipatory Buffer Control and Quality Selection for Wireless Video
  Streaming","  Video streaming is in high demand by mobile users, as recent studies
indicate. In cellular networks, however, the unreliable wireless channel leads
to two major problems. Poor channel states degrade video quality and interrupt
the playback when a user cannot sufficiently fill its local playout buffer:
buffer underruns occur. In contrast to that, good channel conditions cause
common greedy buffering schemes to pile up very long buffers. Such
over-buffering wastes expensive wireless channel capacity.
  To keep buffering in balance, we employ a novel approach. Assuming that we
can predict data rates, we plan the quality and download time of the video
segments ahead. This anticipatory scheduling avoids buffer underruns by
downloading a large number of segments before a channel outage occurs, without
wasting wireless capacity by excessive buffering. We formalize this approach as
an optimization problem and derive practical heuristics for segmented video
streaming protocols (e.g., HLS or MPEG DASH). Simulation results and testbed
measurements show that our solution essentially eliminates playback
interruptions without significantly decreasing video quality.
"
538,An Efficient Authorship Protection Scheme for Shared Multimedia Content,"  Many electronic content providers today like Flickr and Google, offer space
to users to publish their electronic media (e.g. photos and videos) in their
cloud infrastructures, so that they can be publicly accessed. Features like
including other information, such as keywords or owner information into the
digital material is already offered by existing providers. Despite the useful
features made available to users by such infrastructures, the authorship of the
published content is not protected against various attacks such as compression.
In this paper we propose a robust scheme that uses digital invisible
watermarking and hashing to protect the authorship of the digital content and
provide resistance against malicious manipulation of multimedia content. The
scheme is enhanced by an algorithm called MMBEC, that is an extension of an
established scheme MBEC, towards higher resistance.
"
539,"Steganography using the Extensible Messaging and Presence Protocol
  (XMPP)","  We present here the first work to propose different mechanisms for hiding
data in the Extensible Messaging and Presence Protocol (XMPP). This is a very
popular instant messaging protocol used by many messaging platforms such as
Google Talk, Cisco, LiveJournal and many others. Our paper describes how to
send a secret message from one XMPP client to another, without raising the
suspicion of any intermediaries. The methods described primarily focus on using
the underlying protocol as a means for steganography, unlike other related
works that try to hide data in the content of instant messages. In doing so, we
provide a more robust means of data hiding and additionally offer some
preliminary analysis of its general security, in particular against
entropic-based steganalysis.
"
540,"Spatially Scalable Compressed Image Sensing with Hybrid Transform and
  Inter-layer Prediction Model","  Compressive imaging is an emerging application of compressed sensing, devoted
to acquisition, encoding and reconstruction of images using random projections
as measurements. In this paper we propose a novel method to provide a scalable
encoding of an image acquired by means of compressed sensing techniques. Two
bit-streams are generated to provide two distinct quality levels: a
low-resolution base layer and full-resolution enhancement layer. In the
proposed method we exploit a fast preview of the image at the encoder in order
to perform inter-layer prediction and encode the prediction residuals only. The
proposed method successfully provides resolution and quality scalability with
modest complexity and it provides gains in the quality of the reconstructed
images with respect to separate encoding of the quality layers. Remarkably, we
also show that the scheme can also provide significant gains with respect to a
direct, non-scalable system, thus accomplishing two features at once:
scalability and improved reconstruction performance.
"
541,Congestion Control using FEC for Conversational Multimedia Communication,"  In this paper, we propose a new rate control algorithm for conversational
multimedia flows. In our approach, along with Real-time Transport Protocol
(RTP) media packets, we propose sending redundant packets to probe for
available bandwidth. These redundant packets are Forward Error Correction (FEC)
encoded RTP packets. A straightforward interpretation is that if no losses
occur, the sender can increase the sending rate to include the FEC bit rate,
and in the case of losses due to congestion the redundant packets help in
recovering the lost packets. We also show that by varying the FEC bit rate, the
sender is able to conservatively or aggressively probe for available bandwidth.
We evaluate our FEC-based Rate Adaptation (FBRA) algorithm in a network
simulator and in the real-world and compare it to other congestion control
algorithms.
"
542,Early Fire Detection Using HEP and Space-time Analysis,"  In this article, a video base early fire alarm system is developed by
monitoring the smoke in the scene. There are two major contributions in this
work. First, to find the best texture feature for smoke detection, a general
framework, named Histograms of Equivalent Patterns (HEP), is adopted to achieve
an extensive evaluation of various kinds of texture features. Second, the
\emph{Block based Inter-Frame Difference} (BIFD) and a improved version of
LBP-TOP are proposed and ensembled to describe the space-time characteristics
of the smoke. In order to reduce the false alarms, the Smoke History Image
(SHI) is utilized to register the recent classification results of candidate
smoke blocks. Experimental results using SVM show that the proposed method can
achieve better accuracy and less false alarm compared with the state-of-the-art
technologies.
"
543,"Subband coding for large-scale scientific simulation data using JPEG
  2000","  The ISO/IEC JPEG 2000 image coding standard is a family of source coding
algorithms targeting high-resolution image communications. JPEG 2000 features
highly scalable embedded coding features that allow one to interactively zoom
out to reduced resolution thumbnails of enormous data sets or to zoom in on
highly localized regions of interest with very economical communications and
rendering requirements. While intended for fixed-precision input data, the
implementation of the irreversible version of the standard is often done
internally in floating point arithmetic. Moreover, the standard is designed to
support high-bit-depth data. Part 2 of the standard also provides support for
three-dimensional data sets such as multicomponent or volumetric imagery. These
features make JPEG 2000 an appealing candidate for highly scalable
communications coding and visualization of two- and three-dimensional data
produced by scientific simulation software. We present results of initial
experiments applying JPEG 2000 to scientific simulation data produced by the
Parallel Ocean Program (POP) global ocean circulation model, highlighting both
the promise and the many challenges this approach holds for scientific
visualization applications.
"
544,Blind and robust images watermarking based on wavelet and edge insertion,"  This paper gives a new scheme of watermarking technique related to insert the
mark by adding edge in HH sub-band of the host image after wavelet
decomposition. Contrary to most of the watermarking algorithms in wavelet
domain, our method is blind and results show that it is robust against the JPEG
and GIF compression, histogram and spectrum spreading, noise adding and small
rotation. Its robustness against compression is better than others watermarking
algorithms reported in the literature. The algorithm is flexible because its
capacity or robustness can be improved by modifying some parameters.
"
545,"Improving Mobile Video Streaming with Mobility Prediction and
  Prefetching in Integrated Cellular-WiFi Networks","  We present and evaluate a procedure that utilizes mobility and throughput
prediction to prefetch video streaming data in integrated cellular and WiFi
networks. The effective integration of such heterogeneous wireless technologies
will be significant for supporting high performance and energy efficient video
streaming in ubiquitous networking environments. Our evaluation is based on
trace-driven simulation considering empirical measurements and shows how
various system parameters influence the performance, in terms of the number of
paused video frames and the energy consumption; these parameters include the
number of video streams, the mobile, WiFi, and ADSL backhaul throughput, and
the number of WiFi hotspots. Also, we assess the procedure's robustness to time
and throughput variability. Finally, we present our initial prototype that
implements the proposed approach.
"
546,"Multiview Navigation based on Extended Layered Depth Image
  Representation","  Emerging applications in multiview streaming look for providing interactive
navigation services to video players. The user can ask for information from any
viewpoint with a minimum transmission delay. The purpose is to provide user
with as much information as possible with least number of redundancies. The
recent concept of navigation segment representation consists of regrouping a
given number of viewpoints in one signal and transmitting them to the users
according to their navigation path. The question of the best description
strategy of these navigation segments is however still open. In this paper, we
propose to represent and code navigation segments by a method that extends the
recent layered depth image (LDI) format. It consists of describing the scene
from a viewpoint with multiple images organized in layers corresponding to the
different levels of occluded objects. The notion of extended LDI comes from the
fact that the size of this image is adapted to take into account the sides of
the scene also, in contrary to classical LDI. The obtained results show a
significant rate-distortion gain compared to classical multiview compression
approaches in navigation scenario.
"
547,Tracking Deformable Parts via Dynamic Conditional Random Fields,"  Despite the success of many advanced tracking methods in this area, tracking
targets with drastic variation of appearance such as deformation, view change
and partial occlusion in video sequences is still a challenge in practical
applications. In this letter, we take these serious tracking problems into
account simultaneously, proposing a dynamic graph based model to track object
and its deformable parts at multiple resolutions. The method introduces well
learned structural object detection models into object tracking applications as
prior knowledge to deal with deformation and view change. Meanwhile, it
explicitly formulates partial occlusion by integrating spatial potentials and
temporal potentials with an unparameterized occlusion handling mechanism in the
dynamic conditional random field framework. Empirical results demonstrate that
the method outperforms state-of-the-art trackers on different challenging video
sequences.
"
548,"An Efficient Method for Image and Audio Steganography using Least
  Significant Bit (LSB) Substitution","  In order to improve the data hiding in all types of multimedia data formats
such as image and audio and to make hidden message imperceptible, a novel
method for steganography is introduced in this paper. It is based on Least
Significant Bit (LSB) manipulation and inclusion of redundant noise as secret
key in the message. This method is applied to data hiding in images. For data
hiding in audio, Discrete Cosine Transform (DCT) and Discrete Wavelet Transform
(DWT) both are used. All the results displayed prove to be time-efficient and
effective. Also the algorithm is tested for various numbers of bits. For those
values of bits, Mean Square Error (MSE) and Peak-Signal-to-Noise-Ratio (PSNR)
are calculated and plotted. Experimental results show that the stego-image is
visually indistinguishable from the original cover-image when n<=4, because of
better PSNR which is achieved by this technique. The final results obtained
after steganography process does not reveal presence of any hidden message,
thus qualifying the criteria of imperceptible message.
"
549,"Increasing Compression Ratio of Low Complexity Compressive Sensing Video
  Encoder with Application-Aware Configurable Mechanism","  With the development of embedded video acquisition nodes and wireless video
surveillance systems, traditional video coding methods could not meet the needs
of less computing complexity any more, as well as the urgent power consumption.
So, a low-complexity compressive sensing video encoder framework with
application-aware configurable mechanism is proposed in this paper, where novel
encoding methods are exploited based on the practical purposes of the real
applications to reduce the coding complexity effectively and improve the
compression ratio (CR). Moreover, the group of processing (GOP) size and the
measurement matrix size can be configured on the encoder side according to the
post-analysis requirements of an application example of object tracking to
increase the CR of encoder as best as possible. Simulations show the proposed
framework of encoder could achieve 60X of CR when the tracking successful rate
(SR) is still keeping above 90%.
"
550,"Image Steganography using Karhunen-Loeve Transform and Least Bit
  Substitution","  As communication channels are increasing in number, reliability of faithful
communication is reducing. Hacking and tempering of data are two major issues
for which security should be provided by channel. This raises the importance of
steganography. In this paper, a novel method to encode the message information
inside a carrier image has been described. It uses Karhunen-Lo\`eve Transform
for compression of data and Least Bit Substitution for data encryption.
Compression removes redundancy and thus also provides encoding to a level. It
is taken further by means of Least Bit Substitution. The algorithm used for
this purpose uses pixel matrix which serves as a best tool to work on. Three
different sets of images were used with three different numbers of bits to be
substituted by message information. The experimental results show that
algorithm is time efficient and provides high data capacity. Further, it can
decrypt the original data effectively. Parameters such as carrier error and
message error were calculated for each set and were compared for performance
analysis.
"
551,Chaotic Arithmetic Coding for Secure Video Multicast,"  Arithmetic Coding (AC) is widely used for the entropy coding of text and
video data. It involves recursive partitioning of the range [0,1) in accordance
with the relative probabilities of occurrence of the input symbols. A data
(image or video) encryption scheme based on arithmetic coding called as Chaotic
Arithmetic Coding (CAC) has been presented in previous works. In CAC, a large
number of chaotic maps can be used to perform coding, each achieving Shannon
optimal compression performance. The exact choice of map is governed by a key.
CAC has the effect of scrambling the intervals without making any changes to
the width of interval in which the codeword must lie, thereby allowing
encryption without sacrificing any coding efficiency. In this paper, we use a
redundancy in CAC procedure for secure multicast of videos where multiple users
are distributed with different keys to decode same encrypted file. By
encrypting once, we can generate multiple keys, either of which can be used to
decrypt the encoded file. This is very suitable for video distribution over
Internet where a single video can be distributed to multiple clients in a
privacy preserving manner.
"
552,Optimal Foresighted Multi-User Wireless Video,"  Recent years have seen an explosion in wireless video communication systems.
Optimization in such systems is crucial - but most existing methods intended to
optimize the performance of multi-user wireless video transmission are
inefficient. Some works (e.g. Network Utility Maximization (NUM)) are myopic:
they choose actions to maximize instantaneous video quality while ignoring the
future impact of these actions. Such myopic solutions are known to be inferior
to foresighted solutions that optimize the long-term video quality.
Alternatively, foresighted solutions such as rate-distortion optimized packet
scheduling focus on single-user wireless video transmission, while ignoring the
resource allocation among the users.
  In this paper, we propose an optimal solution for performing joint
foresighted resource allocation and packet scheduling among multiple users
transmitting video over a shared wireless network. A key challenge in
developing foresighted solutions for multiple video users is that the users'
decisions are coupled. To decouple the users' decisions, we adopt a novel dual
decomposition approach, which differs from the conventional optimization
solutions such as NUM, and determines foresighted policies. Specifically, we
propose an informationally-decentralized algorithm in which the network manager
updates resource ""prices"" (i.e. the dual variables associated with the resource
constraints), and the users make individual video packet scheduling decisions
based on these prices. Because a priori knowledge of the system dynamics is
almost never available at run-time, the proposed solution can learn online,
concurrently with performing the foresighted optimization. Simulation results
show 7 dB and 3 dB improvements in Peak Signal-to-Noise Ratio (PSNR) over
myopic solutions and existing foresighted solutions, respectively.
"
553,"Mobile Multimedia Streaming Techniques : QoE and Energy Consumption
  Perspective","  Multimedia streaming to mobile devices is challenging for two reasons. First,
the way content is delivered to a client must ensure that the user does not
experience a long initial playback delay or a distorted playback in the middle
of a streaming session. Second, multimedia streaming applications are among the
most energy hungry applications in smartphones. The energy consumption mostly
depends on the delivery techniques and on the power management techniques of
wireless access technologies (Wi-Fi, 3G, and 4G). In order to provide insights
on what kind of streaming techniques exist, how they work on different mobile
platforms, their efforts in providing smooth quality of experience, and their
impact on energy consumption of mobile phones, we did a large set of active
measurements with several smartphones having both Wi-Fi and cellular network
access. Our analysis reveals five different techniques to deliver the content
to the video players. The selection of a technique depends on the mobile
platform, device, player, quality, and service. The results from our traffic
and power measurements allow us to conclude that none of the identified
techniques is optimal because they take none of the following facts into
account: access technology used, user behavior, and user preferences concerning
data waste. We point out the technique with optimal playback buffer
configuration, which provides the most attractive trade-offs in particular
situations.
"
554,"Traffic and Statistical Multiplexing Characterization of 3D Video
  Representation Formats (Extended Version)","  The network transport of 3D video, which contains two views of a video scene,
poses significant challenges due to the increased video data compared to
conventional single-view video. Addressing these challenges requires a thorough
understanding of the traffic and multiplexing characteristics of the different
representation formats of 3D video. We examine the average bitrate-distortion
(RD) and bitrate variability-distortion (VD) characteristics of three main
representation formats. Specifically, we compare multiview video (MV)
representation and encoding, frame sequential (FS) representation, and
side-by-side (SBS) representation, whereby conventional single-view encoding is
employed for the FS and SBS representations. Our results for long 3D videos in
full HD format indicate that the MV representation and encoding achieves the
highest RD efficiency, while exhibiting the highest bitrate variabilities. We
examine the impact of these bitrate variabilities on network transport through
extensive statistical multiplexing simulations. We find that when multiplexing
a small number of streams, the MV and FS representations require the same
bandwidth. However, when multiplexing a large number of streams or smoothing
traffic, the MV representation and encoding reduces the bandwidth requirement
relative to the FS representation.
"
555,"Exploration in Interactive Personalized Music Recommendation: A
  Reinforcement Learning Approach","  Current music recommender systems typically act in a greedy fashion by
recommending songs with the highest user ratings. Greedy recommendation,
however, is suboptimal over the long term: it does not actively gather
information on user preferences and fails to recommend novel songs that are
potentially interesting. A successful recommender system must balance the needs
to explore user preferences and to exploit this information for recommendation.
This paper presents a new approach to music recommendation by formulating this
exploration-exploitation trade-off as a reinforcement learning task called the
multi-armed bandit. To learn user preferences, it uses a Bayesian model, which
accounts for both audio content and the novelty of recommendations. A
piecewise-linear approximation to the model and a variational inference
algorithm are employed to speed up Bayesian inference. One additional benefit
of our approach is a single unified model for both music recommendation and
playlist generation. Both simulation results and a user study indicate strong
potential for the new approach.
"
556,"Modeling the Time-varying Subjective Quality of HTTP Video Streams with
  Rate Adaptations","  Newly developed HTTP-based video streaming technologies enable flexible
rate-adaptation under varying channel conditions. Accurately predicting the
users' Quality of Experience (QoE) for rate-adaptive HTTP video streams is thus
critical to achieve efficiency. An important aspect of understanding and
modeling QoE is predicting the up-to-the-moment subjective quality of a video
as it is played, which is difficult due to hysteresis effects and
nonlinearities in human behavioral responses. This paper presents a
Hammerstein-Wiener model for predicting the time-varying subjective quality
(TVSQ) of rate-adaptive videos. To collect data for model parameterization and
validation, a database of longer-duration videos with time-varying distortions
was built and the TVSQs of the videos were measured in a large-scale subjective
study. The proposed method is able to reliably predict the TVSQ of rate
adaptive videos. Since the Hammerstein-Wiener model has a very simple
structure, the proposed method is suitable for on-line TVSQ prediction in HTTP
based streaming.
"
557,"Rate Adaptation and Admission Control for Video Transmission with
  Subjective Quality Constraints","  Adapting video data rate during streaming can effectively reduce the risk of
playback interruptions caused by channel throughput fluctuations. The
variations in rate, however, also introduce video quality fluctuations and thus
potentially affects viewers' Quality of Experience (QoE). We show how the QoE
of video users can be improved by rate adaptation and admission control. We
conducted a subjective study wherein we found that viewers' QoE was strongly
correlated with the empirical cumulative distribution function (eCDF) of the
predicted video quality. Based on this observation, we propose a
rate-adaptation algorithm that can incorporate QoE constraints on the empirical
cumulative quality distribution per user. We then propose a threshold-based
admission control policy to block users whose empirical cumulative quality
distribution is not likely to satisfy their QoE constraint. We further devise
an online adaptation algorithm to automatically optimize the threshold.
Extensive simulation results show that the proposed scheme can reduce network
resource consumption by $40\%$ over conventional average-quality maximized
rate-adaptation algorithms.
"
558,A Survey: Various Techniques of Image Compression,"  This paper addresses about various image compression techniques. On the basis
of analyzing the various image compression techniques this paper presents a
survey of existing research papers. In this paper we analyze different types of
existing method of image compression. Compression of an image is significantly
different then compression of binary raw data. To solve these use different
types of techniques for image compression. Now there is question may be arise
that how to image compress and which types of technique is used. For this
purpose there are basically two types are method are introduced namely lossless
and lossy image compression techniques. In present time some other techniques
are added with basic method. In some area neural network genetic algorithms are
used for image compression.
  Keywords-Image Compression; Lossless; Lossy; Redundancy; Benefits of
Compression.
"
559,"Cross-Layer MIMO Transceiver Optimization for Multimedia Streaming in
  Interference Networks","  In this paper, we consider dynamic precoder/decorrelator optimization for
multimedia streaming in MIMO interference networks. We propose a truly
cross-layer framework in the sense that the optimization objective is the
application level performance metrics for multimedia streaming, namely the
playback interruption and buffer overflow probabilities. The optimization
variables are the MIMO precoders/decorrelators at the transmitters and the
receivers, which are adaptive to both the instantaneous channel condition and
the playback queue length. The problem is a challenging multi-dimensional
stochastic optimization problem and brute-force solution has exponential
complexity. By exploiting the underlying timescale separation and special
structure in the problem, we derive a closed-form approximation of the value
function based on continuous time perturbation. Using this approximation, we
propose a low complexity dynamic MIMO precoder/decorrelator control algorithm
by solving an equivalent weighted MMSE problem. We also establish the technical
conditions for asymptotic optimality of the low complexity control algorithm.
Finally, the proposed scheme is compared with various baselines through
simulations and it is shown that significant performance gain can be achieved.
"
560,Fake View Analytics in Online Video Services,"  Online video-on-demand(VoD) services invariably maintain a view count for
each video they serve, and it has become an important currency for various
stakeholders, from viewers, to content owners, advertizers, and the online
service providers themselves. There is often significant financial incentive to
use a robot (or a botnet) to artificially create fake views. How can we detect
the fake views? Can we detect them (and stop them) using online algorithms as
they occur? What is the extent of fake views with current VoD service
providers? These are the questions we study in the paper. We develop some
algorithms and show that they are quite effective for this problem.
"
561,"Codebook based Audio Feature Representation for Music Information
  Retrieval","  Digital music has become prolific in the web in recent decades. Automated
recommendation systems are essential for users to discover music they love and
for artists to reach appropriate audience. When manual annotations and user
preference data is lacking (e.g. for new artists) these systems must rely on
\emph{content based} methods. Besides powerful machine learning tools for
classification and retrieval, a key component for successful recommendation is
the \emph{audio content representation}.
  Good representations should capture informative musical patterns in the audio
signal of songs. These representations should be concise, to enable efficient
(low storage, easy indexing, fast search) management of huge music
repositories, and should also be easy and fast to compute, to enable real-time
interaction with a user supplying new songs to the system.
  Before designing new audio features, we explore the usage of traditional
local features, while adding a stage of encoding with a pre-computed
\emph{codebook} and a stage of pooling to get compact vectorial
representations. We experiment with different encoding methods, namely
\emph{the LASSO}, \emph{vector quantization (VQ)} and \emph{cosine similarity
(CS)}. We evaluate the representations' quality in two music information
retrieval applications: query-by-tag and query-by-example. Our results show
that concise representations can be used for successful performance in both
applications. We recommend using top-$\tau$ VQ encoding, which consistently
performs well in both applications, and requires much less computation time
than the LASSO.
"
562,"Three Metrics for Measuring User Engagement with Online Media and a
  YouTube Case Study","  This technical report discusses three metrics of user engagement with online
media. They are Commenting frequency, Voting frequency, and Voting balance.
These relative figures can be derived from established, basic statistics
available for many services, prominently YouTube. The paper includes case a
study of popular YouTube videos to illustrate the characteristics and
usefulness of the measures. The study documents the range of observed values
and their relationships. The empirical sample shows the three measures to be
only moderately correlated with the original statistics despite the common
numerators and denominators. The paper concludes by discussing future
applications and the needs of the quantification of user interaction with new
media services.
"
563,Graph-based representation for multiview image coding,"  In this paper, we propose a new representation for multiview image sets. Our
approach relies on graphs to describe geometry information in a compact and
controllable way. The links of the graph connect pixels in different images and
describe the proximity between pixels in the 3D space. These connections are
dependent on the geometry of the scene and provide the right amount of
information that is necessary for coding and reconstructing multiple views.
This multiview image representation is very compact and adapts the transmitted
geometry information as a function of the complexity of the prediction
performed at the decoder side. To achieve this, our GBR adapts the accuracy of
the geometry representation, in contrast with depth coding, which directly
compresses with losses the original geometry signal. We present the principles
of this graph-based representation (GBR) and we build a complete prototype
coding scheme for multiview images. Experimental results demonstrate the
potential of this new representation as compared to a depth-based approach. GBR
can achieve a gain of 2 dB in reconstructed quality over depth-based schemes
operating at similar rates.
"
564,Manifold regularized kernel logistic regression for web image annotation,"  With the rapid advance of Internet technology and smart devices, users often
need to manage large amounts of multimedia information using smart devices,
such as personal image and video accessing and browsing. These requirements
heavily rely on the success of image (video) annotation, and thus large scale
image annotation through innovative machine learning methods has attracted
intensive attention in recent years. One representative work is support vector
machine (SVM). Although it works well in binary classification, SVM has a
non-smooth loss function and can not naturally cover multi-class case. In this
paper, we propose manifold regularized kernel logistic regression (KLR) for web
image annotation. Compared to SVM, KLR has the following advantages: (1) the
KLR has a smooth loss function; (2) the KLR produces an explicit estimate of
the probability instead of class label; and (3) the KLR can naturally be
generalized to the multi-class case. We carefully conduct experiments on MIR
FLICKR dataset and demonstrate the effectiveness of manifold regularized kernel
logistic regression for image annotation.
"
565,State-of-the Art Motion Estimation in the Context of 3D TV,"  Progress in image sensors and computation power has fueled studies to improve
acquisition, processing, and analysis of 3D streams along with 3D
scenes/objects reconstruction. The role of motion compensation/motion
estimation (MCME) in 3D TV from end-to-end user is investigated in this
chapter. Motion vectors (MVs) are closely related to the concept of
disparities, and they can help improving dynamic scene acquisition, content
creation, 2D to 3D conversion, compression coding, decompression/decoding,
scene rendering, error concealment, virtual/augmented reality handling,
intelligent content retrieval, and displaying. Although there are different 3D
shape extraction methods, this chapter focuses mostly on shape-from-motion
(SfM) techniques due to their relevance to 3D TV. SfM extraction can restore 3D
shape information from a single camera data.
"
566,Mobile Multimedia Recommendation in Smart Communities: A Survey,"  Due to the rapid growth of internet broadband access and proliferation of
modern mobile devices, various types of multimedia (e.g. text, images, audios
and videos) have become ubiquitously available anytime. Mobile device users
usually store and use multimedia contents based on their personal interests and
preferences. Mobile device challenges such as storage limitation have however
introduced the problem of mobile multimedia overload to users. In order to
tackle this problem, researchers have developed various techniques that
recommend multimedia for mobile users. In this survey paper, we examine the
importance of mobile multimedia recommendation systems from the perspective of
three smart communities, namely, mobile social learning, mobile event guide and
context-aware services. A cautious analysis of existing research reveals that
the implementation of proactive, sensor-based and hybrid recommender systems
can improve mobile multimedia recommendations. Nevertheless, there are still
challenges and open issues such as the incorporation of context and social
properties, which need to be tackled in order to generate accurate and
trustworthy mobile multimedia recommendations.
"
567,"IVSS Integration of Color Feature Extraction Techniques for Intelligent
  Video Search Systems","  As large amount of visual Information is available on web in form of images,
graphics, animations and videos, so it is important in internet era to have an
effective video search system. As there are number of video search engine
(blinkx, Videosurf, Google, YouTube, etc.) which search for relevant videos
based on user keyword or term, But very less commercial video search engine are
available which search videos based on visual image/clip/video. In this paper
we are recommending a system that will search for relevant video using color
feature of video in response of user Query.
"
568,Deriving Latent Social Impulses to Determine Longevous Videos,"  Online video websites receive huge amount of videos daily from users all
around the world. How to provide valuable recommendations to viewers is an
important task for both video websites and related third parties, such as
search engines. Previous work conducted numerous analysis on the view counts of
videos, which measure a video's value in terms of popularity. However, the
long-lasting value of an online video, namely longevity, is hidden behind the
history that a video accumulates its ""popularity"" through time. Generally
speaking, a longevous video tends to constantly draw society's attention. With
focus on one of the leading video websites, Youtube, this paper proposes a
scoring mechanism quantifying a video's longevity. Evaluating a video's
longevity can not only improve a video recommender system, but also help us to
discover videos having greater advertising value, as well as adjust a video
website's strategy of storing videos to shorten its responding time. In order
to accurately quantify longevity, we introduce the concept of latent social
impulses and how to use them measure a video's longevity. In order to derive
latent social impulses, we view the video website as a digital signal filter
and formulate the task as a convex minimization problem. The proposed longevity
computation is based on the derived social impulses. Unfortunately, the
required information to derive social impulses are not always public, which
makes a third party unable to directly evaluate every video's longevity. To
solve this problem, we formulate a semi-supervised learning task by using part
of videos having known longevity scores to predict the unknown longevity
scores. We propose a Gaussian Random Markov model with Loopy Belief Propagation
to solve this problem. The conducted experiments on Youtube demonstrate that
the proposed method significantly improves the prediction results comparing to
baselines.
"
569,Evaluating the Performance of IPTV over Fixed WiMAX,"  IEEE specifies different modulation techniques for WiMAX; namely, BPSK, QPSK,
16 QAM and 64 QAM. This paper studies the performance of Internet Protocol
Television (IPTV) over Fixed WiMAX system considering different combinations of
digital modulation. The performance is studied taking into account a number of
key system parameters which include the variation in the video coding,
path-loss, scheduling service classes different rated codes in FEC channel
coding. The performance study was conducted using OPNET simulation. The
performance is studied in terms of packet lost, packet jitter delay, end-to-end
delay, and network throughput. Simulation results show that higher order
modulation and coding schemes (namely, 16 QAM and 64 QAM) yield better
performance than that of QPSK.
"
570,System Analysis And Design For Multimedia Retrieval Systems,"  Due to the extensive use of information technology and the recent
developments in multimedia systems, the amount of multimedia data available to
users has increased exponentially. Video is an example of multimedia data as it
contains several kinds of data such as text, image, meta-data, visual and
audio. Content based video retrieval is an approach for facilitating the
searching and browsing of large multimedia collections over WWW. In order to
create an effective video retrieval system, visual perception must be taken
into account. We conjectured that a technique which employs multiple features
for indexing and retrieval would be more effective in the discrimination and
search tasks of videos. In order to validate this, content based indexing and
retrieval systems were implemented using color histogram, Texture feature
(GLCM), edge density and motion..
"
571,"Non-stationary Resource Allocation Policies for Delay-constrained Video
  Streaming: Application to Video over Internet-of-Things-enabled Networks","  Due to the high bandwidth requirements and stringent delay constraints of
multi-user wireless video transmission applications, ensuring that all video
senders have sufficient transmission opportunities to use before their delay
deadlines expire is a longstanding research problem. We propose a novel
solution that addresses this problem without assuming detailed packet-level
knowledge, which is unavailable at resource allocation time. Instead, we
translate the transmission delay deadlines of each sender's video packets into
a monotonically-decreasing weight distribution within the considered time
horizon. Higher weights are assigned to the slots that have higher probability
for deadline-abiding delivery. Given the sets of weights of the senders' video
streams, we propose the low-complexity Delay-Aware Resource Allocation (DARA)
approach to compute the optimal slot allocation policy that maximizes the
deadline-abiding delivery of all senders. A unique characteristic of the DARA
approach is that it yields a non-stationary slot allocation policy that depends
on the allocation of previous slots. We prove that the DARA approach is optimal
for weight distributions that are exponentially decreasing in time. We further
implement our framework for real-time video streaming in wireless personal area
networks that are gaining significant traction within the new
Internet-of-Things (IoT) paradigm. For multiple surveillance videos encoded
with H.264/AVC and streamed via the 6tisch framework that simulates the
IoT-oriented IEEE 802.15.4e TSCH medium access control, our solution is shown
to be the only one that ensures all video bitstreams are delivered with
acceptable quality in a deadline-abiding manner.
"
572,Content Based Image Indexing and Retrieval,"  In this paper, we present the efficient content based image retrieval systems
which employ the color, texture and shape information of images to facilitate
the retrieval process. For efficient feature extraction, we extract the color,
texture and shape feature of images automatically using edge detection which is
widely used in signal processing and image compression. For facilitated the
speedy retrieval we are implements the antipole-tree algorithm for indexing the
images.
"
573,STIMONT: A core ontology for multimedia stimuli description,"  Affective multimedia documents such as images, sounds or videos elicit
emotional responses in exposed human subjects. These stimuli are stored in
affective multimedia databases and successfully used for a wide variety of
research in psychology and neuroscience in areas related to attention and
emotion processing. Although important all affective multimedia databases have
numerous deficiencies which impair their applicability. These problems, which
are brought forward in the paper, result in low recall and precision of
multimedia stimuli retrieval which makes creating emotion elicitation
procedures difficult and labor-intensive. To address these issues a new core
ontology STIMONT is introduced. The STIMONT is written in OWL-DL formalism and
extends W3C EmotionML format with an expressive and formal representation of
affective concepts, high-level semantics, stimuli document metadata and the
elicited physiology. The advantages of ontology in description of affective
multimedia stimuli are demonstrated in a document retrieval experiment and
compared against contemporary keyword-based querying methods. Also, a software
tool Intelligent Stimulus Generator for retrieval of affective multimedia and
construction of stimuli sequences is presented.
"
574,"Wireless Video Multicast with Cooperative and Incremental Transmission
  of Parity Packets","  In this paper, a cooperative multicast scheme that uses Randomized
Distributed Space Time Codes (R-DSTC), along with packet level Forward Error
Correction (FEC), is studied. Instead of sending source packets and/or parity
packets through two hops using R-DSTC as proposed in our prior work, the new
scheme delivers both source packets and parity packets using only one hop.
After the source station (access point, AP) first sends all the source packets,
the AP as well as all nodes that have received all source packets together send
the parity packets using R-DSTC. As more parity packets are transmitted, more
nodes can recover all source packets and join the parity packet transmission.
The process continues until all nodes acknowledge the receipt of enough packets
for recovering the source packets. For each given node distribution, the
optimum transmission rates for source and parity packets are determined such
that the video rate that can be sustained at all nodes is maximized. This new
scheme can support significantly higher video rates, and correspondingly higher
PSNR of decoded video, than the prior approaches. Three suboptimal approaches,
which do not require full information about user distribution or the feedback,
and hence are more feasible in practice are also presented. The proposed
suboptimal scheme with only the node count information and without feedback
still outperforms our prior approach that assumes full channel information and
no feedback.
"
575,Modeling Emotion Influence from Images in Social Networks,"  Images become an important and prevalent way to express users' activities,
opinions and emotions. In a social network, individual emotions may be
influenced by others, in particular by close friends. We focus on understanding
how users embed emotions into the images they uploaded to the social websites
and how social influence plays a role in changing users' emotions. We first
verify the existence of emotion influence in the image networks, and then
propose a probabilistic factor graph based emotion influence model to answer
the questions of ""who influences whom"". Employing a real network from Flickr as
experimental data, we study the effectiveness of factors in the proposed model
with in-depth data analysis. Our experiments also show that our model, by
incorporating the emotion influence, can significantly improve the accuracy
(+5%) for predicting emotions from images. Finally, a case study is used as the
anecdotal evidence to further demonstrate the effectiveness of the proposed
model.
"
576,Streaming Video over HTTP with Consistent Quality,"  In conventional HTTP-based adaptive streaming (HAS), a video source is
encoded at multiple levels of constant bitrate representations, and a client
makes its representation selections according to the measured network
bandwidth. While greatly simplifying adaptation to the varying network
conditions, this strategy is not the best for optimizing the video quality
experienced by end users. Quality fluctuation can be reduced if the natural
variability of video content is taken into consideration. In this work, we
study the design of a client rate adaptation algorithm to yield consistent
video quality. We assume that clients have visibility into incoming video
within a finite horizon. We also take advantage of the client-side video
buffer, by using it as a breathing room for not only network bandwidth
variability, but also video bitrate variability. The challenge, however, lies
in how to balance these two variabilities to yield consistent video quality
without risking a buffer underrun. We propose an optimization solution that
uses an online algorithm to adapt the video bitrate step-by-step, while
applying dynamic programming at each step. We incorporate our solution into
PANDA -- a practical rate adaptation algorithm designed for HAS deployment at
scale.
"
577,Service Oriented Paradigm for Massive Multiplayer Online Games,"  In recent times Massive Multiplayer Online Game has appeared as a computer
game that enables hundreds of players from all parts of the world to interact
in a game world (common platform) at the same time instance. Current
architecture used for MMOGs based on the classic tightly coupled distributed
system. While, MMOGs are getting more interactive same time number of
interacting users is increasing, classic implementation architecture may raise
scalability and interdependence issues. This requires a loosely coupled service
oriented architecture to support evolution in MMOG application. Data flow
architecture, Event driven architecture and client server architecture are
basic date orchestration approaches used by any service oriented architecture.
Real time service is hottest issue for service oriented architecture. The basic
requirement of any real time service oriented architecture is to ensure the
quality of service. In this paper we have proposed a service oriented
architecture for massive multiplayer online game and a specific middleware
(based on open source DDS) in MMOGs for fulfilling real time constraints.
"
578,A Study of Various Steganographic Techniques Used for Information Hiding,"  Steganography derives from the Greek word steganos, meaning covered or
secret, and graphy (writing or drawing). Steganography is a technology where
modern data compression, information theory, spread spectrum, and cryptography
technologies are brought together to satisfy the need for privacy on the
Internet. This paper is an attempt to analyse the various techniques used in
steganography and to identify areas in which this technique can be applied, so
that the human race can be benefited at large.
"
579,Image Block Loss Restoration Using Sparsity Pattern as Side Information,"  In this paper, we propose a method for image block loss restoration based on
the notion of sparse representation. We use the sparsity pattern as side
information to efficiently restore block losses by iteratively imposing the
constraints of spatial and transform domains on the corrupted image. Two novel
features, including a pre-interpolation and a criterion for stopping the
iterations, are proposed to improve the performance. Also, to deal with
practical applications, we develop a technique to transmit the side information
along with the image. In this technique, we first compress the side information
and then embed its LDPC coded version in the least significant bits of the
image pixels. This technique ensures the error-free transmission of the side
information, while causing only a small perturbation on the transmitted image.
Mathematical analysis and extensive simulations are performed to validate the
method and investigate the efficiency of the proposed techniques. The results
verify that the proposed method outperforms its counterparts for image block
loss restoration.
"
580,"Efficient Image Encryption and Decryption Using Discrete Wavelet
  Transform and Fractional Fourier Transform","  Fractional Fourier transform and chaos functions play a key role in many of
encryption-decryption algorithms. In this work performance of image
encryption-decryption algorithms is quantified and compared using the
computation time i.e. the time consumption of encryption-decryption process and
resemblance of input image to the restored image, quantified by MSE. This work
proposes an improvement in computation-time of image encryptiondecryption
algorithms by utilizing image compression properties of the 2-dimensional
Discrete Wavelet Transform (DWT2). Initially, computation complexity of the
algorithms is evaluated and compared with that of existing algorithms. This
analysis claims the proposed algorithms to be nearly 8 times faster than the
existing algorithms. Further, simulations are performed using MATLAB7.7 to
quantify performance of existing algorithms and the proposed algorithms using
MSE and computation time. The results obtained in these simulations prove that
for the proposed algorithms MSE between restored and original images is lesser
than that of existing algorithms thereby maintaining the robustness of the
existing algorithms. These algorithms are found sensitive to a variation of
1x10-1 in the fractional orders used in encryption-decryption process.
"
581,Differenciated Bandwidth Allocation in P2P Layered Streaming,"  There is an increasing demand for P2P streaming in particular for layered
video. In this category of applications, the stream is composed of
hierarchically encoded sub-streams layers namely the base layer and
enhancements layers. We consider a scenario where the receiver peer uses the
pull-based approach to adjust the video quality level to their capability by
subscribing to different number of layers. We note that higher layers received
without their corresponding lower layers are considered as useless and cannot
be played, consequently the throughput of the system will drastically degrade.
To avoid this situation, we propose an economical model based on auction
mechanisms to optimize the allocation of sender peers' upload bandwidth. The
upstream peers organize auctions to ""sell"" theirs items (links' bandwidth)
according to bids submitted by the downstream peers taking into consideration
the peers priorities and the requested layers importance. The ultimate goal is
to satisfy the quality level requirement for each peer, while reducing the
overall streaming cost. Through theoretical study and performance evaluation we
show the effectiveness of our model in terms of users and network's utility.
"
582,"Control of Multiple Remote Servers for Quality-Fair Delivery of
  Multimedia Contents","  This paper proposes a control scheme for the quality-fair delivery of several
encoded video streams to mobile users sharing a common wireless resource. Video
quality fairness, as well as similar delivery delays are targeted among
streams. The proposed controller is implemented within some aggregator located
near the bottleneck of the network. The transmission rate among streams is
adapted based on the quality of the already encoded and buffered packets in the
aggregator. Encoding rate targets are evaluated by the aggregator and fed back
to each remote video server (fully centralized solution), or directly evaluated
by each server in a distributed way (partially distributed solution). Each
encoding rate target is adjusted for each stream independently based on the
corresponding buffer level or buffering delay in the aggregator. Communication
delays between the servers and the aggregator are taken into account. The
transmission and encoding rate control problems are studied with a
control-theoretic perspective. The system is described with a multi-input
multi-output model. Proportional Integral (PI) controllers are used to adjust
the video quality and control the aggregator buffer levels. The system
equilibrium and stability properties are studied. This provides guidelines for
choosing the parameters of the PI controllers. Experimental results show the
convergence of the proposed control system and demonstrate the improvement in
video quality fairness compared to a classical transmission rate fair streaming
solution and to a utility max-min fair approach.
"
583,Adaptive Video Streaming in MU-MIMO Networks,"  We consider extensions and improvements on our previous work on dynamic
adaptive video streaming in a multi-cell multiuser ``small cell'' wireless
network. Previously, we treated the case of single-antenna base stations and,
starting from a network utility maximization (NUM) formulation, we devised a
``push'' scheduling policy, where users place requests to sequential video
chunks to possibly different base stations with adaptive video quality, and
base stations schedule their downlink transmissions in order to stabilize their
transmission queues. In this paper we consider a ``pull'' strategy, where every
user maintains a request queue, such that users keep track of the video chunks
that are effectively delivered. The pull scheme allows to download the chunks
in the playback order without skipping or missing them. In addition, motivated
by the recent/forthcoming progress in small cell networks (e.g., in wave-2 of
the recent IEEE 802.11ac standard), we extend our dynamic streaming approach to
the case of base stations capable of multiuser MIMO downlink, i.e., serving
multiple users on the same time-frequency slot by spatial multiplexing. By
exploiting the ``channel hardening'' effect of high dimensional MIMO channels,
we devise a low complexity user selection scheme to solve the underlying
max-weighted rate scheduling, which can be easily implemented and runs
independently at each base station. Through simulations, we show MIMO gains in
terms of video streaming QoE metrics like the pre-buffering and re-buffering
times.
"
584,Collaborative Receptive Field Learning,"  The challenge of object categorization in images is largely due to arbitrary
translations and scales of the foreground objects. To attack this difficulty,
we propose a new approach called collaborative receptive field learning to
extract specific receptive fields (RF's) or regions from multiple images, and
the selected RF's are supposed to focus on the foreground objects of a common
category. To this end, we solve the problem by maximizing a submodular function
over a similarity graph constructed by a pool of RF candidates. However,
measuring pairwise distance of RF's for building the similarity graph is a
nontrivial problem. Hence, we introduce a similarity metric called
pyramid-error distance (PED) to measure their pairwise distances through
summing up pyramid-like matching errors over a set of low-level features.
Besides, in consistent with the proposed PED, we construct a simple
nonparametric classifier for classification. Experimental results show that our
method effectively discovers the foreground objects in images, and improves
classification performance.
"
585,"A Study on the Optimal Implementation of Statistical Multiplexing in DVB
  Distribution Systems","  The paper presents an overview of the main methods used to improve the
efficiency of DVB systems, based on multiplexing, through a study on the impact
of the multiplexing methods used in DVB, having as a final goal a better usage
of the data capacity and the possibility to insert new services into the
original DVB Transport Stream. This study revealed that not all DVB providers
are using statistical multiplexing. Based on this study, we were able to
propose a method to improve the original DVB stream, originated from DVB-S or
DVB-T providers. This method is proposing the detection of null packets,
removal and reinserting a new service, with a VBR content. The method developed
in this research can be implemented even in optimized statistical multiplexing
systems, due to a residual use of null packets for data rate adjustment. There
is no need to have access in the original stream multiplexer, since the method
allows the implementation on the fly, near to the end user. The proposed method
is proposed to be applied in DVB-S to DVB-C translation, using the computing
power of a PC or in a FPGA implementation.
"
586,"Analyzing Peer Selection Policies for BitTorrent Multimedia On-Demand
  Streaming Systems in Internet","  The adaptation of the BitTorrent protocol to multimedia on-demand streaming
systems essentially lies on the modification of its two core algorithms, namely
the piece and the peer selection policies, respectively. Much more attention
has though been given to the piece selection policy. Within this context, this
article proposes three novel peer selection policies for the design of
BitTorrent-like protocols targeted at that type of systems: Select Balanced
Neighbour Policy (SBNP), Select Regular Neighbour Policy (SRNP), and Select
Optimistic Neighbour Policy (SONP). These proposals are validated through a
competitive analysis based on simulations which encompass a variety of
multimedia scenarios, defined in function of important characterization
parameters such as content type, content size, and client interactivity
profile. Service time, number of clients served and efficiency retrieving
coefficient are the performance metrics assessed in the analysis. The final
results mainly show that the novel proposals constitute scalable solutions that
may be considered for real project designs. Lastly, future work is included in
the conclusion of this paper.
"
587,Twofold Video Hashing with Automatic Synchronization,"  Video hashing finds a wide array of applications in content authentication,
robust retrieval and anti-piracy search. While much of the existing research
has focused on extracting robust and secure content descriptors, a significant
open challenge still remains: Most existing video hashing methods are fallible
to temporal desynchronization. That is, when the query video results by
deleting or inserting some frames from the reference video, most existing
methods assume the positions of the deleted (or inserted) frames are either
perfectly known or reliably estimated. This assumption may be okay under
typical transcoding and frame-rate changes but is highly inappropriate in
adversarial scenarios such as anti-piracy video search. For example, an illegal
uploader will try to bypass the 'piracy check' mechanism of YouTube/Dailymotion
etc by performing a cleverly designed non-uniform resampling of the video. We
present a new solution based on dynamic time warping (DTW), which can implement
automatic synchronization and can be used together with existing video hashing
methods. The second contribution of this paper is to propose a new robust
feature extraction method called flow hashing (FH), based on frame averaging
and optical flow descriptors. Finally, a fusion mechanism called distance
boosting is proposed to combine the information extracted by DTW and FH.
Experiments on real video collections show that such a hash extraction and
comparison enables unprecedented robustness under both spatial and temporal
attacks.
"
588,"A Multiplierless Pruned DCT-like Transformation for Image and Video
  Compression that Requires 10 Additions Only","  A multiplierless pruned approximate 8-point discrete cosine transform (DCT)
requiring only 10 additions is introduced. The proposed algorithm was assessed
in image and video compression, showing competitive performance with
state-of-the-art methods. Digital implementation in 45 nm CMOS technology up to
place-and-route level indicates clock speed of 288 MHz at a 1.1 V supply. The
8x8 block rate is 36 MHz.The DCT approximation was embedded into HEVC reference
software; resulting video frames, at up to 327 Hz for 8-bit RGB HEVC, presented
negligible image degradation.
"
589,A DCT Approximation for Image Compression,"  An orthogonal approximation for the 8-point discrete cosine transform (DCT)
is introduced. The proposed transformation matrix contains only zeros and ones;
multiplications and bit-shift operations are absent. Close spectral behavior
relative to the DCT was adopted as design criterion. The proposed algorithm is
superior to the signed discrete cosine transform. It could also outperform
state-of-the-art algorithms in low and high image compression scenarios,
exhibiting at the same time a comparable computational complexity.
"
590,"Fundamental Limits of Video Coding: A Closed-form Characterization of
  Rate Distortion Region from First Principles","  Classical motion-compensated video coding methods have been standardized by
MPEG over the years and video codecs have become integral parts of media
entertainment applications. Despite the ubiquitous use of video coding
techniques, it is interesting to note that a closed form rate-distortion
characterization for video coding is not available in the literature. In this
paper, we develop a simple, yet, fundamental characterization of
rate-distortion region in video coding based on information-theoretic first
principles. The concept of conditional motion estimation is used to derive the
closedform expression for rate-distortion region without losing its generality.
Conditional motion estimation offers an elegant means to analyze the
rate-distortion trade-offs and demonstrates the viability of achieving the
bounds derived. The concept involves classifying image regions into active and
inactive based on the amount of motion activity. By appropriately modeling the
residuals corresponding to active and inactive regions, a closed form
expression for rate-distortion function is derived in terms of motion activity
and spatio-temporal correlation that commonly exist in video content.
Experiments on real video clips using H.264 codec are presented to demonstrate
the practicality and validity of the proposed rate-distortion analysis.
"
591,A Novel approach as Multi-place Watermarking for Security in Database,"  Digital multimedia watermarking technology had suggested in the last decade
to embed copyright information in digital objects such as images, audio and
video. However, the increasing use of relational database systems in many
real-life applications created an ever-increasing need for watermarking
database systems. As a result, watermarking relational database system is now
emerging as a research area that deals with the legal issue of copyright
protection of database systems. The main goal of database watermarking is to
generate robust and impersistent watermark for database. In this paper we
propose a method, based on image as watermark and this watermark is embedded
over the database at two different attribute of tuple, one in the numeric
attribute of tuple and another in the date attribute's time (seconds) field.
Our approach can be applied for numerical and categorical database.
"
592,"The Effect of Block-wise Feedback on the Throughput-Delay Trade-off in
  Streaming","  Unlike traditional file transfer where only total delay matters, streaming
applications impose delay constraints on each packet and require them to be in
order. To achieve fast in-order packet decoding, we have to compromise on the
throughput. We study this trade-off between throughput and in-order decoding
delay, and in particular how it is affected by the frequency of block-wise
feedback to the source. When there is immediate feedback, we can achieve the
optimal throughput and delay simultaneously. But as the feedback delay
increases, we have to compromise on at least one of these metrics. We present a
spectrum of coding schemes that span different points on the throughput-delay
trade-off. Depending upon the delay-sensitivity and bandwidth limitations of
the application, one can choose an appropriate operating point on this
trade-off.
"
593,"Saving Energy in Mobile Devices for On-Demand Multimedia Streaming -- A
  Cross-Layer Approach","  This paper proposes a novel energy-efficient multimedia delivery system
called EStreamer. First, we study the relationship between buffer size at the
client, burst-shaped TCP-based multimedia traffic, and energy consumption of
wireless network interfaces in smartphones. Based on the study, we design and
implement EStreamer for constant bit rate and rate-adaptive streaming.
EStreamer can improve battery lifetime by 3x, 1.5x and 2x while streaming over
Wi-Fi, 3G and 4G respectively.
"
594,A Methodology for Implementation of MMS Client on Embedded Platforms,"  MMS (Multimedia Messaging Service) is the next generation of messaging
services in multimedia mobile communications. MMS enables messaging with full
multimedia content including images, audios, videos, texts and data, from
client to client or e-mail. MMS is based on WAP technology, so it is technology
independent. This means that enabling messages from a GSM/GPRS network to be
sent to a TDMA or WCDMA network. In this paper a methodology for implementing
MMS client on embedded platforms especially on Wince OS is described.
"
595,"Pervasive Image Computation: A Mobile Phone Application for getting
  Information of the Images","  Although many of the information processing systems are text-based, much of
the information in the real life is generally multimedia objects, so there is a
need to define and standardize the frame works for multimedia-based information
processing systems. In this paper we consider the application of such a system
namely pervasive image computation system, in which the user uses the cellphone
for taking the picture of the objects, and he wants to get some information
about them. We have implemented two architectures, the first one, called online
architecture, which the user sends the picture to the server and server sends
the picture information directly back to him. In the second one, which is
called offline architecture, the user uploads the image in one public image
database such as Flickr and sends the ID of the image in this database to the
server. The server processes the image and adds the information of the image in
the database, and finally the user can connect to the database and download the
image information. The implementation results show that these architectures are
very flexible and could be easily extended to be used in more complicated
pervasive multimedia systems.
"
596,Web-Based Visualization of Very Large Scientific Astronomy Imagery,"  Visualizing and navigating through large astronomy images from a remote
location with current astronomy display tools can be a frustrating experience
in terms of speed and ergonomics, especially on mobile devices. In this paper,
we present a high performance, versatile and robust client-server system for
remote visualization and analysis of extremely large scientific images.
Applications of this work include survey image quality control, interactive
data query and exploration, citizen science, as well as public outreach. The
proposed software is entirely open source and is designed to be generic and
applicable to a variety of datasets. It provides access to floating point data
at terabyte scales, with the ability to precisely adjust image settings in
real-time. The proposed clients are light-weight, platform-independent web
applications built on standard HTML5 web technologies and compatible with both
touch and mouse-based devices. We put the system to the test and assess the
performance of the system and show that a single server can comfortably handle
more than a hundred simultaneous users accessing full precision 32 bit
astronomy data.
"
597,"WaterRPG: A Graph-based Dynamic Watermarking Model for Software
  Protection","  Software watermarking involves embedding a unique identifier or,
equivalently, a watermark value within a software to prove owner's authenticity
and thus to prevent or discourage copyright infringement. Towards the embedding
process, several graph theoretic watermarking algorithmic techniques encode the
watermark values as graph structures and embed them in application programs.
Recently, we presented an efficient codec system for encoding a watermark
number $w$ as a reducible permutation graph $F[\pi^*]$ through the use of
self-inverting permutations $\pi^*$. In this paper, we propose a dynamic
watermarking model, which we call WaterRPG, for embedding the watermark graph
$F[\pi^*]$ into an application program $P$. The main idea behind the proposed
watermarking model is a systematic use of appropriate calls of specific
functions of the program $P$. More precisely, for a specific input $I_{key}$ of
the program $P$, our model takes the dynamic call-graph $G(P, I_{key})$ of $P$
and the watermark graph $F[\pi^*]$, and produces the watermarked program $P^*$
having the following key property: its dynamic call-graph $G(P^*, I_{key})$ is
isomorphic to the watermark graph $F[\pi^*]$. Within this idea the program
$P^*$ is produced by only altering appropriate calls of specific functions of
the input application program $P$. We have implemented our watermarking model
WaterRPG in real application programs and evaluated its functionality under
various and broadly used watermarking assessment criteria. The evaluation
results show that our model efficiently watermarks Java application programs
with respect to several watermarking metrics like data-rate, bytecode
instructions overhead, resiliency, time and space efficiency. Moreover, the
embedded watermarks withstand several software obfuscation and optimization
attacks.
"
598,"Automatic Segmentation of Broadcast News Audio using Self Similarity
  Matrix","  Generally audio news broadcast on radio is com- posed of music, commercials,
news from correspondents and recorded statements in addition to the actual news
read by the newsreader. When news transcripts are available, automatic
segmentation of audio news broadcast to time align the audio with the text
transcription to build frugal speech corpora is essential. We address the
problem of identifying segmentation in the audio news broadcast corresponding
to the news read by the newsreader so that they can be mapped to the text
transcripts. The existing techniques produce sub-optimal solutions when used to
extract newsreader read segments. In this paper, we propose a new technique
which is able to identify the acoustic change points reliably using an acoustic
Self Similarity Matrix (SSM). We describe the two pass technique in detail and
verify its performance on real audio news broadcast of All India Radio for
different languages.
"
599,Building A Large Concept Bank for Representing Events in Video,"  Concept-based video representation has proven to be effective in complex
event detection. However, existing methods either manually design concepts or
directly adopt concept libraries not specifically designed for events. In this
paper, we propose to build Concept Bank, the largest concept library consisting
of 4,876 concepts specifically designed to cover 631 real-world events. To
construct the Concept Bank, we first gather a comprehensive event collection
from WikiHow, a collaborative writing project that aims to build the world's
largest manual for any possible How-To event. For each event, we then search
Flickr and discover relevant concepts from the tags of the returned images. We
train a Multiple Kernel Linear SVM for each discovered concept as a concept
detector in Concept Bank. We organize the concepts into a five-layer tree
structure, in which the higher-level nodes correspond to the event categories
while the leaf nodes are the event-specific concepts discovered for each event.
Based on such tree ontology, we develop a semantic matching method to select
relevant concepts for each textual event query, and then apply the
corresponding concept detectors to generate concept-based video
representations. We use TRECVID Multimedia Event Detection 2013 and Columbia
Consumer Video open source event definitions and videos as our test sets and
show very promising results on two video event detection tasks: event modeling
over concept space and zero-shot event retrieval. To the best of our knowledge,
this is the largest concept library covering the largest number of real-world
events.
"
600,"Energy-Efficient Adaptive Video Transmission: Exploiting Rate
  Predictions in Wireless Networks","  The unprecedented growth of mobile video traffic is adding significant
pressure to the energy drain at both the network and the end user. Energy
efficient video transmission techniques are thus imperative to cope with the
challenge of satisfying user demand at sustainable costs. In this paper, we
investigate how predicted user rates can be exploited for energy efficient
video streaming with the popular HTTP-based Adaptive Streaming (AS) protocols
(e.g. DASH). To this end, we develop an energy-efficient Predictive Green
Streaming (PGS) optimization framework that leverages predictions of wireless
data rates to achieve the following objectives 1) minimize the required
transmission airtime without causing streaming interruptions, 2) minimize total
downlink Base Station (BS) power consumption for cases where BSs can be
switched off in deep sleep, and 3) enable a trade-off between AS quality and
energy consumption. Our framework is first formulated as a Mixed Integer Linear
Program (MILP) where decisions on multi-user rate allocation, video segment
quality, and BS transmit power are jointly optimized. Then, to provide an
online solution, we present a polynomial-time heuristic algorithm that
decouples the PGS problem into multiple stages. We provide a performance
analysis of the proposed methods by simulations, and numerical results
demonstrate that the PGS framework yields significant energy savings.
"
601,"Color to Gray and Back transformation for distributing color digital
  images","  The Color to Gray and Back transformation watermarking with a secrete key is
considered. Color is embedded into the bit planes of the luminosity component
of the YUV color space with the help of a block algorithm that allows using not
only the least significant bits. An application of the problem of distributing
color digital images from a data base among legitimate users is discussed. The
proposed protocol can protect original images from unauthorized copying.
"
602,"Robust Video Watermarking Schemes in Phase domain Using Binary Phase
  Shift Keying","  This paper presents a robust video watermarking scheme in Discrete Fourier
Transform (DFT) and Sequencyordered Complex Hadamard Transform (SCHT). The DFT
and SCHT coefficients are complex and consist of both magnitude and phase and
are well suited to adopt phase shift keying techniques to embed the watermark.
In the proposed schemes, the phases of DFT and SCHT coefficients are modified
to convey watermark information using binary phase shift keying in cover video.
Low amplitude block selection (LABS) is used to improve transparency, amplitude
boost to improve the resistance of watermark from signal processing and
compression attacks and spread spectrum technique is used for encrypting
watermark in order to protect it from third party. It is observed that both
algorithms showing more or less same robustness but SCHT offers high
transparency, simple implementation and less computational cost than DFT.
"
603,"Text Based Approach For Indexing And Retrieval Of Image And Video: A
  Review","  Text data present in multimedia contain useful information for automatic
annotation, indexing. Extracted information used for recognition of the overlay
or scene text from a given video or image. The Extracted text can be used for
retrieving the videos and images. In this paper, firstly, we are discussed the
different techniques for text extraction from images and videos. Secondly, we
are reviewed the techniques for indexing and retrieval of image and videos by
using extracted text.
"
604,"Steganography - coding and intercepting the information from encoded
  pictures in the absence of any initial information","  The work includes implementation and extraction algorithms capabilities test,
without any additional data (starting position, the number of bits used, gap
between the amount of data encoded) information from encoded files (mostly
images). The software is written using OpenMP standard [1], which allowed them
to run on parallel computers. Performance tests were carried out on computers,
Blue Gene/P [2], Blue Gene/Q [3] and the system consisting of four AMD Opteron
6272 [4]. Source code is available under GNU GPL v3 license and are available
in a repository OLib [5].
"
605,Wireless Transmission of Video for Biomechanical Analysis,"  When there is a possibility to wirelessly stream video over a network, a
sophisticated computer analysis of the transmitted video is possible. Such
process is used in biomechanics when it is important to analyze athletes
performance via streaming digital uncompressed video to a computer and then
analyzing it using specific software such as Arial Performance Analysis Systems
or Dartfish. This manuscript presents some approaches and challenges in
streaming video as well as some applications of Information Technology in
biomechanics. An example of how scientists from Indiana State University
approached the wireless transmission of video is also introduced.
"
606,"Analysis of Computer Hardware Affecting Video Transmission via IEEE
  1394a connection","  When 60 de-interlaced fields per second digital uncompressed video is
streamed to a computer, some video fields are lost and not able to be stored on
a computer s hard drive successfully. Additionally, this problem amplifies once
multiple video sources are deployed. If it is possible to stream digital
uncompressed video without dropped video fields, then a sophisticated computer
analysis of the transmitted via IEEE 1394a connection video is possible. Such
process is used in biomechanics when it is important to analyze athletes
performance via streaming digital uncompressed video to a computer and then
analyzing it. If a loss of video fields occurs, then a quality analysis of
video is not possible.
"
607,Reduction of Field Loss by a Video Processing System,"  Streaming of 60 de-interlaced fields per second digital uncompressed video
with 720x480 resolution without a loss of video fields is one of the desired
technologies by scientists in biomechanics. If it is possible to stream digital
uncompressed video without dropped video fields, then a sophisticated computer
analysis of the transmitted via IEEE 1394a connection video is possible. Such
process is used in biomechanics when it is important to analyze athletes
performance via streaming digital uncompressed video to a computer and then
analyzing it using specific software such as Arial Performance Analysis
Systems.
"
608,A blind robust watermarking scheme based on svd and circulant matrices,"  Multimedia security has been the aim point of considerable research activity
because of its wide application area. The major technology to achieve copyright
protection, content authentication, access control and multimedia security is
watermarking which is the process of embedding data into a multimedia element
such as image or audio, this embedded data can later be extracted from, or
detected in the embedded element for different purposes. In this work, a blind
watermarking algorithm based on SVD and circulant matrices has been presented.
Every circulant matrix is associated with a matrix for which the SVD
decomposition coincides with the spectral decomposition. This leads to improve
the Chandra algorithm [1], our presentation will include a discussion on the
data hiding capacity, watermark transparency and robustness against a wide
range of common image processing attacks.
"
609,"Enhancing User Experience for Multi-Screen Social TV Streaming over
  Wireless Networks","  Recently, multi-screen cloud social TV is invented to transform TV into
social experience. People watching the same content on social TV may come from
different locations, while freely interact with each other through text, image,
audio and video. This crucial virtual living-room experience adds social
aspects into existing performance metrics. In this paper, we parse social TV
user experience into three elements (i.e., inter-user delay, video quality of
experience (QoE), and resource efficiency), and provide a joint analytical
framework to enhance user experience. Specifically, we propose a cloud-based
optimal playback rate allocation scheme to maximize the overall QoE while upper
bounding inter-user delay. Experiment results show that our algorithm achieves
near-optimal tradeoff between inter-user delay and video quality, and
demonstrates resilient performance even under very fast wireless channel
fading.
"
610,"Motion-Compensated Coding and Frame-Rate Up-Conversion: Models and
  Analysis","  Block-based motion estimation (ME) and compensation (MC) techniques are
widely used in modern video processing algorithms and compression systems. The
great variety of video applications and devices results in numerous compression
specifications. Specifically, there is a diversity of frame-rates and
bit-rates. In this paper, we study the effect of frame-rate and compression
bit-rate on block-based ME and MC as commonly utilized in inter-frame coding
and frame-rate up conversion (FRUC). This joint examination yields a
comprehensive foundation for comparing MC procedures in coding and FRUC. First,
the video signal is modeled as a noisy translational motion of an image. Then,
we theoretically model the motion-compensated prediction of an available and
absent frames as in coding and FRUC applications, respectively. The theoretic
MC-prediction error is further analyzed and its autocorrelation function is
calculated for coding and FRUC applications. We show a linear relation between
the variance of the MC-prediction error and temporal-distance. While the
affecting distance in MC-coding is between the predicted and reference frames,
MC-FRUC is affected by the distance between the available frames used for the
interpolation. Moreover, the dependency in temporal-distance implies an inverse
effect of the frame-rate. FRUC performance analysis considers the prediction
error variance, since it equals to the mean-squared-error of the interpolation.
However, MC-coding analysis requires the entire autocorrelation function of the
error; hence, analytic simplicity is beneficial. Therefore, we propose two
constructions of a separable autocorrelation function for prediction error in
MC-coding. We conclude by comparing our estimations with experimental results.
"
611,Improving Low Bit-Rate Video Coding using Spatio-Temporal Down-Scaling,"  Good quality video coding for low bit-rate applications is important for
transmission over narrow-bandwidth channels and for storage with limited memory
capacity. In this work, we develop a previous analysis for image compression at
low bit-rates to adapt it to video signals. Improving compression using
down-scaling in the spatial and temporal dimensions is examined. We show, both
theoretically and experimentally, that at low bit-rates, we benefit from
applying spatio-temporal scaling. The proposed method includes down-scaling
before the compression and a corresponding up-scaling afterwards, while the
codec itself is left unmodified. We propose analytic models for low bit-rate
compression and spatio-temporal scaling operations. Specifically, we use
theoretic models of motion-compensated prediction of available and absent
frames as in coding and frame-rate up-conversion (FRUC) applications,
respectively. The proposed models are designed for multi-resolution analysis.
In addition, we formulate a bit-allocation procedure and propose a method for
estimating good down-scaling factors of a given video based on its second-order
statistics and the given bit-budget. We validate our model with experimental
results of H.264 compression.
"
612,"Prediction of Transformed (DCT) Video Coding Residual for Video
  Compression","  Video compression has been investigated by means of analysis-synthesis, and
more particularly by means of inpainting. The first part of our approach has
been to develop the inpainting of DCT coefficients in an image. This has shown
good results for image compression without overpassing todays compression
standards like JPEG. We then looked at integrating the same approach in a video
coder, and in particular in the widely used H264 AVC standard coder, but the
same approach can be used in the framework of HEVC. The originality of this
work consists in cancelling at the coder, then automatically restoring, at the
decoder, some well chosen DCT residual coefficients. For this purpose, we have
developed a restoration model of transformed coefficients. By using a total
variation based model, we derive conditions for the reconstruction of
transformed coefficients that have been suppressed or altered. The main purpose
here, in a video coding context, is to improve the ratedistortion performance
of existing coders. To this end DCT restoration is used as an additional
prediction step to the spatial prediction of the transformed coefficients,
based on an image regularization process. The method has been successfully
tested with the H.264 AVC video codec standard.
"
613,A Novel Approach for Video Temporal Annotation,"  Recent advances in computing, communication, and data storage have led to an
increasing number of large digital libraries publicly available on the
Internet. Main problem of content-based video retrieval is inferring semantics
from raw video data. Video data play an important role in these libraries.
Instead of words, a video retrieval system deals with collections of video
records. Therefore, the system is confronted with the problem of video
understanding. Because machine understanding of the video data is still an
unsolved research problem, text annotations are usually used to describe the
content of video data according to the annotator's understanding and the
purpose of that video data. Most of proposed systems for video annotation are
domain dependent. In addition, in many of these systems, an important feature
of video data, temporality, is disregarded. In this paper, we proposed a
framework for video temporal annotation. The proposed system uses domain
knowledge and a time ontology to perform temporal annotation of input video.
"
614,Leveraging video annotations in video-based e-learning,"  The e-learning community has been producing and using video content for a
long time, and in the last years, the advent of MOOCs greatly relied on video
recordings of teacher courses. Video annotations are information pieces that
can be anchored in the temporality of the video so as to sustain various
processes ranging from active reading to rich media editing. In this position
paper we study how video annotations can be used in an e-learning context -
especially MOOCs - from the triple point of view of pedagogical processes,
current technical platforms functionalities, and current challenges. Our
analysis is that there is still plenty of room for leveraging video annotations
in MOOCs beyond simple active reading, namely live annotation, performance
annotation and annotation for assignment; and that new developments are needed
to accompany this evolution.
"
615,"A Smart Intelligent Way of Video Authentication Using Classification and
  Decomposition of Watermarking Methods","  Video Watermarking serves as a new technology mainly used to provide security
to the illegal distribution of digital video over the web. The purpose of any
video watermarking scheme is to embed extra information into video in such a
way that must be perceptually undetectable while still holding enough
information in order to extract the watermark beginning with the resultant
video. Information which is embedded within the original image is a Digital
Watermark, which could be visible or invisible. To improved more security,
embedding and extraction Watermark process should be complex against attackers.
Recent research indicates SVD (Singular Value Decomposition) algorithms are
employed owing to their simple scheme with mathematical function. In this
proposed work an advanced SVD transformation algorithm is used for embedding
and extraction process. Experimental results show proposed watermarking process
is more secured than existing SVD approach.
"
616,Antescofo Intermediate Representation,"  We describe an intermediate language designed as a medium-level internal
representation of programs of the interactive music system Antescofo. This
representation is independent both of the Antescofo source language and of the
architecture of the execution platform. It is used in tasks such as
verification of timings, model-based conformance testing, static control-flow
analysis or simulation. This language is essentially a flat representation of
Antescofo's code, as a finite state machine extended with local and global
variables, with delays and with concurrent threads creation. It features a
small number of simple instructions which are either blocking (wait for
external event, signal or duration) or not (variable assignment, message
emission and control).
"
617,Majority Vote of Diverse Classifiers for Late Fusion,"  In the past few years, a lot of attention has been devoted to multimedia
indexing by fusing multimodal informations. Two kinds of fusion schemes are
generally considered: The early fusion and the late fusion. We focus on late
classifier fusion, where one combines the scores of each modality at the
decision level. To tackle this problem, we investigate a recent and elegant
well-founded quadratic program named MinCq coming from the machine learning
PAC-Bayesian theory. MinCq looks for the weighted combination, over a set of
real-valued functions seen as voters, leading to the lowest misclassification
rate, while maximizing the voters' diversity. We propose an extension of MinCq
tailored to multimedia indexing. Our method is based on an order-preserving
pairwise loss adapted to ranking that allows us to improve Mean Averaged
Precision measure while taking into account the diversity of the voters that we
want to fuse. We provide evidence that this method is naturally adapted to late
fusion procedures and confirm the good behavior of our approach on the
challenging PASCAL VOC'07 benchmark.
"
618,"VSCAN: An Enhanced Video Summarization using Density-based Spatial
  Clustering","  In this paper, we present VSCAN, a novel approach for generating static video
summaries. This approach is based on a modified DBSCAN clustering algorithm to
summarize the video content utilizing both color and texture features of the
video frames. The paper also introduces an enhanced evaluation method that
depends on color and texture features. Video Summaries generated by VSCAN are
compared with summaries generated by other approaches found in the literature
and those created by users. Experimental results indicate that the video
summaries generated by VSCAN have a higher quality than those generated by
other approaches.
"
619,"Multiplierless Approximate 4-point DCT VLSI Architectures for Transform
  Block Coding","  Two multiplierless algorithms are proposed for 4x4 approximate-DCT for
transform coding in digital video. Computational architectures for 1-D/2-D
realisations are implemented using Xilinx FPGA devices. CMOS synthesis at the
45 nm node indicate real-time operation at 1 GHz yielding 4x4 block rates of
125 MHz at less than 120 mW of dynamic power consumption.
"
620,"Image Restoration Using Joint Statistical Modeling in Space-Transform
  Domain","  This paper presents a novel strategy for high-fidelity image restoration by
characterizing both local smoothness and nonlocal self-similarity of natural
images in a unified statistical manner. The main contributions are three-folds.
First, from the perspective of image statistics, a joint statistical modeling
(JSM) in an adaptive hybrid space-transform domain is established, which offers
a powerful mechanism of combining local smoothness and nonlocal self-similarity
simultaneously to ensure a more reliable and robust estimation. Second, a new
form of minimization functional for solving image inverse problem is formulated
using JSM under regularization-based framework. Finally, in order to make JSM
tractable and robust, a new Split-Bregman based algorithm is developed to
efficiently solve the above severely underdetermined inverse problem associated
with theoretical proof of convergence. Extensive experiments on image
inpainting, image deblurring and mixed Gaussian plus salt-and-pepper noise
removal applications verify the effectiveness of the proposed algorithm.
"
621,An Adaptive Watermarking Process in Hadamard Transform,"  An adaptive visible/invisible watermarking scheme is done to prevent the
privacy and preserving copyright protection of digital data using Hadamard
transform based on the scaling factor of the image. The value of scaling factor
depends on the control parameter. The scaling factor is calculated to embedded
the watermark. Depend upon the control parameter the visible and invisible
watermarking is determined. The proposed Hadamard transform domain method is
more robust again image/signal processing attacks. Furthermore, it also shows
that the proposed method confirm the efficiency through various performance
analysis and experimental results.
"
622,"MicroCast: Cooperative Video Streaming using Cellular and D2D
  Connections","  We consider a group of mobile users, within proximity of each other, who are
interested in watching the same online video at roughly the same time. The
common practice today is that each user downloads the video independently on
her mobile device using her own cellular connection, which wastes access
bandwidth and may also lead to poor video quality. We propose a novel
cooperative system where each mobile device uses simultaneously two network
interfaces: (i) the cellular to connect to the video server and download parts
of the video and (ii) WiFi to connect locally to all other devices in the group
and exchange those parts. Devices cooperate to efficiently utilize all network
resources and are able to adapt to varying wireless network conditions. In the
local WiFi network, we exploit overhearing, and we further combine it with
network coding. The end result is savings in cellular bandwidth and improved
user experience (faster download) by a factor on the order up to the group
size.
  We follow a complete approach, from theory to practice. First, we formulate
the problem using a network utility maximization (NUM) framework, decompose the
problem, and provide a distributed solution. Then, based on the structure of
the NUM solution, we design a modular system called MicroCast and we implement
it as an Android application. We provide both simulation results of the NUM
solution and experimental evaluation of MicroCast on a testbed consisting of
Android phones. We demonstrate that the proposed approach brings significant
performance benefits without battery penalty.
"
623,YouTube QoE Evaluation Tool for Android Wireless Terminals,"  In this paper, we present an Android application which is able to evaluate
and analyze the perceived Quality of Experience (QoE) for YouTube service in
wireless terminals. To achieve this goal, the application carries out
measurements of objective Quality of Service (QoS) parameters, which are then
mapped onto subjective QoE (in terms of Mean Opinion Score, MOS) by means of a
utility function. Our application also informs the user about potential causes
that lead to a low MOS as well as provides some hints to improve it. After each
YouTube session, the users may optionally qualify the session through an online
opinion survey. This information has been used in a pilot experience to
correlate the theoretical QoE model with real user feedback. Results from such
an experience have shown that the theoretical model (taken from the literature)
provides slightly more pessimistic results compared to user feedback. Users
seem to be more indulgent with wireless connections, increasing the MOS from
the opinion survey in about 20% compared to the theoretical model, which was
obtained from wired scenarios.
"
624,"Block matching algorithm based on Differential Evolution for motion
  estimation","  Motion estimation is one of the major problems in developing video coding
applications. Among all motion estimation approaches, Block matching (BM)
algorithms are the most popular methods due to their effectiveness and
simplicity for both software and hardware implementations. A BM approach
assumes that the movement of pixels within a defined region of the current
frame (Macro-Block, MB) can be modeled as a translation of pixels contained in
the previous frame. In this procedure, the motion vector is obtained by
minimizing the sum of absolute differences (SAD) produced by the MB of the
current frame over a determined search window from the previous frame. The SAD
evaluation is computationally expensive and represents the most consuming
operation in the BM process. The most straightforward BM method is the full
search algorithm (FSA) which finds the most accurate motion vector, calculating
exhaustively the SAD values for all elements of the search window. Over this
decade, several fast BM algorithms have been proposed to reduce the number of
SAD operations by calculating only a fixed subset of search locations at the
price of a poor accuracy. In this paper, a new algorithm based on Differential
Evolution (DE) is proposed to reduce the number of search locations in the BM
process. In order to avoid computing several search locations, the algorithm
estimates the SAD values (fitness) for some locations using the SAD values of
previously calculated neighboring positions. Since the proposed algorithm does
not consider any fixed search pattern or other different assumption, a high
probability for finding the true minimum (accurate motion vector) is expected.
In comparison to other fast BM algorithms, the proposed method deploys more
accurate motion vectors yet delivering competitive time rates.
"
625,Trends and Perspectives for Signal Processing in Consumer Audio,"  The trend in media consumption towards streaming and portability offers new
challenges and opportunities for signal processing in audio and acoustics. The
most significant embodiment of this trend is that most music consumption now
happens on-the-go which has recently led to an explosion in headphone sales and
small portable speakers. In particular, premium headphones offer a gateway for
a younger generation to experience high quality sound. Additionally, through
technologies incorporating head-related transfer functions headphones can also
offer unique new experiences in gaming, augmented reality, and surround sound
listening. Home audio has also seen a transition to smaller sound systems in
the form of sound bars. This speaker configuration offers many exciting
challenges for surround sound reproduction which has traditionally used five
speakers surrounding the listener. Furthermore, modern home entertainment
systems offer more than just content delivery; users now expect wireless and
connected smart devices with video conferencing, gaming, and other interactive
capabilities. With this comes challenges for voice interaction at a distance
and in demanding conditions, e.g., during content playback, and opportunities
for new smart interactive experiences based on awareness of environment and
user biometrics.
"
626,Steganalysis: Detecting LSB Steganographic Techniques,"  Steganalysis means analysis of stego images. Like cryptanalysis, steganalysis
is used to detect messages often encrypted using secret key from stego images
produced by steganography techniques. Recently lots of new and improved
steganography techniques are developed and proposed by researchers which
require robust steganalysis techniques to detect the stego images having
minimum false alarm rate. This paper discusses about the different Steganalysis
techniques and help to understand how, where and when this techniques can be
used based on different situations.
"
627,An Incomplete Cryptography based Digital Rights Management with DCFF,"  In general, DRM (Digital Rights Management) system is responsible for the
safe distribution of digital content, however, DRM system is achieved with
individual function modules of cryptography, watermarking and so on. In this
typical system flow, it has a problem that all original digital contents are
temporarily disclosed with perfect condition via decryption process. In this
paper, we propose the combination of the differential codes and fragile
fingerprinting (DCFF) method based on incomplete cryptography that holds
promise for a better compromise between practicality and security for emerging
digital rights management applications. Experimental results with simulation
confirmed that DCFF keeps compatibility with standard JPEG codec, and revealed
that the proposed method is suitable for DRM in the network distribution
system.
"
628,"A hybrid video quality metric for analyzing quality degradation due to
  frame drop","  In last decade, ever growing internet technologies provided platform to share
the multimedia data among different communities. As the ultimate users are
human subjects who are concerned about quality of visual information, it is
often desired to have good resumed perceptual quality of videos, thus arises
the need of quality assessment. This paper presents a full reference hybrid
video quality metric which is capable to analyse the video quality for
spatially or temporally (frame drop) or spatio-temporally distorted video
sequences. Simulated results show that the metric efficiently analyses the
quality degradation and more closer to the developed human visual system
"
629,"Low-complexity video encoder for smart eyes based on underdetermined
  blind signal separation","  This paper presents a low complexity video coding method based on
Underdetermined Blind Signal Separation (UBSS). The detailed coding framework
is designed. Three key techniques are proposed to enhance the compression ratio
and the quality of the decoded frames. The experiments validate that the
proposed method costs 30ms encoding time less than DISCOVER. The simulation
shows that this new method can save 50% energy compared with H.264.
"
630,Jpeg Image Compression Using Discrete Cosine Transform - A Survey,"  Due to the increasing requirements for transmission of images in computer,
mobile environments, the research in the field of image compression has
increased significantly. Image compression plays a crucial role in digital
image processing, it is also very important for efficient transmission and
storage of images. When we compute the number of bits per image resulting from
typical sampling rates and quantization methods, we find that Image compression
is needed. Therefore development of efficient techniques for image compression
has become necessary .This paper is a survey for lossy image compression using
Discrete Cosine Transform, it covers JPEG compression algorithm which is used
for full-colour still image applications and describes all the components of
it.
"
631,Multi-view Metric Learning for Multi-view Video Summarization,"  Traditional methods on video summarization are designed to generate summaries
for single-view video records; and thus they cannot fully exploit the
redundancy in multi-view video records. In this paper, we present a multi-view
metric learning framework for multi-view video summarization that combines the
advantages of maximum margin clustering with the disagreement minimization
criterion. The learning framework thus has the ability to find a metric that
best separates the data, and meanwhile to force the learned metric to maintain
original intrinsic information between data points, for example geometric
information. Facilitated by such a framework, a systematic solution to the
multi-view video summarization problem is developed. To the best of our
knowledge, it is the first time to address multi-view video summarization from
the viewpoint of metric learning. The effectiveness of the proposed method is
demonstrated by experiments.
"
632,"A scenario based approach for dealing with challenges in a pervasive
  computing environment","  With the surge in modern research focus towards Pervasive Computing, lot of
techniques and challenges needs to be addressed so as to effectively create
smart spaces and achieve miniaturization. In the process of scaling down to
compact devices, the real things to ponder upon are the Information Retrieval
challenges. In this work, we discuss the aspects of multimedia which makes
information access challenging. An Example Pattern Recognition scenario is
presented and the mathematical techniques that can be used to model uncertainty
are also presented for developing a system that can sense, compute and
communicate in a way that can make human life easy with smart objects assisting
from around his surroundings.
"
633,"Detection Bank: An Object Detection Based Video Representation for
  Multimedia Event Recognition","  While low-level image features have proven to be effective representations
for visual recognition tasks such as object recognition and scene
classification, they are inadequate to capture complex semantic meaning
required to solve high-level visual tasks such as multimedia event detection
and recognition. Recognition or retrieval of events and activities can be
improved if specific discriminative objects are detected in a video sequence.
In this paper, we propose an image representation, called Detection Bank, based
on the detection images from a large number of windowed object detectors where
an image is represented by different statistics derived from these detections.
This representation is extended to video by aggregating the key frame level
image representations through mean and max pooling. We empirically show that it
captures complementary information to state-of-the-art representations such as
Spatial Pyramid Matching and Object Bank. These descriptors combined with our
Detection Bank representation significantly outperforms any of the
representations alone on TRECVID MED 2011 data.
"
634,Analysis and Forecasting of Trending Topics in Online Media Streams,"  Among the vast information available on the web, social media streams capture
what people currently pay attention to and how they feel about certain topics.
Awareness of such trending topics plays a crucial role in multimedia systems
such as trend aware recommendation and automatic vocabulary selection for video
concept detection systems.
  Correctly utilizing trending topics requires a better understanding of their
various characteristics in different social media streams. To this end, we
present the first comprehensive study across three major online and social
media streams, Twitter, Google, and Wikipedia, covering thousands of trending
topics during an observation period of an entire year. Our results indicate
that depending on one's requirements one does not necessarily have to turn to
Twitter for information about current events and that some media streams
strongly emphasize content of specific categories. As our second key
contribution, we further present a novel approach for the challenging task of
forecasting the life cycle of trending topics in the very moment they emerge.
Our fully automated approach is based on a nearest neighbor forecasting
technique exploiting our assumption that semantically similar topics exhibit
similar behavior.
  We demonstrate on a large-scale dataset of Wikipedia page view statistics
that forecasts by the proposed approach are about 9-48k views closer to the
actual viewing statistics compared to baseline methods and achieve a mean
average percentage error of 45-19% for time periods of up to 14 days.
"
635,JPEG Noises beyond the First Compression Cycle,"  This paper focuses on the JPEG noises, which include the quantization noise
and the rounding noise, during a JPEG compression cycle. The JPEG noises in the
first compression cycle have been well studied; however, so far less attention
has been paid on the JPEG noises in higher compression cycles. In this work, we
present a statistical analysis on JPEG noises beyond the first compression
cycle. To our knowledge, this is the first work on this topic. We find that the
noise distributions in higher compression cycles are different from those in
the first compression cycle, and they are dependent on the quantization
parameters used between two successive cycles. To demonstrate the benefits from
the statistical analysis, we provide two applications that can employ the
derived noise distributions to uncover JPEG compression history with
state-of-the-art performance.
"
636,QoE assessment for SVC streaming in ENVISION,"  Scalable video coding has drawn great interest in content delivery in many
multimedia services thanks to its capability to handle terminal heterogeneity
and network conditions variation. In our previous work, and under the umbrella
of ENVISION, we have proposed a playout smoothing mechanism to ensure the
uniform delivery of the layered stream, by reducing the quality changes that
the stream undergoes when adapting to changing network conditions. In this
paper we study the resulting video quality, from the final user perception
under different network conditions of loss and delays. For that we have adopted
the Double Stimulus Impairment Scale (DSIS) method. The results show that the
Mean Opinion Score for the smoothed video clips was higher under different
network configuration. This confirms the effectiveness of the proposed
smoothing mechanism.
"
637,"Towards Quality of Experience Determination for Video in Augmented
  Binocular Vision Scenarios","  With the continuous growth in the consumer markets of mobile smartphones and
increasingly in augmented reality wearable devices, several avenues of research
investigate the relationships between the quality perceived by mobile users and
the delivery mechanisms at play to support a high quality of experience for
mobile users. In this paper, we present the first study that evaluates the
relationships of mobile movie quality and the viewer-perceived quality thereof
in an augmented reality setting with see-through devices. We find that
participants tend to overestimate the video quality and exhibit a significant
variation of accuracy that leans onto the movie content and its dynamics. Our
findings, thus, can broadly impact future media adaptation and delivery
mechanisms for this new display format of mobile multimedia.
"
638,"Perceptual Quality of Video with Periodic Frame Rate and Quantization
  Variation-Subjective Studies and Analytical Modeling","  In networked video applications, the frame rate (FR) and quantization
stepsize (QS) of a compressed video are often adapted in response to the
changes of the available bandwidth. It is important to understand how do the
variation of FR and QS and their variation pattern affect the video quality. In
this paper, we investigate the impact of temporal variation of FR and QS on the
perceptual video quality. Among all possible variation patterns, we focus on
videos in which two FR's (or QS's) alternate over a fixed interval. We explore
the human responses to such variation by conducting subjective evaluation of
test videos with different variation magnitudes and frequencies. We further
analyze statistical significance of the impact of variation magnitude,
variation frequency, video content, and their interactions. By analyzing the
subjective ratings, we propose two models for predicting the quality of video
with alternating FR and QS, respectively, The proposed models have simple
mathematical forms with a few content-dependent parameters. The models fit the
measured data very well using parameters determined by least square fitting
with the measured data. We further propose some guidelines for adaptation of FR
and QS based on trends observed from subjective test results.
"
639,On Importance of Steganographic Cost For Network Steganography,"  Network steganography encompasses the information hiding techniques that can
be applied in communication network environments and that utilize hidden data
carriers for this purpose. In this paper we introduce a characteristic called
steganographic cost which is an indicator for the degradation or distortion of
the carrier caused by the application of the steganographic method. Based on
exemplary cases for single- and multi-method steganographic cost analyses we
observe that it can be an important characteristic that allows to express
hidden data carrier degradation - similarly as MSE (Mean-Square Error) or PSNR
(Peak Signal-to-Noise Ratio) are utilized for digital media steganography.
Steganographic cost can moreover be helpful to analyse the relationships
between two or more steganographic methods applied to the same hidden data
carrier.
"
640,real-time audio translation module between iax and rsw,"  At the last few years, multimedia communication has been developed and
improved rapidly in order to enable users to communicate between each other
over the internet. Generally, multimedia communication consists of audio and
video communication. However, this research concentrates on audio conferencing
only. The audio translation between protocols is a very critical issue, because
it solves the communication problems between any two protocols. So, it enables
people around the world to talk with each other even they use different
protocols. In this research, a real time audio translation module between two
protocols has been done. These two protocols are: InterAsterisk eXchange
Protocol (IAX) and Real-Time Switching Control Protocol (RSW), which they are
widely used to provide two ways audio transfer feature. The solution here is to
provide inter-working between the two protocols which they have different media
transports, audio codecs, header formats and different transport protocols for
the audio transmission. This translation will help bridging the gap between the
two protocols by providing inter-working capability between the two audio
streams of IAX and RSW. Some related works have been done to provide
translation between IAX and RSW control signalling messages. But, this research
paper concentrates on the translation that depends on the media transfer. The
proposed translation module was tested and evaluated in different scenarios in
order to examine its performance. The obtained results showed that the
Real-Time Audio Translation Module produces lower rates of packet delay and
jitter than the acceptance values for each of the mentioned performance
metrics.
"
641,Low-cost Augmented Reality prototype for controlling network devices,"  With the evolution of mobile devices, and smart-phones in particular, comes
the ability to create new experiences that enhance the way we see, interact,
and manipulate objects, within the world that surrounds us. It is now possible
to blend data from our senses and our devices in numerous ways that simply were
not possible before using Augmented Reality technology. In a near future, when
all of the office devices as well as your personal electronic gadgets are on a
common wireless network, operating them using a universal remote controller
would be possible. This paper presents an off-the-shelf, low-cost prototype
that leverages the Augmented Reality technology to deliver a novel and
interactive way of operating office network devices around using a mobile
device. We believe this type of system may provide benefits to controlling
multiple integrated devices and visualizing interconnectivity or utilizing
visual elements to pass information from one device to another, or may be
especially beneficial to control devices when interacting with them physically
may be difficult or pose danger or harm.
"
642,Optimized Adaptive Streaming Representations based on System Dynamics,"  Adaptive streaming addresses the increasing and heterogenous demand of
multimedia content over the Internet by offering several encoded versions for
each video sequence. Each version (or representation) has a different
resolution and bit rate, aimed at a specific set of users, like TV or mobile
phone clients. While most existing works on adaptive streaming deal with
effective playout-control strategies at the client side, we take in this paper
a providers' perspective and propose solutions to improve user satisfaction by
optimizing the encoding rates of the video sequences. We formulate an integer
linear program that maximizes users' average satisfaction, taking into account
the network dynamics, the video content information, and the user population
characteristics. The solution of the optimization is a set of encoding
parameters that permit to create different streams to robustly satisfy users'
requests over time. We simulate multiple adaptive streaming sessions
characterized by realistic network connections models, where the proposed
solution outperforms commonly used vendor recommendations, in terms of user
satisfaction but also in terms of fairness and outage probability. The
simulation results further show that video content information as well as
network constraints and users' statistics play a crucial role in selecting
proper encoding parameters to provide fairness a mong users and to reduce
network resource usage. We finally propose a few practical guidelines that can
be used to choose the encoding parameters based on the user base
characteristics, the network capacity and the type of video content.
"
643,A Bengali HMM Based Speech Synthesis System,"  The paper presents the capability of an HMM-based TTS system to produce
Bengali speech. In this synthesis method, trajectories of speech parameters are
generated from the trained Hidden Markov Models. A final speech waveform is
synthesized from those speech parameters. In our experiments, spectral
properties were represented by Mel Cepstrum Coefficients. Both the training and
synthesis issues are investigated in this paper using annotated Bengali speech
database. Experimental evaluation depicts that the developed text-to-speech
system is capable of producing adequately natural speech in terms of
intelligibility and intonation for Bengali.
"
644,"3DTouch: A wearable 3D input device with an optical sensor and a 9-DOF
  inertial measurement unit","  We present 3DTouch, a novel 3D wearable input device worn on the fingertip
for 3D manipulation tasks. 3DTouch is designed to fill the missing gap of a 3D
input device that is self-contained, mobile, and universally working across
various 3D platforms. This paper presents a low-cost solution to designing and
implementing such a device. Our approach relies on relative positioning
technique using an optical laser sensor and a 9-DOF inertial measurement unit.
  3DTouch is self-contained, and designed to universally work on various 3D
platforms. The device employs touch input for the benefits of passive haptic
feedback, and movement stability. On the other hand, with touch interaction,
3DTouch is conceptually less fatiguing to use over many hours than 3D spatial
input devices. We propose a set of 3D interaction techniques including
selection, translation, and rotation using 3DTouch. An evaluation also
demonstrates the device's tracking accuracy of 1.10 mm and 2.33 degrees for
subtle touch interaction in 3D space. Modular solutions like 3DTouch opens up a
whole new design space for interaction techniques to further develop on.
"
645,Designing Sound Collaboratively - Perceptually Motivated Audio Synthesis,"  In this contribution, we will discuss a prototype that allows a group of
users to design sound collaboratively in real time using a multi-touch
tabletop. We make use of a machine learning method to generate a mapping from
perceptual audio features to synthesis parameters. This mapping is then used
for visualization and interaction. Finally, we discuss the results of a
comparative evaluation study.
"
646,"Performance Comparison of Linear Prediction based Vocoders in Linux
  Platform","  Linear predictive coders form an important class of speech coders. This paper
describes the software level implementation of linear prediction based
vocoders, viz. Code Excited Linear Prediction (CELP), Low-Delay CELP (LD-CELP)
and Mixed Excitation Linear Prediction (MELP) at bit rates of 4.8 kb/s, 16 kb/s
and 2.4 kb/s respectively. The C programs of the vocoders have been compiled
and executed in Linux platform. Subjective testing with the help of Mean
Opinion Score test has been performed. Waveform analysis has been done using
Praat and Adobe Audition software. The results show that MELP and CELP produce
comparable quality while the quality of LD-CELP coder is much higher, at the
expense of higher bit rate.
"
647,MSPlayer: Multi-Source and multi-Path LeverAged YoutubER,"  Online video streaming through mobile devices has become extremely popular
nowadays. YouTube, for example, reported that the percentage of its traffic
streaming to mobile devices has soared from 6% to more than 40% over the past
two years. Moreover, people are constantly seeking to stream high quality video
for better experience while often suffering from limited bandwidth. Thanks to
the rapid deployment of content delivery networks (CDNs), popular videos are
now replicated at different sites, and users can stream videos from close-by
locations with low latencies. As mobile devices nowadays are equipped with
multiple wireless interfaces (e.g., WiFi and 3G/4G), aggregating bandwidth for
high definition video streaming has become possible.
  We propose a client-based video streaming solution, MSPlayer, that takes
advantage of multiple video sources as well as multiple network paths through
different interfaces. MSPlayer reduces start-up latency and provides high
quality video streaming and robust data transport in mobile scenarios. We
experimentally demonstrate our solution on a testbed and through the YouTube
video service.
"
648,Securing Medical Images by Watermarking Using DWT DCT and SVD,"  Telemedicine is well known application where enormous amount of medical data
need to be transferred securely over network and manipulate effectively.
Security of digital data, especially medical images, becomes important for many
reasons such as confidentiality, authentication and integrity. Digital
watermarking has emerged as a advanced technology to enhance the security of
digital images. The insertion of watermark in medical images can authenticate
it and guarantee its integrity. The watermark must be generally hidden does not
affect the quality of the medical image. In this paper, we propose blind
watermarking based on Discrete Wavelet Transform (DWT), Discrete Cosine
Transform (DCT) and Singular Value Decomposition (SVD), we compare the
performance of this technique with watermarking based DWT and SVD. The proposed
method DWT, DCT and SVD comparatively better than DWT and SVD method.
"
649,Subjective and Objective Quality Assessment of Image: A Survey,"  With the increasing demand for image-based applications, the efficient and
reliable evaluation of image quality has increased in importance. Measuring the
image quality is of fundamental importance for numerous image processing
applications, where the goal of image quality assessment (IQA) methods is to
automatically evaluate the quality of images in agreement with human quality
judgments. Numerous IQA methods have been proposed over the past years to
fulfill this goal. In this paper, a survey of the quality assessment methods
for conventional image signals, as well as the newly emerged ones, which
includes the high dynamic range (HDR) and 3-D images, is presented. A
comprehensive explanation of the subjective and objective IQA and their
classification is provided. Six widely used subjective quality datasets, and
performance measures are reviewed. Emphasis is given to the full-reference
image quality assessment (FR-IQA) methods, and 9 often-used quality measures
(including mean squared error (MSE), structural similarity index (SSIM),
multi-scale structural similarity index (MS-SSIM), visual information fidelity
(VIF), most apparent distortion (MAD), feature similarity measure (FSIM),
feature similarity measure for color images (FSIMC), dynamic range independent
measure (DRIM), and tone-mapped images quality index (TMQI)) are carefully
described, and their performance and computation time on four subjective
quality datasets are evaluated. Furthermore, a brief introduction to 3-D IQA is
provided and the issues related to this area of research are reviewed.
"
650,A Data-Driven Approach for Tag Refinement and Localization in Web Videos,"  Tagging of visual content is becoming more and more widespread as web-based
services and social networks have popularized tagging functionalities among
their users. These user-generated tags are used to ease browsing and
exploration of media collections, e.g. using tag clouds, or to retrieve
multimedia content. However, not all media are equally tagged by users. Using
the current systems is easy to tag a single photo, and even tagging a part of a
photo, like a face, has become common in sites like Flickr and Facebook. On the
other hand, tagging a video sequence is more complicated and time consuming, so
that users just tag the overall content of a video. In this paper we present a
method for automatic video annotation that increases the number of tags
originally provided by users, and localizes them temporally, associating tags
to keyframes. Our approach exploits collective knowledge embedded in
user-generated tags and web sources, and visual similarity of keyframes and
images uploaded to social sites like YouTube and Flickr, as well as web sources
like Google and Bing. Given a keyframe, our method is able to select on the fly
from these visual sources the training exemplars that should be the most
relevant for this test sample, and proceeds to transfer labels across similar
images. Compared to existing video tagging approaches that require training
classifiers for each tag, our system has few parameters, is easy to implement
and can deal with an open vocabulary scenario. We demonstrate the approach on
tag refinement and localization on DUT-WEBV, a large dataset of web videos, and
show state-of-the-art results.
"
651,Sonic interaction with a virtual orchestra of factory machinery,"  This paper presents an immersive application where users receive sound and
visual feedbacks on their interactions with a virtual environment. In this
application, the users play the part of conductors of an orchestra of factory
machines since each of their actions on interaction devices triggers a pair of
visual and audio responses. Audio stimuli were spatialized around the listener.
The application was exhibited during the 2013 Science and Music day and
designed to be used in a large immersive system with head tracking, shutter
glasses and a 10.2 loudspeaker configuration.
"
652,Genetic Algorithm in Audio Steganography,"  With the advancement of communication technology,data is exchanged digitally
over the network. At the other side the technology is also proven as a tool for
unauthorized access to attackers. Thus the security of data to be transmitted
digitally should get prime focus. Data hiding is the common approach to secure
data. In steganography technique, the existence of data is concealed. GA is an
emerging component of AI to provide suboptimal solutions. In this paper the use
of GA in Steganography is explored to find future scope of research.
"
653,"Numerical investigation of lensless zoomable holographic multiple
  projections to tilted planes","  This paper numerically investigates the feasibility of lensless zoomable
holographic multiple projections to tilted planes. We have already developed
lensless zoomable holographic single projection using scaled diffraction, which
calculates diffraction between parallel planes with different sampling pitches.
The structure of this zoomable holographic projection is very simple because it
does not need a lens; however, it only projects a single image to a plane
parallel to the hologram. The lensless zoomable holographic projection in this
paper is capable of projecting multiple images onto tilted planes
simultaneously.
"
654,A Survey of Digital Watermarking Techniques and its Applications,"  Digital media is the need of a people now a day as the alternate of paper
media.As the technology grown up digital media required protection while
transferring through internet or others mediums.Watermarking techniques have
been developed to fulfill this requirement.This paper aims to provide a
detailed survey of all watermarking techniques specially focuses on image
watermarking types and its applications in today world.
"
655,"Analysis of Attacks on Hybrid DWT-DCT Algorithm for Digital Image
  Watermarking With MATLAB","  Watermarking algorithms needs properties of robustness and perceptibility.
But these properties are affected by different -2 types of attacks performed on
watermarked images. The goal of performing attacks is destroy the information
of watermark hidden in the watermarked image. So every Algorithms should be
previously tested by developers so that it would not affected by attacks.
"
656,Robust Lossless Semi Fragile Information Protection in Images,"  Internet security finds it difficult to keep the information secure and to
maintain the integrity of the data. Sending messages over the internet secretly
is one of the major tasks as it is widely used for passing the message.
"
657,Speaker-following Video Subtitles,"  We propose a new method for improving the presentation of subtitles in video
(e.g. TV and movies). With conventional subtitles, the viewer has to constantly
look away from the main viewing area to read the subtitles at the bottom of the
screen, which disrupts the viewing experience and causes unnecessary eyestrain.
Our method places on-screen subtitles next to the respective speakers to allow
the viewer to follow the visual content while simultaneously reading the
subtitles. We use novel identification algorithms to detect the speakers based
on audio and visual information. Then the placement of the subtitles is
determined using global optimization. A comprehensive usability study indicated
that our subtitle placement method outperformed both conventional
fixed-position subtitling and another previous dynamic subtitling method in
terms of enhancing the overall viewing experience and reducing eyestrain.
"
658,"Quality of Experience (QoE) beyond Quality of Service (QoS) as its
  baseline: QoE at the Interface of Experience Domains","  In this work, a new approach to the definition of the quality of experience
is presented. By considering the quality of service as a baseline, that portion
of the QoE that can be inferred from the QoS is excluded, and then the rest of
the QoE is approached with the notion of QoE at a Boundary (QoEaaB). With the
QoEaaB as the core of the proposed approach, various potential boundaries, and
their associated unseen opportunities to improve the QoE are discussed. In
particular, property, contract, SLA, and content are explored in terms of their
boundaries and also their associated QoEaaB. With an interest in online video
delivery, management of resource sharing and isolation associated with
multi-tenant operations is considered. It is concluded that the proposed QoEaaB
can bring a new perspective in QoE modeling and assessment toward a more
enriched approach to improving the experience based on innovation and deep
connectivity among actors.
"
659,"An Easy yet Effective Method for Detecting Spatial Domain LSB
  Steganography","  Digitization of image was a revolutionary step for the fields of photography
and Image processing as this made the editing of images much effortless and
easier. Image editing was not an issue until it was limited to corrective
editing procedures used to enhance the quality of an image such as, contrast
stretching, noise filtering, sharpening etc. But, it became a headache for many
fields when image editing became manipulative. Digital images have become an
easier source of tampering and forgery during last few decades. Today users and
editing specialists, equipped with easily available image editing software,
manipulate digital images with varied goals. Photo journalists often tamper
photographs to give dramatic effect to their stories. Scientists and
researchers use this trick to get theirs works published. Patients' diagnoses
are misrepresented by manipulating medical imageries. Lawyers and Politicians
use tampered images to direct the opinion of people or court to their favor.
Terrorists, anti-social groups use manipulated Stego images for secret
communication. In this paper we present an effective method for detecting
spatial domain Steganography.
"
660,Detection of Clones in Digital Images,"  During the recent years, tampering of digital images has become a general
habit among people and professionals. As a result, establishment of image
authenticity has become a key issue in fields those make use of digital images.
Authentication of an image involves separation of original camera outputs from
their tampered or Stego counterparts. Digital image cloning being a popular
type of image tampering, in this paper we have experimentally analyzed seven
different algorithms of cloning detection such as the simple overlapped block
matching with lexicographic sorting (SOBMwLS) algorithm, block matching with
discrete cosine transformation, principal component analysis, discrete wavelet
transformation and singular value decomposition performed on the blocks (DCT,
DWT, PCA, SVD), two combination models where, DCT and DWT are combined with
singular value decomposition (DCTSVD and DWTSVD. A comparative study of all
these techniques with respect to their time complexities and robustness of
detection against various post processing operations such as cropping,
brightness and contrast adjustments are presented in the paper.
"
661,When Augmented Reality Meets Big Data,"  With computing and sensing woven into the fabric of everyday life, we live in
an era where we are awash in a flood of data from which we can gain rich
insights. Augmented reality (AR) is able to collect and help analyze the
growing torrent of data about user engagement metrics within our personal
mobile and wearable devices. This enables us to blend information from our
senses and the digitalized world in a myriad of ways that was not possible
before. AR and big data have a logical maturity that inevitably converge them.
The tread of harnessing AR and big data to breed new interesting applications
is starting to have a tangible presence. In this paper, we explore the
potential to capture value from the marriage between AR and big data
technologies, following with several challenges that must be addressed to fully
realize this potential.
"
662,"A Digital Watermarking Approach Based on DCT Domain Combining QR Code
  and Chaotic Theory","  This paper proposes a robust watermarking approach based on Discrete Cosine
Transform domain that combines Quick Response Code and chaotic system.
"
663,Fast Adaptive Algorithm for Robust Evaluation of Quality of Experience,"  Outlier detection is an integral part of robust evaluation for
crowdsourceable Quality of Experience (QoE) and has attracted much attention in
recent years. In QoE for multimedia, outliers happen because of different test
conditions, human errors, abnormal variations in context, {etc}. In this paper,
we propose a simple yet effective algorithm for outlier detection and robust
QoE evaluation named iterative Least Trimmed Squares (iLTS). The algorithm
assigns binary weights to samples, i.e., 0 or 1 indicating if a sample is an
outlier, then the outlier-trimmed subset least squares solutions give robust
ranking scores. An iterative optimization is carried alternatively between
updating weights and ranking scores which converges to a local optimizer in
finite steps. In our test setting, iLTS is up to 190 times faster than
LASSO-based methods with a comparable performance. Moreover, a varied version
of this method shows adaptation in outlier detection, which provides an
automatic detection to determine whether a data sample is an outlier without
\emph{a priori} knowledge about the amount of the outliers. The effectiveness
and efficiency of iLTS are demonstrated on both simulated examples and
real-world applications. A Matlab package is provided to researchers exploiting
crowdsourcing paired comparison data for robust ranking.
"
664,"Impact of video quality and wireless network interface on power
  consumption of mobile devices","  During the last years, many improvements were made to the hardware capability
of mobile devices. As mobile software also became more interactive and data
processing intensive, the increased power demand could not be compensated by
the improvements on battery technology. Adaptive systems can help to balance
the demand of applications with the limitations of battery resources. For
effective systems, the influence of multimedia quality on power consumption of
the components of mobile devices needs to be better understood. In this paper,
we analyze the impact of video quality and wireless network type on the energy
consumption of a mobile device. We have found that the additional power
consumption is up to 38% higher when a movie is played over a WiFi network
instead from internal memory and 64% higher in case of a mobile network (3G).
We have also discovered that a higher movie quality not only affects the power
consumption of the CPU but also the power consumption of the WiFi unit by up to
58% and up to 72% respectively on mobile networks.
"
665,"ITEM: Immersive Telepresence for Entertainment and Meetings - A
  Practical Approach","  This paper presents an Immersive Telepresence system for Entertainment and
Meetings (ITEM). The system aims to provide a radically new video communication
experience by seamlessly merging participants into the same virtual space to
allow a natural interaction among them and shared collaborative contents. With
the goal to make a scalable, flexible system for various business solutions as
well as easily accessible by massive consumers, we address the challenges in
the whole pipeline of media processing, communication, and displaying in our
design and realization of such a system. Particularly, in this paper we focus
on the system aspects that maximize the end-user experience, optimize the
system and network resources, and enable various teleimmersive application
scenarios. In addition, we also present a few key technologies, i.e. fast
object-based video coding for real world data and spatialized audio capture and
3D sound localization for group teleconferencing. Our effort is to investigate
and optimize the key system components and provide an efficient end-to-end
optimization and integration by considering user needs and preferences.
Extensive experiments show the developed system runs reliably and comfortably
in real time with a minimal setup requirement (e.g. a webcam and/or a depth
camera, an optional microphone array, a laptop/desktop connected to the public
Internet) for teleimmersive communication. With such a really minimal
deployment requirement, we present a variety of interesting applications and
user experiences created by ITEM.
"
666,Bags of Affine Subspaces for Robust Object Tracking,"  We propose an adaptive tracking algorithm where the object is modelled as a
continuously updated bag of affine subspaces, with each subspace constructed
from the object's appearance over several consecutive frames. In contrast to
linear subspaces, affine subspaces explicitly model the origin of subspaces.
Furthermore, instead of using a brittle point-to-subspace distance during the
search for the object in a new frame, we propose to use a subspace-to-subspace
distance by representing candidate image areas also as affine subspaces.
Distances between subspaces are then obtained by exploiting the non-Euclidean
geometry of Grassmann manifolds. Experiments on challenging videos (containing
object occlusions, deformations, as well as variations in pose and
illumination) indicate that the proposed method achieves higher tracking
accuracy than several recent discriminative trackers.
"
667,Video Face Editing Using Temporal-Spatial-Smooth Warping,"  Editing faces in videos is a popular yet challenging aspect of computer
vision and graphics, which encompasses several applications including facial
attractiveness enhancement, makeup transfer, face replacement, and expression
manipulation. Simply applying image-based warping algorithms to video-based
face editing produces temporal incoherence in the synthesized videos because it
is impossible to consistently localize facial features in two frames
representing two different faces in two different videos (or even two
consecutive frames representing the same face in one video). Therefore, high
performance face editing usually requires significant manual manipulation. In
this paper we propose a novel temporal-spatial-smooth warping (TSSW) algorithm
to effectively exploit the temporal information in two consecutive frames, as
well as the spatial smoothness within each frame. TSSW precisely estimates two
control lattices in the horizontal and vertical directions respectively from
the corresponding control lattices in the previous frame, by minimizing a novel
energy function that unifies a data-driven term, a smoothness term, and feature
point constraints. Corresponding warping surfaces then precisely map source
frames to the target frames. Experimental testing on facial attractiveness
enhancement, makeup transfer, face replacement, and expression manipulation
demonstrates that the proposed approaches can effectively preserve spatial
smoothness and temporal coherence in editing facial geometry, skin detail,
identity, and expression, which outperform the existing face editing methods.
In particular, TSSW is robust to subtly inaccurate localization of feature
points and is a vast improvement over image-based warping methods.
"
668,"Co-Localization of Audio Sources in Images Using Binaural Features and
  Locally-Linear Regression","  This paper addresses the problem of localizing audio sources using binaural
measurements. We propose a supervised formulation that simultaneously localizes
multiple sources at different locations. The approach is intrinsically
efficient because, contrary to prior work, it relies neither on source
separation, nor on monaural segregation. The method starts with a training
stage that establishes a locally-linear Gaussian regression model between the
directional coordinates of all the sources and the auditory features extracted
from binaural measurements. While fixed-length wide-spectrum sounds (white
noise) are used for training to reliably estimate the model parameters, we show
that the testing (localization) can be extended to variable-length
sparse-spectrum sounds (such as speech), thus enabling a wide range of
realistic applications. Indeed, we demonstrate that the method can be used for
audio-visual fusion, namely to map speech signals onto images and hence to
spatially align the audio and visual modalities, thus enabling to discriminate
between speaking and non-speaking faces. We release a novel corpus of real-room
recordings that allow quantitative evaluation of the co-localization method in
the presence of one or two sound sources. Experiments demonstrate increased
accuracy and speed relative to several state-of-the-art methods.
"
669,Entropy Conserving Binarization Scheme for Video and Image Compression,"  The paper presents a binarization scheme that converts non-binary data into a
set of binary strings. At present, there are many binarization algorithms, but
they are optimal for only specific probability distributions of the data
source. Overcoming the problem, it is shown in this paper that the presented
binarization scheme conserves the entropy of the original data having any
probability distribution of $m$-ary source. The major advantages of this scheme
are that it conserves entropy without the knowledge of the source and the
probability distribution of the source symbols. The scheme has linear
complexity in terms of the length of the input data. The binarization scheme
can be implemented in Context-based Adaptive Binary Arithmetic Coding (CABAC)
for video and image compression. It can also be utilized by various universal
data compression algorithms that have high complexity in compressing non-binary
data, and by binary data compression algorithms to optimally compress
non-binary data.
"
670,Digital Image Data Hiding Techniques: A Comparative Study,"  With the advancements in the field of digital image processing during the
last decade, digital image data hiding techniques such as watermarking,
Steganography have gained wide popularity. Digital image watermarking
techniques hide a small amount of data into a digital image which, later can be
retrieved using some specific retrieval algorithms to prove the copyright of a
piece of digital information whereas, Steganographic techniques are used to
hide a large amount of data secretly into some innocuous looking digital
medium. In this paper we are providing an up-to-date review of these data
hiding techniques.
"
671,High Security Image Steganography with Modified Arnold cat map,"  Information security is concerned with maintaining the secrecy, reliability
and accessibility of data. The main objective of information security is to
protect information and information system from unauthorized access,
revelation, disruption, alteration, annihilation and use. This paper uses
spatial domain LSB substitution method for information embedding and modified
forms of Arnold transform are applied twice in two different phases to ensure
security. The system is tested and validated against a series of standard
images and the results show that the method is highly secure and provides high
data hiding capacity.
"
672,Object Segmentation in Images using EEG Signals,"  This paper explores the potential of brain-computer interfaces in segmenting
objects from images. Our approach is centered around designing an effective
method for displaying the image parts to the users such that they generate
measurable brain reactions. When an image region, specifically a block of
pixels, is displayed we estimate the probability of the block containing the
object of interest using a score based on EEG activity. After several such
blocks are displayed, the resulting probability map is binarized and combined
with the GrabCut algorithm to segment the image into object and background
regions. This study shows that BCI and simple EEG analysis are useful in
locating object boundaries in images.
"
673,Characterizing Internet Video for Large-scale Active Measurements,"  The availability of high definition video content on the web has brought
about a significant change in the characteristics of Internet video, but not
many studies on characterizing video have been done after this change. Video
characteristics such as video length, format, target bit rate, and resolution
provide valuable input to design Adaptive Bit Rate (ABR) algorithms, sizing
playout buffers in Dynamic Adaptive HTTP streaming (DASH) players, model the
variability in video frame sizes, etc. This paper presents datasets collected
in 2013 and 2014 that contains over 130,000 videos from YouTube's most viewed
(or most popular) video charts in 58 countries. We describe the basic
characteristics of the videos on YouTube for each category, format, video
length, file size, and data rate variation, observing that video length and
file size fit a log normal distribution. We show that three minutes of a video
suffice to represent its instant data rate fluctuation and that we can infer
data rate characteristics of different video resolutions from a single given
one. Based on our findings, we design active measurements for measuring the
performance of Internet video.
"
674,Fast Disk Conformal Parameterization of Simply-connected Open Surfaces,"  Surface parameterizations have been widely used in computer graphics and
geometry processing. In particular, as simply-connected open surfaces are
conformally equivalent to the unit disk, it is desirable to compute the disk
conformal parameterizations of the surfaces. In this paper, we propose a novel
algorithm for the conformal parameterization of a simply-connected open surface
onto the unit disk, which significantly speeds up the computation, enhances the
conformality and stability, and guarantees the bijectivity. The conformality
distortions at the inner region and on the boundary are corrected by two steps,
with the aid of an iterative scheme using quasi-conformal theories.
Experimental results demonstrate the effectiveness of our proposed method.
"
675,Image Retrieval And Classification Using Local Feature Vectors,"  Content Based Image Retrieval(CBIR) is one of the important subfield in the
field of Information Retrieval. The goal of a CBIR algorithm is to retrieve
semantically similar images in response to a query image submitted by the end
user. CBIR is a hard problem because of the phenomenon known as $\textit
{semantic gap}$.
  In this thesis, we aim at analyzing the performance of a CBIR system build
using local feature vectors and Intermediate Matching Kernel. We also propose a
Two-Step Matching process for reducing the response time of the CBIR systems.
Further, we develop a Meta-Learning framework for improving the retrieval
performance of these systems. Our results show that the Two-Step Matching
process significantly reduces response time and the Meta-Learning Framework
improves the retrieval performance by more than two fold. We also analyze the
performance of various image classification systems that use different image
representations constructed from the local feature vectors.
"
676,An Approach for Text Steganography Based on Markov Chains,"  A text steganography method based on Markov chains is introduced, together
with a reference implementation. This method allows for information hiding in
texts that are automatically generated following a given Markov model. Other
Markov - based systems of this kind rely on big simplifications of the language
model to work, which produces less natural looking and more easily detectable
texts. The method described here is designed to generate texts within a good
approximation of the original language model provided.
"
677,Physical Light as a Metaphor for Inner Light,"  The metaphor between physical light and inner light has a long history that
permeates diverse languages and cultures. This paper outlines a system for
using basic principles from optics to visually represent psychological states
and processes such as ideation, enlightenment, mindfulness, and fragmentation
versus integrity, as well as situations that occur between people involving
phenomena such as honest versus deceptive communication, and understanding
versus misunderstanding. The paper summarizes two ongoing projects based on
this system: The Light and Enlightenment art installation project, and the
Soultracker virtual reality project. These projects enable people to depict
their inner lives and external worlds including situations and relationships
with others, both as they are and as they could be, and explore alternative
paths for navigating challenges and living to their fullest potential. The
projects aim to be of clinical value as therapeutic tools, as well as of
pedagogical value by providing a concrete language for depicting aspects of
human nature that can otherwise seem elusive and intangible.
"
678,Toward Green Media Delivery: Location-Aware Opportunities and Approaches,"  Mobile media has undoubtedly become the predominant source of traffic in
wireless networks. The result is not only congestion and poor
Quality-of-Experience, but also an unprecedented energy drain at both the
network and user devices. In order to sustain this continued growth, novel
disruptive paradigms of media delivery are urgently needed. We envision that
two key contemporary advancements can be leveraged to develop greener media
delivery platforms: 1) the proliferation of navigation hardware and software in
mobile devices has created an era of location-awareness, where both the current
and future user locations can be predicted; and 2) the rise of context-aware
network architectures and self-organizing functionalities is enabling context
signaling and in-network adaptation. With these developments in mind, this
article investigates the opportunities of exploiting location-awareness to
enable green end-to-end media delivery. In particular, we discuss and propose
approaches for location-based adaptive video quality planning, in-network
caching, content prefetching, and long-term radio resource management. To
provide insights on the energy savings, we then present a cross-layer framework
that jointly optimizes resource allocation and multi-user video quality using
location predictions. Finally, we highlight some of the future research
directions for location-aware media delivery in the conclusion.
"
679,"A Crowdsourcing Procedure for the Discovery of Non-Obvious Attributes of
  Social Image","  Research on mid-level image representations has conventionally concentrated
relatively obvious attributes and overlooked non-obvious attributes, i.e.,
characteristics that are not readily observable when images are viewed
independently of their context or function. Non-obvious attributes are not
necessarily easily nameable, but nonetheless they play a systematic role in
people`s interpretation of images. Clusters of related non-obvious attributes,
called interpretation dimensions, emerge when people are asked to compare
images, and provide important insight on aspects of social images that are
considered relevant. In contrast to aesthetic or affective approaches to image
analysis, non-obvious attributes are not related to the personal perspective of
the viewer. Instead, they encode a conventional understanding of the world,
which is tacit, rather than explicitly expressed. This paper introduces a
procedure for discovering non-obvious attributes using crowdsourcing. We
discuss this procedure using a concrete example of a crowdsourcing task on
Amazon Mechanical Turk carried out in the domain of fashion. An analysis
comparing discovered non-obvious attributes with user tags demonstrated the
added value delivered by our procedure.
"
680,"A new Watermarking Technique for Medical Image using Hierarchical
  Encryption","  In recent years, characterized by the innovation of technology and the
digital revolution, the field of media has become important. The transfer and
exchange of multimedia data and duplication have become major concerns of
researchers. Consequently, protecting copyrights and ensuring service safety is
needed. Cryptography has a specific role, is to protect secret files against
unauthorized access. In this paper, a hierarchical cryptosystem algorithm based
on Logistic Map chaotic systems is proposed. The results show that the proposed
method improves the security of the image. Experimental results on a database
of 200 medical images show that the proposed method significantly gives better
results.
"
681,Developing a Video Steganography Toolkit,"  Although techniques for separate image and audio steganography are widely
known, relatively little has been described concerning the hiding of
information within video streams (""video steganography""). In this paper we
review the current state of the art in this field, and describe the key issues
we have encountered in developing a practical video steganography system. A
supporting video is also available online at
http://www.youtube.com/watch?v=YhnlHmZolRM
"
682,Audio Surveillance: a Systematic Review,"  Despite surveillance systems are becoming increasingly ubiquitous in our
living environment, automated surveillance, currently based on video sensory
modality and machine intelligence, lacks most of the time the robustness and
reliability required in several real applications. To tackle this issue, audio
sensory devices have been taken into account, both alone or in combination with
video, giving birth, in the last decade, to a considerable amount of research.
In this paper audio-based automated surveillance methods are organized into a
comprehensive survey: a general taxonomy, inspired by the more widespread video
surveillance field, is proposed in order to systematically describe the methods
covering background subtraction, event classification, object tracking and
situation analysis. For each of these tasks, all the significant works are
reviewed, detailing their pros and cons and the context for which they have
been proposed. Moreover, a specific section is devoted to audio features,
discussing their expressiveness and their employment in the above described
tasks. Differently, from other surveys on audio processing and analysis, the
present one is specifically targeted to automated surveillance, highlighting
the target applications of each described methods and providing the reader
tables and schemes useful to retrieve the most suited algorithms for a specific
requirement.
"
683,"Adaptive Prioritized Random Linear Coding and Scheduling for Layered
  Data Delivery from Multiple Servers","  In this paper, we deal with the problem of jointly determining the optimal
coding strategy and the scheduling decisions when receivers obtain layered data
from multiple servers. The layered data is encoded by means of Prioritized
Random Linear Coding (PRLC) in order to be resilient to channel loss while
respecting the unequal levels of importance in the data, and data blocks are
transmitted simultaneously in order to reduce decoding delays and improve the
delivery performance. We formulate the optimal coding and scheduling decisions
problem in our novel framework with the help of Markov Decision Processes
(MDP), which are effective tools for modeling adapting streaming systems.
Reinforcement learning approaches are then proposed to derive reduced
computational complexity solutions to the adaptive coding and scheduling
problems. The novel reinforcement learning approaches and the MDP solution are
examined in an illustrative example for scalable video transmission. Our
methods offer large performance gains over competing methods that deliver the
data blocks sequentially. The experimental evaluation also shows that our novel
algorithms offer continuous playback and guarantee small quality variations
which is not the case for baseline solutions. Finally, our work highlights the
advantages of reinforcement learning algorithms to forecast the temporal
evolution of data demands and to decide the optimal coding and scheduling
decisions.
"
684,"An adaptive quasi harmonic broadcasting scheme with optimal bandwidth
  requirement","  The aim of Harmonic Broadcasting protocol is to reduce the bandwidth usage in
video-on-demand service where a video is divided into some equal sized segments
and every segment is repeatedly transmitted over a number of channels that
follows harmonic series for channel bandwidth assignment. As the bandwidth of
channels differs from each other and users can join at any time to these
multicast channels, they may experience a synchronization problem between
download and playback. To deal with this issue, some schemes have been
proposed, however, at the cost of additional or wastage of bandwidth or sudden
extreme bandwidth requirement. In this paper we present an adaptive quasi
harmonic broadcasting scheme (AQHB) which delivers all data segment on time
that is the download and playback synchronization problem is eliminated while
keeping the bandwidth consumption as same as traditional harmonic broadcasting
scheme without cost of any additional or wastage of bandwidth. It also ensures
the video server not to increase the channel bandwidth suddenly that is, also
eliminates the sudden buffer requirement at the client side. We present several
analytical results to exhibit the efficiency of our proposed broadcasting
scheme over the existing ones.
"
685,A New Method for Estimating the Widths of JPEG Images,"  Image width is important for image understanding. We propose a novel method
to estimate widths for JPEG images when their widths are not available. The key
idea is that the distance between two decoded MCUs (Minimum Coded Unit)
adjacent in the vertical direction is usually small, which is measured by the
average Euclidean distance between the pixels from the bottom row of the top
MCU and the top row of the bottom MCU. On PASCAL VOC 2010 challenge dataset and
USC-SIPI image database, experimental results show the high performance of the
proposed approach.
"
686,Image compression overview,"  Compression plays a significant role in a data storage and a transmission. If
we speak about a generall data compression, it has to be a lossless one. It
means, we are able to recover the original data 1:1 from the compressed file.
Multimedia data (images, video, sound...), are a special case. In this area, we
can use something called a lossy compression. Our main goal is not to recover
data 1:1, but only keep them visually similar. This article is about an image
compression, so we will be interested only in image compression. For a human
eye, it is not a huge difference, if we recover RGB color with values
[150,140,138] instead of original [151,140,137]. The magnitude of a difference
determines the loss rate of the compression. The bigger difference usually
means a smaller file, but also worse image quality and noticable differences
from the original image. We want to cover compression techniques mainly from
the last decade. Many of them are variations of existing ones, only some of
them uses new principes.
"
687,"Recommendation Scheme Based on Converging Properties for Contents
  Broadcasting","  Popular videos are often clicked by a mount of users in a short period. With
content recommendation, the popular contents could be broadcast to the
potential users in wireless network, to save huge transmitting resource. In
this paper, the contents propagation model is analyzed due to users' historical
behavior, location, and the converging properties in wireless data
transmission, with the users' communication log in the Chinese commercial
cellular network. And a recommendation scheme is proposed to achieve high
energy efficiency.
"
688,"An Efficient Bit Plane X-OR Algorithm for Irreversible Image
  Steganography","  The science of hiding secret information in another message is known as
Steganography; hence the presence of secret information is concealed. It is the
method of hiding cognitive content in same or another media to avoid
recognition by the intruders. This paper introduces new method wherein
irreversible steganography is used to hide an image in the same medium so that
the secret data is masked. The secret image is known as payload and the carrier
is known as cover image. X-OR operation is used amongst mid level bit planes of
carrier image and high level bit planes of data image to generate new low level
bit planes of the stego image. Recovery process includes the X-ORing of low
level bit planes and mid level bit planes of the stego image. Based on the
result of the recovery, subsequent data image is generated. A RGB color image
is used as carrier and the data image is a grayscale image of dimensions less
than or equal to the dimensions of the carrier image. The proposed method
greatly increases the embedding capacity without significantly decreasing the
PSNR value.
"
689,"Secret Image Sharing Using Grayscale Payload Decomposition and
  Irreversible Image Steganography","  To provide an added security level most of the existing reversible as well as
irreversible image steganography schemes emphasize on encrypting the secret
image (payload) before embedding it to the cover image. The complexity of
encryption for a large payload where the embedding algorithm itself is complex
may adversely affect the steganographic system. Schemes that can induce same
level of distortion, as any standard encryption technique with lower
computational complexity, can improve the performance of stego systems. In this
paper we propose a secure secret image sharing scheme, which bears minimal
computational complexity. The proposed scheme, as a replacement for encryption,
diversifies the payload into different matrices which are embedded into carrier
image (cover image) using bit X-OR operation. A payload is a grayscale image
which is divided into frequency matrix, error matrix, and sign matrix. The
frequency matrix is scaled down using a mapping algorithm to produce Down
Scaled Frequency (DSF) matrix. The DSF matrix, error matrix, and sign matrix
are then embedded in different cover images using bit X-OR operation between
the bit planes of the matrices and respective cover images. Analysis of the
proposed scheme shows that it effectively camouflages the payload with minimum
computation time.
"
690,Multi-View 3D Video Multicast for Broadband IP Networks,"  With the recent emergence of 3D-supported TVs, video service providers now
face an opportunity to provide high resolution multi-view 3D videos over IP
networks. One simple way to support efficient communications between a video
server and multiple clients is to deliver each desired view in a multicast
stream. Nevertheless, it is expected that significantly increased bandwidth
will be required to support the transmission of all views in multi-view 3D
videos. However, the recent emergence of a new video synthesis technique called
Depth-Image-Based Rendering (DIBR) suggests that multi-view 3D video does not
necessarily require the transmission of all views. Therefore, we formulate a
new problem, named Multi-view and Multicast Delivery Selection Problem (MMDS),
and design an algorithm, called MMDEA, to find the optimal solution. Simulation
results manifest that using DIBR can effectively reduce bandwidth consumption
by 35% compared to the original multicast delivery scheme.
"
691,Human Motion Capture Data Tailored Transform Coding,"  Human motion capture (mocap) is a widely used technique for digitalizing
human movements. With growing usage, compressing mocap data has received
increasing attention, since compact data size enables efficient storage and
transmission. Our analysis shows that mocap data have some unique
characteristics that distinguish themselves from images and videos. Therefore,
directly borrowing image or video compression techniques, such as discrete
cosine transform, does not work well. In this paper, we propose a novel
mocap-tailored transform coding algorithm that takes advantage of these
features. Our algorithm segments the input mocap sequences into clips, which
are represented in 2D matrices. Then it computes a set of data-dependent
orthogonal bases to transform the matrices to frequency domain, in which the
transform coefficients have significantly less dependency. Finally, the
compression is obtained by entropy coding of the quantized coefficients and the
bases. Our method has low computational cost and can be easily extended to
compress mocap databases. It also requires neither training nor complicated
parameter setting. Experimental results demonstrate that the proposed scheme
significantly outperforms state-of-the-art algorithms in terms of compression
performance and speed.
"
692,Olfactory Signal Processing,"  Olfaction, the sense of smell, has received scant attention from a signal
processing perspective in comparison to audition and vision. In this paper, we
develop a signal processing paradigm for olfactory signals based on new
scientific discoveries including the psychophysics concept of olfactory white.
We describe a framework for predicting the perception of odorant compounds from
their physicochemical features and use the prediction as a foundation for
several downstream processing tasks. We detail formulations for odor
cancellation and food steganography, and provide real-world empirical examples
for the two tasks. We also discuss adaptive filtering and other olfactory
signal processing tasks at a high level.
"
693,"Comparing CSI and PCA in Amalgamation with JPEG for Spectral Image
  Compression","  Continuing our previous research on color image compression, we move towards
spectral image compression. This enormous amount of data needs more space to
store and more time to transmit. To manage this sheer amount of data,
researchers have investigated different techniques so that image quality can be
conserved and compressibility can be improved. The principle component analysis
(PCA) can be employed to reduce the dimensions of spectral images to achieve
high compressibility and performance. Due to processing complexity of PCA, a
simple interpolation technique called cubic spline interpolation (CSI) was
considered to reduce the dimensionality of spectral domain of spectral images.
The CSI and PCA were employed one by one in the spectral domain and were
amalgamated with the JPEG, which was employed in spatial domain. Three measures
including compression rate (CR), processing time (Tp) and color difference
CIEDE2000 were used for performance analysis. Test results showed that for a
fixed value of compression rate, CSI based algorithm performed poor in terms of
dE00, in comparison with PCA, but is still reliable because of small color
difference. On the other hand it has lower complexity and is computationally
much better as compared to PCA based algorithm, especially for spectral images
with large size.
"
694,Hiding Sound in Image by K-LSB Mutation,"  In this paper a novel approach to hide sound files in a digital image is
proposed and implemented such that it becomes difficult to conclude about the
existence of the hidden data inside the image. In this approach, we utilize the
rightmost k-LSB of pixels in an image to embed MP3 sound bits into a pixel. The
pixels are so chosen that the distortion in image would be minimized due to
embedding. This requires comparing all the possible permutations of pixel
values, which may would lead to exponential time computation. To speed up this,
Cuckoo Search (CS) could be used to find the most optimal solution. The
advantage of using proposed CS is that it is easy to implement and is very
effective at converging in relatively less iterations/generations.
"
695,StegExpose - A Tool for Detecting LSB Steganography,"  Steganalysis tools play an important part in saving time and providing new
angles of attack for forensic analysts. StegExpose is a solution designed for
use in the real world, and is able to analyse images for LSB steganography in
bulk using proven attacks in a time efficient manner. When steganalytic methods
are combined intelligently, they are able generate even more accurate results.
This is the prime focus of StegExpose.
"
696,Steganography in Modern Smartphones and Mitigation Techniques,"  By offering sophisticated services and centralizing a huge volume of personal
data, modern smartphones changed the way we socialize, entertain and work. To
this aim, they rely upon complex hardware/software frameworks leading to a
number of vulnerabilities, attacks and hazards to profile individuals or gather
sensitive information. However, the majority of works evaluating the security
degree of smartphones neglects steganography, which can be mainly used to: i)
exfiltrate confidential data via camouflage methods, and ii) conceal valuable
or personal information into innocent looking carriers.
  Therefore, this paper surveys the state of the art of steganographic
techniques for smartphones, with emphasis on methods developed over the period
2005 to the second quarter of 2014. The different approaches are grouped
according to the portion of the device used to hide information, leading to
three different covert channels, i.e., local, object and network. Also, it
reviews the relevant approaches used to detect and mitigate steganographic
attacks or threats. Lastly, it showcases the most popular software applications
to embed secret data into carriers, as well as possible future directions.
"
697,Fisher-Yates Chaotic Shuffling Based Image Encryption,"  In Present era, information security is of utmost concern and encryption is
one of the alternatives to ensure security. Chaos based cryptography has
brought a secure and efficient way to meet the challenges of secure multimedia
transmission over the networks. In this paper, we have proposed a secure
Grayscale image encryption methodology in wavelet domain. The proposed
algorithm performs shuffling followed by encryption using states of chaotic map
in a secure manner. Firstly, the image is transformed from spatial domain to
wavelet domain by the Haar wavelet. Subsequently, Fisher Yates chaotic
shuffling technique is employed to shuffle the image in wavelet domain to
confuse the relationship between plain image and cipher image. A key dependent
piece-wise linear chaotic map is used to generate chaos for the chaotic
shuffling. Further, the resultant shuffled approximate coefficients are
chaotically modulated. To enhance the statistical characteristics from
cryptographic point of view, the shuffled image is self keyed diffused and
mixing operation is carried out using keystream extracted from one-dimensional
chaotic map and the plain-image. The proposed algorithm is tested over some
standard image dataset. The results of several experimental, statistical and
sensitivity analyses proved that the algorithm provides an efficient and secure
method to achieve trusted gray scale image encryption.
"
698,"DeepSentiBank: Visual Sentiment Concept Classification with Deep
  Convolutional Neural Networks","  This paper introduces a visual sentiment concept classification method based
on deep convolutional neural networks (CNNs). The visual sentiment concepts are
adjective noun pairs (ANPs) automatically discovered from the tags of web
photos, and can be utilized as effective statistical cues for detecting
emotions depicted in the images. Nearly one million Flickr images tagged with
these ANPs are downloaded to train the classifiers of the concepts. We adopt
the popular model of deep convolutional neural networks which recently shows
great performance improvement on classifying large-scale web-based image
dataset such as ImageNet. Our deep CNNs model is trained based on Caffe, a
newly developed deep learning framework. To deal with the biased training data
which only contains images with strong sentiment and to prevent overfitting, we
initialize the model with the model weights trained from ImageNet. Performance
evaluation shows the newly trained deep CNNs model SentiBank 2.0 (or called
DeepSentiBank) is significantly improved in both annotation accuracy and
retrieval performance, compared to its predecessors which mainly use binary SVM
classification models.
"
699,"A Novel No-reference Video Quality Metric for Evaluating Temporal
  Jerkiness due to Frame Freezing","  In this work, we propose a novel no-reference (NR) video quality metric that
evaluates the impact of frame freezing due to either packet loss or late
arrival. Our metric uses a trained neural network acting on features that are
chosen to capture the impact of frame freezing on the perceived quality. The
considered features include the number of freezes, freeze duration statistics,
inter-freeze distance statistics, frame difference before and after the freeze,
normal frame difference, and the ratio of them. We use the neural network to
find the mapping between features and subjective test scores. We optimize the
network structure and the feature selection through a cross validation
procedure, using training samples extracted from both VQEG and LIVE video
databases. The resulting feature set and network structure yields accurate
quality prediction for both the training data containing 54 test videos and a
separate testing dataset including 14 videos, with Pearson Correlation
Coefficients greater than 0.9 and 0.8 for the training set and the testing set,
respectively. Our proposed metric has low complexity and could be utilized in a
system with realtime processing constraint.
"
700,Child Education Through Animation: An Experimental Study,"  Teachers have tried to teach their students by introducing text books along
with verbal instructions in traditional education system. However, teaching and
learning methods could be changed for developing Information and Communication
Technology. It's time to adapt students with interactive learning system so
that they can improve their learning, catching, and memorizing capabilities. It
is indispensable to create high quality and realistic leaning environment for
students. Visual learning can be easier to understand and deal with their
learning. We developed visual learning materials in the form of video for
students of primary level using different multimedia application tools. The
objective of this paper is to examine the impact of students abilities to
acquire new knowledge or skills through visual learning materials and blended
leaning that is integration of visual learning materials with teachers
instructions. We visited a primary school in Dhaka city for this study and
conducted teaching with three different groups of students, (i) teacher taught
students by traditional system on same materials and marked level of students
ability to adapt by a set of questions, (ii) another group was taught with only
visual learning material and assessment was done with 15 questionnaires, (iii)
the third group was taught with the video of solar system combined with
teachers instructions and assessed with the same questionnaires. This
integration of visual materials with verbal instructions is a blended approach
of learning. The interactive blended approach greatly promoted students ability
of acquisition of knowledge and skills. Students response and perception were
very positive towards the blended technique than the other two methods. This
interactive blending leaning system may be an appropriate method especially for
school children.
"
701,"Interactive Digital Learning Materials for Kindergarten Students in
  Bangladesh","  The pedagogy of teaching and learning has changed with the proliferation of
communication technology and it is necessary to develop interactive learning
materials for children that may improve their learning, catching, and
memorizing capabilities. Perhaps, one of the most important innovations in the
age of technology is multimedia and its application. It is imperative to create
high quality and realistic learning environment for children. Interactive
learning materials can be easier to understand and deal with their first
learning. We developed some interactive learning materials in the form of a
video for Playgroup using multimedia application tools. This study investigated
the impact of students' abilities to acquire new knowledge or skills through
interactive learning materials. We visited one kindergartens (Nursery schools),
interviewed class teachers about their teaching methods and level of students'
ability of recognizing English alphabets, pictures, etc. The course teachers
were provided interactive learning materials to show their playgroups for a
number of sessions. The video included English alphabets with related words and
pictures, and motivational fun. We noticed that almost all children were very
interested to interact with their leaning video. The students were assessed
individually and asked to recognize the alphabets, and pictures. The students
adapted with their first alphabets very quickly. However, there were individual
differences in their cognitive development. This interactive multimedia can be
an alternative to traditional pedagogy for teaching playgroups.
"
702,"Precision-Energy-Throughput Scaling Of Generic Matrix Multiplication and
  Convolution Kernels Via Linear Projections","  Generic matrix multiplication (GEMM) and one-dimensional
convolution/cross-correlation (CONV) kernels often constitute the bulk of the
compute- and memory-intensive processing within image/audio recognition and
matching systems. We propose a novel method to scale the energy and processing
throughput of GEMM and CONV kernels for such error-tolerant multimedia
applications by adjusting the precision of computation. Our technique employs
linear projections to the input matrix or signal data during the top-level GEMM
and CONV blocking and reordering. The GEMM and CONV kernel processing then uses
the projected inputs and the results are accumulated to form the final outputs.
Throughput and energy scaling takes place by changing the number of projections
computed by each kernel, which in turn produces approximate results, i.e.
changes the precision of the performed computation. Results derived from a
voltage- and frequency-scaled ARM Cortex A15 processor running face recognition
and music matching algorithms demonstrate that the proposed approach allows for
280%~440% increase of processing throughput and 75%~80% decrease of energy
consumption against optimized GEMM and CONV kernels without any impact in the
obtained recognition or matching accuracy. Even higher gains can be obtained if
one is willing to tolerate some reduction in the accuracy of the recognition
and matching applications.
"
703,6 Seconds of Sound and Vision: Creativity in Micro-Videos,"  The notion of creativity, as opposed to related concepts such as beauty or
interestingness, has not been studied from the perspective of automatic
analysis of multimedia content. Meanwhile, short online videos shared on social
media platforms, or micro-videos, have arisen as a new medium for creative
expression. In this paper we study creative micro-videos in an effort to
understand the features that make a video creative, and to address the problem
of automatic detection of creative content. Defining creative videos as those
that are novel and have aesthetic value, we conduct a crowdsourcing experiment
to create a dataset of over 3,800 micro-videos labelled as creative and
non-creative. We propose a set of computational features that we map to the
components of our definition of creativity, and conduct an analysis to
determine which of these features correlate most with creative video. Finally,
we evaluate a supervised approach to automatically detect creative video, with
promising results, showing that it is necessary to model both aesthetic value
and novelty to achieve optimal classification accuracy.
"
704,Maximizing compression efficiency through block rotation,"  The Discrete Cosine Transform (DCT) is widely used in lossy image and video
compression schemes, e.g., JPEG and MPEG. In this paper, we show that the
compression efficiency of the DCT is dependent on the edge directions within a
block. In particular, higher compression ratios are achieved when edges are
aligned with the image axes. To maximize compression for general images, we
propose a rotated block DCT method. It consists of rotating each block, before
applying the DCT, by an angle that aligns the edges, and rotating back the
block in the decompression stage. We show how to compute the rotation angle and
analyze two alternative block rotation approaches. Our experiments show that
our method enables both a perceptual improvement and a PSNR increase of up to
2dB, compared with the standard DCT, for low and medium bit rates.
"
705,Cross-Modal Similarity Learning : A Low Rank Bilinear Formulation,"  The cross-media retrieval problem has received much attention in recent years
due to the rapid increasing of multimedia data on the Internet. A new approach
to the problem has been raised which intends to match features of different
modalities directly. In this research, there are two critical issues: how to
get rid of the heterogeneity between different modalities and how to match the
cross-modal features of different dimensions. Recently metric learning methods
show a good capability in learning a distance metric to explore the
relationship between data points. However, the traditional metric learning
algorithms only focus on single-modal features, which suffer difficulties in
addressing the cross-modal features of different dimensions. In this paper, we
propose a cross-modal similarity learning algorithm for the cross-modal feature
matching. The proposed method takes a bilinear formulation, and with the
nuclear-norm penalization, it achieves low-rank representation. Accordingly,
the accelerated proximal gradient algorithm is successfully imported to find
the optimal solution with a fast convergence rate O(1/t^2). Experiments on
three well known image-text cross-media retrieval databases show that the
proposed method achieves the best performance compared to the state-of-the-art
algorithms.
"
706,The Art of Data Hiding with Reed-Solomon Error Correcting Codes,"  With the tremendous advancements in technology and the Internet, data
security has become a major issue around the globe. To guarantee that data is
protected and does not go to an unintended endpoint, the art of data hiding
(steganography) emerged. Steganography is the art of hiding information such
that it is not detectable to the naked eye. Various techniques have been
proposed for hiding a secret message in a carrier document. In this paper, we
present a novel design that applies Reed-Solomon (RS) error correcting codes in
steganographic applications. The model works by substituting the redundant RS
codes with the steganographic message. The experimental results show that the
proposed design is satisfactory with the percentage of decoded information 100%
and percentage of decoded secret message 97. 36%. The proposed model proved
that it could be applied in various steganographic applications.
"
707,"Resource Allocation Frameworks for Network-coded Layered Multimedia
  Multicast Services","  The explosive growth of content-on-the-move, such as video streaming to
mobile devices, has propelled research on multimedia broadcast and multicast
schemes. Multi-rate transmission strategies have been proposed as a means of
delivering layered services to users experiencing different downlink channel
conditions. In this paper, we consider Point-to-Multipoint layered service
delivery across a generic cellular system and improve it by applying different
random linear network coding approaches. We derive packet error probability
expressions and use them as performance metrics in the formulation of resource
allocation frameworks. The aim of these frameworks is both the optimization of
the transmission scheme and the minimization of the number of broadcast packets
on each downlink channel, while offering service guarantees to a predetermined
fraction of users. As a case of study, our proposed frameworks are then adapted
to the LTE-A standard and the eMBMS technology. We focus on the delivery of a
video service based on the H.264/SVC standard and demonstrate the advantages of
layered network coding over multi-rate transmission. Furthermore, we establish
that the choice of both the network coding technique and resource allocation
method play a critical role on the network footprint, and the quality of each
received video layer.
"
708,A Tag Identification Approach Based On Fragile Watermark,"  This paper proposes a tag identify approach based on fragile Watermark that
based on Least significant bit of the replacement that we first use a special
way to initialize the cover to ensure that we can use random positions to embed
the information of tag. Using this way enhance the security of other to get the
right information of this tag. Finally as long as the covered information can
be decoded, the completeness and accuracy of the tag information can be
guaranteed. the result of simulation experiment show that this approach has
high sensitivity and security .
"
709,Audio Splicing Detection and Localization Using Environmental Signature,"  Audio splicing is one of the most common manipulation techniques in the area
of audio forensics. In this paper, the magnitudes of acoustic channel impulse
response and ambient noise are proposed as the environmental signature.
Specifically, the spliced audio segments are detected according to the
magnitude correlation between the query frames and reference frames via a
statically optimal threshold. The detection accuracy is further refined by
comparing the adjacent frames. The effectiveness of the proposed method is
tested on two data sets. One is generated from TIMIT database, and the other
one is made in four acoustic environments using a commercial grade microphones.
Experimental results show that the proposed method not only detects the
presence of spliced frames, but also localizes the forgery segments with near
perfect accuracy. Comparison results illustrate that the identification
accuracy of the proposed scheme is higher than the previous schemes. In
addition, experimental results also show that the proposed scheme is robust to
MP3 compression attack, which is also superior to the previous works.
"
710,Optimized Packet Scheduling in Multiview Video Navigation Systems,"  In multiview video systems, multiple cameras generally acquire the same scene
from different perspectives, such that users have the possibility to select
their preferred viewpoint. This results in large amounts of highly redundant
data, which needs to be properly handled during encoding and transmission over
resource-constrained channels. In this work, we study coding and transmission
strategies in multicamera systems, where correlated sources send data through a
bottleneck channel to a central server, which eventually transmits views to
different interactive users. We propose a dynamic correlation-aware packet
scheduling optimization under delay, bandwidth, and interactivity constraints.
The optimization relies both on a novel rate-distortion model, which captures
the importance of each view in the 3D scene reconstruction, and on an objective
function that optimizes resources based on a client navigation model. The
latter takes into account the distortion experienced by interactive clients as
well as the distortion variations that might be observed by clients during
multiview navigation. We solve the scheduling problem with a novel
trellis-based solution, which permits to formally decompose the multivariate
optimization problem thereby significantly reducing the computation complexity.
Simulation results show the gain of the proposed algorithm compared to baseline
scheduling policies. More in details, we show the gain offered by our dynamic
scheduling policy compared to static camera allocation strategies and to
schemes with constant coding strategies. Finally, we show that the best
scheduling policy consistently adapts to the most likely user navigation path
and that it minimizes distortion variations that can be very disturbing for
users in traditional navigation systems.
"
711,"Annotating Video with Open Educational Resources in a Flipped Classroom
  Scenario","  A wealth of Open Educational Resources is now available, and beyond the first
and evident problem of finding them, the issue of articulating a set of
resources is arising. When using audiovisual resources, among different
possibilities, annotating a video resource with additional resources linked to
specific fragments can constitute one of the articulation modalities.
Annotating a video is a complex task, and in a pedagogical context,
intermediary activities should be proposed in order to mitigate this
complexity. In this paper, we describe a tool dedicated to supporting video
annotation activities. It aims at improving learner engagement, by having
students be more active when watching videos by offering a progressive
annotation process, first guided by providing predefined resources, then more
freely, to accompany users in the practice of annotating videos.
"
712,Modeling Dynamics of Online Video Popularity,"  Large Internet video delivery systems serve millions of videos to tens of
millions of users on daily basis, via Video-on-Demand and live streaming. Video
popularity evolves over time. It represents the workload, as welll as business
value, of the video to the overall system. The ability to predict video
popularity is very helpful for improving service quality and operating
efficiency. Previous studies adopted simple models for video popularity, or
directly adopted patterns from measurement studies. In this paper, we develop a
stochastic fluid model that tries to capture two hidden processes that give
rise to different patterns of a given video's popularity evolution: the
information spreading process, and the user reaction process. Specifically,
these processes model how the video is recommended to the user, the videos
inherent attractiveness, and users reaction rate, and yield specific popularity
evolution patterns. We then validate our model by matching the predictions of
the model with observed patterns from our collaborator, a large content
provider in China. This model thus gives us the insight to explain the common
and different video popularity evolution patterns and why.
"
713,EgoSampling: Fast-Forward and Stereo for Egocentric Videos,"  While egocentric cameras like GoPro are gaining popularity, the videos they
capture are long, boring, and difficult to watch from start to end. Fast
forwarding (i.e. frame sampling) is a natural choice for faster video browsing.
However, this accentuates the shake caused by natural head motion, making the
fast forwarded video useless.
  We propose EgoSampling, an adaptive frame sampling that gives more stable
fast forwarded videos. Adaptive frame sampling is formulated as energy
minimization, whose optimal solution can be found in polynomial time.
  In addition, egocentric video taken while walking suffers from the left-right
movement of the head as the body weight shifts from one leg to another. We turn
this drawback into a feature: Stereo video can be created by sampling the
frames from the left most and right most head positions of each step, forming
approximate stereo-pairs.
"
714,"Class-Based Service Connectivity using Multi-Level Bandwidth Adaptation
  in Multimedia Wireless Networks","  Due to the fact that quality of service requirements are not very strict for
all traffic types, more calls of higher priority can be accommodated by
reducing some bandwidth allocation for the bandwidth adaptive calls. The
bandwidth adaptation to accept a higher priority call is more than that of a
lower priority call. Therefore, the multi-level bandwidth adaptation technique
improves the overall forced call termination probability as well as provides
priority of the traffic classes in terms of call blocking probability without
reducing the bandwidth utilization. We propose a novel bandwidth adaptation
model that releases multi-level of bandwidth from the existing multimedia
traffic calls. The amount of released bandwidth is decided based on the
priority of the requesting traffic calls and the number of existing bandwidth
adaptive calls. This prioritization of traffic classes does not reduce the
bandwidth utilization. Moreover, our scheme reduces the overall forced call
termination probability significantly. The proposed scheme is modeled using the
Markov Chain. The numerical results show that the proposed scheme is able to
provide negligible handover call dropping probability as well as significantly
reduced new call blocking probability of higher priority calls without
increasing the overall forced call termination probability.
"
715,"Radio Resource Allocation for Scalable Video Services over Wireless
  Cellular Networks","  Good quality video services always require higher bandwidth. Hence, to
provide the video services e.g., multicast/broadcast services (MBS) and unicast
services along with the existing voice, internet, and other background traffic
services over the wireless cellular networks, it is required to efficiently
manage the wireless resources in order to reduce the overall forced call
termination probability, to maximize the overall service quality, and to
maximize the revenue. Fixed bandwidth allocation for the MBS sessions either
reduces the quality of the MBS videos and bandwidth utilization or increases
the overall forced call termination probability and of course the handover call
dropping probability as well. Scalable Video Coding (SVC) technique allows the
variable bit rate allocation for the video services. In this paper, we propose
a bandwidth allocation scheme that efficiently allocates bandwidth among the
MBS sessions and the non-MBS traffic calls (e.g., voice, unicast, internet, and
other background traffic). The proposed scheme reduces the bandwidth allocation
for the MBS sessions during the congested traffic condition only to accommodate
more calls in the system. Instead of allocating fixed bandwidths for the BMS
sessions and the non-MBS traffic, our scheme allocates variable bandwidths for
them. However, the minimum quality of the videos is guaranteed by allocating
minimum bandwidth for them. Using the mathematical and numerical analyses, we
show that the proposed scheme maximizes the bandwidth utilization and
significantly reduces the overall forced call termination probability as well
as the handover call dropping probability.
"
716,"Call Admission Control based on Adaptive Bandwidth Allocation for
  Wireless Networks","  Provisioning of Quality of Service (QoS) is a key issue in any multi-media
system. However, in wireless systems, supporting QoS requirements of different
traffic types is more challenging due to the need to minimize two performance
metrics - the probability of dropping a handover call and the probability of
blocking a new call. Since QoS requirements are not as stringent for
non-real-time traffic types, as opposed to real-time traffic, more calls can be
accommodated by releasing some bandwidth from the already admitted
non-real-time traffic calls. If we require that such a released bandwidth to
accept a handover call ought to be larger than the bandwidth to accept a new
call, then the resulting probability of dropping a handover call will be
smaller than the probability of blocking a new call. In this paper we propose
an efficient Call Admission Control (CAC) that relies on adaptive multi-level
bandwidth-allocation scheme for non-real-time calls. The scheme allows
reduction of the call dropping probability along with increase of the bandwidth
utilization. The numerical results show that the proposed scheme is capable of
attaining negligible handover call dropping probability without sacrificing
bandwidth utilization.
"
717,"Adaptive Resource Management for Multimedia Applications in
  Femtocellular and Macrocellular Networks","  The increasing demands of various high data rate wireless applications have
been seen in the recent years and it will continue in the future. To fulfill
these demands, the limited existing wireless resources should be utilized
properly or new wireless technology should be developed. Therefore, we propose
some novel idea to manage the wireless resources and deployment of
femtocellular network technology. The study was mainly divided into two parts:
(a) femtocellular network deployment and resource allocation and (b) resource
management for macrocellular networks. The femtocellular network deployment
scenarios, integrated femtocell/macrocell network architectures, cost-effective
frequency planning, and mobility management schemes are presented in first
part. In the second part, we provide a CAC based on adaptive bandwidth
allocation for the wireless network in. The proposed CAC relies on adaptive
multi-level bandwidth-allocation scheme for non-real-time calls. We propose
video service provisioning over wireless networks. We provide a QoS adaptive
radio resource allocation as well as popularity based bandwidth allocation
schemes for scalable videos over wireless cellular networks. All the proposed
schemes are verified through several numerical and simulation results. The
research results presented in this dissertation clearly imply the advantages of
our proposed schemes.
"
718,Multi-Hypothesis Compressed Video Sensing Technique,"  In this paper, we present a compressive sampling and Multi-Hypothesis (MH)
reconstruction strategy for video sequences which has a rather simple encoder,
while the decoding system is not that complex. We introduce a convex cost
function that incorporates the MH technique with the sparsity constraint and
the Tikhonov regularization. Consequently, we derive a new iterative algorithm
based on these criteria. This algorithm surpasses its counterparts (Elasticnet
and Tikhonov) in the recovery performance. Besides it is computationally much
faster than the Elasticnet and comparable to the Tikhonov. Our extensive
simulation results confirm these claims.
"
719,"Energy Efficiency Optimization for MIMO-OFDM Mobile Multimedia
  Communication Systems with QoS Constraints","  It is widely recognized that besides the quality of service (QoS), the energy
efficiency is also a key parameter in designing and evaluating mobile
multimedia communication systems, which has catalyzed great interest in recent
literature. In this paper, an energy efficiency model is first proposed for
multiple-input multiple-output orthogonal-frequency-division-multiplexing
(MIMO-OFDM) mobile multimedia communication systems with statistical QoS
constraints. Employing the channel matrix singular-value-decomposition (SVD)
method, all subchannels are classified by their channel characteristics.
Furthermore, the multi-channel joint optimization problem in conventional
MIMO-OFDM communication systems is transformed into a multi-target single
channel optimization problem by grouping all subchannels. Therefore, a
closed-form solution of the energy efficiency optimization is derived for
MIMO-OFDM mobile mlutimedia communication systems. As a consequence, an
energy-efficiency optimized power allocation (EEOPA) algorithm is proposed to
improve the energy efficiency of MIMO-OFDM mobile multimedia communication
systems. Simulation comparisons validate that the proposed EEOPA algorithm can
guarantee the required QoS with high energy efficiency in MIMO-OFDM mobile
multimedia communication systems.
"
720,"Block Based Medical Image Watermarking Technique for Tamper Detection
  and Recovery","  In this paper, we propose a novel fragile block based medical image
watermarking technique for embedding data of patient into medical image,
verifying the integrity of ROI (Region of Interest), detecting the tampered
blocks inside ROI and recovering original ROI with less size authentication and
recovery data and with simple mathematical calculations. In the proposed
method, the medical image is divided into three regions called ROI, RONI
(Region of Non Interest) and border pixels. Later, authentication data of ROI
and Electronic Patient Record (EPR) are compressed using Run Length Encoding
(RLE) technique and then embedded into ROI. Recovery information of ROI is
embedded inside RONI and information of ROI is embedded inside border pixels.
Results of experiments conducted on several medical images reveal that proposed
method produces high quality watermarked medical images, identifies tampered
areas inside ROI of watermarked medical images and recovers the original ROI.
"
721,"Compression of Video Tracking and Bandwidth Balancing Routing in
  Wireless Multimedia Sensor Networks","  There has been a tremendous growth in multimedia applications over wireless
networks. Wireless Multimedia Sensor Networks(WMSNs) have become the premier
choice in many research communities and industry. Many state-of-art
applications, such as surveillance, traffic monitoring, and remote heath care
are essentially video tracking and transmission in WMSNs. The transmission
speed is constrained by big size of video data and fixed bandwidth allocation
in constant routing path. In this paper, we present a CamShift based algorithm
to compress the tracking of videos. Then we propose a bandwidth balancing
strategy in which each sensor node is able to dynamically select the node for
next hop with the highest potential bandwidth capacity to resume communication.
Key to the strategy is that each node merely maintains two parameters that
contains its historical bandwidth varying trend and then predicts its near
future bandwidth capacity. Then forwarding node selects the next hop with the
highest potential bandwidth capacity. Simulations demonstrate that our approach
significantly increases the data received by sink node and decreases the delay
on video transmission in Wireless Multimedia Sensor Network environment.
"
722,"Mobile Instant Video Clip Sharing: Modeling and Enhancing View
  Experience","  With the rapid development of wireless networking and mobile devices, anytime
and anywhere data access becomes readily available nowadays. Given the
crowdsourced content capturing and sharing, the preferred content length
becomes shorter and shorter, even for such multimedia data as video. A
representative is Twitter's Vine service, which, mainly targeting mobile users,
enables them to create ultra-short video clips and instantly post and share
with their followers. In this paper, we present an initial study on this new
generation of instant video clip sharing service enabled by mobile platforms
and explore the potentials towards its further enhancement. We closely
investigate its unique mobile interface, revealing the key differences between
Vine-enabled anytime anywhere data access patterns and that of traditional
counterparts. We then examine the scheduling policy to maximize the user
watching experience as well as the efficiency on the monetary and energy costs.
We show that the generic scheduling problem involves two subproblems, namely,
pre-fetching scheduling and watch-time download scheduling, and develop
effective solutions towards both of them. The superiority of our solution is
demonstrated by extensive trace-driven simulations. To the best of our
knowledge, this is the first work on modeling and optimizing the instant video
clip sharing on mobile devices.
"
723,"Iterative network-channel decoding with cooperative space-time
  transmission","  One of the most efficient methods of exploiting space diversity for portable
wireless devices is cooperative communication utilizing space-time block codes.
In cooperative communication, users besides communicating their own
information, also relay the information of other users. In this paper we
investigate a scheme where cooperation is achieved using two methods, namely,
distributed space-time coding and network coding. Two cooperating users utilize
Alamouti space time code for inter-user cooperation and in addition utilize a
third relay which performs network coding. The third relay does not have any of
its information to be sent. In this paper we propose a scheme utilizing
convolutional code based network coding, instead of conventional XOR based
network code and utilize iterative joint network-channel decoder for efficient
decoding. Extrinsic information transfer (EXIT) chart analysis is performed to
investigate the convergence property of the proposed decoder.
"
724,Improving image watermarking based on Tabu search by Chaos,"  With the fast development of communication and multimedia technology, the
rights of the owners of multimedia products is vulnerable to the unauthorized
copies and watermarking is one of the best known methods for proving the
ownership of a product. In this paper we prosper the previous watermarking
method which was based on Tabu search by Chaos. The modification applied in the
permutation step of watermarking and the initial population generation of the
Tabu search. We analyze our method on some well known images and experimental
results shows the improvement in the quality and speed of the proposed
watermarking method.
"
725,"Minimization of image watermarking side effects through subjective
  optimization","  This paper investigates the use of Structural Similaritys (SSIM) index on the
minimized side effect to image watermarking. For fast implementation and more
compatibility with the standard DCT based codecs, watermark insertion is
carried out on the DCT coefficients and hence a SSIM model for DCT based
watermarking is developed. For faster implementation, the SSIM index is
maximized over independent 4x4 non-overlapped blocks but the disparity between
the adjacent blocks reduces the overall image quality. This problem is resolved
through optimization of overlapped blocks, but, the higher image quality is
achieved at a cost of high computational complexity. To reduce the
computational complexity while preserving the good quality, optimization of
semi-overlapped blocks is introduced. We show that while SSIM-based
optimization over overlapped blocks has as high as 64 times the complexity of
the 4x4 non-overlapped method, with semi-overlapped optimization the high
quality of overlapped method is preserved only at a cost of less than 8 times
the non-overlapped method.
"
726,"Enhance Robustness of Image-in-Image Watermarking through Data
  Partitioning","  Vulnerability of watermarking schemes against intense signal processing
attacks is generally a major concern, particularly when there are techniques to
reproduce an acceptable copy of the original signal with no chance for
detecting the watermark. In this paper, we propose a two-layer, data
partitioning (DP) based, image in image watermarking method in the DCT domain
to improve the watermark detection performance. Truncated singular value
decomposition, binary wavelet decomposition and spatial scalability idea in
H.264/SVC are analyzed and employed as partitioning methods. It is shown that
the proposed scheme outperforms its two recent competitors in terms of both
data payload and robustness to intense attacks.
"
727,"Optimization of Unequal Error Protection Rateless Codes for Multimedia
  Multicasting","  Rateless codes have been shown to be able to provide greater flexibility and
efficiency than fixed-rate codes for multicast applications. In the following,
we optimize rateless codes for unequal error protection (UEP) for multimedia
multicasting to a set of heterogeneous users. The proposed designs have the
objectives of providing either guaranteed or best-effort quality of service
(QoS). A randomly interleaved rateless encoder is proposed whereby users only
need to decode symbols up to their own QoS level. The proposed coder is
optimized based on measured transmission properties of standardized raptor
codes over wireless channels. It is shown that a guaranteed QoS problem
formulation can be transformed into a convex optimization problem, yielding a
globally optimal solution. Numerical results demonstrate that the proposed
optimized random interleaved UEP rateless coder's performance compares
favorably with that of other recently proposed UEP rateless codes.
"
728,Scalable high-dimensional indexing and searching with Hadoop,"  While high-dimensional search-by-similarity techniques reached their maturity
and in overall provide good performance, most of them are unable to cope with
very large multimedia collections. The 'big data' challenge however has to be
addressed as multimedia collections have been explosively growing and will grow
even faster than ever within the next few years. Luckily, computational
processing power has become more available to researchers due to easier access
to distributed grid infrastructures. In this paper, we show how
high-dimensional indexing and searching methods can be used on scientific grid
environments and present a scalable workflow for indexing and searching over 30
billion SIFT descriptors using a cluster running Hadoop. Besides its
scalability, the proposed scheme not only provides good search quality, but
also achieves a stable throughput of around 210ms per image when searching a
100M image collection. Our findings could help other researchers and
practitioners to cope with huge multimedia collections.
"
729,"A Systematic Scheme for Measuring the Performance of the Display-Camera
  Channel","  Display-camera communication has become a promising direction in both
computer vision and wireless communication communities. However, the
consistency of the channel measurement is an open issue since precise
calibration of the experimental setting has not been fully studied in the
literatures. This paper focuses on establishing a scheme for precise
calibration of the display-camera channel performance. To guarantee high
consistency of the experiment, we propose an accurate measurement scheme for
the geometric parameters, and identify some unstable channel factors, e.g.,
Moire effect, rolling shutter effect, blocking artifacts, inconsistency in
auto-focus, trembling and vibration. In the experiment, we first define the
consistency criteria according to the error-prone region in bit error rate
(BER) plots of the channel measurements. It is demonstrated that the
consistency of the experimental result can be improved by the proposed precise
calibration scheme.
"
730,PacMap: Transferring PacMan to the Physical Realm,"  This paper discusses the implementation of the pervasive game PacMap.
Openness and portability have been the main design objectives for PacMap. We
elaborate on programming techniques which may be applicable to a broad range of
location-based games that involve the movement of virtual characters over map
interfaces. In particular, we present techniques to execute shortest path
algorithms on spatial environments bypassing the restrictions imposed by
commercial mapping services. Last, we present ways to improve the movement and
enhance the intelligence of virtual characters taking into consideration the
actions and position of players in location-based games.
"
731,"Watermarking PDF Documents using Various Representations of
  Self-inverting Permutations","  This work provides to web users copyright protection of their Portable
Document Format (PDF) documents by proposing efficient and easily implementable
techniques for PDF watermarking; our techniques are based on the ideas of our
recently proposed watermarking techniques for software, image, and audio,
expanding thus the digital objects that can be efficiently watermarked through
the use of self-inverting permutations. In particular, we present various
representations of a self-inverting permutation $\pi^*$ namely
1D-representation, 2D-representation, and RPG-representation, and show that
theses representations can be efficiently applied to PDF watermarking. Indeed,
we first present an audio-based technique for marking a PDF document $T$ by
exploiting the 1D-representation of a permutation $\pi^*$, and then, since
pages of a PDF document $T$ are 2D objects, we present an image-based algorithm
for encoding $\pi^*$ into $T$ by first mapping the elements of $\pi^*$ into a
matrix $A^*$ and then using the information stored in $A^*$ to mark invisibly
specific areas of PDF document $T$. Finally, we describe a graph-based
watermarking algorithm for embedding a self-inverting permutation $\pi^*$ into
the document structure of a PDF file $T$ by exploiting the RPG-representation
of $\pi^*$ and the structure of a PDF document. We have evaluated the embedding
and extracting algorithms by testing them on various and different in
characteristics PDF documents.
"
732,A Modified No Search Algorithm for Fractal Image Compression,"  Fractal image compression has some desirable properties like high quality at
high compression ratio, fast decoding, and resolution independence. Therefore
it can be used for many applications such as texture mapping and pattern
recognition and image watermarking. But it suffers from long encoding time due
to its need to find the best match between sub blocks. This time is related to
the approach that is used. In this paper we present a fast encoding Algorithm
based on no search method. Our goal is that more blocks are covered in initial
step of quad tree algorithm. Experimental result has been compared with other
new fast fractal coding methods, showing it is better in term of bit rate in
same condition while the other parameters are fixed.
"
733,"Improved 8-point Approximate DCT for Image and Video Compression
  Requiring Only 14 Additions","  Video processing systems such as HEVC requiring low energy consumption needed
for the multimedia market has lead to extensive development in fast algorithms
for the efficient approximation of 2-D DCT transforms. The DCT is employed in a
multitude of compression standards due to its remarkable energy compaction
properties. Multiplier-free approximate DCT transforms have been proposed that
offer superior compression performance at very low circuit complexity. Such
approximations can be realized in digital VLSI hardware using additions and
subtractions only, leading to significant reductions in chip area and power
consumption compared to conventional DCTs and integer transforms. In this
paper, we introduce a novel 8-point DCT approximation that requires only 14
addition operations and no multiplications. The proposed transform possesses
low computational complexity and is compared to state-of-the-art DCT
approximations in terms of both algorithm complexity and peak signal-to-noise
ratio. The proposed DCT approximation is a candidate for reconfigurable video
standards such as HEVC. The proposed transform and several other DCT
approximations are mapped to systolic-array digital architectures and
physically realized as digital prototype circuits using FPGA technology and
mapped to 45 nm CMOS technology.
"
734,Binary Systematic Network Coding for Progressive Packet Decoding,"  We consider binary systematic network codes and investigate their capability
of decoding a source message either in full or in part. We carry out a
probability analysis, derive closed-form expressions for the decoding
probability and show that systematic network coding outperforms conventional
network coding. We also develop an algorithm based on Gaussian elimination that
allows progressive decoding of source packets. Simulation results show that the
proposed decoding algorithm can achieve the theoretical optimal performance.
Furthermore, we demonstrate that systematic network codes equipped with the
proposed algorithm are good candidates for progressive packet recovery owing to
their overall decoding delay characteristics.
"
735,"Sleep Period Optimization Model For Layered Video Service Delivery Over
  eMBMS Networks","  Long Term Evolution-Advanced (LTE-A) and the evolved Multimedia Broadcast
Multicast System (eMBMS) are the most promising technologies for the delivery
of highly bandwidth demanding applications. In this paper we propose a green
resource allocation strategy for the delivery of layered video streams to users
with different propagation conditions. The goal of the proposed model is to
minimize the user energy consumption. That goal is achieved by minimizing the
time required by each user to receive the broadcast data via an efficient power
transmission allocation model. A key point in our system model is that the
reliability of layered video communications is ensured by means of the Random
Linear Network Coding (RLNC) approach. Analytical results show that the
proposed resource allocation model ensures the desired quality of service
constraints, while the user energy footprint is significantly reduced.
"
736,Optimized Network-coded Scalable Video Multicasting over eMBMS Networks,"  Delivery of multicast video services over fourth generation (4G) networks
such as 3GPP Long Term Evolution-Advanced (LTE-A) is gaining momentum. In this
paper, we address the issue of efficiently multicasting layered video services
by defining a novel resource allocation framework that aims to maximize the
service coverage whilst keeping the radio resource footprint low. A key point
in the proposed system mode is that the reliability of multicast video services
is ensured by means of an Unequal Error Protection implementation of the
Network Coding (UEP-NC) scheme. In addition, both the communication parameters
and the UEP-NC scheme are jointly optimized by the proposed resource allocation
framework. Numerical results show that the proposed allocation framework can
significantly increase the service coverage when compared to a conventional
Multi-rate Transmission (MrT) strategy.
"
737,"LTE enhancements for Public Safety and Security communications to
  support Group Multimedia Communications","  Currently Public Safety and Security communication systems rely on reliable
and secure Professional Mobile Radio (PMR) Networks that are mainly devoted to
provide voice services. However, the evolution trend for PMR networks is
towards the provision of new value-added multimedia services such as video
streaming, in order to improve the situational awareness and enhance the
life-saving operations. The challenge here is to exploit the future commercial
broadband networks to deliver voice and multimedia services satisfying the PMR
service requirements. In particular, a viable solution till now seems that of
adapting the new Long Term Evolution technology to provide IP-based broadband
services with the security and reliability typical of PMR networks. This paper
outlines different alternatives to achieve this goal and, in particular,
proposes a proper solution for providing multimedia services with PMR standards
over commercial LTE networks.
"
738,"Service Provisioning and Profit Maximization in Network-assisted
  Adaptive HTTP Streaming","  Adaptive HTTP streaming with centralized consideration of multiple streams
has gained increasing interest. It poses a special challenge that the interests
of both content provider and network operator need to be deliberately balanced.
More importantly, the adaptation strategy is required to be flexible enough to
be ported to various systems that work under different network environments,
QoE levels, and economic objectives. To address these challenges, we propose a
Markov Decision Process (MDP) based network-assisted adaptation framework,
wherein cost of buffering, significant playback variation, bandwidth management
and income of playback are jointly investigated. We then demonstrate its
promising service provisioning and maximal profit for a mobile network in which
fair or differentiated service is required.
"
739,Transductive Multi-view Zero-Shot Learning,"  Most existing zero-shot learning approaches exploit transfer learning via an
intermediate-level semantic representation shared between an annotated
auxiliary dataset and a target dataset with different classes and no
annotation. A projection from a low-level feature space to the semantic
representation space is learned from the auxiliary dataset and is applied
without adaptation to the target dataset. In this paper we identify two
inherent limitations with these approaches. First, due to having disjoint and
potentially unrelated classes, the projection functions learned from the
auxiliary dataset/domain are biased when applied directly to the target
dataset/domain. We call this problem the projection domain shift problem and
propose a novel framework, transductive multi-view embedding, to solve it. The
second limitation is the prototype sparsity problem which refers to the fact
that for each target class, only a single prototype is available for zero-shot
learning given a semantic representation. To overcome this problem, a novel
heterogeneous multi-view hypergraph label propagation method is formulated for
zero-shot learning in the transductive embedding space. It effectively exploits
the complementary information offered by different semantic representations and
takes advantage of the manifold structures of multiple representation spaces in
a coherent manner. We demonstrate through extensive experiments that the
proposed approach (1) rectifies the projection shift between the auxiliary and
target domains, (2) exploits the complementarity of multiple semantic
representations, (3) significantly outperforms existing methods for both
zero-shot and N-shot recognition on three image and video benchmark datasets,
and (4) enables novel cross-view annotation tasks.
"
740,"Robust Subjective Visual Property Prediction from Crowdsourced Pairwise
  Labels","  The problem of estimating subjective visual properties from image and video
has attracted increasing interest. A subjective visual property is useful
either on its own (e.g. image and video interestingness) or as an intermediate
representation for visual recognition (e.g. a relative attribute). Due to its
ambiguous nature, annotating the value of a subjective visual property for
learning a prediction model is challenging. To make the annotation more
reliable, recent studies employ crowdsourcing tools to collect pairwise
comparison labels because human annotators are much better at ranking two
images/videos (e.g. which one is more interesting) than giving an absolute
value to each of them separately. However, using crowdsourced data also
introduces outliers. Existing methods rely on majority voting to prune the
annotation outliers/errors. They thus require large amount of pairwise labels
to be collected. More importantly as a local outlier detection method, majority
voting is ineffective in identifying outliers that can cause global ranking
inconsistencies. In this paper, we propose a more principled way to identify
annotation outliers by formulating the subjective visual property prediction
task as a unified robust learning to rank problem, tackling both the outlier
detection and learning to rank jointly. Differing from existing methods, the
proposed method integrates local pairwise comparison labels together to
minimise a cost that corresponds to global inconsistency of ranking order. This
not only leads to better detection of annotation outliers but also enables
learning with extremely sparse annotations. Extensive experiments on various
benchmark datasets demonstrate that our new approach significantly outperforms
state-of-the-arts alternatives.
"
741,Embedding of binary image in the Gray planes,"  For watermarking of the digital grayscale image its Gray planes have been
used. With the help of the introduced representation over Gray planes the LSB
embedding method and detection have been discussed. It found that data, a
binary image, hidden in the Gray planes is more robust to JPEG lossy
compression than in the bit planes.
"
742,The Beauty of Capturing Faces: Rating the Quality of Digital Portraits,"  Digital portrait photographs are everywhere, and while the number of face
pictures keeps growing, not much work has been done to on automatic portrait
beauty assessment. In this paper, we design a specific framework to
automatically evaluate the beauty of digital portraits. To this end, we procure
a large dataset of face images annotated not only with aesthetic scores but
also with information about the traits of the subject portrayed. We design a
set of visual features based on portrait photography literature, and
extensively analyze their relation with portrait beauty, exposing interesting
findings about what makes a portrait beautiful. We find that the beauty of a
portrait is linked to its artistic value, and independent from age, race and
gender of the subject. We also show that a classifier trained with our features
to separate beautiful portraits from non-beautiful portraits outperforms
generic aesthetic classifiers.
"
743,"On Optimization of Network-coded Scalable Multimedia Service
  Multicasting","  In the near future, the delivery of multimedia multicast services over
next-generation networks is likely to become one of the main pillars of future
cellular networks. In this extended abstract, we address the issue of
efficiently multicasting layered video services by defining a novel
optimization paradigm that is based on an Unequal Error Protection
implementation of Random Linear Network Coding, and aims to ensure target
service coverages by using a limited amount of radio resources.
"
744,Fragile Watermarking Using Finite Field Trigonometrical Transforms,"  Fragile digital watermarking has been applied for authentication and
alteration detection in images. Utilizing the cosine and Hartley transforms
over finite fields, a new transform domain fragile watermarking scheme is
introduced. A watermark is embedded into a host image via a blockwise
application of two-dimensional finite field cosine or Hartley transforms.
Additionally, the considered finite field transforms are adjusted to be number
theoretic transforms, appropriate for error-free calculation. The employed
technique can provide invisible fragile watermarking for authentication systems
with tamper location capability. It is shown that the choice of the finite
field characteristic is pivotal to obtain perceptually invisible watermarked
images. It is also shown that the generated watermarked images can be used as
publicly available signature data for authentication purposes.
"
745,A Discrete Tchebichef Transform Approximation for Image and Video Coding,"  In this paper, we introduce a low-complexity approximation for the discrete
Tchebichef transform (DTT). The proposed forward and inverse transforms are
multiplication-free and require a reduced number of additions and bit-shifting
operations. Numerical compression simulations demonstrate the efficiency of the
proposed transform for image and video coding. Furthermore, Xilinx Virtex-6
FPGA based hardware realization shows 44.9% reduction in dynamic power
consumption and 64.7% lower area when compared to the literature.
"
746,A Class of DCT Approximations Based on the Feig-Winograd Algorithm,"  A new class of matrices based on a parametrization of the Feig-Winograd
factorization of 8-point DCT is proposed. Such parametrization induces a matrix
subspace, which unifies a number of existing methods for DCT approximation. By
solving a comprehensive multicriteria optimization problem, we identified
several new DCT approximations. Obtained solutions were sought to possess the
following properties: (i) low multiplierless computational complexity, (ii)
orthogonality or near orthogonality, (iii) low complexity invertibility, and
(iv) close proximity and performance to the exact DCT. Proposed approximations
were submitted to assessment in terms of proximity to the DCT, coding
performance, and suitability for image compression. Considering Pareto
efficiency, particular new proposed approximations could outperform various
existing methods archived in literature.
"
747,"Optimization of Quality of Experience through File Duplication in Video
  Sharing Servers","  Consumers of short videos on Internet can have a bad Quality of Experience
QoE due to the long distance between the consumers and the servers that hosting
the videos. We propose an optimization of the file allocation in
telecommunication operators content sharing servers to improve the QoE through
files duplication, thus bringing the files closer to the consumers. This
optimization allows the network operator to set the level of QoE and to have
control over the users access cost by setting a number of parameters. Two
optimization methods are given and are followed by a comparison of their
efficiency. Also, the hosting costs versus the gain of optimization are
analytically discussed.
"
748,"Hash Chain Links Resynchronization Methods in Video Streaming Security
  Performance Comparison","  Hash chains provide a secure and light way of security to data authentication
including two aspects: Data Integrity and Data Origin Authentication. The real
challenge of using the hash chains is how it could recover the synchronization
state and continue keeping the hash link in case of packet loss? Based on the
packet loss tolerance and some accepted delay of video delivery which are
representing the permitted tolerance for heavy loaded applications, we propose
different mechanisms for such synchronization recovery. Each mechanism is
suitable to use according to the video use case and the low capabilities of end
devices. This paper proposes comparative results between them based on the
status of each one and its overhead. Then, we propose a hybrid technique based
Redundancy Code (RC). This hybrid algorithm is simulated and compared
analytically against the other techniques (SHHC, TSP, MLHC and TSS). Moreover,
a global performance evaluation in terms of delay and overhead is conducted for
all techniques.
"
749,"A Secure Electronic Prescription System Using Steganography with
  Encryption Key Implementation","  Over the years health care has seen major improvement due to the introduction
information and communication technology with electronic medical prescription
being one the areas benefiting from it. Within the overall context of
protection of health care information, privacy of prescription data needs
special treatment. This paper presents an e-prescription system that addresses
some challenges pertaining to the prescription privacy protection in the
process of drug prescription. The developed system uses spread spectrum image
steganography algorithm with Advanced Encryption Standard (AES) key
implementation to provide a secure means of delivering medical prescription to
the parties involved. The architecture for encoding and decoding was
implemented with an electronic health record. The software development tools
used were PHP and MySQL database management system for front end and backend
data management respectively. The designed system demonstration shows that the
synergistic combination of steganography and cryptography technologies in
medical prescription is capable of providing a secure transmission to properly
provide security for patients medical prescription.
"
750,CS reconstruction of the speech and musical signals,"  The application of Compressive sensing approach to the speech and musical
signals is considered in this paper. Compressive sensing (CS) is a new approach
to the signal sampling that allows signal reconstruction from a small set of
randomly acquired samples. This method is developed for the signals that
exhibit the sparsity in a certain domain. Here we have observed two sparsity
domains: discrete Fourier and discrete cosine transform domain. Furthermore,
two different types of audio signals are analyzed in terms of sparsity and CS
performance - musical and speech signals. Comparative analysis of the CS
reconstruction using different number of signal samples is performed in the two
domains of sparsity. It is shown that the CS can be successfully applied to
both, musical and speech signals, but the speech signals are more demanding in
terms of the number of observations. Also, our results show that discrete
cosine transform domain allows better reconstruction using lower number of
observations, compared to the Fourier transform domain, for both types of
signals.
"
751,Wavelet based Watermarking approach in the Compressive Sensing Scenario,"  Due to the wide distribution and usage of digital media, an important issue
is protection of the digital content. There is a number of algorithms and
techniques developed for the digital watermarking.In this paper, the invisible
image watermark procedure is considered. Watermark is created as a pseudo
random sequence, embedded in the certain region of the image, obtained using
Haar wavelet decomposition. Generally, the watermarking procedure should be
robust to the various attacks-filtering, noise etc. Here we assume the
Compressive sensing scenario as a new signal processing technique that may
influence the robustness. The focus of this paper was the possibility of the
watermark detection under Compressive Sensing attack with different number of
available image coefficients. The quality of the reconstructed images has been
evaluated using Peak Signal to Noise Ratio (PSNR).The theory is supported with
experimental results.
"
752,Contextual Online Learning for Multimedia Content Aggregation,"  The last decade has witnessed a tremendous growth in the volume as well as
the diversity of multimedia content generated by a multitude of sources (news
agencies, social media, etc.). Faced with a variety of content choices,
consumers are exhibiting diverse preferences for content; their preferences
often depend on the context in which they consume content as well as various
exogenous events. To satisfy the consumers' demand for such diverse content,
multimedia content aggregators (CAs) have emerged which gather content from
numerous multimedia sources. A key challenge for such systems is to accurately
predict what type of content each of its consumers prefers in a certain
context, and adapt these predictions to the evolving consumers' preferences,
contexts and content characteristics. We propose a novel, distributed, online
multimedia content aggregation framework, which gathers content generated by
multiple heterogeneous producers to fulfill its consumers' demand for content.
Since both the multimedia content characteristics and the consumers'
preferences and contexts are unknown, the optimal content aggregation strategy
is unknown a priori. Our proposed content aggregation algorithm is able to
learn online what content to gather and how to match content and users by
exploiting similarities between consumer types. We prove bounds for our
proposed learning algorithms that guarantee both the accuracy of the
predictions as well as the learning speed. Importantly, our algorithms operate
efficiently even when feedback from consumers is missing or content and
preferences evolve over time. Illustrative results highlight the merits of the
proposed content aggregation system in a variety of settings.
"
753,An SVD-based Fragile Watermarking Scheme With Grouped Blocks,"  This paper proposes a novel fragile watermarking scheme for digital image
authentication which is based on Singular Value Decomposition(SVD) and grouped
blocks. The watermark bits which include two types of bits are inserted into
the least significant bit(LSB) plane of the host image using the adaptive
chaotic map to determine the positions. The groped blocks break the block-wise
independence and therefore can withstand the Vector Quantization attack(VQ
attack). The inserting positions are related to the statistical information of
image block data, in order to increase the security and provide an auxiliary
way to authenticate the image data. The effectiveness of the proposed scheme is
checked by a variety of attacks, and the experimental results prove that it has
a remarkable tamper detection ability and also has a precise locating ability.
"
754,"A Control-Theoretic Approach to Adaptive Video Streaming in Dense
  Wireless Networks","  Recently, the way people consume video content has been undergoing a dramatic
change. Plain TV sets, that have been the center of home entertainment for a
long time, are losing grounds to Hybrid TV's, PC's, game consoles, and, more
recently, mobile devices such as tablets and smartphones. The new predominant
paradigm is: watch what I want, when I want, and where I want.
  The challenges of this shift are manifold. On the one hand, broadcast
technologies such as DVB-T/C/S need to be extended or replaced by mechanisms
supporting asynchronous viewing, such as IPTV and video streaming over
best-effort networks, while remaining scalable to millions of users. On the
other hand, the dramatic increase of wireless data traffic begins to stretch
the capabilities of the existing wireless infrastructure to its limits.
Finally, there is a challenge to video streaming technologies to cope with a
high heterogeneity of end-user devices and dynamically changing network
conditions, in particular in wireless and mobile networks.
  In the present work, our goal is to design an efficient system that supports
a high number of unicast streaming sessions in a dense wireless access network.
We address this goal by jointly considering the two problems of wireless
transmission scheduling and video quality adaptation, using techniques inspired
by the robustness and simplicity of Proportional-Integral-Derivative (PID)
controllers. We show that the control-theoretic approach allows to efficiently
utilize available wireless resources, providing high Quality of Experience
(QoE) to a large number of users.
"
755,A DCT And SVD based Watermarking Technique To Identify Tag,"  With the rapid development of the multimedia,the secure of the multimedia is
get more concerned. as far as we know , Digital watermarking is an effective
way to protect copyright. The watermark must be generally hidden does not
affect the quality of the original image. In this paper,a novel way based on
discrete cosine transform(DCT) and singular value decomposition(SVD) .In the
proposed way,we decomposition the image into 8*8 blocks, next we use the DCT to
get the transformed block,then we choose the diagonal to embed the information,
after we do this, we recover the image and then we decomposition the image to
8*8 blocks,we use the SVD way to get the diagonal matrix and embed the
information in the matrix. next we extract the information use both inverse of
DCT and SVD, as we all know,after we embed the information seconded time , the
information we first information we embed must be changed, we choose a measure
way called Peak Signal to Noise Ratio(PSNR) to estimate the similarity of the
two image, and set a threshold to ensure whether the information is same or
not.
"
756,MAP: Microblogging Assisted Profiling of TV Shows,"  Online microblogging services that have been increasingly used by people to
share and exchange information, have emerged as a promising way to profiling
multimedia contents, in a sense to provide users a socialized abstraction and
understanding of these contents. In this paper, we propose a microblogging
profiling framework, to provide a social demonstration of TV shows. Challenges
for this study lie in two folds: First, TV shows are generally offline, i.e.,
most of them are not originally from the Internet, and we need to create a
connection between these TV shows with online microblogging services; Second,
contents in a microblogging service are extremely noisy for video profiling,
and we need to strategically retrieve the most related information for the TV
show profiling.To address these challenges, we propose a MAP, a
microblogging-assisted profiling framework, with contributions as follows: i)
We propose a joint user and content retrieval scheme, which uses information
about both actors and topics of a TV show to retrieve related microblogs; ii)
We propose a social-aware profiling strategy, which profiles a video according
to not only its content, but also the social relationship of its microblogging
users and its propagation in the social network; iii) We present some
interesting analysis, based on our framework to profile real-world TV shows.
"
757,"A two-stage video coding framework with both self-adaptive redundant
  dictionary and adaptively orthonormalized DCT basis","  In this work, we propose a two-stage video coding framework, as an extension
of our previous one-stage framework in [1]. The two-stage frameworks consists
two different dictionaries. Specifically, the first stage directly finds the
sparse representation of a block with a self-adaptive dictionary consisting of
all possible inter-prediction candidates by solving an L0-norm minimization
problem using an improved orthogonal matching pursuit with embedded
orthonormalization (eOMP) algorithm, and the second stage codes the residual
using DCT dictionary adaptively orthonormalized to the subspace spanned by the
first stage atoms. The transition of the first stage and the second stage is
determined based on both stages' quantization stepsizes and a threshold. We
further propose a complete context adaptive entropy coder to efficiently code
the locations and the coefficients of chosen first stage atoms. Simulation
results show that the proposed coder significantly improves the RD performance
over our previous one-stage coder. More importantly, the two-stage coder, using
a fixed block size and inter-prediction only, outperforms the H.264 coder
(x264) and is competitive with the HEVC reference coder (HM) over a large rate
range.
"
758,"Joint Optimization of Masks and Deep Recurrent Neural Networks for
  Monaural Source Separation","  Monaural source separation is important for many real world applications. It
is challenging because, with only a single channel of information available,
without any constraints, an infinite number of solutions are possible. In this
paper, we explore joint optimization of masking functions and deep recurrent
neural networks for monaural source separation tasks, including monaural speech
separation, monaural singing voice separation, and speech denoising. The joint
optimization of the deep recurrent neural networks with an extra masking layer
enforces a reconstruction constraint. Moreover, we explore a discriminative
criterion for training neural networks to further enhance the separation
performance. We evaluate the proposed system on the TSP, MIR-1K, and TIMIT
datasets for speech separation, singing voice separation, and speech denoising
tasks, respectively. Our approaches achieve 2.30--4.98 dB SDR gain compared to
NMF models in the speech separation task, 2.30--2.48 dB GNSDR gain and
4.32--5.42 dB GSIR gain compared to existing models in the singing voice
separation task, and outperform NMF and DNN baselines in the speech denoising
task.
"
759,"On Crowdsourced Interactive Live Streaming: A Twitch.TV-Based
  Measurement Study","  Empowered by today's rich tools for media generation and collaborative
production, the multimedia service paradigm is shifting from the conventional
single source, to multi-source, to many sources, and now toward {\em
crowdsource}. Such crowdsourced live streaming platforms as Twitch.tv allow
general users to broadcast their content to massive viewers, thereby greatly
expanding the content and user bases. The resources available for these
non-professional broadcasters however are limited and unstable, which
potentially impair the streaming quality and viewers' experience. The diverse
live interactions among the broadcasters and viewers can further aggravate the
problem.
  In this paper, we present an initial investigation on the modern crowdsourced
live streaming systems. Taking Twitch as a representative, we outline their
inside architecture using both crawled data and captured traffic of local
broadcasters/viewers. Closely examining the access data collected in a
two-month period, we reveal that the view patterns are determined by both
events and broadcasters' sources. Our measurements explore the unique source-
and event-driven views, showing that the current delay strategy on the viewer's
side substantially impacts the viewers' interactive experience, and there is
significant disparity between the long broadcast latency and the short live
messaging latency. On the broadcaster's side, the dynamic uploading capacity is
a critical challenge, which noticeably affects the smoothness of live streaming
for viewers.
"
760,Efficient Synthesis of Room Acoustics via Scattering Delay Networks,"  An acoustic reverberator consisting of a network of delay lines connected via
scattering junctions is proposed. All parameters of the reverberator are
derived from physical properties of the enclosure it simulates. It allows for
simulation of unequal and frequency-dependent wall absorption, as well as
directional sources and microphones. The reverberator renders the first-order
reflections exactly, while making progressively coarser approximations of
higher-order reflections. The rate of energy decay is close to that obtained
with the image method (IM) and consistent with the predictions of Sabine and
Eyring equations. The time evolution of the normalized echo density, which was
previously shown to be correlated with the perceived texture of reverberation,
is also close to that of IM. However, its computational complexity is one to
two orders of magnitude lower, comparable to the computational complexity of a
feedback delay network (FDN), and its memory requirements are negligible.
"
761,"Evaluating QoS Parameters for IPTV Distribution in Heterogeneous
  Networks","  The present work presents an architecture developed to evaluate the QoS
parameters for the IPTV heterogeneous network. At its very basic level lie two
software technologies: Video LAN and Windows Media Services with two operating
systems: Windows and Linux. Three types of streams are analyzed, which will be
transmitted to a Linux VLC client through means of the aggregation and access
servers. The first stream is generated in real time by a capture camera,
processed by the encapsulated VC-1 encoder and sent to the Media Server, while
the second one is of VoD(Video on Demand) type and the third one will be
handled by DVBViewer through the MPEG TS form. The first stream is transcoded
in H.264-AAC such that the Linux stations will recognize its format. Through
the simultaneous transmission of the three streams, we are analyzing their
performance from a QoS parameters point of view by means of an application
implemented in C programming language. The stream transporting the DVB-S
television content was proven to ensure the best performance regarding loss of
packets, delays and jitter.
"
762,"Intra-and-Inter-Constraint-based Video Enhancement based on Piecewise
  Tone Mapping","  Video enhancement plays an important role in various video applications. In
this paper, we propose a new intra-and-inter-constraint-based video enhancement
approach aiming to 1) achieve high intra-frame quality of the entire picture
where multiple region-of-interests (ROIs) can be adaptively and simultaneously
enhanced, and 2) guarantee the inter-frame quality consistencies among video
frames. We first analyze features from different ROIs and create a piecewise
tone mapping curve for the entire frame such that the intra-frame quality of a
frame can be enhanced. We further introduce new inter-frame constraints to
improve the temporal quality consistency. Experimental results show that the
proposed algorithm obviously outperforms the state-of-the-art algorithms.
"
763,Compressive sensing based velocity estimation in video data,"  This paper considers the use of compressive sensing based algorithms for
velocity estimation of moving vehicles. The procedure is based on sparse
reconstruction algorithms combined with time-frequency analysis applied to
video data. This algorithm provides an accurate estimation of object's velocity
even in the case of a very reduced number of available video frames. The
influence of crucial parameters is analysed for different types of moving
vehicles.
"
764,Crowdsourced Live Streaming over the Cloud,"  Empowered by today's rich tools for media generation and distribution, and
the convenient Internet access, crowdsourced streaming generalizes the
single-source streaming paradigm by including massive contributors for a video
channel. It calls a joint optimization along the path from crowdsourcers,
through streaming servers, to the end-users to minimize the overall latency.
The dynamics of the video sources, together with the globalized request demands
and the high computation demand from each sourcer, make crowdsourced live
streaming challenging even with powerful support from modern cloud computing.
In this paper, we present a generic framework that facilitates a cost-effective
cloud service for crowdsourced live streaming. Through adaptively leasing, the
cloud servers can be provisioned in a fine granularity to accommodate
geo-distributed video crowdsourcers. We present an optimal solution to deal
with service migration among cloud instances of diverse lease prices. It also
addresses the location impact to the streaming quality. To understand the
performance of the proposed strategies in the realworld, we have built a
prototype system running over the planetlab and the Amazon/Microsoft Cloud. Our
extensive experiments demonstrate that the effectiveness of our solution in
terms of deployment cost and streaming quality.
"
765,"Exploiting Feature and Class Relationships in Video Categorization with
  Regularized Deep Neural Networks","  In this paper, we study the challenging problem of categorizing videos
according to high-level semantics such as the existence of a particular human
action or a complex event. Although extensive efforts have been devoted in
recent years, most existing works combined multiple video features using simple
fusion strategies and neglected the utilization of inter-class semantic
relationships. This paper proposes a novel unified framework that jointly
exploits the feature relationships and the class relationships for improved
categorization performance. Specifically, these two types of relationships are
estimated and utilized by rigorously imposing regularizations in the learning
process of a deep neural network (DNN). Such a regularized DNN (rDNN) can be
efficiently realized using a GPU-based implementation with an affordable
training cost. Through arming the DNN with better capability of harnessing both
the feature and the class relationships, the proposed rDNN is more suitable for
modeling video semantics. With extensive experimental evaluations, we show that
rDNN produces superior performance over several state-of-the-art approaches. On
the well-known Hollywood2 and Columbia Consumer Video benchmarks, we obtain
very competitive results: 66.9\% and 73.5\% respectively in terms of mean
average precision. In addition, to substantially evaluate our rDNN and
stimulate future research on large scale video categorization, we collect and
release a new benchmark dataset, called FCVID, which contains 91,223 Internet
videos and 239 manually annotated categories.
"
766,"A Secure Cyclic Steganographic Technique for Color Images using
  Randomization","  Information Security is a major concern in today's modern era. Almost all the
communicating bodies want the security, confidentiality and integrity of their
personal data. But this security goal cannot be achieved easily when we are
using an open network like Internet. Steganography provides one of the best
solutions to this problem. This paper represents a new Cyclic Steganographic T
echnique (CST) based on Least Significant Bit (LSB) for true color (RGB)
images. The proposed method hides the secret data in the LSBs of cover image
pixels in a randomized cyclic manner. The proposed technique is evaluated using
both subjective and objective analysis using histograms changeability, Peak
Signal-to-Noise Ratio (PSNR) and Mean Square Error (MSE). Experimentally it is
found that the proposed method gives promising results in terms of security,
imperceptibility and robustness as compared to some existent methods and
vindicates this new algorithm.
"
767,Hybrid coding of visual content and local image features,"  Distributed visual analysis applications, such as mobile visual search or
Visual Sensor Networks (VSNs) require the transmission of visual content on a
bandwidth-limited network, from a peripheral node to a processing unit.
Traditionally, a Compress-Then-Analyze approach has been pursued, in which
sensing nodes acquire and encode the pixel-level representation of the visual
content, that is subsequently transmitted to a sink node in order to be
processed. This approach might not represent the most effective solution, since
several analysis applications leverage a compact representation of the content,
thus resulting in an inefficient usage of network resources. Furthermore,
coding artifacts might significantly impact the accuracy of the visual task at
hand. To tackle such limitations, an orthogonal approach named
Analyze-Then-Compress has been proposed. According to such a paradigm, sensing
nodes are responsible for the extraction of visual features, that are encoded
and transmitted to a sink node for further processing. In spite of improved
task efficiency, such paradigm implies the central processing node not being
able to reconstruct a pixel-level representation of the visual content. In this
paper we propose an effective compromise between the two paradigms, namely
Hybrid-Analyze-Then-Compress (HATC) that aims at jointly encoding visual
content and local image features. Furthermore, we show how a target tradeoff
between image quality and task accuracy might be achieved by accurately
allocating the bitrate to either visual content or local features.
"
768,"Coding local and global binary visual features extracted from video
  sequences","  Binary local features represent an effective alternative to real-valued
descriptors, leading to comparable results for many visual analysis tasks,
while being characterized by significantly lower computational complexity and
memory requirements. When dealing with large collections, a more compact
representation based on global features is often preferred, which can be
obtained from local features by means of, e.g., the Bag-of-Visual-Word (BoVW)
model. Several applications, including for example visual sensor networks and
mobile augmented reality, require visual features to be transmitted over a
bandwidth-limited network, thus calling for coding techniques that aim at
reducing the required bit budget, while attaining a target level of efficiency.
In this paper we investigate a coding scheme tailored to both local and global
binary features, which aims at exploiting both spatial and temporal redundancy
by means of intra- and inter-frame coding. In this respect, the proposed coding
scheme can be conveniently adopted to support the Analyze-Then-Compress (ATC)
paradigm. That is, visual features are extracted from the acquired content,
encoded at remote nodes, and finally transmitted to a central controller that
performs visual analysis. This is in contrast with the traditional approach, in
which visual content is acquired at a node, compressed and then sent to a
central unit for further processing, according to the Compress-Then-Analyze
(CTA) paradigm. In this paper we experimentally compare ATC and CTA by means of
rate-efficiency curves in the context of two different visual analysis tasks:
homography estimation and content-based retrieval. Our results show that the
novel ATC paradigm based on the proposed coding primitives can be competitive
with CTA, especially in bandwidth limited scenarios.
"
769,"Plagiarism Detection in Polyphonic Music using Monaural Signal
  Separation","  Given the large number of new musical tracks released each year, automated
approaches to plagiarism detection are essential to help us track potential
violations of copyright. Most current approaches to plagiarism detection are
based on musical similarity measures, which typically ignore the issue of
polyphony in music. We present a novel feature space for audio derived from
compositional modelling techniques, commonly used in signal separation, that
provides a mechanism to account for polyphony without incurring an inordinate
amount of computational overhead. We employ this feature representation in
conjunction with traditional audio feature representations in a classification
framework which uses an ensemble of distance features to characterize pairs of
songs as being plagiarized or not. Our experiments on a database of about 3000
musical track pairs show that the new feature space characterization produces
significant improvements over standard baselines.
"
770,"Activity Recognition Using A Combination of Category Components And
  Local Models for Video Surveillance","  This paper presents a novel approach for automatic recognition of human
activities for video surveillance applications. We propose to represent an
activity by a combination of category components, and demonstrate that this
approach offers flexibility to add new activities to the system and an ability
to deal with the problem of building models for activities lacking training
data. For improving the recognition accuracy, a Confident-Frame- based
Recognition algorithm is also proposed, where the video frames with high
confidence for recognizing an activity are used as a specialized local model to
help classify the remainder of the video frames. Experimental results show the
effectiveness of the proposed approach.
"
771,"Group Event Detection with a Varying Number of Group Members for Video
  Surveillance","  This paper presents a novel approach for automatic recognition of group
activities for video surveillance applications. We propose to use a group
representative to handle the recognition with a varying number of group
members, and use an Asynchronous Hidden Markov Model (AHMM) to model the
relationship between people. Furthermore, we propose a group activity detection
algorithm which can handle both symmetric and asymmetric group activities, and
demonstrate that this approach enables the detection of hierarchical
interactions between people. Experimental results show the effectiveness of our
approach.
"
772,"A Computation Control Motion Estimation Method for Complexity-Scalable
  Video Coding","  In this paper, a new Computation-Control Motion Estimation (CCME) method is
proposed which can perform Motion Estimation (ME) adaptively under different
computation or power budgets while keeping high coding performance. We first
propose a new class-based method to measure the Macroblock (MB) importance
where MBs are classified into different classes and their importance is
measured by combining their class information as well as their initial matching
cost information. Based on the new MB importance measure, a complete CCME
framework is then proposed to allocate computation for ME. The proposed method
performs ME in a one-pass flow. Experimental results demonstrate that the
proposed method can allocate computation more accurately than previous methods
and thus has better performance under the same computation budget.
"
773,A Fast Sub-Pixel Motion Estimation Algorithm for H.264/AVC Video Coding,"  Motion Estimation (ME) is one of the most time-consuming parts in video
coding. The use of multiple partition sizes in H.264/AVC makes it even more
complicated when compared to ME in conventional video coding standards. It is
important to develop fast and effective sub-pixel ME algorithms since (a) The
computation overhead by sub-pixel ME has become relatively significant while
the complexity of integer-pixel search has been greatly reduced by fast
algorithms, and (b) Reducing sub-pixel search points can greatly save the
computation for sub-pixel interpolation. In this paper, a novel fast sub-pixel
ME algorithm is proposed which performs a 'rough' sub-pixel search before the
partition selection, and performs a 'precise' sub-pixel search for the best
partition. By reducing the searching load for the large number of non-best
partitions, the computation complexity for sub-pixel search can be greatly
decreased. Experimental results show that our method can reduce the sub-pixel
search points by more than 50% compared to existing fast sub-pixel ME methods
with negligible quality degradation.
"
774,"Macroblock Classification Method for Video Applications Involving
  Motions","  In this paper, a macroblock classification method is proposed for various
video processing applications involving motions. Based on the analysis of the
Motion Vector field in the compressed video, we propose to classify Macroblocks
of each video frame into different classes and use this class information to
describe the frame content. We demonstrate that this low-computation-complexity
method can efficiently catch the characteristics of the frame. Based on the
proposed macroblock classification, we further propose algorithms for different
video processing applications, including shot change detection, motion
discontinuity detection, and outlier rejection for global motion estimation.
Experimental results demonstrate that the methods based on the proposed
approach can work effectively on these applications.
"
775,Facial Expression Cloning with Elastic and Muscle Models,"  Expression cloning plays an important role in facial expression synthesis. In
this paper, a novel algorithm is proposed for facial expression cloning. The
proposed algorithm first introduces a new elastic model to balance the global
and local warping effects, such that the impacts from facial feature diversity
among people can be minimized, and thus more effective geometric warping
results can be achieved. Furthermore, a muscle-distribution-based (MD) model is
proposed, which utilizes the muscle distribution of the human face and results
in more accurate facial illumination details. In addition, we also propose a
new distance-based metric to automatically select the optimal parameters such
that the global and local warping effects in the elastic model can be suitably
balanced. Experimental results show that our proposed algorithm outperforms the
existing methods.
"
776,"An Efficient Coding Method for Coding Region-of-Interest Locations in
  AVS2","  Region-of-Interest (ROI) location information in videos has many practical
usages in video coding field, such as video content analysis and user
experience improvement. Although ROI-based coding has been studied widely by
many researchers to improve coding efficiency for video contents, the ROI
location information itself is seldom coded in video bitstream. In this paper,
we will introduce our proposed ROI location coding tool which has been adopted
in surveillance profile of AVS2 video coding standard (surveillance profile).
Our tool includes three schemes: direct-coding scheme, differential- coding
scheme, and reconstructed-coding scheme. We will illustrate the details of
these schemes, and perform analysis of their advantages and disadvantages,
respectively.
"
777,Region-Based Rate-Control for H.264/AVC for Low Bit-Rate Applications,"  Rate-control plays an important role in video coding. However, in the
conventional rate-control algorithms, the number and position of Macroblocks
(MBs) inside one basic unit for rate-control is inflexible and predetermined.
The different characteristics of the MBs are not fully considered. Also, there
is no overall optimization of the coding of basic units. This paper proposes a
new region-based rate-control scheme for H.264/AVC to improve the coding
efficiency. The inter-frame information is explored to objectively divide one
frame into multiple regions based on their rate-distortion behaviors. The MBs
with the similar characteristics are classified into the same region, and the
entire region instead of a single MB or a group of contiguous MBs is treated as
a basic unit for rate-control. A linear rate-quantization stepsize model and a
linear distortion-quantization stepsize model are proposed to accurately
describe the rate-distortion characteristics for the region-based basic units.
Moreover, based on the above linear models, an overall optimization model is
proposed to obtain suitable Quantization Parameters (QPs) for the region-based
basic units. Experimental results demonstrate that the proposed region-based
rate-control approach can achieve both better subjective and objective quality
by performing the rate-control adaptively with the content, compared to the
conventional rate-control approaches.
"
778,"Novel Metaknowledge-based Processing Technique for Multimedia Big Data
  clustering challenges","  Past research has challenged us with the task of showing relational patterns
between text-based data and then clustering for predictive analysis using Golay
Code technique. We focus on a novel approach to extract metaknowledge in
multimedia datasets. Our collaboration has been an on-going task of studying
the relational patterns between datapoints based on metafeatures extracted from
metaknowledge in multimedia datasets. Those selected are significant to suit
the mining technique we applied, Golay Code algorithm. In this research paper
we summarize findings in optimization of metaknowledge representation for
23-bit representation of structured and unstructured multimedia data in order
to
"
779,"A Novel Image Steganographic Approach for Hiding Text in Color Images
  using HSI Color Model","  Image Steganography is the process of embedding text in images such that its
existence cannot be detected by Human Visual System (HVS) and is known only to
sender and receiver. This paper presents a novel approach for image
steganography using Hue-Saturation-Intensity (HSI) color space based on Least
Significant Bit (LSB). The proposed method transforms the image from RGB color
space to Hue-Saturation-Intensity (HSI) color space and then embeds secret data
inside the Intensity Plane (I-Plane) and transforms it back to RGB color model
after embedding. The said technique is evaluated by both subjective and
Objective Analysis. Experimentally it is found that the proposed method have
larger Peak Signal-to Noise Ratio (PSNR) values, good imperceptibility and
multiple security levels which shows its superiority as compared to several
existing methods
"
780,A Survey On Video Forgery Detection,"  The Digital Forgeries though not visibly identifiable to human perception it
may alter or meddle with underlying natural statistics of digital content.
Tampering involves fiddling with video content in order to cause damage or make
unauthorized alteration/modification. Tampering detection in video is
cumbersome compared to image when considering the properties of the video.
Tampering impacts need to be studied and the applied technique/method is used
to establish the factual information for legal course in judiciary. In this
paper we give an overview of the prior literature and challenges involved in
video forgery detection where passive approach is found.
"
781,Gaussian Mixture Model Based Contrast Enhancement,"  In this paper, a method for enhancing low contrast images is proposed. This
method, called Gaussian Mixture Model based Contrast Enhancement (GMMCE),
brings into play the Gaussian mixture modeling of histograms to model the
content of the images. Based on the fact that each homogeneous area in natural
images has a Gaussian-shaped histogram, it decomposes the narrow histogram of
low contrast images into a set of scaled and shifted Gaussians. The individual
histograms are then stretched by increasing their variance parameters, and are
diffused on the entire histogram by scattering their mean parameters, to build
a broad version of the histogram. The number of Gaussians as well as their
parameters are optimized to set up a GMM with lowest approximation error and
highest similarity to the original histogram. Compared to the existing
histogram-based methods, the experimental results show that the quality of
GMMCE enhanced pictures are mostly consistent and outperform other benchmark
methods. Additionally, the computational complexity analysis show that GMMCE is
a low complexity method.
"
782,YFCC100M: The New Data in Multimedia Research,"  We present the Yahoo Flickr Creative Commons 100 Million Dataset (YFCC100M),
the largest public multimedia collection that has ever been released. The
dataset contains a total of 100 million media objects, of which approximately
99.2 million are photos and 0.8 million are videos, all of which carry a
Creative Commons license. Each media object in the dataset is represented by
several pieces of metadata, e.g. Flickr identifier, owner name, camera, title,
tags, geo, media source. The collection provides a comprehensive snapshot of
how photos and videos were taken, described, and shared over the years, from
the inception of Flickr in 2004 until early 2014. In this article we explain
the rationale behind its creation, as well as the implications the dataset has
for science, research, engineering, and development. We further present several
new challenges in multimedia research that can now be expanded upon with our
dataset.
"
783,Reliable SVD based Semi-blind and Invisible Watermarking Schemes,"  A semi-blind watermarking scheme is presented based on Singular Value
Decomposition (SVD), which makes essential use of the fact that, the SVD
subspace preserves significant amount of information of an image and is a one
way decomposition. The principal components are used, along with the
corresponding singular vectors of the watermark image to watermark the target
image. For further security, the semi-blind scheme is extended to an invisible
hash based watermarking scheme. The hash based scheme commits a watermark with
a key such that, it is incoherent with the actual watermark, and can only be
extracted using the key. Its security is analyzed in the random oracle model
and shown to be unforgeable, invisible and satisfying the property of
non-repudiation.
"
784,"Low-Delay Adaptive Video Streaming Based on Short-Term TCP Throughput
  Prediction","  Recently, HTTP-Based Adaptive Streaming has become the de facto standard for
video streaming over the Internet. It allows the client to adapt media
characteristics to varying network conditions in order to maximize Quality of
Experience (QoE). In the case of live streaming this task becomes particularly
challenging. An important factor than might help improving performance is the
capability to correctly predict network throughput dynamics on short to medium
timescales. It becomes notably difficult in wireless networks that are often
subject to continuous throughput fluctuations.
  In the present work, we develop an adaptation algorithm for HTTP-Based
Adaptive Live Streaming that, for each adaptation decision, maximizes a
QoE-based utility function depending on the probability of playback
interruptions, average video quality, and the amount of video quality
fluctuations. To compute the utility function the algorithm leverages
throughput predictions, and dynamically estimated prediction accuracy.
  We are trying to close the gap created by the lack of studies analyzing TCP
throughput on short to medium timescales. We study several time series
prediction methods and their error distributions. We observe that Simple Moving
Average performs best in most cases. We also observe that the relative
underestimation error is best represented by a truncated normal distribution,
while the relative overestimation error is best represented by a Lomax
distribution. Moreover, underestimations and overestimations exhibit a temporal
correlation that we use to further improve prediction accuracy.
  We compare the proposed algorithm with a baseline approach that uses a fixed
margin between past throughput and selected media bit rate, and an oracle-based
approach that has perfect knowledge over future throughput for a certain time
horizon.
"
785,"A novel hash based least significant bit (2-3-3) image steganography in
  spatial domain","  This paper presents a novel 2-3-3 LSB insertion method. The image
steganography takes the advantage of human eye limitation. It uses color image
as cover media for embedding secret message.The important quality of a
steganographic system is to be less distortive while increasing the size of the
secret message. In this paper a method is proposed to embed a color secret
image into a color cover image. A 2-3-3 LSB insertion method has been used for
image steganography. Experimental results show an improvement in the Mean
squared error (MSE) and Peak Signal to Noise Ratio (PSNR) values of the
proposed technique over the base technique of hash based 3-3-2 LSB insertion.
"
786,Fusing Text and Image for Event Detection in Twitter,"  In this contribution, we develop an accurate and effective event detection
method to detect events from a Twitter stream, which uses visual and textual
information to improve the performance of the mining process. The method
monitors a Twitter stream to pick up tweets having texts and images and stores
them into a database. This is followed by applying a mining algorithm to detect
an event. The procedure starts with detecting events based on text only by
using the feature of the bag-of-words which is calculated using the term
frequency-inverse document frequency (TF-IDF) method. Then it detects the event
based on image only by using visual features including histogram of oriented
gradients (HOG) descriptors, grey-level cooccurrence matrix (GLCM), and color
histogram. K nearest neighbours (Knn) classification is used in the detection.
The final decision of the event detection is made based on the reliabilities of
text only detection and image only detection. The experiment result showed that
the proposed method achieved high accuracy of 0.94, comparing with 0.89 with
texts only, and 0.86 with images only.
"
787,"The YLI-MED Corpus: Characteristics, Procedures, and Plans","  The YLI Multimedia Event Detection corpus is a public-domain index of videos
with annotations and computed features, specialized for research in multimedia
event detection (MED), i.e., automatically identifying what's happening in a
video by analyzing the audio and visual content. The videos indexed in the
YLI-MED corpus are a subset of the larger YLI feature corpus, which is being
developed by the International Computer Science Institute and Lawrence
Livermore National Laboratory based on the Yahoo Flickr Creative Commons 100
Million (YFCC100M) dataset. The videos in YLI-MED are categorized as depicting
one of ten target events, or no target event, and are annotated for additional
attributes like language spoken and whether the video has a musical score. The
annotations also include degree of annotator agreement and average annotator
confidence scores for the event categorization of each video. Version 1.0 of
YLI-MED includes 1823 ""positive"" videos that depict the target events and
48,138 ""negative"" videos, as well as 177 supplementary videos that are similar
to event videos but are not positive examples. Our goal in producing YLI-MED is
to be as open about our data and procedures as possible. This report describes
the procedures used to collect the corpus; gives detailed descriptive
statistics about the corpus makeup (and how video attributes affected
annotators' judgments); discusses possible biases in the corpus introduced by
our procedural choices and compares it with the most similar existing dataset,
TRECVID MED's HAVIC corpus; and gives an overview of our future plans for
expanding the annotation effort.
"
788,User Centric Content Management System for Open IPTV Over SNS (ICTC2012),"  Coupled schemes between service-oriented architecture (SOA) and Web 2.0 have
recently been researched. Web-based content providers and telecommunications
company (Telecom) based Internet protocol television (IPTV) providers have
struggled against each other to accommodate more three-screen service
subscribers. Since the advent of Web 2.0, more abundant reproduced content can
be circulated. However, because according to increasing device's resolution and
content formats IPTV providers transcode content in advance, network bandwidth,
storage and operation costs for content management systems (CMSs) are wasted.
In this paper, we present a user centric CMS for open IPTV, which integrates
SOA and Web 2.0. Considering content popularity based on a Zipf-like
distribution to solve these problems, we analyze the performance between the
user centric CMS and the conventional Web syndication system for normalized
costs. Based on the user centric CMS, we implement a social Web TV with
device-aware function, which can aggregate, transcode, and deploy content over
social networking service (SNS) independently.
"
789,Image Watermaking With Biometric Data For Copyright Protection,"  In this paper, we deal with the proof of ownership or legitimate usage of a
digital content, such as an image, in order to tackle the illegitimate copy.
The proposed scheme based on the combination of the watermark-ing and
cancelable biometrics does not require a trusted third party, all the exchanges
are between the provider and the customer. The use of cancelable biometrics
permits to provide a privacy compliant proof of identity. We illustrate the
robustness of this method against intentional and unintentional attacks of the
watermarked content.
"
790,Identification of Image Operations Based on Steganalytic Features,"  Image forensics have attracted wide attention during the past decade. Though
many forensic methods have been proposed to identify image forgeries, most of
them are targeted ones, since their proposed features are highly dependent on
the image operation under investigation. The performance of the well-designed
features for detecting the targeted operation usually degrades significantly
for other operations. On the other hand, a wise attacker can perform
anti-forensics to fool the existing forensic methods, making countering
anti-forensics become an urgent need. In this paper, we try to find a universal
feature to detect various image processing and anti-forensic operations. Based
on our extensive experiments and analysis, we find that any image
processing/anti-forensic operations would inevitably modify many image pixels.
This would change some inherent statistics within original images, which is
similar to the case of steganography. Therefore, we model image
processing/anti-forensic operations as steganography problems, and propose a
detection strategy by applying steganalytic features. With some advanced
steganalytic features, we are able to detect various image operations and
further identify their types. In our experiments, we have tested several
steganalytic features on 11 different kinds of typical image processing
operations and 4 kinds of anti-forensic operations. The experimental results
have shown that the proposed strategy significantly outperforms the existing
forensic methods in both effectiveness and universality.
"
791,"The blind detection for palette image watermarking without changing the
  color","  To hide a binary pattern in the palette image a steganographic scheme with
blind detection is considered. The embedding algorithm uses the Lehmer code by
palette color permutations for which the cover image palette is generally
required. The found transformation between the palette and RGB images allows to
extract the hidden data without any cover work.
"
792,Video Inpainting of Complex Scenes,"  We propose an automatic video inpainting algorithm which relies on the
optimisation of a global, patch-based functional. Our algorithm is able to deal
with a variety of challenging situations which naturally arise in video
inpainting, such as the correct reconstruction of dynamic textures, multiple
moving objects and moving background. Furthermore, we achieve this in an order
of magnitude less execution time with respect to the state-of-the-art. We are
also able to achieve good quality results on high definition videos. Finally,
we provide specific algorithmic details to make implementation of our algorithm
as easy as possible. The resulting algorithm requires no segmentation or manual
input other than the definition of the inpainting mask, and can deal with a
wider variety of situations than is handled by previous work. 1. Introduction.
Advanced image and video editing techniques are increasingly common in the
image processing and computer vision world, and are also starting to be used in
media entertainment. One common and difficult task closely linked to the world
of video editing is image and video "" inpainting "". Generally speaking, this is
the task of replacing the content of an image or video with some other content
which is visually pleasing. This subject has been extensively studied in the
case of images, to such an extent that commercial image inpainting products
destined for the general public are available, such as Photoshop's "" Content
Aware fill "" [1]. However, while some impressive results have been obtained in
the case of videos, the subject has been studied far less extensively than
image inpainting. This relative lack of research can largely be attributed to
high time complexity due to the added temporal dimension. Indeed, it has only
very recently become possible to produce good quality inpainting results on
high definition videos, and this only in a semi-automatic manner. Nevertheless,
high-quality video inpainting has many important and useful applications such
as film restoration, professional post-production in cinema and video editing
for personal use. For this reason, we believe that an automatic, generic video
inpainting algorithm would be extremely useful for both academic and
professional communities.
"
793,Fast keypoint detection in video sequences,"  A number of computer vision tasks exploit a succinct representation of the
visual content in the form of sets of local features. Given an input image,
feature extraction algorithms identify a set of keypoints and assign to each of
them a description vector, based on the characteristics of the visual content
surrounding the interest point. Several tasks might require local features to
be extracted from a video sequence, on a frame-by-frame basis. Although
temporal downsampling has been proven to be an effective solution for mobile
augmented reality and visual search, high temporal resolution is a key
requirement for time-critical applications such as object tracking, event
recognition, pedestrian detection, surveillance. In recent years, more and more
computationally efficient visual feature detectors and decriptors have been
proposed. Nonetheless, such approaches are tailored to still images. In this
paper we propose a fast keypoint detection algorithm for video sequences, that
exploits the temporal coherence of the sequence of keypoints. According to the
proposed method, each frame is preprocessed so as to identify the parts of the
input frame for which keypoint detection and description need to be performed.
Our experiments show that it is possible to achieve a reduction in
computational time of up to 40%, without significantly affecting the task
accuracy.
"
794,A Low-throughput Wavelet-based Steganography Audio Scheme,"  This paper presents the preliminary of a novel scheme of steganography, and
introduces the idea of combining two secret keys in the operation. The first
secret key encrypts the text using a standard cryptographic scheme (e.g. IDEA,
SAFER+, etc.) prior to the wavelet audio decomposition. The way in which the
cipher text is embedded in the file requires another key, namely a stego-key,
which is associated with features of the audio wavelet analysis.
"
795,"Socializing the Semantic Gap: A Comparative Survey on Image Tag
  Assignment, Refinement and Retrieval","  Where previous reviews on content-based image retrieval emphasize on what can
be seen in an image to bridge the semantic gap, this survey considers what
people tag about an image. A comprehensive treatise of three closely linked
problems, i.e., image tag assignment, refinement, and tag-based image retrieval
is presented. While existing works vary in terms of their targeted tasks and
methodology, they rely on the key functionality of tag relevance, i.e.
estimating the relevance of a specific tag with respect to the visual content
of a given image and its social context. By analyzing what information a
specific method exploits to construct its tag relevance function and how such
information is exploited, this paper introduces a taxonomy to structure the
growing literature, understand the ingredients of the main works, clarify their
connections and difference, and recognize their merits and limitations. For a
head-to-head comparison between the state-of-the-art, a new experimental
protocol is presented, with training sets containing 10k, 100k and 1m images
and an evaluation on three test sets, contributed by various research groups.
Eleven representative works are implemented and evaluated. Putting all this
together, the survey aims to provide an overview of the past and foster
progress for the near future.
"
796,"Error-Resilient Multicasting for Multi-View 3D Videos in Wireless
  Networks","  With the emergence of naked-eye 3D mobile devices, mobile 3D video services
are becoming increasingly important for video service providers, such as
Youtube and Netflix, while multi-view 3D videos have the potential to inspire a
variety of innovative applications. However, enabling multi-view 3D video
services may overwhelm WiFi networks when every view of a video are
multicasted. In this paper, therefore, we propose to incorporate
depth-image-based rendering (DIBR), which allows each mobile client to
synthesize the desired view from nearby left and right views, in order to
effectively reduce the bandwidth consumption. Moreover, when each client
suffers from packet losses, retransmissions incur additional bandwidth
consumption and excess delay, which in turn undermines the quality of
experience in video applications. To address the above issue, we first discover
the merit of view protection via DIBR for multi-view video multicast using a
mathematical analysis and then design a new protocol, named Multi-View Group
Management Protocol (MVGMP), to support the dynamic join and leave of users and
the change of desired views. The simulation results demonstrate that our
protocol effectively reduces bandwidth consumption and increases the
probability for each client to successfully playback the desired views in a
multi-view 3D video.
"
797,"Temporal Localization of Fine-Grained Actions in Videos by Domain
  Transfer from Web Images","  We address the problem of fine-grained action localization from temporally
untrimmed web videos. We assume that only weak video-level annotations are
available for training. The goal is to use these weak labels to identify
temporal segments corresponding to the actions, and learn models that
generalize to unconstrained web videos. We find that web images queried by
action names serve as well-localized highlights for many actions, but are
noisily labeled. To solve this problem, we propose a simple yet effective
method that takes weak video labels and noisy image labels as input, and
generates localized action frames as output. This is achieved by cross-domain
transfer between video frames and web images, using pre-trained deep
convolutional neural networks. We then use the localized action frames to train
action recognition models with long short-term memory networks. We collect a
fine-grained sports action data set FGA-240 of more than 130,000 YouTube
videos. It has 240 fine-grained actions under 85 sports activities. Convincing
results are shown on the FGA-240 data set, as well as the THUMOS 2014
localization data set with untrimmed training videos.
"
798,"Preprint A Game Based Assistive Tool for Rehabilitation of Dysphonic
  Patients","  This is the preprint version of our paper on 3rd International Workshop on
Virtual and Augmented Assistive Technology (VAAT) at IEEE Virtual Reality 2015
(VR2015). An assistive training tool for rehabilitation of dysphonic patients
is designed and developed according to the practical clinical needs. The
assistive tool employs a space flight game as the attractive logic part, and
microphone arrays as input device, which is getting rid of ambient noise by
setting a specific orientation. The therapist can guide the patient to play the
game as well as the voice training simultaneously side by side, while not
interfere the patient voice. The voice information can be recorded and
extracted for evaluating the long-time rehabilitation progress. This paper
outlines a design science approach for the development of an initial useful
software prototype of such a tool, considering 'Intuitive', 'Entertainment',
'Incentive' as main design factors.
"
799,"Improvement of the image quality of random phase--free holography using
  an iterative method","  Our proposed method of random phase-free holography using virtual convergence
light can obtain large reconstructed images exceeding the size of the hologram,
without the assistance of random phase. The reconstructed images have
low-speckle noise in the amplitude and phase-only holograms (kinoforms);
however, in low-resolution holograms, we obtain a degraded image quality
compared to the original image. We propose an iterative random phase-free
method with virtual convergence light to address this problem.
"
800,"Modeling Spatial-Temporal Clues in a Hybrid Deep Learning Framework for
  Video Classification","  Classifying videos according to content semantics is an important problem
with a wide range of applications. In this paper, we propose a hybrid deep
learning framework for video classification, which is able to model static
spatial information, short-term motion, as well as long-term temporal clues in
the videos. Specifically, the spatial and the short-term motion features are
extracted separately by two Convolutional Neural Networks (CNN). These two
types of CNN-based features are then combined in a regularized feature fusion
network for classification, which is able to learn and utilize feature
relationships for improved performance. In addition, Long Short Term Memory
(LSTM) networks are applied on top of the two features to further model
longer-term temporal clues. The main contribution of this work is the hybrid
learning framework that can model several important aspects of the video data.
We also show that (1) combining the spatial and the short-term motion features
in the regularized fusion network is better than direct classification and
fusion using the CNN with a softmax layer, and (2) the sequence-based LSTM is
highly complementary to the traditional classification strategy without
considering the temporal frame orders. Extensive experiments are conducted on
two popular and challenging benchmarks, the UCF-101 Human Actions and the
Columbia Consumer Videos (CCV). On both benchmarks, our framework achieves
to-date the best reported performance: $91.3\%$ on the UCF-101 and $83.5\%$ on
the CCV.
"
801,Video Contents Prior Storing Server for Optical Access Network,"  One of the most important multimedia applications is Internet protocol TV
(IPTV) for next-generation networks. IPTV provides triple-play services that
require high-speed access networks with the functions of multicasting and
quality of service (QoS) guarantees. Among optical access networks, Ethernet
passive optical networks (EPONs) are regarded as among the best solutions to
meet higher bandwidth demands. In this paper, we propose a new architecture for
multicasting live IPTV traffic in optical access network. The proposed
mechanism involves assigning a unique logical link identifier to each IPTV
channel. To manage multicasting, a prior storing server in the optical line
terminal (OLT) and in each optical network unit (ONU) is constructed. In this
work, we propose a partial prior storing strategy that considers the changes in
the popularity of the video content segments over time and the access patterns
of the users to compute the utility of the objects in the prior storage. We
also propose to partition the prior storage to avoid the eviction of the
popular objects (those not accessed frequently) by the unpopular ones which are
accessed with higher frequency. The popularity distribution and ageing of
popularity are measured from two online datasets and use the parameters in
simulations. Simulation results show that our proposed architecture can improve
the system performance and QoS parameters in terms of packet delay, jitter and
packet loss.
"
802,"Exploring Cyberbullying and Other Toxic Behavior in Team Competition
  Online Games","  In this work we explore cyberbullying and other toxic behavior in team
competition online games. Using a dataset of over 10 million player reports on
1.46 million toxic players along with corresponding crowdsourced decisions, we
test several hypotheses drawn from theories explaining toxic behavior. Besides
providing large-scale, empirical based understanding of toxic behavior, our
work can be used as a basis for building systems to detect, prevent, and
counter-act toxic behavior.
"
803,"A Picture Tells a Thousand Words -- About You! User Interest Profiling
  from User Generated Visual Content","  Inference of online social network users' attributes and interests has been
an active research topic. Accurate identification of users' attributes and
interests is crucial for improving the performance of personalization and
recommender systems. Most of the existing works have focused on textual content
generated by the users and have successfully used it for predicting users'
interests and other identifying attributes. However, little attention has been
paid to user generated visual content (images) that is becoming increasingly
popular and pervasive in recent times. We posit that images posted by users on
online social networks are a reflection of topics they are interested in and
propose an approach to infer user attributes from images posted by them. We
analyze the content of individual images and then aggregate the image-level
knowledge to infer user-level interest distribution. We employ image-level
similarity to propagate the label information between images, as well as
utilize the image category information derived from the user created
organization structure to further propagate the category-level knowledge for
all images. A real life social network dataset created from Pinterest is used
for evaluation and the experimental results demonstrate the effectiveness of
our proposed approach.
"
804,On the Security of a Revised Fragile Watermarking Scheme,"  This paper analyzes a revised fragile watermarking scheme proposed by Botta
et al. which was developed as a revision of the watermarking scheme previously
proposed by Rawat et al. A new attack is presented that allows an attacker to
apply a valid watermark on tampered images, therefore circumventing the
protection that the watermarking scheme under study was supposed to offer.
Furthermore, the presented attack has very low computational and memory
requirements.
"
805,"40 Gbps Access for Metro networks: Implications in terms of
  Sustainability and Innovation from an LCA Perspective","  In this work, the implications of new technologies, more specifically the new
optical FTTH technologies, are studied both from the functional and
non-functional perspectives. In particular, some direct impacts are listed in
the form of abandoning non-functional technologies, such as micro-registration,
which would be implicitly required for having a functioning operation before
arrival the new high-bandwidth access technologies. It is shown that such
abandonment of non-functional best practices, which are mainly at the
management level of ICT, immediately results in additional consumption and
environmental footprint, and also there is a chance that some other new
innovations might be 'missed.' Therefore, unconstrained deployment of these
access technologies is not aligned with a possible sustainable ICT picture,
except if they are regulated. An approach to pricing the best practices,
including both functional and non-functional technologies, is proposed in order
to develop a regulation and policy framework for a sustainable broadband
access.
"
806,"Deviation Based Pooling Strategies For Full Reference Image Quality
  Assessment","  The state-of-the-art pooling strategies for perceptual image quality
assessment (IQA) are based on the mean and the weighted mean. They are robust
pooling strategies which usually provide a moderate to high performance for
different IQAs. Recently, standard deviation (SD) pooling was also proposed.
Although, this deviation pooling provides a very high performance for a few
IQAs, its performance is lower than mean poolings for many other IQAs. In this
paper, we propose to use the mean absolute deviation (MAD) and show that it is
a more robust and accurate pooling strategy for a wider range of IQAs. In fact,
MAD pooling has the advantages of both mean pooling and SD pooling. The joint
computation and use of the MAD and SD pooling strategies is also considered in
this paper. Experimental results provide useful information on the choice of
the proper deviation pooling strategy for different IQA models.
"
807,"Evaluating the Performance of Multicast Resource Allocation Policies
  over LTE Systems","  This paper addresses a multi-criteria decision method properly designed to
effectively evaluate the most performing strategy for multicast content
delivery in Long Term Evolution (LTE) and beyond systems. We compared the
legacy conservative-based approach with other promising strategies in
literature, i.e., opportunistic multicasting and subgroup-based policies
tailored to exploit different cost functions, such as maximum throughput,
proportional fairness and the multicast dissatisfaction index (MDI). We provide
a comparison among above schemes in terms of aggregate data rate (ADR),
fairness and spectral efficiency. We further design a multi-criteria decision
making method, namely TOPSIS, to evaluate through a single mark the overall
performance of considered strategies. The obtained results show that the MDI
subgrouping strategy represents the most suitable approach for multicast
content delivery as it provides the most promising trade-off between the
fairness and the throughput achieved by the multicast members.
"
808,Efficient Spectrum Management Exploiting D2D Communication in 5G Systems,"  In the future standardization of the 5G networks, in Long Term Evolution
(LTE) Release 13 and beyond, Device-to-Device communications (D2D) is
recognized as one of the key technologies that will support the 5G
architecture. In fact, D2D can be exploited for different proximity-based
services (ProSe) where the users discover their neighbors and benefit form
different services like social applications, advertisement, public safety, and
warning messages. In such a scenario, the aim is to manage in a proper way the
radio spectrum and the energy consumption to provide high Quality of Experience
(QoE) and better Quality of Services (QoS). To reach this goal, in this paper
we propose a novel D2D-based uploading scheme in order to decrease the amount
of radio resources needed to upload to the eNodeB a certain multimedia content.
As a further improvement, the proposed scheme enhances the energy consumption
of the users in the network, without affects the content uploading time. The
obtained results show that our scheme achieves a gain of about 35\% in term of
mean radio resources used with respect to the standard LTE cellular approach.
In addition, it is also 40 times more efficient in terms of energy consumption
needed to upload the multimedia content.
"
809,"An Active Learning Based Approach For Effective Video Annotation And
  Retrieval","  Conventional multimedia annotation/retrieval systems such as Normalized
Continuous Relevance Model (NormCRM) [16] require a fully labeled training data
for a good performance. Active Learning, by determining an order for labeling
the training data, allows for a good performance even before the training data
is fully annotated. In this work we propose an active learning algorithm, which
combines a novel measure of sample uncertainty with a novel clustering-based
approach for determining sample density and diversity and integrate it with
NormCRM. The clusters are also iteratively refined to ensure both feature and
label-level agreement among samples. We show that our approach outperforms
multiple baselines both on a recent, open character animation dataset and on
the popular TRECVID corpus at both the tasks of annotation and text-based
retrieval of videos.
"
810,Visual Information Retrieval in Endoscopic Video Archives,"  In endoscopic procedures, surgeons work with live video streams from the
inside of their subjects. A main source for documentation of procedures are
still frames from the video, identified and taken during the surgery. However,
with growing demands and technical means, the streams are saved to storage
servers and the surgeons need to retrieve parts of the videos on demand. In
this submission we present a demo application allowing for video retrieval
based on visual features and late fusion, which allows surgeons to re-find
shots taken during the procedure.
"
811,Large Scale Discovery of Seasonal Music From User Data,"  The consumption history of online media content such as music and video
offers a rich source of data from which to mine information. Trends in this
data are of particular interest because they reflect user preferences as well
as associated cultural contexts that can be exploited in systems such as
recommendation or search. This paper classifies songs as seasonal using a
large, real-world dataset of user listening data. Results show strong
performance of classification of Christmas music with Gaussian Mixture Models.
"
812,"Large-scale Classification of Fine-Art Paintings: Learning The Right
  Metric on The Right Feature","  In the past few years, the number of fine-art collections that are digitized
and publicly available has been growing rapidly. With the availability of such
large collections of digitized artworks comes the need to develop multimedia
systems to archive and retrieve this pool of data. Measuring the visual
similarity between artistic items is an essential step for such multimedia
systems, which can benefit more high-level multimedia tasks. In order to model
this similarity between paintings, we should extract the appropriate visual
features for paintings and find out the best approach to learn the similarity
metric based on these features. We investigate a comprehensive list of visual
features and metric learning approaches to learn an optimized similarity
measure between paintings. We develop a machine that is able to make
aesthetic-related semantic-level judgments, such as predicting a painting's
style, genre, and artist, as well as providing similarity measures optimized
based on the knowledge available in the domain of art historical
interpretation. Our experiments show the value of using this similarity measure
for the aforementioned prediction tasks.
"
813,Learning Style Similarity for Searching Infographics,"  Infographics are complex graphic designs integrating text, images, charts and
sketches. Despite the increasing popularity of infographics and the rapid
growth of online design portfolios, little research investigates how we can
take advantage of these design resources. In this paper we present a method for
measuring the style similarity between infographics. Based on human perception
data collected from crowdsourced experiments, we use computer vision and
machine learning algorithms to learn a style similarity metric for infographic
designs. We evaluate different visual features and learning algorithms and find
that a combination of color histograms and Histograms-of-Gradients (HoG)
features is most effective in characterizing the style of infographics. We
demonstrate our similarity metric on a preliminary image retrieval test.
"
814,Jointly Modeling Embedding and Translation to Bridge Video and Language,"  Automatically describing video content with natural language is a fundamental
challenge of multimedia. Recurrent Neural Networks (RNN), which models sequence
dynamics, has attracted increasing attention on visual interpretation. However,
most existing approaches generate a word locally with given previous words and
the visual content, while the relationship between sentence semantics and
visual content is not holistically exploited. As a result, the generated
sentences may be contextually correct but the semantics (e.g., subjects, verbs
or objects) are not true.
  This paper presents a novel unified framework, named Long Short-Term Memory
with visual-semantic Embedding (LSTM-E), which can simultaneously explore the
learning of LSTM and visual-semantic embedding. The former aims to locally
maximize the probability of generating the next word given previous words and
visual content, while the latter is to create a visual-semantic embedding space
for enforcing the relationship between the semantics of the entire sentence and
visual content. Our proposed LSTM-E consists of three components: a 2-D and/or
3-D deep convolutional neural networks for learning powerful video
representation, a deep RNN for generating sentences, and a joint embedding
model for exploring the relationships between visual content and sentence
semantics. The experiments on YouTube2Text dataset show that our proposed
LSTM-E achieves to-date the best reported performance in generating natural
sentences: 45.3% and 31.0% in terms of BLEU@4 and METEOR, respectively. We also
demonstrate that LSTM-E is superior in predicting Subject-Verb-Object (SVO)
triplets to several state-of-the-art techniques.
"
815,Wireless Multicast for Zoomable Video Streaming,"  Zoomable video streaming refers to a new class of interactive video
applications, where users can zoom into a video stream to view a selected
region of interest in higher resolutions and pan around to move the region of
interest. The zoom and pan effects are typically achieved by breaking the
source video into a grid of independently decodable tiles. Streaming the tiles
to a set of heterogeneous users using broadcast is challenging, as users have
different link rates and different regions of interest at different resolution
levels. In this paper, we consider the following problem: given the subset of
tiles that each user requested, the link rate of each user, and the available
time slots, at which resolution should each tile be sent, to maximize the
overall video quality received by all users. We design an efficient algorithm
to solve the problem above, and evaluate the solution on a testbed using 10
mobile devices. Our method is able to achieve up to 12dB improvements over
other heuristic methods.
"
816,Cloud for Gaming,"  Cloud for Gaming refers to the use of cloud computing technologies to build
large-scale gaming infrastructures, with the goal of improving scalability and
responsiveness, improve the user's experience and enable new business models.
"
817,"An Image is Worth More than a Thousand Favorites: Surfacing the Hidden
  Beauty of Flickr Pictures","  The dynamics of attention in social media tend to obey power laws. Attention
concentrates on a relatively small number of popular items and neglecting the
vast majority of content produced by the crowd. Although popularity can be an
indication of the perceived value of an item within its community, previous
research has hinted to the fact that popularity is distinct from intrinsic
quality. As a result, content with low visibility but high quality lurks in the
tail of the popularity distribution. This phenomenon can be particularly
evident in the case of photo-sharing communities, where valuable photographers
who are not highly engaged in online social interactions contribute with
high-quality pictures that remain unseen. We propose to use a computer vision
method to surface beautiful pictures from the immense pool of
near-zero-popularity items, and we test it on a large dataset of
creative-commons photos on Flickr. By gathering a large crowdsourced ground
truth of aesthetics scores for Flickr images, we show that our method retrieves
photos whose median perceived beauty score is equal to the most popular ones,
and whose average is lower by only 1.5%.
"
818,"Image aesthetic evaluation using paralleled deep convolution neural
  network","  Image aesthetic evaluation has attracted much attention in recent years.
Image aesthetic evaluation methods heavily depend on the effective aesthetic
feature. Traditional meth-ods always extract hand-crafted features. However,
these hand-crafted features are always designed to adapt particu-lar datasets,
and extraction of them needs special design. Rather than extracting
hand-crafted features, an automati-cally learn of aesthetic features based on
deep convolutional neural network (DCNN) is first adopt in this paper. As we
all know, when the training dataset is given, the DCNN architecture with high
complexity may meet the over-fitting problem. On the other side, the DCNN
architecture with low complexity would not efficiently extract effective
features. For these reasons, we further propose a paralleled convolutional
neural network (PDCNN) with multi-level structures to automatically adapt to
the training dataset. Experimental results show that our proposed PDCNN
architecture achieves better performance than other traditional methods.
"
819,Compressive Sensing of Large-Scale Images: An Assumption-Free Approach,"  Cost-efficient compressive sensing of big media data with fast reconstructed
high-quality results is very challenging. In this paper, we propose a new
large-scale image compressive sensing method, composed of operator-based
strategy in the context of fixed point continuation method and weighted LASSO
with tree structure sparsity pattern. The main characteristic of our method is
free from any assumptions and restrictions. The feasibility of our method is
verified via simulations and comparisons with state-of-the-art algorithms.
"
820,Efficient Large Scale Video Classification,"  Video classification has advanced tremendously over the recent years. A large
part of the improvements in video classification had to do with the work done
by the image classification community and the use of deep convolutional
networks (CNNs) which produce competitive results with hand- crafted motion
features. These networks were adapted to use video frames in various ways and
have yielded state of the art classification results. We present two methods
that build on this work, and scale it up to work with millions of videos and
hundreds of thousands of classes while maintaining a low computational cost. In
the context of large scale video processing, training CNNs on video frames is
extremely time consuming, due to the large number of frames involved. We
propose to avoid this problem by training CNNs on either YouTube thumbnails or
Flickr images, and then using these networks' outputs as features for other
higher level classifiers. We discuss the challenges of achieving this and
propose two models for frame-level and video-level classification. The first is
a highly efficient mixture of experts while the latter is based on long short
term memory neural networks. We present results on the Sports-1M video dataset
(1 million videos, 487 classes) and on a new dataset which has 12 million
videos and 150,000 labels.
"
821,GWAT: The Geneva Affective Picture Database WordNet Annotation Tool,"  The Geneva Affective Picture Database WordNet Annotation Tool (GWAT) is a
user-friendly web application for manual annotation of pictures in Geneva
Affective Picture Database (GAPED) with WordNet. The annotation tool has an
intuitive interface which can be efficiently used with very little technical
training. A single picture may be labeled with many synsets allowing experts to
describe semantics with different levels of detail. Noun, verb, adjective and
adverb synsets can be keyword-searched and attached to a specific GAPED picture
with their unique identification numbers. Changes are saved automatically in
the tool's relational database. The attached synsets can be reviewed, changed
or deleted later. Additionally, GAPED pictures may be browsed in the tool's
user interface using simple commands where previously attached WordNet synsets
are displayed alongside the pictures. Stored annotations can be exported from
the tool's database to different data formats and used in 3rd party
applications if needed. Since GAPED does not define keywords of individual
pictures but only a general category of picture groups, GWAT represents a
significant improvement towards development of comprehensive picture semantics.
The tool was developed with open technologies WordNet API, Apache, PHP5 and
MySQL. It is freely available for scientific and non-commercial use.
"
822,"Comparing affective responses to standardized pictures and videos: A
  study report","  Multimedia documents such as text, images, sounds or videos elicit emotional
responses of different polarity and intensity in exposed human subjects. These
stimuli are stored in affective multimedia databases. The problem of emotion
processing is an important issue in Human-Computer Interaction and different
interdisciplinary studies particularly those related to psychology and
neuroscience. Accurate prediction of users' attention and emotion has many
practical applications such as the development of affective computer
interfaces, multifaceted search engines, video-on-demand, Internet
communication and video games. To this regard we present results of a study
with N=10 participants to investigate the capability of standardized affective
multimedia databases in stimulation of emotion. Each participant was exposed to
picture and video stimuli with previously determined semantics and emotion.
During exposure participants' physiological signals were recorded and estimated
for emotion in an off-line analysis. Participants reported their emotion states
after each exposure session. The a posteriori and a priori emotion values were
compared. The experiment showed, among other reported results, that carefully
designed video sequences induce a stronger and more accurate emotional reaction
than pictures. Individual participants' differences greatly influence the
intensity and polarity of experienced emotion.
"
823,"Micro protocol engineering for unstructured carriers: On the embedding
  of steganographic control protocols into audio transmissions","  Network steganography conceals the transfer of sensitive information within
unobtrusive data in computer networks. So-called micro protocols are
communication protocols placed within the payload of a network steganographic
transfer. They enrich this transfer with features such as reliability, dynamic
overlay routing, or performance optimization --- just to mention a few. We
present different design approaches for the embedding of hidden channels with
micro protocols in digitized audio signals under consideration of different
requirements. On the basis of experimental results, our design approaches are
compared, and introduced into a protocol engineering approach for micro
protocols.
"
824,"OR-Benchmark: An Open and Reconfigurable Digital Watermarking
  Benchmarking Framework","  Benchmarking digital watermarking algorithms is not an easy task because
different applications of digital watermarking often have very different sets
of requirements and trade-offs between conflicting requirements. While there
have been some general-purpose digital watermarking benchmarking systems
available, they normally do not support complicated benchmarking tasks and
cannot be easily reconfigured to work with different watermarking algorithms
and testing conditions. In this paper, we propose OR-Benchmark, an open and
highly reconfigurable general-purpose digital watermarking benchmarking
framework, which has the following two key features: 1) all the interfaces are
public and general enough to support all watermarking applications and
benchmarking tasks we can think of; 2) end users can easily extend the
functionalities and freely configure what watermarking algorithms are tested,
what system components are used, how the benchmarking process runs, and what
results should be produced. We implemented a prototype of this framework as a
MATLAB software package and used it to benchmark a number of digital
watermarking algorithms involving two types of watermarks for content
authentication and self-restoration purposes. The benchmarking results
demonstrated the advantages of the proposed benchmarking framework, and also
gave us some useful insights about existing image authentication and
self-restoration watermarking algorithms which are an important but less
studied topic in digital watermarking.
"
825,"User Preferences Modeling and Learning for Pleasing Photo Collage
  Generation","  In this paper we consider how to automatically create pleasing photo collages
created by placing a set of images on a limited canvas area. The task is
formulated as an optimization problem. Differently from existing
state-of-the-art approaches, we here exploit subjective experiments to model
and learn pleasantness from user preferences. To this end, we design an
experimental framework for the identification of the criteria that need to be
taken into account to generate a pleasing photo collage. Five different
thematic photo datasets are used to create collages using state-of-the-art
criteria. A first subjective experiment where several subjects evaluated the
collages, emphasizes that different criteria are involved in the subjective
definition of pleasantness. We then identify new global and local criteria and
design algorithms to quantify them. The relative importance of these criteria
are automatically learned by exploiting the user preferences, and new collages
are generated. To validate our framework, we performed several psycho-visual
experiments involving different users. The results shows that the proposed
framework allows to learn a novel computational model which effectively encodes
an inter-user definition of pleasantness. The learned definition of
pleasantness generalizes well to new photo datasets of different themes and
sizes not used in the learning. Moreover, compared with two state of the art
approaches, the collages created using our framework are preferred by the
majority of the users.
"
826,Quantifying Creativity in Art Networks,"  Can we develop a computer algorithm that assesses the creativity of a
painting given its context within art history? This paper proposes a novel
computational framework for assessing the creativity of creative products, such
as paintings, sculptures, poetry, etc. We use the most common definition of
creativity, which emphasizes the originality of the product and its influential
value. The proposed computational framework is based on constructing a network
between creative products and using this network to infer about the originality
and influence of its nodes. Through a series of transformations, we construct a
Creativity Implication Network. We show that inference about creativity in this
network reduces to a variant of network centrality problems which can be solved
efficiently. We apply the proposed framework to the task of quantifying
creativity of paintings (and sculptures). We experimented on two datasets with
over 62K paintings to illustrate the behavior of the proposed framework. We
also propose a methodology for quantitatively validating the results of the
proposed algorithm, which we call the ""time machine experiment"".
"
827,Video (GIF) Sentiment Analysis using Large-Scale Mid-Level Ontology,"  With faster connection speed, Internet users are now making social network a
huge reservoir of texts, images and video clips (GIF). Sentiment analysis for
such online platform can be used to predict political elections, evaluates
economic indicators and so on. However, GIF sentiment analysis is quite
challenging, not only because it hinges on spatio-temporal visual
contentabstraction, but also for the relationship between such abstraction and
final sentiment remains unknown.In this paper, we dedicated to find out such
relationship.We proposed a SentiPairSequence basedspatiotemporal visual
sentiment ontology, which forms the midlevel representations for GIFsentiment.
The establishment process of SentiPair contains two steps. First, we construct
the Synset Forest to define the semantic tree structure of visual sentiment
label elements. Then, through theSynset Forest, we organically select and
combine sentiment label elements to form a mid-level visual sentiment
representation. Our experiments indicate that SentiPair outperforms other
competing mid-level attributes. Using SentiPair, our analysis frameworkcan
achieve satisfying prediction accuracy (72.6%). We also opened ourdataset
(GSO-2015) to the research community. GSO-2015 contains more than 6,000
manually annotated GIFs out of more than 40,000 candidates. Each is labeled
with both sentiment and SentiPair Sequence.
"
828,"Optimum Decoder for an Additive Video Watermarking with Laplacian Noise
  in H.264","  In this paper, we investigate an additive video watermarking method in H.264
standard in presence of the Laplacian noise. In some applications, due to the
loss of some pixels or a region of a frame, we resort to Laplacian noise rather
than Gaussian one. The embedding is performed in the transform domain; while an
optimum and a sub-optimum decoder are derived for the proposed Laplacian model.
Simulation results show that the proposed watermarking scheme has suitable
performance with enough transparency required for watermarking applications.
"
829,Digital image watermarking using normal matrices,"  This paper presents techniques for digital image watermarking based on
eigenvalue decomposition of normal matrices. The introduced methods are
convenient and self-explanatory, achieve satisfactory results, as well as
require less and easy computations compared to some current methods. Through
the proposed methods, host images and watermarks are transformed to the space
of normal matrices, and the properties of spectral decompositions are dealt
with to obtain watermarked images. Watermark extraction is carried out via a
procedure similar to embedding. Experimental results are provided to illustrate
the reliability and robustness of the methods.
"
830,"Random Voting Effects in Social-Digital Spaces: A case study of Reddit
  Post Submissions","  At a time when information seekers first turn to digital sources for news and
opinion, it is critical that we understand the role that social media plays in
human behavior. This is especially true when information consumers also act as
information producers and editors by their online activity. In order to better
understand the effects that editorial ratings have on online human behavior, we
report the results of a large-scale in-vivo experiment in social media. We find
that small, random rating manipulations on social media submissions created
significant changes in downstream ratings resulting in significantly different
final outcomes. Positive treatment resulted in a positive effect that increased
the final rating by 11.02% on average. Compared to the control group, positive
treatment also increased the probability of reaching a high rating (>=2000) by
24.6%. Contrary to the results of related work we also find that negative
treatment resulted in a negative effect that decreased the final rating by
5.15% on average.
"
831,Using Facebook for Image Steganography,"  Because Facebook is available on hundreds of millions of desktop and mobile
computing platforms around the world and because it is available on many
different kinds of platforms (from desktops and laptops running Windows, Unix,
or OS X to hand held devices running iOS, Android, or Windows Phone), it would
seem to be the perfect place to conduct steganography. On Facebook, information
hidden in image files will be further obscured within the millions of pictures
and other images posted and transmitted daily. Facebook is known to alter and
compress uploaded images so they use minimum space and bandwidth when displayed
on Facebook pages. The compression process generally disrupts attempts to use
Facebook for image steganography. This paper explores a method to minimize the
disruption so JPEG images can be used as steganography carriers on Facebook.
"
832,"A novel magic LSB substitution method (M-LSB-SM) using multi-level
  encryption and achromatic component of an image","  Image Steganography is a thriving research area of information security where
secret data is embedded in images to hide its existence while getting the
minimum possible statistical detectability. This paper proposes a novel magic
least significant bit substitution method (M-LSB-SM) for RGB images. The
proposed method is based on the achromatic component (I-plane) of the
hue-saturation-intensity (HSI) color model and multi-level encryption (MLE) in
the spatial domain. The input image is transposed and converted into an HSI
color space. The I-plane is divided into four sub-images of equal size,
rotating each sub-image with a different angle using a secret key. The secret
information is divided into four blocks, which are then encrypted using an MLE
algorithm (MLEA). Each sub-block of the message is embedded into one of the
rotated sub-images based on a specific pattern using magic LSB substitution.
Experimental results validate that the proposed method not only enhances the
visual quality of stego images but also provides good imperceptibility and
multiple security levels as compared to several existing prominent methods.
"
833,StegBlocks: ensuring perfect undetectability of network steganography,"  The paper presents StegBlocks, which defines a new concept for performing
undetectable hidden communication. StegBlocks is a general approach for
constructing methods of network steganography. In StegBlocks, one has to
determine objects with defined properties which will be used to transfer hidden
messages. The objects are dependent on a specific network protocol (or
application) used as a carrier for a given network steganography method.
Moreover, the paper presents the approach to perfect undetectability of network
steganography, which was developed based on the rules of undetectability for
general steganography. The approach to undetectability of network steganography
was used to show the possibility of developing perfectly undetectable network
steganography methods using the StegBlocks concept.
"
834,A Novel Approach for Image Steganography in Spatial Domain,"  This paper presents a new approach for hiding information in digital image in
spatial domain. In this approach three bits of message is embedded in a pixel
using Lucas number system but only one bit plane is allowed for alternation.
The experimental results show that the proposed method has the larger capacity
of embedding data, high peak signal to noise ratio compared to existing methods
and is hardly detectable for steganolysis algorithm.
"
835,LightPanel: Active Mobile Platform for Dense 3D Modelling,"  In this paper we introduce a novel platform for dense 3D modelling. This
platform is an active image acquisition setup assisted with a set of light
sources and a distance sensor. The hardware setup is designed for being mounted
on a mobile robot which is remotely driven to create accurate dense 3D models
from out-of-reach objects. For this reason, the object is actively illuminated
by the imaging setup and Photometric Stereo is used to recover the dense 3D
model. The proposed image acquisition setup, called LightPanel, is described
from design to calibration and discusses the practical challenges of using
Photometric Stereo under uncontrolled lighting conditions.
"
836,"A QoS Guarantee Strategy for Multimedia Conferencing based on Bayesian
  Networks","  Service Oriented Architecture (SOA) is commonly employed in the design and
implementation of web service systems. The key technology to enable media
communications in the context of SOA is the Service Oriented Communication. To
exploit the advantage of SOA, we design and implement a web-based multimedia
conferencing system that provides users with a hybrid orchestration of web and
communication services. As the current SOA lacks effective QoS guarantee
solutions for multimedia services, the user satisfaction is greatly challenged
with QoS violations, e.g., low video PSNR (Peak Signal-to-Noise Ratio) and long
playback delay. Motivated by addressing the critical problem, we firstly employ
the Business Process Execution Language (BPEL) service engine for the hybrid
services orchestration and execution. Secondly, we propose a novel
context-aware approach to quantify and leverage the causal relationships
between QoS metrics and available contexts based on Bayesian networks (CABIN).
This approach includes three phases: (1) information discretization, (2) causal
relationship profiling, and (3) optimal context tuning. We implement CABIN in a
real-life multimedia conferencing system and compare its performance with
existing delay and throughput oriented schemes. Experimental results show that
CABIN outperforms the competing approaches in improving the video quality in
terms of PSNR. It also provides a one-stop shop controls both the web and
communication services.
"
837,"Optimal Layered Representation for Adaptive Interactive Multiview Video
  Streaming","  We consider an interactive multiview video streaming (IMVS) system where
clients select their preferred viewpoint in a given navigation window. To
provide high quality IMVS, many high quality views should be transmitted to the
clients. However, this is not always possible due to the limited and
heterogeneous capabilities of the clients. In this paper, we propose a novel
adaptive IMVS solution based on a layered multiview representation where camera
views are organized into layered subsets to match the different clients
constraints. We formulate an optimization problem for the joint selection of
the views subsets and their encoding rates. Then, we propose an optimal and a
reduced computational complexity greedy algorithms, both based on
dynamic-programming. Simulation results show the good performance of our novel
algorithms compared to a baseline algorithm, proving that an effective IMVS
adaptive solution should consider the scene content and the client capabilities
and their preferences in navigation.
"
838,Data-driven Approaches for Social Video Distribution,"  The Internet has recently witnessed the convergence of online social network
services and online video services: users import videos from content sharing
sites, and propagate them along the social connections by re-sharing them. Such
social behaviors have dramatically reshaped how videos are disseminated, and
the users are now actively engaged to be part of the social ecosystem, rather
than being passively consumers. Despite the increasingly abundant bandwidth and
computation resources, the ever increasing data volume of user generated video
content and the boundless coverage of socialized sharing have presented
unprecedented challenges. In this paper, we first presents the challenges in
social-aware video delivery. Then, we present a principal framework for
data-driven social video delivery approaches. Moreover, we identify the unique
characteristics of social-aware video access and the social content
propagation, and closely reveal the design of individual modules and their
integration towards enhancing users' experience in the social network context.
"
839,"Humor in Collective Discourse: Unsupervised Funniness Detection in the
  New Yorker Cartoon Caption Contest","  The New Yorker publishes a weekly captionless cartoon. More than 5,000
readers submit captions for it. The editors select three of them and ask the
readers to pick the funniest one. We describe an experiment that compares a
dozen automatic methods for selecting the funniest caption. We show that
negative sentiment, human-centeredness, and lexical centrality most strongly
match the funniest captions, followed by positive sentiment. These results are
useful for understanding humor and also in the design of more engaging
conversational agents in text and multimodal (vision+text) systems. As part of
this work, a large set of cartoons and captions is being made available to the
community.
"
840,"Keypoint Encoding for Improved Feature Extraction from Compressed Video
  at Low Bitrates","  In many mobile visual analysis applications, compressed video is transmitted
over a communication network and analyzed by a server. Typical processing steps
performed at the server include keypoint detection, descriptor calculation, and
feature matching. Video compression has been shown to have an adverse effect on
feature-matching performance. The negative impact of compression can be reduced
by using the keypoints extracted from the uncompressed video to calculate
descriptors from the compressed video. Based on this observation, we propose to
provide these keypoints to the server as side information and to extract only
the descriptors from the compressed video. First, we introduce four different
frame types for keypoint encoding to address different types of changes in
video content. These frame types represent a new scene, the same scene, a
slowly changing scene, or a rapidly moving scene and are determined by
comparing features between successive video frames. Then, we propose Intra,
Skip and Inter modes of encoding the keypoints for different frame types. For
example, keypoints for new scenes are encoded using the Intra mode, and
keypoints for unchanged scenes are skipped. As a result, the bitrate of the
side information related to keypoint encoding is significantly reduced.
Finally, we present pairwise matching and image retrieval experiments conducted
to evaluate the performance of the proposed approach using the Stanford mobile
augmented reality dataset and 720p format videos. The results show that the
proposed approach offers significantly improved feature matching and image
retrieval performance at a given bitrate.
"
841,"Social Network Analysis Inspired Content Placement with QoS in
  Cloud-based Content Delivery Networks","  Content Placement (CP) problem in Cloud-based Content Delivery Networks
(CCDNs) leverage resource elasticity to build cost effective CDNs that
guarantee QoS. In this paper, we present our novel CP model, which optimally
places content on surrogates in the cloud, to achieve (a) minimum cost of
leasing storage and bandwidth resources for data coming into and going out of
the cloud zones and regions, (b) guarantee Service Level Agreement (SLA), and
(c) minimize degree of QoS violations. The CP problem is NP-Hard, hence we
design a unique push-based heuristic, called Weighted Social Network Analysis
(W-SNA) for CCDN providers. W-SNA is based on Betweeness Centrality (BC) from
SNA and prioritizes surrogates based on their relationship to the other
vertices in the network graph. To achieve our unique objectives, we further
prioritize surrogates based on weights derived from storage cost and content
requests. We compare our heuristic to current state of the art Greedy Site (GS)
and purely Social Network Analysis (SNA) heuristics, which are relevant to our
work. We show that W-SNA outperforms GS and SNA in minimizing cost and QoS.
Moreover, W-SNA guarantees SLA but also minimizes the degree of QoS violations.
To the best of our knowledge, this is the first model and heuristic of its
kind, which is timely and gives a fundamental pre-allocation scheme for future
online and dynamic resource provision for CCDNs.
"
842,A new approach for image compression using normal matrices,"  In this paper, we present methods for image compression on the basis of
eigenvalue decomposition of normal matrices. The proposed methods are
convenient and self-explanatory, requiring fewer and easier computations as
compared to some existing methods. Through the proposed techniques, the image
is transformed to the space of normal matrices. Then, the properties of
spectral decomposition are dealt with to obtain compressed images. Experimental
results are provided to illustrate the validity of the methods.
"
843,"Low-latency compression of mocap data using learned spatial
  decorrelation transform","  Due to the growing needs of human motion capture (mocap) in movie, video
games, sports, etc., it is highly desired to compress mocap data for efficient
storage and transmission. This paper presents two efficient frameworks for
compressing human mocap data with low latency. The first framework processes
the data in a frame-by-frame manner so that it is ideal for mocap data
streaming and time critical applications. The second one is clip-based and
provides a flexible tradeoff between latency and compression performance. Since
mocap data exhibits some unique spatial characteristics, we propose a very
effective transform, namely learned orthogonal transform (LOT), for reducing
the spatial redundancy. The LOT problem is formulated as minimizing square
error regularized by orthogonality and sparsity and solved via alternating
iteration. We also adopt a predictive coding and temporal DCT for temporal
decorrelation in the frame- and clip-based frameworks, respectively.
Experimental results show that the proposed frameworks can produce higher
compression performance at lower computational cost and latency than the
state-of-the-art methods.
"
844,"TV News Commercials Detection using Success based Locally Weighted
  Kernel Combination","  Commercial detection in news broadcast videos involves judicious selection of
meaningful audio-visual feature combinations and efficient classifiers. And,
this problem becomes much simpler if these combinations can be learned from the
data. To this end, we propose an Multiple Kernel Learning based method for
boosting successful kernel functions while ignoring the irrelevant ones. We
adopt a intermediate fusion approach where, a SVM is trained with a weighted
linear combination of different kernel functions instead of single kernel
function. Each kernel function is characterized by a feature set and kernel
type. We identify the feature sub-space locations of the prediction success of
a particular classifier trained only with particular kernel function. We
propose to estimate a weighing function using support vector regression (with
RBF kernel) for each kernel function which has high values (near 1.0) where the
classifier learned on kernel function succeeded and lower values (nearly 0.0)
otherwise. Second contribution of this work is TV News Commercials Dataset of
150 Hours of News videos. Classifier trained with our proposed scheme has
outperformed the baseline methods on 6 of 8 benchmark dataset and our own TV
commercials dataset.
"
845,SLRMA: Sparse Low-Rank Matrix Approximation for Data Compression,"  Low-rank matrix approximation (LRMA) is a powerful technique for signal
processing and pattern analysis. However, its potential for data compression
has not yet been fully investigated in the literature. In this paper, we
propose sparse low-rank matrix approximation (SLRMA), an effective
computational tool for data compression. SLRMA extends the conventional LRMA by
exploring both the intra- and inter-coherence of data samples simultaneously.
With the aid of prescribed orthogonal transforms (e.g., discrete cosine/wavelet
transform and graph transform), SLRMA decomposes a matrix into a product of two
smaller matrices, where one matrix is made of extremely sparse and orthogonal
column vectors, and the other consists of the transform coefficients.
Technically, we formulate SLRMA as a constrained optimization problem, i.e.,
minimizing the approximation error in the least-squares sense regularized by
$\ell_0$-norm and orthogonality, and solve it using the inexact augmented
Lagrangian multiplier method. Through extensive tests on real-world data, such
as 2D image sets and 3D dynamic meshes, we observe that (i) SLRMA empirically
converges well; (ii) SLRMA can produce approximation error comparable to LRMA
but in a much sparse form; (iii) SLRMA-based compression schemes significantly
outperform the state-of-the-art in terms of rate-distortion performance.
"
846,Deep Multimodal Speaker Naming,"  Automatic speaker naming is the problem of localizing as well as identifying
each speaking character in a TV/movie/live show video. This is a challenging
problem mainly attributes to its multimodal nature, namely face cue alone is
insufficient to achieve good performance. Previous multimodal approaches to
this problem usually process the data of different modalities individually and
merge them using handcrafted heuristics. Such approaches work well for simple
scenes, but fail to achieve high performance for speakers with large appearance
variations. In this paper, we propose a novel convolutional neural networks
(CNN) based learning framework to automatically learn the fusion function of
both face and audio cues. We show that without using face tracking, facial
landmark localization or subtitle/transcript, our system with robust multimodal
feature extraction is able to achieve state-of-the-art speaker naming
performance evaluated on two diverse TV series. The dataset and implementation
of our algorithm are publicly available online.
"
847,Tree-based Visualization and Optimization for Image Collection,"  The visualization of an image collection is the process of displaying a
collection of images on a screen under some specific layout requirements. This
paper focuses on an important problem that is not well addressed by the
previous methods: visualizing image collections into arbitrary layout shapes
while arranging images according to user-defined semantic or visual
correlations (e.g., color or object category). To this end, we first propose a
property-based tree construction scheme to organize images of a collection into
a tree structure according to user-defined properties. In this way, images can
be adaptively placed with the desired semantic or visual correlations in the
final visualization layout. Then, we design a two-step visualization
optimization scheme to further optimize image layouts. As a result, multiple
layout effects including layout shape and image overlap ratio can be
effectively controlled to guarantee a satisfactory visualization. Finally, we
also propose a tree-transfer scheme such that visualization layouts can be
adaptively changed when users select different ""images of interest"". We
demonstrate the effectiveness of our proposed approach through the comparisons
with state-of-the-art visualization techniques.
"
848,"Towards Understanding User Preferences from User Tagging Behavior for
  Personalization","  Personalizing image tags is a relatively new and growing area of research,
and in order to advance this research community, we must review and challenge
the de-facto standard of defining tag importance. We believe that for greater
progress to be made, we must go beyond tags that merely describe objects that
are visually represented in the image, towards more user-centric and subjective
notions such as emotion, sentiment, and preferences.
  We focus on the notion of user preferences and show that the order that users
list tags on images is correlated to the order of preference over the tags that
they provided for the image. While this observation is not completely
surprising, to our knowledge, we are the first to explore this aspect of user
tagging behavior systematically and report empirical results to support this
observation. We argue that this observation can be exploited to help advance
the image tagging (and related) communities.
  Our contributions include: 1.) conducting a user study demonstrating this
observation, 2.) collecting a dataset with user tag preferences explicitly
collected.
"
849,"Joint Data Scheduling and FEC Coding for Multihomed Wireless Video
  Delivery","  This paper studies the problem of mobile video delivery in heterogenous
wireless networks from a server to multihomed device. Most existing works only
consider delivering video streaming on single path which bandwidth is limited
causing ultimate video transmission rate. To solve this live video streaming
transmission bottleneck problem, we propose a novel solution named Joint Data
Allocation and Fountain Coding (JDAFC) method that contain below characters:
(1) path selection, (2) dynamic data allocation, and (3) fountain coding. We
evaluate the performance of JDAFC by simulation experiments using Exata and
JVSM and compare it with some reference solutions. Experimental results
represent that JDAFC outperforms the competing solutions in improving the video
peak signal-to-noise ratio as well as reducing the end-to-end delay.
"
850,Data Hiding in Video using Triangularization LSB Technique,"  The importance of data hiding in the field of Information Technology is a
widely accepted. The challenge is to be able to pass information in a manner
that the very existence of the message is unknown in order to repel attention
of the potential attacker. Steganography is a technique that has been widely
used to achieve this objective. However Steganography is often found to be
lacking when it comes to hiding bulk data. Attempting to hide data in a video
overcomes this problem because of the large sized cover object (video) as
compared to an image in the case of steganography. This paper attempts to
propose a scheme using which data can be hidden in a video. We focus on the
Triangularization method and make use of the Least Significant Bit (LSB)
technique in hiding messages in a video.
"
851,Low Bit-Rate and High Fidelity Reversible Data Hiding,"  An accurate predictor is crucial for histogram-shifting (HS) based reversible
data hiding methods. The embedding capacity is increased and the embedding
distortion is decreased simultaneously if the predictor can generate accurate
predictions. In this paper, we propose an accurate linear predictor based on
weighted least squares (WLS) estimation. The robustness of WLS helps the
proposed predictor generate accurate predictions, especially in complex texture
areas of an image, where other predictors usually fail. To further reduce the
embedding distortion, we propose a new embedding method called dynamic
histogram shifting with pixel selection (DHS-PS) that selects not only the
proper histogram bins but also the proper pixel locations to embed the given
data. As a result, the proposed method can obtain very high fidelity marked
images with low bit-rate data embedded. The experimental results show that the
proposed method outperforms the state-of-the-art low bit-rate reversible data
hiding method.
"
852,Mobile Multi-View Object Image Search,"  High user interaction capability of mobile devices can help improve the
accuracy of mobile visual search systems. At query time, it is possible to
capture multiple views of an object from different viewing angles and at
different scales with the mobile device camera to obtain richer information
about the object compared to a single view and hence return more accurate
results. Motivated by this, we developed a mobile multi-view object image
search system, using a client-server architecture. Multi-view images of objects
acquired by the mobile clients are processed and local features are sent to the
server, which combines the query image representations with early/late fusion
methods based on bag-of-visual-words and sends back the query results. We
performed a comprehensive analysis of early and late fusion approaches using
various similarity functions, on an existing single view and a new multi-view
object image database. The experimental results show that multi-view search
provides significantly better retrieval accuracy compared to single view
search.
"
853,Estimating snow cover from publicly available images,"  In this paper we study the problem of estimating snow cover in mountainous
regions, that is, the spatial extent of the earth surface covered by snow. We
argue that publicly available visual content, in the form of user generated
photographs and image feeds from outdoor webcams, can both be leveraged as
additional measurement sources, complementing existing ground, satellite and
airborne sensor data. To this end, we describe two content acquisition and
processing pipelines that are tailored to such sources, addressing the specific
challenges posed by each of them, e.g., identifying the mountain peaks,
filtering out images taken in bad weather conditions, handling varying
illumination conditions. The final outcome is summarized in a snow cover index,
which indicates for a specific mountain and day of the year, the fraction of
visible area covered by snow, possibly at different elevations. We created a
manually labelled dataset to assess the accuracy of the image snow covered area
estimation, achieving 90.0% precision at 91.1% recall. In addition, we show
that seasonal trends related to air temperature are captured by the snow cover
index.
"
854,Arabic Text Watermarking: A Review,"  The using of the internet with its technologies and applications have been
increased rapidly. So, protecting the text from illegal use is too needed .
Text watermarking is used for this purpose. Arabic text has many
characteristics such existing of diacritics , kashida (extension character) and
points above or under its letters .Each of Arabic letters can take different
shapes with different Unicode. These characteristics are utilized in the
watermarking process. In this paper, several methods are discussed in the area
of Arabic text watermarking with its advantages and disadvantages .Comparison
of these methods is done in term of capacity, robustness and Imperceptibility.
"
855,"Approaching Maximum Embedding Efficiency on Small Covers Using
  Staircase-Generator Codes","  We introduce a new family of binary linear codes suitable for steganographic
matrix embedding. The main characteristic of the codes is the staircase random
block structure of the generator matrix. We propose an efficient list decoding
algorithm for the codes that finds a close codeword to a given random word. We
provide both theoretical analysis of the performance and stability of the
decoding algorithm, as well as practical results. Used for matrix embedding,
these codes achieve almost the upper theoretical bound of the embedding
efficiency for covers in the range of 1000 - 1500 bits, which is at least an
order of magnitude smaller than the values reported in related works.
"
856,Mountain Peak Detection in Online Social Media,"  We present a system for the classification of mountain panoramas from
user-generated photographs followed by identification and extraction of
mountain peaks from those panoramas. We have developed an automatic technique
that, given as input a geo-tagged photograph, estimates its FOV (Field Of View)
and the direction of the camera using a matching algorithm on the photograph
edge maps and a rendered view of the mountain silhouettes that should be seen
from the observer's point of view. The extraction algorithm then identifies the
mountain peaks present in the photograph and their profiles. We discuss
possible applications in social fields such as photograph peak tagging on
social portals, augmented reality on mobile devices when viewing a mountain
panorama, and generation of collective intelligence systems (such as
environmental models) from massive social media collections (e.g. snow water
availability maps based on mountain peak states extracted from photograph
hosting services).
"
857,"Generation of Multimedia Artifacts: An Extractive Summarization-based
  Approach","  We explore methods for content selection and address the issue of coherence
in the context of the generation of multimedia artifacts. We use audio and
video to present two case studies: generation of film tributes, and
lecture-driven science talks. For content selection, we use centrality-based
and diversity-based summarization, along with topic analysis. To establish
coherence, we use the emotional content of music, for film tributes, and ensure
topic similarity between lectures and documentaries, for science talks.
Composition techniques for the production of multimedia artifacts are addressed
as a means of organizing content, in order to improve coherence. We discuss our
results considering the above aspects.
"
858,3D-Computer Animation for a Yoruba Native Folktale,"  Computer graphics has wide range of applications which are implemented into
computer animation, computer modeling among others. Since the invention of
computer graphics researchers have not paid much of attentions toward the
possibility of converting oral tales otherwise known as folktales into possible
cartoon animated videos. This paper is based on how to develop cartoons of
local folktales that will be of huge benefits to Nigerians. The activities were
divided into 5 stages; analysis, design, development, implementation and
evaluation which involved various processes and use of various specialized
software and hardware. After the implementation of this project, the video
characteristics were evaluated using likert scale. Analysis of 30 user
responses indicated that 17 users (56.7 percent) rated the image quality as
excellent, the video and image synchronization was rated as excellent by 9
users (30 percent), the Background noise was rated excellent by 18 users (60
percent), the Character Impression was rated Excellent by 11 users (36.67
percent), the general assessment of the storyline was rated excellent by 17
users (56.7 percent), the video Impression was rated excellent by 11 users
(36.67 percent) and the voice quality was rated by 10 users (33.33 percent) as
excellent.
"
859,"Visual Affect Around the World: A Large-scale Multilingual Visual
  Sentiment Ontology","  Every culture and language is unique. Our work expressly focuses on the
uniqueness of culture and language in relation to human affect, specifically
sentiment and emotion semantics, and how they manifest in social multimedia. We
develop sets of sentiment- and emotion-polarized visual concepts by adapting
semantic structures called adjective-noun pairs, originally introduced by Borth
et al. (2013), but in a multilingual context. We propose a new
language-dependent method for automatic discovery of these adjective-noun
constructs. We show how this pipeline can be applied on a social multimedia
platform for the creation of a large-scale multilingual visual sentiment
concept ontology (MVSO). Unlike the flat structure in Borth et al. (2013), our
unified ontology is organized hierarchically by multilingual clusters of
visually detectable nouns and subclusters of emotionally biased versions of
these nouns. In addition, we present an image-based prediction task to show how
generalizable language-specific models are in a multilingual context. A new,
publicly available dataset of >15.6K sentiment-biased visual concepts across 12
languages with language-specific detector banks, >7.36M images and their
metadata is also released.
"
860,"""The Good, The Bad And The Ugly"": Evaluation of Wi-Fi Steganography","  In this paper we propose a new method for the evaluation of network
steganography algorithms based on the new concept of ""the moving observer"". We
considered three levels of undetectability named: ""good"", ""bad"", and ""ugly"". To
illustrate this method we chose Wi-Fi steganography as a solid family of
information hiding protocols. We present the state of the art in this area
covering well-known hiding techniques for 802.11 networks. ""The moving
observer"" approach could help not only in the evaluation of steganographic
algorithms, but also might be a starting point for a new detection system of
network steganography. The concept of a new detection system, called MoveSteg,
is explained in detail.
"
861,"Diving Deep into Sentiment: Understanding Fine-tuned CNNs for Visual
  Sentiment Prediction","  Visual media are powerful means of expressing emotions and sentiments. The
constant generation of new content in social networks highlights the need of
automated visual sentiment analysis tools. While Convolutional Neural Networks
(CNNs) have established a new state-of-the-art in several vision problems,
their application to the task of sentiment analysis is mostly unexplored and
there are few studies regarding how to design CNNs for this purpose. In this
work, we study the suitability of fine-tuning a CNN for visual sentiment
prediction as well as explore performance boosting techniques within this deep
learning setting. Finally, we provide a deep-dive analysis into a benchmark,
state-of-the-art network architecture to gain insight about how to design
patterns for CNNs on the task of visual sentiment prediction.
"
862,Dot-Diffused Halftoning with Improved Homogeneity,"  Compared to the error diffusion, dot diffusion provides an additional
pixel-level parallelism for digital halftoning. However, even though its
periodic and blocking artifacts had been eased by previous works, it was still
far from satisfactory in terms of the blue noise spectrum perspective. In this
work, we strengthen the relationship among the pixel locations of the same
processing order by an iterative halftoning method, and the results demonstrate
a significant improvement. Moreover, a new approach of deriving the averaged
power spectrum density (APSD) is proposed to avoid the regular sampling of the
well-known Bartlett's procedure which inaccurately presents the halftone
periodicity of certain halftoning techniques with parallelism. As a result, the
proposed dot diffusion is substantially superior to the state-of-the-art
parallel halftoning methods in terms of visual quality and artifact-free
property, and competitive runtime to the theoretical fastest ordered dithering
is offered simultaneously.
"
863,"Reversible Denoising and Lifting Based Color Component Transformation
  for Lossless Image Compression","  An undesirable side effect of reversible color space transformation, which
consists of lifting steps (LSs), is that while removing correlation it
contaminates transformed components with noise from other components. Noise
affects particularly adversely the compression ratios of lossless compression
algorithms. To remove correlation without increasing noise, a reversible
denoising and lifting step (RDLS) was proposed that integrates denoising
filters into LS. Applying RDLS to color space transformation results in a new
image component transformation that is perfectly reversible despite involving
the inherently irreversible denoising; the first application of such a
transformation is presented in this paper. For the JPEG-LS, JPEG 2000, and JPEG
XR standard algorithms in lossless mode, the application of RDLS to the RDgDb
color space transformation with simple denoising filters is especially
effective for images in the native optical resolution of acquisition devices.
It results in improving compression ratios of all those images in cases when
unmodified color space transformation either improves or worsens ratios
compared with the untransformed image. The average improvement is 5.0-6.0\% for
two out of the three sets of such images, whereas average ratios of images from
standard test-sets are improved by up to 2.2\%. For the efficient
image-adaptive determination of filters for RDLS, a couple of fast
entropy-based estimators of compression effects that may be used independently
of the actual compression algorithm are investigated and an immediate filter
selection method based on the detector precision characteristic model driven by
image acquisition parameters is introduced.
"
864,Compressive Video Sensing via Dictionary Learning and Forward Prediction,"  In this paper, we propose a new framework for compressive video sensing (CVS)
that exploits the inherent spatial and temporal redundancies of a video
sequence, effectively. The proposed method splits the video sequence into the
key and non-key frames followed by dividing each frame into small
non-overlapping blocks of equal sizes. At the decoder side, the key frames are
reconstructed using adaptively learned sparsifying (ALS) basis via $\ell_0$
minimization, in order to exploit the spatial redundancy. Also, the
effectiveness of three well-known dictionary learning algorithms is
investigated in our method. For recovery of the non-key frames, a prediction of
the current frame is initialized, by using the previous reconstructed frame, in
order to exploit the temporal redundancy. The prediction is employed in a
proper optimization problem to recover the current non-key frame. To compare
our experimental results with the results of some other methods, we employ peak
signal to noise ratio (PSNR) and structural similarity (SSIM) index as the
quality assessor. The numerical results show the adequacy of our proposed
method in CVS.
"
865,In-Network View Synthesis for Interactive Multiview Video Systems,"  To enable Interactive multiview video systems with a minimum view-switching
delay, multiple camera views are sent to the users, which are used as reference
images to synthesize additional virtual views via depth-image-based rendering.
In practice, bandwidth constraints may however restrict the number of reference
views sent to clients per time unit, which may in turn limit the quality of the
synthesized viewpoints. We argue that the reference view selection should
ideally be performed close to the users, and we study the problem of in-network
reference view synthesis such that the navigation quality is maximized at the
clients. We consider a distributed cloud network architecture where data stored
in a main cloud is delivered to end users with the help of cloudlets, i.e.,
resource-rich proxies close to the users. In order to satisfy last-hop
bandwidth constraints from the cloudlet to the users, a cloudlet re-samples
viewpoints of the 3D scene into a discrete set of views (combination of
received camera views and virtual views synthesized) to be used as reference
for the synthesis of additional virtual views at the client. This in-network
synthesis leads to better viewpoint sampling given a bandwidth constraint
compared to simple selection of camera views, but it may however carry a
distortion penalty in the cloudlet-synthesized reference views. We therefore
cast a new reference view selection problem where the best subset of views is
defined as the one minimizing the distortion over a view navigation window
defined by the user under some transmission bandwidth constraints. We show that
the view selection problem is NP-hard, and propose an effective polynomial time
algorithm using dynamic programming to solve the optimization problem.
Simulation results finally confirm the performance gain offered by virtual view
synthesis in the network.
"
866,Pinterest Board Recommendation for Twitter Users,"  Pinboard on Pinterest is an emerging media to engage online social media
users, on which users post online images for specific topics. Regardless of its
significance, there is little previous work specifically to facilitate
information discovery based on pinboards. This paper proposes a novel pinboard
recommendation system for Twitter users. In order to associate contents from
the two social media platforms, we propose to use MultiLabel classification to
map Twitter user followees to pinboard topics and visual diversification to
recommend pinboards given user interested topics. A preliminary experiment on a
dataset with 2000 users validated our proposed system.
"
867,"Audio Steganography: LSB Technique Using a Pyramid Structure and Range
  of Bytes","  The demand for keeping the information secure and confidential simultaneously
has been progressively increasing. Among various techniques- Audio
Steganography, a technique of embedding information transparently in a digital
media thereby restricting the access to such information has been prominently
developed. Imperceptibility, robustness, and payload or hiding capacity are the
main character for it. In earlier, LSB techniques increased payload capacity
would hamper robustness as well as imperceptibility of the cover media and vice
versa. The proposed technique overcomes the problem. It provides relatively
good improvement in the payload capacity by dividing the bytes of cover media
into ranges to hide the bits of secret message appropriately. As well as due to
the use of ranges of bytes the robustness of cover media has maintained and
imperceptibility preserved by using a pyramid structure.
"
868,"Merge Frame Design for Video Stream Switching using Piecewise Constant
  Functions","  The ability to efficiently switch from one pre-encoded video stream to
another (e.g., for bitrate adaptation or view switching) is important for many
interactive streaming applications. Recently, stream-switching mechanisms based
on distributed source coding (DSC) have been proposed. In order to reduce the
overall transmission rate, these approaches provide a ""merge"" mechanism, where
information is sent to the decoder such that the exact same frame can be
reconstructed given that any one of a known set of side information (SI) frames
is available at the decoder (e.g., each SI frame may correspond to a different
stream from which we are switching). However, the use of bit-plane coding and
channel coding in many DSC approaches leads to complex coding and decoding. In
this paper, we propose an alternative approach for merging multiple SI frames,
using a piecewise constant (PWC) function as the merge operator. In our
approach, for each block to be reconstructed, a series of parameters of these
PWC merge functions are transmitted in order to guarantee identical
reconstruction given the known side information blocks. We consider two
different scenarios. In the first case, a target frame is first given, and then
merge parameters are chosen so that this frame can be reconstructed exactly at
the decoder. In contrast, in the second scenario, the reconstructed frame and
merge parameters are jointly optimized to meet a rate-distortion criteria.
Experiments show that for both scenarios, our proposed merge techniques can
outperform both a recent approach based on DSC and the SP-frame approach in
H.264, in terms of compression efficiency and decoder complexity.
"
869,"A New Method For Digital Watermarking Based on Combination of DCT and
  PCA","  In the digital watermarking with DCT method,the watermark is located within a
range of DCT coefficients of the cover image. In this paper to use the
low-frequency band, a new method is proposed by using a combination of the DCT
and PCA transform. The proposed method is compared to other DCT methods, our
method is robust and keeps the quality of cover image, also increases capacity
of the watermarking.
"
870,"A Tutorial of the Mobile Multimedia Wireless Sensor Network OMNeT++
  Framework","  In this work, we will give a detailed tutorial instruction about how to use
the Mobile Multi-Media Wireless Sensor Networks (M3WSN) simulation framework.
The M3WSN framework has been published as a scientific paper in the 6th
International Workshop on OMNeT++ (2013). M3WSN framework enables the
multimedia transmission of real video sequence. Therefore, a set of multimedia
algorithms, protocols, and services can be evaluated by using QoE metrics.
Moreover, key video-related information, such as frame types, GoP length and
intra-frame dependency can be used for creating new assessment and optimization
solutions. To support mobility, M3WSN utilizes different mobility traces to
enable the understanding of how the network behaves under mobile situations.
This tutorial will cover how to install and configure the M3WSN framework,
setting and running the experiments, creating mobility and video traces, and
how to evaluate the performance of different protocols. The tutorial will be
given in an environment of Ubuntu 12.04 LTS and OMNeT++ 4.2.
"
871,"Hardware Implementation of Compressed Sensing based Low Complex Video
  Encoder","  This paper presents a memory efficient VLSI architecture of low complex video
encoder using three dimensional (3-D) wavelet and Compressed Sensing (CS) is
proposed for space and low power video applications. Majority of the
conventional video coding schemes are based on hybrid model, which requires
complex operations like transform coding (DCT), motion estimation and
deblocking filter at the encoder. Complexity of the proposed encoder is reduced
by replacing those complex operations by 3-D DWT and CS at the encoder. The
proposed architecture uses 3-D DWT to enable the scalability with levels of
wavelet decomposition and also to exploit the spatial and the temporal
redundancies. CS provides the good error resilience and coding efficiency. At
the first stage of the proposed architecture for encoder, 3-D DWT has been
applied (Lifting based 2-D DWT in spatial domain and Haar wavelet in temporal
domain) on each frame of the group of frames (GOF), and in the second stage CS
module exploits the sparsity of the wavelet coefficients. Small set of linear
measurements are extracted by projecting the sparse 3-D wavelet coefficients
onto random Bernoulli matrix at the encoder. Compared with the best existing
3-D DWT architectures, the proposed architecture for 3-D DWT requires less
memory and provide high throughput. For an N?N image, the proposed 3-D DWT
architecture consumes a total of only 2?(3N +40P) words of on-chip memory for
the one level of decomposition. The proposed architecture for an encoder is
first of its kind and to the best of my knowledge, no architecture is noted for
comparison. The proposed VLSI architecture of the encoder has been synthesized
on 90-nm CMOS process technology and results show that it consumes 90.08 mW
power and occupies an area equivalent to 416.799 K equivalent gate at frequency
of 158 MHz.
"
872,Vectors of Locally Aggregated Centers for Compact Video Representation,"  We propose a novel vector aggregation technique for compact video
representation, with application in accurate similarity detection within large
video datasets. The current state-of-the-art in visual search is formed by the
vector of locally aggregated descriptors (VLAD) of Jegou et. al. VLAD generates
compact video representations based on scale-invariant feature transform (SIFT)
vectors (extracted per frame) and local feature centers computed over a
training set. With the aim to increase robustness to visual distortions, we
propose a new approach that operates at a coarser level in the feature
representation. We create vectors of locally aggregated centers (VLAC) by first
clustering SIFT features to obtain local feature centers (LFCs) and then
encoding the latter with respect to given centers of local feature centers
(CLFCs), extracted from a training set. The sum-of-differences between the LFCs
and the CLFCs are aggregated to generate an extremely-compact video description
used for accurate video segment similarity detection. Experimentation using a
video dataset, comprising more than 1000 minutes of content from the Open Video
Project, shows that VLAC obtains substantial gains in terms of mean Average
Precision (mAP) against VLAD and the hyper-pooling method of Douze et. al.,
under the same compaction factor and the same set of distortions.
"
873,Dual-Layer Video Encryption using RSA Algorithm,"  This paper proposes a video encryption algorithm using RSA and Pseudo Noise
(PN) sequence, aimed at applications requiring sensitive video information
transfers. The system is primarily designed to work with files encoded using
the Audio Video Interleaved (AVI) codec, although it can be easily ported for
use with Moving Picture Experts Group (MPEG) encoded files. The audio and video
components of the source separately undergo two layers of encryption to ensure
a reasonable level of security. Encryption of the video component involves
applying the RSA algorithm followed by the PN-based encryption. Similarly, the
audio component is first encrypted using PN and further subjected to encryption
using the Discrete Cosine Transform. Combining these techniques, an efficient
system, invulnerable to security breaches and attacks with favorable values of
parameters such as encryption/decryption speed, encryption/decryption ratio and
visual degradation; has been put forth. For applications requiring encryption
of sensitive data wherein stringent security requirements are of prime concern,
the system is found to yield negligible similarities in visual perception
between the original and the encrypted video sequence. For applications wherein
visual similarity is not of major concern, we limit the encryption task to a
single level of encryption which is accomplished by using RSA, thereby
quickening the encryption process. Although some similarity between the
original and encrypted video is observed in this case, it is not enough to
comprehend the happenings in the video.
"
874,"Kernelized Deep Convolutional Neural Network for Describing Complex
  Images","  With the impressive capability to capture visual content, deep convolutional
neural networks (CNN) have demon- strated promising performance in various
vision-based ap- plications, such as classification, recognition, and objec- t
detection. However, due to the intrinsic structure design of CNN, for images
with complex content, it achieves lim- ited capability on invariance to
translation, rotation, and re-sizing changes, which is strongly emphasized in
the s- cenario of content-based image retrieval. In this paper, to address this
problem, we proposed a new kernelized deep convolutional neural network. We
first discuss our motiva- tion by an experimental study to demonstrate the
sensitivi- ty of the global CNN feature to the basic geometric trans-
formations. Then, we propose to represent visual content with approximate
invariance to the above geometric trans- formations from a kernelized
perspective. We extract CNN features on the detected object-like patches and
aggregate these patch-level CNN features to form a vectorial repre- sentation
with the Fisher vector model. The effectiveness of our proposed algorithm is
demonstrated on image search application with three benchmark datasets.
"
875,"Free-body Gesture Tracking and Augmented Reality Improvisation for Floor
  and Aerial Dance","  This paper describes an updated interactive performance system for floor and
Aerial Dance that controls visual and sonic aspects of the presentation via a
depth sensing camera (MS Kinect). In order to detect, measure and track free
movement in space, 3 degree of freedom (3-DOF) tracking in space (on the ground
and in the air) is performed using IR markers with a method for multi target
tracking capabilities added and described in detail. An improved gesture
tracking and recognition system, called Action Graph (AG), is described in the
paper. Action Graph uses an efficient incremental construction from a single
long sequence of movement features and automatically captures repeated
sub-segments in the movement from start to finish with no manual interaction
needed with other advanced capabilities discussed as well. By using the new
model for the gesture we can unify an entire choreography piece by dynamically
tracking and recognizing gestures and sub-portions of the piece. This gives the
performer the freedom to improvise based on a set of recorded gestures/portions
of the choreography and have the system dynamically respond in relation to the
performer within a set of related rehearsed actions, an ability that has not
been seen in any other system to date.
"
876,User-Curated Image Collections: Modeling and Recommendation,"  Most state-of-the-art image retrieval and recommendation systems
predominantly focus on individual images. In contrast, socially curated image
collections, condensing distinctive yet coherent images into one set, are
largely overlooked by the research communities. In this paper, we aim to design
a novel recommendation system that can provide users with image collections
relevant to individual personal preferences and interests. To this end, two key
issues need to be addressed, i.e., image collection modeling and similarity
measurement. For image collection modeling, we consider each image collection
as a whole in a group sparse reconstruction framework and extract concise
collection descriptors given the pretrained dictionaries. We then consider
image collection recommendation as a dynamic similarity measurement problem in
response to user's clicked image set, and employ a metric learner to measure
the similarity between the image collection and the clicked image set. As there
is no previous work directly comparable to this study, we implement several
competitive baselines and related methods for comparison. The evaluations on a
large scale Pinterest data set have validated the effectiveness of our proposed
methods for modeling and recommending image collections.
"
877,"Fast and Efficient Sparse 2D Discrete Fourier Transform using
  Sparse-Graph Codes","  We present a novel algorithm, named the 2D-FFAST, to compute a sparse
2D-Discrete Fourier Transform (2D-DFT) featuring both low sample complexity and
low computational complexity. The proposed algorithm is based on mixed concepts
from signal processing (sub-sampling and aliasing), coding theory (sparse-graph
codes) and number theory (Chinese-remainder-theorem) and generalizes the
1D-FFAST 2 algorithm recently proposed by Pawar and Ramchandran [1] to the 2D
setting. Concretely, our proposed 2D-FFAST algorithm computes a k-sparse
2D-DFT, with a uniformly random support, of size N = Nx x Ny using O(k)
noiseless spatial-domain measurements in O(k log k) computational time. Our
results are attractive when the sparsity is sub-linear with respect to the
signal dimension, that is, when k -> infinity and k/N -> 0. For the case when
the spatial-domain measurements are corrupted by additive noise, our 2D-FFAST
framework extends to a noise-robust version in sub-linear time of O(k log4 N )
using O(k log3 N ) measurements. Simulation results, on synthetic images as
well as real-world magnetic resonance images, are provided in Section VII and
demonstrate the empirical performance of the proposed 2D-FFAST algorithm.
"
878,Fusing Multi-Stream Deep Networks for Video Classification,"  This paper studies deep network architectures to address the problem of video
classification. A multi-stream framework is proposed to fully utilize the rich
multimodal information in videos. Specifically, we first train three
Convolutional Neural Networks to model spatial, short-term motion and audio
clues respectively. Long Short Term Memory networks are then adopted to explore
long-term temporal dynamics. With the outputs of the individual streams, we
propose a simple and effective fusion method to generate the final predictions,
where the optimal fusion weights are learned adaptively for each class, and the
learning process is regularized by automatically estimated class relationships.
Our contributions are two-fold. First, the proposed multi-stream framework is
able to exploit multimodal features that are more comprehensive than those
previously attempted. Second, we demonstrate that the adaptive fusion method
using the class relationship as a regularizer outperforms traditional
alternatives that estimate the weights in a ""free"" fashion. Our framework
produces significantly better results than the state of the arts on two popular
benchmarks, 92.2\% on UCF-101 (without using audio) and 84.9\% on Columbia
Consumer Videos.
"
879,"A Resource Allocation Mechanism for Video Mixing as a Cloud Computing
  Service in Multimedia Conferencing Applications","  Multimedia conferencing is the conversational exchange of multimedia content
between multiple parties. It has a wide range of applications (e.g. Massively
Multiplayer Online Games (MMOGs) and distance learning). Many multimedia
conferencing applications use video extensively, thus video mixing in
conferencing settings is of critical importance. Cloud computing is a
technology that can solve the scalability issue in multimedia conferencing,
while bringing other benefits, such as, elasticity, efficient use of resources,
rapid development, and introduction of new applications. However, proposed
cloud-based multimedia conferencing approaches so far have several deficiencies
when it comes to efficient resource usage while meeting Quality of Service
(QoS) requirements. We propose a solution to optimize resource allocation for
cloud-based video mixing service in multimedia conferencing applications, which
can support scalability in terms of number of users, while guaranteeing QoS. We
formulate the resource allocation problem mathematically as an Integer Linear
Programming (ILP) problem and design a heuristic for it. Simulation results
show that our resource allocation model can support more participants compared
to the state-of-the-art, while honoring QoS, with respect to end-to-end delay.
"
880,"Feature Evaluation of Deep Convolutional Neural Networks for Object
  Recognition and Detection","  In this paper, we evaluate convolutional neural network (CNN) features using
the AlexNet architecture and very deep convolutional network (VGGNet)
architecture. To date, most CNN researchers have employed the last layers
before output, which were extracted from the fully connected feature layers.
However, since it is unlikely that feature representation effectiveness is
dependent on the problem, this study evaluates additional convolutional layers
that are adjacent to fully connected layers, in addition to executing simple
tuning for feature concatenation (e.g., layer 3 + layer 5 + layer 7) and
transformation, using tools such as principal component analysis. In our
experiments, we carried out detection and classification tasks using the
Caltech 101 and Daimler Pedestrian Benchmark Datasets.
"
881,Data Hiding using Graphical Code based Steganography Technique,"  Data hiding has received much attention due to rapid development of internet
and multimedia technologies where security of information is a very important
concern. This is achieved by Steganography, which is the art or science of
hiding data into another data, so that human eyes cannot catch the hidden
information easily. There are many ways to hide information-like inside an
image, text, audio/ video etc. Among them image steganography is a very
attractive research area. The goal is to transmit a data within a modified
image (called stego-image)by minimizing the number of bit flips. In this paper,
a new steganography technique has been proposed using Graphical codes and also
comparison with steganography technique using BCH codes has been studied.
"
882,"CVC: The Contourlet Video Compression algorithm for real-time
  applications","  Nowadays, real-time video communication over the internet through video
conferencing applications has become an invaluable tool in everyone's
professional and personal life. This trend underlines the need for video coding
algorithms that provide acceptable quality on low bitrates and can support
various resolutions inside the same stream in order to cope with limitations on
computational resources and network bandwidth. In this work, a novel scalable
video coding algorithm based on the contourlet transform is presented. The
algorithm utilizes both lossy and lossless methods in order to achieve
compression. One of its most notable features is that due to the transform
utilised, it does not suffer from blocking artifacts that occur with many
widely adopted compression algorithms. The proposed algorithm takes advantage
of the vast computational capabilities of modern GPUs, in order to achieve
real-time performance and provide satisfactory encoding and decoding times at
relatively low cost, making it suitable for applications like video
conferencing. Experiments show that the proposed algorithm performs
satisfactorily in terms of compression ratio and speed, while it outperforms
standard methods in terms of perceptual quality on lower bitrates.
"
883,"A System for Precise End-to-End Delay Measurements in Video
  Communication","  Low delay video transmission is becoming increasingly important. Delay
critical, video enabled applications range from teleoperation scenarios such as
controlling drones or telesurgery to autonomous control through computer vision
algorithms applied on real-time video. To judge the quality of the video
transmission in such a system, it is important to be able to precisely measure
the end-to-end (E2E) delay of the transmitted video. We present a
low-complexity system that automatically takes pairwise independent
measurements of E2E delay. The precision can be far below the millisecond
order, mainly limited by the sampling rate of the measurement system. In our
implementation, we achieve a precision of 0.5 milliseconds with a sampling rate
of 2kHz.
"
884,"Ontology-based Secure Retrieval of Semantically Significant Visual
  Contents","  Image classification is an enthusiastic research field where large amount of
image data is classified into various classes based on their visual contents.
Researchers have presented various low-level features-based techniques for
classifying images into different categories. However, efficient and effective
classification and retrieval is still a challenging problem due to complex
nature of visual contents. In addition, the traditional information retrieval
techniques are vulnerable to security risks, making it easy for attackers to
retrieve personal visual contents such as patients records and law enforcement
agencies databases. Therefore, we propose a novel ontology-based framework
using image steganography for secure image classification and information
retrieval. The proposed framework uses domain-specific ontology for mapping the
low-level image features to high-level concepts of ontologies which
consequently results in efficient classification. Furthermore, the proposed
method utilizes image steganography for hiding the image semantics as a secret
message inside them, making the information retrieval process secure from third
parties. The proposed framework minimizes the computational complexity of
traditional techniques, increasing its suitability for secure and real-time
visual contents retrieval from personalized image databases. Experimental
results confirm the efficiency, effectiveness, and security of the proposed
framework as compared with other state-of-the-art systems.
"
885,"NTCCRT: A concurrent constraint framework for real-time interaction
  (extended version)","  Writing multimedia interaction systems is not easy. Their concurrent
processes usually access shared resources in a non-deterministic order, often
leading to unpredictable behavior. Using Pure Data (Pd) and Max/MSP is possible
to program concurrency, however, it is difficult to synchronize processes based
on multiple criteria. Process calculi such as the Non-deterministic Timed
Concurrent Constraint (ntcc) calculus, overcome that problem by representing
multiple criteria as constraints. We propose using our framework Ntccrt to
manage concurrency in Pd and Max. Ntccrt is a real-time capable inter- preter
for ntcc. Using Ntccrt externals (binary plugins) in Pd we ran models for
machine improvisation and signal processing.
"
886,"TagBook: A Semantic Video Representation without Supervision for Event
  Detection","  We consider the problem of event detection in video for scenarios where only
few, or even zero examples are available for training. For this challenging
setting, the prevailing solutions in the literature rely on a semantic video
representation obtained from thousands of pre-trained concept detectors.
Different from existing work, we propose a new semantic video representation
that is based on freely available social tagged videos only, without the need
for training any intermediate concept detectors. We introduce a simple
algorithm that propagates tags from a video's nearest neighbors, similar in
spirit to the ones used for image retrieval, but redesign it for video event
detection by including video source set refinement and varying the video tag
assignment. We call our approach TagBook and study its construction,
descriptiveness and detection performance on the TRECVID 2013 and 2014
multimedia event detection datasets and the Columbia Consumer Video dataset.
Despite its simple nature, the proposed TagBook video representation is
remarkably effective for few-example and zero-example event detection, even
outperforming very recent state-of-the-art alternatives building on supervised
representations.
"
887,Congestion Control for P2P Live Streaming,"  In recent years, research efforts tried to exploit peer-to-peer (P2P) systems
in order to provide Live Streaming (LS) and Video-on-Demand (VoD) services.
Most of these research efforts focus on the development of distributed P2P
block schedulers for content exchange among the participating peers and on the
characteristics of the overlay graph (P2P overlay) that interconnects the set
of these peers. Currently, researchers try to combine peer-to-peer systems with
cloud infrastructures. They developed monitoring and control architectures that
use resources from the cloud in order to enhance QoS and achieve an attractive
trade-off between stability and low cost operation. However, there is a lack of
research effort on the congestion control of these systems and the existing
congestion control architectures are not suitable for P2P live streaming
traffic (small sequential non persistent traffic towards multiple network
locations). This paper proposes a P2P live streaming traffic aware congestion
control protocol that: i) is capable to manage sequential traffic heading to
multiple network destinations , ii) efficiently exploits the available
bandwidth, iii) accurately measures the idle peer resources, iv) avoids network
congestion, and v) is friendly to traditional TCP generated traffic. The
proposed P2P congestion control has been implemented, tested and evaluated
through a series of real experiments powered across the BonFIRE infrastructure.
"
888,"Towards non-threaded Concurrent Constraint Programming for implementing
  multimedia interaction systems","  In this work we explain the implementation of event-driven real-time
interpreters for the Concurrent Constraint Programming (CCP) and
Non-deterministic Timed Concurrent Constraint (NTCC) for- malisms. The CCP
interpreter was tested with a program to find, concurrently, paths in a graph
and it will be used in the future to find musical sequences in the music
improvisation software Omax, developed by the French Acoustics/Music Research
Institute (IRCAM). In the other hand, the NTCC interpreter was tested with a
music improvisation system based on NTCC (CCFOMI), developed by the AVISPA
research group and IRCAM. Additionally, we present GECOL 2, a wrapper for the
Generic Constraints Development Environment (GECODE) to Common LISP, de-
veloped to port the interpreters to Common LISP in the future. We concluded
that using GECODE for the concurrency control avoids the need of having threads
and synchronizing them, leading to a simple and efficient implementation of CCP
and NTCC. We also noticed that the time units in NTCC interpreter do not
represent discrete time units, because when we simulate the NTCC specifications
in the interpreter, the time units have different durations. In the future, we
propose forcing the duration of each time unit to a fix time, that way we would
be able to reason about NTCC time units as we do with discrete time units.
"
889,"An Extension of Interactive Scores for Multimedia Scenarios with
  Temporal Relations for Micro and Macro Controls","  Software to design multimedia scenarios is usually based either on a fixed
timeline or on cue lists, but both models are unrelated temporally. On the
contrary, the formalism of interactive scores can describe multimedia scenarios
with flexible and fixed temporal relations among the objects of the scenario,
but cannot express neither temporal relations for micro controls nor signal
processing. We extend interactive scores with such relations and with sound
processing. We show some applications and we describe how they can be
implemented in Pure Data. Our implementation has low average relative jitter
even under high cpu load.
"
890,"Quality-Aware Popularity Based Bandwidth Allocation for Scalable Video
  Broadcast over Wireless Access Networks","  Video broadcast/multicast over wireless access networks is an attractive
research issue in the field of wireless communication. With the rapid
improvement of various wireless network technologies, it is now possible to
provide high quality video transmission over wireless networks. The high
quality video streams need higher bandwidth. Hence, during the video
transmission through wireless networks, it is very important to make the best
utilization of the limited bandwidth. Therefore, when many broadcasting video
sessions are active, the bandwidth per video session can be allocated based on
popularity of the video sessions (programs). Instead of allocating equal
bandwidth to each of them, our proposed scheme allocates bandwidth per
broadcasting video session based on popularity of the video program. When the
system bandwidth is not sufficient to allocate the demanded bandwidth for all
the active video sessions, our proposed scheme efficiently allocates the total
system bandwidth among all the scalable active video sessions in such a way
that higher bandwidth is allocated to higher popularity one. Using the
mathematical and simulation analyses, we show that the proposed scheme
maximizes the average user satisfaction level and achieves the best utilization
of bandwidth. The simulation results indicate that a large number of
subscribers can receive a significantly improved quality of video. To improve
the video quality for large number of subscribers, the only tradeoff is that a
very few subscribers receive slightly degraded video quality.
"
891,"Radio Resource Management Based on Reused Frequency Allocation for
  Dynamic Channel Borrowing Scheme in Wireless Networks","  In the modern era, cellular communication consumers are exponentially
increasing as they find the system more user-friendly. Due to enormous users
and their numerous demands, it has become a mandate to make the best use of the
limited radio resources that assures the highest standard of Quality of Service
(QoS). To reach the guaranteed level of QoS for the maximum number of users,
maximum utilization of bandwidth is not only the key issue to be considered,
rather some other factors like interference, call blocking probability etc. are
also needed to keep under deliberation. The lower performances of these factors
may retrograde the overall cellular networks performances. Keeping these
difficulties under consideration, we propose an effective dynamic channel
borrowing model that safeguards better QoS, other factors as well. The proposed
scheme reduces the excessive overall call blocking probability and does
interference mitigation without sacrificing bandwidth utilization. The proposed
scheme is modeled in such a way that the cells are bifurcated after the channel
borrowing process if the borrowed channels have the same type of frequency band
(i.e. reused frequency). We also propose that the unoccupied interfering
channels of adjacent cells can also be inactivated, instead of cell bifurcation
for interference mitigation. The simulation endings show satisfactory
performances in terms of overall call blocking probability and bandwidth
utilization that are compared to the conventional scheme without channel
borrowing. Furthermore, signal to interference plus noise ratio (SINR) level,
capacity, and outage probability are compared to the conventional scheme
without interference mitigation after channel borrowing that may attract the
considerable concentration to the operators.
"
892,Sketch-based Manga Retrieval using Manga109 Dataset,"  Manga (Japanese comics) are popular worldwide. However, current e-manga
archives offer very limited search support, including keyword-based search by
title or author, or tag-based categorization. To make the manga search
experience more intuitive, efficient, and enjoyable, we propose a content-based
manga retrieval system. First, we propose a manga-specific image-describing
framework. It consists of efficient margin labeling, edge orientation histogram
feature description, and approximate nearest-neighbor search using product
quantization. Second, we propose a sketch-based interface as a natural way to
interact with manga content. The interface provides sketch-based querying,
relevance feedback, and query retouch. For evaluation, we built a novel dataset
of manga images, Manga109, which consists of 109 comic books of 21,142 pages
drawn by professional manga artists. To the best of our knowledge, Manga109 is
currently the biggest dataset of manga images available for research. We
conducted a comparative study, a localization evaluation, and a large-scale
qualitative study. From the experiments, we verified that: (1) the retrieval
accuracy of the proposed method is higher than those of previous methods; (2)
the proposed method can localize an object instance with reasonable runtime and
accuracy; and (3) sketch querying is useful for manga search.
"
893,Secure Image Steganography using Cryptography and Image Transposition,"  Information security is one of the most challenging problems in today's
technological world. In order to secure the transmission of secret data over
the public network (Internet), various schemes have been presented over the
last decade. Steganography combined with cryptography, can be one of the best
choices for solving this problem. This paper proposes a new steganographic
method based on gray-level modification for true colour images using image
transposition, secret key and cryptography. Both the secret key and secret
information are initially encrypted using multiple encryption algorithms
(bitxor operation, bits shuffling, and stego key-based encryption); these are,
subsequently, hidden in the host image pixels. In addition, the input image is
transposed before data hiding. Image transposition, bits shuffling, bitxoring,
stego key-based encryption, and gray-level modification introduce five
different security levels to the proposed scheme, making the data recovery
extremely difficult for attackers. The proposed technique is evaluated by
objective analysis using various image quality assessment metrics, producing
promising results in terms of imperceptibility and security. Moreover, the high
quality stego images and its minimal histogram changeability, also validate the
effectiveness of the proposed approach.
"
894,MSoS: A Multi-Screen-Oriented Web Page Segmentation Approach,"  In this paper we describe a multiscreen-oriented approach for segmenting web
pages. The segmentation is an automatic and hybrid visual and structural
method. It aims at creating coherent blocks which have different functions
determined by the multiscreen environment. It is also characterized by a
dynamic adaptation to the page content. Experiments are conducted on a set of
existing applications that contain multimedia elements, in particular YouTube
and video player pages. Results are compared with one seg-mentation method from
the literature and with a ground truth manually created. With a 75% precision,
the MSoS is a promising method that is capable of producing good segmentation
results.
"
895,"Towards Reversible De-Identification in Video Sequences Using 3D Avatars
  and Steganography","  We propose a de-identification pipeline that protects the privacy of humans
in video sequences by replacing them with rendered 3D human models, hence
concealing their identity while retaining the naturalness of the scene. The
original images of humans are steganographically encoded in the carrier image,
i.e. the image containing the original scene and the rendered 3D human models.
We qualitatively explore the feasibility of our approach, utilizing the Kinect
sensor and its libraries to detect and localize human joints. A 3D avatar is
rendered into the scene using the obtained joint positions, and the original
human image is steganographically encoded in the new scene. Our qualitative
evaluation shows reasonably good results that merit further exploration.
"
896,"The Virtual Splitter: Refactoring Web Applications for the Multiscreen
  Environment","  Creating web applications for the multiscreen environment is still a
challenge. One approach is to transform existing single-screen applications but
this has not been done yet automatically or generically. This paper proposes a
refactor-ing system. It consists of a generic and extensible mapping phase that
automatically analyzes the application content based on a semantic or a visual
criterion determined by the author or the user, and prepares it for the
splitting process. The system then splits the application and as a result
delivers two instrumented applications ready for distribution across devices.
During runtime, the system uses a mirroring phase to maintain the functionality
of the distributed application and to support a dynamic splitting process.
Developed as a Chrome extension, our approach is validated on several web
applications, including a YouTube page and a video application from Mozilla.
"
897,"Content-Aware Delivery of Scalable Video in Network Coding Enabled Named
  Data Networks","  In this paper, we propose a novel network coding enabled NDN architecture for
the delivery of scalable video. Our scheme utilizes network coding in order to
address the problem that arises in the original NDN protocol, where optimal use
of the bandwidth and caching resources necessitates the coordination of the
forwarding decisions. To optimize the performance of the proposed network
coding based NDN protocol and render it appropriate for transmission of
scalable video, we devise a novel rate allocation algorithm that decides on the
optimal rates of Interest messages sent by clients and intermediate nodes. This
algorithm guarantees that the achieved flow of Data objects will maximize the
average quality of the video delivered to the client population. To support the
handling of Interest messages and Data objects when intermediate nodes perform
network coding, we modify the standard NDN protocol and introduce the use of
Bloom filters, which store efficiently additional information about the
Interest messages and Data objects. The proposed architecture is evaluated for
transmission of scalable video over PlanetLab topologies. The evaluation shows
that the proposed scheme performs very close to the optimal performance.
"
898,A Deep Siamese Network for Scene Detection in Broadcast Videos,"  We present a model that automatically divides broadcast videos into coherent
scenes by learning a distance measure between shots. Experiments are performed
to demonstrate the effectiveness of our approach by comparing our algorithm
against recent proposals for automatic scene segmentation. We also propose an
improved performance measure that aims to reduce the gap between numerical
evaluation and expected results, and propose and release a new benchmark
dataset.
"
899,A new chaos-based watermarking algorithm,"  This paper introduces a new watermarking algorithm based on discrete chaotic
iterations. After defining some coefficients deduced from the description of
the carrier medium, chaotic discrete iterations are used to mix the watermark
and to embed it in the carrier medium. It can be proved that this procedure
generates topological chaos, which ensures that desired properties of a
watermarking algorithm are satisfied.
"
900,"Queueing Analysis of Unicast IPTV With User Mobility and Adaptive
  Modulation and Coding in Wireless Cellular Networks","  Unicast IPTV services that can support live TV, video-on-demand (VoD), video
conferencing, and online gaming applications over broadband wireless cellular
networks have been becoming popular in recent years. However, video streaming
services significantly impact the performance of wireless cellular networks
because they are bandwidth hogs. To maintain the system performance, effective
admission control and resource allocation mechanisms based on an accurate
mathematical analysis are required. On the other hand, the quality of a
wireless link usually changes with time due to the user mobility or
time-varying channel characteristics. To counteract such time-varying channels
and improve the spectral efficiency, adaptive modulation and coding (AMC)
scheme can be adopted in offering unicast IPTV services for mobile users. In
this paper, closed-form solutions for the bandwidth usage, blocking rate, and
dropping rate of unicast IPTV services over wireless cellular networks were
derived based on the novel queueing model that considers both user mobility and
AMC. Simulations were also conducted to validate the accuracy of analytical
results. Numerical results demonstrate that the presented analytical results
are accurate. Based on the accurate closed-form solutions, network providers
can implement precise admission control and resource allocation for their
networks to enhance the system performance.
"
901,VideoStory Embeddings Recognize Events when Examples are Scarce,"  This paper aims for event recognition when video examples are scarce or even
completely absent. The key in such a challenging setting is a semantic video
representation. Rather than building the representation from individual
attribute detectors and their annotations, we propose to learn the entire
representation from freely available web videos and their descriptions using an
embedding between video features and term vectors. In our proposed embedding,
which we call VideoStory, the correlations between the terms are utilized to
learn a more effective representation by optimizing a joint objective balancing
descriptiveness and predictability.We show how learning the VideoStory using a
multimodal predictability loss, including appearance, motion and audio
features, results in a better predictable representation. We also propose a
variant of VideoStory to recognize an event in video from just the important
terms in a text query by introducing a term sensitive descriptiveness loss. Our
experiments on three challenging collections of web videos from the NIST
TRECVID Multimedia Event Detection and Columbia Consumer Videos datasets
demonstrate: i) the advantages of VideoStory over representations using
attributes or alternative embeddings, ii) the benefit of fusing video
modalities by an embedding over common strategies, iii) the complementarity of
term sensitive descriptiveness and multimodal predictability for event
recognition without examples. By it abilities to improve predictability upon
any underlying video feature while at the same time maximizing semantic
descriptiveness, VideoStory leads to state-of-the-art accuracy for both few-
and zero-example recognition of events in video.
"
902,"A Novel Adaptation Method for HTTP Streaming of VBR Videos over Mobile
  Networks","  Recently, HTTP streaming has become very popular for delivering video over
the Internet. For adaptivity, a provider should generate multiple versions of a
video as well as the related metadata. Various adaptation methods have been
proposed to support a streaming client in coping with strong bandwidth
variations. However, most of existing methods target at constant bitrate (CBR)
videos only. In this paper, we present a new method for quality adaptation in
on-demand streaming of variable bitrate (VBR) videos. To cope with strong
variations of VBR bitrate, we use a local average bitrate as the representative
bitrate of a version. A buffer-based algorithm is then proposed to
conservatively adapt video quality. Through experiments, we show that our
method can provide quality stability as well as buffer stability even under
very strong variations of bandwidth and video bitrates.
"
903,"Attribute-Based Multi-Dimensional Scalable Access Control For Social
  Media Sharing","  Media sharing is an extremely popular paradigm of social interaction in
online social networks (OSNs) nowadays. The scalable media access control is
essential to perform information sharing among users with various access
privileges. In this paper, we present a multi-dimensional scalable media access
control (MD-SMAC) system based on the proposed scalable ciphertext policy
attribute-based encryption (SCP-ABE) algorithm. In the proposed MD-SMAC system,
fine-grained access control can be performed on the media contents encoded in a
multi-dimensional scalable manner based on data consumers' diverse attributes.
Through security analysis, we show that the proposed MC-SMAC system is able to
resist collusion attacks. Additionally, we conduct experiments to evaluate the
efficiency performance of the proposed system, especially on mobile devices.
"
904,A GMM-Based Stair Quality Model for Human Perceived JPEG Images,"  Based on the notion of just noticeable differences (JND), a stair quality
function (SQF) was recently proposed to model human perception on JPEG images.
Furthermore, a k-means clustering algorithm was adopted to aggregate JND data
collected from multiple subjects to generate a single SQF. In this work, we
propose a new method to derive the SQF using the Gaussian Mixture Model (GMM).
The newly derived SQF can be interpreted as a way to characterize the mean
viewer experience. Furthermore, it has a lower information criterion (BIC)
value than the previous one, indicating that it offers a better model. A
specific example is given to demonstrate the advantages of the new approach.
"
905,"Optimization of the Block-level Bit Allocation in Perceptual Video
  Coding based on MINMAX","  In video coding, it is expected that the encoder could adaptively select the
encoding parameters (e.g., quantization parameter) to optimize the bit
allocation to different sources under the given constraint. However, in hybrid
video coding, the dependency between sources brings high complexity for the bit
allocation optimization, especially in the block-level, and existing
optimization methods mostly focus on frame-level bit allocation. In this paper,
we propose a macroblock (MB) level bit allocation method based on the minimum
maximum (MINMAX) criterion, which has acceptable encoding complexity for
offline applications. An iterative-based algorithm, namely maximum distortion
descend (MDD), is developed to reduce quality fluctuation among MBs within a
frame, where the Structure SIMilarity (SSIM) index is used to measure the
perceptual distortion of MBs. Our extensive experimental results on benchmark
video sequences show that the proposed method can greatly enhance the encoding
performance in terms of both bits saving and perceptual quality improvement.
"
906,"Heterogeneous Knowledge Transfer in Video Emotion Recognition,
  Attribution and Summarization","  Emotion is a key element in user-generated videos. However, it is difficult
to understand emotions conveyed in such videos due to the complex and
unstructured nature of user-generated content and the sparsity of video frames
expressing emotion. In this paper, for the first time, we study the problem of
transferring knowledge from heterogeneous external sources, including image and
textual data, to facilitate three related tasks in understanding video emotion:
emotion recognition, emotion attribution and emotion-oriented summarization.
Specifically, our framework (1) learns a video encoding from an auxiliary
emotional image dataset in order to improve supervised video emotion
recognition, and (2) transfers knowledge from an auxiliary textual corpora for
zero-shot recognition of emotion classes unseen during training. The proposed
technique for knowledge transfer facilitates novel applications of emotion
attribution and emotion-oriented summarization. A comprehensive set of
experiments on multiple datasets demonstrate the effectiveness of our
framework.
"
907,"Deep learning is a good steganalysis tool when embedding key is reused
  for different images, even if there is a cover source-mismatch","  Since the BOSS competition, in 2010, most steganalysis approaches use a
learning methodology involving two steps: feature extraction, such as the Rich
Models (RM), for the image representation, and use of the Ensemble Classifier
(EC) for the learning step. In 2015, Qian et al. have shown that the use of a
deep learning approach that jointly learns and computes the features, is very
promising for the steganalysis. In this paper, we follow-up the study of Qian
et al., and show that, due to intrinsic joint minimization, the results
obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural
Network (FNN), if well parameterized, surpass the conventional use of a RM with
an EC. First, numerous experiments were conducted in order to find the best ""
shape "" of the CNN. Second, experiments were carried out in the clairvoyant
scenario in order to compare the CNN and FNN to an RM with an EC. The results
show more than 16% reduction in the classification error with our CNN or FNN.
Third, experiments were also performed in a cover-source mismatch setting. The
results show that the CNN and FNN are naturally robust to the mismatch problem.
In Addition to the experiments, we provide discussions on the internal
mechanisms of a CNN, and weave links with some previously stated ideas, in
order to understand the impressive results we obtained.
"
908,"Analysis and Optimization of Sparse Random Linear Network Coding for
  Reliable Multicast Services","  Point-to-multipoint communications are expected to play a pivotal role in
next-generation networks. This paper refers to a cellular system transmitting
layered multicast services to a multicast group of users. Reliability of
communications is ensured via different Random Linear Network Coding (RLNC)
techniques. We deal with a fundamental problem: the computational complexity of
the RLNC decoder. The higher the number of decoding operations is, the more the
user's computational overhead grows and, consequently, the faster the battery
of mobile devices drains. By referring to several sparse RLNC techniques, and
without any assumption on the implementation of the RLNC decoder in use, we
provide an efficient way to characterize the performance of users targeted by
ultra-reliable layered multicast services. The proposed modeling allows to
efficiently derive the average number of coded packet transmissions needed to
recover one or more service layers. We design a convex resource allocation
framework that allows to minimize the complexity of the RLNC decoder by jointly
optimizing the transmission parameters and the sparsity of the code. The
designed optimization framework also ensures service guarantees to
predetermined fractions of users. The performance of the proposed optimization
framework is then investigated in a LTE-A eMBMS network multicasting H.264/SVC
video services.
"
909,"An Immersive Telepresence System using RGB-D Sensors and Head Mounted
  Display","  We present a tele-immersive system that enables people to interact with each
other in a virtual world using body gestures in addition to verbal
communication. Beyond the obvious applications, including general online
conversations and gaming, we hypothesize that our proposed system would be
particularly beneficial to education by offering rich visual contents and
interactivity. One distinct feature is the integration of egocentric pose
recognition that allows participants to use their gestures to demonstrate and
manipulate virtual objects simultaneously. This functionality enables the
instructor to ef- fectively and efficiently explain and illustrate complex
concepts or sophisticated problems in an intuitive manner. The highly
interactive and flexible environment can capture and sustain more student
attention than the traditional classroom setting and, thus, delivers a
compelling experience to the students. Our main focus here is to investigate
possible solutions for the system design and implementation and devise
strategies for fast, efficient computation suitable for visual data processing
and network transmission. We describe the technique and experiments in details
and provide quantitative performance results, demonstrating our system can be
run comfortably and reliably for different application scenarios. Our
preliminary results are promising and demonstrate the potential for more
compelling directions in cyberlearning.
"
910,Understanding Music Playlists,"  As music streaming services dominate the music industry, the playlist is
becoming an increasingly crucial element of music consumption. Con- sequently,
the music recommendation problem is often casted as a playlist generation prob-
lem. Better understanding of the playlist is there- fore necessary for
developing better playlist gen- eration algorithms. In this work, we analyse
two playlist datasets to investigate some com- monly assumed hypotheses about
playlists. Our findings indicate that deeper understanding of playlists is
needed to provide better prior infor- mation and improve machine learning
algorithms in the design of recommendation systems.
"
911,Fine-Grain Annotation of Cricket Videos,"  The recognition of human activities is one of the key problems in video
understanding. Action recognition is challenging even for specific categories
of videos, such as sports, that contain only a small set of actions.
Interestingly, sports videos are accompanied by detailed commentaries available
online, which could be used to perform action annotation in a weakly-supervised
setting. For the specific case of Cricket videos, we address the challenge of
temporal segmentation and annotation of ctions with semantic descriptions. Our
solution consists of two stages. In the first stage, the video is segmented
into ""scenes"", by utilizing the scene category information extracted from
text-commentary. The second stage consists of classifying video-shots as well
as the phrases in the textual description into various categories. The relevant
phrases are then suitably mapped to the video-shots. The novel aspect of this
work is the fine temporal scale at which semantic information is assigned to
the video. As a result of our approach, we enable retrieval of specific actions
that last only a few seconds, from several hours of video. This solution yields
a large number of labeled exemplars, with no manual effort, that could be used
by machine learning algorithms to learn complex actions.
"
912,"QoE Optimization of Video Multicast with Heterogeneous Channels and
  Playback Requirements","  We propose an application-layer forward error correction (AL-FEC) code rate
allocation scheme to maximize the quality of experience (QoE) of a video
multicast. The allocation dynamically assigns multicast clients to the quality
layers of a scalable video bitstream, based on their heterogeneous channel
qualities and video playback capabilities. Normalized mean opinion score (NMOS)
is employed to value the client's quality of experience across various possible
adaptations of a multilayer video, coded using mixed spatial-temporal-amplitude
scalability. The scheme provides assurance of reception of the video layers
using fountain coding and effectively allocates coding rates across the layers
to maximize a multicast utility measure. An advantageous feature of the
proposed scheme is that the complexity of the optimization is independent of
the number of clients. Additionally, a convex formulation is proposed that
attains close to the best performance and offers a reliable alternative when
further reduction in computational complexity is desired. The optimization is
extended to perform suppression of QoE fluctuations for clients with marginal
channel qualities. The scheme offers a means to trade-off service utility for
the entire multicast group and clients with the worst channels. According to
the simulation results, the proposed optimization framework is robust against
source rate variations and limited amount of client feedback.
"
913,"Creativity in Mind: Evaluating and Maintaining Advances in Network
  Steganographic Research","  The research discipline of network steganography deals with the hiding of
information within network transmissions, e.g. to transfer illicit information
in networks with Internet censorship. The last decades of research on network
steganography led to more than hundred techniques for hiding data in network
transmissions. However, previous research has shown that most of these hiding
techniques are either based on the same idea or introduce limited novelty,
enabling the application of existing countermeasures. In this paper, we provide
a link between the field of creativity and network steganographic research. We
propose a framework and a metric to help evaluating the creativity bound to a
given hiding technique. This way, we support two sides of the scientific peer
review process as both authors and reviewers can use our framework to analyze
the novelty and applicability of hiding techniques. At the same time, we
contribute to a uniform terminology in network steganography.
"
914,Steganography: A Secure way for Transmission in Wireless Sensor Networks,"  Addressing the security concerns in wireless sensor networks (WSN) is a
challenging task, which has attracted the attention of many researchers from
the last few decades. Researchers have presented various schemes in WSN,
addressing the problems of processing, bandwidth, load balancing, and efficient
routing. However, little work has been done on security aspects of WSN. In a
typical WSN network, the tiny nodes installed on different locations sense the
surrounding environment, send the collected data to their neighbors, which in
turn is forwarded to a sink node. The sink node aggregate the data received
from different sensors and send it to the base station for further processing
and necessary actions. In highly critical sensor networks such as military and
law enforcement agencies networks, the transmission of such aggregated data via
the public network Internet is very sensitive and vulnerable to various attacks
and risks. Therefore, this paper provides a solution for addressing these
security issues based on steganography, where the aggregated data can be
embedded as a secret message inside an innocent-looking cover image. The stego
image containing the embedded data can be then sent to fusion center using
Internet. At the fusion center, the hidden data is extracted from the image,
the required processing is performed and decision is taken accordingly.
Experimentally, the proposed method is evaluated by objective analysis using
peak signal-to-noise ratio (PSNR), mean square error (MSE), normalized cross
correlation (NCC), and structural similarity index metric (SSIM), providing
promising results in terms of security and image quality, thus validating its
superiority.
"
915,Applying deep learning to classify pornographic images and videos,"  It is no secret that pornographic material is now a one-click-away from
everyone, including children and minors. General social media networks are
striving to isolate adult images and videos from normal ones. Intelligent image
analysis methods can help to automatically detect and isolate questionable
images in media. Unfortunately, these methods require vast experience to design
the classifier including one or more of the popular computer vision feature
descriptors. We propose to build a classifier based on one of the recently
flourishing deep learning techniques. Convolutional neural networks contain
many layers for both automatic features extraction and classification. The
benefit is an easier system to build (no need for hand-crafting features and
classifiers). Additionally, our experiments show that it is even more accurate
than the state of the art methods on the most recent benchmark dataset.
"
916,"Window-Object Relationship Guided Representation Learning for Generic
  Object Detections","  In existing works that learn representation for object detection, the
relationship between a candidate window and the ground truth bounding box of an
object is simplified by thresholding their overlap. This paper shows
information loss in this simplification and picks up the relative location/size
information discarded by thresholding. We propose a representation learning
pipeline to use the relationship as supervision for improving the learned
representation in object detection. Such relationship is not limited to object
of the target category, but also includes surrounding objects of other
categories. We show that image regions with multiple contexts and multiple
rotations are effective in capturing such relationship during the
representation learning process and in handling the semantic and visual
variation caused by different window-object configurations. Experimental
results show that the representation learned by our approach can improve the
object detection accuracy by 6.4% in mean average precision (mAP) on
ILSVRC2014. On the challenging ILSVRC2014 test dataset, 48.6% mAP is achieved
by our single model and it is the best among published results. On PASCAL VOC,
it outperforms the state-of-the-art result of Fast RCNN by 3.3% in absolute
mAP.
"
917,"A proposal project for a blind image quality assessment by learning
  distortions from the full reference image quality assessments","  This short paper presents a perspective plan to build a null reference image
quality assessment. Its main goal is to deliver both the objective score and
the distortion map for a given distorted image without the knowledge of its
reference image.
"
918,On Deep Representation Learning from Noisy Web Images,"  The keep-growing content of Web images may be the next important data source
to scale up deep neural networks, which recently obtained a great success in
the ImageNet classification challenge and related tasks. This prospect,
however, has not been validated on convolutional networks (convnet) -- one of
best performing deep models -- because of their supervised regime. While
unsupervised alternatives are not so good as convnet in generalizing the
learned model to new domains, we use convnet to leverage semi-supervised
representation learning. Our approach is to use massive amounts of unlabeled
and noisy Web images to train convnets as general feature detectors despite
challenges coming from data such as high level of mislabeled data, outliers,
and data biases. Extensive experiments are conducted at several data scales,
different network architectures, and data reranking techniques. The learned
representations are evaluated on nine public datasets of various topics. The
best results obtained by our convnets, trained on 3.14 million Web images,
outperform AlexNet trained on 1.2 million clean images of ILSVRC 2012 and is
closing the gap with VGG-16. These prominent results suggest a budget solution
to use deep learning in practice and motivate more research in semi-supervised
representation learning.
"
919,"NEWCAST: Anticipating Resource Management and QoE Provisioning for
  Mobile Video Streaming","  The knowledge of future throughput variations in mobile networks becomes more
and more possible today thanks to the rich contextual information provided by
mobile applications and services and smartphone sensors. It is even likely that
such contextual information, which may include traffic, mobility and radio
conditions will lead to a novel agile resource management not yet thought of.
In this paper, we propose an framework (called NEWCAST) that anticipates the
throughput variations to deliver video streaming content. We develop an
optimization problem that realizes a fundamental trade-off among critical
metrics that impact the user's perceptual quality of experience (QoE) and the
cost of system utilization. Both simulated and real-world throughput traces
collected from [1], were carried out to evaluate the performance of NEWCAST. In
particular, we show from our numerical results that NEWCAST provides the
efficiency that the new 5G architectures require in terms of computational
complexity and robustness. We also implement a prototype system of NEWCAST and
evaluate it in a real environment with a real player to show its efficiency and
scalability compared to baseline adaptive bitrate algorithms.
"
920,"Real-Time Audio-to-Score Alignment of Music Performances Containing
  Errors and Arbitrary Repeats and Skips","  This paper discusses real-time alignment of audio signals of music
performance to the corresponding score (a.k.a. score following) which can
handle tempo changes, errors and arbitrary repeats and/or skips (repeats/skips)
in performances. This type of score following is particularly useful in
automatic accompaniment for practices and rehearsals, where errors and
repeats/skips are often made. Simple extensions of the algorithms previously
proposed in the literature are not applicable in these situations for scores of
practical length due to the problem of large computational complexity. To cope
with this problem, we present two hidden Markov models of monophonic
performance with errors and arbitrary repeats/skips, and derive efficient
score-following algorithms with an assumption that the prior probability
distributions of score positions before and after repeats/skips are independent
from each other. We confirmed real-time operation of the algorithms with music
scores of practical length (around 10000 notes) on a modern laptop and their
tracking ability to the input performance within 0.7 s on average after
repeats/skips in clarinet performance data. Further improvements and extension
for polyphonic signals are also discussed.
"
921,An Overview of Emerging Technologies for High Efficiency 3D Video Coding,"  3D video coding is one of the most popular research area in multimedia. This
paper reviews the recent progress of the coding technologies for multiview
video (MVV) and free view-point video (FVV) which is represented by MVV and
depth maps. We first discuss the traditional multiview video coding (MVC)
framework with different prediction structures. The rate-distortion performance
and the view switching delay of the three main coding prediction structures are
analyzed. We further introduce the joint coding technologies for MVV and depth
maps and evaluate the rate-distortion performance of them. The scalable 3D
video coding technologies are reviewed by the quality and view scalability,
respectively. Finally, we summarize the bit allocation work of 3D video coding.
This paper also points out some future research problems in high efficiency 3D
video coding such as the view switching latency optimization in coding
structure and bit allocation.
"
922,"Capacity Enlargement Of The PVD Steganography Method Using The GLM
  Technique","  In most steganographic methods, increasing in the capacity leads to decrease
in the quality of the stego-image, so in this paper, we propose to combine two
existing techniques, Pixel value differencing and Gray Level Modification, to
come up with a hybrid steganography scheme which can hide more information
without having to compromise much on the quality of the stego-image.
Experimental results demonstrate that the proposed approach has larger capacity
while its results are imperceptible. In comparison with original PVD method
criterion of the quality is declined by 2% dB averagely while the capacity is
increased around 25%.
"
923,Multimodal Classification of Events in Social Media,"  A large amount of social media hosted on platforms like Flickr and Instagram
is related to social events. The task of social event classification refers to
the distinction of event and non-event-related content as well as the
classification of event types (e.g. sports events, concerts, etc.). In this
paper, we provide an extensive study of textual, visual, as well as multimodal
representations for social event classification. We investigate strengths and
weaknesses of the modalities and study synergy effects between the modalities.
Experimental results obtained with our multimodal representation outperform
state-of-the-art methods and provide a new baseline for future research.
"
924,"A New Image Steganographic Technique using Pattern based Bits Shuffling
  and Magic LSB for Grayscale Images","  Image Steganography is a growing research area of information security where
secret information is embedded in innocent-looking public communication. This
paper proposes a novel crystographic technique for grayscale images in spatial
domain. The secret data is encrypted and shuffled using pattern based bits
shuffling algorithm (PBSA) and a secret key. The encrypted data is then
embedded in the cover image using magic least significant bit (M-LSB) method.
Experimentally, the proposed method is evaluated by qualitative and
quantitative analysis which validates the effectiveness of the proposed method
in contrast to several state-of-the-art methods.
"
925,"Comparison of cinepak, intel, microsoft video and indeo codec for video
  compression","  The file size and picture quality are factors to be considered for streaming,
storage and transmitting videos over networks. This work compares Cinepak,
Intel, Microsoft Video and Indeo Codec for video compression. The peak signal
to noise ratio is used to compare the quality of such video compressed using
AVI codecs. The most widely used objective measurement by developers of video
processing systems is Peak Signal-to-Noise Ratio (PSNR). Peak Signal to Noise
Ration is measured on a logarithmic scale and depends on the mean squared error
(MSE) between an original and an impaired image or video, relative to (2n-1)2.
  Previous research done regarding assessing of video quality has been mainly
by the use of subjective methods, and there is still no standard method for
objective assessments. Although it has been considered that compression might
not be significant in future as storage and transmission capabilities improve,
but at low bandwidths compression makes communication possible.
"
926,"An Enhanced Edge Adaptive Steganography Approach Using Threshold Value
  for Region Selection","  This paper attempts to improve the quality and the modification rate of a
Stego Image. The input image provided for estimating the quality of an image
and the modified rate is a bitmap image. The threshold value is used as a
parameter for selecting the high frequency pixels from the Cover Image. The
data embedding process are performed on the pixels that are found with the help
of Threshold value by using LSBMR. The quality of an image is estimated by the
value of PSNR and the modification rate of an image is estimated by the value
of MSE. The proposed approach achieves about 0.2 to 0.6 % of improvement in the
quality of an image and about 4 to 10 % of improvement in the modification rate
of an image compared to the edge detection techniques such as Sobel and Canny.
"
927,"Human Attention Estimation for Natural Images: An Automatic Gaze
  Refinement Approach","  Photo collections and its applications today attempt to reflect user
interactions in various forms. Moreover, photo collections aim to capture the
users' intention with minimum effort through applications capturing user
intentions. Human interest regions in an image carry powerful information about
the user's behavior and can be used in many photo applications. Research on
human visual attention has been conducted in the form of gaze tracking and
computational saliency models in the computer vision community, and has shown
considerable progress. This paper presents an integration between implicit gaze
estimation and computational saliency model to effectively estimate human
attention regions in images on the fly. Furthermore, our method estimates human
attention via implicit calibration and incremental model updating without any
active participation from the user. We also present extensive analysis and
possible applications for personal photo collections.
"
928,"Learning Subclass Representations for Visually-varied Image
  Classification","  In this paper, we present a subclass-representation approach that predicts
the probability of a social image belonging to one particular class. We explore
the co-occurrence of user-contributed tags to find subclasses with a strong
connection to the top level class. We then project each image on to the
resulting subclass space to generate a subclass representation for the image.
The novelty of the approach is that subclass representations make use of not
only the content of the photos themselves, but also information on the
co-occurrence of their tags, which determines membership in both subclasses and
top-level classes. The novelty is also that the images are classified into
smaller classes, which have a chance of being more visually stable and easier
to model. These subclasses are used as a latent space and images are
represented in this space by their probability of relatedness to all of the
subclasses. In contrast to approaches directly modeling each top-level class
based on the image content, the proposed method can exploit more information
for visually diverse classes. The approach is evaluated on a set of $2$ million
photos with 10 classes, released by the Multimedia 2013 Yahoo! Large-scale
Flickr-tag Image Classification Grand Challenge. Experiments show that the
proposed system delivers sound performance for visually diverse classes
compared with methods that directly model top classes.
"
929,Digital Image Forensics vs. Image Composition: An Indirect Arms Race,"  The field of image composition is constantly trying to improve the ways in
which an image can be altered and enhanced. While this is usually done in the
name of aesthetics and practicality, it also provides tools that can be used to
maliciously alter images. In this sense, the field of digital image forensics
has to be prepared to deal with the influx of new technology, in a constant
arms-race. In this paper, the current state of this arms-race is analyzed,
surveying the state-of-the-art and providing means to compare both sides. A
novel scale to classify image forensics assessments is proposed, and
experiments are performed to test composition techniques in regards to
different forensics traces. We show that even though research in forensics
seems unaware of the advanced forms of image composition, it possesses the
basic tools to detect it.
"
930,Lossless Intra Coding in HEVC with 3-tap Filters,"  This paper presents a pixel-by-pixel spatial prediction method for lossless
intra coding within High Efficiency Video Coding (HEVC). A well-known previous
pixel-by-pixel spatial prediction method uses only two neighboring pixels for
prediction, based on the angular projection idea borrowed from block-based
intra prediction in lossy coding. This paper explores a method which uses three
neighboring pixels for prediction according to a two-dimensional correlation
model, and the used neighbor pixels and prediction weights change depending on
intra mode. To find the best prediction weights for each intra mode, a
two-stage offline optimization algorithm is used and a number of implementation
aspects are discussed to simplify the proposed prediction method. The proposed
method is implemented in the HEVC reference software and experimental results
show that the explored 3-tap filtering method can achieve an average 11.34%
bitrate reduction over the default lossless intra coding in HEVC. The proposed
method also decreases average decoding time by 12.7% while it increases average
encoding time by 9.7%
"
931,"Multiple Watermarking Algorithm Based on Spread Transform Dither
  Modulation","  Multiple watermarking technique, embedding several watermarks in one carrier,
has enabled many interesting applications. In this study, a novel multiple
watermarking algorithm is proposed based on the spirit of spread transform
dither modulation (STDM). It can embed multiple watermarks into the same region
and the same transform domain of one image; meanwhile, the embedded watermarks
can be extracted independently and blindly in the detector without any
interference. Furthermore, to improve the fidelity of the watermarked image,
the properties of the dither modulation quantizer and the proposed multiple
watermarks embedding strategy are investigated, and two practical optimization
methods are proposed. Finally, to enhance the application flexibility, an
extension of the proposed algorithm is proposed which can sequentially embeds
different watermarks into one image during each stage of its circulation.
Compared with the pioneering multiple watermarking algorithms, the proposed one
owns more flexibility in practical application and is more robust against
distortion due to basic operations such as random noise, JPEG compression and
volumetric scaling.
"
932,"Architecture-Aware Optimization of an HEVC decoder on Asymmetric
  Multicore Processors","  Low-power asymmetric multicore processors (AMPs) attract considerable
attention due to their appealing performance-power ratio for energy-constrained
environments. However, these processors pose a significant programming
challenge due to the integration of cores with different performance
capabilities, asking for an asymmetry-aware scheduling solution that carefully
distributes the workload.
  The recent HEVC standard, which offers several high-level parallelization
strategies, is an important application that can benefit from an implementation
tailored for the low-power AMPs present in many current mobile or hand-held
devices. In this scenario, we present an architecture-aware implementation of
an HEVC decoder that embeds a criticality-aware scheduling strategy tuned for a
Samsung Exynos 5422 system-on-chip furnished with an ARM big.LITTLE AMP. The
performance and energy efficiency of our solution is further enhanced by
exploiting the NEON vector engine available in the ARM big.LITTLE architecture.
Experimental results expose a 1080p real-time HEVC decoding at 24 frames/sec,
and a reduction of energy consumption over 20%.
"
933,"Who Ordered This?: Exploiting Implicit User Tag Order Preferences for
  Personalized Image Tagging","  What makes a person pick certain tags over others when tagging an image? Does
the order that a person presents tags for a given image follow an implicit bias
that is personal? Can these biases be used to improve existing automated image
tagging systems? We show that tag ordering, which has been largely overlooked
by the image tagging community, is an important cue in understanding user
tagging behavior and can be used to improve auto-tagging systems. Inspired by
the assumption that people order their tags, we propose a new way of measuring
tag preferences, and also propose a new personalized tagging objective function
that explicitly considers a user's preferred tag orderings. We also provide a
(partially) greedy algorithm that produces good solutions to our new objective
and under certain conditions produces an optimal solution. We validate our
method on a subset of Flickr images that spans 5000 users, over 5200 tags, and
over 90,000 images. Our experiments show that exploiting personalized tag
orders improves the average performance of state-of-art approaches both on
per-image and per-user bases.
"
934,"QUOTE: ""Querying"" Users as Oracles in Tag Engines - A Semi-Supervised
  Learning Approach to Personalized Image Tagging","  One common trend in image tagging research is to focus on visually relevant
tags, and this tends to ignore the personal and social aspect of tags,
especially on photoblogging websites such as Flickr. Previous work has
correctly identified that many of the tags that users provide on images are not
visually relevant (i.e. representative of the salient content in the image) and
they go on to treat such tags as noise, ignoring that the users chose to
provide those tags over others that could have been more visually relevant.
Another common assumption about user generated tags for images is that the
order of these tags provides no useful information for the prediction of tags
on future images. This assumption also tends to define usefulness in terms of
what is visually relevant to the image. For general tagging or labeling
applications that focus on providing visual information about image content,
these assumptions are reasonable, but when considering personalized image
tagging applications, these assumptions are at best too rigid, ignoring user
choice and preferences.
  We challenge the aforementioned assumptions, and provide a machine learning
approach to the problem of personalized image tagging with the following
contributions: 1.) We reformulate the personalized image tagging problem as a
search/retrieval ranking problem, 2.) We leverage the order of tags, which does
not always reflect visual relevance, provided by the user in the past as a cue
to their tag preferences, similar to click data, 3.) We propose a technique to
augment sparse user tag data (semi-supervision), and 4.) We demonstrate the
efficacy of our method on a subset of Flickr images, showing improvement over
previous state-of-art methods.
"
935,Egocentric Activity Recognition with Multimodal Fisher Vector,"  With the increasing availability of wearable devices, research on egocentric
activity recognition has received much attention recently. In this paper, we
build a Multimodal Egocentric Activity dataset which includes egocentric videos
and sensor data of 20 fine-grained and diverse activity categories. We present
a novel strategy to extract temporal trajectory-like features from sensor data.
We propose to apply the Fisher Kernel framework to fuse video and temporal
enhanced sensor features. Experiment results show that with careful design of
feature extraction and fusion algorithm, sensor data can enhance
information-rich video data. We make publicly available the Multimodal
Egocentric Activity dataset to facilitate future research.
"
936,A Taxonomy of Deep Convolutional Neural Nets for Computer Vision,"  Traditional architectures for solving computer vision problems and the degree
of success they enjoyed have been heavily reliant on hand-crafted features.
However, of late, deep learning techniques have offered a compelling
alternative -- that of automatically learning problem-specific features. With
this new paradigm, every problem in computer vision is now being re-examined
from a deep learning perspective. Therefore, it has become important to
understand what kind of deep networks are suitable for a given problem.
Although general surveys of this fast-moving paradigm (i.e. deep-networks)
exist, a survey specific to computer vision is missing. We specifically
consider one form of deep networks widely used in computer vision -
convolutional neural networks (CNNs). We start with ""AlexNet"" as our base CNN
and then examine the broad variations proposed over time to suit different
applications. We hope that our recipe-style survey will serve as a guide,
particularly for novice practitioners intending to use deep-learning techniques
for computer vision.
"
937,"Privacy, Secrecy, and Storage with Multiple Noisy Measurements of
  Identifiers","  The key-leakage-storage region is derived for a generalization of a classic
two-terminal key agreement model. The additions to the model are that the
encoder observes a hidden, or noisy, version of the identifier, and that the
encoder and decoder can perform multiple measurements. To illustrate the
behavior of the region, the theory is applied to binary identifiers and noise
modeled via binary symmetric channels. In particular, the key-leakage-storage
region is simplified by applying Mrs. Gerber's lemma twice in different
directions to a Markov chain. The growth in the region as the number of
measurements increases is quantified. The amount by which the privacy-leakage
rate reduces for a hidden identifier as compared to a noise-free (visible)
identifier at the encoder is also given. If the encoder incorrectly models the
source as visible, it is shown that substantial secrecy leakage may occur and
the reliability of the reconstructed key might decrease.
"
938,Robust Image Watermarking Using Non-Regular Wavelets,"  An approach to watermarking digital images using non-regular wavelets is
advanced. Non-regular transforms spread the energy in the transform domain. The
proposed method leads at the same time to increased image quality and increased
robustness with respect to lossy compression. The approach provides robust
watermarking by suitably creating watermarked messages that have energy
compaction and frequency spreading. Our experimental results show that the
application of non-regular wavelets, instead of regular ones, can furnish a
superior robust watermarking scheme. The generated watermarked data is more
immune against non-intentional JPEG and JPEG2000 attacks.
"
939,"Revisiting copy-move forgery detection by considering realistic image
  with similar but genuine objects","  Many images, of natural or man-made scenes often contain Similar but Genuine
Objects (SGO). This poses a challenge to existing Copy-Move Forgery Detection
(CMFD) methods which match the key points / blocks, solely based on the pair
similarity in the scene. To address such issue, we propose a novel CMFD method
using Scaled Harris Feature Descriptors (SHFD) that preform consistently well
on forged images with SGO. It involves the following main steps: (i) Pyramid
scale space and orientation assignment are used to keep scaling and rotation
invariance; (ii) Combined features are applied for precise texture description;
(iii) Similar features of two points are matched and RANSAC is used to remove
the false matches. The experimental results indicate that the proposed
algorithm is effective in detecting SGO and copy-move forgery, which compares
favorably to existing methods. Our method exhibits high robustness even when an
image is operated by geometric transformation and post-processing
"
940,"Geo-distinctive Visual Element Matching for Location Estimation of
  Images","  We propose an image representation and matching approach that substantially
improves visual-based location estimation for images. The main novelty of the
approach, called distinctive visual element matching (DVEM), is its use of
representations that are specific to the query image whose location is being
predicted. These representations are based on visual element clouds, which
robustly capture the connection between the query and visual evidence from
candidate locations. We then maximize the influence of visual elements that are
geo-distinctive because they do not occur in images taken at many other
locations. We carry out experiments and analysis for both geo-constrained and
geo-unconstrained location estimation cases using two large-scale,
publicly-available datasets: the San Francisco Landmark dataset with $1.06$
million street-view images and the MediaEval '15 Placing Task dataset with
$5.6$ million geo-tagged images from Flickr. We present examples that
illustrate the highly-transparent mechanics of the approach, which are based on
common sense observations about the visual patterns in image collections. Our
results show that the proposed method delivers a considerable performance
improvement compared to the state of the art.
"
941,"Assessing 3D scan quality in Virtual Reality through paired-comparisons
  psychophysics test","  Consumer 3D scanners and depth cameras are increasingly being used to
generate content and avatars for Virtual Reality (VR) environments and avoid
the inconveniences of hand modeling; however, it is sometimes difficult to
evaluate quantitatively the mesh quality at which 3D scans should be exported,
and whether the object perception might be affected by its shading. We propose
using a paired-comparisons test based on psychophysics of perception to do that
evaluation. As psychophysics is not subject to opinion, skill level, mental
state, or economic situation it can be considered a quantitative way to measure
how people perceive the mesh quality. In particular, we propose using the
psychophysical measure for the comparison of four different levels of mesh
quality (1K, 5K, 10K and 20K triangles). We present two studies within
subjects: in one we investigate the quality perception variations of seeing an
object in a regular screen monitor against an stereoscopic Head Mounted Display
(HMD); while in the second experiment we aim at detecting the effects of
shading into quality perception. At each iteration of the pair-test comparisons
participants pick the mesh that they think had higher quality; by the end of
the experiment we compile a preference matrix. The matrix evidences the
correlation between real quality and assessed quality. Regarding the shading
mode, we find an interaction with quality and shading when the model has high
definition. Furthermore, we assess the subjective realism of the most/least
preferred scans using an Immersive Augmented Reality (IAR) video-see-through
setup. Results show higher levels of realism were perceived through the HMD
than when using a monitor, although the quality was similarly perceived in both
systems.
"
942,"Real Time Video Quality Representation Classification of Encrypted HTTP
  Adaptive Video Streaming - the Case of Safari","  The increasing popularity of HTTP adaptive video streaming services has
dramatically increased bandwidth requirements on operator networks, which
attempt to shape their traffic through Deep Packet Inspection (DPI). However,
Google and certain content providers have started to encrypt their video
services. As a result, operators often encounter difficulties in shaping their
encrypted video traffic via DPI. This highlights the need for new traffic
classification methods for encrypted HTTP adaptive video streaming to enable
smart traffic shaping. These new methods will have to effectively estimate the
quality representation layer and playout buffer. We present a new method and
show for the first time that video quality representation classification for
(YouTube) encrypted HTTP adaptive streaming is possible. We analyze the
performance of this classification method with Safari over HTTPS. Based on a
large number of offline and online traffic classification experiments, we
demonstrate that it can independently classify, in real time, every video
segment into one of the quality representation layers with 97.18% average
accuracy.
"
943,"I Know What You Saw Last Minute - Encrypted HTTP Adaptive Video
  Streaming Title Classification","  Desktops and laptops can be maliciously exploited to violate privacy. There
are two main types of attack scenarios: active and passive. In this paper, we
consider the passive scenario where the adversary does not interact actively
with the device, but he is able to eavesdrop on the network traffic of the
device from the network side. Most of the Internet traffic is encrypted and
thus passive attacks are challenging. Previous research has shown that
information can be extracted from encrypted multimedia streams. This includes
video title classification of non HTTP adaptive streams (non-HAS). This paper
presents an algorithm for encrypted HTTP adaptive video streaming title
classification. We show that an external attacker can identify the video title
from video HTTP adaptive streams (HAS) sites such as YouTube. To the best of
our knowledge, this is the first work that shows this. We provide a large data
set of 10000 YouTube video streams of 100 popular video titles (each title
downloaded 100 times) as examples for this task. The dataset was collected
under real-world network conditions. We present several machine algorithms for
the task and run a through set of experiments, which shows that our
classification accuracy is more than 95%. We also show that our algorithms are
able to classify video titles that are not in the training set as unknown and
some of the algorithms are also able to eliminate false prediction of video
titles and instead report unknown. Finally, we evaluate our algorithms
robustness to delays and packet losses at test time and show that a solution
that uses SVM is the most robust against these changes given enough training
data. We provide the dataset and the crawler for future research.
"
944,Learning Discriminative Features via Label Consistent Neural Network,"  Deep Convolutional Neural Networks (CNN) enforces supervised information only
at the output layer, and hidden layers are trained by back propagating the
prediction error from the output layer without explicit supervision. We propose
a supervised feature learning approach, Label Consistent Neural Network, which
enforces direct supervision in late hidden layers. We associate each neuron in
a hidden layer with a particular class label and encourage it to be activated
for input signals from the same class. More specifically, we introduce a label
consistency regularization called ""discriminative representation error"" loss
for late hidden layers and combine it with classification error loss to build
our overall objective function. This label consistency constraint alleviates
the common problem of gradient vanishing and tends to faster convergence; it
also makes the features derived from late hidden layers discriminative enough
for classification even using a simple $k$-NN classifier, since input signals
from the same class will have very similar representations. Experimental
results demonstrate that our approach achieves state-of-the-art performances on
several public benchmarks for action and object category recognition.
"
945,GECKA3D: A 3D Game Engine for Commonsense Knowledge Acquisition,"  Commonsense knowledge representation and reasoning is key for tasks such as
artificial intelligence and natural language understanding. Since commonsense
consists of information that humans take for granted, gathering it is an
extremely difficult task. In this paper, we introduce a novel 3D game engine
for commonsense knowledge acquisition (GECKA3D) which aims to collect
commonsense from game designers through the development of serious games.
GECKA3D integrates the potential of serious games and games with a purpose.
This provides a platform for the acquisition of re-usable and multi-purpose
knowledge, and also enables the development of games that can provide
entertainment value and teach players something meaningful about the actual
world they live in.
"
946,"Search Tracker: Human-derived object tracking in-the-wild through
  large-scale search and retrieval","  Humans use context and scene knowledge to easily localize moving objects in
conditions of complex illumination changes, scene clutter and occlusions. In
this paper, we present a method to leverage human knowledge in the form of
annotated video libraries in a novel search and retrieval based setting to
track objects in unseen video sequences. For every video sequence, a document
that represents motion information is generated. Documents of the unseen video
are queried against the library at multiple scales to find videos with similar
motion characteristics. This provides us with coarse localization of objects in
the unseen video. We further adapt these retrieved object locations to the new
video using an efficient warping scheme. The proposed method is validated on
in-the-wild video surveillance datasets where we outperform state-of-the-art
appearance-based trackers. We also introduce a new challenging dataset with
complex object appearance changes.
"
947,"Adaptation Logic for HTTP Dynamic Adaptive Streaming using
  Geo-Predictive Crowdsourcing","  The increasing demand for video streaming services with high Quality of
Experience (QoE) has prompted a lot of research on client-side adaptation logic
approaches. However, most algorithms use the client's previous download
experience and do not use a crowd knowledge database generated by users of a
professional service. We propose a new crowd algorithm that maximizes the QoE.
Additionally, we show how crowd information can be integrated into existing
algorithms and illustrate this with two state-of-the-art algorithms. We
evaluate our algorithm and state-of-the-art algorithms (including our modified
algorithms) on a large, real-life crowdsourcing dataset that contains 336,551
samples on network performance. The dataset was provided by WeFi LTD. Our new
algorithm outperforms all other methods in terms of QoS (eMOS).
"
948,"Science on YouTube: What users find when they search for climate science
  and climate manipulation","  Online video-sharing sites such as YouTube are very popular and also used by
a lot of people to obtain knowledge and information, also on science, health
and technology. Technically they could be valuable tools for the public
communication of science and technology, but the users of YouTube are also
confronted with conspiracy theories and erroneous and misleading information
that deviates from scientific consensus views. This contribution details the
results of a study that investigates what kind of information users find when
they are searching for climate science and climate manipulation topics on
YouTube and whether this information corresponds with or challenges scientific
consensus views. An innovative methodological approach using the anonymization
network Tor is introduced for drawing randomized samples of YouTube videos.
This approach was used to select and examine a sample of 140 YouTube videos on
climate topics.
"
949,"Joint Data Detection and Phase Noise Mitigation for Light Field Video
  Transmission in MIMO-OFDM Systems","  Previous studies in the literature for video transmission over wireless
communication systems focused on combating the effects of additive channel
noise and fading channels without taking the impairments in the physical layer
such as phase noise (PHN) into account. Oscillator phase noise impairs the
performance of multi-input multi-output- orthogonal frequency division
multiplexing (MIMO-OFDM) systems in providing high data rates for video
applications and may lead to decoding failure. In this paper, we propose a
light field (LF) video transmission system in wireless channels, and analyze
joint data detection and phase mitigation in MIMO-OFDM systems for LF video
transmission. The signal model and rate-distortion (RD) model for LF video
transmission in the presence of multiple PHNs are discussed. Moreover, we
propose an iterative algorithm based on the extended Kalman filter for joint
data detection and PHN tracking. Numerical results show that the proposed
detector can significantly improve the average bit-error rate (BER) and
peak-to-noise ratio (PSNR) performance for LF video transmission compared to
existing algorithms. Moreover, the BER and PSNR performance of the proposed
system is closer to that of the ideal case of perfect PHN estimation. Finally,
it is demonstrated that the proposed system model and algorithm are well suited
for LF video transmission in wireless channels.
"
950,Gabor Wavelets in Image Processing,"  This work shows the use of a two-dimensional Gabor wavelets in image
processing. Convolution with such a two-dimensional wavelet can be separated
into two series of one-dimensional ones. The key idea of this work is to
utilize a Gabor wavelet as a multiscale partial differential operator of a
given order. Gabor wavelets are used here to detect edges, corners and blobs. A
performance of such an interest point detector is compared to detectors
utilizing a Haar wavelet and a derivative of a Gaussian function. The proposed
approach may be useful when a fast implementation of the Gabor transform is
available or when the transform is already precomputed.
"
951,"Feasible HCCA Polling Mechanism for Video Transmission in IEEE 802.11e
  WLANs","  IEEE 802.11e standard defines two Medium Access Control (MAC) functions to
support Quality of Service (QoS) for wireless local area networks: Enhanced
Distributed Channel Access (EDCA) and HCF Controlled Channel Access (HCCA).
EDCA provides fair prioritized QoS support while HCCA guarantees parameterized
QoS for the traffics with rigid QoS requirements. The latter shows higher QoS
provisioning with Constant Bit Rate (CBR) traffics. However, it does not
efficiently cope with the fluctuation of the Variable Bit Rate (VBR) video
streams since its reference scheduler generates a schedule based on the mean
characteristics of the traffic. Scheduling based on theses characteristics is
not always accurate as these tra_cs show high irregularity over the time. In
this paper, we propose an enhancement on the HCCA polling mechanism to address
the problem of scheduling pre-recorded VBR video streams. Our approach enhances
the polling mechanism by feed-backing the arrival time of the subsequent video
frame of the uplink traffic obtained through cross-layering approach.
Simulation experiments have been conducted on several publicly available video
traces in order to show the efficiency of our mechanism. The simulation results
reveal the efficiency of the proposed mechanism in providing less delay and
high throughput with conserving medium channel through minimizing the number of
Null-Frames caused by wasted polls
"
952,"Providing Dynamic TXOP for QoS Support of Video Transmission in IEEE
  802.11e WLANs","  The IEEE 802.11e standard introduced by IEEE 802.11 Task Group E (TGe)
enhances the Quality of Service (QoS) by means of HCF Controlled Channel Access
(HCCA). The scheduler of HCCA allocates Transmission Opportunities (TXOPs) to
QoS-enabled Station (QSTA) based on their TS Specifications (TSPECs) negotiated
at the traffic setup time so that it is only efficient for Constant Bit Rate
(CBR) applications. However, Variable Bit Rate (VBR) traffics are not
efficiently supported as they exhibit nondeterministic profile during the time.
In this paper, we present a dynamic TXOP assignment Scheduling Algorithm for
supporting the video traffics transmission over IEEE 802.11e wireless networks.
This algorithm uses a piggybacked information about the size of the subsequent
video frames of the uplink traffic to assist the Hybrid Coordinator accurately
assign the TXOP according to the fast changes in the VBR profile. The proposed
scheduling algorithm has been evaluated using simulation with different
variability level video streams. The simulation results show that the proposed
algorithm reduces the delay experienced by VBR traffic streams comparable to
HCCA scheduler due to the accurate assignment of the TXOP which preserve the
channel time for transmission.
"
953,"High-Quality, Low-Delay Music Coding in the Opus Codec","  The IETF recently standardized the Opus codec as RFC6716. Opus targets a wide
range of real-time Internet applications by combining a linear prediction coder
with a transform coder. We describe the transform coder, with particular
attention to the psychoacoustic knowledge built into the format. The result
out-performs existing audio codecs that do not operate under real-time
constraints.
"
954,"A diffusion and clustering-based approach for finding coherent motions
  and understanding crowd scenes","  This paper addresses the problem of detecting coherent motions in crowd
scenes and presents its two applications in crowd scene understanding: semantic
region detection and recurrent activity mining. It processes input motion
fields (e.g., optical flow fields) and produces a coherent motion filed, named
as thermal energy field. The thermal energy field is able to capture both
motion correlation among particles and the motion trends of individual
particles which are helpful to discover coherency among them. We further
introduce a two-step clustering process to construct stable semantic regions
from the extracted time-varying coherent motions. These semantic regions can be
used to recognize pre-defined activities in crowd scenes. Finally, we introduce
a cluster-and-merge process which automatically discovers recurrent activities
in crowd scenes by clustering and merging the extracted coherent motions.
Experiments on various videos demonstrate the effectiveness of our approach.
"
955,Perceptual Vector Quantization For Video Coding,"  This paper applies energy conservation principles to the Daala video codec
using gain-shape vector quantization to encode a vector of AC coefficients as a
length (gain) and direction (shape). The technique originates from the CELT
mode of the Opus audio codec, where it is used to conserve the spectral
envelope of an audio signal. Conserving energy in video has the potential to
preserve textures rather than low-passing them. Explicitly quantizing a gain
allows a simple contrast masking model with no signaling cost. Vector
quantizing the shape keeps the number of degrees of freedom the same as scalar
quantization, avoiding redundancy in the representation. We demonstrate how to
predict the vector by transforming the space it is encoded in, rather than
subtracting off the predictor, which would make energy conservation impossible.
We also derive an encoding of the vector-quantized codewords that takes
advantage of their non-uniform distribution. We show that the resulting
technique outperforms scalar quantization by an average of 0.90 dB on still
images, equivalent to a 24.8% reduction in bitrate at equal quality, while for
videos, the improvement averages 0.83 dB, equivalent to a 13.7% reduction in
bitrate.
"
956,A Full-Bandwidth Audio Codec With Low Complexity And Very Low Delay,"  We propose an audio codec that addresses the low-delay requirements of some
applications such as network music performance. The codec is based on the
modified discrete cosine transform (MDCT) with very short frames and uses
gain-shape quantization to preserve the spectral envelope. The short frame
sizes required for low delay typically hinder the performance of transform
codecs. However, at 96 kbit/s and with only 4 ms algorithmic delay, the
proposed codec out-performs the ULD codec operating at the same rate. The total
complexity of the codec is small, at only 17 WMOPS for real-time operation at
48 kHz.
"
957,A High-Quality Speech and Audio Codec With Less Than 10 ms Delay,"  With increasing quality requirements for multimedia communications, audio
codecs must maintain both high quality and low delay. Typically, audio codecs
offer either low delay or high quality, but rarely both. We propose a codec
that simultaneously addresses both these requirements, with a delay of only 8.7
ms at 44.1 kHz. It uses gain-shape algebraic vector quantisation in the
frequency domain with time-domain pitch prediction. We demonstrate that the
proposed codec operating at 48 kbit/s and 64 kbit/s out-performs both G.722.1C
and MP3 and has quality comparable to AAC-LD, despite having less than one
fourth of the algorithmic delay of these codecs.
"
958,Weighted Unsupervised Learning for 3D Object Detection,"  This paper introduces a novel weighted unsupervised learning for object
detection using an RGB-D camera. This technique is feasible for detecting the
moving objects in the noisy environments that are captured by an RGB-D camera.
The main contribution of this paper is a real-time algorithm for detecting each
object using weighted clustering as a separate cluster. In a preprocessing
step, the algorithm calculates the pose 3D position X, Y, Z and RGB color of
each data point and then it calculates each data point's normal vector using
the point's neighbor. After preprocessing, our algorithm calculates k-weights
for each data point; each weight indicates membership. Resulting in clustered
objects of the scene.
"
959,The AV1 Constrained Directional Enhancement Filter (CDEF),"  This paper presents the constrained directional enhancement filter designed
for the AV1 royalty-free video codec. The in-loop filter is based on a
non-linear low-pass filter and is designed for vectorization efficiency. It
takes into account the direction of edges and patterns being filtered. The
filter works by identifying the direction of each block and then adaptively
filtering with a high degree of control over the filter strength along the
direction and across it. The proposed enhancement filter is shown to improve
the quality of the Alliance for Open Media (AOM) AV1 and Thor video codecs in
particular in low complexity configurations.
"
960,"VLSI Friendly Framework for Scalable Video Coding based on Compressed
  Sensing","  This paper presents a new VLSI friendly framework for scalable video coding
based on Compressed Sensing (CS). It achieves scalability through 3-Dimensional
Discrete Wavelet Transform (3-D DWT) and better compression ratio by exploiting
the inherent sparsity of the high-frequency wavelet sub-bands through CS. By
using 3-D DWT and a proposed adaptive measurement scheme called AMS at the
encoder, one can succeed in improving the compression ratio and reducing the
complexity of the decoder. The proposed video codec uses only 7% of the total
number of multipliers needed in a conventional CS-based video coding system. A
codebook of Bernoulli matrices with different sizes corresponding to the
predefined sparsity levels is maintained at both the encoder and the decoder.
Based on the calculated l0-norm of the input vector, one of the sixteen
possible Bernoulli matrices will be selected for taking the CS measurements and
its index will be transmitted along with the measurements. Based on this index,
the corresponding Bernoulli matrix has been used in CS reconstruction algorithm
to get back the high-frequency wavelet sub-bands at the decoder. At the
decoder, a new Enhanced Approximate Message Passing (EAMP) algorithm has been
proposed to reconstruct the wavelet coefficients and apply the inverse wavelet
transform for restoring back the video frames. Simulation results have
established the superiority of the proposed framework over the existing schemes
and have increased its suitability for VLSI implementation. Moreover, the coded
video is found to be scalable with an increase in a number of levels of wavelet
decomposition.
"
961,"Narrative Smoothing: Dynamic Conversational Network for the Analysis of
  TV Series Plots","  Modern popular TV series often develop complex storylines spanning several
seasons, but are usually watched in quite a discontinuous way. As a result, the
viewer generally needs a comprehensive summary of the previous season plot
before the new one starts. The generation of such summaries requires first to
identify and characterize the dynamics of the series subplots. One way of doing
so is to study the underlying social network of interactions between the
characters involved in the narrative. The standard tools used in the Social
Networks Analysis field to extract such a network rely on an integration of
time, either over the whole considered period, or as a sequence of several
time-slices. However, they turn out to be inappropriate in the case of TV
series, due to the fact the scenes showed onscreen alternatively focus on
parallel storylines, and do not necessarily respect a traditional chronology.
This makes existing extraction methods inefficient to describe the dynamics of
relationships between characters, or to get a relevant instantaneous view of
the current social state in the plot. This is especially true for characters
shown as interacting with each other at some previous point in the plot but
temporarily neglected by the narrative. In this article, we introduce narrative
smoothing, a novel, still exploratory, network extraction method. It smooths
the relationship dynamics based on the plot properties, aiming at solving some
of the limitations present in the standard approaches. In order to assess our
method, we apply it to a new corpus of 3 popular TV series, and compare it to
both standard approaches. Our results are promising, showing narrative
smoothing leads to more relevant observations when it comes to the
characterization of the protagonists and their relationships. It could be used
as a basis for further modeling the intertwined storylines constituting TV
series plots.
"
962,"Extension spectrale d'un signal de parole de la bande t\'el\'ephonique
  \`a la bande AM","  This document proposes a bandwidth extension system producing a wideband
signal from a narrowband speech signal. The extension is performed
independently for high and low frequencies. High-frequency extension uses the
excitation-filter model. Extension of the excitation is performed in the time
domain using a non-linear function, while the spectral envelope is extended in
the cepstral domain using a multi-layer perceptron. Low-band extension is based
on the sinusoidal model. The amplitude of sinusoids is also estimated using a
multi-layer perceptron.
  The results show that the sound quality after extension is higher than that
of narrowband speech, with a significant variation across listeners. Some of
the techniques, including excitation extension, are of interest in the field of
speech coding.
  -----
  Le pr\'esent m\'emoire propose un syst\`eme d'extension de la bande
permettant de produire un signal en bande AM \`a partir d'un signal de parole
en bande t\'el\'ephonique. L'extension est effectu\'ee de fa\c{c}on
ind\'ependante pour les hautes fr\'equences et les basses fr\'equences.
L'extension des hautes fr\'equences utilise le mod\`ele filtre-excitation.
L'extension de l'excitation est r\'ealis\'ee dans le domaine temporel par une
fonction non lin\'eaire, alors que l'extension de l'enveloppe spectrale
s'effectue dans le domaine cepstral par un perceptron multi-couches.
L'extension de la bande basse utilise le mod\`ele sinuso\""idal. L'amplitude des
sinuso\""ides est aussi estim\'ee par un perceptron multi-couches.
  Les r\'esultats obtenus montrent que la qualit\'e sonore apr\`es extension
est sup\'erieure \`a celle de la bande t\'el\'ephonique, avec une importante
diff\'erence entre les auditeurs. Certaines techniques d\'evelopp\'ees, dont
l'extension de l'excitation, pr\'esentent un certain int\'er\^et pour le
domaine du codage de la parole.
"
963,QoE-Based Low-Delay Live Streaming Using Throughput Predictions,"  Recently, HTTP-based adaptive streaming has become the de facto standard for
video streaming over the Internet. It allows clients to dynamically adapt media
characteristics to network conditions in order to ensure a high quality of
experience, that is, minimize playback interruptions, while maximizing video
quality at a reasonable level of quality changes. In the case of live
streaming, this task becomes particularly challenging due to the latency
constraints. The challenge further increases if a client uses a wireless
network, where the throughput is subject to considerable fluctuations.
Consequently, live streams often exhibit latencies of up to 30 seconds. In the
present work, we introduce an adaptation algorithm for HTTP-based live
streaming called LOLYPOP (Low-Latency Prediction-Based Adaptation) that is
designed to operate with a transport latency of few seconds. To reach this
goal, LOLYPOP leverages TCP throughput predictions on multiple time scales,
from 1 to 10 seconds, along with an estimate of the prediction error
distribution. In addition to satisfying the latency constraint, the algorithm
heuristically maximizes the quality of experience by maximizing the average
video quality as a function of the number of skipped segments and quality
transitions. In order to select an efficient prediction method, we studied the
performance of several time series prediction methods in IEEE 802.11 wireless
access networks. We evaluated LOLYPOP under a large set of experimental
conditions limiting the transport latency to 3 seconds, against a
state-of-the-art adaptation algorithm from the literature, called FESTIVE. We
observed that the average video quality is by up to a factor of 3 higher than
with FESTIVE. We also observed that LOLYPOP is able to reach a broader region
in the quality of experience space, and thus it is better adjustable to the
user profile or service provider requirements.
"
964,"First Steps Toward Camera Model Identification with Convolutional Neural
  Networks","  Detecting the camera model used to shoot a picture enables to solve a wide
series of forensic problems, from copyright infringement to ownership
attribution. For this reason, the forensic community has developed a set of
camera model identification algorithms that exploit characteristic traces left
on acquired images by the processing pipelines specific of each camera model.
In this paper, we investigate a novel approach to solve camera model
identification problem. Specifically, we propose a data-driven algorithm based
on convolutional neural networks, which learns features characterizing each
camera model directly from the acquired pictures. Results on a well-known
dataset of 18 camera models show that: (i) the proposed method outperforms
up-to-date state-of-the-art algorithms on classification of 64x64 color image
patches; (ii) features learned by the proposed network generalize to camera
models never used for training.
"
965,"Anticipatory Radio Resource Management for Mobile Video Streaming with
  Linear Programming","  In anticipatory networking, channel prediction is used to improve
communication performance. This paper describes a new approach for allocating
resources to video streaming traffic while accounting for quality of service.
The proposed method is based on integrating a model of the user's local
play-out buffer into the radio access network. The linearity of this model
allows to formulate a Linear Programming problem that optimizes the trade-off
between the allocated resources and the stalling time of the media stream. Our
simulation results demonstrate the full power of anticipatory optimization in a
simple, yet representative, scenario. Compared to instantaneous adaptation, our
anticipatory solution shows impressive gains in spectral efficiency and
stalling duration at feasible computation time while being robust against
prediction errors.
"
966,Impact Analysis of Baseband Quantizer on Coding Efficiency for HDR Video,"  Digitally acquired high dynamic range (HDR) video baseband signal can take 10
to 12 bits per color channel. It is economically important to be able to reuse
the legacy 8 or 10-bit video codecs to efficiently compress the HDR video.
Linear or nonlinear mapping on the intensity can be applied to the baseband
signal to reduce the dynamic range before the signal is sent to the codec, and
we refer to this range reduction step as a baseband quantization. We show
analytically and verify using test sequences that the use of the baseband
quantizer lowers the coding efficiency. Experiments show that as the baseband
quantizer is strengthened by 1.6 bits, the drop of PSNR at a high bitrate is up
to 1.60dB. Our result suggests that in order to achieve high coding efficiency,
information reduction of videos in terms of quantization error should be
introduced in the video codec instead of on the baseband signal.
"
967,Daala: A Perceptually-Driven Next Generation Video Codec,"  The Daala project is a royalty-free video codec that attempts to compete with
the best patent-encumbered codecs. Part of our strategy is to replace core
tools of traditional video codecs with alternative approaches, many of them
designed to take perceptual aspects into account, rather than optimizing for
simple metrics like PSNR. This paper documents some of our experiences with
these tools, which ones worked and which did not, and what we've learned from
them. The result is a codec which compares favorably with HEVC on still images,
and is on a path to do so for video as well.
"
968,Predicting Chroma from Luma with Frequency Domain Intra Prediction,"  This paper describes a technique for performing intra prediction of the
chroma planes based on the reconstructed luma plane in the frequency domain.
This prediction exploits the fact that while RGB to YUV color conversion has
the property that it decorrelates the color planes globally across an image,
there is still some correlation locally at the block level. Previous proposals
compute a linear model of the spatial relationship between the luma plane (Y)
and the two chroma planes (U and V). In codecs that use lapped transforms this
is not possible since transform support extends across the block boundaries and
thus neighboring blocks are unavailable during intra-prediction. We design a
frequency domain intra predictor for chroma that exploits the same local
correlation with lower complexity than the spatial predictor and which works
with lapped transforms. We then describe a low-complexity algorithm that
directly uses luma coefficients as a chroma predictor based on gain-shape
quantization and band partitioning. An experiment is performed that compares
these two techniques inside the experimental Daala video codec and shows the
lower complexity algorithm to be a better chroma predictor.
"
969,Deep Fully-Connected Networks for Video Compressive Sensing,"  In this work we present a deep learning framework for video compressive
sensing. The proposed formulation enables recovery of video frames in a few
seconds at significantly improved reconstruction quality compared to previous
approaches. Our investigation starts by learning a linear mapping between video
sequences and corresponding measured frames which turns out to provide
promising results. We then extend the linear formulation to deep
fully-connected networks and explore the performance gains using deeper
architectures. Our analysis is always driven by the applicability of the
proposed framework on existing compressive video architectures. Extensive
simulations on several video sequences document the superiority of our approach
both quantitatively and qualitatively. Finally, our analysis offers insights
into understanding how dataset sizes and number of layers affect reconstruction
performance while raising a few points for future investigation.
  Code is available at Github: https://github.com/miliadis/DeepVideoCS
"
970,"Towards Coordinated Bandwidth Adaptations for Hundred-Scale 3D
  Tele-Immersive Systems","  3D tele-immersion improves the state of collaboration among geographically
distributed participants. Unlike the traditional 2D videos, a 3D tele-immersive
system employs multiple 3D cameras based in each physical site to cover a much
larger field of view, generating a very large amount of stream data. One of the
major challenges is how to efficiently transmit these bulky 3D streaming data
to bandwidth-constrained sites. In this paper, we study an adaptive Human
Visual System (HVS) -compliant bandwidth management framework for efficient
delivery of hundred-scale streams produced from distributed 3D tele-immersive
sites to a receiver site with limited bandwidth budget. Our adaptation
framework exploits the semantics link of HVS with multiple 3D streams in the 3D
tele-immersive environment. We developed TELEVIS, a visual simulation tool to
showcase a HVS-aware tele-immersive system for realistic cases. Our evaluation
results show that the proposed adaptation can improve the total quality per
unit of bandwidth used to deliver streams in 3D tele-immersive systems.
"
971,"Optimal Lagrange Multipliers for Dependent Rate Allocation in Video
  Coding","  In a typical video rate allocation problem, the objective is to optimally
distribute a source rate budget among a set of (in)dependently coded data units
to minimize the total distortion of all units. Conventional Lagrangian
approaches convert the lone rate constraint to a linear rate penalty scaled by
a multiplier in the objective, resulting in a simpler unconstrained
formulation. However, the search for the ""optimal"" multiplier, one that results
in a distortion-minimizing solution among all Lagrangian solutions that satisfy
the original rate constraint, remains an elusive open problem in the general
setting. To address this problem, we propose a computation-efficient search
strategy to identify this optimal multiplier numerically. Specifically, we
first formulate a general rate allocation problem where each data unit can be
dependently coded at different quantization parameters (QP) using a previous
unit as predictor, or left uncoded at the encoder and subsequently interpolated
at the decoder using neighboring coded units. After converting the original
rate constrained problem to the unconstrained Lagrangian counterpart, we design
an efficient dynamic programming (DP) algorithm that finds the optimal
Lagrangian solution for a fixed multiplier. Finally, within the DP framework,
we iteratively compute neighboring singular multiplier values, each resulting
in multiple simultaneously optimal Lagrangian solutions, to drive the rates of
the computed Lagrangian solutions towards the bit budget. We terminate when a
singular multiplier value results in two Lagrangian solutions with rates below
and above the bit budget. In extensive monoview and multiview video coding
experiments, we show that our DP algorithm and selection of optimal multipliers
on average outperform comparable rate control solutions used in video
compression standards such as HEVC that do not skip frames in Y-PSNR.
"
972,"Modeling and Resource Allocation for HD Videos over WiMAX Broadband
  Wireless Networks","  Mobile video is considered a major upcoming application and revenue generator
for broadband wireless networks like WiMAX and LTE. Therefore, it is important
to design a proper resource allocation scheme for mobile video, since video
traffic is both throughput consuming and delay sensitive.
"
973,A framework for event co-occurrence detection in event streams,"  This paper shows that characterizing co-occurrence between events is an
important but non-trivial and neglected aspect of discovering potential causal
relationships in multimedia event streams. First an introduction to the notion
of event co-occurrence and its relation to co-occurrence pattern detection is
given. Then a finite state automaton extended with a time model and event
parameterization is introduced to convert high level co-occurrence pattern
definition to its corresponding pattern matching automaton. Finally a
processing algorithm is applied to count the occurrence frequency of a
collection of patterns with only one pass through input event streams. The
method proposed in this paper can be used for detecting co-occurrences between
both events of one event stream (Auto co-occurrence), and events from multiple
event streams (Cross co-occurrence). Some fundamental results concerning the
characterization of event co-occurrence are presented in form of a visual co-
occurrence matrix. Reusable causality rules can be extracted easily from
co-occurrence matrix and fed into various analysis tools, such as
recommendation systems and complex event processing systems for further
analysis.
"
974,"Robust Hybrid Image Watermarking based on Discrete Wavelet and Shearlet
  Transforms","  With the growth of digital networks such as the Internet, digital media have
been explosively developed in e-commerce and online services. This causes
problems such as illegal copy and fake ownership. Watermarking is proposed as
one of the solutions to such cases. Among different watermarking techniques,
the wavelet transform has been used more because of its good ability in
modeling the human visual system. Recently, Shearlet transform as an extension
of Wavelet transform which is based on multi-resolution and multi-directional
analysis is introduced. The most important feature of this transform is the
appropriate representation of image edges. In this paper a hybrid scheme using
Discrete Wavelet Transform (DWT) and Discrete Shearlet Transform (DST) is
presented. In this way, the host image is decomposed using DWT, and then its
low frequency sub-band is decomposed by DST. After that, the bidiagonal
singular value decomposition (BSVD) is applied on the selected sub-band from
Shearlet transform and the gray-scale watermark image is embedded into its
bidiagonal singular values. The proposed method is examined on the images with
different textures and resistance is evaluated against various attacks like
image processing and geometric attacks. The results show good transparency and
high robustness in proposed method.
"
975,"Singing Voice Separation and Vocal F0 Estimation based on Mutual
  Combination of Robust Principal Component Analysis and Subharmonic Summation","  This paper presents a new method of singing voice analysis that performs
mutually-dependent singing voice separation and vocal fundamental frequency
(F0) estimation. Vocal F0 estimation is considered to become easier if singing
voices can be separated from a music audio signal, and vocal F0 contours are
useful for singing voice separation. This calls for an approach that improves
the performance of each of these tasks by using the results of the other. The
proposed method first performs robust principal component analysis (RPCA) for
roughly extracting singing voices from a target music audio signal. The F0
contour of the main melody is then estimated from the separated singing voices
by finding the optimal temporal path over an F0 saliency spectrogram. Finally,
the singing voices are separated again more accurately by combining a
conventional time-frequency mask given by RPCA with another mask that passes
only the harmonic structures of the estimated F0s. Experimental results showed
that the proposed method significantly improved the performances of both
singing voice separation and vocal F0 estimation. The proposed method also
outperformed all the other methods of singing voice separation submitted to an
international music analysis competition called MIREX 2014.
"
976,"Building an Internet Radio System with Interdisciplinary factored system
  for automatic content recommendation","  Automatic systems for music content recommendation have assumed a new role in
recent years. These systems have transformed from being just a convenient,
standalone tool into an inseparable element of modern living. In addition, not
only do these systems strongly influence human moods and feelings with the
selection of proper music content, but they also provide significant commercial
and advertising opportunities. This research aims to examine and implement two
such systems available for the automatic recognition and recommendation of
music and advertisement content for Internet radio. Through analysis of the
practical issues of application fields and spheres of influence, conclusions
will be drawn about the possible perspectives on and future role of such
systems. Other content adaptation that is based on music genres will be
discussed, as wellAnother aim of this study is to provide an innovative
Internet radio implementation as compared to traditional radio and other
Internet broadcast solutions. This will include automatic content
recommendation systems for listeners and marketing companies, as well as the
usage of a voice synthesizer in in automatic program scheduling.
"
977,Steganography -- A Game of Hide and Seek in Information Communication,"  With the growth of communication over computer networks, how to maintain the
confidentiality and security of transmitted information have become some of the
important issues. In order to transfer data securely to the destination without
unwanted disclosure or damage, nature inspired hide and seek tricks such as,
cryptography and Steganography are heavily in use. Just like the Chameleon and
many other bio-species those change their body color and hide themselves in the
background in order to protect them from external attacks, Cryptography and
Steganography are techniques those are used to encrypt and hide the secret data
inside other media to ensure data security. This paper discusses the concept of
a simple spatial domain LSB Steganography that encrypts the secrets using
Fibonacci- Lucas transformation, before hiding, for better security.
"
978,Image Captioning with Deep Bidirectional LSTMs,"  This work presents an end-to-end trainable deep bidirectional LSTM
(Long-Short Term Memory) model for image captioning. Our model builds on a deep
convolutional neural network (CNN) and two separate LSTM networks. It is
capable of learning long term visual-language interactions by making use of
history and future context information at high level semantic space. Two novel
deep bidirectional variant models, in which we increase the depth of
nonlinearity transition in different way, are proposed to learn hierarchical
visual-language embeddings. Data augmentation techniques such as multi-crop,
multi-scale and vertical mirror are proposed to prevent overfitting in training
deep models. We visualize the evolution of bidirectional LSTM internal states
over time and qualitatively analyze how our models ""translate"" image to
sentence. Our proposed models are evaluated on caption generation and
image-sentence retrieval tasks with three benchmark datasets: Flickr8K,
Flickr30K and MSCOCO datasets. We demonstrate that bidirectional LSTM models
achieve highly competitive performance to the state-of-the-art results on
caption generation even without integrating additional mechanism (e.g. object
detection, attention model etc.) and significantly outperform recent methods on
retrieval task.
"
979,Learning to Generate Posters of Scientific Papers,"  Researchers often summarize their work in the form of posters. Posters
provide a coherent and efficient way to convey core ideas from scientific
papers. Generating a good scientific poster, however, is a complex and time
consuming cognitive task, since such posters need to be readable, informative,
and visually aesthetic. In this paper, for the first time, we study the
challenging problem of learning to generate posters from scientific papers. To
this end, a data-driven framework, that utilizes graphical models, is proposed.
Specifically, given content to display, the key elements of a good poster,
including panel layout and attributes of each panel, are learned and inferred
from data. Then, given inferred layout and attributes, composition of graphical
elements within each panel is synthesized. To learn and validate our model, we
collect and make public a Poster-Paper dataset, which consists of scientific
papers and corresponding posters with exhaustively labelled panels and
attributes. Qualitative and quantitative results indicate the effectiveness of
our approach.
"
980,Deep Cross Residual Learning for Multitask Visual Recognition,"  Residual learning has recently surfaced as an effective means of constructing
very deep neural networks for object recognition. However, current incarnations
of residual networks do not allow for the modeling and integration of complex
relations between closely coupled recognition tasks or across domains. Such
problems are often encountered in multimedia applications involving large-scale
content recognition. We propose a novel extension of residual learning for deep
networks that enables intuitive learning across multiple related tasks using
cross-connections called cross-residuals. These cross-residuals connections can
be viewed as a form of in-network regularization and enables greater network
generalization. We show how cross-residual learning (CRL) can be integrated in
multitask networks to jointly train and detect visual concepts across several
tasks. We present a single multitask cross-residual network with >40% less
parameters that is able to achieve competitive, or even better, detection
performance on a visual sentiment concept detection problem normally requiring
multiple specialized single-task networks. The resulting multitask
cross-residual network also achieves better detection performance by about
10.4% over a standard multitask residual network without cross-residuals with
even a small amount of cross-task weighting.
"
981,"Reading Between the Pixels: Photographic Steganography for Camera
  Display Messaging","  We exploit human color metamers to send light-modulated messages less visible
to the human eye, but recoverable by cameras. These messages are a key
component to camera-display messaging, such as handheld smartphones capturing
information from electronic signage. Each color pixel in the display image is
modified by a particular color gradient vector. The challenge is to find the
color gradient that maximizes camera response, while minimizing human response.
The mismatch in human spectral and camera sensitivity curves creates an
opportunity for hidden messaging. Our approach does not require knowledge of
these sensitivity curves, instead we employ a data-driven method. We learn an
ellipsoidal partitioning of the six-dimensional space of colors and color
gradients. This partitioning creates metamer sets defined by the base color at
the display pixel and the color gradient direction for message encoding. We
sample from the resulting metamer sets to find color steps for each base color
to embed a binary message into an arbitrary image with reduced visible
artifacts. Unlike previous methods that rely on visually obtrusive intensity
modulation, we embed with color so that the message is more hidden. Ordinary
displays and cameras are used without the need for expensive LEDs or high speed
devices. The primary contribution of this work is a framework to map the pixels
in an arbitrary image to a metamer pair for steganographic photo messaging.
"
982,"Image Encryption Based On Gradient Haar Wavelet and Rational Order
  Chaotic Maps","  Haar wavelet is one of the best mathematical tools in image cryptography and
analysis. Because of the specific structure, this wavelet has the ability which
is combined with other mathematical tools such as chaotic maps. The rational
order chaotic maps are one of clusters of chaotic maps which their
deterministic behaviors have high sensitivity. In this paper, we propose a
novel method of gradient Haar wavelet transform for image encryption. This
method use linearity properties of the scaling function of the gradient Haar
wavelet and deterministic behaviors of rational order chaotic maps in order to
generate encrypted images with high security factor. The security of the
encrypted images is evaluated by the key space analysis, the correlation
coefficient analysis, and differential attack. The method could be used in
other fields such as image and signal processing.
"
983,"Scene-driven Retrieval in Edited Videos using Aesthetic and Semantic
  Deep Features","  This paper presents a novel retrieval pipeline for video collections, which
aims to retrieve the most significant parts of an edited video for a given
query, and represent them with thumbnails which are at the same time
semantically meaningful and aesthetically remarkable. Videos are first
segmented into coherent and story-telling scenes, then a retrieval algorithm
based on deep learning is proposed to retrieve the most significant scenes for
a textual query. A ranking strategy based on deep features is finally used to
tackle the problem of visualizing the best thumbnail. Qualitative and
quantitative experiments are conducted on a collection of edited videos to
demonstrate the effectiveness of our approach.
"
984,Trends toward real-time network data steganography,"  Network steganography has been a well-known covert data channeling method for
over three decades. The basic set of techniques and implementation tools have
not changed significantly since their introduction in the early 1980's. In this
paper, we review the predominant methods of classical network steganography,
describing the detailed operations and resultant challenges involved in
embedding data in the network transport domain. We also consider the various
cyber threat vectors of network steganography and point out the major
differences between classical network steganography and the widely known
end-point multimedia embedding techniques, which focus exclusively on static
data modification for data hiding. We then challenge the security community by
introducing an entirely new network dat hiding methodology, which we refer to
as real-time network data steganography. Finally we provide the groundwork for
this fundamental change of covert network data embedding by forming a basic
framework for real-time network data operations that will open the path for
even further advances in computer network security.
"
985,An Integrated Method of Data Hiding and Compression of Medical Images,"  A new technique for embedding data into an image coupled with compression has
been proposed in this paper. A fast and efficient coding algorithms are needed
for effective storage and transmission, due to the popularity of telemedicine
and the use of digital medical images. Medical images are produced and
transferred between hospitals for review by physicians who are geographically
apart. Such image data need to be stored for future reference of patients as
well. This necessitates compact storage of medical images before being
transmitted over Internet. Moreover, as the patient information is also
embedded within the medical images, it is very important to maintain the
confidentiality of patient data. Hence, this article aims at hiding patient
information as well, within the medical image followed by joint compression.
The hidden data and the host image are absolutely recoverable from the embedded
image without any loss.
"
986,"Noise Robust Speech Recognition Using Multi-Channel Based Channel
  Selection And ChannelWeighting","  In this paper, we study several microphone channel selection and weighting
methods for robust automatic speech recognition (ASR) in noisy conditions. For
channel selection, we investigate two methods based on the maximum likelihood
(ML) criterion and minimum autoencoder reconstruction criterion, respectively.
For channel weighting, we produce enhanced log Mel filterbank coefficients as a
weighted sum of the coefficients of all channels. The weights of the channels
are estimated by using the ML criterion with constraints. We evaluate the
proposed methods on the CHiME-3 noisy ASR task. Experiments show that channel
weighting significantly outperforms channel selection due to its higher
flexibility. Furthermore, on real test data in which different channels have
different gains of the target signal, the channel weighting method performs
equally well or better than the MVDR beamforming, despite the fact that the
channel weighting does not make use of the phase delay information which is
normally used in beamforming.
"
987,"From Pixels to Sentiment: Fine-tuning CNNs for Visual Sentiment
  Prediction","  Visual multimedia have become an inseparable part of our digital social
lives, and they often capture moments tied with deep affections. Automated
visual sentiment analysis tools can provide a means of extracting the rich
feelings and latent dispositions embedded in these media. In this work, we
explore how Convolutional Neural Networks (CNNs), a now de facto computational
machine learning tool particularly in the area of Computer Vision, can be
specifically applied to the task of visual sentiment prediction. We accomplish
this through fine-tuning experiments using a state-of-the-art CNN and via
rigorous architecture analysis, we present several modifications that lead to
accuracy improvements over prior art on a dataset of images from a popular
social media platform. We additionally present visualizations of local patterns
that the network learned to associate with image sentiment for insight into how
visual positivity (or negativity) is perceived by the model.
"
988,A Practical Approach to Spatiotemporal Data Compression,"  Datasets representing the world around us are becoming ever more unwieldy as
data volumes grow. This is largely due to increased measurement and modelling
resolution, but the problem is often exacerbated when data are stored at
spuriously high precisions. In an effort to facilitate analysis of these
datasets, computationally intensive calculations are increasingly being
performed on specialised remote servers before the reduced data are transferred
to the consumer. Due to bandwidth limitations, this often means data are
displayed as simple 2D data visualisations, such as scatter plots or images. We
present here a novel way to efficiently encode and transmit 4D data fields
on-demand so that they can be locally visualised and interrogated. This nascent
""4D video"" format allows us to more flexibly move the boundary between data
server and consumer client. However, it has applications beyond purely
scientific visualisation, in the transmission of data to virtual and augmented
reality.
"
989,Bags of Local Convolutional Features for Scalable Instance Search,"  This work proposes a simple instance retrieval pipeline based on encoding the
convolutional features of CNN using the bag of words aggregation scheme (BoW).
Assigning each local array of activations in a convolutional layer to a visual
word produces an \textit{assignment map}, a compact representation that relates
regions of an image with a visual word. We use the assignment map for fast
spatial reranking, obtaining object localizations that are used for query
expansion. We demonstrate the suitability of the BoW representation based on
local CNN features for instance retrieval, achieving competitive performance on
the Oxford and Paris buildings benchmarks. We show that our proposed system for
CNN feature aggregation with BoW outperforms state-of-the-art techniques using
sum pooling at a subset of the challenging TRECVid INS benchmark.
"
990,Prediction-error of Prediction Error (PPE)-based Reversible Data Hiding,"  This paper presents a novel reversible data hiding (RDH) algorithm for
gray-scaled images, in which the prediction-error of prediction error (PPE) of
a pixel is used to carry the secret data. In the proposed method, the pixels to
be embedded are firstly predicted with their neighboring pixels to obtain the
corresponding prediction errors (PEs). Then, by exploiting the PEs of the
neighboring pixels, the prediction of the PEs of the pixels can be determined.
And, a sorting technique based on the local complexity of a pixel is used to
collect the PPEs to generate an ordered PPE sequence so that, smaller PPEs will
be processed first for data embedding. By reversibly shifting the PPE histogram
(PPEH) with optimized parameters, the pixels corresponding to the altered PPEH
bins can be finally modified to carry the secret data. Experimental results
have implied that the proposed method can benefit from the prediction procedure
of the PEs, sorting technique as well as parameters selection, and therefore
outperform some state-of-the-art works in terms of payload-distortion
performance when applied to different images.
"
991,Text-based LSTM networks for Automatic Music Composition,"  In this paper, we introduce new methods and discuss results of text-based
LSTM (Long Short-Term Memory) networks for automatic music composition. The
proposed network is designed to learn relationships within text documents that
represent chord progressions and drum tracks in two case studies. In the
experiments, word-RNNs (Recurrent Neural Networks) show good results for both
cases, while character-based RNNs (char-RNNs) only succeed to learn chord
progressions. The proposed system can be used for fully automatic composition
or as semi-automatic systems that help humans to compose music by controlling a
diversity parameter of the model.
"
992,Mainstreaming video annotation software for critical video analysis,"  The range of video annotation software currently available is set within
commercially specialized professions, distributed via outdated sources or
through online video hosting services. As video content becomes an increasingly
significant tool for analysis, there is a demand for appropriate digital
annotation techniques that offer equivalent functionality to tools used for
annotation of text based literature sources. This paper argues for the
importance of video annotating as an effective method for research that is as
accessible as literature annotation is. Video annotation has been shown to
trigger higher learning and engagement but research struggles to explain the
absence of video annotation in contemporary structures of education practice.
In both academic and informal settings the use of video playback as a
meaningful tool of analysis is apparent, yet the availability of supplementary
annotation software is not within obvious grasp or even prevalent in
standardized computer software. Practical software tools produced by the
researcher have demonstrated effective video annotation in a short development
time. With software design programs available for rapid application creation,
this paper also highlights the absence of a development community. This paper
argues that video annotation is an accessible tool, not just for academic
contexts, but also for wider practical video analysis applications, potentially
becoming a mainstream learning tool. This paper thus presents a practical
multimodal public approach to video research that potentially affords a deeper
analysis of media content. This is supported by an in-depth consideration of
the motivation for undertaking video annotation and a critical analysis of
currently available tools.
"
993,"LOH and behold: Web-scale visual search, recommendation and clustering
  using Locally Optimized Hashing","  We propose a novel hashing-based matching scheme, called Locally Optimized
Hashing (LOH), based on a state-of-the-art quantization algorithm that can be
used for efficient, large-scale search, recommendation, clustering, and
deduplication. We show that matching with LOH only requires set intersections
and summations to compute and so is easily implemented in generic distributed
computing systems. We further show application of LOH to: a) large-scale search
tasks where performance is on par with other state-of-the-art hashing
approaches; b) large-scale recommendation where queries consisting of thousands
of images can be used to generate accurate recommendations from collections of
hundreds of millions of images; and c) efficient clustering with a graph-based
algorithm that can be scaled to massive collections in a distributed
environment or can be used for deduplication for small collections, like search
results, performing better than traditional hashing approaches while only
requiring a few milliseconds to run. In this paper we experiment on datasets of
up to 100 million images, but in practice our system can scale to larger
collections and can be used for other types of data that have a vector
representation in a Euclidean space.
"
994,Lossless Intra Coding in HEVC with Adaptive 3-tap Filters,"  In pixel-by-pixel spatial prediction methods for lossless intra coding, the
prediction is obtained by a weighted sum of neighbouring pixels. The proposed
prediction approach in this paper uses a weighted sum of three neighbor pixels
according to a two-dimensional correlation model. The weights are obtained
after a three step optimization procedure. The first two stages are offline
procedures where the computed prediction weights are obtained offline from
training sequences. The third stage is an online optimization procedure where
the offline obtained prediction weights are further fine-tuned and adapted to
each encoded block during encoding using a rate-distortion optimized method and
the modification in this third stage is transmitted to the decoder as side
information. The results of the simulations show average bit rate reductions of
12.02% and 3.28% over the default lossless intra coding in HEVC and the
well-known Sample-based Angular Prediction (SAP) method, respectively.
"
995,"Deep Convolutional Neural Networks and Data Augmentation for Acoustic
  Event Detection","  We propose a novel method for Acoustic Event Detection (AED). In contrast to
speech, sounds coming from acoustic events may be produced by a wide variety of
sources. Furthermore, distinguishing them often requires analyzing an extended
time period due to the lack of a clear sub-word unit. In order to incorporate
the long-time frequency structure for AED, we introduce a convolutional neural
network (CNN) with a large input field. In contrast to previous works, this
enables to train audio event detection end-to-end. Our architecture is inspired
by the success of VGGNet and uses small, 3x3 convolutions, but more depth than
previous methods in AED. In order to prevent over-fitting and to take full
advantage of the modeling capabilities of our network, we further propose a
novel data augmentation method to introduce data variation. Experimental
results show that our CNN significantly outperforms state of the art methods
including Bag of Audio Words (BoAW) and classical CNNs, achieving a 16%
absolute improvement.
"
996,"Towards Reduced Reference Parametric Models for Estimating Audiovisual
  Quality in Multimedia Services","  We have developed reduced reference parametric models for estimating
perceived quality in audiovisual multimedia services. We have created 144
unique configurations for audiovisual content including various application and
network parameters such as bitrates and distortions in terms of bandwidth,
packet loss rate and jitter. To generate the data needed for model training and
validation we have tasked 24 subjects, in a controlled environment, to rate the
overall audiovisual quality on the absolute category rating (ACR) 5-level
quality scale. We have developed models using Random Forest and Neural Network
based machine learning methods in order to estimate Mean Opinion Scores (MOS)
values. We have used information retrieved from the packet headers and side
information provided as network parameters for model training. Random Forest
based models have performed better in terms of Root Mean Square Error (RMSE)
and Pearson correlation coefficient. The side information proved to be very
effective in developing the model. We have found that, while the model
performance might be improved by replacing the side information with more
accurate bit stream level measurements, they are performing well in estimating
perceived quality in audiovisual multimedia services.
"
997,Predictive No-Reference Assessment of Video Quality,"  Among the various means to evaluate the quality of video streams,
No-Reference (NR) methods have low computation and may be executed on thin
clients. Thus, NR algorithms would be perfect candidates in cases of real-time
quality assessment, automated quality control and, particularly, in adaptive
mobile streaming. Yet, existing NR approaches are often inaccurate, in
comparison to Full-Reference (FR) algorithms, especially under lossy network
conditions. In this work, we present an NR method that combines machine
learning with simple NR metrics to achieve a quality index comparably as
accurate as the Video Quality Metric (VQM) Full-Reference algorithm. Our method
is tested in an extensive dataset (960 videos), under lossy network conditions
and considering nine different machine learning algorithms. Overall, we achieve
an over 97% correlation with VQM, while allowing real-time assessment of video
quality of experience in realistic streaming scenarios.
"
998,Compressed-domain visual saliency models: A comparative study,"  Computational modeling of visual saliency has become an important research
problem in recent years, with applications in video quality estimation, video
compression, object tracking, retargeting, summarization, and so on. While most
visual saliency models for dynamic scenes operate on raw video, several models
have been developed for use with compressed-domain information such as motion
vectors and transform coefficients. This paper presents a comparative study of
eleven such models as well as two high-performing pixel-domain saliency models
on two eye-tracking datasets using several comparison metrics. The results
indicate that highly accurate saliency estimation is possible based only on a
partially decoded video bitstream. The strategies that have shown success in
compressed-domain saliency modeling are highlighted, and certain challenges are
identified as potential avenues for further improvement.
"
999,Subjective Assessment of H.264 Compressed Stereoscopic Video,"  The tremendous growth in 3D (stereo) imaging and display technologies has led
to stereoscopic content (video and image) becoming increasingly popular.
However, both the subjective and the objective evaluation of stereoscopic video
content has not kept pace with the rapid growth of the content. Further, the
availability of standard stereoscopic video databases is also quite limited. In
this work, we attempt to alleviate these shortcomings. We present a
stereoscopic video database and its subjective evaluation. We have created a
database containing a set of 144 distorted videos. We limit our attention to
H.264 compression artifacts. The distorted videos were generated using 6
uncompressed pristine videos of left and right views originally created by
Goldmann et al. at EPFL [1]. Further, 19 subjects participated in the
subjective assessment task. Based on the subjective study, we have formulated a
relation between the 2D and stereoscopic subjective scores as a function of
compression rate and depth range. We have also evaluated the performance of
popular 2D and 3D image/video quality assessment (I/VQA) algorithms on our
database.
"
1000,Towards Miss Universe Automatic Prediction: The Evening Gown Competition,"  Can we predict the winner of Miss Universe after watching how they stride
down the catwalk during the evening gown competition? Fashion gurus say they
can! In our work, we study this question from the perspective of computer
vision. In particular, we want to understand whether existing computer vision
approaches can be used to automatically extract the qualities exhibited by the
Miss Universe winners during their catwalk. This study can pave the way towards
new vision-based applications for the fashion industry. To this end, we propose
a novel video dataset, called the Miss Universe dataset, comprising 10 years of
the evening gown competition selected between 1996-2010. We further propose two
ranking-related problems: (1) Miss Universe Listwise Ranking and (2) Miss
Universe Pairwise Ranking. In addition, we also develop an approach that
simultaneously addresses the two proposed problems. To describe the videos we
employ the recently proposed Stacked Fisher Vectors in conjunction with robust
local spatio-temporal features. From our evaluation we found that although the
addressed problems are extremely challenging, the proposed system is able to
rank the winner in the top 3 best predicted scores for 5 out of 10 Miss
Universe competitions.
"
1001,"Compress Voice Transference over low Signal Strength in Satellite
  Communication","  This paper presents the comparison of compression algorithms for voice
transferring method over SMS in satellite communication. Voice transferring
method over SMS is useful in situations when signal strength is low and due to
poor signal strength voice call connection is not possible to initiate or
signal dropped during voice call. This method has one serious flaw that it
produces large number of SMS while converting voice into SMS. Such issue is
catered to some extend by employing any compression algorithm. In this paper
our major aim is to find best compression scheme for said method, for that
purpose we compare 6 different types of compression algorithms which are; LZW
(Lempel-Ziv-Welch), Huffman coding, PPM (Prediction by partial matching),
Arithmetic Coding (AC), BWT (Burrows-Wheeler-Transform), LZMA
(Lempel-Ziv-Markov chain). This comparison shows that PPM compression method
offers better compression ratio and produce small number of SMS. For
experimentation we use Thuraya SG-2520 satellite phone. Moreover, we develop an
application using J2ME platform[Ref:a]. We tested that application more than
100 times and then we compare the result in terms of compression ratio of each
algorithm and number of connected SMS produce after each compression method.
The result of this study will help developers to choose better compression
scheme for their respective applications.
http://www.learnrnd.com/news.php?id=ISSUES_IN_MOLECULAR_COMMUNICATIONS
"
1002,EgoSampling: Wide View Hyperlapse from Egocentric Videos,"  The possibility of sharing one's point of view makes use of wearable cameras
compelling. These videos are often long, boring and coupled with extreme shake,
as the camera is worn on a moving person. Fast forwarding (i.e. frame sampling)
is a natural choice for quick video browsing. However, this accentuates the
shake caused by natural head motion in an egocentric video, making the fast
forwarded video useless. We propose EgoSampling, an adaptive frame sampling
that gives stable, fast forwarded, hyperlapse videos. Adaptive frame sampling
is formulated as an energy minimization problem, whose optimal solution can be
found in polynomial time. We further turn the camera shake from a drawback into
a feature, enabling the increase in field-of-view of the output video. This is
obtained when each output frame is mosaiced from several input frames. The
proposed technique also enables the generation of a single hyperlapse video
from multiple egocentric videos, allowing even faster video consumption.
"
1003,Large-Scale Query-by-Image Video Retrieval Using Bloom Filters,"  We consider the problem of using image queries to retrieve videos from a
database. Our focus is on large-scale applications, where it is infeasible to
index each database video frame independently. Our main contribution is a
framework based on Bloom filters, which can be used to index long video
segments, enabling efficient image-to-video comparisons. Using this framework,
we investigate several retrieval architectures, by considering different types
of aggregation and different functions to encode visual information -- these
play a crucial role in achieving high performance. Extensive experiments show
that the proposed technique improves mean average precision by 24% on a public
dataset, while being 4X faster, compared to the previous state-of-the-art.
"
1004,Context Tree based Image Contour Coding using A Geometric Prior,"  If object contours in images are coded efficiently as side information, then
they can facilitate advanced image / video coding techniques, such as graph
Fourier transform coding or motion prediction of arbitrarily shaped pixel
blocks. In this paper, we study the problem of lossless and lossy compression
of detected contours in images. Specifically, we first convert a detected
object contour composed of contiguous between-pixel edges to a sequence of
directional symbols drawn from a small alphabet. To encode the symbol sequence
using arithmetic coding, we compute an optimal variable-length context tree
(VCT) $\mathcal{T}$ via a maximum a posterior (MAP) formulation to estimate
symbols' conditional probabilities. MAP prevents us from overfitting given a
small training set $\mathcal{X}$ of past symbol sequences by identifying a VCT
$\mathcal{T}$ that achieves a high likelihood $P(\mathcal{X}|\mathcal{T})$ of
observing $\mathcal{X}$ given $\mathcal{T}$, and a large geometric prior
$P(\mathcal{T})$ stating that image contours are more often straight than
curvy. For the lossy case, we design efficient dynamic programming (DP)
algorithms that optimally trade off coding rate of an approximate contour
$\hat{\mathbf{x}}$ given a VCT $\mathcal{T}$ with two notions of distortion of
$\hat{\mathbf{x}}$ with respect to the original contour $\mathbf{x}$. To reduce
the size of the DP tables, a total suffix tree is derived from a given VCT
$\mathcal{T}$ for compact table entry indexing, reducing complexity.
Experimental results show that for lossless contour coding, our proposed
algorithm outperforms state-of-the-art context-based schemes consistently for
both small and large training datasets. For lossy contour coding, our
algorithms outperform comparable schemes in the literature in rate-distortion
performance.
"
1005,Detecting Violence in Video using Subclasses,"  This paper attacks the challenging problem of violence detection in videos.
Different from existing works focusing on combining multi-modal features, we go
one step further by adding and exploiting subclasses visually related to
violence. We enrich the MediaEval 2015 violence dataset by \emph{manually}
labeling violence videos with respect to the subclasses. Such fine-grained
annotations not only help understand what have impeded previous efforts on
learning to fuse the multi-modal features, but also enhance the generalization
ability of the learned fusion to novel test data. The new subclass based
solution, with AP of 0.303 and P100 of 0.55 on the MediaEval 2015 test set,
outperforms several state-of-the-art alternatives. Notice that our solution
does not require fine-grained annotations on the test set, so it can be
directly applied on novel and fully unlabeled videos. Interestingly, our study
shows that motion related features, though being essential part in previous
systems, are dispensable.
"
1006,Text writing in the air,"  This paper presents a real time video based pointing method which allows
sketching and writing of English text over air in front of mobile camera.
Proposed method have two main tasks: first it track the colored finger tip in
the video frames and then apply English OCR over plotted images in order to
recognize the written characters. Moreover, proposed method provides a natural
human-system interaction in such way that it do not require keypad, stylus, pen
or glove etc for character input. For the experiments, we have developed an
application using OpenCv with JAVA language. We tested the proposed method on
Samsung Galaxy3 android mobile. Results show that proposed algorithm gains the
average accuracy of 92.083% when tested for different shaped alphabets. Here,
more than 3000 different Magnetic 3D shaped characters were used [Ref:
http://learnrnd.com/news.php?id=Magnetic_3D_Bio_Printing]. Our proposed system
is the software based approach and relevantly very simple, fast and easy. It
does not require sensors or any hardware rather than camera and red tape.
Moreover, proposed methodology can be applicable for all disconnected languages
but having one issue that it is color sensitive in such a way that existence of
any red color in the background before starting the character writing can lead
to false results.
"
1007,"A Cloud Platform-as-a-Service for Multimedia Conferencing Service
  Provisioning","  Multimedia conferencing is the real-time exchange of multimedia content
between multiple parties. It is the basis of a wide range of applications
(e.g., multimedia multiplayer game). Cloud-based provisioning of the
conferencing services on which these applications rely will bring benefits,
such as easy service provisioning and elastic scalability. However, it remains
a big challenge. This paper proposes a PaaS for conferencing service
provisioning. The proposed PaaS is based on a business model from the state of
the art. It relies on conferencing IaaSs that, instead of VMs, offer
conferencing substrates (e.g., dial-in signaling, video mixer and audio mixer).
The PaaS enables composition of new conferences from substrates on the fly.
This has been prototyped in this paper and, in order to evaluate it, a
conferencing IaaS is also implemented. Performance measurements are also made.
"
1008,"Bloom Filters and Compact Hash Codes for Efficient and Distributed Image
  Retrieval","  This paper presents a novel method for efficient image retrieval, based on a
simple and effective hashing of CNN features and the use of an indexing
structure based on Bloom filters. These filters are used as gatekeepers for the
database of image features, allowing to avoid to perform a query if the query
features are not stored in the database and speeding up the query process,
without affecting retrieval performance. Thanks to the limited memory
requirements the system is suitable for mobile applications and distributed
databases, associating each filter to a distributed portion of the database.
Experimental validation has been performed on three standard image retrieval
datasets, outperforming state-of-the-art hashing methods in terms of precision,
while the proposed indexing method obtains a $2\times$ speedup.
"
1009,"MARLow: A Joint Multiplanar Autoregressive and Low-Rank Approach for
  Image Completion","  In this paper, we propose a novel multiplanar autoregressive (AR) model to
exploit the correlation in cross-dimensional planes of a similar patch group
collected in an image, which has long been neglected by previous AR models. On
that basis, we then present a joint multiplanar AR and low-rank based approach
(MARLow) for image completion from random sampling, which exploits the nonlocal
self-similarity within natural images more effectively. Specifically, the
multiplanar AR model constraints the local stationarity in different
cross-sections of the patch group, while the low-rank minimization captures the
intrinsic coherence of nonlocal patches. The proposed approach can be readily
extended to multichannel images (e.g. color images), by simultaneously
considering the correlation in different channels. Experimental results
demonstrate that the proposed approach significantly outperforms
state-of-the-art methods, even if the pixel missing rate is as high as 90%.
"
1010,"AVEC 2016 - Depression, Mood, and Emotion Recognition Workshop and
  Challenge","  The Audio/Visual Emotion Challenge and Workshop (AVEC 2016) ""Depression, Mood
and Emotion"" will be the sixth competition event aimed at comparison of
multimedia processing and machine learning methods for automatic audio, visual
and physiological depression and emotion analysis, with all participants
competing under strictly the same conditions. The goal of the Challenge is to
provide a common benchmark test set for multi-modal information processing and
to bring together the depression and emotion recognition communities, as well
as the audio, video and physiological processing communities, to compare the
relative merits of the various approaches to depression and emotion recognition
under well-defined and strictly comparable conditions and establish to what
extent fusion of the approaches is possible and beneficial. This paper presents
the challenge guidelines, the common data used, and the performance of the
baseline system on the two tasks.
"
1011,Audio Event Detection using Weakly Labeled Data,"  Acoustic event detection is essential for content analysis and description of
multimedia recordings. The majority of current literature on the topic learns
the detectors through fully-supervised techniques employing strongly labeled
data. However, the labels available for majority of multimedia data are
generally weak and do not provide sufficient detail for such methods to be
employed. In this paper we propose a framework for learning acoustic event
detectors using only weakly labeled data. We first show that audio event
detection using weak labels can be formulated as an Multiple Instance Learning
problem. We then suggest two frameworks for solving multiple-instance learning,
one based on support vector machines, and the other on neural networks. The
proposed methods can help in removing the time consuming and expensive process
of manually annotating data to facilitate fully supervised learning. Moreover,
it can not only detect events in a recording but can also provide temporal
locations of events in the recording. This helps in obtaining a complete
description of the recording and is notable since temporal information was
never known in the first place in weakly labeled data.
"
1012,Efficient Reversible Data Hiding Algorithms Based on Dual Prediction,"  In this paper, a new reversible data hiding (RDH) algorithm that is based on
the concept of shifting of prediction error histograms is proposed. The
algorithm extends the efficient modification of prediction errors (MPE)
algorithm by incorporating two predictors and using one prediction error value
for data embedding. The motivation behind using two predictors is driven by the
fact that predictors have different prediction accuracy which is directly
related to the embedding capacity and quality of the stego image. The key
feature of the proposed algorithm lies in using two predictors without the need
to communicate additional overhead with the stego image. Basically, the
identification of the predictor that is used during embedding is done through a
set of rules. The proposed algorithm is further extended to use two and three
bins in the prediction errors histogram in order to increase the embedding
capacity. Performance evaluation of the proposed algorithm and its extensions
showed the advantage of using two predictors in boosting the embedding capacity
while providing competitive quality for the stego image.
"
1013,"Frame-level quality and memory traffic allocation for lossy embedded
  compression in video codec systems","  For mobile video codecs, the huge energy dissipation for external memory
traffic is a critical challenge under the battery power constraint. Lossy
embedded compression (EC), as a solution to this challenge, is considered in
this paper. While previous studies in EC mostly focused on compression
algorithms at the block level, this work, to the best of our knowledge, is the
first one that addresses the allocation of video quality and memory traffic at
the frame level. For lossy EC, a main difficulty of its application lies in the
error propagation from quality degradation of reference frames. Instinctively,
it is preferred to perform more lossy EC in non-reference frames to minimize
the quality loss. The analysis and experiments in this paper, however, will
show lossy EC should actually be distributed to more frames. Correspondingly,
for hierarchical-B GOPs, we developed an efficient allocation that outperforms
the non-reference-only allocation by up to 4.5 dB in PSNR. In comparison, the
proposed allocation also delivers more consistent quality between frames by
having lower PSNR fluctuation.
"
1014,"Delay-aware Fountain Codes for Video Streaming with Optimal Sampling
  Strategy","  The explosive demand of on-line video from smart mobile devices poses
unprecedented challenges to delivering high quality of experience (QoE) over
wireless networks. Streaming high-definition video with low delay is difficult
mainly due to (i) the stochastic nature of wireless channels and (ii) the
fluctuating videos bit rate. To address this, we propose a novel delay-aware
fountain coding (DAF) technique that integrates channel coding and video
coding. In this paper, we reveal that the fluctuation of video bit rate can
also be exploited to further improve fountain codes for wireless video
streaming. Specifically, we develop two coding techniques: the time-based
sliding window and the optimal window-wise sampling strategy. By adaptively
selecting the window length and optimally adjusting the sampling pattern
according to the ongoing video bit rate, the proposed schemes deliver
significantly higher video quality than existing schemes, with low delay and
constant data rate. To validate our design, we implement the protocols of DAF,
DAF-L (a low-complexity version) and the existing delay-aware video streaming
schemes by streaming H.264/AVC standard videos over an 802.11b network on CORE
emulation platform. The results show that the decoding ratio of our scheme is
15% to 100% higher than the state of the art techniques.
"
1015,Regression-based Intra-prediction for Image and Video Coding,"  By utilizing previously known areas in an image, intra-prediction techniques
can find a good estimate of the current block. This allows the encoder to store
only the error between the original block and the generated estimate, thus
leading to an improvement in coding efficiency. Standards such as AVC and HEVC
describe expert-designed prediction modes operating in certain angular
orientations alongside separate DC and planar prediction modes. Being designed
predictors, while these techniques have been demonstrated to perform well in
image and video coding applications, they do not necessarily fully utilize
natural image structures. In this paper, we describe a novel system for
developing predictors derived from natural image blocks. The proposed algorithm
is seeded with designed predictors (e.g. HEVC-style prediction) and allowed to
iteratively refine these predictors through regularized regression. The
resulting prediction models show significant improvements in estimation quality
over their designed counterparts across all conditions while maintaining
reasonable computational complexity. We also demonstrate how the proposed
algorithm handles the worst-case scenario of intra-prediction with no error
reporting.
"
1016,"Backward-Shifted Strategies Based on SVC for HTTP Adaptive Video
  Streaming","  Although HTTP-based video streaming can easily penetrate firewalls and profit
from Web caches, the underlying TCP may introduce large delays in case of a
sudden capacity loss. To avoid an interruption of the video stream in such
cases we propose the Backward-Shifted Coding (BSC). Based on Scalable Video
Coding (SVC), BSC adds a time-shifted layer of redundancy to the video stream
such that future frames are downloaded at any instant. This pre-fetched content
maintains a fluent video stream even under highly variant network conditions
and leads to high Quality of Experience (QoE). We characterize this QoE gain by
analyzing initial buffering time, re-buffering time and content resolution
using the Ballot theorem. The probability generating functions of the playback
interruption and of the initial buffering latency are provided in closed form.
We further compute the quasi-stationary distribution of the video quality, in
order to compute the average quality, as well as temporal variability in video
quality. Employing these analytic results to optimize QoE shows interesting
trade-offs and video streaming at outstanding fluency.
"
1017,"A First Look at Quality of Mobile Live Streaming Experience: the Case of
  Periscope","  Live multimedia streaming from mobile devices is rapidly gaining popularity
but little is known about the QoE they provide. In this paper, we examine the
Periscope service. We first crawl the service in order to understand its usage
patterns. Then, we study the protocols used, the typical quality of experience
indicators, such as playback smoothness and latency, video quality, and the
energy consumption of the Android application.
"
1018,Automatic Image Annotation via Label Transfer in the Semantic Space,"  Automatic image annotation is among the fundamental problems in computer
vision and pattern recognition, and it is becoming increasingly important in
order to develop algorithms that are able to search and browse large-scale
image collections. In this paper, we propose a label propagation framework
based on Kernel Canonical Correlation Analysis (KCCA), which builds a latent
semantic space where correlation of visual and textual features are well
preserved into a semantic embedding. The proposed approach is robust and can
work either when the training set is well annotated by experts, as well as when
it is noisy such as in the case of user-generated tags in social media. We
report extensive results on four popular datasets. Our results show that our
KCCA-based framework can be applied to several state-of-the-art label transfer
methods to obtain significant improvements. Our approach works even with the
noisy tags of social users, provided that appropriate denoising is performed.
Experiments on a large scale setting show that our method can provide some
benefits even when the semantic space is estimated on a subset of training
images.
"
1019,Video2GIF: Automatic Generation of Animated GIFs from Video,"  We introduce the novel problem of automatically generating animated GIFs from
video. GIFs are short looping video with no sound, and a perfect combination
between image and video that really capture our attention. GIFs tell a story,
express emotion, turn events into humorous moments, and are the new wave of
photojournalism. We pose the question: Can we automate the entirely manual and
elaborate process of GIF creation by leveraging the plethora of user generated
GIF content? We propose a Robust Deep RankNet that, given a video, generates a
ranked list of its segments according to their suitability as GIF. We train our
model to learn what visual content is often selected for GIFs by using over
100K user generated GIFs and their corresponding video sources. We effectively
deal with the noisy web data by proposing a novel adaptive Huber loss in the
ranking formulation. We show that our approach is robust to outliers and picks
up several patterns that are frequently present in popular animated GIFs. On
our new large-scale benchmark dataset, we show the advantage of our approach
over several state-of-the-art methods.
"
1020,Daala: A Perceptually-Driven Still Picture Codec,"  Daala is a new royalty-free video codec based on perceptually-driven coding
techniques. We explore using its keyframe format for still picture coding and
show how it has improved over the past year. We believe the technology used in
Daala could be the basis of an excellent, royalty-free image format.
"
1021,Lossless Compression in HEVC with Integer-to-Integer Transforms,"  Many approaches have been proposed to support lossless coding within video
coding standards that are primarily designed for lossy coding. The simplest
approach is to just skip transform and quantization and directly entropy code
the prediction residual, which is used in HEVC version 1. However, this simple
approach is inefficient for compression. More efficient approaches include
processing the residual with DPCM prior to entropy coding. This paper explores
an alternative approach based on processing the residual with
integer-to-integer (i2i) transforms. I2i transforms map integers to integers,
however, unlike the integer transforms used in HEVC for lossy coding, they do
not increase the dynamic range at the output and can be used in lossless
coding. Experiments with the HEVC reference software show competitive results.
"
1022,Lossless Intra Coding in HEVC with Integer-to-Integer DST,"  It is desirable to support efficient lossless coding within video coding
standards, which are primarily designed for lossy coding, with as little
modification as possible. A simple approach is to skip transform and
quantization, and directly entropy code the prediction residual, but this is
inefficient for compression. A more efficient and popular approach is to
process the residual block with DPCM prior to entropy coding. This paper
explores an alternative approach based on processing the residual block with
integer-to-integer (i2i) transforms. I2i transforms map integers to integers,
however, unlike the integer transforms used in HEVC for lossy coding, they do
not increase the dynamic range at the output and can be used in lossless
coding. We use both an i2i DCT from the literature and a novel i2i
approximation of the DST. Experiments with the HEVC reference software show
competitive results.
"
1023,"Resource Provisioning and Profit Maximization for Transcoding in
  Information Centric Networking","  Adaptive bitrate streaming (ABR) has been widely adopted to support video
streaming services over heterogeneous devices and varying network conditions.
With ABR, each video content is transcoded into multiple representations in
different bitrates and resolutions. However, video transcoding is computing
intensive, which requires the transcoding service providers to deploy a large
number of servers for transcoding the video contents published by the content
producers. As such, a natural question for the transcoding service provider is
how to provision the computing resource for transcoding the video contents
while maximizing service profit. To address this problem, we design a cloud
video transcoding system by taking the advantage of cloud computing technology
to elastically allocate computing resource. We propose a method for jointly
considering the task scheduling and resource provisioning problem in two
timescales, and formulate the service profit maximization as a two-timescale
stochastic optimization problem. We derive some approximate policies for the
task scheduling and resource provisioning. Based on our proposed methods, we
implement our open source cloud video transcoding system Morph and evaluate its
performance in a real environment. The experiment results demonstrate that our
proposed method can reduce the resource consumption and achieve a higher profit
compared with the baseline schemes.
"
1024,Generative Choreography using Deep Learning,"  Recent advances in deep learning have enabled the extraction of high-level
features from raw sensor data which has opened up new possibilities in many
different fields, including computer generated choreography. In this paper we
present a system chor-rnn for generating novel choreographic material in the
nuanced choreographic language and style of an individual choreographer. It
also shows promising results in producing a higher level compositional
cohesion, rather than just generating sequences of movement. At the core of
chor-rnn is a deep recurrent neural network trained on raw motion capture data
and that can generate new dance sequences for a solo dancer. Chor-rnn can be
used for collaborative human-machine choreography or as a creative catalyst,
serving as inspiration for a choreographer.
"
1025,Understanding the Smartrouter-based Peer CDN for Video Streaming,"  Recent years have witnessed a new video delivery paradigm: smartrouter-based
video delivery network, which is enabled by smartrouters deployed at users'
homes, together with the conventional video servers deployed in the
datacenters. Recently, ChinaCache, a large content delivery network (CDN)
provider, and Youku, a video service provider using smartrouters to assist
video delivery, announced their cooperation to create a new paradigm of content
delivery based on householders' network resources. This new paradigm is
different from the conventional peer-to-peer (P2P) approach, because such
dedicated smartrouters are inherently operated by the centralized video service
providers in a coordinative manner. It is intriguing to study the strategies,
performance and potential impact on the content delivery ecosystem of such peer
CDN systems. In this paper, we study the Youku peer CDN, which has deployed
over 300K smartrouter devices for its video streaming. In our measurement, 78K
videos were investigated and 3TB traffic has been analyzed, over controlled
routers and players. Our contributions are the following measurement insights.
First, a global replication and caching strategy is essential for the peer CDN
systems, and proactively scheduling replication and caching on a daily basis
can guarantee their performance. Second, such peer CDN deployment can itself
form an effective Quality of Service (QoS) monitoring sub-system, which can be
used for fine-grained user request redirection. We also provide our analysis on
the performance issues and potential improvements to the peer CDN systems.
"
1026,"Understanding Content Placement Strategies in Smartrouter-based Peer CDN
  for Video Streaming","  Recent years have witnessed a new video delivery paradigm: smartrouter-based
peer video content delivery network, which is enabled by smartrouters deployed
at users' homes. ChinaCache (one of the largest CDN providers in China) and
Youku (a video provider using smartrouters to assist video delivery) announced
their cooperation in 2015, to create a new paradigm of content delivery based
on householders' network resources. This new paradigm is different from the
conventional peer-to-peer (P2P) approach, because millions of dedicated
smartrouters are operated by the centralized video service providers in a
coordinative manner. Thus it is intriguing to study the content placement
strategies used in a smartrouter-based content delivery system, as well as its
potential impact on the content delivery ecosystem. In this paper, we carry out
measurement studies of Youku's peer video CDN, who has deployed over 300K
smartrouter devices for its video delivery. In our measurement studies, 104K
videos were investigated and 4TB traffic has been analyzed, over controlled
smartrouter nodes and players. Our measurement insights are as follows. First,
a global content replication strategy is essential for the peer CDN systems.
Second, such peer CDN deployment itself can form an effective sub-system for
end-to-end QoS monitoring, which can be used for fine-grained request
redirection (e.g., user-level) and content replication. We also show our
analysis on the performance limitations and propose potential improvements to
the peer CDN systems.
"
1027,"Steganalysis via a Convolutional Neural Network using Large Convolution
  Filters for Embedding Process with Same Stego Key","  For the past few years, in the race between image steganography and
steganalysis, deep learning has emerged as a very promising alternative to
steganalyzer approaches based on rich image models combined with ensemble
classifiers. A key knowledge of image steganalyzer, which combines relevant
image features and innovative classification procedures, can be deduced by a
deep learning approach called Convolutional Neural Networks (CNN). These kind
of deep learning networks is so well-suited for classification tasks based on
the detection of variations in 2D shapes that it is the state-of-the-art in
many image recognition problems. In this article, we design a CNN-based
steganalyzer for images obtained by applying steganography with a unique
embedding key. This one is quite different from the previous study of {\em Qian
et al.} and its successor, namely {\em Pibre et al.} The proposed architecture
embeds less convolutions, with much larger filters in the final convolutional
layer, and is more general: it is able to deal with larger images and lower
payloads. For the ""same embedding key"" scenario, our proposal outperforms all
other steganalyzers, in particular the existing CNN-based ones, and defeats
many state-of-the-art image steganography schemes.
"
1028,cvpaper.challenge in 2015 - A review of CVPR2015 and DeepSurvey,"  The ""cvpaper.challenge"" is a group composed of members from AIST, Tokyo Denki
Univ. (TDU), and Univ. of Tsukuba that aims to systematically summarize papers
on computer vision, pattern recognition, and related fields. For this
particular review, we focused on reading the ALL 602 conference papers
presented at the CVPR2015, the premier annual computer vision event held in
June 2015, in order to grasp the trends in the field. Further, we are proposing
""DeepSurvey"" as a mechanism embodying the entire process from the reading
through all the papers, the generation of ideas, and to the writing of paper.
"
1029,Efficient Multiple Line-Based Intra Prediction for HEVC,"  Traditional intra prediction usually utilizes the nearest reference line to
generate the predicted block when considering strong spatial correlation.
However, this kind of single line-based method does not always work well due to
at least two issues. One is the incoherence caused by the signal noise or the
texture of other object, where this texture deviates from the inherent texture
of the current block. The other reason is that the nearest reference line
usually has worse reconstruction quality in block-based video coding. Due to
these two issues, this paper proposes an efficient multiple line-based intra
prediction scheme to improve coding efficiency. Besides the nearest reference
line, further reference lines are also utilized. The further reference lines
with relatively higher quality can provide potential better prediction. At the
same time, the residue compensation is introduced to calibrate the prediction
of boundary regions in a block when we utilize further reference lines. To
speed up the encoding process, this paper designs several fast algorithms.
Experimental results show that, compared with HM-16.9, the proposed fast search
method achieves 2.0% bit saving on average and up to 3.7%, with increasing the
encoding time by 112%.
"
1030,A Feature based Approach for Video Compression,"  It is a high cost problem for panoramic image stitching via image matching
algorithm and not practical for real-time performance. In this paper, we take
full advantage ofHarris corner invariant characterization method light
intensity parallel meaning, translation and rotation, and made a realtime
panoramic image stitching algorithm. According to the basic characteristics and
performance FPGA classical algorithm, several modules such as the feature point
extraction, and matching description is to optimize the feature-based logic.
Real-time optimization system to achieve high precision match. The new
algorithm process the image from pixel domain and obtained from CCD camera
Xilinx Spartan-6 hardware platform. After the image stitching algorithm, will
eventually form a portable interface to output high-definition content on the
display. The results showed that, the proposed algorithm has higher precision
with good real-time performance and robustness.
"
1031,Virtual Reality based Learning Systems,"  This article is based on studies of the existing literature, focusing on the
states-of-the-arts on virtual reality (VR) and its potential uses in learning.
Different platforms have been used to improve the learning effects of VR that
offers exciting opportunities in various fields. As more and more students want
in a distance, part-time, or want to continue their education, VR has attracted
considerable attention in learning, training, and traditional education. VR
based learning enables operators to bring together all disciplinary resources
in a common playground. The VR base multimedia platform has successfully
demonstrated great potential of education and training. In this paper, we will
discuss existing systems and their uses and address the technical challenges
and future directions.
"
1032,Improving Crowdsourced Live Streaming with Aggregated Edge Networks,"  Recent years have witnessed a dramatic increase of user-generated video
services. In such user-generated video services, crowdsourced live streaming
(e.g., Periscope, Twitch) has significantly challenged today's edge network
infrastructure: today's edge networks (e.g., 4G, Wi-Fi) have limited uplink
capacity support, making high-bitrate live streaming over such links
fundamentally impossible. In this paper, we propose to let broadcasters (i.e.,
users who generate the video) upload crowdsourced video streams using
aggregated network resources from multiple edge networks. There are several
challenges in the proposal: First, how to design a framework that aggregates
bandwidth from multiple edge networks? Second, how to make this framework
transparent to today's crowdsourced live streaming services? Third, how to
maximize the streaming quality for the whole system? We design a
multi-objective and deployable bandwidth aggregation system BASS to address
these challenges: (1) We propose an aggregation framework transparent to
today's crowdsourced live streaming services, using an edge proxy box and
aggregation cloud paradigm; (2) We dynamically allocate geo-distributed cloud
aggregation servers to enable MPTCP (i.e., multi-path TCP), according to
location and network characteristics of both broadcasters and the original
streaming servers; (3) We maximize the overall performance gain for the whole
system, by matching streams with the best aggregation paths.
"
1033,Going Deeper for Multilingual Visual Sentiment Detection,"  This technical report details several improvements to the visual concept
detector banks built on images from the Multilingual Visual Sentiment Ontology
(MVSO). The detector banks are trained to detect a total of 9,918
sentiment-biased visual concepts from six major languages: English, Spanish,
Italian, French, German and Chinese. In the original MVSO release,
adjective-noun pair (ANP) detectors were trained for the six languages using an
AlexNet-styled architecture by fine-tuning from DeepSentiBank. Here, through a
more extensive set of experiments, parameter tuning, and training runs, we
detail and release higher accuracy models for detecting ANPs across six
languages from the same image pool and setting as in the original release using
a more modern architecture, GoogLeNet, providing comparable or better
performance with reduced network parameter cost.
  In addition, since the image pool in MVSO can be corrupted by user noise from
social interactions, we partitioned out a sub-corpus of MVSO images based on
tag-restricted queries for higher fidelity labels. We show that as a result of
these higher fidelity labels, higher performing AlexNet-styled ANP detectors
can be trained using the tag-restricted image subset as compared to the models
in full corpus. We release all these newly trained models for public research
use along with the list of tag-restricted images from the MVSO dataset.
"
1034,Models and Algorithms for Graph Watermarking,"  We introduce models and algorithmic foundations for graph watermarking. Our
frameworks include security definitions and proofs, as well as
characterizations when graph watermarking is algorithmically feasible, in spite
of the fact that the general problem is NP-complete by simple reductions from
the subgraph isomorphism or graph edit distance problems. In the digital
watermarking of many types of files, an implicit step in the recovery of a
watermark is the mapping of individual pieces of data, such as image pixels or
movie frames, from one object to another. In graphs, this step corresponds to
approximately matching vertices of one graph to another based on graph
invariants such as vertex degree. Our approach is based on characterizing the
feasibility of graph watermarking in terms of keygen, marking, and
identification functions defined over graph families with known distributions.
We demonstrate the strength of this approach with exemplary watermarking
schemes for two random graph models, the classic Erd\H{o}s-R\'{e}nyi model and
a random power-law graph model, both of which are used to model real-world
networks.
"
1035,Drone Streaming with Wi-Fi Grid Aggregation for Virtual Tour,"  To provide a live, active and high-quality virtual touring streaming
experience, we propose an unmanned drone stereoscopic streaming paradigm using
a control and streaming infrastructure of a 2.4GHz Wi-Fi grid. Our system
allows users to actively control the streaming captured by a drone, receive and
watch the streaming using a head mount display (HMD); a Wi-Fi grid is deployed
across the remote scene with multi-channel support to enable high-bitrate
stream- ing broadcast from the drones. The system adopt a joint view adaptation
and drone control scheme to enable fast viewer movement including both head
rotation and touring. We implement the prototype on Dji M100 quadcopter and HTC
Vive in a demo scene.
"
1036,Advanced Transport Options for the Dynamic Adaptive Streaming over HTTP,"  Multimedia streaming over HTTP is no longer a niche research topic as it has
entered our daily live. The common assumption is that it is deployed on top of
the existing infrastructure utilizing application (HTTP) and transport (TCP)
layer protocols as is. Interestingly, standards like MPEG's Dynamic Adaptive
Streaming over HTTP (DASH) do not mandate the usage of any specific transport
protocol allowing for sufficient deployment flexibility which is further
supported by emerging developments within both protocol layers. This paper
investigates and evaluates the usage of advanced transport options for the
dynamic adaptive streaming over HTTP. We utilize a common test setup to
evaluate HTTP/2.0 and Google's Quick UDP Internet Connections (QUIC) protocol
in the context of DASH-based services.
"
1037,"Which Adaptation Logic? An Objective and Subjective Performance
  Evaluation of HTTP-based Adaptive Media Streaming Systems","  Multimedia content delivery over the Internet is predominantly using the
Hypertext Transfer Protocol (HTTP) as its primary protocol and multiple
proprietary solutions exits. The MPEG standard Dynamic Adaptive Streaming over
HTTP (DASH) provides an interoperable solution and in recent years various
adaptation logics/algorithms have been proposed. However, to the best of our
knowledge, there is no comprehensive evaluation of the various
logics/algorithms. Therefore, this paper provides a comprehensive evaluation of
ten different adaptation logics/algorithms, which have been proposed in the
past years. The evaluation is done both objectively and subjectively. The
former is using a predefined bandwidth trajectory within a controlled
environment and the latter is done in a real-world environment adopting
crowdsourcing. The results shall provide insights about which strategy can be
adopted in actual deployment scenarios. Additionally, the evaluation
methodology described in this paper can be used to evaluate any other/new
adaptation logic and to compare it directly with the results reported here.
"
1038,Automatic Separation of Compound Figures in Scientific Articles,"  Content-based analysis and retrieval of digital images found in scientific
articles is often hindered by images consisting of multiple subfigures
(compound figures). We address this problem by proposing a method to
automatically classify and separate compound figures, which consists of two
main steps: (i) a supervised compound figure classifier (CFC) discriminates
between compound and non-compound figures using task-specific image features;
and (ii) an image processing algorithm is applied to predicted compound images
to perform compound figure separation (CFS). Our CFC approach is shown to
achieve state-of-the-art classification performance on a published dataset. Our
CFS algorithm shows superior separation accuracy on two different datasets
compared to other known automatic approaches. Finally, we propose a method to
evaluate the effectiveness of the CFC-CFS process chain and use it to optimize
the misclassification loss of CFC for maximal effectiveness in the process
chain.
"
1039,Photo Aesthetics Ranking Network with Attributes and Content Adaptation,"  Real-world applications could benefit from the ability to automatically
generate a fine-grained ranking of photo aesthetics. However, previous methods
for image aesthetics analysis have primarily focused on the coarse, binary
categorization of images into high- or low-aesthetic categories. In this work,
we propose to learn a deep convolutional neural network to rank photo
aesthetics in which the relative ranking of photo aesthetics are directly
modeled in the loss function. Our model incorporates joint learning of
meaningful photographic attributes and image content information which can help
regularize the complicated photo aesthetics rating problem.
  To train and analyze this model, we have assembled a new aesthetics and
attributes database (AADB) which contains aesthetic scores and meaningful
attributes assigned to each image by multiple human raters. Anonymized rater
identities are recorded across images allowing us to exploit intra-rater
consistency using a novel sampling strategy when computing the ranking loss of
training image pairs. We show the proposed sampling strategy is very effective
and robust in face of subjective judgement of image aesthetics by individuals
with different aesthetic tastes. Experiments demonstrate that our unified model
can generate aesthetic rankings that are more consistent with human ratings. To
further validate our model, we show that by simply thresholding the estimated
aesthetic scores, we are able to achieve state-or-the-art classification
performance on the existing AVA dataset benchmark.
"
1040,"Towards Playlist Generation Algorithms Using RNNs Trained on
  Within-Track Transitions","  We introduce a novel playlist generation algorithm that focuses on the
quality of transitions using a recurrent neural network (RNN). The proposed
model assumes that optimal transitions between tracks can be modelled and
predicted by internal transitions within music tracks. We introduce modelling
sequences of high-level music descriptors using RNNs and discuss an experiment
involving different similarity functions, where the sequences are provided by a
musical structural analysis algorithm. Qualitative observations show that the
proposed approach can effectively model transitions of music tracks in
playlists.
"
1041,Multilingual Visual Sentiment Concept Matching,"  The impact of culture in visual emotion perception has recently captured the
attention of multimedia research. In this study, we pro- vide powerful
computational linguistics tools to explore, retrieve and browse a dataset of
16K multilingual affective visual concepts and 7.3M Flickr images. First, we
design an effective crowdsourc- ing experiment to collect human judgements of
sentiment connected to the visual concepts. We then use word embeddings to
repre- sent these concepts in a low dimensional vector space, allowing us to
expand the meaning around concepts, and thus enabling insight about
commonalities and differences among different languages. We compare a variety
of concept representations through a novel evaluation task based on the notion
of visual semantic relatedness. Based on these representations, we design
clustering schemes to group multilingual visual concepts, and evaluate them
with novel metrics based on the crowdsourced sentiment annotations as well as
visual semantic relatedness. The proposed clustering framework enables us to
analyze the full multilingual dataset in-depth and also show an application on
a facial data subset, exploring cultural in- sights of portrait-related
affective visual concepts.
"
1042,"High Capacity Image Steganography using Adjunctive Numerical
  Representations with Multiple Bit-Plane Decomposition Methods","  LSB steganography is a one of the most widely used methods for implementing
covert data channels in image file exchanges [1][2]. The low computational
complexity and implementation simplicity of the algorithm are significant
factors for its popularity with the primary reason being low image distortion.
Many attempts have been made to increase the embedding capacity of LSB
algorithms by expanding into the second or third binary layers of the image
while maintaining a low probability of detection with minimal distortive
effects [2][3][4]. In this paper, we introduce an advanced technique for
covertly embedding data within images using redundant number system
decomposition over non-standard digital bit planes. Both grayscale and
bit-mapped images are equally effective as cover files. It will be shown that
this unique steganography method has minimal visual distortive affects while
also preserving the cover file statistics, making it less susceptible to most
general steganography detection algorithms.
"
1043,Generic-Precision algorithm for DCT-Cordic architectures,"  In this paper we propose a generic algorithm to calculate the rotation
parameters of CORDIC angles required for the Discrete Cosine Transform
algorithm (DCT). This leads us to increase the precision of calculation meeting
any accuracy.Our contribution is to use this decomposition in CORDIC based DCT
which is appropriate for domains which require high quality and top precision.
We then propose a hardware implementation of the novel transformation, and as
expected, a substantial improvement in PSNR quality is found.
"
1044,Estimation of solar irradiance using ground-based whole sky imagers,"  Ground-based whole sky imagers (WSIs) can provide localized images of the sky
of high temporal and spatial resolution, which permits fine-grained cloud
observation. In this paper, we show how images taken by WSIs can be used to
estimate solar radiation. Sky cameras are useful here because they provide
additional information about cloud movement and coverage, which are otherwise
not available from weather station data. Our setup includes ground-based
weather stations at the same location as the imagers. We use their measurements
to validate our methods.
"
1045,Audio Content based Geotagging in Multimedia,"  In this paper we propose methods to extract geographically relevant
information in a multimedia recording using its audio. Our method primarily is
based on the fact that urban acoustic environment consists of a variety of
sounds. Hence, location information can be inferred from the composition of
sound events/classes present in the audio. More specifically, we adopt matrix
factorization techniques to obtain semantic content of recording in terms of
different sound classes. These semantic information are then combined to
identify the location of recording.
"
1046,Automatic Genre and Show Identification of Broadcast Media,"  Huge amounts of digital videos are being produced and broadcast every day,
leading to giant media archives. Effective techniques are needed to make such
data accessible further. Automatic meta-data labelling of broadcast media is an
essential task for multimedia indexing, where it is standard to use multi-modal
input for such purposes. This paper describes a novel method for automatic
detection of media genre and show identities using acoustic features, textual
features or a combination thereof. Furthermore the inclusion of available
meta-data, such as time of broadcast, is shown to lead to very high
performance. Latent Dirichlet Allocation is used to model both acoustics and
text, yielding fixed dimensional representations of media recordings that can
then be used in Support Vector Machines based classification. Experiments are
conducted on more than 1200 hours of TV broadcasts from the British
Broadcasting Corporation (BBC), where the task is to categorise the broadcasts
into 8 genres or 133 show identities. On a 200-hour test set, accuracies of
98.6% and 85.7% were achieved for genre and show identification respectively,
using a combination of acoustic and textual features with meta-data.
"
1047,Weakly Supervised Scalable Audio Content Analysis,"  Audio Event Detection is an important task for content analysis of multimedia
data. Most of the current works on detection of audio events is driven through
supervised learning approaches. We propose a weakly supervised learning
framework which can make use of the tremendous amount of web multimedia data
with significantly reduced annotation effort and expense. Specifically, we use
several multiple instance learning algorithms to show that audio event
detection through weak labels is feasible. We also propose a novel scalable
multiple instance learning algorithm and show that its competitive with other
multiple instance learning algorithms for audio event detection tasks.
"
1048,Social- and Mobility-Aware Device-to-Device Content Delivery,"  Mobile online social network services have seen a rapid increase, in which
the huge amount of user-generated social media contents propagating between
users via social connections has significantly challenged the traditional
content delivery paradigm: First, replicating all of the contents generated by
users to edge servers that well ""fit"" the receivers becomes difficult due to
the limited bandwidth and storage capacities. Motivated by device-to-device
(D2D) communication that allows users with smart devices to transfer content
directly, we propose replicating bandwidth-intensive social contents in a
device-to-device manner. Based on large-scale measurement studies on social
content propagation and user mobility patterns in edge-network regions, we
observe that (1) Device-to-device replication can significantly help users
download social contents from nearby neighboring peers; (2) Both social
propagation and mobility patterns affect how contents should be replicated; (3)
The replication strategies depend on regional characteristics ({\em e.g.}, how
users move across regions).
  Using these measurement insights, we propose a joint \emph{propagation- and
mobility-aware} content replication strategy for edge-network regions, in which
social contents are assigned to users in edge-network regions according to a
joint consideration of social graph, content propagation and user mobility. We
formulate the replication scheduling as an optimization problem and design
distributed algorithm only using historical, local and partial information to
solve it. Trace-driven experiments further verify the superiority of our
proposal: compared with conventional pure movement-based and popularity-based
approach, our design can significantly ($2-4$ times) improve the amount of
social contents successfully delivered by device-to-device replication.
"
1049,Bidirectional Long-Short Term Memory for Video Description,"  Video captioning has been attracting broad research attention in multimedia
community. However, most existing approaches either ignore temporal information
among video frames or just employ local contextual temporal knowledge. In this
work, we propose a novel video captioning framework, termed as
\emph{Bidirectional Long-Short Term Memory} (BiLSTM), which deeply captures
bidirectional global temporal structure in video. Specifically, we first devise
a joint visual modelling approach to encode video data by combining a forward
LSTM pass, a backward LSTM pass, together with visual features from
Convolutional Neural Networks (CNNs). Then, we inject the derived video
representation into the subsequent language model for initialization. The
benefits are in two folds: 1) comprehensively preserving sequential and visual
information; and 2) adaptively learning dense visual features and sparse
semantic representations for videos and sentences, respectively. We verify the
effectiveness of our proposed video captioning framework on a commonly-used
benchmark, i.e., Microsoft Video Description (MSVD) corpus, and the
experimental results demonstrate that the superiority of the proposed approach
as compared to several state-of-the-art methods.
"
1050,"Can Machine Learn Steganography? - Implementing LSB Substitution and
  Matrix Coding Steganography with Feed-Forward Neural Networks","  In recent years, due to the powerful abilities to deal with highly complex
tasks, the artificial neural networks (ANNs) have been studied in the hope of
achieving human-like performance in many applications. Since the ANNs have the
ability to approximate complex functions from observations, it is
straightforward to consider the ANNs for steganography. In this paper, we aim
to implement the well-known LSB substitution and matrix coding steganography
with the feed-forward neural networks (FNNs). Our experimental results have
shown that, the used FNNs can achieve the data embedding operation of the LSB
substitution and matrix coding steganography. For steganography with the ANNs,
though there may be some challenges to us, it would be very promising and
valuable to pay attention to the ANNs for steganography, which may be a new
direction for steganography.
"
1051,"Strategies for Searching Video Content with Text Queries or Video
  Examples","  The large number of user-generated videos uploaded on to the Internet
everyday has led to many commercial video search engines, which mainly rely on
text metadata for search. However, metadata is often lacking for user-generated
videos, thus these videos are unsearchable by current search engines.
Therefore, content-based video retrieval (CBVR) tackles this metadata-scarcity
problem by directly analyzing the visual and audio streams of each video. CBVR
encompasses multiple research topics, including low-level feature design,
feature fusion, semantic detector training and video search/reranking. We
present novel strategies in these topics to enhance CBVR in both accuracy and
speed under different query inputs, including pure textual queries and query by
video examples. Our proposed strategies have been incorporated into our
submission for the TRECVID 2014 Multimedia Event Detection evaluation, where
our system outperformed other submissions in both text queries and video
example queries, thus demonstrating the effectiveness of our proposed
approaches.
"
1052,"A Note on Efficiency of Downsampling and Color Transformation in Image
  Quality Assessment","  Several existing and successful full reference image quality assessment (IQA)
models use linear color transformation and downsampling before measuring
similarity or quality of images. This paper indicates to the right order of
these two procedures and that the existing models have not chosen the more
efficient approach. In addition, efficiency of these metrics is not compared in
a fair basis in the literature.
"
1053,Polymetric Rhythmic Feel for a Cognitive Drum Computer,"  This paper addresses a question about music cognition: how do we derive
polymetric structures. A preference rule system is presented which is
implemented into a drum computer. The preference rule system allows inferring
local polymetric structures, like two-over-three and three-over-two. By
analyzing the micro-timing of West African percussion music a timing pattern
consisting of six pulses was discovered. It integrates binary and ternary
rhythmic feels. The presented drum computer integrates the discovered
superimposed polymetric swing (timing and velocity) appropriate to the rhythmic
sequence the user inputs. For binary sequences, the amount of binary swing is
increased and for ternary sequences, the ternary swing is increased.
"
1054,"MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis
  in Online Opinion Videos","  People are sharing their opinions, stories and reviews through online video
sharing websites every day. Studying sentiment and subjectivity in these
opinion videos is experiencing a growing attention from academia and industry.
While sentiment analysis has been successful for text, it is an understudied
research question for videos and multimedia content. The biggest setbacks for
studies in this direction are lack of a proper dataset, methodology, baselines
and statistical analysis of how information from different modality sources
relate to each other. This paper introduces to the scientific community the
first opinion-level annotated corpus of sentiment and subjectivity analysis in
online videos called Multimodal Opinion-level Sentiment Intensity dataset
(MOSI). The dataset is rigorously annotated with labels for subjectivity,
sentiment intensity, per-frame and per-opinion annotated visual features, and
per-milliseconds annotated audio features. Furthermore, we present baselines
for future studies in this direction as well as a new multimodal fusion
approach that jointly models spoken words and visual gestures.
"
1055,"Personality, Culture, and System Factors - Impact on Affective Response
  to Multimedia","  Whilst affective responses to various forms and genres of multimedia content
have been well researched, precious few studies have investigated the combined
impact that multimedia system parameters and human factors have on affect.
Consequently, in this paper we explore the role that two primordial dimensions
of human factors - personality and culture - in conjunction with system factors
- frame rate, resolution, and bit rate - have on user affect and enjoyment of
multimedia presentations. To this end, a two-site, cross-cultural study was
undertaken, the results of which produced three predictve models. Personality
and Culture traits were shown statistically to represent 5.6% of the variance
in positive affect, 13.6% in negative affect and 9.3% in enjoyment. The
correlation between affect and enjoyment, was significant. Predictive modeling
incorporating human factors showed about 8%, 7% and 9% improvement in
predicting positive affect, negative affect and enjoyment respectively when
compared to models trained only on system factors. Results and analysis
indicate the significant role played by human factors in influencing affect
that users experience while watching multimedia.
"
1056,"Multiplierless 16-point DCT Approximation for Low-complexity Image and
  Video Coding","  An orthogonal 16-point approximate discrete cosine transform (DCT) is
introduced. The proposed transform requires neither multiplications nor
bit-shifting operations. A fast algorithm based on matrix factorization is
introduced, requiring only 44 additions---the lowest arithmetic cost in
literature. To assess the introduced transform, computational complexity,
similarity with the exact DCT, and coding performance measures are computed.
Classical and state-of-the-art 16-point low-complexity transforms were used in
a comparative analysis. In the context of image compression, the proposed
approximation was evaluated via PSNR and SSIM measurements, attaining the best
cost-benefit ratio among the competitors. For video encoding, the proposed
approximation was embedded into a HEVC reference software for direct comparison
with the original HEVC standard. Physically realized and tested using FPGA
hardware, the proposed transform showed 35% and 37% improvements of area-time
and area-time-squared VLSI metrics when compared to the best competing
transform in the literature.
"
1057,"N-queens-based algorithm for moving object detection in distributed
  wireless sensor networks","  The main constraint of wireless sensor networks (WSN) in enabling wireless
image communication is the high energy requirement, which may exceed even the
future capabilities of battery technologies. In this paper we have shown that
this bottleneck can be overcome by developing local in-network image processing
algorithm that offers optimal energy consumption. Our algorithm is very
suitable for intruder detection applications. Each node is responsible for
processing the image captured by the video sensor, which consists of NxN
blocks. If an intruder is detected in the monitoring region, the node will
transmit the image for further processing. Otherwise, the node takes no action.
Results provided from our experiments show that our algorithm is better than
the traditional moving object detection techniques by a factor of (N/2) in
terms of energy savings.
"
1058,Label Tree Embeddings for Acoustic Scene Classification,"  We present in this paper an efficient approach for acoustic scene
classification by exploring the structure of class labels. Given a set of class
labels, a category taxonomy is automatically learned by collectively optimizing
a clustering of the labels into multiple meta-classes in a tree structure. An
acoustic scene instance is then embedded into a low-dimensional feature
representation which consists of the likelihoods that it belongs to the
meta-classes. We demonstrate state-of-the-art results on two different datasets
for the acoustic scene classification task, including the DCASE 2013 and LITIS
Rouen datasets.
"
1059,Finding the Topic of a Set of Images,"  In this paper we introduce the problem of determining the topic that a set of
images is describing, where every topic is represented as a set of words.
Different from other problems like tag assignment or similar, a) we assume
multiple images are used as input instead of single image, b) Input images are
typically not visually related, c) Input images are not necessarily
semantically close, and d) Output word space is unconstrained. In our proposed
solution, visual information of each query image is used to retrieve similar
images with text labels (tags) from an image database. We consider a scenario
where the tags are very noisy and diverse, given that they were obtained by
implicit crowd-sourcing in a database of 1 million images and over seventy
seven thousand tags. The words or tags associated to each query are processed
jointly in a word selection algorithm using random walks that allows to refine
the search topic, rejecting words that are not part of the topic and produce a
set of words that fairly describe the topic. Experiments on a dataset of 300
topics, with up to twenty images per topic, show that our algorithm performs
better than the proposed baseline for any number of query images. We also
present a new Conditional Random Field (CRF) word mapping algorithm that
preserves the semantic similarity of the mapped words, increasing the
performance of the results over the baseline.
"
1060,Leveraging Contextual Cues for Generating Basketball Highlights,"  The massive growth of sports videos has resulted in a need for automatic
generation of sports highlights that are comparable in quality to the
hand-edited highlights produced by broadcasters such as ESPN. Unlike previous
works that mostly use audio-visual cues derived from the video, we propose an
approach that additionally leverages contextual cues derived from the
environment that the game is being played in. The contextual cues provide
information about the excitement levels in the game, which can be ranked and
selected to automatically produce high-quality basketball highlights. We
introduce a new dataset of 25 NCAA games along with their play-by-play stats
and the ground-truth excitement data for each basket. We explore the
informativeness of five different cues derived from the video and from the
environment through user studies. Our experiments show that for our study
participants, the highlights produced by our system are comparable to the ones
produced by ESPN for the same games.
"
1061,"De-Hashing: Server-Side Context-Aware Feature Reconstruction for Mobile
  Visual Search","  Due to the prevalence of mobile devices, mobile search becomes a more
convenient way than desktop search. Different from the traditional desktop
search, mobile visual search needs more consideration for the limited resources
on mobile devices (e.g., bandwidth, computing power, and memory consumption).
The state-of-the-art approaches show that bag-of-words (BoW) model is robust
for image and video retrieval; however, the large vocabulary tree might not be
able to be loaded on the mobile device. We observe that recent works mainly
focus on designing compact feature representations on mobile devices for
bandwidth-limited network (e.g., 3G) and directly adopt feature matching on
remote servers (cloud). However, the compact (binary) representation might fail
to retrieve target objects (images, videos). Based on the hashed binary codes,
we propose a de-hashing process that reconstructs BoW by leveraging the
computing power of remote servers. To mitigate the information loss from binary
codes, we further utilize contextual information (e.g., GPS) to reconstruct a
context-aware BoW for better retrieval results. Experiment results show that
the proposed method can achieve competitive retrieval accuracy as BoW while
only transmitting few bits from mobile devices.
"
1062,"Minimum-latency Time-frequency Analysis Using Asymmetric Window
  Functions","  We study the real-time dynamics retrieval from a time series via the
time-frequency (TF) analysis with the minimal latency guarantee. While
different from the well-known intrinsic latency definition in the filter
design, a rigorous definition of intrinsic latency for different time-frequency
representations (TFR) is provided, including the short time Fourier transform
(STFT), synchrosqeezing transform (SST) and reassignment method (RM). To
achieve the minimal latency, a systematic method is proposed to construct an
asymmetric window from a well-designed symmetric one based on the concept of
minimum-phase, if the window satisfies some weak conditions. We theoretically
show that the TFR determined by SST with the constructed asymmetric window does
have a smaller intrinsic latency. Finally, the music onset detection problem is
studied to show the strength of the proposed algorithm.
"
1063,"How smart does your profile image look? Estimating intelligence from
  social network profile images","  Profile images on social networks are users' opportunity to present
themselves and to affect how others judge them. We examine what Facebook images
say about users' perceived and measured intelligence. 1,122 Facebook users
completed a matrices intelligence test and shared their current Facebook
profile image. Strangers also rated the images for perceived intelligence. We
use automatically extracted image features to predict both measured and
perceived intelligence. Intelligence estimation from images is a difficult task
even for humans, but experimental results show that human accuracy can be
equalled using computing methods. We report the image features that predict
both measured and perceived intelligence, and highlight misleading features
such as ""smiling"" and ""wearing glasses"" that are correlated with perceived but
not measured intelligence. Our results give insights into inaccurate
stereotyping from profile images and also have implications for privacy,
especially since in most social networks profile images are public by default.
"
1064,Formal Definition of QoE Metrics,"  This technical report formally defines the QoE metrics which are introduced
and discussed in the article ""QoE Beyond the MOS: An In-Depth Look at QoE via
Better Metrics and their Relation to MOS"" by Tobias Ho{\ss}feld, Poul E.
Heegaard, Martin Varela, Sebastian M\""oller, accepted for publication in the
Springer journal ""Quality and User Experience"". Matlab scripts for computing
the QoE metrics for given data sets are available in GitHub.
"
1065,"Using Social Media to Promote STEM Education: Matching College Students
  with Role Models","  STEM (Science, Technology, Engineering, and Mathematics) fields have become
increasingly central to U.S. economic competitiveness and growth. The shortage
in the STEM workforce has brought promoting STEM education upfront. The rapid
growth of social media usage provides a unique opportunity to predict users'
real-life identities and interests from online texts and photos. In this paper,
we propose an innovative approach by leveraging social media to promote STEM
education: matching Twitter college student users with diverse LinkedIn STEM
professionals using a ranking algorithm based on the similarities of their
demographics and interests. We share the belief that increasing STEM presence
in the form of introducing career role models who share similar interests and
demographics will inspire students to develop interests in STEM related fields
and emulate their models. Our evaluation on 2,000 real college students
demonstrated the accuracy of our ranking algorithm. We also design a novel
implementation that recommends matched role models to the students.
"
1066,Coarse2Fine: Two-Layer Fusion For Image Retrieval,"  This paper addresses the problem of large-scale image retrieval. We propose a
two-layer fusion method which takes advantage of global and local cues and
ranks database images from coarse to fine (C2F). Departing from the previous
methods fusing multiple image descriptors simultaneously, C2F is featured by a
layered procedure composed by filtering and refining. In particular, C2F
consists of three components. 1) Distractor filtering. With holistic
representations, noise images are filtered out from the database, so the number
of candidate images to be used for comparison with the query can be greatly
reduced. 2) Adaptive weighting. For a certain query, the similarity of
candidate images can be estimated by holistic similarity scores in
complementary to the local ones. 3) Candidate refining. Accurate retrieval is
conducted via local features, combining the pre-computed adaptive weights.
Experiments are presented on two benchmarks, \emph{i.e.,} Holidays and Ukbench
datasets. We show that our method outperforms recent fusion methods in terms of
storage consumption and computation complexity, and that the accuracy is
competitive to the state-of-the-arts.
"
1067,Towards Network-Failure-Tolerant Content Delivery for Web Content,"  Popularly used to distribute a variety of multimedia content items in today
Internet, HTTP-based web content delivery still suffers from various content
delivery failures. Hindered by the expensive deployment cost, the conventional
CDN can not deploy as many edge servers as possible to successfully deliver
content items to all users under these delivery failures. In this paper, we
propose a joint CDN and peer-assisted web content delivery framework to address
the delivery failure problem. Different from conventional peer-assisted
approaches for web content delivery, which mainly focus on alleviating the CDN
servers bandwidth load, we study how to use a browser-based peer-assisted
scheme, namely WebRTC, to resolve content delivery failures. To this end, we
carry out large-scale measurement studies on how users access and view
webpages. Our measurement results demonstrate the challenges (e.g., peers stay
on a webpage extremely short) that can not be directly solved by conventional
P2P strategies, and some important webpage viewing patterns. Due to these
unique characteristics, WebRTC peers open up new possibilities for helping the
web content delivery, coming with the problem of how to utilize the dynamic
resources efficiently. We formulate the peer selection that is the critical
strategy in our framework, as an optimization problem, and design a heuristic
algorithm based on the measurement insights to solve it. Our simulation
experiments driven by the traces from Tencent QZone demonstrate the
effectiveness of our design: compared with non-peer-assisted strategy and
random peer selection strategy, our design significantly improves the
successful relay ratio of web content items under network failures, e.g., our
design improves the content download ratio up to 60% even when users located in
a particular region (e.g., city) where none can connect to the regional CDN
server.
"
1068,A Measurement Study of TCP Performance for Chunk Delivery in DASH,"  Dynamic Adaptive Streaming over HTTP (DASH) has emerged as an increasingly
popular paradigm for video streaming [13], in which a video is segmented into
many chunks delivered to users by HTTP request/response over Transmission
Control Protocol (TCP) con- nections. Therefore, it is intriguing to study the
performance of strategies implemented in conventional TCPs, which are not
dedicated for video streaming, e.g., whether chunks are efficiently delivered
when users per- form interactions with the video players. In this paper, we
conduct mea- surement studies on users chunk requesting traces in DASH from a
rep- resentative video streaming provider, to investigate users behaviors in
DASH, and TCP-connection-level traces from CDN servers, to investi- gate the
performance of TCP for DASH. By studying how video chunks are delivered in both
the slow start and congestion avoidance phases, our observations have revealed
the performance characteristics of TCP for DASH as follows: (1) Request
patterns in DASH have a great impact on the performance of TCP variations
including cubic; (2) Strategies in conventional TCPs may cause user perceived
quality degradation in DASH streaming; (3) Potential improvement to TCP
strategies for better delivery in DASH can be further explored.
"
1069,Dynamic Flow Scheduling Strategy in Multihoming Video CDNs,"  Multihoming for a video Content Delivery Network (CDN) allows edge peering
servers to deliver video chunks through different Internet Service Providers
(ISPs), to achieve an improved quality of service (QoS) for video streaming
users. However, since traditional strategies for a multihoming video CDN are
simply designed according to static rules, e.g., simply sending traffic via a
ISP which is the same as the ISP of client, they fail to dynamically allocate
resources among different ISPs over time. In this paper, we perform measurement
studies to demonstrate that such static allocation mechanism is inefficient to
make full utilization of multiple ISPs' resources. To address this problem, we
propose a dynamic flow scheduling strategy for multihoming video CDN. The
challenge is to find the control parameters that can guide the ISP selection
when performing flow scheduling. Using a data-driven approach, we find factors
that have a major impact on the performance improvement in the dynamic flow
scheduling. We further utilize an information gain approach to generate
parameter combinations that can be used to guide the flow scheduling, i.e., to
determine the ISP each request should be responded by. Our evaluation results
demonstrate that our design effectively performs the flow scheduling. In
particular, our design yields near optimal performance in a simulation of
real-world multihoming setup.
"
1070,"Two RPG Flow-graphs for Software Watermarking using Bitonic Sequences of
  Self-inverting Permutations","  Software watermarking has received considerable attention and was adopted by
the software development community as a technique to prevent or discourage
software piracy and copyright infringement. A wide range of software
watermarking techniques has been proposed among which the graph-based methods
that encode watermarks as graph structures. Following up on our recently
proposed methods for encoding watermark numbers $w$ as reducible permutation
flow-graphs $F[\pi^*]$ through the use of self-inverting permutations $\pi^*$,
in this paper, we extend the types of flow-graphs available for software
watermarking by proposing two different reducible permutation flow-graphs
$F_1[\pi^*]$ and $F_2[\pi^*]$ incorporating important properties which are
derived from the bitonic subsequences composing the self-inverting permutation
$\pi^*$. We show that a self-inverting permutation $\pi^*$ can be efficiently
encoded into either $F_1[\pi^*]$ or $F_2[\pi^*]$ and also efficiently decoded
from theses graph structures. The proposed flow-graphs $F_1[\pi^*]$ and
$F_2[\pi^*]$ enrich the repository of graphs which can encode the same
watermark number $w$ and, thus, enable us to embed multiple copies of the same
watermark $w$ into an application program $P$. Moreover, the enrichment of that
repository with new flow-graphs increases our ability to select a graph
structure more similar to the structure of a given application program $P$
thereby enhancing the resilience of our codec system to attacks.
"
1071,"CNN-LTE: a Class of 1-X Pooling Convolutional Neural Networks on Label
  Tree Embeddings for Audio Scene Recognition","  We describe in this report our audio scene recognition system submitted to
the DCASE 2016 challenge. Firstly, given the label set of the scenes, a label
tree is automatically constructed. This category taxonomy is then used in the
feature extraction step in which an audio scene instance is represented by a
label tree embedding image. Different convolutional neural networks, which are
tailored for the task at hand, are finally learned on top of the image features
for scene recognition. Our system reaches an overall recognition accuracy of
81.2% and 83.3% and outperforms the DCASE 2016 baseline with absolute
improvements of 8.7% and 6.1% on the development and test data, respectively.
"
1072,"CaR-FOREST: Joint Classification-Regression Decision Forests for
  Overlapping Audio Event Detection","  This report describes our submissions to Task2 and Task3 of the DCASE 2016
challenge. The systems aim at dealing with the detection of overlapping audio
events in continuous streams, where the detectors are based on random decision
forests. The proposed forests are jointly trained for classification and
regression simultaneously. Initially, the training is classification-oriented
to encourage the trees to select discriminative features from overlapping
mixtures to separate positive audio segments from the negative ones. The
regression phase is then carried out to let the positive audio segments vote
for the event onsets and offsets, and therefore model the temporal structure of
audio events. One random decision forest is specifically trained for each event
category of interest. Experimental results on the development data show that
our systems significantly outperform the baseline on the Task2 evaluation while
they are inferior to the baseline in the Task3 evaluation.
"
1073,Explaining Deep Convolutional Neural Networks on Music Classification,"  Deep convolutional neural networks (CNNs) have been actively adopted in the
field of music information retrieval, e.g. genre classification, mood
detection, and chord recognition. However, the process of learning and
prediction is little understood, particularly when it is applied to
spectrograms. We introduce auralisation of a CNN to understand its underlying
mechanism, which is based on a deconvolution procedure introduced in [2].
Auralisation of a CNN is converting the learned convolutional features that are
obtained from deconvolution into audio signals. In the experiments and
discussions, we explain trained features of a 5-layer CNN based on the
deconvolved spectrograms and auralised signals. The pairwise correlations per
layers with varying different musical attributes are also investigated to
understand the evolution of the learnt features. It is shown that in the deep
layers, the features are learnt to capture textures, the patterns of continuous
distributions, rather than shapes of lines.
"
1074,"Classifying Variable-Length Audio Files with All-Convolutional Networks
  and Masked Global Pooling","  We trained a deep all-convolutional neural network with masked global pooling
to perform single-label classification for acoustic scene classification and
multi-label classification for domestic audio tagging in the DCASE-2016
contest. Our network achieved an average accuracy of 84.5% on the four-fold
cross-validation for acoustic scene recognition, compared to the provided
baseline of 72.5%, and an average equal error rate of 0.17 for domestic audio
tagging, compared to the baseline of 0.21. The network therefore improves the
baselines by a relative amount of 17% and 19%, respectively. The network only
consists of convolutional layers to extract features from the short-time
Fourier transform and one global pooling layer to combine those features. It
particularly possesses neither fully-connected layers, besides the
fully-connected output layer, nor dropout layers.
"
1075,City-Identification of Flickr Videos Using Semantic Acoustic Features,"  City-identification of videos aims to determine the likelihood of a video
belonging to a set of cities. In this paper, we present an approach using only
audio, thus we do not use any additional modality such as images, user-tags or
geo-tags. In this manner, we show to what extent the city-location of videos
correlates to their acoustic information. Success in this task suggests
improvements can be made to complement the other modalities. In particular, we
present a method to compute and use semantic acoustic features to perform
city-identification and the features show semantic evidence of the
identification. The semantic evidence is given by a taxonomy of urban sounds
and expresses the potential presence of these sounds in the city- soundtracks.
We used the MediaEval Placing Task set, which contains Flickr videos labeled by
city. In addition, we used the UrbanSound8K set containing audio clips labeled
by sound- type. Our method improved the state-of-the-art performance and
provides a novel semantic approach to this task
"
1076,Scalar Quadratic-Gaussian Soft Watermarking Games,"  We introduce the zero-sum game problem of soft watermarking: The hidden
information (watermark) comes from a continuum and has a perceptual value; the
receiver generates an estimate of the embedded watermark to minimize the
expected estimation error (unlike the conventional watermarking schemes where
both the hidden information and the receiver output are from a discrete finite
set). Applications include embedding a multimedia content into another. We
consider in this paper the scalar Gaussian case and use expected mean-squared
distortion. We formulate the resulting problem as a zero-sum game between the
encoder & receiver pair and the attacker. We show that for the lin- ear
encoder, the optimal attacker is Gaussian-affine, derive the optimal system
parameters in that case, and discuss the corresponding system behavior. We also
provide numerical results to gain further insight and understanding of the
system behavior at optimality.
"
1077,"Parsimonious Mixed-Effects HodgeRank for Crowdsourced Preference
  Aggregation","  In crowdsourced preference aggregation, it is often assumed that all the
annotators are subject to a common preference or utility function which
generates their comparison behaviors in experiments. However, in reality
annotators are subject to variations due to multi-criteria, abnormal, or a
mixture of such behaviors. In this paper, we propose a parsimonious
mixed-effects model based on HodgeRank, which takes into account both the fixed
effect that the majority of annotators follows a common linear utility model,
and the random effect that a small subset of annotators might deviate from the
common significantly and exhibits strongly personalized preferences. HodgeRank
has been successfully applied to subjective quality evaluation of multimedia
and resolves pairwise crowdsourced ranking data into a global consensus ranking
and cyclic conflicts of interests. As an extension, our proposed methodology
further explores the conflicts of interests through the random effect in
annotator specific variations. The key algorithm in this paper establishes a
dynamic path from the common utility to individual variations, with different
levels of parsimony or sparsity on personalization, based on newly developed
Linearized Bregman Algorithms with Inverse Scale Space method. Finally the
validity of the methodology are supported by experiments with both simulated
examples and three real-world crowdsourcing datasets, which shows that our
proposed method exhibits better performance (i.e. smaller test error) compared
with HodgeRank due to its parsimonious property.
"
1078,Multi-modal image retrieval with random walk on multi-layer graphs,"  The analysis of large collections of image data is still a challenging
problem due to the difficulty of capturing the true concepts in visual data.
The similarity between images could be computed using different and possibly
multimodal features such as color or edge information or even text labels. This
motivates the design of image analysis solutions that are able to effectively
integrate the multi-view information provided by different feature sets. We
therefore propose a new image retrieval solution that is able to sort images
through a random walk on a multi-layer graph, where each layer corresponds to a
different type of information about the image data. We study in depth the
design of the image graph and propose in particular an effective method to
select the edge weights for the multi-layer graph, such that the image ranking
scores are optimised. We then provide extensive experiments in different
real-world photo collections, which confirm the high performance of our new
image retrieval algorithm that generally surpasses state-of-the-art solutions
due to a more meaningful image similarity computation.
"
1079,"DCAR: A Discriminative and Compact Audio Representation to Improve Event
  Detection","  This paper presents a novel two-phase method for audio representation,
Discriminative and Compact Audio Representation (DCAR), and evaluates its
performance at detecting events in consumer-produced videos. In the first phase
of DCAR, each audio track is modeled using a Gaussian mixture model (GMM) that
includes several components to capture the variability within that track. The
second phase takes into account both global structure and local structure. In
this phase, the components are rendered more discriminative and compact by
formulating an optimization problem on Grassmannian manifolds, which we found
represents the structure of audio effectively.
  Our experiments used the YLI-MED dataset (an open TRECVID-style video corpus
based on YFCC100M), which includes ten events. The results show that the
proposed DCAR representation consistently outperforms state-of-the-art audio
representations. DCAR's advantage over i-vector, mv-vector, and GMM
representations is significant for both easier and harder discrimination tasks.
We discuss how these performance differences across easy and hard cases follow
from how each type of model leverages (or doesn't leverage) the intrinsic
structure of the data. Furthermore, DCAR shows a particularly notable accuracy
advantage on events where humans have more difficulty classifying the videos,
i.e., events with lower mean annotator confidence.
"
1080,Distributed Coding of Multiview Sparse Sources with Joint Recovery,"  In support of applications involving multiview sources in distributed object
recognition using lightweight cameras, we propose a new method for the
distributed coding of sparse sources as visual descriptor histograms extracted
from multiview images. The problem is challenging due to the computational and
energy constraints at each camera as well as the limitations regarding
inter-camera communication. Our approach addresses these challenges by
exploiting the sparsity of the visual descriptor histograms as well as their
intra- and inter-camera correlations. Our method couples distributed source
coding of the sparse sources with a new joint recovery algorithm that
incorporates multiple side information signals, where prior knowledge (low
quality) of all the sparse sources is initially sent to exploit their
correlations. Experimental evaluation using the histograms of shift-invariant
feature transform (SIFT) descriptors extracted from multiview images shows that
our method leads to bit-rate saving of up to 43% compared to the
state-of-the-art distributed compressed sensing method with independent
encoding of the sources.
"
1081,Features and Kernels for Audio Event Recognition,"  One of the most important problems in audio event detection research is
absence of benchmark results for comparison with any proposed method. Different
works consider different sets of events and datasets which makes it difficult
to comprehensively analyze any novel method with an existing one. In this paper
we propose to establish results for audio event recognition on two recent
publicly-available datasets. In particular we use Gaussian Mixture model based
feature representation and combine them with linear as well as non-linear
kernel Support Vector Machines.
"
1082,"Hybrid Video Signal Coding Technologies: Past, Current and Future","  The growing needs for high-quality video applications have resulted in a lot
of studies and developments in video signal coding. This chapter presents some
advanced techniques in enhancing the rate-distortion performance of the
block-based hybrid video coding systems. Additionally, as can be seen from the
developments of H.264/AVC and HEVC, most of the current coding tools, such as
prediction, transformation and entropy coding, have less room to improve in the
compression performance. On the other hand, loop filer in the modern video
standards shows the promising results. Thus, we believe that loop filter can be
the candidate in contributing to higher video compression for the
next-generation video coding. Specifically, improvements on ALF and SAO are
also introduced, and the simulation results show that the proposed methods
outperform the existing method, which offer new degrees of freedom to improve
the overall rate-distortion performance. As a result, they can be the candidate
coding tools for the next-generation video codec.
"
1083,A Comprehensive Survey on Cross-modal Retrieval,"  In recent years, cross-modal retrieval has drawn much attention due to the
rapid growth of multimodal data. It takes one type of data as the query to
retrieve relevant data of another type. For example, a user can use a text to
retrieve relevant pictures or videos. Since the query and its retrieved results
can be of different modalities, how to measure the content similarity between
different modalities of data remains a challenge. Various methods have been
proposed to deal with such a problem. In this paper, we first review a number
of representative methods for cross-modal retrieval and classify them into two
main groups: 1) real-valued representation learning, and 2) binary
representation learning. Real-valued representation learning methods aim to
learn real-valued common representations for different modalities of data. To
speed up the cross-modal retrieval, a number of binary representation learning
methods are proposed to map different modalities of data into a common Hamming
space. Then, we introduce several multimodal datasets in the community, and
show the experimental results on two commonly used multimodal datasets. The
comparison reveals the characteristic of different kinds of cross-modal
retrieval methods, which is expected to benefit both practical applications and
future research. Finally, we discuss open problems and future research
directions.
"
1084,"Novel Word Embedding and Translation-based Language Modeling for
  Extractive Speech Summarization","  Word embedding methods revolve around learning continuous distributed vector
representations of words with neural networks, which can capture semantic
and/or syntactic cues, and in turn be used to induce similarity measures among
words, sentences and documents in context. Celebrated methods can be
categorized as prediction-based and count-based methods according to the
training objectives and model architectures. Their pros and cons have been
extensively analyzed and evaluated in recent studies, but there is relatively
less work continuing the line of research to develop an enhanced learning
method that brings together the advantages of the two model families. In
addition, the interpretation of the learned word representations still remains
somewhat opaque. Motivated by the observations and considering the pressing
need, this paper presents a novel method for learning the word representations,
which not only inherits the advantages of classic word embedding methods but
also offers a clearer and more rigorous interpretation of the learned word
representations. Built upon the proposed word embedding method, we further
formulate a translation-based language modeling framework for the extractive
speech summarization task. A series of empirical evaluations demonstrate the
effectiveness of the proposed word representation learning and language
modeling techniques in extractive speech summarization.
"
1085,Inpainting of long audio segments with similarity graphs,"  We present a novel method for the compensation of long duration data loss in
audio signals, in particular music. The concealment of such signal defects is
based on a graph that encodes signal structure in terms of time-persistent
spectral similarity. A suitable candidate segment for the substitution of the
lost content is proposed by an intuitive optimization scheme and smoothly
inserted into the gap, i.e. the lost or distorted signal region. Extensive
listening tests show that the proposed algorithm provides highly promising
results when applied to a variety of real-world music signals.
"
1086,"Restoring highly corrupted images by impulse noise using radial basis
  functions interpolation","  Preserving details in restoring images highly corrupted by impulse noise
remains a challenging problem. We proposed an algorithm based on radial basis
functions (RBF) interpolation which estimates the intensities of corrupted
pixels by their neighbors. In this algorithm, first intensity values of noisy
pixels in the corrupted image are estimated using RBFs. Next, the image is
smoothed. The proposed algorithm can effectively remove the highly dense
impulse noise. Experimental results show the superiority of the proposed
algorithm in comparison to the recent similar methods both in noise suppression
and detail preservation. Extensive simulations show better results in measure
of peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM),
especially when the image is corrupted by very highly dense impulse noise.
"
1087,"Low-complexity feedback-channel-free distributed video coding using
  Local Rank Transform","  In this paper, we propose a new feedback-channel-free Distributed Video
Coding (DVC) algorithm using Local Rank Transform (LRT). The encoder computes
LRT by considering selected neighborhood pixels of Wyner-Ziv frame. The ranks
from the modified LRT are merged, and their positions are entropy coded and
sent to the decoder. In addition, means of each block of Wyner-Ziv frame are
also transmitted to assist motion estimation. Using these measurements, the
decoder generates side information (SI) by implementing motion estimation and
compensation in LRT domain. An iterative algorithm is executed on SI using LRT
to reconstruct the Wyner-Ziv frame. Experimental results show that the coding
efficiency of our codec is close to the efficiency of pixel domain distributed
video coders based on Low-Density Parity Check and Accumulate (LDPCA) or turbo
codes, with less encoder complexity.
"
1088,Natural Steganography: cover-source switching for better steganography,"  This paper proposes a new steganographic scheme relying on the principle of
cover-source switching, the key idea being that the embedding should switch
from one cover-source to another. The proposed implementation, called Natural
Steganography, considers the sensor noise naturally present in the raw images
and uses the principle that, by the addition of a specific noise the
steganographic embedding tries to mimic a change of ISO sensitivity. The
embedding methodology consists in 1) perturbing the image in the raw domain, 2)
modeling the perturbation in the processed domain, 3) embedding the payload in
the processed domain. We show that this methodology is easily tractable
whenever the processes are known and enables to embed large and undetectable
payloads. We also show that already used heuristics such as synchronization of
embedding changes or detectability after rescaling can be respectively
explained by operations such as color demosaicing and down-scaling kernels.
"
1089,A New Approach to SMS Steganography using Mathematical Equations,"  In the era of Information Technology, cyber-crime has always been a worrying
issue for online users. Phishing, social engineering, and third party attacks
have made people reluctant to share their personal information, even with
trusted entities. Messages that are sent via Short Message Service (SMS) are
easily copied and hacked by using special software. To enforce the security of
sending messages through mobile phones, one solution is SMS steganography. SMS
Steganography is a technique that hides a secret message in the SMS. We propose
a new approach for SMS steganography that uses a mathematical equation as the
stego media in order to transmit the data. With this approach, we can hide up
to 35 characters (25%) of a secret message on a single SMS with maximum of 140
characters.
"
1090,"Exploiting Temporal Information for DCNN-based Fine-Grained Object
  Classification","  Fine-grained classification is a relatively new field that has concentrated
on using information from a single image, while ignoring the enormous potential
of using video data to improve classification. In this work we present the
novel task of video-based fine-grained object classification, propose a
corresponding new video dataset, and perform a systematic study of several
recent deep convolutional neural network (DCNN) based approaches, which we
specifically adapt to the task. We evaluate three-dimensional DCNNs, two-stream
DCNNs, and bilinear DCNNs. Two forms of the two-stream approach are used, where
spatial and temporal data from two independent DCNNs are fused either via early
fusion (combination of the fully-connected layers) and late fusion
(concatenation of the softmax outputs of the DCNNs). For bilinear DCNNs,
information from the convolutional layers of the spatial and temporal DCNNs is
combined via local co-occurrences. We then fuse the bilinear DCNN and early
fusion of the two-stream approach to combine the spatial and temporal
information at the local and global level (Spatio-Temporal Co-occurrence).
Using the new and challenging video dataset of birds, classification
performance is improved from 23.1% (using single images) to 41.1% when using
the Spatio-Temporal Co-occurrence system. Incorporating automatically detected
bounding box location further improves the classification accuracy to 53.6%.
"
1091,"Skipping Selected Steps of DWT Computation in Lossless JPEG 2000 for
  Improved Bitrates","  In order to improve bitrates of lossless JPEG 2000, we propose to modify the
discrete wavelet transform (DWT) by skipping selected steps of its computation.
We employ a heuristic to construct the skipped steps DWT (SS-DWT) in an
image-adaptive way and define fixed SS-DWT variants. For a large and diverse
set of images, we find that SS-DWT significantly improves bitrates of
non-photographic images. From a practical standpoint, the most interesting
results are obtained by applying entropy estimation of coding effects for
selecting among the fixed SS-DWT variants. This way we get the compression
scheme that, as opposed to the general SS-DWT case, is compliant with the JPEG
2000 part 2 standard. It provides average bitrate improvement of roughly 5% for
the entire test-set, whereas the overall compression time becomes only 3%
greater than that of the unmodified JPEG 2000. Bitrates of photographic and
non-photographic images are improved by roughly 0.5% and 14%, respectively. At
a significantly increased cost of exploiting a heuristic, selecting the steps
to be skipped based on the actual bitrate instead of an estimated one, and by
applying reversible denoising and lifting steps to SS-DWT, we have attained
greater bitrate improvements of up to about 17.5% for non-photographic images.
"
1092,PicHunt: Social Media Image Retrieval for Improved Law Enforcement,"  First responders are increasingly using social media to identify and reduce
crime for well-being and safety of the society. Images shared on social media
hurting religious, political, communal and other sentiments of people, often
instigate violence and create law & order situations in society. This results
in the need for first responders to inspect the spread of such images and users
propagating them on social media. In this paper, we present a comparison
between different hand-crafted features and a Convolutional Neural Network
(CNN) model to retrieve similar images, which outperforms state-of-art
hand-crafted features. We propose an Open-Source-Intelligent (OSINT) real-time
image search system, robust to retrieve modified images that allows first
responders to analyze the current spread of images, sentiments floating and
details of users propagating such content. The system also aids officials to
save time of manually analyzing the content by reducing the search space on an
average by 67%.
"
1093,"Media Query Processing For The Internet-of-Things: Coupling Of Device
  Energy Consumption And Cloud Infrastructure Billing","  Audio/visual recognition and retrieval applications have recently garnered
significant attention within Internet-of-Things (IoT) oriented services, given
that video cameras and audio processing chipsets are now ubiquitous even in
low-end embedded systems. In the most typical scenario for such services, each
device extracts audio/visual features and compacts them into feature
descriptors, which comprise media queries. These queries are uploaded to a
remote cloud computing service that performs content matching for
classification or retrieval applications. Two of the most crucial aspects for
such services are: (i) controlling the device energy consumption when using the
service; (ii) reducing the billing cost incurred from the cloud infrastructure
provider. In this paper we derive analytic conditions for the optimal coupling
between the device energy consumption and the incurred cloud infrastructure
billing. Our framework encapsulates: the energy consumption to produce and
transmit audio/visual queries, the billing rates of the cloud infrastructure,
the number of devices concurrently connected to the same cloud server, {the
query volume constraint of each cluster of devices,} and the statistics of the
query data production volume per device. Our analytic results are validated via
a deployment with: (i) the device side comprising compact image descriptors
(queries) computed on Beaglebone Linux embedded platforms and transmitted to
Amazon Web Services (AWS) Simple Storage Service; (ii) the cloud side carrying
out image similarity detection via AWS Elastic Compute Cloud (EC2) instances,
with the AWS Auto Scaling being used to control the number of instances
according to the demand.
"
1094,"Daala: Building A Next-Generation Video Codec From Unconventional
  Technology","  Daala is a new royalty-free video codec that attempts to compete with
state-of-the-art royalty-bearing codecs. To do so, it must achieve good
compression while avoiding all of their patented techniques. We use technology
that is as different as possible from traditional approaches to achieve this.
This paper describes the technology behind Daala and discusses where it fits in
the newly created AV1 codec from the Alliance for Open Media. We show that
Daala is approaching the performance level of more mature, state-of-the art
video codecs and can contribute to improving AV1.
"
1095,Detecting Sarcasm in Multimodal Social Platforms,"  Sarcasm is a peculiar form of sentiment expression, where the surface
sentiment differs from the implied sentiment. The detection of sarcasm in
social media platforms has been applied in the past mainly to textual
utterances where lexical indicators (such as interjections and intensifiers),
linguistic markers, and contextual information (such as user profiles, or past
conversations) were used to detect the sarcastic tone. However, modern social
media platforms allow to create multimodal messages where audiovisual content
is integrated with the text, making the analysis of a mode in isolation
partial. In our work, we first study the relationship between the textual and
visual aspects in multimodal posts from three major social media platforms,
i.e., Instagram, Tumblr and Twitter, and we run a crowdsourcing task to
quantify the extent to which images are perceived as necessary by human
annotators. Moreover, we propose two different computational frameworks to
detect sarcasm that integrate the textual and visual modalities. The first
approach exploits visual semantics trained on an external dataset, and
concatenates the semantics features with state-of-the-art textual features. The
second method adapts a visual neural network initialized with parameters
trained on ImageNet to multimodal sarcastic posts. Results show the positive
effect of combining modalities for the detection of sarcasm across platforms
and methods.
"
1096,Semi-Fragile Image Authentication based on CFD and 3-Bit Quantization,"  There is a great adventure of watermarking usage in the context of
conventional authentication since it does not require additional storage space
for supplementary metadata. However JPEG compression, being a conventional
method to compress images, leads to exact authentication breaking. We discuss a
semi-fragile watermarking system for digital images tolerant to JPEG/JPEG2000
compression. Recently we have published a selective authentication method based
on Zernike moments. But unfortunately it has large computational complexity and
not sufficiently good detection of small image modifications. In the current
paper it is proposed (in contrast to Zernike moments approach) the usage of
image finite differences and 3-bit quantization as the main technique. In order
to embed a watermark (WM) into the image, some areas of the Haar wavelet
transform coefficients are used. Simulation results show a good resistance of
this method to JPEG compression with $\mbox{\rm CR}\leq 30\%$ (Compression
Ratio), high probability of small image modification recognition, image quality
assessments $\mbox{\rm PSNR}\geq 40$ (Peak signal-to-noise ratio) dB and
$\mbox{\rm SSIM}\geq 0.98$ (Structural Similarity Index Measure) after
embedding and lower computation complexity of WM embedding and extraction. All
these properties qualify this approach as effective.
"
1097,StegIbiza: New Method for Information Hiding in Club Music,"  In this paper a new method for information hiding in club music is
introduced. The method called StegIbiza is based on using the music tempo as a
carrier. The tempo is modulated by hidden messages with a 3-value coding
scheme, which is an adoption of Morse code for StegIbiza. The evaluation of the
system was performed for several music samples (with and without StegIbiza
enabled) on a selected group of testers who had a music background. Finally,
for the worst case scenario, none of them could identify any differences in the
audio with a 1% margin of changed tempo.
"
1098,"Mining Fashion Outfit Composition Using An End-to-End Deep Learning
  Approach on Set Data","  Composing fashion outfits involves deep understanding of fashion standards
while incorporating creativity for choosing multiple fashion items (e.g.,
Jewelry, Bag, Pants, Dress). In fashion websites, popular or high-quality
fashion outfits are usually designed by fashion experts and followed by large
audiences. In this paper, we propose a machine learning system to compose
fashion outfits automatically. The core of the proposed automatic composition
system is to score fashion outfit candidates based on the appearances and
meta-data. We propose to leverage outfit popularity on fashion oriented
websites to supervise the scoring component. The scoring component is a
multi-modal multi-instance deep learning system that evaluates instance
aesthetics and set compatibility simultaneously. In order to train and evaluate
the proposed composition system, we have collected a large scale fashion outfit
dataset with 195K outfits and 368K fashion items from Polyvore. Although the
fashion outfit scoring and composition is rather challenging, we have achieved
an AUC of 85% for the scoring component, and an accuracy of 77% for a
constrained composition task.
"
1099,Multi-View Product Image Search Using Deep ConvNets Representations,"  Multi-view product image queries can improve retrieval performance over
single view queries significantly. In this paper, we investigated the
performance of deep convolutional neural networks (ConvNets) on multi-view
product image search. First, we trained a VGG-like network to learn deep
ConvNets representations of product images. Then, we computed the deep ConvNets
representations of database and query images and performed single view queries,
and multi-view queries using several early and late fusion approaches.
  We performed extensive experiments on the publicly available Multi-View
Object Image Dataset (MVOD 5K) with both clean background queries from the
Internet and cluttered background queries from a mobile phone. We compared the
performance of ConvNets to the classical bag-of-visual-words (BoWs). We
concluded that (1) multi-view queries with deep ConvNets representations
perform significantly better than single view queries, (2) ConvNets perform
much better than BoWs and have room for further improvement, (3) pre-training
of ConvNets on a different image dataset with background clutter is needed to
obtain good performance on cluttered product image queries obtained with a
mobile phone.
"
1100,"Detecting Dominant Vanishing Points in Natural Scenes with Application
  to Composition-Sensitive Image Retrieval","  Linear perspective is widely used in landscape photography to create the
impression of depth on a 2D photo. Automated understanding of linear
perspective in landscape photography has several real-world applications,
including aesthetics assessment, image retrieval, and on-site feedback for
photo composition, yet adequate automated understanding has been elusive. We
address this problem by detecting the dominant vanishing point and the
associated line structures in a photo. However, natural landscape scenes pose
great technical challenges because often the inadequate number of strong edges
converging to the dominant vanishing point is inadequate. To overcome this
difficulty, we propose a novel vanishing point detection method that exploits
global structures in the scene via contour detection. We show that our method
significantly outperforms state-of-the-art methods on a public ground truth
landscape image dataset that we have created. Based on the detection results,
we further demonstrate how our approach to linear perspective understanding
provides on-site guidance to amateur photographers on their work through a
novel viewpoint-specific image retrieval system.
"
1101,Towards Music Captioning: Generating Music Playlist Descriptions,"  Descriptions are often provided along with recommendations to help users'
discovery. Recommending automatically generated music playlists (e.g.
personalised playlists) introduces the problem of generating descriptions. In
this paper, we propose a method for generating music playlist descriptions,
which is called as music captioning. In the proposed method, audio content
analysis and natural language processing are adopted to utilise the information
of each track.
"
1102,"Globally Variance-Constrained Sparse Representation and Its Application
  in Image Set Coding","  Sparse representation leads to an efficient way to approximately recover a
signal by the linear composition of a few bases from a learnt dictionary, based
on which various successful applications have been achieved. However, in the
scenario of data compression, its efficiency and popularity are hindered. It is
because of the fact that encoding sparsely distributed coefficients may consume
more bits for representing the index of nonzero coefficients. Therefore,
introducing an accurate rate-constraint in sparse coding and dictionary
learning becomes meaningful, which has not been fully exploited in the context
of sparse representation. According to the Shannon entropy inequality, the
variance of a Gaussian distributed data bounds its entropy, indicating the
actual bitrate can be well estimated by its variance. Hence, a Globally
Variance-Constrained Sparse Representation (GVCSR) model is proposed in this
work, where a variance-constrained rate term is introduced to the optimization
process. Specifically, we employ the Alternating Direction Method of
Multipliers (ADMM) to solve the non-convex optimization problem for sparse
coding and dictionary learning, both of them have shown the state-of-the-art
rate-distortion performance for image representation. Furthermore, we
investigate the potential of applying the GVCSR algorithm in the practical
image set compression, where the optimized dictionary is trained to efficiently
represent the images captured in similar scenarios by implicitly utilizing
inter-image correlations. Experimental results have demonstrated superior
rate-distortion performance against the state-of-the-art methods.
"
1103,An image compression and encryption scheme based on deep learning,"  Stacked Auto-Encoder (SAE) is a kind of deep learning algorithm for
unsupervised learning. Which has multi layers that project the vector
representation of input data into a lower vector space. These projection
vectors are dense representations of the input data. As a result, SAE can be
used for image compression. Using chaotic logistic map, the compression ones
can further be encrypted. In this study, an application of image compression
and encryption is suggested using SAE and chaotic logistic map. Experiments
show that this application is feasible and effective. It can be used for image
transmission and image protection on internet simultaneously.
"
1104,"MT3S: Mobile Turkish Scene Text-to-Speech System for the Visually
  Impaired","  Reading text is one of the essential needs of the visually impaired people.
We developed a mobile system that can read Turkish scene and book text, using a
fast gradient-based multi-scale text detection algorithm for real-time
operation and Tesseract OCR engine for character recognition. We evaluated the
OCR accuracy and running time of our system on a new, publicly available mobile
Turkish scene text dataset we constructed and also compared with
state-of-the-art systems. Our system proved to be much faster, able to run on a
mobile device, with OCR accuracy comparable to the state-of-the-art.
"
1105,Steganalyzer performances in operational contexts,"  Steganography and steganalysis are two important branches of the information
hiding field of research. Steganography methods consist in hiding information
in such a way that the secret message is undetectable for the uninitiated.
Steganalyzis encompasses all the techniques that attempt to detect the presence
of such hidden information. This latter is usually designed by making
classifiers able to separate innocent images from steganographied ones
according to their differences on well-selected features. We wonder, in this
article whether it is possible to construct a kind of universal steganalyzer
without any knowledge regarding the steganographier side. The effects on the
classification score of a modification of either parameters or methods between
the learning and testing stages are then evaluated, while the possibility to
improve the separation score by merging many methods during learning stage is
deeper investigated.
"
1106,"A Convolutional Neural Network Approach for Post-Processing in HEVC
  Intra Coding","  Lossy image and video compression algorithms yield visually annoying
artifacts including blocking, blurring, and ringing, especially at low
bit-rates. To reduce these artifacts, post-processing techniques have been
extensively studied. Recently, inspired by the great success of convolutional
neural network (CNN) in computer vision, some researches were performed on
adopting CNN in post-processing, mostly for JPEG compressed images. In this
paper, we present a CNN-based post-processing algorithm for High Efficiency
Video Coding (HEVC), the state-of-the-art video coding standard. We redesign a
Variable-filter-size Residue-learning CNN (VRCNN) to improve the performance
and to accelerate network training. Experimental results show that using our
VRCNN as post-processing leads to on average 4.6% bit-rate reduction compared
to HEVC baseline. The VRCNN outperforms previously studied networks in
achieving higher bit-rate reduction, lower memory cost, and multiplied
computational speedup.
"
1107,Automatic Synchronization of Multi-User Photo Galleries,"  In this paper we address the issue of photo galleries synchronization, where
pictures related to the same event are collected by different users. Existing
solutions to address the problem are usually based on unrealistic assumptions,
like time consistency across photo galleries, and often heavily rely on
heuristics, limiting therefore the applicability to real-world scenarios. We
propose a solution that achieves better generalization performance for the
synchronization task compared to the available literature. The method is
characterized by three stages: at first, deep convolutional neural network
features are used to assess the visual similarity among the photos; then, pairs
of similar photos are detected across different galleries and used to construct
a graph; eventually, a probabilistic graphical model is used to estimate the
temporal offset of each pair of galleries, by traversing the minimum spanning
tree extracted from this graph. The experimental evaluation is conducted on
four publicly available datasets covering different types of events,
demonstrating the strength of our proposed method. A thorough discussion of the
obtained results is provided for a critical assessment of the quality in
synchronization.
"
1108,Title Generation for User Generated Videos,"  A great video title describes the most salient event compactly and captures
the viewer's attention. In contrast, video captioning tends to generate
sentences that describe the video as a whole. Although generating a video title
automatically is a very useful task, it is much less addressed than video
captioning. We address video title generation for the first time by proposing
two methods that extend state-of-the-art video captioners to this new task.
First, we make video captioners highlight sensitive by priming them with a
highlight detector. Our framework allows for jointly training a model for title
generation and video highlight localization. Second, we induce high sentence
diversity in video captioners, so that the generated titles are also diverse
and catchy. This means that a large number of sentences might be required to
learn the sentence structure of titles. Hence, we propose a novel sentence
augmentation method to train a captioner with additional sentence-only examples
that come without corresponding videos. We collected a large-scale Video Titles
in the Wild (VTW) dataset of 18100 automatically crawled user-generated videos
and titles. On VTW, our methods consistently improve title prediction accuracy,
and achieve the best performance in both automatic and human evaluation.
Finally, our sentence augmentation method also outperforms the baselines on the
M-VAD dataset.
"
1109,YouSkyde: Information Hiding for Skype Video Traffic,"  In this paper a new information hiding method for Skype videoconference calls
- YouSkyde - is introduced. A Skype traffic analysis revealed that introducing
intentional losses into the Skype video traffic stream to provide the means for
clandestine communication is the most favourable solution. A YouSkyde
proof-of-concept implementation was carried out and its experimental evaluation
is presented. The results obtained prove that the proposed method is feasible
and offer a steganographic bandwidth as high as 0.93 kbps, while introducing
negligible distortions into transmission quality and providing high
undetectability.
"
1110,"Applying Topological Persistence in Convolutional Neural Network for
  Music Audio Signals","  Recent years have witnessed an increased interest in the application of
persistent homology, a topological tool for data analysis, to machine learning
problems. Persistent homology is known for its ability to numerically
characterize the shapes of spaces induced by features or functions. On the
other hand, deep neural networks have been shown effective in various tasks. To
our best knowledge, however, existing neural network models seldom exploit
shape information. In this paper, we investigate a way to use persistent
homology in the framework of deep neural networks. Specifically, we propose to
embed the so-called ""persistence landscape,"" a rather new topological summary
for data, into a convolutional neural network (CNN) for dealing with audio
signals. Our evaluation on automatic music tagging, a multi-label
classification task, shows that the resulting persistent convolutional neural
network (PCNN) model can perform significantly better than state-of-the-art
models in prediction accuracy. We also discuss the intuition behind the design
of the proposed model, and offer insights into the features that it learns.
"
1111,Human Action Recognition without Human,"  The objective of this paper is to evaluate ""human action recognition without
human"". Motion representation is frequently discussed in human action
recognition. We have examined several sophisticated options, such as dense
trajectories (DT) and the two-stream convolutional neural network (CNN).
However, some features from the background could be too strong, as shown in
some recent studies on human action recognition. Therefore, we considered
whether a background sequence alone can classify human actions in current
large-scale action datasets (e.g., UCF101).
  In this paper, we propose a novel concept for human action analysis that is
named ""human action recognition without human"". An experiment clearly shows the
effect of a background sequence for understanding an action label.
"
1112,"On the Efficiency and Fairness of Multiplayer HTTP-based Adaptive Video
  Streaming","  User-perceived quality-of-experience (QoE) is critical in internet video
delivery systems. Extensive prior work has studied the design of client-side
bitrate adaptation algorithms to maximize single-player QoE. However,
multiplayer QoE fairness becomes critical as the growth of video traffic makes
it more likely that multiple players share a bottleneck in the network. Despite
several recent proposals, there is still a series of open questions. In this
paper, we bring the problem space to light from a control theory perspective by
formalizing the multiplayer QoE fairness problem and addressing two key
questions in the broader problem space. First, we derive the sufficient
conditions of convergence to steady state QoE fairness under TCP-based
bandwidth sharing scheme. Based on the insight from this analysis that
in-network active bandwidth allocation is needed, we propose a non-linear
MPC-based, router-assisted bandwidth allocation algorithm that regards each
player as closed-loop systems. We use trace-driven simulation to show the
improvement over existing approaches. We identify several research directions
enabled by the control theoretic modeling and envision that control theory can
play an important role on guiding real system design in adaptive video
streaming.
"
1113,"Towards Hybrid Cloud-assisted Crowdsourced Live Streaming: Measurement
  and Analysis","  Crowdsourced Live Streaming (CLS), most notably Twitch.tv, has seen explosive
growth in its popularity in the past few years. In such systems, any user can
lively broadcast video content of interest to others, e.g., from a game player
to many online viewers. To fulfill the demands from both massive and
heterogeneous broadcasters and viewers, expensive server clusters have been
deployed to provide video ingesting and transcoding services. Despite the
existence of highly popular channels, a significant portion of the channels is
indeed unpopular. Yet as our measurement shows, these broadcasters are
consuming considerable system resources; in particular, 25% (resp. 30%) of
bandwidth (resp. computation) resources are used by the broadcasters who do not
have any viewers at all. In this paper, we closely examine the challenge of
handling unpopular live-broadcasting channels in CLS systems and present a
comprehensive solution for service partitioning on hybrid cloud. The
trace-driven evaluation shows that our hybrid cloud-assisted design can smartly
assign ingesting and transcoding tasks to the elastic cloud virtual machines,
providing flexible system deployment cost-effectively.
"
1114,"To Click or Not To Click: Automatic Selection of Beautiful Thumbnails
  from Videos","  Thumbnails play such an important role in online videos. As the most
representative snapshot, they capture the essence of a video and provide the
first impression to the viewers; ultimately, a great thumbnail makes a video
more attractive to click and watch. We present an automatic thumbnail selection
system that exploits two important characteristics commonly associated with
meaningful and attractive thumbnails: high relevance to video content and
superior visual aesthetic quality. Our system selects attractive thumbnails by
analyzing various visual quality and aesthetic metrics of video frames, and
performs a clustering analysis to determine the relevance to video content,
thus making the resulting thumbnails more representative of the video. On the
task of predicting thumbnails chosen by professional video editors, we
demonstrate the effectiveness of our system against six baseline methods, using
a real-world dataset of 1,118 videos collected from Yahoo Screen. In addition,
we study what makes a frame a good thumbnail by analyzing the statistical
relationship between thumbnail frames and non-thumbnail frames in terms of
various image quality features. Our study suggests that the selection of a good
thumbnail is highly correlated with objective visual quality metrics, such as
the frame texture and sharpness, implying the possibility of building an
automatic thumbnail selection system based on visual aesthetics.
"
1115,"A Tube-and-Droplet-based Approach for Representing and Analyzing Motion
  Trajectories","  Trajectory analysis is essential in many applications. In this paper, we
address the problem of representing motion trajectories in a highly informative
way, and consequently utilize it for analyzing trajectories. Our approach first
leverages the complete information from given trajectories to construct a
thermal transfer field which provides a context-rich way to describe the global
motion pattern in a scene. Then, a 3D tube is derived which depicts an input
trajectory by integrating its surrounding motion patterns contained in the
thermal transfer field. The 3D tube effectively: 1) maintains the movement
information of a trajectory, 2) embeds the complete contextual motion pattern
around a trajectory, 3) visualizes information about a trajectory in a clear
and unified way. We further introduce a droplet-based process. It derives a
droplet vector from a 3D tube, so as to characterize the high-dimensional 3D
tube information in a simple but effective way. Finally, we apply our
tube-and-droplet representation to trajectory analysis applications including
trajectory clustering, trajectory classification & abnormality detection, and
3D action recognition. Experimental comparisons with state-of-the-art
algorithms demonstrate the effectiveness of our approach.
"
1116,"Active Canny: Edge Detection and Recovery with Open Active Contour
  Models","  We introduce an edge detection and recovery framework based on open active
contour models (snakelets). This is motivated by the noisy or broken edges
output by standard edge detection algorithms, like Canny. The idea is to
utilize the local continuity and smoothness cues provided by strong edges and
grow them to recover the missing edges. This way, the strong edges are used to
recover weak or missing edges by considering the local edge structures, instead
of blindly linking them if gradient magnitudes are above some threshold. We
initialize short snakelets on the gradient magnitudes or binary edges
automatically and then deform and grow them under the influence of gradient
vector flow. The output snakelets are able to recover most of the breaks or
weak edges, and they provide a smooth edge representation of the image; they
can also be used for higher level analysis, like contour segmentation.
"
1117,"Optimal Representations for Adaptive Streaming in Interactive Multi-View
  Video Systems","  Interactive multi-view video streaming (IMVS) services permit to remotely
immerse within a 3D scene. This is possible by transmitting a set of reference
camera views (anchor views), which are used by the clients to freely navigate
in the scene and possibly synthesize additional viewpoints of interest. From a
networking perspective, the big challenge in IMVS systems is to deliver to each
client the best set of anchor views that maximizes the navigation quality,
minimizes the view-switching delay and yet satisfies the network constraints.
Integrating adaptive streaming solutions in free-viewpoint systems offers a
promising solution to deploy IMVS in large and heterogeneous scenarios, as long
as the multi-view video representations on the server are properly selected. We
therefore propose to optimize the multi-view data at the server by minimizing
the overall resource requirements, yet offering a good navigation quality to
the different users. We propose a video representation set optimization for
multiview adaptive streaming systems and we show that it is NP-hard. We
therefore introduce the concept of multi-view navigation segment that permits
to cast the video representation set selection as an integer linear programming
problem with a bounded computational complexity. We then show that the proposed
solution reduces the computational complexity while preserving optimality in
most of the 3D scenes. We then provide simulation results for different classes
of users and show the gain offered by an optimal multi-view video
representation selection compared to recommended representation sets (e.g.,
Netflix and Apple ones) or to a baseline representation selection algorithm
where the encoding parameters are decided a priori for all the views.
"
1118,Convolutional Recurrent Neural Networks for Music Classification,"  We introduce a convolutional recurrent neural network (CRNN) for music
tagging. CRNNs take advantage of convolutional neural networks (CNNs) for local
feature extraction and recurrent neural networks for temporal summarisation of
the extracted features. We compare CRNN with three CNN structures that have
been used for music tagging while controlling the number of parameters with
respect to their performance and training time per sample. Overall, we found
that CRNNs show a strong performance with respect to the number of parameter
and training time, indicating the effectiveness of its hybrid structure in
music feature extraction and feature summarisation.
"
1119,Generalized residual vector quantization for large scale data,"  Vector quantization is an essential tool for tasks involving large scale
data, for example, large scale similarity search, which is crucial for
content-based information retrieval and analysis. In this paper, we propose a
novel vector quantization framework that iteratively minimizes quantization
error. First, we provide a detailed review on a relevant vector quantization
method named \textit{residual vector quantization} (RVQ). Next, we propose
\textit{generalized residual vector quantization} (GRVQ) to further improve
over RVQ. Many vector quantization methods can be viewed as the special cases
of our proposed framework. We evaluate GRVQ on several large scale benchmark
datasets for large scale search, classification and object retrieval. We
compared GRVQ with existing methods in detail. Extensive experiments
demonstrate our GRVQ framework substantially outperforms existing methods in
term of quantization accuracy and computation efficiency.
"
1120,Deep CTR Prediction in Display Advertising,"  Click through rate (CTR) prediction of image ads is the core task of online
display advertising systems, and logistic regression (LR) has been frequently
applied as the prediction model. However, LR model lacks the ability of
extracting complex and intrinsic nonlinear features from handcrafted
high-dimensional image features, which limits its effectiveness. To solve this
issue, in this paper, we introduce a novel deep neural network (DNN) based
model that directly predicts the CTR of an image ad based on raw image pixels
and other basic features in one step. The DNN model employs convolution layers
to automatically extract representative visual features from images, and
nonlinear CTR features are then learned from visual features and other
contextual features by using fully-connected layers. Empirical evaluations on a
real world dataset with over 50 million records demonstrate the effectiveness
and efficiency of this method.
"
1121,An Approach for Self-Training Audio Event Detectors Using Web Data,"  Audio Event Detection (AED) aims to recognize sounds within audio and video
recordings. AED employs machine learning algorithms commonly trained and tested
on annotated datasets. However, available datasets are limited in number of
samples and hence it is difficult to model acoustic diversity. Therefore, we
propose combining labeled audio from a dataset and unlabeled audio from the web
to improve the sound models. The audio event detectors are trained on the
labeled audio and ran on the unlabeled audio downloaded from YouTube. Whenever
the detectors recognized any of the known sounds with high confidence, the
unlabeled audio was use to re-train the detectors. The performance of the
re-trained detectors is compared to the one from the original detectors using
the annotated test set. Results showed an improvement of the AED, and uncovered
challenges of using web audio from videos.
"
1122,FPGA implementation of the procedures for video quality assessment,"  Video resolutions used in variety of media are constantly rising. While
manufacturers struggle to perfect their screens it is also important to ensure
high quality of displayed image. Overall quality can be measured using Mean
Opinion Score (MOS). Video quality can be affected by miscellaneous artifacts,
appearing at every stage of video creation and transmission. In this paper, we
present a solution to calculate four distinct video quality metrics that can be
applied to a real time video quality assessment system. Our assessment module
is capable of processing 8K resolution in real time set at the level of 30
frames per second. Throughput of 2.19 GB/s surpasses performance of pure
software solutions. To concentrate on architectural optimization, the module
was created using high level language.
"
1123,Color-Based Coding Unit Level Adaptive Quantization for HEVC,"  HEVC HM 16 includes a Coding Unit (CU) level perceptual quantization
technique named AdaptiveQP. AdaptiveQP adjusts the Quantization Parameter (QP)
at the CU level based on the spatial activity of samples in the four
constituent NxN sub-blocks of the luma Coding Block (CB), which is contained
within a 2Nx2N CU. In this paper, we propose C-BAQ, which, in contrast to
AdaptiveQP, adjusts the CU level QP according to the spatial activity of
samples in the four constituent NxN sub-blocks of both the luma and chroma CBs.
By computing the sum of luma, chroma Cb and chroma Cr spatial activity in a CU,
a richer reflection of spatial activity in the CU is attained. Therefore, a
more appropriate CU level QP can be selected, thus leading to important
improvements in terms of coding efficiency. We evaluate the proposed technique
in HEVC HM 16.7 using 4:4:4, 4:2:2 and 4:2:0 YCbCr sequences. Both subjective
and objective evaluations are undertaken during which we compare C-BAQ with
AdaptiveQP. The objective evaluation reveals that C-BAQ attains a maximum
BD-Rate reduction of 15.9% (Y), 13.1% (Cr) and 16.1% (Cb) in addition to a
maximum decoding time reduction of 11.0%.
"
1124,"A Consumer BCI for Automated Music Evaluation Within a Popular On-Demand
  Music Streaming Service - Taking Listener's Brainwaves to Extremes","  We investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable EEG-devices for translating listener's
subjective experience of music into scores that can be used for the automated
annotation of music in popular on-demand streaming services. Based on the
established -neuroscientifically sound- concepts of brainwave frequency bands,
activation asymmetry index and cross-frequency-coupling (CFC), we introduce a
Brain Computer Interface (BCI) system that automatically assigns a rating score
to the listened song. Our research operated in two distinct stages: i) a
generic feature engineering stage, in which features from signal-analytics were
ranked and selected based on their ability to associate music induced
perturbations in brainwaves with listener's appraisal of music. ii) a
personalization stage, during which the efficiency of ex- treme learning
machines (ELMs) is exploited so as to translate the derived pat- terns into a
listener's score. Encouraging experimental results, from a pragmatic use of the
system, are presented.
"
1125,"Minimizing Compression Artifacts for High Resolutions with Adaptive
  Quantization Matrices for HEVC","  Visual Display Units (VDUs), capable of displaying video data at High
Definition (HD) and Ultra HD (UHD) resolutions, are frequently employed in a
variety of technological domains. Quantization-induced video compression
artifacts, which are usually unnoticeable in low resolution environments, are
typically conspicuous on high resolution VDUs and video data. The default
quantization matrices (QMs) in HEVC do not take into account specific display
resolutions of VDUs or video data to determine the appropriate levels of
quantization required to reduce unwanted compression artifacts. Therefore, we
propose a novel, adaptive quantization matrix technique for the HEVC standard
including Scalable HEVC (SHVC). Our technique, which is based on a refinement
of the current QM technique in HEVC, takes into consideration specific display
resolutions of the target VDUs in order to minimize compression artifacts. We
undertake a thorough evaluation of the proposed technique by utilizing SHVC SHM
9.0 (two-layered bit-stream) and the BD-Rate and SSIM metrics. For the BD-Rate
evaluation, the proposed method achieves maximum BD-Rate reductions of 56.5% in
the enhancement layer. For the SSIM evaluation, our technique achieves a
maximum structural improvement of 0.8660 vs. 0.8538.
"
1126,Multimedia Communication Quality Assessment Testbeds,"  We make an intensive use of multimedia frameworks in our research on modeling
the perceived quality estimation in streaming services and real-time
communications. In our preliminary work, we have used the VLC VOD software to
generate reference audiovisual files with various degree of coding and network
degradations. We have successfully built machine learning based models on the
subjective quality dataset we have generated using these files. However,
imperfections in the dataset introduced by the multimedia framework we have
used prevented us from achieving the full potential of these models.
  In order to develop better models, we have re-created our end-to-end
multimedia pipeline using the GStreamer framework for audio and video
streaming. A GStreamer based pipeline proved to be significantly more robust to
network degradations than the VLC VOD framework and allowed us to stream a
video flow at a loss rate up to 5\% packet very easily. GStreamer has also
enabled us to collect the relevant RTCP statistics that proved to be more
accurate than network-deduced information. This dataset is free to the public.
The accuracy of the statistics eventually helped us to generate better
performing perceived quality estimation models.
  In this paper, we present the implementation of these VLC and GStreamer-based
multimedia communication quality assessment testbeds with the references to
their publicly available code bases.
"
1127,"Land Use Classification using Convolutional Neural Networks Applied to
  Ground-Level Images","  Land use mapping is a fundamental yet challenging task in geographic science.
In contrast to land cover mapping, it is generally not possible using overhead
imagery. The recent, explosive growth of online geo-referenced photo
collections suggests an alternate approach to geographic knowledge discovery.
In this work, we present a general framework that uses ground-level images from
Flickr for land use mapping. Our approach benefits from several novel aspects.
First, we address the nosiness of the online photo collections, such as
imprecise geolocation and uneven spatial distribution, by performing location
and indoor/outdoor filtering, and semi- supervised dataset augmentation. Our
indoor/outdoor classifier achieves state-of-the-art performance on several
bench- mark datasets and approaches human-level accuracy. Second, we utilize
high-level semantic image features extracted using deep learning, specifically
convolutional neural net- works, which allow us to achieve upwards of 76%
accuracy on a challenging eight class land use mapping problem.
"
1128,Spatio-Temporal Sentiment Hotspot Detection Using Geotagged Photos,"  We perform spatio-temporal analysis of public sentiment using geotagged photo
collections. We develop a deep learning-based classifier that predicts the
emotion conveyed by an image. This allows us to associate sentiment with place.
We perform spatial hotspot detection and show that different emotions have
distinct spatial distributions that match expectations. We also perform
temporal analysis using the capture time of the photos. Our spatio-temporal
hotspot detection correctly identifies emerging concentrations of specific
emotions and year-by-year analyses of select locations show there are strong
temporal correlations between the predicted emotions and known events.
"
1129,Deep Learning for Video Classification and Captioning,"  Accelerated by the tremendous increase in Internet bandwidth and storage
space, video data has been generated, published and spread explosively,
becoming an indispensable part of today's big data. In this paper, we focus on
reviewing two lines of research aiming to stimulate the comprehension of videos
with deep learning: video classification and video captioning. While video
classification concentrates on automatically labeling video clips based on
their semantic contents like human actions or complex events, video captioning
attempts to generate a complete and natural sentence, enriching the single
label as in video classification, to capture the most informative dynamics in
videos. In addition, we also provide a review of popular benchmarks and
competitions, which are critical for evaluating the technical progress of this
vibrant field.
"
1130,Deep Quality: A Deep No-reference Quality Assessment System,"  Image quality assessment (IQA) continues to garner great interest in the
research community, particularly given the tremendous rise in consumer video
capture and streaming. Despite significant research effort in IQA in the past
few decades, the area of no-reference image quality assessment remains a great
challenge and is largely unsolved. In this paper, we propose a novel
no-reference image quality assessment system called Deep Quality, which
leverages the power of deep learning to model the complex relationship between
visual content and the perceived quality. Deep Quality consists of a novel
multi-scale deep convolutional neural network, trained to learn to assess image
quality based on training samples consisting of different distortions and
degradations such as blur, Gaussian noise, and compression artifacts.
Preliminary results using the CSIQ benchmark image quality dataset showed that
Deep Quality was able to achieve strong quality prediction performance (89%
patch-level and 98% image-level prediction accuracy), being able to achieve
similar performance as full-reference IQA methods.
"
1131,"Towards the bio-personalization of music recommendation systems: A
  single-sensor EEG biomarker of subjective music preference","  Recent advances in biosensors technology and mobile electroencephalographic
(EEG) interfaces have opened new application fields for cognitive monitoring. A
computable biomarker for the assessment of spontaneous aesthetic brain
responses during music listening is introduced here. It derives from
well-established measures of cross-frequency coupling (CFC) and quantifies the
music-induced alterations in the dynamic relationships between brain rhythms.
During a stage of exploratory analysis, and using the signals from a suitably
designed experiment, we established the biomarker, which acts on brain
activations recorded over the left prefrontal cortex and focuses on the
functional coupling between high-beta and low-gamma oscillations. Based on data
from an additional experimental paradigm, we validated the introduced biomarker
and showed its relevance for expressing the subjective aesthetic appreciation
of a piece of music. Our approach resulted in an affordable tool that can
promote human-machine interaction and, by serving as a personalized music
annotation strategy, can be potentially integrated into modern flexible music
recommendation systems.
  Keywords: Cross-frequency coupling; Human-computer interaction;
Brain-computer interface
"
1132,"Low-complexity Image and Video Coding Based on an Approximate Discrete
  Tchebichef Transform","  The usage of linear transformations has great relevance for data
decorrelation applications, like image and video compression. In that sense,
the discrete Tchebichef transform (DTT) possesses useful coding and
decorrelation properties. The DTT transform kernel does not depend on the input
data and fast algorithms can be developed to real time applications. However,
the DTT fast algorithm presented in literature possess high computational
complexity. In this work, we introduce a new low-complexity approximation for
the DTT. The fast algorithm of the proposed transform is multiplication-free
and requires a reduced number of additions and bit-shifting operations. Image
and video compression simulations in popular standards shows good performance
of the proposed transform. Regarding hardware resource consumption for FPGA
shows 43.1% reduction of configurable logic blocks and ASIC place and route
realization shows 57.7% reduction in the area-time figure when compared with
the 2-D version of the exact DTT.
"
1133,Location-Based and Audience-Aware Storytelling,"  While the daily user of digital, Internet-enabled devices has some explicit
control over what they read and see, the providers fulfilling searches,
offering options, and presenting material are using increasingly sophisticated
real-time algorithms that tune and target content for the particular user. They
redefine the historical relationships between tellers and users, providing a
responsiveness paralleled only by forms of live performance incorporating
elements of improvisation and audience interaction. The general accessibility
of algorithmically driven content delivery techniques suggests significant
untapped potential for new approaches to narrative beyond advertising and
commercially orientated customization.
"
1134,Viewport-Adaptive Navigable 360-Degree Video Delivery,"  The delivery and display of 360-degree videos on Head-Mounted Displays (HMDs)
presents many technical challenges. 360-degree videos are ultra high resolution
spherical videos, which contain an omnidirectional view of the scene. However
only a portion of this scene is displayed on the HMD. Moreover, HMD need to
respond in 10 ms to head movements, which prevents the server to send only the
displayed video part based on client feedback. To reduce the bandwidth waste,
while still providing an immersive experience, a viewport-adaptive 360-degree
video streaming system is proposed. The server prepares multiple video
representations, which differ not only by their bit-rate, but also by the
qualities of different scene regions. The client chooses a representation for
the next segment such that its bit-rate fits the available throughput and a
full quality region matches its viewing. We investigate the impact of various
spherical-to-plane projections and quality arrangements on the video quality
displayed to the user, showing that the cube map layout offers the best quality
for the given bit-rate budget. An evaluation with a dataset of users navigating
360-degree videos demonstrates that segments need to be short enough to enable
frequent view switches.
"
1135,Adaptive 360 VR Video Streaming: Divide and Conquer!,"  While traditional multimedia applications such as games and videos are still
popular, there has been a significant interest in the recent years towards new
3D media such as 3D immersion and Virtual Reality (VR) applications, especially
360 VR videos. 360 VR video is an immersive spherical video where the user can
look around during playback. Unfortunately, 360 VR videos are extremely
bandwidth intensive, and therefore are difficult to stream at acceptable
quality levels. In this paper, we propose an adaptive bandwidth-efficient 360
VR video streaming system using a divide and conquer approach. In our approach,
we propose a dynamic view-aware adaptation technique to tackle the huge
streaming bandwidth demands of 360 VR videos. We spatially divide the videos
into multiple tiles while encoding and packaging, use MPEG-DASH SRD to describe
the spatial relationship of tiles in the 360-degree space, and prioritize the
tiles in the Field of View (FoV). In order to describe such tiled
representations, we extend MPEG-DASH SRD to the 3D space of 360 VR videos. We
spatially partition the underlying 3D mesh, and construct an efficient 3D
geometry mesh called hexaface sphere to optimally represent a tiled 360 VR
video in the 3D space. Our initial evaluation results report up to 72%
bandwidth savings on 360 VR video streaming with minor negative quality impacts
compared to the baseline scenario when no adaptations is applied.
"
1136,Congestion Control for Network-Aware Telehaptic Communication,"  Telehaptic applications involve delay-sensitive multimedia communication
between remote locations with distinct Quality of Service (QoS) requirements
for different media components. These QoS constraints pose a variety of
challenges, especially when the communication occurs over a shared network,
with unknown and time-varying cross-traffic. In this work, we propose a
transport layer congestion control protocol for telehaptic applications
operating over shared networks, termed as dynamic packetization module (DPM).
DPM is a lossless, network-aware protocol which tunes the telehaptic
packetization rate based on the level of congestion in the network. To monitor
the network congestion, we devise a novel network feedback module, which
communicates the end-to-end delays encountered by the telehaptic packets to the
respective transmitters with negligible overhead. Via extensive simulations, we
show that DPM meets the QoS requirements of telehaptic applications over a wide
range of network cross-traffic conditions. We also report qualitative results
of a real-time telepottery experiment with several human subjects, which reveal
that DPM preserves the quality of telehaptic activity even under heavily
congested network scenarios. Finally, we compare the performance of DPM with
several previously proposed telehaptic communication protocols and demonstrate
that DPM outperforms these protocols.
"
1137,MoveSteg: A Method of Network Steganography Detection,"  This article presents a new method for detecting a source point of time based
network steganography - MoveSteg. A steganography carrier could be an example
of multimedia stream made with packets. These packets are then delayed
intentionally to send hidden information using time based steganography
methods. The presented analysis describes a method that allows finding the
source of steganography stream in network that is under our management.
"
1138,"ILGNet: Inception Modules with Connected Local and Global Features for
  Efficient Image Aesthetic Quality Classification using Domain Adaptation","  In this paper, we address a challenging problem of aesthetic image
classification, which is to label an input image as high or low aesthetic
quality. We take both the local and global features of images into
consideration. A novel deep convolutional neural network named ILGNet is
proposed, which combines both the Inception modules and an connected layer of
both Local and Global features. The ILGnet is based on GoogLeNet. Thus, it is
easy to use a pre-trained GoogLeNet for large-scale image classification
problem and fine tune our connected layers on an large scale database of
aesthetic related images: AVA, i.e. \emph{domain adaptation}. The experiments
reveal that our model achieves the state of the arts in AVA database. Both the
training and testing speeds of our model are higher than those of the original
GoogLeNet.
"
1139,Backward-Shifted Coding (BSC) based on Scalable Video Coding for HAS,"  The main task of HTTP Adaptive Streaming is to adapt video quality
dynamically under variable network conditions. This is a key feature for
multimedia delivery especially when quality of service cannot be granted
network-wide and, e.g., throughput may suffer short term fluctuations.
  Hence, robust bitrate adaptation schemes become crucial in order to improve
video quality. The objective, in this context, is to control the filling level
of the playback buffer and maximize the quality of the video, while avoiding
unnecessary video quality variations.
  In this paper we study bitrate adaptation algorithms based on
Backward-Shifted Coding (BSC), a scalable video coding scheme able to greatly
improve video quality. We design bitrate adaptation algorithms that balance
video rate smoothness and high network capacity utilization, leveraging both on
throughput-based and buffer-based adaptation mechanisms.
  Extensive simulations using synthetic and real-world video traffic traces
show that the proposed scheme performs remarkably well even under challenging
network conditions.
"
1140,"mPDF: Framework for Watermarking PDF Files using Image Watermarking
  Algorithms","  The advancement in digital technologies have made it possible to produce
perfect copies of digital content. In this environment, malicious users
reproduce the digital content and share it without compensation to the content
owner. Content owners are concerned about the potential loss of revenue and
reputation from piracy, especially when the content is available over the
Internet. Digital watermarking has emerged as a deterrent measure towards such
malicious activities. Several methods have been proposed for copyright
protection and fingerprinting of digital images. However, these methods are not
applicable to text documents as these documents lack rich texture information
which is abundantly available in digital images. In this paper, a framework
(mPDF) is proposed which facilitates the usage of digital image watermarking
algorithms on text documents. The proposed method divides a text document into
texture and non-texture blocks using an energy-based approach. After
classification, a watermark is embedded inside the texture blocks in a content
adaptive manner. The proposed method is integrated with five known image
watermarking methods and its performance is studied in terms of quality and
robustness. Experiments are conducted on documents in 11 different languages.
Experimental results clearly show that the proposed method facilitates the
usage of image watermarking algorithms on text documents and is robust against
attacks such as print & scan, print screen, and skew. Also, the proposed method
overcomes the drawbacks of existing text watermarking methods such as manual
inspection and language dependency.
"
1141,Perceptually-Driven Video Coding with the Daala Video Codec,"  The Daala project is a royalty-free video codec that attempts to compete with
the best patent-encumbered codecs. Part of our strategy is to replace core
tools of traditional video codecs with alternative approaches, many of them
designed to take perceptual aspects into account, rather than optimizing for
simple metrics like PSNR. This paper documents some of our experiences with
these tools, which ones worked and which did not. We evaluate which tools are
easy to integrate into a more traditional codec design, and show results in the
context of the codec being developed by the Alliance for Open Media.
"
1142,Saliency-Guided Complexity Control for HEVC Decoding,"  The latest High Efficiency Video Coding (HEVC) standard significantly
improves coding efficiency over its previous video coding standards. The
expense of such improvement is enormous computational complexity, from both
encoding and decoding sides. Since computational capability and power capacity
are diverse across portable devices, it is necessary to reduce decoding
complexity to a target with tolerable quality loss, so called complexity
control. This paper proposes a Saliency-Guided Complexity Control (SGCC)
approach for HEVC decoding, which reduces the decoding complexity to the target
with minimal perceptual quality loss. First, we establish the SGCC formulation
to minimize perceptual quality loss at the constraint on reduced decoding
complexity, which is achieved via disabling Deblocking Filter (DF) and
simplifying Motion Compensation (MC) of some non-salient Coding Tree Units
(CTUs). One important component in this formulation is the modelled
relationship between decoding complexity reduction and DF disabling/MC
simplification, which determines the control accuracy of our approach. Another
component is the modelled relationship between quality loss and DF disabling/MC
simplification, responsible for optimizing perceptual quality. By solving the
SGCC formulation for a given target complexity, we can obtain the DF and MC
settings of each CTU, and then decoding complexity can be reduced to the
target. Finally, the experimental results validate the effectiveness of our
SGCC approach, from the aspects of control performance, complexity-distortion
performance, fluctuation of quality loss and subjective quality.
"
1143,Open-Ended Visual Question-Answering,"  This thesis report studies methods to solve Visual Question-Answering (VQA)
tasks with a Deep Learning framework. As a preliminary step, we explore Long
Short-Term Memory (LSTM) networks used in Natural Language Processing (NLP) to
tackle Question-Answering (text based). We then modify the previous model to
accept an image as an input in addition to the question. For this purpose, we
explore the VGG-16 and K-CNN convolutional neural networks to extract visual
features from the image. These are merged with the word embedding or with a
sentence embedding of the question to predict the answer. This work was
successfully submitted to the Visual Question Answering Challenge 2016, where
it achieved a 53,62% of accuracy in the test dataset. The developed software
has followed the best programming practices and Python code style, providing a
consistent baseline in Keras for different configurations.
"
1144,"Steganography between Silence Intervals of Audio in Video Content Using
  Chaotic Maps","  Steganography is the art of hiding data, in such a way that it is
undetectable under traffic-pattern analysis and the data hidden is only known
to the receiver and the sender. In this paper new method of text steganography
over the silence interval of audio in a video file, is presented. In the
proposed method first the audio signal is extracted from the video. After doing
audio enhancement, the data on the audio signal is steganographed using new
technique and then audio signal is rewritten in video file again.
http://www.learnrnd.com/All_latest_research_findings.php
  To enhance the security level we apply chaotic maps on arbitrary text.
Furthermore, the algorithm in this paper, gives a technique which states that
undetectable stegotext and cover-text has same probability distribution and no
statistical test can detect the presence of the hidden message.
http://www.learnrnd.com/detail.php?id=Biohack_Eyes_through_Chlorin_e6_eye_drop_:Stanford_University_Research
  Moreover, hidden message does not affect the transmission rate of video file
at all.
"
1145,A Classification Engine for Image Ballistics of Social Data,"  Image Forensics has already achieved great results for the source camera
identification task on images. Standard approaches for data coming from Social
Network Platforms cannot be applied due to different processes involved (e.g.,
scaling, compression, etc.). Over 1 billion images are shared each day on the
Internet and obtaining information about their history from the moment they
were acquired could be exploited for investigation purposes. In this paper, a
classification engine for the reconstruction of the history of an image, is
presented. Specifically, exploiting K-NN and decision trees classifiers and
a-priori knowledge acquired through image analysis, we propose an automatic
approach that can understand which Social Network Platform has processed an
image and the software application used to perform the image upload. The engine
makes use of proper alterations introduced by each platform as features.
Results, in terms of global accuracy on a dataset of 2720 images, confirm the
effectiveness of the proposed strategy.
"
1146,"An Efficient Adaptive Boundary Matching Algorithm for Video Error
  Concealment","  Sending compressed video data in error-prone environments (like the Internet
and wireless networks) might cause data degradation. Error concealment
techniques try to conceal the received data in the decoder side. In this paper,
an adaptive boundary matching algorithm is presented for recovering the damaged
motion vectors (MVs). This algorithm uses an outer boundary matching or
directional temporal boundary matching method to compare every boundary of
candidate macroblocks (MBs), adaptively. It gives a specific weight according
to the accuracy of each boundary of the damaged MB. Moreover, if each of the
adjacent MBs is already concealed, different weights are given to the
boundaries. Finally, the MV with minimum adaptive boundary distortion is
selected as the MV of the damaged MB. Experimental results show that the
proposed algorithm can improve both objective and subjective quality of
reconstructed frames without any considerable computational complexity. The
average PSNR in some frames of test sequences increases about 5.20, 5.78, 5.88,
4.37, 4.41, and 3.50 dB compared to average MV, classic boundary matching,
directional boundary matching, directional temporal boundary matching, outer
boundary matching, and dynamical temporal error concealment algorithm,
respectively.
"
1147,QoE-aware Scalable Video Transmission in MIMO~Systems,"  An important concept in wireless systems has been quality of experience
(QoE)-aware video transmission. Such communications are considered not only
connection-based communications but also content-aware communications, since
the video quality is closely related to the content itself. It becomes
necessary therefore for video communications to utilize a cross-layer design
(also known as joint source and channel coding). To provide efficient methods
of allocating network resources, the wireless network uses its cross-layer
knowledge to perform unequal error protection (UEP) solutions. In this article,
we summarize the latest video transmission technologies that are based on
scalable video coding (SVC) over multiple-input multiple-output (MIMO) systems
with cross-layer designs. To provide insight into video transmission in
wireless networks, we investigate UEP solutions in the delivering of video over
massive MIMO systems. Our results show that in terms of quality of experience
(QoE), SVC layer prioritization, which was considered important in the prior
work, is not always beneficial in massive MIMO systems; consideration must be
given to the content characteristics.
"
1148,A Novel Boundary Matching Algorithm for Video Temporal Error Concealment,"  With the fast growth of communication networks, the video data transmission
from these networks is extremely vulnerable. Error concealment is a technique
to estimate the damaged data by employing the correctly received data at the
decoder. In this paper, an efficient boundary matching algorithm for estimating
damaged motion vectors (MVs) is proposed. The proposed algorithm performs error
concealment for each damaged macro block (MB) according to the list of
identified priority of each frame. It then uses a classic boundary matching
criterion or the proposed boundary matching criterion adaptively to identify
matching distortion in each boundary of candidate MB. Finally, the candidate MV
with minimum distortion is selected as an MV of damaged MB and the list of
priorities is updated. Experimental results show that the proposed algorithm
improves both objective and subjective qualities of reconstructed frames
without any significant increase in computational cost. The PSNR for test
sequences in some frames is increased about 4.7, 4.5, and 4.4 dB compared to
the classic boundary matching, directional boundary matching, and directional
temporal boundary matching algorithm, respectively.
"
1149,Cross-Modal Scene Networks,"  People can recognize scenes across many different modalities beyond natural
images. In this paper, we investigate how to learn cross-modal scene
representations that transfer across modalities. To study this problem, we
introduce a new cross-modal scene dataset. While convolutional neural networks
can categorize scenes well, they also learn an intermediate representation not
aligned across modalities, which is undesirable for cross-modal transfer
applications. We present methods to regularize cross-modal convolutional neural
networks so that they have a shared representation that is agnostic of the
modality. Our experiments suggest that our scene representation can help
transfer representations across modalities for retrieval. Moreover, our
visualizations suggest that units emerge in the shared representation that tend
to activate on consistent concepts independently of the modality.
"
1150,Steerable Discrete Cosine Transform,"  In image compression, classical block-based separable transforms tend to be
inefficient when image blocks contain arbitrarily shaped discontinuities. For
this reason, transforms incorporating directional information are an appealing
alternative. In this paper, we propose a new approach to this problem, namely a
discrete cosine transform (DCT) that can be steered in any chosen direction.
Such transform, called steerable DCT (SDCT), allows to rotate in a flexible way
pairs of basis vectors, and enables precise matching of directionality in each
image block, achieving improved coding efficiency. The optimal rotation angles
for SDCT can be represented as solution of a suitable rate-distortion (RD)
problem. We propose iterative methods to search such solution, and we develop a
fully fledged image encoder to practically compare our techniques with other
competing transforms. Analytical and numerical results prove that SDCT
outperforms both DCT and state-of-the-art directional transforms.
"
1151,QoE-based MAC Layer Optimization for Video Teleconferencing over WiFi,"  In IEEE 802.11, the retry limit is set the same value for all packets. In
this paper, we dynamically classify video teleconferencing packets based on the
type of the video frame that a packet carries and the packet loss events that
have happened in the network, and assign them different retry limits. We
consider the IPPP video encoding structure with instantaneous decoder refresh
(IDR) frame insertion based on packet loss feedback. The loss of a single frame
causes error propagation for a period of time equal to the packet loss feedback
delay. To optimize the video quality, we propose a method to concentrate the
packet losses to small segments of the entire video sequence, and study the
performance by an analytic model. Our proposed method is implemented only on
the stations interested in enhanced video quality, and is compatible with
unmodified IEEE 802.11 stations and access points in terms of performance.
Simulation results show that the performance gain can be significant compared
to the IEEE 802.11 standard without negatively affecting cross traffic.
"
1152,"Phase Shift Keying on the Hypersphere: Peak Power-Efficient MIMO
  Communications","  Phase Shift Keying on the Hypersphere (PSKH), a generalization of
conventional Phase Shift Keying (PSK) for Multiple-Input Multiple-Output (MIMO)
systems, is introduced. In PSKH, constellation points are distributed on a
multidimensional hypersphere. The use of such constellations with a
Peak-To-Average-Sum-Power-Ratio (PASPR) of 1 allows to use load-modulated
transmitters which can cope with a small backoff, which in turn results in a
high power efficiency. In this paper, we discuss several methods how to
generate PSKH constellations and compare their performance. After applying
conventional Pulse-Amplitude Modulation (PAM), the PASPR of the continuous time
PSKH signal depends on the choice of the pulse shaping method. This choice also
influences bandwidth and power efficiency of a PSKH system. In order to reduce
the PASPR of the continuous transmission signal, we use spherical interpolation
to generate a smooth signal over the hypersphere and present corresponding
receiver techniques. Additionally, complexity reduction techniques are proposed
and compared. Finally, we discuss the methods presented in this paper regarding
their trade-offs with respect to PASPR, bandwidth, power efficiency and
receiver complexity.
"
1153,Recover Subjective Quality Scores from Noisy Measurements,"  Simple quality metrics such as PSNR are known to not correlate well with
subjective quality when tested across a wide spectrum of video content or
quality regime. Recently, efforts have been made in designing objective quality
metrics trained on subjective data (e.g. VMAF), demonstrating better
correlation with video quality perceived by human. Clearly, the accuracy of
such a metric heavily depends on the quality of the subjective data that it is
trained on. In this paper, we propose a new approach to recover subjective
quality scores from noisy raw measurements, using maximum likelihood
estimation, by jointly estimating the subjective quality of impaired videos,
the bias and consistency of test subjects, and the ambiguity of video contents
all together. We also derive closed-from expression for the confidence interval
of each estimate. Compared to previous methods which partially exploit the
subjective information, our approach is able to exploit the information in
full, yielding tighter confidence interval and better handling of outliers
without the need for z-scoring or subject rejection. It also handles missing
data more gracefully. Finally, as side information, it provides interesting
insights on the test subjects and video contents.
"
1154,Large-scale JPEG steganalysis using hybrid deep-learning framework,"  Adoption of deep learning in image steganalysis is still in its initial
stage. In this paper we propose a generic hybrid deep-learning framework for
JPEG steganalysis incorporating the domain knowledge behind rich steganalytic
models. Our proposed framework involves two main stages. The first stage is
hand-crafted, corresponding to the convolution phase and the quantization &
truncation phase of the rich models. The second stage is a compound deep neural
network containing multiple deep subnets in which the model parameters are
learned in the training procedure. We provided experimental evidences and
theoretical reflections to argue that the introduction of threshold quantizers,
though disable the gradient-descent-based learning of the bottom convolution
phase, is indeed cost-effective. We have conducted extensive experiments on a
large-scale dataset extracted from ImageNet. The primary dataset used in our
experiments contains 500,000 cover images, while our largest dataset contains
five million cover images. Our experiments show that the integration of
quantization and truncation into deep-learning steganalyzers do boost the
detection performance by a clear margin. Furthermore, we demonstrate that our
framework is insensitive to JPEG blocking artifact alterations, and the learned
model can be easily transferred to a different attacking target and even a
different dataset. These properties are of critical importance in practical
applications.
"
1155,"Show me the material evidence: Initial experiments on evaluating
  hypotheses from user-generated multimedia data","  Subjective questions such as `does neymar dive', or `is clinton lying', or
`is trump a fascist', are popular queries to web search engines, as can be seen
by autocompletion suggestions on Google, Yahoo and Bing. In the era of
cognitive computing, beyond search, they could be handled as hypotheses issued
for evaluation. Our vision is to leverage on unstructured data and metadata of
the rich user-generated multimedia that is often shared as material evidence in
favor or against hypotheses in social media platforms. In this paper we present
two preliminary experiments along those lines and discuss challenges for a
cognitive computing system that collects material evidence from user-generated
multimedia towards aggregating it into some form of collective decision on the
hypothesis.
"
1156,Leveraging Video Descriptions to Learn Video Question Answering,"  We propose a scalable approach to learn video-based question answering (QA):
answer a ""free-form natural language question"" about a video content. Our
approach automatically harvests a large number of videos and descriptions
freely available online. Then, a large number of candidate QA pairs are
automatically generated from descriptions rather than manually annotated. Next,
we use these candidate QA pairs to train a number of video-based QA methods
extended fromMN (Sukhbaatar et al. 2015), VQA (Antol et al. 2015), SA (Yao et
al. 2015), SS (Venugopalan et al. 2015). In order to handle non-perfect
candidate QA pairs, we propose a self-paced learning procedure to iteratively
identify them and mitigate their effects in training. Finally, we evaluate
performance on manually generated video-based QA pairs. The results show that
our self-paced learning procedure is effective, and the extended SS model
outperforms various baselines.
"
1157,Columbia MVSO Image Sentiment Dataset,"  The Multilingual Visual Sentiment Ontology (MVSO) consists of 15,600 concepts
in 12 different languages that are strongly related to emotions and sentiments
expressed in images. These concepts are defined in the form of Adjective-Noun
Pair (ANP), which are crawled and discovered from online image forum Flickr. In
this work, we used Amazon Mechanical Turk as a crowd-sourcing platform to
collect human judgments on sentiments expressed in images that are uniformly
sampled over 3,911 English ANPs extracted from a tag-restricted subset of MVSO.
Our goal is to use the dataset as a benchmark for the evaluation of systems
that automatically predict sentiments in images or ANPs.
"
1158,"Zero-resource Machine Translation by Multimodal Encoder-decoder Network
  with Multimedia Pivot","  We propose an approach to build a neural machine translation system with no
supervised resources (i.e., no parallel corpora) using multimodal embedded
representation over texts and images. Based on the assumption that text
documents are often likely to be described with other multimedia information
(e.g., images) somewhat related to the content, we try to indirectly estimate
the relevance between two languages. Using multimedia as the ""pivot"", we
project all modalities into one common hidden space where samples belonging to
similar semantic concepts should come close to each other, whatever the
observed space of each sample is. This modality-agnostic representation is the
key to bridging the gap between different modalities. Putting a decoder on top
of it, our network can flexibly draw the outputs from any input modality.
Notably, in the testing phase, we need only source language texts as the input
for translation. In experiments, we tested our method on two benchmarks to show
that it can achieve reasonable translation performance. We compared and
investigated several possible implementations and found that an end-to-end
model that simultaneously optimized both rank loss in multimodal encoders and
cross-entropy loss in decoders performed the best.
"
1159,"Image Credibility Analysis with Effective Domain Transferred Deep
  Networks","  Numerous fake images spread on social media today and can severely jeopardize
the credibility of online content to public. In this paper, we employ deep
networks to learn distinct fake image related features. In contrast to
authentic images, fake images tend to be eye-catching and visually striking.
Compared with traditional visual recognition tasks, it is extremely challenging
to understand these psychologically triggered visual patterns in fake images.
Traditional general image classification datasets, such as ImageNet set, are
designed for feature learning at the object level but are not suitable for
learning the hyper-features that would be required by image credibility
analysis. In order to overcome the scarcity of training samples of fake images,
we first construct a large-scale auxiliary dataset indirectly related to this
task. This auxiliary dataset contains 0.6 million weakly-labeled fake and real
images collected automatically from social media. Through an AdaBoost-like
transfer learning algorithm, we train a CNN model with a few instances in the
target training set and 0.6 million images in the collected auxiliary set. This
learning algorithm is able to leverage knowledge from the auxiliary set and
gradually transfer it to the target task. Experiments on a real-world testing
set show that our proposed domain transferred CNN model outperforms several
competing baselines. It obtains superiror results over transfer learning
methods based on the general ImageNet set. Moreover, case studies show that our
proposed method reveals some interesting patterns for distinguishing fake and
authentic images.
"
1160,Exploiting Web Images for Dataset Construction: A Domain Robust Approach,"  Labelled image datasets have played a critical role in high-level image
understanding. However, the process of manual labelling is both time-consuming
and labor intensive. To reduce the cost of manual labelling, there has been
increased research interest in automatically constructing image datasets by
exploiting web images. Datasets constructed by existing methods tend to have a
weak domain adaptation ability, which is known as the ""dataset bias problem"".
To address this issue, we present a novel image dataset construction framework
that can be generalized well to unseen target domains. Specifically, the given
queries are first expanded by searching the Google Books Ngrams Corpus to
obtain a rich semantic description, from which the visually non-salient and
less relevant expansions are filtered out. By treating each selected expansion
as a ""bag"" and the retrieved images as ""instances"", image selection can be
formulated as a multi-instance learning problem with constrained positive bags.
We propose to solve the employed problems by the cutting-plane and
concave-convex procedure (CCCP) algorithm. By using this approach, images from
different distributions can be kept while noisy images are filtered out. To
verify the effectiveness of our proposed approach, we build an image dataset
with 20 categories. Extensive experiments on image classification,
cross-dataset generalization, diversity comparison and object detection
demonstrate the domain robustness of our dataset.
"
1161,"CAS-CNN: A Deep Convolutional Neural Network for Image Compression
  Artifact Suppression","  Lossy image compression algorithms are pervasively used to reduce the size of
images transmitted over the web and recorded on data storage media. However, we
pay for their high compression rate with visual artifacts degrading the user
experience. Deep convolutional neural networks have become a widespread tool to
address high-level computer vision tasks very successfully. Recently, they have
found their way into the areas of low-level computer vision and image
processing to solve regression problems mostly with relatively shallow
networks.
  We present a novel 12-layer deep convolutional network for image compression
artifact suppression with hierarchical skip connections and a multi-scale loss
function. We achieve a boost of up to 1.79 dB in PSNR over ordinary JPEG and an
improvement of up to 0.36 dB over the best previous ConvNet result. We show
that a network trained for a specific quality factor (QF) is resilient to the
QF used to compress the input image - a single network trained for QF 60
provides a PSNR gain of more than 1.5 dB over the wide QF range from 40 to 76.
"
1162,MOMOS-MT: Mobile Monophonic System for Music Transcription,"  Music holds a significant cultural role in social identity and in the
encouragement of socialization. Technology, by the destruction of physical and
cultural distance, has lead to many changes in musical themes and the complete
loss of forms. Yet, it also allows for the preservation and distribution of
music from societies without a history of written sheet music. This paper
presents early work on a tool for musicians and ethnomusicologists to
transcribe sheet music from monophonic voiced pieces for preservation and
distribution. Using FFT, the system detects the pitch frequencies, also other
methods detect note durations, tempo, time signatures and generates sheet
music. The final system is able to be used in mobile platforms allowing the
user to take recordings and produce sheet music in situ to a performance.
"
1163,A Second Order Derivatives based Approach for Steganography,"  Steganography schemes are designed with the objective of minimizing a defined
distortion function. In most existing state of the art approaches, this
distortion function is based on image feature preservation. Since smooth
regions or clean edges define image core, even a small modification in these
areas largely modifies image features and is thus easily detectable. On the
contrary, textures, noisy or chaotic regions are so difficult to model that the
features having been modified inside these areas are similar to the initial
ones. These regions are characterized by disturbed level curves. This work
presents a new distortion function for steganography that is based on second
order derivatives, which are mathematical tools that usually evaluate level
curves. Two methods are explained to compute these partial derivatives and have
been completely implemented. The first experiments show that these approaches
are promising.
"
1164,"Prediction of Video Popularity in the Absence of Reliable Data from
  Video Hosting Services: Utility of Traces Left by Users on the Web","  With the growth of user-generated content, we observe the constant rise of
the number of companies, such as search engines, content aggregators, etc.,
that operate with tremendous amounts of web content not being the services
hosting it. Thus, aiming to locate the most important content and promote it to
the users, they face the need of estimating the current and predicting the
future content popularity.
  In this paper, we approach the problem of video popularity prediction not
from the side of a video hosting service, as done in all previous studies, but
from the side of an operating company, which provides a popular video search
service that aggregates content from different video hosting websites. We
investigate video popularity prediction based on features from three primary
sources available for a typical operating company: first, the content hosting
provider may deliver its data via its API, second, the operating company makes
use of its own search and browsing logs, third, the company crawls information
about embeds of a video and links to a video page from publicly available
resources on the Web. We show that video popularity prediction based on the
embed and link data coupled with the internal search and browsing data
significantly improves video popularity prediction based only on the data
provided by the video hosting and can even adequately replace the API data in
the cases when it is partly or completely unavailable.
"
1165,Fast Supervised Discrete Hashing and its Analysis,"  In this paper, we propose a learning-based supervised discrete hashing
method. Binary hashing is widely used for large-scale image retrieval as well
as video and document searches because the compact representation of binary
code is essential for data storage and reasonable for query searches using
bit-operations. The recently proposed Supervised Discrete Hashing (SDH)
efficiently solves mixed-integer programming problems by alternating
optimization and the Discrete Cyclic Coordinate descent (DCC) method. We show
that the SDH model can be simplified without performance degradation based on
some preliminary experiments; we call the approximate model for this the ""Fast
SDH"" (FSDH) model. We analyze the FSDH model and provide a mathematically exact
solution for it. In contrast to SDH, our model does not require an alternating
optimization algorithm and does not depend on initial values. FSDH is also
easier to implement than Iterative Quantization (ITQ). Experimental results
involving a large-scale database showed that FSDH outperforms conventional SDH
in terms of precision, recall, and computation time.
"
1166,"Energy-efficient 8-point DCT Approximations: Theory and Hardware
  Architectures","  Due to its remarkable energy compaction properties, the discrete cosine
transform (DCT) is employed in a multitude of compression standards, such as
JPEG and H.265/HEVC. Several low-complexity integer approximations for the DCT
have been proposed for both 1-D and 2-D signal analysis. The increasing demand
for low-complexity, energy efficient methods require algorithms with even lower
computational costs. In this paper, new 8-point DCT approximations with very
low arithmetic complexity are presented. The new transforms are proposed based
on pruning state-of-the-art DCT approximations. The proposed algorithms were
assessed in terms of arithmetic complexity, energy retention capability, and
image compression performance. In addition, a metric combining performance and
computational complexity measures was proposed. Results showed good performance
and extremely low computational complexity. Introduced algorithms were mapped
into systolic-array digital architectures and physically realized as digital
prototype circuits using FPGA technology and mapped to 45nm CMOS technology.
All hardware-related metrics showed low resource consumption of the proposed
pruned approximate transforms. The best proposed transform according to the
introduced metric presents a reduction in power consumption of 21--25%.
"
1167,Algorithmic Songwriting with ALYSIA,"  This paper introduces ALYSIA: Automated LYrical SongwrIting Application.
ALYSIA is based on a machine learning model using Random Forests, and we
discuss its success at pitch and rhythm prediction. Next, we show how ALYSIA
was used to create original pop songs that were subsequently recorded and
produced. Finally, we discuss our vision for the future of Automated
Songwriting for both co-creative and autonomous systems.
"
1168,A novel Adaptive weighted Kronecker Compressive Sensing,"  Recently, multidimensional signal reconstruction using a low number of
measurements is of great interest. Therefore, an effective sampling scheme
which should acquire the most information of signal using a low number of
measurements is required. In this paper, we study a novel cube-based method for
sampling and reconstruction of multidimensional signals. First, inspired by the
block-based compressive sensing (BCS), we divide a group of pictures (GoP) in a
video sequence into cubes. By this way, we can easily store the measurement
matrix and also easily can generate the sparsifying basis. The reconstruction
process also can be done in parallel. Second, along with the Kronecker
structure of the sampling matrix, we design a weight matrix based on the human
visuality system, i.e. perceptually. We will also benefit from different
weighted $\ell_1$-minimization methods for reconstruction. Furthermore,
conventional methods for BCS consider an equal number of samples for all
blocks. However, the sparsity order of blocks in natural images could be
different and, therefore, a various number of samples could be required for
their reconstruction. Motivated by this point, we will adaptively allocate the
samples for each cube in a video sequence. Our aim is to show that our simple
linear sampling approach can be competitive with the other state-of-the-art
methods.
"
1169,Binary Subspace Coding for Query-by-Image Video Retrieval,"  The query-by-image video retrieval (QBIVR) task has been attracting
considerable research attention recently. However, most existing methods
represent a video by either aggregating or projecting all its frames into a
single datum point, which may easily cause severe information loss. In this
paper, we propose an efficient QBIVR framework to enable an effective and
efficient video search with image query. We first define a
similarity-preserving distance metric between an image and its orthogonal
projection in the subspace of the video, which can be equivalently transformed
to a Maximum Inner Product Search (MIPS) problem.
  Besides, to boost the efficiency of solving the MIPS problem, we propose two
asymmetric hashing schemes, which bridge the domain gap of images and videos.
The first approach, termed Inner-product Binary Coding (IBC), preserves the
inner relationships of images and videos in a common Hamming space. To further
improve the retrieval efficiency, we devise a Bilinear Binary Coding (BBC)
approach, which employs compact bilinear projections instead of a single large
projection matrix. Extensive experiments have been conducted on four real-world
video datasets to verify the effectiveness of our proposed approaches as
compared to the state-of-the-arts.
"
1170,Towards computer-assisted understanding of dynamics in symphonic music,"  Many people enjoy classical symphonic music. Its diverse instrumentation
makes for a rich listening experience. This diversity adds to the conductor's
expressive freedom to shape the sound according to their imagination. As a
result, the same piece may sound quite differently from one conductor to
another. Differences in interpretation may be noticeable subjectively to
listeners, but they are sometimes hard to pinpoint, presumably because of the
acoustic complexity of the sound. We describe a computational model that
interprets dynamics---expressive loudness variations in performances---in terms
of the musical score, highlighting differences between performances of the same
piece. We demonstrate experimentally that the model has predictive power, and
give examples of conductor ideosyncrasies found by using the model as an
explanatory tool. Although the present model is still in active development, it
may pave the road for a consumer-oriented companion to interactive classical
music understanding.
"
1171,Low-complexity Pruned 8-point DCT Approximations for Image Encoding,"  Two multiplierless pruned 8-point discrete cosine transform (DCT)
approximation are presented. Both transforms present lower arithmetic
complexity than state-of-the-art methods. The performance of such new methods
was assessed in the image compression context. A JPEG-like simulation was
performed, demonstrating the adequateness and competitiveness of the introduced
methods. Digital VLSI implementation in CMOS technology was also considered.
Both presented methods were realized in Berkeley Emulation Engine (BEE3).
"
1172,"Spatial multi-LRU: Distributed Caching for Wireless Networks with
  Coverage Overlaps","  This article introduces a novel family of decentralised caching policies,
applicable to wireless networks with finite storage at the edge-nodes
(stations). These policies, that are based on the Least-Recently-Used
replacement principle, are here referred to as spatial multi-LRU. They update
cache inventories in a way that provides content diversity to users who are
covered by, and thus have access to, more than one station. Two variations are
proposed, the multi-LRU-One and -All, which differ in the number of replicas
inserted in the involved caches. We analyse their performance under two types
of traffic demand, the Independent Reference Model (IRM) and a model that
exhibits temporal locality. For IRM, we propose a Che-like approximation to
predict the hit probability, which gives very accurate results. Numerical
evaluations show that the performance of multi-LRU increases the more the
multi-coverage areas increase, and it is close to the performance of
centralised policies, when multi-coverage is sufficient. For IRM traffic,
multi-LRU-One is preferable to multi-LRU-All, whereas when the traffic exhibits
temporal locality the -All variation can perform better. Both variations
outperform the simple LRU. When popularity knowledge is not accurate, the new
policies can perform better than centralised ones.
"
1173,"Algorithmic Analysis of Invisible Video Watermarking using LSB Encoding
  Over a Client-Server Framework","  Video watermarking is extensively used in many media-oriented applications
for embedding watermarks, i.e. hidden digital data, in a video sequence to
protect the video from illegal copying and to identify manipulations made in
the video. In case of an invisible watermark, the human eye can not perceive
any difference in the video, but a watermark extraction application can read
the watermark and obtain the embedded information. Although numerous
methodologies exist for embedding watermarks, many of them have shortcomings
with respect to performance efficiency, especially over a distributed network.
This paper proposes and analyses a 2-bit Least Significant Bit (LSB) parallel
algorithmic approach for achieving performance efficiency to watermark and
distribute videos over a client-server framework.
"
1174,Video Stream Retrieval of Unseen Queries using Semantic Memory,"  Retrieval of live, user-broadcast video streams is an under-addressed and
increasingly relevant challenge. The on-line nature of the problem requires
temporal evaluation and the unforeseeable scope of potential queries motivates
an approach which can accommodate arbitrary search queries. To account for the
breadth of possible queries, we adopt a no-example approach to query retrieval,
which uses a query's semantic relatedness to pre-trained concept classifiers.
To adapt to shifting video content, we propose memory pooling and memory
welling methods that favor recent information over long past content. We
identify two stream retrieval tasks, instantaneous retrieval at any particular
time and continuous retrieval over a prolonged duration, and propose means for
evaluating them. Three large scale video datasets are adapted to the challenge
of stream retrieval. We report results for our search methods on the new stream
retrieval tasks, as well as demonstrate their efficacy in a traditional,
non-streaming video task.
"
1175,"Pseudo Sequence based 2-D hierarchical reference structure for
  Light-Field Image Compression","  In this paper, we present a novel pseudo sequence based 2-D hierarchical
reference structure for light-field image compression. In the proposed scheme,
we first decompose the light-field image into multiple views and organize them
into a 2-D coding structure according to the spatial coordinates of the
corresponding microlens. Then we mainly develop three technologies to optimize
the 2-D coding structure. First, we divide all the views into four quadrants,
and all the views are encoded one quadrant after another to reduce the
reference buffer size as much as possible. Inside each quadrant, all the views
are encoded hierarchically to fully exploit the correlations between different
views. Second, we propose to use the distance between the current view and its
reference views as the criteria for selecting better reference frames for each
inter view. Third, we propose to use the spatial relative positions between
different views to achieve more accurate motion vector scaling. The whole
scheme is implemented in the reference software of High Efficiency Video
Coding. The experimental results demonstrate that the proposed novel
pseudo-sequence based 2-D hierarchical structure can achieve maximum 14.2%
bit-rate savings compared with the state-of-the-art light-field image
compression method.
"
1176,Efficient Action Detection in Untrimmed Videos via Multi-Task Learning,"  This paper studies the joint learning of action recognition and temporal
localization in long, untrimmed videos. We employ a multi-task learning
framework that performs the three highly related steps of action proposal,
action recognition, and action localization refinement in parallel instead of
the standard sequential pipeline that performs the steps in order. We develop a
novel temporal actionness regression module that estimates what proportion of a
clip contains action. We use it for temporal localization but it could have
other applications like video retrieval, surveillance, summarization, etc. We
also introduce random shear augmentation during training to simulate viewpoint
change. We evaluate our framework on three popular video benchmarks. Results
demonstrate that our joint model is efficient in terms of storage and
computation in that we do not need to compute and cache dense trajectory
features, and that it is several times faster than its sequential ConvNets
counterpart. Yet, despite being more efficient, it outperforms state-of-the-art
methods with respect to accuracy.
"
1177,"Object Shape Approximation & Contour Adaptive Depth Image Coding for
  Virtual View Synthesis","  A depth image provides partial geometric information of a 3D scene, namely
the shapes of physical objects as observed from a particular viewpoint. This
information is important when synthesizing images of different virtual camera
viewpoints via depth-image-based rendering (DIBR). It has been shown that depth
images can be efficiently coded using contour-adaptive codecs that preserve
edge sharpness, resulting in visually pleasing DIBR-synthesized images.
However, contours are typically losslessly coded as side information (SI),
which is expensive if the object shapes are complex.
  In this paper, we pursue a new paradigm in depth image coding for
color-plus-depth representation of a 3D scene: we pro-actively simplify object
shapes in a depth and color image pair to reduce depth coding cost, at a
penalty of a slight increase in synthesized view distortion. Specifically, we
first mathematically derive a distortion upper-bound proxy for 3DSwIM---a
quality metric tailored for DIBR-synthesized images. This proxy reduces
interdependency among pixel rows in a block to ease optimization. We then
approximate object contours via a dynamic programming (DP) algorithm to
optimally trade off coding cost of contours using arithmetic edge coding (AEC)
with our proposed view synthesis distortion proxy. We modify the depth and
color images according to the approximated object contours in an inter-view
consistent manner. These are then coded respectively using a contour-adaptive
image codec based on graph Fourier transform (GFT) for edge preservation and
HEVC intra. Experimental results show that by maintaining sharp but simplified
object contours during contour-adaptive coding, for the same visual quality of
DIBR-synthesized virtual views, our proposal can reduce depth image coding rate
by up to 22% compared to alternative coding strategies such as HEVC intra.
"
1178,Cross-Color Channel Perceptually Adaptive Quantization for HEVC,"  HEVC includes a Coding Unit (CU) level luminance-based perceptual
quantization technique known as AdaptiveQP. AdaptiveQP perceptually adjusts the
Quantization Parameter (QP) at the CU level based on the spatial activity of
raw input video data in a luma Coding Block (CB). In this paper, we propose a
novel cross-color channel adaptive quantization scheme which perceptually
adjusts the CU level QP according to the spatial activity of raw input video
data in the constituent luma and chroma CBs; i.e., the combined spatial
activity across all three color channels (the Y, Cb and Cr channels). Our
technique is evaluated in HM 16 with 4:4:4, 4:2:2 and 4:2:0 YCbCr JCT-VC test
sequences. Both subjective and objective visual quality evaluations are
undertaken during which we compare our method with AdaptiveQP. Our technique
achieves considerable coding efficiency improvements, with maximum BD-Rate
reductions of 15.9% (Y), 13.1% (Cr) and 16.1% (Cb) in addition to a maximum
decoding time reduction of 11.0%.
"
1179,Streaming Virtual Reality Content,"  The recent rise of interest in Virtual Reality (VR) came with the
availability of commodity commercial VR prod- ucts, such as the Head Mounted
Displays (HMD) created by Oculus and other vendors. To accelerate the user
adoption of VR headsets, content providers should focus on producing high
quality immersive content for these devices. Similarly, multimedia streaming
service providers should enable the means to stream 360 VR content on their
platforms. In this study, we try to cover different aspects related to VR
content representation, streaming, and quality assessment that will help
establishing the basic knowledge of how to build a VR streaming system.
"
1180,Semantic Perceptual Image Compression using Deep Convolution Networks,"  It has long been considered a significant problem to improve the visual
quality of lossy image and video compression. Recent advances in computing
power together with the availability of large training data sets has increased
interest in the application of deep learning cnns to address image recognition
and image processing tasks. Here, we present a powerful cnn tailored to the
specific task of semantic image understanding to achieve higher visual quality
in lossy compression. A modest increase in complexity is incorporated to the
encoder which allows a standard, off-the-shelf jpeg decoder to be used. While
jpeg encoding may be optimized for generic images, the process is ultimately
unaware of the specific content of the image to be compressed. Our technique
makes jpeg content-aware by designing and training a model to identify multiple
semantic regions in a given image. Unlike object detection techniques, our
model does not require labeling of object positions and is able to identify
objects in a single pass. We present a new cnn architecture directed
specifically to image compression, which generates a map that highlights
semantically-salient regions so that they can be encoded at higher quality as
compared to background regions. By adding a complete set of features for every
class, and then taking a threshold over the sum of all feature activations, we
generate a map that highlights semantically-salient regions so that they can be
encoded at a better quality compared to background regions. Experiments are
presented on the Kodak PhotoCD dataset and the MIT Saliency Benchmark dataset,
in which our algorithm achieves higher visual quality for the same compressed
size.
"
1181,"Creating A Multi-track Classical Musical Performance Dataset for
  Multimodal Music Analysis: Challenges, Insights, and Applications","  We introduce a dataset for facilitating audio-visual analysis of music
performances. The dataset comprises 44 simple multi-instrument classical music
pieces assembled from coordinated but separately recorded performances of
individual tracks. For each piece, we provide the musical score in MIDI format,
the audio recordings of the individual tracks, the audio and video recording of
the assembled mixture, and ground-truth annotation files including frame-level
and note-level transcriptions. We describe our methodology for the creation of
the dataset, particularly highlighting our approaches for addressing the
challenges involved in maintaining synchronization and expressiveness. We
demonstrate the high quality of synchronization achieved with our proposed
approach by comparing the dataset with existing widely-used music audio
datasets.
  We anticipate that the dataset will be useful for the development and
evaluation of existing music information retrieval (MIR) tasks, as well as for
novel multi-modal tasks. We benchmark two existing MIR tasks (multi-pitch
analysis and score-informed source separation) on the dataset and compare with
other existing music audio datasets. Additionally, we consider two novel
multi-modal MIR tasks (visually informed multi-pitch analysis and polyphonic
vibrato analysis) enabled by the dataset and provide evaluation measures and
baseline systems for future comparisons (from our recent work). Finally, we
propose several emerging research directions that the dataset enables.
"
1182,"Improving Blind Steganalysis in Spatial Domain using a Criterion to
  Choose the Appropriate Steganalyzer between CNN and SRM+EC","  Conventional state-of-the-art image steganalysis approaches usually consist
of a classifier trained with features provided by rich image models. As both
features extraction and classification steps are perfectly embodied in the deep
learning architecture called Convolutional Neural Network (CNN), different
studies have tried to design a CNN-based steganalyzer. The network designed by
Xu et al. is the first competitive CNN with the combination Spatial Rich Models
(SRM) and Ensemble Classifier (EC) providing detection performances of the same
order. In this work we propose a criterion to choose either the CNN or the
SRM+EC method for a given input image. Our approach is studied with three
different steganographic spatial domain algorithms: S-UNIWARD, MiPOD, and HILL,
using the Tensorflow computing platform, and exhibits detection capabilities
better than each method alone. Furthermore, as SRM+EC and the CNN are both only
trained with a single embedding algorithm, namely MiPOD, the proposed method
can be seen as an approach for blind steganalysis. In blind detection, error
rates are respectively of 16% for S-UNIWARD, 16% for MiPOD, and 17% for HILL on
the BOSSBase with a payload of 0.4 bpp. For 0.1 bpp, the respective
corresponding error rates are of 39%, 38%, and 41%, and are always better than
the ones provided by SRM+EC.
"
1183,"Duplicate matching and estimating features for detection of copy-move
  images forgery","  Copy-move forgery is the most popular and simplest image manipulation method.
In this type of forgery, an area from the image copied, then after post
processing such as rotation and scaling, placed on the destination. The goal of
Copy-move forgery is to hide or duplicate one or more objects in the image.
Key-point based Copy-move forgery detection methods have five main steps:
preprocessing, feature extraction, matching, transform estimation and post
processing that matching and transform estimation have important effect on the
detection. More over the error could happens in some steps due to the noise.
The existing methods process these steps separately and in case of having an
error in a step, this error could be propagated to the following steps and
affects the detection. To solve the above mentioned problem, in this paper the
steps of the detection system interact with each other and if an error happens
in a step, following steps are trying to detect and solve it. We formulate this
interaction by defining and optimizing a cost function. This function includes
matching and transform estimation steps. Then in an iterative procedure the
steps are executed and in case of detecting error, the error will be corrected.
The efficiency of the proposed method analyzed in diverse cases such as pixel
image precision level on the simple forgery images, robustness to the rotation
and scaling, detecting professional forgery images and the precision of the
transformation matrix. The results indicate the better efficiency of the
proposed method.
"
1184,AENet: Learning Deep Audio Features for Video Analysis,"  We propose a new deep network for audio event recognition, called AENet. In
contrast to speech, sounds coming from audio events may be produced by a wide
variety of sources. Furthermore, distinguishing them often requires analyzing
an extended time period due to the lack of clear sub-word units that are
present in speech. In order to incorporate this long-time frequency structure
of audio events, we introduce a convolutional neural network (CNN) operating on
a large temporal input. In contrast to previous works this allows us to train
an audio event detection system end-to-end. The combination of our network
architecture and a novel data augmentation outperforms previous methods for
audio event detection by 16%. Furthermore, we perform transfer learning and
show that our model learnt generic audio features, similar to the way CNNs
learn generic features on vision tasks. In video analysis, combining visual
features and traditional audio features such as MFCC typically only leads to
marginal improvements. Instead, combining visual features with our AENet
features, which can be computed efficiently on a GPU, leads to significant
performance improvements on action recognition and video highlight detection.
In video highlight detection, our audio features improve the performance by
more than 8% over visual features alone.
"
1185,"Price-based Controller for Quality-Fair HTTP Adaptive Streaming
  (Extended Version)","  HTTP adaptive streaming (HAS) has become the universal technology for video
streaming over the Internet. Many HAS system designs aim at sharing the network
bandwidth in a rate-fair manner. However, rate fairness is in general not
equivalent to quality fairness as different video sequences might have
different characteristics and resource requirements. In this work, we focus on
this limitation and propose a novel controller for HAS clients that is able to
reach quality fairness while preserving the main characteristics of HAS systems
and with a limited support from the network devices. In particular, we adopt a
price-based mechanism in order to build a controller that maximizes the
aggregate video quality for a set of HAS clients that share a common
bottleneck. When network resources are scarce, the clients with simple video
sequences reduce the requested bitrate in favor of users that subscribe to more
complex video sequences, leading to a more efficient network usage. The
proposed controller has been implemented in a network simulator, and the
simulation results demonstrate its ability to share the available bandwidth
among the HAS users in a quality-fair manner.
"
1186,"VideoSet: A Large-Scale Compressed Video Quality Dataset Based on JND
  Measurement","  A new methodology to measure coded image/video quality using the
just-noticeable-difference (JND) idea was proposed. Several small JND-based
image/video quality datasets were released by the Media Communications Lab at
the University of Southern California. In this work, we present an effort to
build a large-scale JND-based coded video quality dataset. The dataset consists
of 220 5-second sequences in four resolutions (i.e., $1920 \times 1080$, $1280
\times 720$, $960 \times 540$ and $640 \times 360$). For each of the 880 video
clips, we encode it using the H.264 codec with $QP=1, \cdots, 51$ and measure
the first three JND points with 30+ subjects. The dataset is called the
""VideoSet"", which is an acronym for ""Video Subject Evaluation Test (SET)"". This
work describes the subjective test procedure, detection and removal of outlying
measured data, and the properties of collected JND data. Finally, the
significance and implications of the VideoSet to future video coding research
and standardization efforts are pointed out. All source/coded video clips as
well as measured JND data included in the VideoSet are available to the public
in the IEEE DataPort.
"
1187,Light Field Super-Resolution Via Graph-Based Regularization,"  Light field cameras capture the 3D information in a scene with a single
exposure. This special feature makes light field cameras very appealing for a
variety of applications: from post-capture refocus, to depth estimation and
image-based rendering. However, light field cameras suffer by design from
strong limitations in their spatial resolution, which should therefore be
augmented by computational methods. On the one hand, off-the-shelf single-frame
and multi-frame super-resolution algorithms are not ideal for light field data,
as they do not consider its particular structure. On the other hand, the few
super-resolution algorithms explicitly tailored for light field data exhibit
significant limitations, such as the need to estimate an explicit disparity map
at each view. In this work we propose a new light field super-resolution
algorithm meant to address these limitations. We adopt a multi-frame alike
super-resolution approach, where the complementary information in the different
light field views is used to augment the spatial resolution of the whole light
field. We show that coupling the multi-frame approach with a graph regularizer,
that enforces the light field structure via nonlocal self similarities, permits
to avoid the costly and challenging disparity estimation step for all the
views. Extensive experiments show that the new algorithm compares favorably to
the other state-of-the-art methods for light field super-resolution, both in
terms of PSNR and visual quality.
"
1188,WiLiTV: A Low-Cost Wireless Framework for Live TV Services,"  With the evolution of HDTV and Ultra HDTV, the bandwidth requirement for
IP-based TV content is rapidly increasing. Consumers demand uninterrupted
service with a high Quality of Experience (QoE). Service providers are
constantly trying to differentiate themselves by innovating new ways of
distributing content more efficiently with lower cost and higher penetration.
In this work, we propose a cost-efficient wireless framework (WiLiTV) for
delivering live TV services, consisting of a mix of wireless access
technologies (e.g. Satellite, WiFi and LTE overlay links). In the proposed
architecture, live TV content is injected into the network at a few residential
locations using satellite dishes. The content is then further distributed to
other homes using a house-to-house WiFi network or via an overlay LTE network.
Our problem is to construct an optimal TV distribution network with the minimum
number of satellite injection points, while preserving the highest QoE, for
different neighborhood densities. We evaluate the framework using realistic
time-varying demand patterns and a diverse set of home location data. Our study
demonstrates that the architecture requires 75 - 90% fewer satellite injection
points, compared to traditional architectures. Furthermore, we show that most
cost savings can be obtained using simple and practical relay routing
solutions.
"
1189,Attention-Based Multimodal Fusion for Video Description,"  Currently successful methods for video description are based on
encoder-decoder sentence generation using recur-rent neural networks (RNNs).
Recent work has shown the advantage of integrating temporal and/or spatial
attention mechanisms into these models, in which the decoder net-work predicts
each word in the description by selectively giving more weight to encoded
features from specific time frames (temporal attention) or to features from
specific spatial regions (spatial attention). In this paper, we propose to
expand the attention model to selectively attend not just to specific times or
spatial regions, but to specific modalities of input such as image features,
motion features, and audio features. Our new modality-dependent attention
mechanism, which we call multimodal attention, provides a natural way to fuse
multimodal information for video description. We evaluate our method on the
Youtube2Text dataset, achieving results that are competitive with current state
of the art. More importantly, we demonstrate that our model incorporating
multimodal attention as well as temporal attention significantly outperforms
the model that uses temporal attention alone.
"
1190,"Investigating the role of musical genre in human perception of music
  stretching resistance","  To stretch a music piece to a given length is a common demand in people's
daily lives, e.g., in audio-video synchronization and animation production.
However, it is not always guaranteed that the stretched music piece is
acceptable for general audience since music stretching suffers from people's
perceptual artefacts. Over-stretching a music piece will make it uncomfortable
for human psychoacoustic hearing. The research on music stretching resistance
attempts to estimate the maximum stretchability of music pieces to further
avoid over-stretch. It has been observed that musical genres can significantly
improve the accuracy of automatic estimation of music stretching resistance,
but how musical genres are related to music stretching resistance has never
been explained or studied in detail in the literature. In this paper, the
characteristics of music stretching resistance are compared across different
musical genres. It is found that music stretching resistance has strong
intra-genre cohesiveness and inter-genre discrepancies in the experiments.
Moreover, the ambiguity and the symmetry of music stretching resistance are
also observed in the experimental analysis. These findings lead to a new
measurement on the similarity between different musical genres based on their
music stretching resistance. In addition, the analysis of variance (ANOVA) also
supports the findings in this paper by verifying the significance of musical
genre in shaping music stretching resistance.
"
1191,Attention Allocation Aid for Visual Search,"  This paper outlines the development and testing of a novel, feedback-enabled
attention allocation aid (AAAD), which uses real-time physiological data to
improve human performance in a realistic sequential visual search task. Indeed,
by optimizing over search duration, the aid improves efficiency, while
preserving decision accuracy, as the operator identifies and classifies targets
within simulated aerial imagery. Specifically, using experimental eye-tracking
data and measurements about target detectability across the human visual field,
we develop functional models of detection accuracy as a function of search
time, number of eye movements, scan path, and image clutter. These models are
then used by the AAAD in conjunction with real time eye position data to make
probabilistic estimations of attained search accuracy and to recommend that the
observer either move on to the next image or continue exploring the present
image. An experimental evaluation in a scenario motivated from human
supervisory control in surveillance missions confirms the benefits of the AAAD.
"
1192,"A Watermarking Technique Using Discrete Curvelet Transform for Security
  of Multiple Biometric Features","  The robustness and security of the biometric watermarking approach can be
improved by using a multiple watermarking. This multiple watermarking proposed
for improving security of biometric features and data. When the imposter tries
to create the spoofed biometric feature, the invisible biometric watermark
features can provide appropriate protection to multimedia data. In this paper,
a biometric watermarking technique with multiple biometric watermarks are
proposed in which biometric features of fingerprint, face, iris and signature
is embedded in the image. Before embedding, fingerprint, iris, face and
signature features are extracted using Shen-Castan edge detection and Principal
Component Analysis. These all biometric watermark features are embedded into
various mid band frequency curvelet coefficients of host image. All four
fingerprint features, iris features, facial features and signature features are
the biometric characteristics of the individual and they are used for cross
verification and copyright protection if any manipulation occurs. The proposed
technique is fragile enough; features cannot be extracted from the watermarked
image when an imposter tries to remove watermark features illegally. It can use
for multiple copyright authentication and verification.
"
1193,Comprehensive Review of Audio Steganalysis Methods,"  Recently, merging signal processing techniques with information security
services has found a lot of attention. Steganography and steganalysis are among
those trends. Like their counterparts in cryptology, steganography and
steganalysis are in a constant battle. Steganography methods try to hide the
presence of covert messages in innocuous-looking data, whereas steganalysis
methods try to reveal existence of such messages and to break steganography
methods. The stream nature of audio signals, their popularity, and their wide
spread usage make them very suitable media for steganography. This has led to a
very rich literature on both steganography and steganalysis of audio signals.
This paper intends to conduct a comprehensive review of audio steganalysis
methods aggregated over near fifteen years. Furthermore, we implement some of
the most recent audio steganalysis methods and conduct a comparative analysis
on their performances. Finally, the paper provides some possible directions for
future researches on audio steganalysis.
"
1194,"Universal Audio Steganalysis Based on Calibration and Reversed Frequency
  Resolution of Human Auditory System","  Calibration and higher order statistics (HOS) are standard components of many
image steganalysis systems. These techniques have not yet found adequate
attention in audio steganalysis context. Specifically, most of current works
are either non-calibrated or only based on noise removal approach. This paper
aims to fill these gaps by proposing a new set of calibrated features based on
re-embedding technique. Additionally, we show that least significant bit (LSB)
is the most sensitive bit-plane to data hiding algorithms and therefore it can
be employed as a universal embedding method. Furthermore, the proposed features
are based on a model that has the maximum deviation from human auditory system
(HAS), and therefore are more suitable for the purpose of steganalysis.
Performance of the proposed method is evaluated on a wide range of data hiding
algorithms in both targeted and universal paradigms. Simulation results show
that the proposed method can detect the finest traces of data hiding algorithms
and in very low embedding rates. The system detects steghide at capacity of
0.06 bit per symbol (BPS) with sensitivity of 98.6% (music) and 78.5% (speech).
These figures are respectively 7.1% and 27.5% higher than state-of-the-art
results based on RMFCC.
"
1195,Adaptive 360 VR Video Streaming based on MPEG-DASH SRD,"  We demonstrate an adaptive bandwidth-efficient 360 VR video streaming system
based on MPEG-DASH SRD. We extend MPEG-DASH SRD to the 3D space of 360 VR
videos, and showcase a dynamic view-aware adaptation technique to tackle the
high bandwidth demands of streaming 360 VR videos to wireless VR headsets. We
spatially partition the underlying 3D mesh into multiple 3D sub-meshes, and
construct an efficient 3D geometry mesh called hexaface sphere to optimally
represent tiled 360 VR videos in the 3D space. We then spatially divide the 360
videos into multiple tiles while encoding and packaging, use MPEG-DASH SRD to
describe the spatial relationship of tiles in the 3D space, and prioritize the
tiles in the Field of View (FoV) for view-aware adaptation. Our initial
evaluation results show that we can save up to 72% of the required bandwidth on
360 VR video streaming with minor negative quality impacts compared to the
baseline scenario when no adaptations is applied.
"
1196,"Analysis of challenges faced by WebRTC videoconferencing and a remedial
  architecture","  Lately, World Wide Web came up with an evolution in the niche of
videoconference applications. Latest technologies give browsers a capacity to
initiate real-time communications. WebRTC is one of the free and open source
projects that aim at providing the users freedom to enjoy real-time
communications, and it does so by following and redefining the standards.
However, WebRTC is still a new project and it lacks some high-end
videoconferencing features such as media mixing, recording of a session and
different network conditions adaptation. This paper is an attempt at analyzing
the shortcomings and challenges faced by WebRTC and proposing a Multipoint
Control Unit or traditional communications entity based architecture as a
solution.
"
1197,"Inkjet printing-based volumetric display projecting multiple full-colour
  2D patterns","  In this study, a method to construct a full-colour volumetric display is
presented using a commercially available inkjet printer. Photoreactive
luminescence materials are minutely and automatically printed as the volume
elements, and volumetric displays are constructed with high resolution using
easy-to-fabricate means that exploit inkjet printing technologies. The results
experimentally demonstrate the first prototype of an inkjet printing-based
volumetric display composed of multiple layers of transparent films that yield
a full-colour three-dimensional (3D) image. Moreover, we propose a design
algorithm with 3D structures that provide multiple different 2D full-colour
patterns when viewed from different directions and experimentally demonstrates
prototypes. It is considered that these types of 3D volumetric structures and
their fabrication methods based on widely deployed existing printing
technologies can be utilised as novel information display devices and systems,
including digital signage, media art, entertainment and security.
"
1198,DCT-like Transform for Image Compression Requires 14 Additions Only,"  A low-complexity 8-point orthogonal approximate DCT is introduced. The
proposed transform requires no multiplications or bit-shift operations. The
derived fast algorithm requires only 14 additions, less than any existing DCT
approximation. Moreover, in several image compression scenarios, the proposed
transform could outperform the well-known signed DCT, as well as
state-of-the-art algorithms.
"
1199,Combining and Steganography of 3D Face Textures,"  One of the serious issues in communication between people is hiding
information from others, and the best way for this, is deceiving them. Since
nowadays face images are mostly used in three dimensional format, in this paper
we are going to steganography 3D face images, detecting which by curious people
will be impossible. As in detecting face only its texture is important, we
separate texture from shape matrices, for eliminating half of the extra
information, steganography is done only for face texture, and for
reconstructing 3D face, we can use any other shape. Moreover, we will indicate
that, by using two textures, how two 3D faces can be combined. For a complete
description of the process, first, 2D faces are used as an input for building
3D faces, and then 3D textures are hidden within other images.
"
1200,Contextually Customized Video Summaries via Natural Language,"  The best summary of a long video differs among different people due to its
highly subjective nature. Even for the same person, the best summary may change
with time or mood. In this paper, we introduce the task of generating
customized video summaries through simple text. First, we train a deep
architecture to effectively learn semantic embeddings of video frames by
leveraging the abundance of image-caption data via a progressive and residual
manner. Given a user-specific text description, our algorithm is able to select
semantically relevant video segments and produce a temporally aligned video
summary. In order to evaluate our textually customized video summaries, we
conduct experimental comparison with baseline methods that utilize ground-truth
information. Despite the challenging baselines, our method still manages to
show comparable or even exceeding performance. We also show that our method is
able to generate semantically diverse video summaries by only utilizing the
learned visual embeddings.
"
1201,"A Digital Hardware Fast Algorithm and FPGA-based Prototype for a Novel
  16-point Approximate DCT for Image Compression Applications","  The discrete cosine transform (DCT) is the key step in many image and video
coding standards. The 8-point DCT is an important special case, possessing
several low-complexity approximations widely investigated. However, 16-point
DCT transform has energy compaction advantages. In this sense, this paper
presents a new 16-point DCT approximation with null multiplicative complexity.
The proposed transform matrix is orthogonal and contains only zeros and ones.
The proposed transform outperforms the well-know Walsh-Hadamard transform and
the current state-of-the-art 16-point approximation. A fast algorithm for the
proposed transform is also introduced. This fast algorithm is experimentally
validated using hardware implementations that are physically realized and
verified on a 40 nm CMOS Xilinx Virtex-6 XC6VLX240T FPGA chip for a maximum
clock rate of 342 MHz. Rapid prototypes on FPGA for 8-bit input word size shows
significant improvement in compressed image quality by up to 1-2 dB at the cost
of only eight adders compared to the state-of-art 16-point DCT approximation
algorithm in the literature [S. Bouguezel, M. O. Ahmad, and M. N. S. Swamy. A
novel transform for image compression. In {\em Proceedings of the 53rd IEEE
International Midwest Symposium on Circuits and Systems (MWSCAS)}, 2010].
"
1202,"Generating Multiple Diverse Hypotheses for Human 3D Pose Consistent with
  2D Joint Detections","  We propose a method to generate multiple diverse and valid human pose
hypotheses in 3D all consistent with the 2D detection of joints in a monocular
RGB image. We use a novel generative model uniform (unbiased) in the space of
anatomically plausible 3D poses. Our model is compositional (produces a pose by
combining parts) and since it is restricted only by anatomical constraints it
can generalize to every plausible human 3D pose. Removing the model bias
intrinsically helps to generate more diverse 3D pose hypotheses. We argue that
generating multiple pose hypotheses is more reasonable than generating only a
single 3D pose based on the 2D joint detection given the depth ambiguity and
the uncertainty due to occlusion and imperfect 2D joint detection. We hope that
the idea of generating multiple consistent pose hypotheses can give rise to a
new line of future work that has not received much attention in the literature.
We used the Human3.6M dataset for empirical evaluation.
"
1203,"Content-Based Video Retrieval in Historical Collections of the German
  Broadcasting Archive","  The German Broadcasting Archive (DRA) maintains the cultural heritage of
radio and television broadcasts of the former German Democratic Republic (GDR).
The uniqueness and importance of the video material stimulates a large
scientific interest in the video content. In this paper, we present an
automatic video analysis and retrieval system for searching in historical
collections of GDR television recordings. It consists of video analysis
algorithms for shot boundary detection, concept classification, person
recognition, text recognition and similarity search. The performance of the
system is evaluated from a technical and an archival perspective on 2,500 hours
of GDR television recordings.
"
1204,"Perceptual Compressive Sensing based on Contrast Sensitivity Function:
  Can we avoid non-visible redundancies acquisition?","  In this paper, we propose a novel CS approach in which the acquisition of
non-visible information is also avoided.
"
1205,From Photo Streams to Evolving Situations,"  Photos are becoming spontaneous, objective, and universal sources of
information. This paper develops evolving situation recognition using photo
streams coming from disparate sources combined with the advances of deep
learning. Using visual concepts in photos together with space and time
information, we formulate the situation detection into a semi-supervised
learning framework and propose new graph-based models to solve the problem. To
extend the method for unknown situations, we introduce a soft label method
which enables the traditional semi-supervised learning framework to accurately
predict predefined labels as well as effectively form new clusters. To overcome
the noisy data which degrades graph quality, leading to poor recognition
results, we take advantage of two kinds of noise-robust norms which can
eliminate the adverse effects of outliers in visual concepts and improve the
accuracy of situation recognition. Finally, we demonstrate the idea and the
effectiveness of the proposed model on Yahoo Flickr Creative Commons 100
Million.
"
1206,I Ate This: A Photo-based Food Journaling System with Expert Feedback,"  What we eat is one of the most frequent and important health decisions we
make in daily life, yet it remains notoriously difficult to capture and
understand. Effective food journaling is thus a grand challenge in personal
health informatics. In this paper we describe a system for food journaling
called I Ate This, which is inspired by the Remote Food Photography Method
(RFPM). I Ate This is simple: you use a smartphone app to take a photo and give
a very basic description of any food or beverage you are about to consume.
Later, a qualified dietitian will evaluate your photo, giving you feedback on
how you did and where you can improve. The aim of I Ate This is to provide a
convenient, visual and reliable way to help users learn from their eating
habits and nudge them towards better choices each and every day. Ultimately,
this incremental approach can lead to long-term behaviour change. Our goal is
to bring RFPM to a wider audience, through APIs that can be incorporated into
other apps.
"
1207,Developing a comprehensive framework for multimodal feature extraction,"  Feature extraction is a critical component of many applied data science
workflows. In recent years, rapid advances in artificial intelligence and
machine learning have led to an explosion of feature extraction tools and
services that allow data scientists to cheaply and effectively annotate their
data along a vast array of dimensions---ranging from detecting faces in images
to analyzing the sentiment expressed in coherent text. Unfortunately, the
proliferation of powerful feature extraction services has been mirrored by a
corresponding expansion in the number of distinct interfaces to feature
extraction services. In a world where nearly every new service has its own API,
documentation, and/or client library, data scientists who need to combine
diverse features obtained from multiple sources are often forced to write and
maintain ever more elaborate feature extraction pipelines. To address this
challenge, we introduce a new open-source framework for comprehensive
multimodal feature extraction. Pliers is an open-source Python package that
supports standardized annotation of diverse data types (video, images, audio,
and text), and is expressly with both ease-of-use and extensibility in mind.
Users can apply a wide range of pre-existing feature extraction tools to their
data in just a few lines of Python code, and can also easily add their own
custom extractors by writing modular classes. A graph-based API enables rapid
development of complex feature extraction pipelines that output results in a
single, standardized format. We describe the package's architecture, detail its
major advantages over previous feature extraction toolboxes, and use a sample
application to a large functional MRI dataset to illustrate how pliers can
significantly reduce the time and effort required to construct sophisticated
feature extraction workflows while increasing code clarity and maintainability.
"
1208,"Learning to Generate Posters of Scientific Papers by Probabilistic
  Graphical Models","  Researchers often summarize their work in the form of scientific posters.
Posters provide a coherent and efficient way to convey core ideas expressed in
scientific papers. Generating a good scientific poster, however, is a complex
and time consuming cognitive task, since such posters need to be readable,
informative, and visually aesthetic. In this paper, for the first time, we
study the challenging problem of learning to generate posters from scientific
papers. To this end, a data-driven framework, that utilizes graphical models,
is proposed. Specifically, given content to display, the key elements of a good
poster, including attributes of each panel and arrangements of graphical
elements are learned and inferred from data. During the inference stage, an MAP
inference framework is employed to incorporate some design principles. In order
to bridge the gap between panel attributes and the composition within each
panel, we also propose a recursive page splitting algorithm to generate the
panel layout for a poster. To learn and validate our model, we collect and
release a new benchmark dataset, called NJU-Fudan Paper-Poster dataset, which
consists of scientific papers and corresponding posters with exhaustively
labelled panels and attributes. Qualitative and quantitative results indicate
the effectiveness of our approach.
"
1209,"Projection based advanced motion model for cubic mapping for 360-degree
  video","  This paper proposes a novel advanced motion model to handle the irregular
motion for the cubic map projection of 360-degree video. Since the irregular
motion is mainly caused by the projection from the sphere to the cube map, we
first try to project the pixels in both the current picture and reference
picture from unfolding cube back to the sphere. Then through utilizing the
characteristic that most of the motions in the sphere are uniform, we can
derive the relationship between the motion vectors of various pixels in the
unfold cube. The proposed advanced motion model is implemented in the High
Efficiency Video Coding reference software. Experimental results demonstrate
that quite obvious performance improvement can be achieved for the sequences
with obvious motions.
"
1210,An Efficient Four-Parameter Affine Motion Model for Video Coding,"  In this paper, we study a simplified affine motion model based coding
framework to overcome the limitation of translational motion model and maintain
low computational complexity. The proposed framework mainly has three key
contributions. First, we propose to reduce the number of affine motion
parameters from 6 to 4. The proposed four-parameter affine motion model can not
only handle most of the complex motions in natural videos but also save the
bits for two parameters. Second, to efficiently encode the affine motion
parameters, we propose two motion prediction modes, i.e., advanced affine
motion vector prediction combined with a gradient-based fast affine motion
estimation algorithm and affine model merge, where the latter attempts to reuse
the affine motion parameters (instead of the motion vectors) of neighboring
blocks. Third, we propose two fast affine motion compensation algorithms. One
is the one-step sub-pixel interpolation, which reduces the computations of each
interpolation. The other is the interpolation-precision-based adaptive block
size motion compensation, which performs motion compensation at the block level
rather than the pixel level to reduce the interpolation times. Our proposed
techniques have been implemented based on the state-of-the-art high efficiency
video coding standard, and the experimental results show that the proposed
techniques altogether achieve on average 11.1% and 19.3% bits saving for random
access and low delay configurations, respectively, on typical video sequences
that have rich rotation or zooming motions. Meanwhile, the computational
complexity increases of both encoder and decoder are within an acceptable
range.
"
1211,"Convolutional Neural Network-Based Block Up-sampling for Intra Frame
  Coding","  Inspired by the recent advances of image super-resolution using convolutional
neural network (CNN), we propose a CNN-based block up-sampling scheme for intra
frame coding. A block can be down-sampled before being compressed by normal
intra coding, and then up-sampled to its original resolution. Different from
previous studies on down/up-sampling-based coding, the up-sampling methods in
our scheme have been designed by training CNN instead of hand-crafted. We
explore a new CNN structure for up-sampling, which features deconvolution of
feature maps, multi-scale fusion, and residue learning, making the network both
compact and efficient. We also design different networks for the up-sampling of
luma and chroma components, respectively, where the chroma up-sampling CNN
utilizes the luma information to boost its performance. In addition, we design
a two-stage up-sampling process, the first stage being within the
block-by-block coding loop, and the second stage being performed on the entire
frame, so as to refine block boundaries. We also empirically study how to set
the coding parameters of down-sampled blocks for pursuing the frame-level
rate-distortion optimization. Our proposed scheme is implemented into the High
Efficiency Video Coding (HEVC) reference software, and a comprehensive set of
experiments have been performed to evaluate our methods. Experimental results
show that our scheme achieves significant bits saving compared with HEVC anchor
especially at low bit rates, leading to on average 5.5% BD-rate reduction on
common test sequences and on average 9.0% BD-rate reduction on ultra high
definition (UHD) test sequences.
"
1212,Regularizing Face Verification Nets For Pain Intensity Regression,"  Limited labeled data are available for the research of estimating facial
expression intensities. For instance, the ability to train deep networks for
automated pain assessment is limited by small datasets with labels of
patient-reported pain intensities. Fortunately, fine-tuning from a
data-extensive pre-trained domain, such as face verification, can alleviate
this problem. In this paper, we propose a network that fine-tunes a
state-of-the-art face verification network using a regularized regression loss
and additional data with expression labels. In this way, the expression
intensity regression task can benefit from the rich feature representations
trained on a huge amount of data for face verification. The proposed
regularized deep regressor is applied to estimate the pain expression intensity
and verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving
the state-of-the-art performance. A weighted evaluation metric is also proposed
to address the imbalance issue of different pain intensities.
"
1213,Steganalysis of 3D Objects Using Statistics of Local Feature Sets,"  3D steganalysis aims to identify subtle invisible changes produced in
graphical objects through digital watermarking or steganography. Sets of
statistical representations of 3D features, extracted from both cover and stego
3D mesh objects, are used as inputs into machine learning classifiers in order
to decide whether any information was hidden in the given graphical object.
According to previous studies, sets of local geometry features can be used to
define the differences between stego and cover-objects. The features proposed
in this paper include those representing the local object curvature, vertex
normals, the local geometry representation in the spherical coordinate system
and are considered in various combinations with others. We also analyze the
effectiveness of various 3D feature sets applied for steganalysis based on the
Pearson correlation coefficient. The classifiers proposed in this study for
discriminating the 3D stego and cover-objects include Support Vector Machine
and the Fisher Linear Discriminant ensemble. Three different watermarking and
steganographic methods are used for hiding information in the 3D objects used
for testing the performance of the proposed steganalysis methodology.
"
1214,"How Gamification Affects Physical Activity: Large-scale Analysis of
  Walking Challenges in a Mobile Application","  Gamification represents an effective way to incentivize user behavior across
a number of computing applications. However, despite the fact that physical
activity is essential for a healthy lifestyle, surprisingly little is known
about how gamification and in particular competitions shape human physical
activity. Here we study how competitions affect physical activity. We focus on
walking challenges in a mobile activity tracking application where multiple
users compete over who takes the most steps over a predefined number of days.
We synthesize our findings in a series of game and app design implications. In
particular, we analyze nearly 2,500 physical activity competitions over a
period of one year capturing more than 800,000 person days of activity
tracking. We observe that during walking competitions, the average user
increases physical activity by 23%. Furthermore, there are large increases in
activity for both men and women across all ages, and weight status, and even
for users that were previously fairly inactive. We also find that the
composition of participants greatly affects the dynamics of the game. In
particular, if highly unequal participants get matched to each other, then
competition suffers and the overall effect on the physical activity drops
significantly. Furthermore, competitions with an equal mix of both men and
women are more effective in increasing the level of activities. We leverage
these insights to develop a statistical model to predict whether or not a
competition will be particularly engaging with significant accuracy. Our models
can serve as a guideline to help design more engaging competitions that lead to
most beneficial behavioral changes.
"
1215,Software Defined Media: Virtualization of Audio-Visual Services,"  Internet-native audio-visual services are witnessing rapid development. Among
these services, object-based audio-visual services are gaining importance. In
2014, we established the Software Defined Media (SDM) consortium to target new
research areas and markets involving object-based digital media and
Internet-by-design audio-visual environments. In this paper, we introduce the
SDM architecture that virtualizes networked audio-visual services along with
the development of smart buildings and smart cities using Internet of Things
(IoT) devices and smart building facilities. Moreover, we design the SDM
architecture as a layered architecture to promote the development of innovative
applications on the basis of rapid advancements in software-defined networking
(SDN). Then, we implement a prototype system based on the architecture, present
the system at an exhibition, and provide it as an SDM API to application
developers at hackathons. Various types of applications are developed using the
API at these events. An evaluation of SDM API access shows that the prototype
SDM platform effectively provides 3D audio reproducibility and interactiveness
for SDM applications.
"
1216,"Analysis of video quality losses in the homogenous HEVC video
  transcoding","  The paper presents quantitative analysis of the video quality losses in the
homogenous HEVC video transcoder. With the use of HM15.0 reference software and
a set of test video sequences, cascaded pixel domain video transcoder (CPDT)
concept has been used to gather all the necessary data needed for the analysis.
This experiment was done for wide range of source and target bitrates. The
essential result of the work is extensive evaluation of CPDT, commonly used as
a reference in works on effective video transcoding. Until now no such
extensively performed study have been made available in the literature. Quality
degradation between transcoded video and the video that would be result of
direct compression of the original video at the same bitrate as the transcoded
one have been reported. The dependency between quality degradation caused by
transcoding and the bitrate changes of the transcoded data stream are clearly
presented on graphs.
"
1217,"Understanding Performance of Edge Content Caching for Mobile Video
  Streaming","  Today's Internet has witnessed an increase in the popularity of mobile video
streaming, which is expected to exceed 3/4 of the global mobile data traffic by
2019. To satisfy the considerable amount of mobile video requests, video
service providers have been pushing their content delivery infrastructure to
edge networks--from regional CDN servers to peer CDN servers (e.g.,
smartrouters in users' homes)--to cache content and serve users with storage
and network resources nearby. Among the edge network content caching paradigms,
Wi-Fi access point caching and cellular base station caching have become two
mainstream solutions. Thus, understanding the effectiveness and performance of
these solutions for large-scale mobile video delivery is important. However,
the characteristics and request patterns of mobile video streaming are unclear
in practical wireless network. In this paper, we use real-world datasets
containing 50 million trace items of nearly 2 million users viewing more than
0.3 million unique videos using mobile devices in a metropolis in China over 2
weeks, not only to understand the request patterns and user behaviors in mobile
video streaming, but also to evaluate the effectiveness of Wi-Fi and
cellular-based edge content caching solutions. To understand performance of
edge content caching for mobile video streaming, we first present temporal and
spatial video request patterns, and we analyze their impacts on caching
performance using frequency-domain and entropy analysis approaches. We then
study the behaviors of mobile video users, including their mobility and
geographical migration behaviors. Using trace-driven experiments, we compare
strategies for edge content caching including LRU and LFU, in terms of
supporting mobile video requests. Moreover, we design an efficient caching
strategy based on the measurement insights and experimentally evaluate its
performance.
"
1218,A Data-driven Approach for Furniture and Indoor Scene Colorization,"  We present a data-driven approach that colorizes 3D furniture models and
indoor scenes by leveraging indoor images on the internet. Our approach is able
to colorize the furniture automatically according to an example image. The core
is to learn image-guided mesh segmentation to segment the model into different
parts according to the image object. Given an indoor scene, the system supports
colorization-by-example, and has the ability to recommend the colorization
scheme that is consistent with a user-desired color theme. The latter is
realized by formulating the problem as a Markov random field model that imposes
user input as an additional constraint. We contribute to the community a
hierarchically organized image-model database with correspondences between each
image and the corresponding model at the part-level. Our experiments and a user
study show that our system produces perceptually convincing results comparable
to those generated by interior designers.
"
1219,Video transrating in AVC and HEVC transcoding,"  HEVC (MPEG-H Part 2 and H.265) is a new coding technology which is expected
to be deployed on the market along with new video services in the near future.
HEVC is a successor of currently widely used AVC (MPEG-4 Part 10 and H.264). In
this paper, the quality coding gains obtained for the Cascaded Pixel Domain
Transcoder of AVC-coded material to HEVC standard are reported. Extensive
experiments showed that transcoding with bitrate reduction allows the
achievement of better rate-distortion performance than by compressing an
original video sequence with the use of AVC at the same (reduced) bitrate.
"
1220,"Second Screen User Profiling and Multi-level Smart Recommendations in
  the context of Social TVs","  In the context of Social TV, the increasing popularity of first and second
screen users, interacting and posting content online, illustrates new business
opportunities and related technical challenges, in order to enrich user
experience on such environments. SAM (Socializing Around Media) project uses
Social Media-connected infrastructure to deal with the aforementioned
challenges, providing intelligent user context management models and mechanisms
capturing social patterns, to apply collaborative filtering techniques and
personalized recommendations towards this direction. This paper presents the
Context Management mechanism of SAM, running in a Social TV environment to
provide smart recommendations for first and second screen content. Work
presented is evaluated using real movie rating dataset found online, to
validate the SAM's approach in terms of effectiveness as well as efficiency.
"
1221,Generating Steganographic Images via Adversarial Training,"  Adversarial training was recently shown to be competitive against supervised
learning methods on computer vision tasks, however, studies have mainly been
confined to generative tasks such as image synthesis. In this paper, we apply
adversarial training techniques to the discriminative task of learning a
steganographic algorithm. Steganography is a collection of techniques for
concealing information by embedding it within a non-secret medium, such as
cover texts or images. We show that adversarial training can produce robust
steganographic techniques: our unsupervised training scheme produces a
steganographic algorithm that competes with state-of-the-art steganographic
techniques, and produces a robust steganalyzer, which performs the
discriminative task of deciding if an image contains secret information. We
define a game between three parties, Alice, Bob and Eve, in order to
simultaneously train both a steganographic algorithm and a steganalyzer. Alice
and Bob attempt to communicate a secret message contained within an image,
while Eve eavesdrops on their conversation and attempts to determine if secret
information is embedded within the image. We represent Alice, Bob and Eve by
neural networks, and validate our scheme on two independent image datasets,
showing our novel method of studying steganographic problems is surprisingly
competitive against established steganographic techniques.
"
1222,"Identification of image source using serialnumber-based watermarking
  under Compressive Sensing conditions","  Although the protection of ownership and the prevention of unauthorized
manipulation of digital images becomes an important concern, there is also a
big issue of image source origin authentication. This paper proposes a
procedure for the identification of the image source and content by using the
Public Key Cryptography Signature (PKCS). The procedure is based on the PKCS
watermarking of the images captured with numerous automatic observing cameras
in the Trap View cloud system. Watermark is created based on 32-bit PKCS serial
number and embedded into the captured image. Watermark detection on the
receiver side extracts the serial number and indicates the camera which
captured the image by comparing the original and the extracted serial numbers.
The watermarking procedure is designed to provide robustness to image
optimization based on the Compressive Sensing approach. Also, the procedure is
tested under various attacks and shows successful identification of ownership.
"
1223,"Learning to Predict Streaming Video QoE: Distortions, Rebuffering and
  Memory","  Mobile streaming video data accounts for a large and increasing percentage of
wireless network traffic. The available bandwidths of modern wireless networks
are often unstable, leading to difficulties in delivering smooth, high-quality
video. Streaming service providers such as Netflix and YouTube attempt to adapt
their systems to adjust in response to these bandwidth limitations by changing
the video bitrate or, failing that, allowing playback interruptions
(rebuffering). Being able to predict end user' quality of experience (QoE)
resulting from these adjustments could lead to perceptually-driven network
resource allocation strategies that would deliver streaming content of higher
quality to clients, while being cost effective for providers. Existing
objective QoE models only consider the effects on user QoE of video quality
changes or playback interruptions. For streaming applications, adaptive network
strategies may involve a combination of dynamic bitrate allocation along with
playback interruptions when the available bandwidth reaches a very low value.
Towards effectively predicting user QoE, we propose Video Assessment of
TemporaL Artifacts and Stalls (Video ATLAS): a machine learning framework where
we combine a number of QoE-related features, including objective quality
features, rebuffering-aware features and memory-driven features to make QoE
predictions. We evaluated our learning-based QoE prediction model on the
recently designed LIVE-Netflix Video QoE Database which consists of practical
playout patterns, where the videos are afflicted by both quality changes and
rebuffering events, and found that it provides improved performance over
state-of-the-art video quality metrics while generalizing well on different
datasets. The proposed algorithm is made publicly available at
http://live.ece.utexas.edu/research/Quality/VideoATLAS release_v2.rar.
"
1224,Unsupervised Steganalysis Based on Artificial Training Sets,"  In this paper, an unsupervised steganalysis method that combines artificial
training setsand supervised classification is proposed. We provide a formal
framework for unsupervisedclassification of stego and cover images in the
typical situation of targeted steganalysis (i.e.,for a known algorithm and
approximate embedding bit rate). We also present a completeset of experiments
using 1) eight different image databases, 2) image features based on
RichModels, and 3) three different embedding algorithms: Least Significant Bit
(LSB) matching,Highly undetectable steganography (HUGO) and Wavelet Obtained
Weights (WOW). Weshow that the experimental results outperform previous methods
based on Rich Models inthe majority of the tested cases. At the same time, the
proposed approach bypasses theproblem of Cover Source Mismatch -when the
embedding algorithm and bit rate are known-, since it removes the need of a
training database when we have a large enough testing set.Furthermore, we
provide a generic proof of the proposed framework in the machine
learningcontext. Hence, the results of this paper could be extended to other
classification problemssimilar to steganalysis.
"
1225,"LSB Matching Steganalysis Based on Patterns of Pixel Differences and
  Random Embedding","  This paper presents a novel method for detection of LSB matching steganogra-
phy in grayscale images. This method is based on the analysis of the
differences between neighboring pixels before and after random data embedding.
In natu- ral images, there is a strong correlation between adjacent pixels.
This correla- tion is disturbed by LSB matching generating new types of
correlations. The pre- sented method generates patterns from these correlations
and analyzes their varia- tion when random data are hidden. The experiments
performed for two different image databases show that the method yields better
classification accuracy com- pared to prior art for both LSB matching and HUGO
steganography. In addition, although the method is designed for the spatial
domain, some experiments show its applicability also for detecting JPEG
steganography.
"
1226,Depth Estimation using Modified Cost Function for Occlusion Handling,"  The paper presents a novel approach to occlusion handling problem in depth
estimation using three views. A solution based on modification of similarity
cost function is proposed. During the depth estimation via optimization
algorithms like Graph Cut similarity metric is constantly updated so that only
non-occluded fragments in side views are considered. At each iteration of the
algorithm non-occluded fragments are detected based on side view virtual depth
maps synthesized from the best currently estimated depth map of the center
view. Then similarity metric is updated for correspondence search only in
non-occluded regions of the side views. The experimental results, conducted on
well-known 3D video test sequences, have proved that the depth maps estimated
with the proposed approach provide about 1.25 dB virtual view quality
improvement in comparison to the virtual view synthesized based on depth maps
generated by the state-of-the-art MPEG Depth Estimation Reference Software.
"
1227,A Survey on Content-Aware Video Analysis for Sports,"  Sports data analysis is becoming increasingly large-scale, diversified, and
shared, but difficulty persists in rapidly accessing the most crucial
information. Previous surveys have focused on the methodologies of sports video
analysis from the spatiotemporal viewpoint instead of a content-based
viewpoint, and few of these studies have considered semantics. This study
develops a deeper interpretation of content-aware sports video analysis by
examining the insight offered by research into the structure of content under
different scenarios. On the basis of this insight, we provide an overview of
the themes particularly relevant to the research on content-aware systems for
broadcast sports. Specifically, we focus on the video content analysis
techniques applied in sportscasts over the past decade from the perspectives of
fundamentals and general review, a content hierarchical model, and trends and
challenges. Content-aware analysis methods are discussed with respect to
object-, event-, and context-oriented groups. In each group, the gap between
sensation and content excitement must be bridged using proper strategies. In
this regard, a content-aware approach is required to determine user demands.
Finally, the paper summarizes the future trends and challenges for sports video
analysis. We believe that our findings can advance the field of research on
content-aware video analysis for broadcast sports.
"
1228,On The Automated Planning And Design Of SMATV Systems,"  The paper presents some theoretical and practical considerations regarding
the TV information distribution in local (small and medium) networks, using
different technologies and architectures. The SMATV concept is chosen to be
presented extensively. The most important design formulae are presented with a
software package supporting the network planner to design and optimize the
network. A case study is realized, using standard components in SMATV, for a 5
floor building. The study proved that it is possible to design and optimize the
entire network, without realizing first a costly experimental setup. It is also
possible to run different architectures, optimizing also the costs of the final
solution of network.
"
1229,"Sample-level Deep Convolutional Neural Networks for Music Auto-tagging
  Using Raw Waveforms","  Recently, the end-to-end approach that learns hierarchical representations
from raw data using deep convolutional neural networks has been successfully
explored in the image, text and speech domains. This approach was applied to
musical signals as well but has been not fully explored yet. To this end, we
propose sample-level deep convolutional neural networks which learn
representations from very small grains of waveforms (e.g. 2 or 3 samples)
beyond typical frame-level input representations. Our experiments show how deep
architectures with sample-level filters improve the accuracy in music
auto-tagging and they provide results comparable to previous state-of-the-art
performances for the Magnatagatune dataset and Million Song Dataset. In
addition, we visualize filters learned in a sample-level DCNN in each layer to
identify hierarchically learned features and show that they are sensitive to
log-scaled frequency along layer, such as mel-frequency spectrogram that is
widely used in music classification systems.
"
1230,"Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained
  Convolutional Neural Networks for Music Auto-tagging","  Music auto-tagging is often handled in a similar manner to image
classification by regarding the 2D audio spectrogram as image data. However,
music auto-tagging is distinguished from image classification in that the tags
are highly diverse and have different levels of abstractions. Considering this
issue, we propose a convolutional neural networks (CNN)-based architecture that
embraces multi-level and multi-scaled features. The architecture is trained in
three steps. First, we conduct supervised feature learning to capture local
audio features using a set of CNNs with different input sizes. Second, we
extract audio features from each layer of the pre-trained convolutional
networks separately and aggregate them altogether given a long audio clip.
Finally, we put them into fully-connected networks and make final predictions
of the tags. Our experiments show that using the combination of multi-level and
multi-scale features is highly effective in music auto-tagging and the proposed
method outperforms previous state-of-the-arts on the MagnaTagATune dataset and
the Million Song Dataset. We further show that the proposed architecture is
useful in transfer learning.
"
1231,"PSUM:Peer-to-peer multimedia content distribution using
  collusion-resistant fingerprinting","  The use of peer-to-peer (P2P) networks for multimedia distribution has spread
out globally in recent years. The mass popularity is primarily driven by
cost-effective distribution of content, also giving rise to piracy. An end user
(buyer/peer) of a P2P content distribution system does not want to reveal
his/her identity during a transaction with a content owner (merchant), whereas
the merchant does not want the buyer to further distribute the content
illegally. To date, different P2P distribution systems have been proposed that
provide copyright and privacy protection at a cost of high computational burden
at the merchants and/or at the buyer's end and thus, making these systems
impractical. In this paper, we propose PSUM, a P2P content distribution system
which allows efficient distribution of large-sized multimedia content while
preserving the security and privacy of merchants and buyers. The security of
PSUM is ensured by using an asymmetric fingerprinting protocol based on
collusion-resistant codes. In addition, PSUM enables buyers to obtain digital
contents anonymously, but this anonymity can be revoked as soon as he/she is
found guilty of copyright violation. The paper presents a thorough performance
analysis of PSUM, through different experiments and simulations, and also
analyzes several security compromising attacks and countermeasures.
"
1232,"Learning from Experience: A Dynamic Closed-Loop QoE Optimization for
  Video Adaptation and Delivery","  The quality of experience (QoE) is known to be subjective and
context-dependent. Identifying and calculating the factors that affect QoE is
indeed a difficult task. Recently, a lot of effort has been devoted to estimate
the users QoE in order to improve video delivery. In the literature, most of
the QoE-driven optimization schemes that realize trade-offs among different
quality metrics have been addressed under the assumption of homogenous
populations. Nevertheless, people perceptions on a given video quality may not
be the same, which makes the QoE optimization harder. This paper aims at taking
a step further in order to address this limitation and meet users profiles. To
do so, we propose a closed-loop control framework based on the
users(subjective) feedbacks to learn the QoE function and optimize it at the
same time. Our simulation results show that our system converges to a steady
state, where the resulting QoE function noticeably improves the users
feedbacks.
"
1233,PathTrack: Fast Trajectory Annotation with Path Supervision,"  Progress in Multiple Object Tracking (MOT) has been historically limited by
the size of the available datasets. We present an efficient framework to
annotate trajectories and use it to produce a MOT dataset of unprecedented
size. In our novel path supervision the annotator loosely follows the object
with the cursor while watching the video, providing a path annotation for each
object in the sequence. Our approach is able to turn such weak annotations into
dense box trajectories. Our experiments on existing datasets prove that our
framework produces more accurate annotations than the state of the art, in a
fraction of the time. We further validate our approach by crowdsourcing the
PathTrack dataset, with more than 15,000 person trajectories in 720 sequences.
Tracking approaches can benefit training on such large-scale datasets, as did
object recognition. We prove this by re-training an off-the-shelf person
matching network, originally trained on the MOT15 dataset, almost halving the
misclassification rate. Additionally, training on our data consistently
improves tracking results, both on our dataset and on MOT15. On the latter, we
improve the top-performing tracker (NOMT) dropping the number of IDSwitches by
18% and fragments by 5%.
"
1234,Optimal Network-Assisted Multi-user DASH Video Streaming,"  Streaming video is becoming the predominant type of traffic over the Internet
with reports forecasting the video content to account for 80% of all traffic by
2019. With significant investment on Internet backbone, the main bottleneck
remains at the edge servers (e.g., WiFi access points, small cells, etc.). In
this work, we propose and prove the optimality of a multiuser resource
allocation mechanism operating at the edge server that minimizes the
probability of stalling of video streams due to buffer under-flows. Our
proposed policy utilizes Media Presentation Description (MPD) files of clients
that are sent in compliant to Dynamic Adaptive Streaming over HTTP (DASH)
protocol to be cognizant of the deadlines of each of the media file to be
displayed by the clients. Then, the policy schedules the users in the order of
their deadlines. After establishing the optimality of this policy to minimize
the stalling probability for a network with links associated with fixed loss
rates, the utility of the algorithm is verified under realistic network
conditions with detailed NS-3 simulations.
"
1235,"A Convolutional Neural Network Approach for Half-Pel Interpolation in
  Video Coding","  Motion compensation is a fundamental technology in video coding to remove the
temporal redundancy between video frames. To further improve the coding
efficiency, sub-pel motion compensation has been utilized, which requires
interpolation of fractional samples. The video coding standards usually adopt
fixed interpolation filters that are derived from the signal processing theory.
However, as video signal is not stationary, the fixed interpolation filters may
turn out less efficient. Inspired by the great success of convolutional neural
network (CNN) in computer vision, we propose to design a CNN-based
interpolation filter (CNNIF) for video coding. Different from previous studies,
one difficulty for training CNNIF is the lack of ground-truth since the
fractional samples are actually not available. Our solution for this problem is
to derive the ""ground-truth"" of fractional samples by smoothing high-resolution
images, which is verified to be effective by the conducted experiments.
Compared to the fixed half-pel interpolation filter for luma in High Efficiency
Video Coding (HEVC), our proposed CNNIF achieves up to 3.2% and on average 0.9%
BD-rate reduction under low-delay P configuration.
"
1236,"Towards Wi-Fi AP-Assisted Content Prefetching for On-Demand TV Series: A
  Reinforcement Learning Approach","  The emergence of smart Wi-Fi APs (Access Point), which are equipped with huge
storage space, opens a new research area on how to utilize these resources at
the edge network to improve users' quality of experience (QoE) (e.g., a short
startup delay and smooth playback). One important research interest in this
area is content prefetching, which predicts and accurately fetches contents
ahead of users' requests to shift the traffic away during peak periods.
However, in practice, the different video watching patterns among users, and
the varying network connection status lead to the time-varying server load,
which eventually makes the content prefetching problem challenging. To
understand this challenge, this paper first performs a large-scale measurement
study on users' AP connection and TV series watching patterns using
real-traces. Then, based on the obtained insights, we formulate the content
prefetching problem as a Markov Decision Process (MDP). The objective is to
strike a balance between the increased prefetching&storage cost incurred by
incorrect prediction and the reduced content download delay because of
successful prediction. A learning-based approach is proposed to solve this
problem and another three algorithms are adopted as baselines. In particular,
first, we investigate the performance lower bound by using a random algorithm,
and the upper bound by using an ideal offline approach. Then, we present a
heuristic algorithm as another baseline. Finally, we design a reinforcement
learning algorithm that is more practical to work in the online manner. Through
extensive trace-based experiments, we demonstrate the performance gain of our
design. Remarkably, our learning-based algorithm achieves a better precision
and hit ratio (e.g., 80%) with about 70% (resp. 50%) cost saving compared to
the random (resp. heuristic) algorithm.
"
1237,Causes of discomfort in stereoscopic content: a review,"  This paper reviews the causes of discomfort in viewing stereoscopic content.
These include objective factors, such as misaligned images, as well as
subjective factors, such as excessive disparity. Different approaches to the
measurement of visual discomfort are also reviewed, in relation to the
underlying physiological and psychophysical processes. The importance of
understanding these issues, in the context of new display technologies, is
emphasized.
"
1238,"Refining Image Categorization by Exploiting Web Images and General
  Corpus","  Studies show that refining real-world categories into semantic subcategories
contributes to better image modeling and classification. Previous image
sub-categorization work relying on labeled images and WordNet's hierarchy is
not only labor-intensive, but also restricted to classify images into NOUN
subcategories. To tackle these problems, in this work, we exploit general
corpus information to automatically select and subsequently classify web images
into semantic rich (sub-)categories. The following two major challenges are
well studied: 1) noise in the labels of subcategories derived from the general
corpus; 2) noise in the labels of images retrieved from the web. Specifically,
we first obtain the semantic refinement subcategories from the text perspective
and remove the noise by the relevance-based approach. To suppress the search
error induced noisy images, we then formulate image selection and classifier
learning as a multi-class multi-instance learning problem and propose to solve
the employed problem by the cutting-plane algorithm. The experiments show
significant performance gains by using the generated data of our way on both
image categorization and sub-categorization tasks. The proposed approach also
consistently outperforms existing weakly supervised and web-supervised
approaches.
"
1239,Steganographic Generative Adversarial Networks,"  Steganography is collection of methods to hide secret information (""payload"")
within non-secret information ""container""). Its counterpart, Steganalysis, is
the practice of determining if a message contains a hidden payload, and
recovering it if possible. Presence of hidden payloads is typically detected by
a binary classifier. In the present study, we propose a new model for
generating image-like containers based on Deep Convolutional Generative
Adversarial Networks (DCGAN). This approach allows to generate more
setganalysis-secure message embedding using standard steganography algorithms.
Experiment results demonstrate that the new model successfully deceives the
steganography analyzer, and for this reason, can be used in steganographic
applications.
"
1240,"Medical Image Watermarking using 2D-DWT with Enhanced security and
  capacity","  Teleradiology enables medical images to be transferred over the computer
networks for many purposes including clinical interpretation, diagnosis,
archive, etc. In telemedicine, medical images can be manipulated while
transferring. In addition, medical information security requirements are
specified by the legislative rules, and concerned entities must adhere to them.
In this research, we propose a new scheme based on 2-dimensional Discrete
Wavelet Transform (2D DWT) to improve the robustness and authentication of
medical images. In addition, the current research improves security and
capacity of watermarking using encryption and compression in medical images.
The evaluation is performed on the personal dataset, which contains 194 CTI and
68 MRI cases.
"
1241,Image denoising by median filter in wavelet domain,"  The details of an image with noise may be restored by removing noise through
a suitable image de-noising method. In this research, a new method of image
de-noising based on using median filter (MF) in the wavelet domain is proposed
and tested. Various types of wavelet transform filters are used in conjunction
with median filter in experimenting with the proposed approach in order to
obtain better results for image de-noising process, and, consequently to select
the best suited filter. Wavelet transform working on the frequencies of
sub-bands split from an image is a powerful method for analysis of images.
According to this experimental work, the proposed method presents better
results than using only wavelet transform or median filter alone. The MSE and
PSNR values are used for measuring the improvement in de-noised images.
"
1242,Dance Dance Convolution,"  Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players
perform steps on a dance platform in synchronization with music as directed by
on-screen step charts. While many step charts are available in standardized
packs, players may grow tired of existing charts, or wish to dance to a song
for which no chart exists. We introduce the task of learning to choreograph.
Given a raw audio track, the goal is to produce a new step chart. This task
decomposes naturally into two subtasks: deciding when to place steps and
deciding which steps to select. For the step placement task, we combine
recurrent and convolutional neural networks to ingest spectrograms of low-level
audio features to predict steps, conditioned on chart difficulty. For step
selection, we present a conditional LSTM generative model that substantially
outperforms n-gram and fixed-window approaches.
"
1243,Learning Correspondence Structures for Person Re-identification,"  This paper addresses the problem of handling spatial misalignments due to
camera-view changes or human-pose variations in person re-identification. We
first introduce a boosting-based approach to learn a correspondence structure
which indicates the patch-wise matching probabilities between images from a
target camera pair. The learned correspondence structure can not only capture
the spatial correspondence pattern between cameras but also handle the
viewpoint or human-pose variation in individual images. We further introduce a
global constraint-based matching process. It integrates a global matching
constraint over the learned correspondence structure to exclude cross-view
misalignments during the image patch matching process, hence achieving a more
reliable matching score between images. Finally, we also extend our approach by
introducing a multi-structure scheme, which learns a set of local
correspondence structures to capture the spatial correspondence sub-patterns
between a camera pair, so as to handle the spatial misalignments between
individual images in a more precise way. Experimental results on various
datasets demonstrate the effectiveness of our approach.
"
1244,Changing Fashion Cultures,"  The paper presents a novel concept that analyzes and visualizes worldwide
fashion trends. Our goal is to reveal cutting-edge fashion trends without
displaying an ordinary fashion style. To achieve the fashion-based analysis, we
created a new fashion culture database (FCDB), which consists of 76 million
geo-tagged images in 16 cosmopolitan cities. By grasping a fashion trend of
mixed fashion styles,the paper also proposes an unsupervised fashion trend
descriptor (FTD) using a fashion descriptor, a codeword vetor, and temporal
analysis. To unveil fashion trends in the FCDB, the temporal analysis in FTD
effectively emphasizes consecutive features between two different times. In
experiments, we clearly show the analysis of fashion trends and fashion-based
city similarity. As the result of large-scale data collection and an
unsupervised analyzer, the proposed approach achieves world-level fashion
visualization in a time series. The code, model, and FCDB will be publicly
available after the construction of the project page.
"
1245,"Video Streaming in Distributed Erasure-coded Storage Systems: Stall
  Duration Analysis","  The demand for global video has been burgeoning across industries. With the
expansion and improvement of video-streaming services, cloud-based video is
evolving into a necessary feature of any successful business for reaching
internal and external audiences. This paper considers video streaming over
distributed systems where the video segments are encoded using an erasure code
for better reliability thus being the first work to our best knowledge that
considers video streaming over erasure-coded distributed cloud systems. The
download time of each coded chunk of each video segment is characterized and
ordered statistics over the choice of the erasure-coded chunks is used to
obtain the playback time of different video segments. Using the playback times,
bounds on the moment generating function on the stall duration is used to bound
the mean stall duration. Moment generating function based bounds on the ordered
statistics are also used to bound the stall duration tail probability which
determines the probability that the stall time is greater than a pre-defined
number. These two metrics, mean stall duration and the stall duration tail
probability, are important quality of experience (QoE) measures for the end
users. Based on these metrics, we formulate an optimization problem to jointly
minimize the convex combination of both the QoE metrics averaged over all
requests over the placement and access of the video content. The non-convex
problem is solved using an efficient iterative algorithm. Numerical results
show significant improvement in QoE metrics for cloud-based video as compared
to the considered baselines.
"
1246,"Smart Spaces: Challenges and Opportunities of BLE-Centered Mobile
  Systems for Public Environments","  The application of mobile computing is currently altering patterns of our
behavior to a greater degree than perhaps any other invention. In combination
with the introduction of BLE (Bluetooth Low Energy) and similar technologies
enabling context-awareness, designers are today finding themselves empowered to
build experiences and facilitate interactions with our physical surroundings in
ways not possible before. The aim of this thesis is to present a research
project, currently underway at the University of Cambridge, which is dealing
with implementation of a BLE system into a museum environment. By assessing the
technology, describing the design decisions as well as presenting a qualitative
evaluation, this paper seeks to provide insight into some of the challenges and
possible solutions connected to the process of developing ubiquitous BLE
computing systems for public spaces. The project outcome revealed the potential
use of BLE to engage whole new groups of audiences as well as made me argue in
favor of a more seamful approach to the design of these systems.
"
1247,Multi-Stream Switching for Interactive Virtual Reality Video Streaming,"  Virtual reality (VR) video provides an immersive 360 viewing experience to a
user wearing a head-mounted display: as the user rotates his head,
correspondingly different fields-of-view (FoV) of the 360 video are rendered
for observation. Transmitting the entire 360 video in high quality over
bandwidth-constrained networks from server to client for real-time playback is
challenging. In this paper we propose a multi-stream switching framework for VR
video streaming: the server pre-encodes a set of VR video streams covering
different view ranges that account for server-client round trip time (RTT)
delay, and during streaming the server transmits and switches streams according
to a user's detected head rotation angle. For a given RTT, we formulate an
optimization to seek multiple VR streams of different view ranges and the
head-angle-to-stream mapping function simultaneously, in order to minimize the
expected distortion subject to bandwidth and storage constraints. We propose an
alternating algorithm that, at each iteration, computes the optimal streams
while keeping the mapping function fixed and vice versa. Experiments show that
for the same bandwidth, our multi-stream switching scheme outperforms a
non-switching single-stream approach by up to 2.9dB in PSNR.
"
1248,"Theoretical Evaluation of Li et al.'s Approach for Improving a Binary
  Watermark-Based Scheme in Remote Sensing Data Communications","  This letter is about a principal weakness of the published article by Li et
al. in 2014. It seems that the mentioned work has a terrible conceptual mistake
while presenting its theoretical approach. In fact, the work has tried to
design a new attack and its effective solution for a basic watermarking
algorithm by Zhu et al. published in 2013, however in practice, we show the Li
et al.'s approach is not correct to obtain the aim. For disproof of the
incorrect approach, we only apply a numerical example as the counterexample of
the Li et al.'s approach.
"
1249,Transfer learning for music classification and regression tasks,"  In this paper, we present a transfer learning approach for music
classification and regression tasks. We propose to use a pre-trained convnet
feature, a concatenated feature vector using the activations of feature maps of
multiple layers in a trained convolutional network. We show how this convnet
feature can serve as general-purpose music representation. In the experiments,
a convnet is trained for music tagging and then transferred to other
music-related classification and regression tasks. The convnet feature
outperforms the baseline MFCC feature in all the considered tasks and several
previous approaches that are aggregating MFCCs as well as low- and high-level
music features.
"
1250,An Evaluation of Digital Image Forgery Detection Approaches,"  With the headway of the advanced image handling software and altering tools,
a computerized picture can be effectively controlled. The identification of
image manipulation is vital in light of the fact that an image can be utilized
as legitimate confirmation, in crime scene investigation, and in numerous
different fields. The image forgery detection techniques intend to confirm the
credibility of computerized pictures with no prior information about the
original image. There are numerous routes for altering a picture, for example,
resampling, splicing, and copy-move. In this paper, we have examined different
type of image forgery and their detection techniques; mainly we focused on
pixel based image forgery detection techniques.
"
1251,"Audio-Visual Speech Enhancement Using Multimodal Deep Convolutional
  Neural Networks","  Speech enhancement (SE) aims to reduce noise in speech signals. Most SE
techniques focus only on addressing audio information. In this work, inspired
by multimodal learning, which utilizes data from different modalities, and the
recent success of convolutional neural networks (CNNs) in SE, we propose an
audio-visual deep CNNs (AVDCNN) SE model, which incorporates audio and visual
streams into a unified network model. We also propose a multi-task learning
framework for reconstructing audio and visual signals at the output layer.
Precisely speaking, the proposed AVDCNN model is structured as an audio-visual
encoder-decoder network, in which audio and visual data are first processed
using individual CNNs, and then fused into a joint network to generate enhanced
speech (the primary task) and reconstructed images (the secondary task) at the
output layer. The model is trained in an end-to-end manner, and parameters are
jointly learned through back-propagation. We evaluate enhanced speech using
five instrumental criteria. Results show that the AVDCNN model yields a notably
superior performance compared with an audio-only CNN-based SE model and two
conventional SE approaches, confirming the effectiveness of integrating visual
information into the SE process. In addition, the AVDCNN model also outperforms
an existing audio-visual SE model, confirming its capability of effectively
combining audio and visual information in SE.
"
1252,Hidden Two-Stream Convolutional Networks for Action Recognition,"  Analyzing videos of human actions involves understanding the temporal
relationships among video frames. State-of-the-art action recognition
approaches rely on traditional optical flow estimation methods to pre-compute
motion information for CNNs. Such a two-stage approach is computationally
expensive, storage demanding, and not end-to-end trainable. In this paper, we
present a novel CNN architecture that implicitly captures motion information
between adjacent frames. We name our approach hidden two-stream CNNs because it
only takes raw video frames as input and directly predicts action classes
without explicitly computing optical flow. Our end-to-end approach is 10x
faster than its two-stage baseline. Experimental results on four challenging
action recognition datasets: UCF101, HMDB51, THUMOS14 and ActivityNet v1.2 show
that our approach significantly outperforms the previous best real-time
approaches.
"
1253,"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance
  for Action Classification and Detection","  General human action recognition requires understanding of various visual
cues. In this paper, we propose a network architecture that computes and
integrates the most important visual cues for action recognition: pose, motion,
and the raw images. For the integration, we introduce a Markov chain model
which adds cues successively. The resulting approach is efficient and
applicable to action classification as well as to spatial and temporal action
localization. The two contributions clearly improve the performance over
respective baselines. The overall approach achieves state-of-the-art action
classification performance on HMDB51, J-HMDB and NTU RGB+D datasets. Moreover,
it yields state-of-the-art spatio-temporal action localization results on
UCF101 and J-HMDB.
"
1254,"Detection of Copy-move Image forgery using SVD and Cuckoo Search
  Algorithm","  Copy-move forgery is one of the simple and effective operations to create
forged images. Recently, techniques based on singular value decomposition (SVD)
are widely used to detect copy-move forgery (CMF). Some approaches based on SVD
are most acceptable to detect copy-move forgery but some copy-move forgery
detection approaches can not produce satisfactory detection results. Sometimes
these approaches may even produce error results. According to our observation,
detection result produced using SVD depend highly on those parameters whose
values are often determined with experiences. These values are only applicable
to a few images, which limit their application. To solve this problem, a novel
approach named as copy-move forgery detection using Cuckoo search algorithm
(CMFD-CS) is proposed in this paper. CMFD-CS integrates the CS algorithm into
SVD. It utilizes the CS algorithm to generate customized parameter values for
images, which are used CMFD under block-based framework.
"
1255,"CCL: Cross-modal Correlation Learning with Multi-grained Fusion by
  Hierarchical Network","  Cross-modal retrieval has become a highlighted research topic for retrieval
across multimedia data such as image and text. A two-stage learning framework
is widely adopted by most existing methods based on Deep Neural Network (DNN):
The first learning stage is to generate separate representation for each
modality, and the second learning stage is to get the cross-modal common
representation. However, the existing methods have three limitations: (1) In
the first learning stage, they only model intra-modality correlation, but
ignore inter-modality correlation with rich complementary context. (2) In the
second learning stage, they only adopt shallow networks with single-loss
regularization, but ignore the intrinsic relevance of intra-modality and
inter-modality correlation. (3) Only original instances are considered while
the complementary fine-grained clues provided by their patches are ignored. For
addressing the above problems, this paper proposes a cross-modal correlation
learning (CCL) approach with multi-grained fusion by hierarchical network, and
the contributions are as follows: (1) In the first learning stage, CCL exploits
multi-level association with joint optimization to preserve the complementary
context from intra-modality and inter-modality correlation simultaneously. (2)
In the second learning stage, a multi-task learning strategy is designed to
adaptively balance the intra-modality semantic category constraints and
inter-modality pairwise similarity constraints. (3) CCL adopts multi-grained
modeling, which fuses the coarse-grained instances and fine-grained patches to
make cross-modal correlation more precise. Comparing with 13 state-of-the-art
methods on 6 widely-used cross-modal datasets, the experimental results show
our CCL approach achieves the best performance.
"
1256,OBTAIN: Real-Time Beat Tracking in Audio Signals,"  In this paper, we design a system in order to perform the real-time beat
tracking for an audio signal. We use Onset Strength Signal (OSS) to detect the
onsets and estimate the tempos. Then, we form Cumulative Beat Strength Signal
(CBSS) by taking advantage of OSS and estimated tempos. Next, we perform peak
detection by extracting the periodic sequence of beats among all CBSS peaks. In
simulations, we can see that our proposed algorithm, Online Beat TrAckINg
(OBTAIN), outperforms state-of-art results in terms of prediction accuracy
while maintaining comparable and practical computational complexity. The
real-time performance is tractable visually as illustrated in the simulations.
"
1257,"An Overview of Cross-media Retrieval: Concepts, Methodologies,
  Benchmarks and Challenges","  Multimedia retrieval plays an indispensable role in big data utilization.
Past efforts mainly focused on single-media retrieval. However, the
requirements of users are highly flexible, such as retrieving the relevant
audio clips with one query of image. So challenges stemming from the ""media
gap"", which means that representations of different media types are
inconsistent, have attracted increasing attention. Cross-media retrieval is
designed for the scenarios where the queries and retrieval results are of
different media types. As a relatively new research topic, its concepts,
methodologies and benchmarks are still not clear in the literatures. To address
these issues, we review more than 100 references, give an overview including
the concepts, methodologies, major challenges and open issues, as well as build
up the benchmarks including datasets and experimental results. Researchers can
directly adopt the benchmarks to promptly evaluate their proposed methods. This
will help them to focus on algorithm design, rather than the time-consuming
compared methods and results. It is noted that we have constructed a new
dataset XMedia, which is the first publicly available dataset with up to five
media types (text, image, video, audio and 3D model). We believe this overview
will attract more researchers to focus on cross-media retrieval and be helpful
to them.
"
1258,"A New Steganographic Technique Matching the Secret Message and Cover
  image Binary Value","  Steganography involves hiding a secret message or image inside another cover
image. Changes are made in the cover image without affecting visual quality of
the image. In contrast to cryptography, Steganography provides complete secrecy
of the communication. Security of very sensitive data can be enhanced by
combining cryptography and steganography. A new technique that uses the concept
of Steganography to obtain the position values from an image is suggested. This
paper proposes a new method where no change is made to the cover image, only
the pixel position LSB (Least Significant Bit) values that match with the
secret message bit values are noted in a separate position file. At the sending
end the position file along with the cover image is sent. At the receiving end
the position file is opened only with a secret key. The bit positions are taken
from the position file and the LSB values from the positions are combined to
get ASCII values and then form characters of the secret message
"
1259,"A Synchronization Algorithm Based on Moving Average for Robust Audio
  Watermarking Scheme","  A synchronization code scheme based on moving average is proposed for robust
audio watermarking in the paper. Two proper positive integers are chosen to
compute the moving average sequence by sliding one sample every time. The
synchronization bits are embedded at crosses of the two moving average
sequences with the quantization index modulation. The experimental results show
that the proposed watermarking scheme maintains high audio quality and is
robust to common attacks such as additive white Gaussian noise, re-sampling,
low-pass filtering, random cropping, MP3 compression, jitter attack and time
scale modification. Simultaneously, the algorithm has high search efficiency
and low false alarm rate.
"
1260,Robust Audio Watermarking Algorithm Based on Moving Average and DCT,"  Noise is often brought to host audio by common signal processing operation,
and it usually changes the high-frequency component of an audio signal. So
embedding watermark by adjusting low-frequency coefficient can improve the
robustness of a watermark scheme. Moving Average sequence is a low-frequency
feature of an audio signal. This work proposed a method which embedding
watermark into the maximal coefficient in discrete cosine transform domain of a
moving average sequence. Subjective and objective tests reveal that the
proposed watermarking scheme maintains highly audio quality, and
simultaneously, the algorithm is highly robust to common digital signal
processing operations, including additive noise, sampling rate change, bit
resolution transformation, MP3 compression, and random cropping, especially
low-pass filtering.
"
1261,"Performance Analysis of Reliable Video Streaming with Strict Playout
  Deadline in Multi-Hop Wireless Networks","  Motivated by emerging vision-based intelligent services, we consider the
problem of rate adaptation for high quality and low delay visual information
delivery over wireless networks using scalable video coding. Rate adaptation in
this setting is inherently challenging due to the interplay between the
variability of the wireless channels, the queuing at the network nodes and the
frame-based decoding and playback of the video content at the receiver at very
short time scales. To address the problem, we propose a low-complexity,
model-based rate adaptation algorithm for scalable video streaming systems,
building on a novel performance model based on stochastic network calculus. We
validate the model using extensive simulations. We show that it allows fast,
near optimal rate adaptation for fixed transmission paths, as well as
cross-layer optimized routing and video rate adaptation in mesh networks, with
less than $10$\% quality degradation compared to the best achievable
performance.
"
1262,A Robust Blind Watermarking Using Convolutional Neural Network,"  This paper introduces a blind watermarking based on a convolutional neural
network (CNN). We propose an iterative learning framework to secure robustness
of watermarking. One loop of learning process consists of the following three
stages: Watermark embedding, attack simulation, and weight update. We have
learned a network that can detect a 1-bit message from a image sub-block.
Experimental results show that this learned network is an extension of the
frequency domain that is widely used in existing watermarking scheme. The
proposed scheme achieved robustness against geometric and signal processing
attacks with a learning time of one day.
"
1263,UC Merced Submission to the ActivityNet Challenge 2016,"  This notebook paper describes our system for the untrimmed classification
task in the ActivityNet challenge 2016. We investigate multiple
state-of-the-art approaches for action recognition in long, untrimmed videos.
We exploit hand-crafted motion boundary histogram features as well feature
activations from deep networks such as VGG16, GoogLeNet, and C3D. These
features are separately fed to linear, one-versus-rest support vector machine
classifiers to produce confidence scores for each action class. These
predictions are then fused along with the softmax scores of the recent
ultra-deep ResNet-101 using weighted averaging.
"
1264,"Explaining the Unexplained: A CLass-Enhanced Attentive Response (CLEAR)
  Approach to Understanding Deep Neural Networks","  In this work, we propose CLass-Enhanced Attentive Response (CLEAR): an
approach to visualize and understand the decisions made by deep neural networks
(DNNs) given a specific input. CLEAR facilitates the visualization of attentive
regions and levels of interest of DNNs during the decision-making process. It
also enables the visualization of the most dominant classes associated with
these attentive regions of interest. As such, CLEAR can mitigate some of the
shortcomings of heatmap-based methods associated with decision ambiguity, and
allows for better insights into the decision-making process of DNNs.
Quantitative and qualitative experiments across three different datasets
demonstrate the efficacy of CLEAR for gaining a better understanding of the
inner workings of DNNs during the decision-making process.
"
1265,Cross-media Similarity Metric Learning with Unified Deep Networks,"  As a highlighting research topic in the multimedia area, cross-media
retrieval aims to capture the complex correlations among multiple media types.
Learning better shared representation and distance metric for multimedia data
is important to boost the cross-media retrieval. Motivated by the strong
ability of deep neural network in feature representation and comparison
functions learning, we propose the Unified Network for Cross-media Similarity
Metric (UNCSM) to associate cross-media shared representation learning with
distance metric in a unified framework. First, we design a two-pathway deep
network pretrained with contrastive loss, and employ double triplet similarity
loss for fine-tuning to learn the shared representation for each media type by
modeling the relative semantic similarity. Second, the metric network is
designed for effectively calculating the cross-media similarity of the shared
representation, by modeling the pairwise similar and dissimilar constraints.
Compared to the existing methods which mostly ignore the dissimilar constraints
and only use sample distance metric as Euclidean distance separately, our UNCSM
approach unifies the representation learning and distance metric to preserve
the relative similarity as well as embrace more complex similarity functions
for further improving the cross-media retrieval accuracy. The experimental
results show that our UNCSM approach outperforms 8 state-of-the-art methods on
4 widely-used cross-media datasets.
"
1266,Multi-View Image Generation from a Single-View,"  This paper addresses a challenging problem -- how to generate multi-view
cloth images from only a single view input. To generate realistic-looking
images with different views from the input, we propose a new image generation
model termed VariGANs that combines the strengths of the variational inference
and the Generative Adversarial Networks (GANs). Our proposed VariGANs model
generates the target image in a coarse-to-fine manner instead of a single pass
which suffers from severe artifacts. It first performs variational inference to
model global appearance of the object (e.g., shape and color) and produce a
coarse image with a different view. Conditioned on the generated low resolution
images, it then proceeds to perform adversarial learning to fill details and
generate images of consistent details with the input. Extensive experiments
conducted on two clothing datasets, MVC and DeepFashion, have demonstrated that
images of a novel view generated by our model are more plausible than those
generated by existing approaches, in terms of more consistent global appearance
as well as richer and sharper details.
"
1267,CNN based music emotion classification,"  Music emotion recognition (MER) is usually regarded as a multi-label tagging
task, and each segment of music can inspire specific emotion tags. Most
researchers extract acoustic features from music and explore the relations
between these features and their corresponding emotion tags. Considering the
inconsistency of emotions inspired by the same music segment for human beings,
seeking for the key acoustic features that really affect on emotions is really
a challenging task. In this paper, we propose a novel MER method by using deep
convolutional neural network (CNN) on the music spectrograms that contains both
the original time and frequency domain information. By the proposed method, no
additional effort on extracting specific features required, which is left to
the training procedure of the CNN model. Experiments are conducted on the
standard CAL500 and CAL500exp dataset. Results show that, for both datasets,
the proposed method outperforms state-of-the-art methods.
"
1268,"Using Mise-En-Sc\`ene Visual Features based on MPEG-7 and Deep Learning
  for Movie Recommendation","  Item features play an important role in movie recommender systems, where
recommendations can be generated by using explicit or implicit preferences of
users on traditional features (attributes) such as tag, genre, and cast.
Typically, movie features are human-generated, either editorially (e.g., genre
and cast) or by leveraging the wisdom of the crowd (e.g., tag), and as such,
they are prone to noise and are expensive to collect. Moreover, these features
are often rare or absent for new items, making it difficult or even impossible
to provide good quality recommendations.
  In this paper, we show that user's preferences on movies can be better
described in terms of the mise-en-sc\`ene features, i.e., the visual aspects of
a movie that characterize design, aesthetics and style (e.g., colors,
textures). We use both MPEG-7 visual descriptors and Deep Learning hidden
layers as example of mise-en-sc\`ene features that can visually describe
movies. Interestingly, mise-en-sc\`ene features can be computed automatically
from video files or even from trailers, offering more flexibility in handling
new items, avoiding the need for costly and error-prone human-based tagging,
and providing good scalability.
  We have conducted a set of experiments on a large catalogue of 4K movies.
Results show that recommendations based on mise-en-sc\`ene features
consistently provide the best performance with respect to richer sets of more
traditional features, such as genre and tag.
"
1269,"The Design, Implementation, and Deployment of a System to Transparently
  Compress Hundreds of Petabytes of Image Files for a File-Storage Service","  We report the design, implementation, and deployment of Lepton, a
fault-tolerant system that losslessly compresses JPEG images to 77% of their
original size on average. Lepton replaces the lowest layer of baseline JPEG
compression-a Huffman code-with a parallelized arithmetic code, so that the
exact bytes of the original JPEG file can be recovered quickly. Lepton matches
the compression efficiency of the best prior work, while decoding more than
nine times faster and in a streaming manner. Lepton has been released as
open-source software and has been deployed for a year on the Dropbox
file-storage backend. As of February 2017, it had compressed more than 203 PiB
of user JPEG files, saving more than 46 PiB.
"
1270,"FISF: Better User Experience using Smaller Bandwidth for Panoramic
  Virtual Reality Video","  The panoramic video is widely used to build virtual reality (VR) and is
expected to be one of the next generation Killer-Apps. Transmitting panoramic
VR videos is a challenging task because of two problems: 1) panoramic VR videos
are typically much larger than normal videos but they need to be transmitted
with limited bandwidth in mobile networks. 2) high-resolution and fluent views
should be provided to guarantee a superior user experience and avoid
side-effects such as dizziness and nausea. To address these two problems, we
propose a novel interactive streaming technology, namely Focus-based
Interactive Streaming Framework (FISF). FISF consists of three parts: 1) we use
the classic clustering algorithm DBSCAN to analyze real user data for Video
Focus Detection (VFD); 2) we propose a Focus-based Interactive Streaming
Technology (FIST), including a static version and a dynamic version; 3) we
propose two optimization methods: focus merging and prefetch strategy.
Experimental results show that FISF significantly outperforms the
state-of-the-art. The paper is submitted to Sigcomm 2017, VR/AR Network on 31
Mar 2017 at 10:44:04am EDT.
"
1271,Accelerated Nearest Neighbor Search with Quick ADC,"  Efficient Nearest Neighbor (NN) search in high-dimensional spaces is a
foundation of many multimedia retrieval systems. Because it offers low
responses times, Product Quantization (PQ) is a popular solution. PQ compresses
high-dimensional vectors into short codes using several sub-quantizers, which
enables in-RAM storage of large databases. This allows fast answers to NN
queries, without accessing the SSD or HDD. The key feature of PQ is that it can
compute distances between short codes and high-dimensional vectors using
cache-resident lookup tables. The efficiency of this technique, named
Asymmetric Distance Computation (ADC), remains limited because it performs many
cache accesses.
  In this paper, we introduce Quick ADC, a novel technique that achieves a 3 to
6 times speedup over ADC by exploiting Single Instruction Multiple Data (SIMD)
units available in current CPUs. Efficiently exploiting SIMD requires
algorithmic changes to the ADC procedure. Namely, Quick ADC relies on two key
modifications of ADC: (i) the use 4-bit sub-quantizers instead of the standard
8-bit sub-quantizers and (ii) the quantization of floating-point distances.
This allows Quick ADC to exceed the performance of state-of-the-art systems,
e.g., it achieves a Recall@100 of 0.94 in 3.4 ms on 1 billion SIFT descriptors
(128-bit codes).
"
1272,A Rate Adaptation Algorithm for Tile-based 360-degree Video Streaming,"  In the 360-degree immersive video, a user only views a part of the entire raw
video frame based on her viewing direction. However, today's 360-degree video
players always fetch the entire panoramic view regardless of users' head
movement, leading to significant bandwidth waste that can be potentially
avoided. In this paper, we propose a novel adaptive streaming scheme for
360-degree videos. The basic idea is to fetch the invisible portion of a video
at the lowest quality based on users' head movement prediction and to
adaptively decide the video playback quality for the visible portion based on
bandwidth prediction. Doing both in a robust manner requires overcome a series
of challenges, such as jointly considering the spatial and temporal domains,
tolerating prediction errors, and achieving low complexity. To overcome these
challenges, we first define quality of experience (QoE) metrics for adaptive
360-degree video streaming. We then formulate an optimization problem and solve
it at a low complexity. The algorithm strategically leverages both future
bandwidth and the distribution of users' head positions to determine the
quality level of each tile (i.e., a sub-area of a raw frame). We further
provide theoretical proof showing that our algorithm achieves optimality under
practical assumptions. Numerical results show that our proposed algorithms
significantly boost the user QoE by at least 20\% compared to baseline
algorithms.
"
1273,Deep Cross-Modal Audio-Visual Generation,"  Cross-modal audio-visual perception has been a long-lasting topic in
psychology and neurology, and various studies have discovered strong
correlations in human perception of auditory and visual stimuli. Despite works
in computational multimodal modeling, the problem of cross-modal audio-visual
generation has not been systematically studied in the literature. In this
paper, we make the first attempt to solve this cross-modal generation problem
leveraging the power of deep generative adversarial training. Specifically, we
use conditional generative adversarial networks to achieve cross-modal
audio-visual generation of musical performances. We explore different encoding
methods for audio and visual signals, and work on two scenarios:
instrument-oriented generation and pose-oriented generation. Being the first to
explore this new problem, we compose two new datasets with pairs of images and
sounds of musical performances of different instruments. Our experiments using
both classification and human evaluations demonstrate that our model has the
ability to generate one modality, i.e., audio/visual, from the other modality,
i.e., visual/audio, to a good extent. Our experiments on various design choices
along with the datasets will facilitate future research in this new problem
space.
"
1274,Deep Convolutional Neural Network to Detect J-UNIWARD,"  This paper presents an empirical study on applying convolutional neural
networks (CNNs) to detecting J-UNIWARD, one of the most secure JPEG
steganographic method. Experiments guiding the architectural design of the CNNs
have been conducted on the JPEG compressed BOSSBase containing 10,000 covers of
size 512x512. Results have verified that both the pooling method and the depth
of the CNNs are critical for performance. Results have also proved that a
20-layer CNN, in general, outperforms the most sophisticated feature-based
methods, but its advantage gradually diminishes on hard-to-detect cases. To
show that the performance generalizes to large-scale databases and to different
cover sizes, one experiment has been conducted on the CLS-LOC dataset of
ImageNet containing more than one million covers cropped to unified size of
256x256. The proposed 20-layer CNN has cut the error achieved by a CNN recently
proposed for large-scale JPEG steganalysis by 35%. Source code is available via
GitHub: https://github.com/GuanshuoXu/deep_cnn_jpeg_steganalysis
"
1275,DNA Steganalysis Using Deep Recurrent Neural Networks,"  Recent advances in next-generation sequencing technologies have facilitated
the use of deoxyribonucleic acid (DNA) as a novel covert channels in
steganography. There are various methods that exist in other domains to detect
hidden messages in conventional covert channels. However, they have not been
applied to DNA steganography. The current most common detection approaches,
namely frequency analysis-based methods, often overlook important signals when
directly applied to DNA steganography because those methods depend on the
distribution of the number of sequence characters. To address this limitation,
we propose a general sequence learning-based DNA steganalysis framework. The
proposed approach learns the intrinsic distribution of coding and non-coding
sequences and detects hidden messages by exploiting distribution variations
after hiding these messages. Using deep recurrent neural networks (RNNs), our
framework identifies the distribution variations by using the classification
score to predict whether a sequence is to be a coding or non-coding sequence.
We compare our proposed method to various existing methods and biological
sequence analysis methods implemented on top of our framework. According to our
experimental results, our approach delivers a robust detection performance
compared to other tools.
"
1276,"TFDASH: A Fairness, Stability, and Efficiency Aware Rate Control
  Approach for Multiple Clients over DASH","  Dynamic adaptive streaming over HTTP (DASH) has recently been widely deployed
in the Internet and adopted in the industry. It, however, does not impose any
adaptation logic for selecting the quality of video fragments requested by
clients and suffers from lackluster performance with respect to a number of
desirable properties: efficiency, stability, and fairness when multiple players
compete for a bottleneck link. In this paper, we propose a throughput-friendly
DASH (TFDASH) rate control scheme for video streaming with multiple clients
over DASH to well balance the trade-offs among efficiency, stability, and
fairness. The core idea behind guaranteeing fairness and high efficiency
(bandwidth utilization) is to avoid OFF periods during the downloading process
for all clients, i.e., the bandwidth is in perfect-subscription or
over-subscription with bandwidth utilization approach to 100\%. We also propose
a dual-threshold buffer model to solve the instability problem caused by the
above idea. As a result, by integrating these novel components, we also propose
a probability-driven rate adaption logic taking into account several key
factors that most influence visual quality, including buffer occupancy, video
playback quality, video bit-rate switching frequency and amplitude, to
guarantee high-quality video streaming. Our experiments evidently demonstrate
the superior performance of the proposed method.
"
1277,Accelerating Discrete Wavelet Transforms on Parallel Architectures,"  The 2-D discrete wavelet transform (DWT) can be found in the heart of many
image-processing algorithms. Until recently, several studies have compared the
performance of such transform on various shared-memory parallel architectures,
especially on graphics processing units (GPUs). All these studies, however,
considered only separable calculation schemes. We show that corresponding
separable parts can be merged into non-separable units, which halves the number
of steps. In addition, we introduce an optional optimization approach leading
to a reduction in the number of arithmetic operations. The discussed schemes
were adapted on the OpenCL framework and pixel shaders, and then evaluated
using GPUs of two biggest vendors. We demonstrate the performance of the
proposed non-separable methods by comparison with existing separable schemes.
The non-separable schemes outperform their separable counterparts on numerous
setups, especially considering the pixel shaders.
"
1278,"Co-projection-plane based 3-D padding for polyhedron projection for
  360-degree video","  The polyhedron projection for 360-degree video is becoming more and more
popular since it can lead to much less geometry distortion compared with the
equirectangular projection. However, in the polyhedron projection, we can
observe very obvious texture discontinuity in the area near the face boundary.
Such a texture discontinuity may lead to serious quality degradation when
motion compensation crosses the discontinuous face boundary. To solve this
problem, in this paper, we first propose to fill the corresponding neighboring
faces in the suitable positions as the extension of the current face to keep
approximated texture continuity. Then a co-projection-plane based 3-D padding
method is proposed to project the reference pixels in the neighboring face to
the current face to guarantee exact texture continuity. Under the proposed
scheme, the reference pixel is always projected to the same plane with the
current pixel when performing motion compensation so that the texture
discontinuity problem can be solved. The proposed scheme is implemented in the
reference software of High Efficiency Video Coding. Compared with the existing
method, the proposed algorithm can significantly improve the rate-distortion
performance. The experimental results obviously demonstrate that the texture
discontinuity in the face boundary can be well handled by the proposed
algorithm.
"
1279,A new image compression by gradient Haar wavelet,"  With the development of human communications the usage of Visual
Communications has also increased. The advancement of image compression methods
is one of the main reasons for the enhancement. This paper first presents main
modes of image compression methods such as JPEG and JPEG2000 without
mathematical details. Also, the paper describes gradient Haar wavelet
transforms in order to construct a preliminary image compression algorithm.
Then, a new image compression method is proposed based on the preliminary image
compression algorithm that can improve standards of image compression. The new
method is compared with original modes of JPEG and JPEG2000 (based on Haar
wavelet) by image quality measures such as MAE, PSNAR, and SSIM. The image
quality and statistical results confirm that can boost image compression
standards. It is suggested that the new method is used in a part or all of an
image compression standard.
"
1280,"Crime Scene Re-investigation: A Postmortem Analysis of Game Account
  Stealers' Behaviors","  As item trading becomes more popular, users can change their game items or
money into real money more easily. At the same time, hackers turn their eyes on
stealing other users game items or money because it is much easier to earn
money than traditional gold-farming by running game bots. Game companies
provide various security measures to block account- theft attempts, but many
security measures on the user-side are disregarded by users because of lack of
usability. In this study, we propose a server-side account theft detection
system base on action sequence analysis to protect game users from malicious
hackers. We tested this system in the real Massively Multiplayer Online Role
Playing Game (MMORPG). By analyzing users full game play log, our system can
find the particular action sequences of hackers with high accuracy. Also, we
can trace where the victim accounts stolen money goes.
"
1281,Deriving Quests from Open World Mechanics,"  Open world games present players with more freedom than games with linear
progression structures. However, without clearly-defined objectives, they often
leave players without a sense of purpose. Most of the time, quests and
objectives are hand-authored and overlaid atop an open world's mechanics. But
what if they could be generated organically from the gameplay itself? The goal
of our project was to develop a model of the mechanics in Minecraft that could
be used to determine the ideal placement of objectives in an open world
setting. We formalized the game logic of Minecraft in terms of logical rules
that can be manipulated in two ways: they may be executed to generate graphs
representative of the player experience when playing an open world game with
little developer direction; and they may be statically analyzed to determine
dependency orderings, feedback loops, and bottlenecks. These analyses may then
be used to place achievements on gameplay actions algorithmically.
"
1282,"Understanding the evolution of multimedia content in the Internet
  through BitTorrent glasses","  Today's Internet traffic is mostly dominated by multimedia content and the
prediction is that this trend will intensify in the future. Therefore, main
Internet players, such as ISPs, content delivery platforms (e.g. Youtube,
Bitorrent, Netflix, etc) or CDN operators, need to understand the evolution of
multimedia content availability and popularity in order to adapt their
infrastructures and resources to satisfy clients requirements while they
minimize their costs. This paper presents a thorough analysis on the evolution
of multimedia content available in BitTorrent. Specifically, we analyze the
evolution of four relevant metrics across different content categories: content
availability, content popularity, content size and user's feedback. To this end
we leverage a large-scale dataset formed by 4 snapshots collected from the most
popular BitTorrent portal, namely The Pirate Bay, between Nov. 2009 and Feb.
2012. Overall our dataset is formed by more than 160k content that attracted
more than 185M of download sessions.
"
1283,"Query-adaptive Video Summarization via Quality-aware Relevance
  Estimation","  Although the problem of automatic video summarization has recently received a
lot of attention, the problem of creating a video summary that also highlights
elements relevant to a search query has been less studied. We address this
problem by posing query-relevant summarization as a video frame subset
selection problem, which lets us optimise for summaries which are
simultaneously diverse, representative of the entire video, and relevant to a
text query. We quantify relevance by measuring the distance between frames and
queries in a common textual-visual semantic embedding space induced by a neural
network. In addition, we extend the model to capture query-independent
properties, such as frame quality. We compare our method against previous state
of the art on textual-visual embeddings for thumbnail selection and show that
our model outperforms them on relevance prediction. Furthermore, we introduce a
new dataset, annotated with diversity and query-specific relevance labels. On
this dataset, we train and test our complete model for video summarization and
show that it outperforms standard baselines such as Maximal Marginal Relevance.
"
1284,"Optimum Decoder for Multiplicative Spread Spectrum Image Watermarking
  with Laplacian Modeling","  This paper investigates the multiplicative spread spectrum watermarking
method for the image. The information bit is spreaded into middle-frequency
Discrete Cosine Transform (DCT) coefficients of each block of an image using a
generated pseudo-random sequence. Unlike the conventional signal modeling, we
suppose that both signal and noise are distributed with Laplacian distribution
because the sample loss of digital media can be better modeled with this
distribution than the Gaussian one. We derive the optimum decoder for the
proposed embedding method thanks to the maximum likelihood decoding scheme. We
also analyze our watermarking system in the presence of noise and provide
analytical evaluations and several simulations. The results show that it has
the suitable performance and transparency required for watermarking
applications.
"
1285,"Towards Predictions of the Image Quality of Experience for Augmented
  Reality Scenarios","  Augmented Reality (AR) devices are commonly head-worn to overlay
context-dependent information into the field of view of the device operators.
One particular scenario is the overlay of still images, either in a traditional
fashion, or as spherical, i.e., immersive, content. For both media types, we
evaluate the interplay of user ratings as Quality of Experience (QoE) with (i)
the non-referential BRISQUE objective image quality metric and (ii) human
subject dry electrode EEG signals gathered with a commercial device.
Additionally, we employ basic machine learning approaches to assess the
possibility of QoE predictions based on rudimentary subject data. Corroborating
prior research for the overall scenario, we find strong correlations for both
approaches with user ratings as Mean Opinion Scores, which we consider as QoE
metric. In prediction scenarios based on data subsets, we find good performance
for the objective metric as well as the EEG-based approach. While the objective
metric can yield high QoE prediction accuracies overall, it is limited i its
application for individual subjects. The subject-based EEG approach, on the
other hand, enables good predictability of the QoE for both media types, but
with better performance for regular content. Our results can be employed in
practical scenarios by content and network service providers to optimize the
user experience in augmented reality scenarios.
"
1286,FOIL it! Find One mismatch between Image and Language caption,"  In this paper, we aim to understand whether current language and vision
(LaVi) models truly grasp the interaction between the two modalities. To this
end, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates
images with both correct and ""foil"" captions, that is, descriptions of the
image that are highly similar to the original ones, but contain one single
mistake (""foil word""). We show that current LaVi models fall into the traps of
this data and perform badly on three tasks: a) caption classification (correct
vs. foil); b) foil word detection; c) foil word correction. Humans, in
contrast, have near-perfect performance on those tasks. We demonstrate that
merely utilising language cues is not enough to model FOIL-COCO and that it
challenges the state-of-the-art by requiring a fine-grained understanding of
the relation between text and image.
"
1287,Comparison of Uniform and Random Sampling for Speech and Music Signals,"  In this paper, we will provide a comparison between uniform and random
sampling for speech and music signals. There are various sampling and recovery
methods for audio signals. Here, we only investigate uniform and random schemes
for sampling and basic low-pass filtering and iterative method with adaptive
thresholding for recovery. The simulation results indicate that uniform
sampling with cubic spline interpolation outperforms other sampling and
recovery methods.
"
1288,"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360{\deg}
  Sports Video","  Watching a 360{\deg} sports video requires a viewer to continuously select a
viewing angle, either through a sequence of mouse clicks or head movements. To
relieve the viewer from this ""360 piloting"" task, we propose ""deep 360 pilot""
-- a deep learning-based agent for piloting through 360{\deg} sports videos
automatically. At each frame, the agent observes a panoramic image and has the
knowledge of previously selected viewing angles. The task of the agent is to
shift the current viewing angle (i.e. action) to the next preferred one (i.e.,
goal). We propose to directly learn an online policy of the agent from data. We
use the policy gradient technique to jointly train our pipeline: by minimizing
(1) a regression loss measuring the distance between the selected and ground
truth viewing angles, (2) a smoothness loss encouraging smooth transition in
viewing angle, and (3) maximizing an expected reward of focusing on a
foreground object. To evaluate our method, we build a new 360-Sports video
dataset consisting of five sports domains. We train domain-specific agents and
achieve the best performance on viewing angle selection accuracy and transition
smoothness compared to [51] and other baselines.
"
1289,"A Comparative Case Study of HTTP Adaptive Streaming Algorithms in Mobile
  Networks","  HTTP Adaptive Streaming (HAS) techniques are now the dominant solution for
video delivery in mobile networks. Over the past few years, several HAS
algorithms have been introduced in order to improve user quality-of-experience
(QoE) by bit-rate adaptation. Their difference is mainly the required input
information, ranging from network characteristics to application-layer
parameters such as the playback buffer. Interestingly, despite the recent
outburst in scientific papers on the topic, a comprehensive comparative study
of the main algorithm classes is still missing. In this paper we provide such
comparison by evaluating the performance of the state-of-the-art HAS algorithms
per class, based on data from field measurements. We provide a systematic study
of the main QoE factors and the impact of the target buffer level. We conclude
that this target buffer level is a critical classifier for the studied HAS
algorithms. While buffer-based algorithms show superior QoE in most of the
cases, their performance may differ at the low target buffer levels of live
streaming services. Overall, we believe that our findings provide valuable
insight for the design and choice of HAS algorithms according to networks
conditions and service requirements.
"
1290,A Hybrid Approach to Video Source Identification,"  Multimedia Forensics allows to determine whether videos or images have been
captured with the same device, and thus, eventually, by the same person.
Currently, the most promising technology to achieve this task, exploits the
unique traces left by the camera sensor into the visual content. Anyway, image
and video source identification are still treated separately from one another.
This approach is limited and anachronistic if we consider that most of the
visual media are today acquired using smartphones, that capture both images and
videos. In this paper we overcome this limitation by exploring a new approach
that allows to synergistically exploit images and videos to study the device
from which they both come. Indeed, we prove it is possible to identify the
source of a digital video by exploiting a reference sensor pattern noise
generated from still images taken by the same device of the query video. The
proposed method provides comparable or even better performance, when compared
to the current video identification strategies, where a reference pattern is
estimated from video frames. We also show how this strategy can be effective
even in case of in-camera digitally stabilized videos, where a non-stabilized
reference is not available, by solving some state-of-the-art limitations. We
explore a possible direct application of this result, that is social media
profile linking, i.e. discovering relationships between two or more social
media profiles by comparing the visual contents - images or videos - shared
therein.
"
1291,Concurrent Constraint Conditional-Branching Timed Interactive Scores,"  Multimedia scenarios have multimedia content and interactive events
associated with computer programs. Interactive Scores (IS) is a formalism to
represent such scenarios by temporal objects, temporal relations (TRs) and
interactive events. IS describe TRs, but IS cannot represent TRs together with
conditional branching. We propose a model for conditional branching timed IS in
the Non-deterministic Timed Concurrent Constraint (ntcc) calculus. We ran a
prototype of our model in Ntccrt (a real-time capable interpreter for ntcc) and
the response time was acceptable for real-time interaction. An advantage of
ntcc over Max/MSP or Petri Nets is that conditions and global constraints are
represented declaratively.
"
1292,Optimized Data Representation for Interactive Multiview Navigation,"  In contrary to traditional media streaming services where a unique media
content is delivered to different users, interactive multiview navigation
applications enable users to choose their own viewpoints and freely navigate in
a 3-D scene. The interactivity brings new challenges in addition to the
classical rate-distortion trade-off, which considers only the compression
performance and viewing quality. On the one hand, interactivity necessitates
sufficient viewpoints for richer navigation; on the other hand, it requires to
provide low bandwidth and delay costs for smooth navigation during view
transitions. In this paper, we formally describe the novel trade-offs posed by
the navigation interactivity and classical rate-distortion criterion. Based on
an original formulation, we look for the optimal design of the data
representation by introducing novel rate and distortion models and practical
solving algorithms. Experiments show that the proposed data representation
method outperforms the baseline solution by providing lower resource
consumptions and higher visual quality in all navigation configurations, which
certainly confirms the potential of the proposed data representation in
practical interactive navigation systems.
"
1293,New Transforms for JPEG Format,"  The two-dimensional discrete cosine transform (DCT) can be found in the heart
of many image compression algorithms. Specifically, the JPEG format uses a
lossy form of compression based on that transform. Since the standardization of
the JPEG, many other transforms become practical in lossy data compression.
This article aims to analyze the use of these transforms as the DCT replacement
in the JPEG compression chain. Each transform is examined for different image
datasets and subsequently compared to other transforms using the peak
signal-to-noise ratio (PSNR). Our experiments show that an overlapping
variation of the DCT, the local cosine transform (LCT), overcame the original
block-wise transform at low bitrates. At high bitrates, the discrete wavelet
transform employing the Cohen-Daubechies-Feauveau 9/7 wavelet offers about the
same compression performance as the DCT.
"
1294,Spatiotemporal Rate Adaptive Tiled Scheme for 360 Sports Events,"  The recent rise of interest in Virtual Reality (VR) came with the
availability of commodity commercial VR products, such as the Head Mounted
Displays (HMD) created by Oculus and other vendors. One of the main
applications of virtual reality that has been recently adopted is streaming
sports events. For instance, the last olympics held in Rio De Janeiro was
streamed over the Internet for users to view on VR headsets or using 360 video
players. A big challenge for streaming VR sports events is the users limited
bandwidth and the amount of data required to transmit 360 videos. While 360
video demands high bandwidth, at any time instant users are only viewing a
small portion of the video according to the HMD field of view (FOV). Many
approaches have been proposed in the literature such as proposing new
representations (e.g. pyramid and offset-cubemap) and tiling the video and
streaming the tiles currently being viewed. In this paper, we propose a tiled
streaming framework, where we provide a degrading quality model similar to the
state-of-the-art offset-cubemap while minimizing its storage requirements at
the server side. We conduct objective studies showing the effectiveness of our
approach providing smooth degradation of quality from the user FOV to the back
of the 360 space. In addition, we conduct subjective studies showing that users
tend to prefer our proposed scheme over offset-cubemap in low bandwidth
connections, and they don't feel difference for higher bandwidth connections.
That is, we achieve better perceived quality with huge storage savings up to
670%.
"
1295,"Generative Adversarial Networks for Multimodal Representation Learning
  in Video Hyperlinking","  Continuous multimodal representations suitable for multimodal information
retrieval are usually obtained with methods that heavily rely on multimodal
autoencoders. In video hyperlinking, a task that aims at retrieving video
segments, the state of the art is a variation of two interlocked networks
working in opposing directions. These systems provide good multimodal
embeddings and are also capable of translating from one representation space to
the other. Operating on representation spaces, these networks lack the ability
to operate in the original spaces (text or image), which makes it difficult to
visualize the crossmodal function, and do not generalize well to unseen data.
Recently, generative adversarial networks have gained popularity and have been
used for generating realistic synthetic data and for obtaining high-level,
single-modal latent representation spaces. In this work, we evaluate the
feasibility of using GANs to obtain multimodal representations. We show that
GANs can be used for multimodal representation learning and that they provide
multimodal representations that are superior to representations obtained with
multimodal autoencoders. Additionally, we illustrate the ability of visualizing
crossmodal translations that can provide human-interpretable insights on
learned GAN-based video hyperlinking models.
"
1296,"I Probe, Therefore I Am: Designing a Virtual Journalist with Human
  Emotions","  By utilizing different communication channels, such as verbal language,
gestures or facial expressions, virtually embodied interactive humans hold a
unique potential to bridge the gap between human-computer interaction and
actual interhuman communication. The use of virtual humans is consequently
becoming increasingly popular in a wide range of areas where such a natural
communication might be beneficial, including entertainment, education, mental
health research and beyond. Behind this development lies a series of
technological advances in a multitude of disciplines, most notably natural
language processing, computer vision, and speech synthesis. In this paper we
discuss a Virtual Human Journalist, a project employing a number of novel
solutions from these disciplines with the goal to demonstrate their viability
by producing a humanoid conversational agent capable of naturally eliciting and
reacting to information from a human user. A set of qualitative and
quantitative evaluation sessions demonstrated the technical feasibility of the
system whilst uncovering a number of deficits in its capacity to engage users
in a way that would be perceived as natural and emotionally engaging. We argue
that naturalness should not always be seen as a desirable goal and suggest that
deliberately suppressing the naturalness of virtual human interactions, such as
by altering its personality cues, might in some cases yield more desirable
results.
"
1297,"Learning Spatiotemporal Features for Infrared Action Recognition with 3D
  Convolutional Neural Networks","  Infrared (IR) imaging has the potential to enable more robust action
recognition systems compared to visible spectrum cameras due to lower
sensitivity to lighting conditions and appearance variability. While the action
recognition task on videos collected from visible spectrum imaging has received
much attention, action recognition in IR videos is significantly less explored.
Our objective is to exploit imaging data in this modality for the action
recognition task. In this work, we propose a novel two-stream 3D convolutional
neural network (CNN) architecture by introducing the discriminative code layer
and the corresponding discriminative code loss function. The proposed network
processes IR image and the IR-based optical flow field sequences. We pretrain
the 3D CNN model on the visible spectrum Sports-1M action dataset and finetune
it on the Infrared Action Recognition (InfAR) dataset. To our best knowledge,
this is the first application of the 3D CNN to action recognition in the IR
domain. We conduct an elaborate analysis of different fusion schemes (weighted
average, single and double-layer neural nets) applied to different 3D CNN
outputs. Experimental results demonstrate that our approach can achieve
state-of-the-art average precision (AP) performances on the InfAR dataset: (1)
the proposed two-stream 3D CNN achieves the best reported 77.5% AP, and (2) our
3D CNN model applied to the optical flow fields achieves the best reported
single stream 75.42% AP.
"
1298,Responsive Action-based Video Synthesis,"  We propose technology to enable a new medium of expression, where video
elements can be looped, merged, and triggered, interactively. Like audio, video
is easy to sample from the real world but hard to segment into clean reusable
elements. Reusing a video clip means non-linear editing and compositing with
novel footage. The new context dictates how carefully a clip must be prepared,
so our end-to-end approach enables previewing and easy iteration.
  We convert static-camera videos into loopable sequences, synthesizing them in
response to simple end-user requests. This is hard because a) users want
essentially semantic-level control over the synthesized video content, and b)
automatic loop-finding is brittle and leaves users limited opportunity to work
through problems. We propose a human-in-the-loop system where adding effort
gives the user progressively more creative control. Artists help us evaluate
how our trigger interfaces can be used for authoring of videos and
video-performances.
"
1299,"Building Emotional Machines: Recognizing Image Emotions through Deep
  Neural Networks","  An image is a very effective tool for conveying emotions. Many researchers
have investigated in computing the image emotions by using various features
extracted from images. In this paper, we focus on two high level features, the
object and the background, and assume that the semantic information of images
is a good cue for predicting emotion. An object is one of the most important
elements that define an image, and we find out through experiments that there
is a high correlation between the object and the emotion in images. Even with
the same object, there may be slight difference in emotion due to different
backgrounds, and we use the semantic information of the background to improve
the prediction performance. By combining the different levels of features, we
build an emotion based feed forward deep neural network which produces the
emotion values of a given image. The output emotion values in our framework are
continuous values in the 2-dimensional space (Valence and Arousal), which are
more effective than using a few number of emotion categories in describing
emotions. Experiments confirm the effectiveness of our network in predicting
the emotion of images.
"
1300,StegIbiza: Steganography in Club Music Implemented in Python,"  This paper introduces the implementation of steganography method called
StegIbiza, which uses tempo modulation as hidden message carrier. With the use
of Python scripting language, a bit string was encoded and decoded using WAV
and MP3 files. Once the message was hidden into a music files, an internet
radio was created to evaluate broadcast possibilities. No dedicated music or
signal processing equipment was used in this StegIbiza implementation
"
1301,A Survey on QoE-oriented Wireless Resources Scheduling,"  Future wireless systems are expected to provide a wide range of services to
more and more users. Advanced scheduling strategies thus arise not only to
perform efficient radio resource management, but also to provide fairness among
the users. On the other hand, the users' perceived quality, i.e., Quality of
Experience (QoE), is becoming one of the main drivers within the schedulers
design. In this context, this paper starts by providing a comprehension of what
is QoE and an overview of the evolution of wireless scheduling techniques.
Afterwards, a survey on the most recent QoE-based scheduling strategies for
wireless systems is presented, highlighting the application/service of the
different approaches reported in the literature, as well as the parameters that
were taken into account for QoE optimization. Therefore, this paper aims at
helping readers interested in learning the basic concepts of QoE-oriented
wireless resources scheduling, as well as getting in touch with its current
research frontier.
"
1302,"Ridiculously Fast Shot Boundary Detection with Fully Convolutional
  Neural Networks","  Shot boundary detection (SBD) is an important component of many video
analysis tasks, such as action recognition, video indexing, summarization and
editing. Previous work typically used a combination of low-level features like
color histograms, in conjunction with simple models such as SVMs. Instead, we
propose to learn shot detection end-to-end, from pixels to final shot
boundaries. For training such a model, we rely on our insight that all shot
boundaries are generated. Thus, we create a dataset with one million frames and
automatically generated transitions such as cuts, dissolves and fades. In order
to efficiently analyze hours of videos, we propose a Convolutional Neural
Network (CNN) which is fully convolutional in time, thus allowing to use a
large temporal context without the need to repeatedly processing frames. With
this architecture our method obtains state-of-the-art results while running at
an unprecedented speed of more than 120x real-time.
"
1303,Accelerating Discrete Wavelet Transforms on GPUs,"  The two-dimensional discrete wavelet transform has a huge number of
applications in image-processing techniques. Until now, several papers compared
the performance of such transform on graphics processing units (GPUs). However,
all of them only dealt with lifting and convolution computation schemes. In
this paper, we show that corresponding horizontal and vertical lifting parts of
the lifting scheme can be merged into non-separable lifting units, which halves
the number of steps. We also discuss an optimization strategy leading to a
reduction in the number of arithmetic operations. The schemes were assessed
using the OpenCL and pixel shaders. The proposed non-separable lifting scheme
outperforms the existing schemes in many cases, irrespective of its higher
complexity.
"
1304,"A New Parallel Message-distribution Technique for Cost-based
  Steganography","  This paper presents two novel approaches to increase performance bounds of
image steganography under the criteria of minimizing distortion. First, in
order to efficiently use the images' capacities, we propose using parallel
images in the embedding stage. The result is then used to prove sub-optimality
of the message distribution technique used by all cost based algorithms
including HUGO, S-UNIWARD, and HILL. Second, a new distribution approach is
presented to further improve the security of these algorithms. Experiments show
that this distribution method avoids embedding in smooth regions and thus
achieves a better performance, measured by state-of-the-art steganalysis, when
compared with the current used distribution.
"
1305,Traffic Profiling for Mobile Video Streaming,"  This paper describes a novel system that provides key parameters of HTTP
Adaptive Streaming (HAS) sessions to the lower layers of the protocol stack. A
non-intrusive traffic profiling solution is proposed that observes packet flows
at the transmit queue of base stations, edge-routers, or gateways. By analyzing
IP flows in real time, the presented scheme identifies different phases of an
HAS session and estimates important application-layer parameters, such as
play-back buffer state and video encoding rate. The introduced estimators only
use IP-layer information, do not require standardization and work even with
traffic that is encrypted via Transport Layer Security (TLS). Experimental
results for a popular video streaming service clearly verify the high accuracy
of the proposed solution. Traffic profiling, thus, provides a valuable
alternative to cross-layer signaling and Deep Packet Inspection (DPI) in order
to perform efficient network optimization for video streaming.
"
1306,"HTTP adaptive streaming with indoors-outdoors detection in mobile
  networks","  In mobile networks, users may lose coverage when entering a building due to
the high signal attenuation at windows and walls. Under such conditions,
services with minimum bit-rate requirements, such as video streaming, often
show poor Quality-of-Experience (QoE). We will present a Bayesian detector that
combines measurements from two Smartphone sensors to decide if a user is inside
a building or not. Based on this coverage classification, we will propose an
HTTP adaptive streaming (HAS) algorithm to increase playback stability at a
high average bitrate. Measurements in a typical office building show high
accuracy for the presented detector and superior QoE for the proposed HAS
algorithm.
"
1307,Fast MPEG-CDVS Encoder with GPU-CPU Hybrid Computing,"  The compact descriptors for visual search (CDVS) standard from ISO/IEC moving
pictures experts group (MPEG) has succeeded in enabling the interoperability
for efficient and effective image retrieval by standardizing the bitstream
syntax of compact feature descriptors. However, the intensive computation of
CDVS encoder unfortunately hinders its widely deployment in industry for
large-scale visual search. In this paper, we revisit the merits of low
complexity design of CDVS core techniques and present a very fast CDVS encoder
by leveraging the massive parallel execution resources of GPU. We elegantly
shift the computation-intensive and parallel-friendly modules to the
state-of-the-arts GPU platforms, in which the thread block allocation and the
memory access are jointly optimized to eliminate performance loss. In addition,
those operations with heavy data dependence are allocated to CPU to resolve the
extra but non-necessary computation burden for GPU. Furthermore, we have
demonstrated the proposed fast CDVS encoder can work well with those
convolution neural network approaches which has harmoniously leveraged the
advantages of GPU platforms, and yielded significant performance improvements.
Comprehensive experimental results over benchmarks are evaluated, which has
shown that the fast CDVS encoder using GPU-CPU hybrid computing is promising
for scalable visual search.
"
1308,"Optimizing Trade-offs Among Stakeholders in Real-Time Bidding by
  Incorporating Multimedia Metrics","  Displaying banner advertisements (in short, ads) on webpages has usually been
discussed as an Internet economics topic where a publisher uses auction models
to sell an online user's page view to advertisers and the one with the highest
bid can have her ad displayed to the user. This is also called \emph{real-time
bidding} (RTB) and the ad displaying process ensures that the publisher's
benefit is maximized or there is an equilibrium in ad auctions. However, the
benefits of the other two stakeholders -- the advertiser and the user -- have
been rarely discussed. In this paper, we propose a two-stage computational
framework that selects a banner ad based on the optimized trade-offs among all
stakeholders. The first stage is still auction based and the second stage
re-ranks ads by considering the benefits of all stakeholders. Our metric
variables are: the publisher's revenue, the advertiser's utility, the ad
memorability, the ad click-through rate (CTR), the contextual relevance, and
the visual saliency. To the best of our knowledge, this is the first work that
optimizes trade-offs among all stakeholders in RTB by incorporating multimedia
metrics. An algorithm is also proposed to determine the optimal weights of the
metric variables. We use both ad auction datasets and multimedia datasets to
validate the proposed framework. Our experimental results show that the
publisher can significantly improve the other stakeholders' benefits by
slightly reducing her revenue in the short-term. In the long run, advertisers
and users will be more engaged, the increased demand of advertising and the
increased supply of page views can then boost the publisher's revenue.
"
1309,Generating Steganographic Text with LSTMs,"  Motivated by concerns for user privacy, we design a steganographic system
(""stegosystem"") that enables two users to exchange encrypted messages without
an adversary detecting that such an exchange is taking place. We propose a new
linguistic stegosystem based on a Long Short-Term Memory (LSTM) neural network.
We demonstrate our approach on the Twitter and Enron email datasets and show
that it yields high-quality steganographic text while significantly improving
capacity (encrypted bits per word) relative to the state-of-the-art.
"
1310,"Putting a Face to the Voice: Fusing Audio and Visual Signals Across a
  Video to Determine Speakers","  In this paper, we present a system that associates faces with voices in a
video by fusing information from the audio and visual signals. The thesis
underlying our work is that an extremely simple approach to generating (weak)
speech clusters can be combined with visual signals to effectively associate
faces and voices by aggregating statistics across a video. This approach does
not need any training data specific to this task and leverages the natural
coherence of information in the audio and visual streams. It is particularly
applicable to tracking speakers in videos on the web where a priori information
about the environment (e.g., number of speakers, spatial signals for
beamforming) is not available. We performed experiments on a real-world dataset
using this analysis framework to determine the speaker in a video. Given a
ground truth labeling determined by human rater consensus, our approach had
~71% accuracy.
"
1311,Cross-modal Common Representation Learning by Hybrid Transfer Network,"  DNN-based cross-modal retrieval is a research hotspot to retrieve across
different modalities as image and text, but existing methods often face the
challenge of insufficient cross-modal training data. In single-modal scenario,
similar problem is usually relieved by transferring knowledge from large-scale
auxiliary datasets (as ImageNet). Knowledge from such single-modal datasets is
also very useful for cross-modal retrieval, which can provide rich general
semantic information that can be shared across different modalities. However,
it is challenging to transfer useful knowledge from single-modal (as image)
source domain to cross-modal (as image/text) target domain. Knowledge in source
domain cannot be directly transferred to both two different modalities in
target domain, and the inherent cross-modal correlation contained in target
domain provides key hints for cross-modal retrieval which should be preserved
during transfer process. This paper proposes Cross-modal Hybrid Transfer
Network (CHTN) with two subnetworks: Modal-sharing transfer subnetwork utilizes
the modality in both source and target domains as a bridge, for transferring
knowledge to both two modalities simultaneously; Layer-sharing correlation
subnetwork preserves the inherent cross-modal semantic correlation to further
adapt to cross-modal retrieval task. Cross-modal data can be converted to
common representation by CHTN for retrieval, and comprehensive experiment on 3
datasets shows its effectiveness.
"
1312,"Data Analysis in Multimedia Quality Assessment: Revisiting the
  Statistical Tests","  Assessment of multimedia quality relies heavily on subjective assessment, and
is typically done by human subjects in the form of preferences or continuous
ratings. Such data is crucial for analysis of different multimedia processing
algorithms as well as validation of objective (computational) methods for the
said purpose. To that end, statistical testing provides a theoretical framework
towards drawing meaningful inferences, and making well grounded conclusions and
recommendations. While parametric tests (such as t test, ANOVA, and error
estimates like confidence intervals) are popular and widely used in the
community, there appears to be a certain degree of confusion in the application
of such tests. Specifically, the assumption of normality and homogeneity of
variance is often not well understood. Therefore, the main goal of this paper
is to revisit them from a theoretical perspective and in the process provide
useful insights into their practical implications. Experimental results on both
simulated and real data are presented to support the arguments made. A software
implementing the said recommendations is also made publicly available, in order
to achieve the goal of reproducible research.
"
1313,Provenance Filtering for Multimedia Phylogeny,"  Departing from traditional digital forensics modeling, which seeks to analyze
single objects in isolation, multimedia phylogeny analyzes the evolutionary
processes that influence digital objects and collections over time. One of its
integral pieces is provenance filtering, which consists of searching a
potentially large pool of objects for the most related ones with respect to a
given query, in terms of possible ancestors (donors or contributors) and
descendants. In this paper, we propose a two-tiered provenance filtering
approach to find all the potential images that might have contributed to the
creation process of a given query $q$. In our solution, the first (coarse) tier
aims to find the most likely ""host"" images --- the major donor or background
--- contributing to a composite/doctored image. The search is then refined in
the second tier, in which we search for more specific (potentially small) parts
of the query that might have been extracted from other images and spliced into
the query image. Experimental results with a dataset containing more than a
million images show that the two-tiered solution underpinned by the context of
the query is highly useful for solving this difficult task.
"
1314,"Efficient Detection of Points of Interest from Georeferenced Visual
  Content","  Many people take photos and videos with smartphones and more recently with
360-degree cameras at popular places and events, and share them in social
media. Such visual content is produced in large volumes in urban areas, and it
is a source of information that online users could exploit to learn what has
got the interest of the general public on the streets of the cities where they
live or plan to visit. A key step to providing users with that information is
to identify the most popular k spots in specified areas. In this paper, we
propose a clustering and incremental sampling (C&IS) approach that trades off
accuracy of top-k results for detection speed. It uses clustering to determine
areas with high density of visual content, and incremental sampling, controlled
by stopping criteria, to limit the amount of computational work. It leverages
spatial metadata, which represent the scenes in the visual content, to rapidly
detect the hotspots, and uses a recently proposed Gaussian probability model to
describe the capture intention distribution in the query area. We evaluate the
approach with metadata, derived from a non-synthetic, user-generated dataset,
for regular mobile and 360-degree visual content. Our results show that the
C&IS approach offers 2.8x-19x reductions in processing time over an optimized
baseline, while in most cases correctly identifying 4 out of 5 top locations.
"
1315,"Localization of JPEG double compression through multi-domain
  convolutional neural networks","  When an attacker wants to falsify an image, in most of cases she/he will
perform a JPEG recompression. Different techniques have been developed based on
diverse theoretical assumptions but very effective solutions have not been
developed yet. Recently, machine learning based approaches have been started to
appear in the field of image forensics to solve diverse tasks such as
acquisition source identification and forgery detection. In this last case, the
aim ahead would be to get a trained neural network able, given a to-be-checked
image, to reliably localize the forged areas. With this in mind, our paper
proposes a step forward in this direction by analyzing how a single or double
JPEG compression can be revealed and localized using convolutional neural
networks (CNNs). Different kinds of input to the CNN have been taken into
consideration, and various experiments have been carried out trying also to
evidence potential issues to be further investigated.
"
1316,"The Effects of Noisy Labels on Deep Convolutional Neural Networks for
  Music Tagging","  Deep neural networks (DNN) have been successfully applied to music
classification including music tagging. However, there are several open
questions regarding the training, evaluation, and analysis of DNNs. In this
article, we investigate specific aspects of neural networks, the effects of
noisy labels, to deepen our understanding of their properties. We analyse and
(re-)validate a large music tagging dataset to investigate the reliability of
training and evaluation. Using a trained network, we compute label vector
similarities which is compared to groundtruth similarity.
  The results highlight several important aspects of music tagging and neural
networks. We show that networks can be effective despite relatively large error
rates in groundtruth datasets, while conjecturing that label noise can be the
cause of varying tag-wise performance differences. Lastly, the analysis of our
trained network provides valuable insight into the relationships between music
tags. These results highlight the benefit of using data-driven methods to
address automatic music tagging.
"
1317,"Characterizing Types of Convolution in Deep Convolutional Recurrent
  Neural Networks for Robust Speech Emotion Recognition","  Deep convolutional neural networks are being actively investigated in a wide
range of speech and audio processing applications including speech recognition,
audio event detection and computational paralinguistics, owing to their ability
to reduce factors of variations, for learning from speech. However, studies
have suggested to favor a certain type of convolutional operations when
building a deep convolutional neural network for speech applications although
there has been promising results using different types of convolutional
operations. In this work, we study four types of convolutional operations on
different input features for speech emotion recognition under noisy and clean
conditions in order to derive a comprehensive understanding. Since affective
behavioral information has been shown to reflect temporally varying of mental
state and convolutional operation are applied locally in time, all deep neural
networks share a deep recurrent sub-network architecture for further temporal
modeling. We present detailed quantitative module-wise performance analysis to
gain insights into information flows within the proposed architectures. In
particular, we demonstrate the interplay of affective information and the other
irrelevant information during the progression from one module to another.
Finally we show that all of our deep neural networks provide state-of-the-art
performance on the eNTERFACE'05 corpus.
"
1318,Link Adaptation for Wireless Video Communication Systems,"  This PhD thesis considers the performance evaluation and enhancement of video
communication over wireless channels. The system model considers hybrid
automatic repeat request (HARQ) with Chase combining and turbo product codes
(TPC). The thesis proposes algorithms and techniques to optimize the
throughput, transmission power and complexity of HARQ-based wireless video
communication. A semi-analytical solution is developed to model the performance
of delay-constrained HARQ systems. The semi-analytical and Monte Carlo
simulation results reveal that significant complexity reduction can be achieved
by noting that the coding gain advantage of the soft over hard decoding is
reduced when Chase combining is used, and it actually vanishes completely for
particular codes. Moreover, the thesis proposes a novel power optimization
algorithm that achieves a significant power saving of up to 80%. Joint
throughput maximization and complexity reduction is considered as well. A CRC
(cyclic redundancy check)-free HARQ is proposed to improve the system
throughput when short packets are transmitted. In addition, the computational
complexity/delay is reduced when the packets transmitted are long. Finally, a
content-aware and occupancy-based HARQ scheme is proposed to ensure minimum
video quality distortion with continuous playback.
"
1319,"Characterizing and Predicting Supply-side Engagement on
  Crowd-contributed Video Sharing Platforms","  Video sharing and entertainment websites have rapidly grown in popularity and
now constitute some of the most visited websites on the Internet. Despite the
active user engagement on these online video-sharing platforms, most of recent
research on online media platforms have restricted themselves to networking
based social media sites, like Facebook or Twitter. We depart from previous
studies in the online media space that have focused exclusively on demand-side
user engagement, by modeling the supply-side of the crowd-contributed videos on
this platform. The current study is among the first to perform a large-scale
empirical study using longitudinal video upload data from a large online video
platform. The modeling and subsequent prediction of video uploads is made
complicated by the heterogeneity of video types (e.g. popular vs. niche video
genres), and the inherent time trend effects associated with media uploads. We
identify distinct genre-clusters from our dataset and employ a self-exciting
Hawkes point-process model on each of these clusters to fully specify and
estimate the video upload process. Additionally, we go beyond prediction to
disentangle potential factors that govern user engagement and determine the
video upload rates, which improves our analysis with additional explanatory
power. Our findings show that using a relatively parsimonious point-process
model, we are able to achieve higher model fit, and predict video uploads to
the platform with a higher accuracy than competing models. The findings from
this study can benefit platform owners in better understanding how their
supply-side users engage with their site over time. We also offer a robust
method for performing media upload prediction that is likely to be
generalizable across media platforms which demonstrate similar temporal and
genre-level heterogeneity.
"
1320,"Modeling Multimodal Clues in a Hybrid Deep Learning Framework for Video
  Classification","  Videos are inherently multimodal. This paper studies the problem of how to
fully exploit the abundant multimodal clues for improved video categorization.
We introduce a hybrid deep learning framework that integrates useful clues from
multiple modalities, including static spatial appearance information, motion
patterns within a short time window, audio information as well as long-range
temporal dynamics. More specifically, we utilize three Convolutional Neural
Networks (CNNs) operating on appearance, motion and audio signals to extract
their corresponding features. We then employ a feature fusion network to derive
a unified representation with an aim to capture the relationships among
features. Furthermore, to exploit the long-range temporal dynamics in videos,
we apply two Long Short Term Memory networks with extracted appearance and
motion features as inputs. Finally, we also propose to refine the prediction
scores by leveraging contextual relationships among video semantics. The hybrid
deep learning framework is able to exploit a comprehensive set of multimodal
features for video classification. Through an extensive set of experiments, we
demonstrate that (1) LSTM networks which model sequences in an explicitly
recurrent manner are highly complementary with CNN models; (2) the feature
fusion network which produces a fused representation through modeling feature
relationships outperforms alternative fusion strategies; (3) the semantic
context of video classes can help further refine the predictions for improved
performance. Experimental results on two challenging benchmarks, the UCF-101
and the Columbia Consumer Videos (CCV), provide strong quantitative evidence
that our framework achieves promising results: $93.1\%$ on the UCF-101 and
$84.5\%$ on the CCV, outperforming competing methods with clear margins.
"
1321,Foveated Video Streaming for Cloud Gaming,"  Good user experience with interactive cloud-based multimedia applications,
such as cloud gaming and cloud-based VR, requires low end-to-end latency and
large amounts of downstream network bandwidth at the same time. In this paper,
we present a foveated video streaming system for cloud gaming. The system
adapts video stream quality by adjusting the encoding parameters on the fly to
match the player's gaze position. We conduct measurements with a prototype that
we developed for a cloud gaming system in conjunction with eye tracker
hardware. Evaluation results suggest that such foveated streaming can reduce
bandwidth requirements by even more than 50% depending on parametrization of
the foveated video coding and that it is feasible from the latency perspective.
"
1322,AI-Powered Social Bots,"  This paper gives an overview of impersonation bots that generate output in
one, or possibly, multiple modalities. We also discuss rapidly advancing areas
of machine learning and artificial intelligence that could lead to
frighteningly powerful new multi-modal social bots. Our main conclusion is that
most commonly known bots are one dimensional (i.e., chatterbot), and far from
deceiving serious interrogators. However, using recent advances in machine
learning, it is possible to unleash incredibly powerful, human-like armies of
social bots, in potentially well coordinated campaigns of deception and
influence.
"
1323,"Kapre: On-GPU Audio Preprocessing Layers for a Quick Implementation of
  Deep Neural Network Models with Keras","  We introduce Kapre, Keras layers for audio and music signal preprocessing.
Music research using deep neural networks requires a heavy and tedious
preprocessing stage, for which audio processing parameters are often ignored in
parameter optimisation. To solve this problem, Kapre implements time-frequency
conversions, normalisation, and data augmentation as Keras layers. We report
simple benchmark results, showing real-time on-GPU preprocessing adds a
reasonable amount of computation.
"
1324,Recent Advance in Content-based Image Retrieval: A Literature Survey,"  The explosive increase and ubiquitous accessibility of visual data on the Web
have led to the prosperity of research activity in image search or retrieval.
With the ignorance of visual content as a ranking clue, methods with text
search techniques for visual retrieval may suffer inconsistency between the
text words and visual content. Content-based image retrieval (CBIR), which
makes use of the representation of visual content to identify relevant images,
has attracted sustained attention in recent two decades. Such a problem is
challenging due to the intention gap and the semantic gap problems. Numerous
techniques have been developed for content-based image retrieval in the last
decade. The purpose of this paper is to categorize and evaluate those
algorithms proposed during the period of 2003 to 2016. We conclude with several
promising directions for future research.
"
1325,"Passive Classification of Source Printer using Text-line-level Geometric
  Distortion Signatures from Scanned Images of Printed Documents","  In this digital era, one thing that still holds the convention is a printed
archive. Printed documents find their use in many critical domains such as
contract papers, legal tenders and proof of identity documents. As more
advanced printing, scanning and image editing techniques are becoming
available, forgeries on these legal tenders pose a serious threat. Ability to
easily and reliably identify source printer of a printed document can help a
lot in reducing this menace. During printing procedure, printer hardware
introduces certain distortions in printed characters' locations and shapes
which are invisible to naked eyes. These distortions are referred as geometric
distortions, their profile (or signature) is generally unique for each printer
and can be used for printer classification purpose. This paper proposes a set
of features for characterizing text-line-level geometric distortions, referred
as geometric distortion signatures and presents a novel system to use them for
identification of the origin of a printed document. Detailed experiments
performed on a set of thirteen printers demonstrate that the proposed system
achieves state of the art performance and gives much higher accuracy under
small training size constraint. For four training and six test pages of three
different fonts, the proposed method gives 99\% classification accuracy.
"
1326,"Multi-Level and Multi-Scale Feature Aggregation Using Sample-level Deep
  Convolutional Neural Networks for Music Classification","  Music tag words that describe music audio by text have different levels of
abstraction. Taking this issue into account, we propose a music classification
approach that aggregates multi-level and multi-scale features using pre-trained
feature extractors. In particular, the feature extractors are trained in
sample-level deep convolutional neural networks using raw waveforms. We show
that this approach achieves state-of-the-art results on several music
classification datasets.
"
1327,"Single Classifier-based Passive System for Source Printer Classification
  using Local Texture Features","  An important aspect of examining printed documents for potential forgeries
and copyright infringement is the identification of source printer as it can be
helpful for ascertaining the leak and detecting forged documents. This paper
proposes a system for classification of source printer from scanned images of
printed documents using all the printed letters simultaneously. This system
uses local texture patterns based features and a single classifier for
classifying all the printed letters. Letters are extracted from scanned images
using connected component analysis followed by morphological filtering without
the need of using an OCR. Each letter is sub-divided into a flat region and an
edge region, and local tetra patterns are estimated separately for these two
regions. A strategically constructed pooling technique is used to extract the
final feature vectors. The proposed method has been tested on both a publicly
available dataset of 10 printers and a new dataset of 18 printers scanned at a
resolution of 600 dpi as well as 300 dpi printed in four different fonts. The
results indicate shape independence property in the proposed method as using a
single classifier it outperforms existing handcrafted feature-based methods and
needs much smaller number of training pages by using all the printed letters.
"
1328,Further Study on GFR Features for JPEG Steganalysis,"  The GFR (Gabor Filter Residual) features, built as histograms of quantized
residuals obtained with 2D Gabor filters, can achieve competitive detection
performance against adaptive JPEG steganography. In this paper, an improved
version of the GFR is proposed. First, a novel histogram merging method is
proposed according to the symmetries between different Gabor filters, thus
making the features more compact and robust. Second, a new weighted histogram
method is proposed by considering the position of the residual value in a
quantization interval, making the features more sensitive to the slight changes
in residual values. The experiments are given to demonstrate the effectiveness
of our proposed methods. Finally, we design a CNN to duplicate the detector
with the improved GFR features and the ensemble classifier, thus optimizing the
design of the filters used to form residuals in JPEG-phase-aware features.
"
1329,Toward Faultless Content-Based Playlists Generation for Instrumentals,"  This study deals with content-based musical playlists generation focused on
Songs and Instrumentals. Automatic playlist generation relies on collaborative
filtering and autotagging algorithms. Autotagging can solve the cold start
issue and popularity bias that are critical in music recommender systems.
However, autotagging remains to be improved and cannot generate satisfying
music playlists. In this paper, we suggest improvements toward better
autotagging-generated playlists compared to state-of-the-art. To assess our
method, we focus on the Song and Instrumental tags. Song and Instrumental are
two objective and opposite tags that are under-studied compared to genres or
moods, which are subjective and multi-modal tags. In this paper, we consider an
industrial real-world musical database that is unevenly distributed between
Songs and Instrumentals and bigger than databases used in previous studies. We
set up three incremental experiments to enhance automatic playlist generation.
Our suggested approach generates an Instrumental playlist with up to three
times less false positives than cutting edge methods. Moreover, we provide a
design of experiment framework to foster research on Songs and Instrumentals.
We give insight on how to improve further the quality of generated playlists
and to extend our methods to other musical tags. Furthermore, we provide the
source code to guarantee reproducible research.
"
1330,"Image Forgery Localization Based on Multi-Scale Convolutional Neural
  Networks","  In this paper, we propose to utilize Convolutional Neural Networks (CNNs) and
the segmentation-based multi-scale analysis to locate tampered areas in digital
images. First, to deal with color input sliding windows of different scales, a
unified CNN architecture is designed. Then, we elaborately design the training
procedures of CNNs on sampled training patches. With a set of robust
multi-scale tampering detectors based on CNNs, complementary tampering
possibility maps can be generated. Last but not least, a segmentation-based
method is proposed to fuse the maps and generate the final decision map. By
exploiting the benefits of both the small-scale and large-scale analyses, the
segmentation-based multi-scale analysis can lead to a performance leap in
forgery localization of CNNs. Numerous experiments are conducted to demonstrate
the effectiveness and efficiency of our method.
"
1331,Large-Scale Mapping of Human Activity using Geo-Tagged Videos,"  This paper is the first work to perform spatio-temporal mapping of human
activity using the visual content of geo-tagged videos. We utilize a recent
deep-learning based video analysis framework, termed hidden two-stream
networks, to recognize a range of activities in YouTube videos. This framework
is efficient and can run in real time or faster which is important for
recognizing events as they occur in streaming video or for reducing latency in
analyzing already captured video. This is, in turn, important for using video
in smart-city applications. We perform a series of experiments to show our
approach is able to accurately map activities both spatially and temporally. We
also demonstrate the advantages of using the visual content over the
tags/titles.
"
1332,"ISTA-Net: Interpretable Optimization-Inspired Deep Network for Image
  Compressive Sensing","  With the aim of developing a fast yet accurate algorithm for compressive
sensing (CS) reconstruction of natural images, we combine in this paper the
merits of two existing categories of CS methods: the structure insights of
traditional optimization-based methods and the speed of recent network-based
ones. Specifically, we propose a novel structured deep network, dubbed
ISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm
(ISTA) for optimizing a general $\ell_1$ norm CS reconstruction model. To cast
ISTA into deep network form, we develop an effective strategy to solve the
proximal mapping associated with the sparsity-inducing regularizer using
nonlinear transforms. All the parameters in ISTA-Net (\eg nonlinear transforms,
shrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than
being hand-crafted. Moreover, considering that the residuals of natural images
are more compressible, an enhanced version of ISTA-Net in the residual domain,
dubbed {ISTA-Net}$^+$, is derived to further improve CS reconstruction.
Extensive CS experiments demonstrate that the proposed ISTA-Nets outperform
existing state-of-the-art optimization-based and network-based CS methods by
large margins, while maintaining fast computational speed. Our source codes are
available: \textsl{http://jianzhang.tech/projects/ISTA-Net}.
"
1333,"On the usefulness of information hiding techniques for wireless sensor
  networks security","  A wireless sensor network (WSN) typically consists of base stations and a
large number of wireless sensors. The sensory data gathered from the whole
network at a certain time snapshot can be visualized as an image. As a result,
information hiding techniques can be applied to this ""sensory data image"".
Steganography refers to the technology of hiding data into digital media
without drawing any suspicion, while steganalysis is the art of detecting the
presence of steganography. This article provides a brief review of
steganography and steganalysis applications for wireless sensor networks
(WSNs). Then we show that the steganographic techniques are both related to
sensed data authentication in wireless sensor networks, and when considering
the attacker point of view, which has not yet been investigated in the
literature. Our simulation results show that the sink level is unable to detect
an attack carried out by the nsF5 algorithm on sensed data.
"
1334,"Proceedings of the First International Workshop on Deep Learning and
  Music","  Proceedings of the First International Workshop on Deep Learning and Music,
joint with IJCNN, Anchorage, US, May 17-18, 2017
"
1335,"A Robust Data Hiding Process Contributing to the Development of a
  Semantic Web","  In this paper, a novel steganographic scheme based on chaotic iterations is
proposed. This research work takes place into the information hiding framework,
and focus more specifically on robust steganography. Steganographic algorithms
can participate in the development of a semantic web: medias being on the
Internet can be enriched by information related to their contents, authors,
etc., leading to better results for the search engines that can deal with such
tags. As media can be modified by users for various reasons, it is preferable
that these embedding tags can resist to changes resulting from some classical
transformations as for example cropping, rotation, image conversion, and so on.
This is why a new robust watermarking scheme for semantic search engines is
proposed in this document. For the sake of completeness, the robustness of this
scheme is finally compared to existing established algorithms.
"
1336,Modeling Musical Context with Word2vec,"  We present a semantic vector space model for capturing complex polyphonic
musical context. A word2vec model based on a skip-gram representation with
negative sampling was used to model slices of music from a dataset of
Beethoven's piano sonatas. A visualization of the reduced vector space using
t-distributed stochastic neighbor embedding shows that the resulting embedded
vector space captures tonal relationships, even without any explicit
information about the musical contents of the slices. Secondly, an excerpt of
the Moonlight Sonata from Beethoven was altered by replacing slices based on
context similarity. The resulting music shows that the selected slice based on
similar word2vec context also has a relatively short tonal distance from the
original slice.
"
1337,"Alternative Semantic Representations for Zero-Shot Human Action
  Recognition","  A proper semantic representation for encoding side information is key to the
success of zero-shot learning. In this paper, we explore two alternative
semantic representations especially for zero-shot human action recognition:
textual descriptions of human actions and deep features extracted from still
images relevant to human actions. Such side information are accessible on Web
with little cost, which paves a new way in gaining side information for
large-scale zero-shot human action recognition. We investigate different
encoding methods to generate semantic representations for human actions from
such side information. Based on our zero-shot visual recognition method, we
conducted experiments on UCF101 and HMDB51 to evaluate two proposed semantic
representations . The results suggest that our proposed text- and image-based
semantic representations outperform traditional attributes and word vectors
considerably for zero-shot human action recognition. In particular, the
image-based semantic representations yield the favourable performance even
though the representation is extracted from a small number of images per class.
"
1338,Toward Inverse Control of Physics-Based Sound Synthesis,"  Long Short-Term Memory networks (LSTMs) can be trained to realize inverse
control of physics-based sound synthesizers. Physics-based sound synthesizers
simulate the laws of physics to produce output sound according to input gesture
signals. When a user's gestures are measured in real time, she or he can use
them to control physics-based sound synthesizers, thereby creating simulated
virtual instruments. An intriguing question is how to program a computer to
learn to play such physics-based models. This work demonstrates that LSTMs can
be trained to accomplish this inverse control task with four physics-based
sound synthesizers.
"
1339,"Chord Label Personalization through Deep Learning of Integrated Harmonic
  Interval-based Representations","  The increasing accuracy of automatic chord estimation systems, the
availability of vast amounts of heterogeneous reference annotations, and
insights from annotator subjectivity research make chord label personalization
increasingly important. Nevertheless, automatic chord estimation systems are
historically exclusively trained and evaluated on a single reference
annotation. We introduce a first approach to automatic chord label
personalization by modeling subjectivity through deep learning of a harmonic
interval-based chord label representation. After integrating these
representations from multiple annotators, we can accurately personalize chord
labels for individual annotators from a single model and the annotators' chord
label vocabulary. Furthermore, we show that chord personalization using
multiple reference annotations outperforms using a single reference annotation.
"
1340,"Transforming Musical Signals through a Genre Classifying Convolutional
  Neural Network","  Convolutional neural networks (CNNs) have been successfully applied on both
discriminative and generative modeling for music-related tasks. For a
particular task, the trained CNN contains information representing the decision
making or the abstracting process. One can hope to manipulate existing music
based on this 'informed' network and create music with new features
corresponding to the knowledge obtained by the network. In this paper, we
propose a method to utilize the stored information from a CNN trained on
musical genre classification task. The network was composed of three
convolutional layers, and was trained to classify five-second song clips into
five different genres. After training, randomly selected clips were modified by
maximizing the sum of outputs from the network layers. In addition to the
potential of such CNNs to produce interesting audio transformation, more
information about the network and the original music could be obtained from the
analysis of the generated features since these features indicate how the
network 'understands' the music.
"
1341,Music Signal Processing Using Vector Product Neural Networks,"  We propose a novel neural network model for music signal processing using
vector product neurons and dimensionality transformations. Here, the inputs are
first mapped from real values into three-dimensional vectors then fed into a
three-dimensional vector product neural network where the inputs, outputs, and
weights are all three-dimensional values. Next, the final outputs are mapped
back to the reals. Two methods for dimensionality transformation are proposed,
one via context windows and the other via spectral coloring. Experimental
results on the iKala dataset for blind singing voice separation confirm the
efficacy of our model.
"
1342,"Vision-based Detection of Acoustic Timed Events: a Case Study on
  Clarinet Note Onsets","  Acoustic events often have a visual counterpart. Knowledge of visual
information can aid the understanding of complex auditory scenes, even when
only a stereo mixdown is available in the audio domain, \eg identifying which
musicians are playing in large musical ensembles. In this paper, we consider a
vision-based approach to note onset detection. As a case study we focus on
challenging, real-world clarinetist videos and carry out preliminary
experiments on a 3D convolutional neural network based on multiple streams and
purposely avoiding temporal pooling. We release an audiovisual dataset with 4.5
hours of clarinetist videos together with cleaned annotations which include
about 36,000 onsets and the coordinates for a number of salient points and
regions of interest. By performing several training trials on our dataset, we
learned that the problem is challenging. We found that the CNN model is highly
sensitive to the optimization algorithm and hyper-parameters, and that treating
the problem as binary classification may prevent the joint optimization of
precision and recall. To encourage further research, we publicly share our
dataset, annotations and all models and detail which issues we came across
during our preliminary experiments.
"
1343,Talking Drums: Generating drum grooves with neural networks,"  Presented is a method of generating a full drum kit part for a provided
kick-drum sequence. A sequence to sequence neural network model used in natural
language translation was adopted to encode multiple musical styles and an
online survey was developed to test different techniques for sampling the
output of the softmax function. The strongest results were found using a
sampling technique that drew from the three most probable outputs at each
subdivision of the drum pattern but the consistency of output was found to be
heavily dependent on style.
"
1344,"Audio Spectrogram Representations for Processing with Convolutional
  Neural Networks","  One of the decisions that arise when designing a neural network for any
application is how the data should be represented in order to be presented to,
and possibly generated by, a neural network. For audio, the choice is less
obvious than it seems to be for visual images, and a variety of representations
have been used for different applications including the raw digitized sample
stream, hand-crafted features, machine discovered features, MFCCs and variants
that include deltas, and a variety of spectral representations. This paper
reviews some of these representations and issues that arise, focusing
particularly on spectrograms for generating audio using neural networks for
style transfer.
"
1345,Multi-scale Multi-band DenseNets for Audio Source Separation,"  This paper deals with the problem of audio source separation. To handle the
complex and ill-posed nature of the problems of audio source separation, the
current state-of-the-art approaches employ deep neural networks to obtain
instrumental spectra from a mixture. In this study, we propose a novel network
architecture that extends the recently developed densely connected
convolutional network (DenseNet), which has shown excellent results on image
classification tasks. To deal with the specific problem of audio source
separation, an up-sampling layer, block skip connection and band-dedicated
dense blocks are incorporated on top of DenseNet. The proposed approach takes
advantage of long contextual information and outperforms state-of-the-art
results on SiSEC 2016 competition by a large margin in terms of
signal-to-distortion ratio. Moreover, the proposed architecture requires
significantly fewer parameters and considerably less training time compared
with other methods.
"
1346,"SocialStegDisc: Application of steganography in social networks to
  create a file system","  The concept named SocialStegDisc was introduced as an application of the
original idea of StegHash method. This new kind of mass-storage was
characterized by unlimited space. The design also attempted to improve the
operation of StegHash by trade-off between memory requirements and computation
time. Applying the mechanism of linked list provided the set of operations on
files: creation, reading, deletion and modification. Features, limitations and
opportunities were discussed.
"
1347,"Evaluation of No Reference Bitstream-based Video Quality Assessment
  Methods","  Many different parametric models for video quality assessment have been
proposed in the past few years. This paper presents a review of nine recent
models which cover a wide range of methodologies and have been validated for
estimating video quality due to different degradation factors. Each model is
briefly described with key algorithms and relevant parametric formulas. The
generalization capability of each model to estimate video quality in
real-application scenarios is evaluated and compared with other models, using a
dataset created with video sequences from practical applications. These video
sequences cover a wide range of possible realistic encoding parameters, labeled
with mean opinion scores (MOS) via subjective test. The weakness and strength
of each model are remarked. Finally, future work towards a more general
parametric model that could apply for a wider range of applications is
discussed.
"
1348,Copy-move Forgery Detection based on Convolutional Kernel Network,"  In this paper, a copy-move forgery detection method based on Convolutional
Kernel Network is proposed. Different from methods based on conventional
hand-crafted features, Convolutional Kernel Network is a kind of data-driven
local descriptor with the deep convolutional structure. Thanks to the
development of deep learning theories and widely available datasets, the
data-driven methods can achieve competitive performance on different conditions
for its excellent discriminative capability. Besides, our Convolutional Kernel
Network is reformulated as a series of matrix computations and convolutional
operations which are easy to parallelize and accelerate by GPU, leading to high
efficiency. Then, appropriate preprocessing and postprocessing for
Convolutional Kernel Network are adopted to achieve copy-move forgery
detection. Particularly, a segmentation-based keypoints distribution strategy
is proposed and a GPU-based adaptive oversegmentation method is adopted.
Numerous experiments are conducted to demonstrate the effectiveness and
robustness of the GPU version of Convolutional Kernel Network, and the
state-of-the-art performance of the proposed copy-move forgery detection method
based on Convolutional Kernel Network.
"
1349,Web Video in Numbers - An Analysis of Web-Video Metadata,"  Web video is often used as a source of data in various fields of study. While
specialized subsets of web video, mainly earmarked for dedicated purposes, are
often analyzed in detail, there is little information available about the
properties of web video as a whole. In this paper we present insights gained
from the analysis of the metadata associated with more than 120 million videos
harvested from two popular web video platforms, vimeo and YouTube, in 2016 and
compare their properties with the ones found in commonly used video
collections. This comparison has revealed that existing collections do not (or
no longer) properly reflect the properties of web video ""in the wild"".
"
1350,On the steganographic image based approach to PDF files protection,"  Digital images can be copied without authorization and have to be protected.
Two schemes for watermarking images in PDF document were considered. Both
schemes include a converter to extract images from PDF pages and return the
protected images back. Frequency and spatial domain embedding were used for
hiding a message presented by a binary pattern. We considered visible and
invisible watermarking and found that spatial domain LSB technique can be more
preferable than frequency embedding using DWT.
"
1351,"Multimedia Semantic Integrity Assessment Using Joint Embedding Of Images
  And Text","  Real world multimedia data is often composed of multiple modalities such as
an image or a video with associated text (e.g. captions, user comments, etc.)
and metadata. Such multimodal data packages are prone to manipulations, where a
subset of these modalities can be altered to misrepresent or repurpose data
packages, with possible malicious intent. It is, therefore, important to
develop methods to assess or verify the integrity of these multimedia packages.
Using computer vision and natural language processing methods to directly
compare the image (or video) and the associated caption to verify the integrity
of a media package is only possible for a limited set of objects and scenes. In
this paper, we present a novel deep learning-based approach for assessing the
semantic integrity of multimedia packages containing images and captions, using
a reference set of multimedia packages. We construct a joint embedding of
images and captions with deep multimodal representation learning on the
reference dataset in a framework that also provides image-caption consistency
scores (ICCSs). The integrity of query media packages is assessed as the
inlierness of the query ICCSs with respect to the reference dataset. We present
the MultimodAl Information Manipulation dataset (MAIM), a new dataset of media
packages from Flickr, which we make available to the research community. We use
both the newly created dataset as well as Flickr30K and MS COCO datasets to
quantitatively evaluate our proposed approach. The reference dataset does not
contain unmanipulated versions of tampered query packages. Our method is able
to achieve F1 scores of 0.75, 0.89 and 0.94 on MAIM, Flickr30K and MS COCO,
respectively, for detecting semantically incoherent media packages.
"
1352,SSGAN: Secure Steganography Based on Generative Adversarial Networks,"  In this paper, a novel strategy of Secure Steganograpy based on Generative
Adversarial Networks is proposed to generate suitable and secure covers for
steganography. The proposed architecture has one generative network, and two
discriminative networks. The generative network mainly evaluates the visual
quality of the generated images for steganography, and the discriminative
networks are utilized to assess their suitableness for information hiding.
Different from the existing work which adopts Deep Convolutional Generative
Adversarial Networks, we utilize another form of generative adversarial
networks. By using this new form of generative adversarial networks,
significant improvements are made on the convergence speed, the training
stability and the image quality. Furthermore, a sophisticated steganalysis
network is reconstructed for the discriminative network, and the network can
better evaluate the performance of the generated images. Numerous experiments
are conducted on the publicly available datasets to demonstrate the
effectiveness and robustness of the proposed method.
"
1353,"High Resilience Diverse Domain Multilevel Audio Watermarking with
  Adaptive Threshold","  A novel diverse domain (DCT-SVD & DWT-SVD) watermarking scheme is proposed in
this paper. Here, the watermark is embedded simultaneously onto the two
domains. It is shown that an audio signal watermarked using this scheme has
better subjective and objective quality when compared with other watermarking
schemes. Also proposed are two novel watermark detection algorithms viz., AOT
(Adaptively Optimised Threshold) and AOTx (AOT eXtended). The fundamental idea
behind both is finding an optimum threshold for detecting a known character
embedded along with the actual watermarks in a known location, with the
constraint that the Bit Error Rate (BER) is minimum. This optimum threshold is
used for detecting the other characters in the watermarks. This approach is
shown to make the watermarking scheme less susceptible to various signal
processing attacks, thus making the watermarks more robust.
"
1354,"Deep CNN Framework for Audio Event Recognition using Weakly Labeled Web
  Data","  The development of audio event recognition models requires labeled training
data, which are generally hard to obtain. One promising source of recordings of
audio events is the large amount of multimedia data on the web. In particular,
if the audio content analysis must itself be performed on web audio, it is
important to train the recognizers themselves from such data. Training from
these web data, however, poses several challenges, the most important being the
availability of labels : labels, if any, that may be obtained for the data are
generally {\em weak}, and not of the kind conventionally required for training
detectors or classifiers. We propose that learning algorithms that can exploit
weak labels offer an effective method to learn from web data. We then propose a
robust and efficient deep convolutional neural network (CNN) based framework to
learn audio event recognizers from weakly labeled data. The proposed method can
train from and analyze recordings of variable length in an efficient manner and
outperforms a network trained with {\em strongly labeled} web data by a
considerable margin.
"
1355,"Efficient Context Management and Personalized User Recommendations in a
  Smart Social TV environment","  With the emergence of Smart TV and related interconnected devices, second
screen solutions have rapidly appeared to provide more content for end-users
and enrich their TV experience. Given the various data and sources involved -
videos, actors, social media and online databases- the aforementioned market
poses great challenges concerning user context management and sophisticated
recommendations that can be addressed to the end-users. This paper presents an
innovative Context Management model and a related first and second screen
recommendation service, based on a user-item graph analysis as well as
collaborative filtering techniques in the context of a Dynamic Social & Media
Content Syndication (SAM) platform. The model evaluation provided is based on
datasets collected online, presenting a comparative analysis concerning
efficiency and effectiveness of the current approach, and illustrating its
added value.
"
1356,Class-Weighted Convolutional Features for Visual Instance Search,"  Image retrieval in realistic scenarios targets large dynamic datasets of
unlabeled images. In these cases, training or fine-tuning a model every time
new images are added to the database is neither efficient nor scalable.
Convolutional neural networks trained for image classification over large
datasets have been proven effective feature extractors for image retrieval. The
most successful approaches are based on encoding the activations of
convolutional layers, as they convey the image spatial information. In this
paper, we go beyond this spatial information and propose a local-aware encoding
of convolutional features based on semantic information predicted in the target
image. To this end, we obtain the most discriminative regions of an image using
Class Activation Maps (CAMs). CAMs are based on the knowledge contained in the
network and therefore, our approach, has the additional advantage of not
requiring external information. In addition, we use CAMs to generate object
proposals during an unsupervised re-ranking stage after a first fast search.
Our experiments on two public available datasets for instance retrieval,
Oxford5k and Paris6k, demonstrate the competitiveness of our approach
outperforming the current state-of-the-art when using off-the-shelf models
trained on ImageNet. The source code and model used in this paper are publicly
available at http://imatge-upc.github.io/retrieval-2017-cam/.
"
1357,"An Augmented Autoregressive Approach to HTTP Video Stream Quality
  Prediction","  HTTP-based video streaming technologies allow for flexible rate selection
strategies that account for time-varying network conditions. Such rate changes
may adversely affect the user's Quality of Experience; hence online prediction
of the time varying subjective quality can lead to perceptually optimised
bitrate allocation policies. Recent studies have proposed to use dynamic
network approaches for continuous-time prediction; yet they do not consider
multiple video quality models as inputs nor consider forecasting ensembles.
Here we address the problem of predicting continuous-time subjective quality
using multiple inputs fed to a non-linear autoregressive network. By
considering multiple network configurations and by applying simple averaging
forecasting techniques, we are able to considerably improve prediction
performance and decrease forecasting errors.
"
1358,"SaltiNet: Scan-path Prediction on 360 Degree Images using Saliency
  Volumes","  We introduce SaltiNet, a deep neural network for scanpath prediction trained
on 360-degree images. The model is based on a temporal-aware novel
representation of saliency information named the saliency volume. The first
part of the network consists of a model trained to generate saliency volumes,
whose parameters are fit by back-propagation computed from a binary cross
entropy (BCE) loss over downsampled versions of the saliency volumes. Sampling
strategies over these volumes are used to generate scanpaths over the
360-degree images. Our experiments show the advantages of using saliency
volumes, and how they can be used for related tasks. Our source code and
trained models available at
https://github.com/massens/saliency-360salient-2017.
"
1359,"Discriminative Block-Diagonal Representation Learning for Image
  Recognition","  Existing block-diagonal representation researches mainly focuses on casting
block-diagonal regularization on training data, while only little attention is
dedicated to concurrently learning both block-diagonal representations of
training and test data. In this paper, we propose a discriminative
block-diagonal low-rank representation (BDLRR) method for recognition. In
particular, the elaborate BDLRR is formulated as a joint optimization problem
of shrinking the unfavorable representation from off-block-diagonal elements
and strengthening the compact block-diagonal representation under the
semi-supervised framework of low-rank representation. To this end, we first
impose penalty constraints on the negative representation to eliminate the
correlation between different classes such that the incoherence criterion of
the extra-class representation is boosted. Moreover, a constructed subspace
model is developed to enhance the self-expressive power of training samples and
further build the representation bridge between the training and test samples,
such that the coherence of the learned intra-class representation is
consistently heightened. Finally, the resulting optimization problem is solved
elegantly by employing an alternative optimization strategy, and a simple
recognition algorithm on the learned representation is utilized for final
prediction. Extensive experimental results demonstrate that the proposed method
achieves superb recognition results on four face image datasets, three
character datasets, and the fifteen scene multi-categories dataset. It not only
shows superior potential on image recognition but also outperforms
state-of-the-art methods.
"
1360,Learning Photography Aesthetics with Deep CNNs,"  Automatic photo aesthetic assessment is a challenging artificial intelligence
task. Existing computational approaches have focused on modeling a single
aesthetic score or a class (good or bad), however these do not provide any
details on why the photograph is good or bad, or which attributes contribute to
the quality of the photograph. To obtain both accuracy and human interpretation
of the score, we advocate learning the aesthetic attributes along with the
prediction of the overall score. For this purpose, we propose a novel multitask
deep convolution neural network, which jointly learns eight aesthetic
attributes along with the overall aesthetic score. We report near human
performance in the prediction of the overall aesthetic score. To understand the
internal representation of these attributes in the learned model, we also
develop the visualization technique using back propagation of gradients. These
visualizations highlight the important image regions for the corresponding
attributes, thus providing insights about model's representation of these
attributes. We showcase the diversity and complexity associated with different
attributes through a qualitative analysis of the activation maps.
"
1361,"Disentangling Motion, Foreground and Background Features in Videos","  This paper introduces an unsupervised framework to extract semantically rich
features for video representation. Inspired by how the human visual system
groups objects based on motion cues, we propose a deep convolutional neural
network that disentangles motion, foreground and background information. The
proposed architecture consists of a 3D convolutional feature encoder for blocks
of 16 frames, which is trained for reconstruction tasks over the first and last
frames of the sequence. A preliminary supervised experiment was conducted to
verify the feasibility of proposed method by training the model with a fraction
of videos from the UCF-101 dataset taking as ground truth the bounding boxes
around the activity regions. Qualitative results indicate that the network can
successfully segment foreground and background in videos as well as update the
foreground appearance based on disentangled motion features. The benefits of
these learned features are shown in a discriminative classification task, where
initializing the network with the proposed pretraining method outperforms both
random initialization and autoencoder pretraining. Our model and source code
are publicly available at https://imatge-upc.github.io/unsupervised-2017-cvprw/ .
"
1362,"Towards Physiology-Aware DASH: Bandwidth-Compliant Prioritized Clinical
  Multimedia Communication in Ambulances","  The ultimate objective of medical cyber-physical systems is to enhance the
safety and effectiveness of patient care. To ensure safe and effective care
during emergency patient transfer from rural areas to center tertiary
hospitals, reliable and real-time communication is essential. Unfortunately,
real-time monitoring of patients involves transmission of various clinical
multimedia data including videos, medical images, and vital signs, which
requires use of mobile network with high-fidelity communication bandwidth.
However, the wireless networks along the roads in rural areas range from 4G to
2G to low speed satellite links, which poses a significant challenge to
transmit critical patient information.
  In this paper, we present a bandwidth-compliant criticality-aware system for
transmission of massive clinical multimedia data adaptive to varying bandwidths
during patient transport. Model-based clinical automata are used to determine
the criticality of clinical multimedia data. We borrow concepts from DASH, and
propose physiology-aware adaptation techniques to transmit more critical
clinical data with higher fidelity in response to changes in disease, clinical
states, and bandwidth condition. In collaboration with Carle's ambulance
service center, we develop a bandwidth profiler, and use it as proof of concept
to support our experiments. Our preliminary evaluation results show that our
solutions ensure that most critical patient's clinical data are communicated
with higher fidelity.
"
1363,"Halftone Image Watermarking by Content Aware Double-sided Embedding
  Error Diffusion","  In this paper, we carry out a performance analysis from a probabilistic
perspective to introduce the EDHVW methods' expected performances and
limitations. Then, we propose a new general error diffusion based halftone
visual watermarking (EDHVW) method, Content aware Double-sided Embedding Error
Diffusion (CaDEED), via considering the expected watermark decoding performance
with specific content of the cover images and watermark, different noise
tolerance abilities of various cover image content and the different importance
levels of every pixel (when being perceived) in the secret pattern (watermark).
To demonstrate the effectiveness of CaDEED, we propose CaDEED with expectation
constraint (CaDEED-EC) and CaDEED-NVF&IF (CaDEED-N&I). Specifically, we build
CaDEED-EC by only considering the expected performances of specific cover
images and watermark. By adopting the noise visibility function (NVF) and
proposing the importance factor (IF) to assign weights to every embedding
location and watermark pixel, respectively, we build the specific method
CaDEED-N&I. In the experiments, we select the optimal parameters for NVF and IF
via extensive experiments. In both the numerical and visual comparisons, the
experimental results demonstrate the superiority of our proposed work.
"
1364,Towards a Social Virtual Reality Learning Environment in High Fidelity,"  Virtual Learning Environments (VLEs) are spaces designed to educate students
remotely via online platforms. Although traditional VLEs such as iSocial have
shown promise in educating students, they offer limited immersion that
diminishes learning effectiveness. This paper outlines a virtual reality
learning environment (VRLE) over a high-speed network, which promotes
educational effectiveness and efficiency via our creation of flexible content
and infrastructure which meet established VLE standards with improved
immersion. This paper further describes our implementation of multiple learning
modules developed in High Fidelity, a ""social VR"" platform. Our experiment
results show that the VR mode of content delivery better stimulates the
generalization of lessons to the real world than non-VR lessons and provides
improved immersion when compared to an equivalent desktop version.
"
1365,Metrical-accent Aware Vocal Onset Detection in Polyphonic Audio,"  The goal of this study is the automatic detection of onsets of the singing
voice in polyphonic audio recordings. Starting with a hypothesis that the
knowledge of the current position in a metrical cycle (i.e. metrical accent)
can improve the accuracy of vocal note onset detection, we propose a novel
probabilistic model to jointly track beats and vocal note onsets. The proposed
model extends a state of the art model for beat and meter tracking, in which
a-priori probability of a note at a specific metrical accent interacts with the
probability of observing a vocal note onset. We carry out an evaluation on a
varied collection of multi-instrument datasets from two music traditions
(English popular music and Turkish makam) with different types of metrical
cycles and singing styles. Results confirm that the proposed model reasonably
improves vocal note onset detection accuracy compared to a baseline model that
does not take metrical position into account.
"
1366,DenseNet for Dense Flow,"  Classical approaches for estimating optical flow have achieved rapid progress
in the last decade. However, most of them are too slow to be applied in
real-time video analysis. Due to the great success of deep learning, recent
work has focused on using CNNs to solve such dense prediction problems. In this
paper, we investigate a new deep architecture, Densely Connected Convolutional
Networks (DenseNet), to learn optical flow. This specific architecture is ideal
for the problem at hand as it provides shortcut connections throughout the
network, which leads to implicit deep supervision. We extend current DenseNet
to a fully convolutional network to learn motion estimation in an unsupervised
manner. Evaluation results on three standard benchmarks demonstrate that
DenseNet is a better fit than other widely adopted CNN architectures for
optical flow estimation.
"
1367,leave a trace - A People Tracking System Meets Anomaly Detection,"  Video surveillance always had a negative connotation, among others because of
the loss of privacy and because it may not automatically increase public
safety. If it was able to detect atypical (i.e. dangerous) situations in real
time, autonomously and anonymously, this could change. A prerequisite for this
is a reliable automatic detection of possibly dangerous situations from video
data. This is done classically by object extraction and tracking. From the
derived trajectories, we then want to determine dangerous situations by
detecting atypical trajectories. However, due to ethical considerations it is
better to develop such a system on data without people being threatened or even
harmed, plus with having them know that there is such a tracking system
installed. Another important point is that these situations do not occur very
often in real, public CCTV areas and may be captured properly even less. In the
artistic project leave a trace the tracked objects, people in an atrium of a
institutional building, become actor and thus part of the installation.
Visualisation in real-time allows interaction by these actors, which in turn
creates many atypical interaction situations on which we can develop our
situation detection. The data set has evolved over three years and hence, is
huge. In this article we describe the tracking system and several approaches
for the detection of atypical trajectories.
"
1368,"Multichannel Attention Network for Analyzing Visual Behavior in Public
  Speaking","  Public speaking is an important aspect of human communication and
interaction. The majority of computational work on public speaking concentrates
on analyzing the spoken content, and the verbal behavior of the speakers. While
the success of public speaking largely depends on the content of the talk, and
the verbal behavior, non-verbal (visual) cues, such as gestures and physical
appearance also play a significant role. This paper investigates the importance
of visual cues by estimating their contribution towards predicting the
popularity of a public lecture. For this purpose, we constructed a large
database of more than $1800$ TED talk videos. As a measure of popularity of the
TED talks, we leverage the corresponding (online) viewers' ratings from
YouTube. Visual cues related to facial and physical appearance, facial
expressions, and pose variations are extracted from the video frames using
convolutional neural network (CNN) models. Thereafter, an attention-based long
short-term memory (LSTM) network is proposed to predict the video popularity
from the sequence of visual features. The proposed network achieves
state-of-the-art prediction accuracy indicating that visual cues alone contain
highly predictive information about the popularity of a talk. Furthermore, our
network learns a human-like attention mechanism, which is particularly useful
for interpretability, i.e. how attention varies with time, and across different
visual cues by indicating their relative importance.
"
1369,"Automatic Curation of Golf Highlights using Multimodal Excitement
  Features","  The production of sports highlight packages summarizing a game's most
exciting moments is an essential task for broadcast media. Yet, it requires
labor-intensive video editing. We propose a novel approach for auto-curating
sports highlights, and use it to create a real-world system for the editorial
aid of golf highlight reels. Our method fuses information from the players'
reactions (action recognition such as high-fives and fist pumps), spectators
(crowd cheering), and commentator (tone of the voice and word analysis) to
determine the most interesting moments of a game. We accurately identify the
start and end frames of key shot highlights with additional metadata, such as
the player's name and the hole number, allowing personalized content
summarization and retrieval. In addition, we introduce new techniques for
learning our classifiers with reduced manual training data annotation by
exploiting the correlation of different modalities. Our work has been
demonstrated at a major golf tournament, successfully extracting highlights
from live video streams over four consecutive days.
"
1370,"Simple Countermeasures to Mitigate the Effect of Pollution Attack in
  Network Coding Based Peer-to-Peer Live Streaming","  Network coding based peer-to-peer streaming represents an effective solution
to aggregate user capacities and to increase system throughput in live
multimedia streaming. Nonetheless, such systems are vulnerable to pollution
attacks where a handful of malicious peers can disrupt the communication by
transmitting just a few bogus packets which are then recombined and relayed by
unaware honest nodes, further spreading the pollution over the network. Whereas
previous research focused on malicious nodes identification schemes and
pollution-resilient coding, in this paper we show pollution countermeasures
which make a standard network coding scheme resilient to pollution attacks.
Thanks to a simple yet effective analytical model of a reference node
collecting packets by malicious and honest neighbors, we demonstrate that i)
packets received earlier are less likely to be polluted and ii) short
generations increase the likelihood to recover a clean generation. Therefore,
we propose a recombination scheme where nodes draw packets to be recombined
according to their age in the input queue, paired with a decoding scheme able
to detect the reception of polluted packets early in the decoding process and
short generations. The effectiveness of our approach is experimentally
evaluated in a real system we developed and deployed on hundreds to thousands
peers. Experimental evidence shows that, thanks to our simple countermeasures,
the effect of a pollution attack is almost canceled and the video quality
experienced by the peers is comparable to pre-attack levels.
"
1371,"Anti-Forensics of Camera Identification and the Triangle Test by
  Improved Fingerprint-Copy Attack","  The fingerprint-copy attack aims to confuse camera identification based on
sensor pattern noise. However, the triangle test shows that the forged images
undergone fingerprint-copy attack would share a non-PRNU (Photo-response
nonuniformity) component with every stolen image, and thus can detect
fingerprint-copy attack. In this paper, we propose an improved fingerprint-copy
attack scheme. Our main idea is to superimpose the estimated fingerprint into
the target image dispersedly, via employing a block-wise method and using the
stolen images randomly and partly. We also develop a practical method to
determine the strength of the superimposed fingerprint based on objective image
quality. In such a way, the impact of non-PRNU component on the triangle test
is reduced, and our improved fingerprint-copy attack is difficultly detected.
The experiments evaluated on 2,900 images from 4 cameras show that our scheme
can effectively fool camera identification, and significantly degrade the
performance of the triangle test simultaneously.
"
1372,"MVP2P: Layer-Dependency-Aware Live MVC Video Streaming over Peer-to-Peer
  Networks","  Multiview video supports observing a scene from different viewpoints. The
Joint Video Team (JVT) developed H.264/MVC to enhance the compression
efficiency for multiview video, however, MVC encoded multiview video (MVC
video) still requires high bitrates for transmission. This paper investigates
live MVC video streaming over Peer-to-Peer (P2P) networks. The goal is to
minimize the server bandwidth costs whist ensuring high streaming quality to
peers. MVC employs intra-view and inter-view prediction structures, which leads
to a complicated layer dependency relationship. As the peers' outbound
bandwidth is shared while supplying all the MVC video layers, the bandwidth
allocation to one MVC layer affects the available outbound bandwidth of the
other layers. To optimise the utilisation of the peers' outbound bandwidth for
providing video layers, a maximum flow based model is proposed which considers
the MVC video layer dependency and the layer supplying relationship between
peers. Based on the model, a layer dependency aware live MVC video streaming
method over a BitTorrent-like P2P network is proposed, named MVP2P. The key
components of MVP2P include a chunk scheduling strategy and a peer selection
strategy for receiving peers, and a bandwidth scheduling algorithm for
supplying peers. To evaluate the efficiency of the proposed solution, MVP2P is
compared with existing methods considering the constraints of peer bandwidth,
peer numbers, view switching rates, and peer churns. The test results show that
MVP2P significantly outperforms the existing methods.
"
1373,Video Highlight Prediction Using Audience Chat Reactions,"  Sports channel video portals offer an exciting domain for research on
multimodal, multilingual analysis. We present methods addressing the problem of
automatic video highlight prediction based on joint visual features and textual
analysis of the real-world audience discourse with complex slang, in both
English and traditional Chinese. We present a novel dataset based on League of
Legends championships recorded from North American and Taiwanese Twitch.tv
channels (will be released for further research), and demonstrate strong
results on these using multimodal, character-level CNN-RNN model architectures.
"
1374,Benchmarking Multimodal Sentiment Analysis,"  We propose a framework for multimodal sentiment analysis and emotion
recognition using convolutional neural network-based feature extraction from
text and visual modalities. We obtain a performance improvement of 10% over the
state of the art by combining visual, text and audio features. We also discuss
some major issues frequently ignored in multimodal sentiment analysis research:
the role of speaker-independent models, importance of the modalities and
generalizability. The paper thus serve as a new benchmark for further research
in multimodal sentiment analysis and also demonstrates the different facets of
analysis to be considered while performing such tasks.
"
1375,"Intra Prediction Using In-Loop Residual Coding for the post-HEVC
  Standard","  A few years after standardization of the High Efficiency Video Coding (HEVC),
now the Joint Video Exploration Team (JVET) group is exploring post-HEVC video
compression technologies. In the intra prediction domain, this effort has
resulted in an algorithm with 67 internal modes, new filters and tools which
significantly improve HEVC. However, the improved algorithm still suffers from
the long distance prediction inaccuracy problem. In this paper, we propose an
In-Loop Residual coding Intra Prediction (ILR-IP) algorithm which utilizes
inner-block reconstructed pixels as references to reduce the distance from
predicted pixels. This is done by using the ILR signal for partially
reconstructing each pixel, right after its prediction and before its
block-level out-loop residual calculation. The ILR signal is decided in the
rate-distortion sense, by a brute-force search on a QP-dependent finite
codebook that is known to the decoder. Experiments show that the proposed
ILR-IP algorithm improves the existing method in the Joint Exploration Model
(JEM) up to 0.45% in terms of bit rate saving, without complexity overhead at
the decoder side.
"
1376,"Learning to Hallucinate Face Images via Component Generation and
  Enhancement","  We propose a two-stage method for face hallucination. First, we generate
facial components of the input image using CNNs. These components represent the
basic facial structures. Second, we synthesize fine-grained facial structures
from high resolution training images. The details of these structures are
transferred into facial components for enhancement. Therefore, we generate
facial components to approximate ground truth global appearance in the first
stage and enhance them through recovering details in the second stage. The
experiments demonstrate that our method performs favorably against
state-of-the-art methods
"
1377,Fast Preprocessing for Robust Face Sketch Synthesis,"  Exemplar-based face sketch synthesis methods usually meet the challenging
problem that input photos are captured in different lighting conditions from
training photos. The critical step causing the failure is the search of similar
patch candidates for an input photo patch. Conventional illumination invariant
patch distances are adopted rather than directly relying on pixel intensity
difference, but they will fail when local contrast within a patch changes. In
this paper, we propose a fast preprocessing method named Bidirectional
Luminance Remapping (BLR), which interactively adjust the lighting of training
and input photos. Our method can be directly integrated into state-of-the-art
exemplar-based methods to improve their robustness with ignorable computational
cost.
"
1378,CREST: Convolutional Residual Learning for Visual Tracking,"  Discriminative correlation filters (DCFs) have been shown to perform
superiorly in visual tracking. They only need a small set of training samples
from the initial frame to generate an appearance model. However, existing DCFs
learn the filters separately from feature extraction, and update these filters
using a moving average operation with an empirical weight. These DCF trackers
hardly benefit from the end-to-end training. In this paper, we propose the
CREST algorithm to reformulate DCFs as a one-layer convolutional neural
network. Our method integrates feature extraction, response map generation as
well as model update into the neural networks for an end-to-end training. To
reduce model degradation during online update, we apply residual learning to
take appearance changes into account. Extensive experiments on the benchmark
datasets demonstrate that our CREST tracker performs favorably against
state-of-the-art trackers.
"
1379,MM2RTB: Bringing Multimedia Metrics to Real-Time Bidding,"  In display advertising, users' online ad experiences are important for the
advertising effectiveness. However, users have not been well accommodated in
real-time bidding (RTB). This further influences their site visits and
perception of the displayed banner ads. In this paper, we propose a novel
computational framework which brings multimedia metrics, like the contextual
relevance, the visual saliency and the ad memorability into RTB to improve the
users' ad experiences as well as maintain the benefits of the publisher and the
advertiser. We aim at developing a vigorous ecosystem by optimizing the
trade-offs among all stakeholders. The framework considers the scenario of a
webpage with multiple ad slots. Our experimental results show that the benefits
of the advertiser and the user can be significantly improved if the publisher
would slightly sacrifice his short-term revenue. The improved benefits will
increase the advertising requests (demand) and the site visits (supply), which
can further boost the publisher's revenue in the long run.
"
1380,OmniArt: Multi-task Deep Learning for Artistic Data Analysis,"  Vast amounts of artistic data is scattered on-line from both museums and art
applications. Collecting, processing and studying it with respect to all
accompanying attributes is an expensive process. With a motivation to speed up
and improve the quality of categorical analysis in the artistic domain, in this
paper we propose an efficient and accurate method for multi-task learning with
a shared representation applied in the artistic domain. We continue to show how
different multi-task configurations of our method behave on artistic data and
outperform handcrafted feature approaches as well as convolutional neural
networks. In addition to the method and analysis, we propose a challenge like
nature to the new aggregated data set with almost half a million samples and
structured meta-data to encourage further research and societal engagement.
"
1381,"Aligned and Non-Aligned Double JPEG Detection Using Convolutional Neural
  Networks","  Due to the wide diffusion of JPEG coding standard, the image forensic
community has devoted significant attention to the development of double JPEG
(DJPEG) compression detectors through the years. The ability of detecting
whether an image has been compressed twice provides paramount information
toward image authenticity assessment. Given the trend recently gained by
convolutional neural networks (CNN) in many computer vision tasks, in this
paper we propose to use CNNs for aligned and non-aligned double JPEG
compression detection. In particular, we explore the capability of CNNs to
capture DJPEG artifacts directly from images. Results show that the proposed
CNN-based detectors achieve good performance even with small size images (i.e.,
64x64), outperforming state-of-the-art solutions, especially in the non-aligned
case. Besides, good results are also achieved in the commonly-recognized
challenging case in which the first quality factor is larger than the second
one.
"
1382,Attention Transfer from Web Images for Video Recognition,"  Training deep learning based video classifiers for action recognition
requires a large amount of labeled videos. The labeling process is
labor-intensive and time-consuming. On the other hand, large amount of
weakly-labeled images are uploaded to the Internet by users everyday. To
harness the rich and highly diverse set of Web images, a scalable approach is
to crawl these images to train deep learning based classifier, such as
Convolutional Neural Networks (CNN). However, due to the domain shift problem,
the performance of Web images trained deep classifiers tend to degrade when
directly deployed to videos. One way to address this problem is to fine-tune
the trained models on videos, but sufficient amount of annotated videos are
still required. In this work, we propose a novel approach to transfer knowledge
from image domain to video domain. The proposed method can adapt to the target
domain (i.e. video data) with limited amount of training data. Our method maps
the video frames into a low-dimensional feature space using the
class-discriminative spatial attention map for CNNs. We design a novel Siamese
EnergyNet structure to learn energy functions on the attention maps by jointly
optimizing two loss functions, such that the attention map corresponding to a
ground truth concept would have higher energy. We conduct extensive experiments
on two challenging video recognition datasets (i.e. TVHI and UCF101), and
demonstrate the efficacy of our proposed method.
"
1383,What your Facebook Profile Picture Reveals about your Personality,"  People spend considerable effort managing the impressions they give others.
Social psychologists have shown that people manage these impressions
differently depending upon their personality. Facebook and other social media
provide a new forum for this fundamental process; hence, understanding people's
behaviour on social media could provide interesting insights on their
personality. In this paper we investigate automatic personality recognition
from Facebook profile pictures. We analyze the effectiveness of four families
of visual features and we discuss some human interpretable patterns that
explain the personality traits of the individuals. For example, extroverts and
agreeable individuals tend to have warm colored pictures and to exhibit many
faces in their portraits, mirroring their inclination to socialize; while
neurotic ones have a prevalence of pictures of indoor places. Then, we propose
a classification approach to automatically recognize personality traits from
these visual features. Finally, we compare the performance of our
classification approach to the one obtained by human raters and we show that
computer-based classifications are significantly more accurate than averaged
human-based classifications for Extraversion and Neuroticism.
"
1384,Aktuelle Entwicklungen in der Automatischen Musikverfolgung,"  In this paper we present current trends in real-time music tracking (a.k.a.
score following). Casually speaking, these algorithms ""listen"" to a live
performance of music, compare the audio signal to an abstract representation of
the score, and ""read"" along in the sheet music. In this way at any given time
the exact position of the musician(s) in the sheet music is computed. Here, we
focus on the aspects of flexibility and usability of these algorithms. This
comprises work on automatic identification and flexible tracking of the piece
being played as well as current approaches based on Deep Learning. The latter
enables direct learning of correspondences between complex audio data and
images of the sheet music, avoiding the complicated and time-consuming
definition of a mid-level representation.
  -----
  Diese Arbeit befasst sich mit aktuellen Entwicklungen in der automatischen
Musikverfolgung durch den Computer. Es handelt sich dabei um Algorithmen, die
einer musikalischen Auff\""uhrung ""zuh\""oren"", das aufgenommene Audiosignal mit
einer (abstrakten) Repr\""asentation des Notentextes vergleichen und sozusagen
in diesem mitlesen. Der Algorithmus kennt also zu jedem Zeitpunkt die Position
der Musiker im Notentext. Neben der Vermittlung eines generellen \""Uberblicks,
liegt der Schwerpunkt dieser Arbeit auf der Beleuchtung des Aspekts der
Flexibilit\""at und der einfacheren Nutzbarkeit dieser Algorithmen. Es wird
dargelegt, welche Schritte get\""atigt wurden (und aktuell get\""atigt werden) um
den Prozess der automatischen Musikverfolgung einfacher zug\""anglich zu machen.
Dies umfasst Arbeiten zur automatischen Identifikation von gespielten St\""ucken
und deren flexible Verfolgung ebenso wie aktuelle Ans\""atze mithilfe von Deep
Learning, die es erlauben Bild und Ton direkt zu verbinden, ohne Umwege \""uber
abstrakte und nur unter gro{\ss}em Zeitaufwand zu erstellende
Zwischenrepr\""asentationen.
"
1385,"Speaker Diarization using Deep Recurrent Convolutional Neural Networks
  for Speaker Embeddings","  In this paper we propose a new method of speaker diarization that employs a
deep learning architecture to learn speaker embeddings. In contrast to the
traditional approaches that build their speaker embeddings using manually
hand-crafted spectral features, we propose to train for this purpose a
recurrent convolutional neural network applied directly on magnitude
spectrograms. To compare our approach with the state of the art, we collect and
release for the public an additional dataset of over 6 hours of fully annotated
broadcast material. The results of our evaluation on the new dataset and three
other benchmark datasets show that our proposed method significantly
outperforms the competitors and reduces diarization error rate by a large
margin of over 30% with respect to the baseline.
"
1386,"Joint Optimization of QoE and Fairness Through Network Assisted Adaptive
  Mobile Video Streaming","  MPEG has recently proposed Server and Network Assisted Dynamic Adaptive
Streaming over HTTP (SAND-DASH) for video streaming over the Internet. In
contrast to the purely client-based video streaming in which each client makes
its own decision to adjust its bitrate, SAND-DASH enables a group of
simultaneous clients to select their bitrates in a coordinated fashion in order
to improve resource utilization and quality of experience. In this paper, we
study the performance of such an adaptation strategy compared to the
traditional approach with large number of clients having mobile Internet
access. We propose a multi-servers multi-coordinators (MSs-MCs) framework to
model groups of remote clients accessing video content replicated to spatially
distributed edge servers. We then formulate an optimization problem to maximize
jointly the QoE of individual clients, proportional fairness in allocating the
limited resources of base stations as well as balancing the utilized resources
among multiple serves. We then present an efficient heuristic-based solution to
the problem and perform simulations in order to explore parameter space of the
scheme as well as to compare the performance to purely client-based DASH.
"
1387,"An evaluation of large-scale methods for image instance and class
  discovery","  This paper aims at discovering meaningful subsets of related images from
large image collections without annotations. We search groups of images related
at different levels of semantic, i.e., either instances or visual classes.
While k-means is usually considered as the gold standard for this task, we
evaluate and show the interest of diffusion methods that have been neglected by
the state of the art, such as the Markov Clustering algorithm.
  We report results on the ImageNet and the Paris500k instance dataset, both
enlarged with images from YFCC100M. We evaluate our methods with a labelling
cost that reflects how much effort a human would require to correct the
generated clusters.
  Our analysis highlights several properties. First, when powered with an
efficient GPU implementation, the cost of the discovery process is small
compared to computing the image descriptors, even for collections as large as
100 million images. Second, we show that descriptions selected for instance
search improve the discovery of object classes. Third, the Markov Clustering
technique consistently outperforms other methods; to our knowledge it has never
been considered in this large scale scenario.
"
1388,Robust Video Watermarking against H.264 and H.265 Compression Attacks,"  This paper proposes a robust watermarking method for uncompressed video data
against H.264/AVC and H.265/HEVC compression standards. We embed the watermark
data in the mid-range transform coefficients of a block that is less similar to
its corresponding block in the previous and next frames. This idea makes the
watermark robust against the compression standards that use the inter
prediction technique. The last two video compression standards also use inter
prediction for motion compensation like previous video compression standards.
Therefore, the proposed method is also well suited with these standards.
Simulation results show the adequate robustness and transparency of our
watermarking scheme.
"
1389,Image Quality Assessment Guided Deep Neural Networks Training,"  For many computer vision problems, the deep neural networks are trained and
validated based on the assumption that the input images are pristine (i.e.,
artifact-free). However, digital images are subject to a wide range of
distortions in real application scenarios, while the practical issues regarding
image quality in high level visual information understanding have been largely
ignored. In this paper, in view of the fact that most widely deployed deep
learning models are susceptible to various image distortions, the distorted
images are involved for data augmentation in the deep neural network training
process to learn a reliable model for practical applications. In particular, an
image quality assessment based label smoothing method, which aims at
regularizing the label distribution of training images, is further proposed to
tune the objective functions in learning the neural network. Experimental
results show that the proposed method is effective in dealing with both low and
high quality images in the typical image classification task.
"
1390,"uStash: a Novel Mobile Content Delivery System for Improving User QoE in
  Public Transport","  Mobile data traffic is growing exponentially and it is even more challenging
to distribute content efficiently while users are ""on the move"" such as in
public transport.The use of mobile devices for accessing content (e.g. videos)
while commuting are both expensive and unreliable, although it is becoming
common practice worldwide. Leveraging on the spatial and temporal correlation
of content popularity and users' diverse network connectivity, we propose a
novel content distribution system, \textit{uStash}, which guarantees better QoE
with regards to access delays and cost of usage. The proposed collaborative
download and content stashing schemes provide the uStash provider the
flexibility to control the cost of content access via cellular networks. We
model the uStash system in a probabilistic framework and thereby analytically
derive the optimal portions for collaborative downloading. Then, we validate
the proposed models using real-life trace driven simulations. In particular, we
use dataset from 22 inter-city buses running on 6 different routes and from a
mobile VoD service provider to show that uStash reduces the cost of monthly
cellular data by approximately 50\% and the expected delay for content access
by 60\% compared to content downloaded via users' cellular network connections.
"
1391,"Attacking Automatic Video Analysis Algorithms: A Case Study of Google
  Cloud Video Intelligence API","  Due to the growth of video data on Internet, automatic video analysis has
gained a lot of attention from academia as well as companies such as Facebook,
Twitter and Google. In this paper, we examine the robustness of video analysis
algorithms in adversarial settings. Specifically, we propose targeted attacks
on two fundamental classes of video analysis algorithms, namely video
classification and shot detection. We show that an adversary can subtly
manipulate a video in such a way that a human observer would perceive the
content of the original video, but the video analysis algorithm will return the
adversary's desired outputs.
  We then apply the attacks on the recently released Google Cloud Video
Intelligence API. The API takes a video file and returns the video labels
(objects within the video), shot changes (scene changes within the video) and
shot labels (description of video events over time). Through experiments, we
show that the API generates video and shot labels by processing only the first
frame of every second of the video. Hence, an adversary can deceive the API to
output only her desired video and shot labels by periodically inserting an
image into the video at the rate of one frame per second. We also show that the
pattern of shot changes returned by the API can be mostly recovered by an
algorithm that compares the histograms of consecutive frames. Based on our
equivalent model, we develop a method for slightly modifying the video frames,
in order to deceive the API into generating our desired pattern of shot
changes. We perform extensive experiments with different videos and show that
our attacks are consistently successful across videos with different
characteristics. At the end, we propose introducing randomness to video
analysis algorithms as a countermeasure to our attacks.
"
1392,"MHTN: Modal-adversarial Hybrid Transfer Network for Cross-modal
  Retrieval","  Cross-modal retrieval has drawn wide interest for retrieval across different
modalities of data. However, existing methods based on DNN face the challenge
of insufficient cross-modal training data, which limits the training
effectiveness and easily leads to overfitting. Transfer learning is for
relieving the problem of insufficient training data, but it mainly focuses on
knowledge transfer only from large-scale datasets as single-modal source domain
to single-modal target domain. Such large-scale single-modal datasets also
contain rich modal-independent semantic knowledge that can be shared across
different modalities. Besides, large-scale cross-modal datasets are very
labor-consuming to collect and label, so it is significant to fully exploit the
knowledge in single-modal datasets for boosting cross-modal retrieval. This
paper proposes modal-adversarial hybrid transfer network (MHTN), which to the
best of our knowledge is the first work to realize knowledge transfer from
single-modal source domain to cross-modal target domain, and learn cross-modal
common representation. It is an end-to-end architecture with two subnetworks:
(1) Modal-sharing knowledge transfer subnetwork is proposed to jointly transfer
knowledge from a large-scale single-modal dataset in source domain to all
modalities in target domain with a star network structure, which distills
modal-independent supplementary knowledge for promoting cross-modal common
representation learning. (2) Modal-adversarial semantic learning subnetwork is
proposed to construct an adversarial training mechanism between common
representation generator and modality discriminator, making the common
representation discriminative for semantics but indiscriminative for modalities
to enhance cross-modal semantic consistency during transfer process.
Comprehensive experiments on 4 widely-used datasets show its effectiveness and
generality.
"
1393,"Modality-specific Cross-modal Similarity Measurement with Recurrent
  Attention Network","  Nowadays, cross-modal retrieval plays an indispensable role to flexibly find
information across different modalities of data. Effectively measuring the
similarity between different modalities of data is the key of cross-modal
retrieval. Different modalities such as image and text have imbalanced and
complementary relationships, which contain unequal amount of information when
describing the same semantics. For example, images often contain more details
that cannot be demonstrated by textual descriptions and vice versa. Existing
works based on Deep Neural Network (DNN) mostly construct one common space for
different modalities to find the latent alignments between them, which lose
their exclusive modality-specific characteristics. Different from the existing
works, we propose modality-specific cross-modal similarity measurement (MCSM)
approach by constructing independent semantic space for each modality, which
adopts end-to-end framework to directly generate modality-specific cross-modal
similarity without explicit common representation. For each semantic space,
modality-specific characteristics within one modality are fully exploited by
recurrent attention network, while the data of another modality is projected
into this space with attention based joint embedding to utilize the learned
attention weights for guiding the fine-grained cross-modal correlation
learning, which can capture the imbalanced and complementary relationships
between different modalities. Finally, the complementarity between the semantic
spaces for different modalities is explored by adaptive fusion of the
modality-specific cross-modal similarities to perform cross-modal retrieval.
Experiments on the widely-used Wikipedia and Pascal Sentence datasets as well
as our constructed large-scale XMediaNet dataset verify the effectiveness of
our proposed approach, outperforming 9 state-of-the-art methods.
"
1394,Deep Binary Reconstruction for Cross-modal Hashing,"  With the increasing demand of massive multimodal data storage and
organization, cross-modal retrieval based on hashing technique has drawn much
attention nowadays. It takes the binary codes of one modality as the query to
retrieve the relevant hashing codes of another modality. However, the existing
binary constraint makes it difficult to find the optimal cross-modal hashing
function. Most approaches choose to relax the constraint and perform
thresholding strategy on the real-value representation instead of directly
solving the original objective. In this paper, we first provide a concrete
analysis about the effectiveness of multimodal networks in preserving the
inter- and intra-modal consistency. Based on the analysis, we provide a
so-called Deep Binary Reconstruction (DBRC) network that can directly learn the
binary hashing codes in an unsupervised fashion. The superiority comes from a
proposed simple but efficient activation function, named as Adaptive Tanh
(ATanh). The ATanh function can adaptively learn the binary codes and be
trained via back-propagation. Extensive experiments on three benchmark datasets
demonstrate that DBRC outperforms several state-of-the-art methods in both
image2text and text2image retrieval task.
"
1395,"Automatic Organisation and Quality Analysis of User-Generated Content
  with Audio Fingerprinting","  The increase of the quantity of user-generated content experienced in social
media has boosted the importance of analysing and organising the content by its
quality. Here, we propose a method that uses audio fingerprinting to organise
and infer the quality of user-generated audio content. The proposed method
detects the overlapping segments between different audio clips to organise and
cluster the data according to events, and to infer the audio quality of the
samples. A test setup with concert recordings manually crawled from YouTube is
used to validate the presented method. The results show that the proposed
method achieves better results than previous methods.
"
1396,"Automatic Organisation, Segmentation, and Filtering of User-Generated
  Audio Content","  Using solely the information retrieved by audio fingerprinting techniques, we
propose methods to treat a possibly large dataset of user-generated audio
content, that (1) enable the grouping of several audio files that contain a
common audio excerpt (i.e., are relative to the same event), and (2) give
information about how those files are correlated in terms of time and quality
inside each event. Furthermore, we use supervised learning to detect incorrect
matches that may arise from the audio fingerprinting algorithm itself, whilst
ensuring our model learns with previous predictions. All the presented methods
were further validated by user-generated recordings of several different
concerts manually crawled from YouTube.
"
1397,Image2song: Song Retrieval via Bridging Image Content and Lyric Words,"  Image is usually taken for expressing some kinds of emotions or purposes,
such as love, celebrating Christmas. There is another better way that combines
the image and relevant song to amplify the expression, which has drawn much
attention in the social network recently. Hence, the automatic selection of
songs should be expected. In this paper, we propose to retrieve semantic
relevant songs just by an image query, which is named as the image2song
problem. Motivated by the requirements of establishing correlation in
semantic/content, we build a semantic-based song retrieval framework, which
learns the correlation between image content and lyric words. This model uses a
convolutional neural network to generate rich tags from image regions, a
recurrent neural network to model lyric, and then establishes correlation via a
multi-layer perceptron. To reduce the content gap between image and lyric, we
propose to make the lyric modeling focus on the main image content via a tag
attention. We collect a dataset from the social-sharing multimodal data to
study the proposed problem, which consists of (image, music clip, lyric)
triplets. We demonstrate that our proposed model shows noticeable results in
the image2song retrieval task and provides suitable songs. Besides, the
song2image task is also performed.
"
1398,"360-degree Video Stitching for Dual-fisheye Lens Cameras Based On Rigid
  Moving Least Squares","  Dual-fisheye lens cameras are becoming popular for 360-degree video capture,
especially for User-generated content (UGC), since they are affordable and
portable. Images generated by the dual-fisheye cameras have limited overlap and
hence require non-conventional stitching techniques to produce high-quality
360x180-degree panoramas. This paper introduces a novel method to align these
images using interpolation grids based on rigid moving least squares.
Furthermore, jitter is the critical issue arising when one applies the
image-based stitching algorithms to video. It stems from the unconstrained
movement of stitching boundary from one frame to another. Therefore, we also
propose a new algorithm to maintain the temporal coherence of stitching
boundary to provide jitter-free 360-degree videos. Results show that the method
proposed in this paper can produce higher quality stitched images and videos
than prior work.
"
1399,An improved watermarking scheme for Internet applications,"  In this paper, a data hiding scheme ready for Internet applications is
proposed. An existing scheme based on chaotic iterations is improved, to
respond to some major Internet security concerns, such as digital rights
management, communication over hidden channels, and social search engines. By
using Reed Solomon error correcting codes and wavelets domain, we show that
this data hiding scheme can be improved to solve issues and requirements raised
by these Internet fields.
"
1400,More cat than cute? Interpretable Prediction of Adjective-Noun Pairs,"  The increasing availability of affect-rich multimedia resources has bolstered
interest in understanding sentiment and emotions in and from visual content.
Adjective-noun pairs (ANP) are a popular mid-level semantic construct for
capturing affect via visually detectable concepts such as ""cute dog"" or
""beautiful landscape"". Current state-of-the-art methods approach ANP prediction
by considering each of these compound concepts as individual tokens, ignoring
the underlying relationships in ANPs. This work aims at disentangling the
contributions of the `adjectives' and `nouns' in the visual prediction of ANPs.
Two specialised classifiers, one trained for detecting adjectives and another
for nouns, are fused to predict 553 different ANPs. The resulting ANP
prediction model is more interpretable as it allows us to study contributions
of the adjective and noun components. Source code and models are available at
https://imatge-upc.github.io/affective-2017-musa2/ .
"
1401,"Visually Lossless Coding in HEVC: A High Bit Depth and 4:4:4 Capable
  JND-Based Perceptual Quantisation Technique for HEVC","  Due to the increasing prevalence of high bit depth and YCbCr 4:4:4 video
data, it is desirable to develop a JND-based visually lossless coding technique
which can account for high bit depth 4:4:4 data in addition to standard 8-bit
precision chroma subsampled data. In this paper, we propose a Coding Block
(CB)-level JND-based luma and chroma perceptual quantisation technique for HEVC
named Pixel-PAQ. Pixel-PAQ exploits both luminance masking and chrominance
masking to achieve JND-based visually lossless coding; the proposed method is
compatible with high bit depth YCbCr 4:4:4 video data of any resolution. When
applied to YCbCr 4:4:4 high bit depth video data, Pixel-PAQ can achieve vast
bitrate reductions, of up to 75% (68.6% over four QP data points), compared
with a state-of-the-art luma-based JND method for HEVC named IDSQ. Moreover,
the participants in the subjective evaluations confirm that visually lossless
coding is successfully achieved by Pixel-PAQ (at a PSNR value of 28.04 dB in
one test).
"
1402,"Towards Automatic Construction of Diverse, High-quality Image Dataset","  The availability of labeled image datasets has been shown critical for
high-level image understanding, which continuously drives the progress of
feature designing and models developing. However, constructing labeled image
datasets is laborious and monotonous. To eliminate manual annotation, in this
work, we propose a novel image dataset construction framework by employing
multiple textual queries. We aim at collecting diverse and accurate images for
given queries from the Web. Specifically, we formulate noisy textual queries
removing and noisy images filtering as a multi-view and multi-instance learning
problem separately. Our proposed approach not only improves the accuracy but
also enhances the diversity of the selected images. To verify the effectiveness
of our proposed approach, we construct an image dataset with 100 categories.
The experiments show significant performance gains by using the generated data
of our approach on several tasks, such as image classification, cross-dataset
generalization, and object detection. The proposed method also consistently
outperforms existing weakly supervised and web-supervised approaches.
"
1403,Causally Regularized Learning with Agnostic Data Selection Bias,"  Most of previous machine learning algorithms are proposed based on the i.i.d.
hypothesis. However, this ideal assumption is often violated in real
applications, where selection bias may arise between training and testing
process. Moreover, in many scenarios, the testing data is not even available
during the training process, which makes the traditional methods like transfer
learning infeasible due to their need on prior of test distribution. Therefore,
how to address the agnostic selection bias for robust model learning is of
paramount importance for both academic research and real applications. In this
paper, under the assumption that causal relationships among variables are
robust across domains, we incorporate causal technique into predictive modeling
and propose a novel Causally Regularized Logistic Regression (CRLR) algorithm
by jointly optimize global confounder balancing and weighted logistic
regression. Global confounder balancing helps to identify causal features,
whose causal effect on outcome are stable across domains, then performing
logistic regression on those causal features constructs a robust predictive
model against the agnostic bias. To validate the effectiveness of our CRLR
algorithm, we conduct comprehensive experiments on both synthetic and real
world datasets. Experimental results clearly demonstrate that our CRLR
algorithm outperforms the state-of-the-art methods, and the interpretability of
our method can be fully depicted by the feature visualization.
"
1404,ElasticPlay: Interactive Video Summarization with Dynamic Time Budgets,"  Video consumption is being shifted from sit-and-watch to selective skimming.
Existing video player interfaces, however, only provide indirect manipulation
to support this emerging behavior. Video summarization alleviates this issue to
some extent, shortening a video based on the desired length of a summary as an
input variable. But an optimal length of a summarized video is often not
available in advance. Moreover, the user cannot edit the summary once it is
produced, limiting its practical applications. We argue that video
summarization should be an interactive, mixed-initiative process in which users
have control over the summarization procedure while algorithms help users
achieve their goal via video understanding. In this paper, we introduce
ElasticPlay, a mixed-initiative approach that combines an advanced video
summarization technique with direct interface manipulation to help users
control the video summarization process. Users can specify a time budget for
the remaining content while watching a video; our system then immediately
updates the playback plan using our proposed cut-and-forward algorithm,
determining which parts to skip or to fast-forward. This interactive process
allows users to fine-tune the summarization result with immediate feedback. We
show that our system outperforms existing video summarization techniques on the
TVSum50 dataset. We also report two lab studies (22 participants) and a
Mechanical Turk deployment study (60 participants), and show that the
participants responded favorably to ElasticPlay.
"
1405,Lossless Image and Intra-frame Compression with Integer-to-Integer DST,"  Video coding standards are primarily designed for efficient lossy
compression, but it is also desirable to support efficient lossless compression
within video coding standards using small modifications to the lossy coding
architecture. A simple approach is to skip transform and quantization, and
simply entropy code the prediction residual. However, this approach is
inefficient at compression. A more efficient and popular approach is to skip
transform and quantization but also process the residual block with DPCM, along
the horizontal or vertical direction, prior to entropy coding. This paper
explores an alternative approach based on processing the residual block with
integer-to-integer (i2i) transforms. I2i transforms can map integer pixels to
integer transform coefficients without increasing the dynamic range and can be
used for lossless compression. We focus on lossless intra coding and develop
novel i2i approximations of the odd type-3 DST (ODST-3). Experimental results
with the HEVC reference software show that the developed i2i approximations of
the ODST-3 improve lossless intra-frame compression efficiency with respect to
HEVC version 2, which uses the popular DPCM method, by an average 2.7% without
a significant effect on computational complexity.
"
1406,Stylizing Face Images via Multiple Exemplars,"  We address the problem of transferring the style of a headshot photo to face
images. Existing methods using a single exemplar lead to inaccurate results
when the exemplar does not contain sufficient stylized facial components for a
given photo. In this work, we propose an algorithm to stylize face images using
multiple exemplars containing different subjects in the same style. Patch
correspondences between an input photo and multiple exemplars are established
using a Markov Random Field (MRF), which enables accurate local energy transfer
via Laplacian stacks. As image patches from multiple exemplars are used, the
boundaries of facial components on the target image are inevitably
inconsistent. The artifacts are removed by a post-processing step using an
edge-preserving filter. Experimental results show that the proposed algorithm
consistently produces visually pleasing results.
"
1407,Dual-fisheye lens stitching for 360-degree imaging,"  Dual-fisheye lens cameras have been increasingly used for 360-degree
immersive imaging. However, the limited overlapping field of views and
misalignment between the two lenses give rise to visible discontinuities in the
stitching boundaries. This paper introduces a novel method for dual-fisheye
camera stitching that adaptively minimizes the discontinuities in the
overlapping regions to generate full spherical 360-degree images. Results show
that this approach can produce good quality stitched images for Samsung Gear
360 -- a dual-fisheye camera, even with hard-to-stitch objects in the stitching
borders.
"
1408,"A secure blind watermarking scheme based on DCT domain of the scrambled
  image","  This paper investigates a secure blind watermarking scheme. The main idea of
the scheme not only protects the watermark information but also the embedding
positions. To achieve a higher level of security, we propose a sub key
generation mechanism based on the singular value decomposition and hash
function, where sub keys depend on both the main key and the feature codes of
the original image. The different sub keys ensure that the embedding positions
are randomly selected for different original images. Watermark is embedded in
the Discrete Cosine Transform (DCT) coefficients of the scrambled original
image. Simulation results show that such embedded method resolves well the
contradiction of imperceptibility and robustness. Based on good correlation
properties of chaotic sequences, we design a detection method, which can
accurately compute geometric transformation (rotation and translation
transformations) parameters. The security analysis, including key space
analysis, key sensitivity analysis, cryptanalysis, and the comparison results
demonstrate that the proposed watermarking scheme also achieves high security.
"
1409,Abnormal Event Detection in Videos using Generative Adversarial Nets,"  In this paper we address the abnormality detection problem in crowded scenes.
We propose to use Generative Adversarial Nets (GANs), which are trained using
normal frames and corresponding optical-flow images in order to learn an
internal representation of the scene normality. Since our GANs are trained with
only normal data, they are not able to generate abnormal events. At testing
time the real data are compared with both the appearance and the motion
representations reconstructed by our GANs and abnormal areas are detected by
computing local differences. Experimental results on challenging abnormality
detection datasets show the superiority of the proposed method compared to the
state of the art in both frame-level and pixel-level abnormality detection
tasks.
"
1410,"Code Constructions for Physical Unclonable Functions and Biometric
  Secrecy Systems","  The two-terminal key agreement problem with biometric or physical identifiers
is considered. Two linear code constructions based on Wyner-Ziv coding are
developed. The first construction uses random linear codes and achieves all
points of the key-leakage-storage regions of the generated-secret and
chosen-secret models. The second construction uses nested polar codes for
vector quantization during enrollment and for error correction during
reconstruction. Simulations show that the nested polar codes achieve
privacy-leakage and storage rates that improve on existing code designs. One
proposed code achieves a rate tuple that cannot be achieved by existing
methods.
"
1411,"Query-by-example Spoken Term Detection using Attention-based Multi-hop
  Networks","  Retrieving spoken content with spoken queries, or query-by- example spoken
term detection (STD), is attractive because it makes possible the matching of
signals directly on the acoustic level without transcribing them into text.
Here, we propose an end-to-end query-by-example STD model based on an
attention-based multi-hop network, whose input is a spoken query and an audio
segment containing several utterances; the output states whether the audio
segment includes the query. The model can be trained in either a supervised
scenario using labeled data, or in an unsupervised fashion. In the supervised
scenario, we find that the attention mechanism and multiple hops improve
performance, and that the attention weights indicate the time span of the
detected terms. In the unsupervised setting, the model mimics the behavior of
the existing query-by-example STD system, yielding performance comparable to
the existing system but with a lower search time complexity.
"
1412,Simulated Annealing for JPEG Quantization,"  JPEG is one of the most widely used image formats, but in some ways remains
surprisingly unoptimized, perhaps because some natural optimizations would go
outside the standard that defines JPEG. We show how to improve JPEG compression
in a standard-compliant, backward-compatible manner, by finding improved
default quantization tables. We describe a simulated annealing technique that
has allowed us to find several quantization tables that perform better than the
industry standard, in terms of both compressed size and image fidelity.
Specifically, we derive tables that reduce the FSIM error by over 10% while
improving compression by over 20% at quality level 95 in our tests; we also
provide similar results for other quality levels. While we acknowledge our
approach can in some images lead to visible artifacts under large
magnification, we believe use of these quantization tables, or additional
tables that could be found using our methodology, would significantly reduce
JPEG file sizes with improved overall image quality.
"
1413,"Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional
  Neural Network","  Speech enhancement (SE) aims to reduce noise in speech signals. Most SE
techniques focus on addressing audio information only. In this work, inspired
by multimodal learning, which utilizes data from different modalities, and the
recent success of convolutional neural networks (CNNs) in SE, we propose an
audio-visual deep CNN (AVDCNN) SE model, which incorporates audio and visual
streams into a unified network model. In the proposed AVDCNN SE model, audio
and visual data are first processed using individual CNNs, and then, fused into
a joint network to generate enhanced speech at the output layer. The AVDCNN
model is trained in an end-to-end manner, and parameters are jointly learned
through back-propagation. We evaluate enhanced speech using five objective
criteria. Results show that the AVDCNN yields notably better performance,
compared with an audio-only CNN-based SE model and two conventional SE
approaches, confirming the effectiveness of integrating visual information into
the SE process.
"
1414,"Musical NeuroPicks: a consumer-grade BCI for on-demand music streaming
  services","  We investigated the possibility of using a machine-learning scheme in
conjunction with commercial wearable EEG-devices for translating listener's
subjective experience of music into scores that can be used in popular
on-demand music streaming services. Our study resulted into two variants,
differing in terms of performance and execution time, and hence, subserving
distinct applications in online streaming music platforms. The first method,
NeuroPicks, is extremely accurate but slower. It is based on the
well-established neuroscientific concepts of brainwave frequency bands,
activation asymmetry index and cross frequency coupling (CFC). The second
method, NeuroPicksVQ, offers prompt predictions of lower credibility and relies
on a custom-built version of vector quantization procedure that facilitates a
novel parameterization of the music-modulated brainwaves. Beyond the feature
engineering step, both methods exploit the inherent efficiency of extreme
learning machines (ELMs) so as to translate, in a personalized fashion, the
derived patterns into a listener's score. NeuroPicks method may find
applications as an integral part of contemporary music recommendation systems,
while NeuroPicksVQ can control the selection of music tracks. Encouraging
experimental results, from a pragmatic use of the systems, are presented.
"
1415,"SketchParse : Towards Rich Descriptions for Poorly Drawn Sketches using
  Multi-Task Hierarchical Deep Networks","  The ability to semantically interpret hand-drawn line sketches, although very
challenging, can pave way for novel applications in multimedia. We propose
SketchParse, the first deep-network architecture for fully automatic parsing of
freehand object sketches. SketchParse is configured as a two-level fully
convolutional network. The first level contains shared layers common to all
object categories. The second level contains a number of expert sub-networks.
Each expert specializes in parsing sketches from object categories which
contain structurally similar parts. Effectively, the two-level configuration
enables our architecture to scale up efficiently as additional categories are
added. We introduce a router layer which (i) relays sketch features from shared
layers to the correct expert (ii) eliminates the need to manually specify
object category during inference. To bypass laborious part-level annotation, we
sketchify photos from semantic object-part image datasets and use them for
training. Our architecture also incorporates object pose prediction as a novel
auxiliary task which boosts overall performance while providing supplementary
information regarding the sketch. We demonstrate SketchParse's abilities (i) on
two challenging large-scale sketch datasets (ii) in parsing unseen,
semantically related object categories (iii) in improving fine-grained
sketch-based image retrieval. As a novel application, we also outline how
SketchParse's output can be used to generate caption-style descriptions for
hand-drawn sketches.
"
1416,Cross-Domain Image Retrieval with Attention Modeling,"  With the proliferation of e-commerce websites and the ubiquitousness of smart
phones, cross-domain image retrieval using images taken by smart phones as
queries to search products on e-commerce websites is emerging as a popular
application. One challenge of this task is to locate the attention of both the
query and database images. In particular, database images, e.g. of fashion
products, on e-commerce websites are typically displayed with other
accessories, and the images taken by users contain noisy background and large
variations in orientation and lighting. Consequently, their attention is
difficult to locate. In this paper, we exploit the rich tag information
available on the e-commerce websites to locate the attention of database
images. For query images, we use each candidate image in the database as the
context to locate the query attention. Novel deep convolutional neural network
architectures, namely TagYNet and CtxYNet, are proposed to learn the attention
weights and then extract effective representations of the images. Experimental
results on public datasets confirm that our approaches have significant
improvement over the existing methods in terms of the retrieval accuracy and
efficiency.
"
1417,"Multi-modal Conditional Attention Fusion for Dimensional Emotion
  Prediction","  Continuous dimensional emotion prediction is a challenging task where the
fusion of various modalities usually achieves state-of-the-art performance such
as early fusion or late fusion. In this paper, we propose a novel multi-modal
fusion strategy named conditional attention fusion, which can dynamically pay
attention to different modalities at each time step. Long-short term memory
recurrent neural networks (LSTM-RNN) is applied as the basic uni-modality model
to capture long time dependencies. The weights assigned to different modalities
are automatically decided by the current input features and recent history
information rather than being fixed at any kinds of situation. Our experimental
results on a benchmark dataset AVEC2015 show the effectiveness of our method
which outperforms several common fusion strategies for valence prediction.
"
1418,"Image Processing Operations Identification via Convolutional Neural
  Network","  In recent years, image forensics has attracted more and more attention, and
many forensic methods have been proposed for identifying image processing
operations. Up to now, most existing methods are based on hand crafted
features, and just one specific operation is considered in their methods. In
many forensic scenarios, however, multiple classification for various image
processing operations is more practical. Besides, it is difficult to obtain
effective features by hand for some image processing operations. In this paper,
therefore, we propose a new convolutional neural network (CNN) based method to
adaptively learn discriminative features for identifying typical image
processing operations. We carefully design the high pass filter bank to get the
image residuals of the input image, the channel expansion layer to mix up the
resulting residuals, the pooling layers, and the activation functions employed
in our method. The extensive results show that the proposed method can
outperform the currently best method based on hand crafted features and three
related methods based on CNN for image steganalysis and/or forensics, achieving
the state-of-the-art results. Furthermore, we provide more supplementary
results to show the rationality and robustness of the proposed model.
"
1419,"Hierarchical Watermarking Framework Based on Analysis of Local
  Complexity Variations","  Increasing production and exchange of multimedia content has increased the
need for better protection of copyright by means of watermarking. Different
methods have been proposed to satisfy the tradeoff between imperceptibility and
robustness as two important characteristics in watermarking while maintaining
proper data-embedding capacity. Many watermarking methods use image independent
set of parameters. Different images possess different potentials for robust and
transparent hosting of watermark data. To overcome this deficiency, in this
paper we have proposed a new hierarchical adaptive watermarking framework. At
the higher level of hierarchy, complexity of an image is ranked in comparison
with complexities of images of a dataset. For a typical dataset of images, the
statistical distribution of block complexities is found. At the lower level of
the hierarchy, for a single cover image that is to be watermarked, complexities
of blocks can be found. Local complexity variation (LCV) among a block and its
neighbors is used to adaptively control the watermark strength factor of each
block. Such local complexity analysis creates an adaptive embedding scheme,
which results in higher transparency by reducing blockiness effects. This two
level hierarchy has enabled our method to take advantage of all image blocks to
elevate the embedding capacity while preserving imperceptibility. For testing
the effectiveness of the proposed framework, contourlet transform (CT) in
conjunction with discrete cosine transform (DCT) is used to embed pseudo-random
binary sequences as watermark. Experimental results show that the proposed
framework elevates the performance the watermarking routine in terms of both
robustness and transparency.
"
1420,PQk-means: Billion-scale Clustering for Product-quantized Codes,"  Data clustering is a fundamental operation in data analysis. For handling
large-scale data, the standard k-means clustering method is not only slow, but
also memory-inefficient. We propose an efficient clustering method for
billion-scale feature vectors, called PQk-means. By first compressing input
vectors into short product-quantized (PQ) codes, PQk-means achieves fast and
memory-efficient clustering, even for high-dimensional vectors. Similar to
k-means, PQk-means repeats the assignment and update steps, both of which can
be performed in the PQ-code domain. Experimental results show that even
short-length (32 bit) PQ-codes can produce competitive results compared with
k-means. This result is of practical importance for clustering in
memory-restricted environments. Using the proposed PQk-means scheme, the
clustering of one billion 128D SIFT features with K = 10^5 is achieved within
14 hours, using just 32 GB of memory consumption on a single computer.
"
1421,Multimodal Content Analysis for Effective Advertisements on YouTube,"  The rapid advances in e-commerce and Web 2.0 technologies have greatly
increased the impact of commercial advertisements on the general public. As a
key enabling technology, a multitude of recommender systems exists which
analyzes user features and browsing patterns to recommend appealing
advertisements to users. In this work, we seek to study the characteristics or
attributes that characterize an effective advertisement and recommend a useful
set of features to aid the designing and production processes of commercial
advertisements. We analyze the temporal patterns from multimedia content of
advertisement videos including auditory, visual and textual components, and
study their individual roles and synergies in the success of an advertisement.
The objective of this work is then to measure the effectiveness of an
advertisement, and to recommend a useful set of features to advertisement
designers to make it more successful and approachable to users. Our proposed
framework employs the signal processing technique of cross modality feature
learning where data streams from different components are employed to train
separate neural network models and are then fused together to learn a shared
representation. Subsequently, a neural network model trained on this joint
feature embedding representation is utilized as a classifier to predict
advertisement effectiveness. We validate our approach using subjective ratings
from a dedicated user study, the sentiment strength of online viewer comments,
and a viewer opinion metric of the ratio of the Likes and Views received by
each advertisement from an online platform.
"
1422,"Contrast Enhancement of Brightness-Distorted Images by Improved Adaptive
  Gamma Correction","  As an efficient image contrast enhancement (CE) tool, adaptive gamma
correction (AGC) was previously proposed by relating gamma parameter with
cumulative distribution function (CDF) of the pixel gray levels within an
image. ACG deals well with most dimmed images, but fails for globally bright
images and the dimmed images with local bright regions. Such two categories of
brightness-distorted images are universal in real scenarios, such as improper
exposure and white object regions. In order to attenuate such deficiencies,
here we propose an improved AGC algorithm. The novel strategy of negative
images is used to realize CE of the bright images, and the gamma correction
modulated by truncated CDF is employed to enhance the dimmed ones. As such,
local over-enhancement and structure distortion can be alleviated. Both
qualitative and quantitative experimental results show that our proposed method
yields consistently good CE results.
"
1423,"Acceleration of Histogram-Based Contrast Enhancement via Selective
  Downsampling","  In this paper, we propose a general framework to accelerate the universal
histogram-based image contrast enhancement (CE) algorithms. Both spatial and
gray-level selective down- sampling of digital images are adopted to decrease
computational cost, while the visual quality of enhanced images is still
preserved and without apparent degradation. Mapping function calibration is
novelly proposed to reconstruct the pixel mapping on the gray levels missed by
downsampling. As two case studies, accelerations of histogram equalization (HE)
and the state-of-the-art global CE algorithm, i.e., spatial mutual information
and PageRank (SMIRANK), are presented detailedly. Both quantitative and
qualitative assessment results have verified the effectiveness of our proposed
CE acceleration framework. In typical tests, computational efficiencies of HE
and SMIRANK have been speeded up by about 3.9 and 13.5 times, respectively.
"
1424,Neural network-based arithmetic coding of intra prediction modes in HEVC,"  In both H.264 and HEVC, context-adaptive binary arithmetic coding (CABAC) is
adopted as the entropy coding method. CABAC relies on manually designed
binarization processes as well as handcrafted context models, which may
restrict the compression efficiency. In this paper, we propose an arithmetic
coding strategy by training neural networks, and make preliminary studies on
coding of the intra prediction modes in HEVC. Instead of binarization, we
propose to directly estimate the probability distribution of the 35 intra
prediction modes with the adoption of a multi-level arithmetic codec. Instead
of handcrafted context models, we utilize convolutional neural network (CNN) to
perform the probability estimation. Simulation results show that our proposed
arithmetic coding leads to as high as 9.9% bits saving compared with CABAC.
"
1425,Continuous Multimodal Emotion Recognition Approach for AVEC 2017,"  This paper reports the analysis of audio and visual features in predicting
the continuous emotion dimensions under the seventh Audio/Visual Emotion
Challenge (AVEC 2017), which was done as part of a B.Tech. 2nd year internship
project. For visual features we used the HOG (Histogram of Gradients) features,
Fisher encodings of SIFT (Scale-Invariant Feature Transform) features based on
Gaussian mixture model (GMM) and some pretrained Convolutional Neural Network
layers as features; all these extracted for each video clip. For audio features
we used the Bag-of-audio-words (BoAW) representation of the LLDs (low-level
descriptors) generated by openXBOW provided by the organisers of the event.
Then we trained fully connected neural network regression model on the dataset
for all these different modalities. We applied multimodal fusion on the output
models to get the Concordance correlation coefficient on Development set as
well as Test set.
"
1426,"Depression Scale Recognition from Audio, Visual and Text Analysis","  Depression is a major mental health disorder that is rapidly affecting lives
worldwide. Depression not only impacts emotional but also physical and
psychological state of the person. Its symptoms include lack of interest in
daily activities, feeling low, anxiety, frustration, loss of weight and even
feeling of self-hatred. This report describes work done by us for Audio Visual
Emotion Challenge (AVEC) 2017 during our second year BTech summer internship.
With the increase in demand to detect depression automatically with the help of
machine learning algorithms, we present our multimodal feature extraction and
decision level fusion approach for the same. Features are extracted by
processing on the provided Distress Analysis Interview Corpus-Wizard of Oz
(DAIC-WOZ) database. Gaussian Mixture Model (GMM) clustering and Fisher vector
approach were applied on the visual data; statistical descriptors on gaze,
pose; low level audio features and head pose and text features were also
extracted. Classification is done on fused as well as independent features
using Support Vector Machine (SVM) and neural networks. The results obtained
were able to cross the provided baseline on validation data set by 17% on audio
features and 24.5% on video features.
"
1427,"Protest Activity Detection and Perceived Violence Estimation from Social
  Media Images","  We develop a novel visual model which can recognize protesters, describe
their activities by visual attributes and estimate the level of perceived
violence in an image. Studies of social media and protests use natural language
processing to track how individuals use hashtags and links, often with a focus
on those items' diffusion. These approaches, however, may not be effective in
fully characterizing actual real-world protests (e.g., violent or peaceful) or
estimating the demographics of participants (e.g., age, gender, and race) and
their emotions. Our system characterizes protests along these dimensions. We
have collected geotagged tweets and their images from 2013-2017 and analyzed
multiple major protest events in that period. A multi-task convolutional neural
network is employed in order to automatically classify the presence of
protesters in an image and predict its visual attributes, perceived violence
and exhibited emotions. We also release the UCLA Protest Image Dataset, our
novel dataset of 40,764 images (11,659 protest images and hard negatives) with
various annotations of visual attributes and sentiments. Using this dataset, we
train our model and demonstrate its effectiveness. We also present experimental
results from various analysis on geotagged image data in several prevalent
protest events. Our dataset will be made accessible at
https://www.sscnet.ucla.edu/comm/jjoo/mm-protest/.
"
1428,"Adaptive Blind Image Watermarking Using Fuzzy Inference System Based on
  Human Visual Perception","  Development of digital content has increased the necessity of copyright
protection by means of watermarking. Imperceptibility and robustness are two
important features of watermarking algorithms. The goal of watermarking methods
is to satisfy the tradeoff between these two contradicting characteristics.
Recently watermarking methods in transform domains have displayed favorable
results. In this paper, we present an adaptive blind watermarking method which
has high transparency in areas that are important to human visual system. We
propose a fuzzy system for adaptive control of the embedding strength factor.
Features such as saliency, intensity, and edge-concentration, are used as fuzzy
attributes. Redundant embedding in discrete cosine transform (DCT) of wavelet
domain has increased the robustness of our method. Experimental results show
the efficiency of the proposed method and better results are obtained as
compared to comparable methods with same size of watermark logo.
"
1429,A new adaptive method for hiding data in images,"  LSB method is one of the well-known steganography methods which hides the
message bits into the least significant bit of pixel values. This method
changes the statistical information of images, which causes to have an
unsecured channel. To increase the security of this method against the
steganalysis methods, in this paper an adaptive method for hiding data into
images will be proposed. So, the amount of data and the method which is used
for hiding data in each area of image will be different. Experimental results
show that the security of the proposed method is higher than general LSB method
and in some cases the capacity of the carrier signal is increased.
"
1430,Enhancing Quality for HEVC Compressed Videos,"  The latest High Efficiency Video Coding (HEVC) standard has been increasingly
applied to generate video streams over the Internet. However, HEVC compressed
videos may incur severe quality degradation, particularly at low bit-rates.
Thus, it is necessary to enhance the visual quality of HEVC videos at the
decoder side. To this end, this paper proposes a Quality Enhancement
Convolutional Neural Network (QE-CNN) method that does not require any
modification of the encoder to achieve quality enhancement for HEVC. In
particular, our QE-CNN method learns QE-CNN-I and QE-CNN-P models to reduce the
distortion of HEVC I and P frames, respectively. The proposed method differs
from the existing CNN-based quality enhancement approaches, which only handle
intra-coding distortion and are thus not suitable for P frames. Our
experimental results validate that our QE-CNN method is effective in enhancing
quality for both I and P frames of HEVC videos. To apply our QE-CNN method in
time-constrained scenarios, we further propose a Time-constrained Quality
Enhancement Optimization (TQEO) scheme. Our TQEO scheme controls the
computational time of QE-CNN to meet a target, meanwhile maximizing the quality
enhancement. Next, the experimental results demonstrate the effectiveness of
our TQEO scheme from the aspects of time control accuracy and quality
enhancement under different time constraints. Finally, we design a prototype to
implement our TQEO scheme in a real-time scenario.
"
1431,Temporal Multimodal Fusion for Video Emotion Classification in the Wild,"  This paper addresses the question of emotion classification. The task
consists in predicting emotion labels (taken among a set of possible labels)
best describing the emotions contained in short video clips. Building on a
standard framework -- lying in describing videos by audio and visual features
used by a supervised classifier to infer the labels -- this paper investigates
several novel directions. First of all, improved face descriptors based on 2D
and 3D Convo-lutional Neural Networks are proposed. Second, the paper explores
several fusion methods, temporal and multimodal, including a novel hierarchical
method combining features and scores. In addition, we carefully reviewed the
different stages of the pipeline and designed a CNN architecture adapted to the
task; this is important as the size of the training set is small compared to
the difficulty of the problem, making generalization difficult. The so-obtained
model ranked 4th at the 2017 Emotion in the Wild challenge with the accuracy of
58.8 %.
"
1432,Calibrated steganalysis of mp3stego in multi-encoder scenario,"  Comparing popularity of mp3 and wave with the amount of works published on
each of them shows mp3 steganalysis has not found adequate attention.
Furthermore, investigating existing works on mp3 steganalysis shows that a
major factor has been overlooked. Experimenting with different mp3 encoders
shows there are subtle differences in their outputs. This shows that mp3
standard has been implemented in dissimilar fashions, which in turn could
degrade performance of steganalysis if it is not addressed properly.
Additionally, calibration is a powerful technique which has not found its true
potential for mp3 steganalysis. This paper tries to fill these gaps. First, we
present our analysis on different encoders and show they can be classified
quite accurately with only four features. Then, we propose a new set of
calibrated features based on quantization step. To that end, we show
quantization step is a band limited signal and steganography noise affects its
high frequency components more prominently. By applying a low pass filter on
quantization steps, we arrive at an estimation of quantization step, which in
turn is used for calibrating the features.
"
1433,Spatial-Temporal Residue Network Based In-Loop Filter for Video Coding,"  Deep learning has demonstrated tremendous break through in the area of
image/video processing. In this paper, a spatial-temporal residue network
(STResNet) based in-loop filter is proposed to suppress visual artifacts such
as blocking, ringing in video coding. Specifically, the spatial and temporal
information is jointly exploited by taking both current block and co-located
block in reference frame into consideration during the processing of in-loop
filter. The architecture of STResNet only consists of four convolution layers
which shows hospitality to memory and coding complexity. Moreover, to fully
adapt the input content and improve the performance of the proposed in-loop
filter, coding tree unit (CTU) level control flag is applied in the sense of
rate-distortion optimization. Extensive experimental results show that our
scheme provides up to 5.1% bit-rate reduction compared to the state-of-the-art
video coding standard.
"
1434,"Encoding Bitrate Optimization Using Playback Statistics for HTTP-based
  Adaptive Video Streaming","  HTTP video streaming is in wide use to deliver video over the Internet. With
HTTP adaptive steaming, a video playback dynamically selects a video stream
from a pre-encoded representation based on available bandwidth and viewport
(screen) size. The viewer's video quality is therefore influenced by the
encoded bitrates. We minimize the average delivered bitrate subject to a
quality lower bound on a per-chunk basis by modeling the probability that a
player selects a particular encoding. Through simulation and real-world
experiments, the proposed method saves 9.6% of bandwidth while average
delivered video quality comparing with state of the art while keeping average
delivered video quality.
"
1435,Region-Based Image Retrieval Revisited,"  Region-based image retrieval (RBIR) technique is revisited. In early attempts
at RBIR in the late 90s, researchers found many ways to specify region-based
queries and spatial relationships; however, the way to characterize the
regions, such as by using color histograms, were very poor at that time. Here,
we revisit RBIR by incorporating semantic specification of objects and
intuitive specification of spatial relationships. Our contributions are the
following. First, to support multiple aspects of semantic object specification
(category, instance, and attribute), we propose a multitask CNN feature that
allows us to use deep learning technique and to jointly handle multi-aspect
object specification. Second, to help users specify spatial relationships among
objects in an intuitive way, we propose recommendation techniques of spatial
relationships. In particular, by mining the search results, a system can
recommend feasible spatial relationships among the objects. The system also can
recommend likely spatial relationships by assigned object category names based
on language prior. Moreover, object-level inverted indexing supports very fast
shortlist generation, and re-ranking based on spatial constraints provides
users with instant RBIR experiences.
"
1436,"On the Complex Network Structure of Musical Pieces: Analysis of Some Use
  Cases from Different Music Genres","  This paper focuses on the modeling of musical melodies as networks. Notes of
a melody can be treated as nodes of a network. Connections are created whenever
notes are played in sequence. We analyze some main tracks coming from different
music genres, with melodies played using different musical instruments. We find
out that the considered networks are, in general, scale free networks and
exhibit the small world property. We measure the main metrics and assess
whether these networks can be considered as formed by sub-communities. Outcomes
confirm that peculiar features of the tracks can be extracted from this
analysis methodology. This approach can have an impact in several multimedia
applications such as music didactics, multimedia entertainment, and digital
music generation.
"
1437,"Impact of Three-Dimensional Video Scalability on Multi-View Activity
  Recognition using Deep Learning","  Human activity recognition is one of the important research topics in
computer vision and video understanding. It is often assumed that high quality
video sequences are available for recognition. However, relaxing such a
requirement and implementing robust recognition using videos having reduced
data rates can achieve efficiency in storing and transmitting video data.
Three-dimensional video scalability, which refers to the possibility of
reducing spatial, temporal, and quality resolutions of videos, is an effective
way for flexible representation and management of video data. In this paper, we
investigate the impact of the video scalability on multi-view activity
recognition. We employ both a spatiotemporal feature extraction-based method
and a deep learning-based method using convolutional and recurrent neural
networks. The recognition performance of the two methods is examined, along
with in-depth analysis regarding how their performance vary with respect to
various scalability combinations. In particular, we demonstrate that the deep
learning-based method can achieve significantly improved robustness in
comparison to the feature-based method. Furthermore, we investigate optimal
scalability combinations with respect to bitrate in order to provide useful
guidelines for an optimal operation policy in resource-constrained activity
recognition systems.
"
1438,Video Generation From Text,"  Generating videos from text has proven to be a significant challenge for
existing generative models. We tackle this problem by training a conditional
generative model to extract both static and dynamic information from text. This
is manifested in a hybrid framework, employing a Variational Autoencoder (VAE)
and a Generative Adversarial Network (GAN). The static features, called ""gist,""
are used to sketch text-conditioned background color and object layout
structure. Dynamic features are considered by transforming input text into an
image filter. To obtain a large amount of data for training the deep-learning
model, we develop a method to automatically create a matched text-video corpus
from publicly available online videos. Experimental results show that the
proposed framework generates plausible and diverse videos, while accurately
reflecting the input text information. It significantly outperforms baseline
models that directly adapt text-to-image generation procedures to produce
videos. Performance is evaluated both visually and by adapting the inception
score used to evaluate image generation in GANs.
"
1439,"Multi-layer architecture for efficient steganalysis of Undermp3cover in
  multi-encoder scenario","  Mp3 is a very popular audio format and hence it can be a good host for
carrying hidden messages. Therefore, different steganography methods have been
proposed for mp3 hosts. But, current literature has only focused on
steganalysis of mp3stego. In this paper we mention some of the limitations of
mp3stego and argue that UnderMp3Cover (Ump3c) does not have those limitations.
Ump3c makes subtle changes only to the global gain of bitstream and keeps the
rest of bitstream intact. Therefore, its detection is much harder than
mp3stego. To address this, joint distributions between global gain and other
fields of mp3 bit stream are used. The changes are detected by measuring the
mutual information from those joint distributions. Furthermore, we show that
different mp3 encoders have dissimilar performances. Consequently, a novel
multi-layer architecture for steganalysis of Ump3c is proposed. In this manner,
the first layer detects the encoder and the second layer performs the
steganalysis job. One of advantages of this architecture is that feature
extraction and feature selection can be optimized for each encoder separately.
We show this multi-layer architecture outperforms the conventional single-layer
methods. Comparing results of the proposed method with other works shows an
improvement of 20.4% in the accuracy of steganalysis.
"
1440,Evaluation of the Performance of Adaptive HTTP Streaming Systems,"  Adaptive video streaming over HTTP is becoming omnipresent in our daily life.
In the past, dozens of research papers have proposed novel approaches to
address different aspects of adaptive streaming and a decent amount of player
implementations (commercial and open source) are available. However, state of
the art evaluations are sometimes superficial as many proposals only
investigate a certain aspect of the problem or focus on a specific platform -
player implementations used in actual services are rarely considered. HTML5 is
now available on many platforms and foster the deployment of adaptive media
streaming applications. We propose a common evaluation framework for adaptive
HTML5 players and demonstrate its applicability by evaluating eight different
players which are actually deployed in real-world services.
"
1441,"Attribute Compression of 3D Point Clouds Using Laplacian Sparsity
  Optimized Graph Transform","  3D sensing and content capture have made significant progress in recent years
and the MPEG standardization organization is launching a new project on
immersive media with point cloud compression (PCC) as one key corner stone. In
this work, we introduce a new binary tree based point cloud content partition
and explore the graph signal processing tools, especially the graph transform
with optimized Laplacian sparsity, to achieve better energy compaction and
compression efficiency. The resulting rate-distortion operating points are
convex-hull optimized over the existing Lagrangian solutions. Simulation
results with the latest high quality point cloud content captured from the MPEG
PCC demonstrated the transform efficiency and rate-distortion (R-D) optimal
potential of the proposed solutions.
"
1442,Recent Advances in Zero-shot Recognition,"  With the recent renaissance of deep convolution neural networks, encouraging
breakthroughs have been achieved on the supervised recognition tasks, where
each class has sufficient training data and fully annotated training data.
However, to scale the recognition to a large number of classes with few or now
training samples for each class remains an unsolved problem. One approach to
scaling up the recognition is to develop models capable of recognizing unseen
categories without any training instances, or zero-shot recognition/ learning.
This article provides a comprehensive review of existing zero-shot recognition
techniques covering various aspects ranging from representations of models, and
from datasets and evaluation settings. We also overview related recognition
tasks including one-shot and open set recognition which can be used as natural
extensions of zero-shot recognition when limited number of class samples become
available or when zero-shot recognition is implemented in a real-world setting.
Importantly, we highlight the limitations of existing approaches and point out
future research directions in this existing new research area.
"
1443,"CM-GANs: Cross-modal Generative Adversarial Networks for Common
  Representation Learning","  It is known that the inconsistent distribution and representation of
different modalities, such as image and text, cause the heterogeneity gap that
makes it challenging to correlate such heterogeneous data. Generative
adversarial networks (GANs) have shown its strong ability of modeling data
distribution and learning discriminative representation, existing GANs-based
works mainly focus on generative problem to generate new data. We have
different goal, aim to correlate heterogeneous data, by utilizing the power of
GANs to model cross-modal joint distribution. Thus, we propose Cross-modal GANs
to learn discriminative common representation for bridging heterogeneity gap.
The main contributions are: (1) Cross-modal GANs architecture is proposed to
model joint distribution over data of different modalities. The inter-modality
and intra-modality correlation can be explored simultaneously in generative and
discriminative models. Both of them beat each other to promote cross-modal
correlation learning. (2) Cross-modal convolutional autoencoders with
weight-sharing constraint are proposed to form generative model. They can not
only exploit cross-modal correlation for learning common representation, but
also preserve reconstruction information for capturing semantic consistency
within each modality. (3) Cross-modal adversarial mechanism is proposed, which
utilizes two kinds of discriminative models to simultaneously conduct
intra-modality and inter-modality discrimination. They can mutually boost to
make common representation more discriminative by adversarial training process.
To the best of our knowledge, our proposed CM-GANs approach is the first to
utilize GANs to perform cross-modal common representation learning. Experiments
are conducted to verify the performance of our proposed approach on cross-modal
retrieval paradigm, compared with 10 methods on 3 cross-modal datasets.
"
1444,"Vector Quantization using the Improved Differential Evolution Algorithm
  for Image Compression","  Vector Quantization, VQ is a popular image compression technique with a
simple decoding architecture and high compression ratio. Codebook designing is
the most essential part in Vector Quantization. LindeBuzoGray, LBG is a
traditional method of generation of VQ Codebook which results in lower PSNR
value. A Codebook affects the quality of image compression, so the choice of an
appropriate codebook is a must. Several optimization techniques have been
proposed for global codebook generation to enhance the quality of image
compression. In this paper, a novel algorithm called IDE-LBG is proposed which
uses Improved Differential Evolution Algorithm coupled with LBG for generating
optimum VQ Codebooks. The proposed IDE works better than the traditional DE
with modifications in the scaling factor and the boundary control mechanism.
The IDE generates better solutions by efficient exploration and exploitation of
the search space. Then the best optimal solution obtained by the IDE is
provided as the initial Codebook for the LBG. This approach produces an
efficient Codebook with less computational time and the consequences include
excellent PSNR values and superior quality reconstructed images. It is observed
that the proposed IDE-LBG find better VQ Codebooks as compared to IPSO-LBG,
BA-LBG and FA-LBG.
"
1445,"A multi-branch convolutional neural network for detecting double JPEG
  compression","  Detection of double JPEG compression is important to forensics analysis. A
few methods were proposed based on convolutional neural networks (CNNs). These
methods only accept inputs from pre-processed data, such as histogram features
and/or decompressed images. In this paper, we present a CNN solution by using
raw DCT (discrete cosine transformation) coefficients from JPEG images as
input. Considering the DCT sub-band nature in JPEG, a multiple-branch CNN
structure has been designed to reveal whether a JPEG format image has been
doubly compressed. Comparing with previous methods, the proposed method
provides end-to-end detection capability. Extensive experiments have been
carried out to demonstrate the effectiveness of the proposed network.
"
1446,Learning Social Image Embedding with Deep Multimodal Attention Networks,"  Learning social media data embedding by deep models has attracted extensive
research interest as well as boomed a lot of applications, such as link
prediction, classification, and cross-modal search. However, for social images
which contain both link information and multimodal contents (e.g., text
description, and visual content), simply employing the embedding learnt from
network structure or data content results in sub-optimal social image
representation. In this paper, we propose a novel social image embedding
approach called Deep Multimodal Attention Networks (DMAN), which employs a deep
model to jointly embed multimodal contents and link information. Specifically,
to effectively capture the correlations between multimodal contents, we propose
a multimodal attention network to encode the fine-granularity relation between
image regions and textual words. To leverage the network structure for
embedding learning, a novel Siamese-Triplet neural network is proposed to model
the links among images. With the joint deep model, the learnt embedding can
capture both the multimodal contents and the nonlinear network information.
Extensive experiments are conducted to investigate the effectiveness of our
approach in the applications of multi-label classification and cross-modal
search. Compared to state-of-the-art image embeddings, our proposed DMAN
achieves significant improvement in the tasks of multi-label classification and
cross-modal search.
"
1447,"Compressive Online Robust Principal Component Analysis with Optical Flow
  for Video Foreground-Background Separation","  In the context of online Robust Principle Component Analysis (RPCA) for the
video foreground-background separation, we propose a compressive online RPCA
with optical flow that separates recursively a sequence of frames into sparse
(foreground) and low-rank (background) components. Our method considers a small
set of measurements taken per data vector (frame), which is different from
conventional batch RPCA, processing all the data directly. The proposed method
also incorporates multiple prior information, namely previous foreground and
background frames, to improve the separation and then updates the prior
information for the next frame. Moreover, the foreground prior frames are
improved by estimating motions between the previous foreground frames using
optical flow and compensating the motions to achieve higher quality foreground
prior. The proposed method is applied to online video foreground and background
separation from compressive measurements. The visual and quantitative results
show that our method outperforms the existing methods.
"
1448,JND-Based Perceptual Video Coding for 4:4:4 Screen Content Data in HEVC,"  The JCT-VC standardized Screen Content Coding (SCC) extension in the HEVC HM
RExt + SCM reference codec offers an impressive coding efficiency performance
when compared with HM RExt alone; however, it is not significantly perceptually
optimized. For instance, it does not include advanced HVS-based perceptual
coding methods, such as JND-based spatiotemporal masking schemes. In this
paper, we propose a novel JND-based perceptual video coding technique for HM
RExt + SCM. The proposed method is designed to further improve the compression
performance of HM RExt + SCM when applied to YCbCr 4:4:4 SC video data. In the
proposed technique, luminance masking and chrominance masking are exploited to
perceptually adjust the Quantization Step Size (QStep) at the Coding Block (CB)
level. Compared with HM RExt 16.10 + SCM 8.0, the proposed method considerably
reduces bitrates (Kbps), with a maximum reduction of 48.3%. In addition to
this, the subjective evaluations reveal that SC-PAQ achieves visually lossless
coding at very low bitrates.
"
1449,"A Single-Channel Architecture for Algebraic Integer Based 8$\times$8 2-D
  DCT Computation","  An area efficient row-parallel architecture is proposed for the real-time
implementation of bivariate algebraic integer (AI) encoded 2-D discrete cosine
transform (DCT) for image and video processing. The proposed architecture
computes 8$\times$8 2-D DCT transform based on the Arai DCT algorithm. An
improved fast algorithm for AI based 1-D DCT computation is proposed along with
a single channel 2-D DCT architecture. The design improves on the 4-channel AI
DCT architecture that was published recently by reducing the number of integer
channels to one and the number of 8-point 1-D DCT cores from 5 down to 2. The
architecture offers exact computation of 8$\times$8 blocks of the 2-D DCT
coefficients up to the FRS, which converts the coefficients from the AI
representation to fixed-point format using the method of expansion factors.
Prototype circuits corresponding to FRS blocks based on two expansion factors
are realized, tested, and verified on FPGA-chip, using a Xilinx Virtex-6
XC6VLX240T device. Post place-and-route results show a 20% reduction in terms
of area compared to the 2-D DCT architecture requiring five 1-D AI cores. The
area-time and area-time${}^2$ complexity metrics are also reduced by 23% and
22% respectively for designs with 8-bit input word length. The digital
realizations are simulated up to place and route for ASICs using 45 nm CMOS
standard cells. The maximum estimated clock rate is 951 MHz for the CMOS
realizations indicating 7.608$\cdot$10$^9$ pixels/seconds and a 8$\times$8
block rate of 118.875 MHz.
"
1450,"Watching Videos with Certain and Constant Quality: PID-based Quality
  Control Method","  In video coding, compressed videos with certain and constant quality can
ensure quality of experience (QoE). To this end, we propose in this paper a
novel PID-based quality control (PQC) method for video coding. Specifically, a
formulation is modelled to control quality of video coding with two objectives:
minimizing control error and quality fluctuation. Then, we apply the Laplace
domain analysis to model the relationship between quantization parameter (QP)
and control error in this formulation. Given the relationship between QP and
control error, we propose a solution to the PQC formulation, such that videos
can be compressed at certain and constant quality. Finally, experimental
results show that our PQC method is effective in both control accuracy and
quality fluctuation.
"
1451,"Sample-level CNN Architectures for Music Auto-tagging Using Raw
  Waveforms","  Recent work has shown that the end-to-end approach using convolutional neural
network (CNN) is effective in various types of machine learning tasks. For
audio signals, the approach takes raw waveforms as input using an 1-D
convolution layer. In this paper, we improve the 1-D CNN architecture for music
auto-tagging by adopting building blocks from state-of-the-art image
classification models, ResNets and SENets, and adding multi-level feature
aggregation to it. We compare different combinations of the modules in building
CNN architectures. The results show that they achieve significant improvements
over previous state-of-the-art models on the MagnaTagATune dataset and
comparable results on Million Song Dataset. Furthermore, we analyze and
visualize our model to show how the 1-D CNN operates.
"
1452,Prediction of Satisfied User Ratio for Compressed Video,"  A large-scale video quality dataset called the VideoSet has been constructed
recently to measure human subjective experience of H.264 coded video in terms
of the just-noticeable-difference (JND). It measures the first three JND points
of 5-second video of resolution 1080p, 720p, 540p and 360p. Based on the
VideoSet, we propose a method to predict the satisfied-user-ratio (SUR) curves
using a machine learning framework. First, we partition a video clip into local
spatial-temporal segments and evaluate the quality of each segment using the
VMAF quality index. Then, we aggregate these local VMAF measures to derive a
global one. Finally, the masking effect is incorporated and the support vector
regression (SVR) is used to predict the SUR curves, from which the JND points
can be derived. Experimental results are given to demonstrate the performance
of the proposed SUR prediction method.
"
1453,VLSI Computational Architectures for the Arithmetic Cosine Transform,"  The discrete cosine transform (DCT) is a widely-used and important signal
processing tool employed in a plethora of applications. Typical fast algorithms
for nearly-exact computation of DCT require floating point arithmetic, are
multiplier intensive, and accumulate round-off errors. Recently proposed fast
algorithm arithmetic cosine transform (ACT) calculates the DCT exactly using
only additions and integer constant multiplications, with very low area
complexity, for null mean input sequences. The ACT can also be computed
non-exactly for any input sequence, with low area complexity and low power
consumption, utilizing the novel architecture described. However, as a
trade-off, the ACT algorithm requires 10 non-uniformly sampled data points to
calculate the 8-point DCT. This requirement can easily be satisfied for
applications dealing with spatial signals such as image sensors and biomedical
sensor arrays, by placing sensor elements in a non-uniform grid. In this work,
a hardware architecture for the computation of the null mean ACT is proposed,
followed by a novel architectures that extend the ACT for non-null mean
signals. All circuits are physically implemented and tested using the Xilinx
XC6VLX240T FPGA device and synthesized for 45 nm TSMC standard-cell library for
performance assessment.
"
1454,"Melody Generation for Pop Music via Word Representation of Musical
  Properties","  Automatic melody generation for pop music has been a long-time aspiration for
both AI researchers and musicians. However, learning to generate euphonious
melody has turned out to be highly challenging due to a number of factors.
Representation of multivariate property of notes has been one of the primary
challenges. It is also difficult to remain in the permissible spectrum of
musical variety, outside of which would be perceived as a plain random play
without auditory pleasantness. Observing the conventional structure of pop
music poses further challenges. In this paper, we propose to represent each
note and its properties as a unique `word,' thus lessening the prospect of
misalignments between the properties, as well as reducing the complexity of
learning. We also enforce regularization policies on the range of notes, thus
encouraging the generated melody to stay close to what humans would find easy
to follow. Furthermore, we generate melody conditioned on song part
information, thus replicating the overall structure of a full song.
Experimental results demonstrate that our model can generate auditorily
pleasant songs that are more indistinguishable from human-written ones than
previous models.
"
1455,"Beautiful and damned. Combined effect of content quality and social ties
  on user engagement","  User participation in online communities is driven by the intertwinement of
the social network structure with the crowd-generated content that flows along
its links. These aspects are rarely explored jointly and at scale. By looking
at how users generate and access pictures of varying beauty on Flickr, we
investigate how the production of quality impacts the dynamics of online social
systems. We develop a deep learning computer vision model to score images
according to their aesthetic value and we validate its output through
crowdsourcing. By applying it to over 15B Flickr photos, we study for the first
time how image beauty is distributed over a large-scale social system.
Beautiful images are evenly distributed in the network, although only a small
core of people get social recognition for them. To study the impact of exposure
to quality on user engagement, we set up matching experiments aimed at
detecting causality from observational data. Exposure to beauty is
double-edged: following people who produce high-quality content increases one's
probability of uploading better photos; however, an excessive imbalance between
the quality generated by a user and the user's neighbors leads to a decline in
engagement. Our analysis has practical implications for improving link
recommender systems.
"
1456,"TasNet: time-domain audio separation network for real-time,
  single-channel speech separation","  Robust speech processing in multi-talker environments requires effective
speech separation. Recent deep learning systems have made significant progress
toward solving this problem, yet it remains challenging particularly in
real-time, short latency applications. Most methods attempt to construct a mask
for each source in time-frequency representation of the mixture signal which is
not necessarily an optimal representation for speech separation. In addition,
time-frequency decomposition results in inherent problems such as
phase/magnitude decoupling and long time window which is required to achieve
sufficient frequency resolution. We propose Time-domain Audio Separation
Network (TasNet) to overcome these limitations. We directly model the signal in
the time-domain using an encoder-decoder framework and perform the source
separation on nonnegative encoder outputs. This method removes the frequency
decomposition step and reduces the separation problem to estimation of source
masks on encoder outputs which is then synthesized by the decoder. Our system
outperforms the current state-of-the-art causal and noncausal speech separation
algorithms, reduces the computational cost of speech separation, and
significantly reduces the minimum required latency of the output. This makes
TasNet suitable for applications where low-power, real-time implementation is
desirable such as in hearable and telecommunication devices.
"
1457,Set-to-Set Hashing with Applications in Visual Recognition,"  Visual data, such as an image or a sequence of video frames, is often
naturally represented as a point set. In this paper, we consider the
fundamental problem of finding a nearest set from a collection of sets, to a
query set. This problem has obvious applications in large-scale visual
retrieval and recognition, and also in applied fields beyond computer vision.
One challenge stands out in solving the problem---set representation and
measure of similarity. Particularly, the query set and the sets in dataset
collection can have varying cardinalities. The training collection is large
enough such that linear scan is impractical. We propose a simple representation
scheme that encodes both statistical and structural information of the sets.
The derived representations are integrated in a kernel framework for flexible
similarity measurement. For the query set process, we adopt a learning-to-hash
pipeline that turns the kernel representations into hash bits based on simple
learners, using multiple kernel learning. Experiments on two visual retrieval
datasets show unambiguously that our set-to-set hashing framework outperforms
prior methods that do not take the set-to-set search setting.
"
1458,"Deep Learning-Based Dynamic Watermarking for Secure Signal
  Authentication in the Internet of Things","  Securing the Internet of Things (IoT) is a necessary milestone toward
expediting the deployment of its applications and services. In particular, the
functionality of the IoT devices is extremely dependent on the reliability of
their message transmission. Cyber attacks such as data injection,
eavesdropping, and man-in-the-middle threats can lead to security challenges.
Securing IoT devices against such attacks requires accounting for their
stringent computational power and need for low-latency operations. In this
paper, a novel deep learning method is proposed for dynamic watermarking of IoT
signals to detect cyber attacks. The proposed learning framework, based on a
long short-term memory (LSTM) structure, enables the IoT devices to extract a
set of stochastic features from their generated signal and dynamically
watermark these features into the signal. This method enables the IoT's cloud
center, which collects signals from the IoT devices, to effectively
authenticate the reliability of the signals. Furthermore, the proposed method
prevents complicated attack scenarios such as eavesdropping in which the cyber
attacker collects the data from the IoT devices and aims to break the
watermarking algorithm. Simulation results show that, with an attack detection
delay of under 1 second the messages can be transmitted from IoT devices with
an almost 100% reliability.
"
1459,"Knowledge Transfer from Weakly Labeled Audio using Convolutional Neural
  Network for Sound Events and Scenes","  In this work we propose approaches to effectively transfer knowledge from
weakly labeled web audio data. We first describe a convolutional neural network
(CNN) based framework for sound event detection and classification using weakly
labeled audio data. Our model trains efficiently from audios of variable
lengths; hence, it is well suited for transfer learning. We then propose
methods to learn representations using this model which can be effectively used
for solving the target task. We study both transductive and inductive transfer
learning tasks, showing the effectiveness of our methods for both domain and
task adaptation. We show that the learned representations using the proposed
CNN model generalizes well enough to reach human level accuracy on ESC-50 sound
events dataset and set state of art results on this dataset. We further use
them for acoustic scene classification task and once again show that our
proposed approaches suit well for this task as well. We also show that our
methods are helpful in capturing semantic meanings and relations as well.
Moreover, in this process we also set state-of-art results on Audioset dataset,
relying on balanced training set.
"
1460,"Multimodal Signal Processing and Learning Aspects of Human-Robot
  Interaction for an Assistive Bathing Robot","  We explore new aspects of assistive living on smart human-robot interaction
(HRI) that involve automatic recognition and online validation of speech and
gestures in a natural interface, providing social features for HRI. We
introduce a whole framework and resources of a real-life scenario for elderly
subjects supported by an assistive bathing robot, addressing health and hygiene
care issues. We contribute a new dataset and a suite of tools used for data
acquisition and a state-of-the-art pipeline for multimodal learning within the
framework of the I-Support bathing robot, with emphasis on audio and RGB-D
visual streams. We consider privacy issues by evaluating the depth visual
stream along with the RGB, using Kinect sensors. The audio-gestural recognition
task on this new dataset yields up to 84.5%, while the online validation of the
I-Support system on elderly users accomplishes up to 84% when the two
modalities are fused together. The results are promising enough to support
further research in the area of multimodal recognition for assistive social
HRI, considering the difficulties of the specific task. Upon acceptance of the
paper part of the data will be publicly available.
"
1461,"Radical analysis network for zero-shot learning in printed Chinese
  character recognition","  Chinese characters have a huge set of character categories, more than 20,000
and the number is still increasing as more and more novel characters continue
being created. However, the enormous characters can be decomposed into a
compact set of about 500 fundamental and structural radicals. This paper
introduces a novel radical analysis network (RAN) to recognize printed Chinese
characters by identifying radicals and analyzing two-dimensional spatial
structures among them. The proposed RAN first extracts visual features from
input by employing convolutional neural networks as an encoder. Then a decoder
based on recurrent neural networks is employed, aiming at generating captions
of Chinese characters by detecting radicals and two-dimensional structures
through a spatial attention mechanism. The manner of treating a Chinese
character as a composition of radicals rather than a single character class
largely reduces the size of vocabulary and enables RAN to possess the ability
of recognizing unseen Chinese character classes, namely zero-shot learning.
"
1462,"ADS: Adaptive and Dynamic Scaling Mechanism for Multimedia Conferencing
  Services in the Cloud","  Multimedia conferencing is used extensively in a wide range of applications,
such as online games and distance learning. These applications need to
efficiently scale the conference size as the number of participants fluctuates.
Cloud is a technology that addresses the scalability issue. However, the
proposed cloud-based solutions have several shortcomings in considering the
future demand of applications while meeting both Quality of Service (QoS)
requirements and efficiency in resource usage. In this paper, we propose an
Adaptive and Dynamic Scaling mechanism (ADS) for multimedia conferencing
services in the cloud. This mechanism enables scalable and elastic resource
allocation with respect to the number of participants. ADS produces a
cost-efficient scaling schedule while considering the QoS requirements and the
future demand of the conferencing service. We formulate the problem using
Integer Linear Programming (ILP) and design a heuristic for it. Simulation
results show that ADS mechanism elastically scales conferencing services.
Moreover, the ADS heuristic is shown to outperform a greedy algorithm from a
resource-efficiency perspective.
"
1463,"Visually-Aware Fashion Recommendation and Design with Generative Image
  Models","  Building effective recommender systems for domains like fashion is
challenging due to the high level of subjectivity and the semantic complexity
of the features involved (i.e., fashion styles). Recent work has shown that
approaches to `visual' recommendation (e.g.~clothing, art, etc.) can be made
more accurate by incorporating visual signals directly into the recommendation
objective, using `off-the-shelf' feature representations derived from deep
networks. Here, we seek to extend this contribution by showing that
recommendation performance can be significantly improved by learning `fashion
aware' image representations directly, i.e., by training the image
representation (from the pixel level) and the recommender system jointly; this
contribution is related to recent work using Siamese CNNs, though we are able
to show improvements over state-of-the-art recommendation techniques such as
BPR and variants that make use of pre-trained visual features. Furthermore, we
show that our model can be used \emph{generatively}, i.e., given a user and a
product category, we can generate new images (i.e., clothing items) that are
most consistent with their personal taste. This represents a first step towards
building systems that go beyond recommending existing items from a product
corpus, but which can be used to suggest styles and aid the design of new
products.
"
1464,"Viewport-aware adaptive 360{\deg} video streaming using tiles for
  virtual reality","  360{\deg} video is attracting an increasing amount of attention in the
context of Virtual Reality (VR). Owing to its very high-resolution
requirements, existing professional streaming services for 360{\deg} video
suffer from severe drawbacks. This paper introduces a novel end-to-end
streaming system from encoding to displaying, to transmit 8K resolution
360{\deg} video and to provide an enhanced VR experience using Head Mounted
Displays (HMDs). The main contributions of the proposed system are about
tiling, integration of the MPEG-Dynamic Adaptive Streaming over HTTP (DASH)
standard, and viewport-aware bitrate level selection. Tiling and adaptive
streaming enable the proposed system to deliver very high-resolution 360{\deg}
video at good visual quality. Further, the proposed viewport-aware bitrate
assignment selects an optimum DASH representation for each tile in a
viewport-aware manner. The quality performance of the proposed system is
verified in simulations with varying network bandwidth using realistic view
trajectories recorded from user experiments. Our results show that the proposed
streaming system compares favorably compared to existing methods in terms of
PSNR and SSIM inside the viewport.
"
1465,Convolutional Neural Network Steganalysis's Application to Steganography,"  This paper presents a novel approach to increase the performance bounds of
image steganography under the criteria of minimizing distortion. The proposed
approach utilizes a steganalysis convolutional neural network (CNN) framework
to understand an image's model and embed in less detectable regions to preserve
the model. In other word, the trained steganalysis CNN is used to calculate
derivatives of the statistical model of an image with respect to embedding
changes. The experimental results show that the proposed algorithm outperforms
previous state-of-the-art methods in a wide range of low relative payloads when
compared with HUGO, S-UNIWARD, and HILL by the state-of-the-art steganalysis.
"
1466,"Estimation of optimal encoding ladders for tiled 360{\deg} VR video in
  adaptive streaming systems","  Given the significant industrial growth of demand for virtual reality (VR),
360{\deg} video streaming is one of the most important VR applications that
require cost-optimal solutions to achieve widespread proliferation of VR
technology. Because of its inherent variability of data-intensive content types
and its tiled-based encoding and streaming, 360{\deg} video requires new
encoding ladders in adaptive streaming systems to achieve cost-optimal and
immersive streaming experiences. In this context, this paper targets both the
provider's and client's perspectives and introduces a new content-aware
encoding ladder estimation method for tiled 360{\deg} VR video in adaptive
streaming systems. The proposed method first categories a given 360{\deg} video
using its features of encoding complexity and estimates the visual distortion
and resource cost of each bitrate level based on the proposed distortion and
resource cost models. An optimal encoding ladder is then formed using the
proposed integer linear programming (ILP) algorithm by considering practical
constraints. Experimental results of the proposed method are compared with the
recommended encoding ladders of professional streaming service providers.
Evaluations show that the proposed encoding ladders deliver better results
compared to the recommended encoding ladders in terms of objective quality for
360{\deg} video, providing optimal encoding ladders using a set of service
provider's constraint parameters.
"
1467,IP Video Conferencing: A Tutorial,"  Video conferencing is a well-established area of communications, which have
been studied for decades. Recently this area has received a new impulse due to
significantly increased bandwidth of Local and Wide area networks, appearance
of low-priced video equipment and development of web based media technologies.
This paper presents the main techniques behind the modern IP-based
videoconferencing services, with a particular focus on codecs, network
protocols, architectures and standardization efforts. Questions of security and
topologies are also tackled. A description of a typical video conference
scenario is provided, demonstrating how the technologies, responsible for
different conference aspects, are working together. Traditional industrial
disposition as well as modern innovative approaches are both addressed. Current
industry trends are highlighted in respect to the topics, described in the
tutorial. Legacy analog/digital technologies, together with the gateways
between the traditional and the IP videoconferencing systems, are not
considered.
"
1468,Predicting Chroma from Luma in AV1,"  Chroma from luma (CfL) prediction is a new and promising chroma-only intra
predictor that models chroma pixels as a linear function of the coincident
reconstructed luma pixels. In this paper, we present the CfL predictor adopted
in Alliance Video 1 (AV1), a royalty-free video codec developed by the Alliance
for Open Media (AOM). The proposed CfL distinguishes itself from prior art not
only by reducing decoder complexity, but also by producing more accurate
predictions. On average, CfL reduces the BD-rate, when measured with CIEDE2000,
by 5% for still images and 2% for video sequences.
"
1469,Unified Spectral Clustering with Optimal Graph,"  Spectral clustering has found extensive use in many areas. Most traditional
spectral clustering algorithms work in three separate steps: similarity graph
construction; continuous labels learning; discretizing the learned labels by
k-means clustering. Such common practice has two potential flaws, which may
lead to severe information loss and performance degradation. First, predefined
similarity graph might not be optimal for subsequent clustering. It is
well-accepted that similarity graph highly affects the clustering results. To
this end, we propose to automatically learn similarity information from data
and simultaneously consider the constraint that the similarity matrix has exact
c connected components if there are c clusters. Second, the discrete solution
may deviate from the spectral solution since k-means method is well-known as
sensitive to the initialization of cluster centers. In this work, we transform
the candidate solution into a new one that better approximates the discrete
one. Finally, those three subtasks are integrated into a unified framework,
with each subtask iteratively boosted by using the results of the others
towards an overall optimal solution. It is known that the performance of a
kernel method is largely determined by the choice of kernels. To tackle this
practical problem of how to select the most suitable kernel for a particular
data set, we further extend our model to incorporate multiple kernel learning
ability. Extensive experiments demonstrate the superiority of our proposed
method as compared to existing clustering approaches.
"
1470,"Generative Steganography with Kerckhoffs' Principle based on Generative
  Adversarial Networks","  The distortion in steganography that usually comes from the modification or
recoding on the cover image during the embedding process leaves the
steganalyzer with possibility of discriminating. Faced with such a risk, we
propose generative steganography with Kerckhoffs' principle (GSK) in this
letter. In GSK, the secret messages are generated by a cover image using a
generator rather than embedded into the cover, thus resulting in no
modifications in the cover. To ensure the security, the generators are trained
to meet Kerckhoffs' principle based on generative adversarial networks (GAN).
Everything about the GSK system, except the extraction key, is public knowledge
for the receivers. The secret messages can be outputted by the generator if and
only if the extraction key and the cover image are both inputted. In the
generator training procedures, there are two GANs, Message- GAN and Cover-GAN,
designed to work jointly making the generated results under the control of the
extraction key and the cover image. We provide experimental results on the
training process and give an example of the working process by adopting a
generator trained on MNIST, which demonstrate that GSK can use a cover image
without any modification to generate messages, and without the extraction key
or the cover image, only meaningless results would be obtained.
"
1471,"No Reference Stereoscopic Video Quality Assessment Using Joint Motion
  and Depth Statistics","  We present a no reference (NR) quality assessment algorithm for assessing the
perceptual quality of natural stereoscopic 3D (S3D) videos. This work is
inspired by our finding that the joint statistics of the subband coefficients
of motion (optical flow or motion vector magnitude) and depth (disparity map)
of natural S3D videos possess a unique signature. Specifically, we empirically
show that the joint statistics of the motion and depth subband coefficients of
S3D video frames can be modeled accurately using a Bivariate Generalized
Gaussian Distribution (BGGD). We then demonstrate that the parameters of the
BGGD model possess the ability to discern quality variations in S3D videos.
Therefore, the BGGD model parameters are employed as motion and depth quality
features. In addition to these features, we rely on a frame level spatial
quality feature that is computed using a robust off the shelf NR image quality
assessment (IQA) algorithm. These frame level motion, depth and spatial
features are consolidated and used with the corresponding S3D video's
difference mean opinion score (DMOS) labels for supervised learning using
support vector regression (SVR). The overall quality of an S3D video is
computed by averaging the frame level quality predictions of the constituent
video frames. The proposed algorithm, dubbed Video QUality Evaluation using
MOtion and DEpth Statistics (VQUEMODES) is shown to outperform the state of the
art methods when evaluated over the IRCCYN and LFOVIA S3D subjective quality
assessment databases.
"
1472,Dual-Path Convolutional Image-Text Embedding with Instance Loss,"  Matching images and sentences demands a fine understanding of both
modalities. In this paper, we propose a new system to discriminatively embed
the image and text to a shared visual-textual space. In this field, most
existing works apply the ranking loss to pull the positive image / text pairs
close and push the negative pairs apart from each other. However, directly
deploying the ranking loss is hard for network learning, since it starts from
the two heterogeneous features to build inter-modal relationship. To address
this problem, we propose the instance loss which explicitly considers the
intra-modal data distribution. It is based on an unsupervised assumption that
each image / text group can be viewed as a class. So the network can learn the
fine granularity from every image/text group. The experiment shows that the
instance loss offers better weight initialization for the ranking loss, so that
more discriminative embeddings can be learned. Besides, existing works usually
apply the off-the-shelf features, i.e., word2vec and fixed visual feature. So
in a minor contribution, this paper constructs an end-to-end dual-path
convolutional network to learn the image and text representations. End-to-end
learning allows the system to directly learn from the data and fully utilize
the supervision. On two generic retrieval datasets (Flickr30k and MSCOCO),
experiments demonstrate that our method yields competitive accuracy compared to
state-of-the-art methods. Moreover, in language based person retrieval, we
improve the state of the art by a large margin. The code has been made publicly
available.
"
1473,"A Double Joint Bayesian Approach for J-Vector Based Text-dependent
  Speaker Verification","  J-vector has been proved to be very effective in text-dependent speaker
verification with short-duration speech. However, the current state-of-the-art
back-end classifiers, e.g. joint Bayesian model, cannot make full use of such
deep features. In this paper, we generalize the standard joint Bayesian
approach to model the multi-faceted information in the j-vector explicitly and
jointly. In our generalization, the j-vector was modeled as a result derived by
a generative Double Joint Bayesian (DoJoBa) model, which contains several kinds
of latent variables. With DoJoBa, we are able to explicitly build a model that
can combine multiple heterogeneous information from the j-vectors. In
verification step, we calculated the likelihood to describe whether the two
j-vectors having consistent labels or not. On the public RSR2015 data corpus,
the experimental results showed that our approach can achieve 0.02\% EER and
0.02\% EER for impostor wrong and impostor correct cases respectively.
"
1474,End-to-end Trained CNN Encode-Decoder Networks for Image Steganography,"  All the existing image steganography methods use manually crafted features to
hide binary payloads into cover images. This leads to small payload capacity
and image distortion. Here we propose a convolutional neural network based
encoder-decoder architecture for embedding of images as payload. To this end,
we make following three major contributions: (i) we propose a deep learning
based generic encoder-decoder architecture for image steganography; (ii) we
introduce a new loss function that ensures joint end-to-end training of
encoder-decoder networks; (iii) we perform extensive empirical evaluation of
proposed architecture on a range of challenging publicly available datasets
(MNIST, CIFAR10, PASCAL-VOC12, ImageNet, LFW) and report state-of-the-art
payload capacity at high PSNR and SSIM values.
"
1475,"A Novel Convolutional Neural Network for Image Steganalysis with Shared
  Normalization","  Deep learning based image steganalysis has attracted increasing attentions in
recent years. Several Convolutional Neural Network (CNN) models have been
proposed and achieved state-of-the-art performances on detecting steganography.
In this paper, we explore an important technique in deep learning, the batch
normalization, for the task of image steganalysis. Different from natural image
classification, steganalysis is to discriminate cover images and stego images
which are the result of adding weak stego signals into covers. This
characteristic makes a cover image is more statistically similar to its stego
than other cover images, requiring steganalytic methods to use paired learning
to extract effective features for image steganalysis. Our theoretical analysis
shows that a CNN model with multiple normalization layers is hard to be
generalized to new data in the test set when it is well trained with paired
learning. To hand this difficulty, we propose a novel normalization technique
called Shared Normalization (SN) in this paper. Unlike the batch normalization
layer utilizing the mini-batch mean and standard deviation to normalize each
input batch, SN shares same statistics for all training and test batches. Based
on the proposed SN layer, we further propose a novel neural network model for
image steganalysis. Extensive experiments demonstrate that the proposed network
with SN layers is stable and can detect the state of the art steganography with
better performances than previous methods.
"
1476,"Action Recognition with Coarse-to-Fine Deep Feature Integration and
  Asynchronous Fusion","  Action recognition is an important yet challenging task in computer vision.
In this paper, we propose a novel deep-based framework for action recognition,
which improves the recognition accuracy by: 1) deriving more precise features
for representing actions, and 2) reducing the asynchrony between different
information streams. We first introduce a coarse-to-fine network which extracts
shared deep features at different action class granularities and progressively
integrates them to obtain a more accurate feature representation for input
actions. We further introduce an asynchronous fusion network. It fuses
information from different streams by asynchronously integrating stream-wise
features at different time points, hence better leveraging the complementary
information in different streams. Experimental results on action recognition
benchmarks demonstrate that our approach achieves the state-of-the-art
performance.
"
1477,Optimized Pre-Compensating Compression,"  In imaging systems, following acquisition, an image/video is transmitted or
stored and eventually presented to human observers using different and often
imperfect display devices. While the resulting quality of the output image may
severely be affected by the display, this degradation is usually ignored in the
preceding compression. In this paper we model the sub-optimality of the display
device as a known degradation operator applied on the decompressed image/video.
We assume the use of a standard compression path, and augment it with a
suitable pre-processing procedure, providing a compressed signal intended to
compensate the degradation without any post-filtering. Our approach originates
from an intricate rate-distortion problem, optimizing the modifications to the
input image/video for reaching best end-to-end performance. We address this
seemingly computationally intractable problem using the alternating direction
method of multipliers (ADMM) approach, leading to a procedure in which a
standard compression technique is iteratively applied. We demonstrate the
proposed method for adjusting HEVC image/video compression to compensate
post-decompression visual effects due to a common type of displays.
Particularly, we use our method to reduce motion-blur perceived while viewing
video on LCD devices. The experiments establish our method as a leading
approach for preprocessing high bit-rate compression to counterbalance a
post-decompression degradation.
"
1478,Channel Transition Invariant Fast Broadcasting Scheme,"  Fast broadcasting (FB) is a popular near video-on-demand system where a video
is divided into equal size segments those are repeatedly transmitted over a
number of channels following a pattern. For user satisfaction, it is required
to reduce the initial user waiting time and client side buffer requirement at
streaming. Use of additional channels can achieve the objective. However, some
augmentation is required to the basic FB scheme as it lacks any mechanism to
realise a well defined relationship among the segment sizes at channel
transition. Lack of correspondence between the segments causes intermediate
waiting for the clients while watching videos. Use of additional channel
requires additional bandwidth. In this paper, we propose a modified FB scheme
that achieves zero initial clients waiting time and provides a mechanism to
control client side buffer requirement at streaming without requiring
additional channels. We present several results to demonstrate the
effectiveness of the proposed FB scheme over the existing ones.
"
1479,Calibrated Audio Steganalysis,"  Calibration is a common practice in image steganalysis for extracting
prominent features. Based on the idea of reembedding, a new set of calibrated
features for audio steganalysis applications are proposed. These features are
extracted from a model that has maximum deviation from human auditory system
and had been specifically designed for audio steganalysis. Ability of the
proposed system is tested extensively. Simulations demonstrate that the
proposed method can accurately detect the presence of hidden messages even in
very low embedding rates. Proposed method achieves an accuracy of 99.3%
(StegHide@0.76% BPB) which is 9.5% higher than the previous R-MFCC based
steganalysis method.
"
1480,"Attended End-to-end Architecture for Age Estimation from Facial
  Expression Videos","  The main challenges of age estimation from facial expression videos lie not
only in the modeling of the static facial appearance, but also in the capturing
of the temporal facial dynamics. Traditional techniques to this problem focus
on constructing handcrafted features to explore the discriminative information
contained in facial appearance and dynamics separately. This relies on
sophisticated feature-refinement and framework-design. In this paper, we
present an end-to-end architecture for age estimation, called Spatially-Indexed
Attention Model (SIAM), which is able to simultaneously learn both the
appearance and dynamics of age from raw videos of facial expressions.
Specifically, we employ convolutional neural networks to extract effective
latent appearance representations and feed them into recurrent networks to
model the temporal dynamics. More importantly, we propose to leverage attention
models for salience detection in both the spatial domain for each single image
and the temporal domain for the whole video as well. We design a specific
spatially-indexed attention mechanism among the convolutional layers to extract
the salient facial regions in each individual image, and a temporal attention
layer to assign attention weights to each frame. This two-pronged approach not
only improves the performance by allowing the model to focus on informative
frames and facial areas, but it also offers an interpretable correspondence
between the spatial facial regions as well as temporal frames, and the task of
age estimation. We demonstrate the strong performance of our model in
experiments on a large, gender-balanced database with 400 subjects with ages
spanning from 8 to 76 years. Experiments reveal that our model exhibits
significant superiority over the state-of-the-art methods given sufficient
training data.
"
1481,A Gamut-Mapping Framework for Color-Accurate Reproduction of HDR Images,"  Few tone mapping operators (TMOs) take color management into consideration,
limiting compression to luminance values only. This may lead to changes in
image chroma and hues which are typically managed with a post-processing step.
However, current post-processing techniques for tone reproduction do not
explicitly consider the target display gamut. Gamut mapping on the other hand,
deals with mapping images from one color gamut to another, usually smaller,
gamut but has traditionally focused on smaller scale, chromatic changes. In
this context, we present a novel gamut and tone management framework for
color-accurate reproduction of high dynamic range (HDR) images, which is
conceptually and computationally simple, parameter-free, and compatible with
existing TMOs. In the CIE LCh color space, we compress chroma to fit the gamut
of the output color space. This prevents hue and luminance shifts while taking
gamut boundaries into consideration. We also propose a compatible lightness
compression scheme that minimizes the number of color space conversions. Our
results show that our gamut management method effectively compresses the chroma
of tone mapped images, respecting the target gamut and without reducing image
quality.
"
1482,JPEG Steganalysis Based on DenseNet,"  Different from the conventional deep learning work based on an images content
in computer vision, deep steganalysis is an art to detect the secret
information embedded in an image via deep learning, pose challenge of detection
weak information invisible hidden in a host image thus learning in a very low
signal-to-noise (SNR) case. In this paper, we propose a 32- layer convolutional
neural Networks (CNNs) in to improve the efficiency of preprocess and reuse the
features by concatenating all features from the previous layers with the same
feature- map size, thus improve the flow of information and gradient. The
shared features and bottleneck layers further improve the feature propagation
and reduce the CNN model parameters dramatically. Experimental results on the
BOSSbase, BOWS2 and ImageNet datasets have showed that the proposed CNN
architecture can improve the performance and enhance the robustness. To further
boost the detection accuracy, an ensemble architecture called as CNN-SCA-GFR is
proposed, CNN-SCA- GFR is also the first work to combine the CNN architecture
and conventional method in the JPEG domain. Experiments show that it can
further lower detection errors. Compared with the state-of-the-art method XuNet
[1] on BOSSbase, the proposed CNN-SCA-GFR architecture can reduce detection
error rate by 5.67% for 0.1 bpnzAC and by 4.41% for 0.4 bpnzAC while the number
of training parameters in CNN is only 17% of what used by XuNet. It also
decreases the detection errors from the conventional method SCA-GFR by 7.89%
for 0.1 bpnzAC and 8.06% for 0.4 bpnzAC, respectively.
"
1483,Real-Time System for Human Activity Analysis,"  We propose a real-time human activity analysis system, where a user's
activity can be quantiatively evaluated with respect to a ground truth
recording. We use two Kinects to solve the ptorblem of self-occlusion through
extraction optimal joint positions using Singular Value Decomposition (SVD) and
Sequential Quadratic Programming (SQP). Incremental Dynamic Time Warping (IDTW)
is used to compare the user and expert (ground truth) to quantiatively score
the user's performance. Furthermore, the user's performance is displayed
through a visual feedback system, where colors on the skeleton represent the
user's score. Our experiements use a motion capture suit as ground truth to
compare our dual Kinect setup to a single Kinect. We also show that with out
visual feedback method, users gain statistically significant boost to learning
as opposed to watching a simple video.
"
1484,High Dynamic Range Imaging Technology,"  In this lecture note, we describe high dynamic range (HDR) imaging systems;
such systems are able to represent luminances of much larger brightness and,
typically, also a larger range of colors than conventional standard dynamic
range (SDR) imaging systems. The larger luminance range greatly improve the
overall quality of visual content, making it appears much more realistic and
appealing to observers. HDR is one of the key technologies of the future
imaging pipeline, which will change the way the digital visual content is
represented and manipulated today.
"
1485,"Direct Segmented Sonification of Characteristic Features of the Data
  Domain","  Sonification and audification create auditory displays of datasets.
Audification translates data points into digital audio samples and the auditory
display's duration is determined by the playback rate. Like audification,
auditory graphs maintain the temporal relationships of data while using
parameter mappings (typically data-to-frequency) to represent the ordinate
values. Such direct approaches have the advantage of presenting the data stream
`as is' without the imposed interpretations or accentuation of particular
features found in indirect approaches. However, datasets can often be
subdivided into short non-overlapping variable length segments that each
encapsulate a discrete unit of domain-specific significant information and
current direct approaches cannot represent these. We present Direct Segmented
Sonification (DSSon) for highlighting the segments' data distributions as
individual sonic events. Using domain knowledge to segment data, DSSon presents
segments as discrete auditory gestalts while retaining the overall temporal
regime and relationships of the dataset. The method's structural decoupling
from the sound stream's formation means playback speed is independent of the
individual sonic event durations, thereby offering highly flexible time
compression/stretching to allow zooming into or out of the data. Demonstrated
by three models applied to biomechanical data, DSSon displays high directness,
letting the data `speak' for themselves.
"
1486,Deep Neural Networks for Multiple Speaker Detection and Localization,"  We propose to use neural networks for simultaneous detection and localization
of multiple sound sources in human-robot interaction. In contrast to
conventional signal processing techniques, neural network-based sound source
localization methods require fewer strong assumptions about the environment.
Previous neural network-based methods have been focusing on localizing a single
sound source, which do not extend to multiple sources in terms of detection and
localization. In this paper, we thus propose a likelihood-based encoding of the
network output, which naturally allows the detection of an arbitrary number of
sources. In addition, we investigate the use of sub-band cross-correlation
information as features for better localization in sound mixtures, as well as
three different network architectures based on different motivations.
Experiments on real data recorded from a robot show that our proposed methods
significantly outperform the popular spatial spectrum-based approaches.
"
1487,"A Color Intensity Invariant Low Level Feature Optimization Framework for
  Image Quality Assessment","  Image Quality Assessment (IQA) algorithms evaluate the perceptual quality of
an image using evaluation scores that assess the similarity or difference
between two images. We propose a new low-level feature based IQA technique,
which applies filter-bank decomposition and center-surround methodology.
Differing from existing methods, our model incorporates color intensity
adaptation and frequency scaling optimization at each filter-bank level and
spatial orientation to extract and enhance perceptually significant features.
Our computational model exploits the concept of object detection and
encapsulates characteristics proposed in other IQA algorithms in a unified
architecture. We also propose a systematic approach to review the evolution of
IQA algorithms using unbiased test datasets, instead of looking at individual
scores in isolation. Experimental results demonstrate the feasibility of our
approach.
"
1488,Enabling Embodied Analogies in Intelligent Music Systems,"  The present methodology is aimed at cross-modal machine learning and uses
multidisciplinary tools and methods drawn from a broad range of areas and
disciplines, including music, systematic musicology, dance, motion capture,
human-computer interaction, computational linguistics and audio signal
processing. Main tasks include: (1) adapting wisdom-of-the-crowd approaches to
embodiment in music and dance performance to create a dataset of music and
music lyrics that covers a variety of emotions, (2) applying
audio/language-informed machine learning techniques to that dataset to identify
automatically the emotional content of the music and the lyrics, and (3)
integrating motion capture data from a Vicon system and dancers performing on
that music.
"
1489,"Raw Waveform-based Audio Classification Using Sample-level CNN
  Architectures","  Music, speech, and acoustic scene sound are often handled separately in the
audio domain because of their different signal characteristics. However, as the
image domain grows rapidly by versatile image classification models, it is
necessary to study extensible classification models in the audio domain as
well. In this study, we approach this problem using two types of sample-level
deep convolutional neural networks that take raw waveforms as input and uses
filters with small granularity. One is a basic model that consists of
convolution and pooling layers. The other is an improved model that
additionally has residual connections, squeeze-and-excitation modules and
multi-level concatenation. We show that the sample-level models reach
state-of-the-art performance levels for the three different categories of
sound. Also, we visualize the filters along layers and compare the
characteristics of learned filters.
"
1490,Learning to Fuse Music Genres with Generative Adversarial Dual Learning,"  FusionGAN is a novel genre fusion framework for music generation that
integrates the strengths of generative adversarial networks and dual learning.
In particular, the proposed method offers a dual learning extension that can
effectively integrate the styles of the given domains. To efficiently quantify
the difference among diverse domains and avoid the vanishing gradient issue,
FusionGAN provides a Wasserstein based metric to approximate the distance
between the target domain and the existing domains. Adopting the Wasserstein
distance, a new domain is created by combining the patterns of the existing
domains using adversarial learning. Experimental results on public music
datasets demonstrated that our approach could effectively merge two genres.
"
1491,Pose-Normalized Image Generation for Person Re-identification,"  Person Re-identification (re-id) faces two major challenges: the lack of
cross-view paired training data and learning discriminative identity-sensitive
and view-invariant features in the presence of large pose variations. In this
work, we address both problems by proposing a novel deep person image
generation model for synthesizing realistic person images conditional on the
pose. The model is based on a generative adversarial network (GAN) designed
specifically for pose normalization in re-id, thus termed pose-normalization
GAN (PN-GAN). With the synthesized images, we can learn a new type of deep
re-id feature free of the influence of pose variations. We show that this
feature is strong on its own and complementary to features learned with the
original images. Importantly, under the transfer learning setting, we show that
our model generalizes well to any new re-id dataset without the need for
collecting any training data for model fine-tuning. The model thus has the
potential to make re-id model truly scalable.
"
1492,"DCT-domain Deep Convolutional Neural Networks for Multiple JPEG
  Compression Classification","  With the rapid advancements in digital imaging systems and networking,
low-cost hand-held image capture devices equipped with network connectivity are
becoming ubiquitous. This ease of digital image capture and sharing is also
accompanied by widespread usage of user-friendly image editing software. Thus,
we are in an era where digital images can be very easily used for the massive
spread of false information and their integrity need to be seriously
questioned. Application of multiple lossy compressions on images is an
essential part of any image editing pipeline involving lossy compressed images.
This paper aims to address the problem of classifying images based on the
number of JPEG compressions they have undergone, by utilizing deep
convolutional neural networks in DCT domain. The proposed system incorporates a
well designed pre-processing step before feeding the image data to CNN to
capture essential characteristics of compression artifacts and make the system
image content independent. Detailed experiments are performed to optimize
different aspects of the system, such as depth of CNN, number of DCT
frequencies, and execution time. Results on the standard UCID dataset
demonstrate that the proposed system outperforms existing systems for multiple
JPEG compression detection and is capable of classifying more number of
re-compression cycles then existing systems.
"
1493,Real-time Video Processing in Web Applications,"  The OpenGL ES standard is implemented in modern desktop and mobile browsers
through the WebGL API. This paper explores the potential for using OpenGL ES
hardware acceleration for real time video processing in standard HTML5
applications. It analyses the WebGL performance across device types and
compares it with the standard JavaScript and canvas performance.
"
1494,Exploiting Modern Hardware for High-Dimensional Nearest Neighbor Search,"  Many multimedia information retrieval or machine learning problems require
efficient high-dimensional nearest neighbor search techniques. For instance,
multimedia objects (images, music or videos) can be represented by
high-dimensional feature vectors. Finding two similar multimedia objects then
comes down to finding two objects that have similar feature vectors. In the
current context of mass use of social networks, large scale multimedia
databases or large scale machine learning applications are more and more
common, calling for efficient nearest neighbor search approaches.
  This thesis builds on product quantization, an efficient nearest neighbor
search technique that compresses high-dimensional vectors into short codes.
This makes it possible to store very large databases entirely in RAM, enabling
low response times. We propose several contributions that exploit the
capabilities of modern CPUs, especially SIMD and the cache hierarchy, to
further decrease response times offered by product quantization.
"
1495,"Online Red Packets: A Large-scale Empirical Study of Gift Giving on
  WeChat","  Gift giving is a ubiquitous social phenomenon, and red packets have been used
as monetary gifts in Asian countries for thousands of years. In recent years,
online red packets have become widespread in China through the WeChat platform.
Exploiting a unique dataset consisting of 61 million group red packets and
seven million users, we conduct a large-scale, data-driven study to understand
the spread of red packets and the effect of red packets on group activity. We
find that the cash flows between provinces are largely consistent with
provincial GDP rankings, e.g., red packets are sent from users in the south to
those in the north. By distinguishing spontaneous from reciprocal red packets,
we reveal the behavioral patterns in sending red packets: males, seniors, and
people with more in-group friends are more inclined to spontaneously send red
packets, while red packets from females, youths, and people with less in-group
friends are more reciprocal. Furthermore, we use propensity score matching to
study the external effects of red packets on group dynamics. We show that red
packets increase group participation and strengthen in-group relationships,
which partly explain the benefits and motivations for sending red packets.
"
1496,A Graph-theoretic Model to Steganography on Social Networks,"  Steganography aims to conceal the very fact that the communication takes
place, by embedding a message into a digit object such as image without
introducing noticeable artifacts. A number of steganographic systems have been
developed in past years, most of which, however, are confined to the laboratory
conditions where the real-world use of steganography are rarely concerned. In
this paper, we introduce an alternative perspective to steganography. A
graph-theoretic model to steganography on social networks is presented to
analyze real-world steganographic scenarios. In the graph, steganographic
participants are corresponding to the vertices with meaningless unique
identifiers. Each edge allows the two vertices to communicate with each other
by any steganographic algorithm. Meanwhile, the edges are associated with
weights to quantize the corresponding communication risk (or say cost). The
optimization task is to minimize the overall risk, which is modeled as additive
over the social network. We analyze different scenarios on a social network,
and provide the suited solutions to the corresponding optimization tasks. We
prove that a multiplicative probabilistic graph is equivalent to an additive
weighted graph. From the viewpoint of an attacker, he may hope to detect
suspicious communication channels, the data encoder(s) and the data decoder(s).
We present limited detection analysis to steganographic communication on a
network.
"
1497,A Hierarchical Recurrent Neural Network for Symbolic Melody Generation,"  In recent years, neural networks have been used to generate symbolic
melodies. However, the long-term structure in the melody has posed great
difficulty for designing a good model. In this paper, we present a hierarchical
recurrent neural network for melody generation, which consists of three
Long-Short-Term-Memory (LSTM) subnetworks working in a coarse-to-fine manner
along time. Specifically, the three subnetworks generate bar profiles, beat
profiles and notes in turn, and the output of the high-level subnetworks are
fed into the low-level subnetworks, serving as guidance for generating the
finer time-scale melody components in low-level subnetworks. Two human behavior
experiments demonstrate the advantage of this structure over the single-layer
LSTM which attempts to learn all hidden structures in melodies. Compared with
the state-of-the-art models MidiNet and MusicVAE, the hierarchical recurrent
neural network produces better melodies evaluated by humans.
"
1498,Sentiment Predictability for Stocks,"  In this work, we present our findings and experiments for stock-market
prediction using various textual sentiment analysis tools, such as mood
analysis and event extraction, as well as prediction models, such as LSTMs and
specific convolutional architectures.
"
1499,"Automatic Music Highlight Extraction using Convolutional Recurrent
  Attention Networks","  Music highlights are valuable contents for music services. Most methods
focused on low-level signal features. We propose a method for extracting
highlights using high-level features from convolutional recurrent attention
networks (CRAN). CRAN utilizes convolution and recurrent layers for sequential
learning with an attention mechanism. The attention allows CRAN to capture
significant snippets for distinguishing between genres, thus being used as a
high-level feature. CRAN was evaluated on over 32,000 popular tracks in Korea
for two months. Experimental results show our method outperforms three baseline
methods through quantitative and qualitative evaluations. Also, we analyze the
effects of attention and sequence information on performance.
"
1500,"Probabilistic Semantic Retrieval for Surveillance Videos with Activity
  Graphs","  We present a novel framework for finding complex activities matching
user-described queries in cluttered surveillance videos. The wide diversity of
queries coupled with unavailability of annotated activity data limits our
ability to train activity models. To bridge the semantic gap we propose to let
users describe an activity as a semantic graph with object attributes and
inter-object relationships associated with nodes and edges, respectively. We
learn node/edge-level visual predictors during training and, at test-time,
propose to retrieve activity by identifying likely locations that match the
semantic graph. We formulate a novel CRF based probabilistic activity
localization objective that accounts for mis-detections, mis-classifications
and track-losses, and outputs a likelihood score for a candidate grounded
location of the query in the video. We seek groundings that maximize overall
precision and recall. To handle the combinatorial search over all
high-probability groundings, we propose a highest precision subgraph matching
algorithm. Our method outperforms existing retrieval methods on benchmarked
datasets.
"
1501,"Minimizing Embedding Distortion with Weighted Bigraph Matching in
  Reversible Data Hiding","  For a required payload, the existing reversible data hiding (RDH) methods
always expect to reduce the embedding distortion as much as possible, such as
by utilizing a well-designed predictor, taking into account the carrier-content
characteristics, and/or improving modification efficiency etc. However, due to
the diversity of natural images, it is actually very hard to accurately model
the statistical characteristics of natural images, which has limited the
practical use of traditional RDH methods that rely heavily on the content
characteristics. Based on this perspective, instead of directly exploiting the
content characteristics, in this paper, we model the embedding operation on a
weighted bipartite graph to reduce the introduced distortion due to data
embedding, which is proved to be equivalent to a graph problem called as
\emph{minimum weight maximum matching (MWMM)}. By solving the MWMM problem, we
can find the optimal histogram shifting strategy under the given condition.
Since the proposed method is essentially a general embedding model for the RDH,
it can be utilized for designing an RDH scheme. In our experiments, we
incorporate the proposed method into some related works, and, our experimental
results have shown that the proposed method can significantly improve the
payload-distortion performance, indicating that the proposed method could be
desirable and promising for practical use and the design of RDH schemes.
"
1502,Objects that Sound,"  In this paper our objectives are, first, networks that can embed audio and
visual inputs into a common space that is suitable for cross-modal retrieval;
and second, a network that can localize the object that sounds in an image,
given the audio signal. We achieve both these objectives by training from
unlabelled video using only audio-visual correspondence (AVC) as the objective
function. This is a form of cross-modal self-supervision from video.
  To this end, we design new network architectures that can be trained for
cross-modal retrieval and localizing the sound source in an image, by using the
AVC task. We make the following contributions: (i) show that audio and visual
embeddings can be learnt that enable both within-mode (e.g. audio-to-audio) and
between-mode retrieval; (ii) explore various architectures for the AVC task,
including those for the visual stream that ingest a single image, or multiple
images, or a single image and multi-frame optical flow; (iii) show that the
semantic object that sounds within an image can be localized (using only the
sound, no motion or flow information); and (iv) give a cautionary tale on how
to avoid undesirable shortcuts in the data preparation.
"
1503,Coverless Information Hiding Based on Generative adversarial networks,"  Traditional image steganography modifies the content of the image more or
less, it is hard to resist the detection of image steganalysis tools. To
address this problem, a novel method named generative coverless information
hiding method based on generative adversarial networks is proposed in this
paper. The main idea of the method is that the class label of generative
adversarial networks is replaced with the secret information as a driver to
generate hidden image directly, and then extract the secret information from
the hidden image through the discriminator. It's the first time that the
coverless information hiding is achieved by generative adversarial networks.
Compared with the traditional image steganography, this method does not modify
the content of the original image. therefore, this method can resist image
steganalysis tools effectively. In terms of steganographic capacity,
anti-steganalysis, safety and reliability, the experimen shows that this hidden
algorithm performs well.
"
1504,"Blind High Dynamic Range Quality estimation by disentangling perceptual
  and noise features in images","  Assessing the visual quality of High Dynamic Range (HDR) images is an
unexplored and an interesting research topic that has become relevant with the
current boom in HDR technology. We propose a new convolutional neural network
based model for No reference image quality assessment(NR-IQA) on HDR data. This
model predicts the amount and location of noise, perceptual influence of image
pixels on the noise, and the perceived quality, of a distorted image without
any reference image. The proposed model extracts numerical values corresponding
to the noise present in any given distorted image, and the perceptual effects
exhibited by a human eye when presented with the same. These two measures are
extracted separately yet sequentially and combined in a mixing function to
compute the quality of the distorted image perceived by a human eye. Our
training process derives the the component that computes perceptual effects
from a real world image quality dataset, rather than using results of
psycovisual experiments. With the proposed model, we demonstrate state of the
art performance for HDR NR-IQA and our results show performance similar to HDR
Full Reference Image Quality Assessment algorithms (FR-IQA).
"
1505,Image Registration Techniques: A Survey,"  Image Registration is the process of aligning two or more images of the same
scene with reference to a particular image. The images are captured from
various sensors at different times and at multiple view-points. Thus to get a
better picture of any change of a scene or object over a considerable period of
time image registration is important. Image registration finds application in
medical sciences, remote sensing and in computer vision. This paper presents a
detailed review of several approaches which are classified accordingly along
with their contributions and drawbacks. The main steps of an image registration
procedure are also discussed. Different performance measures are presented that
determine the registration quality and accuracy. The scope for the future
research are presented as well.
"
1506,Recurrent Pixel Embedding for Instance Grouping,"  We introduce a differentiable, end-to-end trainable framework for solving
pixel-level grouping problems such as instance segmentation consisting of two
novel components. First, we regress pixels into a hyper-spherical embedding
space so that pixels from the same group have high cosine similarity while
those from different groups have similarity below a specified margin. We
analyze the choice of embedding dimension and margin, relating them to
theoretical results on the problem of distributing points uniformly on the
sphere. Second, to group instances, we utilize a variant of mean-shift
clustering, implemented as a recurrent neural network parameterized by kernel
bandwidth. This recurrent grouping module is differentiable, enjoys convergent
dynamics and probabilistic interpretability. Backpropagating the group-weighted
loss through this module allows learning to focus on only correcting embedding
errors that won't be resolved during subsequent clustering. Our framework,
while conceptually simple and theoretically abundant, is also practically
effective and computationally efficient. We demonstrate substantial
improvements over state-of-the-art instance segmentation for object proposal
generation, as well as demonstrating the benefits of grouping loss for
classification tasks such as boundary detection and semantic segmentation.
"
1507,Towards Structured Analysis of Broadcast Badminton Videos,"  Sports video data is recorded for nearly every major tournament but remains
archived and inaccessible to large scale data mining and analytics. It can only
be viewed sequentially or manually tagged with higher-level labels which is
time consuming and prone to errors. In this work, we propose an end-to-end
framework for automatic attributes tagging and analysis of sport videos. We use
commonly available broadcast videos of matches and, unlike previous approaches,
does not rely on special camera setups or additional sensors.
  Our focus is on Badminton as the sport of interest. We propose a method to
analyze a large corpus of badminton broadcast videos by segmenting the points
played, tracking and recognizing the players in each point and annotating their
respective badminton strokes. We evaluate the performance on 10 Olympic matches
with 20 players and achieved 95.44% point segmentation accuracy, 97.38% player
detection score (mAP@0.5), 97.98% player identification accuracy, and stroke
segmentation edit scores of 80.48%. We further show that the automatically
annotated videos alone could enable the gameplay analysis and inference by
computing understandable metrics such as player's reaction time, speed, and
footwork around the court, etc.
"
1508,"Robust and discriminative zero-watermark scheme based on invariant
  feature and similarity-based retrieval for protecting large-scale DIBR 3D
  videos","  Digital rights management (DRM) of depth-image-based rendering (DIBR) 3D
video is an emerging area of research. Existing schemes for DIBR 3D video cause
video distortions, are vulnerable to severe signal and geometric attacks,
cannot protect 2D frame and depth map independently or can hardly deal with
large-scale videos. To address these issues, a novel zero-watermark scheme
based on invariant feature and similarity-based retrieval for protecting DIBR
3D video (RZW-SR3D) is proposed in this study. In RZW-SR3D, invariant features
are extracted to generate master and ownership shares for providing
distortion-free, robust and discriminative copyright identification under
various attacks. Different from traditional zero-watermark schemes, features
and ownership shares are stored correlatively, and a similarity-based retrieval
phase is designed to provide effective solutions for large-scale videos. In
addition, flexible mechanisms based on attention-based fusion are designed to
protect 2D frame and depth map independently and simultaneously. Experimental
results demonstrate that RZW-SR3D have superior DRM performances than existing
schemes. First, RZW-SR3D can extracted the ownership shares relevant to a
particular 3D video precisely and reliably for effective copyright
identification of large-scale videos. Second, RZW-SR3D ensures lossless,
precise, reliable and flexible copyright identification for 2D frame and depth
map of 3D videos.
"
1509,"Field Studies with Multimedia Big Data: Opportunities and Challenges
  (Extended Version)","  Social multimedia users are increasingly sharing all kinds of data about the
world. They do this for their own reasons, not to provide data for field
studies-but the trend presents a great opportunity for scientists. The Yahoo
Flickr Creative Commons 100 Million (YFCC100M) dataset comprises 99 million
images and nearly 800 thousand videos from Flickr, all shared under Creative
Commons licenses. To enable scientists to leverage these media records for
field studies, we propose a new framework that extracts targeted subcorpora
from the YFCC100M, in a format usable by researchers who are not experts in big
data retrieval and processing.
  This paper discusses a number of examples from the literature-as well as some
entirely new ideas-of natural and social science field studies that could be
piloted, supplemented, replicated, or conducted using YFCC100M data. These
examples illustrate the need for a general new open-source framework for
Multimedia Big Data Field Studies. There is currently a gap between the
separate aspects of what multimedia researchers have shown to be possible with
consumer-produced big data and the follow-through of creating a comprehensive
field study framework that supports scientists across other disciplines.
  To bridge this gap, we must meet several challenges. For example, the
framework must handle unlabeled and noisily labeled data to produce a filtered
dataset for a scientist-who naturally wants it to be both as large and as clean
as possible. This requires an iterative approach that provides access to
statistical summaries and refines the search by constructing new classifiers.
The first phase of our framework is available as Multimedia Commons Search, an
intuitive interface that enables complex search queries at a large scale...
"
1510,Cross-domain Human Parsing via Adversarial Feature and Label Adaptation,"  Human parsing has been extensively studied recently due to its wide
applications in many important scenarios. Mainstream fashion parsing models
focus on parsing the high-resolution and clean images. However, directly
applying the parsers trained on benchmarks to a particular application scenario
in the wild, e.g., a canteen, airport or workplace, often gives
non-satisfactory performance due to domain shift. In this paper, we explore a
new and challenging cross-domain human parsing problem: taking the benchmark
dataset with extensive pixel-wise labeling as the source domain, how to obtain
a satisfactory parser on a new target domain without requiring any additional
manual labeling? To this end, we propose a novel and efficient cross-domain
human parsing model to bridge the cross-domain differences in terms of visual
appearance and environment conditions and fully exploit commonalities across
domains. Our proposed model explicitly learns a feature compensation network,
which is specialized for mitigating the cross-domain differences. A
discriminative feature adversarial network is introduced to supervise the
feature compensation to effectively reduce the discrepancy between feature
distributions of two domains. Besides, our model also introduces a structured
label adversarial network to guide the parsing results of the target domain to
follow the high-order relationships of the structured labels shared across
domains. The proposed framework is end-to-end trainable, practical and scalable
in real applications. Extensive experiments are conducted where LIP dataset is
the source domain and 4 different datasets including surveillance videos,
movies and runway shows are evaluated as target domains. The results
consistently confirm data efficiency and performance advantages of the proposed
method for the cross-domain human parsing problem.
"
1511,"Text Extraction and Retrieval from Smartphone Screenshots: Building a
  Repository for Life in Media","  Daily engagement in life experiences is increasingly interwoven with mobile
device use. Screen capture at the scale of seconds is being used in behavioral
studies and to implement ""just-in-time"" health interventions. The increasing
psychological breadth of digital information will continue to make the actual
screens that people view a preferred if not required source of data about life
experiences. Effective and efficient Information Extraction and Retrieval from
digital screenshots is a crucial prerequisite to successful use of screen data.
In this paper, we present the experimental workflow we exploited to: (i)
pre-process a unique collection of screen captures, (ii) extract unstructured
text embedded in the images, (iii) organize image text and metadata based on a
structured schema, (iv) index the resulting document collection, and (v) allow
for Image Retrieval through a dedicated vertical search engine application. The
adopted procedure integrates different open source libraries for traditional
image processing, Optical Character Recognition (OCR), and Image Retrieval. Our
aim is to assess whether and how state-of-the-art methodologies can be applied
to this novel data set. We show how combining OpenCV-based pre-processing
modules with a Long short-term memory (LSTM) based release of Tesseract OCR,
without ad hoc training, led to a 74% character-level accuracy of the extracted
text. Further, we used the processed repository as baseline for a dedicated
Image Retrieval system, for the immediate use and application for behavioral
and prevention scientists. We discuss issues of Text Information Extraction and
Retrieval that are particular to the screenshot image case and suggest
important future work.
"
1512,Neural Style Transfer for Audio Spectograms,"  There has been fascinating work on creating artistic transformations of
images by Gatys. This was revolutionary in how we can in some sense alter the
'style' of an image while generally preserving its 'content'. In our work, we
present a method for creating new sounds using a similar approach, treating it
as a style-transfer problem, starting from a random-noise input signal and
iteratively using back-propagation to optimize the sound to conform to
filter-outputs from a pre-trained neural architecture of interest.
  For demonstration, we investigate two different tasks, resulting in bandwidth
expansion/compression, and timbral transfer from singing voice to musical
instruments. A feature of our method is that a single architecture can generate
these different audio-style-transfer types using the same set of parameters
which otherwise require different complex hand-tuned diverse signal processing
pipelines.
"
1513,"Optimized Preference-Aware Multi-path Video Streaming with Scalable
  Video Coding","  Most client hosts are equipped with multiple network interfaces (e.g., WiFi
and cellular networks). Simultaneous access of multiple interfaces can
significantly improve the users' quality of experience (QoE) in video
streaming. An intuitive approach to achieve it is to use Multi-path TCP
(MPTCP). However, the deployment of MPTCP, especially with link preference,
requires OS kernel update at both the client and server side, and a vast amount
of commercial content providers do not support MPTCP. Thus, in this paper, we
realize a multi-path video streaming algorithm in the application layer
instead, by considering Scalable Video Coding (SVC), where each layer of every
chunk can be fetched from only one of the orthogonal paths. We formulate the
quality decisions of video chunks subject to the available bandwidth of the
different paths, chunk deadlines, and link preferences as an optimization
problem. The objective is to to optimize a QoE metric that maintains a tradeoff
between maximizing the playback rate of every chunk and ensuring fairness among
chunks. The QoE is a weighted some of the following metrics: skip/stall
duration, average playback rate, and quality switching rate. However, the
weights are chosen such that pushing more chunks to the same quality level is
more preferable over any other choice. Even though the formulation is a
non-convex discrete optimization, we show that the problem can be solved
optimally with a polynomial complexity in some special cases. We further
propose an online algorithm where several challenges including bandwidth
prediction errors, are addressed. Extensive emulated experiments in a real
testbed with real traces of public dataset reveal the robustness of our scheme
and demonstrate its significant performance improvement compared to other
multi-path algorithms.
"
1514,Fake Colorized Image Detection,"  Image forensics aims to detect the manipulation of digital images. Currently,
splicing detection, copy-move detection and image retouching detection are
drawing much attentions from researchers. However, image editing techniques
develop with time goes by. One emerging image editing technique is
colorization, which can colorize grayscale images with realistic colors.
Unfortunately, this technique may also be intentionally applied to certain
images to confound object recognition algorithms. To the best of our knowledge,
no forensic technique has yet been invented to identify whether an image is
colorized. We observed that, compared to natural images, colorized images,
which are generated by three state-of-the-art methods, possess statistical
differences for the hue and saturation channels. Besides, we also observe
statistical inconsistencies in the dark and bright channels, because the
colorization process will inevitably affect the dark and bright channel values.
Based on our observations, i.e., potential traces in the hue, saturation, dark
and bright channels, we propose two simple yet effective detection methods for
fake colorized images: Histogram based Fake Colorized Image Detection
(FCID-HIST) and Feature Encoding based Fake Colorized Image Detection
(FCID-FE). Experimental results demonstrate that both proposed methods exhibit
a decent performance against multiple state-of-the-art colorization approaches.
"
1515,"Polar $n$-Complex and $n$-Bicomplex Singular Value Decomposition and
  Principal Component Pursuit","  Informed by recent work on tensor singular value decomposition and circulant
algebra matrices, this paper presents a new theoretical bridge that unifies the
hypercomplex and tensor-based approaches to singular value decomposition and
robust principal component analysis. We begin our work by extending the
principal component pursuit to Olariu's polar $n$-complex numbers as well as
their bicomplex counterparts. In so doing, we have derived the polar
$n$-complex and $n$-bicomplex proximity operators for both the $\ell_1$- and
trace-norm regularizers, which can be used by proximal optimization methods
such as the alternating direction method of multipliers. Experimental results
on two sets of audio data show that our algebraically-informed formulation
outperforms tensor robust principal component analysis. We conclude with the
message that an informed definition of the trace norm can bridge the gap
between the hypercomplex and tensor-based approaches. Our approach can be seen
as a general methodology for generating other principal component pursuit
algorithms with proper algebraic structures.
"
1516,"Complex and Quaternionic Principal Component Pursuit and Its Application
  to Audio Separation","  Recently, the principal component pursuit has received increasing attention
in signal processing research ranging from source separation to video
surveillance. So far, all existing formulations are real-valued and lack the
concept of phase, which is inherent in inputs such as complex spectrograms or
color images. Thus, in this letter, we extend principal component pursuit to
the complex and quaternionic cases to account for the missing phase
information. Specifically, we present both complex and quaternionic proximity
operators for the $\ell_1$- and trace-norm regularizers. These operators can be
used in conjunction with proximal minimization methods such as the inexact
augmented Lagrange multiplier algorithm. The new algorithms are then applied to
the singing voice separation problem, which aims to separate the singing voice
from the instrumental accompaniment. Results on the iKala and MSD100 datasets
confirmed the usefulness of phase information in principal component pursuit.
"
1517,"How to augment a small learning set for improving the performances of a
  CNN-based steganalyzer?","  Deep learning and convolutional neural networks (CNN) have been intensively
used in many image processing topics during last years. As far as steganalysis
is concerned, the use of CNN allows reaching the state-of-the-art results. The
performances of such networks often rely on the size of their learning
database. An obvious preliminary assumption could be considering that ""the
bigger a database is, the better the results are"". However, it appears that
cautions have to be taken when increasing the database size if one desire to
improve the classification accuracy i.e. enhance the steganalysis efficiency.
To our knowledge, no study has been performed on the enrichment impact of a
learning database on the steganalysis performance. What kind of images can be
added to the initial learning set? What are the sensitive criteria: the camera
models used for acquiring the images, the treatments applied to the images, the
cameras proportions in the database, etc? This article continues the work
carried out in a previous paper, and explores the ways to improve the
performances of CNN. It aims at studying the effects of ""base augmentation"" on
the performance of steganalysis using a CNN. We present the results of this
study using various experimental protocols and various databases to define the
good practices in base augmentation for steganalysis.
"
1518,"Separation of Instrument Sounds using Non-negative Matrix Factorization
  with Spectral Envelope Constraints","  Spectral envelope is one of the most important features that characterize the
timbre of an instrument sound. However, it is difficult to use spectral
information in the framework of conventional spectrogram decomposition methods.
We overcome this problem by suggesting a simple way to provide a constraint on
the spectral envelope calculated by linear prediction. In the first part of
this study, we use a pre-trained spectral envelope of known instruments as the
constraint. Then we apply the same idea to a blind scenario in which the
instruments are unknown. The experimental results reveal that the proposed
method outperforms the conventional methods.
"
1519,Ensemble Reversible Data Hiding,"  The conventional reversible data hiding (RDH) algorithms often consider the
host as a whole to embed a secret payload. In order to achieve satisfactory
rate-distortion performance, the secret bits are embedded into the noise-like
component of the host such as prediction errors. From the rate-distortion
optimization view, it may be not optimal since the data embedding units use the
identical parameters. This motivates us to present a segmented data embedding
strategy for efficient RDH in this paper, in which the raw host could be
partitioned into multiple subhosts such that each one can freely optimize and
use the data embedding parameters. Moreover, it enables us to apply different
RDH algorithms within different subhosts, which is defined as ensemble. Notice
that, the ensemble defined here is different from that in machine learning.
Accordingly, the conventional operation corresponds to a special case of the
proposed work. Since it is a general strategy, we combine some state-of-the-art
algorithms to construct a new system using the proposed embedding strategy to
evaluate the rate-distortion performance. Experimental results have shown that,
the ensemble RDH system could outperform the original versions in most cases,
which has shown the superiority and applicability.
"
1520,Reversible Embedding to Covers Full of Boundaries,"  In reversible data embedding, to avoid overflow and underflow problem, before
data embedding, boundary pixels are recorded as side information, which may be
losslessly compressed. The existing algorithms often assume that a natural
image has little boundary pixels so that the size of side information is small.
Accordingly, a relatively high pure payload could be achieved. However, there
actually may exist a lot of boundary pixels in a natural image, implying that,
the size of side information could be very large. Therefore, when to directly
use the existing algorithms, the pure embedding capacity may be not sufficient.
In order to address this problem, in this paper, we present a new and efficient
framework to reversible data embedding in images that have lots of boundary
pixels. The core idea is to losslessly preprocess boundary pixels so that it
can significantly reduce the side information. Experimental results have shown
the superiority and applicability of our work.
"
1521,"Enabling Quality-Driven Scalable Video Transmission over Multi-User NOMA
  System","  Recently, non-orthogonal multiple access (NOMA) has been proposed to achieve
higher spectral efficiency over conventional orthogonal multiple access.
Although it has the potential to meet increasing demands of video services, it
is still challenging to provide high performance video streaming. In this
research, we investigate, for the first time, a multi-user NOMA system design
for video transmission. Various NOMA systems have been proposed for data
transmission in terms of throughput or reliability. However, the perceived
quality, or the quality-of-experience of users, is more critical for video
transmission. Based on this observation, we design a quality-driven scalable
video transmission framework with cross-layer support for multi-user NOMA. To
enable low complexity multi-user NOMA operations, a novel user grouping
strategy is proposed. The key features in the proposed framework include the
integration of the quality model for encoded video with the physical layer
model for NOMA transmission, and the formulation of multi-user NOMA-based video
transmission as a quality-driven power allocation problem. As the problem is
non-concave, a global optimal algorithm based on the hidden monotonic property
and a suboptimal algorithm with polynomial time complexity are developed.
Simulation results show that the proposed multi-user NOMA system outperforms
existing schemes in various video delivery scenarios.
"
1522,"Adaptive Reversible Watermarking Based on Linear Prediction for Medical
  Videos","  Reversible video watermarking can guarantee that the watermark logo and the
original frame can be recovered from the watermarked frame without any
distortion. Although reversible video watermarking has successfully been
applied in multimedia, its application has not been extensively explored in
medical videos. Reversible watermarking in medical videos is still a
challenging problem. The existing reversible video watermarking algorithms,
which are based on error prediction expansion, use motion vectors for
prediction. In this study, we propose an adaptive reversible watermarking
method for medical videos. We suggest using temporal correlations for improving
the prediction accuracy. Hence, two temporal neighbor pixels in upcoming frames
are used alongside the four spatial rhombus neighboring pixels to minimize the
prediction error. To the best of our knowledge, this is the first time this
method is applied to medical videos. The method helps to protect patients'
personal and medical information by watermarking, i.e., increase the security
of Health Information Systems (HIS). Experimental results demonstrate the high
quality of the proposed watermarking method based on PSNR metric and a large
capacity for data hiding in medical videos.
"
1523,Time Matters: Multi-scale Temporalization of Social Media Popularity,"  The evolution of social media popularity exhibits rich temporality, i.e.,
popularities change over time at various levels of temporal granularity. This
is influenced by temporal variations of public attentions or user activities.
For example, popularity patterns of street snap on Flickr are observed to
depict distinctive fashion styles at specific time scales, such as season-based
periodic fluctuations for Trench Coat or one-off peak in days for Evening
Dress. However, this fact is often overlooked by existing research of
popularity modeling. We present the first study to incorporate multiple
time-scale dynamics into predicting online popularity. We propose a novel
computational framework in the paper, named Multi-scale Temporalization, for
estimating popularity based on multi-scale decomposition and structural
reconstruction in a tensor space of user, post, and time by joint low-rank
constraints. By considering the noise caused by context inconsistency, we
design a data rearrangement step based on context aggregation as preprocessing
to enhance contextual relevance of neighboring data in the tensor space. As a
result, our approach can leverage multiple levels of temporal characteristics
and reduce the noise of data decomposition to improve modeling effectiveness.
We evaluate our approach on two large-scale Flickr image datasets with over 1.8
million photos in total, for the task of popularity prediction. The results
show that our approach significantly outperforms state-of-the-art popularity
prediction techniques, with a relative improvement of 10.9%-47.5% in terms of
prediction accuracy.
"
1524,"Perceived Audiovisual Quality Modelling based on Decison Trees, Genetic
  Programming and Neural Networks","  Our objective is to build machine learning based models that predict
audiovisual quality directly from a set of correlated parameters that are
extracted from a target quality dataset. We have used the bitstream version of
the INRS audiovisual quality dataset that reflects contemporary real-time
configurations for video frame rate, video quantization, noise reduction
parameters and network packet loss rate. We have utilized this dataset to build
bitstream perceived quality estimation models based on the Random Forests,
Bagging, Deep Learning and Genetic Programming methods.
  We have taken an empirical approach and have generated models varying from
very simple to the most complex depending on the number of features used from
the quality dataset. Random Forests and Bagging models have overall generated
the most accurate results in terms of RMSE and Pearson correlation coefficient
values. Deep Learning and Genetic Programming based bitstream models have also
achieved good results but that high performance was observed only with a
limited range of features. We have also obtained the epsilon-insensitive RMSE
values for each model and have computed the significance of the difference
between the correlation coefficients.
  Overall we conclude that computing the bitstream information is worth the
effort it takes to generate and helps to build more accurate models for
real-time communications. However, it is useful only for the deployment of the
right algorithms with the carefully selected subset of the features. The
dataset and tools that have been developed during this research are publicly
available for research and development purposes.
"
1525,"Multi-measures fusion based on multi-objective genetic programming for
  full-reference image quality assessment","  In this paper, we exploit the flexibility of multi-objective fitness
functions, and the efficiency of the model structure selection ability of a
standard genetic programming (GP) with the parameter estimation power of
classical regression via multi-gene genetic programming (MGGP), to propose a
new fusion technique for image quality assessment (IQA) that is called
Multi-measures Fusion based on Multi-Objective Genetic Programming (MFMOGP).
This technique can automatically select the most significant suitable measures,
from 16 full-reference IQA measures, used in aggregation and finds weights in a
weighted sum of their outputs while simultaneously optimizing for both accuracy
and complexity. The obtained well-performing fusion of IQA measures are
evaluated on four largest publicly available image databases and compared
against state-of-the-art full-reference IQA approaches. Results of comparison
reveal that the proposed approach outperforms other state-of-the-art recently
developed fusion approaches.
"
1526,Multiple Description Convolutional Neural Networks for Image Compression,"  Multiple description coding (MDC) is able to stably transmit the signal in
the un-reliable and non-prioritized networks, which has been broadly studied
for several decades. However, the traditional MDC doesn't well leverage image's
context features to generate multiple descriptions. In this paper, we propose a
novel standard-compliant convolutional neural network-based MDC framework in
term of image's context features. Firstly, multiple description generator
network (MDGN) is designed to produce appearance-similar yet feature-different
multiple descriptions automatically according to image's content, which are
compressed by standard codec. Secondly, we present multiple description
reconstruction network (MDRN) including side reconstruction network (SRN) and
central reconstruction network (CRN). When any one of two lossy descriptions is
received at the decoder, SRN network is used to improve the quality of this
decoded lossy description by removing the compression artifact and up-sampling
simultaneously. Meanwhile, we utilize CRN network with two decoded descriptions
as inputs for better reconstruction, if both of lossy descriptions are
available. Thirdly, multiple description virtual codec network (MDVCN) is
proposed to bridge the gap between MDGN network and MDRN network in order to
train an end-to-end MDC framework. Here, two learning algorithms are provided
to train our whole framework. In addition to structural similarity loss
function, the produced descriptions are used as opposing labels with multiple
description distance loss function to regularize the training of MDGN network.
These losses guarantee that the generated description images are structurally
similar yet finely diverse. Experimental results show a great deal of objective
and subjective quality measurements to validate the efficiency of the proposed
method.
"
1527,"Food recognition and recipe analysis: integrating visual content,
  context and external knowledge","  The central role of food in our individual and social life, combined with
recent technological advances, has motivated a growing interest in applications
that help to better monitor dietary habits as well as the exploration and
retrieval of food-related information. We review how visual content, context
and external knowledge can be integrated effectively into food-oriented
applications, with special focus on recipe analysis and retrieval, food
recommendation, and the restaurant context as emerging directions.
"
1528,"An Optimized Information-Preserving Relational Database Watermarking
  Scheme for Ownership Protection of Medical Data","  Recently, a significant amount of interest has been developed in motivating
physicians to use e-health technology (especially Electronic Medical Records
(EMR) systems). An important utility of such EMR systems is: a next generation
of Clinical Decision Support Systems (CDSS) will extract knowledge from these
electronic medical records to enable physicians to do accurate and effective
diagnosis. It is anticipated that in future such medical records will be shared
through cloud among different physicians to improve the quality of health care.
Therefore, right protection of medical records is important to protect their
ownership once they are shared with third parties. Watermarking is a proven
well known technique to achieve this objective. The challenges associated with
watermarking of EMR systems are: (1) some fields in EMR are more relevant in
the diagnosis process; as a result, small variations in them could change the
diagnosis, and (2) a misdiagnosis might not only result in a life threatening
scenario but also might lead to significant costs of the treatment for the
patients. The major contribution of this paper is an information-preserving
watermarking scheme to address the above-mentioned challenges. We model the
watermarking process as a constrained optimization problem. We demonstrate,
through experiments, that our scheme not only preserves the diagnosis accuracy
but is also resilient to well known attacks for corrupting the watermark. Last
but not least, we also compare our scheme with a well known threshold-based
scheme to evaluate relative merits of a classifier. Our pilot studies reveal
that -- using proposed information-preserving scheme -- the overall
classification accuracy is never degraded by more than 1%. In comparison, the
diagnosis accuracy, using the threshold-based technique, is degraded by more
than 18% in a worst case scenario.
"
1529,"The New Modality: Emoji Challenges in Prediction, Anticipation, and
  Retrieval","  Over the past decade, emoji have emerged as a new and widespread form of
digital communication, spanning diverse social networks and spoken languages.
We propose to treat these ideograms as a new modality in their own right,
distinct in their semantic structure from both the text in which they are often
embedded as well as the images which they resemble. As a new modality, emoji
present rich novel possibilities for representation and interaction. In this
paper, we explore the challenges that arise naturally from considering the
emoji modality through the lens of multimedia research. Specifically, the ways
in which emoji can be related to other common modalities such as text and
images. To do so, we first present a large scale dataset of real-world emoji
usage collected from Twitter. This dataset contains examples of both text-emoji
and image-emoji relationships. We present baseline results on the challenge of
predicting emoji from both text and images, using state-of-the-art neural
networks. Further, we offer a first consideration into the problem of how to
account for new, unseen emoji - a relevant issue as the emoji vocabulary
continues to expand on a yearly basis. Finally, we present results for
multimedia retrieval using emoji as queries.
"
1530,Visually Explainable Recommendation,"  Images account for a significant part of user decisions in many application
scenarios, such as product images in e-commerce, or user image posts in social
networks. It is intuitive that user preferences on the visual patterns of image
(e.g., hue, texture, color, etc) can be highly personalized, and this provides
us with highly discriminative features to make personalized recommendations.
  Previous work that takes advantage of images for recommendation usually
transforms the images into latent representation vectors, which are adopted by
a recommendation component to assist personalized user/item profiling and
recommendation. However, such vectors are hardly useful in terms of providing
visual explanations to users about why a particular item is recommended, and
thus weakens the explainability of recommendation systems.
  As a step towards explainable recommendation models, we propose visually
explainable recommendation based on attentive neural networks to model the user
attention on images, under the supervision of both implicit feedback and
textual reviews. By this, we can not only provide recommendation results to the
users, but also tell the users why an item is recommended by providing
intuitive visual highlights in a personalized manner. Experimental results show
that our models are not only able to improve the recommendation performance,
but also can provide persuasive visual explanations for the users to take the
recommendations.
"
1531,Biomedical Signals Reconstruction Under the Compressive Sensing Approach,"  The paper analyses the possibility to recover different biomedical signals if
limited number of samples is available. Having in mind that monitoring of
health condition is done by measuring and observing key parameters such as
heart activity through electrocardiogram or anatomy and body processes through
magnetic resonance imaging, it is important to keep the quality of the
reconstructed signal as better as possible. To recover the signal from limited
set of available coefficients, the Compressive Sensing approach and
optimization algorithms are used. The theory is verified by the experimental
results.
"
1532,"Computer-Aided Annotation for Video Tampering Dataset of Forensic
  Research","  The annotation of video tampering dataset is a boring task that takes a lot
of manpower and financial resources. At present, there is no published
literature which is capable to improve the annotation efficiency of forged
videos. We presented a computer-aided annotation method for video tampering
dataset in this paper. This annotation method can be utilized to label the
frames of forged video sequences. By means of comparing the original video
frames with the forged video frames, we can locate the position and the
trajectory of the forged areas of the forged video frames. Then, we select
several key points on the temporal domain according to the trajectory of the
forged areas, and mark the forged area of the forged frames in the key point
with a mouse. Finally, we use the linear prediction algorithm based on the
coordinates of the key positions in the temporal domain to generate the
annotation information of forged areas in other video frames which without
manually labeled. If the bounding box generated by the computer-aided algorithm
deviates from the actual location of the forged area, we can use the mouse to
change the position of the bounding box during the preview period. This method
combines the manual annotation with computer-aided annotation. It solves the
problems of the inaccuracy of annotation by computer-aided as well as the low
efficiency of annotation manually, and meet the needs of annotation for an
enormous amount of forged videos in the research of video passive forensics.
"
1533,"Fine-Grained Land Use Classification at the City Scale Using
  Ground-Level Images","  We perform fine-grained land use mapping at the city scale using ground-level
images. Mapping land use is considerably more difficult than mapping land cover
and is generally not possible using overhead imagery as it requires close-up
views and seeing inside buildings. We postulate that the growing collections of
georeferenced, ground-level images suggest an alternate approach to this
geographic knowledge discovery problem. We develop a general framework that
uses Flickr images to map 45 different land-use classes for the City of San
Francisco. Individual images are classified using a novel convolutional neural
network containing two streams, one for recognizing objects and another for
recognizing scenes. This network is trained in an end-to-end manner directly on
the labeled training images. We propose several strategies to overcome the
noisiness of our user-generated data including search-based training set
augmentation and online adaptive training. We derive a ground truth map of San
Francisco in order to evaluate our method. We demonstrate the effectiveness of
our approach through geo-visualization and quantitative analysis. Our framework
achieves over 29% recall at the individual land parcel level which represents a
strong baseline for the challenging 45-way land use classification problem
especially given the noisiness of the image data.
"
1534,Learning to score the figure skating sports videos,"  This paper targets at learning to score the figure skating sports videos. To
address this task, we propose a deep architecture that includes two
complementary components, i.e., Self-Attentive LSTM and Multi-scale
Convolutional Skip LSTM. These two components can efficiently learn the local
and global sequential information in each video. Furthermore, we present a
large-scale figure skating sports video dataset -- FisV dataset. This dataset
includes 500 figure skating videos with the average length of 2 minutes and 50
seconds. Each video is annotated by two scores of nine different referees,
i.e., Total Element Score(TES) and Total Program Component Score (PCS). Our
proposed model is validated on FisV and MIT-skate datasets. The experimental
results show the effectiveness of our models in learning to score the figure
skating videos.
"
1535,Compression for Multiple Reconstructions,"  In this work we propose a method for optimizing the lossy compression for a
network of diverse reconstruction systems. We focus on adapting a standard
image compression method to a set of candidate displays, presenting the
decompressed signals to viewers. Each display is modeled as a linear operator
applied after decompression, and its probability to serve a network user. We
formulate a complicated operational rate-distortion optimization trading-off
the network's expected mean-squared reconstruction error and the compression
bit-cost. Using the alternating direction method of multipliers (ADMM) we
develop an iterative procedure where the network structure is separated from
the compression method, enabling the reliance on standard compression
techniques. We present experimental results showing our method to be the best
approach for adjusting high bit-rate image compression (using the
state-of-the-art HEVC standard) to a set of displays modeled as blur
degradations.
"
1536,Weakly supervised collective feature learning from curated media,"  The current state-of-the-art in feature learning relies on the supervised
learning of large-scale datasets consisting of target content items and their
respective category labels. However, constructing such large-scale
fully-labeled datasets generally requires painstaking manual effort. One
possible solution to this problem is to employ community contributed text tags
as weak labels, however, the concepts underlying a single text tag strongly
depends on the users. We instead present a new paradigm for learning
discriminative features by making full use of the human curation process on
social networking services (SNSs). During the process of content curation, SNS
users collect content items manually from various sources and group them by
context, all for their own benefit. Due to the nature of this process, we can
assume that (1) content items in the same group share the same semantic concept
and (2) groups sharing the same images might have related semantic concepts.
Through these insights, we can define human curated groups as weak labels from
which our proposed framework can learn discriminative features as a
representation in the space of semantic concepts the users intended when
creating the groups. We show that this feature learning can be formulated as a
problem of link prediction for a bipartite graph whose nodes corresponds to
content items and human curated groups, and propose a novel method for feature
learning based on sparse coding or network fine-tuning.
"
1537,MemeSequencer: Sparse Matching for Embedding Image Macros,"  The analysis of the creation, mutation, and propagation of social media
content on the Internet is an essential problem in computational social
science, affecting areas ranging from marketing to political mobilization. A
first step towards understanding the evolution of images online is the analysis
of rapidly modifying and propagating memetic imagery or `memes'. However, a
pitfall in proceeding with such an investigation is the current incapability to
produce a robust semantic space for such imagery, capable of understanding
differences in Image Macros. In this study, we provide a first step in the
systematic study of image evolution on the Internet, by proposing an algorithm
based on sparse representations and deep learning to decouple various types of
content in such images and produce a rich semantic embedding. We demonstrate
the benefits of our approach on a variety of tasks pertaining to memes and
Image Macros, such as image clustering, image retrieval, topic prediction and
virality prediction, surpassing the existing methods on each. In addition to
its utility on quantitative tasks, our method opens up the possibility of
obtaining the first large-scale understanding of the evolution and propagation
of memetic imagery.
"
1538,Comparison between CS and JPEG in terms of image compression,"  The comparison between two approaches, JPEG and Compressive Sensing, is done
in the paper. The approaches are compared in terms of image compression.
Comparison is done by measuring the image quality versus number of samples used
for image recovering. Images are visually compared. Also, numerical quality
value, PSNR, is calculated and compared for the two approaches. It is shown
that images, recovered by using the Compressive Sensing approach, have higher
PSNR values compared to the images under JPEG compression. Difference is larger
in grayscale images with small number of details, like e.g. medical images
(x-ray). The theory is supported by the experimental results.
"
1539,"The Hermite and Fourier transforms in sparse reconstruction of
  sinusoidal signals","  The paper observes the Hermite and the Fourier Transform domains in terms of
Frequency Hopping Spread Spectrum signals sparsification. Sparse signals can be
recovered from a reduced set of samples by using the Compressive Sensing
approach. The under-sampling and the reconstruction of those signals are also
analyzed in this paper. The number of measurements (available signal samples)
is varied and reconstruction performance is tested in all considered cases and
for both observed domains. The signal recovery is done using an adaptive
gradient based algorithm. The theory is verified with the experimental results.
"
1540,"Similarity measures for vocal-based drum sample retrieval using deep
  convolutional auto-encoders","  The expressive nature of the voice provides a powerful medium for
communicating sonic ideas, motivating recent research on methods for query by
vocalisation. Meanwhile, deep learning methods have demonstrated
state-of-the-art results for matching vocal imitations to imitated sounds, yet
little is known about how well learned features represent the perceptual
similarity between vocalisations and queried sounds. In this paper, we address
this question using similarity ratings between vocal imitations and imitated
drum sounds. We use a linear mixed effect regression model to show how features
learned by convolutional auto-encoders (CAEs) perform as predictors for
perceptual similarity between sounds. Our experiments show that CAEs outperform
three baseline feature sets (spectrogram-based representations, MFCCs, and
temporal features) at predicting the subjective similarity ratings. We also
investigate how the size and shape of the encoded layer effects the predictive
power of the learned features. The results show that preservation of temporal
information is more important than spectral resolution for this application.
"
1541,Power Control and Mode Selection for VBR Video Streaming in D2D Networks,"  In this paper, we investigate the problem of power control for streaming
variable-bit-rate (VBR) videos in a device-to-device (D2D) wireless network. A
VBR video traffic model that considers video frame sizes and playout buffers at
the mobile users is adopted. A setup with one pair of D2D users (DUs) and one
cellular user (CU) is considered and three modes, namely cellular mode,
dedicated mode and reuse mode, are employed. Mode selection for the data
delivery is determined and the transmit powers of the base station (BS) and
device transmitter are optimized with the goal of maximizing the overall
transmission rate while VBR video data can be delivered to the CU and DU
without causing playout buffer underflows or overflows. A low-complexity
algorithm is proposed. Through simulations with VBR video traces over fading
channels, we demonstrate that video delivery with mode selection and power
control achieves a better performance than just using a single mode throughout
the transmission.
"
1542,Coding Block-Level Perceptual Video Coding for 4:4:4 Data in HEVC,"  There is an increasing consumer demand for high bit-depth 4:4:4 HD video data
playback due to its superior perceptual visual quality compared with standard
8-bit subsampled 4:2:0 video data. Due to vast file sizes and associated
bitrates, it is desirable to compress raw high bit-depth 4:4:4 HD video
sequences as much as possible without incurring a discernible decrease in
visual quality. In this paper, we propose a Coding Block (CB)-level perceptual
video coding technique for HEVC named Full Color Perceptual Quantization
(FCPQ). FCPQ is designed to adjust the Quantization Parameter (QP) at the CB
level (i.e., the luma CB and the chroma Cb and Cr CBs) according to the
variances of pixel data in each CB. FCPQ is based on the default perceptual
quantization method in HEVC called AdaptiveQP. AdaptiveQP adjusts the QP of an
entire CU based only on the spatial activity of the constituent luma CB. As
demonstrated in this paper, by not accounting for the spatial activity of the
constituent chroma CBs, as is the case with AdaptiveQP, coding performance can
be significantly affected; this is because the variance of pixel data in a luma
CB is notably different from the variances of pixel data in chroma Cb and Cr
CBs. FCPQ, therefore, addresses this problem. In terms of coding performance,
FCPQ achieves BD-Rate improvements of up to 39.5% (Y), 16% (Cb) and 29.9% (Cr)
compared with AdaptiveQP.
"
1543,"Viewport Adaptation-Based Immersive Video Streaming: Perceptual Modeling
  and Applications","  Immersive video offers the freedom to navigate inside virtualized
environment. Instead of streaming the bulky immersive videos entirely, a
viewport (also referred to as field of view, FoV) adaptive streaming is
preferred. We often stream the high-quality content within current viewport,
while reducing the quality of representation elsewhere to save the network
bandwidth consumption. Consider that we could refine the quality when focusing
on a new FoV, in this paper, we model the perceptual impact of the quality
variations (through adapting the quantization stepsize and spatial resolution)
with respect to the refinement duration, and yield a product of two closed-form
exponential functions that well explain the joint quantization and resolution
induced quality impact. Analytical model is cross-validated using another set
of data, where both Pearson and Spearman's rank correlation coefficients are
close to 0.98. Our work is devised to optimize the adaptive FoV streaming of
the immersive video under limited network resource. Numerical results show that
our proposed model significantly improves the quality of experience of users,
with about 9.36\% BD-Rate (Bjontegaard Delta Rate) improvement on average as
compared to other representative methods, particularly under the limited
bandwidth.
"
1544,Be-Educated: Multimedia Learning through 3D Animation,"  Multimedia learning tools and techniques are placing its importance with
large scale in education sector. With the help of multimedia learning, various
complex phenomenon and theories can be explained and taught easily and
conveniently. This project aims to teach and spread the importance of education
and respecting the tools of education: pen, paper, pencil, rubber. To achieve
this cognitive learning, a 3D animated movie has been developed using
principles of multimedia learning with 3D cartoon characters resembling the
actual educational objects, where the buildings have also been modelled to
resemble real books and diaries. For modelling and animation of these
characters, polygon mesh tools are used in 3D Studio Max. Additionally, the
final composition of video and audio is performed in adobe premiere. This 3D
animated video aims to highlight a message of importance for education and
stationary. The Moral of movie is that do not waste your stationary material,
use your Pen and Paper for the purpose they are made for. To be a good citizen
you have to Be-Educated yourself and for that you need to give value to Pen.
The final rendered and composited 3D animated video reflects this moral and
portrays the intended message with very vibrant visuals
"
1545,"TRLF: An Effective Semi-fragile Watermarking Method for Tamper Detection
  and Recovery based on LWT and FNN","  This paper proposes a novel method for tamper detection and recovery using
semi-fragile data hiding, based on Lifting Wavelet Transform (LWT) and
Feed-Forward Neural Network (FNN). In TRLF, first, the host image is decomposed
up to one level using LWT, and the Discrete Cosine Transform (DCT) is applied
to each 2*2 blocks of diagonal details. Next, a random binary sequence is
embedded in each block as the watermark by correlating $DC$ coefficients. In
authentication stage, first, the watermarked image geometry is reconstructed by
using Speeded Up Robust Features (SURF) algorithm and extract watermark bits by
using FNN. Afterward, logical exclusive-or operation between original and
extracted watermark is applied to detect tampered region. Eventually, in the
recovery stage, tampered regions are recovered by image digest which is
generated by inverse halftoning technique. The performance and efficiency of
TRLF and its robustness against various geometric, non-geometric and hybrid
attacks are reported. From the experimental results, it can be seen that TRLF
is superior in terms of robustness and quality of the digest and watermarked
image respectively, compared to the-state-of-the-art fragile and semi-fragile
watermarking methods. In addition, imperceptibility has been improved by using
different correlation steps as the gain factor for flat (smooth) and texture
(rough) blocks.
"
1546,Comparison of threshold-based algorithms for sparse signal recovery,"  Intensively growing approach in signal processing and acquisition, the
Compressive Sensing approach, allows sparse signals to be recovered from small
number of randomly acquired signal coefficients. This paper analyses some of
the commonly used threshold-based algorithms for sparse signal reconstruction.
Signals satisfy the conditions required by the Compressive Sensing theory. The
Orthogonal Matching Pursuit, Iterative Hard Thresholding and Single Iteration
Reconstruction algorithms are observed. Comparison in terms of reconstruction
error and execution time is performed within the experimental part of the
paper.
"
1547,Adaptive Streaming in Interactive Multiview Video Systems,"  Multiview applications endow final users with the possibility to freely
navigate within 3D scenes with minimum-delay. A real feeling of scene
navigation is enabled by transmitting multiple high-quality camera views, which
can be used to synthesize additional virtual views to offer a smooth
navigation. However, when network resources are limited, not all camera views
can be sent at high quality. It is therefore important, yet challenging, to
find the right tradeoff between coding artifacts (reducing the quality of
camera views) and virtual synthesis artifacts (reducing the number of camera
views sent to users). To this aim, we propose an optimal transmission strategy
for interactive multiview HTTP adaptive streaming (HAS). We propose a problem
formulation to select the optimal set of camera views that the client requests
for downloading, such that the navigation quality experienced by the user is
optimized while the bandwidth constraints are satisfied. We show that our
optimization problem is NP-hard, and we therefore develop an optimal solution
based on the dynamic programming algorithm with polynomial time complexity. To
further simplify the deployment, we present a suboptimal greedy algorithm with
effective performance and lower complexity. The proposed controller is
evaluated in theoretical and realistic settings characterized by realistic
network statistics estimation, buffer management and server-side representation
optimization. Simulation results show significant improvement in terms of
navigation quality compared with alternative baseline multiview adaptation
logic solutions.
"
1548,"Perceptual Quality Assessment of Immersive Images Considering Peripheral
  Vision Impact","  Conventional images/videos are often rendered within the central vision area
of the human visual system (HVS) with uniform quality. Recent virtual reality
(VR) device with head mounted display (HMD) extends the field of view (FoV)
significantly to include both central and peripheral vision areas. It exhibits
the unequal image quality sensation among these areas because of the
non-uniform distribution of photoreceptors on our retina. We propose to study
the sensation impact on the image subjective quality with respect to the
eccentric angle $\theta$ across different vision areas. Often times, image
quality is controlled by the quantization stepsize $q$ and spatial resolution
$s$, separately and jointly. Therefore, the sensation impact can be understood
by exploring the $q$ and/or $s$ in terms of the $\theta$, resulting in
self-adaptive analytical models that have shown quite impressive accuracy
through independent cross validations. These models can further be applied to
give different quality weights at different regions, so as to significantly
reduce the transmission data size but without subjective quality loss. As
demonstrated in a gigapixel imaging system, we have shown that the image
rendering can be speed up about 10$\times$ with the model guided unequal
quality scales, in comparison to the the legacy scheme with uniform quality
scales everywhere.
"
1549,"User Satisfaction-Driven Bandwidth Allocation for Image Transmission in
  a Crowded Environment","  A major portion of postings on social networking sites constitute high
quality digital images and videos. These images and videos require a fairly
large amount of bandwidth during transmission. Accordingly, high quality image
and video postings become a challenge for the network service provider,
especially in a crowded environment where bandwidth is in high demand. In this
paper we present a user satisfaction driven bandwidth allocation scheme for
image transmission in such environments. In an image, there are always objects
that stand out more than others. The reason behind some set of objects being
more important in a scene is based on a number of visual, as well as, cognitive
factors. Being motivated by the fact that user satisfaction is more dependent
on the quality of these salient objects in an image than non-salient ones, we
propose a quantifiable metric for measuring user-satisfiability (based on image
quality and delay of transmission). The bandwidth allocation technique proposed
thereafter, ensures that this user-satisfiability is maximized. Unlike the
existing approaches that utilize some fixed set of non-linear functions for
framing the user-satisfiability index, our metric is modelled over customer
survey data, where the unknown parameters are trained with machine learning
methods.
"
1550,The Cut and Dominating Set Problem in A Steganographer Network,"  A steganographer network corresponds to a graphic structure that the involved
vertices (or called nodes) denote social entities such as the data encoders and
data decoders, and the associated edges represent any real communicable
channels or other social links that could be utilized for steganography. Unlike
traditional steganographic algorithms, a steganographer network models
steganographic communication by an abstract way such that the concerned
underlying characteristics of steganography are quantized as analyzable
parameters in the network. In this paper, we will analyze two problems in a
steganographer network. The first problem is a passive attack to a
steganographer network where a network monitor has collected a list of
suspicious vertices corresponding to the data encoders or decoders. The network
monitor expects to break (disconnect) the steganographic communication down
between the suspicious vertices while keeping the cost as low as possible. The
second one relates to determining a set of vertices corresponding to the data
encoders (senders) such that all vertices can share a message by neighbors. We
point that, the two problems are equivalent to the minimum cut problem and the
minimum-weight dominating set problem.
"
1551,Pop Music Highlighter: Marking the Emotion Keypoints,"  The goal of music highlight extraction is to get a short consecutive segment
of a piece of music that provides an effective representation of the whole
piece. In a previous work, we introduced an attention-based convolutional
recurrent neural network that uses music emotion classification as a surrogate
task for music highlight extraction, for Pop songs. The rationale behind that
approach is that the highlight of a song is usually the most emotional part.
This paper extends our previous work in the following two aspects. First,
methodology-wise we experiment with a new architecture that does not need any
recurrent layers, making the training process faster. Moreover, we compare a
late-fusion variant and an early-fusion variant to study which one better
exploits the attention mechanism. Second, we conduct and report an extensive
set of experiments comparing the proposed attention-based methods against a
heuristic energy-based method, a structural repetition-based method, and a few
other simple feature-based methods for this task. Due to the lack of
public-domain labeled data for highlight extraction, following our previous
work we use the RWC POP 100-song data set to evaluate how the detected
highlights overlap with any chorus sections of the songs. The experiments
demonstrate the effectiveness of our methods over competing methods. For
reproducibility, we open source the code and pre-trained model at
https://github.com/remyhuang/pop-music-highlighter/.
"
1552,"Classifying flows and buffer state for YouTube's HTTP adaptive streaming
  service in mobile networks","  Accurate cross-layer information is very useful to optimize mobile networks
for specific applications. However, providing application-layer information to
lower protocol layers has become very difficult due to the wide adoption of
end-to-end encryption and due to the absence of cross-layer signaling
standards. As an alternative, this paper presents a traffic profiling solution
to passively estimate parameters of HTTP Adaptive Streaming (HAS) applications
at the lower layers. By observing IP packet arrivals, our machine learning
system identifies video flows and detects the state of an HAS client's
play-back buffer in real time. Our experiments with YouTube's mobile client
show that Random Forests achieve very high accuracy even with a strong
variation of link quality. Since this high performance is achieved at IP level
with a small, generic feature set, our approach requires no Deep Packet
Inspection (DPI), comes at low complexity, and does not interfere with
end-to-end encryption. Traffic profiling is, thus, a powerful new tool for
monitoring and managing even encrypted HAS traffic in mobile networks.
"
1553,"Raw Multi-Channel Audio Source Separation using Multi-Resolution
  Convolutional Auto-Encoders","  Supervised multi-channel audio source separation requires extracting useful
spectral, temporal, and spatial features from the mixed signals. The success of
many existing systems is therefore largely dependent on the choice of features
used for training. In this work, we introduce a novel multi-channel,
multi-resolution convolutional auto-encoder neural network that works on raw
time-domain signals to determine appropriate multi-resolution features for
separating the singing-voice from stereo music. Our experimental results show
that the proposed method can achieve multi-channel audio source separation
without the need for hand-crafted features or any pre- or post-processing.
"
1554,Stylize Aesthetic QR Code,"  With the continued proliferation of smart mobile devices, Quick Response (QR)
code has become one of the most-used types of two-dimensional code in the
world. Aiming at beautifying the visual-unpleasant appearance of QR codes,
existing works have developed a series of techniques. However, these works
still leave much to be desired, such as personalization, artistry, and
robustness. To address these issues, in this paper, we propose a novel type of
aesthetic QR codes, SEE (Stylize aEsthEtic) QR code, and a three-stage approach
to automatically produce such robust style-oriented codes. Specifically, in the
first stage, we propose a method to generate an optimized baseline aesthetic QR
code, which reduces the visual contrast between the noise-like black/white
modules and the blended image. In the second stage, to obtain art style QR
code, we tailor an appropriate neural style transformation network to endow the
baseline aesthetic QR code with artistic elements. In the third stage, we
design an error-correction mechanism by balancing two competing terms, visual
quality and readability, to ensure the performance robust. Extensive
experiments demonstrate that SEE QR code has high quality in terms of both
visual appearance and robustness, and also offers a greater variety of
personalized choices to users.
"
1555,"Multiple Sound Source Localisation with Steered Response Power Density
  and Hierarchical Grid Refinement","  Estimation of the direction-of-arrival (DOA) of sound sources is an important
step in sound field analysis. Rigid spherical microphone arrays allow the
calculation of a compact spherical harmonic representation of the sound field.
A basic method for analysing sound fields recorded using such arrays is steered
response power (SRP) maps wherein the source DOA can be estimated as the
steering direction that maximises the output power of a maximally-directive
beam. This approach is computationally costly since it requires steering the
beam in all possible directions. This paper presents an extension to SRP called
steered response power density (SRPD) and an associated, signal-adaptive search
method called hierarchical grid refinement (HiGRID) for reducing the number of
steering directions needed for DOA estimation. The proposed method can localise
coherent as well as incoherent sources while jointly providing the number of
prominent sources in the scene. It is shown to be robust to reverberation and
additive white noise. An evaluation of the proposed method using simulations
and real recordings under highly reverberant conditions as well as a comparison
with state- of-the-art methods are presented.
"
1556,ART-UP: A Novel Method for Generating Scanning-robust Aesthetic QR codes,"  QR codes are usually scanned in different environments, so they must be
robust to variations in illumination, scale, coverage, and camera angles.
Aesthetic QR codes improve the visual quality, but subtle changes in their
appearance may cause scanning failure. In this paper, a new method to generate
scanning-robust aesthetic QR codes is proposed, which is based on a
module-based scanning probability estimation model that can effectively balance
the tradeoff between visual quality and scanning robustness. Our method locally
adjusts the luminance of each module by estimating the probability of
successful sampling. The approach adopts the hierarchical, coarse-to-fine
strategy to enhance the visual quality of aesthetic QR codes, which
sequentially generate the following three codes: a binary aesthetic QR code, a
grayscale aesthetic QR code, and the final color aesthetic QR code. Our
approach also can be used to create QR codes with different visual styles by
adjusting some initialization parameters. User surveys and decoding experiments
were adopted for evaluating our method compared with state-of-the-art
algorithms, which indicates that the proposed approach has excellent
performance in terms of both visual quality and scanning robustness.
"
1557,"TRLG: Fragile blind quad watermarking for image tamper detection and
  recovery by providing compact digests with quality optimized using LWT and GA","  In this paper, an efficient fragile blind quad watermarking scheme for image
tamper detection and recovery based on lifting wavelet transform and genetic
algorithm is proposed. TRLG generates four compact digests with super quality
based on lifting wavelet transform and halftoning technique by distinguishing
the types of image blocks. In other words, for each 2*2 non-overlap blocks,
four chances for recovering destroyed blocks are considered. A special
parameter estimation technique based on genetic algorithm is performed to
improve and optimize the quality of digests and watermarked image. Furthermore,
CCS map is used to determine the mapping block for embedding information,
encrypting and confusing the embedded information. In order to improve the
recovery rate, Mirror-aside and Partner-block are proposed. The experiments
that have been conducted to evaluate the performance of TRLG proved the
superiority in terms of quality of the watermarked and recovered image, tamper
localization and security compared with state-of-the-art methods. The results
indicate that the PSNR and SSIM of the watermarked image are about 46 dB and
approximately one, respectively. Also, the mean of PSNR and SSIM of several
recovered images which has been destroyed about 90% is reached to 24 dB and
0.86, respectively.
"
1558,Deep Cross-media Knowledge Transfer,"  Cross-media retrieval is a research hotspot in multimedia area, which aims to
perform retrieval across different media types such as image and text. The
performance of existing methods usually relies on labeled data for model
training. However, cross-media data is very labor consuming to collect and
label, so how to transfer valuable knowledge in existing data to new data is a
key problem towards application. For achieving the goal, this paper proposes
deep cross-media knowledge transfer (DCKT) approach, which transfers knowledge
from a large-scale cross-media dataset to promote the model training on another
small-scale cross-media dataset. The main contributions of DCKT are: (1)
Two-level transfer architecture is proposed to jointly minimize the media-level
and correlation-level domain discrepancies, which allows two important and
complementary aspects of knowledge to be transferred: intra-media semantic and
inter-media correlation knowledge. It can enrich the training information and
boost the retrieval accuracy. (2) Progressive transfer mechanism is proposed to
iteratively select training samples with ascending transfer difficulties, via
the metric of cross-media domain consistency with adaptive feedback. It can
drive the transfer process to gradually reduce vast cross-media domain
discrepancy, so as to enhance the robustness of model training. For verifying
the effectiveness of DCKT, we take the largescale dataset XMediaNet as source
domain, and 3 widelyused datasets as target domain for cross-media retrieval.
Experimental results show that DCKT achieves promising improvement on retrieval
accuracy.
"
1559,Learning to Localize Sound Source in Visual Scenes,"  Visual events are usually accompanied by sounds in our daily lives. We pose
the question: Can the machine learn the correspondence between visual scene and
the sound, and localize the sound source only by observing sound and visual
scene pairs like human? In this paper, we propose a novel unsupervised
algorithm to address the problem of localizing the sound source in visual
scenes. A two-stream network structure which handles each modality, with
attention mechanism is developed for sound source localization. Moreover,
although our network is formulated within the unsupervised learning framework,
it can be extended to a unified architecture with a simple modification for the
supervised and semi-supervised learning settings as well. Meanwhile, a new
sound source dataset is developed for performance evaluation. Our empirical
evaluation shows that the unsupervised method eventually go through false
conclusion in some cases. We show that even with a few supervision, false
conclusion is able to be corrected and the source of sound in a visual scene
can be localized effectively.
"
1560,Learning Local Distortion Visibility From Image Quality Data-sets,"  Accurate prediction of local distortion visibility thresholds is critical in
many image and video processing applications. Existing methods require an
accurate modeling of the human visual system, and are derived through
pshycophysical experiments with simple, artificial stimuli. These approaches,
however, are difficult to generalize to natural images with complex types of
distortion. In this paper, we explore a different perspective, and we
investigate whether it is possible to learn local distortion visibility from
image quality scores. We propose a convolutional neural network based
optimization framework to infer local detection thresholds in a distorted
image. Our model is trained on multiple quality datasets, and the results are
correlated with empirical visibility thresholds collected on complex stimuli in
a recent study. Our results are comparable to state-of-the-art mathematical
models that were trained on phsycovisual data directly. This suggests that it
is possible to predict psychophysical phenomena from visibility information
embedded in image quality scores.
"
1561,Multi-Reference Video Coding Using Stillness Detection,"  Encoders of AOM/AV1 codec consider an input video sequence as succession of
frames grouped in Golden-Frame (GF) groups. The coding structure of a GF group
is fixed with a given GF group size. In the current AOM/AV1 encoder, video
frames are coded using a hierarchical, multilayer coding structure within one
GF group. It has been observed that the use of multilayer coding structure may
result in worse coding performance if the GF group presents consistent
stillness across its frames. This paper proposes a new approach that adaptively
designs the Golden-Frame (GF) group coding structure through the use of
stillness detection. Our new approach hence develops an automatic stillness
detection scheme using three metrics extracted from each GF group. It then
differentiates those GF groups of stillness from other non- still GF groups and
uses different GF coding structures accordingly. Experimental result
demonstrates a consistent coding gain using the new approach.
"
1562,Robust LSB Watermarking Optimized for Local Structural Similarity,"  Growth of the Internet and networked multimedia systems has emphasized the
need for copyright protection of the media. Media can be images, audio clips,
videos and etc. Digital watermarking is today extensively used for many
applications such as authentication of ownership or identification of illegal
copies. Digital watermark is an invisible or maybe visible structure added to
the original media (known as asset). Images are considered as communication
channel when they are subject to a watermark embedding procedure so in the case
of embedding a digital watermark in an image, the capacity of the channel
should be considered. There is a trade-off between imperceptibility, robustness
and capacity for embedding a watermark in an asset. In the case of image
watermarks, it is reasonable that the watermarking algorithm should depend on
the content and structure of the image. Conventionally, mean squared error
(MSE) has been used as a common distortion measure to assess the quality of the
images. Newly developed quality metrics proposed some distortion measures that
are based on human visual system (HVS). These metrics show that MSE is not
based on HVS and it has a lack of accuracy when dealing with perceptually
important signals such as images and videos. SSIM or structural similarity is a
state of the art HVS based image quality criterion that has recently been of
much interest. In this paper we propose a robust least significant bit (LSB)
watermarking scheme which is optimized for structural similarity. The watermark
is embedded into a host image through an adaptive algorithm. Various attacks
examined on the embedding approach and simulation results revealed the fact
that the watermarked sequence can be extracted with an acceptable accuracy
after all attacks.
"
1563,Effect of Eye Dominance on the Perception of Stereoscopic 3D Video,"  Asymmetric schemes have widespread applications in the 3D video transmission
pipeline. The significance of eye dominance becomes a concern when designing
such schemes. In this paper, in order to investigate the effect of eye
dominance on the perceptual 3D video quality, a database of representative
asymmetric stereoscopic sequences is prepared and the overall 3D quality of
these sequences is evaluated through subjective experiments. Experiment results
showed that viewers find an asymmetric video more pleasant when the view with
higher quality is projected to their dominant eye. Moreover, the eye dominance
changes the mean opinion quality score by 16 % at most, a result caused by
slight asymmetric video compression. For all other representative types of
asymmetry, the statistical difference is much lower and in some cases even
negligible.
"
1564,Multi-Frame Quality Enhancement for Compressed Video,"  The past few years have witnessed great success in applying deep learning to
enhance the quality of compressed image/video. The existing approaches mainly
focus on enhancing the quality of a single frame, ignoring the similarity
between consecutive frames. In this paper, we investigate that heavy quality
fluctuation exists across compressed video frames, and thus low quality frames
can be enhanced using the neighboring high quality frames, seen as Multi-Frame
Quality Enhancement (MFQE). Accordingly, this paper proposes an MFQE approach
for compressed video, as a first attempt in this direction. In our approach, we
firstly develop a Support Vector Machine (SVM) based detector to locate Peak
Quality Frames (PQFs) in compressed video. Then, a novel Multi-Frame
Convolutional Neural Network (MF-CNN) is designed to enhance the quality of
compressed video, in which the non-PQF and its nearest two PQFs are as the
input. The MF-CNN compensates motion between the non-PQF and PQFs through the
Motion Compensation subnet (MC-subnet). Subsequently, the Quality Enhancement
subnet (QE-subnet) reduces compression artifacts of the non-PQF with the help
of its nearest PQFs. Finally, the experiments validate the effectiveness and
generality of our MFQE approach in advancing the state-of-the-art quality
enhancement of compressed video. The code of our MFQE approach is available at
https://github.com/ryangBUAA/MFQE.git
"
1565,"Robust Contrast Enhancement Forensics Using Pixel and Histogram Domain
  CNNs","  Contrast enhancement (CE) forensics has always been ofconcern to image
forensics community. It can provide aneffective tool for recovering image
history and identifyingtampered images. Although several CE forensic
algorithmshave been proposed, their robustness against some processingis still
unsatisfactory, such as JPEG compression and anti-forensic attacks. In order to
attenuate such deficiency, inthis paper we first present a discriminability
analysis of CEforensics in pixel and gray level histogram domains. Then, insuch
two domains, two end-to-end methods based on convo-lutional neural networks
(P-CNN, H-CNN) are proposed toachieve robust CE forensics against pre-JPEG
compressionand anti-forensics attacks. Experimental results show that
theproposed methods achieve much better performance than thestate-of-the-art
schemes for CE detection in the case of noother operation and comparable
performance when pre-JPEGcompression and anti-foresics attacks is used.
"
1566,"WISERNet: Wider Separate-then-reunion Network for Steganalysis of Color
  Images","  Until recently, deep steganalyzers in spatial domain have been all designed
for gray-scale images. In this paper, we propose WISERNet (the wider
separate-then-reunion network) for steganalysis of color images. We provide
theoretical rationale to claim that the summation in normal convolution is one
sort of ""linear collusion attack"" which reserves strong correlated patterns
while impairs uncorrelated noises. Therefore in the bottom convolutional layer
which aims at suppressing correlated image contents, we adopt separate
channel-wise convolution without summation instead. Conversely, in the upper
convolutional layers we believe that the summation in normal convolution is
beneficial. Therefore we adopt united normal convolution in those layers and
make them remarkably wider to reinforce the effect of ""linear collusion
attack"". As a result, our proposed wide-and-shallow, separate-then-reunion
network structure is specifically suitable for color image steganalysis. We
have conducted extensive experiments on color image datasets generated from
BOSSBase raw images and another large-scale dataset which contains 100,000 raw
images, with different demosaicking algorithms and down-sampling algorithms.
The experimental results show that our proposed network outperforms other
state-of-the-art color image steganalytic models either hand-crafted or learned
using deep networks in the literature by a clear margin. Specifically, it is
noted that the detection performance gain is achieved with less than half the
complexity compared to the most advanced deep-learning steganalyzer as far as
we know, which is scarce in the literature.
"
1567,"An Improvement Technique based on Structural Similarity Thresholding for
  Digital Watermarking","  Digital watermarking is extensively used in ownership authentication and
copyright protection. In this paper, we propose an efficient thresholding
scheme to improve the watermark embedding procedure in an image. For the
proposed algorithm, watermark casting is performed separately in each block of
an image, and embedding in each block continues until a certain structural
similarity threshold is reached. Numerical evaluations demonstrate that our
scheme improves the imperceptibility of the watermark when the capacity remains
fix, and at the same time, robustness against attacks is assured. The proposed
method is applicable to most image watermarking algorithms. We verify this
issue on watermarking schemes in Discrete Cosine Transform (DCT), wavelet, and
spatial domain.
"
1568,A nonlinear transform based analog video transmission framework,"  Soft-cast, a cross-layer design for wireless video transmission, is proposed
to solve the drawbacks of digital video transmission: threshold transmission
framework achieving the same effect. Specifically, in encoder, we carry out
power allocation on the transformed coefficients and encode the coefficients
based on the new formulation of power distortion. In decoder, the process of
LLSE estimator is also improved. Accompanied with the inverse nonlinear
transform, DCT coefficients can be recovered depending on the scaling factors ,
LLSE estimator coefficients and metadata. Experiment results show that our
proposed framework outperforms the Soft-cast in PSNR 1.08 dB and the MSSIM gain
reaches to 2.35% when transmitting under the same bandwidth and total power.
"
1569,"Joint Rate Allocation with Both Look-ahead And Feedback Model For High
  Efficiency Video Coding","  The objective of joint rate allocation among multiple coded video streams is
to share the bandwidth to meet the demands of minimum average distortion
(minAVE) or minimum distortion variance (minVAR). In previous works on minVAR
problems, bits are directly assigned in proportion to their complexity measures
and we call it look-ahead allocation model (LAM), which leads to the fact that
the performance will totally depend on the accuracy of the complexity measures.
This paper proposes a look-ahead and feedback allocation model (LFAM) for joint
rate allocation for High Efficiency Video Coding (HEVC) platform which requires
negligible computational cost. We derive the model from the target function of
minVAR theoretically. The bits are assigned according to the complexity
measures, the distortion and bitrate values fed back by the encoder together.
We integrated the proposed allocation model in HEVC reference software HM16.0
and several complexity measures were applied to our allocation model. Results
demonstrate that our proposed LFAM performs better than LAM, and an average of
65.94% variance of mean square error (MSE) is saved with different complexity
measures.
"
1570,Multi-Codec DASH Dataset,"  The number of bandwidth-hungry applications and services is constantly
growing. HTTP adaptive streaming of audio-visual content accounts for the
majority of today's internet traffic. Although the internet bandwidth increases
also constantly, audio-visual compression technology is inevitable and we are
currently facing the challenge to be confronted with multiple video codecs.
This paper proposes a multi-codec DASH dataset comprising AVC, HEVC, VP9, and
AV1 in order to enable interoperability testing and streaming experiments for
the efficient usage of these codecs under various conditions. We adopt state of
the art encoding and packaging options and also provide basic quality metrics
along with the DASH segments. Additionally, we briefly introduce a multi-codec
DASH scheme and possible usage scenarios. Finally, we provide a preliminary
evaluation of the encoding efficiency in the context of HTTP adaptive streaming
services and applications.
"
1571,Dynamic Variational Autoencoders for Visual Process Modeling,"  This work studies the problem of modeling visual processes by leveraging deep
generative architectures for learning linear, Gaussian representations from
observed sequences. We propose a joint learning framework, combining a vector
autoregressive model and Variational Autoencoders. This results in an
architecture that allows Variational Autoencoders to simultaneously learn a
non-linear observation as well as a linear state model from sequences of
frames. We validate our approach on artificial sequences and dynamic textures.
"
1572,"QoE-Oriented Resource Allocation for 360-degree Video Transmission over
  Heterogeneous Networks","  Immersive media streaming, especially virtual reality (VR)/360-degree video
streaming which is very bandwidth demanding, has become more and more popular
due to the rapid growth of the multimedia and networking deployments. To better
explore the usage of resource and achieve better quality of experience (QoE)
perceived by users, this paper develops an application-layer scheme to jointly
exploit the available bandwidth from the LTE and Wi-Fi networks in 360-degree
video streaming. This newly proposed scheme and the corresponding solution
algorithms utilize the saliency of video, prediction of users' view and the
status information of users to obtain an optimal association of the users with
different Wi-Fi access points (APs) for maximizing the system's utility.
Besides, a novel buffer strategy is proposed to mitigate the influence of
short-time prediction problem for transmitting 360-degree videos in
time-varying networks. The promising performance and low complexity of the
proposed scheme and algorithms are validated in simulations with various
360-degree videos.
"
1573,Viewport-Driven Rate-Distortion Optimized 360{\deg} Video Streaming,"  The growing popularity of virtual and augmented reality communications and
360{\deg} video streaming is moving video communication systems into much more
dynamic and resource-limited operating settings. The enormous data volume of
360{\deg} videos requires an efficient use of network bandwidth to maintain the
desired quality of experience for the end user. To this end, we propose a
framework for viewport-driven rate-distortion optimized 360{\deg} video
streaming that integrates the user view navigation pattern and the
spatiotemporal rate-distortion characteristics of the 360{\deg} video content
to maximize the delivered user quality of experience for the given
network/system resources. The framework comprises a methodology for
constructing dynamic heat maps that capture the likelihood of navigating
different spatial segments of a 360{\deg} video over time by the user, an
analysis and characterization of its spatiotemporal rate-distortion
characteristics that leverage preprocessed spatial tilling of the 360{\deg}
view sphere, and an optimization problem formulation that characterizes the
delivered user quality of experience given the user navigation patterns,
360{\deg} video encoding decisions, and the available system/network resources.
Our experimental results demonstrate the advantages of our framework over the
conventional approach of streaming a monolithic uniformly encoded 360{\deg}
video and a state-of-the-art reference method. Considerable video quality gains
of 4 - 5 dB are demonstrated in the case of two popular 4K 360{\deg} videos.
"
1574,Towards Universal Representation for Unseen Action Recognition,"  Unseen Action Recognition (UAR) aims to recognise novel action categories
without training examples. While previous methods focus on inner-dataset
seen/unseen splits, this paper proposes a pipeline using a large-scale training
source to achieve a Universal Representation (UR) that can generalise to a more
realistic Cross-Dataset UAR (CD-UAR) scenario. We first address UAR as a
Generalised Multiple-Instance Learning (GMIL) problem and discover
'building-blocks' from the large-scale ActivityNet dataset using distribution
kernels. Essential visual and semantic components are preserved in a shared
space to achieve the UR that can efficiently generalise to new datasets.
Predicted UR exemplars can be improved by a simple semantic adaptation, and
then an unseen action can be directly recognised using UR during the test.
Without further training, extensive experiments manifest significant
improvements over the UCF101 and HMDB51 benchmarks.
"
1575,KonIQ-10k: Towards an ecologically valid and large-scale IQA database,"  The main challenge in applying state-of-the-art deep learning methods to
predict image quality in-the-wild is the relatively small size of existing
quality scored datasets. The reason for the lack of larger datasets is the
massive resources required in generating diverse and publishable content. We
present a new systematic and scalable approach to create large-scale, authentic
and diverse image datasets for Image Quality Assessment (IQA). We show how we
built an IQA database, KonIQ-10k, consisting of 10,073 images, on which we
performed very large scale crowdsourcing experiments in order to obtain
reliable quality ratings from 1,467 crowd workers (1.2 million ratings). We
argue for its ecological validity by analyzing the diversity of the dataset, by
comparing it to state-of-the-art IQA databases, and by checking the reliability
of our user studies.
"
1576,"PDNet: Prior-model Guided Depth-enhanced Network for Salient Object
  Detection","  Fully convolutional neural networks (FCNs) have shown outstanding performance
in many computer vision tasks including salient object detection. However,
there still remains two issues needed to be addressed in deep learning based
saliency detection. One is the lack of tremendous amount of annotated data to
train a network. The other is the lack of robustness for extracting salient
objects in images containing complex scenes. In this paper, we present a new
architecture$ - $PDNet, a robust prior-model guided depth-enhanced network for
RGB-D salient object detection. In contrast to existing works, in which RGB-D
values of image pixels are fed directly to a network, the proposed architecture
is composed of a master network for processing RGB values, and a sub-network
making full use of depth cues and incorporate depth-based features into the
master network. To overcome the limited size of the labeled RGB-D dataset for
training, we employ a large conventional RGB dataset to pre-train the master
network, which proves to contribute largely to the final accuracy. Extensive
evaluations over five benchmark datasets demonstrate that our proposed method
performs favorably against the state-of-the-art approaches.
"
1577,Object Detection for Comics using Manga109 Annotations,"  With the growth of digitized comics, image understanding techniques are
becoming important. In this paper, we focus on object detection, which is a
fundamental task of image understanding. Although convolutional neural networks
(CNN)-based methods archived good performance in object detection for
naturalistic images, there are two problems in applying these methods to the
comic object detection task. First, there is no large-scale annotated comics
dataset. The CNN-based methods require large-scale annotations for training.
Secondly, the objects in comics are highly overlapped compared to naturalistic
images. This overlap causes the assignment problem in the existing CNN-based
methods. To solve these problems, we proposed a new annotation dataset and a
new CNN model. We annotated an existing image dataset of comics and created the
largest annotation dataset, named Manga109-annotations. For the assignment
problem, we proposed a new CNN-based detector, SSD300-fork. We compared
SSD300-fork with other detection methods using Manga109-annotations and
confirmed that our model outperformed them based on the mAP score.
"
1578,Automatic Music Accompanist,"  Automatic musical accompaniment is where a human musician is accompanied by a
computer musician. The computer musician is able to produce musical
accompaniment that relates musically to the human performance. The
accompaniment should follow the performance using observations of the notes
they are playing. This paper describes a complete and detailed construction of
a score following and accompanying system using Hidden Markov Models (HMMs). It
details how to train a score HMM, how to deal with polyphonic input, how this
HMM work when following score, how to build up a musical accompanist. It
proposes a new parallel hidden Markov model for score following and a fast
decoding algorithm to deal with performance errors.
"
1579,"CNN Based Adversarial Embedding with Minimum Alteration for Image
  Steganography","  Historically, steganographic schemes were designed in a way to preserve image
statistics or steganalytic features. Since most of the state-of-the-art
steganalytic methods employ a machine learning (ML) based classifier, it is
reasonable to consider countering steganalysis by trying to fool the ML
classifiers. However, simply applying perturbations on stego images as
adversarial examples may lead to the failure of data extraction and introduce
unexpected artefacts detectable by other classifiers. In this paper, we present
a steganographic scheme with a novel operation called adversarial embedding,
which achieves the goal of hiding a stego message while at the same time
fooling a convolutional neural network (CNN) based steganalyzer. The proposed
method works under the conventional framework of distortion minimization.
Adversarial embedding is achieved by adjusting the costs of image element
modifications according to the gradients backpropagated from the CNN classifier
targeted by the attack. Therefore, modification direction has a higher
probability to be the same as the sign of the gradient. In this way, the so
called adversarial stego images are generated. Experiments demonstrate that the
proposed steganographic scheme is secure against the targeted adversary-unaware
steganalyzer. In addition, it deteriorates the performance of other
adversary-aware steganalyzers opening the way to a new class of modern
steganographic schemes capable to overcome powerful CNN-based steganalysis.
"
1580,Digital Cardan Grille: A Modern Approach for Information Hiding,"  In this paper, a new framework for construction of Cardan grille for
information hiding is proposed. Based on the semantic image inpainting
technique, the stego image are driven by secret messages directly. A mask
called Digital Cardan Grille (DCG) for determining the hidden location is
introduced to hide the message. The message is written to the corrupted region
that needs to be filled in the corrupted image in advance. Then the corrupted
image with secret message is feeded into a Generative Adversarial Network (GAN)
for semantic completion. The adversarial game not only reconstruct the
corrupted image , but also generate a stego image which contains the logic
rationality of image content. The experimental results verify the feasibility
of the proposed method.
"
1581,"Distinguishing Computer-generated Graphics from Natural Images Based on
  Sensor Pattern Noise and Deep Learning","  Computer-generated graphics (CGs) are images generated by computer software.
The~rapid development of computer graphics technologies has made it easier to
generate photorealistic computer graphics, and these graphics are quite
difficult to distinguish from natural images (NIs) with the naked eye. In this
paper, we propose a method based on sensor pattern noise (SPN) and deep
learning to distinguish CGs from NIs. Before being fed into our convolutional
neural network (CNN)-based model, these images---CGs and NIs---are clipped into
image patches. Furthermore, three high-pass filters (HPFs) are used to remove
low-frequency signals, which represent the image content. These filters are
also used to reveal the residual signal as well as SPN introduced by the
digital camera device. Different from the traditional methods of distinguishing
CGs from NIs, the proposed method utilizes a five-layer CNN to classify the
input image patches. Based on the classification results of the image patches,
we deploy a majority vote scheme to obtain the classification results for the
full-size images. The~experiments have demonstrated that (1) the proposed
method with three HPFs can achieve better results than that with only one HPF
or no HPF and that (2) the proposed method with three HPFs achieves 100\%
accuracy, although the NIs undergo a JPEG compression with a quality factor of
75.
"
1582,Weakening the Detecting Capability of CNN-based Steganalysis,"  Recently, the application of deep learning in steganalysis has drawn many
researchers' attention. Most of the proposed steganalytic deep learning models
are derived from neural networks applied in computer vision. These kinds of
neural networks have distinguished performance. However, all these kinds of
back-propagation based neural networks may be cheated by forging input named
the adversarial example. In this paper we propose a method to generate
steganographic adversarial example in order to enhance the steganographic
security of existing algorithms. These adversarial examples can increase the
detection error of steganalytic CNN. The experiments prove the effectiveness of
the proposed method.
"
1583,Security Consideration For Deep Learning-Based Image Forensics,"  Recently, image forensics community has paied attention to the research on
the design of effective algorithms based on deep learning technology and facts
proved that combining the domain knowledge of image forensics and deep learning
would achieve more robust and better performance than the traditional schemes.
Instead of improving it, in this paper, the safety of deep learning based
methods in the field of image forensics is taken into account. To the best of
our knowledge, this is a first work focusing on this topic. Specifically, we
experimentally find that the method using deep learning would fail when adding
the slight noise into the images (adversarial images). Furthermore, two kinds
of strategys are proposed to enforce security of deep learning-based method.
Firstly, an extra penalty term to the loss function is added, which is referred
to the 2-norm of the gradient of the loss with respect to the input images, and
then an novel training method are adopt to train the model by fusing the normal
and adversarial images. Experimental results show that the proposed algorithm
can achieve good performance even in the case of adversarial images and provide
a safety consideration for deep learning-based image forensics
"
1584,"High Capacity Image Data Hiding of Scanned Text Documents Using Improved
  Quadtree","  In this paper, an effective method was introduced to steganography of text
document in the host image. In the available steganography methods, the message
has a random form. Therefore, the embedding capacity is generally low. In the
proposed method, the main underlying idea was the sparse property of scanned
documents. The scanned documents were converted from gray-level form to binary
values by halftoning idea and then the information-included parts were
extracted using the improved quadtree and separated from document context.
Next, in order to compress the extracted parts, an algorithm was proposed based
on reading the binary string bits, ignoring the zero behind the number, and
converting them to decimal values. Embedding capacity of the proposed method is
higher than that of other available methods with a random-based message.
Therefore, the proposed method can be used in the secure and intangible
transfer of text documents in the host image.
"
1585,"Cache-Enabled Dynamic Rate Allocation via Deep Self-Transfer
  Reinforcement Learning","  Caching and rate allocation are two promising approaches to support video
streaming over wireless network. However, existing rate allocation designs do
not fully exploit the advantages of the two approaches. This paper investigates
the problem of cache-enabled QoE-driven video rate allocation problem. We
establish a mathematical model for this problem, and point out that it is
difficult to solve the problem with traditional dynamic programming. Then we
propose a deep reinforcement learning approaches to solve it. First, we model
the problem as a Markov decision problem. Then we present a deep Q-learning
algorithm with a special knowledge transfer process to find out effective
allocation policy. Finally, numerical results are given to demonstrate that the
proposed solution can effectively maintain high-quality user experience of
mobile user moving among small cells. We also investigate the impact of
configuration of critical parameters on the performance of our algorithm.
"
1586,"Can Multisensory Cues in VR Help Train Pattern Recognition to Citizen
  Scientists?","  As the internet of things (IoT) has integrated physical and digital
technologies, designing for multiple sensory media (mulsemedia) has become more
attainable. Designing technology for multiple senses has the capacity to
improve virtual realism, extend our ability to process information, and more
easily transfer knowledge between physical and digital environments. HCI
researchers are beginning to explore the viability of integrating multimedia
into virtual experiences, however research has yet to consider whether
mulsemedia truly enhances realism, immersion and knowledge transfer. My work
developing StreamBED, a VR training platform to train citizen science water
monitors plans to consider the role of mulsemedia in immersion and learning
goals. Future findings about the role of mulsemedia in learning contexts will
potentially allow learners to experience, connect to, learn from spaces that
are impossible to experience firsthand.
"
1587,Image Compression Using Proposed Enhanced Run Length Encoding Algorithm,"  In this paper, we will present p roposed enhance process of image compression
by using RLE algorithm. This proposed yield to decrease the size of compressing
image, but the original method used primarily for compressing a binary images
[1].Which will yield increasing the size of an original image mostly when used
for color images. The test of an enhanced algorithm is performed on sample
consists of ten BMP 24-bit true color images, building an application by using
visual basic 6.0 to show the size after and before compression process and
computing the compression ratio for RLE and for the enhanced RLE algorithm.
"
1588,"Intra-Frame Error Concealment Scheme using 3D Reversible Data Hiding in
  Mobile Cloud Environment","  Data in mobile cloud environment are mainly transmitted via wireless noisy
channels, which may result in transmission errors with a high probability due
to its unreliable connectivity. For video transmission, unreliable connectivity
may cause significant degradation of the content. Improving or keeping video
quality over lossy channel is therefore a very important research topic. Error
concealment with data hiding (ECDH) is an effective way to conceal the errors
introduced by channels. It can reduce error propagation between neighbor
blocks/frames comparing with the methods exploiting temporal/spatial
correlations. The existing video ECDH methods often embed the motion vectors
(MVs) into the specific locations. Nevertheless, specific embedding locations
cannot resist against random errors. To compensate the unreliable connectivity
in mobile cloud environment, in this paper, we present a video ECDH scheme
using 3D reversible data hiding (RDH), in which each MV is repeated multiple
times, and the repeated MVs are embedded into different macroblocks (MBs)
randomly. Though the multiple embedding requires more embedding space,
satisfactory trade-off between the introduced distortion and the reconstructed
video quality can be achieved by tuning the repeating times of the MVs. For
random embedding, the lost probability of the MVs decreases rapidly, resulting
in better error concealment performance. Experimental results show that the
PSNR values gain about 5dB at least comparing with the existing ECDH methods.
Meanwhile, the proposed method improves the video quality significantly.
"
1589,"Cache-Aided Interactive Multiview Video Streaming in Small Cell Wireless
  Networks","  The emergence of novel interactive multimedia applications with high rate and
low latency requirements has led to a drastic increase in the video data
traffic over wireless cellular networks. Endowing the small base stations of a
macro-cell with caches that can store some of the content is a promising
technology to cope with the increasing pressure on the backhaul connections,
and to reduce the delay for demanding video applications. In this work,
delivery of an interactive multiview video to a set of wireless users is
studied in an heterogeneous cellular network. Differently from existing works
that focus on the optimization of the delivery delay and ignore the video
characteristics, the caching and scheduling policies are jointly optimized,
taking into account the quality of the delivered video and the video delivery
time constraints. We formulate our joint caching and scheduling problem as the
average expected video distortion minimization, and show that this problem is
NP-hard. We then provide an equivalent formulation based on submodular set
function maximization and propose a greedy solution with
$\frac{1}{2}(1-\mbox{e}^{-1})$ approximation guarantee. The evaluation of the
proposed joint caching and scheduling policy shows that it significantly
outperforms benchmark algorithms based on popularity caching and independent
scheduling. Another important contribution of this paper is a new constant
approximation ratio for the greedy submodular set function maximization subject
to a $d$-dimensional knapsack constraint.
"
1590,"Controllable Identifier Measurements for Private Authentication with
  Secret Keys","  The problem of secret-key based authentication under a privacy constraint on
the source sequence is considered. The identifier measurements during
authentication are assumed to be controllable via a cost-constrained ""action""
sequence. Single-letter characterizations of the optimal trade-off among the
secret-key rate, storage rate, privacy-leakage rate, and action cost are given
for the four problems where noisy or noiseless measurements of the source are
enrolled to generate or embed secret keys. The results are relevant for several
user-authentication scenarios including physical and biometric authentications
with multiple measurements. Our results include, as special cases, new results
for secret-key generation and embedding with action-dependent side information
without any privacy constraint on the enrolled source sequence.
"
1591,Learning to Separate Object Sounds by Watching Unlabeled Video,"  Perceiving a scene most fully requires all the senses. Yet modeling how
objects look and sound is challenging: most natural scenes and events contain
multiple objects, and the audio track mixes all the sound sources together. We
propose to learn audio-visual object models from unlabeled video, then exploit
the visual context to perform audio source separation in novel videos. Our
approach relies on a deep multi-instance multi-label learning framework to
disentangle the audio frequency bases that map to individual visual objects,
even without observing/hearing those objects in isolation. We show how the
recovered disentangled bases can be used to guide audio source separation to
obtain better-separated, object-level sounds. Our work is the first to learn
audio source separation from large-scale ""in the wild"" videos containing
multiple audio sources per video. We obtain state-of-the-art results on
visually-aided audio source separation and audio denoising. Our video results:
http://vision.cs.utexas.edu/projects/separating_object_sounds/
"
1592,The diveXplore System at the Video Browser Showdown 2018 - Final Notes,"  This short paper provides further details of the diveXplore system (formerly
known as CoViSS), which has been used by team ITEC1 for the Video Browser
Showdown (VBS) 2018. In particular, it gives a short overview of search
features and some details of final system changes, not included in the
corresponding VBS2018 paper, as well as a basic analysis of how the system has
been used for VBS2018 (from a user perspective).
"
1593,"Semi-fragile Tamper Detection and Recovery based on Region
  Categorization and Two-Sided Circular Block Dependency","  This paper presents a new semi-fragile algorithm for image tamper detection
and recovery, which is based on region attention and two-sided circular block
dependency. This method categorizes the image blocks into three categories
according to their texture. In this method, less information is extracted from
areas with the smooth texture, and more information is extracted from areas
with the rough texture. Also, the extracted information for each type of blocks
is embedded in another block with the same type. So, changes in the smooth
areas are invisible to Human Visual System. To increase the localization power
a two-sided circular block dependency is proposed, which is able to distinguish
partially destroyed blocks. Pairwise block dependency and circular block
dependency, which are common methods in the block-based tamper detection, are
not able to distinguish the partially destroyed blocks. Cubic interpolation is
used in order to decrease the blocking effects in the recovery phase. The
results of the proposed method for regions with different texture show that the
proposed method is superior to non-region-attention based methods.
"
1594,"Adaptive Spatial Steganography Based on Probability-Controlled
  Adversarial Examples","  Explanation from Sai Ma: The experiments in this paper are conducted on Caffe
framework. In Caffe, there is an API to directly set the gradient in Matlab. I
wrongly use it to control the 'probability', in fact, I modify the gradient
directly. The misusage of API leads to wrong experiment results, and wrong
theoretical analysis.
  Apologize to readers who have read this paper. We have submitted a correct
version of this paper to Multimedia Tools and Applications and it is under
revision.
  Thanks to Dr. Patrick Bas, who is the Associate Editor of TIFS and the
anonymous reviewers of this paper.
  Thanks to Tingting Song from Sun Yat-sen University. We discussed some
problems of this paper. Her advice helps me to improve the submitted paper to
Multimedia Tools and Applications.
"
1595,Occluded Person Re-identification,"  Person re-identification (re-id) suffers from a serious occlusion problem
when applied to crowded public places. In this paper, we propose to retrieve a
full-body person image by using a person image with occlusions. This differs
significantly from the conventional person re-id problem where it is assumed
that person images are detected without any occlusion. We thus call this new
problem the occluded person re-identitification. To address this new problem,
we propose a novel Attention Framework of Person Body (AFPB) based on deep
learning, consisting of 1) an Occlusion Simulator (OS) which automatically
generates artificial occlusions for full-body person images, and 2) multi-task
losses that force the neural network not only to discriminate a person's
identity but also to determine whether a sample is from the occluded data
distribution or the full-body data distribution. Experiments on a new occluded
person re-id dataset and three existing benchmarks modified to include
full-body person images and occluded person images show the superiority of the
proposed method.
"
1596,DeepQoE: A unified Framework for Learning to Predict Video QoE,"  Motivated by the prowess of deep learning (DL) based techniques in
prediction, generalization, and representation learning, we develop a novel
framework called DeepQoE to predict video quality of experience (QoE). The
end-to-end framework first uses a combination of DL techniques (e.g., word
embeddings) to extract generalized features. Next, these features are combined
and fed into a neural network for representation learning. Such representations
serve as inputs for classification or regression tasks. Evaluating the
performance of DeepQoE with two datasets, we show that for the small dataset,
the accuracy of all shallow learning algorithm is improved by using the
representation derived from DeepQoE. For the large dataset, our DeepQoE
framework achieves significant performance improvement in comparison to the
best baseline method (90.94% vs. 82.84%). Moreover, DeepQoE, also released as
an open source tool, provides video QoE research much-needed flexibility in
fitting different datasets, extracting generalized features, and learning
representations.
"
1597,"The Effect of Pets on Happiness: A Large-scale Multi-Factor Analysis
  using Social Multimedia","  From reducing stress and loneliness, to boosting productivity and overall
well-being, pets are believed to play a significant role in people's daily
lives. Many traditional studies have identified that frequent interactions with
pets could make individuals become healthier and more optimistic, and
ultimately enjoy a happier life. However, most of those studies are not only
restricted in scale, but also may carry biases by using subjective
self-reports, interviews, and questionnaires as the major approaches. In this
paper, we leverage large-scale data collected from social media and the
state-of-the-art deep learning technologies to study this phenomenon in depth
and breadth. Our study includes four major steps: 1) collecting timeline posts
from around 20,000 Instagram users, 2) using face detection and recognition on
2-million photos to infer users' demographics, relationship status, and whether
having children, 3) analyzing a user's degree of happiness based on images and
captions via smiling classification and textual sentiment analysis, 3) applying
transfer learning techniques to retrain the final layer of the Inception v3
model for pet classification, and 4) analyzing the effects of pets on happiness
in terms of multiple factors of user demographics. Our main results have
demonstrated the efficacy of our proposed method with many new insights. We
believe this method is also applicable to other domains as a scalable,
efficient, and effective methodology for modeling and analyzing social
behaviors and psychological well-being. In addition, to facilitate the research
involving human faces, we also release our dataset of 700K analyzed faces.
"
1598,"Demoir\'eing of Camera-Captured Screen Images Using Deep Convolutional
  Neural Network","  Taking photos of optoelectronic displays is a direct and spontaneous way of
transferring data and keeping records, which is widely practiced. However, due
to the analog signal interference between the pixel grids of the display screen
and camera sensor array, objectionable moir\'e (alias) patterns appear in
captured screen images. As the moir\'e patterns are structured and highly
variant, they are difficult to be completely removed without affecting the
underneath latent image. In this paper, we propose an approach of deep
convolutional neural network for demoir\'eing screen photos. The proposed DCNN
consists of a coarse-scale network and a fine-scale network. In the
coarse-scale network, the input image is first downsampled and then processed
by stacked residual blocks to remove the moir\'e artifacts. After that, the
fine-scale network upsamples the demoir\'ed low-resolution image back to the
original resolution. Extensive experimental results have demonstrated that the
proposed technique can efficiently remove the moir\'e patterns for camera
acquired screen images; the new technique outperforms the existing ones.
"
1599,Understanding Actors and Evaluating Personae with Gaussian Embeddings,"  Understanding narrative content has become an increasingly popular topic.
Nonetheless, research on identifying common types of narrative characters, or
personae, is impeded by the lack of automatic and broad-coverage evaluation
methods. We argue that computationally modeling actors provides benefits,
including novel evaluation mechanisms for personae. Specifically, we propose
two actor-modeling tasks, cast prediction and versatility ranking, which can
capture complementary aspects of the relation between actors and the characters
they portray. For an actor model, we present a technique for embedding actors,
movies, character roles, genres, and descriptive keywords as Gaussian
distributions and translation vectors, where the Gaussian variance corresponds
to actors' versatility. Empirical results indicate that (1) the technique
considerably outperforms TransE (Bordes et al. 2013) and ablation baselines and
(2) automatically identified persona topics (Bamman, O'Connor, and Smith 2013)
yield statistically significant improvements in both tasks, whereas simplistic
persona descriptors including age and gender perform inconsistently, validating
prior research.
"
1600,Cross-Modal Retrieval with Implicit Concept Association,"  Traditional cross-modal retrieval assumes explicit association of concepts
across modalities, where there is no ambiguity in how the concepts are linked
to each other, e.g., when we do the image search with a query ""dogs"", we expect
to see dog images. In this paper, we consider a different setting for
cross-modal retrieval where data from different modalities are implicitly
linked via concepts that must be inferred by high-level reasoning; we call this
setting implicit concept association. To foster future research in this
setting, we present a new dataset containing 47K pairs of animated GIFs and
sentences crawled from the web, in which the GIFs depict physical or emotional
reactions to the scenarios described in the text (called ""reaction GIFs""). We
report on a user study showing that, despite the presence of implicit concept
association, humans are able to identify video-sentence pairs with matching
concepts, suggesting the feasibility of our task. Furthermore, we propose a
novel visual-semantic embedding network based on multiple instance learning.
Unlike traditional approaches, we compute multiple embeddings from each
modality, each representing different concepts, and measure their similarity by
considering all possible combinations of visual-semantic embeddings in the
framework of multiple instance learning. We evaluate our approach on two
video-sentence datasets with explicit and implicit concept association and
report competitive results compared to existing approaches on cross-modal
retrieval.
"
1601,STAIR Actions: A Video Dataset of Everyday Home Actions,"  A new large-scale video dataset for human action recognition, called STAIR
Actions is introduced. STAIR Actions contains 100 categories of action labels
representing fine-grained everyday home actions so that it can be applied to
research in various home tasks such as nursing, caring, and security. In STAIR
Actions, each video has a single action label. Moreover, for each action
category, there are around 1,000 videos that were obtained from YouTube or
produced by crowdsource workers. The duration of each video is mostly five to
six seconds. The total number of videos is 102,462. We explain how we
constructed STAIR Actions and show the characteristics of STAIR Actions
compared to existing datasets for human action recognition. Experiments with
three major models for action recognition show that STAIR Actions can train
large models and achieve good performance. STAIR Actions can be downloaded from
http://actions.stair.center
"
1602,Personalized Classifier for Food Image Recognition,"  Currently, food image recognition tasks are evaluated against fixed datasets.
However, in real-world conditions, there are cases in which the number of
samples in each class continues to increase and samples from novel classes
appear. In particular, dynamic datasets in which each individual user creates
samples and continues the updating process often have content that varies
considerably between different users, and the number of samples per person is
very limited. A single classifier common to all users cannot handle such
dynamic data. Bridging the gap between the laboratory environment and the real
world has not yet been accomplished on a large scale. Personalizing a
classifier incrementally for each user is a promising way to do this. In this
paper, we address the personalization problem, which involves adapting to the
user's domain incrementally using a very limited number of samples. We propose
a simple yet effective personalization framework which is a combination of the
nearest class mean classifier and the 1-nearest neighbor classifier based on
deep features. To conduct realistic experiments, we made use of a new dataset
of daily food images collected by a food-logging application. Experimental
results show that our proposed method significantly outperforms existing
methods.
"
1603,"SpatioTemporal Feature Integration and Model Fusion for Full Reference
  Video Quality Assessment","  Perceptual video quality assessment models are either frame-based or
video-based, i.e., they apply spatiotemporal filtering or motion estimation to
capture temporal video distortions. Despite their good performance on video
quality databases, video-based approaches are time-consuming and harder to
efficiently deploy. To balance between high performance and computational
efficiency, Netflix developed the Video Multi-method Assessment Fusion (VMAF)
framework, which integrates multiple quality-aware features to predict video
quality. Nevertheless, this fusion framework does not fully exploit temporal
video quality measurements which are relevant to temporal video distortions. To
this end, we propose two improvements to the VMAF framework: SpatioTemporal
VMAF and Ensemble VMAF. Both algorithms exploit efficient temporal video
features which are fed into a single or multiple regression models. To train
our models, we designed a large subjective database and evaluated the proposed
models against state-of-the-art approaches. The compared algorithms will be
made available as part of the open source package in
https://github.com/Netflix/vmaf.
"
1604,"The PS-Battles Dataset - an Image Collection for Image Manipulation
  Detection","  The boost of available digital media has led to a significant increase in
derivative work. With tools for manipulating objects becoming more and more
mature, it can be very difficult to determine whether one piece of media was
derived from another one or tampered with. As derivations can be done with
malicious intent, there is an urgent need for reliable and easily usable
tampering detection methods. However, even media considered semantically
untampered by humans might have already undergone compression steps or light
post-processing, making automated detection of tampering susceptible to false
positives. In this paper, we present the PS-Battles dataset which is gathered
from a large community of image manipulation enthusiasts and provides a basis
for media derivation and manipulation detection in the visual domain. The
dataset consists of 102'028 images grouped into 11'142 subsets, each containing
the original image as well as a varying number of manipulated derivatives.
"
1605,A survey of comics research in computer science,"  Graphical novels such as comics and mangas are well known all over the world.
The digital transition started to change the way people are reading comics,
more and more on smartphones and tablets and less and less on paper. In the
recent years, a wide variety of research about comics has been proposed and
might change the way comics are created, distributed and read in future years.
Early work focuses on low level document image analysis: indeed comic books are
complex, they contains text, drawings, balloon, panels, onomatopoeia, etc.
Different fields of computer science covered research about user interaction
and content generation such as multimedia, artificial intelligence,
human-computer interaction, etc. with different sets of values. We propose in
this paper to review the previous research about comics in computer science, to
state what have been done and to give some insights about the main outlooks.
"
1606,"Multimodal Co-Training for Selecting Good Examples from Webly Labeled
  Video","  We tackle the problem of learning concept classifiers from videos on the web
without using manually labeled data. Although metadata attached to videos
(e.g., video titles, descriptions) can be of help collecting training data for
the target concept, the collected data is often very noisy. The main challenge
is therefore how to select good examples from noisy training data. Previous
approaches firstly learn easy examples that are unlikely to be noise and then
gradually learn more complex examples. However, hard examples that are much
different from easy ones are never learned. In this paper, we propose an
approach called multimodal co-training (MMCo) for selecting good examples from
noisy training data. MMCo jointly learns classifiers for multiple modalities
that complement each other to select good examples. Since MMCo selects examples
by consensus of multimodal classifiers, a hard example for one modality can
still be used as a training example by exploiting the power of the other
modalities. The algorithm is very simple and easily implemented but yields
consistent and significant boosts in example selection and classification
performance on the FCVID and YouTube8M benchmarks.
"
1607,PHD-GIFs: Personalized Highlight Detection for Automatic GIF Creation,"  Highlight detection models are typically trained to identify cues that make
visual content appealing or interesting for the general public, with the
objective of reducing a video to such moments. However, the ""interestingness""
of a video segment or image is subjective. Thus, such highlight models provide
results of limited relevance for the individual user. On the other hand,
training one model per user is inefficient and requires large amounts of
personal information which is typically not available. To overcome these
limitations, we present a global ranking model which conditions on each
particular user's interests. Rather than training one model per user, our model
is personalized via its inputs, which allows it to effectively adapt its
predictions, given only a few user-specific examples. To train this model, we
create a large-scale dataset of users and the GIFs they created, giving us an
accurate indication of their interests. Our experiments show that using the
user history substantially improves the prediction accuracy. On our test set of
850 videos, our model improves the recall by 8% with respect to generic
highlight detectors. Furthermore, our method proves more precise than the
user-agnostic baselines even with just one person-specific example.
"
1608,Reversible Video Data Hiding Using Zero QDCT Coefficient-Pairs,"  H.264/Advanced Video Coding (AVC) is one of the most commonly used video
compression standard currently. In this paper, we propose a Reversible Data
Hiding (RDH) method based on H.264/AVC videos. In the proposed method, the
macroblocks with intra-frame $4\times 4$ prediction modes in intra frames are
first selected as embeddable blocks. Then, the last zero Quantized Discrete
Cosine Transform (QDCT) coefficients in all $4\times 4$ blocks of the
embeddable macroblocks are paired. In the following, a modification mapping
rule based on making full use of modification directions are given. Finally,
each zero coefficient-pair is changed by combining the given mapping rule with
the to-be-embedded information bits. Since most of last QDCT coefficients in
all $4\times 4$ blocks are zero and they are located in high frequency area.
Therefore, the proposed method can obtain high embedding capacity and low
distortion.
"
1609,"An Improved Reversible Data Hiding Scheme by Changing Modification
  Direction of Partial Coefficients in JPEG Images","  This paper first reviews the reversible data hiding scheme, of Liu et al. in
2018, for JPEG images. After that, a novel reversible data hiding scheme, in
which modification directions of partial nonzero quantized alternating current
(AC) coefficients are utilized to decrease distortion and file size increase
caused by data hiding, is proposed. Experimental results have shown that the
proposed scheme has indeed advantages in visual quality and smaller increase in
file size of marked JPEG images while compared to the state-of-the-art scheme
with the same embedding payload so far.
"
1610,"Large Margin Structured Convolution Operator for Thermal Infrared Object
  Tracking","  Compared with visible object tracking, thermal infrared (TIR) object tracking
can track an arbitrary target in total darkness since it cannot be influenced
by illumination variations. However, there are many unwanted attributes that
constrain the potentials of TIR tracking, such as the absence of visual color
patterns and low resolutions. Recently, structured output support vector
machine (SOSVM) and discriminative correlation filter (DCF) have been
successfully applied to visible object tracking, respectively. Motivated by
these, in this paper, we propose a large margin structured convolution operator
(LMSCO) to achieve efficient TIR object tracking. To improve the tracking
performance, we employ the spatial regularization and implicit interpolation to
obtain continuous deep feature maps, including deep appearance features and
deep motion features, of the TIR targets. Finally, a collaborative optimization
strategy is exploited to significantly update the operators. Our approach not
only inherits the advantage of the strong discriminative capability of SOSVM
but also achieves accurate and robust tracking with higher-dimensional features
and more dense samples. To the best of our knowledge, we are the first to
incorporate the advantages of DCF and SOSVM for TIR object tracking.
Comprehensive evaluations on two thermal infrared tracking benchmarks, i.e.
VOT-TIR2015 and VOT-TIR2016, clearly demonstrate that our LMSCO tracker
achieves impressive results and outperforms most state-of-the-art trackers in
terms of accuracy and robustness with sufficient frame rate.
"
1611,Simple Yet Efficient Content Based Video Copy Detection,"  Given a collection of videos, how to detect content-based copies efficiently
with high accuracy? Detecting copies in large video collections still remains
one of the major challenges of multimedia retrieval. While many video copy
detection approaches show high computation times and insufficient quality, we
propose a new efficient content-based video copy detection algorithm improving
both aspects. The idea of our approach consists in utilizing self-similarity
matrices as video descriptors in order to capture different visual properties.
We benchmark our algorithm on the MuscleVCD ST1 benchmark dataset and show that
our approach is able to achieve a score of 100\% and a score of at least 93\%
in a wide range of parameters.
"
1612,Spatial Image Steganography Based on Generative Adversarial Network,"  With the recent development of deep learning on steganalysis, embedding
secret information into digital images faces great challenges. In this paper, a
secure steganography algorithm by using adversarial training is proposed. The
architecture contain three component modules: a generator, an embedding
simulator and a discriminator. A generator based on U-NET to translate a cover
image into an embedding change probability is proposed. To fit the optimal
embedding simulator and propagate the gradient, a function called
Tanh-simulator is proposed. As for the discriminator, the selection-channel
awareness (SCA) is incorporated to resist the SCA based steganalytic methods.
Experimental results have shown that the proposed framework can increase the
security performance dramatically over the recently reported method ASDL-GAN,
while the training time is only 30% of that used by ASDL-GAN. Furthermore, it
also performs better than the hand-crafted steganographic algorithm S-UNIWARD.
"
1613,High Performance Visual Tracking with Circular and Structural Operators,"  In this paper, a novel circular and structural operator tracker (CSOT) is
proposed for high performance visual tracking, it not only possesses the
powerful discriminative capability of SOSVM but also efficiently inherits the
superior computational efficiency of DCF. Based on the proposed circular and
structural operators, a set of primal confidence score maps can be obtained by
circular correlating feature maps with their corresponding structural
correlation filters. Furthermore, an implicit interpolation is applied to
convert the multi-resolution feature maps to the continuous domain and make all
primal confidence score maps have the same spatial resolution. Then, we exploit
an efficient ensemble post-processor based on relative entropy, which can
coalesce primal confidence score maps and create an optimal confidence score
map for more accurate localization. The target is localized on the peak of the
optimal confidence score map. Besides, we introduce a collaborative
optimization strategy to update circular and structural operators by
iteratively training structural correlation filters, which significantly
reduces computational complexity and improves robustness. Experimental results
demonstrate that our approach achieves state-of-the-art performance in mean AUC
scores of 71.5% and 69.4% on the OTB-2013 and OTB-2015 benchmarks respectively,
and obtains a third-best expected average overlap (EAO) score of 29.8% on the
VOT-2017 benchmark.
"
1614,"Progressive refinement: a method of coarse-to-fine image parsing using
  stacked network","  To parse images into fine-grained semantic parts, the complex fine-grained
elements will put it in trouble when using off-the-shelf semantic segmentation
networks. In this paper, for image parsing task, we propose to parse images
from coarse to fine with progressively refined semantic classes. It is achieved
by stacking the segmentation layers in a segmentation network several times.
The former segmentation module parses images at a coarser-grained level, and
the result will be feed to the following one to provide effective contextual
clues for the finer-grained parsing. To recover the details of small
structures, we add skip connections from shallow layers of the network to
fine-grained parsing modules. As for the network training, we merge classes in
groundtruth to get coarse-to-fine label maps, and train the stacked network
with these hierarchical supervision end-to-end. Our coarse-to-fine stacked
framework can be injected into many advanced neural networks to improve the
parsing results. Extensive evaluations on several public datasets including
face parsing and human parsing well demonstrate the superiority of our method.
"
1615,Efficient Pose Tracking from Natural Features in Standard Web Browsers,"  Computer Vision-based natural feature tracking is at the core of modern
Augmented Reality applications. Still, Web-based Augmented Reality typically
relies on location-based sensing (using GPS and orientation sensors) or
marker-based approaches to solve the pose estimation problem.
  We present an implementation and evaluation of an efficient natural feature
tracking pipeline for standard Web browsers using HTML5 and WebAssembly. Our
system can track image targets at real-time frame rates tablet PCs (up to 60
Hz) and smartphones (up to 25 Hz).
"
1616,"Beyond Narrative Description: Generating Poetry from Images by
  Multi-Adversarial Training","  Automatic generation of natural language from images has attracted extensive
attention. In this paper, we take one step further to investigate generation of
poetic language (with multiple lines) to an image for automatic poetry
creation. This task involves multiple challenges, including discovering poetic
clues from the image (e.g., hope from green), and generating poems to satisfy
both relevance to the image and poeticness in language level. To solve the
above challenges, we formulate the task of poem generation into two correlated
sub-tasks by multi-adversarial training via policy gradient, through which the
cross-modal relevance and poetic language style can be ensured. To extract
poetic clues from images, we propose to learn a deep coupled visual-poetic
embedding, in which the poetic representation from objects, sentiments and
scenes in an image can be jointly learned. Two discriminative networks are
further introduced to guide the poem generation, including a multi-modal
discriminator and a poem-style discriminator. To facilitate the research, we
have released two poem datasets by human annotators with two distinct
properties: 1) the first human annotated image-to-poem pair dataset (with 8,292
pairs in total), and 2) to-date the largest public English poem corpus dataset
(with 92,265 different poems in total). Extensive experiments are conducted
with 8K images, among which 1.5K image are randomly picked for evaluation. Both
objective and subjective evaluations show the superior performances against the
state-of-the-art methods for poem generation from images. Turing test carried
out with over 500 human subjects, among which 30 evaluators are poetry experts,
demonstrates the effectiveness of our approach.
"
1617,ECO: Efficient Convolutional Network for Online Video Understanding,"  The state of the art in video understanding suffers from two problems: (1)
The major part of reasoning is performed locally in the video, therefore, it
misses important relationships within actions that span several seconds. (2)
While there are local methods with fast per-frame processing, the processing of
the whole video is not efficient and hampers fast video retrieval or online
classification of long-term activities. In this paper, we introduce a network
architecture that takes long-term content into account and enables fast
per-video processing at the same time. The architecture is based on merging
long-term content already in the network rather than in a post-hoc fusion.
Together with a sampling strategy, which exploits that neighboring frames are
largely redundant, this yields high-quality action classification and video
captioning at up to 230 videos per second, where each video can consist of a
few hundred frames. The approach achieves competitive performance across all
datasets while being 10x to 80x faster than state-of-the-art methods.
"
1618,A Closer Look at Weak Label Learning for Audio Events,"  Audio content analysis in terms of sound events is an important research
problem for a variety of applications. Recently, the development of weak
labeling approaches for audio or sound event detection (AED) and availability
of large scale weakly labeled dataset have finally opened up the possibility of
large scale AED. However, a deeper understanding of how weak labels affect the
learning for sound events is still missing from literature. In this work, we
first describe a CNN based approach for weakly supervised training of audio
events. The approach follows some basic design principle desirable in a
learning method relying on weakly labeled audio. We then describe important
characteristics, which naturally arise in weakly supervised learning of sound
events. We show how these aspects of weak labels affect the generalization of
models. More specifically, we study how characteristics such as label density
and corruption of labels affects weakly supervised training for audio events.
We also study the feasibility of directly obtaining weak labeled data from the
web without any manual label and compare it with a dataset which has been
manually labeled. The analysis and understanding of these factors should be
taken into picture in the development of future weak label learning methods.
Audioset, a large scale weakly labeled dataset for sound events is used in our
experiments.
"
1619,Cross-media Multi-level Alignment with Relation Attention Network,"  With the rapid growth of multimedia data, such as image and text, it is a
highly challenging problem to effectively correlate and retrieve the data of
different media types. Naturally, when correlating an image with textual
description, people focus on not only the alignment between discriminative
image regions and key words, but also the relations lying in the visual and
textual context. Relation understanding is essential for cross-media
correlation learning, which is ignored by prior cross-media retrieval works. To
address the above issue, we propose Cross-media Relation Attention Network
(CRAN) with multi-level alignment. First, we propose visual-language relation
attention model to explore both fine-grained patches and their relations of
different media types. We aim to not only exploit cross-media fine-grained
local information, but also capture the intrinsic relation information, which
can provide complementary hints for correlation learning. Second, we propose
cross-media multi-level alignment to explore global, local and relation
alignments across different media types, which can mutually boost to learn more
precise cross-media correlation. We conduct experiments on 2 cross-media
datasets, and compare with 10 state-of-the-art methods to verify the
effectiveness of proposed approach.
"
1620,"Off the Beaten Track: Using Deep Learning to Interpolate Between Music
  Genres","  We describe a system based on deep learning that generates drum patterns in
the electronic dance music domain. Experimental results reveal that generated
patterns can be employed to produce musically sound and creative transitions
between different genres, and that the process of generation is of interest to
practitioners in the field.
"
1621,"Rate-Utility Optimized Streaming of Volumetric Media for Augmented
  Reality","  Volumetric media, popularly known as holograms, need to be delivered to users
using both on-demand and live streaming, for new augmented reality (AR) and
virtual reality (VR) experiences. As in video streaming, hologram streaming
must support network adaptivity and fast startup, but must also moderate large
bandwidths, multiple simultaneously streaming objects, and frequent user
interaction, which requires low delay. In this paper, we introduce the first
system to our knowledge designed specifically for streaming volumetric media.
The system reduces bandwidth by introducing 3D tiles, and culling them or
reducing their level of detail depending on their relation to the user's view
frustum and distance to the user. Our system reduces latency by introducing a
window-based buffer, which in contrast to a queue-based buffer allows
insertions near the head of the buffer rather than only at the tail of the
buffer, to respond quickly to user interaction. To allocate bits between
different tiles across multiple objects, we introduce a simple greedy yet
provably optimal algorithm for rate-utility optimization. We introduce utility
measures based not only on the underlying quality of the representation, but on
the level of detail relative to the user's viewpoint and device resolution.
Simulation results show that the proposed algorithm provides superior quality
compared to existing video-streaming approaches adapted to hologram streaming,
in terms of utility and user experience over variable, throughput-constrained
networks.
"
1622,Learning for Video Compression,"  One key challenge to learning-based video compression is that motion
predictive coding, a very effective tool for video compression, can hardly be
trained into a neural network. In this paper we propose the concept of
PixelMotionCNN (PMCNN) which includes motion extension and hybrid prediction
networks. PMCNN can model spatiotemporal coherence to effectively perform
predictive coding inside the learning network. On the basis of PMCNN, we
further explore a learning-based framework for video compression with
additional components of iterative analysis/synthesis, binarization, etc.
Experimental results demonstrate the effectiveness of the proposed scheme.
Although entropy coding and complex configurations are not employed in this
paper, we still demonstrate superior performance compared with MPEG-2 and
achieve comparable results with H.264 codec. The proposed learning-based scheme
provides a possible new direction to further improve compression efficiency and
functionalities of future video coding.
"
1623,Generative Steganography by Sampling,"  In this paper, a novel data-driven information hiding scheme called
generative steganography by sampling (GSS) is proposed. Unlike in traditional
modification-based steganography, in our method the stego image is directly
sampled by a powerful generator: no explicit cover is used. Both parties share
a secret key used for message embedding and extraction. The Jensen-Shannon
divergence is introduced as a new criterion for evaluating the security of
generative steganography. Based on these principles, we propose a simple
practical generative steganography method that uses semantic image inpainting.
The message is written in advance to an uncorrupted region that needs to be
retained in the corrupted image. Then, the corrupted image with the secret
message is fed into a Generator trained by a generative adversarial network
(GAN) for semantic completion. Message loss and prior loss terms are proposed
for penalizing message extraction error and unrealistic stego image. In our
design, we first train a generator whose training target is the generation of
new data samples from the same distribution as that of existing training data.
Next, for the trained generator, backpropagation to the message and prior loss
are introduced to optimize the coding of the input noise data for the
generator. The presented experiments demonstrate the potential of the proposed
framework based on both qualitative and quantitative evaluations of the
generated stego images.
"
1624,"Hybrid Point Cloud Attribute Compression Using Slice-based Layered
  Structure and Block-based Intra Prediction","  Point cloud compression is a key enabler for the emerging applications of
immersive visual communication, autonomous driving and smart cities, etc. In
this paper, we propose a hybrid point cloud attribute compression scheme built
on an original layered data structure. First, a slice-partition scheme and
geometry-adaptive k dimensional-tree (kd-tree) method are devised to generate
the four-layer structure. Second, we introduce an efficient block-based intra
prediction scheme containing a DC prediction mode and several angular modes, in
order to exploit the spatial correlation between adjacent points. Third, an
adaptive transform scheme based on Graph Fourier Transform (GFT) is Lagrangian
optimized to achieve better transform efficiency. The Lagrange multiplier is
off-line derived based on the statistics of color attribute coding. Last but
not least, multiple reordering scan modes are dedicated to improve coding
efficiency for entropy coding. In intra-frame compression of point cloud color
attributes, results demonstrate that our method performs better than the
state-of-the-art region-adaptive hierarchical transform (RAHT) system, and on
average a 29.37$\%$ BD-rate gain is achieved. Comparing with the test model for
category 1 (TMC1) anchor's coding results, which were recently published by
MPEG-3DG group on 121st meeting, a 16.37$\%$ BD-rate gain is obtained.
"
1625,"A Bimodal Learning Approach to Assist Multi-sensory Effects
  Synchronization","  In mulsemedia applications, traditional media content (text, image, audio,
video, etc.) can be related to media objects that target other human senses
(e.g., smell, haptics, taste). Such applications aim at bridging the virtual
and real worlds through sensors and actuators. Actuators are responsible for
the execution of sensory effects (e.g., wind, heat, light), which produce
sensory stimulations on the users. In these applications sensory stimulation
must happen in a timely manner regarding the other traditional media content
being presented. For example, at the moment in which an explosion is presented
in the audiovisual content, it may be adequate to activate actuators that
produce heat and light. It is common to use some declarative multimedia
authoring language to relate the timestamp in which each media object is to be
presented to the execution of some sensory effect. One problem in this setting
is that the synchronization of media objects and sensory effects is done
manually by the author(s) of the application, a process which is time-consuming
and error prone. In this paper, we present a bimodal neural network
architecture to assist the synchronization task in mulsemedia applications. Our
approach is based on the idea that audio and video signals can be used
simultaneously to identify the timestamps in which some sensory effect should
be executed. Our learning architecture combines audio and video signals for the
prediction of scene components. For evaluation purposes, we construct a dataset
based on Google's AudioSet. We provide experiments to validate our bimodal
architecture. Our results show that the bimodal approach produces better
results when compared to several variants of unimodal architectures.
"
1626,Dynamic Adaptive Point Cloud Streaming,"  High-quality point clouds have recently gained interest as an emerging form
of representing immersive 3D graphics. Unfortunately, these 3D media are bulky
and severely bandwidth intensive, which makes it difficult for streaming to
resource-limited and mobile devices. This has called researchers to propose
efficient and adaptive approaches for streaming of high-quality point clouds.
  In this paper, we run a pilot study towards dynamic adaptive point cloud
streaming, and extend the concept of dynamic adaptive streaming over HTTP
(DASH) towards DASH-PC, a dynamic adaptive bandwidth-efficient and view-aware
point cloud streaming system. DASH-PC can tackle the huge bandwidth demands of
dense point cloud streaming while at the same time can semantically link to
human visual acuity to maintain high visual quality when needed. In order to
describe the various quality representations, we propose multiple thinning
approaches to spatially sub-sample point clouds in the 3D space, and design a
DASH Media Presentation Description manifest specific for point cloud
streaming. Our initial evaluations show that we can achieve significant
bandwidth and performance improvement on dense point cloud streaming with minor
negative quality impacts compared to the baseline scenario when no adaptations
is applied.
"
1627,Explainable Recommendation: A Survey and New Perspectives,"  Explainable recommendation attempts to develop models that generate not only
high-quality recommendations but also intuitive explanations. The explanations
may either be post-hoc or directly come from an explainable model (also called
interpretable or transparent model in some contexts). Explainable
recommendation tries to address the problem of why: by providing explanations
to users or system designers, it helps humans to understand why certain items
are recommended by the algorithm, where the human can either be users or system
designers. Explainable recommendation helps to improve the transparency,
persuasiveness, effectiveness, trustworthiness, and satisfaction of
recommendation systems. It also facilitates system designers for better system
debugging. In recent years, a large number of explainable recommendation
approaches -- especially model-based methods -- have been proposed and applied
in real-world systems.
  In this survey, we provide a comprehensive review for the explainable
recommendation research. We first highlight the position of explainable
recommendation in recommender system research by categorizing recommendation
problems into the 5W, i.e., what, when, who, where, and why. We then conduct a
comprehensive survey of explainable recommendation on three perspectives: 1) We
provide a chronological research timeline of explainable recommendation. 2) We
provide a two-dimensional taxonomy to classify existing explainable
recommendation research. 3) We summarize how explainable recommendation applies
to different recommendation tasks. We also devote a chapter to discuss the
explanation perspectives in broader IR and AI/ML research. We end the survey by
discussing potential future directions to promote the explainable
recommendation research area and beyond.
"
1628,"A blind robust watermarking method based on Arnold Cat map and amplified
  pseudo-noise strings with weak correlation","  In this paper, a robust and blind watermarking method is proposed, which is
highly resistant to the common image watermarking attacks, such as noises,
compression, and image quality enhancement processing. In this method, Arnold
Cat map is used as a pre-processing on the host image, which increases the
security and imperceptibility of embedding watermark bits with a strong gain
factor. Moreover, two pseudo-noise strings with weak correlation are used as
the symbol of each 0 or 1 bit of the watermark, which increases the accuracy in
detecting the state of watermark bits at extraction phase in comparison to
using two random pseudo-noise strings. In this method, to increase the
robustness and further imperceptibility of the embedding, the Arnold Cat mapped
image is subjected to non-overlapping blocking, and then the high frequency
coefficients of the approximation sub-band of the FDCuT transform are used as
the embedding location for each block. Comparison of the proposed method with
recent robust methods under the same experimental conditions indicates the
superiority of the proposed method.
"
1629,LBP: Robust Rate Adaptation Algorithm for SVC Video Streaming,"  Video streaming today accounts for up to 55\% of mobile traffic. In this
paper, we explore streaming videos encoded using Scalable Video Coding scheme
(SVC) over highly variable bandwidth conditions such as cellular networks.
SVC's unique encoding scheme allows the quality of a video chunk to change
incrementally, making it more flexible and adaptive to challenging network
conditions compared to other encoding schemes. Our contribution is threefold.
First, we formulate the quality decisions of video chunks constrained by the
available bandwidth, the playback buffer, and the chunk deadlines as an
optimization problem. The objective is to optimize a novel QoE metric that
models a combination of the three objectives of minimizing the stall/skip
duration of the video, maximizing the playback quality of every chunk, and
minimizing the number of quality switches. Second, we develop Layered Bin
Packing (LBP) Adaptation Algorithm, a novel algorithm that solves the proposed
optimization problem. Moreover, we show that LBP achieves the optimal solution
of the proposed optimization problem with linear complexity in the number of
video chunks. Third, we propose an online algorithm (online LBP) where several
challenges are addressed including handling bandwidth prediction errors, and
short prediction duration. Extensive simulations with real bandwidth traces of
public datasets reveal the robustness of our scheme and demonstrate its
significant performance improvement as compared to the state-of-the-art SVC
streaming algorithms. The proposed algorithm is also implemented on a TCP/IP
emulation test bed with real LTE bandwidth traces, and the emulation confirms
the simulation results and validates that the algorithm can be implemented and
deployed on today's mobile devices.
"
1630,"Realistic Multimedia Tools based on Physical Models: I. The Spectrum
  Analyzer and Animator (SA2)","  The present sequence of two articles reports on a custom-built toolkit
implementing a technique similar to multi-directional medical tomography to
simulate and visualize the composite 3D structure of winds from hot close
double stars. In such hot binaries, the light sources scanning and probing the
composite wind volume are the bright ""surfaces"" (photospheres) of the
individual stars. Then, as the Keplerian orbit is traced out and the geometry
presented to the observer varies, each star constitutes an analyzer upon its
companion's wind. In contrast to medical tomography, however, these targets are
too far to be resolved spatially so we resort to modeling the ultraviolet (UV)
spectral lines of certain wind ions (e.g., N+4, Si+3, C+3) whose shapes vary
with Keplerian phase as the stars revolve around their common centre of mass.
The flagships of the toolkit are the Spectrum Analyzer and Animator (SA 2 ) and
the Binary 3D Renderer (B3dR). The SA 2 is the subject of the present article
(paper I). It automates (a) the derivation of light curves from the observed
spectra and (b) the generation of synthetic binary wind-line profiles which
reproduce the morphologies and variabilities of the observed wind profiles. The
second tool, the B3dR is discussed in paper II.
"
1631,"Realistic Multimedia Tools based on Physical Models: II. The Binary 3D
  Renderer (B3dR)","  The present article reports on the second tool of a custom-built toolkit
intended to train astronomers into simulating and visualizing the composite 3D
structure of winds from hot close double stars by implementing a technique
which is similar to multi-directional medical tomography. The flagships of the
toolkit are the Spectrum Analyzer and Animator (SA 2 ) and the Binary 3D
Renderer (B3dR). Following application of the first tool, SA 2 as detailed in
paper I, the composite wind structure of the binary has been recovered and the
B3dR is subsequently employed to visualize the results and simulate the
revolution of the entire system (stars, winds and wind-interaction effects)
around the common centre of mass. The B3dR thus repackages the end product of a
lengthy physical modeling process to generate realistic multimedia content and
enable the presentation of the 3D system from the point of view of an observer
on Earth as well as from any other observer location in the Galaxy.
"
1632,Neural Compatibility Modeling with Attentive Knowledge Distillation,"  Recently, the booming fashion sector and its huge potential benefits have
attracted tremendous attention from many research communities. In particular,
increasing research efforts have been dedicated to the complementary clothing
matching as matching clothes to make a suitable outfit has become a daily
headache for many people, especially those who do not have the sense of
aesthetics. Thanks to the remarkable success of neural networks in various
applications such as image classification and speech recognition, the
researchers are enabled to adopt the data-driven learning methods to analyze
fashion items. Nevertheless, existing studies overlook the rich valuable
knowledge (rules) accumulated in fashion domain, especially the rules regarding
clothing matching. Towards this end, in this work, we shed light on
complementary clothing matching by integrating the advanced deep neural
networks and the rich fashion domain knowledge. Considering that the rules can
be fuzzy and different rules may have different confidence levels to different
samples, we present a neural compatibility modeling scheme with attentive
knowledge distillation based on the teacher-student network scheme. Extensive
experiments on the real-world dataset show the superiority of our model over
several state-of-the-art baselines. Based upon the comparisons, we observe
certain fashion insights that add value to the fashion matching study. As a
byproduct, we released the codes, and involved parameters to benefit other
researchers.
"
1633,"Analysis of Problem Tokens to Rank Factors Impacting Quality in VoIP
  Applications","  User-perceived quality-of-experience (QoE) in internet telephony systems is
commonly evaluated using subjective ratings computed as a Mean Opinion Score
(MOS). In such systems, while user MOS can be tracked on an ongoing basis, it
does not give insight into which factors of a call induced any perceived
degradation in QoE -- it does not tell us what caused a user to have a
sub-optimal experience. For effective planning of product improvements, we are
interested in understanding the impact of each of these degrading factors,
allowing the estimation of the return (i.e., the improvement in user QoE) for a
given investment. To obtain such insights, we advocate the use of an
end-of-call ""problem token questionnaire"" (PTQ) which probes the user about
common call quality issues (e.g., distorted audio or frozen video) which they
may have experienced. In this paper, we show the efficacy of this questionnaire
using data gathered from over 700,000 end-of-call surveys gathered from Skype
(a large commercial VoIP application). We present a method to rank call quality
and reliability issues and address the challenge of isolating independent
factors impacting the QoE. Finally, we present representative examples of how
these problem tokens have proven to be useful in practice.
"
1634,"Delay-Constrained Rate Control for Real-Time Video Streaming with
  Bounded Neural Network","  Rate control is widely adopted during video streaming to provide both high
video qualities and low latency under various network conditions. However,
despite that many work have been proposed, they fail to tackle one major
problem: previous methods determine a future transmission rate as a single for
value which will be used in an entire time-slot, while real-world network
conditions, unlike lab setup, often suffer from rapid and stochastic changes,
resulting in the failures of predictions.
  In this paper, we propose a delay-constrained rate control approach based on
end-to-end deep learning. The proposed model predicts future bit rate not as a
single value, but as possible bit rate ranges using target delay gradient, with
which the transmission delay is guaranteed. We collect a large scale of
real-world live streaming data to train our model, and as a result, it
automatically learns the correlation between throughput and target delay
gradient. We build a testbed to evaluate our approach. Compared with the
state-of-the-art methods, our approach demonstrates a better performance in
bandwidth utilization. In all considered scenarios, a range based rate control
approach outperforms the one without range by 19% to 35% in average QoE
improvement.
"
1635,Fine-Grained Facial Expression Analysis Using Dimensional Emotion Model,"  Automated facial expression analysis has a variety of applications in
human-computer interaction. Traditional methods mainly analyze prototypical
facial expressions of no more than eight discrete emotions as a classification
task. However, in practice, spontaneous facial expressions in naturalistic
environment can represent not only a wide range of emotions, but also different
intensities within an emotion family. In such situation, these methods are not
reliable or adequate. In this paper, we propose to train deep convolutional
neural networks (CNNs) to analyze facial expressions explainable in a
dimensional emotion model. The proposed method accommodates not only a set of
basic emotion expressions, but also a full range of other emotions and subtle
emotion intensities that we both feel in ourselves and perceive in others in
our daily life. Specifically, we first mapped facial expressions into
dimensional measures so that we transformed facial expression analysis from a
classification problem to a regression one. We then tested our CNN-based
methods for facial expression regression and these methods demonstrated
promising performance. Moreover, we improved our method by a bilinear pooling
which encodes second-order statistics of features. We showed such bilinear-CNN
models significantly outperformed their respective baselines.
"
1636,Weakly-supervised Visual Instrument-playing Action Detection in Videos,"  Instrument playing is among the most common scenes in music-related videos,
which represent nowadays one of the largest sources of online videos. In order
to understand the instrument-playing scenes in the videos, it is important to
know what instruments are played, when they are played, and where the playing
actions occur in the scene. While audio-based recognition of instruments has
been widely studied, the visual aspect of the music instrument playing remains
largely unaddressed in the literature. One of the main obstacles is the
difficulty in collecting annotated data of the action locations for
training-based methods. To address this issue, we propose a weakly-supervised
framework to find when and where the instruments are played in the videos. We
propose to use two auxiliary models, a sound model and an object model, to
provide supervisions for training the instrument-playing action model. The
sound model provides temporal supervisions, while the object model provides
spatial supervisions. They together can simultaneously provide temporal and
spatial supervisions. The resulted model only needs to analyze the visual part
of a music video to deduce which, when and where instruments are played. We
found that the proposed method significantly improves the localization
accuracy. We evaluate the result of the proposed method temporally and
spatially on a small dataset (totally 5,400 frames) that we manually annotated.
"
1637,Multimodal Machine Translation with Reinforcement Learning,"  Multimodal machine translation is one of the applications that integrates
computer vision and language processing. It is a unique task given that in the
field of machine translation, many state-of-the-arts algorithms still only
employ textual information. In this work, we explore the effectiveness of
reinforcement learning in multimodal machine translation. We present a novel
algorithm based on the Advantage Actor-Critic (A2C) algorithm that specifically
cater to the multimodal machine translation task of the EMNLP 2018 Third
Conference on Machine Translation (WMT18). We experiment our proposed algorithm
on the Multi30K multilingual English-German image description dataset and the
Flickr30K image entity dataset. Our model takes two channels of inputs, image
and text, uses translation evaluation metrics as training rewards, and achieves
better results than supervised learning MLE baseline models. Furthermore, we
discuss the prospects and limitations of using reinforcement learning for
machine translation. Our experiment results suggest a promising reinforcement
learning solution to the general task of multimodal sequence to sequence
learning.
"
1638,"Competitive Video Retrieval with vitrivr at the Video Browser Showdown
  2018 - Final Notes","  This paper presents an after-the-fact summary of the participation of the
vitrivr system to the 2018 Video Browser Showdown. A particular focus is on
additions made since the original publication and the systems performance
during the competition.
"
1639,"QARC: Video Quality Aware Rate Control for Real-Time Video Streaming via
  Deep Reinforcement Learning","  Due to the fluctuation of throughput under various network conditions, how to
choose a proper bitrate adaptively for real-time video streaming has become an
upcoming and interesting issue. Recent work focuses on providing high video
bitrates instead of video qualities. Nevertheless, we notice that there exists
a trade-off between sending bitrate and video quality, which motivates us to
focus on how to get a balance between them. In this paper, we propose QARC
(video Quality Awareness Rate Control), a rate control algorithm that aims to
have a higher perceptual video quality with possibly lower sending rate and
transmission latency. Starting from scratch, QARC uses deep reinforcement
learning(DRL) algorithm to train a neural network to select future bitrates
based on previously observed network status and past video frames, and we
design a neural network to predict future perceptual video quality as a vector
for taking the place of the raw picture in the DRL's inputs. We evaluate QARC
over a trace-driven emulation. As excepted, QARC betters existing approaches.
"
1640,Learning Optical Flow via Dilated Networks and Occlusion Reasoning,"  Despite the significant progress that has been made on estimating optical
flow recently, most estimation methods, including classical and deep learning
approaches, still have difficulty with multi-scale estimation, real-time
computation, and/or occlusion reasoning. In this paper, we introduce dilated
convolution and occlusion reasoning into unsupervised optical flow estimation
to address these issues. The dilated convolution allows our network to avoid
upsampling via deconvolution and the resulting gridding artifacts. Dilated
convolution also results in a smaller memory footprint which speeds up
interference. The occlusion reasoning prevents our network from learning
incorrect deformations due to occluded image regions during training. Our
proposed method outperforms state-of-the-art unsupervised approaches on the
KITTI benchmark. We also demonstrate its generalization capability by applying
it to action recognition in video.
"
1641,CloudAR: A Cloud-based Framework for Mobile Augmented Reality,"  Computation capabilities of recent mobile devices enable natural feature
processing for Augmented Reality (AR). However, mobile AR applications are
still faced with scalability and performance challenges. In this paper, we
propose CloudAR, a mobile AR framework utilizing the advantages of cloud and
edge computing through recognition task offloading. We explore the design space
of cloud-based AR exhaustively and optimize the offloading pipeline to minimize
the time and energy consumption. We design an innovative tracking system for
mobile devices which provides lightweight tracking in 6 degree of freedom
(6DoF) and hides the offloading latency from users' perception. We also design
a multi-object image retrieval pipeline that executes fast and accurate image
recognition tasks on servers. In our evaluations, the mobile AR application
built with the CloudAR framework runs at 30 frames per second (FPS) on average
with precise tracking of only 1~2 pixel errors and image recognition of at
least 97% accuracy. Our results also show that CloudAR outperforms one of the
leading commercial AR framework in several performance metrics.
"
1642,Optimization of Occlusion-Inducing Depth Pixels in 3-D Video Coding,"  The optimization of occlusion-inducing depth pixels in depth map coding has
received little attention in the literature, since their associated texture
pixels are occluded in the synthesized view and their effect on the synthesized
view is considered negligible. However, the occlusion-inducing depth pixels
still need to consume the bits to be transmitted, and will induce geometry
distortion that inherently exists in the synthesized view. In this paper, we
propose an efficient depth map coding scheme specifically for the
occlusion-inducing depth pixels by using allowable depth distortions. Firstly,
we formulate a problem of minimizing the overall geometry distortion in the
occlusion subject to the bit rate constraint, for which the depth distortion is
properly adjusted within the set of allowable depth distortions that introduce
the same disparity error as the initial depth distortion. Then, we propose a
dynamic programming solution to find the optimal depth distortion vector for
the occlusion. The proposed algorithm can improve the coding efficiency without
alteration of the occlusion order. Simulation results confirm the performance
improvement compared to other existing algorithms.
"
1643,"Enhancing HEVC Compressed Videos with a Partition-masked Convolutional
  Neural Network","  In this paper, we propose a partition-masked Convolution Neural Network (CNN)
to achieve compressed-video enhancement for the state-of-the-art coding
standard, High Efficiency Video Coding (HECV). More precisely, our method
utilizes the partition information produced by the encoder to guide the quality
enhancement process. In contrast to existing CNN-based approaches, which only
take the decoded frame as the input to the CNN, the proposed approach considers
the coding unit (CU) size information and combines it with the distorted
decoded frame such that the degradation introduced by HEVC is reduced more
efficiently. Experimental results show that our approach leads to over 9.76%
BD-rate saving on benchmark sequences, which achieves the state-of-the-art
performance.
"
1644,Low Rank Tensor Completion for Multiway Visual Data,"  Tensor completion recovers missing entries of multiway data. Teh missing of
entries could often be caused during teh data acquisition and transformation.
In dis paper, we provide an overview of recent development in low rank tensor
completion for estimating teh missing components of visual data, e. g. , color
images and videos. First, we categorize these methods into two groups based on
teh different optimization models. One optimizes factors of tensor
decompositions wif predefined tensor rank. Teh other iteratively updates teh
estimated tensor via minimizing teh tensor rank. Besides, we summarize teh
corresponding algorithms to solve those optimization problems in details.
Numerical experiments are given to demonstrate teh performance comparison when
different methods are applied to color image and video processing.
"
1645,Video Processing on the Edge for Multimedia IoT Systems,"  In this article, we first survey the current situation of video processing on
the edge for multimedia Internet-of-Things (M-IoT) systems in three typical
scenarios, i.e., smart cities, satellite networks, and Internet-of-Vehicles. By
summarizing a general model of the edge video processing, the importance of
developing an edge computing platform is highlighted. Then, we give a method of
implementing cooperative video processing on an edge computing platform based
on light-weighted virtualization technologies. Performance evaluation is
conducted and some insightful observations can be obtained. Moreover, we
summarize challenges and opportunities of realizing effective edge video
processing for M-IoT systems.
"
1646,Visual Comfort Assessment for Stereoscopic Image Retargeting,"  In recent years, visual comfort assessment (VCA) for 3D/stereoscopic content
has aroused extensive attention. However, much less work has been done on the
perceptual evaluation of stereoscopic image retargeting. In this paper, we
first build a Stereoscopic Image Retargeting Database (SIRD), which contains
source images and retargeted images produced by four typical stereoscopic
retargeting methods. Then, the subjective experiment is conducted to assess
four aspects of visual distortion, i.e. visual comfort, image quality, depth
quality and the overall quality. Furthermore, we propose a Visual Comfort
Assessment metric for Stereoscopic Image Retargeting (VCA-SIR). Based on the
characteristics of stereoscopic retargeted images, the proposed model
introduces novel features like disparity range, boundary disparity as well as
disparity intensity distribution into the assessment model. Experimental
results demonstrate that VCA-SIR can achieve high consistency with subjective
perception.
"
1647,Topological Eulerian Synthesis of Slow Motion Periodic Videos,"  We consider the problem of taking a video that is comprised of multiple
periods of repetitive motion, and reordering the frames of the video into a
single period, producing a detailed, single cycle video of motion. This problem
is challenging, as such videos often contain noise, drift due to camera motion
and from cycle to cycle, and irrelevant background motion/occlusions, and these
factors can confound the relevant periodic motion we seek in the video. To
address these issues in a simple and efficient manner, we introduce a tracking
free Eulerian approach for synthesizing a single cycle of motion. Our approach
is geometric: we treat each frame as a point in high-dimensional Euclidean
space, and analyze the sliding window embedding formed by this sequence of
points, which yields samples along a topological loop regardless of the type of
periodic motion. We combine tools from topological data analysis and spectral
geometric analysis to estimate the phase of each window, and we exploit the
sliding window structure to robustly reorder frames. We show quantitative
results that highlight the robustness of our technique to camera shake, noise,
and occlusions, and qualitative results of single-cycle motion synthesis across
a variety of scenarios.
"
1648,A practical convolutional neural network as loop filter for intra frame,"  Loop filters are used in video coding to remove artifacts or improve
performance. Recent advances in deploying convolutional neural network (CNN) to
replace traditional loop filters show large gains but with problems for
practical application. First, different model is used for frames encoded with
different quantization parameter (QP), respectively. It is expensive for
hardware. Second, float points operation in CNN leads to inconsistency between
encoding and decoding across different platforms. Third, redundancy within CNN
model consumes precious computational resources.
  This paper proposes a CNN as the loop filter for intra frames and proposes a
scheme to solve the above problems. It aims to design a single CNN model with
low redundancy to adapt to decoded frames with different qualities and ensure
consistency. To adapt to reconstructions with different qualities, both
reconstruction and QP are taken as inputs. After training, the obtained model
is compressed to reduce redundancy. To ensure consistency, dynamic fixed points
(DFP) are adopted in testing CNN. Parameters in the compressed model are first
quantized to DFP and then used for inference of CNN. Outputs of each layer in
CNN are computed by DFP operations. Experimental results on JEM 7.0 report
3.14%, 5.21%, 6.28% BD-rate savings for luma and two chroma components with all
intra configuration when replacing all traditional filters.
"
1649,"Robust curvelet domain watermarking technique that preserves cleanness
  of high quality images","  Watermarking inserts invisible data into content to protect copyright. The
embedded information provides proof of authorship and facilitates tracking
illegal distribution, etc. Current robust watermarking techniques have been
proposed to preserve inserted copyright information from various attacks, such
as content modification and watermark removal attack. However, since the
watermark is inserted in the form of noise, there is an inevitable effect of
reducing content visual quality. In general, more robust watermarking
techniques tend to have larger effect on the quality, and content creators and
users are often reluctant to insert watermarks. Thus, there is a demand for a
watermark that maintains maximum image quality, even if the watermark
performance is slightly inferior. Therefore, we propose a watermarking
technique that maximizes invisibility while maintaining sufficient robustness
and data capacity enough to be applied for real situations. The proposed method
minimizes watermarking energy by adopting curvelet domain multi-directional
decomposition to maximize invisibility, and maximizes robustness against signal
processing attack by watermarking pattern suitable for curvelet transformation.
The method is also robust against geometric attack by employing watermark
detection method utilizing curvelet characteristics. The proposed method showed
very good results of 57.65 dB peak signal-to-noise ratio in fidelity tests, and
mean opinion score showed that images treated with the proposed method were
hardly distinguishable from the originals. The proposed technique also showed
good robustness against signal processing and geometric attacks compared with
existing techniques.
"
1650,"Convolutional Neural Network Architecture for Recovering Watermark
  Synchronization","  Since real-time contents can be captured and downloaded very easily,
copyright infringement has become a serious problem. In order to reduce the
loss caused by copyright infringement, copyright owners insert a watermark in
the content to protect the copyright using illegal distribution route tracking
and copyright authentication. However, whereas many existing watermarking
techniques are robust to signal distortion such as compression, they are
vulnerable to geometric distortion that causes synchronization errors. In
particular, capturing real-time content in Internet browsers and smartphone
applications is problematic because geometric distortion such as scaling and
translation frequently occurs. In this paper, we propose a convolutional neural
network-based template architecture that compensates for the disadvantages of
existing watermarking techniques that are vulnerable to geometric distortion.
The proposed template consists of a template generation network, a template
extraction network, and a template matching network. The template generation
network generates a template in the form of noise and the template is inserted
into certain pre-defined spatial locations of the image. The extraction network
detects spatial locations where the template is inserted in the image. Finally,
the template matching network estimates the parameters of the geometric
distortion by comparing the shape of spatial locations where the template was
inserted with the locations where the template was detected. It is possible to
recover an image in its original geometrical form using the estimated
parameters, and as a result, watermarks applied using existing watermarking
techniques that are vulnerable to geometric distortion can be decoded normally.
"
1651,Modeling Continuous Video QoE Evolution: A State Space Approach,"  A rapid increase in the video traffic together with an increasing demand for
higher quality videos has put a significant load on content delivery networks
in the recent years. Due to the relatively limited delivery infrastructure, the
video users in HTTP streaming often encounter dynamically varying quality over
time due to rate adaptation, while the delays in video packet arrivals result
in rebuffering events. The user quality-of-experience (QoE) degrades and varies
with time because of these factors. Thus, it is imperative to monitor the QoE
continuously in order to minimize these degradations and deliver an optimized
QoE to the users. Towards this end, we propose a nonlinear state space model
for efficiently and effectively predicting the user QoE on a continuous time
basis. The QoE prediction using the proposed approach relies on a state space
that is defined by a set of carefully chosen time varying QoE determining
features. An evaluation of the proposed approach conducted on two publicly
available continuous QoE databases shows a superior QoE prediction performance
over the state-of-the-art QoE modeling approaches. The evaluation results also
demonstrate the efficacy of the selected features and the model order employed
for predicting the QoE. Finally, we show that the proposed model is completely
state controllable and observable, so that the potential of state space
modeling approaches can be exploited for further improving QoE prediction.
"
1652,"Extraction and Analysis of Dynamic Conversational Networks from TV
  Series","  Identifying and characterizing the dynamics of modern tv series subplots is
an open problem. One way is to study the underlying social network of
interactions between the characters. Standard dynamic network extraction
methods rely on temporal integration, either over the whole considered period,
or as a sequence of several time-slices. However, they turn out to be
inappropriate in the case of tv series, because the scenes shown onscreen
alternatively focus on parallel storylines, and do not necessarily respect a
traditional chronology. In this article, we introduce Narrative Smoothing, a
novel network extraction method taking advantage of the plot properties to
solve some of their limitations. We apply our method to a corpus of 3 popular
series, and compare it to both standard approaches. Narrative smoothing leads
to more relevant observations when it comes to the characterization of the
protagonists and their relationships, confirming its appropriateness to model
the intertwined storylines constituting the plots.
"
1653,Ask No More: Deciding when to guess in referential visual dialogue,"  Our goal is to explore how the abilities brought in by a dialogue manager can
be included in end-to-end visually grounded conversational agents. We make
initial steps towards this general goal by augmenting a task-oriented visual
dialogue model with a decision-making component that decides whether to ask a
follow-up question to identify a target referent in an image, or to stop the
conversation to make a guess. Our analyses show that adding a decision making
component produces dialogues that are less repetitive and that include fewer
unnecessary questions, thus potentially leading to more efficient and less
unnatural interactions.
"
1654,"Semisupervised Learning on Heterogeneous Graphs and its Applications to
  Facebook News Feed","  Graph-based semi-supervised learning is a fundamental machine learning
problem, and has been well studied. Most studies focus on homogeneous networks
(e.g. citation network, friend network). In the present paper, we propose the
Heterogeneous Embedding Label Propagation (HELP) algorithm, a graph-based
semi-supervised deep learning algorithm, for graphs that are characterized by
heterogeneous node types. Empirically, we demonstrate the effectiveness of this
method in domain classification tasks with Facebook user-domain interaction
graph, and compare the performance of the proposed HELP algorithm with the
state of the art algorithms. We show that the HELP algorithm improves the
predictive performance across multiple tasks, together with semantically
meaningful embedding that are discriminative for downstream classification or
regression tasks.
"
1655,Performance Bound Analysis for Crowdsourced Mobile Video Streaming,"  Adaptive bitrate (ABR) streaming enables video users to adapt the playing
bitrate to the real-time network conditions to achieve the desirable quality of
experience (QoE). In this work, we propose a novel crowdsourced streaming
framework for multi-user ABR video streaming over wireless networks. This
framework enables the nearby mobile video users to crowdsource their radio
links and resources for cooperative video streaming. We focus on analyzing the
social welfare performance bound of the proposed crowdsourced streaming system.
Directly solving this bound is challenging due to the asynchronous operations
of users. To this end, we introduce a virtual time-slotted system with the
synchronized operations, and formulate the associated social welfare
optimization problem as a linear programming. We show that the optimal social
welfare performance of the virtual system provides effective upper-bound and
lower-bound for the optimal performance (bound) of the original asynchronous
system, hence characterizes the feasible performance region of the proposed
crowdsourced streaming system. The performance bounds derived in this work can
serve as a benchmark for the future online algorithm design and incentive
mechanism design.
"
1656,"Towards Global Optimization in Display Advertising by Integrating
  Multimedia Metrics with Real-Time Bidding","  Real-time bidding (RTB) has become a new norm in display advertising where a
publisher uses auction models to sell online user's page view to advertisers.
In RTB, the ad with the highest bid price will be displayed to the user. This
ad displaying process is biased towards the publisher. In fact, the benefits of
the advertiser and the user have been rarely discussed. Towards the global
optimization, we argue that all stakeholders' benefits should be considered. To
this end, we propose a novel computation framework where multimedia techniques
and auction theory are integrated. This doctoral research mainly focus on 1)
figuring out the multimedia metrics that affect the effectiveness of online
advertising; 2) integrating the discovered metrics into the RTB framework. We
have presented some preliminary results and discussed the future directions.
"
1657,Semi-supervised classification by reaching consensus among modalities,"  Deep learning has demonstrated abilities to learn complex structures, but
they can be restricted by available data. Recently, Consensus Networks (CNs)
were proposed to alleviate data sparsity by utilizing features from multiple
modalities, but they too have been limited by the size of labeled data. In this
paper, we extend CN to Transductive Consensus Networks (TCNs), suitable for
semi-supervised learning. In TCNs, different modalities of input are compressed
into latent representations, which we encourage to become indistinguishable
during iterative adversarial training. To understand TCNs two mechanisms,
consensus and classification, we put forward its three variants in ablation
studies on these mechanisms. To further investigate TCN models, we treat the
latent representations as probability distributions and measure their
similarities as the negative relative Jensen-Shannon divergences. We show that
a consensus state beneficial for classification desires a stable but imperfect
similarity between the representations. Overall, TCNs outperform or align with
the best benchmark algorithms given 20 to 200 labeled samples on the Bank
Marketing and the DementiaBank datasets.
"
1658,"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual
  Question Answering","  Recently, Visual Question Answering (VQA) has emerged as one of the most
significant tasks in multimodal learning as it requires understanding both
visual and textual modalities. Existing methods mainly rely on extracting image
and question features to learn their joint feature embedding via multimodal
fusion or attention mechanism. Some recent studies utilize external
VQA-independent models to detect candidate entities or attributes in images,
which serve as semantic knowledge complementary to the VQA task. However, these
candidate entities or attributes might be unrelated to the VQA task and have
limited semantic capacities. To better utilize semantic knowledge in images, we
propose a novel framework to learn visual relation facts for VQA. Specifically,
we build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset
via a semantic similarity module, in which each data consists of an image, a
corresponding question, a correct answer and a supporting relation fact. A
well-defined relation detector is then adopted to predict visual
question-related relation facts. We further propose a multi-step attention
model composed of visual attention and semantic attention sequentially to
extract related visual knowledge and semantic knowledge. We conduct
comprehensive experiments on the two benchmark datasets, demonstrating that our
model achieves state-of-the-art performance and verifying the benefit of
considering visual relation facts.
"
1659,Dynamicity and Durability in Scalable Visual Instance Search,"  Visual instance search involves retrieving from a collection of images the
ones that contain an instance of a visual query. Systems designed for visual
instance search face the major challenge of scalability: a collection of a few
million images used for instance search typically creates a few billion
features that must be indexed. Furthermore, as real image collections grow
rapidly, systems must also provide dynamicity, i.e., be able to handle on-line
insertions while concurrently serving retrieval operations. Durability, which
is the ability to recover correctly from software and hardware crashes, is the
natural complement of dynamicity. Durability, however, has rarely been
integrated within scalable and dynamic high-dimensional indexing solutions.
This article addresses the issue of dynamicity and durability for scalable
indexing of very large and rapidly growing collections of local features for
instance retrieval. By extending the NV-tree, a scalable disk-based
high-dimensional index, we show how to implement the ACID properties of
transactions which ensure both dynamicity and durability. We present a detailed
performance evaluation of the transactional NV-tree: (i) We show that the
insertion throughput is excellent despite the overhead for enforcing the ACID
properties; (ii) We also show that this transactional index is truly scalable
using a standard image benchmark embedded in collections of up to 28.5 billion
high-dimensional vectors; the largest single-server evaluations reported in the
literature.
"
1660,Surface Light Field Compression using a Point Cloud Codec,"  Light field (LF) representations aim to provide photo-realistic,
free-viewpoint viewing experiences. However, the most popular LF
representations are images from multiple views. Multi-view image-based
representations generally need to restrict the range or degrees of freedom of
the viewing experience to what can be interpolated in the image domain,
essentially because they lack explicit geometry information. We present a new
surface light field (SLF) representation based on explicit geometry, and a
method for SLF compression. First, we map the multi-view images of a scene onto
a 3D geometric point cloud. The color of each point in the point cloud is a
function of viewing direction known as a view map. We represent each view map
efficiently in a B-Spline wavelet basis. This representation is capable of
modeling diverse surface materials and complex lighting conditions in a highly
scalable and adaptive manner. The coefficients of the B-Spline wavelet
representation are then compressed spatially. To increase the spatial
correlation and thus improve compression efficiency, we introduce a smoothing
term to make the coefficients more similar across the 3D space. We compress the
coefficients spatially using existing point cloud compression (PCC) methods. On
the decoder side, the scene is rendered efficiently from any viewing direction
by reconstructing the view map at each point. In contrast to multi-view
image-based LF approaches, our method supports photo-realistic rendering of
real-world scenes from arbitrary viewpoints, i.e., with an unlimited six
degrees of freedom (6DOF). In terms of rate and distortion, experimental
results show that our method achieves superior performance with lighter decoder
complexity compared with a reference image-plus-geometry compression (IGC)
scheme, indicating its potential in practical virtual and augmented reality
applications.
"
1661,"Hierarchical One Permutation Hashing: Efficient Multimedia Near
  Duplicate Detection","  With advances in multimedia technologies and the proliferation of smart
phone, digital cameras, storage devices, there are a rapidly growing massive
amount of multimedia data collected in many applications such as multimedia
retrieval and management system, in which the data element is composed of text,
image, video and audio. Consequently, the study of multimedia near duplicate
detection has attracted significant concern from research organizations and
commercial communities. Traditional solution minwish hashing (\minwise) faces
two challenges: expensive preprocessing time and lower comparison speed. Thus,
this work first introduce a hashing method called one permutation hashing
(\oph) to shun the costly preprocessing time. Based on \oph, a more efficient
strategy group based one permutation hashing (\goph) is developed to deal with
the high comparison time. Based on the fact that the similarity of most
multimedia data is not very high, this work design an new hashing method namely
hierarchical one permutation hashing (\hoph) to further improve the
performance. Comprehensive experiments on real multimedia datasets clearly show
that with similar accuracy \hoph is five to seven times faster than
"
1662,Deep Segment Hash Learning for Music Generation,"  Music generation research has grown in popularity over the past decade,
thanks to the deep learning revolution that has redefined the landscape of
artificial intelligence. In this paper, we propose a novel approach to music
generation inspired by musical segment concatenation methods and hash learning
algorithms. Given a segment of music, we use a deep recurrent neural network
and ranking-based hash learning to assign a forward hash code to the segment to
retrieve candidate segments for continuation with matching backward hash codes.
The proposed method is thus called Deep Segment Hash Learning (DSHL). To the
best of our knowledge, DSHL is the first end-to-end segment hash learning
method for music generation, and the first to use pair-wise training with
segments of music. We demonstrate that this method is capable of generating
music which is both original and enjoyable, and that DSHL offers a promising
new direction for music generation research.
"
1663,"Synchronous Prediction of Arousal and Valence Using LSTM Network for
  Affective Video Content Analysis","  The affect embedded in video data conveys high-level semantic information
about the content and has direct impact on the understanding and perception of
reviewers, as well as their emotional responses. Affective Video Content
Analysis (AVCA) attempts to generate a direct mapping between video content and
the corresponding affective states such as arousal and valence dimensions. Most
existing studies establish the mapping for each dimension separately using
knowledge-based rules or traditional classifiers such as Support Vector Machine
(SVM). The inherent correlations between affective dimensions have largely been
unexploited, which are anticipated to include important information for
accurate prediction of affective dimensions. To address this issue, this paper
presents an approach to predict arousal and valance dimensions synchronously
using the Long Short Term Memory (LSTM) network. The approach extracts a set of
low-level audio and visual features from video data and projects them
synchronously into pairs of arousal and valence values using the LSTM network
which automatically incorporates the correlations between arousal and valance
dimensions. We evaluate the performance of the proposed approach on a dataset
comprising video clips segmented from real-world resources such as film, drama,
and news, and demonstrate its superior performance over the traditional SVM
based method. The results provide one of the earliest preliminary evidence to
the benefit of considering correlations between affective dimensions towards
accurate AVCA.
"
1664,"A Revision Control System for Image Editing in Collaborative Multimedia
  Design","  Revision control is a vital component in the collaborative development of
artifacts such as software code and multimedia. While revision control has been
widely deployed for text files, very few attempts to control the versioning of
binary files can be found in the literature. This can be inconvenient for
graphics applications that use a significant amount of binary data, such as
images, videos, meshes, and animations. Existing strategies such as storing
whole files for individual revisions or simple binary deltas, respectively
consume significant storage and obscure semantic information. To overcome these
limitations, in this paper we present a revision control system for digital
images that stores revisions in form of graphs. Besides, being integrated with
Git, our revision control system also facilitates artistic creation processes
in common image editing and digital painting workflows. A preliminary user
study demonstrates the usability of the proposed system.
"
1665,Efficient Interactive Search for Geo-tagged Multimedia Data,"  Due to the advances in mobile computing and multimedia techniques, there are
vast amount of multimedia data with geographical information collected in
multifarious applications. In this paper, we propose a novel type of image
search named interactive geo-tagged image search which aims to find out a set
of images based on geographical proximity and similarity of visual content, as
well as the preference of users. Existing approaches for spatial keyword query
and geo-image query cannot address this problem effectively since they do not
consider these three type of information together for query. In order to solve
this challenge efficiently, we propose the definition of interactive top-$k$
geo-tagged image query and then present a framework including candidate search
stage , interaction stage and termination stage. To enhance the searching
efficiency in a large-scale database, we propose the candidate search algorithm
named GI-SUPER Search based on a new notion called superior relationship and
GIR-Tree, a novel index structure. Furthermore, two candidate selection methods
are proposed for learning the preferences of the user during the interaction.
At last, the termination procedure and estimation procedure are introduced in
brief. Experimental evaluation on real multimedia dataset demonstrates that our
solution has a really high performance.
"
1666,"Patch-Based Image Hallucination for Super Resolution with Detail
  Reconstruction from Similar Sample Images","  Image hallucination and super-resolution have been studied for decades, and
many approaches have been proposed to upsample low-resolution images using
information from the images themselves, multiple example images, or large image
databases. However, most of this work has focused exclusively on small
magnification levels because the algorithms simply sharpen the blurry edges in
the upsampled images - no actual new detail is typically reconstructed in the
final result. In this paper, we present a patch-based algorithm for image
hallucination which, for the first time, properly synthesizes novel high
frequency detail. To do this, we pose the synthesis problem as a patch-based
optimization which inserts coherent, high-frequency detail from
contextually-similar images of the same physical scene/subject provided from
either a personal image collection or a large online database. The resulting
image is visually plausible and contains coherent high frequency information.
We demonstrate the robustness of our algorithm by testing it on a large number
of images and show that its performance is considerably superior to all
state-of-the-art approaches, a result that is verified to be statistically
significant through a randomized user study.
"
1667,Sloth Search System at the Video Browser Showdown 2018 - Final Notes,"  This short paper provides further details of the Sloth Search System, which
was developed by the NECTEC team for the Video Browser Showdown (VBS) 2018.
"
1668,Confidence Interval Estimators for MOS Values,"  For the quantification of QoE, subjects often provide individual rating
scores on certain rating scales which are then aggregated into Mean Opinion
Scores (MOS). From the observed sample data, the expected value is to be
estimated. While the sample average only provides a point estimator, confidence
intervals (CI) are an interval estimate which contains the desired expected
value with a given confidence level. In subjective studies, the number of
subjects performing the test is typically small, especially in lab
environments. The used rating scales are bounded and often discrete like the
5-point ACR rating scale. Therefore, we review statistical approaches in the
literature for their applicability in the QoE domain for MOS interval
estimation (instead of having only a point estimator, which is the MOS). We
provide a conservative estimator based on the SOS hypothesis and binomial
distributions and compare its performance (CI width, outlier ratio of CI
violating the rating scale bounds) and coverage probability with well known CI
estimators. We show that the provided CI estimator works very well in practice
for MOS interval estimators, while the commonly used studentized CIs suffer
from a positive outlier ratio, i.e., CIs beyond the bounds of the rating scale.
As an alternative, bootstrapping, i.e., random sampling of the subjective
ratings with replacement, is an efficient CI estimator leading to typically
smaller CIs, but lower coverage than the proposed estimator.
"
1669,"Revisiting Singing Voice Detection: a Quantitative Review and the Future
  Outlook","  Since the vocal component plays a crucial role in popular music, singing
voice detection has been an active research topic in music information
retrieval. Although several proposed algorithms have shown high performances,
we argue that there still is a room to improve to build a more robust singing
voice detection system. In order to identify the area of improvement, we first
perform an error analysis on three recent singing voice detection systems.
Based on the analysis, we design novel methods to test the systems on multiple
sets of internally curated and generated data to further examine the pitfalls,
which are not clearly revealed with the current datasets. From the experiment
results, we also propose several directions towards building a more robust
singing voice detector.
"
1670,"Double JPEG Compression Detection by Exploring the Correlations in DCT
  Domain","  In the field of digital image processing, JPEG image compression technique
has been widely applied. And numerous image processing software suppose this.
It is likely for the images undergoing double JPEG compression to be tampered.
Therefore, double JPEG compression detection schemes can provide an important
clue for image forgery detection. In this paper, we propose an effective
algorithm to detect double JPEG compression with different quality factors.
Firstly, the quantized DCT coefficients with same frequency are extracted to
build the new data matrices. Then, considering the direction effect on the
correlation between the adjacent positions in DCT domain, twelve kinds of
high-pass filter templates with different directions are executed and the
translation probability matrix is calculated for each filtered data.
Furthermore, principal component analysis and support vector machine technique
are applied to reduce the feature dimension and train a classifier,
respectively. Experimental results have demonstrated that the proposed method
is effective and has comparable performance.
"
1671,"FastScan: Robust Low-Complexity Rate Adaptation Algorithm for Video
  Streaming over HTTP","  This paper proposes and evaluates a novel algorithm for streaming video over
HTTP. The problem is formulated as a non-convex optimization problem which is
constrained by the predicted available bandwidth, chunk deadlines, available
video rates, and buffer occupancy. The objective is to optimize a QoE metric
that maintains a tradeoff between maximizing the playback rate of every chunk
and ensuring fairness among different chunks for the minimum re-buffering time.
We propose FastScan, a low complexity algorithm that solves the problem. Online
adaptations for dynamic bandwidth environments are proposed with imperfect
available bandwidth prediction. Results of experiments driven by Variable Bit
Rate (VBR) encoded video, video platform system (dash.js), and cellular
bandwidth traces of a public dataset reveal the robustness of the online
version of FastScan algorithm and demonstrate its significant performance
improvement as compared to the considered state-of-the-art video streaming
algorithms. For example, on an experiment conducted over 100 real cellular
available bandwidth traces of a public dataset that spans different available
bandwidth regimes, our proposed algorithm (FastScan) achieves the minimum
re-buffering (stall) time and the maximum average playback rate in every single
trace as compared to Bola, Festive, BBA, RB, and FastMPC, and Pensieve
algorithms.
"
1672,Convolutional Video Steganography with Temporal Residual Modeling,"  Steganography represents the art of unobtrusively concealing a secrete
message within some cover data. The key scope of this work is about visual
steganography techniques that hide a full-sized color image / video within
another. A majority of existing works are devoted to the image case, where both
secret and cover data are images. We empirically validate that image
steganography model does not naturally extend to the video case (i.e., hiding a
video into another video), mainly because it completely ignores the temporal
redundancy within consecutive video frames. Our work proposes a novel solution
to the problem of video steganography. The technical contributions are
two-fold: first, the residual between two consecutive frames tends to zero at
most pixels. Hiding such highly-sparse data is significantly easier than hiding
the original frames. Motivated by this fact, we propose to explicitly consider
inter-frame residuals rather than blindly applying image steganography model on
every video frame. Specifically, our model contains two branches, one of which
is specially designed for hiding inter-frame difference into a cover video
frame and the other instead hides the original secret frame. A simple
thresholding method determines which branch a secret video frame shall choose.
When revealing the concealed secret video, two decoders are devised, revealing
difference or frame respectively. Second, we develop the model based on deep
convolutional neural networks, which is the first of its kind in the literature
of video steganography. In experiments, comprehensive evaluations are conducted
to compare our model with both classic least significant bit (LSB) method and
pure image steganography models. All results strongly suggest that the proposed
model enjoys advantages over previous methods. We also carefully investigate
key factors in the success of our deep video steganography model.
"
1673,"Hierarchical Information Quadtree: Efficient Spatial Temporal Image
  Search for Multimedia Stream","  Massive amount of multimedia data that contain times- tamps and geographical
information are being generated at an unprecedented scale in many emerging
applications such as photo sharing web site and social networks applications.
Due to their importance, a large body of work has focused on efficiently
computing various spatial image queries. In this paper,we study the spatial
temporal image query which considers three important constraints during the
search including time recency, spatial proximity and visual relevance. A novel
index structure, namely Hierarchical Information Quadtree(\hiq), to efficiently
insert/delete spatial temporal images with high arrive rates. Base on \hiq an
efficient algorithm is developed to support spatial temporal image query. We
show via extensive experimentation with real spatial databases clearly
demonstrate the efficiency of our methods.
"
1674,Steganography Security: Principle and Practice,"  This paper focuses on several theoretical issues and principles in
steganography security, and defines four security levels by analyzing the
corresponding algorithm instances. In the theoretical analysis, we discuss the
differences between steganography security and watermarking security. The two
necessary conditions for the steganography security are obtained. Under the
current technology situation, we then analyze the indistinguishability of the
cover and stego-cover, and consider that the steganography security should rely
on the key secrecy with algorithms open. By specifying the role of key in
steganography, the necessary conditions for a secure steganography algorithm in
theory are formally presented. When analyzing the security instances, we have
classified the steganalysis attacks according to their variable access to the
steganography system, and then defined the four security levels. The higher
level security one has, the higher level attacks one can resist. We have also
presented algorithm instances based on current technical conditions, and
analyzed their data hiding process, security level, and practice requirements.
"
1675,"Grayscale-based Block Scrambling Image Encryption for Social Networking
  Services","  This paper proposes a new block scrambling encryption scheme that enhances
the security of encryption-then-compression (EtC) systems for JPEG images,
which are used, for example, to securely transmit images through an untrusted
channel provider. The proposed method allows the use of a smaller block size
and a larger number of blocks than the conventional ones. Moreover, images
encrypted using proposed scheme include less color information due to the use
of grayscale even when the original image has three color channels. These
features enhance security against various attacks such as jigsaw puzzle solver
and brute-force attacks. The results of an experiment in which encrypted images
were uploaded to and then downloaded from Twitter and Facebook demonstrated the
effectiveness of the proposed scheme for EtC systems.
"
1676,Hierarchy of GANs for learning embodied self-awareness model,"  In recent years several architectures have been proposed to learn embodied
agents complex self-awareness models. In this paper, dynamic incremental
self-awareness (SA) models are proposed that allow experiences done by an agent
to be modeled in a hierarchical fashion, starting from more simple situations
to more structured ones. Each situation is learned from subsets of private
agent perception data as a model capable to predict normal behaviors and detect
abnormalities. Hierarchical SA models have been already proposed using low
dimensional sensorial inputs. In this work, a hierarchical model is introduced
by means of a cross-modal Generative Adversarial Networks (GANs) processing
high dimensional visual data. Different levels of the GANs are detected in a
self-supervised manner using GANs discriminators decision boundaries. Real
experiments on semi-autonomous ground vehicles are presented.
"
1677,iParaphrasing: Extracting Visually Grounded Paraphrases via an Image,"  A paraphrase is a restatement of the meaning of a text in other words.
Paraphrases have been studied to enhance the performance of many natural
language processing tasks. In this paper, we propose a novel task iParaphrasing
to extract visually grounded paraphrases (VGPs), which are different phrasal
expressions describing the same visual concept in an image. These extracted
VGPs have the potential to improve language and image multimodal tasks such as
visual question answering and image captioning. How to model the similarity
between VGPs is the key of iParaphrasing. We apply various existing methods as
well as propose a novel neural network-based method with image attention, and
report the results of the first attempt toward iParaphrasing.
"
1678,Cross-modal Hallucination for Few-shot Fine-grained Recognition,"  State-of-the-art deep learning algorithms generally require large amounts of
data for model training. Lack thereof can severely deteriorate the performance,
particularly in scenarios with fine-grained boundaries between categories. To
this end, we propose a multimodal approach that facilitates bridging the
information gap by means of meaningful joint embeddings. Specifically, we
present a benchmark that is multimodal during training (i.e. images and texts)
and single-modal in testing time (i.e. images), with the associated task to
utilize multimodal data in base classes (with many samples), to learn explicit
visual classifiers for novel classes (with few samples). Next, we propose a
framework built upon the idea of cross-modal data hallucination. In this
regard, we introduce a discriminative text-conditional GAN for sample
generation with a simple self-paced strategy for sample selection. We show the
results of our proposed discriminative hallucinated method for 1-, 2-, and 5-
shot learning on the CUB dataset, where the accuracy is improved by employing
multimodal data.
"
1679,"A Survey of Automatic Facial Micro-expression Analysis: Databases,
  Methods and Challenges","  Over the last few years, automatic facial micro-expression analysis has
garnered increasing attention from experts across different disciplines because
of its potential applications in various fields such as clinical diagnosis,
forensic investigation and security systems. Advances in computer algorithms
and video acquisition technology have rendered machine analysis of facial
micro-expressions possible today, in contrast to decades ago when it was
primarily the domain of psychiatrists where analysis was largely manual.
Indeed, although the study of facial micro-expressions is a well-established
field in psychology, it is still relatively new from the computational
perspective with many interesting problems. In this survey, we present a
comprehensive review of state-of-the-art databases and methods for
micro-expressions spotting and recognition. Individual stages involved in the
automation of these tasks are also described and reviewed at length. In
addition, we also deliberate on the challenges and future directions in this
growing field of automatic facial micro-expression analysis.
"
1680,"StegNet: Mega Image Steganography Capacity with Deep Convolutional
  Network","  Traditional image steganography often leans interests towards safely
embedding hidden information into cover images with payload capacity almost
neglected. This paper combines recent deep convolutional neural network methods
with image-into-image steganography. It successfully hides the same size images
with a decoding rate of 98.2% or bpp (bits per pixel) of 23.57 by changing only
0.76% of the cover image on average. Our method directly learns end-to-end
mappings between the cover image and the embedded image and between the hidden
image and the decoded image. We~further show that our embedded image, while
with mega payload capacity, is still robust to statistical analysis.
"
1681,"Source Printer Classification using Printer Specific Local Texture
  Descriptor","  The knowledge of source printer can help in printed text document
authentication, copyright ownership, and provide important clues about the
author of a fraudulent document along with his/her potential means and motives.
Development of automated systems for classifying printed documents based on
their source printer, using image processing techniques, is gaining a lot of
attention in multimedia forensics. Currently, state-of-the-art systems require
that the font of letters present in test documents of unknown origin must be
available in those used for training the classifier. In this work, we attempt
to take the first step towards overcoming this limitation. Specifically, we
introduce a novel printer specific local texture descriptor. The highlight of
our technique is the use of encoding and regrouping strategy based on small
linear-shaped structures composed of pixels having similar intensity and
gradient. The results of experiments performed on two separate datasets show
that: 1) on a publicly available dataset, the proposed method outperforms
state-of-the-art algorithms for characters printed in the same font, and 2) on
another dataset\footnote{Code and dataset will be made publicly available with
published version of this paper.} having documents printed in four different
fonts, the proposed method correctly classifies all test samples when
sufficient training data is available in same font setup. In addition, it
outperforms state-of-the-art methods for cross font experiments. Moreover, it
reduces the confusion between the printers of same brand and model.
"
1682,"A Group Variational Transformation Neural Network for Fractional
  Interpolation of Video Coding","  Motion compensation is an important technology in video coding to remove the
temporal redundancy between coded video frames. In motion compensation,
fractional interpolation is used to obtain more reference blocks at sub-pixel
level. Existing video coding standards commonly use fixed interpolation filters
for fractional interpolation, which are not efficient enough to handle diverse
video signals well. In this paper, we design a group variational transformation
convolutional neural network (GVTCNN) to improve the fractional interpolation
performance of the luma component in motion compensation. GVTCNN infers samples
at different sub-pixel positions from the input integer-position sample. It
first extracts a shared feature map from the integer-position sample to infer
various sub-pixel position samples. Then a group variational transformation
technique is used to transform a group of copied shared feature maps to samples
at different sub-pixel positions. Experimental results have identified the
interpolation efficiency of our GVTCNN. Compared with the interpolation method
of High Efficiency Video Coding, our method achieves 1.9% bit saving on average
and up to 5.6% bit saving under low-delay P configuration.
"
1683,"Edge Intelligence: On-Demand Deep Learning Model Co-Inference with
  Device-Edge Synergy","  As the backbone technology of machine learning, deep neural networks (DNNs)
have have quickly ascended to the spotlight. Running DNNs on
resource-constrained mobile devices is, however, by no means trivial, since it
incurs high performance and energy overhead. While offloading DNNs to the cloud
for execution suffers unpredictable performance, due to the uncontrolled long
wide-area network latency. To address these challenges, in this paper, we
propose Edgent, a collaborative and on-demand DNN co-inference framework with
device-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that
adaptively partitions DNN computation between device and edge, in order to
leverage hybrid computation resources in proximity for real-time DNN inference.
(2) DNN right-sizing that accelerates DNN inference through early-exit at a
proper intermediate DNN layer to further reduce the computation latency. The
prototype implementation and extensive evaluations based on Raspberry Pi
demonstrate Edgent's effectiveness in enabling on-demand low-latency edge
intelligence.
"
1684,"Towards Commodity, Web-Based Augmented Reality Applications for Research
  and Education in Chemistry and Structural Biology","  This article reports prototype web apps that use commodity, open-source
technologies for augmented and virtual reality to provide immersive,
interactive human-computer interfaces for chemistry, structural biology and
related disciplines. The examples, which run in any standard web browser and
are accessible at
https://lucianoabriata.altervista.org/jsinscience/arjs/armodeling/ together
with demo videos, showcase applications that could go well beyond pedagogy,
i.e. advancing actual utility in research settings: molecular visualization at
atomistic and coarse-grained levels in interactive immersive 3D, coarse-grained
modeling of molecular physics and chemistry, and on-the-fly calculation of
experimental observables and overlay onto experimental data. From this
playground, I depict perspectives on how these emerging technologies might
couple in the future to neural network-based quantum mechanical calculations,
advanced forms of human-computer interaction such as speech-based
communication, and sockets for concurrent collaboration through the internet
-all technologies that are today maturing in web browsers- to deliver the next
generation of tools for truly interactive, immersive molecular modeling that
can streamline human thought and intent with the numerical processing power of
computers.
"
1685,Temporal Activity Path Based Character Correction in Social Networks,"  Vast amount of multimedia data contains massive and multifarious social
information which is used to construct large-scale social networks. In a
complex social network, a character should be ideally denoted by one and only
one vertex. However, it is pervasive that a character is denoted by two or more
vertices with different names, thus it is usually considered as multiple,
different characters. This problem causes incorrectness of results in network
analysis and mining. The factual challenge is that character uniqueness is hard
to correctly confirm due to lots of complicated factors, e.g. name changing and
anonymization, leading to character duplication. Early, limited research has
shown that previous methods depended overly upon supplementary attribute
information from databases. In this paper, we propose a novel method to merge
the character vertices which refer to as the same entity but are denoted with
different names. With this method, we firstly build the relationship network
among characters based on records of social activities participated, which are
extracted from multimedia sources. Then define temporal activity paths (TAPs)
for each character over time. After that, we measure similarity of the TAPs for
any two characters. If the similarity is high enough, the two vertices should
be considered to the same character. Based on TAPs, we can determine whether to
merge the two character vertices. Our experiments shown that this solution can
accurately confirm character uniqueness in large-scale social network.
"
1686,Tracking Emerges by Colorizing Videos,"  We use large amounts of unlabeled video to learn models for visual tracking
without manual human supervision. We leverage the natural temporal coherency of
color to create a model that learns to colorize gray-scale videos by copying
colors from a reference frame. Quantitative and qualitative experiments suggest
that this task causes the model to automatically learn to track visual regions.
Although the model is trained without any ground-truth labels, our method
learns to track well enough to outperform the latest methods based on optical
flow. Moreover, our results suggest that failures to track are correlated with
failures to colorize, indicating that advancing video colorization may further
improve self-supervised visual tracking.
"
1687,"Generalization of LRU Cache Replacement Policy with Applications to
  Video Streaming","  Caching plays a crucial role in networking systems to reduce the load on the
network and is commonly employed by content delivery networks (CDNs) in order
to improve performance. One of the commonly used mechanisms, Least Recently
Used (LRU), works well for identical file sizes. However, for asymmetric file
sizes, the performance deteriorates. This paper proposes an adaptation to the
LRU strategy, called gLRU, where the file is sub-divided into equal-sized
chunks. In this strategy, a chunk of the newly requested file is added in the
cache, and a chunk of the least-recently-used file is removed from the cache.
Even though approximate analysis for the hit rate has been studied for LRU, the
analysis does not extend to gLRU since the metric of interest is no longer the
hit rate as the cache has partial files. This paper provides a novel
approximation analysis for this policy where the cache may have partial file
contents. The approximation approach is validated by simulations. Further, gLRU
outperforms the LRU strategy for a Zipf file popularity distribution and
censored Pareto file size distribution for the file download times. Video
streaming applications can further use the partial cache contents to help the
stall duration significantly, and the numerical results indicate significant
improvements (32\%) in stall duration using the gLRU strategy as compared to
the LRU strategy. Furthermore, the gLRU replacement policy compares favorably
to two other cache replacement policies when simulated on MSR Cambridge Traces
obtained from the SNIA IOTTA repository.
"
1688,Deep learning for dehazing: Comparison and analysis,"  We compare a recent dehazing method based on deep learning, Dehazenet, with
traditional state-of-the-art approaches , on benchmark data with reference.
Dehazenet estimates the depth map from transmission factor on a single color
image, which is used to inverse the Koschmieder model of imaging in the
presence of haze. In this sense, the solution is still attached to the
Koschmieder model. We demonstrate that the transmission is very well estimated
by the network, but also that this method exhibits the same limitation than
others due to the use of the same imaging model.
"
1689,Analysis and prediction of JND-based video quality model,"  The just-noticeable-difference (JND) visual perception property has received
much attention in characterizing human subjective viewing experience of
compressed video. In this work, we quantify the JND-based video quality
assessment model using the satisfied user ratio (SUR) curve, and show that the
SUR model can be greatly simplified since the JND points of multiple subjects
for the same content in the VideoSet can be well modeled by the normal
distribution. Then, we design an SUR prediction method with video quality
degradation features and masking features and use them to predict the first,
second and the third JND points and their corresponding SUR curves. Finally, we
verify the performance of the proposed SUR prediction method with different
configurations on the VideoSet. The experimental results demonstrate that the
proposed SUR prediction method achieves good performance in various resolutions
with the mean absolute error (MAE) of the SUR smaller than 0.05 on average.
"
1690,A JND-based Video Quality Assessment Model and Its Application,"  Based on the Just-Noticeable-Difference (JND) criterion, a subjective video
quality assessment (VQA) dataset, called the VideoSet, was constructed
recently. In this work, we propose a JND-based VQA model using a probabilistic
framework to analyze and clean collected subjective test data. While most
traditional VQA models focus on content variability, our proposed VQA model
takes both subject and content variabilities into account. The model parameters
used to describe subject and content variabilities are jointly optimized by
solving a maximum likelihood estimation (MLE) problem. As an application, the
new subjective VQA model is used to filter out unreliable video quality scores
collected in the VideoSet. Experiments are conducted to demonstrate the
effectiveness of the proposed model.
"
1691,A Study of Material Sonification in Touchscreen Devices,"  Even in the digital age, designers largely rely on physical material samples
to illustrate their products, as existing visual representations fail to
sufficiently reproduce the look and feel of real world materials. Here, we
investigate the use of interactive material sonification as an additional
sensory modality for communicating well-established material qualities like
softness, pleasantness or value. We developed a custom application for
touchscreen devices that receives tactile input and translate it into material
rubbing sound using granular synthesis. We used this system to perform a
psychophysical study, in which the ability of the user to rate subjective
material qualities is evaluated, with the actual material samples serving as
reference stimulus. Our experimental results indicate that the considered audio
cues do not significantly contribute to the perception of material qualities
but are able to increase the level of immersion when interacting with digital
samples.
"
1692,"FastTrack: Minimizing Stalls for CDN-based Over-the-top Video Streaming
  Systems","  Traffic for internet video streaming has been rapidly increasing and is
further expected to increase with the higher definition videos and IoT
applications, such as 360 degree videos and augmented virtual reality
applications. While efficient management of heterogeneous cloud resources to
optimize the quality of experience is important, existing work in this problem
space often left out important factors. In this paper, we present a model for
describing a today's representative system architecture for video streaming
applications, typically composed of a centralized origin server and several CDN
sites. Our model comprehensively considers the following factors: limited
caching spaces at the CDN sites, allocation of CDN for a video request, choice
of different ports from the CDN, and the central storage and bandwidth
allocation. With the model, we focus on minimizing a performance metric, stall
duration tail probability (SDTP), and present a novel, yet efficient, algorithm
to solve the formulated optimization problem. The theoretical bounds with
respect to the SDTP metric are also analyzed and presented. Our extensive
simulation results demonstrate that the proposed algorithms can significantly
improve the SDTP metric, compared to the baseline strategies. Small-scale video
streaming system implementation in a real cloud environment further validates
our results.
"
1693,Delay-Aware Coded Caching for Mobile Users,"  In this work, we study the trade-off between the cache capacity and the user
delay for a cooperative Small Base Station (SBS) coded caching system with
mobile users. First, a delay-aware coded caching policy, which takes into
account the popularity of the files and the maximum re-buffering delay to
minimize the average rebuffering delay of a mobile user under a given cache
capacity constraint is introduced. Subsequently, we address a scenario where
some files are served by the macro-cell base station (MBS) when the cache
capacity of the SBSs is not sufficient to store all the files in the library.
For this scenario, we develop a coded caching policy that minimizes the average
amount of data served by the MBS under an average re-buffering delay
constraint.
"
1694,A Filter of Minhash for Image Similarity Measures,"  Image similarity measures play an important role in nearest neighbor search
and duplicate detection for large-scale image datasets. Recently, Minwise
Hashing (or Minhash) and its related hashing algorithms have achieved great
performances in large-scale image retrieval systems. However, there are a large
number of comparisons for image pairs in these applications, which may spend a
lot of computation time and affect the performance. In order to quickly obtain
the pairwise images that theirs similarities are higher than the specific
threshold T (e.g., 0.5), we propose a dynamic threshold filter of Minwise
Hashing for image similarity measures. It greatly reduces the calculation time
by terminating the unnecessary comparisons in advance. We also find that the
filter can be extended to other hashing algorithms, on when the estimator
satisfies the binomial distribution, such as b-Bit Minwise Hashing, One
Permutation Hashing, etc. In this pager, we use the Bag-of-Visual-Words (BoVW)
model based on the Scale Invariant Feature Transform (SIFT) to represent the
image features. We have proved that the filter is correct and effective through
the experiment on real image datasets.
"
1695,"Deep Learning for Singing Processing: Achievements, Challenges and
  Impact on Singers and Listeners","  This paper summarizes some recent advances on a set of tasks related to the
processing of singing using state-of-the-art deep learning techniques. We
discuss their achievements in terms of accuracy and sound quality, and the
current challenges, such as availability of data and computing resources. We
also discuss the impact that these advances do and will have on listeners and
singers when they are integrated in commercial applications.
"
1696,Deep Multimodal Clustering for Unsupervised Audiovisual Learning,"  The seen birds twitter, the running cars accompany with noise, etc. These
naturally audiovisual correspondences provide the possibilities to explore and
understand the outside world. However, the mixed multiple objects and sounds
make it intractable to perform efficient matching in the unconstrained
environment. To settle this problem, we propose to adequately excavate audio
and visual components and perform elaborate correspondence learning among them.
Concretely, a novel unsupervised audiovisual learning model is proposed, named
as \Deep Multimodal Clustering (DMC), that synchronously performs sets of
clustering with multimodal vectors of convolutional maps in different shared
spaces for capturing multiple audiovisual correspondences. And such integrated
multimodal clustering network can be effectively trained with max-margin loss
in the end-to-end fashion. Amounts of experiments in feature evaluation and
audiovisual tasks are performed. The results demonstrate that DMC can learn
effective unimodal representation, with which the classifier can even
outperform human performance. Further, DMC shows noticeable performance in
sound localization, multisource detection, and audiovisual understanding.
"
1697,EAST Real-Time VOD System Based on MDSplus,"  As with EAST (Experimental Advanced Superconducting Tokamak) experimental
data analyzed by more and more collaborators, the experimental videos which
directly reflect the real status of vacuum attract more and more researchers'
attention. The real time VOD (Video On Demand) system based on MDSplus allows
users reading the video frames in real time as same as the signal data which is
also stored in the MDSplus database. User can display the plasma discharge
videos and analyze videos frame by frame through jScope or our VOD web station.
The system mainly includes the frames storing and frames displaying. The frames
storing application accepts shot information by using socket TCP communication
firstly, then reads video frames through disk mapping, finally stores them into
MDSplus. The displaying process is implemented through B/S (Browser/Server)
framework, it uses PHP and JavaScript to realize VOD function and read frames
information from MDSplus. The system offers a unit way to access and backup
experimental data and video during the EAST experiment, which is of great
benefit to EAST experimenter than the formal VOD system in VOD function and
real time performance.
"
1698,"Competitive Analysis System for Theatrical Movie Releases Based on Movie
  Trailer Deep Video Representation","  Audience discovery is an important activity at major movie studios. Deep
models that use convolutional networks to extract frame-by-frame features of a
movie trailer and represent it in a form that is suitable for prediction are
now possible thanks to the availability of pre-built feature extractors trained
on large image datasets. Using these pre-built feature extractors, we are able
to process hundreds of publicly available movie trailers, extract
frame-by-frame low level features (e.g., a face, an object, etc) and create
video-level representations. We use the video-level representations to train a
hybrid Collaborative Filtering model that combines video features with
historical movie attendance records. The trained model not only makes accurate
attendance and audience prediction for existing movies, but also successfully
profiles new movies six to eight months prior to their release.
"
1699,"A Bayesian Approach to Block Structure Inference in AV1-based Multi-rate
  Video Encoding","  Due to differences in frame structure, existing multi-rate video encoding
algorithms cannot be directly adapted to encoders utilizing special reference
frames such as AV1 without introducing substantial rate-distortion loss. To
tackle this problem, we propose a novel bayesian block structure inference
model inspired by a modification to an HEVC-based algorithm. It estimates the
posterior probabilistic distributions of block partitioning, and adapts early
terminations in the RDO procedure accordingly. Experimental results show that
the proposed method provides flexibility for controlling the tradeoff between
speed and coding efficiency, and can achieve an average time saving of 36.1%
(up to 50.6%) with negligible bitrate cost.
"
1700,"Convex Optimization Based Bit Allocation for Light Field Compression
  under Weighting and Consistency Constraints","  Compared with conventional image and video, light field images introduce the
weight channel, as well as the visual consistency of rendered view, information
that has to be taken into account when compressing the pseudo-temporal-sequence
(PTS) created from light field images. In this paper, we propose a novel frame
level bit allocation framework for PTS coding. A joint model that measures
weighted distortion and visual consistency, combined with an iterative encoding
system, yields the optimal bit allocation for each frame by solving a convex
optimization problem. Experimental results show that the proposed framework is
effective in producing desired distortion distribution based on weights, and
achieves up to 24.7% BD-rate reduction comparing to the default rate control
algorithm.
"
1701,"Fast Block Structure Determination in AV1-based Multiple Resolutions
  Video Encoding","  The widely used adaptive HTTP streaming requires an efficient algorithm to
encode the same video to different resolutions. In this paper, we propose a
fast block structure determination algorithm based on the AV1 codec that
accelerates high resolution encoding, which is the bottle-neck of multiple
resolutions encoding. The block structure similarity across resolutions is
modeled by the fineness of frame detail and scale of object motions, this
enables us to accelerate high resolution encoding based on low resolution
encoding results. The average depth of a block's co-located neighborhood is
used to decide early termination in the RDO process. Encoding results show that
our proposed algorithm reduces encoding time by 30.1%-36.8%, while keeping
BD-rate low at 0.71%-1.04%. Comparing to the state-of-the-art, our method
halves performance loss without sacrificing time savings.
"
1702,Layer-wise Relevance Propagation for Explainable Recommendations,"  In this paper, we tackle the problem of explanations in a deep-learning based
model for recommendations by leveraging the technique of layer-wise relevance
propagation. We use a Deep Convolutional Neural Network to extract relevant
features from the input images before identifying similarity between the images
in feature space. Relationships between the images are identified by the model
and layer-wise relevance propagation is used to infer pixel-level details of
the images that may have significantly informed the model's choice. We evaluate
our method on an Amazon products dataset and demonstrate the efficacy of our
approach.
"
1703,"Photo-unrealistic Image Enhancement for Subject Placement in Outdoor
  Photography","  Camera display reflections are an issue in bright light situations, as they
may prevent users from correctly positioning the subject in the picture. We
propose a software solution to this problem, which consists in modifying the
image in the viewer, in real time. In our solution, the user is seeing a
posterized image which roughly represents the contour of the objects. Five
enhancement methods are compared in a user study. Our results indicate that the
problem considered is a valid one, as users had problems locating landmarks
nearly 37% of the time under sunny conditions, and that our proposed
enhancement method using contrasting colors is a practical solution to that
problem.
"
1704,Deep Content-User Embedding Model for Music Recommendation,"  Recently deep learning based recommendation systems have been actively
explored to solve the cold-start problem using a hybrid approach. However, the
majority of previous studies proposed a hybrid model where collaborative
filtering and content-based filtering modules are independently trained. The
end-to-end approach that takes different modality data as input and jointly
trains the model can provide better optimization but it has not been fully
explored yet. In this work, we propose deep content-user embedding model, a
simple and intuitive architecture that combines the user-item interaction and
music audio content. We evaluate the model on music recommendation and music
auto-tagging tasks. The results show that the proposed model significantly
outperforms the previous work. We also discuss various directions to improve
the proposed model further.
"
1705,"Streaming Video QoE Modeling and Prediction: A Long Short-Term Memory
  Approach","  HTTP based adaptive video streaming has become a popular choice of streaming
due to the reliable transmission and the flexibility offered to adapt to
varying network conditions. However, due to rate adaptation in adaptive
streaming, the quality of the videos at the client keeps varying with time
depending on the end-to-end network conditions. Further, varying network
conditions can lead to the video client running out of playback content
resulting in rebuffering events. These factors affect the user satisfaction and
cause degradation of the user quality of experience (QoE). It is important to
quantify the perceptual QoE of the streaming video users and monitor the same
in a continuous manner so that the QoE degradation can be minimized. However,
the continuous evaluation of QoE is challenging as it is determined by complex
dynamic interactions among the QoE influencing factors. Towards this end, we
present LSTM-QoE, a recurrent neural network based QoE prediction model using a
Long Short-Term Memory (LSTM) network. The LSTM-QoE is a network of cascaded
LSTM blocks to capture the nonlinearities and the complex temporal dependencies
involved in the time varying QoE. Based on an evaluation over several publicly
available continuous QoE databases, we demonstrate that the LSTM-QoE has the
capability to model the QoE dynamics effectively. We compare the proposed model
with the state-of-the-art QoE prediction models and show that it provides
superior performance across these databases. Further, we discuss the state
space perspective for the LSTM-QoE and show the efficacy of the state space
modeling approaches for QoE prediction.
"
1706,"A Hand-Held Multimedia Translation and Interpretation System with
  Application to Diet Management","  We propose a network independent, hand-held system to translate and
disambiguate foreign restaurant menu items in real-time. The system is based on
the use of a portable multimedia device, such as a smartphones or a PDA. An
accurate and fast translation is obtained using a Machine Translation engine
and a context-specific corpora to which we apply two pre-processing steps,
called translation standardization and $n$-gram consolidation. The phrase-table
generated is orders of magnitude lighter than the ones commonly used in market
applications, thus making translations computationally less expensive, and
decreasing the battery usage. Translation ambiguities are mitigated using
multimedia information including images of dishes and ingredients, along with
ingredient lists. We implemented a prototype of our system on an iPod Touch
Second Generation for English speakers traveling in Spain. Our tests indicate
that our translation method yields higher accuracy than translation engines
such as Google Translate, and does so almost instantaneously. The memory
requirements of the application, including the database of images, are also
well within the limits of the device. By combining it with a database of
nutritional information, our proposed system can be used to help individuals
who follow a medical diet maintain this diet while traveling.
"
1707,Few-Shot Adaptation for Multimedia Semantic Indexing,"  We propose a few-shot adaptation framework, which bridges zero-shot learning
and supervised many-shot learning, for semantic indexing of image and video
data. Few-shot adaptation provides robust parameter estimation with few
training examples, by optimizing the parameters of zero-shot learning and
supervised many-shot learning simultaneously. In this method, first we build a
zero-shot detector, and then update it by using the few examples. Our
experiments show the effectiveness of the proposed framework on three datasets:
TRECVID Semantic Indexing 2010, 2014, and ImageNET. On the ImageNET dataset, we
show that our method outperforms recent few-shot learning methods. On the
TRECVID 2014 dataset, we achieve 15.19% and 35.98% in Mean Average Precision
under the zero-shot condition and the supervised condition, respectively. To
the best of our knowledge, these are the best results on this dataset.
"
1708,Audio-to-Score Alignment using Transposition-invariant Features,"  Audio-to-score alignment is an important pre-processing step for in-depth
analysis of classical music. In this paper, we apply novel
transposition-invariant audio features to this task. These low-dimensional
features represent local pitch intervals and are learned in an unsupervised
fashion by a gated autoencoder. Our results show that the proposed features are
indeed fully transposition-invariant and enable accurate alignments between
transposed scores and performances. Furthermore, they can even outperform
widely used features for audio-to-score alignment on `untransposed data', and
thus are a viable and more flexible alternative to well-established features
for music alignment and matching.
"
1709,SoniControl - A Mobile Ultrasonic Firewall,"  The exchange of data between mobile devices in the near-ultrasonic frequency
band is a new promising technology for near field communication (NFC) but also
raises a number of privacy concerns. We present the first ultrasonic firewall
that reliably detects ultrasonic communication and provides the user with
effective means to prevent hidden data exchange. This demonstration showcases a
new media-based communication technology (""data over audio"") together with its
related privacy concerns. It enables users to (i) interactively test out and
experience ultrasonic information exchange and (ii) shows how to protect
oneself against unwanted tracking.
"
1710,"Twitter Sentiment Analysis via Bi-sense Emoji Embedding and
  Attention-based LSTM","  Sentiment analysis on large-scale social media data is important to bridge
the gaps between social media contents and real world activities including
political election prediction, individual and public emotional status
monitoring and analysis, and so on. Although textual sentiment analysis has
been well studied based on platforms such as Twitter and Instagram, analysis of
the role of extensive emoji uses in sentiment analysis remains light. In this
paper, we propose a novel scheme for Twitter sentiment analysis with extra
attention on emojis. We first learn bi-sense emoji embeddings under positive
and negative sentimental tweets individually, and then train a sentiment
classifier by attending on these bi-sense emoji embeddings with an
attention-based long short-term memory network (LSTM). Our experiments show
that the bi-sense embedding is effective for extracting sentiment-aware
embeddings of emojis and outperforms the state-of-the-art models. We also
visualize the attentions to show that the bi-sense emoji embedding provides
better guidance on the attention mechanism to obtain a more robust
understanding of the semantics and sentiments.
"
1711,"A Convolutional Neural Networks Denoising Approach for Salt and Pepper
  Noise","  The salt and pepper noise, especially the one with extremely high percentage
of impulses, brings a significant challenge to image denoising. In this paper,
we propose a non-local switching filter convolutional neural network denoising
algorithm, named NLSF-CNN, for salt and pepper noise. As its name suggested,
our NLSF-CNN consists of two steps, i.e., a NLSF processing step and a CNN
training step. First, we develop a NLSF pre-processing step for noisy images
using non-local information. Then, the pre-processed images are divided into
patches and used for CNN training, leading to a CNN denoising model for future
noisy images. We conduct a number of experiments to evaluate the effectiveness
of NLSF-CNN. Experimental results show that NLSF-CNN outperforms the
state-of-the-art denoising algorithms with a few training images.
"
1712,Actor-Action Semantic Segmentation with Region Masks,"  In this paper, we study the actor-action semantic segmentation problem, which
requires joint labeling of both actor and action categories in video frames.
One major challenge for this task is that when an actor performs an action,
different body parts of the actor provide different types of cues for the
action category and may receive inconsistent action labeling when they are
labeled independently. To address this issue, we propose an end-to-end
region-based actor-action segmentation approach which relies on region masks
from an instance segmentation algorithm. Our main novelty is to avoid labeling
pixels in a region mask independently - instead we assign a single action label
to these pixels to achieve consistent action labeling. When a pixel belongs to
multiple region masks, max pooling is applied to resolve labeling conflicts.
Our approach uses a two-stream network as the front-end (which learns features
capturing both appearance and motion information), and uses two region-based
segmentation networks as the back-end (which takes the fused features from the
two-stream network as the input and predicts actor-action labeling).
Experiments on the A2D dataset demonstrate that both the region-based
segmentation strategy and the fused features from the two-stream network
contribute to the performance improvements. The proposed approach outperforms
the state-of-the-art results by more than 8% in mean class accuracy, and more
than 5% in mean class IOU, which validates its effectiveness.
"
1713,Invisible Steganography via Generative Adversarial Networks,"  Nowadays, there are plenty of works introducing convolutional neural networks
(CNNs) to the steganalysis and exceeding conventional steganalysis algorithms.
These works have shown the improving potential of deep learning in information
hiding domain. There are also several works based on deep learning to do image
steganography, but these works still have problems in capacity, invisibility
and security. In this paper, we propose a novel CNN architecture named as
\isgan to conceal a secret gray image into a color cover image on the sender
side and exactly extract the secret image out on the receiver side. There are
three contributions in our work: (i) we improve the invisibility by hiding the
secret image only in the Y channel of the cover image; (ii) We introduce the
generative adversarial networks to strengthen the security by minimizing the
divergence between the empirical probability distributions of stego images and
natural images. (iii) In order to associate with the human visual system
better, we construct a mixed loss function which is more appropriate for
steganography to generate more realistic stego images and reveal out more
better secret images. Experiment results show that ISGAN can achieve
start-of-art performances on LFW, Pascal VOC2012 and ImageNet datasets.
"
1714,360 virtual reality travel media for elderly,"  The objectives of this qualitative research were to study the model of
360-degree virtual reality travel media, to compare appropriateness of moving
360-degree virtual reality travel media for elderly with both still and moving
cameras, and to study satisfaction of elderly in 360-degree virtual reality
travel media. The informants are 10 elders with age above and equal to 60 years
old who live in Bangkok regardless of genders. Data were collected through
documents, detailed interview, and non-participant observation of elders to
360-degree virtual reality travel media with data triangulation. 1. From the
literature review 1. The creation must primarily consider the target consumers
on their physics 2. must have fluidity on changing the view of the camera by
calibrating with the target consumers 3. The image displayed must not move too
fast to prevent dizziness and improve the comfort of the target consumers. It
is also highly recommended to implement a function to customize the movement
rate for the customer. 2. From the in-depth interview with the target
consumers, the results found that 1. They are worried and not used to the
equipment 2. They have no idea where to look 3. They feel excited 5. They are
interested in what is more to see 6. They feel like they did actually travel
there 7. They can hear the sound clearly 8. They do not like when the camera is
moving and find still camera more comfortable. 3. From the non-participant
observation and found that they are always excited, laughed, and smiled when
watching the media. They always asked where this is and why they cannot see
anything when turning around.
"
1715,Video Storytelling: Textual Summaries for Events,"  Bridging vision and natural language is a longstanding goal in computer
vision and multimedia research. While earlier works focus on generating a
single-sentence description for visual content, recent works have studied
paragraph generation. In this work, we introduce the problem of video
storytelling, which aims at generating coherent and succinct stories for long
videos. Video storytelling introduces new challenges, mainly due to the
diversity of the story and the length and complexity of the video. We propose
novel methods to address the challenges. First, we propose a context-aware
framework for multimodal embedding learning, where we design a Residual
Bidirectional Recurrent Neural Network to leverage contextual information from
past and future. Second, we propose a Narrator model to discover the underlying
storyline. The Narrator is formulated as a reinforcement learning agent which
is trained by directly optimizing the textual metric of the generated story. We
evaluate our method on the Video Story dataset, a new dataset that we have
collected to enable the study. We compare our method with multiple
state-of-the-art baselines, and show that our method achieves better
performance, in terms of quantitative measures and user study.
"
1716,"Who is the director of this movie? Automatic style recognition based on
  shot features","  We show how low-level formal features, such as shot duration, meant as length
of camera takes, and shot scale, i.e. the distance between the camera and the
subject, are distinctive of a director's style in art movies. So far such
features were thought of not having enough varieties to become distinctive of
an author. However our investigation on the full filmographies of six different
authors (Scorsese, Godard, Tarr, Fellini, Antonioni, and Bergman) for a total
number of 120 movies analysed second by second, confirms that these
shot-related features do not appear as random patterns in movies from the same
director. For feature extraction we adopt methods based on both conventional
and deep learning techniques. Our findings suggest that feature sequential
patterns, i.e. how features evolve in time, are at least as important as the
related feature distributions. To the best of our knowledge this is the first
study dealing with automatic attribution of movie authorship, which opens up
interesting lines of cross-disciplinary research on the impact of style on the
aesthetic and emotional effects on the viewers.
"
1717,Visual Display and Retrieval of Music Information,"  This paper describes computational methods for the visual display and
analysis of music information. We provide a concise description of software,
music descriptors and data visualization techniques commonly used in music
information retrieval. Finally, we provide use cases where the described
software, descriptors and visualizations are showcased.
"
1718,"The Helmholtz Method: Using Perceptual Compression to Reduce Machine
  Learning Complexity","  This paper proposes a fundamental answer to a frequently asked question in
multimedia computing and machine learning: Do artifacts from perceptual
compression contribute to error in the machine learning process and if so, how
much? Our approach to the problem is a reinterpretation of the Helmholtz Free
Energy formula from physics to explain the relationship between content and
noise when using sensors (such as cameras or microphones) to capture multimedia
data. The reinterpretation allows a bit-measurement of the noise contained in
images, audio, and video by combining a classifier with perceptual compression,
such as JPEG or MP3. Our experiments on CIFAR-10 as well as Fraunhofer's
IDMT-SMT-Audio-Effects dataset indicate that, at the right quality level,
perceptual compression is actually not harmful but contributes to a significant
reduction of complexity of the machine learning process. That is, our noise
quantification method can be used to speed up the training of deep learning
classifiers significantly while maintaining, or sometimes even improving,
overall classification accuracy. Moreover, our results provide insights into
the reasons for the success of deep learning.
"
1719,"A user model for JND-based video quality assessment: theory and
  applications","  The video quality assessment (VQA) technology has attracted a lot of
attention in recent years due to an increasing demand of video streaming
services. Existing VQA methods are designed to predict video quality in terms
of the mean opinion score (MOS) calibrated by humans in subjective experiments.
However, they cannot predict the satisfied user ratio (SUR) of an aggregated
viewer group. Furthermore, they provide little guidance to video coding
parameter selection, e.g. the Quantization Parameter (QP) of a set of
consecutive frames, in practical video streaming services. To overcome these
shortcomings, the just-noticeable-difference (JND) based VQA methodology has
been proposed as an alternative. It is observed experimentally that the JND
location is a normally distributed random variable. In this work, we explain
this distribution by proposing a user model that takes both subject
variabilities and content variabilities into account. This model is built upon
user's capability to discern the quality difference between video clips encoded
with different QPs. Moreover, it analyzes video content characteristics to
account for inter-content variability. The proposed user model is validated on
the data collected in the VideoSet. It is demonstrated that the model is
flexible to predict SUR distribution of a specific user group.
"
1720,A Margin-based MLE for Crowdsourced Partial Ranking,"  A preference order or ranking aggregated from pairwise comparison data is
commonly understood as a strict total order. However, in real-world scenarios,
some items are intrinsically ambiguous in comparisons, which may very well be
an inherent uncertainty of the data. In this case, the conventional total order
ranking can not capture such uncertainty with mere global ranking or utility
scores. In this paper, we are specifically interested in the recent surge in
crowdsourcing applications to predict partial but more accurate (i.e., making
less incorrect statements) orders rather than complete ones. To do so, we
propose a novel framework to learn some probabilistic models of partial orders
as a \emph{margin-based Maximum Likelihood Estimate} (MLE) method. We prove
that the induced MLE is a joint convex optimization problem with respect to all
the parameters, including the global ranking scores and margin parameter.
Moreover, three kinds of generalized linear models are studied, including the
basic uniform model, Bradley-Terry model, and Thurstone-Mosteller model,
equipped with some theoretical analysis on FDR and Power control for the
proposed methods. The validity of these models are supported by experiments
with both simulated and real-world datasets, which shows that the proposed
models exhibit improvements compared with traditional state-of-the-art
algorithms.
"
1721,"Efficient feature learning and multi-size image steganalysis based on
  CNN","  For steganalysis, many studies showed that convolutional neural network has
better performances than the two-part structure of traditional machine learning
methods. However, there are still two problems to be resolved: cutting down
signal to noise ratio of the steganalysis feature map and steganalyzing images
of arbitrary size. Some algorithms required fixed size images as the input and
had low accuracy due to the underutilization of the noise residuals obtained by
various types of filters. In this paper, we focus on designing an improved
network structure based on CNN to resolve the above problems. First, we use 3x3
kernels instead of the traditional 5x5 kernels and optimize convolution kernels
in the preprocessing layer. The smaller convolution kernels are used to reduce
the number of parameters and model the features in a small local region. Next,
we use separable convolutions to utilize channel correlation of the residuals,
compress the image content and increase the signal-to-noise ratio (between the
stego signal and the image signal). Then, we use spatial pyramid pooling (SPP)
to aggregate the local features, enhance the representation ability of
features, and steganalyze arbitrary size image. Finally, data augmentation is
adopted to further improve network performance. The experimental results show
that the proposed CNN structure is significantly better than other four methods
such as SRM, Ye-Net, Xu-Net, and Yedroudj-Net, when it is used to detect two
spatial algorithms such as WOW and S-UNIWARAD with a wide variety of datasets
and payloads.
"
1722,Develop the application for learning place value,"  The objectives of this research were 1) to develop the application for
learning place value, 2) to determine the efficiency of developed application,
3) to compare academic achievement to compare academic achievement between
pre-lesson and post-lesson of students who learned with the developed
application about place value, 4) to compare academic achievement between
students who learned place value by the developed application and through
traditional method during post-lesson, 5) to compare retention of academic
achievement of application for learning place value after 2 weeks, and 6) to
find satisfactory of student who learned the application for learning place
value. The sample group selected through purposive sampling was 5 content
specialists and 400 pratomsuksa 1 students.
"
1723,An Advert Creation System for Next-Gen Publicity,"  With the rapid proliferation of multimedia data in the internet, there has
been a fast rise in the creation of videos for the viewers. This enables the
viewers to skip the advertisement breaks in the videos, using ad blockers and
'skip ad' buttons -- bringing online marketing and publicity to a stall. In
this paper, we demonstrate a system that can effectively integrate a new
advertisement into a video sequence. We use state-of-the-art techniques from
deep learning and computational photogrammetry, for effective detection of
existing adverts, and seamless integration of new adverts into video sequences.
This is helpful for targeted advertisement, paving the path for next-gen
publicity.
"
1724,"From Thumbnails to Summaries - A single Deep Neural Network to Rule Them
  All","  Video summaries come in many forms, from traditional single-image thumbnails,
animated thumbnails, storyboards, to trailer-like video summaries. Content
creators use the summaries to display the most attractive portion of their
videos; the users use them to quickly evaluate if a video is worth watching.
All forms of summaries are essential to video viewers, content creators, and
advertisers. Often video content management systems have to generate multiple
versions of summaries that vary in duration and presentational forms. We
present a framework ReconstSum that utilizes LSTM-based autoencoder
architecture to extract and select a sparse subset of video frames or keyshots
that optimally represent the input video in an unsupervised manner. The encoder
selects a subset from the input video while the decoder seeks to reconstruct
the video from the selection. The goal is to minimize the difference between
the original input video and the reconstructed video. Our method is easily
extendable to generate a variety of applications including static video
thumbnails, animated thumbnails, storyboards and ""trailer-like"" highlights. We
specifically study and evaluate two most popular use cases: thumbnail
generation and storyboard generation. We demonstrate that our methods generate
better results than the state-of-the-art techniques in both use cases.
"
1725,"The Importance of Context When Recommending TV Content: Dataset and
  Algorithms","  Home entertainment systems feature in a variety of usage scenarios with one
or more simultaneous users, for whom the complexity of choosing media to
consume has increased rapidly over the last decade. Users' decision processes
are complex and highly influenced by contextual settings, but data supporting
the development and evaluation of context-aware recommender systems are scarce.
In this paper we present a dataset of self-reported TV consumption enriched
with contextual information of viewing situations. We show how choice of genre
associates with, among others, the number of present users and users' attention
levels. Furthermore, we evaluate the performance of predicting chosen genres
given different configurations of contextual information, and compare the
results to contextless predictions. The results suggest that including
contextual features in the prediction cause notable improvements, and both
temporal and social context show significant contributions.
"
1726,"Two-pass Light Field Image Compression for Spatial Quality and Angular
  Consistency","  The quality assessment of light field images presents new challenges to
conventional compression methods, as the spatial quality is affected by the
optical distortion of capturing devices, and the angular consistency affects
the performance of dynamic rendering applications. In this paper, we propose a
two-pass encoding system for pseudo-temporal sequence based light field image
compression with a novel frame level bit allocation framework that optimizes
spatial quality and angular consistency simultaneously. Frame level
rate-distortion models are estimated during the first pass, and the second pass
performs the actual encoding with optimized bit allocations given by a two-step
convex programming. The proposed framework supports various encoder
configurations. Experimental results show that comparing to the anchor HM 16.16
(HEVC reference software), the proposed two-pass encoding system on average
achieves 11.2% to 11.9% BD-rate reductions for the all-intra configuration,
15.8% to 32.7% BD-rate reductions for the random-access configuration, and
12.1% to 15.7% BD-rate reductions for the low-delay configuration. The
resulting bit errors are limited, and the total time cost is less than twice of
the one-pass anchor. Comparing with our earlier low-delay configuration based
method, the proposed system improves BD-rate reduction by 3.1% to 8.3%, reduces
the bit errors by more than 60%, and achieves more than 12x speed up.
"
1727,"Normalization Before Shaking Toward Learning Symmetrically Distributed
  Representation Without Margin in Speech Emotion Recognition","  Regularization is crucial to the success of many practical deep learning
models, in particular in a more often than not scenario where there are only a
few to a moderate number of accessible training samples. In addition to weight
decay, data augmentation and dropout, regularization based on multi-branch
architectures, such as Shake-Shake regularization, has been proven successful
in many applications and attracted more and more attention. However, beyond
model-based representation augmentation, it is unclear how Shake-Shake
regularization helps to provide further improvement on classification tasks,
let alone the baffling interaction between batch normalization and shaking. In
this work, we present our investigation on Shake-Shake regularization, drawing
connections to the vicinal risk minimization principle and discriminative
feature learning in verification tasks. Furthermore, we identify a strong
resemblance between batch normalized residual blocks and batch normalized
recurrent neural networks, where both of them share a similar convergence
behavior, which could be mitigated by a proper initialization of batch
normalization. Based on the findings, our experiments on speech emotion
recognition demonstrate simultaneously an improvement on the classification
accuracy and a reduction on the generalization gap both with statistical
significance.
"
1728,Simultaneous Edge Alignment and Learning,"  Edge detection is among the most fundamental vision problems for its role in
perceptual grouping and its wide applications. Recent advances in
representation learning have led to considerable improvements in this area.
Many state of the art edge detection models are learned with fully
convolutional networks (FCNs). However, FCN-based edge learning tends to be
vulnerable to misaligned labels due to the delicate structure of edges. While
such problem was considered in evaluation benchmarks, similar issue has not
been explicitly addressed in general edge learning. In this paper, we show that
label misalignment can cause considerably degraded edge learning quality, and
address this issue by proposing a simultaneous edge alignment and learning
framework. To this end, we formulate a probabilistic model where edge alignment
is treated as latent variable optimization, and is learned end-to-end during
network training. Experiments show several applications of this work, including
improved edge detection with state of the art performance, and automatic
refinement of noisy annotations.
"
1729,"Semi-supervised Deep Generative Modelling of Incomplete Multi-Modality
  Emotional Data","  There are threefold challenges in emotion recognition. First, it is difficult
to recognize human's emotional states only considering a single modality.
Second, it is expensive to manually annotate the emotional data. Third,
emotional data often suffers from missing modalities due to unforeseeable
sensor malfunction or configuration issues. In this paper, we address all these
problems under a novel multi-view deep generative framework. Specifically, we
propose to model the statistical relationships of multi-modality emotional data
using multiple modality-specific generative networks with a shared latent
space. By imposing a Gaussian mixture assumption on the posterior approximation
of the shared latent variables, our framework can learn the joint deep
representation from multiple modalities and evaluate the importance of each
modality simultaneously. To solve the labeled-data-scarcity problem, we extend
our multi-view model to semi-supervised learning scenario by casting the
semi-supervised classification problem as a specialized missing data imputation
task. To address the missing-modality problem, we further extend our
semi-supervised multi-view model to deal with incomplete data, where a missing
view is treated as a latent variable and integrated out during inference. This
way, the proposed overall framework can utilize all available (both labeled and
unlabeled, as well as both complete and incomplete) data to improve its
generalization ability. The experiments conducted on two real multi-modal
emotion datasets demonstrated the superiority of our framework.
"
1730,Question-Guided Hybrid Convolution for Visual Question Answering,"  In this paper, we propose a novel Question-Guided Hybrid Convolution (QGHC)
network for Visual Question Answering (VQA). Most state-of-the-art VQA methods
fuse the high-level textual and visual features from the neural network and
abandon the visual spatial information when learning multi-modal features.To
address these problems, question-guided kernels generated from the input
question are designed to convolute with visual features for capturing the
textual and visual relationship in the early stage. The question-guided
convolution can tightly couple the textual and visual information but also
introduce more parameters when learning kernels. We apply the group
convolution, which consists of question-independent kernels and
question-dependent kernels, to reduce the parameter size and alleviate
over-fitting. The hybrid convolution can generate discriminative multi-modal
features with fewer parameters. The proposed approach is also complementary to
existing bilinear pooling fusion and attention based VQA methods. By
integrating with them, our method could further boost the performance.
Extensive experiments on public VQA datasets validate the effectiveness of
QGHC.
"
1731,Efficient Continuous Top-$k$ Geo-Image Search on Road Network,"  With the rapid development of mobile Internet and cloud computing technology,
large-scale multimedia data, e.g., texts, images, audio and videos have been
generated, collected, stored and shared. In this paper, we propose a novel
query problem named continuous top-$k$ geo-image query on road network which
aims to search out a set of geo-visual objects based on road network distance
proximity and visual content similarity. Existing approaches for spatial
textual query and geo-image query cannot address this problem effectively
because they do not consider both of visual content similarity and road network
distance proximity on road network. In order to address this challenge
effectively and efficiently, firstly we propose the definition of geo-visual
objects and continuous top-$k$ geo-visual objects query on road network, then
develop a score function for search. To improve the query efficiency in a
large-scale road network, we propose the search algorithm named geo-visual
search on road network based on a novel hybrid indexing framework called
VIG-Tree, which combines G-Tree and visual inverted index technique. In
addition, an important notion named safe interval and results updating rule are
proposed, and based on them we develop an efficient algorithm named moving
monitor algorithm to solve continuous query. Experimental evaluation on real
multimedia dataset and road network dataset illustrates that our solution
outperforms state-of-the-art method.
"
1732,"Low-complexity 8-point DCT Approximation Based on Angle Similarity for
  Image and Video Coding","  The principal component analysis (PCA) is widely used for data decorrelation
and dimensionality reduction. However, the use of PCA may be impractical in
real-time applications, or in situations were energy and computing constraints
are severe. In this context, the discrete cosine transform (DCT) becomes a
low-cost alternative to data decorrelation. This paper presents a method to
derive computationally efficient approximations to the DCT. The proposed method
aims at the minimization of the angle between the rows of the exact DCT matrix
and the rows of the approximated transformation matrix. The resulting
transformations matrices are orthogonal and have extremely low arithmetic
complexity. Considering popular performance measures, one of the proposed
transformation matrices outperforms the best competitors in both matrix error
and coding capabilities. Practical applications in image and video coding
demonstrate the relevance of the proposed transformation. In fact, we show that
the proposed approximate DCT can outperform the exact DCT for image encoding
under certain compression ratios. The proposed transform and its direct
competitors are also physically realized as digital prototype circuits using
FPGA technology.
"
1733,Reconfigurable Inverted Index,"  Existing approximate nearest neighbor search systems suffer from two
fundamental problems that are of practical importance but have not received
sufficient attention from the research community. First, although existing
systems perform well for the whole database, it is difficult to run a search
over a subset of the database. Second, there has been no discussion concerning
the performance decrement after many items have been newly added to a system.
We develop a reconfigurable inverted index (Rii) to resolve these two issues.
Based on the standard IVFADC system, we design a data layout such that items
are stored linearly. This enables us to efficiently run a subset search by
switching the search method to a linear PQ scan if the size of a subset is
small. Owing to the linear layout, the data structure can be dynamically
adjusted after new items are added, maintaining the fast speed of the system.
Extensive comparisons show that Rii achieves a comparable performance with
state-of-the art systems such as Faiss.
"
1734,"Learning Discriminative Hashing Codes for Cross-Modal Retrieval based on
  Multi-view Features","  Hashing techniques have been applied broadly in retrieval tasks due to their
low storage requirements and high speed of processing. Many hashing methods
based on a single view have been extensively studied for information retrieval.
However, the representation capacity of a single view is insufficient and some
discriminative information is not captured, which results in limited
improvement. In this paper, we employ multiple views to represent images and
texts for enriching the feature information. Our framework exploits the
complementary information among multiple views to better learn the
discriminative compact hash codes. A discrete hashing learning framework that
jointly performs classifier learning and subspace learning is proposed to
complete multiple search tasks simultaneously. Our framework includes two
stages, namely a kernelization process and a quantization process.
Kernelization aims to find a common subspace where multi-view features can be
fused. The quantization stage is designed to learn discriminative unified
hashing codes. Extensive experiments are performed on single-label datasets
(WiKi and MMED) and multi-label datasets (MIRFlickr and NUS-WIDE) and the
experimental results indicate the superiority of our method compared with the
state-of-the-art methods.
"
1735,X-GANs: Image Reconstruction Made Easy for Extreme Cases,"  Image reconstruction including image restoration and denoising is a
challenging problem in the field of image computing. We present a new method,
called X-GANs, for reconstruction of arbitrary corrupted resource based on a
variant of conditional generative adversarial networks (conditional GANs). In
our method, a novel generator and multi-scale discriminators are proposed, as
well as the combined adversarial losses, which integrate a VGG perceptual loss,
an adversarial perceptual loss, and an elaborate corresponding point loss
together based on the analysis of image feature. Our conditional GANs have
enabled a variety of applications in image reconstruction, including image
denoising, image restoration from quite a sparse sampling, image inpainting,
image recovery from the severely polluted block or even color-noise dominated
images, which are extreme cases and haven't been addressed in the status quo.
We have significantly improved the accuracy and quality of image
reconstruction. Extensive perceptual experiments on datasets ranging from human
faces to natural scenes demonstrate that images reconstructed by the presented
approach are considerably more realistic than alternative work. Our method can
also be extended to handle high-ratio image compression.
"
1736,"Discriminative multi-view Privileged Information learning for image
  re-ranking","  Conventional multi-view re-ranking methods usually perform asymmetrical
matching between the region of interest (ROI) in the query image and the whole
target image for similarity computation. Due to the inconsistency in the visual
appearance, this practice tends to degrade the retrieval accuracy particularly
when the image ROI, which is usually interpreted as the image objectness,
accounts for a smaller region in the image. Since Privileged Information (PI),
which can be viewed as the image prior, enables well characterizing the image
objectness, we are aiming at leveraging PI for further improving the
performance of the multi-view re-ranking accuracy in this paper. Towards this
end, we propose a discriminative multi-view re-ranking approach in which both
the original global image visual contents and the local auxiliary PI features
are simultaneously integrated into a unified training framework for generating
the latent subspaces with sufficient discriminating power. For the on-the-fly
re-ranking, since the multi-view PI features are unavailable, we only project
the original multi-view image representations onto the latent subspace, and
thus the re-ranking can be achieved by computing and sorting the distances from
the multi-view embeddings to the separating hyperplane. Extensive experimental
evaluations on the two public benchmarks Oxford5k and Paris6k reveal our
approach provides further performance boost for accurate image re-ranking,
whilst the comparative study demonstrates the advantage of our method against
other multi-view re-ranking methods.
"
1737,IceBreaker: Solving Cold Start Problem for Video Recommendation Engines,"  Internet has brought about a tremendous increase in content of all forms and,
in that, video content constitutes the major backbone of the total content
being published as well as watched. Thus it becomes imperative for video
recommendation engines such as Hulu to look for novel and innovative ways to
recommend the newly added videos to their users. However, the problem with new
videos is that they lack any sort of metadata and user interaction so as to be
able to rate the videos for the consumers. To this effect, this paper
introduces the several techniques we develop for the Content Based Video
Relevance Prediction (CBVRP) Challenge being hosted by Hulu for the ACM
Multimedia Conference 2018. We employ different architectures on the CBVRP
dataset to make use of the provided frame and video level features and generate
predictions of videos that are similar to the other videos. We also implement
several ensemble strategies to explore complementarity between both the types
of provided features. The obtained results are encouraging and will impel the
boundaries of research for multimedia based video recommendation systems.
"
1738,"First Steps Toward CNN based Source Classification of Document Images
  Shared Over Messaging App","  Knowledge of source smartphone corresponding to a document image can be
helpful in a variety of applications including copyright infringement,
ownership attribution, leak identification and usage restriction. In this
letter, we investigate a convolutional neural network-based approach to solve
source smartphone identification problem for printed text documents which have
been captured by smartphone cameras and shared over messaging platform. In
absence of any publicly available dataset addressing this problem, we introduce
a new image dataset consisting of 315 images of documents printed in three
different fonts, captured using 21 smartphones and shared over WhatsApp.
Experiments conducted on this dataset demonstrate that, in all scenarios, the
proposed system performs as well as or better than the state-of-the-art system
based on handcrafted features and classification of letters extracted from
document images. The new dataset and code of the proposed system will be made
publicly available along with this letter's publication, presently they are
submitted for review.
"
1739,An Efficient Approach for Geo-Multimedia Cross-Modal Retrieval,"  Due to the rapid development of mobile Internet techniques, cloud computation
and popularity of online social networking and location-based services, massive
amount of multimedia data with geographical information is generated and
uploaded to the Internet. In this paper, we propose a novel type of cross-modal
multimedia retrieval called geo-multimedia cross-modal retrieval which aims to
search out a set of geo-multimedia objects based on geographical distance
proximity and semantic similarity between different modalities. Previous
studies for cross-modal retrieval and spatial keyword search cannot address
this problem effectively because they do not consider multimedia data with
geo-tags and do not focus on this type of query. In order to address this
problem efficiently, we present the definition of $k$NN geo-multimedia
cross-modal query at the first time and introduce relevant conceptions such as
cross-modal semantic representation space. To bridge the semantic gap between
different modalities, we propose a method named cross-modal semantic matching
which contains two important component, i.e., CorrProj and LogsTran, which aims
to construct a common semantic representation space for cross-modal semantic
similarity measurement. Besides, we designed a framework based on deep learning
techniques to implement common semantic representation space construction. In
addition, a novel hybrid indexing structure named GMR-Tree combining
geo-multimedia data and R-Tree is presented and a efficient $k$NN search
algorithm called $k$GMCMS is designed. Comprehensive experimental evaluation on
real and synthetic dataset clearly demonstrates that our solution outperforms
the-state-of-the-art methods.
"
1740,Cross-Modal Health State Estimation,"  Individuals create and consume more diverse data about themselves today than
any time in history. Sources of this data include wearable devices, images,
social media, geospatial information and more. A tremendous opportunity rests
within cross-modal data analysis that leverages existing domain knowledge
methods to understand and guide human health. Especially in chronic diseases,
current medical practice uses a combination of sparse hospital based biological
metrics (blood tests, expensive imaging, etc.) to understand the evolving
health status of an individual. Future health systems must integrate data
created at the individual level to better understand health status perpetually,
especially in a cybernetic framework. In this work we fuse multiple user
created and open source data streams along with established biomedical domain
knowledge to give two types of quantitative state estimates of cardiovascular
health. First, we use wearable devices to calculate cardiorespiratory fitness
(CRF), a known quantitative leading predictor of heart disease which is not
routinely collected in clinical settings. Second, we estimate inherent genetic
traits, living environmental risks, circadian rhythm, and biological metrics
from a diverse dataset. Our experimental results on 24 subjects demonstrate how
multi-modal data can provide personalized health insight. Understanding the
dynamic nature of health status will pave the way for better health based
recommendation engines, better clinical decision making and positive lifestyle
changes.
"
1741,"Intrinsic and Extrinsic Motivation Modeling Essential for Multi-Modal
  Health Recommender Systems","  Managing health lays the core foundation to enabling quality life
experiences. Modern computer science research, and especially the field of
recommender systems, has enhanced the quality of experiences in fields such as
entertainment, shopping, and advertising; yet lags in the health domain. We are
developing an approach to leverage multimedia for human health based on
motivation modeling and recommendation of actions. Health is primarily a
product of our everyday lifestyle actions, yet we have minimal health guidance
on making everyday choices. Recommendations are the key to modern content
consumption and decisions. Furthermore, long-term engagement with recommender
systems is key for true effectiveness. Distinguishing intrinsic and extrinsic
motivations from multi-modal data is key to provide recommendations that
primarily fuel the intrinsic intentions, while using extrinsic motivation to
further support intrinsic motivation. This understanding builds the foundation
of sustainable behavioral adaptation for optimal personalized lifestyle health
benefits.
"
1742,"Endogenous and Exogenous Multi-Modal Layers in Context Aware
  Recommendation Systems for Health","  People care more about the solutions to their problems rather than data
alone. Inherently, this means using data to generate a list of recommendations
for a given situation. The rapid growth of multi-modal wearables and sensors
have not made this jump effectively in the domain of health. Modern user
content consumption and decision making in both cyber (e.g. entertainment,
news) and physical (eg. food, shopping) spaces rely heavily on targeted
personalized recommender systems. The utility function is the primary ranking
method to predict what a given person would explicitly prefer. In this work we
describe two unique layers of user and context modeling that can be coupled to
traditional recommender system approaches. The exogenous layer incorporates
factors outside of the person's body (eg. location, weather, social context),
while the endogenous layer integrates data to estimate the physiologic or
innate needs of the user. This is accomplished through multi-modal sensor data
integration applied to domain-specific utility functions, filters and
re-ranking weights. We showcase this concept through a nutrition guidance
system focused on controlling sodium intake at a personalized level,
dramatically improving upon the fixed recommendations.
"
1743,Deep Multimodal Image-Repurposing Detection,"  Nefarious actors on social media and other platforms often spread rumors and
falsehoods through images whose metadata (e.g., captions) have been modified to
provide visual substantiation of the rumor/falsehood. This type of modification
is referred to as image repurposing, in which often an unmanipulated image is
published along with incorrect or manipulated metadata to serve the actor's
ulterior motives. We present the Multimodal Entity Image Repurposing (MEIR)
dataset, a substantially challenging dataset over that which has been
previously available to support research into image repurposing detection. The
new dataset includes location, person, and organization manipulations on
real-world data sourced from Flickr. We also present a novel, end-to-end, deep
multimodal learning model for assessing the integrity of an image by combining
information extracted from the image with related information from a knowledge
base. The proposed method is compared against state-of-the-art techniques on
existing datasets as well as MEIR, where it outperforms existing methods across
the board, with AUC improvement up to 0.23.
"
1744,A Survey on Food Computing,"  Food is very essential for human life and it is fundamental to the human
experience. Food-related study may support multifarious applications and
services, such as guiding the human behavior, improving the human health and
understanding the culinary culture. With the rapid development of social
networks, mobile networks, and Internet of Things (IoT), people commonly
upload, share, and record food images, recipes, cooking videos, and food
diaries, leading to large-scale food data. Large-scale food data offers rich
knowledge about food and can help tackle many central issues of human society.
Therefore, it is time to group several disparate issues related to food
computing. Food computing acquires and analyzes heterogenous food data from
disparate sources for perception, recognition, retrieval, recommendation, and
monitoring of food. In food computing, computational approaches are applied to
address food related issues in medicine, biology, gastronomy and agronomy. Both
large-scale food data and recent breakthroughs in computer science are
transforming the way we analyze food data. Therefore, vast amounts of work has
been conducted in the food area, targeting different food-oriented tasks and
applications. However, there are very few systematic reviews, which shape this
area well and provide a comprehensive and in-depth summary of current efforts
or detail open problems in this area. In this paper, we formalize food
computing and present such a comprehensive overview of various emerging
concepts, methods, and tasks. We summarize key challenges and future directions
ahead for food computing. This is the first comprehensive survey that targets
the study of computing technology for the food area and also offers a
collection of research studies and technologies to benefit researchers and
practitioners working in different food-related fields.
"
1745,Deep Adaptive Temporal Pooling for Activity Recognition,"  Deep neural networks have recently achieved competitive accuracy for human
activity recognition. However, there is room for improvement, especially in
modeling long-term temporal importance and determining the activity relevance
of different temporal segments in a video. To address this problem, we propose
a learnable and differentiable module: Deep Adaptive Temporal Pooling (DATP).
DATP applies a self-attention mechanism to adaptively pool the classification
scores of different video segments. Specifically, using frame-level features,
DATP regresses importance of different temporal segments and generates weights
for them. Remarkably, DATP is trained using only the video-level label. There
is no need of additional supervision except video-level activity class label.
We conduct extensive experiments to investigate various input features and
different weight models. Experimental results show that DATP can learn to
assign large weights to key video segments. More importantly, DATP can improve
training of frame-level feature extractor. This is because relevant temporal
segments are assigned large weights during back-propagation. Overall, we
achieve state-of-the-art performance on UCF101, HMDB51 and Kinetics datasets.
"
1746,CentralNet: a Multilayer Approach for Multimodal Fusion,"  This paper proposes a novel multimodal fusion approach, aiming to produce
best possible decisions by integrating information coming from multiple media.
While most of the past multimodal approaches either work by projecting the
features of different modalities into the same space, or by coordinating the
representations of each modality through the use of constraints, our approach
borrows from both visions. More specifically, assuming each modality can be
processed by a separated deep convolutional network, allowing to take decisions
independently from each modality, we introduce a central network linking the
modality specific networks. This central network not only provides a common
feature embedding but also regularizes the modality specific networks through
the use of multi-task learning. The proposed approach is validated on 4
different computer vision tasks on which it consistently improves the accuracy
of existing multimodal fusion approaches.
"
1747,"Identification of Deep Network Generated Images Using Disparities in
  Color Components","  With the powerful deep network architectures, such as generative adversarial
networks, one can easily generate photorealistic images. Although the generated
images are not dedicated for fooling human or deceiving biometric
authentication systems, research communities and public media have shown great
concerns on the security issues caused by these images. This paper addresses
the problem of identifying deep network generated (DNG) images. Taking the
differences between camera imaging and DNG image generation into
considerations, we analyze the disparities between DNG images and real images
in different color components. We observe that the DNG images are more
distinguishable from real ones in the chrominance components, especially in the
residual domain. Based on these observations, we propose a feature set to
capture color image statistics for identifying DNG images. Additionally, we
evaluate several detection situations, including the training-testing data are
matched or mismatched in image sources or generative models and detection with
only real images. Extensive experimental results show that the proposed method
can accurately identify DNG images and outperforms existing methods when the
training and testing data are mismatched. Moreover, when the GAN model is
unknown, our methods also achieves good performance with one-class
classification by using only real images for training.
"
1748,Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval,"  Cross-modal retrieval between visual data and natural language description
remains a long-standing challenge in multimedia. While recent image-text
retrieval methods offer great promise by learning deep representations aligned
across modalities, most of these methods are plagued by the issue of training
with small-scale datasets covering a limited number of images with ground-truth
sentences. Moreover, it is extremely expensive to create a larger dataset by
annotating millions of images with sentences and may lead to a biased model.
Inspired by the recent success of webly supervised learning in deep neural
networks, we capitalize on readily-available web images with noisy annotations
to learn robust image-text joint representation. Specifically, our main idea is
to leverage web images and corresponding tags, along with fully annotated
datasets, in training for learning the visual-semantic joint embedding. We
propose a two-stage approach for the task that can augment a typical supervised
pair-wise ranking loss based formulation with weakly-annotated web images to
learn a more robust visual-semantic embedding. Experiments on two standard
benchmark datasets demonstrate that our method achieves a significant
performance gain in image-text retrieval compared to state-of-the-art
approaches.
"
1749,Towards Machine Learning-Based Optimal HAS,"  Mobile video consumption is increasing and sophisticated video quality
adaptation strategies are required to deal with mobile throughput fluctuations.
These adaptation strategies have to keep the switching frequency low, the
average quality high and prevent stalling occurrences to ensure customer
satisfaction. This paper proposes a novel methodology for the design of machine
learning-based adaptation logics named HASBRAIN. Furthermore, the performance
of a trained neural network against two algorithms from the literature is
evaluated. We first use a modified existing optimization formulation to
calculate optimal adaptation paths with a minimum number of quality switches
for a wide range of videos and for challenging mobile throughput patterns.
Afterwards we use the resulting optimal adaptation paths to train and compare
different machine learning models. The evaluation shows that an artificial
neural network-based model can reach a high average quality with a low number
of switches in the mobile scenario. The proposed methodology is general enough
to be extended for further designs of machine learning-based algorithms and the
provided model can be deployed in on-demand streaming scenarios or be further
refined using reward-based mechanisms such as reinforcement learning. All
tools, models and datasets created during the work are provided as open-source
software.
"
1750,How do Convolutional Neural Networks Learn Design?,"  In this paper, we aim to understand the design principles in book cover
images which are carefully crafted by experts. Book covers are designed in a
unique way, specific to genres which convey important information to their
readers. By using Convolutional Neural Networks (CNN) to predict book genres
from cover images, visual cues which distinguish genres can be highlighted and
analyzed. In order to understand these visual clues contributing towards the
decision of a genre, we present the application of Layer-wise Relevance
Propagation (LRP) on the book cover image classification results. We use LRP to
explain the pixel-wise contributions of book cover design and highlight the
design elements contributing towards particular genres. In addition, with the
use of state-of-the-art object and text detection methods, insights about
genre-specific book cover designs are discovered.
"
1751,Patch-based Contour Prior Image Denoising for Salt and Pepper Noise,"  The salt and pepper noise brings a significant challenge to image denoising
technology, i.e. how to removal the noise clearly and retain the details
effectively? In this paper, we propose a patch-based contour prior denoising
approach for salt and pepper noise. First, noisy image is cut into patches as
basic representation unit, a discrete total variation model is designed to
extract contour structures; Second, a weighted Euclidean distance is designed
to search the most similar patches, then, corresponding contour stencils are
extracted from these similar patches; At the last, we build filter from contour
stencils in the framework of regression. Numerical results illustrate that the
proposed method is competitive with the state-of-the-art methods in terms of
the peak signal-to-noise (PSNR) and visual effects.
"
1752,Representation Learning for Image-based Music Recommendation,"  Image perception is one of the most direct ways to provide contextual
information about a user concerning his/her surrounding environment; hence
images are a suitable proxy for contextual recommendation. We propose a novel
representation learning framework for image-based music recommendation that
bridges the heterogeneity gap between music and image data; the proposed method
is a key component for various contextual recommendation tasks. Preliminary
experiments show that for an image-to-song retrieval task, the proposed method
retrieves relevant or conceptually similar songs for input images.
"
1753,Efficient Region of Visual Interests Search for Geo-multimedia Data,"  With the proliferation of online social networking services and mobile smart
devices equipped with mobile communications module and position sensor module,
massive amount of multimedia data has been collected, stored and shared. This
trend has put forward higher request on massive multimedia data retrieval. In
this paper, we investigate a novel spatial query named region of visual
interests query (RoVIQ), which aims to search users containing geographical
information and visual words. Three baseline methods are presented to introduce
how to exploit existing techniques to address this problem. Then we propose the
definition of this query and related notions at the first time. To improve the
performance of query, we propose a novel spatial indexing structure called
quadtree based inverted visual index which is a combination of quadtree,
inverted index and visual words. Based on it, we design a efficient search
algorithm named region of visual interests search to support RoVIQ.
Experimental evaluations on real geo-image datasets demonstrate that our
solution outperforms state-of-the-art method.
"
1754,"Wavelet Video Coding Algorithm Based on Energy Weighted Significance
  Probability Balancing Tree","  This work presents a 3-D wavelet video coding algorithm. By analyzing the
contribution of each biorthogonal wavelet basis to reconstructed signal's
energy, we weight each wavelet subband according to its basis energy. Based on
distribution of weighted coefficients, we further discuss a 3-D wavelet tree
structure named \textbf{significance probability balancing tree}, which places
the coefficients with similar probabilities of being significant on the same
layer. It is implemented by using hybrid spatial orientation tree and
temporal-domain block tree. Subsequently, a novel 3-D wavelet video coding
algorithm is proposed based on the energy-weighted significance probability
balancing tree. Experimental results illustrate that our algorithm always
achieves good reconstruction quality for different classes of video sequences.
Compared with asymmetric 3-D orientation tree, the average peak signal-to-noise
ratio (PSNR) gain of our algorithm are 1.24dB, 2.54dB and 2.57dB for luminance
(Y) and chrominance (U,V) components, respectively. Compared with
temporal-spatial orientation tree algorithm, our algorithm gains 0.38dB, 2.92dB
and 2.39dB higher PSNR separately for Y, U, and V components. In addition, the
proposed algorithm requires lower computation cost than those of the above two
algorithms.
"
1755,"Large-Scale Cover Song Detection in Digital Music Libraries Using
  Metadata, Lyrics and Audio Features","  Cover song detection is a very relevant task in Music Information Retrieval
(MIR) studies and has been mainly addressed using audio-based systems. Despite
its potential impact in industrial contexts, low performances and lack of
scalability have prevented such systems from being adopted in practice for
large applications. In this work, we investigate whether textual music
information (such as metadata and lyrics) can be used along with audio for
large-scale cover identification problem in a wide digital music library. We
benchmark this problem using standard text and state of the art audio
similarity measures. Our studies shows that these methods can significantly
increase the accuracy and scalability of cover detection systems on Million
Song Dataset (MSD) and Second Hand Song (SHS) datasets. By only leveraging
standard tf-idf based text similarity measures on song titles and lyrics, we
achieved 35.5% of absolute increase in mean average precision compared to the
current scalable audio content-based state of the art methods on MSD. These
experimental results suggests that new methodologies can be encouraged among
researchers to leverage and identify more sophisticated NLP-based techniques to
improve current cover song identification systems in digital music libraries
with metadata.
"
1756,"Exchange-Based Diffusion in Hb-Graphs: Highlighting Complex
  Relationships","  Most networks tend to show complex and multiple relationships between
entities. Networks are usually modeled by graphs or hypergraphs; nonetheless a
given entity can occur many times in a relationship: this brings the need to
deal with multisets instead of sets or simple edges. Diffusion processes are
useful to highlight interesting parts of a network: they usually start with a
stroke at one vertex and diffuse throughout the network to reach a uniform
distribution. Several iterations of the process are required prior to reaching
a stable solution. We propose an alternative solution to highlighting the main
components of a network using a diffusion process based on exchanges: it is an
iterative two-phase step exchange process. This process allows to evaluate the
importance not only of the vertices but also of the regrouping level. To model
the diffusion process, we extend the concept of hypergraphs that are families
of sets to families of multisets, that we call hb-graphs. This version is an
extended version of arXiv:1809.00190v1: the overlaps with the v1 are in black,
the new content is in blue. The contributions of this extended version are: the
proofs of conservation and convergence of the extracted sequences of the
diffusion process, as well as the illustration of the speed of convergence and
comparison to classical and modified random walks; the algorithms of the
exchange-based diffusion and the modified random walk; the application to a use
case based on Arxiv publications. All the figures except one have been either
modified or added in this extended version to take into account the new
developments.
"
1757,"Activity Recognition on a Large Scale in Short Videos - Moments in Time
  Dataset","  Moments capture a huge part of our lives. Accurate recognition of these
moments is challenging due to the diverse and complex interpretation of the
moments. Action recognition refers to the act of classifying the desired
action/activity present in a given video. In this work, we perform experiments
on Moments in Time dataset to recognize accurately activities occurring in 3
second clips. We use state of the art techniques for visual, auditory and
spatio temporal localization and develop method to accurately classify the
activity in the Moments in Time dataset. Our novel approach of using Visual
Based Textual features and fusion techniques performs well providing an overall
89.23 % Top - 5 accuracy on the 20 classes - a significant improvement over the
Baseline TRN model.
"
1758,Natural Language Person Search Using Deep Reinforcement Learning,"  Recent success in deep reinforcement learning is having an agent learn how to
play Go and beat the world champion without any prior knowledge of the game. In
that task, the agent has to make a decision on what action to take based on the
positions of the pieces. Person Search is recently explored using natural
language based text description of images for video surveillance applications
(S.Li et.al). We see (Fu.et al) provides an end to end approach for
object-based retrieval using deep reinforcement learning without constraints
placed on which objects are being detected. However, we believe for real-world
applications such as person search defining specific constraints which identify
a person as opposed to starting with a general object detection will have
benefits in terms of performance and computational resources required. In our
task, Deep reinforcement learning would localize the person in an image by
reshaping the sizes of the bounding boxes. Deep Reinforcement learning with
appropriate constraints would look only for the relevant person in the image as
opposed to an unconstrained approach where each individual objects in the image
are ranked. For person search, the agent is trying to form a tight bounding box
around the person in the image who matches the description. The bounding box is
initialized to the full image and at each time step, the agent makes a decision
on how to change the current bounding box so that it has a tighter bound around
the person based on the description of the person and the pixel values of the
current bounding box. After the agent takes an action, it will be given a
reward based on the Intersection over Union (IoU) of the current bounding box
and the ground truth box. Once the agent believes that the bounding box is
covering the person, it will indicate that the person is found.
"
1759,Deep Learning of Human Perception in Audio Event Classification,"  In this paper, we introduce our recent studies on human perception in audio
event classification by different deep learning models. In particular, the
pre-trained model VGGish is used as feature extractor to process audio data,
and DenseNet is trained by and used as feature extractor for our
electroencephalography (EEG) data. The correlation between audio stimuli and
EEG is learned in a shared space. In the experiments, we record brain
activities (EEG signals) of several subjects while they are listening to music
events of 8 audio categories selected from Google AudioSet, using a 16-channel
EEG headset with active electrodes. Our experimental results demonstrate that
i) audio event classification can be improved by exploiting the power of human
perception, and ii) the correlation between audio stimuli and EEG can be
learned to complement audio event understanding.
"
1760,Music Sequence Prediction with Mixture Hidden Markov Models,"  Recommendation systems that automatically generate personalized music
playlists for users have attracted tremendous attention in recent years.
Nowadays, most music recommendation systems rely on item-based or user-based
collaborative filtering or content-based approaches. In this paper, we propose
a novel mixture hidden Markov model (HMM) for music play sequence prediction.
We compare the mixture model with state-of-the-art methods and evaluate the
predictions quantitatively and qualitatively on a large-scale real-world
dataset in a Kaggle competition. Results show that our model significantly
outperforms traditional methods as well as other competitors. We conclude by
envisioning a next-generation music recommendation system that integrates our
model with recent advances in deep learning, computer vision, and speech
techniques, and has promising potential in both academia and industry.
"
1761,Local Music Event Recommendation with Long Tail Artists,"  In this paper, we explore the task of local music event recommendation. Many
local artists tend to be obscure long-tail artists with a small digital
footprint. That is, it can be hard to find social tag and artist similarity
information for many of the artists who are playing shows in the local music
community. To address this problem, we explore using Latent Semantic Analysis
(LSA) to embed artists and tags into a latent feature space and examine how
well artists with small digital footprints are represented in this space. We
find that only a relatively small digital footprint is needed to effectively
model artist similarity. We also introduce the concept of a Music Event Graph
as a data structure that makes it easy and efficient to recommend events based
on user-selected genre tags and popular artists. Finally, we conduct a small
user study to explore the feasibility of our proposed system for event
recommendation.
"
1762,Self-Supervised Generation of Spatial Audio for 360 Video,"  We introduce an approach to convert mono audio recorded by a 360 video camera
into spatial audio, a representation of the distribution of sound over the full
viewing sphere. Spatial audio is an important component of immersive 360 video
viewing, but spatial audio microphones are still rare in current 360 video
production. Our system consists of end-to-end trainable neural networks that
separate individual sound sources and localize them on the viewing sphere,
conditioned on multi-modal analysis of audio and 360 video frames. We introduce
several datasets, including one filmed ourselves, and one collected in-the-wild
from YouTube, consisting of 360 videos uploaded with spatial audio. During
training, ground-truth spatial audio serves as self-supervision and a mixed
down mono track forms the input to our network. Using our approach, we show
that it is possible to infer the spatial location of sound sources based only
on 360 video and a mono audio track.
"
1763,"Visualization of High-dimensional Scalar Functions Using Principal
  Parameterizations","  Insightful visualization of multidimensional scalar fields, in particular
parameter spaces, is key to many fields in computational science and
engineering. We propose a principal component-based approach to visualize such
fields that accurately reflects their sensitivity to input parameters. The
method performs dimensionality reduction on the vast $L^2$ Hilbert space formed
by all possible partial functions (i.e., those defined by fixing one or more
input parameters to specific values), which are projected to low-dimensional
parameterized manifolds such as 3D curves, surfaces, and ensembles thereof. Our
mapping provides a direct geometrical and visual interpretation in terms of
Sobol's celebrated method for variance-based sensitivity analysis. We
furthermore contribute a practical realization of the proposed method by means
of tensor decomposition, which enables accurate yet interactive integration and
multilinear principal component analysis of high-dimensional models.
"
1764,"Evaluation of Preference of Multimedia Content using Deep Neural
  Networks for Electroencephalography","  Evaluation of quality of experience (QoE) based on electroencephalography
(EEG) has received great attention due to its capability of real-time QoE
monitoring of users. However, it still suffers from rather low recognition
accuracy. In this paper, we propose a novel method using deep neural networks
toward improved modeling of EEG and thereby improved recognition accuracy. In
particular, we aim to model spatio-temporal characteristics relevant for QoE
analysis within learning models. The results demonstrate the effectiveness of
the proposed method.
"
1765,Efficient Multimedia Similarity Measurement Using Similar Elements,"  Online social networking techniques and large-scale multimedia systems are
developing rapidly, which not only has brought great convenience to our daily
life, but generated, collected, and stored large-scale multimedia data. This
trend has put forward higher requirements and greater challenges on massive
multimedia data retrieval. In this paper, we investigate the problem of image
similarity measurement which is used to lots of applications. At first we
propose the definition of similarity measurement of images and the related
notions. Based on it we present a novel basic method of similarity measurement
named SMIN. To improve the performance of calculation, we propose a novel
indexing structure called SMI Temp Index (SMII for short). Besides, we
establish an index of potential similar visual words off-line to solve to
problem that the index cannot be reused. Experimental evaluations on two real
image datasets demonstrate that our solution outperforms state-of-the-art
method.
"
1766,FIVR: Fine-grained Incident Video Retrieval,"  This paper introduces the problem of Fine-grained Incident Video Retrieval
(FIVR). Given a query video, the objective is to retrieve all associated
videos, considering several types of associations that range from duplicate
videos to videos from the same incident. FIVR offers a single framework that
contains several retrieval tasks as special cases. To address the benchmarking
needs of all such tasks, we construct and present a large-scale annotated video
dataset, which we call FIVR-200K, and it comprises 225,960 videos. To create
the dataset, we devise a process for the collection of YouTube videos based on
major news events from recent years crawled from Wikipedia and deploy a
retrieval pipeline for the automatic selection of query videos based on their
estimated suitability as benchmarks. We also devise a protocol for the
annotation of the dataset with respect to the four types of video associations
defined by FIVR. Finally, we report the results of an experimental study on the
dataset comparing five state-of-the-art methods developed based on a variety of
visual descriptors, highlighting the challenges of the current problem.
"
1767,"Implicit Analysis of Perceptual Multimedia Experience Based on
  Physiological Response: A Review","  The exponential growth of popularity of multimedia has led to needs for
user-centric adaptive applications that manage multimedia content more
effectively. Implicit analysis, which examines users' perceptual experience of
multimedia by monitoring physiological or behavioral cues, has potential to
satisfy such demands. Particularly, physiological signals categorized into
cerebral physiological signals (electroencephalography, functional magnetic
resonance imaging, and functional near-infrared spectroscopy) and peripheral
physiological signals (heart rate, respiration, skin temperature, etc.) have
recently received attention along with notable development of wearable
physiological sensors. In this paper, we review existing studies on
physiological signal analysis exploring perceptual experience of multimedia.
Furthermore, we discuss current trends and challenges.
"
1768,"Perceptual Experience Analysis for Tone-mapped HDR Videos based on EEG
  and Peripheral Physiological Signals","  High dynamic range (HDR) imaging has been attracting much attention as a
technology that can provide immersive experience. Its ultimate goal is to
provide better quality of experience (QoE) via enhanced contrast. In this
paper, we analyze perceptual experience of tone-mapped HDR videos both
explicitly by conducting a subjective questionnaire assessment and implicitly
by using EEG and peripheral physiological signals. From the results of the
subjective assessment, it is revealed that tone-mapped HDR videos are more
interesting and more natural, and give better quality than low dynamic range
(LDR) videos. Physiological signals were recorded during watching tone-mapped
HDR and LDR videos, and classification systems are constructed to explore
perceptual difference captured by the physiological signals. Significant
difference in the physiological signals is observed between tone-mapped HDR and
LDR videos in the classification under both a subject-dependent and a
subject-independent scenarios. Also, significant difference in the signals
between high versus low perceived contrast and overall quality is detected via
classification under the subject-dependent scenario. Moreover, it is shown that
features extracted from the gamma frequency band are effective for
classification.
"
1769,On Evaluating Perceptual Quality of Online User-Generated Videos,"  This paper deals with the issue of the perceptual quality evaluation of
user-generated videos shared online, which is an important step toward
designing video-sharing services that maximize users' satisfaction in terms of
quality. We first analyze viewers' quality perception patterns by applying
graph analysis techniques to subjective rating data. We then examine the
performance of existing state-of-the-art objective metrics for the quality
estimation of user-generated videos. In addition, we investigate the
feasibility of metadata accompanied with videos in online video-sharing
services for quality estimation. Finally, various issues in the quality
assessment of online user-generated videos are discussed, including
difficulties and opportunities.
"
1770,"Follow Me at the Edge: Mobility-Aware Dynamic Service Placement for
  Mobile Edge Computing","  Mobile edge computing is a new computing paradigm, which pushes cloud
computing capabilities away from the centralized cloud to the network edge.
However, with the sinking of computing capabilities, the new challenge incurred
by user mobility arises: since end-users typically move erratically, the
services should be dynamically migrated among multiple edges to maintain the
service performance, i.e., user-perceived latency. Tackling this problem is
non-trivial since frequent service migration would greatly increase the
operational cost. To address this challenge in terms of the performance-cost
trade-off, in this paper we study the mobile edge service performance
optimization problem under long-term cost budget constraint. To address user
mobility which is typically unpredictable, we apply Lyapunov optimization to
decompose the long-term optimization problem into a series of real-time
optimization problems which do not require a priori knowledge such as user
mobility. As the decomposed problem is NP-hard, we first design an
approximation algorithm based on Markov approximation to seek a near-optimal
solution. To make our solution scalable and amenable to future 5G application
scenario with large-scale user devices, we further propose a distributed
approximation scheme with greatly reduced time complexity, based on the
technique of best response update. Rigorous theoretical analysis and extensive
evaluations demonstrate the efficacy of the proposed centralized and
distributed schemes.
"
1771,CADP: A Novel Dataset for CCTV Traffic Camera based Accident Analysis,"  This paper presents a novel dataset for traffic accidents analysis. Our goal
is to resolve the lack of public data for research about automatic
spatio-temporal annotations for traffic safety in the roads. Through the
analysis of the proposed dataset, we observed a significant degradation of
object detection in pedestrian category in our dataset, due to the object sizes
and complexity of the scenes. To this end, we propose to integrate contextual
information into conventional Faster R-CNN using Context Mining (CM) and
Augmented Context Mining (ACM) to complement the accuracy for small pedestrian
detection. Our experiments indicate a considerable improvement in object
detection accuracy: +8.51% for CM and +6.20% for ACM. Finally, we demonstrate
the performance of accident forecasting in our dataset using Faster R-CNN and
an Accident LSTM architecture. We achieved an average of 1.684 seconds in terms
of Time-To-Accident measure with an Average Precision of 47.25%. Our Webpage
for the paper is https://goo.gl/cqK2wE
"
1772,Cloud Gaming With Foveated Graphics,"  Cloud gaming enables playing high end games, originally designed for PC or
game console setups, on low end devices, such as net-books and smartphones, by
offloading graphics rendering to GPU powered cloud servers. However,
transmitting the high end graphics requires a large amount of available network
bandwidth, even though it is a compressed video stream. Foveated video encoding
(FVE) reduces the bandwidth requirement by taking advantage of the non-uniform
acuity of human visual system and by knowing where the user is looking. We have
designed and implemented a system for cloud gaming with foveated graphics using
a consumer grade real-time eye tracker and an open source cloud gaming
platform. In this article, we describe the system and its evaluation through
measurements with representative games from different genres to understand the
effect of parameterization of the FVE scheme on bandwidth requirements and to
understand its feasibility from the latency perspective. We also present
results from a user study. The results suggest that it is possible to find a
""sweet spot"" for the encoding parameters so that the users hardly notice the
presence of foveated encoding but at the same time the scheme yields most of
the bandwidth savings achievable.
"
1773,"Multi-Label Image Classification via Knowledge Distillation from
  Weakly-Supervised Detection","  Multi-label image classification is a fundamental but challenging task
towards general visual understanding. Existing methods found the region-level
cues (e.g., features from RoIs) can facilitate multi-label classification.
Nevertheless, such methods usually require laborious object-level annotations
(i.e., object labels and bounding boxes) for effective learning of the
object-level visual features. In this paper, we propose a novel and efficient
deep framework to boost multi-label classification by distilling knowledge from
weakly-supervised detection task without bounding box annotations.
Specifically, given the image-level annotations, (1) we first develop a
weakly-supervised detection (WSD) model, and then (2) construct an end-to-end
multi-label image classification framework augmented by a knowledge
distillation module that guides the classification model by the WSD model
according to the class-level predictions for the whole image and the
object-level visual features for object RoIs. The WSD model is the teacher
model and the classification model is the student model. After this cross-task
knowledge distillation, the performance of the classification model is
significantly improved and the efficiency is maintained since the WSD model can
be safely discarded in the test phase. Extensive experiments on two large-scale
datasets (MS-COCO and NUS-WIDE) show that our framework achieves superior
performances over the state-of-the-art methods on both performance and
efficiency.
"
1774,"Intermediate Deep Feature Compression: the Next Battlefield of
  Intelligent Sensing","  The recent advances of hardware technology have made the intelligent analysis
equipped at the front-end with deep learning more prevailing and practical. To
better enable the intelligent sensing at the front-end, instead of compressing
and transmitting visual signals or the ultimately utilized top-layer deep
learning features, we propose to compactly represent and convey the
intermediate-layer deep learning features of high generalization capability, to
facilitate the collaborating approach between front and cloud ends. This
strategy enables a good balance among the computational load, transmission load
and the generalization ability for cloud servers when deploying the deep neural
networks for large scale cloud based visual analysis. Moreover, the presented
strategy also makes the standardization of deep feature coding more feasible
and promising, as a series of tasks can simultaneously benefit from the
transmitted intermediate layers. We also present the results for evaluation of
lossless deep feature compression with four benchmark data compression methods,
which provides meaningful investigations and baselines for future research and
standardization activities.
"
1775,"Symbolic Tensor Neural Networks for Digital Media - from Tensor
  Processing via BNF Graph Rules to CREAMS Applications","  This tutorial material on Convolutional Neural Networks (CNN) and its
applications in digital media research is based on the concept of Symbolic
Tensor Neural Networks. The set of STNN expressions is specified in Backus-Naur
Form (BNF) which is annotated by constraints typical for labeled acyclic
directed graphs (DAG). The BNF induction begins from a collection of neural
unit symbols with extra (up to five) decoration fields (including tensor depth
and sharing fields). The inductive rules provide not only the general graph
structure but also the specific shortcuts for residual blocks of units. A
syntactic mechanism for network fragments modularization is introduced via user
defined units and their instances. Moreover, the dual BNF rules are specified
in order to generate the Dual Symbolic Tensor Neural Network (DSTNN). The
joined interpretation of STNN and DSTNN provides the correct flow of gradient
tensors, back propagated at the training stage. The proposed symbolic
representation of CNNs is illustrated for six generic digital media
applications (CREAMS): Compression, Recognition, Embedding, Annotation, 3D
Modeling for human-computer interfacing, and data Security based on digital
media objects. In order to make the CNN description and its gradient flow
complete, for all presented applications, the symbolic representations of
mathematically defined loss/gain functions and gradient flow equations for all
used core units, are given. The tutorial is to convince the reader that STNN is
not only a convenient symbolic notation for public presentations of CNN based
solutions for CREAMS problems but also that it is a design blueprint with a
potential for automatic generation of application source code.
"
1776,Adversarial Training Towards Robust Multimedia Recommender System,"  With the prevalence of multimedia content on the Web, developing recommender
solutions that can effectively leverage the rich signal in multimedia data is
in urgent need. Owing to the success of deep neural networks in representation
learning, recent advance on multimedia recommendation has largely focused on
exploring deep learning methods to improve the recommendation accuracy. To
date, however, there has been little effort to investigate the robustness of
multimedia representation and its impact on the performance of multimedia
recommendation.
  In this paper, we shed light on the robustness of multimedia recommender
system. Using the state-of-the-art recommendation framework and deep image
features, we demonstrate that the overall system is not robust, such that a
small (but purposeful) perturbation on the input image will severely decrease
the recommendation accuracy. This implies the possible weakness of multimedia
recommender system in predicting user preference, and more importantly, the
potential of improvement by enhancing its robustness. To this end, we propose a
novel solution named Adversarial Multimedia Recommendation (AMR), which can
lead to a more robust multimedia recommender model by using adversarial
learning. The idea is to train the model to defend an adversary, which adds
perturbations to the target image with the purpose of decreasing the model's
accuracy. We conduct experiments on two representative multimedia
recommendation tasks, namely, image recommendation and visually-aware product
recommendation. Extensive results verify the positive effect of adversarial
learning and demonstrate the effectiveness of our AMR method. Source codes are
available in https://github.com/duxy-me/AMR.
"
1777,"Binocular Rivalry - Psychovisual Challenge in Stereoscopic Video Error
  Concealment","  During Stereoscopic 3D (S3D) video transmission, one or both views can be
affected by bit errors and packet losses caused by adverse channel conditions,
delay or jitter. Typically, the Human Visual System (HVS) is incapable of
aligning and fusing stereoscopic content if one view is affected by artefacts
caused by compression, transmission and rendering with distorted patterns being
perceived as alterations of the original which presents a shimmering effect
known as binocular rivalry and is detrimental to a user's Quality of Experience
(QoE). This study attempts to quantify the effects of binocular rivalry for
stereoscopic videos. Existing approaches, in which one or more frames are lost
in one or both views undergo error concealment, are implemented. Then,
subjective testing is carried out on the error concealed 3D video sequences.
The evaluations provided by these subjects were then combined and analysed
using a standard Student t-test thus quantifying the impact of binocular
rivalry and allowing the impact to be compared with that of monocular viewing.
The main focus is implementing error-resilient video communication, avoiding
the detrimental effects of binocular rivalry and improving the overall QoE of
viewers.
"
1778,"Survey on Error Concealment Strategies and Subjective Testing of 3D
  Videos","  Over the last decade, different technologies to visualize 3D scenes have been
introduced and improved. These technologies include stereoscopic, multi-view,
integral imaging and holographic types. Despite increasing consumer interest;
poor image quality, crosstalk or side effects of 3D displays and also the lack
of defined broadcast standards has hampered the advancement of 3D displays to
the mass consumer market. Also, in real time transmission of 3DTV sequences
over packet-based networks may results in visual quality degradations due to
packet loss and others. In the conventional 2D videos different extrapolation
and directional interpolation strategies have been used for concealing the
missing blocks but in 3D, it is still an emerging field of research. Few
studies have been carried out to define the assessment methods of stereoscopic
images and videos. But through industrial and commercial perspective,
subjective quality evaluation is the most direct way to evaluate human
perception on 3DTV systems. This paper reviews the state-of-the-art error
concealment strategies and the subjective evaluation of 3D videos and proposes
a low complexity frame loss concealment method for the video decoder.
Subjective testing on prominent datasets videos and comparison with existing
concealment methods show that the proposed method is very much efficient to
conceal errors of stereoscopic videos in terms of computation time, comfort and
distortion.
"
1779,Multimodal Dual Attention Memory for Video Story Question Answering,"  We propose a video story question-answering (QA) architecture, Multimodal
Dual Attention Memory (MDAM). The key idea is to use a dual attention mechanism
with late fusion. MDAM uses self-attention to learn the latent concepts in
scene frames and captions. Given a question, MDAM uses the second attention
over these latent concepts. Multimodal fusion is performed after the dual
attention processes (late fusion). Using this processing pipeline, MDAM learns
to infer a high-level vision-language joint representation from an abstraction
of the full video content. We evaluate MDAM on PororoQA and MovieQA datasets
which have large-scale QA annotations on cartoon videos and movies,
respectively. For both datasets, MDAM achieves new state-of-the-art results
with significant margins compared to the runner-up models. We confirm the best
performance of the dual attention mechanism combined with late fusion by
ablation studies. We also perform qualitative analysis by visualizing the
inference mechanisms of MDAM.
"
1780,"Understanding the Gist of Images - Ranking of Concepts for Multimedia
  Indexing","  Nowadays, where multimedia data is continuously generated, stored, and
distributed, multimedia indexing, with its purpose of group- ing similar data,
becomes more important than ever. Understanding the gist (=message) of
multimedia instances is framed in related work as a ranking of concepts from a
knowledge base, i.e., Wikipedia. We cast the task of multimedia indexing as a
gist understanding problem. Our pipeline benefits from external knowledge and
two subsequent learning- to-rank (l2r) settings. The first l2r produces a
ranking of concepts rep- resenting the respective multimedia instance. The
second l2r produces a mapping between the concept representation of an instance
and the targeted class topic(s) for the multimedia indexing task. The
evaluation on an established big size corpus (MIRFlickr25k, with 25,000
images), shows that multimedia indexing benefits from understanding the gist.
Finally, with a MAP of 61.42, it can be shown that the multimedia in- dexing
task benefits from understanding the gist. Thus, the presented end-to-end
setting outperforms DBM and competes with Hashing-based methods.
"
1781,An Iterative Refinement Approach for Social Media Headline Prediction,"  In this study, we propose a novel iterative refinement approach to predict
the popularity score of the social media meta-data effectively. With the rapid
growth of the social media on the Internet, how to adequately forecast the view
count or popularity becomes more important. Conventionally, the ensemble
approach such as random forest regression achieves high and stable performance
on various prediction tasks. However, most of the regression methods may not
precisely predict the extreme high or low values. To address this issue, we
first predict the initial popularity score and retrieve their residues. In
order to correctly compensate those extreme values, we adopt an ensemble
regressor to compensate the residues to further improve the prediction
performance. Comprehensive experiments are conducted to demonstrate the
proposed iterative refinement approach outperforms the state-of-the-art
regression approach.
"
1782,Learning to Detect Fake Face Images in the Wild,"  Although Generative Adversarial Network (GAN) can be used to generate the
realistic image, improper use of these technologies brings hidden concerns. For
example, GAN can be used to generate a tampered video for specific people and
inappropriate events, creating images that are detrimental to a particular
person, and may even affect that personal safety. In this paper, we will
develop a deep forgery discriminator (DeepFD) to efficiently and effectively
detect the computer-generated images. Directly learning a binary classifier is
relatively tricky since it is hard to find the common discriminative features
for judging the fake images generated from different GANs. To address this
shortcoming, we adopt contrastive loss in seeking the typical features of the
synthesized images generated by different GANs and follow by concatenating a
classifier to detect such computer-generated images. Experimental results
demonstrate that the proposed DeepFD successfully detected 94.7% fake images
generated by several state-of-the-art GANs.
"
1783,A Coarse-To-Fine Framework For Video Object Segmentation,"  In this study, we develop an unsupervised coarse-to-fine video analysis
framework and prototype system to extract a salient object in a video sequence.
This framework starts from tracking grid-sampled points along temporal frames,
typically using KLT tracking method. The tracking points could be divided into
several groups due to their inconsistent movements. At the same time, the SLIC
algorithm is extended into 3D space to generate supervoxels. Coarse
segmentation is achieved by combining the categorized tracking points and
supervoxels of the corresponding frame in the video sequence. Finally, a
graph-based fine segmentation algorithm is used to extract the moving object in
the scene. Experimental results reveal that this method outperforms the
previous approaches in terms of accuracy and robustness.
"
1784,Multi-View Frame Reconstruction with Conditional GAN,"  Multi-view frame reconstruction is an important problem particularly when
multiple frames are missing and past and future frames within the camera are
far apart from the missing ones. Realistic coherent frames can still be
reconstructed using corresponding frames from other overlapping cameras. We
propose an adversarial approach to learn the spatio-temporal representation of
the missing frame using conditional Generative Adversarial Network (cGAN). The
conditional input to each cGAN is the preceding or following frames within the
camera or the corresponding frames in other overlapping cameras, all of which
are merged together using a weighted average. Representations learned from
frames within the camera are given more weight compared to the ones learned
from other cameras when they are close to the missing frames and vice versa.
Experiments on two challenging datasets demonstrate that our framework produces
comparable results with the state-of-the-art reconstruction method in a single
camera and achieves promising performance in multi-camera scenario.
"
1785,Cross-Layer Effects on Training Neural Algorithms for Video Streaming,"  Nowadays Dynamic Adaptive Streaming over HTTP (DASH) is the most prevalent
solution on the Internet for multimedia streaming and responsible for the
majority of global traffic. DASH uses adaptive bit rate (ABR) algorithms, which
select the video quality considering performance metrics such as throughput and
playout buffer level. Pensieve is a system that allows to train ABR algorithms
using reinforcement learning within a simulated network environment and is
outperforming existing approaches in terms of achieved performance. In this
paper, we demonstrate that the performance of the trained ABR algorithms
depends on the implementation of the simulated environment used to train the
neural network. We also show that the used congestion control algorithm impacts
the algorithms' performance due to cross-layer effects.
"
1786,"Variational Bayesian Inference for Audio-Visual Tracking of Multiple
  Speakers","  In this paper we address the problem of tracking multiple speakers via the
fusion of visual and auditory information. We propose to exploit the
complementary nature of these two modalities in order to accurately estimate
smooth trajectories of the tracked persons, to deal with the partial or total
absence of one of the modalities over short periods of time, and to estimate
the acoustic status -- either speaking or silent -- of each tracked person
along time. We propose to cast the problem at hand into a generative
audio-visual fusion (or association) model formulated as a latent-variable
temporal graphical model. This may well be viewed as the problem of maximizing
the posterior joint distribution of a set of continuous and discrete latent
variables given the past and current observations, which is intractable. We
propose a variational inference model which amounts to approximate the joint
distribution with a factorized distribution. The solution takes the form of a
closed-form expectation maximization procedure. We describe in detail the
inference algorithm, we evaluate its performance and we compare it with several
baseline methods. These experiments show that the proposed audio-visual tracker
performs well in informal meetings involving a time-varying number of people.
"
1787,"GroupCast: Preference-Aware Cooperative Video Streaming with Scalable
  Video Coding","  In this paper, we propose a preference-aware cooperative video streaming
system for videos encoded using Scalable Video Coding (SVC) where all the
collaborating users are interested in watching a video together on a shared
screen. However, each user's willingness to cooperate is subject to her own
constraints such as user data plans and/or energy consumption. Using SVC, each
layer of every chunk can be fetched through any of the cooperating users. We
formulate the problem of finding the optimal quality decisions and fetching
policy of the SVC layers of video chunks subject to the available bandwidth,
chunk deadlines, and cooperation willingness of the different users as an
optimization problem. The objective is to optimize a QoE metric that maintains
a trade-off between maximizing the playback rate of every chunk while ensuring
fairness among all chunks for the minimum skip/stall duration without violating
any of the imposed constraints. We propose an offline algorithm to solve the
non-convex optimization problem when the bandwidth prediction is non-causally
known. This algorithm has a run-time complexity that is polynomial in the video
length and the number of cooperating users. Furthermore, we propose an online
version of the algorithm for more practical scenarios where erroneous bandwidth
prediction for a short window is used. Real implementation with android devices
using SVC encoded video on public bandwidth traces' dataset reveals the
robustness and performance of the proposed algorithm and shows that the
algorithm significantly outperforms round robin based mechanisms in terms of
avoiding skips/stalls and fetching video chunks at their highest quality
possible.
"
1788,"Older Adults and Crowdsourcing: Android TV App for Evaluating TEDx
  Subtitle Quality","  In this paper we describe the insights from an exploratory qualitative pilot
study testing the feasibility of a solution that would encourage older adults
to participate in online crowdsourcing tasks in a non-computer scenario.
Therefore, we developed an Android TV application using Amara API to retrieve
subtitles for TEDx talks which allows the participants to detect and categorize
errors to support the quality of the translation and transcription processes.
It relies on the older adults' innate skills as long-time native language users
and the motivating factors of this socially and personally beneficial task. The
study allowed us to verify the underlying concept of using Smart TVs as
interfaces for crowdsourcing, as well as possible barriers, including the
interface, configuration issues, topics and the process itself. We have also
assessed the older adults' interaction and engagement with this TV-enabled
online crowdsourcing task and we are convinced that the design of our setup
addresses some key barriers to crowdsourcing by older adults. It also validates
avenues for further research in this area focused on such considerations as
autonomy and freedom of choice, familiarity, physical and cognitive comfort as
well as building confidence and the edutainment value.
"
1789,SVS-JOIN: Efficient Spatial Visual Similarity Join over Multimedia Data,"  In the big data era, massive amount of multimedia data with geo-tags has been
generated and collected by mobile smart devices equipped with mobile
communications module and position sensor module. This trend has put forward
higher request on large-scale of geo-multimedia data retrieval. Spatial
similarity join is one of the important problem in the area of spatial
database. Previous works focused on textual document with geo-tags, rather than
geo-multimedia data such as geo-images. In this paper, we study a novel search
problem named spatial visual similarity join (SVS-JOIN for short), which aims
to find similar geo-image pairs in both the aspects of geo-location and visual
content. We propose the definition of SVS-JOIN at the first time and present
how to measure geographical similarity and visual similarity. Then we introduce
a baseline inspired by the method for textual similarity join and a extension
named SVS-JOIN$_G$ which applies spatial grid strategy to improve the
efficiency. To further improve the performance of search, we develop a novel
approach called SVS-JOIN$_Q$ which utilizes a quadtree and a global inverted
index. Experimental evaluations on real geo-image datasets demonstrate that our
solution has a really high performance.
"
1790,Fusion Hashing: A General Framework for Self-improvement of Hashing,"  Hashing has been widely used for efficient similarity search based on its
query and storage efficiency. To obtain better precision, most studies focus on
designing different objective functions with different constraints or penalty
terms that consider neighborhood information. In this paper, in contrast to
existing hashing methods, we propose a novel generalized framework called
fusion hashing (FH) to improve the precision of existing hashing methods
without adding new constraints or penalty terms. In the proposed FH, given an
existing hashing method, we first execute it several times to get several
different hash codes for a set of training samples. We then propose two novel
fusion strategies that combine these different hash codes into one set of final
hash codes. Based on the final hash codes, we learn a simple linear hash
function for the samples that can significantly improve model precision. In
general, the proposed FH can be adopted in existing hashing method and achieve
more precise and stable performance compared to the original hashing method
with little extra expenditure in terms of time and space. Extensive experiments
were performed based on three benchmark datasets and the results demonstrate
the superior performance of the proposed framework
"
1791,A Lightweight Music Texture Transfer System,"  Deep learning researches on the transformation problems for image and text
have raised great attention. However, present methods for music feature
transfer using neural networks are far from practical application. In this
paper, we initiate a novel system for transferring the texture of music, and
release it as an open source project. Its core algorithm is composed of a
converter which represents sounds as texture spectra, a corresponding
reconstructor and a feed-forward transfer network. We evaluate this system from
multiple perspectives, and experimental results reveal that it achieves
convincing results in both sound effects and computational performance.
"
1792,Diversifying Music Recommendations,"  We compare submodular and Jaccard methods to diversify Amazon Music
recommendations. Submodularity significantly improves recommendation quality
and user engagement. Unlike the Jaccard method, our submodular approach
incorporates item relevance score within its optimization function, and
produces a relevant and uniformly diverse set.
"
1793,"An Analysis of Approaches Taken in the ACM RecSys Challenge 2018 for
  Automatic Music Playlist Continuation","  The ACM Recommender Systems Challenge 2018 focused on the task of automatic
music playlist continuation, which is a form of the more general task of
sequential recommendation. Given a playlist of arbitrary length with some
additional meta-data, the task was to recommend up to 500 tracks that fit the
target characteristics of the original playlist. For the RecSys Challenge,
Spotify released a dataset of one million user-generated playlists.
Participants could compete in two tracks, i.e., main and creative tracks.
Participants in the main track were only allowed to use the provided training
set, however, in the creative track, the use of external public sources was
permitted. In total, 113 teams submitted 1,228 runs to the main track; 33 teams
submitted 239 runs to the creative track. The highest performing team in the
main track achieved an R-precision of 0.2241, an NDCG of 0.3946, and an average
number of recommended songs clicks of 1.784. In the creative track, an
R-precision of 0.2233, an NDCG of 0.3939, and a click rate of 1.785 was
obtained by the best team. This article provides an overview of the challenge,
including motivation, task definition, dataset description, and evaluation. We
further report and analyze the results obtained by the top performing teams in
each track and explore the approaches taken by the winners. We finally
summarize our key findings, discuss generalizability of approaches and results
to domains other than music, and list the open avenues and possible future
directions in the area of automatic playlist continuation.
"
1794,Rethinking Recurrent Latent Variable Model for Music Composition,"  We present a model for capturing musical features and creating novel
sequences of music, called the Convolutional Variational Recurrent Neural
Network. To generate sequential data, the model uses an encoder-decoder
architecture with latent probabilistic connections to capture the hidden
structure of music. Using the sequence-to-sequence model, our generative model
can exploit samples from a prior distribution and generate a longer sequence of
music. We compare the performance of our proposed model with other types of
Neural Networks using the criteria of Information Rate that is implemented by
Variable Markov Oracle, a method that allows statistical characterization of
musical information dynamics and detection of motifs in a song. Our results
suggest that the proposed model has a better statistical resemblance to the
musical structure of the training data, which improves the creation of new
sequences of music in the style of the originals.
"
1795,Deep LDA Hashing,"  The conventional supervised hashing methods based on classification do not
entirely meet the requirements of hashing technique, but Linear Discriminant
Analysis (LDA) does. In this paper, we propose to perform a revised LDA
objective over deep networks to learn efficient hashing codes in a truly
end-to-end fashion. However, the complicated eigenvalue decomposition within
each mini-batch in every epoch has to be faced with when simply optimizing the
deep network w.r.t. the LDA objective. In this work, the revised LDA objective
is transformed into a simple least square problem, which naturally overcomes
the intractable problems and can be easily solved by the off-the-shelf
optimizer. Such deep extension can also overcome the weakness of LDA Hashing in
the limited linear projection and feature learning. Amounts of experiments are
conducted on three benchmark datasets. The proposed Deep LDA Hashing shows
nearly 70 points improvement over the conventional one on the CIFAR-10 dataset.
It also beats several state-of-the-art methods on various metrics.
"
1796,Dense Multimodal Fusion for Hierarchically Joint Representation,"  Multiple modalities can provide more valuable information than single one by
describing the same contents in various ways. Hence, it is highly expected to
learn effective joint representation by fusing the features of different
modalities. However, previous methods mainly focus on fusing the shallow
features or high-level representations generated by unimodal deep networks,
which only capture part of the hierarchical correlations across modalities. In
this paper, we propose to densely integrate the representations by greedily
stacking multiple shared layers between different modality-specific networks,
which is named as Dense Multimodal Fusion (DMF). The joint representations in
different shared layers can capture the correlations in different levels, and
the connection between shared layers also provides an efficient way to learn
the dependence among hierarchical correlations. These two properties jointly
contribute to the multiple learning paths in DMF, which results in faster
convergence, lower training loss, and better performance. We evaluate our model
on three typical multimodal learning tasks, including audiovisual speech
recognition, cross-modal retrieval, and multimodal classification. The
noticeable performance in the experiments demonstrates that our model can learn
more effective joint representation.
"
1797,3D Holoscopic Imaging for Cultural Heritage Digitalisation,"  The growing interest in archaeology has enabled the discovery of an immense
number of cultural heritage assets and historical sites. Hence, preservation of
CH through digitalisation is becoming a primordial requirement for many
countries as a part of national cultural programs. However, CH digitalisation
is still posing serious challenges such as cost and time-consumption. In this
manuscript, 3D holoscopic (H3D) technology is applied to capture small sized CH
assets. The H3D camera utilises micro lens array within a single aperture lens
and typical 2D sensor to acquire 3D information. This technology allows 3D
autostereoscopic visualisation with full motion parallax if convenient
Microlens Array (MLA)is used on the display side. Experimental works have shown
easiness and simplicity of H3D acquisition compared to existing technologies.
In fact, H3D capture process took an equal time of shooting a standard 2D
image. These advantages qualify H3D technology to be cost effective and
time-saving technology for cultural heritage 3D digitisation.
"
1798,"Local Frequency Interpretation and Non-Local Self-Similarity on Graph
  for Point Cloud Inpainting","  As 3D scanning devices and depth sensors mature, point clouds have attracted
increasing attention as a format for 3D object representation, with
applications in various fields such as tele-presence, navigation and heritage
reconstruction. However, point clouds usually exhibit holes of missing data,
mainly due to the limitation of acquisition techniques and complicated
structure. Further, point clouds are defined on irregular non-Euclidean
domains, which is challenging to address especially with conventional signal
processing tools. Hence, leveraging on recent advances in graph signal
processing, we propose an efficient point cloud inpainting method, exploiting
both the local smoothness and the non-local self-similarity in point clouds.
Specifically, we first propose a frequency interpretation in graph nodal
domain, based on which we introduce the local graph-signal smoothness prior in
order to describe the local smoothness of point clouds. Secondly, we explore
the characteristics of non-local self-similarity, by globally searching for the
most similar area to the missing region. The similarity metric between two
areas is defined based on the direct component and the anisotropic graph total
variation of normals in each area. Finally, we formulate the hole-filling step
as an optimization problem based on the selected most similar area and
regularized by the graph-signal smoothness prior. Besides, we propose
voxelization and automatic hole detection methods for the point cloud prior to
inpainting. Experimental results show that the proposed approach outperforms
four competing methods significantly, both in objective and subjective quality.
"
1799,V3C - a Research Video Collection,"  With the widespread use of smartphones as recording devices and the massive
growth in bandwidth, the number and volume of video collections has increased
significantly in the last years. This poses novel challenges to the management
of these large-scale video data and especially to the analysis of and retrieval
from such video collections. At the same time, existing video datasets used for
research and experimentation are either not large enough to represent current
collections or do not reflect the properties of video commonly found on the
Internet in terms of content, length, or resolution. In this paper, we
introduce the Vimeo Creative Commons Collection, in short V3C, a collection of
28'450 videos (with overall length of about 3'800 hours) published under
creative commons license on Vimeo. V3C comes with a shot segmentation for each
video, together with the resulting keyframes in original as well as reduced
resolution and additional metadata. It is intended to be used from 2019 at the
International large-scale TREC Video Retrieval Evaluation campaign (TRECVid).
"
1800,"Inferring User Gender from User Generated Visual Content on a Deep
  Semantic Space","  In this paper we address the task of gender classification on picture sharing
social media networks such as Instagram and Flickr. We aim to infer the gender
of an user given only a small set of the images shared in its profile. We make
the assumption that user's images contain a collection of visual elements that
implicitly encode discriminative patterns that allow inferring its gender, in a
language independent way. This information can then be used in personalisation
and recommendation. Our main hypothesis is that semantic visual features are
more adequate for discriminating high-level classes.
  The gender detection task is formalised as: given an user's profile,
represented as a bag of images, we want to infer the gender of the user. Social
media profiles can be noisy and contain confounding factors, therefore we
classify bags of user-profile's images to provide a more robust prediction.
Experiments using a dataset from the picture sharing social network Instagram
show that the use of multiple images is key to improve detection performance.
Moreover, we verify that deep semantic features are more suited for gender
detection than low-level image representations. The methods proposed can infer
the gender with precision scores higher than 0.825, and the best performing
method achieving 0.911 precision.
"
1801,Temporal Cross-Media Retrieval with Soft-Smoothing,"  Multimedia information have strong temporal correlations that shape the way
modalities co-occur over time. In this paper we study the dynamic nature of
multimedia and social-media information, where the temporal dimension emerges
as a strong source of evidence for learning the temporal correlations across
visual and textual modalities. So far, cross-media retrieval models, explored
the correlations between different modalities (e.g. text and image) to learn a
common subspace, in which semantically similar instances lie in the same
neighbourhood. Building on such knowledge, we propose a novel temporal
cross-media neural architecture, that departs from standard cross-media
methods, by explicitly accounting for the temporal dimension through temporal
subspace learning. The model is softly-constrained with temporal and
inter-modality constraints that guide the new subspace learning task by
favouring temporal correlations between semantically similar and temporally
close instances. Experiments on three distinct datasets show that accounting
for time turns out to be important for cross-media retrieval. Namely, the
proposed method outperforms a set of baselines on the task of temporal
cross-media retrieval, demonstrating its effectiveness for performing temporal
subspace learning.
"
1802,"Combined Image Encryption and Steganography Algorithm in the Spatial
  Domain","  In recent years, steganography has emerged as one of the main research areas
in information security. Least significant bit (LSB) steganography is one of
the fundamental and conventional spatial domain methods, which is capable of
hiding larger secret information in a cover image without noticeable visual
distortions. In this paper, a combined algorithm based on LSB steganography and
chaotic encryption is proposed. Experimental results show the feasibility of
the proposed method. In comparison with existing steganographic spatial domain
based algorithms, the suggested algorithm is shown to have some advantages over
existing ones, namely, larger key space and a higher level of security against
some existing attacks.
"
1803,Efficient Multi-level Correlating for Visual Tracking,"  Correlation filter (CF) based tracking algorithms have demonstrated favorable
performance recently. Nevertheless, the top performance trackers always employ
complicated optimization methods which constraint their real-time applications.
How to accelerate the tracking speed while retaining the tracking accuracy is a
significant issue. In this paper, we propose a multi-level CF-based tracking
approach named MLCFT which further explores the potential capacity of CF with
two-stage detection: primal detection and oriented re-detection. The cascaded
detection scheme is simple but competent to prevent model drift and accelerate
the speed. An effective fusion method based on relative entropy is introduced
to combine the complementary features extracted from deep and shallow layers of
convolutional neural networks (CNN). Moreover, a novel online model update
strategy is utilized in our tracker, which enhances the tracking performance
further. Experimental results demonstrate that our proposed approach
outperforms the most state-of-the-art trackers while tracking at speed of
exceeded 16 frames per second on challenging benchmarks.
"
1804,"CNN-VWII: An Efficient Approach for Large-Scale Video Retrieval by Image
  Queries","  This paper aims to solve the problem of large-scale video retrieval by a
query image. Firstly, we define the problem of top-$k$ image to video query.
Then, we combine the merits of convolutional neural networks(CNN for short) and
Bag of Visual Word(BoVW for short) module to design a model for video frames
information extraction and representation. In order to meet the requirements of
large-scale video retrieval, we proposed a visual weighted inverted index(VWII
for short) and related algorithm to improve the efficiency and accuracy of
retrieval process. Comprehensive experiments show that our proposed technique
achieves substantial improvements (up to an order of magnitude speed up) over
the state-of-the-art techniques with similar accuracy.
"
1805,"The Focus-Aspect-Polarity Model for Predicting Subjective Noun
  Attributes in Images","  Subjective visual interpretation is a challenging yet important topic in
computer vision. Many approaches reduce this problem to the prediction of
adjective- or attribute-labels from images. However, most of these do not take
attribute semantics into account, or only process the image in a holistic
manner. Furthermore, there is a lack of relevant datasets with fine-grained
subjective labels. In this paper, we propose the Focus-Aspect-Polarity model to
structure the process of capturing subjectivity in image processing, and
introduce a novel dataset following this way of modeling. We run experiments on
this dataset to compare several deep learning methods and find that
incorporating context information based on tensor multiplication in several
cases outperforms the default way of information fusion (concatenation).
"
1806,"UnrealROX: An eXtremely Photorealistic Virtual Reality Environment for
  Robotics Simulations and Synthetic Data Generation","  Data-driven algorithms have surpassed traditional techniques in almost every
aspect in robotic vision problems. Such algorithms need vast amounts of quality
data to be able to work properly after their training process. Gathering and
annotating that sheer amount of data in the real world is a time-consuming and
error-prone task. Those problems limit scale and quality. Synthetic data
generation has become increasingly popular since it is faster to generate and
automatic to annotate. However, most of the current datasets and environments
lack realism, interactions, and details from the real world. UnrealROX is an
environment built over Unreal Engine 4 which aims to reduce that reality gap by
leveraging hyperrealistic indoor scenes that are explored by robot agents which
also interact with objects in a visually realistic manner in that simulated
world. Photorealistic scenes and robots are rendered by Unreal Engine into a
virtual reality headset which captures gaze so that a human operator can move
the robot and use controllers for the robotic hands; scene information is
dumped on a per-frame basis so that it can be reproduced offline to generate
raw data and ground truth annotations. This virtual reality environment enables
robotic vision researchers to generate realistic and visually plausible data
with full ground truth for a wide variety of problems such as class and
instance semantic segmentation, object detection, depth estimation, visual
grasping, and navigation.
"
1807,ReDMark: Framework for Residual Diffusion Watermarking on Deep Networks,"  Due to the rapid growth of machine learning tools and specifically deep
networks in various computer vision and image processing areas, application of
Convolutional Neural Networks for watermarking have recently emerged. In this
paper, we propose a deep end-to-end diffusion watermarking framework (ReDMark)
which can be adapted for any desired transform space. The framework is composed
of two Fully Convolutional Neural Networks with the residual structure for
embedding and extraction. The whole deep network is trained end-to-end to
conduct a blind secure watermarking. The framework is customizable for the
level of robustness vs. imperceptibility. It is also adjustable for the
trade-off between capacity and robustness. The proposed framework simulates
various attacks as a differentiable network layer to facilitate end-to-end
training. For JPEG attack, a differentiable approximation is utilized, which
drastically improves the watermarking robustness to this attack. Another
important characteristic of the proposed framework, which leads to improved
security and robustness, is its capability to diffuse watermark information
among a relatively wide area of the image. Comparative results versus recent
state-of-the-art researches highlight the superiority of the proposed framework
in terms of imperceptibility and robustness.
"
1808,"Domain Adaptation for Semantic Segmentation via Class-Balanced
  Self-Training","  Recent deep networks achieved state of the art performance on a variety of
semantic segmentation tasks. Despite such progress, these models often face
challenges in real world `wild tasks' where large difference between labeled
training/source data and unseen test/target data exists. In particular, such
difference is often referred to as `domain gap', and could cause significantly
decreased performance which cannot be easily remedied by further increasing the
representation power. Unsupervised domain adaptation (UDA) seeks to overcome
such problem without target domain labels. In this paper, we propose a novel
UDA framework based on an iterative self-training procedure, where the problem
is formulated as latent variable loss minimization, and can be solved by
alternatively generating pseudo labels on target data and re-training the model
with these labels. On top of self-training, we also propose a novel
class-balanced self-training framework to avoid the gradual dominance of large
classes on pseudo-label generation, and introduce spatial priors to refine
generated labels. Comprehensive experiments show that the proposed methods
achieve state of the art semantic segmentation performance under multiple major
UDA settings.
"
1809,"Exploiting High-Level Semantics for No-Reference Image Quality
  Assessment of Realistic Blur Images","  To guarantee a satisfying Quality of Experience (QoE) for consumers, it is
required to measure image quality efficiently and reliably. The neglect of the
high-level semantic information may result in predicting a clear blue sky as
bad quality, which is inconsistent with human perception. Therefore, in this
paper, we tackle this problem by exploiting the high-level semantics and
propose a novel no-reference image quality assessment method for realistic blur
images. Firstly, the whole image is divided into multiple overlapping patches.
Secondly, each patch is represented by the high-level feature extracted from
the pre-trained deep convolutional neural network model. Thirdly, three
different kinds of statistical structures are adopted to aggregate the
information from different patches, which mainly contain some common statistics
(i.e., the mean\&standard deviation, quantiles and moments). Finally, the
aggregated features are fed into a linear regression model to predict the image
quality. Experiments show that, compared with low-level features, high-level
features indeed play a more critical role in resolving the aforementioned
challenging problem for quality estimation. Besides, the proposed method
significantly outperforms the state-of-the-art methods on two realistic blur
image databases and achieves comparable performance on two synthetic blur image
databases.
"
1810,"Quality Assessment for Tone-Mapped HDR Images Using Multi-Scale and
  Multi-Layer Information","  Tone mapping operators and multi-exposure fusion methods allow us to enjoy
the informative contents of high dynamic range (HDR) images with standard
dynamic range devices, but also introduce distortions into HDR contents.
Therefore methods are needed to evaluate tone-mapped image quality. Due to the
complexity of possible distortions in a tone-mapped image, information from
different scales and different levels should be considered when predicting
tone-mapped image quality. So we propose a new no-reference method of
tone-mapped image quality assessment based on multi-scale and multi-layer
features that are extracted from a pre-trained deep convolutional neural
network model. After being aggregated, the extracted features are mapped to
quality predictions by regression. The proposed method is tested on the largest
public database for TMIQA and compared to existing no-reference methods. The
experimental results show that the proposed method achieves better performance.
"
1811,"Investigation of Monaural Front-End Processing for Robust ASR without
  Retraining or Joint-Training","  In recent years, monaural speech separation has been formulated as a
supervised learning problem, which has been systematically researched and shown
the dramatical improvement of speech intelligibility and quality for human
listeners. However, it has not been well investigated whether the methods can
be employed as the front-end processing and directly improve the performance of
a machine listener, i.e., an automatic speech recognizer, without retraining or
joint-training the acoustic model. In this paper, we explore the effectiveness
of the independent front-end processing for the multi-conditional trained ASR
on the CHiME-3 challenge. We find that directly feeding the enhanced features
to ASR can make 36.40% and 11.78% relative WER reduction for the GMM-based and
DNN-based ASR respectively. We also investigate the affect of noisy phase and
generalization ability under unmatched noise condition.
"
1812,"Hierarchy-Dependent Cross-Platform Multi-View Feature Learning for Venue
  Category Prediction","  In this work, we focus on visual venue category prediction, which can
facilitate various applications for location-based service and personalization.
Considering that the complementarity of different media platforms, it is
reasonable to leverage venue-relevant media data from different platforms to
boost the prediction performance. Intuitively, recognizing one venue category
involves multiple semantic cues, especially objects and scenes, and thus they
should contribute together to venue category prediction. In addition, these
venues can be organized in a natural hierarchical structure, which provides
prior knowledge to guide venue category estimation. Taking these aspects into
account, we propose a Hierarchy-dependent Cross-platform Multi-view Feature
Learning (HCM-FL) framework for venue category prediction from videos by
leveraging images from other platforms. HCM-FL includes two major components,
namely Cross-Platform Transfer Deep Learning (CPTDL) and Multi-View Feature
Learning with the Hierarchical Venue Structure (MVFL-HVS). CPTDL is capable of
reinforcing the learned deep network from videos using images from other
platforms. Specifically, CPTDL first trained a deep network using videos. These
images from other platforms are filtered by the learnt network and these
selected images are then fed into this learnt network to enhance it. Two kinds
of pre-trained networks on the ImageNet and Places dataset are employed.
MVFL-HVS is then developed to enable multi-view feature fusion. It is capable
of embedding the hierarchical structure ontology to support more discriminative
joint feature learning. We conduct the experiment on videos from Vine and
images from Foursqure. These experimental results demonstrate the advantage of
our proposed framework.
"
1813,Textually Guided Ranking Network for Attentional Image Retweet Modeling,"  Retweet prediction is a challenging problem in social media sites (SMS). In
this paper, we study the problem of image retweet prediction in social media,
which predicts the image sharing behavior that the user reposts the image
tweets from their followees. Unlike previous studies, we learn user preference
ranking model from their past retweeted image tweets in SMS. We first propose
heterogeneous image retweet modeling network (IRM) that exploits users' past
retweeted image tweets with associated contexts, their following relations in
SMS and preference of their followees. We then develop a novel attentional
multi-faceted ranking network learning framework with textually guided
multi-modal neural networks for the proposed heterogenous IRM network to learn
the joint image tweet representations and user preference representations for
prediction task. The extensive experiments on a large-scale dataset from
Twitter site shows that our method achieves better performance than other
state-of-the-art solutions to the problem.
"
1814,"Towards improved lossy image compression: Human image reconstruction
  with public-domain images","  Lossy image compression has been studied extensively in the context of
typical loss functions such as RMSE, MS-SSIM, etc. However, compression at low
bitrates generally produces unsatisfying results. Furthermore, the availability
of massive public image datasets appears to have hardly been exploited in image
compression. Here, we present a paradigm for eliciting human image
reconstruction in order to perform lossy image compression. In this paradigm,
one human describes images to a second human, whose task is to reconstruct the
target image using publicly available images and text instructions. The
resulting reconstructions are then evaluated by human raters on the Amazon
Mechanical Turk platform and compared to reconstructions obtained using
state-of-the-art compressor WebP. Our results suggest that prioritizing
semantic visual elements may be key to achieving significant improvements in
image compression, and that our paradigm can be used to develop a more
human-centric loss function.
  The images, results and additional data are available at
https://compression.stanford.edu/human-compression
"
1815,Image Super-Resolution Using TV Priori Guided Convolutional Network,"  We proposed a TV priori information guided deep learning method for single
image super-resolution(SR). The new alogorithm up-sample method based on TV
priori, new learning method and neural networks architecture are embraced in
our TV guided priori Convolutional Neural Network which diretcly learns an end
to end mapping between the low level to high level images.
"
1816,Feature Bagging for Steganographer Identification,"  Traditional steganalysis algorithms focus on detecting the existence of
steganography in a single object. In practice, one may face a complex scenario
where one or some of multiple users also called actors are guilty of using
steganography, which is defined as the steganographer identification problem
(SIP). This requires steganalysis experts to design effective and robust
detection algorithms to identify the guilty actor(s). The mainstream works use
clustering, ensemble and anomaly detection, where distances in high dimensional
space between features of actors are determined to find out the outlier(s)
corresponding to steganographer(s). However, in high dimensional space, feature
points could be sparse such that distances between feature points may become
relatively similar to each other, which cannot benefit the detection. Moreover,
it is well-known in machine learning that combining techniques such as boosting
and bagging can be effective in improving detection performance. This motivates
the authors in this paper to present a feature bagging approach to SIP. The
proposed work merges results from multiple detection sub-models, each of which
feature space is randomly sampled from the raw full dimensional space. We
create a new dataset called ImgNetEase including 5108 images downloaded from a
social website to mimic the real-world scenario. We extract PEV-274 features
from images, and take nsF5 as the steganographic algorithm for evaluation.
Experiments have shown that our work improves the detection accuracy
significantly on created dataset in most cases, which has shown the superiority
and applicability.
"
1817,Gated Transfer Network for Transfer Learning,"  Deep neural networks have led to a series of breakthroughs in computer vision
given sufficient annotated training datasets. For novel tasks with limited
labeled data, the prevalent approach is to transfer the knowledge learned in
the pre-trained models to the new tasks by fine-tuning. Classic model
fine-tuning utilizes the fact that well trained neural networks appear to learn
cross domain features. These features are treated equally during transfer
learning. In this paper, we explore the impact of feature selection in model
fine-tuning by introducing a transfer module, which assigns weights to features
extracted from pre-trained models. The proposed transfer module proves the
importance of feature selection for transferring models from source to target
domains. It is shown to significantly improve upon fine-tuning results with
only marginal extra computational cost. We also incorporate an auxiliary
classifier as an extra regularizer to avoid over-fitting. Finally, we build a
Gated Transfer Network (GTN) based on our transfer module and achieve
state-of-the-art results on six different tasks.
"
1818,Random Temporal Skipping for Multirate Video Analysis,"  Current state-of-the-art approaches to video understanding adopt temporal
jittering to simulate analyzing the video at varying frame rates. However, this
does not work well for multirate videos, in which actions or subactions occur
at different speeds. The frame sampling rate should vary in accordance with the
different motion speeds. In this work, we propose a simple yet effective
strategy, termed random temporal skipping, to address this situation. This
strategy effectively handles multirate videos by randomizing the sampling rate
during training. It is an exhaustive approach, which can potentially cover all
motion speed variations. Furthermore, due to the large temporal skipping, our
network can see video clips that originally cover over 100 frames. Such a time
range is enough to analyze most actions/events. We also introduce an
occlusion-aware optical flow learning method that generates improved motion
maps for human action recognition. Our framework is end-to-end trainable, runs
in real-time, and achieves state-of-the-art performance on six widely adopted
video benchmarks.
"
1819,"Nonlinear Prediction of Multidimensional Signals via Deep Regression
  with Applications to Image Coding","  Deep convolutional neural networks (DCNN) have enjoyed great successes in
many signal processing applications because they can learn complex, non-linear
causal relationships from input to output. In this light, DCNNs are well suited
for the task of sequential prediction of multidimensional signals, such as
images, and have the potential of improving the performance of traditional
linear predictors. In this research we investigate how far DCNNs can push the
envelop in terms of prediction precision. We propose, in a case study, a
two-stage deep regression DCNN framework for nonlinear prediction of
two-dimensional image signals. In the first-stage regression, the proposed deep
prediction network (PredNet) takes the causal context as input and emits a
prediction of the present pixel. Three PredNets are trained with the regression
objectives of minimizing $\ell_1$, $\ell_2$ and $\ell_\infty$ norms of
prediction residuals, respectively. The second-stage regression combines the
outputs of the three PredNets to generate an even more precise and robust
prediction. The proposed deep regression model is applied to lossless
predictive image coding, and it outperforms the state-of-the-art linear
predictors by appreciable margin.
"
1820,Semantic Modeling of Textual Relationships in Cross-Modal Retrieval,"  Feature modeling of different modalities is a basic problem in current
research of cross-modal information retrieval. Existing models typically
project texts and images into one embedding space, in which semantically
similar information will have a shorter distance. Semantic modeling of textural
relationships is notoriously difficult. In this paper, we propose an approach
to model texts using a featured graph by integrating multi-view textual
relationships including semantic relations, statistical co-occurrence, and
prior relations in the knowledge base. A dual-path neural network is adopted to
learn multi-modal representations of information and cross-modal similarity
measure jointly. We use a Graph Convolutional Network (GCN) for generating
relation-aware text representations, and use a Convolutional Neural Network
(CNN) with non-linearities for image representations. The cross-modal
similarity measure is learned by distance metric learning. Experimental results
show that, by leveraging the rich relational semantics in texts, our model can
outperform the state-of-the-art models by 3.4% and 6.3% on accuracy on two
benchmark datasets.
"
1821,"Modeling Melodic Feature Dependency with Modularized Variational
  Auto-Encoder","  Automatic melody generation has been a long-time aspiration for both AI
researchers and musicians. However, learning to generate euphonious melodies
has turned out to be highly challenging. This paper introduces 1) a new variant
of variational autoencoder (VAE), where the model structure is designed in a
modularized manner in order to model polyphonic and dynamic music with domain
knowledge, and 2) a hierarchical encoding/decoding strategy, which explicitly
models the dependency between melodic features. The proposed framework is
capable of generating distinct melodies that sounds natural, and the
experiments for evaluating generated music clips show that the proposed model
outperforms the baselines in human evaluation.
"
1822,"Referenceless Performance Evaluation of Audio Source Separation using
  Deep Neural Networks","  Current performance evaluation for audio source separation depends on
comparing the processed or separated signals with reference signals. Therefore,
common performance evaluation toolkits are not applicable to real-world
situations where the ground truth audio is unavailable. In this paper, we
propose a performance evaluation technique that does not require reference
signals in order to assess separation quality. The proposed technique uses a
deep neural network (DNN) to map the processed audio into its quality score.
Our experiment results show that the DNN is capable of predicting the
sources-to-artifacts ratio from the blind source separation evaluation toolkit
without the need for reference signals.
"
1823,"Listen to Dance: Music-driven choreography generation using
  Autoregressive Encoder-Decoder Network","  Automatic choreography generation is a challenging task because it often
requires an understanding of two abstract concepts - music and dance - which
are realized in the two different modalities, namely audio and video,
respectively. In this paper, we propose a music-driven choreography generation
system using an auto-regressive encoder-decoder network. To this end, we first
collect a set of multimedia clips that include both music and corresponding
dance motion. We then extract the joint coordinates of the dancer from video
and the mel-spectrogram of music from audio, and train our network using
music-choreography pairs as input. Finally, a novel dance motion is generated
at the inference time when only music is given as an input. We performed a user
study for a qualitative evaluation of the proposed method, and the results show
that the proposed model is able to generate musically meaningful and natural
dance movements given an unheard song.
"
1824,Deep Multiple Description Coding by Learning Scalar Quantization,"  In this paper, we propose a deep multiple description coding framework, whose
quantizers are adaptively learned via the minimization of multiple description
compressive loss. Firstly, our framework is built upon auto-encoder networks,
which have multiple description multi-scale dilated encoder network and
multiple description decoder networks. Secondly, two entropy estimation
networks are learned to estimate the informative amounts of the quantized
tensors, which can further supervise the learning of multiple description
encoder network to represent the input image delicately. Thirdly, a pair of
scalar quantizers accompanied by two importance-indicator maps is automatically
learned in an end-to-end self-supervised way. Finally, multiple description
structural dissimilarity distance loss is imposed on multiple description
decoded images in pixel domain for diversified multiple description generations
rather than on feature tensors in feature domain, in addition to multiple
description reconstruction loss. Through testing on two commonly used datasets,
it is verified that our method is beyond several state-of-the-art multiple
description coding approaches in terms of coding efficiency.
"
1825,Facing Device Attribution Problem for Stabilized Video Sequences,"  A problem deeply investigated by multimedia forensics researchers is the one
of detecting which device has been used to capture a video. This enables to
trace down the owner of a video sequence, which proves extremely helpful to
solve copyright infringement cases as well as to fight distribution of illicit
material (e.g., underage clips, terroristic threats, etc.). Currently, the most
promising methods to tackle this task exploit unique noise traces left by
camera sensors on acquired images. However, given the recent advancements in
motion stabilization of video content, robustness of sensor pattern noise-based
techniques are strongly hindered. Indeed, video stabilization introduces
geometric transformations between video frames, thus making camera fingerprint
estimation problematic with classical approaches. In this paper, we deal with
the challenging problem of attributing stabilized videos to their recording
device. Specifically, we propose: (i) a strategy to extract the characteristic
fingerprint of a device, starting from either a set of images or stabilized
video sequences; (ii) a strategy to match a stabilized video sequence with a
given fingerprint in order to solve the device attribution problem. The
proposed methodology is tested on videos coming from a set of different
smartphones, taken from the modern publicly available Vision Dataset. The
conducted experiments also provide an interesting insight on the effect of
modern smartphones video stabilization algorithms on specific video frames.
"
1826,Facial Landmark Detection for Manga Images,"  The topic of facial landmark detection has been widely covered for pictures
of human faces, but it is still a challenge for drawings. Indeed, the
proportions and symmetry of standard human faces are not always used for comics
or mangas. The personal style of the author, the limitation of colors, etc.
makes the landmark detection on faces in drawings a difficult task. Detecting
the landmarks on manga images will be useful to provide new services for easily
editing the character faces, estimating the character emotions, or generating
automatically some animations such as lip or eye movements.
  This paper contains two main contributions: 1) a new landmark annotation
model for manga faces, and 2) a deep learning approach to detect these
landmarks. We use the ""Deep Alignment Network"", a multi stage architecture
where the first stage makes an initial estimation which gets refined in further
stages. The first results show that the proposed method succeed to accurately
find the landmarks in more than 80% of the cases.
"
1827,Performance Comparison of Contemporary DNN Watermarking Techniques,"  DNNs shall be considered as the intellectual property (IP) of the model
builder due to the impeding cost of designing/training a highly accurate model.
Research attempts have been made to protect the authorship of the trained model
and prevent IP infringement using DNN watermarking techniques. In this paper,
we provide a comprehensive performance comparison of the state-of-the-art DNN
watermarking methodologies according to the essential requisites for an
effective watermarking technique. We identify the pros and cons of each scheme
and provide insights into the underlying rationale. Empirical results
corroborate that DeepSigns framework proposed in [4] has the best overall
performance in terms of the evaluation metrics. Our comparison facilitates the
development of pending watermarking approaches and enables the model owner to
deploy the watermarking scheme that satisfying her requirements.
"
1828,When Provably Secure Steganography Meets Generative Models,"  Steganography is the art and science of hiding secret messages in public
communication so that the presence of the secret messages cannot be detected.
There are two provably secure steganographic frameworks, one is black-box
sampling based and the other is compression based. The former requires a
perfect sampler which yields data following the same distribution, and the
latter needs explicit distributions of generative objects. However, these two
conditions are too strict even unrealistic in the traditional data environment,
because it is hard to model the explicit distribution of natural image. With
the development of deep learning, generative models bring new vitality to
provably secure steganography, which can serve as the black-box sampler or
provide the explicit distribution of generative media. Motivated by this, this
paper proposes two types of provably secure stegosystems with generative
models. Specifically, we first design block-box sampling based provably secure
stegosystem for broad generative models without explicit distribution, such as
GAN, VAE, and flow-based generative models, where the generative network can
serve as the perfect sampler. For compression based stegosystem, we leverage
the generative models with explicit distribution such as autoregressive models
instead, where the adaptive arithmetic coding plays the role of the perfect
compressor, decompressing the encrypted message bits into generative media, and
the receiver can compress the generative media into the encrypted message bits.
To show the effectiveness of our method, we take DFC-VAE, Glow, WaveNet as
instances of generative models and demonstrate the perfectly secure performance
of these stegosystems with the state-of-the-art steganalysis methods.
"
1829,ADNet: A Deep Network for Detecting Adverts,"  Online video advertising gives content providers the ability to deliver
compelling content, reach a growing audience, and generate additional revenue
from online media. Recently, advertising strategies are designed to look for
original advert(s) in a video frame, and replacing them with new adverts. These
strategies, popularly known as product placement or embedded marketing, greatly
help the marketing agencies to reach out to a wider audience. However, in the
existing literature, such detection of candidate frames in a video sequence for
the purpose of advert integration, is done manually. In this paper, we propose
a deep-learning architecture called ADNet, that automatically detects the
presence of advertisements in video frames. Our approach is the first of its
kind that automatically detects the presence of adverts in a video frame, and
achieves state-of-the-art results on a public dataset.
"
1830,"A Ginga-enabled Digital Radio Mondiale Broadcasting chain: Signaling and
  Definitions","  ISDB-T International standard is currently adopted by most Latin America
countries and is already installed in most TV sets sold in recent years in the
region. To support interactive applications in Digital TV receivers, ISDB-T
defines the middleware Ginga. Similar to Digital TV, Digital Radio standards
also provide the means to carry interactive applications; however, their
specifications for interactive applications are usually more restricted than
the ones used in Digital TV. Also, interactive applications for Digital TV and
Digital Radio are usually incompatible. Motivated by such observations, this
report considers the importance of interactive applications for both TV and
Radio Broadcasting and the advantages of using the same middleware and
languages specification for Digital TV and Radio. More specifically, it
establishes the signaling and definitions on how to transport and execute
Ginga-NCL and Ginga-HTML5 applications over DRM (Digital Radio Mondiale)
transmission. Ministry of Science, Technology, Innovation and Communication of
Brazil is carrying trials with Digital Radio Mondiale standard in order to
define the reference model of the Brazilian Digital Radio System (Portuguese:
Sistema Brasileiro de R\'adio Digital - SBRD).
"
1831,"PerformanceNet: Score-to-Audio Music Generation with Multi-Band
  Convolutional Residual Network","  Music creation is typically composed of two parts: composing the musical
score, and then performing the score with instruments to make sounds. While
recent work has made much progress in automatic music generation in the
symbolic domain, few attempts have been made to build an AI model that can
render realistic music audio from musical scores. Directly synthesizing audio
with sound sample libraries often leads to mechanical and deadpan results,
since musical scores do not contain performance-level information, such as
subtle changes in timing and dynamics. Moreover, while the task may sound like
a text-to-speech synthesis problem, there are fundamental differences since
music audio has rich polyphonic sounds. To build such an AI performer, we
propose in this paper a deep convolutional model that learns in an end-to-end
manner the score-to-audio mapping between a symbolic representation of music
called the piano rolls and an audio representation of music called the
spectrograms. The model consists of two subnets: the ContourNet, which uses a
U-Net structure to learn the correspondence between piano rolls and
spectrograms and to give an initial result; and the TextureNet, which further
uses a multi-band residual network to refine the result by adding the spectral
texture of overtones and timbre. We train the model to generate music clips of
the violin, cello, and flute, with a dataset of moderate size. We also present
the result of a user study that shows our model achieves higher mean opinion
score (MOS) in naturalness and emotional expressivity than a WaveNet-based
model and two commercial sound libraries. We open our source code at
https://github.com/bwang514/PerformanceNet
"
1832,"Multi-Temporal Resolution Convolutional Neural Networks for Acoustic
  Scene Classification","  In this paper we present a Deep Neural Network architecture for the task of
acoustic scene classification which harnesses information from increasing
temporal resolutions of Mel-Spectrogram segments. This architecture is composed
of separated parallel Convolutional Neural Networks which learn spectral and
temporal representations for each input resolution. The resolutions are chosen
to cover fine-grained characteristics of a scene's spectral texture as well as
its distribution of acoustic events. The proposed model shows a 3.56% absolute
improvement of the best performing single resolution model and 12.49% of the
DCASE 2017 Acoustic Scenes Classification task baseline.
"
1833,Spherical clustering of users navigating 360{\deg} content,"  In Virtual Reality (VR) applications, understanding how users explore the
omnidirectional content is important to optimize content creation, to develop
user-centric services, or even to detect disorders in medical applications.
Clustering users based on their common navigation patterns is a first direction
to understand users behaviour. However, classical clustering techniques fail in
identifying these common paths, since they are usually focused on minimizing a
simple distance metric. In this paper, we argue that minimizing the distance
metric does not necessarily guarantee to identify users that experience similar
navigation path in the VR domain. Therefore, we propose a graph-based method to
identify clusters of users who are attending the same portion of the spherical
content over time. The proposed solution takes into account the spherical
geometry of the content and aims at clustering users based on the actual
overlap of displayed content among users. Our method is tested on real VR user
navigation patterns. Results show that our solution leads to clusters in which
at least 85% of the content displayed by one user is shared among the other
users belonging to the same cluster.
"
1834,Neural Wavetable: a playable wavetable synthesizer using neural networks,"  We present Neural Wavetable, a proof-of-concept wavetable synthesizer that
uses neural networks to generate playable wavetables. The system can produce
new, distinct waveforms through the interpolation of traditional wavetables in
an autoencoder's latent space. It is available as a VST/AU plugin for use in a
Digital Audio Workstation.
"
1835,"A Multimodal Approach towards Emotion Recognition of Music using Audio
  and Lyrical Content","  We propose MoodNet - A Deep Convolutional Neural Network based architecture
to effectively predict the emotion associated with a piece of music given its
audio and lyrical content.We evaluate different architectures consisting of
varying number of two-dimensional convolutional and subsampling layers,followed
by dense layers.We use Mel-Spectrograms to represent the audio content and word
embeddings-specifically 100 dimensional word vectors, to represent the textual
content represented by the lyrics.We feed input data from both modalities to
our MoodNet architecture.The output from both the modalities are then fused as
a fully connected layer and softmax classfier is used to predict the category
of emotion.Using F1-score as our metric,our results show excellent performance
of MoodNet over the two datasets we experimented on-The MIREX Multimodal
dataset and the Million Song Dataset.Our experiments reflect the hypothesis
that more complex models perform better with more training data.We also observe
that lyrics outperform audio as a better expressed modality and conclude that
combining and using features from multiple modalities for prediction tasks
result in superior performance in comparison to using a single modality as
input.
"
1836,"Tiyuntsong: A Self-Play Reinforcement Learning Approach for ABR Video
  Streaming","  Existing reinforcement learning~(RL)-based adaptive bitrate~(ABR) approaches
outperform the previous fixed control rules based methods by improving the
Quality of Experience~(QoE) score, as the QoE metric can hardly provide clear
guidance for optimization, finally resulting in the unexpected strategies. In
this paper, we propose \emph{Tiyuntsong}, a self-play reinforcement learning
approach with generative adversarial network~(GAN)-based method for ABR video
streaming. Tiyuntsong learns strategies automatically by training two agents
who are competing against each other. Note that the competition results are
determined by a set of rules rather than a numerical QoE score that allows
clearer optimization objectives. Meanwhile, we propose GAN Enhancement Module
to extract hidden features from the past status for preserving the information
without the limitations of sequence lengths. Using testbed experiments, we show
that the utilization of GAN significantly improves the Tiyuntsong's
performance. By comparing the performance of ABRs, we observe that Tiyuntsong
also betters existing ABR algorithms in the underlying metrics.
"
1837,Motion Style Extraction Based on Sparse Coding Decomposition,"  We present a sparse coding-based framework for motion style decomposition and
synthesis. Dynamic Time Warping is firstly used to synchronized input motions
in the time domain as a pre-processing step. A sparse coding-based
decomposition has been proposed, we also introduce the idea of core component
and basic motion. Decomposed motions are then combined, transfer to synthesize
new motions. Lastly, we develop limb length constraint as a post-processing
step to remove distortion skeletons. Our framework has the advantage of less
time-consuming, no manual alignment and large dataset requirement. As a result,
our experiments show smooth and natural synthesized motion.
"
1838,"Content-Aware Personalised Rate Adaptation for Adaptive Streaming via
  Deep Video Analysis","  Adaptive bitrate (ABR) streaming is the de facto solution for achieving
smooth viewing experiences under unstable network conditions. However, most of
the existing rate adaptation approaches for ABR are content-agnostic, without
considering the semantic information of the video content. Nevertheless,
semantic information largely determines the informativeness and interestingness
of the video content, and consequently affects the QoE for video streaming. One
common case is that the user may expect higher quality for the parts of video
content that are more interesting or informative so as to reduce video
distortion and information loss, given that the overall bitrate budgets are
limited. This creates two main challenges for such a problem: First, how to
determine which parts of the video content are more interesting? Second, how to
allocate bitrate budgets for different parts of the video content with
different significances? To address these challenges, we propose a
Content-of-Interest (CoI) based rate adaptation scheme for ABR. We first design
a deep learning approach for recognizing the interestingness of the video
content, and then design a Deep Q-Network (DQN) approach for rate adaptation by
incorporating video interestingness information. The experimental results show
that our method can recognize video interestingness precisely, and the bitrate
allocation for ABR can be aligned with the interestingness of video content
while not compromising the performances on objective QoE metrics.
"
1839,"PerSIM: Multi-resolution Image Quality Assessment in the Perceptually
  Uniform Color Domain","  An average observer perceives the world in color instead of black and white.
Moreover, the visual system focuses on structures and segments instead of
individual pixels. Based on these observations, we propose a full reference
objective image quality metric modeling visual system characteristics and
chroma similarity in the perceptually uniform color domain (Lab). Laplacian of
Gaussian features are obtained in the L channel to model the retinal ganglion
cells in human visual system and color similarity is calculated over the a and
b channels. In the proposed perceptual similarity index (PerSIM), a
multi-resolution approach is followed to mimic the hierarchical nature of human
visual system. LIVE and TID2013 databases are used in the validation and PerSIM
outperforms all the compared metrics in the overall databases in terms of
ranking, monotonic behavior and linearity.
"
1840,"Visual-Texual Emotion Analysis with Deep Coupled Video and Danmu Neural
  Networks","  User emotion analysis toward videos is to automatically recognize the general
emotional status of viewers from the multimedia content embedded in the online
video stream. Existing works fall in two categories: 1) visual-based methods,
which focus on visual content and extract a specific set of features of videos.
However, it is generally hard to learn a mapping function from low-level video
pixels to high-level emotion space due to great intra-class variance. 2)
textual-based methods, which focus on the investigation of user-generated
comments associated with videos. The learned word representations by
traditional linguistic approaches typically lack emotion information and the
global comments usually reflect viewers' high-level understandings rather than
instantaneous emotions. To address these limitations, in this paper, we propose
to jointly utilize video content and user-generated texts simultaneously for
emotion analysis. In particular, we introduce exploiting a new type of
user-generated texts, i.e., ""danmu"", which are real-time comments floating on
the video and contain rich information to convey viewers' emotional opinions.
To enhance the emotion discriminativeness of words in textual feature
extraction, we propose Emotional Word Embedding (EWE) to learn text
representations by jointly considering their semantics and emotions.
Afterwards, we propose a novel visual-textual emotion analysis model with Deep
Coupled Video and Danmu Neural networks (DCVDN), in which visual and textual
features are synchronously extracted and fused to form a comprehensive
representation by deep-canonically-correlated-autoencoder-based multi-view
learning. Through extensive experiments on a self-crawled real-world
video-danmu dataset, we prove that DCVDN significantly outperforms the
state-of-the-art baselines.
"
1841,A Comparative Study of Computational Aesthetics,"  Objective metrics model image quality by quantifying image degradations or
estimating perceived image quality. However, image quality metrics do not model
what makes an image more appealing or beautiful. In order to quantify the
aesthetics of an image, we need to take it one step further and model the
perception of aesthetics. In this paper, we examine computational aesthetics
models that use hand-crafted, generic and hybrid descriptors. We show that
generic descriptors can perform as well as state of the art hand-crafted
aesthetics models that use global features. However, neither generic nor
hand-crafted features is sufficient to model aesthetics when we only use global
features without considering spatial composition or distribution. We also
follow a visual dictionary approach similar to state of the art methods and
show that it performs poorly without the spatial pyramid step.
"
1842,"A Baseline for Multi-Label Image Classification Using An Ensemble of
  Deep Convolutional Neural Networks","  Recent studies on multi-label image classification have focused on designing
more complex architectures of deep neural networks such as the use of attention
mechanisms and region proposal networks. Although performance gains have been
reported, the backbone deep models of the proposed approaches and the
evaluation metrics employed in different works vary, making it difficult to
compare each fairly. Moreover, due to the lack of properly investigated
baselines, the advantage introduced by the proposed techniques are often
ambiguous. To address these issues, we make a thorough investigation of the
mainstream deep convolutional neural network architectures for multi-label
image classification and present a strong baseline. With the use of proper data
augmentation techniques and model ensembles, the basic deep architectures can
achieve better performance than many existing more complex ones on three
benchmark datasets, providing great insight for the future studies on
multi-label image classification.
"
1843,Boosting in Image Quality Assessment,"  In this paper, we analyze the effect of boosting in image quality assessment
through multi-method fusion. Existing multi-method studies focus on proposing a
single quality estimator. On the contrary, we investigate the generalizability
of multi-method fusion as a framework. In addition to support vector machines
that are commonly used in the multi-method fusion, we propose using neural
networks in the boosting. To span different types of image quality assessment
algorithms, we use quality estimators based on fidelity, perceptually-extended
fidelity, structural similarity, spectral similarity, color, and learning. In
the experiments, we perform k-fold cross validation using the LIVE, the
multiply distorted LIVE, and the TID 2013 databases and the performance of
image quality assessment algorithms are measured via accuracy-, linearity-, and
ranking-based metrics. Based on the experiments, we show that boosting methods
generally improve the performance of image quality assessment and the level of
improvement depends on the type of the boosting algorithm. Our experimental
results also indicate that boosting the worst performing quality estimator with
two or more additional methods leads to statistically significant performance
enhancements independent of the boosting technique and neural network-based
boosting outperforms support vector machine-based boosting when two or more
methods are fused.
"
1844,Effectiveness of 3VQM in Capturing Depth Inconsistencies,"  The 3D video quality metric (3VQM) was proposed to evaluate the temporal and
spatial variation of the depth errors for the depth values that would lead to
inconsistencies between left and right views, fast changing disparities, and
geometric distortions. Previously, we evaluated 3VQM against subjective scores.
In this paper, we show the effectiveness of 3VQM in capturing errors and
inconsistencies that exist in the rendered depth-based 3D videos. We further
investigate how 3VQM could measure excessive disparities, fast changing
disparities, geometric distortions, temporal flickering and/or spatial noise in
the form of depth cues inconsistency. Results show that 3VQM best captures the
depth inconsistencies based on errors in the reference views. However, the
metric is not sensitive to depth map mild errors such as those resulting from
blur. We also performed a subjective quality test and showed that 3VQM performs
better than PSNR, weighted PSNR and SSIM in terms of accuracy, coherency and
consistency.
"
1845,Coding of 3D Videos Based on Visual Discomfort,"  We propose a rate-distortion optimization method for 3D videos based on
visual discomfort estimation. We calculate visual discomfort in the encoded
depth maps using two indexes: temporal outliers (TO) and spatial outliers (SO).
These two indexes are used to measure the difference between the processed
depth map and the ground truth depth map. These indexes implicitly depend on
the amount of edge information within a frame and on the amount of motion
between frames. Moreover, we fuse these indexes considering the temporal and
spatial complexities of the content. We test the proposed method on a number of
videos and compare the results with the default rate-distortion algorithms in
the H.264/AVC codec. We evaluate rate-distortion algorithms by comparing
achieved bit-rates, visual degradations in the depth sequences and the fidelity
of the depth videos measured by SSIM and PSNR.
"
1846,"A Comparative Study of Quality and Content-Based Spatial Pooling
  Strategies in Image Quality Assessment","  The process of quantifying image quality consists of engineering the quality
features and pooling these features to obtain a value or a map. There has been
a significant research interest in designing the quality features but pooling
is usually overlooked compared to feature design. In this work, we compare the
state of the art quality and content-based spatial pooling strategies and show
that although features are the key in any image quality assessment, pooling
also matters. We also propose a quality-based spatial pooling strategy that is
based on linearly weighted percentile pooling (WPP). Pooling strategies are
analyzed for squared error, SSIM and PerSIM in LIVE, multiply distorted LIVE
and TID2013 image databases.
"
1847,"Generating Adaptive and Robust Filter Sets Using an Unsupervised
  Learning Framework","  In this paper, we introduce an adaptive unsupervised learning framework,
which utilizes natural images to train filter sets. The applicability of these
filter sets is demonstrated by evaluating their performance in two contrasting
applications - image quality assessment and texture retrieval. While assessing
image quality, the filters need to capture perceptual differences based on
dissimilarities between a reference image and its distorted version. In texture
retrieval, the filters need to assess similarity between texture images to
retrieve closest matching textures. Based on experiments, we show that the
filter responses span a set in which a monotonicity-based metric can measure
both the perceptual dissimilarity of natural images and the similarity of
texture images. In addition, we corrupt the images in the test set and
demonstrate that the proposed method leads to robust and reliable retrieval
performance compared to existing methods.
"
1848,"MS-UNIQUE: Multi-model and Sharpness-weighted Unsupervised Image Quality
  Estimation","  In this paper, we train independent linear decoder models to estimate the
perceived quality of images. More specifically, we calculate the responses of
individual non-overlapping image patches to each of the decoders and scale
these responses based on the sharpness characteristics of filter set. We use
multiple linear decoders to capture different abstraction levels of the image
patches. Training each model is carried out on 100,000 image patches from the
ImageNet database in an unsupervised fashion. Color space selection and ZCA
Whitening are performed over these patches to enhance the descriptiveness of
the data. The proposed quality estimator is tested on the LIVE and the TID 2013
image quality assessment databases. Performance of the proposed method is
compared against eleven other state of the art methods in terms of accuracy,
consistency, linearity, and monotonic behavior. Based on experimental results,
the proposed method is generally among the top performing quality estimators in
all categories.
"
1849,Self Paced Adversarial Training for Multimodal Few-shot Learning,"  State-of-the-art deep learning algorithms yield remarkable results in many
visual recognition tasks. However, they still fail to provide satisfactory
results in scarce data regimes. To a certain extent this lack of data can be
compensated by multimodal information. Missing information in one modality of a
single data point (e.g. an image) can be made up for in another modality (e.g.
a textual description). Therefore, we design a few-shot learning task that is
multimodal during training (i.e. image and text) and single-modal during test
time (i.e. image). In this regard, we propose a self-paced class-discriminative
generative adversarial network incorporating multimodality in the context of
few-shot learning. The proposed approach builds upon the idea of cross-modal
data generation in order to alleviate the data sparsity problem. We improve
few-shot learning accuracies on the finegrained CUB and Oxford-102 datasets.
"
1850,Image Quality Assessment and Color Difference,"  An average healthy person does not perceive the world in just black and
white. Moreover, the perceived world is not composed of pixels and through
vision humans perceive structures. However, the acquisition and display systems
discretize the world. Therefore, we need to consider pixels, structures and
colors to model the quality of experience. Quality assessment methods use the
pixel-wise and structural metrics whereas color science approaches use the
patch-based color differences. In this work, we combine these approaches by
extending CIEDE2000 formula with perceptual color difference to assess image
quality. We examine how perceptual color difference-based metric (PCDM)
performs compared to PSNR, CIEDE2000, SSIM, MS-SSIM and CW-SSIM on the LIVE
database. In terms of linear correlation, PCDM obtains compatible results under
white noise (97.9%), Jpeg (95.9%) and Jp2k (95.6%) with an overall correlation
of 92.7%. We also show that PCDM captures color-based artifacts that can not be
captured by structure-based metrics.
"
1851,"Sewer Rats in Teaching Action: An explorative field study on students'
  perception of a game-based learning app in graduate engineering education","  Game-based technologies and mobile learning aids open up many opportunities
for learners; however, evidence-based decisions on their appropriate use are
necessary. This explorative study (N = 100) examines the role of game elements
in university education using a game-based learning app for mobile devices. The
educational goal of the app is to support students in the field of engineering
to memorize factual knowledge. The study investigates how the game-based app
affects learners' motivation. It analyses the perceived impact and appeal as
well as the game elements as an incentive in learners' perception. To realize
this aim, the study combines structured methods like questionnaires with
semi-structured methods like thinking aloud, game diaries, and interviews. The
results indicate that flexible tem-poral and spatial use of the app was an
important factor of learners' motivation. The app allowed more spontaneous
involvement with the subject matter and the learners took advantage of an
improved attitude toward the subject matter. However, only a low impact on
intrinsic motivation could be observed. We discuss reasons and present
practical implications.
"
1852,Learning Sound Events From Webly Labeled Data,"  In the last couple of years, weakly labeled learning has turned out to be an
exciting approach for audio event detection. In this work, we introduce webly
labeled learning for sound events which aims to remove human supervision
altogether from the learning process. We first develop a method of obtaining
labeled audio data from the web (albeit noisy), in which no manual labeling is
involved. We then describe methods to efficiently learn from these webly
labeled audio recordings. In our proposed system, WeblyNet, two deep neural
networks co-teach each other to robustly learn from webly labeled data, leading
to around 17% relative improvement over the baseline method. The method also
involves transfer learning to obtain efficient representations
"
1853,"Multilevel active registration for kinect human body scans: from low
  quality to high quality","  Registration of 3D human body has been a challenging research topic for over
decades. Most of the traditional human body registration methods require manual
assistance, or other auxiliary information such as texture and markers. The
majority of these methods are tailored for high-quality scans from expensive
scanners. Following the introduction of the low-quality scans from
cost-effective devices such as Kinect, the 3D data capturing of human body
becomes more convenient and easier. However, due to the inevitable holes,
noises and outliers in the low-quality scan, the registration of human body
becomes even more challenging. To address this problem, we propose a fully
automatic active registration method which deforms a high-resolution template
mesh to match the low-quality human body scans. Our registration method
operates on two levels of statistical shape models: (1) the first level is a
holistic body shape model that defines the basic figure of human; (2) the
second level includes a set of shape models for every body part, aiming at
capturing more body details. Our fitting procedure follows a coarse-to-fine
approach that is robust and efficient. Experiments show that our method is
comparable with the state-of-the-art methods.
"
1854,"VECTORS: Video communication through opportunistic relays and scalable
  video coding","  Crowd-sourced video distribution is frequently of interest in the local
vicinity. In this paper, we propose a novel design to transfer such content
over opportunistic networks with adaptive quality encoding to achieve
reasonable delay bounds. The video segments are transmitted between source and
destination in a delay tolerant manner using the Nearby Connections Android
library. This implementation can be applied to multiple domains, including farm
monitoring, wildlife, and environmental tracking, disaster response scenarios,
etc. In this work, we present the design of an opportunistic contact based
system, and we discuss basic results for the trial runs within our institute.
"
1855,"Traffic Danger Recognition With Surveillance Cameras Without Training
  Data","  We propose a traffic danger recognition model that works with arbitrary
traffic surveillance cameras to identify and predict car crashes. There are too
many cameras to monitor manually. Therefore, we developed a model to predict
and identify car crashes from surveillance cameras based on a 3D reconstruction
of the road plane and prediction of trajectories. For normal traffic, it
supports real-time proactive safety checks of speeds and distances between
vehicles to provide insights about possible high-risk areas. We achieve good
prediction and recognition of car crashes without using any labeled training
data of crashes. Experiments on the BrnoCompSpeed dataset show that our model
can accurately monitor the road, with mean errors of 1.80% for distance
measurement, 2.77 km/h for speed measurement, 0.24 m for car position
prediction, and 2.53 km/h for speed prediction.
"
1856,Deep Multimodal Learning: An Effective Method for Video Classification,"  Videos have become ubiquitous on the Internet. And video analysis can provide
lots of information for detecting and recognizing objects as well as help
people understand human actions and interactions with the real world. However,
facing data as huge as TB level, effective methods should be applied. Recurrent
neural network (RNN) architecture has wildly been used on many sequential
learning problems such as Language Model, Time-Series Analysis, etc. In this
paper, we propose some variations of RNN such as stacked bidirectional LSTM/GRU
network with attention mechanism to categorize large-scale video data. We also
explore different multimodal fusion methods. Our model combines both visual and
audio information on both video and frame level and received great result.
Ensemble methods are also applied. Because of its multimodal characteristics,
we decide to call this method Deep Multimodal Learning(DML). Our DML-based
model was trained on Google Cloud and our own server and was tested in a
well-known video classification competition on Kaggle held by Google.
"
1857,"Hybrid Distortion Aggregated Visual Comfort Assessment for Stereoscopic
  Image Retargeting","  Visual comfort is a quite important factor in 3D media service. Few research
efforts have been carried out in this area especially in case of 3D content
retargeting which may introduce more complicated visual distortions. In this
paper, we propose a Hybrid Distortion Aggregated Visual Comfort Assessment
(HDA-VCA) scheme for stereoscopic retargeted images (SRI), considering
aggregation of hybrid distortions including structure distortion, information
loss, binocular incongruity and semantic distortion. Specifically, a Local-SSIM
feature is proposed to reflect the local structural distortion of SRI, and
information loss is represented by Dual Natural Scene Statistics (D-NSS)
feature extracted from the binocular summation and difference channels.
Regarding binocular incongruity, visual comfort zone, window violation,
binocular rivalry, and accommodation-vergence conflict of human visual system
(HVS) are evaluated. Finally, the semantic distortion is represented by the
correlation distance of paired feature maps extracted from original
stereoscopic image and its retargeted image by using trained deep neural
network. We validate the effectiveness of HDA-VCA on published Stereoscopic
Image Retargeting Database (SIRD) and two stereoscopic image databases IEEE-SA
and NBU 3D-VCA. The results demonstrate HDA-VCA's superior performance in
handling hybrid distortions compared to state-of-the-art VCA schemes.
"
1858,"Large-Scale and Fine-Grained Evaluation of Popular JPEG Forgery
  Localization Schemes","  Over the years, researchers have proposed various approaches to JPEG forgery
detection and localization. In most cases, experimental evaluation was limited
to JPEG quality levels that are multiples of 5 or 10. Each study used a
different dataset, making it difficult to directly compare the reported
results. The goal of this work is to perform a unified, large-scale and
fine-grained evaluation of the most popular state-of-the-art detectors. The
obtained results allow to compare the detectors with respect to various
criteria, and shed more light on the compression configurations where reliable
tampering localization can be expected.
"
1859,"Music Popularity: Metrics, Characteristics, and Audio-Based Prediction","  Understanding music popularity is important not only for the artists who
create and perform music but also for the music-related industry. It has not
been studied well how music popularity can be defined, what its characteristics
are, and whether it can be predicted, which are addressed in this paper. We
first define eight popularity metrics to cover multiple aspects of popularity.
Then, the analysis of each popularity metric is conducted with long-term
real-world chart data to deeply understand the characteristics of music
popularity in the real world. We also build classification models for
predicting popularity metrics using acoustic data. In particular, we focus on
evaluating features describing music complexity together with other
conventional acoustic features including MPEG-7 and Mel-frequency cepstral
coefficient (MFCC) features. The results show that, although room still exists
for improvement, it is feasible to predict the popularity metrics of a song
significantly better than random chance based on its audio signal, particularly
using both the complexity and MFCC features.
"
1860,"A Robust Algorithm for Tile-based 360-degree Video Streaming with
  Uncertain FoV Estimation","  We propose a robust scheme for streaming 360-degree immersive videos to
maximize the quality of experience (QoE). Our streaming approach introduces a
holistic analytical framework built upon the formal method of stochastic
optimization. We propose a robust algorithm which provides a streaming rate
such that the video quality degrades below that rate with very low probability
even in presence of uncertain head movement, and bandwidth. It assumes the
knowledge of the viewing probability of different portions (tiles) of a
panoramic scene. Such probabilities can be easily derived from crowdsourced
measurements performed by 360 video content providers. We then propose
efficient methods to solve the problem at runtime while achieving a bounded
optimality gap (in terms of the QoE). We implemented our proposed approaches
using emulation. Using real users' head movement traces and real cellular
bandwidth traces, we show that our algorithms significantly outperform the
baseline algorithms by at least in $30\%$ in the QoE metric. Our algorithm
gives a streaming rate which is $50\%$ higher compared to the baseline
algorithms when the prediction error is high.
"
1861,"Novel Quality Metric for Duration Variability Compensation in Speaker
  Verification using i-Vectors","  Automatic speaker verification (ASV) is the process to recognize persons
using voice as biometric. The ASV systems show considerable recognition
performance with sufficient amount of speech from matched condition. One of the
crucial challenges of ASV technology is to improve recognition performance with
speech segments of short duration. In short duration condition, the model
parameters are not properly estimated due to inadequate speech information, and
this results poor recognition accuracy even with the state-of-the-art i-vector
based ASV system. We hypothesize that considering the estimation quality during
recognition process would help to improve the ASV performance. This can be
incorporated as a quality measure during fusion of ASV systems. This paper
investigates a new quality measure for i-vector representation of speech
utterances computed directly from Baum-Welch statistics. The proposed metric is
subsequently used as quality measure during fusion of ASV systems. In
experiments with the NIST SRE 2008 corpus, We have shown that inclusion of
proposed quality metric exhibits considerable improvement in speaker
verification performance. The results also indicate the potentiality of the
proposed method in real-world scenario with short test utterances.
"
1862,"SUGAMAN: Describing Floor Plans for Visually Impaired by Annotation
  Learning and Proximity based Grammar","  In this paper, we propose SUGAMAN (Supervised and Unified framework using
Grammar and Annotation Model for Access and Navigation). SUGAMAN is a Hindi
word meaning ""easy passage from one place to another"". SUGAMAN synthesizes
textual description from a given floor plan image for the visually impaired. A
visually impaired person can navigate in an indoor environment using the
textual description generated by SUGAMAN. With the help of a text reader
software, the target user can understand the rooms within the building and
arrangement of furniture to navigate. SUGAMAN is the first framework for
describing a floor plan and giving direction for obstacle-free movement within
a building. We learn $5$ classes of room categories from $1355$ room image
samples under a supervised learning paradigm. These learned annotations are fed
into a description synthesis framework to yield a holistic description of a
floor plan image. We demonstrate the performance of various supervised
classifiers on room learning. We also provide a comparative analysis of system
generated and human written descriptions. SUGAMAN gives state of the art
performance on challenging, real-world floor plan images. This work can be
applied to areas like understanding floor plans of historical monuments,
stability analysis of buildings, and retrieval.
"
1863,"Content Authentication for Neural Imaging Pipelines: End-to-end
  Optimization of Photo Provenance in Complex Distribution Channels","  Forensic analysis of digital photo provenance relies on intrinsic traces left
in the photograph at the time of its acquisition. Such analysis becomes
unreliable after heavy post-processing, such as down-sampling and
re-compression applied upon distribution in the Web. This paper explores
end-to-end optimization of the entire image acquisition and distribution
workflow to facilitate reliable forensic analysis at the end of the
distribution channel. We demonstrate that neural imaging pipelines can be
trained to replace the internals of digital cameras, and jointly optimized for
high-fidelity photo development and reliable provenance analysis. In our
experiments, the proposed approach increased image manipulation detection
accuracy from 45% to over 90%. The findings encourage further research towards
building more reliable imaging pipelines with explicit provenance-guaranteeing
properties.
"
1864,"Improving Semantic Segmentation via Video Propagation and Label
  Relaxation","  Semantic segmentation requires large amounts of pixel-wise annotations to
learn accurate models. In this paper, we present a video prediction-based
methodology to scale up training sets by synthesizing new training samples in
order to improve the accuracy of semantic segmentation networks. We exploit
video prediction models' ability to predict future frames in order to also
predict future labels. A joint propagation strategy is also proposed to
alleviate mis-alignments in synthesized samples. We demonstrate that training
segmentation models on datasets augmented by the synthesized samples leads to
significant improvements in accuracy. Furthermore, we introduce a novel
boundary label relaxation technique that makes training robust to annotation
noise and propagation artifacts along object boundaries. Our proposed methods
achieve state-of-the-art mIoUs of 83.5% on Cityscapes and 82.9% on CamVid. Our
single model, without model ensembles, achieves 72.8% mIoU on the KITTI
semantic segmentation test set, which surpasses the winning entry of the ROB
challenge 2018. Our code and videos can be found at
https://nv-adlr.github.io/publication/2018-Segmentation.
"
1865,Complete the Look: Scene-based Complementary Product Recommendation,"  Modeling fashion compatibility is challenging due to its complexity and
subjectivity. Existing work focuses on predicting compatibility between product
images (e.g. an image containing a t-shirt and an image containing a pair of
jeans). However, these approaches ignore real-world 'scene' images (e.g.
selfies); such images are hard to deal with due to their complexity, clutter,
variations in lighting and pose (etc.) but on the other hand could potentially
provide key context (e.g. the user's body type, or the season) for making more
accurate recommendations. In this work, we propose a new task called 'Complete
the Look', which seeks to recommend visually compatible products based on scene
images. We design an approach to extract training data for this task, and
propose a novel way to learn the scene-product compatibility from fashion or
interior design images. Our approach measures compatibility both globally and
locally via CNNs and attention mechanisms. Extensive experiments show that our
method achieves significant performance gains over alternative systems. Human
evaluation and qualitative analysis are also conducted to further understand
model behavior. We hope this work could lead to useful applications which link
large corpora of real-world scenes with shoppable products.
"
1866,Wireless Access to Ultimate Virtual Reality 360-Degree Video At Home,"  Virtual reality 360-degree videos will become the first prosperous online VR
application. VR 360 videos are data-hungry and latency-sensitive that pose
unique challenges to the networking infrastructure. In this paper, we focus on
the ultimate VR 360 that satisfies human eye fidelity. The ultimate VR 360
requires downlink 1.5 Gbps for viewing and uplink 6.6 Gbps for live
broadcasting, with round-trip time of less than 8.3 ms. On the other hand,
wireless access to VR 360 services is preferred over wire-line transmission
because of the better user experience and the safety concern (e.g., tripping
hazard). We explore in this paper whether the most advanced wireless
technologies from both cellular communications and WiFi communications support
the ultimate VR 360. Specifically, we consider 5G in cellular communications,
IEEE 802.11ac (operating in 5GHz) and IEEE 802.11ad (operating in 60GHz) in
WiFi communications. According to their performance specified in their
standards and/or empirical measurements, we have the following findings: (1)
Only 5G has the potential to support both the the ultimate VR 360 viewing and
live broadcasting. However, it is difficult for 5G to support multiple users of
the ultimate VR live broadcasting at home; (2) IEEE 802.11ac supports the
ultimate VR 360 viewing but fails to support the ultimate VR 360 live
broadcasting because it does not meet the data rate requirement of the ultimate
VR 360 live broadcasting; (3) IEEE 802.11ad fails to support the ultimate VR
360, because its current implementation incurs very high latency. Our
preliminary results indicate that more advanced wireless technologies are
needed to fully support multiple ultimate VR 360 users at home.
"
1867,"VideoMem: Constructing, Analyzing, Predicting Short-term and Long-term
  Video Memorability","  Humans share a strong tendency to memorize/forget some of the visual
information they encounter. This paper focuses on providing computational
models for the prediction of the intrinsic memorability of visual content. To
address this new challenge, we introduce a large scale dataset (VideoMem)
composed of 10,000 videos annotated with memorability scores. In contrast to
previous work on image memorability -- where memorability was measured a few
minutes after memorization -- memory performance is measured twice: a few
minutes after memorization and again 24-72 hours later. Hence, the dataset
comes with short-term and long-term memorability annotations. After an in-depth
analysis of the dataset, we investigate several deep neural network based
models for the prediction of video memorability. Our best model using a ranking
loss achieves a Spearman's rank correlation of 0.494 for short-term
memorability prediction, while our proposed model with attention mechanism
provides insights of what makes a content memorable. The VideoMem dataset with
pre-extracted features is publicly available.
"
1868,"HEVC Inter Coding Using Deep Recurrent Neural Networks and Artificial
  Reference Pictures","  The efficiency of motion compensated prediction in modern video codecs highly
depends on the available reference pictures. Occlusions and non-linear motion
pose challenges for the motion compensation and often result in high bit rates
for the prediction error. We propose the generation of artificial reference
pictures using deep recurrent neural networks. Conceptually, a reference
picture at the time instance of the currently coded picture is generated from
previously reconstructed conventional reference pictures. Based on these
artificial reference pictures, we propose a complete coding pipeline based on
HEVC. By using the artificial reference pictures for motion compensated
prediction, average BD-rate gains of 1.5% over HEVC are achieved.
"
1869,"An Experimental Evaluation Of Analog TV Cable Services Distributed In
  GPON Architecture","  This paper explores the benefits of GPON (Gigabit Passive Optical Networks)
in analog TV services. Analog TV service is still present in the standard
triple play distribution architectures, as an effect of unique advantages:
simple distribution in an apartment via standard RF splitters, unlimited number
of viewing sites, real time behavior by lack of encoding/decoding processes. Of
course, the quality is still limited by analogic standards, but the
price/performance ratio is unbeatable. The most important parameters
characterizing the analog TV performance are described, the network
architecture is emphasized. To have a reference, the test architecture is a
sub-network of a commercial telecom company. In this case only the quality of
TV reception is performed. Using open-source software, and the integrated TV
tuner board makes possible to test the levels and S/N ratio for all the analog
TV channels of the spectrum. The system opens the possibility to do the same
for digital channels in DVB-C standard, with minimal changes.
"
1870,"Scene Synchronization for Real-Time Interaction in Distributed Mixed
  Reality and Virtual Reality Environments","  Advances in computer networks and rendering systems facilitate the creation
of distributed collaborative environments in which the distribution of
information at remote locations allows efficient communication. One of the
challenges in networked virtual environments is maintaining a consistent view
of the shared state in the presence of inevitable network latency and jitter. A
consistent view in a shared scene may significantly increase the sense of
presence among participants and facilitate their interactivity. The dynamic
shared state is directly affected by the frequency of actions applied on the
objects in the scene. Mixed Reality (MR) and Virtual Reality (VR) environments
contain several types of action producers including human users, a wide range
of electronic motion sensors, and haptic devices. In this paper, the authors
propose a novel criterion for categorization of distributed MR/VR systems and
present an adaptive synchronization algorithm for distributed MR/VR
collaborative environments. In spite of significant network latency, results
show that for low levels of update frequencies the dynamic shared state can be
maintained consistent at multiple remotely located sites.
"
1871,On Attention Modules for Audio-Visual Synchronization,"  With the development of media and networking technologies, multimedia
applications ranging from feature presentation in a cinema setting to video on
demand to interactive video conferencing are in great demand. Good
synchronization between audio and video modalities is a key factor towards
defining the quality of a multimedia presentation. The audio and visual signals
of a multimedia presentation are commonly managed by independent workflows -
they are often separately authored, processed, stored and even delivered to the
playback system. This opens up the possibility of temporal misalignment between
the two modalities - such a tendency is often more pronounced in the case of
produced content (such as movies).
  To judge whether audio and video signals of a multimedia presentation are
synchronized, we as humans often pay close attention to discriminative
spatio-temporal blocks of the video (e.g. synchronizing the lip movement with
the utterance of words, or the sound of a bouncing ball at the moment it hits
the ground). At the same time, we ignore large portions of the video in which
no discriminative sounds exist (e.g. background music playing in a movie).
Inspired by this observation, we study leveraging attention modules for
automatically detecting audio-visual synchronization. We propose neural network
based attention modules, capable of weighting different portions
(spatio-temporal blocks) of the video based on their respective discriminative
power. Our experiments indicate that incorporating attention modules yields
state-of-the-art results for the audio-visual synchronization classification
problem.
"
1872,"Proactive Video Chunks Caching and Processing for Latency and Cost
  Minimization in Edge Networks","  Recently, the growing demand for rich multimedia content such as Video on
Demand (VoD) has made the data transmission from content delivery networks
(CDN) to end-users quite challenging. Edge networks have been proposed as an
extension to CDN networks to alleviate this excessive data transfer through
caching and to delegate the computation tasks to edge servers. To maximize the
caching efficiency in the edge networks, different Mobile Edge Computing (MEC)
servers assist each others to effectively select which content to store and the
appropriate computation tasks to process. In this paper, we adopt a
collaborative caching and transcoding model for VoD in MEC networks. However,
unlike other models in the literature, different chunks of the same video are
not fetched and cached in the same MEC server. Instead, neighboring servers
will collaborate to store and transcode different video chunks and consequently
optimize the limited resources usage. Since we are dealing with chunks caching
and processing, we propose to maximize the edge efficiency by studying the
viewers watching pattern and designing a probabilistic model where chunks
popularities are evaluated. Based on this model, popularity-aware policies,
namely Proactive caching policy (PcP) and Cache replacement Policy (CrP), are
introduced to cache only highest probably requested chunks. In addition to PcP
and CrP, an online algorithm (PCCP) is proposed to schedule the collaborative
caching and processing. The evaluation results prove that our model and
policies give better performance than approaches using conventional replacement
policies. This improvement reaches up to 50% in some cases.
"
1873,Robust Graph Learning from Noisy Data,"  Learning graphs from data automatically has shown encouraging performance on
clustering and semisupervised learning tasks. However, real data are often
corrupted, which may cause the learned graph to be inexact or unreliable. In
this paper, we propose a novel robust graph learning scheme to learn reliable
graphs from real-world noisy data by adaptively removing noise and errors in
the raw data. We show that our proposed model can also be viewed as a robust
version of manifold regularized robust PCA, where the quality of the graph
plays a critical role. The proposed model is able to boost the performance of
data clustering, semisupervised classification, and data recovery
significantly, primarily due to two key factors: 1) enhanced low-rank recovery
by exploiting the graph smoothness assumption, 2) improved graph construction
by exploiting clean data recovered by robust PCA. Thus, it boosts the
clustering, semi-supervised classification, and data recovery performance
overall. Extensive experiments on image/document clustering, object
recognition, image shadow removal, and video background subtraction reveal that
our model outperforms the previous state-of-the-art methods.
"
1874,"Receiver-driven Video Multicast over NOMA Systems in Heterogeneous
  Environments","  Non-orthogonal multiple access (NOMA) has shown potential for scalable
multicast of video data. However, one key drawback for NOMA-based video
multicast is the limited number of layers allowed by the embedded successive
interference cancellation algorithm, failing to meet satisfaction of
heterogeneous receivers. We propose a novel receiver-driven superposed video
multicast (Supcast) scheme by integrating Softcast, an analog-like transmission
scheme, into the NOMA-based system to achieve high bandwidth efficiency as well
as gradual decoding quality proportional to channel conditions at receivers.
Although Softcast allows gradual performance by directly transmitting
power-scaled transformation coefficients of frames, it suffers performance
degradation due to discarding coefficients under insufficient bandwidth and its
power allocation strategy cannot be directly applied in NOMA due to
interference. In Supcast, coefficients are grouped into chunks, which are basic
units for power allocation and superposition scheduling. By bisecting chunks
into base-layer chunks and enhanced-layer chunks, the joint power allocation
and chunk scheduling is formulated as a distortion minimization problem. A
two-stage power allocation strategy and a near-optimal low-complexity algorithm
for chunk scheduling based on the matching theory are proposed. Simulation
results have shown the advantage of Supcast against Softcast as well as the
reference scheme in NOMA under various practical scenarios.
"
1875,"Grayscale-Based Image Encryption Considering Color Sub-sampling
  Operation for Encryption-then-Compression Systems","  A new grayscale-based block scrambling image encryption scheme is presented
to enhance the security of Encryption-then-Compression (EtC) systems, which are
used to securely transmit images through an untrusted channel provider. The
proposed scheme enables the use of a smaller block size and a larger number of
blocks than the conventional scheme. Images encrypted using the proposed scheme
include less color information due to the use of grayscale images even when the
original image has three color channels. These features enhance security
against various attacks, such as jigsaw puzzle solver and brute-force attacks.
Moreover, it allows the use of color sub-sampling, which can improve the
compression performance, although the encrypted images have no color
information. In an experiment, encrypted images were uploaded to and then
downloaded from Facebook and Twitter, and the results demonstrated that the
proposed scheme is effective for EtC systems, while maintaining a high
compression performance.
"
1876,"BandNet: A Neural Network-based, Multi-Instrument Beatles-Style MIDI
  Music Composition Machine","  In this paper, we propose a recurrent neural network (RNN)-based MIDI music
composition machine that is able to learn musical knowledge from existing
Beatles' songs and generate music in the style of the Beatles with little human
intervention. In the learning stage, a sequence of stylistically uniform,
multiple-channel music samples was modeled by a RNN. In the composition stage,
a short clip of randomly-generated music was used as a seed for the RNN to
start music score prediction. To form structured music, segments of generated
music from different seeds were concatenated together. To improve the quality
and structure of the generated music, we integrated music theory knowledge into
the model, such as controlling the spacing of gaps in the vocal melody,
normalizing the timing of chord changes, and requiring notes to be related to
the song's key (C major, for example). This integration improved the quality of
the generated music as verified by a professional composer. We also conducted a
subjective listening test that showed our generated music was close to original
music by the Beatles in terms of style similarity, professional quality, and
interestingness. Generated music samples are at https://goo.gl/uaLXoB.
"
1877,D{\'e}tection de locuteurs dans les s{\'e}ries TV,"  Speaker diarization of audio streams turns out to be particularly challenging
when applied to fictional films, where many characters talk in various acoustic
conditions (background music, sound effects, variations in intonation...).
Despite this acoustic variability, such movies exhibit specific visual
patterns, particularly within dialogue scenes. In this paper, we introduce a
two-step method to achieve speaker diarization in TV series: speaker
diarization is first performed locally within scenes visually identified as
dialogues; then, the hypothesized local speakers are compared to each other
during a second clustering process in order to detect recurring speakers: this
second stage of clustering is subject to the constraint that the different
speakers involved in the same dialogue have to be assigned to different
clusters. The performances of our approach are compared to those obtained by
standard speaker diarization tools applied to the same data.
"
1878,Audiovisual speaker diarization of TV series,"  Speaker diarization may be difficult to achieve when applied to narrative
films, where speakers usually talk in adverse acoustic conditions: background
music, sound effects, wide variations in intonation may hide the inter-speaker
variability and make audio-based speaker diarization approaches error prone. On
the other hand, such fictional movies exhibit strong regularities at the image
level, particularly within dialogue scenes. In this paper, we propose to
perform speaker diarization within dialogue scenes of TV series by combining
the audio and video modalities: speaker diarization is first performed by using
each modality, the two resulting partitions of the instance set are then
optimally matched, before the remaining instances, corresponding to cases of
disagreement between both modalities, are finally processed. The results
obtained by applying such a multi-modal approach to fictional films turn out to
outperform those obtained by relying on a single modality.
"
1879,Constrained speaker diarization of TV series based on visual patterns,"  Speaker diarization, usually denoted as the ''who spoke when'' task, turns
out to be particularly challenging when applied to fictional films, where many
characters talk in various acoustic conditions (background music, sound
effects...). Despite this acoustic variability , such movies exhibit specific
visual patterns in the dialogue scenes. In this paper, we introduce a two-step
method to achieve speaker diarization in TV series: a speaker diarization is
first performed locally in the scenes detected as dialogues; then, the
hypothesized local speakers are merged in a second agglomerative clustering
process, with the constraint that speakers locally hypothesized to be distinct
must not be assigned to the same cluster. The performances of our approach are
compared to those obtained by standard speaker diarization tools applied to the
same data.
"
1880,The Prefetch Aggressiveness Tradeoff in 360$^{\circ}$ Video Streaming,"  With 360$^{\circ}$ video, only a limited fraction of the full view is
displayed at each point in time. This has prompted the design of streaming
delivery techniques that allow alternative playback qualities to be delivered
for each candidate viewing direction. However, while prefetching based on the
user's expected viewing direction is best done close to playback deadlines,
large buffers are needed to protect against shortfalls in future available
bandwidth. This results in conflicting goals and an important prefetch
aggressiveness tradeoff problem regarding how far ahead in time from the
current playpoint prefetching should be done. This paper presents the first
characterization of this tradeoff. The main contributions include an empirical
characterization of head movement behavior based on data from viewing sessions
of four different categories of 360$^{\circ}$ video, an optimization-based
comparison of the prefetch aggressiveness tradeoffs seen for these video
categories, and a data-driven discussion of further optimizations, which
include a novel system design that allows both tradeoff objectives to be
targeted simultaneously. By qualitatively and quantitatively analyzing the
above tradeoffs, we provide insights into how to best design tomorrow's
delivery systems for 360$^{\circ}$ videos, allowing content providers to reduce
bandwidth costs and improve users' playback experiences.
"
1881,Discriminative Supervised Hashing for Cross-Modal similarity Search,"  With the advantage of low storage cost and high retrieval efficiency, hashing
techniques have recently been an emerging topic in cross-modal similarity
search. As multiple modal data reflect similar semantic content, many
researches aim at learning unified binary codes. However, discriminative
hashing features learned by these methods are not adequate. This results in
lower accuracy and robustness. We propose a novel hashing learning framework
which jointly performs classifier learning, subspace learning and matrix
factorization to preserve class-specific semantic content, termed
Discriminative Supervised Hashing (DSH), to learn the discrimative unified
binary codes for multi-modal data. Besides, reducing the loss of information
and preserving the non-linear structure of data, DSH non-linearly projects
different modalities into the common space in which the similarity among
heterogeneous data points can be measured. Extensive experiments conducted on
the three publicly available datasets demonstrate that the framework proposed
in this paper outperforms several state-of -the-art methods.
"
1882,A Smart Security System with Face Recognition,"  Web-based technology has improved drastically in the past decade. As a
result, security technology has become a major help to protect our daily life.
In this paper, we propose a robust security based on face recognition system
(SoF). In particular, we develop this system to giving access into a home for
authenticated users. The classifier is trained by using a new adaptive learning
method. The training data are initially collected from social networks. The
accuracy of the classifier is incrementally improved as the user starts using
the system. A novel method has been introduced to improve the classifier model
by human interaction and social media. By using a deep learning framework -
TensorFlow, it will be easy to reuse the framework to adopt with many devices
and applications.
"
1883,"Learned Scalable Image Compression with Bidirectional Context
  Disentanglement Network","  In this paper, we propose a learned scalable/progressive image compression
scheme based on deep neural networks (DNN), named Bidirectional Context
Disentanglement Network (BCD-Net). For learning hierarchical representations,
we first adopt bit-plane decomposition to decompose the information coarsely
before the deep-learning-based transformation. However, the information carried
by different bit-planes is not only unequal in entropy but also of different
importance for reconstruction. We thus take the hidden features corresponding
to different bit-planes as the context and design a network topology with
bidirectional flows to disentangle the contextual information for more
effective compressed representations. Our proposed scheme enables us to obtain
the compressed codes with scalable rates via a one-pass encoding-decoding.
Experiment results demonstrate that our proposed model outperforms the
state-of-the-art DNN-based scalable image compression methods in both PSNR and
MS-SSIM metrics. In addition, our proposed model achieves higher performance in
MS-SSIM metric than conventional scalable image codecs. Effectiveness of our
technical components is also verified through sufficient ablation experiments.
"
1884,"Reversible Data Hiding in Encrypted Images based on MSB Prediction and
  Huffman Coding","  With the development of cloud storage and privacy protection, reversible data
hiding in encrypted images (RDHEI) has attracted increasing attention as a
technology that can embed additional data in the encryption domain. In general,
an RDHEI method embeds secret data in an encrypted image while ensuring that
the embedded data can be extracted error-free and the original image can be
restored lossless. In this paper, A high-capacity RDHEI algorithm is proposed.
At first, the Most Significant Bits (MSB) of each pixel was predicted
adaptively and marked by Huffman coding in the original image. Then, the image
was encrypted by a stream cipher method. At last, the vacated space can be used
to embed additional data. Experimental results show that our method achieved
higher embedding capacity while comparing with the state-of-the-art methods.
"
1885,"Scene Graph Reasoning with Prior Visual Relationship for Visual Question
  Answering","  One of the key issues of Visual Question Answering (VQA) is to reason with
semantic clues in the visual content under the guidance of the question, how to
model relational semantics still remains as a great challenge. To fully capture
visual semantics, we propose to reason over a structured visual representation
- scene graph, with embedded objects and inter-object relationships. This shows
great benefit over vanilla vector representations and implicit visual
relationship learning. Based on existing visual relationship models, we propose
a visual relationship encoder that projects visual relationships into a learned
deep semantic space constrained by visual context and language priors. Upon the
constructed graph, we propose a Scene Graph Convolutional Network (SceneGCN) to
jointly reason the object properties and relational semantics for the correct
answer. We demonstrate the model's effectiveness and interpretability on the
challenging GQA dataset and the classical VQA 2.0 dataset, remarkably achieving
state-of-the-art 54.56% accuracy on GQA compared to the existing best model.
"
1886,"TextNet: Irregular Text Reading from Images with an End-to-End Trainable
  Network","  Reading text from images remains challenging due to multi-orientation,
perspective distortion and especially the curved nature of irregular text. Most
of existing approaches attempt to solve the problem in two or multiple stages,
which is considered to be the bottleneck to optimize the overall performance.
To address this issue, we propose an end-to-end trainable network architecture,
named TextNet, which is able to simultaneously localize and recognize irregular
text from images. Specifically, we develop a scale-aware attention mechanism to
learn multi-scale image features as a backbone network, sharing fully
convolutional features and computation for localization and recognition. In
text detection branch, we directly generate text proposals in quadrangles,
covering oriented, perspective and curved text regions. To preserve text
features for recognition, we introduce a perspective RoI transform layer, which
can align quadrangle proposals into small feature maps. Furthermore, in order
to extract effective features for recognition, we propose to encode the aligned
RoI features by RNN into context information, combining spatial attention
mechanism to generate text sequences. This overall pipeline is capable of
handling both regular and irregular cases. Finally, text localization and
recognition tasks can be jointly trained in an end-to-end fashion with designed
multi-task loss. Experiments on standard benchmarks show that the proposed
TextNet can achieve state-of-the-art performance, and outperform existing
approaches on irregular datasets by a large margin.
"
1887,Learning based Facial Image Compression with Semantic Fidelity Metric,"  Surveillance and security scenarios usually require high efficient facial
image compression scheme for face recognition and identification. While either
traditional general image codecs or special facial image compression schemes
only heuristically refine codec separately according to face verification
accuracy metric. We propose a Learning based Facial Image Compression (LFIC)
framework with a novel Regionally Adaptive Pooling (RAP) module whose
parameters can be automatically optimized according to gradient feedback from
an integrated hybrid semantic fidelity metric, including a successfully
exploration to apply Generative Adversarial Network (GAN) as metric directly in
image compression scheme. The experimental results verify the framework's
efficiency by demonstrating performance improvement of 71.41%, 48.28% and
52.67% bitrate saving separately over JPEG2000, WebP and neural network-based
codecs under the same face verification accuracy distortion metric. We also
evaluate LFIC's superior performance gain compared with latest specific facial
image codecs. Visual experiments also show some interesting insight on how LFIC
can automatically capture the information in critical areas based on semantic
distortion metrics for optimized compression, which is quite different from the
heuristic way of optimization in traditional image compression algorithms.
"
1888,Security analysis of a self-embedding fragile image watermark scheme,"  Recently, a self-embedding fragile watermark scheme based on reference-bits
interleaving and adaptive selection of embedding mode was proposed. Reference
bits are derived from the scrambled MSB bits of a cover image, and then are
combined with authentication bits to form the watermark bits for LSB embedding.
We find this algorithm has a feature of block independence of embedding
watermark such that it is vulnerable to a collage attack. In addition, because
the generation of authentication bits via hash function operations is not
related to secret keys, we analyze this algorithm by a multiple stego-image
attack. We find that the cost of obtaining all the permutation relations of
$l\cdot b^2$ watermark bits of each block (i.e., equivalent permutation keys)
is about $(l\cdot b^2)!$ for the embedding mode $(m, l)$, where $m$ MSB layers
of a cover image are used for generating reference bits and $l$ LSB layers for
embedding watermark, and $b\times b$ is the size of image block. The simulation
results and the statistical results demonstrate our analysis is effective.
"
1889,"End-to-End Model for Speech Enhancement by Consistent Spectrogram
  Masking","  Recently, phase processing is attracting increasinginterest in speech
enhancement community. Some researchersintegrate phase estimations module into
speech enhancementmodels by using complex-valued short-time Fourier
transform(STFT) spectrogram based training targets, e.g. Complex RatioMask
(cRM) [1]. However, masking on spectrogram would violentits consistency
constraints. In this work, we prove that theinconsistent problem enlarges the
solution space of the speechenhancement model and causes unintended artifacts.
ConsistencySpectrogram Masking (CSM) is proposed to estimate the
complexspectrogram of a signal with the consistency constraint in asimple but
not trivial way. The experiments comparing ourCSM based end-to-end model with
other methods are conductedto confirm that the CSM accelerate the model
training andhave significant improvements in speech quality. From
ourexperimental results, we assured that our method could enha
"
1890,"Automatic playlist continuation using a hybrid recommender system
  combining features from text and audio","  The ACM RecSys Challenge 2018 focuses on music recommendation in the context
of automatic playlist continuation. In this paper, we describe our approach to
the problem and the final hybrid system that was submitted to the challenge by
our team Cocoplaya. This system consists in combining the recommendations
produced by two different models using ranking fusion. The first model is based
on Matrix Factorization and it incorporates information from tracks' audio and
playlist titles. The second model generates recommendations based on typical
track co-occurrences considering their proximity in the playlists. The proposed
approach is efficient and achieves a good overall performance, with our model
ranked 4th on the creative track of the challenge leaderboard.
"
1891,Introduction to Voice Presentation Attack Detection and Recent Advances,"  Over the past few years significant progress has been made in the field of
presentation attack detection (PAD) for automatic speaker recognition (ASV).
This includes the development of new speech corpora, standard evaluation
protocols and advancements in front-end feature extraction and back-end
classifiers. The use of standard databases and evaluation protocols has enabled
for the first time the meaningful benchmarking of different PAD solutions. This
chapter summarises the progress, with a focus on studies completed in the last
three years. The article presents a summary of findings and lessons learned
from two ASVspoof challenges, the first community-led benchmarking efforts.
These show that ASV PAD remains an unsolved problem and that further attention
is required to develop generalised PAD solutions which have potential to detect
diverse and previously unseen spoofing attacks.
"
1892,AVA-ActiveSpeaker: An Audio-Visual Dataset for Active Speaker Detection,"  Active speaker detection is an important component in video analysis
algorithms for applications such as speaker diarization, video re-targeting for
meetings, speech enhancement, and human-robot interaction. The absence of a
large, carefully labeled audio-visual dataset for this task has constrained
algorithm evaluations with respect to data diversity, environments, and
accuracy. This has made comparisons and improvements difficult. In this paper,
we present the AVA Active Speaker detection dataset (AVA-ActiveSpeaker) that
will be released publicly to facilitate algorithm development and enable
comparisons. The dataset contains temporally labeled face tracks in video,
where each face instance is labeled as speaking or not, and whether the speech
is audible. This dataset contains about 3.65 million human labeled frames or
about 38.5 hours of face tracks, and the corresponding audio. We also present a
new audio-visual approach for active speaker detection, and analyze its
performance, demonstrating both its strength and the contributions of the
dataset.
"
1893,Bilinear Supervised Hashing Based on 2D Image Features,"  Hashing has been recognized as an efficient representation learning method to
effectively handle big data due to its low computational complexity and memory
cost. Most of the existing hashing methods focus on learning the
low-dimensional vectorized binary features based on the high-dimensional raw
vectorized features. However, studies on how to obtain preferable binary codes
from the original 2D image features for retrieval is very limited. This paper
proposes a bilinear supervised discrete hashing (BSDH) method based on 2D image
features which utilizes bilinear projections to binarize the image matrix
features such that the intrinsic characteristics in the 2D image space are
preserved in the learned binary codes. Meanwhile, the bilinear projection
approximation and vectorization binary codes regression are seamlessly
integrated together to formulate the final robust learning framework.
Furthermore, a discrete optimization strategy is developed to alternatively
update each variable for obtaining the high-quality binary codes. In addition,
two 2D image features, traditional SURF-based FVLAD feature and CNN-based
AlexConv5 feature are designed for further improving the performance of the
proposed BSDH method. Results of extensive experiments conducted on four
benchmark datasets show that the proposed BSDH method almost outperforms all
competing hashing methods with different input features by different evaluation
protocols.
"
1894,Visual Distortions in 360-degree Videos,"  Omnidirectional (or 360-degree) images and videos are emergent signals in
many areas such as robotics and virtual/augmented reality. In particular, for
virtual reality, they allow an immersive experience in which the user is
provided with a 360-degree field of view and can navigate throughout a scene,
e.g., through the use of Head Mounted Displays. Since it represents the full
360-degree field of view from one point of the scene, omnidirectional content
is naturally represented as spherical visual signals. Current approaches for
capturing, processing, delivering, and displaying 360-degree content, however,
present many open technical challenges and introduce several types of
distortions in these visual signals. Some of the distortions are specific to
the nature of 360-degree images, and often different from those encountered in
the classical image communication framework. This paper provides a first
comprehensive review of the most common visual distortions that alter
360-degree signals undergoing state of the art processing in common
applications. While their impact on viewers' visual perception and on the
immersive experience at large is still unknown ---thus, it stays an open
research topic--- this review serves the purpose of identifying the main causes
of visual distortions in the end-to-end 360-degree content distribution
pipeline. It is essential as a basis for benchmarking different processing
techniques, allowing the effective design of new algorithms and applications.
It is also necessary to the deployment of proper psychovisual studies to
characterise the human perception of these new images in interactive and
immersive applications.
"
1895,A Spatial-temporal 3D Human Pose Reconstruction Framework,"  3D human pose reconstruction from single-view camera is a difficult and
challenging topic. Many approaches have been proposed, but almost focusing on
frame-by-frame independently while inter-frames are highly correlated in a pose
sequence. In contrast, we introduce a novel spatial-temporal 3D reconstruction
framework that leverages both intra and inter frame relationships in
consecutive 2D pose sequences. Orthogonal Matching Pursuit (OMP) algorithm,
pre-trained Pose-angle Limits and Temporal Models have been implemented. We
quantitatively compare our framework versus recent works on CMU motion capture
dataset and Vietnamese traditional dance sequences. Our method outperforms
others with 10 percent lower of Euclidean reconstruction error and robustness
against Gaussian noise. Additionally, it is also important to mention that our
reconstructed 3D pose sequences are smoother and more natural than others.
"
1896,"Guess What's on my Screen? Clustering Smartphone Screenshots with Active
  Learning","  A significant proportion of individuals' daily activities is experienced
through digital devices. Smartphones in particular have become one of the
preferred interfaces for content consumption and social interaction.
Identifying the content embedded in frequently-captured smartphone screenshots
is thus a crucial prerequisite to studies of media behavior and health
intervention planning that analyze activity interplay and content switching
over time. Screenshot images can depict heterogeneous contents and
applications, making the a priori definition of adequate taxonomies a
cumbersome task, even for humans. Privacy protection of the sensitive data
captured on screens means the costs associated with manual annotation are
large, as the effort cannot be crowd-sourced. Thus, there is need to examine
utility of unsupervised and semi-supervised methods for digital screenshot
classification. This work introduces the implications of applying clustering on
large screenshot sets when only a limited amount of labels is available. In
this paper we develop a framework for combining K-Means clustering with Active
Learning for efficient leveraging of labeled and unlabeled samples, with the
goal of discovering latent classes and describing a large collection of
screenshot data. We tested whether SVM-embedded or XGBoost-embedded solutions
for class probability propagation provide for more well-formed cluster
configurations. Visual and textual vector representations of the screenshot
images are derived and combined to assess the relative contribution of
multi-modal features to the overall performance.
"
1897,"Handcrafted vs Deep Learning Classification for Scalable Video QoE
  Modeling","  Mobile video traffic is dominant in cellular and enterprise wireless
networks. With the advent of diverse applications, network administrators face
the challenge to provide high QoE in the face of diverse wireless conditions
and application contents. Yet, state-of-the-art networks lack analytics for
QoE, as this requires support from the application or user feedback. While
there are existing techniques to map QoS to QoE by training machine learning
models without requiring user feedback, these techniques are limited to only
few applications, due to insufficient QoE ground-truth annotation for ML. To
address these limitations, we focus on video telephony applications and model
key artefacts of spatial and temporal video QoE. Our key contribution is
designing content- and device-independent metrics and training across diverse
WiFi conditions. We show that our metrics achieve a median 90% accuracy by
comparing with mean-opinion-score from more than 200 users and 800 video
samples over three popular video telephony applications -- Skype, FaceTime and
Google Hangouts. We further extend our metrics by using deep neural networks,
more specifically we use a combined CNN and LSTM model. We achieve a median
accuracy of 95% by combining our QoE metrics with the deep learning model,
which is a 38% improvement over the state-of-the-art well known techniques.
"
1898,"Somatic Practices for Understanding Real, Imagined, and Virtual
  Realities","  In most VR experiences, the visual sense dominates other modes of sensory
input, encouraging non-visual senses to respond as if the visual were real. The
simulated visual world thus becomes a sort of felt actuality, where the
'actual' physical body and environment can 'drop away', opening up
possibilities for designing entirely new kinds of experience. Most VR
experiences place visual sensory input (of the simulated environment) in the
perceptual foreground, and the physical body in the background. In what
follows, we discuss methods for resolving the apparent tension which arises
from VR's prioritization of visual perception. We specifically aim to
understand how somatic techniques encouraging participants to 'attend to their
attention' enable them to access more subtle aspects of sensory phenomena in a
VR experience, bound neither by rigid definitions of vision-based virtuality
nor body-based corporeality. During a series of workshops, we implemented
experimental somatic-dance practices to better understand perceptual and
imaginative subtleties that arise for participants whilst they are embedded in
a multi-person VR framework. Our preliminary observations suggest that somatic
methods can be used to design VR experiences which enable (i) a tactile quality
or felt sense of phenomena in the virtual environment (VE), (ii) lingering
impacts on participant imagination even after the VR headset is taken off, and
(iii) an expansion of imaginative potential.
"
1899,"The Deeper, the Better: Analysis of Person Attributes Recognition","  In person attributes recognition, we describe a person in terms of their
appearance. Typically, this includes a wide range of traits including age,
gender, clothing, and footwear. Although this could be used in a wide variety
of scenarios, it generally is applied to video surveillance, where attribute
recognition is impacted by low resolution, and other issues such as variable
pose, occlusion and shadow. Recent approaches have used deep convolutional
neural networks (CNNs) to improve the accuracy in person attribute recognition.
However, many of these networks are relatively shallow and it is unclear to
what extent they use contextual cues to improve classification accuracy. In
this paper, we propose deeper methods for person attribute recognition.
Interpreting the reasons behind the classification is highly important, as it
can provide insight into how the classifier is making decisions. Interpretation
suggests that deeper networks generally take more contextual information into
consideration, which helps improve classification accuracy and
generalizability. We present experimental analysis and results for whole body
attributes using the PA-100K and PETA datasets and facial attributes using the
CelebA dataset.
"
1900,SteganoGAN: High Capacity Image Steganography with GANs,"  Image steganography is a procedure for hiding messages inside pictures. While
other techniques such as cryptography aim to prevent adversaries from reading
the secret message, steganography aims to hide the presence of the message
itself. In this paper, we propose a novel technique for hiding arbitrary binary
data in images using generative adversarial networks which allow us to optimize
the perceptual quality of the images produced by our model. We show that our
approach achieves state-of-the-art payloads of 4.4 bits per pixel, evades
detection by steganalysis tools, and is effective on images from multiple
datasets. To enable fair comparisons, we have released an open source library
that is available online at https://github.com/DAI-Lab/SteganoGAN.
"
1901,"Learning Shared Semantic Space with Correlation Alignment for
  Cross-modal Event Retrieval","  In this paper, we propose to learn shared semantic space with correlation
alignment (${S}^{3}CA$) for multimodal data representations, which aligns
nonlinear correlations of multimodal data distributions in deep neural networks
designed for heterogeneous data. In the context of cross-modal (event)
retrieval, we design a neural network with convolutional layers and
fully-connected layers to extract features for images, including images on
Flickr-like social media. Simultaneously, we exploit a fully-connected neural
network to extract semantic features for texts, including news articles from
news media. In particular, nonlinear correlations of layer activations in the
two neural networks are aligned with correlation alignment during the joint
training of the networks. Furthermore, we project the multimodal data into a
shared semantic space for cross-modal (event) retrieval, where the distances
between heterogeneous data samples can be measured directly. In addition, we
contribute a Wiki-Flickr Event dataset, where the multimodal data samples are
not describing each other in pairs like the existing paired datasets, but all
of them are describing semantic events. Extensive experiments conducted on both
paired and unpaired datasets manifest the effectiveness of ${S}^{3}CA$,
outperforming the state-of-the-art methods.
"
1902,Music Artist Classification with Convolutional Recurrent Neural Networks,"  Previous attempts at music artist classification use frame level audio
features which summarize frequency content within short intervals of time.
Comparatively, more recent music information retrieval tasks take advantage of
temporal structure in audio spectrograms using deep convolutional and recurrent
models. This paper revisits artist classification with this new framework and
empirically explores the impacts of incorporating temporal structure in the
feature representation. To this end, an established classification
architecture, a Convolutional Recurrent Neural Network (CRNN), is applied to
the artist20 music artist identification dataset under a comprehensive set of
conditions. These include audio clip length, which is a novel contribution in
this work, and previously identified considerations such as dataset split and
feature level. Our results improve upon baseline works, verify the influence of
the producer effect on classification performance and demonstrate the
trade-offs between audio length and training set size. The best performing
model achieves an average F1 score of 0.937 across three independent trials
which is a substantial improvement over the corresponding baseline under
similar conditions. Additionally, to showcase the effectiveness of the CRNN's
feature extraction capabilities, we visualize audio samples at the model's
bottleneck layer demonstrating that learned representations segment into
clusters belonging to their respective artists.
"
1903,"CBA: Contextual Quality Adaptation for Adaptive Bitrate Video Streaming
  (Extended Version)","  Recent advances in quality adaptation algorithms leave adaptive bitrate (ABR)
streaming architectures at a crossroads: When determining the sustainable video
quality one may either rely on the information gathered at the client vantage
point or on server and network assistance. The fundamental problem here is to
determine how valuable either information is for the adaptation decision. This
problem becomes particularly hard in future Internet settings such as Named
Data Networking (NDN) where the notion of a network connection does not exist.
  In this paper, we provide a fresh view on ABR quality adaptation for QoE
maximization, which we formalize as a decision problem under uncertainty, and
for which we contribute a sparse Bayesian contextual bandit algorithm denoted
CBA. This allows taking high-dimensional streaming context information,
including client-measured variables and network assistance, to find online the
most valuable information for the quality adaptation. Since sparse Bayesian
estimation is computationally expensive, we develop a fast new inference scheme
to support online video adaptation. We perform an extensive evaluation of our
adaptation algorithm in the particularly challenging setting of NDN, where we
use an emulation testbed to demonstrate the efficacy of CBA compared to
state-of-the-art algorithms.
"
1904,Video Multimethod Assessment Fusion (VMAF) on 360VR contents,"  This paper describes the subjective experiments and subsequent analysis
carried out to validate the application of one of the most robust and
influential video quality metrics, Video Multimethod Assessment Fusion (VMAF),
to 360VR contents. VMAF is a full reference metric initially designed to work
with traditional 2D contents. Hence, at first, it cannot be assumed to be
compatible with the particularities of the scenario where omnidirectional
content is visualized using a Head-Mounted Display (HMD). Therefore, through a
complete set of tests, we prove that this metric can be successfully used
without any specific training or adjustments to obtain the quality of 360VR
sequences actually perceived by users.
"
1905,"Spec-ResNet: A General Audio Steganalysis scheme based on Deep Residual
  Network of Spectrogram","  The widespread application of audio and video communication technology make
the compressed audio data flowing over the Internet, and make it become an
important carrier for covert communication. There are many steganographic
schemes emerged in the mainstream audio compression data, such as AAC and MP3,
followed by many steganalysis schemes. However, these steganalysis schemes are
only effective in the specific embedded domain. In this paper, a general
steganalysis scheme Spec-ResNet (Deep Residual Network of Spectrogram) is
proposed to detect the steganography schemes of different embedding domain for
AAC and MP3. The basic idea is that the steganographic modification of
different embedding domain will all introduce the change of the decoded audio
signal. In this paper, the spectrogram, which is the visual representation of
the spectrum of frequencies of audio signal, is adopted as the input of the
feature network to extract the universal features introduced by steganography
schemes; Deep Neural Network Spec-ResNet is well-designed to represent the
steganalysis feature; and the features extracted from different spectrogram
windows are combined to fully capture the steganalysis features. The experiment
results show that the proposed scheme has good detection accuracy and
generality. The proposed scheme has better detection accuracy for three
different AAC steganographic schemes and MP3Stego than the state-of-arts
steganalysis schemes which are based on traditional hand-crafted or CNN-based
feature. To the best of our knowledge, the audio steganalysis scheme based on
the spectrogram and deep residual network is first proposed in this paper. The
method proposed in this paper can be extended to the audio steganalysis of
other codec or audio forensics.
"
1906,A Fourier Disparity Layer representation for Light Fields,"  In this paper, we present a new Light Field representation for efficient
Light Field processing and rendering called Fourier Disparity Layers (FDL). The
proposed FDL representation samples the Light Field in the depth (or
equivalently the disparity) dimension by decomposing the scene as a discrete
sum of layers. The layers can be constructed from various types of Light Field
inputs including a set of sub-aperture images, a focal stack, or even a
combination of both. From our derivations in the Fourier domain, the layers are
simply obtained by a regularized least square regression performed
independently at each spatial frequency, which is efficiently parallelized in a
GPU implementation. Our model is also used to derive a gradient descent based
calibration step that estimates the input view positions and an optimal set of
disparity values required for the layer construction. Once the layers are
known, they can be simply shifted and filtered to produce different viewpoints
of the scene while controlling the focus and simulating a camera aperture of
arbitrary shape and size. Our implementation in the Fourier domain allows real
time Light Field rendering. Finally, direct applications such as view
interpolation or extrapolation and denoising are presented and evaluated.
"
1907,"Hybrid Design Tools - Image Quality Assessment of a Digitally Augmented
  Blackboard Integrated System","  In the last two decades, Interactive White Boards (IWBs) have been widely
available as a pedagogic tool. The usability of these boards for teaching
disciplines where complex drawings are needed, we consider debatable in
multiple regards. In a previous study, we proposed an alternative to the IWBs
as a blackboard augmented with a minimum of necessary digital elements. The
current study continues our previous research on hybrid design tools, analyzing
the limitations of the developed hybrid system regarding the perceived quality
of the images being repeatedly captured, annotated, and reprojected onto the
board. We validated the hybrid system by evaluating the quality of the
projected and reprojected images over a blackboard, using both objective
measurements and subjective human perception in extensive and realistic case
studies. Based on the results achieved in the current research, we conclude
that the proposed hybrid system provides good quality support for teaching
disciplines that require complex drawings and board interaction.
"
1908,Efficient Image Splicing Localization via Contrastive Feature Extraction,"  In this work, we propose a new data visualization and clustering technique
for discovering discriminative structures in high-dimensional data. This
technique, referred to as cPCA++, utilizes the fact that the interesting
features of a ""target"" dataset may be obscured by high variance components
during traditional PCA. By analyzing what is referred to as a ""background""
dataset (i.e., one that exhibits the high variance principal components but not
the interesting structures), our technique is capable of efficiently
highlighting the structure that is unique to the ""target"" dataset. Similar to
another recently proposed algorithm called ""contrastive PCA"" (cPCA), the
proposed cPCA++ method identifies important dataset specific patterns that are
not detected by traditional PCA in a wide variety of settings. However, the
proposed cPCA++ method is significantly more efficient than cPCA, because it
does not require the parameter sweep in the latter approach. We applied the
cPCA++ method to the problem of image splicing localization. In this
application, we utilize authentic edges as the background dataset and the
spliced edges as the target dataset. The proposed method is significantly more
efficient than state-of-the-art methods, as the former does not require
iterative updates of filter weights via stochastic gradient descent and
backpropagation, nor the training of a classifier. Furthermore, the cPCA++
method is shown to provide performance scores comparable to the
state-of-the-art Multi-task Fully Convolutional Network (MFCN).
"
1909,On basis images for the digital image representation,"  Digital array orthogonal transformations that can be presented as a
decomposition over basis items or basis images are considered. The orthogonal
transform provides digital data scattering, a process of pixel energy
redistributing, that is illustrated with the help of basis images. Data
scattering plays important role for applications as image coding and
watermarking. We established a simple quantum analogues of basis images. They
are representations of quantum operators that describe transition of single
particle between its states.
  Considering basis images as items of a matrix, we introduced a block matrix
that is suitable for orthogonal transforms of multi-dimensional arrays such as
block vector, components of which are matrices. We present an orthogonal
transform that produces correlation between arrays. Due to correlation new
feature of data scattering was found. A presented detection algorithm is an
example of how it can be used in frequency domain watermarking.
"
1910,"Generalization of Spoofing Countermeasures: a Case Study with ASVspoof
  2015 and BTAS 2016 Corpora","  Voice-based biometric systems are highly prone to spoofing attacks. Recently,
various countermeasures have been developed for detecting different kinds of
attacks such as replay, speech synthesis (SS) and voice conversion (VC). Most
of the existing studies are conducted with a specific training set defined by
the evaluation protocol. However, for realistic scenarios, selecting
appropriate training data is an open challenge for the system administrator.
Motivated by this practical concern, this work investigates the generalization
capability of spoofing countermeasures in restricted training conditions where
speech from a broad attack types are left out in the training database. We
demonstrate that different spoofing types have considerably different
generalization capabilities. For this study, we analyze the performance using
two kinds of features, mel-frequency cepstral coefficients (MFCCs) which are
considered as baseline and recently proposed constant Q cepstral coefficients
(CQCCs). The experiments are conducted with standard Gaussian mixture model -
maximum likelihood (GMM-ML) classifier on two recently released spoofing
corpora: ASVspoof 2015 and BTAS 2016 that includes cross-corpora performance
analysis. Feature-level analysis suggests that static and dynamic coefficients
of spectral features, both are important for detecting spoofing attacks in the
real-life condition.
"
1911,"Multi-stream Network With Temporal Attention For Environmental Sound
  Classification","  Environmental sound classification systems often do not perform robustly
across different sound classification tasks and audio signals of varying
temporal structures. We introduce a multi-stream convolutional neural network
with temporal attention that addresses these problems. The network relies on
three input streams consisting of raw audio and spectral features and utilizes
a temporal attention function computed from energy changes over time. Training
and classification utilizes decision fusion and data augmentation techniques
that incorporate uncertainty. We evaluate this network on three commonly used
data sets for environmental sound and audio scene classification and achieve
new state-of-the-art performance without any changes in network architecture or
front-end preprocessing, thus demonstrating better generalizability.
"
1912,User Donations in a Crowdsourced Video System,"  Crowdsourced video systems like YouTube and Twitch.tv have been a major
internet phenomenon and are nowadays entertaining over a billion users. In
addition to video sharing and viewing, over the years they have developed new
features to boost the community engagement and some managed to attract users to
donate, to the community as well as to other users. User donation directly
reflects and influences user engagement in the community, and has a great
impact on the success of such systems. Nevertheless, user donations in
crowdsourced video systems remain trade secrets for most companies and to date
are still unexplored. In this work, we attempt to fill this gap, and we obtain
and provide a publicly available dataset on user donations in one crowdsourced
video system named BiliBili. Based on information on nearly 40 thousand
donators, we examine the dynamics of user donations and their social
relationships, we quantitively reveal the factors that potentially impact user
donation, and we adopt machine-learned classifiers and network representation
learning models to timely and accurately predict the destinations of the
majority and the individual donations.
"
1913,Attribute-Guided Sketch Generation,"  Facial attributes are important since they provide a detailed description and
determine the visual appearance of human faces. In this paper, we aim at
converting a face image to a sketch while simultaneously generating facial
attributes. To this end, we propose a novel Attribute-Guided Sketch Generative
Adversarial Network (ASGAN) which is an end-to-end framework and contains two
pairs of generators and discriminators, one of which is used to generate faces
with attributes while the other one is employed for image-to-sketch
translation. The two generators form a W-shaped network (W-net) and they are
trained jointly with a weight-sharing constraint. Additionally, we also propose
two novel discriminators, the residual one focusing on attribute generation and
the triplex one helping to generate realistic looking sketches. To validate our
model, we have created a new large dataset with 8,804 images, named the
Attribute Face Photo & Sketch (AFPS) dataset which is the first dataset
containing attributes associated to face sketch images. The experimental
results demonstrate that the proposed network (i) generates more
photo-realistic faces with sharper facial attributes than baselines and (ii)
has good generalization capability on different generative tasks.
"
1914,"Who's Afraid of Adversarial Queries? The Impact of Image Modifications
  on Content-based Image Retrieval","  An adversarial query is an image that has been modified to disrupt
content-based image retrieval (CBIR) while appearing nearly untouched to the
human eye. This paper presents an analysis of adversarial queries for CBIR
based on neural, local, and global features. We introduce an innovative neural
image perturbation approach, called Perturbations for Image Retrieval Error
(PIRE), that is capable of blocking neural-feature-based CBIR. PIRE differs
significantly from existing approaches that create images adversarial with
respect to CNN classifiers because it is unsupervised, i.e., it needs no
labelled data from the data set to which it is applied. Our experimental
analysis demonstrates the surprising effectiveness of PIRE in blocking CBIR,
and also covers aspects of PIRE that must be taken into account in practical
settings, including saving images, image quality and leaking adversarial
queries into the background collection. Our experiments also compare PIRE (a
neural approach) with existing keypoint removal and injection approaches (which
modify local features). Finally, we discuss the challenges that face multimedia
researchers in the future study of adversarial queries.
"
1915,"Matching Users' Preference Under Target Revenue Constraints in Optimal
  Data Recommendation Systems","  This paper focuses on the problem of finding a particular data recommendation
strategy based on the user preferences and a system expected revenue. To this
end, we formulate this problem as an optimization by designing the
recommendation mechanism as close to the user behavior as possible with a
certain revenue constraint. In fact, the optimal recommendation distribution is
the one that is the closest to the utility distribution in the sense of
relative entropy and satisfies expected revenue. We show that the optimal
recommendation distribution follows the same form as the message importance
measure (MIM) if the target revenue is reasonable, i.e., neither too small nor
too large. Therefore, the optimal recommendation distribution can be regarded
as the normalized MIM, where the parameter, called importance coefficient,
presents the concern of the system and switches the attention of the system
over data sets with different occurring probability. By adjusting the
importance coefficient, our MIM based framework of data recommendation can then
be applied to system with various system requirements and data
distributions.Therefore,the obtained results illustrate the physical meaning of
MIM from the data recommendation perspective and validate the rationality of
MIM in one aspect.
"
1916,A study for Image compression using Re-Pair algorithm,"  The compression is an important topic in computer science which allows we to
storage more amount of data on our data storage. There are several techniques
to compress any file. In this manuscript will be described the most important
algorithm to compress images such as JPEG and it will be compared with another
method to retrieve good reason to not use this method on images. So to compress
the text the most encoding technique known is the Huffman Encoding which it
will be explained in exhaustive way. In this manuscript will showed how to
compute a text compression method on images in particular the method and the
reason to choice a determinate image format against the other. The method
studied and analyzed in this manuscript is the Re-Pair algorithm which is
purely for grammatical context to be compress. At the and it will be showed the
good result of this application.
"
1917,"Benefiting from Duplicates of Compressed Data: Shift-Based Holographic
  Compression of Images","  Storage systems often rely on multiple copies of the same compressed data,
enabling recovery in case of binary data errors, of course, at the expense of a
higher storage cost. In this paper we show that a wiser method of duplication
entails great potential benefits for data types tolerating approximate
representations, like images and videos. We propose a method to produce a set
of distinct compressed representations for a given signal, such that any subset
of them allows reconstruction of the signal at a quality depending only on the
number of compressed representations utilized. Essentially, we implement the
holographic representation idea, where all the representations are equally
important in refining the reconstruction. Here we propose to exploit the shift
sensitivity of common compression processes and generate holographic
representations via compression of various shifts of the signal. Two
implementations for the idea, based on standard compression methods, are
presented: the first is a simple, optimization-free design. The second approach
originates in a challenging rate-distortion optimization, mitigated by the
alternating direction method of multipliers (ADMM), leading to a process of
repeatedly applying standard compression techniques. Evaluation of the
approach, in conjunction with the JPEG2000 image compression standard, shows
the effectiveness of the optimization in providing compressed holographic
representations that, by means of an elementary reconstruction process, enable
impressive gains of several dBs in PSNR over exact duplications.
"
1918,"ACSEE: Antagonistic Crowd Simulation Model with Emotional Contagion and
  Evolutionary Game Theory","  Antagonistic crowd behaviors are often observed in cases of serious conflict.
Antagonistic emotions, which is the typical psychological state of agents in
different roles (i.e. cops, activists, and civilians) in crowd violent scenes,
and the way they spread through contagion in a crowd are important causes of
crowd antagonistic behaviors. Moreover, games, which refers to the interaction
between opposing groups adopting different strategies to obtain higher benefits
and less casualties, determine the level of crowd violence. We present an
antagonistic crowd simulation model, ACSEE, which is integrated with
antagonistic emotional contagion and evolutionary game theories. Our approach
models the antagonistic emotions between agents in different roles using two
components: mental emotion and external emotion. We combine enhanced
susceptible-infectious-susceptible (SIS) and game approaches to evaluate the
role of antagonistic emotional contagion in crowd violence. Our evolutionary
game theoretic approach incorporates antagonistic emotional contagion through
deterrent force, which is modelled by a mixture of emotional forces and
physical forces defeating the opponents. Antagonistic emotional contagion and
evolutionary game theories influence each other to determine antagonistic crowd
behaviors. We evaluate our approach on real-world scenarios consisting of
different kinds of agents. We also compare the simulated crowd behaviors with
real-world crowd videos and use our approach to predict the trends of crowd
movements in violence incidents. We investigate the impact of various factors
(number of agents, emotion, strategy, etc.) on the outcome of crowd violence.
We present results from user studies suggesting that our model can simulate
antagonistic crowd behaviors similar to those seen in real-world scenarios.
"
1919,"Multiuser Video Streaming Rate Adaptation: A Physical Layer
  Resource-Aware Deep Reinforcement Learning Approach","  We consider a multi-user video streaming service optimization problem over a
time-varying and mutually interfering multi-cell wireless network. The key
research challenge is to appropriately adapt each user's video streaming rate
according to the radio frequency environment (e.g., channel fading and
interference level) and service demands (e.g., play request), so that the
users' long-term experience for watching videos can be optimized. To address
the above challenge, we propose a novel two-level cross-layer optimization
framework for multiuser adaptive video streaming over wireless networks. The
key idea is to jointly design the physical layer optimization-based beamforming
scheme (performed at the base stations) and the application layer Deep
Reinforcement Learning (DRL)-based scheme (performed at the user terminals), so
that a highly complex multi-user, cross-layer, time-varying video streaming
problem can be decomposed into relatively simple problems and solved
effectively. Our strategy represents a significant departure for the existing
schemes where either short-term user experience optimization is considered, or
only single-user point-to-point long-term optimization is considered. Extensive
simulations based on real-data sets show that the proposed cross-layer design
is effective and promising.
"
1920,Data Driven Analysis of Tiny Touchscreen Performance with MicroJam,"  The widespread adoption of mobile devices, such as smartphones and tablets,
has made touchscreens a common interface for musical performance. New mobile
musical instruments have been designed that embrace collaborative creation and
that explore the affordances of mobile devices, as well as their constraints.
While these have been investigated from design and user experience
perspectives, there is little examination of the performers' musical outputs.
In this work, we introduce a constrained touchscreen performance app, MicroJam,
designed to enable collaboration between performers, and engage in a novel
data-driven analysis of more than 1600 performances using the app. MicroJam
constrains performances to five seconds, and emphasises frequent and casual
music making through a social media-inspired interface. Performers collaborate
by replying to performances, adding new musical layers that are played back at
the same time. Our analysis shows that users tend to focus on the centre and
diagonals of the touchscreen area, and tend to swirl or swipe rather than tap.
We also observe that while long swipes dominate the visual appearance of
performances, the majority of interactions are short with limited expressive
possibilities. Our findings are summarised into a set of design recommendations
for MicroJam and other touchscreen apps for social musical interaction.
"
1921,"Real-Time Steganalysis for Stream Media Based on Multi-channel
  Convolutional Sliding Windows","  Previous VoIP steganalysis methods face great challenges in detecting speech
signals at low embedding rates, and they are also generally difficult to
perform real-time detection, making them hard to truly maintain cyberspace
security. To solve these two challenges, in this paper, combined with the
sliding window detection algorithm and Convolution Neural Network we propose a
real-time VoIP steganalysis method which based on multi-channel convolution
sliding windows. In order to analyze the correlations between frames and
different neighborhood frames in a VoIP signal, we define multi channel sliding
detection windows. Within each sliding window, we design two feature extraction
channels which contain multiple convolution layers with multiple convolution
kernels each layer to extract correlation features of the input signal. Then
based on these extracted features, we use a forward fully connected network for
feature fusion. Finally, by analyzing the statistical distribution of these
features, the discriminator will determine whether the input speech signal
contains covert information or not.We designed several experiments to test the
proposed model's detection ability under various conditions, including
different embedding rates, different speech length, etc. Experimental results
showed that the proposed model outperforms all the previous methods, especially
in the case of low embedding rate, which showed state-of-the-art performance.
In addition, we also tested the detection efficiency of the proposed model, and
the results showed that it can achieve almost real-time detection of VoIP
speech signals.
"
1922,"Vignette: Perceptual Compression for Video Storage and Processing
  Systems","  Compressed videos constitute 70% of Internet traffic, and video upload growth
rates far outpace compute and storage improvement trends. Past work in
leveraging perceptual cues like saliency, i.e., regions where viewers focus
their perceptual attention, reduces compressed video size while maintaining
perceptual quality, but requires significant changes to video codecs and
ignores the data management of this perceptual information.
  In this paper, we propose Vignette, a compression technique and storage
manager for perception-based video compression. Vignette complements
off-the-shelf compression software and hardware codec implementations.
Vignette's compression technique uses a neural network to predict saliency
information used during transcoding, and its storage manager integrates
perceptual information into the video storage system to support a perceptual
compression feedback loop. Vignette's saliency-based optimizations reduce
storage by up to 95% with minimal quality loss, and Vignette videos lead to
power savings of 50% on mobile phones during video playback. Our results
demonstrate the benefit of embedding information about the human visual system
into the architecture of video storage systems.
"
1923,Iris Image Processing in Compressive Sensing Scenario,"  This paper observes the application of the Compressive Sensing in
reconstruction of the under-sampled iris images. Iris recognition represents
form of biometric identification whose usage in real applications is growing.
Compressive Sensing represents a novel form of sparse signal acquisition and
recovering when small amount of data is a available. Different sparsity domains
are considered and compared using various number of available image pixels. The
theory is verified on iris images.
"
1924,"Generative Moment Matching Network-based Random Modulation Post-filter
  for DNN-based Singing Voice Synthesis and Neural Double-tracking","  This paper proposes a generative moment matching network (GMMN)-based
post-filter that provides inter-utterance pitch variation for deep neural
network (DNN)-based singing voice synthesis. The natural pitch variation of a
human singing voice leads to a richer musical experience and is used in
double-tracking, a recording method in which two performances of the same
phrase are recorded and mixed to create a richer, layered sound. However,
singing voices synthesized using conventional DNN-based methods never vary
because the synthesis process is deterministic and only one waveform is
synthesized from one musical score. To address this problem, we use a GMMN to
model the variation of the modulation spectrum of the pitch contour of natural
singing voices and add a randomized inter-utterance variation to the pitch
contour generated by conventional DNN-based singing voice synthesis.
Experimental evaluations suggest that 1) our approach can provide perceptible
inter-utterance pitch variation while preserving speech quality. We extend our
approach to double-tracking, and the evaluation demonstrates that 2) GMMN-based
neural double-tracking is perceptually closer to natural double-tracking than
conventional signal processing-based artificial double-tracking is.
"
1925,"Towards an All-Purpose Content-Based Multimedia Information Retrieval
  System","  The growth of multimedia collections - in terms of size, heterogeneity, and
variety of media types - necessitates systems that are able to conjointly deal
with several forms of media, especially when it comes to searching for
particular objects. However, existing retrieval systems are organized in silos
and treat different media types separately. As a consequence, retrieval across
media types is either not supported at all or subject to major limitations. In
this paper, we present vitrivr, a content-based multimedia information
retrieval stack. As opposed to the keyword search approach implemented by most
media management systems, vitrivr makes direct use of the object's content to
facilitate different types of similarity search, such as Query-by-Example or
Query-by-Sketch, for and, most importantly, across different media types -
namely, images, audio, videos, and 3D models. Furthermore, we introduce a new
web-based user interface that enables easy-to-use, multimodal retrieval from
and browsing in mixed media collections. The effectiveness of vitrivr is shown
on the basis of a user study that involves different query and media types. To
the best of our knowledge, the full vitrivr stack is unique in that it is the
first multimedia retrieval system that seamlessly integrates support for four
different types of media. As such, it paves the way towards an all-purpose,
content-based multimedia information retrieval system.
"
1926,A Fast Iterative Method for Removing Impulsive Noise from Sparse Signals,"  In this paper, we propose a new method to reconstruct a signal corrupted by
noise where both signal and noise are sparse but in different domains. The
problem investigated in this paper arises in different applications such as
impulsive noise removal from images, audios and videos, decomposition of
low-rank and sparse components of matrices, and separation of texts from
images. First, we provide a cost function for our problem and then present an
iterative method to find its local minimum. The analysis of the algorithm is
also provided. As an application of this problem, we apply our algorithm for
impulsive noise Salt-and-Pepper noise (SPN) and Random-Valued Impulsive Noise
(RVIN)) removal from images and compare our results with other notable
algorithms in the literature. Furthermore, we apply our algorithm for removing
clicks from audio signals. Simulation results show that our algorithms is
simple and fast, and it outperforms other state-of-the-art methods in terms of
reconstruction quality and/or complexity.
"
1927,"Multi-tier Caching Analysis in CDN-based Over-the-top Video Streaming
  Systems","  Internet video traffic has been been rapidly increasing and is further
expected to increase with the emerging 5G applications such as higher
definition videos, IoT and augmented/virtual reality applications. As end-users
consume video in massive amounts and in an increasing number of ways, the
content distribution network (CDN) should be efficiently managed to improve the
system efficiency. The streaming service can include multiple caching tiers, at
the distributed servers and the edge routers, and efficient content management
at these locations affect the quality of experience (QoE) of the end users. In
this paper, we propose a model for video streaming systems, typically composed
of a centralized origin server, several CDN sites, and edge-caches located
closer to the end user. We comprehensively consider different systems design
factors including the limited caching space at the CDN sites, allocation of CDN
for a video request, choice of different ports (or paths) from the CDN and the
central storage, bandwidth allocation, the edge-cache capacity, and the caching
policy. We focus on minimizing a performance metric, stall duration tail
probability (SDTP), and present a novel and efficient algorithm accounting for
the multiple design flexibilities. The theoretical bounds with respect to the
SDTP metric are also analyzed and presented. The implementation on a
virtualized cloud system managed by Openstack demonstrate that the proposed
algorithms can significantly improve the SDTP metric, compared to the baseline
strategies.
"
1928,"Occupancy-map-based rate distortion optimization for video-based point
  cloud compression","  The state-of-the-art video-based point cloud compression scheme projects the
3D point cloud to 2D patch by patch and organizes the patches into frames to
compress them using the efficient video compression scheme. Such a scheme shows
a good trade-off between the number of points projected and the video
continuity to utilize the video compression scheme. However, some unoccupied
pixels between different patches are compressed using almost the same quality
with the occupied pixels, which will lead to the waste of lots of bits since
the unoccupied pixels are useless for the reconstructed point cloud. In this
paper, we propose to consider only the rate instead of the rate distortion cost
for the unoccupied pixels during the rate distortion optimization process. The
proposed scheme can be applied to both the geometry and attribute frames. The
experimental results show that the proposed algorithm can achieve an average of
11.9% and 15.4% bitrate savings for the geometry and attribute, respectively.
"
1929,"A block-based inter-band predictor using multilayer propagation neural
  network for hyperspectral image compression","  In this paper, a block-based inter-band predictor (BIP) with multilayer
propagation neural network model (MLPNN) is presented by a completely new
framework. This predictor can combine with diversity entropy coding methods.
Hyperspectral (HS) images are composed by a series high similarity spectral
bands. Our assumption is to use trained MLPNN predict the succeeding bands
based on current band information. The purpose is to explore whether BIP-MLPNN
can provide better image predictive results with high efficiency. The algorithm
also changed from the traditional compression methods encoding images pixel by
pixel, the compression process only encodes the weights and the biases vectors
of BIP-MLPNN which require few bits to transfer. The decoder will reconstruct a
band by using the same structure of the network at the encoder side. The
BIP-MLPNN decoder does not need to be trained as the weights and biases have
already been transmitted. We can easily reconstruct the succeeding bands by
using the BIP-MLPNN decoder. The experimental results indicate that BIP-MLPNN
predictor outperforms the CCSDS-123 HS image coding standard. Due to a good
approximation of the target band, the proposed method outperforms the CCSDS-123
by more than 2.0dB PSNR image quality in the predicted bands. Moreover, the
proposed method provides high quality image e.g., 30 to 40dB PSNR at very low
bit rate (less than 0.1 bpppb) and outperforms the existing methods e.g., JPEG,
3DSPECK, 3DSPIHT and in terms of rate-distortion performance.
"
1930,"Cross-Modal Music Retrieval and Applications: An Overview of Key
  Methodologies","  There has been a rapid growth of digitally available music data, including
audio recordings, digitized images of sheet music, album covers and liner
notes, and video clips. This huge amount of data calls for retrieval strategies
that allow users to explore large music collections in a convenient way. More
precisely, there is a need for cross-modal retrieval algorithms that, given a
query in one modality (e.g., a short audio excerpt), find corresponding
information and entities in other modalities (e.g., the name of the piece and
the sheet music). This goes beyond exact audio identification and subsequent
retrieval of metainformation as performed by commercial applications like
Shazam [1].
"
1931,"Super-Resolution of Brain MRI Images using Overcomplete Dictionaries and
  Nonlocal Similarity","  Recently, the Magnetic Resonance Imaging (MRI) images have limited and
unsatisfactory resolutions due to various constraints such as physical,
technological and economic considerations. Super-resolution techniques can
obtain high-resolution MRI images. The traditional methods obtained the
resolution enhancement of brain MRI by interpolations, affecting the accuracy
of the following diagnose process. The requirement for brain image quality is
fast increasing. In this paper, we propose an image super-resolution (SR)
method based on overcomplete dictionaries and inherent similarity of an image
to recover the high-resolution (HR) image from a single low-resolution (LR)
image. We explore the nonlocal similarity of the image to tentatively search
for similar blocks in the whole image and present a joint reconstruction method
based on compressive sensing (CS) and similarity constraints. The sparsity and
self-similarity of the image blocks are taken as the constraints. The proposed
method is summarized in the following steps. First, a dictionary classification
method based on the measurement domain is presented. The image blocks are
classified into smooth, texture and edge parts by analyzing their features in
the measurement domain. Then, the corresponding dictionaries are trained using
the classified image blocks. Equally important, in the reconstruction part, we
use the CS reconstruction method to recover the HR brain MRI image, considering
both nonlocal similarity and the sparsity of an image as the constraints. This
method performs better both visually and quantitatively than some existing
methods.
"
1932,"Development of Video Frame Enhancement Technique Using Pixel Intensity
  Analysis","  This paper developed a brightness enhancement technique for video frame pixel
intensity improvement. Frames extracted from the six sample video data used in
this work were stored in the form of images in a buffer. Noise was added to the
extracted image frames to vary the intensity of their pixels so that the pixel
values of the noisy images differ from their true values in order to determine
the efficiency of the developed technique. Simulation results showed that, the
developed technique was efficient with an improved pixel intensity and
histogram distribution. The Peak to Signal Noise Ratio evaluation showed that
the efficiency of the developed technique for both grayscale and coloured video
frames were improved by PSNR of 12.45%, 16.32%, 27.57% and 19.83% over the grey
level colour (black and white) for the NAELS1.avi, NAELS2.avi, NTA1.avi and
NTA2.avi respectively. Also, a percentage improvement of 28.93% and 31.68% were
obtained for the coloured image over the grey level image for Akiyo.avi and
Forman.avi benchmark video frame, respectively.
"
1933,"Multi-task learning with compressible features for Collaborative
  Intelligence","  A promising way to deploy Artificial Intelligence (AI)-based services on
mobile devices is to run a part of the AI model (a deep neural network) on the
mobile itself, and the rest in the cloud. This is sometimes referred to as
collaborative intelligence. In this framework, intermediate features from the
deep network need to be transmitted to the cloud for further processing. We
study the case where such features are used for multiple purposes in the cloud
(multi-tasking) and where they need to be compressible in order to allow
efficient transmission to the cloud. To this end, we introduce a new loss
function that encourages feature compressibility while improving system
performance on multiple tasks. Experimental results show that with the
compression-friendly loss, one can achieve around 20% bitrate reduction without
sacrificing the performance on several vision-related tasks.
"
1934,"Multimodal music information processing and retrieval: survey and future
  challenges","  Towards improving the performance in various music information processing
tasks, recent studies exploit different modalities able to capture diverse
aspects of music. Such modalities include audio recordings, symbolic music
scores, mid-level representations, motion, and gestural data, video recordings,
editorial or cultural tags, lyrics and album cover arts. This paper critically
reviews the various approaches adopted in Music Information Processing and
Retrieval and highlights how multimodal algorithms can help Music Computing
applications. First, we categorize the related literature based on the
application they address. Subsequently, we analyze existing information fusion
approaches, and we conclude with the set of challenges that Music Information
Retrieval and Sound and Music Computing research communities should focus in
the next years.
"
1935,"License Plate Recognition with Compressive Sensing Based Feature
  Extraction","  License plate recognition is the key component to many automatic traffic
control systems. It enables the automatic identification of vehicles in many
applications. Such systems must be able to identify vehicles from images taken
in various conditions including low light, rain, snow, etc. In order to reduce
the complexity and cost of the hardware required for such devices, the
algorithm should be as efficient as possible. This paper proposes a license
plate recognition system which uses a new approach based on compressive sensing
techniques for dimensionality reduction and feature extraction. Dimensionality
reduction will enable precise classification with less training data while
demanding less computational power. Based on the extracted features, character
recognition and classification is done by a Support Vector Machine classifier.
"
1936,"Predicting tongue motion in unlabeled ultrasound videos using
  convolutional LSTM neural network","  A challenge in speech production research is to predict future tongue
movements based on a short period of past tongue movements. This study tackles
speaker-dependent tongue motion prediction problem in unlabeled ultrasound
videos with convolutional long short-term memory (ConvLSTM) networks. The model
has been tested on two different ultrasound corpora. ConvLSTM outperforms
3-dimensional convolutional neural network (3DCNN) in predicting the
9\textsuperscript{th} frames based on 8 preceding frames, and also demonstrates
good capacity to predict only the tongue contours in future frames. Further
tests reveal that ConvLSTM can also learn to predict tongue movements in more
distant frames beyond the immediately following frames. Our codes are available
at: https://github.com/shuiliwanwu/ConvLstm-ultrasound-videos.
"
1937,"Effectiveness of Crypto-Transcoding for H.264/AVC and HEVC Video
  Bit-streams","  To avoid delays arising from a need to decrypt a video prior to transcoding
and then re-encrypt it afterwards, this paper assesses a selective encryption
(SE) content protection scheme. The scheme is suited to both recent
standardized codecs, namely H.264/Advanced Video Coding (AVC) and High
Efficiency Video Coding (HEVC). Specifically, the paper outlines a joint
crypto-transcoding scheme for secure transrating of a video bitstream. That is
to say it generates new video bitrates, possibly as part of an HTTP Adaptive
Streaming (HAS) content delivery network. The scheme will reduce the bitrate to
one or more lower desired bit-rate without consuming time in the
encryption/decryption process, which would be the case when full encryption is
used. In addition, the decryption key no longer needs to be exposed at
intermediate middleboxes, including when transrating is performed in a cloud
datacenter. The effectiveness of the scheme is variously evaluated: by
examination of the SE generated visual distortion; by the extent of
computational and bitrate overheads; and by choice of cipher when encrypting
the selected elements within the bitstream. Results indicate that there
remains: a content; quantization level (after transrating of an encrypted
video); and codec-type dependency to any distortion introduced. A further
recommendation is that the Advanced Encryption Standard (AES) is preferred for
SE to lightweight XOR encryption, despite it being taken up elsewhere as a
real-time encryption method.
"
1938,The NIGENS General Sound Events Database,"  Computational auditory scene analysis is gaining interest in the last years.
Trailing behind the more mature field of speech recognition, it is particularly
general sound event detection that is attracting increasing attention. Crucial
for training and testing reasonable models is having available enough suitable
data -- until recently, general sound event databases were hardly found. We
release and present a database with 714 wav files containing isolated high
quality sound events of 14 different types, plus 303 `general' wav files of
anything else but these 14 types. All sound events are strongly labeled with
perceptual on- and offset times, paying attention to omitting in-between
silences. The amount of isolated sound events, the quality of annotations, and
the particular general sound class distinguish NIGENS from other databases.
"
1939,"Tile-Based Joint Caching and Delivery of $360^o$ Videos in Heterogeneous
  Networks","  The recent surge of applications involving the use of $360^o$ video
challenges mobile networks infrastructure, as $360^o$ video files are of
significant size, and current delivery and edge caching architectures are
unable to guarantee their timely delivery. In this paper, we investigate the
problem of joint collaborative content-aware caching and delivery of $360^o$
videos in a video on demand setting. The proposed scheme takes advantage of
$360^o$ video encoding in multiple tiles and layers to make fine-grained
decisions regarding which tiles to cache in each Small Base Station (SBS), and
where to deliver them from to the end users, as users may reside in the
coverage area of multiple SBSs. This permits to cache the most popular tiles in
the SBSs, while the remaining tiles may be obtained through the backhaul. In
addition, we explicitly consider the time delivery constraints to ensure
continuous video playback. To reduce the computational complexity of the
optimization problem, we simplify it by introducing a fairness constraint. This
allows us to split the original problem into subproblems corresponding to
Groups of Pictures (GoP). Each of the subproblems is then solved with the
method of Lagrange partial relaxation. Finally, we evaluate the performance of
the proposed method for various system parameters and compare it with schemes
that do not consider $360^o$ video encoding into multiple tiles and quality
layers, as well as with two variants of the proposed method one that considers
layered encoding and SBSs collaboration and another that uses tiles encoding
but with no SBSs collaboration. The results showcase the benefits coming from
caching and delivery decisions on per tile basis and the importance of
exploiting SBSs collaboration.
"
1940,"MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on
  Compressed Video","  The past few years have witnessed great success in applying deep learning to
enhance the quality of compressed image/video. The existing approaches mainly
focus on enhancing the quality of a single frame, not considering the
similarity between consecutive frames. Since heavy fluctuation exists across
compressed video frames as investigated in this paper, frame similarity can be
utilized for quality enhancement of low-quality frames given their neighboring
high-quality frames. This task is Multi-Frame Quality Enhancement (MFQE).
Accordingly, this paper proposes an MFQE approach for compressed video, as the
first attempt in this direction. In our approach, we firstly develop a
Bidirectional Long Short-Term Memory (BiLSTM) based detector to locate Peak
Quality Frames (PQFs) in compressed video. Then, a novel Multi-Frame
Convolutional Neural Network (MF-CNN) is designed to enhance the quality of
compressed video, in which the non-PQF and its nearest two PQFs are the input.
In MF-CNN, motion between the non-PQF and PQFs is compensated by a motion
compensation subnet. Subsequently, a quality enhancement subnet fuses the
non-PQF and compensated PQFs, and then reduces the compression artifacts of the
non-PQF. Also, PQF quality is enhanced in the same way. Finally, experiments
validate the effectiveness and generalization ability of our MFQE approach in
advancing the state-of-the-art quality enhancement of compressed video. The
code is available at https://github.com/RyanXingQL/MFQEv2.0.git.
"
1941,A multimodal movie review corpus for fine-grained opinion mining,"  In this paper, we introduce a set of opinion annotations for the POM movie
review dataset, composed of 1000 videos. The annotation campaign is motivated
by the development of a hierarchical opinion prediction framework allowing one
to predict the different components of the opinions (e.g. polarity and aspect)
and to identify the corresponding textual spans. The resulting annotations have
been gathered at two granularity levels: a coarse one (opinionated span) and a
finer one (span of opinion components). We introduce specific categories in
order to make the annotation of opinions easier for movie reviews. For example,
some categories allow the discovery of user recommendation and preference in
movie reviews. We provide a quantitative analysis of the annotations and report
the inter-annotator agreement under the different levels of granularity. We
provide thus the first set of ground-truth annotations which can be used for
the task of fine-grained multimodal opinion prediction. We provide an analysis
of the data gathered through an inter-annotator study and show that a linear
structured predictor learns meaningful features even for the prediction of
scarce labels. Both the annotations and the baseline system will be made
publicly available.
"
1942,Utterance-level Aggregation For Speaker Recognition In The Wild,"  The objective of this paper is speaker recognition ""in the wild""-where
utterances may be of variable length and also contain irrelevant signals.
Crucial elements in the design of deep networks for this task are the type of
trunk (frame level) network, and the method of temporal aggregation. We propose
a powerful speaker recognition deep network, using a ""thin-ResNet"" trunk
architecture, and a dictionary-based NetVLAD or GhostVLAD layer to aggregate
features across time, that can be trained end-to-end. We show that our network
achieves state of the art performance by a significant margin on the VoxCeleb1
test set for speaker recognition, whilst requiring fewer parameters than
previous methods. We also investigate the effect of utterance length on
performance, and conclude that for ""in the wild"" data, a longer length is
beneficial.
"
1943,"Deep Learning-based Concept Detection in vitrivr at the Video Browser
  Showdown 2019 - Final Notes","  This paper presents an after-the-fact summary of the participation of the
vitrivr system to the 2019 Video Browser Showdown. Analogously to last year's
report, the focus of this paper lies on additions made since the original
publication and the system's performance during the competition.
"
1944,Neural Imaging Pipelines - the Scourge or Hope of Forensics?,"  Forensic analysis of digital photographs relies on intrinsic statistical
traces introduced at the time of their acquisition or subsequent editing. Such
traces are often removed by post-processing (e.g., down-sampling and
re-compression applied upon distribution in the Web) which inhibits reliable
provenance analysis. Increasing adoption of computational methods within
digital cameras further complicates the process and renders explicit
mathematical modeling infeasible. While this trend challenges forensic analysis
even in near-acquisition conditions, it also creates new opportunities. This
paper explores end-to-end optimization of the entire image acquisition and
distribution workflow to facilitate reliable forensic analysis at the end of
the distribution channel, where state-of-the-art forensic techniques fail. We
demonstrate that a neural network can be trained to replace the entire photo
development pipeline, and jointly optimized for high-fidelity photo rendering
and reliable provenance analysis. Such optimized neural imaging pipeline
allowed us to increase image manipulation detection accuracy from approx. 45%
to over 90%. The network learns to introduce carefully crafted artifacts, akin
to digital watermarks, which facilitate subsequent manipulation detection.
Analysis of performance trade-offs indicates that most of the gains can be
obtained with only minor distortion. The findings encourage further research
towards building more reliable imaging pipelines with explicit
provenance-guaranteeing properties.
"
1945,"PixelSteganalysis: Pixel-wise Hidden Information Removal with Low Visual
  Degradation","  It is difficult to detect and remove secret images that are hidden in natural
images using deep-learning algorithms. Our technique is the first work to
effectively disable covert communications and transactions that use
deep-learning steganography. We address the problem by exploiting sophisticated
pixel distributions and edge areas of images using a deep neural network. Based
on the given information, we adaptively remove secret information at the pixel
level. We also introduce a new quantitative metric called destruction rate
since the decoding method of deep-learning steganography is approximate
(lossy), which is different from conventional steganography. We evaluate our
technique using three public benchmarks in comparison with conventional
steganalysis methods and show that the decoding rate improves by 10 ~ 20%.
"
1946,"Usage of analytic hierarchy process for steganographic inserts detection
  in images","  This article presents the method of steganography detection, which is formed
by replacing the least significant bit (LSB). Detection is performed by
dividing the image into layers and making an analysis of zero-layer of adjacent
bits for every bit. First-layer and second-layer are analyzed too. Hierarchies
analysis method is used for making decision if current bit is changed.
Weighting coefficients as part of the analytic hierarchy process are formed on
the values of bits. Then a matrix of corrupted pixels is generated.
Visualization of matrix with corrupted pixels allows to determine size,
location and presence of the embedded message. Computer experiment was
performed. Message was embedded in a bounded rectangular area of the image.
This method demonstrated efficiency even at low filling container, less than
10\%. Widespread statistical methods are unable to detect this steganographic
insert. The location and size of the embedded message can be determined with an
error which is not exceeding to five pixels.
"
1947,"PixelSteganalysis: Destroying Hidden Information with a Low Degree of
  Visual Degradation","  Steganography is the science of unnoticeably concealing a secret message
within a certain image, called a cover image. The cover image with the secret
message is called a stego image. Steganography is commonly used for illegal
purposes such as terrorist activities and pornography. To thwart covert
communications and transactions, attacking algorithms against steganography,
called steganalysis, exist. Currently, there are many studies implementing deep
learning to the steganography algorithm. However, conventional steganalysis is
no longer effective for deep learning based steganography algorithms. Our
framework is the first one to disturb covert communications and transactions
via the recent deep learning-based steganography algorithms. We first extract a
sophisticated pixel distribution of the potential stego image from the
auto-regressive model induced by deep learning. Using the extracted pixel
distributions, we detect whether an image is the stego or not at the pixel
level. Each pixel value is adjusted as required and the adjustment induces an
effective removal of the secret image. Because the decoding method of deep
learning-based steganography algorithms is approximate (lossy), which is
different from the conventional steganography, we propose a new quantitative
metric that is more suitable for measuring the accurate effect. We evaluate our
method using three public benchmarks in comparison with a conventional
steganalysis method and show up to a 20% improvement in terms of decoding rate.
"
1948,"Analysis of non-stationary multicomponent signals with a focus on the
  Compressive Sensing approach","  The characterization of multicomponent signals with a particular emphasis on
musical and communication signals is one of the problems studied in the
dissertation. In order to provide an efficient analysis of the multicomponent
signals, the possibility to separate signal components is observed. The
procedure for decomposition and classification of the signal components whose
energy and physical characteristics differ in the time-frequency domain is
proposed in this work. A special focus in the dissertation is on the
application of the compressive sensing approach in multicomponent signals. The
compressive sensing method becomes popular in the field of signal processing
until recently, and its application in various fields can increase the
acquisition and transmission speed, reduce the complexity of devices, and
reduce energy consumption. The procedure that applies the compressive sensing
in the classification of the wireless communication signals is proposed. The
algorithms for reconstruction of the compressive sensed signals are intensively
developing, and therefore special emphasis in the dissertation is devoted to
the hardware implementation of one of the algorithms for sparse signal
reconstruction.
"
1949,"Deep Inverse Tone Mapping Using LDR Based Learning for Estimating HDR
  Images with Absolute Luminance","  In this paper, a novel inverse tone mapping method using a convolutional
neural network (CNN) with LDR based learning is proposed. In conventional
inverse tone mapping with CNNs, generated HDR images cannot have absolute
luminance, although relative luminance can. Moreover, loss functions suitable
for learning HDR images are problematic, so it is difficult to train CNNs by
directly using HDR images. In contrast, the proposed method enables us not only
to estimate absolute luminance, but also to train a CNN by using LDR images.
The CNN used in the proposed method learns a transformation from various input
LDR images to LDR images mapped by Reinhard's global operator. Experimental
results show that HDR images generated by the proposed method have
higher-quality than HDR ones generated by conventional inverse tone mapping
methods,in terms of HDR-VDP-2.2 and PU encoding + MS-SSIM.
"
1950,Unsupervised Rank-Preserving Hashing for Large-Scale Image Retrieval,"  We propose an unsupervised hashing method which aims to produce binary codes
that preserve the ranking induced by a real-valued representation. Such compact
hash codes enable the complete elimination of real-valued feature storage and
allow for significant reduction of the computation complexity and storage cost
of large-scale image retrieval applications. Specifically, we learn a neural
network-based model, which transforms the input representation into a binary
representation. We formalize the training objective of the network in an
intuitive and effective way, considering each training sample as a query and
aiming to obtain the same retrieval results using the produced hash codes as
those obtained with the original features. This training formulation directly
optimizes the hashing model for the target usage of the hash codes it produces.
We further explore the addition of a decoder trained to obtain an approximated
reconstruction of the original features. At test time, we retrieved the most
promising database samples with an efficient graph-based search procedure using
only our hash codes and perform re-ranking using the reconstructed features,
thus without needing to access the original features at all. Experiments
conducted on multiple publicly available large-scale datasets show that our
method consistently outperforms all compared state-of-the-art unsupervised
hashing methods and that the reconstruction procedure can effectively boost the
search accuracy with a minimal constant additional cost.
"
1951,"How to Prove Your Model Belongs to You: A Blind-Watermark based
  Framework to Protect Intellectual Property of DNN","  Deep learning techniques have made tremendous progress in a variety of
challenging tasks, such as image recognition and machine translation, during
the past decade. Training deep neural networks is computationally expensive and
requires both human and intellectual resources. Therefore, it is necessary to
protect the intellectual property of the model and externally verify the
ownership of the model. However, previous studies either fail to defend against
the evasion attack or have not explicitly dealt with fraudulent claims of
ownership by adversaries. Furthermore, they can not establish a clear
association between the model and the creator's identity.
  To fill these gaps, in this paper, we propose a novel intellectual property
protection (IPP) framework based on blind-watermark for watermarking deep
neural networks that meet the requirements of security and feasibility. Our
framework accepts ordinary samples and the exclusive logo as inputs, outputting
newly generated samples as watermarks, which are almost indistinguishable from
the origin, and infuses these watermarks into DNN models by assigning specific
labels, leaving the backdoor as the basis for our copyright claim. We evaluated
our IPP framework on two benchmark datasets and 15 popular deep learning
models. The results show that our framework successfully verifies the ownership
of all the models without a noticeable impact on their primary task. Most
importantly, we are the first to successfully design and implement a
blind-watermark based framework, which can achieve state-of-art performances on
undetectability against evasion attack and unforgeability against fraudulent
claims of ownership. Further, our framework shows remarkable robustness and
establishes a clear association between the model and the author's identity.
"
1952,Camera Obscurer: Generative Art for Design Inspiration,"  We investigate using generated decorative art as a source of inspiration for
design tasks. Using a visual similarity search for image retrieval, the
\emph{Camera Obscurer} app enables rapid searching of tens of thousands of
generated abstract images of various types. The seed for a visual similarity
search is a given image, and the retrieved generated images share some visual
similarity with the seed. Implemented in a hand-held device, the app empowers
users to use photos of their surroundings to search through the archive of
generated images and other image archives. Being abstract in nature, the
retrieved images supplement the seed image rather than replace it, providing
different visual stimuli including shapes, colours, textures and
juxtapositions, in addition to affording their own interpretations. This
approach can therefore be used to provide inspiration for a design task, with
the abstract images suggesting new ideas that might give direction to a graphic
design project. We describe a crowdsourcing experiment with the app to estimate
user confidence in retrieved images, and we describe a pilot study where Camera
Obscurer provided inspiration for a design task. These experiments have enabled
us to describe future improvements, and to begin to understand sources of
visual inspiration for design tasks.
"
1953,HTML5 MSE Playback of MPEG 360 VR Tiled Streaming,"  Virtual Reality (VR) and 360-degree video streaming have gained significant
attention in recent years. First standards have been published in order to
avoid market fragmentation. For instance, 3GPP released its first VR
specification to enable 360-degree video streaming over 5G networks which
relies on several technologies specified in ISO/IEC 23090-2, also known as
MPEG-OMAF. While some implementations of OMAF-compatible players have already
been demonstrated at several trade shows, so far, no web browser-based
implementations have been presented. In this demo paper we describe a
browser-based JavaScript player implementation of the most advanced media
profile of OMAF: HEVC-based viewport-dependent OMAF video profile, also known
as tile-based streaming, with multi-resolution HEVC tiles. We also describe the
applied workarounds for the implementation challenges we encountered with
state-of-the-art HTML5 browsers. The presented implementation was tested in the
Safari browser with support of HEVC video through the HTML5 Media Source
Extensions API. In addition, the WebGL API was used for rendering, using
region-wise packing metadata as defined in OMAF.
"
1954,HoloCast: Graph Signal Processing for Graceful Point Cloud Delivery,"  In conventional point cloud delivery, a sender uses octree-based digital
video compression to stream three-dimensional (3D) points and the corresponding
color attributes over band-limited links, e.g., wireless channels, for 3D scene
reconstructions. However, the digital-based delivery schemes have an issue
called cliff effect, where the 3D reconstruction quality is a step function in
terms of wireless channel quality. We propose a novel scheme of point cloud
delivery, called HoloCast, to gracefully improve the reconstruction quality
with the improvement of wireless channel quality. HoloCast regards the 3D
points and color components as graph signals and directly transmits
linear-transformed signals based on graph Fourier transform (GFT), without
digital quantization and entropy coding operations. One of main contributions
in HoloCast is that the use of GFT can deal with non-ordered and non-uniformly
distributed multi-dimensional signals such as holographic data unlike
conventional delivery schemes. Performance results with point cloud data show
that HoloCast yields better 3D reconstruction quality compared to digital-based
methods in noisy wireless environment.
"
1955,Similarity Learning via Kernel Preserving Embedding,"  Data similarity is a key concept in many data-driven applications. Many
algorithms are sensitive to similarity measures. To tackle this fundamental
problem, automatically learning of similarity information from data via
self-expression has been developed and successfully applied in various models,
such as low-rank representation, sparse subspace learning, semi-supervised
learning. However, it just tries to reconstruct the original data and some
valuable information, e.g., the manifold structure, is largely ignored. In this
paper, we argue that it is beneficial to preserve the overall relations when we
extract similarity information. Specifically, we propose a novel similarity
learning framework by minimizing the reconstruction error of kernel matrices,
rather than the reconstruction error of original data adopted by existing work.
Taking the clustering task as an example to evaluate our method, we observe
considerable improvements compared to other state-of-the-art methods. More
importantly, our proposed framework is very general and provides a novel and
fundamental building block for many other similarity-based tasks. Besides, our
proposed kernel preserving opens up a large number of possibilities to embed
high-dimensional data into low-dimensional space.
"
1956,Learning Symmetric and Asymmetric Steganography via Adversarial Training,"  Steganography refers to the art of concealing secret messages within multiple
media carriers so that an eavesdropper is unable to detect the presence and
content of the hidden messages. In this paper, we firstly propose a novel
key-dependent steganographic scheme that achieves steganographic objectives
with adversarial training. Symmetric (secret-key) and Asymmetric (public-key)
steganographic scheme are separately proposed and each scheme is successfully
designed and implemented. We show that these encodings produced by our scheme
improve the invisibility by 20% than previous deep-leanring-based work, and
further that perform competitively remarkable undetectability 25% better than
classic steganographic algorithms. Finally, we simulated our scheme in a real
situation where the decoder achieved an accuracy of more than 98% of the
original message.
"
1957,Notation for Subject Answer Analysis,"  It is believed that consistent notation helps the research community in many
ways. First and foremost, it provides a consistent interface of communication.
Subjective experiments described according to uniform rules are easier to
understand and analyze. Additionally, a comparison of various results is less
complicated. In this publication we describe notation proposed by VQEG (Video
Quality Expert Group) working group SAM (Statistical Analysis and Methods).
"
1958,Object tracking in video signals using Compressive Sensing,"  Reducing the number of pixels in video signals while maintaining quality
needed for recovering the trace of an object using Compressive Sensing is main
subject of this work. Quality of frames, from video that contains moving
object, are gradually reduced by keeping different number of pixels in each
iteration, going from 45% all the way to 1%. Using algorithm for tracing
object, results were satisfactory and showed mere changes in trajectory graphs,
obtained from original and reconstructed videos.
"
1959,"A Ground-Truth Data Set and a Classification Algorithm for Eye Movements
  in 360-degree Videos","  The segmentation of a gaze trace into its constituent eye movements has been
actively researched since the early days of eye tracking. As we move towards
more naturalistic viewing conditions, the segmentation becomes even more
challenging and convoluted as more complex patterns emerge. The definitions and
the well-established methods that were developed for monitor-based eye tracking
experiments are often not directly applicable to unrestrained set-ups such as
eye tracking in wearable contexts or with head-mounted displays. The main
contributions of this work to the eye movement research for 360-degree content
are threefold: First, we collect, partially annotate, and make publicly
available a new eye tracking data set, which consists of 13 participants
viewing 15 video clips that are recorded in 360-degree. Second, we propose a
new two-stage pipeline for ground truth annotation of the traditional
fixations, saccades, smooth pursuits, as well as (optokinetic) nystagmus,
vestibulo-ocular reflex, and pursuit of moving objects performed exclusively
via the movement of the head. A flexible user interface for this pipeline is
implemented and made freely accessible for use or modification. Lastly, we
develop and test a simple proof-of-concept algorithm for automatic
classification of all the eye movement types in our data set based on their
operational definitions that were used for manual annotation. The data set and
the source code for both the annotation tool and the algorithm are publicly
available at https://web.gin.g-node.org/ioannis.agtzidis/360_em_dataset.
"
1960,Surface Compression Using Dynamic Color Palettes,"  Off-chip memory traffic is a major source of power and energy consumption on
mobile platforms. A large amount of this off-chip traffic is used to manipulate
graphics framebuffer surfaces. To cut down the cost of accessing off-chip
memory, framebuffer surfaces are compressed to reduce the bandwidth consumed on
surface manipulation when rendering or displaying.
  In this work, we study the compression properties of framebuffer surfaces and
highlight the fact that surfaces from different applications have different
compression characteristics. We use the results of our analysis to propose a
scheme, Dynamic Color Palettes (DCP), which achieves higher compression rates
with UI and 2D surfaces.
  DCP is a hardware mechanism for exploiting inter-frame coherence in lossless
surface compression; it implements a scheme that dynamically constructs color
palettes, which are then used to efficiently compress framebuffer surfaces. To
evaluate DCP, we created an extensive set of OpenGL workload traces from 124
Android applications. We found that DCP improves compression rates by 91% for
UI and 20% for 2D applications compared to previous proposals. We also evaluate
a hybrid scheme that combines DCP with a generic compression scheme. We found
that compression rates improve over previous proposals by 161%, 124% and 83%
for UI, 2D and 3D applications, respectively.
"
1961,Older Adults and Voice Interaction: A Pilot Study with Google Home,"  In this paper we present the results of an exploratory study examining the
potential of voice assistants (VA) for some groups of older adults in the
context of Smart Home Technology (SHT). To research the aspect of older adults'
interaction with voice user interfaces (VUI) we organized two workshops and
gathered insights concerning possible benefits and barriers to the use of VA
combined with SHT by older adults. Apart from evaluating the participants'
interaction with the devices during the two workshops we also discuss some
improvements to the VA interaction paradigm.
"
1962,"Scene Segmentation-Based Luminance Adjustment for Multi-Exposure Image
  Fusion","  We propose a novel method for adjusting luminance for multi-exposure image
fusion. For the adjustment, two novel scene segmentation approaches based on
luminance distribution are also proposed. Multi-exposure image fusion is a
method for producing images that are expected to be more informative and
perceptually appealing than any of the input ones, by directly fusing photos
taken with different exposures. However, existing fusion methods often produce
unclear fused images when input images do not have a sufficient number of
different exposure levels. In this paper, we point out that adjusting the
luminance of input images makes it possible to improve the quality of the final
fused images. This insight is the basis of the proposed method. The proposed
method enables us to produce high-quality images, even when undesirable inputs
are given. Visual comparison results show that the proposed method can produce
images that clearly represent a whole scene. In addition, multi-exposure image
fusion with the proposed method outperforms state-of-the-art fusion methods in
terms of MEF-SSIM, discrete entropy, tone mapped image quality index, and
statistical naturalness.
"
1963,Audio Watermarking over the Air With Modulated Self-Correlation,"  We propose a novel audio watermarking system that is robust to the distortion
due to the indoor acoustic propagation channel between the loudspeaker and the
receiving microphone. The system utilizes a set of new algorithms that
effectively mitigate the impact of room reverberation and interfering sound
sources without using dereverberation procedures. The decoder has low-latency
and it operates asynchronously, which alleviates the need for explicit
synchronization with the encoder. It is also robust to standard audio
processing operations in legacy watermarking systems, e.g., compression and
volume change. The effectiveness of the system is established with a real-time
system under general room conditions.
"
1964,"Detecting the Presence of ENF Signal in Digital Videos: a Superpixel
  based Approach","  ENF (Electrical Network Frequency) instantaneously fluctuates around its
nominal value (50/60 Hz) due to a continuous disparity between generated power
and consumed power. Consequently, luminous intensity of a mains-powered light
source varies depending on ENF fluctuations in the grid network. Variations in
the luminance over time can be captured from video recordings and ENF can be
estimated through content analysis of these recordings. In ENF based video
forensics, it is critical to check whether a given video file is appropriate
for this type of analysis. That is, if ENF signal is not present in a given
video, it would be useless to apply ENF based forensic analysis. In this work,
an ENF signal presence detection method is introduced for videos. The proposed
method is based on multiple ENF signal estimations from steady superpixels,
i.e. pixels that are most likely uniform in color, brightness, and texture, and
intraclass similarity of the estimated signals. Subsequently, consistency among
these estimates is then used to determine the presence or absence of an ENF
signal in a given video. The proposed technique can operate on video clips as
short as 2 minutes and is independent of the camera sensor type, i.e. CCD or
CMOS.
"
1965,Analysis of Rolling Shutter Effect on ENF based Video Forensics,"  ENF is a time-varying signal of the frequency of mains electricity in a power
grid. It continuously fluctuates around a nominal value (50/60 Hz) due to
changes in supply and demand of power over time. Depending on these ENF
variations, the luminous intensity of a mains-powered light source also
fluctuates. These fluctuations in luminance can be captured by video
recordings. Accordingly, ENF can be estimated from such videos by analysis of
steady content in the video scene. When videos are captured by using a rolling
shutter sampling mechanism, as is done mostly with CMOS cameras, there is an
idle period between successive frames. Consequently, a number of illumination
samples of the scene are effectively lost due to the idle period. These missing
samples affect ENF estimation, in the sense of the frequency shift caused and
the power attenuation that results. This work develops an analytical model for
videos captured using a rolling shutter mechanism. The model illustrates how
the frequency of the main ENF harmonic varies depending on the idle period
length, and how the power of the captured ENF attenuates as idle period
increases. Based on this, a novel idle period estimation method for potential
use in camera forensics that is able to operate independently of video frame
rate is proposed. Finally, a novel time-of-recording verification approach
based on use of multiple ENF components, idle period assumptions and
interpolation of missing ENF samples is also proposed.
"
1966,"Wav2Pix: Speech-conditioned Face Generation using Generative Adversarial
  Networks","  Speech is a rich biometric signal that contains information about the
identity, gender and emotional state of the speaker. In this work, we explore
its potential to generate face images of a speaker by conditioning a Generative
Adversarial Network (GAN) with raw speech input. We propose a deep neural
network that is trained from scratch in an end-to-end fashion, generating a
face directly from the raw speech waveform without any additional identity
information (e.g reference image or one-hot encoding). Our model is trained in
a self-supervised approach by exploiting the audio and visual signals naturally
aligned in videos. With the purpose of training from video data, we present a
novel dataset collected for this work, with high-quality videos of youtubers
with notable expressiveness in both the speech and visual signals.
"
1967,Mask-ShadowGAN: Learning to Remove Shadows from Unpaired Data,"  This paper presents a new method for shadow removal using unpaired data,
enabling us to avoid tedious annotations and obtain more diverse training
samples. However, directly employing adversarial learning and cycle-consistency
constraints is insufficient to learn the underlying relationship between the
shadow and shadow-free domains, since the mapping between shadow and
shadow-free images is not simply one-to-one. To address the problem, we
formulate Mask-ShadowGAN, a new deep framework that automatically learns to
produce a shadow mask from the input shadow image and then takes the mask to
guide the shadow generation via re-formulated cycle-consistency constraints.
Particularly, the framework simultaneously learns to produce shadow masks and
learns to remove shadows, to maximize the overall performance. Also, we
prepared an unpaired dataset for shadow removal and demonstrated the
effectiveness of Mask-ShadowGAN on various experiments, even it was trained on
unpaired data.
"
1968,"Resource Allocation Mechanism for Media Handling Services in Cloud
  Multimedia Conferencing","  Multimedia conferencing is the conversational exchange of multimedia content
between multiple parties. It has a wide range of applications (e.g., Massively
Multiplayer Online Games (MMOGs) and distance learning). Media handling
services (e.g., video mixing, transcoding, and compressing) are critical to
multimedia conferencing. However, efficient resource usage and scalability
still remain important challenges. Unfortunately, the cloud-based approaches
proposed so far have several deficiencies in terms of efficiency in resource
usage and scaling, while meeting Quality of Service (QoS) requirements. This
paper proposes a solution which optimizes resource allocation and scales in
terms of the number of participants while guaranteeing QoS. Moreover, our
solution composes different media handling services to support the
participants' demands. We formulate the resource allocation problem
mathematically as an Integer Linear Programming (ILP) problem and design a
heuristic for it. We evaluate our proposed solution for different numbers of
participants and different participants' geographical distributions. Simulation
results show that our resource allocation mechanism can compose the media
handling services and allocate the required resources in an optimal manner
while honoring the QoS in terms of end-to-end delay.
"
1969,"SRDGAN: learning the noise prior for Super Resolution with Dual
  Generative Adversarial Networks","  Single Image Super Resolution (SISR) is the task of producing a high
resolution (HR) image from a given low-resolution (LR) image. It is a well
researched problem with extensive commercial applications such as digital
camera, video compression, medical imaging and so on. Most super resolution
works focus on the features learning architecture, which can recover the
texture details as close as possible. However, these works suffer from the
following challenges: (1) The low-resolution (LR) training images are
artificially synthesized using HR images with bicubic downsampling, which have
much richer-information than real demosaic-upscaled mobile images. The mismatch
between training and inference mobile data heavily blocks the improvement of
practical super resolution algorithms. (2) These methods cannot effectively
handle the blind distortions during super resolution in practical applications.
In this work, an end-to-end novel framework, including high-to-low network and
low-to-high network, is proposed to solve the above problems with dual
Generative Adversarial Networks (GAN). First, the above mismatch problems are
well explored with the high-to-low network, where clear high-resolution image
and the corresponding realistic low-resolution image pairs can be generated.
Moreover, a large-scale General Mobile Super Resolution Dataset, GMSR, is
proposed, which can be utilized for training or as a fair comparison benchmark
for super resolution methods. Second, an effective low-to-high network (super
resolution network) is proposed in the framework. Benefiting from the GMSR
dataset and novel training strategies, the super resolution model can
effectively handle detail recovery and denoising at the same time.
"
1970,"Universal chosen-ciphertext attack for a family of image encryption
  schemes","  During the past decades, there is a great popularity employing nonlinear
dynamics and permutation-substitution architecture for image encryption. There
are three primary procedures in such encryption schemes, the key schedule
module for producing encryption factors, permutation for image scrambling and
substitution for pixel modification. Under the assumption of chosen-ciphertext
attack, we evaluate the security of a class of image ciphers which adopts
pixel-level permutation and modular addition for substitution. It is
mathematically revealed that the mapping from differentials of ciphertexts to
those of plaintexts are linear and has nothing to do with the key schedules,
permutation techniques and encryption rounds. Moreover, a universal
chosen-ciphertext attack is proposed and validated. Experimental results
demonstrate that the plaintexts can be directly reconstructed without any
security key or encryption elements. Related cryptographic discussions are also
given.
"
1971,"GANs-NQM: A Generative Adversarial Networks based No Reference Quality
  Assessment Metric for RGB-D Synthesized Views","  In this paper, we proposed a no-reference (NR) quality metric for RGB plus
image-depth (RGB-D) synthesis images based on Generative Adversarial Networks
(GANs), namely GANs-NQM. Due to the failure of the inpainting on dis-occluded
regions in RGB-D synthesis process, to capture the non-uniformly distributed
local distortions and to learn their impact on perceptual quality are
challenging tasks for objective quality metrics. In our study, based on the
characteristics of GANs, we proposed i) a novel training strategy of GANs for
RGB-D synthesis images using existing large-scale computer vision datasets
rather than RGB-D dataset; ii) a referenceless quality metric based on the
trained discriminator by learning a `Bag of Distortion Word' (BDW) codebook and
a local distortion regions selector; iii) a hole filling inpainter, i.e., the
generator of the trained GANs, for RGB-D dis-occluded regions as a side
outcome. According to the experimental results on IRCCyN/IVC DIBR database, the
proposed model outperforms the state-of-the-art quality metrics, in addition,
is more applicable in real scenarios. The corresponding context inpainter also
shows appealing results over other inpainting algorithms.
"
1972,"Quality Assessment of Free-viewpoint Videos by Quantifying the Elastic
  Changes of Multi-Scale Motion Trajectories","  Virtual viewpoints synthesis is an essential process for many immersive
applications including Free-viewpoint TV (FTV). A widely used technique for
viewpoints synthesis is Depth-Image-Based-Rendering (DIBR) technique. However,
such techniques may introduce challenging non-uniform spatial-temporal
structure-related distortions. Most of the existing state-of-the-art quality
metrics fail to handle these distortions, especially the temporal structure
inconsistencies observed during the switch of different viewpoints. To tackle
this problem, an elastic metric and multi-scale trajectory based video quality
metric (EM-VQM) is proposed in this paper. Dense motion trajectory is first
used as a proxy for selecting temporal sensitive regions, where local geometric
distortions might significantly diminish the perceived quality. Afterwards, the
amount of temporal structure inconsistencies and unsmooth viewpoints
transitions are quantified by calculating 1) the amount of motion trajectory
deformations with elastic metric and, 2) the spatial-temporal structural
dissimilarity. According to the comprehensive experimental results on two FTV
video datasets, the proposed metric outperforms the state-of-the-art metrics
designed for free-viewpoint videos significantly and achieves a gain of 12.86%
and 16.75% in terms of median Pearson linear correlation coefficient values on
the two datasets compared to the best one, respectively.
"
1973,"A Study on the Characteristics of Douyin Short Videos and Implications
  for Edge Caching","  Douyin, internationally known as TikTok, has become one of the most
successful short-video platforms. To maintain its popularity, Douyin has to
provide better Quality of Experience (QoE) to its growing user base.
Understanding the characteristics of Douyin videos is thus critical to its
service improvement and system design. In this paper, we present an initial
study on the fundamental characteristics of Douyin videos based on a dataset of
over 260 thousand short videos collected across three months. The
characteristics of Douyin videos are found to be significantly different from
traditional online videos, ranging from video bitrate, size, to popularity. In
particular, the distributions of the bitrate and size of videos follow Weibull
distribution. We further observe that the most popular Douyin videos follow
Zifp's law on video popularity, but the rest of the videos do not. We also
investigate the correlation between popularity metrics used for Douyin videos.
It is found that the correlation between the number of views and the number of
likes are strong, while other correlations are relatively low. Finally, by
using a case study, we demonstrate that the above findings can provide
important guidance on designing an efficient edge caching system.
"
1974,Learning Affective Correspondence between Music and Image,"  We introduce the problem of learning affective correspondence between audio
(music) and visual data (images). For this task, a music clip and an image are
considered similar (having true correspondence) if they have similar emotion
content. In order to estimate this crossmodal, emotion-centric similarity, we
propose a deep neural network architecture that learns to project the data from
the two modalities to a common representation space, and performs a binary
classification task of predicting the affective correspondence (true or false).
To facilitate the current study, we construct a large scale database containing
more than $3,500$ music clips and $85,000$ images with three emotion classes
(positive, neutral, negative). The proposed approach achieves $61.67\%$
accuracy for the affective correspondence prediction task on this database,
outperforming two relevant and competitive baselines. We also demonstrate that
our network learns modality-specific representations of emotion (without
explicitly being trained with emotion labels), which are useful for emotion
recognition in individual modalities.
"
1975,BlackMarks: Blackbox Multibit Watermarking for Deep Neural Networks,"  Deep Neural Networks have created a paradigm shift in our ability to
comprehend raw data in various important fields ranging from computer vision
and natural language processing to intelligence warfare and healthcare. While
DNNs are increasingly deployed either in a white-box setting where the model
internal is publicly known, or a black-box setting where only the model outputs
are known, a practical concern is protecting the models against Intellectual
Property (IP) infringement. We propose BlackMarks, the first end-to-end
multi-bit watermarking framework that is applicable in the black-box scenario.
BlackMarks takes the pre-trained unmarked model and the owner's binary
signature as inputs and outputs the corresponding marked model with a set of
watermark keys. To do so, BlackMarks first designs a model-dependent encoding
scheme that maps all possible classes in the task to bit '0' and bit '1' by
clustering the output activations into two groups. Given the owner's watermark
signature (a binary string), a set of key image and label pairs are designed
using targeted adversarial attacks. The watermark (WM) is then embedded in the
prediction behavior of the target DNN by fine-tuning the model with generated
WM key set. To extract the WM, the remote model is queried by the WM key images
and the owner's signature is decoded from the corresponding predictions
according to the designed encoding scheme. We perform a comprehensive
evaluation of BlackMarks's performance on MNIST, CIFAR10, ImageNet datasets and
corroborate its effectiveness and robustness. BlackMarks preserves the
functionality of the original DNN and incurs negligible WM embedding runtime
overhead as low as 2.054%.
"
1976,Layered Image Compression using Scalable Auto-encoder,"  This paper presents a novel convolutional neural network (CNN) based image
compression framework via scalable auto-encoder (SAE). Specifically, our SAE
based deep image codec consists of hierarchical coding layers, each of which is
an end-to-end optimized auto-encoder. The coarse image content and texture are
encoded through the first (base) layer while the consecutive (enhance) layers
iteratively code the pixel-level reconstruction errors between the original and
former reconstructed images. The proposed SAE structure alleviates the need to
train multiple models for different bit-rate points by recently proposed
auto-encoder based codecs. The SAE layers can be combined to realize multiple
rate points, or to produce a scalable stream. The proposed method has similar
rate-distortion performance in the low-to-medium rate range as the
state-of-the-art CNN based image codec (which uses different optimized networks
to realize different bit rates) over a standard public image dataset.
Furthermore, the proposed codec generates better perceptual quality in this bit
rate range.
"
1977,Constructing Hierarchical Q&A Datasets for Video Story Understanding,"  Video understanding is emerging as a new paradigm for studying human-like AI.
Question-and-Answering (Q&A) is used as a general benchmark to measure the
level of intelligence for video understanding. While several previous studies
have suggested datasets for video Q&A tasks, they did not really incorporate
story-level understanding, resulting in highly-biased and lack of variance in
degree of question difficulty. In this paper, we propose a hierarchical method
for building Q&A datasets, i.e. hierarchical difficulty levels. We introduce
three criteria for video story understanding, i.e. memory capacity, logical
complexity, and DIKW (Data-Information-Knowledge-Wisdom) pyramid. We discuss
how three-dimensional map constructed from these criteria can be used as a
metric for evaluating the levels of intelligence relating to video story
understanding.
"
1978,Unsupervised Multi-modal Hashing for Cross-modal retrieval,"  With the advantage of low storage cost and high efficiency, hashing learning
has received much attention in the domain of Big Data. In this paper, we
propose a novel unsupervised hashing learning method to cope with this open
problem to directly preserve the manifold structure by hashing. To address this
problem, both the semantic correlation in textual space and the locally
geometric structure in the visual space are explored simultaneously in our
framework. Besides, the `2;1-norm constraint is imposed on the projection
matrices to learn the discriminative hash function for each modality. Extensive
experiments are performed to evaluate the proposed method on the three publicly
available datasets and the experimental results show that our method can
achieve superior performance over the state-of-the-art methods.
"
1979,"Cross-modal Subspace Learning via Kernel Correlation Maximization and
  Discriminative Structure Preserving","  The measure between heterogeneous data is still an open problem. Many
research works have been developed to learn a common subspace where the
similarity between different modalities can be calculated directly. However,
most of existing works focus on learning a latent subspace but the semantically
structural information is not well preserved. Thus, these approaches cannot get
desired results. In this paper, we propose a novel framework, termed
Cross-modal subspace learning via Kernel correlation maximization and
Discriminative structure-preserving (CKD), to solve this problem in two
aspects. Firstly, we construct a shared semantic graph to make each modality
data preserve the neighbor relationship semantically. Secondly, we introduce
the Hilbert-Schmidt Independence Criteria (HSIC) to ensure the consistency
between feature-similarity and semantic-similarity of samples. Our model not
only considers the inter-modality correlation by maximizing the kernel
correlation but also preserves the semantically structural information within
each modality. The extensive experiments are performed to evaluate the proposed
framework on the three public datasets. The experimental results demonstrated
that the proposed CKD is competitive compared with the classic subspace
learning methods.
"
1980,"The bilateral solver for quality estimation based multi-focus image
  fusion","  In this work, a fast Bilateral Solver for Quality Estimation Based
multi-focus Image Fusion method (BS-QEBIF) is proposed. The all-in-focus image
is generated by pixel-wise summing up the multi-focus source images with their
focus-levels maps as weights. Since the visual quality of an image patch is
highly correlated with its focus level, the focus-level maps are preliminarily
obtained based on visual quality scores, as pre-estimations. However, the
pre-estimations are not ideal. Thus the fast bilateral solver is then adopted
to smooth the pre-estimations, and edges in the multi-focus source images can
be preserved simultaneously. The edge-preserving smoothed results are utilized
as final focus-level maps. Moreover, this work provides a confidence-map
solution for the unstable fusion in the focus-level-changed boundary regions.
Experiments were conducted on $25$ pairs of source images. The proposed
BS-QEBIF outperforms the other $13$ fusion methods objectively and
subjectively. The all-in-focus image produced by the proposed method can well
maintain the details in the multi-focus source images and does not suffer from
any residual errors. Experimental results show that BS-QEBIF can handle the
focus-level-changed boundary regions without any blocking, ringing and blurring
artifacts.
"
1981,Source Camera Attribution of Multi-Format Devices,"  Photo Response Non-Uniformity (PRNU) based source camera attribution is an
effective method to determine the origin camera of visual media (an image or a
video). However, given that modern devices, especially smartphones, capture
images, and videos at different resolutions using the same sensor array, PRNU
attribution can become ineffective as the camera fingerprint and query visual
media can be misaligned. We examine different resizing techniques such as
binning, line-skipping, cropping and scaling that cameras use to downsize the
raw sensor image to different media. Taking such techniques into account, this
paper studies the problem of source camera attribution. We define the notion of
Ratio of Alignment, which is a measure of shared sensor elements among
spatially corresponding pixels within two media objects resized with different
techniques. We then compute the Ratio of Alignment between the different
combinations of three common resizing methods under simplified conditions and
experimentally validate our analysis. Based on the insights drawn from the
different techniques used by cameras and the RoA analysis, the paper proposes
an algorithm for matching the source of a video with an image and vice versa.
We also present an efficient search method resulting in significantly improved
performance in matching as well as computation time.
"
1982,SADIH: Semantic-Aware DIscrete Hashing,"  Due to its low storage cost and fast query speed, hashing has been recognized
to accomplish similarity search in large-scale multimedia retrieval
applications. Particularly supervised hashing has recently received
considerable research attention by leveraging the label information to preserve
the pairwise similarities of data points in the Hamming space. However, there
still remain two crucial bottlenecks: 1) the learning process of the full
pairwise similarity preservation is computationally unaffordable and unscalable
to deal with big data; 2) the available category information of data are not
well-explored to learn discriminative hash functions. To overcome these
challenges, we propose a unified Semantic-Aware DIscrete Hashing (SADIH)
framework, which aims to directly embed the transformed semantic information
into the asymmetric similarity approximation and discriminative hashing
function learning. Specifically, a semantic-aware latent embedding is
introduced to asymmetrically preserve the full pairwise similarities while
skillfully handle the cumbersome n times n pairwise similarity matrix.
Meanwhile, a semantic-aware autoencoder is developed to jointly preserve the
data structures in the discriminative latent semantic space and perform data
reconstruction. Moreover, an efficient alternating optimization algorithm is
proposed to solve the resulting discrete optimization problem. Extensive
experimental results on multiple large-scale datasets demonstrate that our
SADIH can clearly outperform the state-of-the-art baselines with the additional
benefit of lower computational costs.
"
1983,Graph based Nearest Neighbor Search: Promises and Failures,"  Recently, graph based nearest neighbor search gets more and more popular on
large-scale retrieval tasks. The attractiveness of this type of approaches lies
in its superior performance over most of the known nearest neighbor search
approaches as well as its genericness to various metrics. In this paper, the
role of two strategies, namely hierarchical structure and graph diversification
that are adopted as the key steps in the graph based approaches, is
investigated. We find the hierarchical structure could not achieve ""much better
logarithmic complexity scaling"" as it was claimed in the original paper,
particularly on high dimensional cases. Moreover, we find that similar high
search speed efficiency as the one with hierarchical structure could be
achieved with the support of flat k-NN graph after graph diversification.
Finally, we point out the difficulty, that is faced by most of the graph based
search approaches, is directly linked to ""curse of dimensionality"".
"
1984,Orthogonal Voronoi Diagram and Treemap,"  In this paper, we propose a novel space partitioning strategy for implicit
hierarchy visualization such that the new plot not only has a tidy layout
similar to the treemap, but also is flexible to data changes similar to the
Voronoi treemap. To achieve this, we define a new distance function and
neighborhood relationship between sites so that space will be divided by
axis-aligned segments. Then a sweepline+skyline based heuristic algorithm is
proposed to allocate the partitioned spaces to form an orthogonal Voronoi
diagram with orthogonal rectangles. To the best of our knowledge, it is the
first time to use a sweepline-based strategy for the Voronoi treemap. Moreover,
we design a novel strategy to initialize the diagram status and modify the
status update procedure so that the generation of our plot is more effective
and efficient. We show that the proposed algorithm has an O(nlog(n)) complexity
which is the same as the state-of-the-art Voronoi treemap. To this end, we show
via experiments on the artificial dataset and real-world dataset the
performance of our algorithm in terms of computation time, converge rate, and
aspect ratio. Finally, we discuss the pros and cons of our method and make a
conclusion.
"
1985,MMED: A Multi-domain and Multi-modality Event Dataset,"  In this work, we construct and release a multi-domain and multi-modality
event dataset (MMED), containing 25,165 textual news articles collected from
hundreds of news media sites (e.g., Yahoo News, Google News, CNN News.) and
76,516 image posts shared on Flickr social media, which are annotated according
to 412 real-world events. The dataset is collected to explore the problem of
organizing heterogeneous data contributed by professionals and amateurs in
different data domains, and the problem of transferring event knowledge
obtained from one data domain to heterogeneous data domain, thus summarizing
the data with different contributors. We hope that the release of the MMED
dataset can stimulate innovate research on related challenging problems, such
as event discovery, cross-modal (event) retrieval, and visual question
answering, etc.
"
1986,"A biologically constrained encoding solution for long-term storage of
  images onto synthetic DNA","  Living in the age of the digital media explosion, the amount of data that is
being stored increases dramatically. However, even if existing storage systems
suggest efficiency in capacity, they are lacking in durability. Hard disks,
flash, tape or even optical storage have limited lifespan in the range of 5 to
20 years. Interestingly, recent studies have proven that it was possible to use
synthetic DNA for the storage of digital data, introducing a strong candidate
to achieve data longevity. The DNA's biological properties allows the storage
of a great amount of information into an extraordinary small volume while also
promising efficient storage for centuries or even longer with no loss of
information. However, encoding digital data onto DNA is not obvious, because
when decoding, we have to face the problem of sequencing noise robustness.
Furthermore, synthesizing DNA is an expensive process and thus, controlling the
compression ratio by optimizing the rate-distortion trade-off is an important
challenge we have to deal with. This work proposes a coding solution for the
storage of digital images onto synthetic DNA. We developed a new encoding
algorithm which generates a DNA code robust to biological errors coming from
the synthesis and the sequencing processes. Furthermore, thanks to an optimized
allocation process the solution is able to control the compression ratio and
thus the length of the synthesized DNA strand. Results show an improvement in
terms of coding potential compared to previous state-of-the-art works.
"
1987,Weakly Supervised Video Moment Retrieval From Text Queries,"  There have been a few recent methods proposed in text to video moment
retrieval using natural language queries, but requiring full supervision during
training. However, acquiring a large number of training videos with temporal
boundary annotations for each text description is extremely time-consuming and
often not scalable. In order to cope with this issue, in this work, we
introduce the problem of learning from weak labels for the task of text to
video moment retrieval. The weak nature of the supervision is because, during
training, we only have access to the video-text pairs rather than the temporal
extent of the video to which different text descriptions relate. We propose a
joint visual-semantic embedding based framework that learns the notion of
relevant segments from video using only video-level sentence descriptions.
Specifically, our main idea is to utilize latent alignment between video frames
and sentence descriptions using Text-Guided Attention (TGA). TGA is then used
during the test phase to retrieve relevant moments. Experiments on two
benchmark datasets demonstrate that our method achieves comparable performance
to state-of-the-art fully supervised approaches.
"
1988,"Affordance Analysis of Virtual and Augmented Reality Mediated
  Communication","  Virtual and augmented reality communication platforms are seen as promising
modalities for next-generation remote face-to-face interactions. Our study
attempts to explore non-verbal communication features in relation to their
conversation context for virtual and augmented reality mediated communication
settings. We perform a series of user experiments, triggering nine conversation
tasks in 4 settings, each containing corresponding non-verbal communication
features. Our results indicate that conversation types which involve less
emotional engagement are more likely to be acceptable in virtual reality and
augmented reality settings with low-fidelity avatar representation, compared to
scenarios that involve high emotional engagement or intellectually difficult
discussions. We further systematically analyze and rank the impact of
low-fidelity representation of micro-expressions, body scale, head pose, and
hand gesture in affecting the user experience in one-on-one conversations, and
validate that preserving micro-expression cues plays the most effective role in
improving bi-directional conversations in future virtual and augmented reality
settings.
"
1989,"Neuralogram: A Deep Neural Network Based Representation for Audio
  Signals","  We propose the Neuralogram -- a deep neural network based representation for
understanding audio signals which, as the name suggests, transforms an audio
signal to a dense, compact representation based upon embeddings learned via a
neural architecture. Through a series of probing signals, we show how our
representation can encapsulate pitch, timbre and rhythm-based information, and
other attributes. This representation suggests a method for revealing
meaningful relationships in arbitrarily long audio signals that are not readily
represented by existing algorithms. This has the potential for numerous
applications in audio understanding, music recommendation, meta-data extraction
to name a few.
"
1990,A Framework for Multi-f0 Modeling in SATB Choir Recordings,"  Fundamental frequency (f0) modeling is an important but relatively unexplored
aspect of choir singing. Performance evaluation as well as auditory analysis of
singing, whether individually or in a choir, often depend on extracting f0
contours for the singing voice. However, due to the large number of singers,
singing at a similar frequency range, extracting the exact individual pitch
contours from choir recordings is a challenging task. In this paper, we address
this task and develop a methodology for modeling pitch contours of SATB choir
recordings. A typical SATB choir consists of four parts, each covering a
distinct range of pitches and often with multiple singers each. We first
evaluate some state-of-the-art multi-f0 estimation systems for the particular
case of choirs with a single singer per part, and observe that the pitch of
individual singers can be estimated to a relatively high degree of accuracy. We
observe, however, that the scenario of multiple singers for each choir part
(i.e. unison singing) is far more challenging. In this work we propose a
methodology based on combining a multi-f0 estimation methodology based on deep
learning followed by a set of traditional DSP techniques to model f0 and its
dispersion instead of a single f0 trajectory for each choir part. We present
and discuss our observations and test our framework with different singer
configurations.
"
1991,Black-box Adversarial Attacks on Video Recognition Models,"  Deep neural networks (DNNs) are known for their vulnerability to adversarial
examples. These are examples that have undergone small, carefully crafted
perturbations, and which can easily fool a DNN into making misclassifications
at test time. Thus far, the field of adversarial research has mainly focused on
image models, under either a white-box setting, where an adversary has full
access to model parameters, or a black-box setting where an adversary can only
query the target model for probabilities or labels. Whilst several white-box
attacks have been proposed for video models, black-box video attacks are still
unexplored. To close this gap, we propose the first black-box video attack
framework, called V-BAD. V-BAD utilizes tentative perturbations transferred
from image models, and partition-based rectifications found by the NES on
partitions (patches) of tentative perturbations, to obtain good adversarial
gradient estimates with fewer queries to the target model. V-BAD is equivalent
to estimating the projection of an adversarial gradient on a selected subspace.
Using three benchmark video datasets, we demonstrate that V-BAD can craft both
untargeted and targeted attacks to fool two state-of-the-art deep video
recognition models. For the targeted attack, it achieves $>$93\% success rate
using only an average of $3.4 \sim 8.4 \times 10^4$ queries, a similar number
of queries to state-of-the-art black-box image attacks. This is despite the
fact that videos often have two orders of magnitude higher dimensionality than
static images. We believe that V-BAD is a promising new tool to evaluate and
improve the robustness of video recognition models to black-box adversarial
attacks.
"
1992,YouTube UGC Dataset for Video Compression Research,"  Non-professional video, commonly known as User Generated Content (UGC) has
become very popular in today's video sharing applications. However, traditional
metrics used in compression and quality assessment, like BD-Rate and PSNR, are
designed for pristine originals. Thus, their accuracy drops significantly when
being applied on non-pristine originals (the majority of UGC). Understanding
difficulties for compression and quality assessment in the scenario of UGC is
important, but there are few public UGC datasets available for research. This
paper introduces a large scale UGC dataset (1500 20 sec video clips) sampled
from millions of YouTube videos. The dataset covers popular categories like
Gaming, Sports, and new features like High Dynamic Range (HDR). Besides a novel
sampling method based on features extracted from encoding, challenges for UGC
compression and quality evaluation are also discussed. Shortcomings of
traditional reference-based metrics on UGC are addressed. We demonstrate a
promising way to evaluate UGC quality by no-reference objective quality
metrics, and evaluate the current dataset with three no-reference metrics
(Noise, Banding, and SLEEQ).
"
1993,"dipIQ: Blind Image Quality Assessment by Learning-to-Rank Discriminable
  Image Pairs","  Objective assessment of image quality is fundamentally important in many
image processing tasks. In this work, we focus on learning blind image quality
assessment (BIQA) models which predict the quality of a digital image with no
access to its original pristine-quality counterpart as reference. One of the
biggest challenges in learning BIQA models is the conflict between the gigantic
image space (which is in the dimension of the number of image pixels) and the
extremely limited reliable ground truth data for training. Such data are
typically collected via subjective testing, which is cumbersome, slow, and
expensive. Here we first show that a vast amount of reliable training data in
the form of quality-discriminable image pairs (DIP) can be obtained
automatically at low cost by exploiting large-scale databases with diverse
image content. We then learn an opinion-unaware BIQA (OU-BIQA, meaning that no
subjective opinions are used for training) model using RankNet, a pairwise
learning-to-rank (L2R) algorithm, from millions of DIPs, each associated with a
perceptual uncertainty level, leading to a DIP inferred quality (dipIQ) index.
Extensive experiments on four benchmark IQA databases demonstrate that dipIQ
outperforms state-of-the-art OU-BIQA models. The robustness of dipIQ is also
significantly improved as confirmed by the group MAximum Differentiation (gMAD)
competition method. Furthermore, we extend the proposed framework by learning
models with ListNet (a listwise L2R algorithm) on quality-discriminable image
lists (DIL). The resulting DIL Inferred Quality (dilIQ) index achieves an
additional performance gain.
"
1994,"A Personalized Preference Learning Framework for Caching in Mobile
  Networks","  This paper comprehensively studies a content-centric mobile network based on
a preference learning framework, where each mobile user is equipped with a
finite-size cache. We consider a practical scenario where each user requests a
content file according to its own preferences, which is motivated by the
existence of heterogeneity in file preferences among different users. Under our
model, we consider a single-hop-based device-to-device (D2D) content delivery
protocol and characterize the average hit ratio for the following two file
preference cases: the personalized file preferences and the common file
preferences. By assuming that the model parameters such as user activity
levels, user file preferences, and file popularity are unknown and thus need to
be inferred, we present a collaborative filtering (CF)-based approach to learn
these parameters. Then, we reformulate the hit ratio maximization problems into
a submodular function maximization and propose two computationally efficient
algorithms including a greedy approach to efficiently solve the cache
allocation problems. We analyze the computational complexity of each algorithm.
Moreover, we analyze the corresponding level of the approximation that our
greedy algorithm can achieve compared to the optimal solution. Using a
real-world dataset, we demonstrate that the proposed framework employing the
personalized file preferences brings substantial gains over its counterpart for
various system parameters.
"
1995,"Multi-Channel Attention Selection GAN with Cascaded Semantic Guidance
  for Cross-View Image Translation","  Cross-view image translation is challenging because it involves images with
drastically different views and severe deformation. In this paper, we propose a
novel approach named Multi-Channel Attention SelectionGAN (SelectionGAN) that
makes it possible to generate images of natural scenes in arbitrary viewpoints,
based on an image of the scene and a novel semantic map. The proposed
SelectionGAN explicitly utilizes the semantic information and consists of two
stages. In the first stage, the condition image and the target semantic map are
fed into a cycled semantic-guided generation network to produce initial coarse
results. In the second stage, we refine the initial results by using a
multi-channel attention selection mechanism. Moreover, uncertainty maps
automatically learned from attentions are used to guide the pixel loss for
better network optimization. Extensive experiments on Dayton, CVUSA and Ego2Top
datasets show that our model is able to generate significantly better results
than the state-of-the-art methods. The source code, data and trained models are
available at https://github.com/Ha0Tang/SelectionGAN.
"
1996,Proximal binaural sound can induce subjective frisson,"  Auditory frisson is the experience of feeling of cold or shivering related to
sound in the absence of a physical cold stimulus. Multiple examples of
frisson-inducing sounds have been reported, but the mechanism of auditory
frisson remains elusive. Typical frisson-inducing sounds may contain a looming
effect, in which a sound appears to approach the listener's peripersonal space.
Previous studies on sound in peripersonal space have provided objective
measurements of sound-inducing effects, but few have investigated the
subjective experience of frisson-inducing sounds. Here we explored whether it
is possible to produce subjective feelings of frisson by moving a noise sound
(white noise, rolling beads noise, or frictional noise produced by rubbing a
plastic bag) stimulus around a listener's head. Our results demonstrated that
sound-induced frisson can be experienced stronger when auditory stimuli are
rotated around the head (binaural moving sounds) than the one without the
rotation (monaural static sounds), regardless of the source of the noise sound.
Pearson's correlation analysis showed that several acoustic features of
auditory stimuli, such as variance of interaural level difference (ILD),
loudness, and sharpness, were correlated with the magnitude of subjective
frisson. We had also observed that the subjective feelings of frisson by moving
a musical sound had increased comparing with a static musical sound.
"
1997,"Saliency Prediction on Omnidirectional Images with Generative
  Adversarial Imitation Learning","  When watching omnidirectional images (ODIs), subjects can access different
viewports by moving their heads. Therefore, it is necessary to predict
subjects' head fixations on ODIs. Inspired by generative adversarial imitation
learning (GAIL), this paper proposes a novel approach to predict saliency of
head fixations on ODIs, named SalGAIL. First, we establish a dataset for
attention on ODIs (AOI). In contrast to traditional datasets, our AOI dataset
is large-scale, which contains the head fixations of 30 subjects viewing 600
ODIs. Next, we mine our AOI dataset and determine three findings: (1) The
consistency of head fixations are consistent among subjects, and it grows
alongside the increased subject number; (2) The head fixations exist with a
front center bias (FCB); and (3) The magnitude of head movement is similar
across subjects. According to these findings, our SalGAIL approach applies deep
reinforcement learning (DRL) to predict the head fixations of one subject, in
which GAIL learns the reward of DRL, rather than the traditional human-designed
reward. Then, multi-stream DRL is developed to yield the head fixations of
different subjects, and the saliency map of an ODI is generated via convoluting
predicted head fixations. Finally, experiments validate the effectiveness of
our approach in predicting saliency maps of ODIs, significantly better than 10
state-of-the-art approaches.
"
1998,Steganographer Identification,"  Conventional steganalysis detects the presence of steganography within single
objects. In the real-world, we may face a complex scenario that one or some of
multiple users called actors are guilty of using steganography, which is
typically defined as the Steganographer Identification Problem (SIP). One might
use the conventional steganalysis algorithms to separate stego objects from
cover objects and then identify the guilty actors. However, the guilty actors
may be lost due to a number of false alarms. To deal with the SIP, most of the
state-of-the-arts use unsupervised learning based approaches. In their
solutions, each actor holds multiple digital objects, from which a set of
feature vectors can be extracted. The well-defined distances between these
feature sets are determined to measure the similarity between the corresponding
actors. By applying clustering or outlier detection, the most suspicious
actor(s) will be judged as the steganographer(s). Though the SIP needs further
study, the existing works have good ability to identify the steganographer(s)
when non-adaptive steganographic embedding was applied. In this chapter, we
will present foundational concepts and review advanced methodologies in SIP.
This chapter is self-contained and intended as a tutorial introducing the SIP
in the context of media steganography.
"
1999,Co-Separating Sounds of Visual Objects,"  Learning how objects sound from video is challenging, since they often
heavily overlap in a single audio channel. Current methods for visually-guided
audio source separation sidestep the issue by training with artificially mixed
video clips, but this puts unwieldy restrictions on training data collection
and may even prevent learning the properties of ""true"" mixed sounds. We
introduce a co-separation training paradigm that permits learning object-level
sounds from unlabeled multi-source videos. Our novel training objective
requires that the deep neural network's separated audio for similar-looking
objects be consistently identifiable, while simultaneously reproducing accurate
video-level audio tracks for each source training pair. Our approach
disentangles sounds in realistic test videos, even in cases where an object was
not observed individually during training. We obtain state-of-the-art results
on visually-guided audio source separation and audio denoising for the MUSIC,
AudioSet, and AV-Bench datasets.
"
2000,"Adversarial Cross-Modal Retrieval via Learning and Transferring
  Single-Modal Similarities","  Cross-modal retrieval aims to retrieve relevant data across different
modalities (e.g., texts vs. images). The common strategy is to apply
element-wise constraints between manually labeled pair-wise items to guide the
generators to learn the semantic relationships between the modalities, so that
the similar items can be projected close to each other in the common
representation subspace. However, such constraints often fail to preserve the
semantic structure between unpaired but semantically similar items (e.g. the
unpaired items with the same class label are more similar than items with
different labels). To address the above problem, we propose a novel cross-modal
similarity transferring (CMST) method to learn and preserve the semantic
relationships between unpaired items in an unsupervised way. The key idea is to
learn the quantitative similarities in single-modal representation subspace,
and then transfer them to the common representation subspace to establish the
semantic relationships between unpaired items across modalities. Experiments
show that our method outperforms the state-of-the-art approaches both in the
class-based and pair-based retrieval tasks.
"
2001,SCE: A manifold regularized set-covering method for data partitioning,"  Cluster analysis plays a very important role in data analysis. In these
years, cluster ensemble, as a cluster analysis tool, has drawn much attention
for its robustness, stability, and accuracy. Many efforts have been done to
combine different initial clustering results into a single clustering solution
with better performance. However, they neglect the structure information of the
raw data in performing the cluster ensemble. In this paper, we propose a
Structural Cluster Ensemble (SCE) algorithm for data partitioning formulated as
a set-covering problem. In particular, we construct a Laplacian regularized
objective function to capture the structure information among clusters.
Moreover, considering the importance of the discriminative information
underlying in the initial clustering results, we add a discriminative
constraint into our proposed objective function. Finally, we verify the
performance of the SCE algorithm on both synthetic and real data sets. The
experimental results show the effectiveness of our proposed method SCE
algorithm.
"
2002,"An efficient multi-language Video Search Engine to facilitate the HADJ
  and the UMRA","  Videos clips became the most important and prominent multimedia document to
illustrate the rituals process of Hajj and Umrah. Therefore, it is necessary to
develop a system to facilitate access to information related to the duties, the
pillars, the stages and the prayers. In this paper present a new project
accomplishing a search engine in a large video database enabling any pilgrims
to get the information that he care about as fast, accurate. This project is
based on two techniques: (a) the weighting method to determine the degree of
affiliation of a video clip to a particular topic (b) organizing data using
several layers.
"
2003,"Exploring Uncertainty Measures for Image-Caption Embedding-and-Retrieval
  Task","  With the wide development of black-box machine learning algorithms,
particularly deep neural network (DNN), the practical demand for the
reliability assessment is rapidly rising. On the basis of the concept that
`Bayesian deep learning knows what it does not know,' the uncertainty of DNN
outputs has been investigated as a reliability measure for the classification
and regression tasks. However, in the image-caption retrieval task, well-known
samples are not always easy-to-retrieve samples. This study investigates two
aspects of image-caption embedding-and-retrieval systems. On one hand, we
quantify feature uncertainty by considering image-caption embedding as a
regression task, and use it for model averaging, which can improve the
retrieval performance. On the other hand, we further quantify posterior
uncertainty by considering the retrieval as a classification task, and use it
as a reliability measure, which can greatly improve the retrieval performance
by rejecting uncertain queries. The consistent performance of two uncertainty
measures is observed with different datasets (MS COCO and Flickr30k), different
deep learning architectures (dropout and batch normalization), and different
similarity functions.
"
2004,Exquisitor: Interactive Learning at Large,"  Increasing scale is a dominant trend in today's multimedia collections, which
especially impacts interactive applications. To facilitate interactive
exploration of large multimedia collections, new approaches are needed that are
capable of learning on the fly new analytic categories based on the visual and
textual content. To facilitate general use on standard desktops, laptops, and
mobile devices, they must furthermore work with limited computing resources. We
present Exquisitor, a highly scalable interactive learning approach, capable of
intelligent exploration of the large-scale YFCC100M image collection with
extremely efficient responses from the interactive classifier. Based on
relevance feedback from the user on previously suggested items, Exquisitor uses
semantic features, extracted from both visual and text attributes, to suggest
relevant media items to the user. Exquisitor builds upon the state of the art
in large-scale data representation, compression and indexing, introducing a
cluster-based retrieval mechanism that facilitates the efficient suggestions.
With Exquisitor, each interaction round over the full YFCC100M collection is
completed in less than 0.3 seconds using a single CPU core. That is 4x less
time using 16x smaller computational resources than the most efficient
state-of-the-art method, with a positive impact on result quality. These
results open up many interesting research avenues, both for exploration of
industry-scale media collections and for media exploration on mobile devices.
"
2005,On Acoustic Modeling for Broadband Beamforming,"  In this work, we describe limitations of the free-field propagation model for
designing broadband beamformers for microphone arrays on a rigid surface.
Towards this goal, we describe a general framework for quantifying the
microphone array performance in a general wave-field by directly solving the
acoustic wave equation. The model utilizes Finite-Element-Method (FEM) for
evaluating the response of the microphone array surface to background 3D planar
and spherical waves. The effectiveness of the framework is established by
designing and evaluating a representative broadband beamformer under realistic
acoustic conditions.
"
2006,Listen to the Image,"  Visual-to-auditory sensory substitution devices can assist the blind in
sensing the visual environment by translating the visual information into a
sound pattern. To improve the translation quality, the task performances of the
blind are usually employed to evaluate different encoding schemes. In contrast
to the toilsome human-based assessment, we argue that machine model can be also
developed for evaluation, and more efficient. To this end, we firstly propose
two distinct cross-modal perception model w.r.t. the late-blind and
congenitally-blind cases, which aim to generate concrete visual contents based
on the translated sound. To validate the functionality of proposed models, two
novel optimization strategies w.r.t. the primary encoding scheme are presented.
Further, we conduct sets of human-based experiments to evaluate and compare
them with the conducted machine-based assessments in the cross-modal generation
task. Their highly consistent results w.r.t. different encoding schemes
indicate that using machine model to accelerate optimization evaluation and
reduce experimental cost is feasible to some extent, which could dramatically
promote the upgrading of encoding scheme then help the blind to improve their
visual perception ability.
"
2007,StegoAppDB: a Steganography Apps Forensics Image Database,"  In this paper, we present a new reference dataset simulating digital evidence
for image steganography. Steganography detection is a digital image forensic
topic that is relatively unknown in practical forensics, although stego app use
in the wild is on the rise. This paper introduces the first database consisting
of mobile phone photographs and stego images produced from mobile stego apps,
including a rich set of side information, offering simulated digital evidence.
StegoAppDB, a steganography apps forensics image database, contains over
810,000 innocent and stego images using a minimum of 10 different phone models
from 24 distinct devices, with detailed provenanced data comprising a wide
range of ISO and exposure settings, EXIF data, message information, embedding
rates, etc. We develop a camera app, Cameraw, specifically for data
acquisition, with multiple images per scene, saving simultaneously in both DNG
and high-quality JPEG formats. Stego images are created from these original
images using selected mobile stego apps through a careful process of reverse
engineering. StegoAppDB contains cover-stego image pairs including for apps
that resize the stego dimensions. We retainthe original devices and continue to
enlarge the database, and encourage the image forensics community to use
StegoAppDB. While designed for steganography, we discuss uses of this publicly
available database to other digital image forensic topics.
"
2008,"A Novel QoE-Aware SDN-enabled, NFV-based Management Architecture for
  Future Multimedia Applications on 5G Systems","  This paper proposes a novel QoE-aware SDN enabled NFV architecture for
controlling and managing Future Multimedia Applications on 5G systems. The aim
is to improve the QoE of the delivered multimedia services through the
fulfilment of personalized QoE application requirements. This novel approach
provides some new features, functionalities, concepts and opportunities for
overcoming the key QoE provisioning limitations in current 4G systems such as
increased network management complexity and inability to adapt dynamically to
changing application, network transmission or traffic or end-users demand.
"
2009,"Siamese Attentional Keypoint Network for High Performance Visual
  Tracking","  In this paper, we investigate the impacts of three main aspects of visual
tracking, i.e., the backbone network, the attentional mechanism, and the
detection component, and propose a Siamese Attentional Keypoint Network, dubbed
SATIN, for efficient tracking and accurate localization. Firstly, a new Siamese
lightweight hourglass network is specially designed for visual tracking. It
takes advantage of the benefits of the repeated bottom-up and top-down
inference to capture more global and local contextual information at multiple
scales. Secondly, a novel cross-attentional module is utilized to leverage both
channel-wise and spatial intermediate attentional information, which can
enhance both discriminative and localization capabilities of feature maps.
Thirdly, a keypoints detection approach is invented to trace any target object
by detecting the top-left corner point, the centroid point, and the
bottom-right corner point of its bounding box. Therefore, our SATIN tracker not
only has a strong capability to learn more effective object representations,
but also is computational and memory storage efficiency, either during the
training or testing stages. To the best of our knowledge, we are the first to
propose this approach. Without bells and whistles, experimental results
demonstrate that our approach achieves state-of-the-art performance on several
recent benchmark datasets, at a speed far exceeding 27 frames per second.
"
2010,"Syst\`{e}me d'indexation et de recherche de vid\'{e}o int\'{e}grant un
  syst\`{e}me gestuel pour les personnes handicap\'{e}es","  The amount of audio-visual information has increased dramatically with the
advent of High Speed Internet. Furthermore, technological advances in recent
years in the field of information technology, have simplified the use of video
data in various fields by the general public. This made it possible to store
large collections of video documents into computer systems. To enable efficient
use of these collections, it is necessary to develop tools to facilitate access
to these documents and handling them. In this paper we propose a method for
indexing and retrieval of video sequences in a video database of large
dimension, based on a weighting technique to calculate the degree of membership
of a concept in a video also a structuring of the data of the audio-visual
(context / concept / video). Finally, we decided to create a search system,
offering in addition to the usual commands, different types of access to the
system, depending on the disability of the person. Indeed, the application
consists of a search system but offers access to commands through voice or
gestures. Our contribution at the experimental level consists with the
implementation of prototype. We integrated the techniques proposed in system to
evaluate it contributions in terms of effectiveness and precision.
"
2011,A Noise-aware Enhancement Method for Underexposed Images,"  A novel method of contrast enhancement is proposed for underexposed images,
in which heavy noise is hidden. Under low light conditions, images taken by
digital cameras have low contrast in dark or bright regions. This is due to a
limited dynamic range that imaging sensors have. For these reasons, various
contrast enhancement methods have been proposed so far. These methods, however,
have two problems: (1) The loss of details in bright regions due to
over-enhancement of contrast. (2) The noise is amplified in dark regions
because conventional enhancement methods do not consider noise included in
images. The proposed method aims to overcome these problems. In the proposed
method, a shadow-up function is applied to adaptive gamma correction with
weighting distribution, and a denoising filter is also used to avoid noise
being amplified in dark regions. As a result, the proposed method allows us not
only to enhance contrast of dark regions, but also to avoid amplifying noise,
even under strong noise environments.
"
2012,Video coding technique with parametric modeling of noise,"  This paper presents a video encoding method in which noise is encoded using a
novel parametric model representing spectral envelope and spatial distribution
of energy. The proposed method has been experimentally assessed using video
test sequences in a practical setup consisting of a simple, real-time noise
reduction technique and High Efficiency Video Codec (HEVC). The attained
results show that the use of the proposed parametric modeling of noise can
improve the subjective quality of reconstructed video by approximately 1.8 Mean
Opinion Scope (MOS) points (in 11-point scale) related to the classical video
coding. Moreover, the present work confirms results attained in the previous
works that the usage of even sole noise reduction prior to the encoding
provides quality increase.
"
2013,3D Dynamic Point Cloud Denoising via Spatial-Temporal Graph Learning,"  The prevalence of accessible depth sensing and 3D laser scanning techniques
has enabled the convenient acquisition of 3D dynamic point clouds, which
provide efficient representation of arbitrarily-shaped objects in motion.
Nevertheless, dynamic point clouds are often perturbed by noise due to
hardware, software or other causes. While a plethora of methods have been
proposed for static point cloud denoising, few efforts are made for the
denoising of dynamic point clouds with varying number of irregularly-sampled
points in each frame. In this paper, we represent dynamic point clouds
naturally on graphs and address the denoising problem by inferring the
underlying graph via spatio-temporal graph learning, exploiting both the
intra-frame similarity and inter-frame consistency. Firstly, assuming the
availability of a relevant feature vector per node, we pose spatial-temporal
graph learning as optimizing a Mahalanobis distance metric $\mathbf{M}$, which
is formulated as the minimization of graph Laplacian regularizer. Secondly, to
ease the optimization of the symmetric and positive definite metric matrix
$\mathbf{M}$, we decompose it into $\mathbf{M}=\mathbf{R}^{\top}\mathbf{R}$ and
solve $\mathbf{R}$ instead via proximal gradient. Finally, based on the
spatial-temporal graph learning, we formulate dynamic point cloud denoising as
the joint optimization of the desired point cloud and underlying
spatio-temporal graph, which leverages both intra-frame affinities and
inter-frame consistency and is solved via alternating minimization.
Experimental results show that the proposed method significantly outperforms
independent denoising of each frame from state-of-the-art static point cloud
denoising approaches.
"
2014,Deep Learning-Based Video Coding: A Review and A Case Study,"  The past decade has witnessed great success of deep learning technology in
many disciplines, especially in computer vision and image processing. However,
deep learning-based video coding remains in its infancy. This paper reviews the
representative works about using deep learning for image/video coding, which
has been an actively developing research area since the year of 2015. We divide
the related works into two categories: new coding schemes that are built
primarily upon deep networks (deep schemes), and deep network-based coding
tools (deep tools) that shall be used within traditional coding schemes or
together with traditional coding tools. For deep schemes, pixel probability
modeling and auto-encoder are the two approaches, that can be viewed as
predictive coding scheme and transform coding scheme, respectively. For deep
tools, there have been several proposed techniques using deep learning to
perform intra-picture prediction, inter-picture prediction, cross-channel
prediction, probability distribution prediction, transform, post- or in-loop
filtering, down- and up-sampling, as well as encoding optimizations. In the
hope of advocating the research of deep learning-based video coding, we present
a case study of our developed prototype video codec, namely Deep Learning Video
Coding (DLVC). DLVC features two deep tools that are both based on
convolutional neural network (CNN), namely CNN-based in-loop filter (CNN-ILF)
and CNN-based block adaptive resolution coding (CNN-BARC). Both tools help
improve the compression efficiency by a significant margin. With the two deep
tools as well as other non-deep coding tools, DLVC is able to achieve on
average 39.6\% and 33.0\% bits saving than HEVC, under random-access and
low-delay configurations, respectively. The source code of DLVC has been
released for future researches.
"
2015,AnonymousNet: Natural Face De-Identification with Measurable Privacy,"  With billions of personal images being generated from social media and
cameras of all sorts on a daily basis, security and privacy are unprecedentedly
challenged. Although extensive attempts have been made, existing face image
de-identification techniques are either insufficient in photo-reality or
incapable of balancing privacy and usability qualitatively and quantitatively,
i.e., they fail to answer counterfactual questions such as ""is it private
now?"", ""how private is it?"", and ""can it be more private?"" In this paper, we
propose a novel framework called AnonymousNet, with an effort to address these
issues systematically, balance usability, and enhance privacy in a natural and
measurable manner. The framework encompasses four stages: facial attribute
estimation, privacy-metric-oriented face obfuscation, directed natural image
synthesis, and adversarial perturbation. Not only do we achieve the
state-of-the-arts in terms of image quality and attribute prediction accuracy,
we are also the first to show that facial privacy is measurable, can be
factorized, and accordingly be manipulated in a photo-realistic fashion to
fulfill different requirements and application scenarios. Experiments further
demonstrate the effectiveness of the proposed framework.
"
2016,"Computational Attention System for Children, Adults and Elderly","  The existing computational visual attention systems have focused on the
objective to basically simulate and understand the concept of visual attention
system in adults. Consequently, the impact of observer's age in scene viewing
behavior has rarely been considered. This study quantitatively analyzed the
age-related differences in gaze landings during scene viewing for three
different class of images: naturals, man-made, and fractals. Observer's of
different age-group have shown different scene viewing tendencies independent
to the class of the image viewed. Several interesting observations are drawn
from the results. First, gaze landings for man-made dataset showed that whereas
child observers focus more on the scene foreground, i.e., locations that are
near, elderly observers tend to explore the scene background, i.e., locations
farther in the scene. Considering this result a framework is proposed in this
paper to quantitatively measure the depth bias tendency across age groups.
Second, the quantitative analysis results showed that children exhibit the
lowest exploratory behavior level but the highest central bias tendency among
the age groups and across the different scene categories. Third,
inter-individual similarity metrics reveal that an adult had significantly
lower gaze consistency with children and elderly compared to other adults for
all the scene categories. Finally, these analysis results were consequently
leveraged to develop a more accurate age-adapted saliency model independent to
the image type. The prediction accuracy suggests that our model fits better to
the collected eye-gaze data of the observers belonging to different age groups
than the existing models do.
"
2017,Effective and Efficient Indexing in Cross-Modal Hashing-Based Datasets,"  To overcome the barrier of storage and computation, the hashing technique has
been widely used for nearest neighbor search in multimedia retrieval
applications recently. Particularly, cross-modal retrieval that searches across
different modalities becomes an active but challenging problem. Although dozens
of cross-modal hashing algorithms are proposed to yield compact binary codes,
the exhaustive search is impractical for the real-time purpose, and Hamming
distance computation suffers inaccurate results. In this paper, we propose a
novel search method that utilizes a probability-based index scheme over binary
hash codes in cross-modal retrieval. The proposed hash code indexing scheme
exploits a few binary bits of the hash code as the index code. We construct an
inverted index table based on index codes and train a neural network to improve
the indexing accuracy and efficiency. Experiments are performed on two
benchmark datasets for retrieval across image and text modalities, where hash
codes are generated by three cross-modal hashing methods. Results show the
proposed method effectively boost the performance on these hash methods.
"
2018,"State-of-the-art in 360{\deg} Video/Image Processing: Perception,
  Assessment and Compression","  Nowadays, 360{\deg} video/image has been increasingly popular and drawn great
attention. The spherical viewing range of 360{\deg} video/image accounts for
huge data, which pose the challenges to 360{\deg} video/image processing in
solving the bottleneck of storage, transmission, etc. Accordingly, the recent
years have witnessed the explosive emergence of works on 360{\deg} video/image
processing. In this paper, we review the state-of-the-art works on 360{\deg}
video/image processing from the aspects of perception, assessment and
compression. First, this paper reviews both datasets and visual attention
modelling approaches for 360{\deg} video/image. Second, we survey the related
works on both subjective and objective visual quality assessment (VQA) of
360{\deg} video/image. Third, we overview the compression approaches for
360{\deg} video/image, which either utilize the spherical characteristics or
visual attention models. Finally, we summarize this overview paper and outlook
the future research trends on 360{\deg} video/image processing.
"
2019,"Learned Image Compression with Soft Bit-based Rate-Distortion
  Optimization","  This paper introduces the notion of soft bits to address the rate-distortion
optimization for learning-based image compression. Recent methods for such
compression train an autoencoder end-to-end with an objective to strike a
balance between distortion and rate. They are faced with the zero gradient
issue due to quantization and the difficulty of estimating the rate accurately.
Inspired by soft quantization, we represent quantization indices of feature
maps with differentiable soft bits. This allows us to couple tightly the rate
estimation with context-adaptive binary arithmetic coding. It also provides a
differentiable distortion objective function. Experimental results show that
our approach achieves the state-of-the-art compression performance among the
learning-based schemes in terms of MS-SSIM and PSNR.
"
2020,"Fully Automatic Brain Tumor Segmentation using a Normalized Gaussian
  Bayesian Classifier and 3D Fluid Vector Flow","  Brain tumor segmentation from Magnetic Resonance Images (MRIs) is an
important task to measure tumor responses to treatments. However, automatic
segmentation is very challenging. This paper presents an automatic brain tumor
segmentation method based on a Normalized Gaussian Bayesian classification and
a new 3D Fluid Vector Flow (FVF) algorithm. In our method, a Normalized
Gaussian Mixture Model (NGMM) is proposed and used to model the healthy brain
tissues. Gaussian Bayesian Classifier is exploited to acquire a Gaussian
Bayesian Brain Map (GBBM) from the test brain MR images. GBBM is further
processed to initialize the 3D FVF algorithm, which segments the brain tumor.
This algorithm has two major contributions. First, we present a NGMM to model
healthy brains. Second, we extend our 2D FVF algorithm to 3D space and use it
for brain tumor segmentation. The proposed method is validated on a publicly
available dataset.
"
2021,"Herding Effect based Attention for Personalized Time-Sync Video
  Recommendation","  Time-sync comment (TSC) is a new form of user-interaction review associated
with real-time video contents, which contains a user's preferences for videos
and therefore well suited as the data source for video recommendations.
However, existing review-based recommendation methods ignore the
context-dependent (generated by user-interaction), real-time, and
time-sensitive properties of TSC data. To bridge the above gaps, in this paper,
we use video images and users' TSCs to design an Image-Text Fusion model with a
novel Herding Effect Attention mechanism (called ITF-HEA), which can predict
users' favorite videos with model-based collaborative filtering. Specifically,
in the HEA mechanism, we weight the context information based on the semantic
similarities and time intervals between each TSC and its context, thereby
considering influences of the herding effect in the model. Experiments show
that ITF-HEA is on average 3.78\% higher than the state-of-the-art method upon
F1-score in baselines.
"
2022,Time-sync Video Tag Extraction Using Semantic Association Graph,"  Time-sync comments reveal a new way of extracting the online video tags.
However, such time-sync comments have lots of noises due to users' diverse
comments, introducing great challenges for accurate and fast video tag
extractions. In this paper, we propose an unsupervised video tag extraction
algorithm named Semantic Weight-Inverse Document Frequency (SW-IDF).
Specifically, we first generate corresponding semantic association graph (SAG)
using semantic similarities and timestamps of the time-sync comments. Second,
we propose two graph cluster algorithms, i.e., dialogue-based algorithm and
topic center-based algorithm, to deal with the videos with different density of
comments. Third, we design a graph iteration algorithm to assign the weight to
each comment based on the degrees of the clustered subgraphs, which can
differentiate the meaningful comments from the noises. Finally, we gain the
weight of each word by combining Semantic Weight (SW) and Inverse Document
Frequency (IDF). In this way, the video tags are extracted automatically in an
unsupervised way. Extensive experiments have shown that SW-IDF (dialogue-based
algorithm) achieves 0.4210 F1-score and 0.4932 MAP (Mean Average Precision) in
high-density comments, 0.4267 F1-score and 0.3623 MAP in low-density comments;
while SW-IDF (topic center-based algorithm) achieves 0.4444 F1-score and 0.5122
MAP in high-density comments, 0.4207 F1-score and 0.3522 MAP in low-density
comments. It has a better performance than the state-of-the-art unsupervised
algorithms in both F1-score and MAP.
"
2023,"Learning Cross-Modal Embeddings with Adversarial Networks for Cooking
  Recipes and Food Images","  Food computing is playing an increasingly important role in human daily life,
and has found tremendous applications in guiding human behavior towards smart
food consumption and healthy lifestyle. An important task under the
food-computing umbrella is retrieval, which is particularly helpful for health
related applications, where we are interested in retrieving important
information about food (e.g., ingredients, nutrition, etc.). In this paper, we
investigate an open research task of cross-modal retrieval between cooking
recipes and food images, and propose a novel framework Adversarial Cross-Modal
Embedding (ACME) to resolve the cross-modal retrieval task in food domains.
Specifically, the goal is to learn a common embedding feature space between the
two modalities, in which our approach consists of several novel ideas: (i)
learning by using a new triplet loss scheme together with an effective sampling
strategy, (ii) imposing modality alignment using an adversarial learning
strategy, and (iii) imposing cross-modal translation consistency such that the
embedding of one modality is able to recover some important information of
corresponding instances in the other modality. ACME achieves the
state-of-the-art performance on the benchmark Recipe1M dataset, validating the
efficacy of the proposed technique.
"
2024,"Efficient Discrete Supervised Hashing for Large-scale Cross-modal
  Retrieval","  Supervised cross-modal hashing has gained increasing research interest on
large-scale retrieval task owning to its satisfactory performance and
efficiency. However, it still has some challenging issues to be further
studied: 1) most of them fail to well preserve the semantic correlations in
hash codes because of the large heterogenous gap; 2) most of them relax the
discrete constraint on hash codes, leading to large quantization error and
consequent low performance; 3) most of them suffer from relatively high memory
cost and computational complexity during training procedure, which makes them
unscalable. In this paper, to address above issues, we propose a supervised
cross-modal hashing method based on matrix factorization dubbed Efficient
Discrete Supervised Hashing (EDSH). Specifically, collective matrix
factorization on heterogenous features and semantic embedding with class labels
are seamlessly integrated to learn hash codes. Therefore, the feature based
similarities and semantic correlations can be both preserved in hash codes,
which makes the learned hash codes more discriminative. Then an efficient
discrete optimal algorithm is proposed to handle the scalable issue. Instead of
learning hash codes bit-by-bit, hash codes matrix can be obtained directly
which is more efficient. Extensive experimental results on three public
real-world datasets demonstrate that EDSH produces a superior performance in
both accuracy and scalability over some existing cross-modal hashing methods.
"
2025,Game-theoretic Analysis to Content-adaptive Reversible Watermarking,"  While many games were designed for steganography and robust watermarking, few
focused on reversible watermarking. We present a two-encoder game related to
the rate-distortion optimization of content-adaptive reversible watermarking.
In the game, Alice first hides a payload into a cover. Then, Bob hides another
payload into the modified cover. The embedding strategy of Alice affects the
embedding capacity of Bob. The embedding strategy of Bob may produce
data-extraction errors to Alice. Both want to embed as many pure secret bits as
possible, subjected to an upper-bounded distortion. We investigate
non-cooperative game and cooperative game between Alice and Bob. When they
cooperate with each other, one may consider them as a whole, i.e., an encoder
uses a cover for data embedding with two times. When they do not cooperate with
each other, the game corresponds to a separable system, i.e., both want to
independently hide a payload within the cover, but recovering the cover may
need cooperation. We find equilibrium strategies for both players under
constraints.
"
2026,Few-Shot Unsupervised Image-to-Image Translation,"  Unsupervised image-to-image translation methods learn to map images in a
given class to an analogous image in a different class, drawing on unstructured
(non-registered) datasets of images. While remarkably successful, current
methods require access to many images in both source and destination classes at
training time. We argue this greatly limits their use. Drawing inspiration from
the human capability of picking up the essence of a novel object from a small
number of examples and generalizing from there, we seek a few-shot,
unsupervised image-to-image translation algorithm that works on previously
unseen target classes that are specified, at test time, only by a few example
images. Our model achieves this few-shot generation capability by coupling an
adversarial training scheme with a novel network design. Through extensive
experimental validation and comparisons to several baseline methods on
benchmark datasets, we verify the effectiveness of the proposed framework. Our
implementation and datasets are available at https://github.com/NVlabs/FUNIT .
"
2027,A multimodal lossless coding method for skeletons in videos,"  Nowadays, skeleton information in videos plays an important role in
human-centric video analysis but effective coding such massive skeleton
information has never been addressed in previous work. In this paper, we make
the first attempt to solve this problem by proposing a multimodal skeleton
coding tool containing three different coding schemes, namely, spatial
differential-coding scheme, motionvector-based differential-coding scheme and
inter prediction scheme, thus utilizing both spatial and temporal redundancy to
losslessly compress skeleton data. More importantly, these schemes are switched
properly for different types of skeletons in video frames, hence achieving
further improvement of compression rate. Experimental results show that our
approach leads to 74.4% and 54.7% size reduction on our surveillance sequences
and overall test sequences respectively, which demonstrates the effectiveness
of our skeleton coding tool.
"
2028,Compressed Image Quality Assessment Based on Saak Features,"  Compressed image quality assessment plays an important role in image
services, especially in image compression applications, which can be utilized
as a guidance to optimize image processing algorithms. In this paper, we
propose an objective image quality assessment algorithm to measure the quality
of compressed images. The proposed method utilizes a data-driven transform,
Saak (Subspace approximation with augmented kernels), to decompose images into
hierarchical structural feature space. We measure the distortions of Saak
features and accumulate these distortions according to the feature importance
to human visual system. Compared with the state-of-the-art image quality
assessment methods on widely utilized datasets, the proposed method correlates
better with the subjective results. In addition, the proposed methods achieves
more robust results on different datasets.
"
2029,"Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for
  Lipreading","  We focus on the word-level visual lipreading, which requires recognizing the
word being spoken, given only the video but not the audio. State-of-the-art
methods explore the use of end-to-end neural networks, including a shallow (up
to three layers) 3D convolutional neural network (CNN) + a deep 2D CNN (e.g.,
ResNet) as the front-end to extract visual features, and a recurrent neural
network (e.g., bidirectional LSTM) as the back-end for classification. In this
work, we propose to replace the shallow 3D CNNs + deep 2D CNNs front-end with
recent successful deep 3D CNNs --- two-stream (i.e., grayscale video and
optical flow streams) I3D. We evaluate different combinations of front-end and
back-end modules with the grayscale video and optical flow inputs on the LRW
dataset. The experiments show that, compared to the shallow 3D CNNs + deep 2D
CNNs front-end, the deep 3D CNNs front-end with pre-training on the large-scale
image and video datasets (e.g., ImageNet and Kinetics) can improve the
classification accuracy. Also, we demonstrate that using the optical flow input
alone can achieve comparable performance as using the grayscale video as input.
Moreover, the two-stream network using both the grayscale video and optical
flow inputs can further improve the performance. Overall, our two-stream I3D
front-end with a Bi-LSTM back-end results in an absolute improvement of 5.3%
over the previous art on the LRW dataset.
"
2030,Learning Cascaded Siamese Networks for High Performance Visual Tracking,"  Visual tracking is one of the most challenging computer vision problems. In
order to achieve high performance visual tracking in various negative
scenarios, a novel cascaded Siamese network is proposed and developed based on
two different deep learning networks: a matching subnetwork and a
classification subnetwork. The matching subnetwork is a fully convolutional
Siamese network. According to the similarity score between the exemplar image
and the candidate image, it aims to search possible object positions and crop
scaled candidate patches. The classification subnetwork is designed to further
evaluate the cropped candidate patches and determine the optimal tracking
results based on the classification score. The matching subnetwork is trained
offline and fixed online, while the classification subnetwork performs
stochastic gradient descent online to learn more target-specific information.
To improve the tracking performance further, an effective classification
subnetwork update method based on both similarity and classification scores is
utilized for updating the classification subnetwork. Extensive experimental
results demonstrate that our proposed approach achieves state-of-the-art
performance in recent benchmarks.
"
2031,Generative Reversible Data Hiding by Image to Image Translation via GANs,"  The traditional reversible data hiding technique is based on cover image
modification which inevitably leaves some traces of rewriting that can be more
easily analyzed and attacked by the warder. Inspired by the cover synthesis
steganography based generative adversarial networks, in this paper, a novel
generative reversible data hiding scheme (GRDH) by image translation is
proposed. First, an image generator is used to obtain a realistic image, which
is used as an input to the image-to-image translation model with CycleGAN.
After image translation, a stego image with different semantic information will
be obtained. The secret message and the original input image can be recovered
separately by a well-trained message extractor and the inverse transform of the
image translation. Experimental results have verified the effectiveness of the
scheme.
"
2032,"Convolutional Neural Networks Considering Local and Global features for
  Image Enhancement","  In this paper, we propose a novel convolutional neural network (CNN)
architecture considering both local and global features for image enhancement.
Most conventional image enhancement methods, including Retinex-based methods,
cannot restore lost pixel values caused by clipping and quantizing. CNN-based
methods have recently been proposed to solve the problem, but they still have a
limited performance due to network architectures not handling global features.
To handle both local and global features, the proposed architecture consists of
three networks: a local encoder, a global encoder, and a decoder. In addition,
high dynamic range (HDR) images are used for generating training data for our
networks. The use of HDR images makes it possible to train CNNs with
better-quality images than images directly captured with cameras. Experimental
results show that the proposed method can produce higher-quality images than
conventional image enhancement methods including CNN-based methods, in terms of
various objective quality metrics: TMQI, entropy, NIQE, and BRISQUE.
"
2033,"Methodology for accurately assessing the quality perceived by users on
  360VR contents","  To properly evaluate the performance of 360VR-specific encoding and
transmission schemes, and particularly of the solutions based on viewport
adaptation, it is necessary to consider not only the bandwidth saved, but also
the quality of the portion of the scene actually seen by users over time. With
this motivation, we propose a robust, yet flexible methodology for accurately
assessing the quality within the viewport along the visualization session. This
procedure is based on a complete analysis of the geometric relations involved.
Moreover, the designed methodology allows for both offline and online usage
thanks to the use of different approximations. In this way, our methodology can
be used regardless of the approach to properly evaluate the implemented
strategy, obtaining a fairer comparison between them.
"
2034,Reversible Data Hiding in JPEG Images with Multi-objective Optimization,"  Among various methods of reversible data hiding (RDH) in JPEG images, the
consideration in designing is only the image quality, but the image quality and
the file size expansion are equally important in JPEG images. Based on this
situation, we propose a RDH scheme in JPEG images considering both the image
quality and the file size expansion while designing the algorithm. The
multi-objective optimization strategy is utilized to realize the balance of the
two objectives. Specifically, the cover is divided into several non-overlapping
signals firstly, and after that, the embedding costs of signals are calculated
using the knowledge of the JPEG compression. Next, the optimized combination of
signals for embedding data is gained by the multi-objective optimization.
Experimental results show the better performance of our proposed RDH compared
with state-of-the-art RDH in JPEG images.
"
2035,Deep AutoEncoder-based Lossy Geometry Compression for Point Clouds,"  Point cloud is a fundamental 3D representation which is widely used in real
world applications such as autonomous driving. As a newly-developed media
format which is characterized by complexity and irregularity, point cloud
creates a need for compression algorithms which are more flexible than existing
codecs. Recently, autoencoders(AEs) have shown their effectiveness in many
visual analysis tasks as well as image compression, which inspires us to employ
it in point cloud compression. In this paper, we propose a general
autoencoder-based architecture for lossy geometry point cloud compression. To
the best of our knowledge, it is the first autoencoder-based geometry
compression codec that directly takes point clouds as input rather than voxel
grids or collections of images. Compared with handcrafted codecs, this approach
adapts much more quickly to previously unseen media contents and media formats,
meanwhile achieving competitive performance. Our architecture consists of a
pointnet-based encoder, a uniform quantizer, an entropy estimation block and a
nonlinear synthesis transformation module. In lossy geometry compression of
point cloud, results show that the proposed method outperforms the test model
for categories 1 and 3 (TMC13) published by MPEG-3DG group on the 125th
meeting, and on average a 73.15\% BD-rate gain is achieved.
"
2036,Supervised Online Hashing via Hadamard Codebook Learning,"  In recent years, binary code learning, a.k.a hashing, has received extensive
attention in large-scale multimedia retrieval. It aims to encode
high-dimensional data points to binary codes, hence the original
high-dimensional metric space can be efficiently approximated via Hamming
space. However, most existing hashing methods adopted offline batch learning,
which is not suitable to handle incremental datasets with streaming data or new
instances. In contrast, the robustness of the existing online hashing remains
as an open problem, while the embedding of supervised/semantic information
hardly boosts the performance of the online hashing, mainly due to the defect
of unknown category numbers in supervised learning. In this paper, we proposed
an online hashing scheme, termed Hadamard Codebook based Online Hashing (HCOH),
which aims to solve the above problems towards robust and supervised online
hashing. In particular, we first assign an appropriate high-dimensional binary
codes to each class label, which is generated randomly by Hadamard codes to
each class label, which is generated randomly by Hadamard codes. Subsequently,
LSH is adopted to reduce the length of such Hadamard codes in accordance with
the hash bits, which can adapt the predefined binary codes online, and
theoretically guarantee the semantic similarity. Finally, we consider the
setting of stochastic data acquisition, which facilitates our method to
efficiently learn the corresponding hashing functions via stochastic gradient
descend (SGD) online. Notably, the proposed HCOH can be embedded with
supervised labels and it not limited to a predefined category number. Extensive
experiments on three widely-used benchmarks demonstrate the merits of the
proposed scheme over the state-of-the-art methods. The code is available at
https://github.com/lmbxmu/mycode/tree/master/2018ACMMM_HCOH.
"
2037,A Taxonomy and Dataset for 360{\deg} Videos,"  In this paper, we propose a taxonomy for 360{\deg} videos that categorizes
videos based on moving objects and camera motion. We gathered and produced 28
videos based on the taxonomy, and recorded viewport traces from 60 participants
watching the videos. In addition to the viewport traces, we provide the
viewers' feedback on their experience watching the videos, and we also analyze
viewport patterns on each category.
"
2038,DEMC: A Deep Dual-Encoder Network for Denoising Monte Carlo Rendering,"  In this paper, we present DEMC, a deep Dual-Encoder network to remove Monte
Carlo noise efficiently while preserving details. Denoising Monte Carlo
rendering is different from natural image denoising since inexpensive
by-products (feature buffers) can be extracted in the rendering stage. Most of
them are noise-free and can provide sufficient details for image
reconstruction. However, these feature buffers also contain redundant
information, which makes Monte Carlo denoising different from natural image
denoising. Hence, the main challenge of this topic is how to extract useful
information and reconstruct clean images. To address this problem, we propose a
novel network structure, Dual-Encoder network with a feature fusion
sub-network, to fuse feature buffers firstly, then encode the fused feature
buffers and a noisy image simultaneously, and finally reconstruct a clean image
by a decoder network. Compared with the state-of-the-art methods, our model is
more robust on a wide range of scenes and is able to generate satisfactory
results in a significantly faster way.
"
2039,Compressing Weight-updates for Image Artifacts Removal Neural Networks,"  In this paper, we present a novel approach for fine-tuning a decoder-side
neural network in the context of image compression, such that the
weight-updates are better compressible. At encoder side, we fine-tune a
pre-trained artifact removal network on target data by using a compression
objective applied on the weight-update. In particular, the compression
objective encourages weight-updates which are sparse and closer to quantized
values. This way, the final weight-update can be compressed more efficiently by
pruning and quantization, and can be included into the encoded bitstream
together with the image bitstream of a traditional codec. We show that this
approach achieves reconstruction quality which is on-par or slightly superior
to a traditional codec, at comparable bitrates. To our knowledge, this is the
first attempt to combine image compression and neural network's weight update
compression.
"
2040,Deep Vocoder: Low Bit Rate Compression of Speech with Deep Autoencoder,"  Inspired by the success of deep neural networks (DNNs) in speech processing,
this paper presents Deep Vocoder, a direct end-to-end low bit rate speech
compression method with deep autoencoder (DAE). In Deep Vocoder, DAE is used
for extracting the latent representing features (LRFs) of speech, which are
then efficiently quantized by an analysis-by-synthesis vector quantization (AbS
VQ) method. AbS VQ aims to minimize the perceptual spectral reconstruction
distortion rather than the distortion of LRFs vector itself. Also, a suboptimal
codebook searching technique is proposed to further reduce the computational
complexity. Experimental results demonstrate that Deep Vocoder yields
substantial improvements in terms of frequency-weighted segmental SNR, STOI and
PESQ score when compared to the output of the conventional SQ- or VQ-based
codec. The yielded PESQ score over the TIMIT corpus is 3.34 and 3.08 for speech
coding at 2400 bit/s and 1200 bit/s, respectively.
"
2041,"DotSCN: Group Re-identification via Domain-Transferred Single and Couple
  Representation Learning","  Group re-identification (G-ReID) is an important yet less-studied task. Its
challenges not only lie in appearance changes of individuals which have been
well-investigated in general person re-identification (ReID), but also derive
from group layout and membership changes. So the key task of G-ReID is to learn
representations robust to such changes. To address this issue, we propose a
Transferred Single and Couple Representation Learning Network (TSCN). Its
merits are two aspects: 1) Due to the lack of labelled training samples,
existing G-ReID methods mainly rely on unsatisfactory hand-crafted features. To
gain the superiority of deep learning models, we treat a group as multiple
persons and transfer the domain of a labeled ReID dataset to a G-ReID target
dataset style to learn single representations. 2) Taking into account the
neighborhood relationship in a group, we further propose learning a novel
couple representation between two group members, that achieves more
discriminative power in G-ReID tasks. In addition, an unsupervised weight
learning method is exploited to adaptively fuse the results of different views
together according to result patterns. Extensive experimental results
demonstrate the effectiveness of our approach that significantly outperforms
state-of-the-art methods by 11.7\% CMC-1 on the Road Group dataset and by
39.0\% CMC-1 on the DukeMCMT dataset.
"
2042,FPGA-based Binocular Image Feature Extraction and Matching System,"  Image feature extraction and matching is a fundamental but computation
intensive task in machine vision. This paper proposes a novel FPGA-based
embedded system to accelerate feature extraction and matching. It implements
SURF feature point detection and BRIEF feature descriptor construction and
matching. For binocular stereo vision, feature matching includes both tracking
matching and stereo matching, which simultaneously provide feature point
correspondences and parallax information. Our system is evaluated on a ZYNQ
XC7Z045 FPGA. The result demonstrates that it can process binocular video data
at a high frame rate (640$\times$480 @ 162fps). Moreover, an extensive test
proves our system has robustness for image compression, blurring and
illumination.
"
2043,"Reversible data hiding based on reducing invalid shifting of pixels in
  histogram shifting","  In recent years, reversible data hiding (RDH), a new research hotspot in the
field of information security, has been paid more and more attention by
researchers. Most of the existing RDH schemes do not fully take it into account
that natural image's texture has influence on embedding distortion. The image
distortion caused by embedding data in the image's smooth region is much
smaller than that in the unsmooth region, essentially, it is because embedding
additional data in the smooth region corresponds to fewer invalid shifting
pixels (ISPs) in histogram shifting. Thus, we propose a RDH scheme based on the
images texture to reduce invalid shifting of pixels in histogram shifting.
Specifically, first, a cover image is divided into two sub-images by the
checkerboard pattern, and then each sub-image's fluctuation values are
calculated. Finally, additional data can be embedded into the region of
sub-images with smaller fluctuation value preferentially. The experimental
results demonstrate that the proposed method has higher capacity and better
stego-image quality than some existing RDH schemes.
"
2044,"Expression Conditional GAN for Facial Expression-to-Expression
  Translation","  In this paper, we focus on the facial expression translation task and propose
a novel Expression Conditional GAN (ECGAN) which can learn the mapping from one
image domain to another one based on an additional expression attribute. The
proposed ECGAN is a generic framework and is applicable to different expression
generation tasks where specific facial expression can be easily controlled by
the conditional attribute label. Besides, we introduce a novel face mask loss
to reduce the influence of background changing. Moreover, we propose an entire
framework for facial expression generation and recognition in the wild, which
consists of two modules, i.e., generation and recognition. Finally, we evaluate
our framework on several public face datasets in which the subjects have
different races, illumination, occlusion, pose, color, content and background
conditions. Even though these datasets are very diverse, both the qualitative
and quantitative results demonstrate that our approach is able to generate
facial expressions accurately and robustly.
"
2045,"High Capacity Lossless Data Hiding in JPEG Bitstream Based on General
  VLC Mapping","  JPEG is the most popular image format, which is widely used in our daily
life. Therefore, reversible data hiding (RDH) for JPEG images is important.
Most of the RDH schemes for JPEG images will cause significant distortions and
large file size increments in the marked JPEG image. As a special case of RDH,
the lossless data hiding (LDH) technique can keep the visual quality of the
marked images no degradation. In this paper, a novel high capacity LDH scheme
is proposed. In the JPEG bitstream, not all the variable length codes (VLC) are
used to encode image data. By constructing the mapping between the used and
unused VLCs, the secret data can be embedded by replacing the used VLC with the
unused VLC. Different from the previous schemes, our mapping strategy allows
the lengths of unused and used VLCs in a mapping set to be unequal. We present
some basic insights into the construction of the mapping relationship.
Experimental results show that most of the JPEG images using the proposed
scheme obtain smaller file size increments than previous RDH schemes.
Furthermore, the proposed scheme can obtain high embedding capacity while
keeping the marked JPEG image with no distortion.
"
2046,"SmartBullets: A Cloud-Assisted Bullet Screen Filter based on Deep
  Learning","  Bullet-screen is a technique that enables the website users to send real-time
comment `bullet' cross the screen. Compared with the traditional review of a
video, bullet-screen provides new features of feeling expression to video
watching and more iterations between video viewers. However, since all the
comments from the viewers are shown on the screen publicly and simultaneously,
some low-quality bullets will reduce the watching enjoyment of the users.
Although the bullet-screen video websites have provided filter functions based
on regular expression, bad bullets can still easily pass the filter through
making a small modification.
  In this paper, we present SmartBullets, a user-centered bullet-screen filter
based on deep learning techniques. A convolutional neural network is trained as
the classifier to determine whether a bullet need to be removed according to
its quality. Moreover, to increase the scalability of the filter, we employ a
cloud-assisted framework by developing a backend cloud server and a front-end
browser extension. The evaluation of 40 volunteers shows that SmartBullets can
effectively remove the low-quality bullets and improve the overall watching
experience of viewers.
"
2047,"Statistical Learning Based Congestion Control for Real-time Video
  Communication","  With the increasing demands on interactive video applications, how to adapt
video bit rate to avoid network congestion has become critical, since
congestion results in self-inflicted delay and packet loss which deteriorate
the quality of real-time video service. The existing congestion control is hard
to simultaneously achieve low latency, high throughput, good adaptability and
fair bandwidth allocation, mainly because of the hardwired control strategy and
egocentric convergence objective. To address these issues, we propose an
end-to-end statistical learning based congestion control, named Iris. By
exploring the underlying principles of self-inflicted delay, we reveal that
congestion delay is determined by sending rate, receiving rate and network
status, which inspires us to control video bit rate using a
statistical-learning congestion control model. The key idea of Iris is to force
all flows to converge to the same queue load, and adjust the bit rate by the
model. All flows keep a small and fixed number of packets queuing in the
network, thus the fair bandwidth allocation and low latency are both achieved.
Besides, the adjustment step size of sending rate is updated by online
learning, to better adapt to dynamically changing networks. We carried out
extensive experiments to evaluate the performance of Iris, with the
implementations of transport layer (UDP) and application layer (QUIC)
respectively. The testing environment includes emulated network, real-world
Internet and commercial LTE networks. Compared against TCP flavors and
state-of-the-art protocols, Iris is able to achieve high bandwidth utilization,
low latency and good fairness concurrently. Especially over QUIC, Iris is able
to increase the video bitrate up to 25%, and PSNR up to 1dB.
"
2048,Learning to Groove with Inverse Sequence Transformations,"  We explore models for translating abstract musical ideas (scores, rhythms)
into expressive performances using Seq2Seq and recurrent Variational
Information Bottleneck (VIB) models. Though Seq2Seq models usually require
painstakingly aligned corpora, we show that it is possible to adapt an approach
from the Generative Adversarial Network (GAN) literature (e.g. Pix2Pix (Isola
et al., 2017) and Vid2Vid (Wang et al. 2018a)) to sequences, creating large
volumes of paired data by performing simple transformations and training
generative models to plausibly invert these transformations. Music, and
drumming in particular, provides a strong test case for this approach because
many common transformations (quantization, removing voices) have clear
semantics, and models for learning to invert them have real-world applications.
Focusing on the case of drum set players, we create and release a new dataset
for this purpose, containing over 13 hours of recordings by professional
drummers aligned with fine-grained timing and dynamics information. We also
explore some of the creative potential of these models, including demonstrating
improvements on state-of-the-art methods for Humanization (instantiating a
performance from a musical score).
"
2049,"Food Recommendation: Framework, Existing Solutions and Challenges","  A growing proportion of the global population is becoming overweight or
obese, leading to various diseases (e.g., diabetes, ischemic heart disease and
even cancer) due to unhealthy eating patterns, such as increased intake of food
with high energy and high fat. Food recommendation is of paramount importance
to alleviate this problem. Unfortunately, modern multimedia research has
enhanced the performance and experience of multimedia recommendation in many
fields such as movies and POI, yet largely lags in the food domain. This
article proposes a unified framework for food recommendation, and identifies
main issues affecting food recommendation including building the personal
model, analyzing unique food characteristics, incorporating various context and
domain knowledge. We then review existing solutions for these issues, and
finally elaborate research challenges and future directions in this field. To
our knowledge, this is the first survey that targets the study of food
recommendation in the multimedia field and offers a collection of research
studies and technologies to benefit researchers in this field.
"
2050,"EVSO: Environment-aware Video Streaming Optimization of Power
  Consumption","  Streaming services gradually support high-quality videos for better user
experience. However, streaming high-quality video on mobile devices consumes a
considerable amount of energy. This paper presents the design and prototype of
EVSO, which achieves power saving by applying adaptive frame rates to parts of
videos with a little degradation of the user experience. EVSO utilizes a novel
perceptual similarity measurement method based on human visual perception
specialized for a video encoder. We also extend the media presentation
description, in which the video content is selected based only on the network
bandwidth, to allow for additional consideration of the user's battery status.
EVSO's streaming server preprocesses the video into several processed videos
according to the similarity intensity of each part of the video and then
provides the client with the processed video suitable for the network bandwidth
and the battery status of the client's mobile device. The EVSO system was
implemented on the commonly used H.264/AVC encoder. We conduct various
experiments and a user study with nine videos. Our experimental results show
that EVSO effectively reduces energy consumption when mobile devices use
streaming services by 22% on average and up to 27% while maintaining the
quality of the user experience.
"
2051,Reactive Video Caching via long-short-term fusion approach,"  Video caching has been a basic network functionality in today's network
architectures. Although the abundance of caching replacement algorithms has
been proposed recently, these methods all suffer from a key limitation: due to
their immature rules, inaccurate feature engineering or unresponsive model
update, they cannot strike a balance between the long-term history and
short-term sudden events. To address this concern, we propose LA-E2, a
long-short-term fusion caching replacement approach, which is based on a
learning-aided exploration-exploitation process. Specifically, by effectively
combining the deep neural network (DNN) based prediction with the online
exploitation-exploration process through a \emph{top-k} method, LA-E2 can both
make use of the historical information and adapt to the constantly changing
popularity responsively. Through the extensive experiments in two real-world
datasets, we show that LA-E2 can achieve state-of-the-art performance and
generalize well. Especially when the cache size is small, our approach can
outperform the baselines by 17.5\%-68.7\% higher in total hit rate.
"
2052,Evaluation of 4D Light Field Compression Methods,"  Light field data records the amount of light at multiple points in space,
captured e.g. by an array of cameras or by a light-field camera that uses
microlenses. Since the storage and transmission requirements for such data are
tremendous, compression techniques for light fields are gaining momentum in
recent years. Although plenty of efficient compression formats do exist for
still and moving images, only a little research on the impact of these methods
on light field imagery is performed. In this paper, we evaluate the impact of
state-of-the-art image and video compression methods on quality of images
rendered from light field data. The methods include recent video compression
standards, especially AV1 and XVC finalised in 2018. To fully exploit the
potential of common image compression methods on four-dimensional light field
imagery, we have extended these methods into three and four dimensions. In this
paper, we show that the four-dimensional light field data can be compressed
much more than independent still images while maintaining the same visual
quality of a perceived picture. We gradually compare the compression
performance of all image and video compression methods, and eventually answer
the question, ""What is the best compression method for light field data?"".
"
2053,"Economical Caching for Scalable Videos in Cache-enabled Heterogeneous
  Networks","  We develop the optimal economical caching schemes in cache-enabled
heterogeneous networks, while delivering multimedia video services with
personalized viewing qualities to mobile users. By applying scalable video
coding (SVC), each video file to be requested is divided into one base layer
(BL) and several enhancement layers (ELs). In order to assign different
transmission tasks, the serving small-cell base stations (SBSs) are grouped
into K clusters. The SBSs are able to cache and cooperatively transmit BL and
EL contents to the user. We analytically derive the expressions for successful
transmission probability and ergodic service rate, and then the closed form of
EConomical Efficiency (ECE) is obtained. In order to enhance the ECE
performance, we formulate the ECE optimization problems for two cases. In the
first case, with equal cache size equipped at each SBS, the layer caching
indicator is determined. Since this problem is NP-hard, after the l0-norm
approximation, the discrete optimization variables are relaxed to be
continuous, and this relaxed problem is convex. Next, based on the optimal
solution derived from the relaxed problem, we devise a greedystrategy based
heuristic algorithm to achieve the near-optimal layer caching indicators. In
the second case, the cache size for each SBS, the layer size and the layer
caching indicator are jointly optimized. This problem is a mixed integer
programming problem, which is more challenging. To effectively solve this
problem, the original ECE maximization problem is divided into two subproblems.
These two subproblems are iteratively solved until the original optimization
problem is convergent. Numerical results verify the correctness of theoretical
derivations. Additionally, compared to the most popular layer placement
strategy, the performance superiority of the proposed SVC-based caching schemes
is testified.
"
2054,Multiple reconstruction compression framework based on PNG image,"  It is shown that neural networks (NNs) achieve excellent performances in
image compression and reconstruction. However, there are still many
shortcomings in the practical application, which eventually lead to the loss of
neural network image processing ability. Based on this, this paper proposes a
joint framework based on neural network and zoom compression. The framework
first encodes the incoming PNG or JPEG image information, and then the image is
converted into binary input decoder to reconstruct the intermediate state
image, next we import the intermediate state image into the zooming compressor
and re-pressurize it, and reconstruct the final image. From the experimental
results, this method can better process the digital image and suppress the
reverse expansion problem, and the compression effect can be improved by 4 to
10 times as much as that of using RNN alone, showing better ability in
application. In this paper, the method is transmitted over a digital image, the
effect is far better than the existing compression method alone, the Human
visual system can not feel the change of the effect.
"
2055,"An Improved Reversible Data Hiding in Encrypted Images using Parametric
  Binary Tree Labeling","  This work proposes an improved reversible data hiding scheme in encrypted
images using parametric binary tree labeling(IPBTL-RDHEI), which takes
advantage of the spatial correlation in the entire original image but not in
small image blocks to reserve room for hiding data. Then the original image is
encrypted with an encryption key and the parametric binary tree is used to
label encrypted pixels into two different categories. Finally, one of the two
categories of encrypted pixels can embed secret information by bit replacement.
According to the experimental results, compared with several state-of-the-art
methods, the proposed IPBTL-RDHEI method achieves higher embedding rate and
outperforms the competitors. Due to the reversibility of IPBTL-RDHEI, the
original plaintext image and the secret information can be restored and
extracted losslessly and separately.
"
2056,Speech2Face: Learning the Face Behind a Voice,"  How much can we infer about a person's looks from the way they speak? In this
paper, we study the task of reconstructing a facial image of a person from a
short audio recording of that person speaking. We design and train a deep
neural network to perform this task using millions of natural Internet/YouTube
videos of people speaking. During training, our model learns voice-face
correlations that allow it to produce images that capture various physical
attributes of the speakers such as age, gender and ethnicity. This is done in a
self-supervised manner, by utilizing the natural co-occurrence of faces and
speech in Internet videos, without the need to model attributes explicitly. We
evaluate and numerically quantify how--and in what manner--our Speech2Face
reconstructions, obtained directly from audio, resemble the true face images of
the speakers.
"
2057,"Saliency detection based on structural dissimilarity induced by image
  quality assessment model","  The distinctiveness of image regions is widely used as the cue of saliency.
Generally, the distinctiveness is computed according to the absolute difference
of features. However, according to the image quality assessment (IQA) studies,
the human visual system is highly sensitive to structural changes rather than
absolute difference. Accordingly, we propose the computation of the structural
dissimilarity between image patches as the distinctiveness measure for saliency
detection. Similar to IQA models, the structural dissimilarity is computed
based on the correlation of the structural features. The global structural
dissimilarity of a patch to all the other patches represents saliency of the
patch. We adopt two widely used structural features, namely the local contrast
and gradient magnitude, into the structural dissimilarity computation in the
proposed model. Without any postprocessing, the proposed model based on the
correlation of either of the two structural features outperforms 11
state-of-the-art saliency models on three saliency databases.
"
2058,Temporal Attentive Alignment for Video Domain Adaptation,"  Although various image-based domain adaptation (DA) techniques have been
proposed in recent years, domain shift in videos is still not well-explored.
Most previous works only evaluate performance on small-scale datasets which are
saturated. Therefore, we first propose a larger-scale dataset with larger
domain discrepancy: UCF-HMDB_full. Second, we investigate different DA
integration methods for videos, and show that simultaneously aligning and
learning temporal dynamics achieves effective alignment even without
sophisticated DA methods. Finally, we propose Temporal Attentive Adversarial
Adaptation Network (TA3N), which explicitly attends to the temporal dynamics
using domain discrepancy for more effective domain alignment, achieving
state-of-the-art performance on three video DA datasets. The code and data are
released at http://github.com/cmhungsteve/TA3N.
"
2059,Bridging Dialogue Generation and Facial Expression Synthesis,"  Spoken dialogue systems that assist users to solve complex tasks such as
movie ticket booking have become an emerging research topic in artificial
intelligence and natural language processing areas. With a well-designed
dialogue system as an intelligent personal assistant, people can accomplish
certain tasks more easily via natural language interactions. Today there are
several virtual intelligent assistants in the market; however, most systems
only focus on single modality, such as textual or vocal interaction. A
multimodal interface has various advantages: (1) allowing human to communicate
with machines in a natural and concise form using the mixture of modalities
that most precisely convey the intention to satisfy communication needs, and
(2) providing more engaging experience by natural and human-like feedback. This
paper explores a brand new research direction, which aims at bridging dialogue
generation and facial expression synthesis for better multimodal interaction.
The goal is to generate dialogue responses and simultaneously synthesize
corresponding visual expressions on faces, which is also an ultimate step
toward more human-like virtual assistants.
"
2060,EncryptGAN: Image Steganography with Domain Transform,"  We propose an image steganographic algorithm called EncryptGAN, which
disguises private image communication in an open communication channel. The
insight is that content transform between two very different domains (e.g.,
face to flower) allows one to hide image messages in one domain (face) and
communicate using its counterpart in another domain (flower). The key
ingredient in our method, unlike related approaches, is a specially trained
network to extract transformed images from both domains and use them as the
public and private keys. We ensure the image communication remain secret except
for the intended recipient even when the content transformation networks are
exposed.
  To communicate, one directly pastes the `message' image onto a larger public
key image (face). Depending on the location and content of the message image,
the `disguise' image (flower) alters its appearance and shape while maintaining
its overall objectiveness (flower). The recipient decodes the alternated image
to uncover the original image message using its message image key. We implement
the entire procedure as a constrained Cycle-GAN, where the public and the
private key generating network is used as an additional constraint to the cycle
consistency. Comprehensive experimental results show our EncryptGAN outperforms
the state-of-arts in terms of both encryption and security measures.
"
2061,"Optimizing Adaptive Video Streaming in Mobile Networks via Online
  Learning","  In this paper, we propose a novel algorithm for video rate adaptation in HTTP
Adaptive Streaming (HAS), based on online learning. The proposed algorithm,
named Learn2Adapt (L2A), is shown to provide a robust rate adaptation strategy
which, unlike most of the state-of-the-art techniques, does not require
parameter tuning, channel model assumptions or application-specific
adjustments. These properties make it very suitable for mobile users, who
typically experience fast variations in channel characteristics. Simulations
show that L2A improves on the overall Quality of Experience (QoE) and in
particular the average streaming rate, a result obtained independently of the
channel and application scenarios.
"
2062,"Automatic Realistic Music Video Generation from Segments of Youtube
  Videos","  A Music Video (MV) is a video aiming at visually illustrating or extending
the meaning of its background music. This paper proposes a novel method to
automatically generate, from an input music track, a music video made of
segments of Youtube music videos which would fit this music. The system
analyzes the input music to find its genre (pop, rock, ...) and finds segmented
MVs with the same genre in the database. Then, a K-Means clustering is done to
group video segments by color histogram, meaning segments of MVs having the
same global distribution of colors. A few clusters are randomly selected, then
are assembled around music boundaries, which are moments where a significant
change in the music occurs (for instance, transitioning from verse to chorus).
This way, when the music changes, the video color mood changes as well. This
work aims at generating high-quality realistic MVs, which could be mistaken for
man-made MVs. By asking users to identify, in a batch of music videos
containing professional MVs, amateur-made MVs and generated MVs by our
algorithm, we show that our algorithm gives satisfying results, as 45% of
generated videos are mistaken for professional MVs and 21.6% are mistaken for
amateur-made MVs. More information can be found in the project website:
http://ml.cs.tsinghua.edu.cn/~sarah/
"
2063,"Towards robust audio spoofing detection: a detailed comparison of
  traditional and learned features","  Automatic speaker verification, like every other biometric system, is
vulnerable to spoofing attacks. Using only a few minutes of recorded voice of a
genuine client of a speaker verification system, attackers can develop a
variety of spoofing attacks that might trick such systems. Detecting these
attacks using the audio cues present in the recordings is an important
challenge. Most existing spoofing detection systems depend on knowing the used
spoofing technique. With this research, we aim at overcoming this limitation,
by examining robust audio features, both traditional and those learned through
an autoencoder, that are generalizable over different types of replay spoofing.
Furthermore, we provide a detailed account of all the steps necessary in
setting up state-of-the-art audio feature detection, pre-, and postprocessing,
such that the (non-audio expert) machine learning researcher can implement such
systems. Finally, we evaluate the performance of our robust replay speaker
detection system with a wide variety and different combinations of both
extracted and machine learned audio features on the `out in the wild' ASVspoof
2017 dataset. This dataset contains a variety of new spoofing configurations.
Since our focus is on examining which features will ensure robustness, we base
our system on a traditional Gaussian Mixture Model-Universal Background Model.
We then systematically investigate the relative contribution of each feature
set. The fused models, based on both the known audio features and the machine
learned features respectively, have a comparable performance with an Equal
Error Rate (EER) of 12. The final best performing model, which obtains an EER
of 10.8, is a hybrid model that contains both known and machine learned
features, thus revealing the importance of incorporating both types of features
when developing a robust spoofing prediction model.
"
2064,TS-RNN: Text Steganalysis Based on Recurrent Neural Networks,"  With the rapid development of natural language processing technologies, more
and more text steganographic methods based on automatic text generation
technology have appeared in recent years. These models use the powerful
self-learning and feature extraction ability of the neural networks to learn
the feature expression of massive normal texts. Then they can automatically
generate dense steganographic texts which conform to such statistical
distribution based on the learned statistical patterns. In this paper, we
observe that the conditional probability distribution of each word in the
automatically generated steganographic texts will be distorted after embedded
with hidden information. We use Recurrent Neural Networks (RNNs) to extract
these feature distribution differences and then classify those features into
cover text and stego text categories. Experimental results show that the
proposed model can achieve high detection accuracy. Besides, the proposed model
can even make use of the subtle differences of the feature distribution of
texts to estimate the amount of hidden information embedded in the generated
steganographic text.
"
2065,"Technical Report of the Video Event Reconstruction and Analysis (VERA)
  System -- Shooter Localization, Models, Interface, and Beyond","  Every minute, hundreds of hours of video are uploaded to social media sites
and the Internet from around the world. This material creates a visual record
of the experiences of a significant percentage of humanity and can help
illuminate how we live in the present moment. When properly analyzed, this
video can also help analysts to reconstruct events of interest, including war
crimes, human rights violations, and terrorist acts. Machine learning and
computer vision can play a crucial role in this process. In this technical
report, we describe the Video Event Reconstruction and Analysis (VERA) system.
This new tool brings together a variety of capabilities we have developed over
the past few years (including video synchronization and geolocation to order
unstructured videos lacking metadata over time and space, and sound recognition
algorithms) to enable the reconstruction and analysis of events captured on
video. Among other uses, VERA enables the localization of a shooter from just a
few videos that include the sound of gunshots. To demonstrate the efficacy of
this suite of tools, we present the results of estimating the shooter's
location of the Las Vegas Shooting in 2017 and show that VERA accurately
predicts the shooter's location using only the first few gunshots. We then
point out future directions that can help improve the system and further reduce
unnecessary human labor in the process. All of the components of VERA run
through a web interface that enables human-in-the-loop verification to ensure
accurate estimations. All relevant source code, including the web interface and
machine learning models, is freely available on Github. We hope that
researchers and software developers will be inspired to improve and expand this
system moving forward to better meet the needs of human rights and public
safety.
"
2066,Supervised Online Hashing via Similarity Distribution Learning,"  Online hashing has attracted extensive research attention when facing
streaming data. Most online hashing methods, learning binary codes based on
pairwise similarities of training instances, fail to capture the semantic
relationship, and suffer from a poor generalization in large-scale applications
due to large variations. In this paper, we propose to model the similarity
distributions between the input data and the hashing codes, upon which a novel
supervised online hashing method, dubbed as Similarity Distribution based
Online Hashing (SDOH), is proposed, to keep the intrinsic semantic relationship
in the produced Hamming space. Specifically, we first transform the discrete
similarity matrix into a probability matrix via a Gaussian-based normalization
to address the extremely imbalanced distribution issue. And then, we introduce
a scaling Student t-distribution to solve the challenging initialization
problem, and efficiently bridge the gap between the known and unknown
distributions. Lastly, we align the two distributions via minimizing the
Kullback-Leibler divergence (KL-diverence) with stochastic gradient descent
(SGD), by which an intuitive similarity constraint is imposed to update hashing
model on the new streaming data with a powerful generalizing ability to the
past data. Extensive experiments on three widely-used benchmarks validate the
superiority of the proposed SDOH over the state-of-the-art methods in the
online retrieval task.
"
2067,"CNN-based Steganalysis and Parametric Adversarial Embedding: a
  Game-Theoretic Framework","  CNN-based steganalysis has recently achieved very good performance in
detecting content-adaptive steganography. At the same time, recent works have
shown that, by adopting an approach similar to that used to build adversarial
examples, a steganographer can adopt an adversarial embedding strategy to
effectively counter a target CNN steganalyzer. In turn, the good performance of
the steganalyzer can be restored by retraining the CNN with adversarial stego
images. A problem with this model is that, arguably, at training time the
steganalizer is not aware of the exact parameters used by the steganograher for
adversarial embedding and, vice versa, the steganographer does not know how the
images that will be used to train the steganalyzer are generated. In order to
exit this apparent deadlock, we introduce a game theoretic framework wherein
the problem of setting the parameters of the steganalyzer and the
steganographer is solved in a strategic way. More specifically, a non-zero sum
game is first formulated to model the problem, and then instantiated by
considering a specific adversarial embedding scheme setting its operating
parameters in a game-theoretic fashion. Our analysis shows that the equilibrium
solution of the non zero-sum game can be conveniently found by solving an
associated zero-sum game, thus reducing greatly the complexity of the problem.
Then we run several experiments to derive the optimum strategies for the
steganographer and the staganalyst in a game-theoretic sense, and to evaluate
the performance of the game at the equilibrium, characterizing the loss with
respect to the conventional non-adversarial case. Eventually, by leveraging on
the analysis of the equilibrium point of the game, we introduce a new strategy
to improve the reliability of the steganalysis, which shows the benefits of
addressing the security issue in a game-theoretic perspective.
"
2068,Effects of Packet Loss and Jitter on VoLTE Call Quality,"  This work performs a preliminary, comparative analysis of the end-to-end
quality guaranteed by Voice over LTE (VoLTE), examining several millions of
VoLTE calls that employ two popular speech audio codecs, namely, Adaptive
Multi-Rate (AMR) and Adaptive Multi-Rate WideBand (AMR-WB). To assess call
quality, VQmon, an enhanced version of the standardized E-Model, is utilized.
The study reveals to what extent AMR-WB based calls are more robust against
network impairments than their narrowband counterparts; it further shows that
the dependence of call quality on the packet loss rate is approximately
exponential when the AMR codec is used, whereas it is nearly linear for the
AMR-WB codec.
"
2069,"Cross-Modal Interaction Networks for Query-Based Moment Retrieval in
  Videos","  Query-based moment retrieval aims to localize the most relevant moment in an
untrimmed video according to the given natural language query. Existing works
often only focus on one aspect of this emerging task, such as the query
representation learning, video context modeling or multi-modal fusion, thus
fail to develop a comprehensive system for further performance improvement. In
this paper, we introduce a novel Cross-Modal Interaction Network (CMIN) to
consider multiple crucial factors for this challenging task, including (1) the
syntactic structure of natural language queries; (2) long-range semantic
dependencies in video context and (3) the sufficient cross-modal interaction.
Specifically, we devise a syntactic GCN to leverage the syntactic structure of
queries for fine-grained representation learning, propose a multi-head
self-attention to capture long-range semantic dependencies from video context,
and next employ a multi-stage cross-modal interaction to explore the potential
relations of video and query contents. The extensive experiments demonstrate
the effectiveness of our proposed method.
"
2070,"Grounding Natural Language Commands to StarCraft II Game States for
  Narration-Guided Reinforcement Learning","  While deep reinforcement learning techniques have led to agents that are
successfully able to learn to perform a number of tasks that had been
previously unlearnable, these techniques are still susceptible to the
longstanding problem of {\em reward sparsity}. This is especially true for
tasks such as training an agent to play StarCraft II, a real-time strategy game
where reward is only given at the end of a game which is usually very long.
While this problem can be addressed through reward shaping, such approaches
typically require a human expert with specialized knowledge. Inspired by the
vision of enabling reward shaping through the more-accessible paradigm of
natural-language narration, we investigate to what extent we can contextualize
these narrations by grounding them to the goal-specific states. We present a
mutual-embedding model using a multi-input deep-neural network that projects a
sequence of natural language commands into the same high-dimensional
representation space as corresponding goal states. We show that using this
model we can learn an embedding space with separable and distinct clusters that
accurately maps natural-language commands to corresponding game states . We
also discuss how this model can allow for the use of narrations as a robust
form of reward shaping to improve RL performance and efficiency.
"
2071,Image Encryption Algorithm Based on Facebook Social Network,"  Facebook is the online social networks (OSNs) platform with the largest
number of users in the world today, information protection based on Facebook
social network platform have important practical significance. Since the
information users share on social networks is often based on images, this paper
proposes a more secure image encryption algorithm based on Facebook social
network platform to ensure the loss of information as much as possible. When
the sender encrypts the image for uploading, it can first resist the third
party's attack on the encrypted image and prevent the image data from leaking,
simultaneously processed by some unknown processing such as compression and
filtering of the image on the Facebook platform, the receiver can still decrypt
the corresponding image data.
"
2072,"Parametric context adaptive Laplace distribution for multimedia
  compression","  Data compression often subtracts prediction and encodes the difference
(residue) e.g. assuming Laplace distribution, for example for images, videos,
audio, or numerical data. Its performance is strongly dependent on the proper
choice of width (scale parameter) of this parametric distribution, can be
improved if optimizing it based on local situation like context. For example in
popular LOCO-I \cite{loco} (JPEG-LS) lossless image compressor there is used 3
dimensional context quantized into 365 discrete possibilities treated
independently. This article discusses inexpensive approaches for exploiting
their dependencies with autoregressive ARCH-like context dependent models for
parameters of parametric distribution for residue, also evolving in time for
adaptive case. For example tested such 4 or 11 parameter models turned out to
provide similar performance as 365 parameter LOCO-I model for 48 tested images.
Beside smaller headers, such reduction of number of parameters can lead to
better generalization. In contrast to context quantization approaches,
parameterized models also allow to directly use higher dimensional contexts,
for example using information from all 3 color channels, further pixels, some
additional region classifiers, or from interleaving multi-scale scanning - for
which there is proposed Haar upscale scan combining advantages of Haar wavelets
with possibility of scanning exploiting local contexts.
"
2073,"Frequency-Dependent Perceptual Quantisation for Visually Lossless
  Compression Applications","  The default quantisation algorithms in the state-of-the-art High Efficiency
Video Coding (HEVC) standard, namely Uniform Reconstruction Quantisation (URQ)
and Rate-Distortion Optimised Quantisation (RDOQ), do not take into account the
perceptual relevance of individual transform coefficients. In this paper, a
Frequency-Dependent Perceptual Quantisation (FDPQ) technique for HEVC is
proposed. FDPQ exploits the well-established Modulation Transfer Function (MTF)
characteristics of the linear transformation basis functions by taking into
account the Euclidean distance of an AC transform coefficient from the DC
coefficient. As such, in luma and chroma Cb and Cr Transform Blocks (TBs), FDPQ
quantises more coarsely the least perceptually relevant transform coefficients
(i.e., the high frequency AC coefficients). Conversely, FDPQ preserves the
integrity of the DC coefficient and the very low frequency AC coefficients.
Compared with RDOQ, which is the most widely used transform coefficient-level
quantisation technique in video coding, FDPQ successfully achieves bitrate
reductions of up to 41%. Furthermore, the subjective evaluations confirm that
the FDPQ-coded video data is perceptually indistinguishable (i.e., visually
lossless) from the raw video data for a given Quantisation Parameter (QP).
"
2074,Predicting TED Talk Ratings from Language and Prosody,"  We use the largest open repository of public speaking---TED Talks---to
predict the ratings of the online viewers. Our dataset contains over 2200 TED
Talk transcripts (includes over 200 thousand sentences), audio features and the
associated meta information including about 5.5 Million ratings from
spontaneous visitors of the website. We propose three neural network
architectures and compare with statistical machine learning. Our experiments
reveal that it is possible to predict all the 14 different ratings with an
average AUC of 0.83 using the transcripts and prosody features only. The
dataset and the complete source code is available for further analysis.
"
2075,"Stereoscopic Omnidirectional Image Quality Assessment Based on
  Predictive Coding Theory","  Objective quality assessment of stereoscopic omnidirectional images is a
challenging problem since it is influenced by multiple aspects such as
projection deformation, field of view (FoV) range, binocular vision, visual
comfort, etc. Existing studies show that classic 2D or 3D image quality
assessment (IQA) metrics are not able to perform well for stereoscopic
omnidirectional images. However, very few research works have focused on
evaluating the perceptual visual quality of omnidirectional images, especially
for stereoscopic omnidirectional images. In this paper, based on the predictive
coding theory of the human vision system (HVS), we propose a stereoscopic
omnidirectional image quality evaluator (SOIQE) to cope with the
characteristics of 3D 360-degree images. Two modules are involved in SOIQE:
predictive coding theory based binocular rivalry module and multi-view fusion
module. In the binocular rivalry module, we introduce predictive coding theory
to simulate the competition between high-level patterns and calculate the
similarity and rivalry dominance to obtain the quality scores of viewport
images. Moreover, we develop the multi-view fusion module to aggregate the
quality scores of viewport images with the help of both content weight and
location weight. The proposed SOIQE is a parametric model without necessary of
regression learning, which ensures its interpretability and generalization
performance. Experimental results on our published stereoscopic omnidirectional
image quality assessment database (SOLID) demonstrate that our proposed SOIQE
method outperforms state-of-the-art metrics. Furthermore, we also verify the
effectiveness of each proposed module on both public stereoscopic image
datasets and panoramic image datasets.
"
2076,Differential Imaging Forensics,"  We introduce some new forensics based on differential imaging, where a novel
category of visual evidence created via subtle interactions of light with a
scene, such as dim reflections, can be computationally extracted and amplified
from an image of interest through a comparative analysis with an additional
reference baseline image acquired under similar conditions. This paradigm of
differential imaging forensics (DIF) enables forensic examiners for the first
time to retrieve the said visual evidence that is readily available in an image
or video footage but would otherwise remain faint or even invisible to a human
observer. We demonstrate the relevance and effectiveness of our approach
through practical experiments. We also show that DIF provides a novel method
for detecting forged images and video clips, including deep fakes.
"
2077,Eye Contact Correction using Deep Neural Networks,"  In a typical video conferencing setup, it is hard to maintain eye contact
during a call since it requires looking into the camera rather than the
display. We propose an eye contact correction model that restores the eye
contact regardless of the relative position of the camera and display. Unlike
previous solutions, our model redirects the gaze from an arbitrary direction to
the center without requiring a redirection angle or camera/display/user
geometry as inputs. We use a deep convolutional neural network that inputs a
monocular image and produces a vector field and a brightness map to correct the
gaze. We train this model in a bi-directional way on a large set of
synthetically generated photorealistic images with perfect labels. The learned
model is a robust eye contact corrector which also predicts the input gaze
implicitly at no additional cost. Our system is primarily designed to improve
the quality of video conferencing experience. Therefore, we use a set of
control mechanisms to prevent creepy results and to ensure a smooth and natural
video conferencing experience. The entire eye contact correction system runs
end-to-end in real-time on a commodity CPU and does not require any dedicated
hardware, making our solution feasible for a variety of devices.
"
2078,A Security Case Study for Blockchain Games,"  Blockchain gaming is an emerging entertainment paradigm. However, blockchain
games are still suffering from security issues, due to the immature blockchain
technologies and its unsophisticated developers. In this work, we analyzed the
blockchain game architecture and reveal the possible penetration methods of
cracking. We scanned more than 600 commercial blockchain games to summarize a
security overview from the perspective of the web server and smart contract,
respectively. We also conducted three case studies for blockchain games to show
detailed vulnerability detection.
"
2079,Blockchain Games: A Survey,"  With the support of the blockchain systems, the cryptocurrency has changed
the world of virtual assets. Digital games, especially those with massive
multi-player scenarios, will be significantly impacted by this novel
technology. However, there are insufficient academic studies on this topic. In
this work, we filled the blank by surveying the state-of-the-art blockchain
games. We discuss the blockchain integration for games and then categorize
existing blockchain games from the aspects of their genres and technical
platforms. Moreover, by analyzing the industrial trend with a statistical
approach, we envision the future of blockchain games from technological and
commercial perspectives.
"
2080,Deep Learning Development Environment in Virtual Reality,"  Virtual reality (VR) offers immersive visualization and intuitive
interaction. We leverage VR to enable any biomedical professional to deploy a
deep learning (DL) model for image classification. While DL models can be
powerful tools for data analysis, they are also challenging to understand and
develop. To make deep learning more accessible and intuitive, we have built a
virtual reality-based DL development environment. Within our environment, the
user can move tangible objects to construct a neural network only using their
hands. Our software automatically translates these configurations into a
trainable model and then reports its resulting accuracy on a test dataset in
real-time. Furthermore, we have enriched the virtual objects with
visualizations of the model's components such that users can achieve insight
about the DL models that they are developing. With this approach, we bridge the
gap between professionals in different fields of expertise while offering a
novel perspective for model analysis and data interaction. We further suggest
that techniques of development and visualization in deep learning can benefit
by integrating virtual reality.
"
2081,Grounding Object Detections With Transcriptions,"  A vast amount of audio-visual data is available on the Internet thanks to
video streaming services, to which users upload their content. However, there
are difficulties in exploiting available data for supervised statistical models
due to the lack of labels. Unfortunately, generating labels for such amount of
data through human annotation can be expensive, time-consuming and prone to
annotation errors. In this paper, we propose a method to automatically extract
entity-video frame pairs from a collection of instruction videos by using
speech transcriptions and videos. We conduct experiments on image recognition
and visual grounding tasks on the automatically constructed entity-video frame
dataset of How2. The models will be evaluated on new manually annotated portion
of How2 dev5 and val set and on the Flickr30k dataset. This work constitutes a
first step towards meta-algorithms capable of automatically construct
task-specific training sets.
"
2082,A Holistic Survey of Wireless Multipath Video Streaming,"  Most of today's mobile devices are equipped with multiple network interfaces
and one of the main bandwidth-hungry applications that would benefit from
multipath communications is wireless video streaming. However, most of current
transport protocols do not match the requirements of video streaming
applications or are not designed to address relevant issues, such as delay
constraints, networks heterogeneity, and head-of-line blocking issues. This
article provides a holistic survey of multipath wireless video streaming,
shedding light on the different alternatives from an end-to-end layered stack
perspective, unveiling trade-offs of each approach and presenting a suitable
taxonomy to classify the state-of-the-art. Finally, we discuss open issues and
avenues for future work.
"
2083,Relevance Feedback with Latent Variables in Riemann spaces,"  In this paper we develop and evaluate two methods for relevance feedback
based on endowing a suitable ""semantic query space"" with a Riemann metric
derived from the probability distribution of the positive samples of the
feedback. The first method uses a Gaussian distribution to model the data,
while the second uses a more complex Latent Semantic variable model. A mixed
(discrete-continuous) version of the Expectation-Maximization algorithm is
developed for this model.
  We motivate the need for the semantic query space by analyzing in some depth
three well-known relevance feedback methods, and we develop a new experimental
methodology to evaluate these methods and compare their performance in a
neutral way, that is, without making assumptions on the system in which they
will be embedded.
"
2084,"ParNet: Position-aware Aggregated Relation Network for Image-Text
  matching","  Exploring fine-grained relationship between entities(e.g. objects in image or
words in sentence) has great contribution to understand multimedia content
precisely. Previous attention mechanism employed in image-text matching either
takes multiple self attention steps to gather correspondences or uses image
objects (or words) as context to infer image-text similarity. However, they
only take advantage of semantic information without considering that objects'
relative position also contributes to image understanding. To this end, we
introduce a novel position-aware relation module to model both the semantic and
spatial relationship simultaneously for image-text matching in this paper.
Given an image, our method utilizes the location of different objects to
capture spatial relationship innovatively. With the combination of semantic and
spatial relationship, it's easier to understand the content of different
modalities (images and sentences) and capture fine-grained latent
correspondences of image-text pairs. Besides, we employ a two-step aggregated
relation module to capture interpretable alignment of image-text pairs. The
first step, we call it intra-modal relation mechanism, in which we computes
responses between different objects in an image or different words in a
sentence separately; The second step, we call it inter-modal relation
mechanism, in which the query plays a role of textual context to refine the
relationship among object proposals in an image. In this way, our
position-aware aggregated relation network (ParNet) not only knows which
entities are relevant by attending on different objects (words) adaptively, but
also adjust the inter-modal correspondence according to the latent alignments
according to query's content. Our approach achieves the state-of-the-art
results on MS-COCO dataset.
"
2085,Multimodal Abstractive Summarization for How2 Videos,"  In this paper, we study abstractive summarization for open-domain videos.
Unlike the traditional text news summarization, the goal is less to ""compress""
text information but rather to provide a fluent textual summary of information
that has been collected and fused from different source modalities, in our case
video and audio transcripts (or text). We show how a multi-source
sequence-to-sequence model with hierarchical attention can integrate
information from different modalities into a coherent output, compare various
models trained with different modalities and present pilot experiments on the
How2 corpus of instructional videos. We also propose a new evaluation metric
(Content F1) for abstractive summarization task that measures semantic adequacy
rather than fluency of the summaries, which is covered by metrics like ROUGE
and BLEU.
"
2086,"A Monaural Speech Enhancement Method for Robust Small-Footprint Keyword
  Spotting","  Robustness against noise is critical for keyword spotting (KWS) in real-world
environments. To improve the robustness, a speech enhancement front-end is
involved. Instead of treating the speech enhancement as a separated
preprocessing before the KWS system, in this study, a pre-trained speech
enhancement front-end and a convolutional neural networks (CNNs) based KWS
system are concatenated, where a feature transformation block is used to
transform the output from the enhancement front-end into the KWS system's
input. The whole model is trained jointly, thus the linguistic and other useful
information from the KWS system can be back-propagated to the enhancement
front-end to improve its performance. To fit the small-footprint device, a
novel convolution recurrent network is proposed, which needs fewer parameters
and computation and does not degrade performance. Furthermore, by changing the
input features from the power spectrogram to Mel-spectrogram, less computation
and better performance are obtained. our experimental results demonstrate that
the proposed method significantly improves the KWS system with respect to noise
robustness.
"
2087,"Probabilistic Tile Visibility-Based Server-Side Rate Adaptation for
  Adaptive 360-Degree Video Streaming","  In this paper, we study the server-side rate adaptation problem for streaming
tile-based adaptive 360-degree videos to multiple users who are competing for
transmission resources at the network bottleneck. Specifically, we develop a
convolutional neural network (CNN)-based viewpoint prediction model to capture
the nonlinear relationship between the future and historical viewpoints. A
Laplace distribution model is utilized to characterize the probability
distribution of the prediction error. Given the predicted viewpoint, we then
map the viewport in the spherical space into its corresponding planar
projection in the 2-D plane, and further derive the visibility probability of
each tile based on the planar projection and the prediction error probability.
According to the visibility probability, tiles are classified as viewport,
marginal and invisible tiles. The server-side tile rate allocation problem for
multiple users is then formulated as a non-linear discrete optimization problem
to minimize the overall received video distortion of all users and the quality
difference between the viewport and marginal tiles of each user, subject to the
transmission capacity constraints and users' specific viewport requirements. We
develop a steepest descent algorithm to solve this non-linear discrete
optimization problem, by initializing the feasible starting point in accordance
with the optimal solution of its continuous relaxation. Extensive experimental
results show that the proposed algorithm can achieve a near-optimal solution,
and outperforms the existing rate adaptation schemes for tile-based adaptive
360-video streaming.
"
2088,"Understanding, Categorizing and Predicting Semantic Image-Text Relations","  Two modalities are often used to convey information in a complementary and
beneficial manner, e.g., in online news, videos, educational resources, or
scientific publications. The automatic understanding of semantic correlations
between text and associated images as well as their interplay has a great
potential for enhanced multimodal web search and recommender systems. However,
automatic understanding of multimodal information is still an unsolved research
problem. Recent approaches such as image captioning focus on precisely
describing visual content and translating it to text, but typically address
neither semantic interpretations nor the specific role or purpose of an
image-text constellation. In this paper, we go beyond previous work and
investigate, inspired by research in visual communication, useful semantic
image-text relations for multimodal information retrieval. We derive a
categorization of eight semantic image-text classes (e.g., ""illustration"" or
""anchorage"") and show how they can systematically be characterized by a set of
three metrics: cross-modal mutual information, semantic correlation, and the
status relation of image and text. Furthermore, we present a deep learning
system to predict these classes by utilizing multimodal embeddings. To obtain a
sufficiently large amount of training data, we have automatically collected and
augmented data from a variety of data sets and web resources, which enables
future research on this topic. Experimental results on a demanding test set
demonstrate the feasibility of the approach.
"
2089,"Zero-shot Learning and Knowledge Transfer in Music Classification and
  Tagging","  Music classification and tagging is conducted through categorical supervised
learning with a fixed set of labels. In principle, this cannot make predictions
on unseen labels. Zero-shot learning is an approach to solve the problem by
using side information about the semantic labels. We recently investigated this
concept of zero-shot learning in music classification and tagging task by
projecting both audio and label space on a single semantic space. In this work,
we extend the work to verify the generalization ability of zero-shot learning
model by conducting knowledge transfer to different music corpora.
"
2090,"Enhancement of Underwater Images with Statistical Model of Background
  Light and Optimization of Transmission Map","  Underwater images often have severe quality degradation and distortion due to
light absorption and scattering in the water medium. A hazed image formation
model is widely used to restore the image quality. It depends on two optical
parameters: the background light and the transmission map. Underwater images
can also be enhanced by color and contrast correction from the perspective of
image processing. In this paper, we propose an effective underwater image
enhancement method for underwater images in composition of underwater image
restoration and color correction. Firstly, a manually annotated background
lights (MABLs) database is developed. With reference to the relationship
between MABLs and the histogram distributions of various underwater images,
robust statistical models of BLs estimation are provided. Next, the TM of R
channel is roughly estimated based on the new underwater dark channel prior via
the statistic of clear and high resolution underwater images, then a scene
depth map based on the underwater light attenuation prior and an adjusted
reversed saturation map are applied to compensate and modify the coarse TM of R
channel. Next, TMs of G-B channels are estimated based on the difference of
attenuation ratios between R channel and G-B channels. Finally, to improve the
color and contrast of the restored image with a natural appearance, a variation
of white balance is introduced as post-processing. In order to guide the
priority of underwater image enhancement, sufficient evaluations are conducted
to discuss the impacts of the key parameters including BL and TM, and the
importance of the color correction. Comparisons with other state-of-the-art
methods demonstrate that our proposed underwater image enhancement method can
achieve higher accuracy of estimated BLs, less computation time, more superior
performance, and more valuable information retention.
"
2091,"QoE-Aware Resource Allocation for Crowdsourced Live Streaming: A Machine
  Learning Approach","  Driven by the tremendous technological advancement of personal devices and
the prevalence of wireless mobile network accesses, the world has witnessed an
explosion in crowdsourced live streaming. Ensuring a better viewers quality of
experience (QoE) is the key to maximize the audiences number and increase
streaming providers' profits. This can be achieved by advocating a
geo-distributed cloud infrastructure to allocate the multimedia resources as
close as possible to viewers, in order to minimize the access delay and video
stalls. Moreover, allocating the exact needed resources beforehand avoids
over-provisioning, which may lead to significant costs by the service
providers. In the contrary, under-provisioning might cause significant delays
to the viewers. In this paper, we introduce a prediction driven resource
allocation framework, to maximize the QoE of viewers and minimize the resource
allocation cost. First, by exploiting the viewers locations available in our
unique dataset, we implement a machine learning model to predict the viewers
number near each geo-distributed cloud site. Second, based on the predicted
results that showed to be close to the actual values, we formulate an
optimization problem to proactively allocate resources at the viewers
proximity. Additionally, we will present a trade-off between the video access
delay and the cost of resource allocation.
"
2092,"The Shape of RemiXXXes to Come: Audio Texture Synthesis with
  Time-frequency Scattering","  This article explains how to apply time--frequency scattering, a
convolutional operator extracting modulations in the time--frequency domain at
different rates and scales, to the re-synthesis and manipulation of audio
textures. After implementing phase retrieval in the scattering network by
gradient backpropagation, we introduce scale--rate DAFx, a class of audio
transformations expressed in the domain of time--frequency scattering
coefficients. One example of scale--rate DAFx is chirp rate inversion, which
causes each sonic event to be locally reversed in time while leaving the arrow
of time globally unchanged. Over the past two years, our work has led to the
creation of four electroacoustic pieces: ``FAVN''; ``Modulator (Scattering
Transform)''; ``Experimental Palimpsest''; ``Inspection''; and a remix of
Lorenzo Senni's ``XAllegroX'', released by Warp Records on a vinyl entitled
``The Shape of RemiXXXes to Come''. The source code to reproduce experiments
and figures is made freely available at:
https://github.com/lostanlen/scattering.m. A companion website containing demos
is at: https://lostanlen.com/pubs/dafx2019
"
2093,"Had You Looked Where I'm Looking: Cross-user Similarities in Viewing
  Behavior for 360$^{\circ}$ Video and Caching Implications","  The demand and usage of 360$^{\circ}$ video services are expected to
increase. However, despite these services being highly bandwidth intensive, not
much is known about the potential value that basic bandwidth saving techniques
such as server or edge-network on-demand caching (e.g., in a CDN) could have
when used for delivery of such services. This problem is both important and
complicated as client-side solutions have been developed that split the full
360$^{\circ}$ view into multiple tiles, and adapt the quality of the downloaded
tiles based on the user's expected viewing direction and bandwidth conditions.
To better understand the potential bandwidth savings that caching-based
techniques may offer for this context, this paper presents the first
characterization of the similarities in the viewing directions of users
watching the same 360$^{\circ}$ video, the overlap in viewports of these users
(the area of the full 360$^{\circ}$ view they actually see), and the potential
cache hit rates for different video categories, network conditions, and
accuracy levels in the prediction of future viewing direction when prefetching.
The results provide substantial insight into the conditions under which overlap
can be considerable and caching effective, and can inform the design of new
caching system policies tailored for 360$^{\circ}$ video.
"
2094,"Channel-by-Channel Demosaicking Networks with Embedded Spectral
  Correlation","  Demosaicking is standardly the first step in today's Image Signal Processing
(ISP) pipeline of digital cameras. It reconstructs image RGB values from the
spatially and spectrally sparse Color Filter Array (CFA) samples, which are the
original raw data digitized from electrical signals. High quality and low cost
demosaicking is not only necessary for photography, but also fundamental for
many machine vision tasks. This paper proposes an accurate and fast
demosaicking model based on Convolutional Neural Networks (CNN) for the Bayer
CFA, which is the most popular color filter arrangement adopted by digital
camera manufacturers. Observing that each channel has different estimation
complexity, we reconstruct each channel by an individual sub-network. Moreover,
instead of directly estimating the red and blue values, our model infers the
green-red and green-blue color difference. This strategy allows recovering the
most complex channel by a light weight network. Although the total size of our
model is significantly smaller than the state of the art demosaicking networks,
it achieves substantially higher performance in both demosaicking quality and
computational cost, as validated by extensive experiments. Source code will be
released along with paper publication.
"
2095,"A novel music-based game with motion capture to support cognitive and
  motor function in the elderly","  This paper presents a novel game prototype that uses music and motion
detection as preventive medicine for the elderly. Given the aging populations
around the globe, and the limited resources and staff able to care for these
populations, eHealth solutions are becoming increasingly important, if not
crucial, additions to modern healthcare and preventive medicine. Furthermore,
because compliance rates for performing physical exercises are often quite low
in the elderly, systems able to motivate and engage this population are a
necessity. Our prototype uses music not only to engage listeners, but also to
leverage the efficacy of music to improve mental and physical wellness. The
game is based on a memory task to stimulate cognitive function, and requires
users to perform physical gestures to mimic the playing of different musical
instruments. To this end, the Microsoft Kinect sensor is used together with a
newly developed gesture detection module in order to process users' gestures.
The resulting prototype system supports both cognitive functioning and physical
strengthening in the elderly.
"
2096,Pooled Steganalysis in JPEG: how to deal with the spreading strategy?,"  In image pooled steganalysis, a steganalyst, Eve, aims to detect if a set of
images sent by a steganographer, Alice, to a receiver, Bob, contains a hidden
message. We can reasonably assess that the steganalyst does not know the
strategy used to spread the payload across images. To the best of our
knowledge, in this case, the most appropriate solution for pooled steganalysis
is to use a Single-Image Detector (SID) to estimate/quantify if an image is
cover or stego, and to average the scores obtained on the set of images.
  In such a scenario, where Eve does not know the spreading strategies, we
experimentally show that if Eve can discriminate among few well-known spreading
strategies, she can improve her steganalysis performances compared to a simple
averaging or maximum pooled approach. Our discriminative approach allows
obtaining steganalysis efficiencies comparable to those obtained by a
clairvoyant, Eve, who knows the Alice spreading strategy. Another interesting
observation is that DeLS spreading strategy behaves really better than all the
other spreading strategies.
  Those observations results in the experimentation with six different
spreading strategies made on Jpeg images with J-UNIWARD, a state-of-the-art
Single-Image-Detector, and a discriminative architecture that is invariant to
the individual payload in each image, invariant to the size of the analyzed set
of images, and build on a binary detector (for the pooling) that is able to
deal with various spreading strategies.
"
2097,Audio-Based Music Classification with DenseNet And Data Augmentation,"  In recent years, deep learning technique has received intense attention owing
to its great success in image recognition. A tendency of adaption of deep
learning in various information processing fields has formed, including music
information retrieval (MIR). In this paper, we conduct a comprehensive study on
music audio classification with improved convolutional neural networks (CNNs).
To the best of our knowledge, this the first work to apply Densely Connected
Convolutional Networks (DenseNet) to music audio tagging, which has been
demonstrated to perform better than Residual neural network (ResNet).
Additionally, two specific data augmentation approaches of time overlapping and
pitch shifting have been proposed to address the deficiency of labelled data in
the MIR. Moreover, an ensemble learning of stacking is employed based on SVM.
We believe that the proposed combination of strong representation of DenseNet
and data augmentation can be adapted to other audio processing tasks.
"
2098,"Representation Learning of Music Using Artist, Album, and Track
  Information","  Supervised music representation learning has been performed mainly using
semantic labels such as music genres. However, annotating music with semantic
labels requires time and cost. In this work, we investigate the use of factual
metadata such as artist, album, and track information, which are naturally
annotated to songs, for supervised music representation learning. The results
show that each of the metadata has individual concept characteristics, and
using them jointly improves overall performance.
"
2099,"PRNU Based Source Camera Attribution for Image Sets Anonymized with
  Patch-Match Algorithm","  Patch-Match is an efficient algorithm used for structural image editing and
available as a tool on popular commercial photo-editing software. The tool
allows users to insert or remove objects from photos using information from
similar scene content. Recently, a modified version of this algorithm was
proposed as a counter-measure against Photo-Response Non-Uniformity (PRNU)
based Source Camera Identification (SCI). The algorithm can provide anonymity
at a great rate (97\%) and impede PRNU based SCI without the need of any other
information, hence leaving no-known recourse for the PRNU-based SCI. In this
paper, we propose a method to identify sources of the Patch-Match-applied
images by using randomized subsets of images and the traditional PRNU based SCI
methods. We evaluate the proposed method on two forensics scenarios in which an
adversary makes use of the Patch-Match algorithm and distorts the PRNU noise
pattern in the incriminating images he took with his camera. Our results show
that it is possible to link sets of Patch-Match-applied images back to their
source camera even in the presence of images that come from unknown cameras. To
our best knowledge, the proposed method represents the very first
counter-measure against the usage of of Patch-Match in the digital forensics
literature.
"
2100,"Non-user Inclusive Design for Maintaining Harmony of Real-Virtual Human
  Interaction in Augmented Reality","  Augmented reality enables the illusion of contents such as objects and humans
in the virtual world co-existing with users in the real world. However,
non-users who are not aware of the presence of the virtual world and
dynamically move nearby might either cause a conflict by directly breaking into
space where a user is talking to a Virtual Human (VH), or be troubled when try
to avoid disturbing the user. To maintain harmony and keep both the user's and
non-users' comfort, we propose a method that controls the VH to adjust its own
position to avoid such potential conflict. The difficulty to address this
problem is that the agent must avoid potential conflict in a natural way to
keep the user away from feeling unnatural. Our idea is to endow the VH with
three capabilities: anticipating non-users walking around, understanding how to
establish and maintain proper formation to adapt to the environment, and
planning to avoid conflicts by shifting formation in advance. We develop a
non-user inclusive spatial formation model that realizes natural arrangement
shift corresponding to the environment based on theoretical sources from
literature. We implemented our proposed model into a VH behavior planning
system to achieve natural conflict avoidance. Evaluation experiments showed
that it successfully reduces potential conflicts caused by non-users.
"
2101,Cross-Platform Modeling of Users' Behavior on Social Media,"  With the booming development and popularity of mobile applications, different
verticals accumulate abundant data of user information and social behavior,
which are spontaneous, genuine and diversified. However, each platform
describes user's portraits in only certain aspect, resulting in difficult
combination of those internet footprints together. In our research, we proposed
a modeling approach to analyze user's online behavior across different social
media platforms. Structured and unstructured data of same users shared by
NetEase Music and Sina Weibo have been collected for cross-platform analysis of
correlations between music preference and other users' characteristics. Based
on music tags of genre and mood, genre cluster of five groups and mood cluster
of four groups have been formed by computing their collected song lists with
K-means method. Moreover, with the help of user data of Weibo, correlations
between music preference (i.e. genre, mood) and Big Five personalities (BFPs)
and basic information (e.g. gender, resident region, tags) have been
comprehensively studied, building up full-scale user portraits with finer
grain. Our findings indicate that people's music preference could be linked
with their real social activities. For instance, people living in mountainous
areas generally prefer folk music, while those in urban areas like pop music
more. Interestingly, dog lovers could love sad music more than cat lovers.
Moreover, our proposed cross-platform modeling approach could be adapted to
other verticals, providing an online automatic way for profiling users in a
more precise and comprehensive way.
"
2102,Rhythm Dungeon: A Blockchain-based Music Roguelike Game,"  Rhythm Dungeon is a rhythm game which leverages the blockchain as a shared
open database. During the gaming session, the player explores a roguelike
dungeon by inputting specific sequences in time to music rhythm. By integrating
smart contract to the game program, the enemies through the venture are
generated from other games which share the identical blockchain. On the other
hand, the player may upload their characters at the end of their journey, so
that their own character may appear in other games and make an influence.
Rhythm Dungeon is designed and implemented to show the potential of
decentralized gaming experience, which utilizes the blockchain to provide
asynchronous interactions among massive players.
"
2103,Music Performance Analysis: A Survey,"  Music Information Retrieval (MIR) tends to focus on the analysis of audio
signals. Often, a single music recording is used as representative of a ""song""
even though different performances of the same song may reveal different
properties. A performance is distinct in many ways from a (arguably more
abstract) representation of a ""song,"" ""piece,"" or musical score. The
characteristics of the (recorded) performance -- as opposed to the score or
musical idea -- can have a major impact on how a listener perceives music. The
analysis of music performance, however, has been traditionally only a
peripheral topic for the MIR research community. This paper surveys the field
of Music Performance Analysis (MPA) from various perspectives, discusses its
significance to the field of MIR, and points out opportunities for future
research in this field.
"
2104,Frame attention networks for facial expression recognition in videos,"  The video-based facial expression recognition aims to classify a given video
into several basic emotions. How to integrate facial features of individual
frames is crucial for this task. In this paper, we propose the Frame Attention
Networks (FAN), to automatically highlight some discriminative frames in an
end-to-end framework. The network takes a video with a variable number of face
images as its input and produces a fixed-dimension representation. The whole
network is composed of two modules. The feature embedding module is a deep
Convolutional Neural Network (CNN) which embeds face images into feature
vectors. The frame attention module learns multiple attention weights which are
used to adaptively aggregate the feature vectors to form a single
discriminative video representation. We conduct extensive experiments on CK+
and AFEW8.0 datasets. Our proposed FAN shows superior performance compared to
other CNN based methods and achieves state-of-the-art performance on CK+.
"
2105,Effects of Foraging in Personalized Content-based Image Recommendation,"  A major challenge of recommender systems is to help users locating
interesting items. Personalized recommender systems have become very popular as
they attempt to predetermine the needs of users and provide them with
recommendations to personalize their navigation. However, few studies have
addressed the question of what drives the users' attention to specific content
within the collection and what influences the selection of interesting items.
To this end, we employ the lens of Information Foraging Theory (IFT) to image
recommendation to demonstrate how the user could utilize visual bookmarks to
locate interesting images. We investigate a personalized content-based image
recommendation system to understand what affects user attention by reinforcing
visual attention cues based on IFT. We further find that visual bookmarks
(cues) lead to a stronger scent of the recommended image collection. Our
evaluation is based on the Pinterest image collection.
"
2106,Universal audio synthesizer control with normalizing flows,"  The ubiquity of sound synthesizers has reshaped music production and even
entirely defined new music genres. However, the increasing complexity and
number of parameters in modern synthesizers make them harder to master. Hence,
the development of methods allowing to easily create and explore with
synthesizers is a crucial need. Here, we introduce a novel formulation of audio
synthesizer control. We formalize it as finding an organized latent audio space
that represents the capabilities of a synthesizer, while constructing an
invertible mapping to the space of its parameters. By using this formulation,
we show that we can address simultaneously automatic parameter inference,
macro-control learning and audio-based preset exploration within a single
model. To solve this new formulation, we rely on Variational Auto-Encoders
(VAE) and Normalizing Flows (NF) to organize and map the respective auditory
and parameter spaces. We introduce the disentangling flows, which allow to
perform the invertible mapping between separate latent spaces, while steering
the organization of some latent dimensions to match target variation factors by
splitting the objective as partial density evaluation. We evaluate our proposal
against a large set of baseline models and show its superiority in both
parameter inference and audio reconstruction. We also show that the model
disentangles the major factors of audio variations as latent dimensions, that
can be directly used as macro-parameters. We also show that our model is able
to learn semantic controls of a synthesizer by smoothly mapping to its
parameters. Finally, we discuss the use of our model in creative applications
and its real-time implementation in Ableton Live
"
2107,"Private Authentication with Physical Identifiers Through Broadcast
  Channel Measurements","  A basic model for key agreement with biometric or physical identifiers is
extended to include measurements of a hidden source through a general broadcast
channel (BC). An inner bound for strong secrecy, maximum key rate, and minimum
privacy-leakage and database-storage rates is proposed. The inner bound is
shown to be tight for physically-degraded and less-noisy BCs.
"
2108,Adaptive Music Composition for Games,"  The generation of music that adapts dynamically to content and actions has an
important role in building more immersive, memorable and emotive game
experiences. To date, the development of adaptive music systems for video games
is limited by both the nature of algorithms used for real-time music generation
and the limited modelling of player action, game world context and emotion in
current games. We propose that these issues must be addressed in tandem for the
quality and flexibility of adaptive game music to significantly improve.
Cognitive models of knowledge organisation and emotional affect are integrated
with multi-modal, multi-agent composition techniques to produce a novel
Adaptive Music System (AMS). The system is integrated into two stylistically
distinct games. Gamers reported an overall higher immersion and correlation of
music with game-world concepts with the AMS than with the original game
soundtracks in both games.
"
2109,"MIDI-Sandwich: Multi-model Multi-task Hierarchical Conditional VAE-GAN
  networks for Symbolic Single-track Music Generation","  Most existing neural network models for music generation explore how to
generate music bars, then directly splice the music bars into a song. However,
these methods do not explore the relationship between the bars, and the
connected song as a whole has no musical form structure and sense of musical
direction. To address this issue, we propose a Multi-model Multi-task
Hierarchical Conditional VAE-GAN (Variational Autoencoder-Generative
adversarial networks) networks, named MIDI-Sandwich, which combines musical
knowledge, such as musical form, tonic, and melodic motion. The MIDI-Sandwich
has two submodels: Hierarchical Conditional Variational Autoencoder (HCVAE) and
Hierarchical Conditional Generative Adversarial Network (HCGAN). The HCVAE uses
hierarchical structure. The underlying layer of HCVAE uses Local Conditional
Variational Autoencoder (L-CVAE) to generate a music bar which is pre-specified
by the First and Last Notes (FLN). The upper layer of HCVAE uses Global
Variational Autoencoder(G-VAE) to analyze the latent vector sequence generated
by the L-CVAE encoder, to explore the musical relationship between the bars,
and to produce the song pieced together by multiple music bars generated by the
L-CVAE decoder, which makes the song both have musical structure and sense of
direction. At the same time, the HCVAE shares a part of itself with the HCGAN
to further improve the performance of the generated music. The MIDI-Sandwich is
validated on the Nottingham dataset and is able to generate a single-track
melody sequence (17x8 beats), which is superior to the length of most of the
generated models (8 to 32 beats). Meanwhile, by referring to the experimental
methods of many classical kinds of literature, the quality evaluation of the
generated music is performed. The above experiments prove the validity of the
model.
"
2110,"Recent Advances of Image Steganography with Generative Adversarial
  Networks","  In the past few years, the Generative Adversarial Network (GAN) which
proposed in 2014 has achieved great success. GAN has achieved many research
results in the field of computer vision and natural language processing. Image
steganography is dedicated to hiding secret messages in digital images, and has
achieved the purpose of covert communication. Recently, research on image
steganography has demonstrated great potential for using GAN and neural
networks. In this paper we review different strategies for steganography such
as cover modification, cover selection and cover synthesis by GANs, and discuss
the characteristics of these methods as well as evaluation metrics and provide
some possible future research directions in image steganography.
"
2111,Intrinsic Image Popularity Assessment,"  The goal of research in automatic image popularity assessment (IPA) is to
develop computational models that can accurately predict the potential of a
social image to go viral on the Internet. Here, we aim to single out the
contribution of visual content to image popularity, i.e., intrinsic image
popularity. Specifically, we first describe a probabilistic method to generate
massive popularity-discriminable image pairs, based on which the first
large-scale image database for intrinsic IPA (I$^2$PA) is established. We then
develop computational models for I$^2$PA based on deep neural networks,
optimizing for ranking consistency with millions of popularity-discriminable
image pairs. Experiments on Instagram and other social platforms demonstrate
that the optimized model performs favorably against existing methods, exhibits
reasonable generalizability on different databases, and even surpasses
human-level performance on Instagram. In addition, we conduct a psychophysical
experiment to analyze various aspects of human behavior in I$^2$PA.
"
2112,"The DKU Replay Detection System for the ASVspoof 2019 Challenge: On Data
  Augmentation, Feature Representation, Classification, and Fusion","  This paper describes our DKU replay detection system for the ASVspoof 2019
challenge. The goal is to develop spoofing countermeasure for automatic speaker
recognition in physical access scenario. We leverage the countermeasure system
pipeline from four aspects, including the data augmentation, feature
representation, classification, and fusion. First, we introduce an
utterance-level deep learning framework for anti-spoofing. It receives the
variable-length feature sequence and outputs the utterance-level scores
directly. Based on the framework, we try out various kinds of input feature
representations extracted from either the magnitude spectrum or phase spectrum.
Besides, we also perform the data augmentation strategy by applying the speed
perturbation on the raw waveform. Our best single system employs a residual
neural network trained by the speed-perturbed group delay gram. It achieves EER
of 1.04% on the development set, as well as EER of 1.08% on the evaluation set.
Finally, using the simple average score from several single systems can further
improve the performance. EER of 0.24% on the development set and 0.66% on the
evaluation set is obtained for our primary system.
"
2113,"Blind Image Quality Assessment Using A Deep Bilinear Convolutional
  Neural Network","  We propose a deep bilinear model for blind image quality assessment (BIQA)
that handles both synthetic and authentic distortions. Our model consists of
two convolutional neural networks (CNN), each of which specializes in one
distortion scenario. For synthetic distortions, we pre-train a CNN to classify
image distortion type and level, where we enjoy large-scale training data. For
authentic distortions, we adopt a pre-trained CNN for image classification. The
features from the two CNNs are pooled bilinearly into a unified representation
for final quality prediction. We then fine-tune the entire model on target
subject-rated databases using a variant of stochastic gradient descent.
Extensive experiments demonstrate that the proposed model achieves superior
performance on both synthetic and authentic databases. Furthermore, we verify
the generalizability of our method on the Waterloo Exploration Database using
the group maximum differentiation competition.
"
2114,Zero-shot Learning for Audio-based Music Classification and Tagging,"  Audio-based music classification and tagging is typically based on
categorical supervised learning with a fixed set of labels. This intrinsically
cannot handle unseen labels such as newly added music genres or semantic words
that users arbitrarily choose for music retrieval. Zero-shot learning can
address this problem by leveraging an additional semantic space of labels where
side information about the labels is used to unveil the relationship between
each other. In this work, we investigate the zero-shot learning in the music
domain and organize two different setups of side information. One is using
human-labeled attribute information based on Free Music Archive and
OpenMIC-2018 datasets. The other is using general word semantic information
based on Million Song Dataset and Last.fm tag annotations. Considering a music
track is usually multi-labeled in music classification and tagging datasets, we
also propose a data split scheme and associated evaluation settings for the
multi-label zero-shot learning. Finally, we report experimental results and
discuss the effectiveness and new possibilities of zero-shot learning in the
music domain.
"
2115,Extraction and Analysis of Fictional Character Networks: A Survey,"  A character network is a graph extracted from a narrative, in which vertices
represent characters and edges correspond to interactions between them. A
number of narrative-related problems can be addressed automatically through the
analysis of character networks, such as summarization, classification, or role
detection. Character networks are particularly relevant when considering works
of fictions (e.g. novels, plays, movies, TV series), as their exploitation
allows developing information retrieval and recommendation systems. However,
works of fiction possess specific properties making these tasks harder. This
survey aims at presenting and organizing the scientific literature related to
the extraction of character networks from works of fiction, as well as their
analysis. We first describe the extraction process in a generic way, and
explain how its constituting steps are implemented in practice, depending on
the medium of the narrative, the goal of the network analysis, and other
factors. We then review the descriptive tools used to characterize character
networks, with a focus on the way they are interpreted in this context. We
illustrate the relevance of character networks by also providing a review of
applications derived from their analysis. Finally, we identify the limitations
of the existing approaches, and the most promising perspectives.
"
2116,Benchmarking unsupervised near-duplicate image detection,"  Unsupervised near-duplicate detection has many practical applications ranging
from social media analysis and web-scale retrieval, to digital image forensics.
It entails running a threshold-limited query on a set of descriptors extracted
from the images, with the goal of identifying all possible near-duplicates,
while limiting the false positives due to visually similar images. Since the
rate of false alarms grows with the dataset size, a very high specificity is
thus required, up to $1 - 10^{-9}$ for realistic use cases; this important
requirement, however, is often overlooked in literature. In recent years,
descriptors based on deep convolutional neural networks have matched or
surpassed traditional feature extraction methods in content-based image
retrieval tasks. To the best of our knowledge, ours is the first attempt to
establish the performance range of deep learning-based descriptors for
unsupervised near-duplicate detection on a range of datasets, encompassing a
broad spectrum of near-duplicate definitions. We leverage both established and
new benchmarks, such as the Mir-Flick Near-Duplicate (MFND) dataset, in which a
known ground truth is provided for all possible pairs over a general, large
scale image collection. To compare the specificity of different descriptors, we
reduce the problem of unsupervised detection to that of binary classification
of near-duplicate vs. not-near-duplicate images. The latter can be conveniently
characterized using Receiver Operating Curve (ROC). Our findings in general
favor the choice of fine-tuning deep convolutional networks, as opposed to
using off-the-shelf features, but differences at high specificity settings
depend on the dataset and are often small. The best performance was observed on
the MFND benchmark, achieving 96\% sensitivity at a false positive rate of
$1.43 \times 10^{-6}$.
"
2117,"Dependency-aware Attention Control for Unconstrained Face Recognition
  with Image Sets","  This paper targets the problem of image set-based face verification and
identification. Unlike traditional single media (an image or video) setting, we
encounter a set of heterogeneous contents containing orderless images and
videos. The importance of each image is usually considered either equal or
based on their independent quality assessment. How to model the relationship of
orderless images within a set remains a challenge. We address this problem by
formulating it as a Markov Decision Process (MDP) in the latent space.
Specifically, we first present a dependency-aware attention control (DAC)
network, which resorts to actor-critic reinforcement learning for sequential
attention decision of each image embedding to fully exploit the rich
correlation cues among the unordered images. Moreover, we introduce its
sample-efficient variant with off-policy experience replay to speed up the
learning process. The pose-guided representation scheme can further boost the
performance at the extremes of the pose variation.
"
2118,Informative Visual Storytelling with Cross-modal Rules,"  Existing methods in the Visual Storytelling field often suffer from the
problem of generating general descriptions, while the image contains a lot of
meaningful contents remaining unnoticed. The failure of informative story
generation can be concluded to the model's incompetence of capturing enough
meaningful concepts. The categories of these concepts include entities,
attributes, actions, and events, which are in some cases crucial to grounded
storytelling. To solve this problem, we propose a method to mine the
cross-modal rules to help the model infer these informative concepts given
certain visual input. We first build the multimodal transactions by
concatenating the CNN activations and the word indices. Then we use the
association rule mining algorithm to mine the cross-modal rules, which will be
used for the concept inference. With the help of the cross-modal rules, the
generated stories are more grounded and informative. Besides, our proposed
method holds the advantages of interpretation, expandability, and
transferability, indicating potential for wider application. Finally, we
leverage these concepts in our encoder-decoder framework with the attention
mechanism. We conduct several experiments on the VIsual StoryTelling~(VIST)
dataset, the results of which demonstrate the effectiveness of our approach in
terms of both automatic metrics and human evaluation. Additional experiments
are also conducted showing that our mined cross-modal rules as additional
knowledge helps the model gain better performance when trained on a small
dataset.
"
2119,"An Experimental-based Review of Image Enhancement and Image Restoration
  Methods for Underwater Imaging","  Underwater images play a key role in ocean exploration, but often suffer from
severe quality degradation due to light absorption and scattering in water
medium. Although major breakthroughs have been made recently in the general
area of image enhancement and restoration, the applicability of new methods for
improving the quality of underwater images has not specifically been captured.
In this paper, we review the image enhancement and restoration methods that
tackle typical underwater image impairments, including some extreme
degradations and distortions. Firstly, we introduce the key causes of quality
reduction in underwater images, in terms of the underwater image formation
model (IFM). Then, we review underwater restoration methods, considering both
the IFM-free and the IFM-based approaches. Next, we present an
experimental-based comparative evaluation of state-of-the-art IFM-free and
IFM-based methods, considering also the prior-based parameter estimation
algorithms of the IFM-based methods, using both subjective and objective
analysis (the used code is freely available at
https://github.com/wangyanckxx/Single-Underwater-Image-Enhancement-and-Color-Restoration).
Starting from this study, we pinpoint the key shortcomings of existing methods,
drawing recommendations for future research in this area. Our review of
underwater image enhancement and restoration provides researchers with the
necessary background to appreciate challenges and opportunities in this
important field.
"
2120,"TrackNet: A Deep Learning Network for Tracking High-speed and Tiny
  Objects in Sports Applications","  Ball trajectory data are one of the most fundamental and useful information
in the evaluation of players' performance and analysis of game strategies.
Although vision-based object tracking techniques have been developed to analyze
sport competition videos, it is still challenging to recognize and position a
high-speed and tiny ball accurately. In this paper, we develop a deep learning
network, called TrackNet, to track the tennis ball from broadcast videos in
which the ball images are small, blurry, and sometimes with afterimage tracks
or even invisible. The proposed heatmap-based deep learning network is trained
to not only recognize the ball image from a single frame but also learn flying
patterns from consecutive frames. TrackNet takes images with a size of
$640\times360$ to generate a detection heatmap from either a single frame or
several consecutive frames to position the ball and can achieve high precision
even on public domain videos. The network is evaluated on the video of the
men's singles final at the 2017 Summer Universiade, which is available on
YouTube. The precision, recall, and F1-measure of TrackNet reach $99.7\%$,
$97.3\%$, and $98.5\%$, respectively. To prevent overfitting, 9 additional
videos are partially labeled together with a subset from the previous dataset
to implement 10-fold cross-validation, and the precision, recall, and
F1-measure are $95.3\%$, $75.7\%$, and $84.3\%$, respectively. A conventional
image processing algorithm is also implemented to compare with TrackNet. Our
experiments indicate that TrackNet outperforms conventional method by a big
margin and achieves exceptional ball tracking performance. The dataset and demo
video are available at https://nol.cs.nctu.edu.tw/ndo3je6av9/.
"
2121,"Barriers towards no-reference metrics application to compressed video
  quality analysis: on the example of no-reference metric NIQE","  This paper analyses the application of no-reference metric NIQE to the task
of video-codec comparison. A number of issues in the metric behaviour on videos
was detected and described. The metric has outlying scores on black and
solid-coloured frames. The proposed averaging technique for metric quality
scores helped to improve the results in some cases. Also, NIQE has low-quality
scores for videos with detailed textures and higher scores for videos of lower
bitrates due to the blurring of these textures after compression. Although NIQE
showed natural results for many tested videos, it is not universal and
currently can not be used for video-codec comparisons.
"
2122,On the Security and Applicability of Fragile Camera Fingerprints,"  Camera sensor noise is one of the most reliable device characteristics in
digital image forensics, enabling the unique linkage of images to digital
cameras. This so-called camera fingerprint gives rise to different
applications, such as image forensics and authentication. However, if images
are publicly available, an adversary can estimate the fingerprint from her
victim and plant it into spurious images. The concept of fragile camera
fingerprints addresses this attack by exploiting asymmetries in data access:
While the camera owner will always have access to a full fingerprint from
uncompressed images, the adversary has typically access to compressed images
and thus only to a truncated fingerprint. The security of this defense,
however, has not been systematically explored yet. This paper provides the
first comprehensive analysis of fragile camera fingerprints under attack. A
series of theoretical and practical tests demonstrate that fragile camera
fingerprints allow a reliable device identification for common compression
levels in an adversarial environment.
"
2123,BASN -- Learning Steganography with Binary Attention Mechanism,"  Secret information sharing through image carrier has aroused much research
attention in recent years with images' growing domination on the Internet and
mobile applications. However, with the booming trend of convolutional neural
networks, image steganography is facing a more significant challenge from
neural-network-automated tasks. To improve the security of image steganography
and minimize task result distortion, models must maintain the feature maps
generated by task-specific networks being irrelative to any hidden information
embedded in the carrier. This paper introduces a binary attention mechanism
into image steganography to help alleviate the security issue, and in the
meanwhile, increase embedding payload capacity. The experimental results show
that our method has the advantage of high payload capacity with little feature
map distortion and still resist detection by state-of-the-art image
steganalysis algorithms.
"
2124,"Learning from History: Recreating and Repurposing Sister Harriet
  Padberg's Computer Composed Canon and Free Fugue","  Harriet Padberg wrote Computer-Composed Canon and Free Fugue as part of her
1964 dissertation in Mathematics and Music at Saint Louis University. This
program is one of the earliest examples of text-to-music software and
algorithmic composition, which are areas of great interest in the present-day
field of music technology. This paper aims to analyze the technological
innovation, aesthetic design process, and impact of Harriet Padberg's original
1964 thesis as well as the design of a modern recreation and utilization, in
order to gain insight to the nature of revisiting older works. Here, we present
our open source recreation of Padberg's program with a modern interface and,
through its use as an artistic tool by three composers, show how historical
works can be effectively used for new creative purposes in contemporary
contexts. Not Even One by Molly Jones draws on the historical and social
significance of Harriet Padberg through using her program in a piece about the
lack of representation of women judges in composition competitions. Brevity by
Anna Savery utilizes the original software design as a composition tool, and
The Padberg Piano by Anthony Caulkins uses the melodic generation of the
original to create a software instrument.
"
2125,A New Benchmark and Approach for Fine-grained Cross-media Retrieval,"  Cross-media retrieval is to return the results of various media types
corresponding to the query of any media type. Existing researches generally
focus on coarse-grained cross-media retrieval. When users submit an image of
""Slaty-backed Gull"" as a query, coarse-grained cross-media retrieval treats it
as ""Bird"", so that users can only get the results of ""Bird"", which may include
other bird species with similar appearance (image and video), descriptions
(text) or sounds (audio), such as ""Herring Gull"". Such coarse-grained
cross-media retrieval is not consistent with human lifestyle, where we
generally have the fine-grained requirement of returning the exactly relevant
results of ""Slaty-backed Gull"" instead of ""Herring Gull"". However, few
researches focus on fine-grained cross-media retrieval, which is a highly
challenging and practical task. Therefore, in this paper, we first construct a
new benchmark for fine-grained cross-media retrieval, which consists of 200
fine-grained subcategories of the ""Bird"", and contains 4 media types, including
image, text, video and audio. To the best of our knowledge, it is the first
benchmark with 4 media types for fine-grained cross-media retrieval. Then, we
propose a uniform deep model, namely FGCrossNet, which simultaneously learns 4
types of media without discriminative treatments. We jointly consider three
constraints for better common representation learning: classification
constraint ensures the learning of discriminative features, center constraint
ensures the compactness characteristic of the features of the same subcategory,
and ranking constraint ensures the sparsity characteristic of the features of
different subcategories. Extensive experiments verify the usefulness of the new
benchmark and the effectiveness of our FGCrossNet. They will be made available
at https://github.com/PKU-ICST-MIPL/FGCrossNet_ACMMM2019.
"
2126,Hacking VMAF with Video Color and Contrast Distortion,"  Video quality measurement takes an important role in many applications.
Full-reference quality metrics which are usually used in video codecs
comparisons are expected to reflect any changes in videos. In this article, we
consider different color corrections of compressed videos which increase the
values of full-reference metric VMAF and almost don't decrease other
widely-used metric SSIM. The proposed video contrast enhancement approach shows
the metric inapplicability in some cases for video codecs comparisons, as it
may be used for cheating in the comparisons via tuning to improve this metric
values.
"
2127,"LakhNES: Improving multi-instrumental music generation with cross-domain
  pre-training","  We are interested in the task of generating multi-instrumental music scores.
The Transformer architecture has recently shown great promise for the task of
piano score generation; here we adapt it to the multi-instrumental setting.
Transformers are complex, high-dimensional language models which are capable of
capturing long-term structure in sequence data, but require large amounts of
data to fit. Their success on piano score generation is partially explained by
the large volumes of symbolic data readily available for that domain. We
leverage the recently-introduced NES-MDB dataset of four-instrument scores from
an early video game sound synthesis chip (the NES), which we find to be
well-suited to training with the Transformer architecture. To further improve
the performance of our model, we propose a pre-training technique to leverage
the information in a large collection of heterogeneous music, namely the Lakh
MIDI dataset. Despite differences between the two corpora, we find that this
transfer learning procedure improves both quantitative and qualitative
performance for our primary task.
"
2128,"Synchronizing Audio-Visual Film Stimuli in Unity (version 5.5.1f1): Game
  Engines as a Tool for Research","  Unity is a software specifically designed for the development of video games.
However, due to its programming possibilities and the polyvalence of its
architecture, it can prove to be a versatile tool for stimuli presentation in
research experiments. Nevertheless, it also has some limitations and conditions
that need to be taken into account to ensure optimal performance in particular
experimental situations. Such is the case if we want to use it in an
experimental design that includes the acquisition of biometric signals
synchronized with the broadcasting of video and audio in real time. In the
present paper, we analyse how Unity (version 5.5.1f1) reacts in one such
experimental design that requires the execution of audio-visual material. From
the analysis of an experimental procedure in which the video was executed
following the standard software specifications, we have detected the following
problems desynchronization between the emission of the video and the audio;
desynchronization between the temporary counter and the video; a delay in the
execution of the screenshot; and depending on the encoding of the video a bad
fluency in the video playback, which even though it maintains the total
playback time, it causes Unity to freeze frames and proceed to compensate with
little temporary jumps in the video. Finally, having detected all the problems,
a compensation and verification process is designed to be able to work with
audio-visual material in Unity (version 5.5.1f1) in an accurate way. We present
a protocol for checks and compensations that allows solving these problems to
ensure the execution of robust experiments in terms of reliability.
"
2129,Heard More Than Heard: An Audio Steganography Method Based on GAN,"  Audio steganography is a collection of techniques for concealing the
existence of information by embedding it within a non-secret audio, which is
referred to as carrier. Distinct from cryptography, the steganography put
emphasis on the hiding of the secret existence. The existing audio
steganography methods mainly depend on human handcraft, while we proposed an
audio steganography algorithm which automatically generated from adversarial
training. The method consists of three neural networks: encoder which embeds
the secret message in the carrier, decoder which extracts the message, and
discriminator which determine the carriers contain secret messages. All the
networks are simultaneously trained to create embedding, extracting and
discriminating process. The system is trained with different training settings
on two datasets. Competed the majority of audio steganographic schemes, the
proposed scheme could produce high fidelity steganographic audio which contains
secret audio. Besides, the additional experiments verify the robustness and
security of our algorithm.
"
2130,"Reversible Data Hiding in Encrypted Images using Local Difference of
  Neighboring Pixels","  This paper presents a reversible data hiding in encrypted image (RDHEI),
which divides image into non-overlapping blocks. In each block, central pixel
of the block is considered as leader pixel and others as follower ones. The
prediction errors between the intensity of follower pixels and leader ones are
calculated and analyzed to determine a feature for block embedding capacity.
This feature indicates the amount of data that can be embedded in a block.
Using this pre-process for whole blocks, we vacate rooms before the encryption
of the original image to achieve high embedding capacity. Also, using the
features of all blocks, embedded data is extracted and the original image is
perfectly reconstructed at the decoding phase. In effect, comparing to existent
RDHEI algorithms, embedding capacity is significantly increased in the proposed
algorithm. Experimental results confirm that the proposed algorithm outperforms
state of the art ones.
"
2131,"Sorting Methods and Adaptive Thresholding for Histogram Based Reversible
  Data Hiding","  This paper presents a histogram based reversible data hiding (RDH) scheme,
which divides image pixels into different cell frequency bands to sort them for
data embedding. Data hiding is more efficient in lower cell frequency bands
because it provides more accurate prediction. Using pixel existence probability
in some pixels of ultra-low cell frequency band, another sorting is performed.
Employing these two novel sorting methods in combination with the hiding
intensity analysis that determines optimum prediction error, we improve the
quality of the marked image especially for low embedding capacities. In effect,
comparing to existent RDH algorithms, the hiding capacity is increased for a
specific level of the distortion for the marked image. Experimental results
confirm that the proposed algorithm outperforms state of the art ones.
"
2132,"Beyond Imitation: Generative and Variational Choreography via Machine
  Learning","  Our team of dance artists, physicists, and machine learning researchers has
collectively developed several original, configurable machine-learning tools to
generate novel sequences of choreography as well as tunable variations on input
choreographic sequences. We use recurrent neural network and autoencoder
architectures from a training dataset of movements captured as 53
three-dimensional points at each timestep. Sample animations of generated
sequences and an interactive version of our model can be found at http:
//www.beyondimitation.com.
"
2133,"Gesture-to-Gesture Translation in the Wild via Category-Independent
  Conditional Maps","  Recent works have shown Generative Adversarial Networks (GANs) to be
particularly effective in image-to-image translations. However, in tasks such
as body pose and hand gesture translation, existing methods usually require
precise annotations, e.g. key-points or skeletons, which are time-consuming to
draw. In this work, we propose a novel GAN architecture that decouples the
required annotations into a category label - that specifies the gesture type -
and a simple-to-draw category-independent conditional map - that expresses the
location, rotation and size of the hand gesture. Our architecture synthesizes
the target gesture while preserving the background context, thus effectively
dealing with gesture translation in the wild. To this aim, we use an attention
module and a rolling guidance approach, which loops the generated images back
into the network and produces higher quality images compared to competing
works. Thus, our GAN learns to generate new images from simple annotations
without requiring key-points or skeleton labels. Results on two public datasets
show that our method outperforms state of the art approaches both
quantitatively and qualitatively. To the best of our knowledge, no work so far
has addressed the gesture-to-gesture translation in the wild by requiring
user-friendly annotations.
"
2134,Towards QoS-Aware Recommendations,"  In this paper we propose that recommendation systems (RSs) for multimedia
services should be ""QoS-aware"", i.e., take into account the expected QoS with
which a content can be delivered, to increase the user satisfaction.
Network-aware recommendations have been very recently proposed as a promising
solution to improve network performance. However, the idea of QoS-aware RSs has
been studied from the network perspective. Its feasibility and performance
performance advantages for the content-provider or user perspective have only
been speculated. Hence, in this paper we aim to provide initial answers for the
feasibility of the concept of QoS-aware RS, by investigating its impact on real
user experience. To this end, we conduct experiments with real users on a
testbed, and present initial experimental results. Our analysis demonstrates
the potential of the idea: QoS-aware RSs could be beneficial for both the users
(better experience) and content providers (higher user engagement). Moreover,
based on the collected dataset, we build statistical models to (i) predict the
user experience as a function of QoS, relevance of recommendations (QoR) and
user interest, and (ii) provide useful insights for the design of QoS-aware
RSs. We believe that our study is an important first step towards QoS-aware
recommendations, by providing experimental evidence for their feasibility and
benefits, and can help open a future research direction.
"
2135,Steganography using a 3 player game,"  Image steganography aims to securely embed secret information into cover
images. Until now, adaptive embedding algorithms such as S-UNIWARD or Mi-POD,
are among the most secure and most used methods for image steganography. With
the arrival of deep learning and more specifically the Generative Adversarial
Networks (GAN), new techniques have appeared. Among these techniques, there is
the 3 player game approaches, where three networks compete against each
other.In this paper, we propose three different architectures based on the 3
player game. The first-architecture is proposed as a rigorous alternative to
two recent publications. The second takes into account stego noise power.
Finally, our third architecture enriches the second one with a better
interaction between the embedding and extracting networks. Our method achieves
better results compared to the existing works GSIVAT, HiDDeN, and paves the way
for future research on this topic.
"
2136,Towards Data-Driven Automatic Video Editing,"  Automatic video editing involving at least the steps of selecting the most
valuable footage from points of view of visual quality and the importance of
action filmed; and cutting the footage into a brief and coherent visual story
that would be interesting to watch is implemented in a purely data-driven
manner. Visual semantic and aesthetic features are extracted by the
ImageNet-trained convolutional neural network, and the editing controller is
trained by an imitation learning algorithm. As a result, at test time the
controller shows the signs of observing basic cinematography editing rules
learned from the corpus of motion pictures masterpieces.
"
2137,The Statistical Analysis of the Live TV Bit Rate,"  This paper studies the statistical nature of TV channels streaming variable
bit rate distribution and allocation. The goal of the paper is to derive the
best-fit rate distribution to describe TV streaming bandwidth allocation, which
can reveal traffic demands of users. Our analysis uses multiplexers channel
bandwidth allocation (PID) data of 13 TV live channels. We apply 17 continuous
and 3 discrete distributions to determine the best-fit distribution function
for each individual channel and for the whole set of channels. We found that
the generalized extreme distribution fitting most of our channels most
precisely according to the Bayesian information criterion. By the same
criterion tlocationscale distribution matches best for the whole system. We use
these results to propose parameters for streaming server queuing model. Results
are useful for streaming servers scheduling policy design process targeting to
improve limited infrastructural resources, traffic engineering through dynamic
routing at CDN, SDN.
"
2138,Deep Graph-Convolutional Image Denoising,"  Non-local self-similarity is well-known to be an effective prior for the
image denoising problem. However, little work has been done to incorporate it
in convolutional neural networks, which surpass non-local model-based methods
despite only exploiting local information. In this paper, we propose a novel
end-to-end trainable neural network architecture employing layers based on
graph convolution operations, thereby creating neurons with non-local receptive
fields. The graph convolution operation generalizes the classic convolution to
arbitrary graphs. In this work, the graph is dynamically computed from
similarities among the hidden features of the network, so that the powerful
representation learning capabilities of the network are exploited to uncover
self-similar patterns. We introduce a lightweight Edge-Conditioned Convolution
which addresses vanishing gradient and over-parameterization issues of this
particular graph convolution. Extensive experiments show state-of-the-art
performance with improved qualitative and quantitative results on both
synthetic Gaussian noise and real noise.
"
2139,A Retina-inspired Sampling Method for Visual Texture Reconstruction,"  Conventional frame-based camera is not able to meet the demand of rapid
reaction for real-time applications, while the emerging dynamic vision sensor
(DVS) can realize high speed capturing for moving objects. However, to achieve
visual texture reconstruction, DVS need extra information apart from the output
spikes. This paper introduces a fovea-like sampling method inspired by the
neuron signal processing in retina, which aims at visual texture reconstruction
only taking advantage of the properties of spikes. In the proposed method, the
pixels independently respond to the luminance changes with temporal
asynchronous spikes. Analyzing the arrivals of spikes makes it possible to
restore the luminance information, enabling reconstructing the natural scene
for visualization. Three decoding methods of spike stream for texture
reconstruction are proposed for high-speed motion and stationary scenes.
Compared to conventional frame-based camera and DVS, our model can achieve
better image quality and higher flexibility, which is capable of changing the
way that demanding machine vision applications are built.
"
2140,"Automatic Radiology Report Generation based on Multi-view Image Fusion
  and Medical Concept Enrichment","  Generating radiology reports is time-consuming and requires extensive
expertise in practice. Therefore, reliable automatic radiology report
generation is highly desired to alleviate the workload. Although deep learning
techniques have been successfully applied to image classification and image
captioning tasks, radiology report generation remains challenging in regards to
understanding and linking complicated medical visual contents with accurate
natural language descriptions. In addition, the data scales of open-access
datasets that contain paired medical images and reports remain very limited. To
cope with these practical challenges, we propose a generative encoder-decoder
model and focus on chest x-ray images and reports with the following
improvements. First, we pretrain the encoder with a large number of chest x-ray
images to accurately recognize 14 common radiographic observations, while
taking advantage of the multi-view images by enforcing the cross-view
consistency. Second, we synthesize multi-view visual features based on a
sentence-level attention mechanism in a late fusion fashion. In addition, in
order to enrich the decoder with descriptive semantics and enforce the
correctness of the deterministic medical-related contents such as mentions of
organs or diagnoses, we extract medical concepts based on the radiology reports
in the training data and fine-tune the encoder to extract the most frequent
medical concepts from the x-ray images. Such concepts are fused with each
decoding step by a word-level attention model. The experimental results
conducted on the Indiana University Chest X-Ray dataset demonstrate that the
proposed model achieves the state-of-the-art performance compared with other
baseline approaches.
"
2141,A Coverage-Aware Resource Provisioning Method for Network Slicing,"  With network slicing in 5G networks, Mobile Network Operators can create
various slices for Service Providers (SPs) to accommodate customized services.
Usually, the various Service Function Chains (SFCs) belonging to a slice are
deployed on a best-effort basis. Nothing ensures that the Infrastructure
Provider (InP) will be able to allocate enough resources to cope with the
increasing demands of some SP. Moreover, in many situations, slices have to be
deployed over some geographical area: coverage as well as minimum per-user rate
constraints have then to be taken into account. This paper takes the InP
perspective and proposes a slice resource provisioning approach to cope with
multiple slice demands in terms of computing, storage, coverage, and rate
constraints. The resource requirements of the various SFCs within a slice are
aggregated within a graph of Slice Resource Demands (SRD). Infrastructure nodes
and links have then to be provisioned so as to satisfy all SRDs. This problem
leads to a Mixed Integer Linear Programming formulation. A two-step approach is
considered, with several variants, depending on whether the constraints of each
slice to be provisioned are taken into account sequentially or jointly. Once
provisioning has been performed, any slice deployment strategy may be
considered on the reduced-size infrastructure graph on which resources have
been provisioned. Simulation results demonstrate the effectiveness of the
proposed approach compared to a more classical direct slice embedding approach.
"
2142,DREAMT -- Embodied Motivational Conversational Storytelling,"  Storytelling is fundamental to language, including culture, conversation and
communication in their broadest senses. It thus emerges as an essential
component of intelligent systems, including systems where natural language is
not a primary focus or where we do not usually think of a story being involved.
In this paper we explore the emergence of storytelling as a requirement in
embodied conversational agents, including its role in educational and health
interventions, as well as in a general-purpose computer interface for people
with disabilities or other constraints that prevent the use of traditional
keyboard and speech interfaces. We further present a characterization of
storytelling as an inventive fleshing out of detail according to a particular
personal perspective, and propose the DREAMT model to focus attention on the
different layers that need to be present in a character-driven storytelling
system. Most if not all aspects of the DREAMT model have arisen from or been
explored in some aspect of our implemented research systems, but currently only
at a primitive and relatively unintegrated level. However, this experience
leads us to formalize and elaborate the DREAMT model mnemonically as follows: -
Description/Dialogue/Definition/Denotation - Realization/Representation/Role -
Explanation/Education/Entertainment - Actualization/Activation -
Motivation/Modelling - Topicalization/Transformation
"
2143,"Deep Learning Approaches for Image Retrieval and Pattern Spotting in
  Ancient Documents","  This paper describes two approaches for content-based image retrieval and
pattern spotting in document images using deep learning. The first approach
uses a pre-trained CNN model to cope with the lack of training data, which is
fine-tuned to achieve a compact yet discriminant representation of queries and
image candidates. The second approach uses a Siamese Convolution Neural Network
trained on a previously prepared subset of image pairs from the ImageNet
dataset to provide the similarity-based feature maps. In both methods, the
learned representation scheme considers feature maps of different sizes which
are evaluated in terms of retrieval performance. A robust experimental protocol
using two public datasets (Tobacoo-800 and DocExplore) has shown that the
proposed methods compare favorably against state-of-the-art document image
retrieval and pattern spotting methods.
"
2144,"Understanding the Political Ideology of Legislators from Social Media
  Images","  In this paper, we seek to understand how politicians use images to express
ideological rhetoric through Facebook images posted by members of the U.S.
House and Senate. In the era of social media, politics has become saturated
with imagery, a potent and emotionally salient form of political rhetoric which
has been used by politicians and political organizations to influence public
sentiment and voting behavior for well over a century. To date, however, little
is known about how images are used as political rhetoric. Using deep learning
techniques to automatically predict Republican or Democratic party affiliation
solely from the Facebook photographs of the members of the 114th U.S. Congress,
we demonstrate that predicted class probabilities from our model function as an
accurate proxy of the political ideology of images along a left-right
(liberal-conservative) dimension. After controlling for the gender and race of
politicians, our method achieves an accuracy of 59.28% from single photographs
and 82.35% when aggregating scores from multiple photographs (up to 150) of the
same person. To better understand image content distinguishing liberal from
conservative images, we also perform in-depth content analyses of the
photographs. Our findings suggest that conservatives tend to use more images
supporting status quo political institutions and hierarchy maintenance,
featuring individuals from dominant social groups, and displaying greater
happiness than liberals.
"
2145,"Investigating Correlations of Inter-coder Agreement and Machine
  Annotation Performance for Historical Video Data","  Video indexing approaches such as visual concept classification and person
recognition are essential to enable fine-grained semantic search in large-scale
video archives such as the historical video collection of former German
Democratic Republic (GDR) maintained by the German Broadcasting Archive (DRA).
Typically, a lexicon of visual concepts has to be defined for semantic search.
However, the definition of visual concepts can be more or less subjective due
to individually differing judgments of annotators, which may have an impact on
annotation quality and subsequently training of supervised machine learning
methods. In this paper, we analyze the inter-coder agreement for historical TV
data of the former GDR for visual concept classification and person
recognition. The inter-coder agreement is evaluated for a group of expert as
well as non-expert annotators in order to determine differences in annotation
homogeneity. Furthermore, correlations between visual recognition performance
and inter-annotator agreement are measured. In this context, information about
image quantity and agreement are used to predict average precision for concept
classification. Finally, the influence of expert vs. non-expert annotations
acquired in the study are used to evaluate person recognition.
"
2146,"QRMODA and BRMODA: Novel Models for Face Recognition Accuracy in
  Computer Vision Systems with Adapted Video Streams","  A major challenge facing Computer Vision systems is providing the ability to
accurately detect threats and recognize subjects and/or objects under
dynamically changing network conditions. We propose two novel models that
characterize the face recognition accuracy in terms of video encoding
parameters. Specifically, we model the accuracy in terms of video resolution,
quantization, and actual bit rate. We validate the models using two distinct
video datasets and a large image dataset by conducting 1, 668 experiments that
involve simultaneously varying combinations of encoding parameters. We show
that both models hold true for the deep learning and statistical based face
recognition. Furthermore, we show that the models can be used to capture
different accuracy metrics, specifically the recall, precision, and F1-score.
Ultimately, we provide meaningful insights on the factors affecting the
constants of each proposed model.
"
2147,"A Color Compensation Method Using Inverse Camera Response Function for
  Multi-exposure Image Fusion","  Multi-exposure image fusion is a method for producing an image with a wide
dynamic range by fusing multiple images taken under various exposure values. In
this paper, we discuss color distortion included in fused images, and propose a
novel color compensation method for multi-exposure image fusion. In the
proposed method, an inverse camera response function (CRF) is estimated by
using multi-exposure images, and then a high dynamic range (HDR) radiance map
is recovered. The color information of the radiance map is applied to images
fused by conventional multi-exposure imaging to correct the color distortion.
The proposed method can be applied to any existing fusion approaches for
improving the quality of the fused images.
"
2148,"Outfit Compatibility Prediction and Diagnosis with Multi-Layered
  Comparison Network","  Existing works about fashion outfit compatibility focus on predicting the
overall compatibility of a set of fashion items with their information from
different modalities. However, there are few works explore how to explain the
prediction, which limits the persuasiveness and effectiveness of the model. In
this work, we propose an approach to not only predict but also diagnose the
outfit compatibility. We introduce an end-to-end framework for this goal, which
features for: (1) The overall compatibility is learned from all type-specified
pairwise similarities between items, and the backpropagation gradients are used
to diagnose the incompatible factors. (2) We leverage the hierarchy of CNN and
compare the features at different layers to take into account the
compatibilities of different aspects from the low level (such as color,
texture) to the high level (such as style). To support the proposed method, we
build a new type-specified outfit dataset named Polyvore-T based on Polyvore
dataset. We compare our method with the prior state-of-the-art in two tasks:
outfit compatibility prediction and fill-in-the-blank. Experiments show that
our approach has advantages in both prediction performance and diagnosis
ability.
"
2149,"Many could be better than all: A novel instance-oriented algorithm for
  Multi-modal Multi-label problem","  With the emergence of diverse data collection techniques, objects in real
applications can be represented as multi-modal features. What's more, objects
may have multiple semantic meanings. Multi-modal and Multi-label (MMML) problem
becomes a universal phenomenon. The quality of data collected from different
channels are inconsistent and some of them may not benefit for prediction. In
real life, not all the modalities are needed for prediction. As a result, we
propose a novel instance-oriented Multi-modal Classifier Chains (MCC) algorithm
for MMML problem, which can make convince prediction with partial modalities.
MCC extracts different modalities for different instances in the testing phase.
Extensive experiments are performed on one real-world herbs dataset and two
public datasets to validate our proposed algorithm, which reveals that it may
be better to extract many instead of all of the modalities at hand.
"
2150,"What Should I Ask? Using Conversationally Informative Rewards for
  Goal-Oriented Visual Dialog","  The ability to engage in goal-oriented conversations has allowed humans to
gain knowledge, reduce uncertainty, and perform tasks more efficiently.
Artificial agents, however, are still far behind humans in having goal-driven
conversations. In this work, we focus on the task of goal-oriented visual
dialogue, aiming to automatically generate a series of questions about an image
with a single objective. This task is challenging since these questions must
not only be consistent with a strategy to achieve a goal, but also consider the
contextual information in the image. We propose an end-to-end goal-oriented
visual dialogue system, that combines reinforcement learning with regularized
information gain. Unlike previous approaches that have been proposed for the
task, our work is motivated by the Rational Speech Act framework, which models
the process of human inquiry to reach a goal. We test the two versions of our
model on the GuessWhat?! dataset, obtaining significant results that outperform
the current state-of-the-art models in the task of generating questions to find
an undisclosed object in an image.
"
2151,ScaleTrotter: Illustrative Visual Travels Across Negative Scales,"  We present ScaleTrotter, a conceptual framework for an interactive,
multi-scale visualization of biological mesoscale data and, specifically,
genome data. ScaleTrotter allows viewers to smoothly transition from the
nucleus of a cell to the atomistic composition of the DNA, while bridging
several orders of magnitude in scale. The challenges in creating an interactive
visualization of genome data are fundamentally different in several ways from
those in other domains like astronomy that require a multi-scale representation
as well. First, genome data has intertwined scale levels---the DNA is an
extremely long, connected molecule that manifests itself at all scale levels.
Second, elements of the DNA do not disappear as one zooms out---instead the
scale levels at which they are observed group these elements differently.
Third, we have detailed information and thus geometry for the entire dataset
and for all scale levels, posing a challenge for interactive visual
exploration. Finally, the conceptual scale levels for genome data are close in
scale space, requiring us to find ways to visually embed a smaller scale into a
coarser one. We address these challenges by creating a new multi-scale
visualization concept. We use a scale-dependent camera model that controls the
visual embedding of the scales into their respective parents, the rendering of
a subset of the scale hierarchy, and the location, size, and scope of the view.
In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual
representations that are depicted in integrated visuals. We discuss,
specifically, how this form of multi-scale visualization follows from the
specific characteristics of the genome data and describe its implementation.
Finally, we discuss the implications of our work to the general illustrative
depiction of multi-scale data.
"
2152,"Deep Cross-Modal Hashing with Hashing Functions and Unified Hash Codes
  Jointly Learning","  Due to their high retrieval efficiency and low storage cost, cross-modal
hashing methods have attracted considerable attention. Generally, compared with
shallow cross-modal hashing methods, deep cross-modal hashing methods can
achieve a more satisfactory performance by integrating feature learning and
hash codes optimizing into a same framework. However, most existing deep
cross-modal hashing methods either cannot learn a unified hash code for the two
correlated data-points of different modalities in a database instance or cannot
guide the learning of unified hash codes by the feedback of hashing function
learning procedure, to enhance the retrieval accuracy. To address the issues
above, in this paper, we propose a novel end-to-end Deep Cross-Modal Hashing
with Hashing Functions and Unified Hash Codes Jointly Learning (DCHUC).
Specifically, by an iterative optimization algorithm, DCHUC jointly learns
unified hash codes for image-text pairs in a database and a pair of hash
functions for unseen query image-text pairs. With the iterative optimization
algorithm, the learned unified hash codes can be used to guide the hashing
function learning procedure; Meanwhile, the learned hashing functions can
feedback to guide the unified hash codes optimizing procedure. Extensive
experiments on three public datasets demonstrate that the proposed method
outperforms the state-of-the-art cross-modal hashing methods.
"
2153,Temporal Attentive Alignment for Large-Scale Video Domain Adaptation,"  Although various image-based domain adaptation (DA) techniques have been
proposed in recent years, domain shift in videos is still not well-explored.
Most previous works only evaluate performance on small-scale datasets which are
saturated. Therefore, we first propose two large-scale video DA datasets with
much larger domain discrepancy: UCF-HMDB_full and Kinetics-Gameplay. Second, we
investigate different DA integration methods for videos, and show that
simultaneously aligning and learning temporal dynamics achieves effective
alignment even without sophisticated DA methods. Finally, we propose Temporal
Attentive Adversarial Adaptation Network (TA3N), which explicitly attends to
the temporal dynamics using domain discrepancy for more effective domain
alignment, achieving state-of-the-art performance on four video DA datasets
(e.g. 7.9% accuracy gain over ""Source only"" from 73.9% to 81.8% on ""HMDB -->
UCF"", and 10.3% gain on ""Kinetics --> Gameplay""). The code and data are
released at http://github.com/cmhungsteve/TA3N.
"
2154,"CoachAI: A Project for Microscopic Badminton Match Data Collection and
  Tactical Analysis","  Computer vision based object tracking has been used to annotate and augment
sports video. For sports learning and training, video replay is often used in
post-match review and training review for tactical analysis and movement
analysis. For automatically and systematically competition data collection and
tactical analysis, a project called CoachAI has been supported by the Ministry
of Science and Technology, Taiwan. The proposed project also includes research
of data visualization, connected training auxiliary devices, and data
warehouse. Deep learning techniques will be used to develop video-based
real-time microscopic competition data collection based on broadcast
competition video. Machine learning techniques will be used to develop a
tactical analysis. To reveal data in more understandable forms and to help in
pre-match training, AR/VR techniques will be used to visualize data, tactics,
and so on. In addition, training auxiliary devices including smart badminton
rackets and connected serving machines will be developed based on the IoT
technology to further utilize competition data and tactical data and boost
training efficiency. Especially, the connected serving machines will be
developed to perform specified tactics and to interact with players in their
training.
"
2155,Learned Image Downscaling for Upscaling using Content Adaptive Resampler,"  Deep convolutional neural network based image super-resolution (SR) models
have shown superior performance in recovering the underlying high resolution
(HR) images from low resolution (LR) images obtained from the predefined
downscaling methods. In this paper we propose a learned image downscaling
method based on content adaptive resampler (CAR) with consideration on the
upscaling process. The proposed resampler network generates content adaptive
image resampling kernels that are applied to the original HR input to generate
pixels on the downscaled image. Moreover, a differentiable upscaling (SR)
module is employed to upscale the LR result into its underlying HR counterpart.
By back-propagating the reconstruction error down to the original HR input
across the entire framework to adjust model parameters, the proposed framework
achieves a new state-of-the-art SR performance through upscaling guided image
resamplers which adaptively preserve detailed information that is essential to
the upscaling. Experimental results indicate that the quality of the generated
LR image is comparable to that of the traditional interpolation based method,
but the significant SR performance gain is achieved by deep SR models trained
jointly with the CAR model. The code is publicly available on: URL
https://github.com/sunwj/CAR.
"
2156,"Evolutionary Algorithms and Efficient Data Analytics for Image
  Processing","  Steganography algorithms facilitate communication between a source and a
destination in a secret manner. This is done by embedding messages/text/data
into images without impacting the appearance of the resultant images/videos.
Steganalysis is the science of determining if an image has secret messages
embedded/hidden in it. Because there are numerous steganography algorithms, and
since each one of them requires a different type of steganalysis, the
steganalysis process is extremely challenging. Thus, researchers aim to develop
one universal steganalysis to detect all known and unknown steganography
algorithms, ideally in real-time. Universal steganalysis extracts a large
number of features to distinguish stego images from cover images. However, the
increase in features leads to the problem of the curse of dimensionality (CoD),
which is considered to be an NP-hard problem. This COD problem additionally
makes real-time steganalysis hard. A large number of features generates large
datasets for which machine learning cannot generate an optimal model.
Generating a machine learning based model also takes a long time which makes
real-time processing appear impossible in any optimization for time-intensive
fields such as visual computing. Possible solutions for CoD are deep learning
and evolutionary algorithms that overcome the machine learning limitations. In
this study, we investigate previously developed evolutionary algorithms for
boosting real-time image processing and argue that they provide the most
promising solutions for the CoD problem.
"
2157,EmoCo: Visual Analysis of Emotion Coherence in Presentation Videos,"  Emotions play a key role in human communication and public presentations.
Human emotions are usually expressed through multiple modalities. Therefore,
exploring multimodal emotions and their coherence is of great value for
understanding emotional expressions in presentations and improving presentation
skills. However, manually watching and studying presentation videos is often
tedious and time-consuming. There is a lack of tool support to help conduct an
efficient and in-depth multi-level analysis. Thus, in this paper, we introduce
EmoCo, an interactive visual analytics system to facilitate efficient analysis
of emotion coherence across facial, text, and audio modalities in presentation
videos. Our visualization system features a channel coherence view and a
sentence clustering view that together enable users to obtain a quick overview
of emotion coherence and its temporal evolution. In addition, a detail view and
word view enable detailed exploration and comparison from the sentence level
and word level, respectively. We thoroughly evaluate the proposed system and
visualization techniques through two usage scenarios based on TED Talk videos
and interviews with two domain experts. The results demonstrate the
effectiveness of our system in gaining insights into emotion coherence in
presentations.
"
2158,Inertial nonconvex alternating minimizations for the image deblurring,"  In image processing, Total Variation (TV) regularization models are commonly
used to recover blurred images. One of the most efficient and popular methods
to solve the convex TV problem is the Alternating Direction Method of
Multipliers (ADMM) algorithm, recently extended using the inertial proximal
point method. Although all the classical studies focus on only a convex
formulation, recent articles are paying increasing attention to the nonconvex
methodology due to its good numerical performance and properties. In this
paper, we propose to extend the classical formulation with a novel nonconvex
Alternating Direction Method of Multipliers with the Inertial technique
(IADMM). Under certain assumptions on the parameters, we prove the convergence
of the algorithm with the help of the Kurdyka-{\L}ojasiewicz property. We also
present numerical simulations on classical TV image reconstruction problems to
illustrate the efficiency of the new algorithm and its behavior compared with
the well established ADMM method.
"
2159,"Online Multi-Object Tracking Framework with the GMPHD Filter and
  Occlusion Group Management","  In this paper, we propose an efficient online multi-object tracking framework
based on the GMPHD filter and occlusion group management scheme where the GMPHD
filter utilizes hierarchical data association to reduce the false negatives
caused by miss detection. The hierarchical data association consists of two
steps: detection-to-track and track-to-track associations, which can recover
the lost tracks and their switched IDs. In addition, the proposed framework is
equipped with an object grouping management scheme which handles occlusion
problems with two main parts. The first part is ""track merging"" which can merge
the false positive tracks caused by false positive detections from occlusions,
where the false positive tracks are usually occluded with a measure. The
measure is the occlusion ratio between visual objects,
sum-of-intersection-over-area (SIOA) we defined instead of the IOU metric. The
second part is ""occlusion group energy minimization (OGEM)"" which prevents the
occluded true positive tracks from false ""track merging"". We define each group
of the occluded objects as an energy function and find an optimal hypothesis
which makes the energy minimal. We evaluate the proposed tracker in benchmark
datasets such as MOT15 and MOT17 which are built for multi-person tracking. An
ablation study in training dataset shows that not only ""track merging"" and
""OGEM"" complement each other but also the proposed tracking method has more
robust performance and less sensitive to parameters than baseline methods.
Also, SIOA works better than IOU for various sizes of false positives.
Experimental results show that the proposed tracker efficiently handles
occlusion situations and achieves competitive performance compared to the
state-of-the-art methods. Especially, our method shows the best multi-object
tracking accuracy among the online and real-time executable methods.
"
2160,Quality Assessment of In-the-Wild Videos,"  Quality assessment of in-the-wild videos is a challenging problem because of
the absence of reference videos and shooting distortions. Knowledge of the
human visual system can help establish methods for objective quality assessment
of in-the-wild videos. In this work, we show two eminent effects of the human
visual system, namely, content-dependency and temporal-memory effects, could be
used for this purpose. We propose an objective no-reference video quality
assessment method by integrating both effects into a deep neural network. For
content-dependency, we extract features from a pre-trained image classification
neural network for its inherent content-aware property. For temporal-memory
effects, long-term dependencies, especially the temporal hysteresis, are
integrated into the network with a gated recurrent unit and a
subjectively-inspired temporal pooling layer. To validate the performance of
our method, experiments are conducted on three publicly available in-the-wild
video quality assessment databases: KoNViD-1k, CVD2014, and LIVE-Qualcomm,
respectively. Experimental results demonstrate that our proposed method
outperforms five state-of-the-art methods by a large margin, specifically,
12.39%, 15.71%, 15.45%, and 18.09% overall performance improvements over the
second-best method VBLIINDS, in terms of SROCC, KROCC, PLCC and RMSE,
respectively. Moreover, the ablation study verifies the crucial role of both
the content-aware features and the modeling of temporal-memory effects. The
PyTorch implementation of our method is released at
https://github.com/lidq92/VSFA.
"
2161,Deep Video Precoding,"  Several groups are currently investigating how deep learning may advance the
state-of-the-art in image and video coding. An open question is how to make
deep neural networks work in conjunction with existing (and upcoming) video
codecs, such as MPEG AVC, HEVC, VVC, Google VP9 and AOM AV1, as well as
existing container and transport formats, without imposing any changes at the
client side. Such compatibility is a crucial aspect when it comes to practical
deployment, especially due to the fact that the video content industry and
hardware manufacturers are expected to remain committed to these standards for
the foreseeable future. We propose to use deep neural networks as precoders for
current and future video codecs and adaptive video streaming systems. In our
current design, the core precoding component comprises a cascaded structure of
downscaling neural networks that operates during video encoding, prior to
transmission. This is coupled with a precoding mode selection algorithm for
each independently-decodable stream segment, which adjusts the downscaling
factor according to scene characteristics, the utilized encoder, and the
desired bitrate and encoding configuration. Our framework is compatible with
all current and future codec and transport standards, as our deep precoding
network structure is trained in conjunction with linear upscaling filters
(e.g., the bilinear filter), which are supported by all web video players.
Results with FHD and UHD content and widely-used AVC, HEVC and VP9 encoders
show that coupling such standards with the proposed deep video precoding allows
for 15% to 45% rate reduction under encoding configurations and bitrates
suitable for video-on-demand adaptive streaming systems. The use of precoding
can also lead to encoding complexity reduction, which is essential for
cost-effective cloud deployment of complex encoders like H.265/HEVC and VP9.
"
2162,Effects of Illumination on the Categorization of Shiny Materials,"  The present research was designed to examine how patterns of illumination
influence the perceptual categorization of metal, shiny black, and shiny white
materials. The stimuli depicted three possible objects that were illuminated by
five possible HDRI light maps, which varied in their overall distributions of
illuminant directions and intensities. The surfaces included a low roughness
chrome material, a shiny black material, and a shiny white material with both
diffuse and specular components. Observers rated each stimulus by adjusting
four sliders to indicate their confidence that the depicted material was metal,
shiny black, shiny white or something else, and these adjustments were
constrained so that the sum of all four settings was always 100%. The results
revealed that the metal and shiny black categories are easily confused. For
example, metal materials with low intensity light maps or a narrow range of
illuminant directions are often judged as shiny black, whereas shiny black
materials with high intensity light maps or a wide range of illuminant
directions are often judged as metal. A spherical harmonic analysis was
performed on the different light maps in an effort to quantitatively predict
how they would bias observers' judgments of metal and shiny black surfaces.
"
2163,"Deep Learning Based Energy Disaggregation and On/Off Detection of
  Household Appliances","  Energy disaggregation, a.k.a. Non-Intrusive Load Monitoring, aims to separate
the energy consumption of individual appliances from the readings of a mains
power meter measuring the total energy consumption of, e.g. a whole house.
Energy consumption of individual appliances can be useful in many applications,
e.g., providing appliance-level feedback to the end users to help them
understand their energy consumption and ultimately save energy. Recently, with
the availability of large-scale energy consumption datasets, various neural
network models such as convolutional neural networks and recurrent neural
networks have been investigated to solve the energy disaggregation problem.
Neural network models can learn complex patterns from large amounts of data and
have been shown to outperform the traditional machine learning methods such as
variants of hidden Markov models. However, current neural network methods for
energy disaggregation are either computational expensive or are not capable of
handling long-term dependencies. In this paper, we investigate the application
of the recently developed WaveNet models for the task of energy disaggregation.
Based on a real-world energy dataset collected from 20 households over two
years, we show that WaveNet models outperforms the state-of-the-art deep
learning methods proposed in the literature for energy disaggregation in terms
of both error measures and computational cost. On the basis of energy
disaggregation, we then investigate the performance of two deep-learning based
frameworks for the task of on/off detection which aims at estimating whether an
appliance is in operation or not. Based on the same dataset, we show that for
the task of on/off detection the second framework, i.e., directly training a
binary classifier, achieves better performance in terms of F1 score.
"
2164,"Interactive Visualisation of Hierarchical Quantitative Data: An
  Evaluation","  We have compared three common visualisations for hierarchical quantitative
data, treemaps, icicle plots and sunburst charts as well as a semicircular
variant of sunburst charts we call the sundown chart. In a pilot study, we
found that the sunburst chart was least preferred. In a controlled study with
12 participants, we compared treemaps, icicle plots and sundown charts. Treemap
was the least preferred and had a slower performance on a basic navigation task
and slower performance and accuracy in hierarchy understanding tasks. The
icicle plot and sundown chart had similar performance with slight user
preference for the icicle plot.
"
2165,Image Steganography using Gaussian Markov Random Field Model,"  Recent advances on adaptive steganography show that the performance of image
steganographic communication can be improved by incorporating the non-additive
models that capture the dependences among adjacent pixels. In this paper, a
Gaussian Markov Random Field model (GMRF) with four-element cross neighborhood
is proposed to characterize the interactions among local elements of cover
images, and the problem of secure image steganography is formulated as the one
of minimization of KL-divergence in terms of a series of low-dimensional clique
structures associated with GMRF by taking advantages of the conditional
independence of GMRF. The adoption of the proposed GMRF tessellates the cover
image into two disjoint subimages, and an alternating iterative optimization
scheme is developed to effectively embed the given payload while minimizing the
total KL-divergence between cover and stego, i.e., the statistical
detectability. Experimental results demonstrate that the proposed GMRF
outperforms the prior arts of model based schemes, e.g., MiPOD, and rivals the
state-of-the-art HiLL for practical steganography, where the selection channel
knowledges are unavailable to steganalyzers.
"
2166,"An Efficient JPEG Steganographic Scheme Design Using Domain
  Transformation of Embedding Cost","  Although the recently proposed JPEG steganography using Block embedding
Entropy Transformation scheme (BET) shows excellent security performance, its
procedure is much complicate. In this paper, we intend to introduce a Block
embedding Cost Transformation (BCT) scheme for JPEG steganography. The core of
our proposed BCT is the embedding cost domain transformation function, which
comprises of the proposed distinguish factors of inter-block and intra-block,
i.e., spatial (pixel) block embedding costs and spatial (pixel) block embedding
changes, respectively. Moreover, for further maintaining the statistical
undetectability of the stego, an exponential model is then introduced to
facilitate the construction of domain transformation function. Then, the JPEG
embedding cost can be easily obtained through weighting the spatial embedding
costs by the spatial embedding changes, which discards the mediums in BET. And
following this paradigm, the spatial image steganography will be more
meaningful as well. Experimental results show that the proposed BCT has a more
comprehensive performance improvement than UERD with the same computational
complexity, and is superior to J-UNIWARD and GUED in resisting the detection of
GFR and SCA-GFR. In addition, it can also rival BET with an order of magnitude
lower computational complexity.
"
2167,"Predictive Generalized Graph Fourier Transform for Attribute Compression
  of Dynamic Point Clouds","  As 3D scanning devices and depth sensors advance, dynamic point clouds have
attracted increasing attention as a format for 3D objects in motion, with
applications in various fields such as immersive telepresence, navigation for
autonomous driving and gaming. Nevertheless, the tremendous amount of data in
dynamic point clouds significantly burden transmission and storage. To this
end, we propose a complete compression framework for attributes of 3D dynamic
point clouds, focusing on optimal inter-coding. Firstly, we derive the optimal
inter-prediction and predictive transform coding assuming the Gaussian Markov
Random Field model with respect to a spatio-temporal graph underlying the
attributes of dynamic point clouds. The optimal predictive transform proves to
be the Generalized Graph Fourier Transform in terms of spatio-temporal
decorrelation. Secondly, we propose refined motion estimation via efficient
registration prior to inter-prediction, which searches the temporal
correspondence between adjacent frames of irregular point clouds. Finally, we
present a complete framework based on the optimal inter-coding and our
previously proposed intra-coding, where we determine the optimal coding mode
from rate-distortion optimization with the proposed offline-trained $\lambda$-Q
model. Experimental results show that we achieve around 17% bit rate reduction
on average over competitive dynamic point cloud compression methods.
"
2168,Digital Watermarking of video streams: Review of the State-Of-The-Art,"  Digital Watermarking is an extremely wide aspect of information security,
either by its applications, by its properties, or by its designs. In
particular, a lot of research has been made about video watermarking and it can
make it quite difficult to put into perspective the various schemes possible in
order to implement a watermarking process for a given application. This paper
presents an in-depth overview of the current video watermarking technologies
and how they each respond to certain criteria that may be imposed by the aimed
application. The goal being in first place to be able to define the desired
equilibrium point between invisibility, robustness and efficiency for an
application. Then, given this balance, being able to deduce the best location
of the information embedding as well as the method used to embed it. The
equilibrium point is to be found using the needed properties of the watermark
and by studying the threat model that the scheme will have to face. The
location describes whether the extra information should be added to the
metadata of the video, to its frames or to specific regions of its frames.
Finally, the method to embed the watermark refers to the insertion domain and
its coefficients to be altered in order to insert the wanted information.
"
2169,Many-to-Many Geographically-Embedded Flow Visualisation: An Evaluation,"  Showing flows of people and resources between multiple geographic locations
is a challenging visualisation problem. We conducted two quantitative user
studies to evaluate different visual representations for such dense
many-to-many flows. In our first study we compared a bundled node-link flow map
representation and OD Maps [37] with a new visualisation we call MapTrix. Like
OD Maps, MapTrix overcomes the clutter associated with a traditional flow map
while providing geographic embedding that is missing in standard OD matrix
representations. We found that OD Maps and MapTrix had similar performance
while bundled node-link flow map representations did not scale at all well. Our
second study compared participant performance with OD Maps and MapTrix on
larger data sets. Again performance was remarkably similar.
"
2170,Maps and Globes in Virtual Reality,"  This paper explores different ways to render world-wide geographic maps in
virtual reality (VR). We compare: (a) a 3D exocentric globe, where the user's
viewpoint is outside the globe; (b) a flat map (rendered to a plane in VR); (c)
an egocentric 3D globe, with the viewpoint inside the globe; and (d) a curved
map, created by projecting the map onto a section of a sphere which curves
around the user. In all four visualisations the geographic centre can be
smoothly adjusted with a standard handheld VR controller and the user, through
a head-tracked headset, can physically move around the visualisation. For
distance comparison, exocentric globe is more accurate than egocentric globe
and flat map. For area comparison, more time is required with exocentric and
egocentric globes than with flat and curved maps. For direction estimation, the
exocentric globe is more accurate and faster than the other visual
presentations. Our study participants had a weak preference for the exocentric
globe. Generally, the curved map had benefits over the flat map. In almost all
cases the egocentric globe was found to be the least effective visualisation.
Overall, our results provide support for the use of exocentric globes for
geographic visualisation in mixed-reality.
"
2171,Origin-Destination Flow Maps in Immersive Environments,"  Immersive virtual- and augmented-reality headsets can overlay a flat image
against any surface or hang virtual objects in the space around the user. The
technology is rapidly improving and may, in the long term, replace traditional
flat panel displays in many situations. When displays are no longer
intrinsically flat, how should we use the space around the user for abstract
data visualisation? In this paper, we ask this question with respect to
origin-destination flow data in a global geographic context. We report on the
findings of three studies exploring different spatial encodings for flow maps.
The first experiment focuses on different 2D and 3D encodings for flows on flat
maps. We find that participants are significantly more accurate with raised
flow paths whose height is proportional to flow distance but fastest with
traditional straight line 2D flows. In our second and third experiment, we
compared flat maps, 3D globes and a novel interactive design we call MapsLink,
involving a pair of linked flat maps. We find that participants took
significantly more time with MapsLink than other flow maps while the 3D globe
with raised flows was the fastest, most accurate, and most preferred method.
Our work suggests that careful use of the third spatial dimension can resolve
visual clutter in complex flow maps.
"
2172,Aligning Linguistic Words and Visual Semantic Units for Image Captioning,"  Image captioning attempts to generate a sentence composed of several
linguistic words, which are used to describe objects, attributes, and
interactions in an image, denoted as visual semantic units in this paper. Based
on this view, we propose to explicitly model the object interactions in
semantics and geometry based on Graph Convolutional Networks (GCNs), and fully
exploit the alignment between linguistic words and visual semantic units for
image captioning. Particularly, we construct a semantic graph and a geometry
graph, where each node corresponds to a visual semantic unit, i.e., an object,
an attribute, or a semantic (geometrical) interaction between two objects.
Accordingly, the semantic (geometrical) context-aware embeddings for each unit
are obtained through the corresponding GCN learning processers. At each time
step, a context gated attention module takes as inputs the embeddings of the
visual semantic units and hierarchically align the current word with these
units by first deciding which type of visual semantic unit (object, attribute,
or interaction) the current word is about, and then finding the most correlated
visual semantic units under this type. Extensive experiments are conducted on
the challenging MS-COCO image captioning dataset, and superior results are
reported when comparing to state-of-the-art approaches.
"
2173,Comyco: Quality-Aware Adaptive Video Streaming via Imitation Learning,"  Learning-based Adaptive Bit Rate~(ABR) method, aiming to learn outstanding
strategies without any presumptions, has become one of the research hotspots
for adaptive streaming. However, it typically suffers from several issues,
i.e., low sample efficiency and lack of awareness of the video quality
information. In this paper, we propose Comyco, a video quality-aware ABR
approach that enormously improves the learning-based methods by tackling the
above issues. Comyco trains the policy via imitating expert trajectories given
by the instant solver, which can not only avoid redundant exploration but also
make better use of the collected samples. Meanwhile, Comyco attempts to pick
the chunk with higher perceptual video qualities rather than video bitrates. To
achieve this, we construct Comyco's neural network architecture, video datasets
and QoE metrics with video quality features. Using trace-driven and real-world
experiments, we demonstrate significant improvements of Comyco's sample
efficiency in comparison to prior work, with 1700x improvements in terms of the
number of samples required and 16x improvements on training time required.
Moreover, results illustrate that Comyco outperforms previously proposed
methods, with the improvements on average QoE of 7.5% - 16.79%. Especially,
Comyco also surpasses state-of-the-art approach Pensieve by 7.37% on average
video quality under the same rebuffering time.
"
2174,"Report of 2017 NSF Workshop on Multimedia Challenges, Opportunities and
  Research Roadmaps","  With the transformative technologies and the rapidly changing global R&D
landscape, the multimedia and multimodal community is now faced with many new
opportunities and uncertainties. With the open source dissemination platform
and pervasive computing resources, new research results are being discovered at
an unprecedented pace. In addition, the rapid exchange and influence of ideas
across traditional discipline boundaries have made the emphasis on multimedia
multimodal research even more important than before. To seize these
opportunities and respond to the challenges, we have organized a workshop to
specifically address and brainstorm the challenges, opportunities, and research
roadmaps for MM research. The two-day workshop, held on March 30 and 31, 2017
in Washington DC, was sponsored by the Information and Intelligent Systems
Division of the National Science Foundation of the United States. Twenty-three
(23) invited participants were asked to review and identify research areas in
the MM field that are most important over the next 10-15 year timeframe.
Important topics were selected through discussion and consensus, and then
discussed in depth in breakout groups. Breakout groups reported initial
discussion results to the whole group, who continued with further extensive
deliberation. For each identified topic, a summary was produced after the
workshop to describe the main findings, including the state of the art,
challenges, and research roadmaps planned for the next 5, 10, and 15 years in
the identified area.
"
2175,"A Robust Billboard-based Free-viewpoint Video Synthesizing Algorithm for
  Sports Scenes","  We present a billboard-based free-viewpoint video synthesizing algorithm for
sports scenes that can robustly reconstruct and render a high-fidelity
billboard model for each object, including an occluded one, in each camera. Its
contributions are (1) applicable to a challenging shooting condition where a
high precision 3D model cannot be built because a small number of cameras
featuring wide-baseline are equipped; (2) capable of reproducing appearances of
occlusions, that is one of the most significant issues for billboard-based
approaches due to the ineffective detection of overlaps. To achieve
contributions above, the proposed method does not attempt to find a
high-quality 3D model but utilizes a raw 3D model that is obtained directly
from space carving. Although the model is insufficiently accurate for producing
an impressive visual effect, precise objects segmentation and occlusions
detection can be performed by back-projecting it onto each camera plane. The
billboard model of each object in each camera is rendered according to whether
it is occluded or not, and its location in the virtual stadium is determined
considering the location of its 3D model. We synthesized free-viewpoint videos
of two soccer sequences recorded by five cameras with the proposed and
state-of-art methods to demonstrate its performance.
"
2176,"Separable Reversible Data Hiding Based on Integer Mapping and Multi-MSB
  Prediction for Encrypted 3D Mesh Models","  Reversible data hiding in encrypted domain (RDH-ED) has received tremendous
attention from the research community because data can be embedded into cover
media without exposing it to the third party data hider and the cover media can
be losslessly recovered after the extraction of the embedded data. Although, in
recent years, extensive studies have been carried out about images based
RDH-ED, little attention is paid to RDH-ED in 3D meshes due to its complex data
structure and irregular geometry. In this paper, we propose a separable RDH-ED
method for 3D meshes based on integer mapping and Multi-MSB (multiplication
most significant bit) prediction. The proposed method divides all the vertices
of the mesh into the ""embedded"" set and ""reference"" set, and maps decimals of
the vertex into integers. Then, we calculate the Multi-MSB prediction errors
for the vertices of the ""embedded"" set and a bit-stream encryption technique
will be executed. Finally, additional data is embedded by replacing the
Multi-MSB of the encrypted vertex coordinates. According to different
permissions, recipient can obtain the original plaintext meshes, additional
data or both. Experimental results show that the proposed method has higher
embedding capacity and higher quality of the recovered meshes compared to the
state-of-art methods.
"
2177,Cascaded Revision Network for Novel Object Captioning,"  Image captioning, a challenging task where the machine automatically
describes an image by sentences, has drawn significant attention in recent
years. Despite the remarkable improvements of recent approaches, however, these
methods are built upon a large set of training image-sentence pairs. The
expensive labor efforts hence limit the captioning model to describe the wider
world. In this paper, we present a novel network structure, Cascaded Revision
Network, which aims at relieving the problem by equipping the model with
out-of-domain knowledge. CRN first tries its best to describe an image using
the existing vocabulary from in-domain knowledge. Due to the lack of
out-of-domain knowledge, the caption may be inaccurate or include ambiguous
words for the image with unknown (novel) objects. We propose to re-edit the
primary captioning sentence by a series of cascaded operations. We introduce a
perplexity predictor to find out which words are most likely to be inaccurate
given the input image. Thereafter, we utilize external knowledge from a
pre-trained object detection model and select more accurate words from
detection results by the visual matching module. In the last step, we design a
semantic matching module to ensure that the novel object is fit in the right
position. By this novel cascaded captioning-revising mechanism, CRN can
accurately describe images with unseen objects. We validate the proposed method
with state-of-the-art performance on the held-out MSCOCO dataset as well as
scale to ImageNet, demonstrating the effectiveness of this method.
"
2178,"Enhancing Flood Impact Analysis using Interactive Retrieval of Social
  Media Images","  The analysis of natural disasters such as floods in a timely manner often
suffers from limited data due to a coarse distribution of sensors or sensor
failures. This limitation could be alleviated by leveraging information
contained in images of the event posted on social media platforms, so-called
""Volunteered Geographic Information (VGI)"". To save the analyst from the need
to inspect all images posted online manually, we propose to use content-based
image retrieval with the possibility of relevance feedback for retrieving only
relevant images of the event to be analyzed. To evaluate this approach, we
introduce a new dataset of 3,710 flood images, annotated by domain experts
regarding their relevance with respect to three tasks (determining the flooded
area, inundation depth, water pollution). We compare several image features and
relevance feedback methods on that dataset, mixed with 97,085 distractor
images, and are able to improve the precision among the top 100 retrieval
results from 55% with the baseline retrieval to 87% after 5 rounds of feedback.
"
2179,"Interactive Variance Attention based Online Spoiler Detection for
  Time-Sync Comments","  Nowadays, time-sync comment (TSC), a new form of interactive comments, has
become increasingly popular in Chinese video websites. By posting TSCs, people
can easily express their feelings and exchange their opinions with others when
watching online videos. However, some spoilers appear among the TSCs. These
spoilers reveal crucial plots in videos that ruin people's surprise when they
first watch the video. In this paper, we proposed a novel Similarity-Based
Network with Interactive Variance Attention (SBN-IVA) to classify comments as
spoilers or not. In this framework, we firstly extract textual features of TSCs
through the word-level attentive encoder. We design Similarity-Based Network
(SBN) to acquire neighbor and keyframe similarity according to semantic
similarity and timestamps of TSCs. Then, we implement Interactive Variance
Attention (IVA) to eliminate the impact of noise comments. Finally, we obtain
the likelihood of spoiler based on the difference between the neighbor and
keyframe similarity. Experiments show SBN-IVA is on average 11.2\% higher than
the state-of-the-art method on F1-score in baselines.
"
2180,A Benchmark of Visual Storytelling in Social Media,"  Media editors in the newsroom are constantly pressed to provide a ""like-being
there"" coverage of live events. Social media provides a disorganised collection
of images and videos that media professionals need to grasp before publishing
their latest news updated. Automated news visual storyline editing with social
media content can be very challenging, as it not only entails the task of
finding the right content but also making sure that news content evolves
coherently over time. To tackle these issues, this paper proposes a benchmark
for assessing social media visual storylines. The SocialStories benchmark,
comprised by total of 40 curated stories covering sports and cultural events,
provides the experimental setup and introduces novel quantitative metrics to
perform a rigorous evaluation of visual storytelling with social media data.
"
2181,Recent Advances in Deep Learning for Object Detection,"  Object detection is a fundamental visual recognition problem in computer
vision and has been widely studied in the past decades. Visual object detection
aims to find objects of certain target classes with precise localization in a
given image and assign each object instance a corresponding class label. Due to
the tremendous successes of deep learning based image classification, object
detection techniques using deep learning have been actively studied in recent
years. In this paper, we give a comprehensive survey of recent advances in
visual object detection with deep learning. By reviewing a large body of recent
related work in literature, we systematically analyze the existing object
detection frameworks and organize the survey into three major parts: (i)
detection components, (ii) learning strategies, and (iii) applications &
benchmarks. In the survey, we cover a variety of factors affecting the
detection performance in detail, such as detector architectures, feature
learning, proposal generation, sampling strategies, etc. Finally, we discuss
several future directions to facilitate and spur future research for visual
object detection with deep learning. Keywords: Object Detection, Deep Learning,
Deep Convolutional Neural Networks
"
2182,"Deep Triplet Neural Networks with Cluster-CCA for Audio-Visual
  Cross-modal Retrieval","  Cross-modal retrieval aims to retrieve data in one modality by a query in
another modality, which has been avery interesting research issue in the filed
of multimedia, information retrieval, and computer vision, anddatabase. Most
existing works focus on cross-modal retrieval between text-image, text-video,
and lyrics-audio.little research addresses cross-modal retrieval between audio
and video due to limited audio-video paireddataset and semantic information.
The main challenge of audio-visual cross-modal retrieval task focuses on
learning joint embeddings from a shared subspace for computing the similarity
across different modalities, were generating new representations is to maximize
the correlation between audio and visual modalities space. In this work, we
propose a novel deep triplet neural network with cluster-based canonical
correlationanalysis (TNN-C-CCA), which is an end-to-end supervised learning
architecture with audio branch and videobranch. we not only consider the
matching pairs in the common space but also compute the mismatching pairs when
maximizing the correlation. In particular, two significant contributions are
made in this work: i) abetter representation by constructing deep triplet
neural network with triplet loss for optimal projections canbe generated to
maximize correlation in the shared subspace. ii) positive examples and negative
examplesare used in the learning stage to improve the capability of embedding
learning between audio and video. Our experiment is run over 5-fold
cross-validation, where average performance is applied to demonstratethe
performance of audio-video cross-modal retrieval. The experimental results
achieved on two different audio-visual datasets show the proposed learning
architecture with two branches outperforms the state-of-art cross-modal
retrieval methods.
"
2183,Personalized Music Recommendation with Triplet Network,"  Since many online music services emerged in recent years so that effective
music recommendation systems are desirable. Some common problems in
recommendation system like feature representations, distance measure and cold
start problems are also challenges for music recommendation. In this paper, I
proposed a triplet neural network, exploiting both positive and negative
samples to learn the representation and distance measure between users and
items, to solve the recommendation task.
"
2184,"Audio-Visual Embedding for Cross-Modal MusicVideo Retrieval through
  Supervised Deep CCA","  Deep learning has successfully shown excellent performance in learning joint
representations between different data modalities. Unfortunately, little
research focuses on cross-modal correlation learning where temporal structures
of different data modalities, such as audio and video, should be taken into
account. Music video retrieval by given musical audio is a natural way to
search and interact with music contents. In this work, we study cross-modal
music video retrieval in terms of emotion similarity. Particularly, audio of an
arbitrary length is used to retrieve a longer or full-length music video. To
this end, we propose a novel audio-visual embedding algorithm by Supervised
Deep CanonicalCorrelation Analysis (S-DCCA) that projects audio and video into
a shared space to bridge the semantic gap between audio and video. This also
preserves the similarity between audio and visual contents from different
videos with the same class label and the temporal structure. The contribution
of our approach is mainly manifested in the two aspects: i) We propose to
select top k audio chunks by attention-based Long Short-Term Memory
(LSTM)model, which can represent good audio summarization with local
properties. ii) We propose an end-to-end deep model for cross-modal
audio-visual learning where S-DCCA is trained to learn the semantic correlation
between audio and visual modalities. Due to the lack of music video dataset, we
construct 10K music video dataset from YouTube 8M dataset. Some promising
results such as MAP and precision-recall show that our proposed model can be
applied to music video retrieval.
"
2185,"Exploiting Temporal Relationships in Video Moment Localization with
  Natural Language","  We address the problem of video moment localization with natural language,
i.e. localizing a video segment described by a natural language sentence. While
most prior work focuses on grounding the query as a whole, temporal
dependencies and reasoning between events within the text are not fully
considered. In this paper, we propose a novel Temporal Compositional Modular
Network (TCMN) where a tree attention network first automatically decomposes a
sentence into three descriptions with respect to the main event, context event
and temporal signal. Two modules are then utilized to measure the visual
similarity and location similarity between each segment and the decomposed
descriptions. Moreover, since the main event and context event may rely on
different modalities (RGB or optical flow), we use late fusion to form an
ensemble of four models, where each model is independently trained by one
combination of the visual input. Experiments show that our model outperforms
the state-of-the-art methods on the TEMPO dataset.
"
2186,Emotion Dependent Facial Animation from Affective Speech,"  In human-to-computer interaction, facial animation in synchrony with
affective speech can deliver more naturalistic conversational agents. In this
paper, we present a two-stage deep learning approach for affective speech
driven facial shape animation. In the first stage, we classify affective speech
into seven emotion categories. In the second stage, we train separate deep
estimators within each emotion category to synthesize facial shape from the
affective speech. Objective and subjective evaluations are performed over the
SAVEE dataset. The proposed emotion dependent facial shape model performs
better in terms of the Mean Squared Error (MSE) loss and in generating the
landmark animations, as compared to training a universal model regardless of
the emotion.
"
2187,Automatic Fashion Knowledge Extraction from Social Media,"  Fashion knowledge plays a pivotal role in helping people in their dressing.
In this paper, we present a novel system to automatically harvest fashion
knowledge from social media. It unifies three tasks of occasion, person and
clothing discovery from multiple modalities of images, texts and metadata. A
contextualized fashion concept learning model is applied to leverage the rich
contextual information for improving the fashion concept learning performance.
At the same time, to counter the label noise within training data, we employ a
weak label modeling method to further boost the performance. We build a website
to demonstrate the quality of fashion knowledge extracted by our system.
"
2188,SIP Server Load Balancing Based on SDN,"  Session Initiation Protocol (SIP) grows for VoIP applications, and faces
challenges including security and overload. On the other hand, the new concept
of Software-defined Networking (SDN) has made great changes in the networked
world. SDN is the idea of separating the control plane from the network
infrastructure that can bring several benefits. We used this idea to provide a
new architecture for SIP networks. Moreover, for the load distribution
challenge in these networks, a framework based on SDN was offered, in which the
load balancing and network management can be easily done by a central
controller considering the network status. Unlike the traditional methods, in
this framework, there is no need to change the infrastructures like SIP servers
or SIP load balancer to implement the distribution method. Also, several types
of load distribution algorithms can be performed as software in the controller.
We were able to achieve the desired results by simulating the three methods
based on the proposed framework in Mininet.
"
2189,Super-resolution of Omnidirectional Images Using Adversarial Learning,"  An omnidirectional image (ODI) enables viewers to look in every direction
from a fixed point through a head-mounted display providing an immersive
experience compared to that of a standard image. Designing immersive virtual
reality systems with ODIs is challenging as they require high resolution
content. In this paper, we study super-resolution for ODIs and propose an
improved generative adversarial network based model which is optimized to
handle the artifacts obtained in the spherical observational space.
Specifically, we propose to use a fast PatchGAN discriminator, as it needs
fewer parameters and improves the super-resolution at a fine scale. We also
explore the generative models with adversarial learning by introducing a
spherical-content specific loss function, called 360-SS. To train and test the
performance of our proposed model we prepare a dataset of 4500 ODIs. Our
results demonstrate the efficacy of the proposed method and identify new
challenges in ODI super-resolution for future investigations.
"
2190,Exploiting Multi-domain Visual Information for Fake News Detection,"  The increasing popularity of social media promotes the proliferation of fake
news. With the development of multimedia technology, fake news attempts to
utilize multimedia contents with images or videos to attract and mislead
readers for rapid dissemination, which makes visual contents an important part
of fake news. Fake-news images, images attached in fake news posts,include not
only fake images which are maliciously tampered but also real images which are
wrongly used to represent irrelevant events. Hence, how to fully exploit the
inherent characteristics of fake-news images is an important but challenging
problem for fake news detection. In the real world, fake-news images may have
significantly different characteristics from real-news images at both physical
and semantic levels, which can be clearly reflected in the frequency and pixel
domain, respectively. Therefore, we propose a novel framework Multi-domain
Visual Neural Network (MVNN) to fuse the visual information of frequency and
pixel domains for detecting fake news. Specifically, we design a CNN-based
network to automatically capture the complex patterns of fake-news images in
the frequency domain; and utilize a multi-branch CNN-RNN model to extract
visual features from different semantic levels in the pixel domain. An
attention mechanism is utilized to fuse the feature representations of
frequency and pixel domains dynamically. Extensive experiments conducted on a
real-world dataset demonstrate that MVNN outperforms existing methods with at
least 9.2% in accuracy, and can help improve the performance of multimodal fake
news detection by over 5.2%.
"
2191,"daBNN: A Super Fast Inference Framework for Binary Neural Networks on
  ARM devices","  It is always well believed that Binary Neural Networks (BNNs) could
drastically accelerate the inference efficiency by replacing the arithmetic
operations in float-valued Deep Neural Networks (DNNs) with bit-wise
operations. Nevertheless, there has not been open-source implementation in
support of this idea on low-end ARM devices (e.g., mobile phones and embedded
devices). In this work, we propose daBNN --- a super fast inference framework
that implements BNNs on ARM devices. Several speed-up and memory refinement
strategies for bit-packing, binarized convolution, and memory layout are
uniquely devised to enhance inference efficiency. Compared to the recent
open-source BNN inference framework, BMXNet, our daBNN is
$7\times$$\sim$$23\times$ faster on a single binary convolution, and about
$6\times$ faster on Bi-Real Net 18 (a BNN variant of ResNet-18). The daBNN is a
BSD-licensed inference framework, and its source code, sample projects and
pre-trained models are available on-line: https://github.com/JDAI-CV/dabnn.
"
2192,Context-Aware Emotion Recognition Networks,"  Traditional techniques for emotion recognition have focused on the facial
expression analysis only, thus providing limited ability to encode context that
comprehensively represents the emotional responses. We present deep networks
for context-aware emotion recognition, called CAER-Net, that exploit not only
human facial expression but also context information in a joint and boosting
manner. The key idea is to hide human faces in a visual scene and seek other
contexts based on an attention mechanism. Our networks consist of two
sub-networks, including two-stream encoding networks to seperately extract the
features of face and context regions, and adaptive fusion networks to fuse such
features in an adaptive fashion. We also introduce a novel benchmark for
context-aware emotion recognition, called CAER, that is more appropriate than
existing benchmarks both qualitatively and quantitatively. On several
benchmarks, CAER-Net proves the effect of context for emotion recognition. Our
dataset is available at http://caer-dataset.github.io.
"
2193,"Adaptive Embedding Pattern for Grayscale-Invariance Reversible Data
  Hiding","  In traditional reversible data hiding (RDH) methods, researchers pay
attention to enlarge the embedding capacity (EC) and to reduce the embedding
distortion (ED). Recently, a completely novel RDH algorithm was developed to
embed secret data into color image without changing the corresponding grayscale
[1], which largely expands the applications of RDH. In [1], for color image,
channel R and channel B are exploited to carry secret information, channel G is
adjusted for balancing the modifications of channel R and channel B to keep the
invariance of grayscale. However, we found that the embedding performance (EP)
of that method is still unsatisfied and could be further enhanced. To improve
the EP, an adaptive embedding pattern is introduced to enhance the competence
of algorithm for selectively embedding different bits of secret data into
pixels according to context information. Moreover, a novel two-level predictor
is designed by uniting two normal predictors for reducing the ED for embedding
more bits. Experimental results demonstrate that, compared to the previous
method, our scheme could significantly enhance the image fidelity while keeping
the grayscale invariant.
"
2194,"FiFTy: Large-scale File Fragment Type Identification using Neural
  Networks","  We present FiFTy, a modern file type identification tool for memory forensics
and data carving. In contrast to previous approaches based on hand-crafted
features, we design a compact neural network architecture, which uses a
trainable embedding space, akin to successful natural language processing
models. Our approach dispenses with explicit feature extraction which is a
bottleneck in legacy systems. We evaluate the proposed method on a novel
dataset with 75 file types - the most diverse and balanced dataset reported to
date. FiFTy consistently outperforms all baselines in terms of speed, accuracy
and individual misclassification rates. We achieved an average accuracy of
77.5% with processing speed of approx 38 sec/GB, which is better and more than
an order of magnitude faster than the previous state-of-the-art tool - Sceadan
(69% at 9 min/GB). Our tool and the corresponding dataset are available
publicly online.
"
2195,"Impacts of Retina-related Zones on Quality Perception of Omnidirectional
  Image","  Virtual Reality (VR), which brings immersive experiences to viewers, has been
gaining popularity in recent years. A key feature in VR systems is the use of
omnidirectional content, which provides 360-degree views of scenes. In this
work, we study the human quality perception of omnidirectional images, focusing
on different zones surrounding the foveation point. For that purpose, an
extensive subjective experiment is carried out to assess the perceptual quality
of omnidirectional images with non-uniform quality. Through experimental
results, the impacts of different zones are analyzed. Moreover, nineteen
objective quality metrics, including foveal quality metrics, are evaluated
using our database. It is quantitatively shown that the zones corresponding to
the fovea and parafovea of human eyes are extremely important for quality
perception, while the impacts of the other zones corresponding to the perifovea
and periphery are small. Besides, the investigated metrics are found to be not
effective enough to reflect the quality perceived by viewers.
"
2196,"No-Reference Light Field Image Quality Assessment Based on
  Spatial-Angular Measurement","  Light field image quality assessment (LFI-QA) is a significant and
challenging research problem. It helps to better guide light field acquisition,
processing and applications. However, only a few objective models have been
proposed and none of them completely consider intrinsic factors affecting the
LFI quality. In this paper, we propose a No-Reference Light Field image Quality
Assessment (NR-LFQA) scheme, where the main idea is to quantify the LFI quality
degradation through evaluating the spatial quality and angular consistency. We
first measure the spatial quality deterioration by capturing the naturalness
distribution of the light field cyclopean image array, which is formed when
human observes the LFI. Then, as a transformed representation of LFI, the
Epipolar Plane Image (EPI) contains the slopes of lines and involves the
angular information. Therefore, EPI is utilized to extract the global and local
features from LFI to measure angular consistency degradation. Specifically, the
distribution of gradient direction map of EPI is proposed to measure the global
angular consistency distortion in the LFI. We further propose the weighted
local binary pattern to capture the characteristics of local angular
consistency degradation. Extensive experimental results on four publicly
available LFI quality datasets demonstrate that the proposed method outperforms
state-of-the-art 2D, 3D, multi-view, and LFI quality assessment algorithms.
"
2197,Towards Generating Ambisonics Using Audio-Visual Cue for Virtual Reality,"  Ambisonics i.e., a full-sphere surround sound, is quintessential with
360-degree visual content to provide a realistic virtual reality (VR)
experience. While 360-degree visual content capture gained a tremendous boost
recently, the estimation of corresponding spatial sound is still challenging
due to the required sound-field microphones or information about the
sound-source locations. In this paper, we introduce a novel problem of
generating Ambisonics in 360-degree videos using the audio-visual cue. With
this aim, firstly, a novel 360-degree audio-visual video dataset of 265 videos
is introduced with annotated sound-source locations. Secondly, a pipeline is
designed for an automatic Ambisonic estimation problem. Benefiting from the
deep learning-based audio-visual feature-embedding and prediction modules, our
pipeline estimates the 3D sound-source locations and further use such locations
to encode to the B-format. To benchmark our dataset and pipeline, we
additionally propose evaluation criteria to investigate the performance using
different 360-degree input representations. Our results demonstrate the
efficacy of the proposed pipeline and open up a new area of research in
360-degree audio-visual analysis for future investigations.
"
2198,Prosodic Phrase Alignment for Machine Dubbing,"  Dubbing is a type of audiovisual translation where dialogues are translated
and enacted so that they give the impression that the media is in the target
language. It requires a careful alignment of dubbed recordings with the lip
movements of performers in order to achieve visual coherence. In this paper, we
deal with the specific problem of prosodic phrase synchronization within the
framework of machine dubbing. Our methodology exploits the attention mechanism
output in neural machine translation to find plausible phrasing for the
translated dialogue lines and then uses them to condition their synthesis. Our
initial work in this field records comparable speech rate ratio to professional
dubbing translation, and improvement in terms of lip-syncing of long dialogue
lines.
"
2199,Learning Joint Embedding for Cross-Modal Retrieval,"  A cross-modal retrieval process is to use a query in one modality to obtain
relevant data in another modality. The challenging issue of cross-modal
retrieval lies in bridging the heterogeneous gap for similarity computation,
which has been broadly discussed in image-text, audio-text, and video-text
cross-modal multimedia data mining and retrieval. However, the gap in temporal
structures of different data modalities is not well addressed due to the lack
of alignment relationship between temporal cross-modal structures. Our research
focuses on learning the correlation between different modalities for the task
of cross-modal retrieval. We have proposed an architecture: Supervised-Deep
Canonical Correlation Analysis (S-DCCA), for cross-modal retrieval. In this
forum paper, we will talk about how to exploit triplet neural networks (TNN) to
enhance the correlation learning for cross-modal retrieval. The experimental
result shows the proposed TNN-based supervised correlation learning
architecture can get the best result when the data representation extracted by
supervised learning.
"
2200,"Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video
  Translation","  In this paper, we investigate the problem of unpaired video-to-video
translation. Given a video in the source domain, we aim to learn the
conditional distribution of the corresponding video in the target domain,
without seeing any pairs of corresponding videos. While significant progress
has been made in the unpaired translation of images, directly applying these
methods to an input video leads to low visual quality due to the additional
time dimension. In particular, previous methods suffer from semantic
inconsistency (i.e., semantic label flipping) and temporal flickering
artifacts. To alleviate these issues, we propose a new framework that is
composed of carefully-designed generators and discriminators, coupled with two
core objective functions: 1) content preserving loss and 2) temporal
consistency loss. Extensive qualitative and quantitative evaluations
demonstrate the superior performance of the proposed method against previous
approaches. We further apply our framework to a domain adaptation task and
achieve favorable results.
"
2201,User Diverse Preference Modeling by Multimodal Attentive Metric Learning,"  Most existing recommender systems represent a user's preference with a
feature vector, which is assumed to be fixed when predicting this user's
preferences for different items. However, the same vector cannot accurately
capture a user's varying preferences on all items, especially when considering
the diverse characteristics of various items. To tackle this problem, in this
paper, we propose a novel Multimodal Attentive Metric Learning (MAML) method to
model user diverse preferences for various items. In particular, for each
user-item pair, we propose an attention neural network, which exploits the
item's multimodal features to estimate the user's special attention to
different aspects of this item. The obtained attention is then integrated into
a metric-based learning method to predict the user preference on this item. The
advantage of metric learning is that it can naturally overcome the problem of
dot product similarity, which is adopted by matrix factorization (MF) based
recommendation models but does not satisfy the triangle inequality property. In
addition, it is worth mentioning that the attention mechanism cannot only help
model user's diverse preferences towards different items, but also overcome the
geometrically restrictive problem caused by collaborative metric learning.
Extensive experiments on large-scale real-world datasets show that our model
can substantially outperform the state-of-the-art baselines, demonstrating the
potential of modeling user diverse preference for recommendation.
"
2202,Improving Captioning for Low-Resource Languages by Cycle Consistency,"  Improving the captioning performance on low-resource languages by leveraging
English caption datasets has received increasing research interest in recent
years. Existing works mainly fall into two categories: translation-based and
alignment-based approaches. In this paper, we propose to combine the merits of
both approaches in one unified architecture. Specifically, we use a pre-trained
English caption model to generate high-quality English captions, and then take
both the image and generated English captions to generate low-resource language
captions. We improve the captioning performance by adding the cycle consistency
constraint on the cycle of image regions, English words, and low-resource
language words. Moreover, our architecture has a flexible design which enables
it to benefit from large monolingual English caption datasets. Experimental
results demonstrate that our approach outperforms the state-of-the-art methods
on common evaluation metrics. The attention visualization also shows that the
proposed approach really improves the fine-grained alignment between words and
image regions.
"
2203,ColorNet -- Estimating Colorfulness in Natural Images,"  Measuring the colorfulness of a natural or virtual scene is critical for many
applications in image processing field ranging from capturing to display. In
this paper, we propose the first deep learning-based colorfulness estimation
metric. For this purpose, we develop a color rating model which simultaneously
learns to extracts the pertinent characteristic color features and the mapping
from feature space to the ideal colorfulness scores for a variety of natural
colored images. Additionally, we propose to overcome the lack of adequate
annotated dataset problem by combining/aligning two publicly available
colorfulness databases using the results of a new subjective test which employs
a common subset of both databases. Using the obtained subjectively annotated
dataset with 180 colored images, we finally demonstrate the efficacy of our
proposed model over the traditional methods, both quantitatively and
qualitatively.
"
2204,"Who, Where, and What to Wear? Extracting Fashion Knowledge from Social
  Media","  Fashion knowledge helps people to dress properly and addresses not only
physiological needs of users, but also the demands of social activities and
conventions. It usually involves three mutually related aspects of: occasion,
person and clothing. However, there are few works focusing on extracting such
knowledge, which will greatly benefit many downstream applications, such as
fashion recommendation. In this paper, we propose a novel method to
automatically harvest fashion knowledge from social media. We unify three tasks
of occasion, person and clothing discovery from multiple modalities of images,
texts and metadata. For person detection and analysis, we use the off-the-shelf
tools due to their flexibility and satisfactory performance. For clothing
recognition and occasion prediction, we unify the two tasks by using a
contextualized fashion concept learning module, which captures the dependencies
and correlations among different fashion concepts. To alleviate the heavy
burden of human annotations, we introduce a weak label modeling module which
can effectively exploit machine-labeled data, a complementary of clean data. In
experiments, we contribute a benchmark dataset and conduct extensive
experiments from both quantitative and qualitative perspectives. The results
demonstrate the effectiveness of our model in fashion concept prediction, and
the usefulness of extracted knowledge with comprehensive analysis.
"
2205,"Kinesthetic Learning -- Haptic User Interfaces for Gyroscopic Precession
  Simulation","  Some forces in nature are difficult to comprehend due to their non-intuitive
and abstract nature. Forces driving gyroscopic precession are invisible, yet
their effect is very important in a variety of applications, from space
navigation to motion tracking. Current technological advancements in haptic
interfaces, enables development of revolutionary user interfaces, combining
multiple modalities: tactile, visual and auditory. Tactile augmented user
interfaces have been deployed in a variety of areas, from surgical training to
elementary education. This research provides an overview of haptic user
interfaces in higher education, and presents the development and assessment of
a haptic-user interface that supports the learner's understanding of gyroscopic
precession forces. The visual-haptic simulator proposed, is one module from a
series of simulators targeted at complex concept representation, using
multi-modal user interfaces. Various higher education domains, from classical
physics to mechanical engineering, will benefit from the mainstream adoption of
multi-modal interfaces for hands-on training and content delivery. Experimental
results are promising, and underline the valuable impact that haptic user
interfaces have on enabling abstract concepts understanding, through
kinesthetic learning and hands-on practice.
"
2206,Mocycle-GAN: Unpaired Video-to-Video Translation,"  Unsupervised image-to-image translation is the task of translating an image
from one domain to another in the absence of any paired training examples and
tends to be more applicable to practical applications. Nevertheless, the
extension of such synthesis from image-to-image to video-to-video is not
trivial especially when capturing spatio-temporal structures in videos. The
difficulty originates from the aspect that not only the visual appearance in
each frame but also motion between consecutive frames should be realistic and
consistent across transformation. This motivates us to explore both appearance
structure and temporal continuity in video synthesis. In this paper, we present
a new Motion-guided Cycle GAN, dubbed as Mocycle-GAN, that novelly integrates
motion estimation into unpaired video translator. Technically, Mocycle-GAN
capitalizes on three types of constrains: adversarial constraint discriminating
between synthetic and real frame, cycle consistency encouraging an inverse
translation on both frame and motion, and motion translation validating the
transfer of motion between consecutive frames. Extensive experiments are
conducted on video-to-labels and labels-to-video translation, and superior
results are reported when comparing to state-of-the-art methods. More
remarkably, we qualitatively demonstrate our Mocycle-GAN for both
flower-to-flower and ambient condition transfer.
"
2207,Confidence Regularized Self-Training,"  Recent advances in domain adaptation show that deep self-training presents a
powerful means for unsupervised domain adaptation. These methods often involve
an iterative process of predicting on target domain and then taking the
confident predictions as pseudo-labels for retraining. However, since
pseudo-labels can be noisy, self-training can put overconfident label belief on
wrong classes, leading to deviated solutions with propagated errors. To address
the problem, we propose a confidence regularized self-training (CRST)
framework, formulated as regularized self-training. Our method treats
pseudo-labels as continuous latent variables jointly optimized via alternating
optimization. We propose two types of confidence regularization: label
regularization (LR) and model regularization (MR). CRST-LR generates soft
pseudo-labels while CRST-MR encourages the smoothness on network output.
Extensive experiments on image classification and semantic segmentation show
that CRSTs outperform their non-regularized counterpart with state-of-the-art
performance. The code and models of this work are available at
https://github.com/yzou2/CRST.
"
2208,Personalized Hashtag Recommendation for Micro-videos,"  Personalized hashtag recommendation methods aim to suggest users hashtags to
annotate, categorize, and describe their posts. The hashtags, that a user
provides to a post (e.g., a micro-video), are the ones which in her mind can
well describe the post content where she is interested in. It means that we
should consider both users' preferences on the post contents and their personal
understanding on the hashtags. Most existing methods rely on modeling either
the interactions between hashtags and posts or the interactions between users
and hashtags for hashtag recommendation. These methods have not well explored
the complicated interactions among users, hashtags, and micro-videos. In this
paper, towards the personalized micro-video hashtag recommendation, we propose
a Graph Convolution Network based Personalized Hashtag Recommendation (GCN-PHR)
model, which leverages recently advanced GCN techniques to model the complicate
interactions among <users, hashtags, micro-videos> and learn their
representations. In our model, the users, hashtags, and micro-videos are three
types of nodes in a graph and they are linked based on their direct
associations. In particular, the message-passing strategy is used to learn the
representation of a node (e.g., user) by aggregating the message passed from
the directly linked other types of nodes (e.g., hashtag and micro-video).
Because a user is often only interested in certain parts of a micro-video and a
hashtag is typically used to describe the part (of a micro-video) that the user
is interested in, we leverage the attention mechanism to filter the message
passed from micro-videos to users and hashtags, which can significantly improve
the representation capability. Extensive experiments have been conducted on two
real-world micro-video datasets and demonstrate that our model outperforms the
state-of-the-art approaches by a large margin.
"
2209,"A Comparative Study of Younger and Older Adults' Interaction with a
  Crowdsourcing Android TV App for Detecting Errors in TEDx Video Subtitles","  In this paper we report the results of a pilot study comparing the older and
younger adults' interaction with an Android TV application which enables users
to detect errors in video subtitles. Overall, the interaction with the
TV-mediated crowdsourcing system relying on language profficiency was seen as
intuitive, fun and accessible, but also cognitively demanding; more so for
younger adults who focused on the task of detecting errors, than for older
adults who concentrated more on the meaning and edutainment aspect of the
videos. We also discuss participants' motivations and preliminary
recommendations for the design of TV-enabled crowdsourcing tasks and subtitle
QA systems.
"
2210,"Quality Assessment of Stereoscopic 360-degree Images from
  Multi-viewports","  Objective quality assessment of stereoscopic panoramic images becomes a
challenging problem owing to the rapid growth of 360-degree contents. Different
from traditional 2D image quality assessment (IQA), more complex aspects are
involved in 3D omnidirectional IQA, especially unlimited field of view (FoV)
and extra depth perception, which brings difficulty to evaluate the quality of
experience (QoE) of 3D omnidirectional images. In this paper, we propose a
multi-viewport based fullreference stereo 360 IQA model. Due to the freely
changeable viewports when browsing in the head-mounted display (HMD), our
proposed approach processes the image inside FoV rather than the projected one
such as equirectangular projection (ERP). In addition, since overall QoE
depends on both image quality and depth perception, we utilize the features
estimated by the difference map between left and right views which can reflect
disparity. The depth perception features along with binocular image qualities
are employed to further predict the overall QoE of 3D 360 images. The
experimental results on our public Stereoscopic OmnidirectionaL Image quality
assessment Database (SOLID) show that the proposed method achieves a
significant improvement over some well-known IQA metrics and can accurately
reflect the overall QoE of perceived images.
"
2211,"No-Reference Light Field Image Quality Assessment Based on Micro-Lens
  Image","  Light field image quality assessment (LF-IQA) plays a significant role due to
its guidance to Light Field (LF) contents acquisition, processing and
application. The LF can be represented as 4-D signal, and its quality depends
on both angular consistency and spatial quality. However, few existing LF-IQA
methods concentrate on effects caused by angular inconsistency. Especially,
no-reference methods lack effective utilization of 2-D angular information. In
this paper, we focus on measuring the 2-D angular consistency for LF-IQA. The
Micro-Lens Image (MLI) refers to the angular domain of the LF image, which can
simultaneously record the angular information in both horizontal and vertical
directions. Since the MLI contains 2-D angular information, we propose a
No-Reference Light Field image Quality assessment model based on MLI (LF-QMLI).
Specifically, we first utilize Global Entropy Distribution (GED) and Uniform
Local Binary Pattern descriptor (ULBP) to extract features from the MLI, and
then pool them together to measure angular consistency. In addition, the
information entropy of Sub-Aperture Image (SAI) is adopted to measure spatial
quality. Extensive experimental results show that LF-QMLI achieves the
state-of-the-art performance.
"
2212,False News Detection on Social Media,"  Social media has become a major information platform where people consume and
share news. However, it has also enabled the wide dissemination of false news,
i.e., news posts published on social media that are verifiably false, causing
significant negative effects on society. In order to help prevent further
propagation of false news on social media, we set up this competition to
motivate the development of automated real-time false news detection
approaches. Specifically, this competition includes three sub-tasks: false-news
text detection, false-news image detection and false-news multi-modal
detetcion, which aims to motivate participants to further explore the
efficiency of multiple modalities in detecting false news and reasonable fusion
approaches of multi-modal contents. To better support this competition, we also
construct and publicize a multi-modal data repository about False News on Weibo
Social platform(MCG-FNeWS}) to help evaluate the performance of different
approaches from participants.
"
2213,"A steganographic approach based on the chaotic fractional map and in the
  DCT domain","  A steganographic method based on the chaotic fractional map and in the DCT
domain is proposed. This method embeds a secret message in some high frequency
coefficients of the image using a 128-bit private key and a chaotic fractional
map which generate a permutation indicating the positions where the secret bits
will be embedded. An experimental work on the validation of the proposed method
is also presented, showing performance in imperceptibility, quality, similarity
and security analysis of the steganographic system. The proposed algorithm
improved the level of imperceptibility and Cachin's security of stego-system
analyzed through the values of Peak Signal-to-Noise Ratio (PSNR) and the
Relative Entropy (RE).
"
2214,On Energy Compaction of 2D Saab Image Transforms,"  The block Discrete Cosine Transform (DCT) is commonly used in image and video
compression due to its good energy compaction property. The Saab transform was
recently proposed as an effective signal transform for image understanding. In
this work, we study the energy compaction property of the Saab transform in the
context of intra-coding of the High Efficiency Video Coding (HEVC) standard. We
compare the energy compaction property of the Saab transform, the DCT, and the
Karhunen-Loeve transform (KLT) by applying them to different sizes of
intra-predicted residual blocks in HEVC. The basis functions of the Saab
transform are visualized. Extensive experimental results are given to
demonstrate the energy compaction capability of the Saab transform.
"
2215,A Robust Image Watermarking System Based on Deep Neural Networks,"  Digital image watermarking is the process of embedding and extracting
watermark covertly on a carrier image. Incorporating deep learning networks
with image watermarking has attracted increasing attention during recent years.
However, existing deep learning-based watermarking systems cannot achieve
robustness, blindness, and automated embedding and extraction simultaneously.
In this paper, a fully automated image watermarking system based on deep neural
networks is proposed to generalize the image watermarking processes. An
unsupervised deep learning structure and a novel loss computation are proposed
to achieve high capacity and high robustness without any prior knowledge of
possible attacks. Furthermore, a challenging application of watermark
extraction from camera-captured images is provided to validate the practicality
as well as the robustness of the proposed system. Experimental results show the
superiority performance of the proposed system as comparing against several
currently available techniques.
"
2216,UGC-VIDEO: perceptual quality assessment of user-generated videos,"  Recent years have witnessed an ever-expandingvolume of user-generated content
(UGC) videos available on the Internet. Nevertheless, progress on perceptual
quality assessmentof UGC videos still remains quite limited. There are many
distinguished characteristics of UGC videos in the complete video production
and delivery chain, and one important property closely relevant to video
quality is that there does not exist the pristine source after they are
uploaded to the hosting platform,such that they often undergo multiple
compression stages before ultimately viewed. To facilitate the UGC video
quality assessment,we created a UGC video perceptual quality assessment
database. It contains 50 source videos collected from TikTok with diverse
content, along with multiple distortion versions generated bythe compression
with different quantization levels and coding standards. Subjective quality
assessment was conducted to evaluate the video quality. Furthermore, we
benchmark the database using existing quality assessment algorithms, and
potential roomis observed to future improve the accuracy of UGC video quality
measures.
"
2217,Generating Persuasive Visual Storylines for Promotional Videos,"  Video contents have become a critical tool for promoting products in
E-commerce. However, the lack of automatic promotional video generation
solutions makes large-scale video-based promotion campaigns infeasible. The
first step of automatically producing promotional videos is to generate visual
storylines, which is to select the building block footage and place them in an
appropriate order. This task is related to the subjective viewing experience.
It is hitherto performed by human experts and thus, hard to scale. To address
this problem, we propose WundtBackpack, an algorithmic approach to generate
storylines based on available visual materials, which can be video clips or
images. It consists of two main parts, 1) the Learnable Wundt Curve to evaluate
the perceived persuasiveness based on the stimulus intensity of a sequence of
visual materials, which only requires a small volume of data to train; and 2) a
clustering-based backpacking algorithm to generate persuasive sequences of
visual materials while considering video length constraints. In this way, the
proposed approach provides a dynamic structure to empower artificial
intelligence (AI) to organize video footage in order to construct a sequence of
visual stimuli with persuasive power. Extensive real-world experiments show
that our approach achieves close to 10% higher perceived persuasiveness scores
by human testers, and 12.5% higher expected revenue compared to the best
performing state-of-the-art approach.
"
2218,VISIR: Visual and Semantic Image Label Refinement,"  The social media explosion has populated the Internet with a wealth of
images. There are two existing paradigms for image retrieval: 1) content-based
image retrieval (CBIR), which has traditionally used visual features for
similarity search (e.g., SIFT features), and 2) tag-based image retrieval
(TBIR), which has relied on user tagging (e.g., Flickr tags). CBIR now gains
semantic expressiveness by advances in deep-learning-based detection of visual
labels. TBIR benefits from query-and-click logs to automatically infer more
informative labels. However, learning-based tagging still yields noisy labels
and is restricted to concrete objects, missing out on generalizations and
abstractions. Click-based tagging is limited to terms that appear in the
textual context of an image or in queries that lead to a click. This paper
addresses the above limitations by semantically refining and expanding the
labels suggested by learning-based object detection. We consider the semantic
coherence between the labels for different objects, leverage lexical and
commonsense knowledge, and cast the label assignment into a constrained
optimization problem solved by an integer linear program. Experiments show that
our method, called VISIR, improves the quality of the state-of-the-art visual
labeling tools like LSDA and YOLO.
"
2219,Graph-based Transforms for Video Coding,"  In many state-of-the-art compression systems, signal transformation is an
integral part of the encoding and decoding process, where transforms provide
compact representations for the signals of interest. This paper introduces a
class of transforms called graph-based transforms (GBTs) for video compression,
and proposes two different techniques to design GBTs. In the first technique,
we formulate an optimization problem to learn graphs from data and provide
solutions for optimal separable and nonseparable GBT designs, called GL-GBTs.
The optimality of the proposed GL-GBTs is also theoretically analyzed based on
Gaussian-Markov random field (GMRF) models for intra and inter predicted block
signals. The second technique develops edge-adaptive GBTs (EA-GBTs) in order to
flexibly adapt transforms to block signals with image edges (discontinuities).
The advantages of EA-GBTs are both theoretically and empirically demonstrated.
Our experimental results demonstrate that the proposed transforms can
significantly outperform the traditional Karhunen-Loeve transform (KLT).
"
2220,Embedding Symbolic Knowledge into Deep Networks,"  In this work, we aim to leverage prior symbolic knowledge to improve the
performance of deep models. We propose a graph embedding network that projects
propositional formulae (and assignments) onto a manifold via an augmented Graph
Convolutional Network (GCN). To generate semantically-faithful embeddings, we
develop techniques to recognize node heterogeneity, and semantic regularization
that incorporate structural constraints into the embedding. Experiments show
that our approach improves the performance of models trained to perform
entailment checking and visual relation prediction. Interestingly, we observe a
connection between the tractability of the propositional theory representation
and the ease of embedding. Future exploration of this connection may elucidate
the relationship between knowledge compilation and vector representation
learning.
"
2221,Robust Invisible Video Watermarking with Attention,"  The goal of video watermarking is to embed a message within a video file in a
way such that it minimally impacts the viewing experience but can be recovered
even if the video is redistributed and modified, allowing media producers to
assert ownership over their content. This paper presents RivaGAN, a novel
architecture for robust video watermarking which features a custom
attention-based mechanism for embedding arbitrary data as well as two
independent adversarial networks which critique the video quality and optimize
for robustness. Using this technique, we are able to achieve state-of-the-art
results in deep learning-based video watermarking and produce watermarked
videos which have minimal visual distortion and are robust against common video
processing operations.
"
2222,"Binocular Rivalry Oriented Predictive Auto-Encoding Network for Blind
  Stereoscopic Image Quality Measurement","  Stereoscopic image quality measurement (SIQM) has become increasingly
important for guiding stereo image processing and commutation systems due to
the widespread usage of 3D contents. Compared with conventional methods which
are relied on hand-crafted features, deep learning oriented measurements have
achieved remarkable performance in recent years. However, most existing deep
SIQM evaluators are not specifically built for stereoscopic contents and
consider little prior domain knowledge of the 3D human visual system (HVS) in
network design. In this paper, we develop a Predictive Auto-encoDing Network
(PAD-Net) for blind/No-Reference stereoscopic image quality measurement. In the
first stage, inspired by the predictive coding theory that the cognition system
tries to match bottom-up visual signal with top-down predictions, we adopt the
encoder-decoder architecture to reconstruct the distorted inputs. Besides,
motivated by the binocular rivalry phenomenon, we leverage the likelihood and
prior maps generated from the predictive coding process in the Siamese
framework for assisting SIQM. In the second stage, quality regression network
is applied to the fusion image for acquiring the perceptual quality prediction.
The performance of PAD-Net has been extensively evaluated on three benchmark
databases and the superiority has been well validated on both symmetrically and
asymmetrically distorted stereoscopic images under various distortion types.
"
2223,"Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis","  The Visual Question Answering (VQA) task combines challenges for processing
data with both Visual and Linguistic processing, to answer basic `common sense'
questions about given images. Given an image and a question in natural
language, the VQA system tries to find the correct answer to it using visual
elements of the image and inference gathered from textual questions. In this
survey, we cover and discuss the recent datasets released in the VQA domain
dealing with various types of question-formats and enabling robustness of the
machine-learning models. Next, we discuss about new deep learning models that
have shown promising results over the VQA datasets. At the end, we present and
discuss some of the results computed by us over the vanilla VQA models, Stacked
Attention Network and the VQA Challenge 2017 winner model. We also provide the
detailed analysis along with the challenges and future research directions.
"
2224,Depth Map Estimation for Free-Viewpoint Television,"  The paper presents a new method of depth estimation dedicated for
free-viewpoint television (FTV). The estimation is performed for segments and
thus their size can be used to control a trade-off between the quality of depth
maps and the processing time of their estimation. The proposed algorithm can
take as its input multiple arbitrarily positioned views which are
simultaneously used to produce multiple inter view consistent output depth
maps. The presented depth estimation method uses novel parallelization and
temporal consistency enhancement methods that significantly reduce the
processing time of depth estimation. An experimental assessment of the
proposals has been performed, based on the analysis of virtual view quality in
FTV. The results show that the proposed method provides an improvement of the
depth map quality over the state of-the-art method, simultaneously reducing the
complexity of depth estimation. The consistency of depth maps, which is crucial
for the quality of the synthesized video and thus the quality of experience of
navigating through a 3D scene, is also vastly improved.
"
2225,Tensor Oriented No-Reference Light Field Image Quality Assessment,"  Light field image (LFI) quality assessment is becoming more and more
important, which helps to better guide the acquisition, processing and
application of immersive media. However, due to the inherent high dimensional
characteristics of LFI, the LFI quality assessment turns into a
multi-dimensional problem that requires consideration of the quality
degradation in both spatial and angular dimensions. Therefore, we propose a
novel Tensor oriented No-reference Light Field image Quality evaluator
(Tensor-NLFQ) based on tensor theory. Specifically, since the LFI is regarded
as a low-rank 4D tensor, the principle components of four oriented sub-aperture
view stacks are obtained via Tucker decomposition. Then, the Principal
Component Spatial Characteristic (PCSC) is designed to measure the
spatial-dimensional quality of LFI considering its global naturalness and local
frequency properties. Finally, the Tensor Angular Variation Index (TAVI) is
proposed to measure angular consistency quality by analyzing the structural
similarity distribution between the first principal component and each view in
the view stack. Extensive experimental results on four publicly available LFI
quality databases demonstrate that the proposed Tensor-NLFQ model outperforms
state-of-the-art 2D, 3D, multi-view, and LFI quality assessment algorithms.
"
2226,"Remembering Winter Was Coming: Character-Oriented Video Summaries of TV
  Series","  Today's popular TV series tend to develop continuous, complex plots spanning
several seasons, but are often viewed in controlled and discontinuous
conditions. Consequently, most viewers need to be re-immersed in the story
before watching a new season. Although discussions with friends and family can
help, we observe that most viewers make extensive use of summaries to re-engage
with the plot. Automatic generation of video summaries of TV series' complex
stories requires, first, modeling the dynamics of the plot and, second,
extracting relevant sequences. In this paper, we tackle plot modeling by
considering the social network of interactions between the characters involved
in the narrative: substantial, durable changes in a major character's social
environment suggest a new development relevant for the summary. Once
identified, these major stages in each character's storyline can be used as a
basis for completing the summary with related sequences. Our algorithm combines
such social network analysis with filmmaking grammar to automatically generate
character-oriented video summaries of TV series from partially annotated data.
We carry out evaluation with a user study in a real-world scenario: a large
sample of viewers were asked to rank video summaries centered on five
characters of the popular TV series Game of Thrones, a few weeks before the
new, sixth season was released. Our results reveal the ability of
character-oriented summaries to re-engage viewers in television series and
confirm the contributions of modeling the plot content and exploiting stylistic
patterns to identify salient sequences.
"
2227,Cumulative Quality Modeling for HTTP Adaptive Streaming,"  Thanks to the abundance of Web platforms and broadband connections, HTTP
Adaptive Streaming has become the de facto choice for multimedia delivery
nowadays. However, the visual quality of adaptive video streaming may fluctuate
strongly during a session due to bandwidth fluctuations. So, it is important to
evaluate the quality of a streaming session over time. In this paper, we
propose a model to estimate the cumulative quality for HTTP Adaptive Streaming.
In the model, a sliding window of video segments is employed as the basic
building block. Through statistical analysis using a subjective dataset, we
identify three important components of the cumulative quality model, namely the
minimum window quality, the last window quality, and the average window
quality. Experiment results show that the proposed model achieves high
prediction performance and outperforms related quality models. In addition,
another advantage of the proposed model is its simplicity and effectiveness for
deployment in real-time estimation. The source code of the proposed model has
been made available to the public at https://github.com/TranHuyen1191/CQM.
"
2228,Hit Ratio Driven Mobile Edge Caching Scheme for Video on Demand Services,"  More and more scholars focus on mobile edge computing (MEC) technology,
because the strong storage and computing capabilities of MEC servers can reduce
the long transmission delay, bandwidth waste, energy consumption, and privacy
leaks in the data transmission process. In this paper, we study the cache
placement problem to determine how to cache videos and which videos to be
cached in a mobile edge computing system. First, we derive the video request
probability by taking into account video popularity, user preference and the
characteristic of video representations. Second, based on the acquired request
probability, we formulate a cache placement problem with the objective to
maximize the cache hit ratio subject to the storage capacity constraints.
Finally, in order to solve the formulated problem, we transform it into a
grouping knapsack problem and develop a dynamic programming algorithm to obtain
the optimal caching strategy. Simulation results show that the proposed
algorithm can greatly improve the cache hit ratio.
"
2229,Deep Metric Learning with Density Adaptivity,"  The problem of distance metric learning is mostly considered from the
perspective of learning an embedding space, where the distances between pairs
of examples are in correspondence with a similarity metric. With the rise and
success of Convolutional Neural Networks (CNN), deep metric learning (DML)
involves training a network to learn a nonlinear transformation to the
embedding space. Existing DML approaches often express the supervision through
maximizing inter-class distance and minimizing intra-class variation. However,
the results can suffer from overfitting problem, especially when the training
examples of each class are embedded together tightly and the density of each
class is very high. In this paper, we integrate density, i.e., the measure of
data concentration in the representation, into the optimization of DML
frameworks to adaptively balance inter-class similarity and intra-class
variation by training the architecture in an end-to-end manner. Technically,
the knowledge of density is employed as a regularizer, which is pluggable to
any DML architecture with different objective functions such as contrastive
loss, N-pair loss and triplet loss. Extensive experiments on three public
datasets consistently demonstrate clear improvements by amending three types of
embedding with the density adaptivity. More remarkably, our proposal increases
Recall@1 from 67.95% to 77.62%, from 52.01% to 55.64% and from 68.20% to 70.56%
on Cars196, CUB-200-2011 and Stanford Online Products dataset, respectively.
"
2230,General Fragment Model for Information Artifacts,"  The use of semantic descriptions in data intensive domains require a
systematic model for linking semantic descriptions with their manifestations in
fragments of heterogeneous information and data objects. Such information
heterogeneity requires a fragment model that is general enough to support the
specification of anchors from conceptual models to multiple types of
information artifacts. While diverse proposals of anchoring models exist in the
literature, they are usually focused in audiovisual information. We propose a
generalized fragment model that can be instantiated to different kinds of
information artifacts. Our objective is to systematize the way in which
fragments and anchors can be described in conceptual models, without committing
to a specific vocabulary.
"
2231,Generalized Score Distribution,"  A class of discrete probability distributions contains distributions with
limited support, i.e. possible argument values are limited to a set of numbers
(typically consecutive). Examples of such data are results from subjective
experiments utilizing the Absolute Category Rating (ACR) technique, where
possible answers (argument values) are $\{1, 2, \cdots, 5\}$ or typical Likert
scale $\{-3, -2, \cdots, 3\}$. An interesting subclass of those distributions
are distributions limited to two parameters: describing the mean value and the
spread of the answers, and having no more than one change in the probability
monotonicity. In this paper we propose a general distribution passing those
limitations called Generalized Score Distribution (GSD). The proposed GSD
covers all spreads of the answers, from very small, given by the Bernoulli
distribution, to the maximum given by a Beta Binomial distribution. We also
show that GSD correctly describes subjective experiments scores from video
quality evaluations with probability of 99.7\%. A Google Collaboratory website
with implementation of the GSD estimation, simulation, and visualization is
provided.
"
2232,Camera Fingerprint Extraction via Spatial Domain Averaged Frames,"  Photo Response Non-Uniformity (PRNU) based camera attribution is an effective
method to determine the source camera of visual media (an image or a video). To
apply this method, images or videos need to be obtained from a camera to create
a ""camera fingerprint"" which then can be compared against the PRNU of the query
media whose origin is under question. The fingerprint extraction process can be
time-consuming when a large number of video frames or images have to be
denoised. This may need to be done when the individual images have been
subjected to high compression or other geometric processing such as video
stabilization. This paper investigates a simple, yet effective and efficient
technique to create a camera fingerprint when so many still images need to be
denoised. The technique utilizes Spatial Domain Averaged (SDA) frames. An
SDA-frame is the arithmetic mean of multiple still images. When it is used for
fingerprint extraction, the number of denoising operations can be significantly
decreased with little or no performance loss. Experimental results show that
the proposed method can work more than 50 times faster than conventional
methods while providing similar matching results.
"
2233,"Image Steganography: Protection of Digital Properties against
  Eavesdropping","  Steganography is the art of hiding the fact that communication is taking
place, by hiding information in other information. Different types of carrier
file formats can be used, but digital images are the most popular ones because
of their frequency on the internet. For hiding secret information in images,
there exists a large variety of steganography techniques. Some are more complex
than others and all of them have respective strong and weak points. Many
applications may require absolute invisibility of the secret information. This
paper intends to give an overview of image steganography, it's usage and
techniques, basically, to store the confidential information within images such
as details of working strategy, secret missions, criminal and confidential
information in various organizations that work for the national security such
as army, police, FBI, secret service etc. We develop a desktop application that
incorporates Advanced Encryption Standard for encryption of the original
message, and Spatially Desynchronized Steganography Algorithm for hiding the
text file inside the image.
"
2234,Probabilistic framework for solving Visual Dialog,"  In this paper, we propose a probabilistic framework for solving the task of
`Visual Dialog'. Solving this task requires reasoning and understanding of
visual modality, language modality, and common sense knowledge to answer.
Various architectures have been proposed to solve this task by variants of
multi-modal deep learning techniques that combine visual and language
representations. However, we believe that it is crucial to understand and
analyze the sources of uncertainty for solving this task. Our approach allows
for estimating uncertainty and also aids a diverse generation of answers. The
proposed approach is obtained through a probabilistic representation module
that provides us with representations for image, question and conversation
history, a module that ensures that diverse latent representations for
candidate answers are obtained given the probabilistic representations and an
uncertainty representation module that chooses the appropriate answer that
minimizes uncertainty. We thoroughly evaluate the model with a detailed
ablation analysis, comparison with state of the art and visualization of the
uncertainty that aids in the understanding of the method. Using the proposed
probabilistic framework, we thus obtain an improved visual dialog system that
is also more explainable.
"
2235,"Correlation-based Initialization Algorithm for Tensor-based HSI
  Compression Methods","  Tensor decomposition (TD) is widely used in hyperspectral image (HSI)
compression. The initialization of factor matrix in tensor decomposition can
determine the HSI compression performance. It is worth noting that HSI is
highly correlated in bands. However, this phenomenon is ignored by the previous
TD method. Aiming at improving the HSI compression performance, we propose a
method called correlation-based TD initialization algorithm. As HSI is well
approximated by means of a reference band. In accordance with the SVD result of
the reference band, the initialized factor matrices of TD are produced. We
compare our methods with random and SVD-based initialization methods. The
experimental results reveal that our correlation-based TD initialization method
is capable of significantly reducing the computational cost of TD while keeping
the initialization quality and compression performance.
"
2236,"Faster and Accurate Classification for JPEG2000 Compressed Images in
  Networked Applications","  JPEG2000 (j2k) is a highly popular format for image and video
compression.With the rapidly growing applications of cloud based image
classification, most existing j2k-compatible schemes would stream compressed
color images from the source before reconstruction at the processing center as
inputs to deep CNNs. We propose to remove the computationally costly
reconstruction step by training a deep CNN image classifier using the CDF 9/7
Discrete Wavelet Transformed (DWT) coefficients directly extracted from
j2k-compressed images. We demonstrate additional computation savings by
utilizing shallower CNN to achieve classification of good accuracy in the DWT
domain. Furthermore, we show that traditional augmentation transforms such as
flipping/shifting are ineffective in the DWT domain and present different
augmentation transformations to achieve more accurate classification without
any additional cost. This way, faster and more accurate classification is
possible for j2k encoded images without image reconstruction. Through
experiments on CIFAR-10 and Tiny ImageNet data sets, we show that the
performance of the proposed solution is consistent for image transmission over
limited channel bandwidth.
"
2237,"PDANet: Polarity-consistent Deep Attention Network for Fine-grained
  Visual Emotion Regression","  Existing methods on visual emotion analysis mainly focus on coarse-grained
emotion classification, i.e. assigning an image with a dominant discrete
emotion category. However, these methods cannot well reflect the complexity and
subtlety of emotions. In this paper, we study the fine-grained regression
problem of visual emotions based on convolutional neural networks (CNNs).
Specifically, we develop a Polarity-consistent Deep Attention Network (PDANet),
a novel network architecture that integrates attention into a CNN with an
emotion polarity constraint. First, we propose to incorporate both spatial and
channel-wise attentions into a CNN for visual emotion regression, which jointly
considers the local spatial connectivity patterns along each channel and the
interdependency between different channels. Second, we design a novel
regression loss, i.e. polarity-consistent regression (PCR) loss, based on the
weakly supervised emotion polarity to guide the attention generation. By
optimizing the PCR loss, PDANet can generate a polarity preserved attention map
and thus improve the emotion regression performance. Extensive experiments are
conducted on the IAPS, NAPS, and EMOTIC datasets, and the results demonstrate
that the proposed PDANet outperforms the state-of-the-art approaches by a large
margin for fine-grained visual emotion regression. Our source code is released
at: https://github.com/ZizhouJia/PDANet.
"
2238,BasketballGAN: Generating Basketball Play Simulation Through Sketching,"  We present a data-driven basketball set play simulation. Given an offensive
set play sketch, our method simulates potential scenarios that may occur in the
game. The simulation provides coaches and players with insights on how a given
set play can be executed. To achieve the goal, we train a conditional
adversarial network on NBA movement data to imitate the behaviors of how
players move around the court through two major components: a generator that
learns to generate natural player movements based on a latent noise and a user
sketched set play; and a discriminator that is used to evaluate the realism of
the basketball play. To improve the quality of simulation, we minimize 1.) a
dribbler loss to prevent the ball from drifting away from the dribbler; 2.) a
defender loss to prevent the dribbler from not being defended; 3.) a ball
passing loss to ensure the straightness of passing trajectories; and 4) an
acceleration loss to minimize unnecessary players' movements. To evaluate our
system, we objectively compared real and simulated basketball set plays.
Besides, a subjective test was conducted to judge whether a set play was real
or generated by our network. On average, the mean correct rates to the binary
tests were 56.17 \%. Experiment results and the evaluations demonstrated the
effectiveness of our system.
"
2239,"Data-Efficient Classification of Birdcall Through Convolutional Neural
  Networks Transfer Learning","  Deep learning Convolutional Neural Network (CNN) models are powerful
classification models but require a large amount of training data. In niche
domains such as bird acoustics, it is expensive and difficult to obtain a large
number of training samples. One method of classifying data with a limited
number of training samples is to employ transfer learning. In this research, we
evaluated the effectiveness of birdcall classification using transfer learning
from a larger base dataset (2814 samples in 46 classes) to a smaller target
dataset (351 samples in 10 classes) using the ResNet-50 CNN. We obtained 79%
average validation accuracy on the target dataset in 5-fold cross-validation.
The methodology of transfer learning from an ImageNet-trained CNN to a
project-specific and a much smaller set of classes and images was extended to
the domain of spectrogram images, where the base dataset effectively played the
role of the ImageNet.
"
2240,Enhancing JPEG Steganography using Iterative Adversarial Examples,"  Convolutional Neural Networks (CNN) based methods have significantly improved
the performance of image steganalysis compared with conventional ones based on
hand-crafted features. However, many existing literatures on computer vision
have pointed out that those effective CNN-based methods can be easily fooled by
adversarial examples. In this paper, we propose a novel steganography framework
based on adversarial example in an iterative manner. The proposed framework
first starts from an existing embedding cost, such as J-UNIWARD in this work,
and then updates the cost iteratively based on adversarial examples derived
from a series of steganalytic networks until achieving satisfactory results. We
carefully analyze two important factors that would affect the security
performance of the proposed framework, i.e. the percentage of selected
gradients with larger amplitude and the adversarial intensity to modify
embedding cost. The experimental results evaluated on three modern steganalytic
models, including GFR, SCA-GFR and SRNet, show that the proposed framework is
very promising to enhance the security performances of JPEG steganography.
"
2241,Alleviating Feature Confusion for Generative Zero-shot Learning,"  Lately, generative adversarial networks (GANs) have been successfully applied
to zero-shot learning (ZSL) and achieved state-of-the-art performance. By
synthesizing virtual unseen visual features, GAN-based methods convert the
challenging ZSL task into a supervised learning problem. However, GAN-based ZSL
methods have to train the generator on the seen categories and further apply it
to unseen instances. An inevitable issue of such a paradigm is that the
synthesized unseen features are prone to seen references and incapable to
reflect the novelty and diversity of real unseen instances. In a nutshell, the
synthesized features are confusing. One cannot tell unseen categories from seen
ones using the synthesized features. As a result, the synthesized features are
too subtle to be classified in generalized zero-shot learning (GZSL) which
involves both seen and unseen categories at the test stage. In this paper, we
first introduce the feature confusion issue. Then, we propose a new feature
generating network, named alleviating feature confusion GAN (AFC-GAN), to
challenge the issue. Specifically, we present a boundary loss which maximizes
the decision boundary of seen categories and unseen ones. Furthermore, a novel
metric named feature confusion score (FCS) is proposed to quantify the feature
confusion. Extensive experiments on five widely used datasets verify that our
method is able to outperform previous state-of-the-arts under both ZSL and GZSL
protocols.
"
2242,Cycle-consistent Conditional Adversarial Transfer Networks,"  Domain adaptation investigates the problem of cross-domain knowledge transfer
where the labeled source domain and unlabeled target domain have distinctive
data distributions. Recently, adversarial training have been successfully
applied to domain adaptation and achieved state-of-the-art performance.
However, there is still a fatal weakness existing in current adversarial models
which is raised from the equilibrium challenge of adversarial training.
Specifically, although most of existing methods are able to confuse the domain
discriminator, they cannot guarantee that the source domain and target domain
are sufficiently similar. In this paper, we propose a novel approach named {\it
cycle-consistent conditional adversarial transfer networks} (3CATN) to handle
this issue. Our approach takes care of the domain alignment by leveraging
adversarial training. Specifically, we condition the adversarial networks with
the cross-covariance of learned features and classifier predictions to capture
the multimodal structures of data distributions. However, since the classifier
predictions are not certainty information, a strong condition with the
predictions is risky when the predictions are not accurate. We, therefore,
further propose that the truly domain-invariant features should be able to be
translated from one domain to the other. To this end, we introduce two feature
translation losses and one cycle-consistent loss into the conditional
adversarial domain adaptation networks. Extensive experiments on both classical
and large-scale datasets verify that our model is able to outperform previous
state-of-the-arts with significant improvements.
"
2243,Multi-Task Music Representation Learning from Multi-Label Embeddings,"  This paper presents a novel approach to music representation learning.
Triplet loss based networks have become popular for representation learning in
various multimedia retrieval domains. Yet, one of the most crucial parts of
this approach is the appropriate selection of triplets, which is indispensable,
considering that the number of possible triplets grows cubically. We present an
approach to harness multi-tag annotations for triplet selection, by using
Latent Semantic Indexing to project the tags onto a high-dimensional space.
From this we estimate tag-relatedness to select hard triplets. The approach is
evaluated in a multi-task scenario for which we introduce four large multi-tag
annotations for the Million Song Dataset for the music properties genres,
styles, moods, and themes.
"
2244,"ICDAR 2019 Competition on Large-scale Street View Text with Partial
  Labeling -- RRC-LSVT","  Robust text reading from street view images provides valuable information for
various applications. Performance improvement of existing methods in such a
challenging scenario heavily relies on the amount of fully annotated training
data, which is costly and in-efficient to obtain. To scale up the amount of
training data while keeping the labeling procedure cost-effective, this
competition introduces a new challenge on Large-scale Street View Text with
Partial Labeling (LSVT), providing 50, 000 and 400, 000 images in full and weak
annotations, respectively. This competition aims to explore the abilities of
state-of-the-art methods to detect and recognize text instances from
large-scale street view images, closing the gap between research benchmarks and
real applications. During the competition period, a total of 41 teams
participated in the two proposed tasks with 132 valid submissions, i.e., text
detection and end-to-end text spotting. This paper includes dataset
descriptions, task definitions, evaluation protocols and results summaries of
the ICDAR 2019-LSVT challenge.
"
2245,"Chinese Street View Text: Large-scale Chinese Text Reading with
  Partially Supervised Learning","  Most existing text reading benchmarks make it difficult to evaluate the
performance of more advanced deep learning models in large vocabularies due to
the limited amount of training data. To address this issue, we introduce a new
large-scale text reading benchmark dataset named Chinese Street View Text
(C-SVT) with 430,000 street view images, which is at least 14 times as large as
the existing Chinese text reading benchmarks. To recognize Chinese text in the
wild while keeping large-scale datasets labeling cost-effective, we propose to
annotate one part of the CSVT dataset (30,000 images) in locations and text
labels as full annotations and add 400,000 more images, where only the
corresponding text-of-interest in the regions is given as weak annotations. To
exploit the rich information from the weakly annotated data, we design a text
reading network in a partially supervised learning framework, which enables to
localize and recognize text, learn from fully and weakly annotated data
simultaneously. To localize the best matched text proposals from weakly labeled
images, we propose an online proposal matching module incorporated in the whole
model, spotting the keyword regions by sharing parameters for end-to-end
training. Compared with fully supervised training algorithms, this model can
improve the end-to-end recognition performance remarkably by 4.03% in F-score
at the same labeling cost. The proposed model can also achieve state-of-the-art
results on the ICDAR 2017-RCTW dataset, which demonstrates the effectiveness of
the proposed partially supervised learning framework.
"
2246,AdaCompress: Adaptive Compression for Online Computer Vision Services,"  With the growth of computer vision based applications and services, an
explosive amount of images have been uploaded to cloud servers which host such
computer vision algorithms, usually in the form of deep learning models. JPEG
has been used as the {\em de facto} compression and encapsulation method before
one uploads the images, due to its wide adaptation. However, standard JPEG
configuration does not always perform well for compressing images that are to
be processed by a deep learning model, e.g., the standard quality level of JPEG
leads to 50\% of size overhead (compared with the best quality level selection)
on ImageNet under the same inference accuracy in popular computer vision models
including InceptionNet, ResNet, etc. Knowing this, designing a better JPEG
configuration for online computer vision services is still extremely
challenging: 1) Cloud-based computer vision models are usually a black box to
end-users; thus it is difficult to design JPEG configuration without knowing
their model structures. 2) JPEG configuration has to change when different
users use it. In this paper, we propose a reinforcement learning based JPEG
configuration framework. In particular, we design an agent that adaptively
chooses the compression level according to the input image's features and
backend deep learning models. Then we train the agent in a reinforcement
learning way to adapt it for different deep learning cloud services that act as
the {\em interactive training environment} and feeding a reward with
comprehensive consideration of accuracy and data size. In our real-world
evaluation on Amazon Rekognition, Face++ and Baidu Vision, our approach can
reduce the size of images by 1/2 -- 1/3 while the overall classification
accuracy only decreases slightly.
"
2247,"Multi-user Augmented Reality Application for Video Communication in
  Virtual Space","  Communication is the most useful tool to impart knowledge, understand ideas,
clarify thoughts and expressions, organize plan and manage every single
day-to-day activity. Although there are different modes of communication,
physical barrier always affects the clarity of the message due to the absence
of body language and facial expressions. These barriers are overcome by video
calling, which is technically the most advance mode of communication at
present. The proposed work concentrates around the concept of video calling in
a more natural and seamless way using Augmented Reality (AR). AR can be helpful
in giving the users an experience of physical presence in each other's
environment. Our work provides an entirely new platform for video calling,
wherein the users can enjoy the privilege of their own virtual space to
interact with the individual's environment. Moreover, there is no limitation of
sharing the same screen space. Any number of participants can be accommodated
over a single conference without having to compromise the screen size.
"
2248,Gradual Network for Single Image De-raining,"  Most advances in single image de-raining meet a key challenge, which is
removing rain streaks with different scales and shapes while preserving image
details. Existing single image de-raining approaches treat rain-streak removal
as a process of pixel-wise regression directly. However, they are lacking in
mining the balance between over-de-raining (e.g. removing texture details in
rain-free regions) and under-de-raining (e.g. leaving rain streaks). In this
paper, we firstly propose a coarse-to-fine network called Gradual Network
(GraNet) consisting of coarse stage and fine stage for delving into single
image de-raining with different granularities. Specifically, to reveal
coarse-grained rain-streak characteristics (e.g. long and thick rain
streaks/raindrops), we propose a coarse stage by utilizing local-global spatial
dependencies via a local-global subnetwork composed of region-aware blocks.
Taking the residual result (the coarse de-rained result) between the rainy
image sample (i.e. the input data) and the output of coarse stage (i.e. the
learnt rain mask) as input, the fine stage continues to de-rain by removing the
fine-grained rain streaks (e.g. light rain streaks and water mist) to get a
rain-free and well-reconstructed output image via a unified contextual merging
sub-network with dense blocks and a merging block. Solid and comprehensive
experiments on synthetic and real data demonstrate that our GraNet can
significantly outperform the state-of-the-art methods by removing rain streaks
with various densities, scales and shapes while keeping the image details of
rain-free regions well-preserved.
"
2249,"CANZSL: Cycle-Consistent Adversarial Networks for Zero-Shot Learning
  from Natural Language","  Existing methods using generative adversarial approaches for Zero-Shot
Learning (ZSL) aim to generate realistic visual features from class semantics
by a single generative network, which is highly under-constrained. As a result,
the previous methods cannot guarantee that the generated visual features can
truthfully reflect the corresponding semantics. To address this issue, we
propose a novel method named Cycle-consistent Adversarial Networks for
Zero-Shot Learning (CANZSL). It encourages a visual feature generator to
synthesize realistic visual features from semantics, and then inversely
translate back synthesized the visual feature to corresponding semantic space
by a semantic feature generator. Furthermore, in this paper a more challenging
and practical ZSL problem is considered where the original semantics are from
natural language with irrelevant words instead of clean semantics that are
widely used in previous work. Specifically, a multi-modal consistent
bidirectional generative adversarial network is trained to handle unseen
instances by leveraging noise in the natural language. A forward one-to-many
mapping from one text description to multiple visual features is coupled with
an inverse many-to-one mapping from the visual space to the semantic space.
Thus, a multi-modal cycle-consistency loss between the synthesized semantic
representations and the ground truth can be learned and leveraged to enforce
the generated semantic features to approximate to the real distribution in
semantic space. Extensive experiments are conducted to demonstrate that our
method consistently outperforms state-of-the-art approaches on natural
language-based zero-shot learning tasks.
"
2250,"sZoom: A Framework for Automatic Zoom into High Resolution Surveillance
  Videos","  Current cameras are capable of recording high resolution video. While viewing
on a mobile device, a user can manually zoom into this high resolution video to
get more detailed view of objects and activities. However, manual zooming is
not suitable for surveillance and monitoring. It is tiring to continuously keep
zooming into various regions of the video. Also, while viewing one region, the
operator may miss activities in other regions. In this paper, we propose sZoom,
a framework to automatically zoom into a high resolution surveillance video.
The proposed framework selectively zooms into the sensitive regions of the
video to present details of the scene, while still preserving the overall
context required for situation assessment. A multi-variate Gaussian penalty is
introduced to ensure full coverage of the scene. The method achieves near
real-time performance through a number of timing optimizations. An extensive
user study shows that, while watching a full HD video on a mobile device, the
system enhances the security operator's efficiency in understanding the details
of the scene by 99% on the average compared to a scaled version of the original
high resolution video. The produced video achieved 46% higher ratings for
usefulness in a surveillance task.
"
2251,Sensor-Augmented Neural Adaptive Bitrate Video Streaming on UAVs,"  Recent advances in unmanned aerial vehicle (UAV) technology have
revolutionized a broad class of civil and military applications. However, the
designs of wireless technologies that enable real-time streaming of
high-definition video between UAVs and ground clients present a conundrum. Most
existing adaptive bitrate (ABR) algorithms are not optimized for the
air-to-ground links, which usually fluctuate dramatically due to the dynamic
flight states of the UAV. In this paper, we present SA-ABR, a new
sensor-augmented system that generates ABR video streaming algorithms with the
assistance of various kinds of inherent sensor data that are used to pilot
UAVs. By incorporating the inherent sensor data with network observations,
SA-ABR trains a deep reinforcement learning (DRL) model to extract salient
features from the flight state information and automatically learn an ABR
algorithm to adapt to the varying UAV channel capacity through the training
process. SA-ABR does not rely on any assumptions or models about UAV's flight
states or the environment, but instead, it makes decisions by exploiting
temporal properties of past throughput through the long short-term memory
(LSTM) to adapt itself to a wide range of highly dynamic environments. We have
implemented SA-ABR in a commercial UAV and evaluated it in the wild. We compare
SA-ABR with a variety of existing state-of-the-art ABR algorithms, and the
results show that our system outperforms the best known existing ABR algorithm
by 21.4% in terms of the average quality of experience (QoE) reward.
"
2252,"Posture and sequence recognition for Bharatanatyam dance performances
  using machine learning approach","  Understanding the underlying semantics of performing arts like dance is a
challenging task. Dance is multimedia in nature and spans over time as well as
space. Capturing and analyzing the multimedia content of the dance is useful
for the preservation of cultural heritage, to build video recommendation
systems, to assist learners to use tutoring systems. To develop an application
for dance, three aspects of dance analysis need to be addressed: 1)
Segmentation of the dance video to find the representative action elements, 2)
Matching or recognition of the detected action elements, and 3) Recognition of
the dance sequences formed by combining a number of action elements under
certain rules. This paper attempts to solve three fundamental problems of dance
analysis for understanding the underlying semantics of dance forms. Our focus
is on an Indian Classical Dance (ICD) form known as Bharatanatyam. As dance is
driven by music, we use the music as well as motion information for key posture
extraction. Next, we recognize the key postures using machine learning as well
as deep learning techniques. Finally, the dance sequence is recognized using
the Hidden Markov Model (HMM). We capture the multi-modal data of Bharatanatyam
dance using Kinect and build an annotated data set for research in ICD.
"
2253,"Focus Your Attention: A Bidirectional Focal Attention Network for
  Image-Text Matching","  Learning semantic correspondence between image and text is significant as it
bridges the semantic gap between vision and language. The key challenge is to
accurately find and correlate shared semantics in image and text. Most existing
methods achieve this goal by representing the shared semantic as a weighted
combination of all the fragments (image regions or text words), where fragments
relevant to the shared semantic obtain more attention, otherwise less. However,
despite relevant ones contribute more to the shared semantic, irrelevant ones
will more or less disturb it, and thus will lead to semantic misalignment in
the correlation phase. To address this issue, we present a novel Bidirectional
Focal Attention Network (BFAN), which not only allows to attend to relevant
fragments but also diverts all the attention into these relevant fragments to
concentrate on them. The main difference with existing works is they mostly
focus on learning attention weight while our BFAN focus on eliminating
irrelevant fragments from the shared semantic. The focal attention is achieved
by pre-assigning attention based on inter-modality relation, identifying
relevant fragments based on intra-modality relation and reassigning attention.
Furthermore, the focal attention is jointly applied in both image-to-text and
text-to-image directions, which enables to avoid preference to long text or
complex image. Experiments show our simple but effective framework
significantly outperforms state-of-the-art, with relative Recall@1 gains of
2.2% on both Flicr30K and MSCOCO benchmarks.
"
2254,"Lightweight Image Super-Resolution with Information Multi-distillation
  Network","  In recent years, single image super-resolution (SISR) methods using deep
convolution neural network (CNN) have achieved impressive results. Thanks to
the powerful representation capabilities of the deep networks, numerous
previous ways can learn the complex non-linear mapping between low-resolution
(LR) image patches and their high-resolution (HR) versions. However, excessive
convolutions will limit the application of super-resolution technology in low
computing power devices. Besides, super-resolution of any arbitrary scale
factor is a critical issue in practical applications, which has not been well
solved in the previous approaches. To address these issues, we propose a
lightweight information multi-distillation network (IMDN) by constructing the
cascaded information multi-distillation blocks (IMDB), which contains
distillation and selective fusion parts. Specifically, the distillation module
extracts hierarchical features step-by-step, and fusion module aggregates them
according to the importance of candidate features, which is evaluated by the
proposed contrast-aware channel attention mechanism. To process real images
with any sizes, we develop an adaptive cropping strategy (ACS) to super-resolve
block-wise image patches using the same well-trained model. Extensive
experiments suggest that the proposed method performs favorably against the
state-of-the-art SR algorithms in term of visual quality, memory footprint, and
inference time. Code is available at \url{https://github.com/Zheng222/IMDN}.
"
2255,FoodAI: Food Image Recognition via Deep Learning for Smart Food Logging,"  An important aspect of health monitoring is effective logging of food
consumption. This can help management of diet-related diseases like obesity,
diabetes, and even cardiovascular diseases. Moreover, food logging can help
fitness enthusiasts, and people who wanting to achieve a target weight.
However, food-logging is cumbersome, and requires not only taking additional
effort to note down the food item consumed regularly, but also sufficient
knowledge of the food item consumed (which is difficult due to the availability
of a wide variety of cuisines). With increasing reliance on smart devices, we
exploit the convenience offered through the use of smart phones and propose a
smart-food logging system: FoodAI, which offers state-of-the-art deep-learning
based image recognition capabilities. FoodAI has been developed in Singapore
and is particularly focused on food items commonly consumed in Singapore.
FoodAI models were trained on a corpus of 400,000 food images from 756
different classes. In this paper we present extensive analysis and insights
into the development of this system. FoodAI has been deployed as an API service
and is one of the components powering Healthy 365, a mobile app developed by
Singapore's Heath Promotion Board. We have over 100 registered organizations
(universities, companies, start-ups) subscribing to this service and actively
receive several API requests a day. FoodAI has made food logging convenient,
aiding smart consumption and a healthy lifestyle.
"
2256,Multi-scale Dynamic Feature Encoding Network for Image Demoireing,"  The prevalence of digital sensors, such as digital cameras and mobile phones,
simplifies the acquisition of photos. Digital sensors, however, suffer from
producing Moire when photographing objects having complex textures, which
deteriorates the quality of photos. Moire spreads across various frequency
bands of images and is a dynamic texture with varying colors and shapes, which
pose two main challenges in demoireing---an important task in image
restoration. In this paper, towards addressing the first challenge, we design a
multi-scale network to process images at different spatial resolutions,
obtaining features in different frequency bands, and thus our method can
jointly remove moire in different frequency bands. Towards solving the second
challenge, we propose a dynamic feature encoding module (DFE), embedded in each
scale, for dynamic texture. Moire pattern can be eliminated more effectively
via DFE.Our proposed method, termed Multi-scale convolutional network with
Dynamic feature encoding for image DeMoireing (MDDM), can outperform the state
of the arts in fidelity as well as perceptual on benchmarks.
"
2257,Query by Semantic Sketch,"  Sketch-based query formulation is very common in image and video retrieval as
these techniques often complement textual retrieval methods that are based on
either manual or machine generated annotations. In this paper, we present a
retrieval approach that allows to query visual media collections by sketching
concept maps, thereby merging sketch-based retrieval with the search for
semantic labels. Users can draw a spatial distribution of different concept
labels, such as ""sky"", ""sea"" or ""person"" and then use these sketches to find
images or video scenes that exhibit a similar distribution of these concepts.
Hence, this approach does not only take the semantic concepts themselves into
account, but also their semantic relations as well as their spatial context.
The efficient vector representation enables efficient retrieval even in large
multimedia collections. We have integrated the semantic sketch query mode into
our retrieval engine vitrivr and demonstrated its effectiveness.
"
2258,"Active Learning for Event Detection in Support of Disaster Analysis
  Applications","  Disaster analysis in social media content is one of the interesting research
domains having abundance of data. However, there is a lack of labeled data that
can be used to train machine learning models for disaster analysis
applications. Active learning is one of the possible solutions to such problem.
To this aim, in this paper we propose and assess the efficacy of an active
learning based framework for disaster analysis using images shared on social
media outlets. Specifically, we analyze the performance of different active
learning techniques employing several sampling and disagreement strategies.
Moreover, we collect a large-scale dataset covering images from eight common
types of natural disasters. The experimental results show that the use of
active learning techniques for disaster analysis using images results in a
performance comparable to that obtained using human annotated images, and could
be used in frameworks for disaster analysis in images without tedious job of
manual annotation.
"
2259,"Deeply Matting-based Dual Generative Adversarial Network for Image and
  Document Label Supervision","  Although many methods have been proposed to deal with nature image
super-resolution (SR) and get impressive performance, the text images SR is not
good due to their ignorance of document images. In this paper, we propose a
matting-based dual generative adversarial network (mdGAN) for document image
SR. Firstly, the input image is decomposed into document text, foreground and
background layers using deep image matting. Then two parallel branches are
constructed to recover text boundary information and color information
respectively. Furthermore, in order to improve the restoration accuracy of
characters in output image, we use the input image's corresponding ground truth
text label as extra supervise information to refine the two-branch networks
during training. Experiments on real text images demonstrate that our method
outperforms several state-of-the-art methods quantitatively and qualitatively.
"
2260,"Semantic and Visual Similarities for Efficient Knowledge Transfer in CNN
  Training","  In recent years, representation learning approaches have disrupted many
multimedia computing tasks. Among those approaches, deep convolutional neural
networks (CNNs) have notably reached human level expertise on some constrained
image classification tasks. Nonetheless, training CNNs from scratch for new
task or simply new data turns out to be complex and time-consuming. Recently,
transfer learning has emerged as an effective methodology for adapting
pre-trained CNNs to new data and classes, by only retraining the last
classification layer. This paper focuses on improving this process, in order to
better transfer knowledge between CNN architectures for faster trainings in the
case of fine tuning for image classification. This is achieved by combining and
transfering supplementary weights, based on similarity considerations between
source and target classes. The study includes a comparison between semantic and
content-based similarities, and highlights increased initial performances and
training speed, along with superior long term performances when limited
training samples are available.
"
2261,Historical and Modern Features for Buddha Statue Classification,"  While Buddhism has spread along the Silk Roads, many pieces of art have been
displaced. Only a few experts may identify these works, subjectively to their
experience. The construction of Buddha statues was taught through the
definition of canon rules, but the applications of those rules greatly varies
across time and space. Automatic art analysis aims at supporting these
challenges. We propose to automatically recover the proportions induced by the
construction guidelines, in order to use them and compare between different
deep learning features for several classification tasks, in a medium size but
rich dataset of Buddha statues, collected with experts of Buddhism art history.
"
2262,"BUDA.ART: A Multimodal Content-Based Analysis and Retrieval System for
  Buddha Statues","  We introduce BUDA.ART, a system designed to assist researchers in Art
History, to explore and analyze an archive of pictures of Buddha statues. The
system combines different CBIR and classical retrieval techniques to assemble
2D pictures, 3D statue scans and meta-data, that is focused on the Buddha
facial characteristics. We build the system from an archive of 50,000 Buddhism
pictures, identify unique Buddha statues, extract contextual information, and
provide specific facial embedding to first index the archive. The system allows
for mobile, on-site search, and to explore similarities of statues in the
archive. In addition, we provide search visualization and 3D analysis of the
statues
"
2263,MG-VAE: Deep Chinese Folk Songs Generation with Specific Regional Style,"  Regional style in Chinese folk songs is a rich treasure that can be used for
ethnic music creation and folk culture research. In this paper, we propose
MG-VAE, a music generative model based on VAE (Variational Auto-Encoder) that
is capable of capturing specific music style and generating novel tunes for
Chinese folk songs (Min Ge) in a manipulatable way. Specifically, we
disentangle the latent space of VAE into four parts in an adversarial training
way to control the information of pitch and rhythm sequence, as well as of
music style and content. In detail, two classifiers are used to separate style
and content latent space, and temporal supervision is utilized to disentangle
the pitch and rhythm sequence. The experimental results show that the
disentanglement is successful and our model is able to create novel folk songs
with controllable regional styles. To our best knowledge, this is the first
study on applying deep generative model and adversarial training for Chinese
music generation.
"
2264,Diachronic Cross-modal Embeddings,"  Understanding the semantic shifts of multimodal information is only possible
with models that capture cross-modal interactions over time. Under this
paradigm, a new embedding is needed that structures visual-textual interactions
according to the temporal dimension, thus, preserving data's original temporal
organisation. This paper introduces a novel diachronic cross-modal embedding
(DCM), where cross-modal correlations are represented in embedding space,
throughout the temporal dimension, preserving semantic similarity at each
instant t. To achieve this, we trained a neural cross-modal architecture, under
a novel ranking loss strategy, that for each multimodal instance, enforces
neighbour instances' temporal alignment, through subspace structuring
constraints based on a temporal alignment window. Experimental results show
that our DCM embedding successfully organises instances over time. Quantitative
experiments, confirm that DCM is able to preserve semantic cross-modal
correlations at each instant t while also providing better alignment
capabilities. Qualitative experiments unveil new ways to browse multimodal
content and hint that multimodal understanding tasks can benefit from this new
embedding.
"
2265,"Towards Multimodal Understanding of Passenger-Vehicle Interactions in
  Autonomous Vehicles: Intent/Slot Recognition Utilizing Audio-Visual Data","  Understanding passenger intents from spoken interactions and car's vision
(both inside and outside the vehicle) are important building blocks towards
developing contextual dialog systems for natural interactions in autonomous
vehicles (AV). In this study, we continued exploring AMIE (Automated-vehicle
Multimodal In-cabin Experience), the in-cabin agent responsible for handling
certain multimodal passenger-vehicle interactions. When the passengers give
instructions to AMIE, the agent should parse such commands properly considering
available three modalities (language/text, audio, video) and trigger the
appropriate functionality of the AV system. We had collected a multimodal
in-cabin dataset with multi-turn dialogues between the passengers and AMIE
using a Wizard-of-Oz scheme via realistic scavenger hunt game. In our previous
explorations, we experimented with various RNN-based models to detect
utterance-level intents (set destination, change route, go faster, go slower,
stop, park, pull over, drop off, open door, and others) along with intent
keywords and relevant slots (location, position/direction, object,
gesture/gaze, time-guidance, person) associated with the action to be performed
in our AV scenarios. In this recent work, we propose to discuss the benefits of
multimodal understanding of in-cabin utterances by incorporating
verbal/language input (text and speech embeddings) together with the
non-verbal/acoustic and visual input from inside and outside the vehicle (i.e.,
passenger gestures and gaze from in-cabin video stream, referred objects
outside of the vehicle from the road view camera stream). Our experimental
results outperformed text-only baselines and with multimodality, we achieved
improved performances for utterance-level intent detection and slot filling.
"
2266,Cross-Modal Subspace Learning with Scheduled Adaptive Margin Constraints,"  Cross-modal embeddings, between textual and visual modalities, aim to
organise multimodal instances by their semantic correlations. State-of-the-art
approaches use maximum-margin methods, based on the hinge-loss, to enforce a
constant margin m, to separate projections of multimodal instances from
different categories. In this paper, we propose a novel scheduled adaptive
maximum-margin (SAM) formulation that infers triplet-specific constraints
during training, therefore organising instances by adaptively enforcing
inter-category and inter-modality correlations. This is supported by a
scheduled adaptive margin function, that is smoothly activated, replacing a
static margin by an adaptively inferred one reflecting triplet-specific
semantic correlations while accounting for the incremental learning behaviour
of neural networks to enforce category cluster formation and enforcement.
Experiments on widely used datasets show that our model improved upon
state-of-the-art approaches, by achieving a relative improvement of up to
~12.5% over the second best method, thus confirming the effectiveness of our
scheduled adaptive margin formulation.
"
2267,ROMark: A Robust Watermarking System Using Adversarial Training,"  The availability and easy access to digital communication increase the risk
of copyrighted material piracy. In order to detect illegal use or distribution
of data, digital watermarking has been proposed as a suitable tool. It protects
the copyright of digital content by embedding imperceptible information into
the data in the presence of an adversary. The goal of the adversary is to
remove the copyrighted content of the data. Therefore, an efficient
watermarking framework must be robust to multiple image-processing operations
known as attacks that can alter embedded copyright information. Another line of
research \textit{adversarial machine learning} also tackles with similar
problems to guarantee robustness to imperceptible perturbations of the input.
In this work, we propose to apply robust optimization from adversarial machine
learning to improve the robustness of a CNN-based watermarking framework. Our
experimental results on the COCO dataset show that the robustness of a
watermarking framework can be improved by utilizing robust optimization in
training.
"
2268,"iVRNote: Design, Creation and Evaluation of an Interactive Note-Taking
  Interface for Study and Reflection in VR Learning Environments","  In this contribution, we design, implement and evaluate the pedagogical
benefits of a novel interactive note taking interface (iVRNote) in VR for the
purpose of learning and reflection lectures. In future VR learning
environments, students would have challenges in taking notes when they wear a
head mounted display (HMD). To solve this problem, we installed a digital
tablet on the desk and provided several tools in VR to facilitate the learning
experience. Specifically, we track the stylus position and orientation in the
physical world and then render a virtual stylus in VR. In other words, when
students see a virtual stylus somewhere on the desk, they can reach out with
their hand for the physical stylus. The information provided will also enable
them to know where they will draw or write before the stylus touches the
tablet. Since the presented iVRNote featuring our note taking system is a
digital environment, we also enable students save efforts in taking extensive
notes by providing several functions, such as post-editing and picture taking,
so that they can pay more attention to lectures in VR. We also record the time
of each stroke on the note to help students review a lecture. They can select a
part of their note to revisit the corresponding segment in a virtual online
lecture. Figures and the accompanying video demonstrate the feasibility of the
presented iVRNote system. To evaluate the system, we conducted a user study
with 20 participants to assess the preference and pedagogical benefits of the
iVRNote interface.
"
2269,"Secondary Inputs for Measuring User Engagement in Immersive VR Education
  Environments","  This paper presents an experiment to assess the feasibility of using
secondary input data as a method of determining user engagement in immersive
virtual reality (VR). The work investigates whether secondary data (biosignals)
acquired from users are useful as a method of detecting levels of
concentration, stress, relaxation etc. in immersive environments, and if they
could be used to create an affective feedback loop in immersive VR
environments, including educational contexts. A VR Experience was developed in
the Unity game engine, with three different levels, each designed to expose the
user in one of three different states (relaxation, concentration, stress).
While in the VR Experience users physiological responses were measured using
ECG and EEG sensors. After the experience users completed questionnaires to
establish their perceived state during the levels, and to established the
usability of the system. Next a comparison between the reported levels of
emotion and the measured signals is presented, which show a strong
correspondence between the two measures indicating that biosignals are a useful
indicator of emotional state while in VR. Finally we make some recommendations
on the practicalities of using biosensors, and design considerations for their
incorporation in to a VR system, with particular focus on their integration in
to task-based training and educational virtual environments.
"
2270,SMP Challenge: An Overview of Social Media Prediction Challenge 2019,"  ""SMP Challenge"" aims to discover novel prediction tasks for numerous data on
social multimedia and seek excellent research teams. Making predictions via
social multimedia data (e.g. photos, videos or news) is not only helps us to
make better strategic decisions for the future, but also explores advanced
predictive learning and analytic methods on various problems and scenarios,
such as multimedia recommendation, advertising system, fashion analysis etc.
  In the SMP Challenge at ACM Multimedia 2019, we introduce a novel prediction
task Temporal Popularity Prediction, which focuses on predicting future
interaction or attractiveness (in terms of clicks, views or likes etc.) of new
online posts in social media feeds before uploading. We also collected and
released a large-scale SMPD benchmark with over 480K posts from 69K users. In
this paper, we define the challenge problem, give an overview of the dataset,
present statistics of rich information for data and annotation and design the
accuracy and correlation evaluation metrics for temporal popularity prediction
to the challenge.
"
2271,Vulnerability of Face Recognition to Deep Morphing,"  It is increasingly easy to automatically swap faces in images and video or
morph two faces into one using generative adversarial networks (GANs). The high
quality of the resulted deep-morph raises the question of how vulnerable the
current face recognition systems are to such fake images and videos. It also
calls for automated ways to detect these GAN-generated faces. In this paper, we
present the publicly available dataset of the Deepfake videos with faces
morphed with a GAN-based algorithm. To generate these videos, we used open
source software based on GANs, and we emphasize that training and blending
parameters can significantly impact the quality of the resulted videos. We show
that the state of the art face recognition systems based on VGG and Facenet
neural networks are vulnerable to the deep morph videos, with 85.62 and 95.00
false acceptance rates, respectively, which means methods for detecting these
videos are necessary. We consider several baseline approaches for detecting
deep morphs and find that the method based on visual quality metrics (often
used in presentation attack detection domain) leads to the best performance
with 8.97 equal error rate. Our experiments demonstrate that GAN-generated deep
morph videos are challenging for both face recognition systems and existing
detection methods, and the further development of deep morphing technologies
will make it even more so.
"
2272,"Hate Speech in Pixels: Detection of Offensive Memes towards Automatic
  Moderation","  This work addresses the challenge of hate speech detection in Internet memes,
and attempts using visual information to automatically detect hate speech,
unlike any previous work of our knowledge. Memes are pixel-based multimedia
documents that contain photos or illustrations together with phrases which,
when combined, usually adopt a funny meaning. However, hate memes are also used
to spread hate through social networks, so their automatic detection would help
reduce their harmful societal impact. Our results indicate that the model can
learn to detect some of the memes, but that the task is far from being solved
with this simple architecture. While previous work focuses on linguistic hate
speech, our experiments indicate how the visual modality can be much more
informative for hate speech detection than the linguistic one in memes. In our
experiments, we built a dataset of 5,020 memes to train and evaluate a
multi-layer perceptron over the visual and language representations, whether
independently or fused. The source code and mode and models are available
https://github.com/imatge-upc/hate-speech-detection .
"
2273,"Multi-Modal Machine Learning for Flood Detection in News, Social Media
  and Satellite Sequences","  In this paper we present our methods for the MediaEval 2019 Mul-timedia
Satellite Task, which is aiming to extract complementaryinformation associated
with adverse events from Social Media andsatellites. For the first challenge,
we propose a framework jointly uti-lizing colour, object and scene-level
information to predict whetherthe topic of an article containing an image is a
flood event or not.Visual features are combined using early and late fusion
techniquesachieving an average F1-score of82.63,82.40,81.40and76.77. Forthe
multi-modal flood level estimation, we rely on both visualand textual
information achieving an average F1-score of58.48and46.03, respectively.
Finally, for the flooding detection in time-based satellite image sequences we
used a combination of classicalcomputer-vision and machine learning approaches
achieving anaverage F1-score of58.82%
"
2274,Fast Session Resumption in DTLS for Mobile Communications,"  DTLS is a protocol that provides security guarantees to Internet
communications. It can operate on top of both TCP and UDP transport protocols.
Thus, it is particularly suited for peer-to-peer and distributed multimedia
applications. The same holds if the endpoints are mobile devices. In this
scenario, mechanisms are needed to surmount possible network disconnections,
often arising due to the mobility or the scarce resources of devices, that can
jeopardize the quality of the communications. Session resumption is thus a main
issue to deal with. To this aim, we propose a fast reconnection scheme that
employs non-connected sockets to quickly resume DTLS communication sessions.
The proposed scheme is assessed in a performance evaluation that confirms its
viability.
"
2275,Sentiment Analysis from Images of Natural Disasters,"  Social media have been widely exploited to detect and gather relevant
information about opinions and events. However, the relevance of the
information is very subjective and rather depends on the application and the
end-users. In this article, we tackle a specific facet of social media data
processing, namely the sentiment analysis of disaster-related images by
considering people's opinions, attitudes, feelings and emotions. We analyze how
visual sentiment analysis can improve the results for the
end-users/beneficiaries in terms of mining information from social media. We
also identify the challenges and related applications, which could help
defining a benchmark for future research efforts in visual sentiment analysis.
"
2276,"Hierarchical Representation Network for Steganalysis of QIM
  Steganography in Low-Bit-Rate Speech Signals","  With the Volume of Voice over IP (VoIP) traffic rises shapely, more and more
VoIP-based steganography methods have emerged in recent years, which poses a
great threat to the security of cyberspace. Low bit-rate speech codecs are
widely used in the VoIP application due to its powerful compression capability.
QIM steganography makes it possible to hide secret information in VoIP streams.
Previous research mostly focus on capturing the inter-frame correlation or
inner-frame correlation features in code-words but ignore the hierarchical
structure which exists in speech frame. In this paper, motivated by the complex
multi-scale structure, we design a Hierarchical Representation Network to
tackle the steganalysis of QIM steganography in low-bit-rate speech signal. In
the proposed model, Convolution Neural Network (CNN) is used to model the
hierarchical structure in the speech frame, and three level of attention
mechanisms are applied at different convolution block, enabling it to attend
differentially to more and less important content in speech frame. Experiments
demonstrated that the steganalysis performance of the proposed method can
outperforms the state-of-the-art methods especially in detecting both short and
low embeded speech samples. Moreover, our model needs less computation and has
higher time efficiency to be applied to real online services.
"
2277,"Immersive virtual worlds: Multi-sensory virtual environments for health
  and safety training","  Virtual environments (VEs) offer potential benefits to health and safety
training: exposure to dangerous (virtual) environments; the opportunity for
experiential learning; and a high level of control over the training, in that
aspects can be repeated or reviewed based on the trainee's performance.
However, VEs are typically presented as audiovisual (AV) systems, whereas
engagement of other senses could increase the immersion in the virtual
experience. Moreover, other senses play a key role in certain health and safety
contexts, for example the feel of heat and smell in a fire or smell in a fuel
leak. A multisensory (MS) VE was developed, which provided simulated heat and
smell in accordance with events in a virtual world. As users approached a
virtual fire, they felt heat from three 2 kW heaters and smelled smoke from a
scent diffuser. Behaviours in the MS VE demonstrated higher validity than those
in a comparable AV VE, which ratings and verbatim responses indicated was down
to a greater belief that participants were in a real fire. However, a study of
the effectiveness of the MS VE as a training tool demonstrated that it did not
offer benefits over AV as measured by a written knowledge test and subjective
ratings of engagement, attitude towards health and safety and desire to repeat.
However, the study found further evidence for the use of AV VEs in health and
safety training, particularly as the subjective ratings were generally better
than for PowerPoint based training. Despite the lack of evidence for MS
simulation on traditional measures of training, the different attitudes and
experiences of users suggest that it may have value as a system for changing
trainees' attitudes towards their personal safety and awareness. This view was
supported by feedback from industrial partners.
"
2278,"An Automatic Digital Terrain Generation Technique for Terrestrial
  Sensing and Virtual Reality Applications","  The identification and modeling of the terrain from point cloud data is an
important component of Terrestrial Remote Sensing (TRS) applications. The main
focus in terrain modeling is capturing details of complex geological features
of landforms. Traditional terrain modeling approaches rely on the user to exert
control over terrain features. However, relying on the user input to manually
develop the digital terrain becomes intractable when considering the amount of
data generated by new remote sensing systems capable of producing massive
aerial and ground-based point clouds from scanned environments. This article
provides a novel terrain modeling technique capable of automatically generating
accurate and physically realistic Digital Terrain Models (DTM) from a variety
of point cloud data. The proposed method runs efficiently on large-scale point
cloud data with real-time performance over large segments of terrestrial
landforms. Moreover, generated digital models are designed to effectively
render within a Virtual Reality (VR) environment in real time. The paper
concludes with an in-depth discussion of possible research directions and
outstanding technical and scientific challenges to improve the proposed
approach.
"
2279,Multi-modal Deep Analysis for Multimedia,"  With the rapid development of Internet and multimedia services in the past
decade, a huge amount of user-generated and service provider-generated
multimedia data become available. These data are heterogeneous and multi-modal
in nature, imposing great challenges for processing and analyzing them.
Multi-modal data consist of a mixture of various types of data from different
modalities such as texts, images, videos, audios etc. In this article, we
present a deep and comprehensive overview for multi-modal analysis in
multimedia. We introduce two scientific research problems, data-driven
correlational representation and knowledge-guided fusion for multimedia
analysis. To address the two scientific problems, we investigate them from the
following aspects: 1) multi-modal correlational representation: multi-modal
fusion of data across different modalities, and 2) multi-modal data and
knowledge fusion: multi-modal fusion of data with domain knowledge. More
specifically, on data-driven correlational representation, we highlight three
important categories of methods, such as multi-modal deep representation,
multi-modal transfer learning, and multi-modal hashing. On knowledge-guided
fusion, we discuss the approaches for fusing knowledge with data and four
exemplar applications that require various kinds of domain knowledge, including
multi-modal visual question answering, multi-modal video summarization,
multi-modal visual pattern mining and multi-modal recommendation. Finally, we
bring forward our insights and future research directions.
"
2280,Content Delivery Through Hybrid Architecture in Video on Demand System,"  Peer-to-Peer (P2P) network needs architectural modification for smooth and
fast transportation of video content. The viewer imports chunk video objects
through the proxy server. The enormous growth of user requests in a small
session of time creates huge load on the VOD system. The situation requires
either the proxy server streamed video-content fully or partly to the viewers.
The missing chunk at the proxy server is imported from the connected peer
nodes. Peers exchange chunks among themselves according to some chunk selection
policy. Peer node randomly contacts another peer to download a missing chunk
from the buffers during each time slot. In video streaming, when the relevant
frame is required at the viewer ends that should be available at the respective
proxy server. The video watcher also initiates various types of interactive
operations like a move forward or skips some finite number of frames that
create congestion inside the VOD system. To elevate the situation it needs an
effective content delivery mechanism for smooth transportation of content. The
proposed hybrid architecture is composed of P2P and mesh architecture that
effectively enhances the search mechanism and content transportation in the VOD
system.
"
2281,"A CNN-RNN Framework for Image Annotation from Visual Cues and Social
  Network Metadata","  Images represent a commonly used form of visual communication among people.
Nevertheless, image classification may be a challenging task when dealing with
unclear or non-common images needing more context to be correctly annotated.
Metadata accompanying images on social-media represent an ideal source of
additional information for retrieving proper neighborhoods easing image
annotation task. To this end, we blend visual features extracted from neighbors
and their metadata to jointly leverage context and visual cues. Our models use
multiple semantic embeddings to achieve the dual objective of being robust to
vocabulary changes between train and test sets and decoupling the architecture
from the low-level metadata representation. Convolutional and recurrent neural
networks (CNNs-RNNs) are jointly adopted to infer similarity among neighbors
and query images. We perform comprehensive experiments on the NUS-WIDE dataset
showing that our models outperform state-of-the-art architectures based on
images and metadata, and decrease both sensory and semantic gaps to better
annotate images.
"
2282,Real-Time Visual Navigation in Huge Image Sets Using Similarity Graphs,"  Nowadays stock photo agencies often have millions of images. Non-stop viewing
of 20 million images at a speed of 10 images per second would take more than
three weeks. This demonstrates the impossibility to inspect all images and the
difficulty to get an overview of the entire collection. Although there has been
a lot of effort to improve visual image search, there is little research and
support for visual image exploration. Typically, users start ""exploring"" an
image collection with a keyword search or an example image for a similarity
search. Both searches lead to long unstructured lists of result images. In
earlier publications, we introduced the idea of graph-based image navigation
and proposed an efficient algorithm for building hierarchical image similarity
graphs for dynamically changing image collections. In this demo we showcase
real-time visual exploration of millions of images with a standard web browser.
Subsets of images are successively retrieved from the graph and displayed as a
visually sorted 2D image map, which can be zoomed and dragged to explore
related concepts. Maintaining the positions of previously shown images creates
the impression of an ""endless map"". This approach allows an easy visual
image-based navigation, while preserving the complex image relationships of the
graph.
"
2283,A Hybrid Control Scheme for Adaptive Live Streaming,"  The live streaming is more challenging than on-demand streaming, because the
low latency is also a strong requirement in addition to the trade-off between
video quality and jitters in playback. To balance several inherently
conflicting performance metrics and improve the overall quality of experience
(QoE), many adaptation schemes have been proposed. Bitrate adaptation is one of
the major solutions for video streaming under time-varying network conditions,
which works even better combining with some latency control methods, such as
adaptive playback rate control and frame dropping. However, it still remains a
challenging problem to design an algorithm to combine these adaptation schemes
together. To tackle this problem, we propose a hybrid control scheme for
adaptive live streaming, namely HYSA, based on heuristic playback rate control,
latency-constrained bitrate control and QoE-oriented adaptive frame dropping.
The proposed scheme utilizes Kaufman's Adaptive Moving Average (KAMA) to
predict segment bitrates for better rate decisions. Extensive simulations
demonstrate that HYSA outperforms most of the existing adaptation schemes on
overall QoE.
"
2284,"KonIQ-10k: An ecologically valid database for deep learning of blind
  image quality assessment","  Deep learning methods for image quality assessment (IQA) are limited due to
the small size of existing datasets. Extensive datasets require substantial
resources both for generating publishable content and annotating it accurately.
We present a systematic and scalable approach to creating KonIQ-10k, the
largest IQA dataset to date, consisting of 10,073 quality scored images. It is
the first in-the-wild database aiming for ecological validity, concerning the
authenticity of distortions, the diversity of content, and quality-related
indicators. Through the use of crowdsourcing, we obtained 1.2 million reliable
quality ratings from 1,459 crowd workers, paving the way for more general IQA
models. We propose a novel, deep learning model (KonCept512), to show an
excellent generalization beyond the test set (0.921 SROCC), to the current
state-of-the-art database LIVE-in-the-Wild (0.825 SROCC). The model derives its
core performance from the InceptionResNet architecture, being trained at a
higher resolution than previous models (512x384). Correlation analysis shows
that KonCept512 performs similar to having 9 subjective scores for each test
image.
"
2285,Target-Oriented Deformation of Visual-Semantic Embedding Space,"  Multimodal embedding is a crucial research topic for cross-modal
understanding, data mining, and translation. Many studies have attempted to
extract representations from given entities and align them in a shared
embedding space. However, because entities in different modalities exhibit
different abstraction levels and modality-specific information, it is
insufficient to embed related entities close to each other. In this study, we
propose the Target-Oriented Deformation Network (TOD-Net), a novel module that
continuously deforms the embedding space into a new space under a given
condition, thereby adjusting similarities between entities. Unlike methods
based on cross-modal attention, TOD-Net is a post-process applied to the
embedding space learned by existing embedding systems and improves their
performances of retrieval. In particular, when combined with cutting-edge
models, TOD-Net gains the state-of-the-art cross-modal retrieval model
associated with the MSCOCO dataset. Qualitative analysis reveals that TOD-Net
successfully emphasizes entity-specific concepts and retrieves diverse targets
via handling higher levels of diversity than existing models.
"
2286,IMMVP: An Efficient Daytime and Nighttime On-Road Object Detector,"  It is hard to detect on-road objects under various lighting conditions. To
improve the quality of the classifier, three techniques are used. We define
subclasses to separate daytime and nighttime samples. Then we skip similar
samples in the training set to prevent overfitting. With the help of the
outside training samples, the detection accuracy is also improved. To detect
objects in an edge device, Nvidia Jetson TX2 platform, we exert the lightweight
model ResNet-18 FPN as the backbone feature extractor. The FPN (Feature Pyramid
Network) generates good features for detecting objects over various scales.
With Cascade R-CNN technique, the bounding boxes are iteratively refined for
better results.
"
2287,"Generating Human Action Videos by Coupling 3D Game Engines and
  Probabilistic Graphical Models","  Deep video action recognition models have been highly successful in recent
years but require large quantities of manually annotated data, which are
expensive and laborious to obtain. In this work, we investigate the generation
of synthetic training data for video action recognition, as synthetic data have
been successfully used to supervise models for a variety of other computer
vision tasks. We propose an interpretable parametric generative model of human
action videos that relies on procedural generation, physics models and other
components of modern game engines. With this model we generate a diverse,
realistic, and physically plausible dataset of human action videos, called PHAV
for ""Procedural Human Action Videos"". PHAV contains a total of 39,982 videos,
with more than 1,000 examples for each of 35 action categories. Our video
generation approach is not limited to existing motion capture sequences: 14 of
these 35 categories are procedurally defined synthetic actions. In addition,
each video is represented with 6 different data modalities, including RGB,
optical flow and pixel-level semantic labels. These modalities are generated
almost simultaneously using the Multiple Render Targets feature of modern GPUs.
In order to leverage PHAV, we introduce a deep multi-task (i.e. that considers
action classes from multiple datasets) representation learning architecture
that is able to simultaneously learn from synthetic and real video datasets,
even when their action categories differ. Our experiments on the UCF-101 and
HMDB-51 benchmarks suggest that combining our large set of synthetic videos
with small real-world datasets can boost recognition performance. Our approach
also significantly outperforms video representations produced by fine-tuning
state-of-the-art unsupervised generative models of videos.
"
2288,"Scalable Intelligence-Enabled Networking with Traffic Engineering in 5G
  Scenarios for Future Audio-Visual-Tactile Internet","  In order to improve future network performance, this paper proposes scalable
intelligence-enabled networking (SIEN) with eliminating traffic redundancy for
audio-visual-tactile Internet in 5G scenarios such as enhanced mobile
broadband, ultra-reliable and low latency communication, and massive
machine-type communication. The SIEN consists of an intelligent management
plane (ImP), an intelligence-enabled plane (IeP), a control plane and a user
plane. For the ImP, the containers with decision execution are constructed by a
novel graph algorithm to organize objects such as network elements and resource
partitions. For the IeP, a novel learning system is designed with decision
making using a congruity function for generalization and personalization in the
presence of imbalanced, conflicting and partial data. For the control plane, a
scheme of identifier-locator mapping is designed by referring to
information-centric networking and software-defined networking. For the user
plane, the registrations, requests and data are forwarded to implement the SIEN
and test its performance. The evaluation shows the SIEN outperforms four
state-of-the-art techniques for redundant traffic reduction by up to 46.04%
based on a mix of assumption, simulation and proof-of-concept implementation
for audio-visual-tactile Internet multimedia service. To confirm the validity,
the best case and the worst case for traffic offloading are tested with the
data rate, the latency and the density. The evaluation only focused on the
scalability issue, while the SIEN would be beneficial to improve more issues
such as inter-domain security, ultra-low latency, on-demand mobility,
multi-homing routing, and cross-layer feature incongruity.
"
2289,Hiding data inside images using orthogonal moments,"  In this contribution we propose a novel steganographic method based on
several orthogonal polynomials and their combinations. The steganographic
algorithm embeds a secrete message at the first eight coefficients of high
frequency image. Moreover, this embedding method uses the Beta chaotic map to
determine the order of the blocks where the secret bits will be inserted. In
addition, from a 128-bit private key and the steps of a cryptography algorithm
according to the Advanced Encryption Standard (AES) to generate the key
expansion, the proposed method generates a key expansion of 2560 bits, with the
purpose to permute the first eight coefficients of high frequency before the
insertion. The insertion takes eventually place at the first eight high
frequency coefficients in the transformed orthogonal moments domain. Before the
insertion of the message the image undergoes a series of transformations. After
the insertion the inverse transformations are applied to the original
transformations in reverse order. The experimental work on the validation of
the algorithm consists of the calculation of the Peak Signal-to-Noise Ratio
(PSNR), the Universal Image Quality Index (UIQI), the Image Fidelity (IF), and
the Relative Entropy (RE), comparing the same characteristics for the cover and
stego image. The proposed algorithm improves the level of imperceptibility and
security analyzed through the PSNR and RE values, respectively.
"
2290,"A Study of Annotation and Alignment Accuracy for Performance Comparison
  in Complex Orchestral Music","  Quantitative analysis of commonalities and differences between recorded music
performances is an increasingly common task in computational musicology. A
typical scenario involves manual annotation of different recordings of the same
piece along the time dimension, for comparative analysis of, e.g., the musical
tempo, or for mapping other performance-related information between
performances. This can be done by manually annotating one reference
performance, and then automatically synchronizing other performances, using
audio-to-audio alignment algorithms. In this paper we address several questions
related to those tasks. First, we analyze different annotations of the same
musical piece, quantifying timing deviations between the respective human
annotators. A statistical evaluation of the marker time stamps will provide (a)
an estimate of the expected timing precision of human annotations and (b) a
ground truth for subsequent automatic alignment experiments. We then carry out
a systematic evaluation of different audio features for audio-to-audio
alignment, quantifying the degree of alignment accuracy that can be achieved,
and relate this to the results from the annotation study.
"
2291,"Dual-Domain Fusion Convolutional Neural Network for Contrast Enhancement
  Forensics","  Contrast enhancement (CE) forensics techniques have always been of great
interest for image forensics community, as they can be an effective tool for
recovering image history and identifying tampered images. Although several CE
forensic algorithms have been proposed, their accuracy and robustness against
some kinds of processing are still unsatisfactory. In order to attenuate such
deficiency, in this paper we propose a new framework based on dual-domain
fusion convolutional neural network to fuse the features of pixel and histogram
domains for CE forensics. Specifically, we first present a pixel-domain
convolutional neural network (P-CNN) to automatically capture the patterns of
contrast-enhanced images in the pixel domain. Then, we present a
histogram-domain convolutional neural network (H-CNN) to extract the features
in the histogram domain. The feature representations of pixel and histogram
domains are fused and fed into two fully connected layers for the
classification of contrast-enhanced images. Experimental results show that the
proposed method achieve better performance and is robust against pre-JPEG
compression and anti-forensics attacks. In addition, a strategy for performance
improvement of CNN-based forensics is explored, which could provide guidance
for the design of CNN-based forensics tools.
"
2292,Hide the Image in FC-DenseNets to another Image,"  In the past, steganography was to embed text in a carrier, the sender Alice
and the recipient Bob share the key, and the text is extracted by Bob through
the key. If more information is embedded, the image is easily distorted. In
contrast, if there is less embedded information, the image maintains good
visual integrity, but does not meet our requirements for steganographic
capacity. In this paper, we focus on tackling these challenges and limitations
to improve steganographic capacity. An image steganography method based on
Fully Convolutional Dense Network(FC-DenseNet) was proposed by us. The hidden
network and the extracted network are trained at the same time. The dataset of
the deep neural network is derived from various natural images of ImageNet. The
experimental results show that the stego-image after steganography and the
secret image extracted from stego-imge have a visually good effect, and the
stego-image has high capacity and high peak signal to noise ratio.
Image-to-image full size hiding is implemented.
"
2293,"Coordinated Joint Multimodal Embeddings for Generalized Audio-Visual
  Zeroshot Classification and Retrieval of Videos","  We present an audio-visual multimodal approach for the task of zeroshot
learning (ZSL) for classification and retrieval of videos. ZSL has been studied
extensively in the recent past but has primarily been limited to visual
modality and to images. We demonstrate that both audio and visual modalities
are important for ZSL for videos. Since a dataset to study the task is
currently not available, we also construct an appropriate multimodal dataset
with 33 classes containing 156,416 videos, from an existing large scale audio
event dataset. We empirically show that the performance improves by adding
audio modality for both tasks of zeroshot classification and retrieval, when
using multimodal extensions of embedding learning methods. We also propose a
novel method to predict the `dominant' modality using a jointly learned
modality attention network. We learn the attention in a semi-supervised setting
and thus do not require any additional explicit labelling for the modalities.
We provide qualitative validation of the modality specific attention, which
also successfully generalizes to unseen test classes.
"
2294,Automated Composition of Picture-Synched Music Soundtracks for Movies,"  We describe the implementation of and early results from a system that
automatically composes picture-synched musical soundtracks for videos and
movies. We use the phrase ""picture-synched"" to mean that the structure of the
automatically composed music is determined by visual events in the input movie,
i.e. the final music is synchronised to visual events and features such as cut
transitions or within-shot key-frame events. Our system combines automated
video analysis and computer-generated music-composition techniques to create
unique soundtracks in response to the video input, and can be thought of as an
initial step in creating a computerised replacement for a human composer
writing music to fit the picture-locked edit of a movie. Working only from the
video information in the movie, key features are extracted from the input
video, using video analysis techniques, which are then fed into a
machine-learning-based music generation tool, to compose a piece of music from
scratch. The resulting soundtrack is tied to video features, such as scene
transition markers and scene-level energy values, and is unique to the input
video. Although the system we describe here is only a preliminary
proof-of-concept, user evaluations of the output of the system have been
positive.
"
2295,"Musical Instrument Playing Technique Detection Based on FCN: Using
  Chinese Bowed-Stringed Instrument as an Example","  Unlike melody extraction and other aspects of music transcription, research
on playing technique detection is still in its early stages. Compared to
existing work mostly focused on playing technique detection for individual
single notes, we propose a general end-to-end method based on Sound Event
Detection by FCN for musical instrument playing technique detection. In our
case, we choose Erhu, a well-known Chinese bowed-stringed instrument, to
experiment with our method. Because of the limitation of FCN, we present an
algorithm to detect on variable length audio. The effectiveness of the proposed
framework is tested on a new dataset, its categorization of techniques is
similar to our training dataset. The highest accuracy of our 3 experiments on
the new test set is 87.31%. Furthermore, we also evaluate the performance of
the proposed framework on 10 real-world studio music (produced by midi) and 7
real-world recording samples to address the ability of generalization on our
model.
"
2296,"User-Aware Folk Popularity Rank: User-Popularity-Based Tag
  Recommendation That Can Enhance Social Popularity","  In this paper we propose a method that can enhance the social popularity of a
post (i.e., the number of views or likes) by recommending appropriate hash tags
considering both content popularity and user popularity. A previous approach
called FolkPopularityRank (FP-Rank) considered only the relationship among
images, tags, and their popularity. However, the popularity of an image/video
is strongly affected by who uploaded it. Therefore, we develop an algorithm
that can incorporate user popularity and users' tag usage tendency into the
FP-Rank algorithm. The experimental results using 60,000 training images with
their accompanying tags and 1,000 test data, which were actually uploaded to a
real social network service (SNS), show that, in ten days, our proposed
algorithm can achieve 1.2 times more views than the FP-Rank algorithm. This
technology would be critical to individual users and companies/brands who want
to promote themselves in SNSs.
"
2297,"Recent Advances on HEVC Inter-frame Coding: From Optimization to
  Implementation and Beyond","  High Efficiency Video Coding (HEVC) has doubled the video compression ratio
with equivalent subjective quality as compared to its predecessor H.264/AVC.
The significant coding efficiency improvement is attributed to many new
techniques. Inter-frame coding is one of the most powerful yet complicated
techniques therein and has posed high computational burden thus main obstacle
in HEVC-based real-time applications. Recently, plenty of research has been
done to optimize the inter-frame coding, either to reduce the complexity for
real-time applications, or to further enhance the encoding efficiency. In this
paper, we provide a comprehensive review of the state-of-the-art techniques for
HEVC inter-frame coding from three aspects, namely fast inter coding solutions,
implementation on different hardware platforms as well as advanced inter coding
techniques. More specifically, different algorithms in each aspect are further
subdivided into sub-categories and compared in terms of pros, cons, coding
efficiency and coding complexity. To the best of our knowledge, this is the
first such comprehensive review of the recent advances of the inter-frame
coding for HEVC and hopefully it would help the improvement, implementation and
applications of HEVC as well as the ongoing development of the next generation
video coding standard.
"
2298,"Cross-Representation Transferability of Adversarial Attacks: From
  Spectrograms to Audio Waveforms","  This paper shows the susceptibility of spectrogram-based audio classifiers to
adversarial attacks and the transferability of such attacks to audio waveforms.
Some commonly used adversarial attacks to images have been applied to
Mel-frequency and short-time Fourier transform spectrograms, and such perturbed
spectrograms are able to fool a 2D convolutional neural network (CNN). Such
attacks produce perturbed spectrograms that are visually imperceptible by
humans. Furthermore, the audio waveforms reconstructed from the perturbed
spectrograms are also able to fool a 1D CNN trained on the original audio.
Experimental results on a dataset of western music have shown that the 2D CNN
achieves up to 81.87% of mean accuracy on legitimate examples and such
performance drops to 12.09% on adversarial examples. Likewise, the 1D CNN
achieves up to 78.29% of mean accuracy on original audio samples and such
performance drops to 27.91% on adversarial audio waveforms reconstructed from
the perturbed spectrograms.
"
2299,"Word-level Deep Sign Language Recognition from Video: A New Large-scale
  Dataset and Methods Comparison","  Vision-based sign language recognition aims at helping deaf people to
communicate with others. However, most existing sign language datasets are
limited to a small number of words. Due to the limited vocabulary size, models
learned from those datasets cannot be applied in practice. In this paper, we
introduce a new large-scale Word-Level American Sign Language (WLASL) video
dataset, containing more than 2000 words performed by over 100 signers. This
dataset will be made publicly available to the research community. To our
knowledge, it is by far the largest public ASL dataset to facilitate word-level
sign recognition research.
  Based on this new large-scale dataset, we are able to experiment with several
deep learning methods for word-level sign recognition and evaluate their
performances in large scale scenarios. Specifically we implement and compare
two different models,i.e., (i) holistic visual appearance-based approach, and
(ii) 2D human pose based approach. Both models are valuable baselines that will
benefit the community for method benchmarking. Moreover, we also propose a
novel pose-based temporal graph convolution networks (Pose-TGCN) that models
spatial and temporal dependencies in human pose trajectories simultaneously,
which has further boosted the performance of the pose-based method. Our results
show that pose-based and appearance-based models achieve comparable
performances up to 66% at top-10 accuracy on 2,000 words/glosses, demonstrating
the validity and challenges of our dataset. Our dataset and baseline deep
models are available at \url{https://dxli94.github.io/WLASL/}.
"
2300,"Vatex Video Captioning Challenge 2020: Multi-View Features and Hybrid
  Reward Strategies for Video Captioning","  This report describes our solution for the VATEX Captioning Challenge 2020,
which requires generating descriptions for the videos in both English and
Chinese languages. We identified three crucial factors that improve the
performance, namely: multi-view features, hybrid reward, and diverse ensemble.
Based on our method of VATEX 2019 challenge, we achieved significant
improvements this year with more advanced model architectures, combination of
appearance and motion features, and careful hyper-parameters tuning. Our method
achieves very competitive results on both of the Chinese and English video
captioning tracks.
"
2301,"Security analysis of an audio data encryption scheme based on key
  chaining and DNA encoding","  Fairly recently, a new encryption scheme for audio data encryption has been
proposed by Naskar, P.K., et al. The cryptosystem is based on
substitution-permutation encryption structure using DNA encoding at the
substitution stage, in which the key generation is based on a key chaining
algorithm that generates new key block for every plain block using a logistic
chaotic map. After some several statistical tests done by the authors of the
scheme, they claimed that their cryptosystem is robust and can resist
conventional cryptanalysis attacks. Negatively, in this paper we show the
opposite: the scheme is extremely weak against chosen ciphertext and plaintext
attacks thus only two chosen plaintexts of 32 byte size are sufficient to
recover the equivalent key used for encryption. The cryptosystem's shuffling
process design is vulnerable which allow us recovering the unknown original
plaintext by applying repeated encryptions. Our study proves that the scheme is
extremely weak and should not be used for any information security or
cryptographic concern. Lessons learned from this cryptanalytic paper are then
outlined in order to be considered in further designs and proposals.
"
2302,Breaking an image encryption scheme based on Arnold map and Lucas series,"  Fairly recently, a novel image encryption based on Arnold scrambling and
Lucas series has been proposed in the literature. The scheme design is based on
permutation-substitution operations, where Arnold map is used to permute pixels
for some T rounds, and Lucas sequence is used to mask the image and substitute
pixel's values. The authors of the cryptosystem have claimed, after several
statistical analyses, that their system is ""with high efficiency"" and resists
chosen and known plaintext attacks. Negatively, in this paper we showed the
opposite. The key space of the scheme under study could be reduced considerably
after our equivalent keys analysis, and thus the system is breakable under
reasonable brute force attack. After all, the design of the scheme has several
weaknesses that make it weak against chosen and known plaintext attacks.
Consequently, we do not recommend the use of this system for any cryptographic
concern or security purpose.
"
2303,"Cryptanalysis of a Chaos-Based Fast Image Encryption Algorithm for
  Embedded Systems","  Fairly recently, a new encryption scheme for embedded systems based on
continuous third-order hyperbolic sine chaotic system was proposed by Z. Lin et
al. The cryptosystem's main objective is to provide a faster algorithm with
lowest computational time in order to be qualified for use in embedded systems
especially on a program of UAV (unmanned aerial vehicle). In this paper, we
scrutinize the design architecture of this recently proposed scheme against
conventional attacks e.g., chosen plaintext attack, differential attack, known
plaintext attack. We prove in this paper that, negatively, the studied system
is vulnerable. For differential attack, only two chosen plain images are
required to recover the full equivalent key. Moreover, only one 3x400 size
image is sufficient to break the cryptosystem under chosen plaintext attack
considering stability of sort algorithm. Therefore, the proposed scheme is not
recommended for security purposes.
"
2304,Automatic Reminiscence Therapy for Dementia,"  With people living longer than ever, the number of cases with dementia such
as Alzheimer's disease increases steadily. It affects more than 46 million
people worldwide, and it is estimated that in 2050 more than 100 million will
be affected. While there are not effective treatments for these terminal
diseases, therapies such as reminiscence, that stimulate memories from the past
are recommended. Currently, reminiscence therapy takes place in care homes and
is guided by a therapist or a carer. In this work, we present an AI-based
solution to automatize the reminiscence therapy, which consists in a dialogue
system that uses photos as input to generate questions. We run a usability case
study with patients diagnosed of mild cognitive impairment that shows they
found the system very entertaining and challenging. Overall, this paper
presents how reminiscence therapy can be automatized by using machine learning,
and deployed to smartphones and laptops, making the therapy more accessible to
every person affected by dementia.
"
2305,"Blind Robust 3-D Mesh Watermarking based on Mesh Saliency and QIM
  quantization for Copyright Protection","  Due to the recent demand of 3-D models in several applications like medical
imaging, video games, among others, the necessity of implementing 3-D mesh
watermarking schemes aiming to protect copyright has increased considerably.
The majority of robust 3-D watermarking techniques have essentially focused on
the robustness against attacks while the imperceptibility of these techniques
is still a real issue. In this context, a blind robust 3-D mesh watermarking
method based on mesh saliency and Quantization Index Modulation (QIM) for
Copyright protection is proposed. The watermark is embedded by quantifying the
vertex norms of the 3-D mesh using QIM scheme since it offers a good
robustness-capacity tradeoff. The choice of the vertices is adjusted by the
mesh saliency to achieve watermark robustness and to avoid visual distortions.
The experimental results show the high imperceptibility of the proposed scheme
while ensuring a good robustness against a wide range of attacks including
additive noise, similarity transformations, smoothing, quantization, etc.
"
2306,A Hierarchical Mixture Density Network,"  The relationship among three correlated variables could be very
sophisticated, as a result, we may not be able to find their hidden causality
and model their relationship explicitly. However, we still can make our best
guess for possible mappings among these variables, based on the observed
relationship. One of the complicated relationships among three correlated
variables could be a two-layer hierarchical many-to-many mapping. In this
paper, we proposed a Hierarchical Mixture Density Network (HMDN) to model the
two-layer hierarchical many-to-many mapping. We apply HMDN on an indoor
positioning problem and show its benefit.
"
2307,"Indian EmoSpeech Command Dataset: A dataset for emotion based speech
  recognition in the wild","  Speech emotion analysis is an important task which further enables several
application use cases. The non-verbal sounds within speech utterances also play
a pivotal role in emotion analysis in speech. Due to the widespread use of
smartphones, it becomes viable to analyze speech commands captured using
microphones for emotion understanding by utilizing on-device machine learning
models. The non-verbal information includes the environment background sounds
describing the type of surroundings, current situation and activities being
performed. In this work, we consider both verbal (speech commands) and
non-verbal sounds (background noises) within an utterance for emotion analysis
in real-life scenarios. We create an indigenous dataset for this task namely
""Indian EmoSpeech Command Dataset"". It contains keywords with diverse emotions
and background sounds, presented to explore new challenges in audio analysis.
We exhaustively compare with various baseline models for emotion analysis on
speech commands on several performance metrics. We demonstrate that we achieve
a significant average gain of 3.3% in top-one score over a subset of speech
command dataset for keyword spotting.
"
2308,"Prediction, Communication, and Computing Duration Optimization for VR
  Video Streaming","  Proactive tile-based video streaming can avoid motion-to-photon latency of
wireless virtual reality (VR) by computing and delivering the predicted tiles
to be requested before playback. All existing works either focus on the task of
tile prediction or on the tasks of computing and communications, overlooking
the facts that these successively executed tasks have to share the same
duration to avoid the latency and the quality of experience (QoE) of proactive
VR streaming depends on the worst performance of the three tasks. In this
paper, we jointly optimize the duration of the observation window for
predicting tiles and the durations for computing and transmitting the predicted
tiles to maximize the QoE given arbitrary predictor and configured resources.
We obtain the global optimal solution with closed-form expression by
decomposing the formulated problem equivalently into two subproblems. With the
optimized durations, we find a resource-limited region where the QoE can be
improved effectively by configuring more resources, and a prediction-limited
region where the QoE can be improved with a better predictor. Simulation
results using three existing tile predictors with a real dataset demonstrate
the gain of the joint optimization over the non-optimized counterparts.
"
2309,Fast Steganalysis Method for VoIP Streams,"  In this letter, we present a novel and extremely fast steganalysis method of
Voice over IP (VoIP) streams, driven by the need for a quick and accurate
detection of possible steganography in VoIP streams. We firstly analyzed the
correlations in carriers. To better exploit the correlation in code-words, we
mapped vector quantization code-words into a semantic space. In order to
achieve high detection efficiency, only one hidden layer is utilized to extract
the correlations between these code-words. Finally, based on the extracted
correlation features, we used the softmax classifier to categorize the input
stream carriers. To boost the performance of this proposed model, we
incorporate a simple knowledge distillation framework into the training
process. Experimental results show that the proposed method achieves
state-of-the-art performance both in detection accuracy and efficiency. In
particular, the processing time of this method on average is only about 0.05\%
when sample length is as short as 0.1s, attaching strong practical value to
online serving of steganography monitor.
"
2310,Privacy-Preserving Machine Learning Using EtC Images,"  In this paper, we propose a novel privacy-preserving machine learning scheme
with encrypted images, called EtC (Encryption-then-Compression) images. Using
machine learning algorithms in cloud environments has been spreading in many
fields. However, there are serious issues with it for end users, due to
semi-trusted cloud providers. Accordingly, we propose using EtC images, which
have been proposed for EtC systems with JPEG compression. In this paper, a
novel property of EtC images is considered under the use of z-score
normalization. It is demonstrated that the use of EtC images allows us not only
to protect visual information of images, but also to preserve both the
Euclidean distance and the inner product between vectors. In addition,
dimensionality reduction is shown to can be applied to EtC images for fast and
accurate matching. In an experiment, the proposed scheme is applied to a facial
recognition algorithm with classifiers for confirming the effectiveness of the
scheme under the use of support vector machine (SVM) with the kernel trick.
"
2311,"Learning a Representation for Cover Song Identification Using
  Convolutional Neural Network","  Cover song identification represents a challenging task in the field of Music
Information Retrieval (MIR) due to complex musical variations between query
tracks and cover versions. Previous works typically utilize hand-crafted
features and alignment algorithms for the task. More recently, further
breakthroughs are achieved employing neural network approaches. In this paper,
we propose a novel Convolutional Neural Network (CNN) architecture based on the
characteristics of the cover song task. We first train the network through
classification strategies; the network is then used to extract music
representation for cover song identification. A scheme is designed to train
robust models against tempo changes. Experimental results show that our
approach outperforms state-of-the-art methods on all public datasets, improving
the performance especially on the large dataset.
"
2312,"BlessMark: A Blind Diagnostically-Lossless Watermarking Framework for
  Medical Applications Based on Deep Neural Networks","  Nowadays, with the development of public network usage, medical information
is transmitted throughout the hospitals. The watermarking system can help for
the confidentiality of medical information distributed over the internet. In
medical images, regions-of-interest (ROI) contain diagnostic information. The
watermark should be embedded only into non-regions-of-interest (NROI) to keep
diagnostic information without distortion. Recently, ROI based watermarking has
attracted the attention of the medical research community. The ROI map can be
used as an embedding key for improving confidentiality protection purposes.
However, in most existing works, the ROI map that is used for the embedding
process must be sent as side-information along with the watermarked image. This
side information is a disadvantage and makes the extraction process non-blind.
Also, most existing algorithms do not recover NROI of the original cover image
after the extraction of the watermark. In this paper, we propose a framework
for blind diagnostically-lossless watermarking, which iteratively embeds only
into NROI. The significance of the proposed framework is in satisfying the
confidentiality of the patient information through a blind watermarking system,
while it preserves diagnostic/medical information of the image throughout the
watermarking process. A deep neural network is used to recognize the ROI map in
the embedding, extraction, and recovery processes. In the extraction process,
the same ROI map of the embedding process is recognized without requiring any
additional information. Hence, the watermark is blindly extracted from the
NROI.
"
2313,"A Generalized Rate-Distortion-${\lambda}$ Model Based HEVC Rate Control
  Algorithm","  The High Efficiency Video Coding (HEVC/H.265) standard doubles the
compression efficiency of the widely used H.264/AVC standard. For practical
applications, rate control (RC) algorithms for HEVC need to be developed. Based
on the R-Q, R-${\rho}$ or R-${\lambda}$ models, rate control algorithms aim at
encoding a video clip/segment to a target bit rate accurately with high video
quality after compression. Among the various models used by HEVC rate control
algorithms, the R-${\lambda}$ model performs the best in both coding efficiency
and rate control accuracy. However, compared with encoding with a fixed
quantization parameter (QP), even the best rate control algorithm [1] still
under-performs when comparing the video quality achieved at identical average
bit rates. In this paper, we propose a novel generalized
rate-distortion-${\lambda}$ (R-D-${\lambda}$) model for the relationship
between rate (R), distortion (D) and the Lagrangian multiplier (${\lambda}$) in
rate-distortion (RD) optimized encoding. In addition to the well designed
hierarchical initialization and coefficient update scheme, a new model based
rate allocation scheme composed of amortization, smooth window and consistency
control is proposed for a better rate allocation. Experimental results
implementing the proposed algorithm in the HEVC reference software HM-16.9 show
that the proposed rate control algorithm is able to achieve an average of BDBR
saving of 6.09%, 3.15% and 4.03% for random access (RA), low delay P (LDP) and
low delay B (LDB) configurations respectively as compared with the
R-${\lambda}$ model based RC algorithm [1] implemented in HM. The proposed
algorithm also outperforms the state-of-the-art algorithms, while rate control
accuracy and encoding speed are hardly impacted.
"
2314,"FCEM: A Novel Fast Correlation Extract Model For Real Time Steganalysis
  of VoIP Stream via Multi-head Attention","  Extracting correlation features between codes-words with high computational
efficiency is crucial to steganalysis of Voice over IP (VoIP) streams. In this
paper, we utilized attention mechanisms, which have recently attracted enormous
interests due to their highly parallelizable computation and flexibility in
modeling correlation in sequence, to tackle steganalysis problem of
Quantization Index Modulation (QIM) based steganography in compressed VoIP
stream. We design a light-weight neural network named Fast Correlation Extract
Model (FCEM) only based on a variant of attention called multi-head attention
to extract correlation features from VoIP frames. Despite its simple form, FCEM
outperforms complicated Recurrent Neural Networks (RNNs) and Convolutional
Neural Networks (CNNs) models on both prediction accuracy and time efficiency.
It significantly improves the best result in detecting both low embedded rates
and short samples recently. Besides, the proposed model accelerates the
detection speed as twice as before when the sample length is as short as 0.1s,
making it a excellent method for online services.
"
2315,Visual Relationship Detection with Relative Location Mining,"  Visual relationship detection, as a challenging task used to find and
distinguish the interactions between object pairs in one image, has received
much attention recently. In this work, we propose a novel visual relationship
detection framework by deeply mining and utilizing relative location of
object-pair in every stage of the procedure. In both the stages, relative
location information of each object-pair is abstracted and encoded as auxiliary
feature to improve the distinguishing capability of object-pairs proposing and
predicate recognition, respectively; Moreover, one Gated Graph Neural
Network(GGNN) is introduced to mine and measure the relevance of predicates
using relative location. With the location-based GGNN, those non-exclusive
predicates with similar spatial position can be clustered firstly and then be
smoothed with close classification scores, thus the accuracy of top $n$ recall
can be increased further. Experiments on two widely used datasets VRD and VG
show that, with the deeply mining and exploiting of relative location
information, our proposed model significantly outperforms the current
state-of-the-art.
"
2316,"Hybrid blind robust image watermarking technique based on DFT-DCT and
  Arnold transform","  In this paper, a robust blind image watermarking method is proposed for
copyright protection of digital images. This hybrid method relies on combining
two well-known transforms that are the discrete Fourier transform (DFT) and the
discrete cosine transform (DCT). The motivation behind this combination is to
enhance the imperceptibility and the robustness. The imperceptibility
requirement is achieved by using magnitudes of DFT coefficients while the
robustness improvement is ensured by applying DCT to the DFT coefficients
magnitude. The watermark is embedded by modifying the coefficients of the
middle band of the DCT using a secret key. The security of the proposed method
is enhanced by applying Arnold transform (AT) to the watermark before
embedding. Experiments were conducted on natural and textured images. Results
show that, compared with state-of-the-art methods, the proposed method is
robust to a wide range of attacks while preserving high imperceptibility.
"
2317,"Robustness and Imperceptibility Enhancement in Watermarked Images by
  Color Transformation","  One of the effective methods for the preservation of copyright ownership of
digital media is watermarking. Different watermarking techniques try to set a
tradeoff between robustness and transparency of the process. In this research
work, we have used color space conversion and frequency transform to achieve
high robustness and transparency. Due to the distribution of image information
in the RGB domain, we use the YUV color space, which concentrates the visual
information in the Y channel. Embedding of the watermark is performed in the
DCT coefficients of the specific wavelet subbands. Experimental results show
high transparency and robustness of the proposed method.
"
2318,Adaptive Rate Allocation for View-Aware Point-Cloud Streaming,"  In the context of view-dependent point-cloud streaming in a scene, our rate
allocation is ""adaptive"" in the sense that it priorities the point-cloud models
depending on the camera view and the visibility of the objects and their
distance as described. The algorithm delivers higher bitrate to the point-cloud
models which are inside user's viewport, more likely for the user to look at,
or are closer to the view camera or, while delivers lower quality level to the
point-cloud models outside of a user's immediate viewport or farther away from
the camera. For that purpose, we hereby explain the rate allocation problem
within the context of multi-point-cloud streaming where multiple point-cloud
models are aimed to be streamed to the target device, and propose a rate
allocation heuristic algorithm to enable the adaptations within this context.
To the best of our knowledge, this is the first work to mathematically model,
and propose a rate allocation heuristic algorithm within the context of
point-cloud streaming.
"
2319,Video-based compression for plenoptic point clouds,"  The plenoptic point cloud that has multiple colors from various directions,
is a more complete representation than the general point cloud that usually has
only one color. It is more realistic but also brings a larger volume of data
that needs to be compressed efficiently. The state-of-the-art method to
compress the plenoptic point cloud is an extension of the region-based adaptive
hierarchical transform (RAHT). As far as we can see, in addition to RAHT, the
video-based point cloud compression (V-PCC) is also an efficient point cloud
compression method. However, to the best of our knowledge, no works have used a
video-based solution to compress the plenoptic point cloud yet. In this paper,
we first extend the V-PCC to support the plenoptic point cloud compression by
generating multiple attribute videos. Then based on the observation that these
videos from multiple views have very high correlations, we propose encoding
them using multiview high efficiency video coding. We further propose a
block-based padding method that unifies the unoccupied attribute pixels from
different views to reduce their bit cost. The proposed algorithms are
implemented in the V-PCC reference software. The experimental results show that
the proposed algorithms can bring significant bitrate savings compared with the
state-of-the-art method for plenoptic point cloud compression.
"
2320,"Reversible Data Hiding in Encrypted Images based on Pixel Prediction and
  Bit-plane Compression","  Reversible data hiding in encrypted images (RDHEI) receives growing attention
because it protects the content of the original image while the embedded data
can be accurately extracted and the original image can be reconstructed
lossless. To make full use of the correlation of the adjacent pixels, this
paper proposes an RDHEI scheme based on pixel prediction and bit-plane
compression. Firstly, to vacate room for data embedding, the prediction error
of the original image is calculated and used for bit-plane rearrangement and
compression. Then, the image after vacating room is encrypted by a stream
cipher. Finally, the additional data is embedded in the vacated room by
multi-LSB substitution. Experimental results show that the embedding capacity
of the proposed method outperforms the state-of-the-art methods.
"
2321,"Mixture factorized auto-encoder for unsupervised hierarchical deep
  factorization of speech signal","  Speech signal is constituted and contributed by various informative factors,
such as linguistic content and speaker characteristic. There have been notable
recent studies attempting to factorize speech signal into these individual
factors without requiring any annotation. These studies typically assume
continuous representation for linguistic content, which is not in accordance
with general linguistic knowledge and may make the extraction of speaker
information less successful. This paper proposes the mixture factorized
auto-encoder (mFAE) for unsupervised deep factorization. The encoder part of
mFAE comprises a frame tokenizer and an utterance embedder. The frame tokenizer
models linguistic content of input speech with a discrete categorical
distribution. It performs frame clustering by assigning each frame a soft
mixture label. The utterance embedder generates an utterance-level vector
representation. A frame decoder serves to reconstruct speech features from the
encoders'outputs. The mFAE is evaluated on speaker verification (SV) task and
unsupervised subword modeling (USM) task. The SV experiments on VoxCeleb 1 show
that the utterance embedder is capable of extracting speaker-discriminative
embeddings with performance comparable to a x-vector baseline. The USM
experiments on ZeroSpeech 2017 dataset verify that the frame tokenizer is able
to capture linguistic content and the utterance embedder can acquire
speaker-related information.
"
2322,Who is Real Bob? Adversarial Attacks on Speaker Recognition Systems,"  Speaker recognition (SR) is widely used in our daily life as a biometric
authentication or identification mechanism. The popularity of SR brings in
serious security concerns, as demonstrated by recent adversarial attacks.
However, the impacts of such threats in the practical black-box setting are
still open, since current attacks consider the white-box setting only. In this
paper, we conduct the first comprehensive and systematic study of the
adversarial attacks on SR systems (SRSs) to understand their security weakness
in the practical blackbox setting. For this purpose, we propose an adversarial
attack, named FAKEBOB, to craft adversarial samples. Specifically, we formulate
the adversarial sample generation as an optimization problem, incorporated with
the confidence of adversarial samples and maximal distortion to balance between
the strength and imperceptibility of adversarial voices. One key contribution
is to propose a novel algorithm to estimate the score threshold, a feature in
SRSs, and use it in the optimization problem to solve the optimization problem.
We demonstrate that FAKEBOB achieves 99% targeted attack success rate on both
open-source and commercial systems. We further demonstrate that FAKEBOB is also
effective on both open-source and commercial systems when playing over the air
in the physical world. Moreover, we have conducted a human study which reveals
that it is hard for human to differentiate the speakers of the original and
adversarial voices. Last but not least, we show that four promising defense
methods for adversarial attack from the speech recognition domain become
ineffective on SRSs against FAKEBOB, which calls for more effective defense
methods. We highlight that our study peeks into the security implications of
adversarial attacks on SRSs, and realistically fosters to improve the security
robustness of SRSs.
"
2323,Recurrent Instance Segmentation using Sequences of Referring Expressions,"  The goal of this work is to segment the objects in an image that are referred
to by a sequence of linguistic descriptions (referring expressions). We propose
a deep neural network with recurrent layers that output a sequence of binary
masks, one for each referring expression provided by the user. The recurrent
layers in the architecture allow the model to condition each predicted mask on
the previous ones, from a spatial perspective within the same image. Our
multimodal approach uses off-the-shelf architectures to encode both the image
and the referring expressions. The visual branch provides a tensor of pixel
embeddings that are concatenated with the phrase embeddings produced by a
language encoder. Our experiments on the RefCOCO dataset for still images
indicate how the proposed architecture successfully exploits the sequences of
referring expressions to solve a pixel-wise task of instance segmentation.
"
2324,Reversible Adversarial Example based on Reversible Image Transformation,"  Currently, there emerge many companies taking Deep Neural Networks (DNNs) to
classify and analyze user-uploaded photos on social platforms. Hence for users
to protect image privacy without affecting human eyes to correctly extract the
semantic information, it is possible to rely upon the attack capability of
adversarial examples to fool these DNNs. In this paper, we take advantage of
Reversible Image Transformation (RIT) to disguise original image as its
adversarial example to get a controllable adversarial example, namely
reversible adversarial example, which is still an adversarial example to DNNs.
However, it not only deceives DNNs to extract the wrong information, but also
can be recovered to original image without distortion. Experimental results on
ImageNet demonstrate that our proposed scheme is superior to Liu et al. Since
RIT can reversibly transform an image into an arbitrarily-chosen image with the
same size, there is no need to worry, as Liu et al., about adversarial
perturbations that are too large to be fully embedded. More importantly, our
reversible adversarial examples achieve higher attack success rate to reach
desired privacy protection goals, while ensuring the image quality is still
good.
"
2325,"Extracting temporal features into a spatial domain using autoencoders
  for sperm video analysis","  In this paper, we present a two-step deep learning method that is used to
predict sperm motility and morphology-based on video recordings of human
spermatozoa. First, we use an autoencoder to extract temporal features from a
given semen video and plot these into image-space, which we call
feature-images. Second, these feature-images are used to perform transfer
learning to predict the motility and morphology values of human sperm. The
presented method shows it's capability to extract temporal information into
spatial domain feature-images which can be used with traditional convolutional
neural networks. Furthermore, the accuracy of the predicted motility of a given
semen sample shows that a deep learning-based model can capture the temporal
information of microscopic recordings of human semen.
"
2326,"A Robust Blind 3-D Mesh Watermarking based on Wavelet Transform for
  Copyright Protection","  Nowadays, three-dimensional meshes have been extensively used in several
applications such as, industrial, medical, computer-aided design (CAD) and
entertainment due to the processing capability improvement of computers and the
development of the network infrastructure. Unfortunately, like digital images
and videos, 3-D meshes can be easily modified, duplicated and redistributed by
unauthorized users. Digital watermarking came up while trying to solve this
problem. In this paper, we propose a blind robust watermarking scheme for
three-dimensional semiregular meshes for Copyright protection. The watermark is
embedded by modifying the norm of the wavelet coefficient vectors associated
with the lowest resolution level using the edge normal norms as synchronizing
primitives. The experimental results show that in comparison with alternative
3-D mesh watermarking approaches, the proposed method can resist to a wide
range of common attacks, such as similarity transformations including
translation, rotation, uniform scaling and their combination, noise addition,
Laplacian smoothing, quantization, while preserving high imperceptibility.
"
2327,A Multimodal CNN-based Tool to Censure Inappropriate Video Scenes,"  Due to the extensive use of video-sharing platforms and services for their
storage, the amount of such media on the internet has become massive. This
volume of data makes it difficult to control the kind of content that may be
present in such video files. One of the main concerns regarding the video
content is if it has an inappropriate subject matter, such as nudity, violence,
or other potentially disturbing content. More than telling if a video is either
appropriate or inappropriate, it is also important to identify which parts of
it contain such content, for preserving parts that would be discarded in a
simple broad analysis. In this work, we present a multimodal~(using audio and
image features) architecture based on Convolutional Neural Networks (CNNs) for
detecting inappropriate scenes in video files. In the task of classifying video
files, our model achieved 98.95\% and 98.94\% of F1-score for the appropriate
and inappropriate classes, respectively. We also present a censoring tool that
automatically censors inappropriate segments of a video file.
"
2328,"Pano: Optimizing 360{\deg} Video Streaming with a Better Understanding
  of Quality Perception","  Streaming 360{\deg} videos requires more bandwidth than non-360{\deg} videos.
This is because current solutions assume that users perceive the quality of
360{\deg} videos in the same way they perceive the quality of non-360{\deg}
videos. This means the bandwidth demand must be proportional to the size of the
user's field of view. However, we found several qualitydetermining factors
unique to 360{\deg}videos, which can help reduce the bandwidth demand. They
include the moving speed of a user's viewpoint (center of the user's field of
view), the recent change of video luminance, and the difference in
depth-of-fields of visual objects around the viewpoint. This paper presents
Pano, a 360{\deg} video streaming system that leverages the 360{\deg}
video-specific factors. We make three contributions. (1) We build a new quality
model for 360{\deg} videos that captures the impact of the 360{\deg}
video-specific factors. (2) Pano proposes a variable-sized tiling scheme in
order to strike a balance between the perceived quality and video encoding
efficiency. (3) Pano proposes a new qualityadaptation logic that maximizes
360{\deg} video user-perceived quality and is readily deployable. Our
evaluation (based on user study and trace analysis) shows that compared with
state-of-the-art techniques, Pano can save 41-46% bandwidth without any drop in
the perceived quality, or it can raise the perceived quality (user rating) by
25%-142% without using more bandwidth.
"
2329,"CALPA-NET: Channel-pruning-assisted Deep Residual Network for
  Steganalysis of Digital Images","  Over the past few years, detection performance improvements of deep-learning
based steganalyzers have been usually achieved through structure expansion.
However, excessive expanded structure results in huge computational cost,
storage overheads, and consequently difficulty in training and deployment. In
this paper we propose CALPA-NET, a ChAnneL-Pruning-Assisted deep residual
network architecture search approach to shrink the network structure of
existing vast, over-parameterized deep-learning based steganalyzers. We observe
that the broad inverted-pyramid structure of existing deep-learning based
steganalyzers might contradict the well-established model diversity oriented
philosophy, and therefore is not suitable for steganalysis. Then a hybrid
criterion combined with two network pruning schemes is introduced to adaptively
shrink every involved convolutional layer in a data-driven manner. The
resulting network architecture presents a slender bottleneck-like structure. We
have conducted extensive experiments on BOSSBase+BOWS2 dataset, more diverse
ALASKA dataset and even a large-scale subset extracted from ImageNet CLS-LOC
dataset. The experimental results show that the model structure generated by
our proposed CALPA-NET can achieve comparative performance with less than two
percent of parameters and about one third FLOPs compared to the original
steganalytic model. The new model possesses even better adaptivity,
transferability, and scalability.
"
2330,Visual cryptography in single-pixel imaging,"  Two novel visual cryptography (VC) schemes are proposed by combining VC with
single-pixel imaging (SPI) for the first time. It is pointed out that the
overlapping of visual key images in VC is similar to the superposition of pixel
intensities by a single-pixel detector in SPI. In the first scheme, QR-code VC
is designed by using opaque sheets instead of transparent sheets. The secret
image can be recovered when identical illumination patterns are projected onto
multiple visual key images and a single detector is used to record the total
light intensities. In the second scheme, the secret image is shared by multiple
illumination pattern sequences and it can be recovered when the visual key
patterns are projected onto identical items. The application of VC can be
extended to more diversified scenarios by our proposed schemes.
"
2331,"Affective Computing for Large-Scale Heterogeneous Multimedia Data: A
  Survey","  The wide popularity of digital photography and social networks has generated
a rapidly growing volume of multimedia data (i.e., image, music, and video),
resulting in a great demand for managing, retrieving, and understanding these
data. Affective computing (AC) of these data can help to understand human
behaviors and enable wide applications. In this article, we survey the
state-of-the-art AC technologies comprehensively for large-scale heterogeneous
multimedia data. We begin this survey by introducing the typical emotion
representation models from psychology that are widely employed in AC. We
briefly describe the available datasets for evaluating AC algorithms. We then
summarize and compare the representative methods on AC of different multimedia
types, i.e., images, music, videos, and multimodal data, with the focus on both
handcrafted features-based methods and deep learning methods. Finally, we
discuss some challenges and future directions for multimedia affective
computing.
"
2332,"Emotion and Theme Recognition in Music with Frequency-Aware
  RF-Regularized CNNs","  We present CP-JKU submission to MediaEval 2019; a Receptive
Field-(RF)-regularized and Frequency-Aware CNN approach for tagging music with
emotion/mood labels. We perform an investigation regarding the impact of the RF
of the CNNs on their performance on this dataset. We observe that ResNets with
smaller receptive fields -- originally adapted for acoustic scene
classification -- also perform well in the emotion tagging task. We improve the
performance of such architectures using techniques such as Frequency Awareness
and Shake-Shake regularization, which were used in previous work on general
acoustic recognition tasks.
"
2333,Scene-Aware Audio Rendering via Deep Acoustic Analysis,"  We present a new method to capture the acoustic characteristics of real-world
rooms using commodity devices, and use the captured characteristics to generate
similar sounding sources with virtual models. Given the captured audio and an
approximate geometric model of a real-world room, we present a novel
learning-based method to estimate its acoustic material properties. Our
approach is based on deep neural networks that estimate the reverberation time
and equalization of the room from recorded audio. These estimates are used to
compute material properties related to room reverberation using a novel
material optimization objective. We use the estimated acoustic material
characteristics for audio rendering using interactive geometric sound
propagation and highlight the performance on many real-world scenarios. We also
perform a user study to evaluate the perceptual similarity between the recorded
sounds and our rendered audio.
"
2334,"Accessibility to textual and visual information on websites for visually
  impaired persons","  Access to textual and visual information for visually impaired persons
becomes very difficult with screen readers which are not adapted to different
websites.This paper analyses the use of different technologies for access
digital content and to establish some ameliorations to the existing
recommendations to accessible website conception for all. The preliminary
evaluation results with visually impaired people of our website ACCESSPACE
which is constructed with the existing recommendations, confirm the project's
relevance.
"
2335,Parametric Graph-based Separable Transforms for Video Coding,"  In many video coding systems, separable transforms (such as two-dimensional
DCT-2) have been used to code block residual signals obtained after prediction.
This paper proposes a parametric approach to build graph-based separable
transforms (GBSTs) for video coding. Specifically, a GBST is derived from a
pair of line graphs, whose weights are determined based on two non-negative
parameters. As certain choices of those parameters correspond to the discrete
sine and cosine transform types used in recent video coding standards
(including DCT-2, DST-7 and DCT-8), this paper further optimizes these graph
parameters to better capture residual block statistics and improve video coding
efficiency. The proposed GBSTs are tested on the Versatile Video Coding (VVC)
reference software, and the experimental results show that about 0.4% average
coding gain is achieved over the existing set of separable transforms
constructed based on DCT-2, DST-7 and DCT-8 in VVC.
"
2336,Quality Assessment of DIBR-synthesized views: An Overview,"  The Depth-Image-Based-Rendering (DIBR) is one of the main fundamental
technique to generate new views in 3D video applications, such as Multi-View
Videos (MVV), Free-Viewpoint Videos (FVV) and Virtual Reality (VR). However,
the quality assessment of DIBR-synthesized views is quite different from the
traditional 2D images/videos. In recent years, several efforts have been made
towards this topic, but there lacks a detailed survey in literature. In this
paper, we provide a comprehensive survey on various current approaches for
DIBR-synthesized views. The current accessible datasets of DIBR-synthesized
views are firstly reviewed. Followed by a summary and analysis of the
representative state-of-the-art objective metrics. Then, the performances of
different objective metrics are evaluated and discussed on all available
datasets. Finally, we discuss the potential challenges and suggest possible
directions for future research.
"
2337,"Understanding the Teaching Styles by an Attention based Multi-task
  Cross-media Dimensional modelling","  Teaching style plays an influential role in helping students to achieve
academic success. In this paper, we explore a new problem of effectively
understanding teachers' teaching styles. Specifically, we study 1) how to
quantitatively characterize various teachers' teaching styles for various
teachers and 2) how to model the subtle relationship between cross-media
teaching related data (speech, facial expressions and body motions, content et
al.) and teaching styles. Using the adjectives selected from more than 10,000
feedback questionnaires provided by an educational enterprise, a novel concept
called Teaching Style Semantic Space (TSSS) is developed based on the
pleasure-arousal dimensional theory to describe teaching styles quantitatively
and comprehensively. Then a multi-task deep learning based model,
Attention-based Multi-path Multi-task Deep Neural Network (AMMDNN), is proposed
to accurately and robustly capture the internal correlations between
cross-media features and TSSS. Based on the benchmark dataset, we further
develop a comprehensive data set including 4,541 full-annotated cross-modality
teaching classes. Our experimental results demonstrate that the proposed AMMDNN
outperforms (+0.0842 in terms of the concordance correlation coefficient (CCC)
on average) baseline methods. To further demonstrate the advantages of the
proposed TSSS and our model, several interesting case studies are carried out,
such as teaching styles comparison among different teachers and courses, and
leveraging the proposed method for teaching quality analysis.
"
2338,"Deep Verifier Networks: Verification of Deep Discriminative Models with
  Deep Generative Models","  AI Safety is a major concern in many deep learning applications such as
autonomous driving. Given a trained deep learning model, an important natural
problem is how to reliably verify the model's prediction. In this paper, we
propose a novel framework --- deep verifier networks (DVN) to verify the inputs
and outputs of deep discriminative models with deep generative models. Our
proposed model is based on conditional variational auto-encoders with
disentanglement constraints. We give both intuitive and theoretical
justifications of the model. Our verifier network is trained independently with
the prediction model, which eliminates the need of retraining the verifier
network for a new model. We test the verifier network on out-of-distribution
detection and adversarial example detection problems, as well as anomaly
detection problems in structured prediction tasks such as image caption
generation. We achieve state-of-the-art results in all of these problems.
"
2339,"Exploiting Human Social Cognition for the Detection of Fake and
  Fraudulent Faces via Memory Networks","  Advances in computer vision have brought us to the point where we have the
ability to synthesise realistic fake content. Such approaches are seen as a
source of disinformation and mistrust, and pose serious concerns to governments
around the world. Convolutional Neural Networks (CNNs) demonstrate encouraging
results when detecting fake images that arise from the specific type of
manipulation they are trained on. However, this success has not transitioned to
unseen manipulation types, resulting in a significant gap in the
line-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,
which is able to successfully detect faked faces by utilising knowledge stored
in neural memories as well as visual cues to reason about the perceived face
and anticipate its future semantic embeddings. This renders a generalisable
face tampering detection framework. Experimental results demonstrate the
proposed approach achieves superior performance for fake and fraudulent face
detection compared to the state-of-the-art.
"
2340,"Modality to Modality Translation: An Adversarial Representation Learning
  and Graph Fusion Network for Multimodal Fusion","  Learning joint embedding space for various modalities is of vital importance
for multimodal fusion. Mainstream modality fusion approaches fail to achieve
this goal, leaving a modality gap which heavily affects cross-modal fusion. In
this paper, we propose a novel adversarial encoder-decoder-classifier framework
to learn a modality-invariant embedding space. Since the distributions of
various modalities vary in nature, to reduce the modality gap, we translate the
distributions of source modalities into that of target modality via their
respective encoders using adversarial training. Furthermore, we exert
additional constraints on embedding space by introducing reconstruction loss
and classification loss. Then we fuse the encoded representations using
hierarchical graph neural network which explicitly explores unimodal, bimodal
and trimodal interactions in multi-stage. Our method achieves state-of-the-art
performance on multiple datasets. Visualization of the learned embeddings
suggests that the joint embedding space learned by our method is
discriminative.
"
2341,Cluster-wise Unsupervised Hashing for Cross-Modal Similarity Search,"  Large-scale cross-modal hashing similarity retrieval has attracted more and
more attention in modern search applications such as search engines and
autopilot, showing great superiority in computation and storage. However,
current unsupervised cross-modal hashing methods still have some limitations:
(1)many methods relax the discrete constraints to solve the optimization
objective which may significantly degrade the retrieval performance;(2)most
existing hashing model project heterogenous data into a common latent space,
which may always lose sight of diversity in heterogenous data;(3)transforming
real-valued data point to binary codes always results in abundant loss of
information, producing the suboptimal continuous latent space. To overcome
above problems, in this paper, a novel Cluster-wise Unsupervised Hashing (CUH)
method is proposed. Specifically, CUH jointly performs the multi-view
clustering that projects the original data points from different modalities
into its own low-dimensional latent semantic space and finds the cluster
centroid points and the common clustering indicators in its own low-dimensional
space, and learns the compact hash codes and the corresponding linear hash
functions. An discrete optimization framework is developed to learn the unified
binary codes across modalities under the guidance cluster-wise code-prototypes.
The reasonableness and effectiveness of CUH is well demonstrated by
comprehensive experiments on diverse benchmark datasets.
"
2342,"A Knowledge-Driven Quality-of-Experience Model for Adaptive Streaming
  Videos","  The fundamental conflict between the enormous space of adaptive streaming
videos and the limited capacity for subjective experiment casts significant
challenges to objective Quality-of-Experience (QoE) prediction. Existing
objective QoE models exhibit complex functional form, failing to generalize
well in diverse streaming environments. In this study, we propose an objective
QoE model namely knowledge-driven streaming quality index (KSQI) to integrate
prior knowledge on the human visual system and human annotated data in a
principled way. By analyzing the subjective characteristics towards streaming
videos from a corpus of subjective studies, we show that a family of QoE
functions lies in a convex set. Using a variant of projected gradient descent,
we optimize the objective QoE model over a database of training videos. The
proposed KSQI demonstrates strong generalizability to diverse streaming
environments, evident by state-of-the-art performance on four publicly
available benchmark datasets.
"
2343,"Unsupervised Domain Adaptation via Structured Prediction Based Selective
  Pseudo-Labeling","  Unsupervised domain adaptation aims to address the problem of classifying
unlabeled samples from the target domain whilst labeled samples are only
available from the source domain and the data distributions are different in
these two domains. As a result, classifiers trained from labeled samples in the
source domain suffer from significant performance drop when directly applied to
the samples from the target domain. To address this issue, different approaches
have been proposed to learn domain-invariant features or domain-specific
classifiers. In either case, the lack of labeled samples in the target domain
can be an issue which is usually overcome by pseudo-labeling. Inaccurate
pseudo-labeling, however, could result in catastrophic error accumulation
during learning. In this paper, we propose a novel selective pseudo-labeling
strategy based on structured prediction. The idea of structured prediction is
inspired by the fact that samples in the target domain are well clustered
within the deep feature space so that unsupervised clustering analysis can be
used to facilitate accurate pseudo-labeling. Experimental results on four
datasets (i.e. Office-Caltech, Office31, ImageCLEF-DA and Office-Home) validate
our approach outperforms contemporary state-of-the-art methods.
"
2344,"Crowd Counting via Segmentation Guided Attention Networks and Curriculum
  Loss","  Automatic crowd behaviour analysis is an important task for intelligent
transportation systems to enable effective flow control and dynamic route
planning for varying road participants. Crowd counting is one of the keys to
automatic crowd behaviour analysis. Crowd counting using deep convolutional
neural networks (CNN) has achieved encouraging progress in recent years.
Researchers have devoted much effort to the design of variant CNN architectures
and most of them are based on the pre-trained VGG16 model. Due to the
insufficient expressive capacity, the backbone network of VGG16 is usually
followed by another cumbersome network specially designed for good counting
performance. Although VGG models have been outperformed by Inception models in
image classification tasks, the existing crowd counting networks built with
Inception modules still only have a small number of layers with basic types of
Inception modules. To fill in this gap, in this paper, we firstly benchmark the
baseline Inception-v3 model on commonly used crowd counting datasets and
achieve surprisingly good performance comparable with or better than most
existing crowd counting models. Subsequently, we push the boundary of this
disruptive work further by proposing a Segmentation Guided Attention Network
(SGANet) with Inception-v3 as the backbone and a novel curriculum loss for
crowd counting. We conduct thorough experiments to compare the performance of
our SGANet with prior arts and the proposed model can achieve state-of-the-art
performance with MAE of 57.6, 6.3 and 87.6 on ShanghaiTechA, ShanghaiTechB and
UCF\_QNRF, respectively.
"
2345,Weakly-Supervised Video Moment Retrieval via Semantic Completion Network,"  Video moment retrieval is to search the moment that is most relevant to the
given natural language query. Existing methods are mostly trained in a
fully-supervised setting, which requires the full annotations of temporal
boundary for each query. However, manually labeling the annotations is actually
time-consuming and expensive. In this paper, we propose a novel
weakly-supervised moment retrieval framework requiring only coarse video-level
annotations for training. Specifically, we devise a proposal generation module
that aggregates the context information to generate and score all candidate
proposals in one single pass. We then devise an algorithm that considers both
exploitation and exploration to select top-K proposals. Next, we build a
semantic completion module to measure the semantic similarity between the
selected proposals and query, compute reward and provide feedbacks to the
proposal generation module for scoring refinement. Experiments on the
ActivityCaptions and Charades-STA demonstrate the effectiveness of our proposed
method.
"
2346,Constrained R-CNN: A general image manipulation detection model,"  Recently, deep learning-based models have exhibited remarkable performance
for image manipulation detection. However, most of them suffer from poor
universality of handcrafted or predetermined features. Meanwhile, they only
focus on manipulation localization and overlook manipulation classification. To
address these issues, we propose a coarse-to-fine architecture named
Constrained R-CNN for complete and accurate image forensics. First, the
learnable manipulation feature extractor learns a unified feature
representation directly from data. Second, the attention region proposal
network effectively discriminates manipulated regions for the next manipulation
classification and coarse localization. Then, the skip structure fuses
low-level and high-level information to refine the global manipulation
features. Finally, the coarse localization information guides the model to
further learn the finer local features and segment out the tampered region.
Experimental results show that our model achieves state-of-the-art performance.
Especially, the F1 score is increased by 28.4%, 73.2%, 13.3% on the NIST16,
COVERAGE, and Columbia dataset.
"
2347,"Mini Lesions Detection on Diabetic Retinopathy Images via Large Scale
  CNN Features","  Diabetic retinopathy (DR) is a diabetes complication that affects eyes. DR is
a primary cause of blindness in working-age people and it is estimated that 3
to 4 million people with diabetes are blinded by DR every year worldwide. Early
diagnosis have been considered an effective way to mitigate such problem. The
ultimate goal of our research is to develop novel machine learning techniques
to analyze the DR images generated by the fundus camera for automatically DR
diagnosis. In this paper, we focus on identifying small lesions on DR fundus
images. The results from our analysis, which include the lesion category and
their exact locations in the image, can be used to facilitate the determination
of DR severity (indicated by DR stages). Different from traditional object
detection for natural images, lesion detection for fundus images have unique
challenges. Specifically, the size of a lesion instance is usually very small,
compared with the original resolution of the fundus images, making them
diffcult to be detected. We analyze the lesion-vs-image scale carefully and
propose a large-size feature pyramid network (LFPN) to preserve more image
details for mini lesion instance detection. Our method includes an effective
region proposal strategy to increase the sensitivity. The experimental results
show that our proposed method is superior to the original feature pyramid
network (FPN) method and Faster RCNN.
"
2348,Explanation vs Attention: A Two-Player Game to Obtain Attention for VQA,"  In this paper, we aim to obtain improved attention for a visual question
answering (VQA) task. It is challenging to provide supervision for attention.
An observation we make is that visual explanations as obtained through class
activation mappings (specifically Grad-CAM) that are meant to explain the
performance of various networks could form a means of supervision. However, as
the distributions of attention maps and that of Grad-CAMs differ, it would not
be suitable to directly use these as a form of supervision. Rather, we propose
the use of a discriminator that aims to distinguish samples of visual
explanation and attention maps. The use of adversarial training of the
attention regions as a two-player game between attention and explanation serves
to bring the distributions of attention maps and visual explanations closer.
Significantly, we observe that providing such a means of supervision also
results in attention maps that are more closely related to human attention
resulting in a substantial improvement over baseline stacked attention network
(SAN) models. It also results in a good improvement in rank correlation metric
on the VQA task. This method can also be combined with recent MCB based methods
and results in consistent improvement. We also provide comparisons with other
means for learning distributions such as based on Correlation Alignment
(Coral), Maximum Mean Discrepancy (MMD) and Mean Square Error (MSE) losses and
observe that the adversarial loss outperforms the other forms of learning the
attention maps. Visualization of the results also confirms our hypothesis that
attention maps improve using this form of supervision.
"
2349,"Learning mappings onto regularized latent spaces for biometric
  authentication","  We propose a novel architecture for generic biometric authentication based on
deep neural networks: RegNet. Differently from other methods, RegNet learns a
mapping of the input biometric traits onto a target distribution in a
well-behaved space in which users can be separated by means of simple and
tunable boundaries. More specifically, authorized and unauthorized users are
mapped onto two different and well behaved Gaussian distributions. The novel
approach of learning the mapping instead of the boundaries further avoids the
problem encountered in typical classifiers for which the learnt boundaries may
be complex and difficult to analyze. RegNet achieves high performance in terms
of security metrics such as Equal Error Rate (EER), False Acceptance Rate (FAR)
and Genuine Acceptance Rate (GAR). The experiments we conducted on publicly
available datasets of face and fingerprint confirm the effectiveness of the
proposed system.
"
2350,The dynamics of the stomatognathic system from 4D multimodal data,"  The purpose of this chapter is to discuss methods of acquisition,
visualization and analysis of the dynamics of a complex biomedical system,
illustrated by the human stomatognathic system. The stomatognathic system
consists of the teeth and the skull bones with the maxilla and the mandible.
Its dynamics can be described by the change of mutual position of the
lower/mandibular part versus the upper/maxillary one due to the physiological
motion of opening, chewing and swallowing. In order to analyse the dynamics of
the stomatognathic system its morphology and motion has to be digitized, which
is done using static and dynamic multimodal imagery like CBCT and 3D scans data
and temporal measurements of motion. The integration of multimodal data
incorporates different direct and indirect methods of registration - aligning
of all the data in the same coordinate system. The integrated sets of data form
4D multimodal data which can be further visualized, modeled, and subjected to
multivariate time series analysis. Example results are shown. Although there is
no direct method of imaging the TMJ motion, the integration of multimodal data
forms an adequate tool. As medical imaging becomes ever more diverse and ever
more accessible, organizing the imagery and measurements into unified,
comprehensive records can deliver to the doctor the most information in the
most accessible form, creating a new quality in data simulation, analysis and
interpretation.
"
2351,Impact of the Net Neutrality Repeal on Communication Networks,"  Network neutrality (net neutrality) is the principle of treating equally all
Internet traffic regardless of its source, destination, content, application or
other related distinguishing metrics. Under net neutrality, ISPs are compelled
to charge all content providers (CPs) the same per Gbps rate despite the
growing profit achieved by CPs. In this paper, we study the impact of the
repeal of net neutrality on communication networks by developing a
techno-economic Mixed Integer Linear Programming (MILP) model to maximize the
potential profit ISPs can achieve by offering their services to CPs. We focus
on video delivery as video traffic accounts for 78% of the cloud traffic. We
consider an ISP that offers CPs different classes of service representing
typical video content qualities including standard definition (SD), high
definition (HD) and ultra-high definition (UHD) video. The MILP model maximizes
the ISP profit by optimizing the prices of the different classes according to
the users demand sensitivity to the change in price, referred to as Price
Elasticity of Demand (PED). We analyze how PED impacts the profit in different
CP delivery scenarios in cloud-fog architectures. The results show that the
repeal of net neutrality can potentially increase ISPs profit by a factor of 8
with a pricing scheme that discriminates against data intensive content. Also,
the repeal of net neutrality positively impacts the network energy efficiency
by reducing the core network power consumption by 55% as a result of
suppressing data intensive content compared to the net neutrality scenario.
"
2352,"An End-to-End Audio Classification System based on Raw Waveforms and
  Mix-Training Strategy","  Audio classification can distinguish different kinds of sounds, which is
helpful for intelligent applications in daily life. However, it remains a
challenging task since the sound events in an audio clip is probably multiple,
even overlapping. This paper introduces an end-to-end audio classification
system based on raw waveforms and mix-training strategy. Compared to
human-designed features which have been widely used in existing research, raw
waveforms contain more complete information and are more appropriate for
multi-label classification. Taking raw waveforms as input, our network consists
of two variants of ResNet structure which can learn a discriminative
representation. To explore the information in intermediate layers, a
multi-level prediction with attention structure is applied in our model.
Furthermore, we design a mix-training strategy to break the performance
limitation caused by the amount of training data. Experiments show that the
mean average precision of the proposed audio classification system on Audio Set
dataset is 37.2%. Without using extra training data, our system exceeds the
state-of-the-art multi-level attention model.
"
2353,"An Introduction to Symbolic Artificial Intelligence Applied to
  Multimedia","  In this chapter, we give an introduction to symbolic artificial intelligence
(AI) and discuss its relation and application to multimedia. We begin by
defining what symbolic AI is, what distinguishes it from non-symbolic
approaches, such as machine learning, and how it can used in the construction
of advanced multimedia applications. We then introduce description logic (DL)
and use it to discuss symbolic representation and reasoning. DL is the logical
underpinning of OWL, the most successful family of ontology languages. After
discussing DL, we present OWL and related Semantic Web technologies, such as
RDF and SPARQL. We conclude the chapter by discussing a hybrid model for
multimedia representation, called Hyperknowledge. Throughout the text, we make
references to technologies and extensions specifically designed to solve the
kinds of problems that arise in multimedia representation.
"
2354,Dual Learning-based Video Coding with Inception Dense Blocks,"  In this paper, a dual learning-based method in intra coding is introduced for
PCS Grand Challenge. This method is mainly composed of two parts: intra
prediction and reconstruction filtering. They use different network structures,
the neural network-based intra prediction uses the full-connected network to
predict the block while the neural network-based reconstruction filtering
utilizes the convolutional networks. Different with the previous filtering
works, we use a network with more powerful feature extraction capabilities in
our reconstruction filtering network. And the filtering unit is the block-level
so as to achieve a more accurate filtering compensation. To our best knowledge,
among all the learning-based methods, this is the first attempt to combine two
different networks in one application, and we achieve the state-of-the-art
performance for AI configuration on the HEVC Test sequences. The experimental
result shows that our method leads to significant BD-rate saving for provided 8
sequences compared to HM-16.20 baseline (average 10.24% and 3.57% bitrate
reductions for all-intra and random-access coding, respectively). For HEVC test
sequences, our model also achieved a 9.70% BD-rate saving compared to HM-16.20
baseline for all-intra configuration.
"
2355,Analysis of Evolutionary Behavior in Self-Learning Media Search Engines,"  The diversity of intrinsic qualities of multimedia entities tends to impede
their effective retrieval. In a SelfLearning Search Engine architecture, the
subtle nuances of human perceptions and deep knowledge are taught and captured
through unsupervised reinforcement learning, where the degree of reinforcement
may be suitably calibrated. Such architectural paradigm enables indexes to
evolve naturally while accommodating the dynamic changes of user interests. It
operates by continuously constructing indexes over time, while injecting
progressive improvement in search performance. For search operations to be
effective, convergence of index learning is of crucial importance to ensure
efficiency and robustness. In this paper, we develop a Self-Learning Search
Engine architecture based on reinforcement learning using a Markov Decision
Process framework. The balance between exploration and exploitation is achieved
through evolutionary exploration Strategies. The evolutionary index learning
behavior is then studied and formulated using stochastic analysis. Experimental
results are presented which corroborate the steady convergence of the index
evolution mechanism. Index Term
"
2356,"Performance Effectiveness of Multimedia Information Search Using the
  Epsilon-Greedy Algorithm","  In the search and retrieval of multimedia objects, it is impractical to
either manually or automatically extract the contents for indexing since most
of the multimedia contents are not machine extractable, while manual extraction
tends to be highly laborious and time-consuming. However, by systematically
capturing and analyzing the feedback patterns of human users, vital information
concerning the multimedia contents can be harvested for effective indexing and
subsequent search. By learning from the human judgment and mental evaluation of
users, effective search indices can be gradually developed and built up, and
subsequently be exploited to find the most relevant multimedia objects. To
avoid hovering around a local maximum, we apply the epsilon-greedy method to
systematically explore the search space. Through such methodic exploration, we
show that the proposed approach is able to guarantee that the most relevant
objects can always be discovered, even though initially it may have been
overlooked or not regarded as relevant. The search behavior of the present
approach is quantitatively analyzed, and closed-form expressions are obtained
for the performance of two variants of the epsilon-greedy algorithm, namely
EGSE-A and EGSE-B. Simulations and experiments on real data set have been
performed which show good agreement with the theoretical findings. The present
method is able to leverage exploration in an effective way to significantly
raise the performance of multimedia information search, and enables the certain
discovery of relevant objects which may be otherwise undiscoverable.
"
2357,Kernelized Multiview Subspace Analysis by Self-weighted Learning,"  With the popularity of multimedia technology, information is always
represented or transmitted from multiple views. Most of the existing algorithms
are graph-based ones to learn the complex structures within multiview data but
overlooked the information within data representations. Furthermore, many
existing works treat multiple views discriminatively by introducing some
hyperparameters, which is undesirable in practice. To this end, abundant
multiview based methods have been proposed for dimension reduction. However,
there are still no research to leverage the existing work into a unified
framework. To address this issue, in this paper, we propose a general framework
for multiview data dimension reduction, named Kernelized Multiview Subspace
Analysis (KMSA). It directly handles the multi-view feature representation in
the kernel space, which provides a feasible channel for direct manipulations on
multiview data with different dimensions. Meanwhile, compared with those
graph-based methods, KMSA can fully exploit information from multiview data
with nothing to lose. Furthermore, since different views have different
influences on KMSA, we propose a self-weighted strategy to treat different
views discriminatively according to their contributions. A co-regularized term
is proposed to promote the mutual learning from multi-views. KMSA combines
self-weighted learning with the co-regularized term to learn appropriate
weights for all views. We also discuss the influence of the parameters in KMSA
regarding the weights of multi-views. We evaluate our proposed framework on 6
multiview datasets for classification and image retrieval. The experimental
results validate the advantages of our proposed method.
"
2358,A Proposal-based Approach for Activity Image-to-Video Retrieval,"  Activity image-to-video retrieval task aims to retrieve videos containing the
similar activity as the query image, which is a challenging task because videos
generally have many background segments irrelevant to the activity. In this
paper, we utilize R-C3D model to represent a video by a bag of activity
proposals, which can filter out background segments to some extent. However,
there are still noisy proposals in each bag. Thus, we propose an Activity
Proposal-based Image-to-Video Retrieval (APIVR) approach, which incorporates
multi-instance learning into cross-modal retrieval framework to address the
proposal noise issue. Specifically, we propose a Graph Multi-Instance Learning
(GMIL) module with graph convolutional layer, and integrate this module with
classification loss, adversarial loss, and triplet loss in our cross-modal
retrieval framework. Moreover, we propose geometry-aware triplet loss based on
point-to-subspace distance to preserve the structural information of activity
proposals. Extensive experiments on three widely-used datasets verify the
effectiveness of our approach.
"
2359,"GAC-GAN: A General Method for Appearance-Controllable Human Video Motion
  Transfer","  Human video motion transfer has a wide range of applications in multimedia,
computer vision and graphics. Recently, due to the rapid development of
Generative Adversarial Networks (GANs), there has been significant progress in
the field. However, almost all existing GAN-based works are prone to address
the mapping from human motions to video scenes, with scene appearances are
encoded individually in the trained models. Therefore, each trained model can
only generate videos with a specific scene appearance, new models are required
to be trained to generate new appearances. Besides, existing works lack the
capability of appearance control. For example, users have to provide video
records of wearing new clothes or performing in new backgrounds to enable
clothes or background changing in their synthetic videos, which greatly limits
the application flexibility. In this paper, we propose GAC-GAN, a general
method for appearance-controllable human video motion transfer. To enable
general-purpose appearance synthesis, we propose to include appearance
information in the conditioning inputs. Thus, once trained, our model can
generate new appearances by altering the input appearance information. To
achieve appearance control, we first obtain the appearance-controllable
conditioning inputs and then utilize a two-stage GAC-GAN to generate the
corresponding appearance-controllable outputs, where we utilize an ACGAN loss
and a shadow extraction module for output foreground and background appearance
control respectively. We further build a solo dance dataset containing a large
number of dance videos for training and evaluation. Experimental results show
that, our proposed GAC-GAN can not only support appearance-controllable human
video motion transfer but also achieve higher video quality than state-of-art
methods.
"
2360,Text2FaceGAN: Face Generation from Fine Grained Textual Descriptions,"  Powerful generative adversarial networks (GAN) have been developed to
automatically synthesize realistic images from text. However, most existing
tasks are limited to generating simple images such as flowers from captions. In
this work, we extend this problem to the less addressed domain of face
generation from fine-grained textual descriptions of face, e.g., ""A person has
curly hair, oval face, and mustache"". We are motivated by the potential of
automated face generation to impact and assist critical tasks such as criminal
face reconstruction. Since current datasets for the task are either very small
or do not contain captions, we generate captions for images in the CelebA
dataset by creating an algorithm to automatically convert a list of attributes
to a set of captions. We then model the highly multi-modal problem of text to
face generation as learning the conditional distribution of faces (conditioned
on text) in same latent space. We utilize the current state-of-the-art GAN
(DC-GAN with GAN-CLS loss) for learning conditional multi-modality. The
presence of more fine-grained details and variable length of the captions makes
the problem easier for a user but more difficult to handle compared to the
other text-to-image tasks. We flipped the labels for real and fake images and
added noise in discriminator. Generated images for diverse textual descriptions
show promising results. In the end, we show how the widely used inceptions
score is not a good metric to evaluate the performance of generative models
used for synthesizing faces from text.
"
2361,Bridging the Gap between Semantics and Multimedia Processing,"  In this paper, we give an overview of the semantic gap problem in multimedia
and discuss how machine learning and symbolic AI can be combined to narrow this
gap. We describe the gap in terms of a classical architecture for multimedia
processing and discuss a structured approach to bridge it. This approach
combines machine learning (for mapping signals to objects) and symbolic AI (for
linking objects to meanings). Our main goal is to raise awareness and discuss
the challenges involved in this structured approach to multimedia
understanding, especially in the view of the latest developments in machine
learning and symbolic AI.
"
2362,"A Graph-based Ranking Approach to Extract Key-frames for Static Video
  Summarization","  Video abstraction has become one of the efficient approaches to grasp the
content of a video without seeing it entirely. Key frame-based static video
summarization falls under this category. In this paper, we propose a
graph-based approach which summarizes the video with best user satisfaction. We
treated each video frame as a node of the graph and assigned a rank to each
node by our proposed VidRank algorithm. We developed three different models of
VidRank algorithm and performed a comparative study on those models. A
comprehensive evaluation of 50 videos from open video database using objective
and semi-objective measures indicates the superiority of our static video
summary generation method.
"
2363,"An Attention-Based Speaker Naming Method for Online Adaptation in
  Non-Fixed Scenarios","  A speaker naming task, which finds and identifies the active speaker in a
certain movie or drama scene, is crucial for dealing with high-level video
analysis applications such as automatic subtitle labeling and video
summarization. Modern approaches have usually exploited biometric features with
a gradient-based method instead of rule-based algorithms. In a certain
situation, however, a naive gradient-based method does not work efficiently.
For example, when new characters are added to the target identification list,
the neural network needs to be frequently retrained to identify new people and
it causes delays in model preparation. In this paper, we present an
attention-based method which reduces the model setup time by updating the newly
added data via online adaptation without a gradient update process. We
comparatively analyzed with three evaluation metrics(accuracy, memory usage,
setup time) of the attention-based method and existing gradient-based methods
under various controlled settings of speaker naming. Also, we applied existing
speaker naming models and the attention-based model to real video to prove that
our approach shows comparable accuracy to the existing state-of-the-art models
and even higher accuracy in some cases.
"
2364,"Automated speech-based screening of depression using deep convolutional
  neural networks","  Early detection and treatment of depression is essential in promoting
remission, preventing relapse, and reducing the emotional burden of the
disease. Current diagnoses are primarily subjective, inconsistent across
professionals, and expensive for individuals who may be in urgent need of help.
This paper proposes a novel approach to automated depression detection in
speech using convolutional neural network (CNN) and multipart interactive
training. The model was tested using 2568 voice samples obtained from 77
non-depressed and 30 depressed individuals. In experiment conducted, data were
applied to residual CNNs in the form of spectrograms, images auto-generated
from audio samples. The experimental results obtained using different ResNet
architectures gave a promising baseline accuracy reaching 77%.
"
2365,The Plausibility Paradox for Scaled-Down Users in Virtual Environments,"  This paper identifies a new phenomenon: when users interact with simulated
objects in a virtual environment where the user is much smaller than usual,
there is a mismatch between the object physics that they expect and the object
physics that would be correct at that scale. We report the findings of our
study investigating the relationship between perceived realism and a physically
accurate approximation of reality in a virtual reality experience in which the
user has been scaled down by a factor of ten. We conducted a within-subjects
experiment in which 44 subjects performed a simple interaction task with
objects under two different physics simulation conditions. In one condition,
the objects, when dropped and thrown, behaved accurately according to the
physics that would be correct at that reduced scale in the real world, our true
physics condition. In the other condition, the movie physics condition, the
objects behaved in a similar manner as they would if no scaling of the user had
occurred. We found that a significant majority of the users considered the
latter condition to be the more realistic one. We argue that our findings have
implications for many virtual reality and telepresence applications involving
operation with simulated or physical objects in small scales.
"
2366,"Investigating U-Nets with various Intermediate Blocks for
  Spectrogram-based Singing Voice Separation","  Singing Voice Separation (SVS) tries to separate singing voice from a given
mixed musical signal. Recently, many U-Net-based models have been proposed for
the SVS task, but there were no existing works that evaluate and compare
various types of intermediate blocks that can be used in the U-Net
architecture. In this paper, we introduce a variety of intermediate spectrogram
transformation blocks. We implement U-nets based on these blocks and train them
on complex-valued spectrograms to consider both magnitude and phase. These
networks are then compared on the SDR metric. When using a particular block
composed of convolutional and fully-connected layers, it achieves
state-of-the-art SDR on the MUSDB singing voice separation task by a large
margin of 0.9 dB. Our code and models are available online.
"
2367,"5G network slicing using SDN and NFV- A survey of taxonomy,
  architectures and future challenges","  In this paper, we provide a comprehensive review and updated solutions
related to 5G network slicing using SDN and NFV. Firstly, we present 5G service
quality and business requirements followed by a description of 5G network
softwarization and slicing paradigms including essential concepts, history and
different use cases. Secondly, we provide a tutorial of 5G network slicing
technology enablers including SDN, NFV, MEC, cloud/Fog computing, network
hypervisors, virtual machines & containers. Thidly, we comprehensively survey
different industrial initiatives and projects that are pushing forward the
adoption of SDN and NFV in accelerating 5G network slicing. A comparison of
various 5G architectural approaches in terms of practical implementations,
technology adoptions and deployment strategies is presented. Moreover, we
provide a discussion on various open source orchestrators and proof of concepts
representing industrial contribution. The work also investigates the
standardization efforts in 5G networks regarding network slicing and
softwarization. Additionally, the article presents the management and
orchestration of network slices in a single domain followed by a comprehensive
survey of management and orchestration approaches in 5G network slicing across
multiple domains while supporting multiple tenants. Furthermore, we highlight
the future challenges and research directions regarding network softwarization
and slicing using SDN and NFV in 5G networks.
"
2368,"Reversible Data Hiding in Encrypted Images Using MSBs Integration and
  Histogram Modification","  This paper presents a reversible data hiding in encrypted image that employs
based notions of the RDH in plain-image schemes including histogram
modification and prediction-error computation. In the proposed method, original
image may be encrypted by desire encryption algorithm. Most significant bit
(MSB) of encrypted pixels are integrated to vacate room for embedding data
bits. Integrated ones will be more resistant against failure of reconstruction
if they are modified for embedding data bits. At the recipient, we employ
chess-board predictor for lossless reconstruction of the original image by the
aim of prediction-error analysis. Comparing to existent RDHEI algorithms, not
only we propose a separable method to extract data bits, but also content-owner
may attain a perfect reconstruction of the original image without having data
hider key. Experimental results confirm that the proposed algorithm outperforms
state of the art ones.
"
2369,"Learning 2D Temporal Adjacent Networks for Moment Localization with
  Natural Language","  We address the problem of retrieving a specific moment from an untrimmed
video by a query sentence. This is a challenging problem because a target
moment may take place in relations to other temporal moments in the untrimmed
video. Existing methods cannot tackle this challenge well since they consider
temporal moments individually and neglect the temporal dependencies. In this
paper, we model the temporal relations between video moments by a
two-dimensional map, where one dimension indicates the starting time of a
moment and the other indicates the end time. This 2D temporal map can cover
diverse video moments with different lengths, while representing their adjacent
relations. Based on the 2D map, we propose a Temporal Adjacent Network
(2D-TAN), a single-shot framework for moment localization. It is capable of
encoding the adjacent temporal relation, while learning discriminative features
for matching video moments with referring expressions. We evaluate the proposed
2D-TAN on three challenging benchmarks, i.e., Charades-STA, ActivityNet
Captions, and TACoS, where our 2D-TAN outperforms the state-of-the-art.
"
2370,Universal Stego Post-processing for Enhancing Image Steganography,"  It is well known that the designing or improving embedding cost becomes a key
issue for current steganographic methods. Unlike existing works, we propose a
novel framework to enhance the steganography security via post-processing on
the embedding units (i.e., pixel values and DCT coefficients) of stego
directly. In this paper, we firstly analyze the characteristics of STCs
(Syndrome-Trellis Codes), and then design the rule for post-processing to
ensure the correct extraction of hidden message. Since the steganography
artifacts are typically reflected on image residuals, we try to reduce the
residual distance between cover and the modified stego in order to enhance
steganography security. To this end, we model the post-processing as a
non-linear integer programming, and implement it via heuristic search. In
addition, we carefully determine several important issues in the proposed
post-processing, such as the candidate embedding units to be modified, the
direction and amplitude of post-modification, the adaptive filters for getting
residuals, and the distance measure of residuals. Extensive experimental
results evaluated on both hand-crafted steganalytic features and deep learning
based ones demonstrate that the proposed method can effectively enhance the
security of most modern steganographic methods both in spatial and JPEG
domains.
"
2371,"Hybrid Style Siamese Network: Incorporating style loss in complementary
  apparels retrieval","  Image Retrieval grows to be an integral part of fashion e-commerce ecosystem
as it keeps expanding in multitudes. Other than the retrieval of visually
similar items, the retrieval of visually compatible or complementary items is
also an important aspect of it. Normal Siamese Networks tend to work well on
complementary items retrieval. But it fails to identify low level style
features which make items compatible in human eyes. These low level style
features are captured to a large extent in techniques used in neural style
transfer. This paper proposes a mechanism of utilising those methods in this
retrieval task and capturing the low level style features through a hybrid
siamese network coupled with a hybrid loss. The experimental results indicate
that the proposed method outperforms traditional siamese networks in retrieval
tasks for complementary items.
"
2372,"CineFilter: Unsupervised Filtering for Real Time Autonomous Camera
  Systems","  Autonomous camera systems are often subjected to an optimization/filtering
operation to smoothen and stabilize the rough trajectory estimates. Most common
filtering techniques do reduce the irregularities in data; however, they fail
to mimic the behavior of a human cameraman. Global filtering methods modeling
human camera operators have been successful; however, they are limited to
offline settings. In this paper, we propose two online filtering methods called
Cinefilters, which produce smooth camera trajectories that are motivated by
cinematographic principles. The first filter (CineConvex) uses a sliding
window-based convex optimization formulation, and the second (CineCNN) is a CNN
based encoder-decoder model. We evaluate the proposed filters in two different
settings, namely a basketball dataset and a stage performance dataset. Our
models outperform previous methods and baselines on both quantitative and
qualitative metrics. The CineConvex and CineCNN filters operate at about 250fps
and 1000fps, respectively, with a minor latency (half a second), making them
apt for a variety of real-time applications.
"
2373,"Learned Video Compression via Joint Spatial-Temporal Correlation
  Exploration","  Traditional video compression technologies have been developed over decades
in pursuit of higher coding efficiency. Efficient temporal information
representation plays a key role in video coding. Thus, in this paper, we
propose to exploit the temporal correlation using both first-order optical flow
and second-order flow prediction. We suggest an one-stage learning approach to
encapsulate flow as quantized features from consecutive frames which is then
entropy coded with adaptive contexts conditioned on joint spatial-temporal
priors to exploit second-order correlations. Joint priors are embedded in
autoregressive spatial neighbors, co-located hyper elements and temporal
neighbors using ConvLSTM recurrently. We evaluate our approach for the
low-delay scenario with High-Efficiency Video Coding (H.265/HEVC), H.264/AVC
and another learned video compression method, following the common test
settings. Our work offers the state-of-the-art performance, with consistent
gains across all popular test sequences.
"
2374,"CIS-Net: A Novel CNN Model for Spatial Image Steganalysis via Cover
  Image Suppression","  Image steganalysis is a special binary classification problem that aims to
classify natural cover images and suspected stego images which are the results
of embedding very weak secret message signals into covers. How to effectively
suppress cover image content and thus make the classification of cover images
and stego images easier is the key of this task. Recent researches show that
Convolutional Neural Networks (CNN) are very effective to detect steganography
by learning discriminative features between cover images and their stegos.
Several deep CNN models have been proposed via incorporating domain knowledge
of image steganography/steganalysis into the design of the network and achieve
state of the art performance on standard database. Following such direction, we
propose a novel model called Cover Image Suppression Network (CIS-Net), which
improves the performance of spatial image steganalysis by suppressing cover
image content as much as possible in model learning. Two novel layers, the
Single-value Truncation Layer (STL) and Sub-linear Pooling Layer (SPL), are
proposed in this work. Specifically, STL truncates input values into a same
threshold when they are out of a predefined interval. Theoretically, we have
proved that STL can reduce the variance of input feature map without
deteriorating useful information. For SPL, it utilizes sub-linear power
function to suppress large valued elements introduced by cover image contents
and aggregates weak embedded signals via average pooling. Extensive experiments
demonstrate the proposed network equipped with STL and SPL achieves better
performance than rich model classifiers and existing CNN models on challenging
steganographic algorithms.
"
2375,Music-oriented Dance Video Synthesis with Pose Perceptual Loss,"  We present a learning-based approach with pose perceptual loss for automatic
music video generation. Our method can produce a realistic dance video that
conforms to the beats and rhymes of almost any given music. To achieve this, we
firstly generate a human skeleton sequence from music and then apply the
learned pose-to-appearance mapping to generate the final video. In the stage of
generating skeleton sequences, we utilize two discriminators to capture
different aspects of the sequence and propose a novel pose perceptual loss to
produce natural dances. Besides, we also provide a new cross-modal evaluation
to evaluate the dance quality, which is able to estimate the similarity between
two modalities of music and dance. Finally, a user study is conducted to
demonstrate that dance video synthesized by the presented approach produces
surprisingly realistic results. The results are shown in the supplementary
video at https://youtu.be/0rMuFMZa_K4
"
2376,"Efficient Bitmap-based Indexing and Retrieval of Similarity Search Image
  Queries","  Finding similar images is a necessary operation in many multimedia
applications. Images are often represented and stored as a set of
high-dimensional features, which are extracted using localized feature
extraction algorithms. Locality Sensitive Hashing is one of the most popular
approximate processing techniques for finding similar points in
high-dimensional spaces. Locality Sensitive Hashing (LSH) and its variants are
designed to find similar points, but they are not designed to find objects
(such as images, which are made up of a collection of points) efficiently. In
this paper, we propose an index structure, Bitmap-Image LSH (bImageLSH), for
efficient processing of high-dimensional images. Using a real dataset, we
experimentally show the performance benefit of our novel design while keeping
the accuracy of the image results high.
"
2377,"Characterizing Generalized Rate-Distortion Performance of Video Coding:
  An Eigen Analysis Approach","  Rate-distortion (RD) theory is at the heart of lossy data compression. Here
we aim to model the generalized RD (GRD) trade-off between the visual quality
of a compressed video and its encoding profiles (e.g., bitrate and spatial
resolution). We first define the theoretical functional space $\mathcal{W}$ of
the GRD function by analyzing its mathematical properties.We show that
$\mathcal{W}$ is a convex set in a Hilbert space, inspiring a computational
model of the GRD function, and a method of estimating model parameters from
sparse measurements. To demonstrate the feasibility of our idea, we collect a
large-scale database of real-world GRD functions, which turn out to live in a
low-dimensional subspace of $\mathcal{W}$. Combining the GRD reconstruction
framework and the learned low-dimensional space, we create a low-parameter
eigen GRD method to accurately estimate the GRD function of a source video
content from only a few queries. Experimental results on the database show that
the learned GRD method significantly outperforms state-of-the-art empirical RD
estimation methods both in accuracy and efficiency. Last, we demonstrate the
promise of the proposed model in video codec comparison.
"
2378,"Enhanced Spatially Interleaved Techniques for Multi-View Distributed
  Video Coding","  This paper presents a multi-view distributed video coding framework for
independent camera encoding and centralized decoding. Spatio-temporal-view
concealment methods are developed that exploit the interleaved nature of the
employed hybrid KEY/Wyner-Ziv frames for block-wise generation of the side
information (SI). We study a number of view concealment methods and develop a
joint approach that exploits all available correlation for forming the side
information. We apply a diversity technique for fusing multiple such
predictions thereby achieving more reliable results. We additionally introduce
systems enhancements for further improving the rate distortion performance
through selective feedback, inter-view bitplane projection and frame
subtraction. Results show a significant improvement in performance relative to
H.264 intra coding of up to 25% reduction in bitrate or equivalently 2.5 dB
increase in PSNR.
"
2379,"No-Reference Video Quality Assessment using Multi-Level Spatially Pooled
  Features","  Video Quality Assessment (VQA) methods have been designed with a focus on
particular degradation types, usually artificially induced on a small set of
reference videos. Hence, most traditional VQA methods under-perform
in-the-wild. Deep learning approaches have had limited success due to the small
size and diversity of existing VQA datasets, either artificial or authentically
distorted. We introduce a new in-the-wild VQA dataset that is substantially
larger and diverse: FlickrVid-150k. It consists of a coarsely annotated set of
153,841 videos having 5 quality ratings each, and 1600 videos with a minimum of
89 ratings each. Additionally, we propose new efficient VQA approaches
(MLSP-VQA) relying on multi-level spatially pooled deep features (MLSP). They
are extremely well suited for training at scale, compared to deep transfer
learning approaches. Our best method MLSP-VQA-FF improves the Spearman
Rank-order Correlation Coefficient (SRCC) performance metric on the standard
KonVid-1k in-the-wild benchmark dataset to 0.83 surpassing the best existing
deep-learning model (0.8 SRCC) and hand-crafted feature-based method (0.78
SRCC). We further investigate how alternative approaches perform under
different levels of label noise, and dataset size, showing that MLSP-VQA-FF is
the overall best method. Finally, we show that MLSP-VQA-FF trained on
FlickrVid-150k sets the new state-of-the-art for cross-test performance on
KonVid-1k and LIVE-Qualcomm with a 0.79 and 0.58 SRCC, respectively, showing
excellent generalization.
"
2380,"Point Cloud Rendering after Coding: Impacts on Subjective and Objective
  Quality","  Recently, point clouds have shown to be a promising way to represent 3D
visual data for a wide range of immersive applications, from augmented reality
to autonomous cars. Emerging imaging sensors have made easier to perform richer
and denser point cloud acquisition, notably with millions of points, thus
raising the need for efficient point cloud coding solutions. In such a
scenario, it is important to evaluate the impact and performance of several
processing steps in a point cloud communication system, notably the quality
degradations associated to point cloud coding solutions. Moreover, since point
clouds are not directly visualized but rather processed with a rendering
algorithm before shown on any display, the perceived quality of point cloud
data highly depends on the rendering solution. In this context, the main
objective of this paper is to study the impact of several coding and rendering
solutions on the perceived user quality and in the performance of available
objective quality assessment metrics. Another contribution regards the
assessment of recent MPEG point cloud coding solutions for several popular
rendering methods which were never presented before. The conclusions regard the
visibility of three types of coding artifacts for the three considered
rendering approaches as well as the strengths and weakness of objective quality
metrics when point clouds are rendered after coding.
"
2381,Implementation of encryption on telemedicine,"  In the era of technology, data security is one of the most important things
that both individuals and companies need. Information plays a huge role in our
everyday life and keeping it safe should be our number one priority. Nowadays
most of the information is transferred via the internet. One of the ways to use
it is telemedicine. With the help of telemedicine, people can have an
appointment at the doctors without losing their time or money. All of the
information about one's health is transferred through the internet but is it
that safe? What techniques are used to provide the safety of our confidential
information? To guarantee that the information is not changed or that in case
it will be stolen no one can still have access to it.
"
2382,An Efficient Coding Method for Spike Camera using Inter-Spike Intervals,"  Recently, a novel bio-inspired spike camera has been proposed, which
continuously accumulates luminance intensity and fires spikes while the
dispatch threshold is reached. Compared to the conventional frame-based cameras
and the emerging dynamic vision sensors, the spike camera has shown great
advantages in capturing fast-moving scene in a frame-free manner with full
texture reconstruction capabilities. However, it is difficult to transmit or
store the large amount of spike data. To address this problem, we first
investigate the spatiotemporal distribution of inter-spike intervals and
propose an intensity-based measurement of spike train distance. Then, we design
an efficient spike coding method, which integrates the techniques of adaptive
temporal partitioning, intra-/inter-pixel prediction, quantization and entropy
coding into a unified lossy coding framework. Finally, we construct a PKU-Spike
dataset captured by the spike camera to evaluate the compression performance.
The experimental results on the dataset demonstrate that the proposed approach
is effective in compressing such spike data while maintaining the fidelity.
"
2383,"Spatial and Temporal Consistency-Aware Dynamic Adaptive Streaming for
  360-Degree Videos","  The 360-degree video allows users to enjoy the whole scene by interactively
switching viewports. However, the huge data volume of the 360-degree video
limits its remote applications via network. To provide high quality of
experience (QoE) for remote web users, this paper presents a tile-based
adaptive streaming method for 360-degree videos. First, we propose a simple yet
effective rate adaptation algorithm to determine the requested bitrate for
downloading the current video segment by considering the balance between the
buffer length and video quality. Then, we propose to use a Gaussian model to
predict the field of view at the beginning of each requested video segment. To
deal with the circumstance that the view angle is switched during the display
of a video segment, we propose to download all the tiles in the 360-degree
video with different priorities based on a Zipf model. Finally, in order to
allocate bitrates for all the tiles, a two-stage optimization algorithm is
proposed to preserve the quality of tiles in FoV and guarantee the spatial and
temporal smoothness. Experimental results demonstrate the effectiveness and
advantage of the proposed method compared with the state-of-the-art methods.
That is, our method preserves both the quality and the smoothness of tiles in
FoV, thus providing the best QoE for users.
"
2384,Destruction of Image Steganography using Generative Adversarial Networks,"  Digital image steganalysis, or the detection of image steganography, has been
studied in depth for years and is driven by Advanced Persistent Threat (APT)
groups', such as APT37 Reaper, utilization of steganographic techniques to
transmit additional malware to perform further post-exploitation activity on a
compromised host. However, many steganalysis algorithms are constrained to work
with only a subset of all possible images in the wild or are known to produce a
high false positive rate. This results in blocking any suspected image being an
unreasonable policy. A more feasible policy is to filter suspicious images
prior to reception by the host machine. However, how does one optimally filter
specifically to obfuscate or remove image steganography while avoiding
degradation of visual image quality in the case that detection of the image was
a false positive? We propose the Deep Digital Steganography Purifier (DDSP), a
Generative Adversarial Network (GAN) which is optimized to destroy
steganographic content without compromising the perceptual quality of the
original image. As verified by experimental results, our model is capable of
providing a high rate of destruction of steganographic image content while
maintaining a high visual quality in comparison to other state-of-the-art
filtering methods. Additionally, we test the transfer learning capability of
generalizing to to obfuscate real malware payloads embedded into different
image file formats and types using an unseen steganographic algorithm and prove
that our model can in fact be deployed to provide adequate results.
"
2385,"From Patches to Pictures (PaQ-2-PiQ): Mapping the Perceptual Space of
  Picture Quality","  Blind or no-reference (NR) perceptual picture quality prediction is a
difficult, unsolved problem of great consequence to the social and streaming
media industries that impacts billions of viewers daily. Unfortunately, popular
NR prediction models perform poorly on real-world distorted pictures. To
advance progress on this problem, we introduce the largest (by far) subjective
picture quality database, containing about 40000 real-world distorted pictures
and 120000 patches, on which we collected about 4M human judgments of picture
quality. Using these picture and patch quality labels, we built deep
region-based architectures that learn to produce state-of-the-art global
picture quality predictions as well as useful local picture quality maps. Our
innovations include picture quality prediction architectures that produce
global-to-local inferences as well as local-to-global inferences (via
feedback).
"
2386,"Leveraging Topics and Audio Features with Multimodal Attention for Audio
  Visual Scene-Aware Dialog","  With the recent advancements in Artificial Intelligence (AI), Intelligent
Virtual Assistants (IVA) such as Alexa, Google Home, etc., have become a
ubiquitous part of many homes. Currently, such IVAs are mostly audio-based, but
going forward, we are witnessing a confluence of vision, speech and dialog
system technologies that are enabling the IVAs to learn audio-visual groundings
of utterances. This will enable agents to have conversations with users about
the objects, activities and events surrounding them. In this work, we present
three main architectural explorations for the Audio Visual Scene-Aware Dialog
(AVSD): 1) investigating `topics' of the dialog as an important contextual
feature for the conversation, 2) exploring several multimodal attention
mechanisms during response generation, 3) incorporating an end-to-end audio
classification ConvNet, AclNet, into our architecture. We discuss detailed
analysis of the experimental results and show that our model variations
outperform the baseline system presented for the AVSD task.
"
2387,"Look, Read and Feel: Benchmarking Ads Understanding with Multimodal
  Multitask Learning","  Given the massive market of advertising and the sharply increasing online
multimedia content (such as videos), it is now fashionable to promote
advertisements (ads) together with the multimedia content. It is exhausted to
find relevant ads to match the provided content manually, and hence, some
automatic advertising techniques are developed. Since ads are usually hard to
understand only according to its visual appearance due to the contained visual
metaphor, some other modalities, such as the contained texts, should be
exploited for understanding. To further improve user experience, it is
necessary to understand both the topic and sentiment of the ads. This motivates
us to develop a novel deep multimodal multitask framework to integrate multiple
modalities to achieve effective topic and sentiment prediction simultaneously
for ads understanding. In particular, our model first extracts multimodal
information from ads and learn high-level and comparable representations. The
visual metaphor of the ad is decoded in an unsupervised manner. The obtained
representations are then fed into the proposed hierarchical multimodal
attention modules to learn task-specific representations for final prediction.
A multitask loss function is also designed to train both the topic and
sentiment prediction models jointly in an end-to-end manner. We conduct
extensive experiments on the latest and large advertisement dataset and achieve
state-of-the-art performance for both prediction tasks. The obtained results
could be utilized as a benchmark for ads understanding.
"
2388,Hiding Data in Images Using Cryptography and Deep Neural Network,"  Steganography is an art of obscuring data inside another quotidian file of
similar or varying types. Hiding data has always been of significant importance
to digital forensics. Previously, steganography has been combined with
cryptography and neural networks separately. Whereas, this research combines
steganography, cryptography with the neural networks all together to hide an
image inside another container image of the larger or same size. Although the
cryptographic technique used is quite simple, but is effective when convoluted
with deep neural nets. Other steganography techniques involve hiding data
efficiently, but in a uniform pattern which makes it less secure. This method
targets both the challenges and make data hiding secure and non-uniform.
"
2389,"JPEG Image Compression using the Discrete Cosine Transform: An Overview,
  Applications, and Hardware Implementation","  Digital images are becoming large in size containing more information day by
day to represent the as is state of the original one due to the availability of
high resolution digital cameras, smartphones, and medical tests images.
Therefore, we need to come up with some technique to convert these images into
smaller size without loosing much information from the actual. There are both
lossy and lossless image compression format available and JPEG is one of the
popular lossy compression among them. In this paper, we present the
architecture and implementation of JPEG compression using VHDL (VHSIC Hardware
Description Language) and compare the performance with some contemporary
implementation. JPEG compression takes place in five steps with color space
conversion, down sampling, discrete cosine transformation (DCT), quantization,
and entropy encoding. The five steps cover for the compression purpose only.
Additionally, we implement the reverse order in VHDL to get the original image
back. We use optimized matrix multiplication and quantization for DCT to
achieve better performance. Our experimental results show that significant
amount of compression ratio has been achieved with very little change in the
images, which is barely noticeable to human eye.
"
2390,"Visual Summarization of Scholarly Videos using Word Embeddings and
  Keyphrase Extraction","  Effective learning with audiovisual content depends on many factors. Besides
the quality of the learning resource's content, it is essential to discover the
most relevant and suitable video in order to support the learning process most
effectively. Video summarization techniques facilitate this goal by providing a
quick overview over the content. It is especially useful for longer recordings
such as conference presentations or lectures. In this paper, we present an
approach that generates a visual summary of video content based on semantic
word embeddings and keyphrase extraction. For this purpose, we exploit video
annotations that are automatically generated by speech recognition and video
OCR (optical character recognition).
"
2391,"Reducing Storage in Large-Scale Photo Sharing Services using
  Recompression","  The popularity of photo sharing services has increased dramatically in recent
years. Increases in users, quantity of photos, and quality/resolution of photos
combined with the user expectation that photos are reliably stored indefinitely
creates a growing burden on the storage backend of these services. We identify
a new opportunity for storage savings with application-specific compression for
photo sharing services: photo recompression.
  We explore new photo storage management techniques that are fast so they do
not adversely affect photo download latency, are complementary to existing
distributed erasure coding techniques, can efficiently be converted to the
standard JPEG user devices expect, and significantly increase compression. We
implement our photo recompression techniques in two novel codecs, ROMP and
L-ROMP. ROMP is a lossless JPEG recompression codec that compresses typical
photos 15% over standard JPEG. L-ROMP is a lossy JPEG recompression codec that
distorts photos in a perceptually un-noticeable way and typically achieves 28%
compression over standard JPEG. We estimate the benefits of our approach on
Facebook's photo stack and find that our approaches can reduce the photo
storage by 0.3-0.9x the logical size of the stored photos, and offer
additional, collateral benefits to the photo caching stack, including 5-11%
fewer requests to the backend storage, 15-31% reduction in wide-area bandwidth,
and 16% reduction in external bandwidth.
"
2392,"Quality of Experience for Streaming Services: Measurements, Challenges
  and Insights","  Over the last few years, the evolution of network and user handsets'
technologies, have challenged the telecom industry and the Internet ecosystem.
Especially, the unprecedented progress of multimedia streaming services like
YouTube, Vimeo and DailyMotion resulted in an impressive demand growth and a
significant need of Quality of Service (QoS) (e.g., high data rate, low
latency/jitter, etc.). Mainly, numerous difficulties are to be considered while
delivering a specific service, such as a strict QoS, human-centric features,
massive number of devices, heterogeneous devices and networks, and
uncontrollable environments. Thenceforth, the concept of Quality of Experience
(QoE) is gaining visibility, and tremendous research efforts have been spent on
improving and/or delivering reliable and addedvalue services, at a high user
experience. In this paper, we present the importance of QoE in wireless and
mobile networks (4G, 5G, and beyond), by providing standard definitions and the
most important measurement methods developed. Moreover, we exhibit notable
enhancements and controlling approaches proposed by researchers to meet the
user expectation in terms of service experience.
"
2393,"Partition-Aware Adaptive Switching Neural Networks for Post-Processing
  in HEVC","  This paper addresses neural network based post-processing for the
state-of-the-art video coding standard, High Efficiency Video Coding (HEVC). We
first propose a partition-aware Convolution Neural Network (CNN) that utilizes
the partition information produced by the encoder to assist in the
post-processing. In contrast to existing CNN-based approaches, which only take
the decoded frame as input, the proposed approach considers the coding unit
(CU) size information and combines it with the distorted decoded frame such
that the artifacts introduced by HEVC are efficiently reduced. We further
introduce an adaptive-switching neural network (ASN) that consists of multiple
independent CNNs to adaptively handle the variations in content and distortion
within compressed-video frames, providing further reduction in visual
artifacts. Additionally, an iterative training procedure is proposed to train
these independent CNNs attentively on different local patch-wise classes.
Experiments on benchmark sequences demonstrate the effectiveness of our
partition-aware and adaptive-switching neural networks. The source code can be
found at http://min.sjtu.edu.cn/lwydemo/HEVCpostprocessing.html.
"
2394,"Multi-Modal Attention-based Fusion Model for Semantic Segmentation of
  RGB-Depth Images","  The 3D scene understanding is mainly considered as a crucial requirement in
computer vision and robotics applications. One of the high-level tasks in 3D
scene understanding is semantic segmentation of RGB-Depth images. With the
availability of RGB-D cameras, it is desired to improve the accuracy of the
scene understanding process by exploiting the depth features along with the
appearance features. As depth images are independent of illumination, they can
improve the quality of semantic labeling alongside RGB images. Consideration of
both common and specific features of these two modalities improves the
performance of semantic segmentation. One of the main problems in RGB-Depth
semantic segmentation is how to fuse or combine these two modalities to achieve
more advantages of each modality while being computationally efficient.
Recently, the methods that encounter deep convolutional neural networks have
reached the state-of-the-art results by early, late, and middle fusion
strategies. In this paper, an efficient encoder-decoder model with the
attention-based fusion block is proposed to integrate mutual influences between
feature maps of these two modalities. This block explicitly extracts the
interdependences among concatenated feature maps of these modalities to exploit
more powerful feature maps from RGB-Depth images. The extensive experimental
results on three main challenging datasets of NYU-V2, SUN RGB-D, and Stanford
2D-3D-Semantic show that the proposed network outperforms the state-of-the-art
models with respect to computational cost as well as model size. Experimental
results also illustrate the effectiveness of the proposed lightweight
attention-based fusion model in terms of accuracy.
"
2395,"An Ensemble Rate Adaptation Framework for Dynamic Adaptive Streaming
  Over HTTP","  Rate adaptation is one of the most important issues in dynamic adaptive
streaming over HTTP (DASH). Due to the frequent fluctuations of the network
bandwidth and complex variations of video content, it is difficult to deal with
the varying network conditions and video content perfectly by using a single
rate adaptation method. In this paper, we propose an ensemble rate adaptation
framework for DASH, which aims to leverage the advantages of multiple methods
involved in the framework to improve the quality of experience (QoE) of users.
The proposed framework is simple yet very effective. Specifically, the proposed
framework is composed of two modules, i.e., the method pool and method
controller. In the method pool, several rate adap tation methods are
integrated. At each decision time, only the method that can achieve the best
QoE is chosen to determine the bitrate of the requested video segment. Besides,
we also propose two strategies for switching methods, i.e., InstAnt Method
Switching, and InterMittent Method Switching, for the method controller to
determine which method can provide the best QoEs. Simulation results
demonstrate that, the proposed framework always achieves the highest QoE for
the change of channel environment and video complexity, compared with
state-of-the-art rate adaptation methods.
"
2396,"Non-Cooperative Game Theory Based Rate Adaptation for Dynamic Video
  Streaming over HTTP","  Dynamic Adaptive Streaming over HTTP (DASH) has demonstrated to be an
emerging and promising multimedia streaming technique, owing to its capability
of dealing with the variability of networks. Rate adaptation mechanism, a
challenging and open issue, plays an important role in DASH based systems since
it affects Quality of Experience (QoE) of users, network utilization, etc. In
this paper, based on non-cooperative game theory, we propose a novel algorithm
to optimally allocate the limited export bandwidth of the server to multi-users
to maximize their QoE with fairness guaranteed. The proposed algorithm is
proxy-free. Specifically, a novel user QoE model is derived by taking a variety
of factors into account, like the received video quality, the reference buffer
length, and user accumulated buffer lengths, etc. Then, the bandwidth competing
problem is formulated as a non-cooperation game with the existence of Nash
Equilibrium that is theoretically proven. Finally, a distributed iterative
algorithm with stability analysis is proposed to find the Nash Equilibrium.
Compared with state-of-the-art methods, extensive experimental results in terms
of both simulated and realistic networking scenarios demonstrate that the
proposed algorithm can produce higher QoE, and the actual buffer lengths of all
users keep nearly optimal states, i.e., moving around the reference buffer all
the time. Besides, the proposed algorithm produces no playback interruption.
"
2397,Real Time Pattern Matching with Dynamic Normalization,"  Pattern matching in time series data streams is considered to be an essential
data mining problem that still stays challenging for many practical scenarios.
Different factors such as noise, varying amplitude scale or shift, signal
stretches or shrinks in time are all leading to performance degradation of many
existing pattern matching algorithms. In this paper, we introduce a dynamic
z-normalization mechanism allowing for proper signal scaling even under
significant time and amplitude distortions. Based on that, we further propose a
Dynamic Time Warping-based real-time pattern matching method to recover hidden
patterns that can be distorted in both time and amplitude. We evaluate our
proposed method on synthetic and real-world scenarios under realistic
conditions demonstrating its high operational characteristics comparing to
other state-of-the-art pattern matching methods.
"
2398,Structural characterization of musical harmonies,"  Understanding the structural characteristics of harmony is essential for an
effective use of music as a communication medium. Of the three expressive axes
of music (melody, rhythm, harmony), harmony is the foundation on which the
emotional content is built, and its understanding is important in areas such as
multimedia and affective computing. The common tool for studying this kind of
structure in computing science is the formal grammar but, in the case of music,
grammars run into problems due to the ambiguous nature of some of the concepts
defined in music theory. In this paper, we consider one of such constructs:
modulation, that is, the change of key in the middle of a musical piece, an
important tool used by many authors to enhance the capacity of music to express
emotions. We develop a hybrid method in which an evidence-gathering numerical
method detects modulation and then, based on the detected tonalities, a
non-ambiguous grammar can be used for analyzing the structure of each tonal
component. Experiments with music from the XVII and XVIII centuries show that
we can detect the precise point of modulation with an error of at most two
chords in almost 97% of the cases. Finally, we show examples of complete
modulation and structural analysis of musical harmonies.
"
2399,OpenRadar: A Toolkit for Prototyping mmWave Radar Applications,"  Millimeter-Wave (mmWave) radar sensors are gaining popularity for their
robust sensing and increasing imaging capabilities. However, current radar
signal processing is hardware specific, which makes it impossible to build
sensor agnostic solutions. OpenRadar serves as an interface to prototype,
research, and benchmark solutions in a modular manner. This enables creating
software processing stacks in a way that has not yet been extensively explored.
In the wake of increased AI adoption, OpenRadar can accelerate the growth of
the combined fields of radar and AI. The OpenRadar API was released on Oct 2,
2019 as an open-source package under the Apache 2.0 license. The codebase
exists at https://github.com/presenseradar/openradar.
"
2400,"QoE Management of Multimedia Streaming Services in Future Networks: A
  Tutorial and Survey","  We provide in this paper a tutorial and a comprehensive survey of QoE
management solutions in current and future networks. We start with a high level
description of QoE management for multimedia services, which integrates QoE
modelling, monitoring, and optimization. This followed by a discussion of HTTP
Adaptive Streaming (HAS) solutions as the dominant technique for streaming
videos over the best-effort Internet. We then summarize the key elements in
SDN/NFV along with an overview of ongoing research projects, standardization
activities and use cases related to SDN, NFV, and other emerging applications.
We provide a survey of the state-of-the-art of QoE management techniques
categorized into three different groups: a) QoE-aware/driven strategies using
SDN and/or NFV; b) QoE-aware/driven approaches for adaptive streaming over
emerging architectures such as multi-access edge computing, cloud/fog
computing, and information-centric networking; and c) extended QoE management
approaches in new domains such as immersive augmented and virtual reality,
mulsemedia and video gaming applications. Based on the review, we present a
list of identified future QoE management challenges regarding emerging
multimedia applications, network management and orchestration, network slicing
and collaborative service management in softwarized networks. Finally, we
provide a discussion on future research directions with a focus on emerging
research areas in QoE management, such as QoE-oriented business models,
QoE-based big data strategies, and scalability issues in QoE optimization.
"
2401,Text Steganalysis with Attentional LSTM-CNN,"  With the rapid development of Natural Language Processing (NLP) technologies,
text steganography methods have been significantly innovated recently, which
poses a great threat to cybersecurity. In this paper, we propose a novel
attentional LSTM-CNN model to tackle the text steganalysis problem. The
proposed method firstly maps words into semantic space for better exploitation
of the semantic feature in texts and then utilizes a combination of
Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM)
recurrent neural networks to capture both local and long-distance contextual
information in steganography texts. In addition, we apply attention mechanism
to recognize and attend to important clues within suspicious sentences. After
merge feature clues from Convolutional Neural Networks (CNNs) and Recurrent
Neural Networks (RNNs), we use a softmax layer to categorize the input text as
cover or stego. Experiments showed that our model can achieve the state-of-art
result in the text steganalysis task.
"
2402,Hiding Information in Big Data based on Deep Learning,"  The current approach of information hiding based on deep learning model can
not directly use the original data as carriers, which means the approach can
not make use of the existing data in big data to hiding information. We
proposed a novel method of information hiding in big data based on deep
learning. Our method uses the existing data in big data as carriers and uses
deep learning models to hide and extract secret messages in big data. The data
amount of big data is unlimited and thus the data amount of secret messages
hided in big data can also be unlimited. Before opponents want to extract
secret messages from carriers, they need to find the carriers, however finding
out the carriers from big data is just like finding out a box from the sea.
Deep learning models are well known as deep black boxes in which the process
from the input to the output is very complex, and thus the deep learning model
for information hiding is almost impossible for opponents to reconstruct. The
results also show that our method can hide secret messages safely,
conveniently, quickly and with no limitation on the data amount.
"
2403,"Quantum GestART: Identifying and Applying Correlations between
  Mathematics, Art, and Perceptual Organization","  Mathematics can help analyze the arts and inspire new artwork. Mathematics
can also help make transformations from one artistic medium to another,
considering exceptions and choices, as well as artists' individual and unique
contributions. We propose a method based on diagrammatic thinking and quantum
formalism. We exploit decompositions of complex forms into a set of simple
shapes, discretization of complex images, and Dirac notation, imagining a world
of ""prototypes"" that can be connected to obtain a fine or coarse-graining
approximation of a given visual image. Visual prototypes are exchanged with
auditory ones, and the information (position, size) characterizing visual
prototypes is connected with the information (onset, duration, loudness, pitch
range) characterizing auditory prototypes. The topic is contextualized within a
philosophical debate (discreteness and comparison of apparently unrelated
objects), it develops through mathematical formalism, and it leads to
programming, to spark interdisciplinary thinking and ignite creativity within
STEAM.
"
2404,DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection,"  The free access to large-scale public databases, together with the fast
progress of deep learning techniques, in particular Generative Adversarial
Networks, have led to the generation of very realistic fake content with its
corresponding implications towards society in this era of fake news. This
survey provides a thorough review of techniques for manipulating face images
including DeepFake methods, and methods to detect such manipulations. In
particular, four types of facial manipulation are reviewed: i) entire face
synthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv)
expression swap. For each manipulation group, we provide details regarding
manipulation techniques, existing public databases, and key benchmarks for
technology evaluation of fake detection methods, including a summary of results
from those evaluations. Among all the aspects discussed in the survey, we pay
special attention to the latest generation of DeepFakes, highlighting its
improvements and challenges for fake detection.
  In addition to the survey information, we also discuss open issues and future
trends that should be considered to advance in the field.
"
2405,"Biometric and Physical Identifiers with Correlated Noise for
  Controllable Private Authentication","  The problem of secret-key based authentication under privacy and storage
constraints on the source sequence is considered. The identifier measurement
channels during authentication are assumed to be controllable via a
cost-constrained action sequence. Single-letter inner and outer bounds for the
key-leakage-storage-cost regions are derived for a generalization of a classic
two-terminal key agreement model with an eavesdropper that observes a sequence
that is correlated with the sequences observed by the legitimate terminals. The
additions to the model are that the encoder observes a noisy version of a
remote source, and the noisy output and the remote source output together with
an action sequence are given as inputs to the measurement channel at the
decoder. Thus, correlation is introduced between the noise components on the
encoder and decoder measurements. The model with a secret key generated by an
encoder is extended to the randomized models, where a secret-key is embedded to
the encoder. The results are relevant for several user and device
authentication scenarios including physical and biometric identifiers with
multiple measurements that provide diversity and multiplexing gains. To
illustrate the behavior of the rate region, achievable (secret-key rate,
storage-rate, cost) tuples are given for binary identifiers and measurement
channels that can be represented as a mixture of binary symmetric subchannels.
The gains from using an action sequence such as a large secret-key rate at a
significantly small hardware cost, are illustrated to motivate the use of
low-complexity transform-coding algorithms with cost-constrained actions.
"
2406,"Joint Communication and Computational Resource Allocation for QoE-driven
  Point Cloud Video Streaming","  Point cloud video is the most popular representation of hologram, which is
the medium to precedent natural content in VR/AR/MR and is expected to be the
next generation video. Point cloud video system provides users immersive
viewing experience with six degrees of freedom and has wide applications in
many fields such as online education, entertainment. To further enhance these
applications, point cloud video streaming is in critical demand. The inherent
challenges lie in the large size by the necessity of recording the
three-dimensional coordinates besides color information, and the associated
high computation complexity of encoding. To this end, this paper proposes a
communication and computation resource allocation scheme for QoE-driven point
cloud video streaming. In particular, we maximize system resource utilization
by selecting different quantities, transmission forms and quality level tiles
to maximize the quality of experience. Extensive simulations are conducted and
the simulation results show the superior performance over the existing schemes
"
2407,Modeling Musical Structure with Artificial Neural Networks,"  In recent years, artificial neural networks (ANNs) have become a universal
tool for tackling real-world problems. ANNs have also shown great success in
music-related tasks including music summarization and classification,
similarity estimation, computer-aided or autonomous composition, and automatic
music analysis. As structure is a fundamental characteristic of Western music,
it plays a role in all these tasks. Some structural aspects are particularly
challenging to learn with current ANN architectures. This is especially true
for mid- and high-level self-similarity, tonal and rhythmic relationships. In
this thesis, I explore the application of ANNs to different aspects of musical
structure modeling, identify some challenges involved and propose strategies to
address them. First, using probability estimations of a Restricted Boltzmann
Machine (RBM), a probabilistic bottom-up approach to melody segmentation is
studied. Then, a top-down method for imposing a high-level structural template
in music generation is presented, which combines Gibbs sampling using a
convolutional RBM with gradient-descent optimization on the intermediate
solutions. Furthermore, I motivate the relevance of musical transformations in
structure modeling and show how a connectionist model, the Gated Autoencoder
(GAE), can be employed to learn transformations between musical fragments. For
learning transformations in sequences, I propose a special predictive training
of the GAE, which yields a representation of polyphonic music as a sequence of
intervals. Furthermore, the applicability of these interval representations to
a top-down discovery of repeated musical sections is shown. Finally, a
recurrent variant of the GAE is proposed, and its efficacy in music prediction
and modeling of low-level repetition structure is demonstrated.
"
2408,"SUR-FeatNet: Predicting the Satisfied User Ratio Curvefor Image
  Compression with Deep Feature Learning","  The satisfied user ratio (SUR) curve for a lossy image compression scheme,
e.g., JPEG, characterizes the complementary cumulative distribution function of
the just noticeable difference (JND), the smallest distortion level that can be
perceived by a subject when a reference image is compared to a distorted one. A
sequence of JNDs can be defined with a suitable successive choice of reference
images. We propose the first deep learning approach to predict SUR curves. We
show how to apply maximum likelihood estimation and the Anderson-Darling test
to select a suitable parametric model for the distribution function. We then
use deep feature learning to predict samples of the SUR curve and apply the
method of least squares to fit the parametric model to the predicted samples.
Our deep learning approach relies on a siamese convolutional neural network,
transfer learning, and deep feature learning, using pairs consisting of a
reference image and a compressed image for training. Experiments on the MCL-JCI
dataset showed state-of-the-art performance. For example, the mean
Bhattacharyya distances between the predicted and ground truth first, second,
and third JND distributions were 0.0810, 0.0702, and 0.0522, respectively, and
the corresponding average absolute differences of the peak signal-to-noise
ratio at a median of the first JND distribution were 0.58, 0.69, and 0.58 dB.
Further experiments on the JND-Pano dataset showed that the method transfers
well to high resolution panoramic images viewed on head-mounted displays.
"
2409,Natural Steganography in JPEG Domain with a Linear Development Pipeline,"  In order to achieve high practical security, Natural Steganography (NS) uses
cover images captured at ISO sensitivity $ISO_{1}$ and generates stego images
mimicking ISO sensitivity $ISO_{2}>ISO_{1}$. This is achieved by adding a stego
signal to the cover that mimics the sensor photonic noise. This paper proposes
an embedding mechanism to perform NS in the JPEG domain after linear
developments by explicitly computing the correlations between DCT coefficients
before quantization. In order to compute the covariance matrix of the photonic
noise in the DCT domain, we first develop the matrix representation of
demosaicking, luminance averaging, pixel section, and 2D-DCT. A detailed
analysis of the resulting covariance matrix is done in order to explain the
origins of the correlations between the coefficients of $3\times3$ DCT blocks.
An embedding scheme is then presented that takes in order to take into account
all the correlations. It employs 4 sub-lattices and 64 lattices per
sub-lattices. The modification probabilities of each DCT coefficient are then
derived by computing conditional probabilities from the multivariate Gaussian
distribution using the Cholesky decomposition of the covariance matrix. This
derivation is also used to compute the embedding capacity of each image. Using
a specific database called E1 Base, we show that in the JPEG domain NS
(J-Cov-NS) enables to achieve high capacity (more than 2 bits per non-zero AC
DCT) and with high practical security ($P_{\mathrm{E}}\simeq40\%$ using DCTR
from QF 75 to QF 100).
"
2410,"Adaptive Control of Embedding Strength in Image Watermarking using
  Neural Networks","  Digital image watermarking has been widely used in different applications
such as copyright protection of digital media, such as audio, image, and video
files. Two opposing criteria of robustness and transparency are the goals of
watermarking methods. In this paper, we propose a framework for determining the
appropriate embedding strength factor. The framework can use most DWT and DCT
based blind watermarking approaches. We use Mask R-CNN on the COCO dataset to
find a good strength factor for each sub-block. Experiments show that this
method is robust against different attacks and has good transparency.
"
2411,"Measuring Similarity between Brands using Followers' Post in Social
  Media","  In this paper, we propose a new measure to estimate the similarity between
brands via posts of brands' followers on social network services (SNS). Our
method was developed with the intention of exploring the brands that customers
are likely to jointly purchase. Nowadays, brands use social media for targeted
advertising because influencing users' preferences can greatly affect the
trends in sales. We assume that data on SNS allows us to make quantitative
comparisons between brands. Our proposed algorithm analyzes the daily photos
and hashtags posted by each brand's followers. By clustering them and
converting them to histograms, we can calculate the similarity between brands.
We evaluated our proposed algorithm with purchase logs, credit card
information, and answers to the questionnaires. The experimental results show
that the purchase data maintained by a mall or a credit card company can
predict the co-purchase very well, but not the customer's willingness to buy
products of new brands. On the other hand, our method can predict the users'
interest on brands with a correlation value over 0.53, which is pretty high
considering that such interest to brands are high subjective and individual
dependent.
"
2412,"QoE-driven Coupled Uplink and Downlink Rate Adaptation for 360-degree
  Video Live Streaming","  360-degree video provides an immersive 360-degree viewing experience and has
been widely used in many areas. The 360-degree video live streaming systems
involve capturing, compression, uplink (camera to video server) and downlink
(video server to user) transmissions. However, few studies have jointly
investigated such complex systems, especially the rate adaptation for the
coupled uplink and downlink in the 360-degree video streaming under limited
bandwidth constraints. In this letter, we propose a quality of experience
(QoE)-driven 360-degree video live streaming system, in which a video server
performs rate adaptation based on the uplink and downlink bandwidths and
information concerning each user's real-time field-of-view (FOV). We formulate
it as a nonlinear integer programming problem and propose an algorithm, which
combines the Karush-Kuhn-Tucker (KKT) condition and branch and bound method, to
solve it. The numerical results show that the proposed optimization model can
improve users' QoE significantly in comparison with other baseline schemes.
"
2413,"Exploratory Study on User's Dynamic Visual Acuity and Quality Perception
  of Impaired Images","  In this paper we assess the impact of head movement on user's visual acuity
and their quality perception of impaired images. There are physical limitations
on the amount of visual information a person can perceive and physical
limitations regarding the speed at which our body, and as a consequence our
head, can explore a scene. In these limitations lie fundamental solutions for
the communication of multimedia systems. As such, subjects were asked to
evaluate the perceptual quality of static images presented on a TV screen while
their head was in a dynamic (moving) state. The idea is potentially applicable
to virtual reality applications and therefore, we also measured the image
quality perception of each subject on a head mounted display. Experiments show
the significant decrease in visual acuity and quality perception when the
user's head is not static, and give an indication on how much the quality can
be reduced without the user noticing any impairments.
"
2414,Visually Guided Self Supervised Learning of Speech Representations,"  Self supervised representation learning has recently attracted a lot of
research interest for both the audio and visual modalities. However, most works
typically focus on a particular modality or feature alone and there has been
very limited work that studies the interaction between the two modalities for
learning self supervised representations. We propose a framework for learning
audio representations guided by the visual modality in the context of
audiovisual speech. We employ a generative audio-to-video training scheme in
which we animate a still image corresponding to a given audio clip and optimize
the generated video to be as close as possible to the real video of the speech
segment. Through this process, the audio encoder network learns useful speech
representations that we evaluate on emotion recognition and speech recognition.
We achieve state of the art results for emotion recognition and competitive
results for speech recognition. This demonstrates the potential of visual
supervision for learning audio representations as a novel way for
self-supervised learning which has not been explored in the past. The proposed
unsupervised audio features can leverage a virtually unlimited amount of
training data of unlabelled audiovisual speech and have a large number of
potentially promising applications.
"
2415,Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders,"  We present an unsupervised approach that enables us to convert the speech
input of any one individual to an output set of potentially-infinitely many
speakers. One can stand in front of a mic and be able to make their favorite
celebrity say the same words. Our approach builds on simple autoencoders that
project out-of-sample data to the distribution of the training set (motivated
by PCA/linear autoencoders). We use an exemplar autoencoder to learn the voice
and specific style (emotions and ambiance) of a target speaker. In contrast to
existing methods, the proposed approach can be easily extended to an
arbitrarily large number of speakers in a very little time using only two-three
minutes of audio data from a speaker. We also exhibit the usefulness of our
approach for generating video from audio signals and vice-versa. We suggest the
reader to check out our project webpage for various synthesized examples:
https://dunbar12138.github.io/projectpage/Audiovisual/
"
2416,Distortion Agnostic Deep Watermarking,"  Watermarking is the process of embedding information into an image that can
survive under distortions, while requiring the encoded image to have little or
no perceptual difference from the original image. Recently, deep learning-based
methods achieved impressive results in both visual quality and message payload
under a wide variety of image distortions. However, these methods all require
differentiable models for the image distortions at training time, and may
generalize poorly to unknown distortions. This is undesirable since the types
of distortions applied to watermarked images are usually unknown and
non-differentiable. In this paper, we propose a new framework for
distortion-agnostic watermarking, where the image distortion is not explicitly
modeled during training. Instead, the robustness of our system comes from two
sources: adversarial training and channel coding. Compared to training on a
fixed set of distortions and noise levels, our method achieves comparable or
better results on distortions available during training, and better performance
on unknown distortions.
"
2417,"Disseminating Research News in HCI: Perceived Hazards, How-To's, and
  Opportunities for Innovation","  Mass media afford researchers critical opportunities to disseminate research
findings and trends to the general public. Yet researchers also perceive that
their work can be miscommunicated in mass media, thus generating unintended
understandings of HCI research by the general public. We conduct a Grounded
Theory analysis of interviews with 12 HCI researchers and find that
miscommunication can occur at four origins along the socio-technical
infrastructure known as the Media Production Pipeline (MPP) for science news.
Results yield researchers' perceived hazards of disseminating their work
through mass media, as well as strategies for fostering effective communication
of research. We conclude with implications for augmenting or innovating new MPP
technologies.
"
2418,Evaluating image matching methods for book cover identification,"  Humans are capable of identifying a book only by looking at its cover, but
how can computers do the same? In this paper, we explore different feature
detectors and matching methods for book cover identification, and compare their
performances in terms of both speed and accuracy. This will allow, for example,
libraries to develop interactive services based on cover book picture. Only one
single image of a cover book needs to be available through a database. Tests
have been performed by taking into account different transformations of each
book cover image. Encouraging results have been achieved.
"
2419,Everybody's Talkin': Let Me Talk as You Want,"  We present a method to edit a target portrait footage by taking a sequence of
audio as input to synthesize a photo-realistic video. This method is unique
because it is highly dynamic. It does not assume a person-specific rendering
network yet capable of translating arbitrary source audio into arbitrary video
output. Instead of learning a highly heterogeneous and nonlinear mapping from
audio to the video directly, we first factorize each target video frame into
orthogonal parameter spaces, i.e., expression, geometry, and pose, via
monocular 3D face reconstruction. Next, a recurrent network is introduced to
translate source audio into expression parameters that are primarily related to
the audio content. The audio-translated expression parameters are then used to
synthesize a photo-realistic human subject in each video frame, with the
movement of the mouth regions precisely mapped to the source audio. The
geometry and pose parameters of the target human portrait are retained,
therefore preserving the context of the original video footage. Finally, we
introduce a novel video rendering network and a dynamic programming method to
construct a temporally coherent and photo-realistic video. Extensive
experiments demonstrate the superiority of our method over existing approaches.
Our method is end-to-end learnable and robust to voice variations in the source
audio.
"
2420,"Weakly Supervised Video Summarization by Hierarchical Reinforcement
  Learning","  Conventional video summarization approaches based on reinforcement learning
have the problem that the reward can only be received after the whole summary
is generated. Such kind of reward is sparse and it makes reinforcement learning
hard to converge. Another problem is that labelling each frame is tedious and
costly, which usually prohibits the construction of large-scale datasets. To
solve these problems, we propose a weakly supervised hierarchical reinforcement
learning framework, which decomposes the whole task into several subtasks to
enhance the summarization quality. This framework consists of a manager network
and a worker network. For each subtask, the manager is trained to set a subgoal
only by a task-level binary label, which requires much fewer labels than
conventional approaches. With the guide of the subgoal, the worker predicts the
importance scores for video frames in the subtask by policy gradient according
to both global reward and innovative defined sub-rewards to overcome the sparse
problem. Experiments on two benchmark datasets show that our proposal has
achieved the best performance, even better than supervised approaches.
"
2421,"#MeToo on Campus: Studying College Sexual Assault at Scale Using Data
  Reported on Social Media","  Recently, the emergence of the #MeToo trend on social media has empowered
thousands of people to share their own sexual harassment experiences. This
viral trend, in conjunction with the massive personal information and content
available on Twitter, presents a promising opportunity to extract data driven
insights to complement the ongoing survey based studies about sexual harassment
in college. In this paper, we analyze the influence of the #MeToo trend on a
pool of college followers. The results show that the majority of topics
embedded in those #MeToo tweets detail sexual harassment stories, and there
exists a significant correlation between the prevalence of this trend and
official reports on several major geographical regions. Furthermore, we
discover the outstanding sentiments of the #MeToo tweets using deep semantic
meaning representations and their implications on the affected users
experiencing different types of sexual harassment. We hope this study can raise
further awareness regarding sexual misconduct in academia.
"
2422,"Low-latency Cloud-based Volumetric Video Streaming Using Head Motion
  Prediction","  Volumetric video is an emerging key technology for immersive representation
of 3D spaces and objects. Rendering volumetric video requires lots of
computational power which is challenging especially for mobile devices. To
mitigate this, we developed a streaming system that renders a 2D view from the
volumetric video at a cloud server and streams a 2D video stream to the client.
However, such network-based processing increases the motion-to-photon (M2P)
latency due to the additional network and processing delays. In order to
compensate the added latency, prediction of the future user pose is necessary.
We developed a head motion prediction model and investigated its potential to
reduce the M2P latency for different look-ahead times. Our results show that
the presented model reduces the rendering errors caused by the M2P latency
compared to a baseline system in which no prediction is performed.
"
2423,"Information Foraging for Enhancing Implicit Feedback in Content-based
  Image Recommendation","  User implicit feedback plays an important role in recommender systems.
However, finding implicit features is a tedious task. This paper aims to
identify users' preferences through implicit behavioural signals for image
recommendation based on the Information Scent Model of Information Foraging
Theory. In the first part, we hypothesise that the users' perception is
improved with visual cues in the images as behavioural signals that provide
users' information scent during information seeking. We designed a
content-based image recommendation system to explore which image attributes
(i.e., visual cues or bookmarks) help users find their desired image. We found
that users prefer recommendations predicated by visual cues and therefore
consider the visual cues as good information scent for their information
seeking. In the second part, we investigated if visual cues in the images
together with the images itself can be better perceived by the users than each
of them on its own. We evaluated the information scent artifacts in image
recommendation on the Pinterest image collection and the WikiArt dataset. We
find our proposed image recommendation system supports the implicit signals
through Information Foraging explanation of the information scent model.
"
2424,"A multimodal deep learning approach for named entity recognition from
  social media","  Named Entity Recognition (NER) from social media posts is a challenging task.
User generated content that forms the nature of social media, is noisy and
contains grammatical and linguistic errors. This noisy content makes it much
harder for tasks such as named entity recognition. We propose two novel deep
learning approaches utilizing multimodal deep learning and Transformers. Both
of our approaches use image features from short social media posts to provide
better results on the NER task. On the first approach, we extract image
features using InceptionV3 and use fusion to combine textual and image
features. This presents more reliable name entity recognition when the images
related to the entities are provided by the user. On the second approach, we
use image features combined with text and feed it into a BERT like Transformer.
The experimental results, namely, the precision, recall and F1 score metrics
show the superiority of our work compared to other state-of-the-art NER
solutions.
"
2425,"Recommending Themes for Ad Creative Design via Visual-Linguistic
  Representations","  There is a perennial need in the online advertising industry to refresh ad
creatives, i.e., images and text used for enticing online users towards a
brand. Such refreshes are required to reduce the likelihood of ad fatigue among
online users, and to incorporate insights from other successful campaigns in
related product categories. Given a brand, to come up with themes for a new ad
is a painstaking and time consuming process for creative strategists.
Strategists typically draw inspiration from the images and text used for past
ad campaigns, as well as world knowledge on the brands. To automatically infer
ad themes via such multimodal sources of information in past ad campaigns, we
propose a theme (keyphrase) recommender system for ad creative strategists. The
theme recommender is based on aggregating results from a visual question
answering (VQA) task, which ingests the following: (i) ad images, (ii) text
associated with the ads as well as Wikipedia pages on the brands in the ads,
and (iii) questions around the ad. We leverage transformer based cross-modality
encoders to train visual-linguistic representations for our VQA task. We study
two formulations for the VQA task along the lines of classification and
ranking; via experiments on a public dataset, we show that cross-modal
representations lead to significantly better classification accuracy and
ranking precision-recall metrics. Cross-modal representations show better
performance compared to separate image and text representations. In addition,
the use of multimodal information shows a significant lift over using only
textual or visual information.
"
2426,"AutoMATES: Automated Model Assembly from Text, Equations, and Software","  Models of complicated systems can be represented in different ways - in
scientific papers, they are represented using natural language text as well as
equations. But to be of real use, they must also be implemented as software,
thus making code a third form of representing models. We introduce the
AutoMATES project, which aims to build semantically-rich unified
representations of models from scientific code and publications to facilitate
the integration of computational models from different domains and allow for
modeling large, complicated systems that span multiple domains and levels of
abstraction.
"
2427,Evaluation of a course mediatised with Xerte,"  Interactive multimedia educational content has recently been of interest to
attract attention on the learner and increase understanding by the latter. In
parallel several open source authoring tools offer a quick and easy production
of this type of content. As such, our contribution is to mediatize a course
i.e. 'English' with the authoring system 'Xerte' which is intended both for
simple users and developers in ActionScript. An experiment of course is
conducted on a sample of a private school's students. At the end of this
experience, we administered a questionnaire to evaluate the device, the results
obtained, evidenced by the favorable reception of interactive multimedia
integration in educational content.
"
2428,AMP: Authentication of Media via Provenance,"  Advances in graphics and machine learning have led to the general
availability of easy-to-use tools for modifying and synthesizing media. The
proliferation of these tools threatens to cast doubt on the veracity of all
media. One approach to thwarting the flow of fake media is to detect modified
or synthesized media through machine learning methods. While detection may help
in the short term, we believe that it is destined to fail as the quality of
fake media generation continues to improve. Soon, neither humans nor algorithms
will be able to reliably distinguish fake versus real content. Thus, pipelines
for assuring the source and integrity of media will be required---and
increasingly relied upon. We propose AMP, a system that ensures the
authentication of media via certifying provenance. AMP creates one or more
publisher-signed manifests for a media instance uploaded by a content provider.
These manifests are stored in a database allowing fast lookup from applications
such as browsers. For reference, the manifests are also registered and signed
by a permissioned ledger, implemented using the Confidential Consortium
Framework (CCF). CCF employs both software and hardware techniques to ensure
the integrity and transparency of all registered manifests. AMP, through its
use of CCF, enables a consortium of media providers to govern the service while
making all its operations auditable. The authenticity of the media can be
communicated to the user via visual elements in the browser, indicating that an
AMP manifest has been successfully located and verified.
"
2429,Robust Explanations for Visual Question Answering,"  In this paper, we propose a method to obtain robust explanations for visual
question answering(VQA) that correlate well with the answers. Our model
explains the answers obtained through a VQA model by providing visual and
textual explanations. The main challenges that we address are i) Answers and
textual explanations obtained by current methods are not well correlated and
ii) Current methods for visual explanation do not focus on the right location
for explaining the answer. We address both these challenges by using a
collaborative correlated module which ensures that even if we do not train for
noise based attacks, the enhanced correlation ensures that the right
explanation and answer can be generated. We further show that this also aids in
improving the generated visual and textual explanations. The use of the
correlated module can be thought of as a robust method to verify if the answer
and explanations are coherent. We evaluate this model using VQA-X dataset. We
observe that the proposed method yields better textual and visual justification
that supports the decision. We showcase the robustness of the model against a
noise-based perturbation attack using corresponding visual and textual
explanations. A detailed empirical analysis is shown. Here we provide source
code link for our model \url{https://github.com/DelTA-Lab-IITK/CCM-WACV}.
"
2430,Deep Bayesian Network for Visual Question Generation,"  Generating natural questions from an image is a semantic task that requires
using vision and language modalities to learn multimodal representations.
Images can have multiple visual and language cues such as places, captions, and
tags. In this paper, we propose a principled deep Bayesian learning framework
that combines these cues to produce natural questions. We observe that with the
addition of more cues and by minimizing uncertainty in the among cues, the
Bayesian network becomes more confident. We propose a Minimizing Uncertainty of
Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues
experts for generating probabilistic questions. This is a Bayesian framework
and the results show a remarkable similarity to natural questions as validated
by a human study. We observe that with the addition of more cues and by
minimizing uncertainty among the cues, the Bayesian framework becomes more
confident. Ablation studies of our model indicate that a subset of cues is
inferior at this task and hence the principled fusion of cues is preferred.
Further, we observe that the proposed approach substantially improves over
state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE,
and CIDEr). Here we provide project link for Deep Bayesian VQG
\url{https://delta-lab-iitk.github.io/BVQG/}
"
2431,"aiTPR: Attribute Interaction-Tensor Product Representation for Image
  Caption","  Region visual features enhance the generative capability of the machines
based on features, however they lack proper interaction attentional perceptions
and thus ends up with biased or uncorrelated sentences or pieces of
misinformation. In this work, we propose Attribute Interaction-Tensor Product
Representation (aiTPR) which is a convenient way of gathering more information
through orthogonal combination and learning the interactions as physical
entities (tensors) and improving the captions. Compared to previous works,
where features are added up to undefined feature spaces, TPR helps in
maintaining sanity in combinations and orthogonality helps in defining familiar
spaces. We have introduced a new concept layer that defines the objects and
also their interactions that can play a crucial role in determination of
different descriptions. The interaction portions have contributed heavily for
better caption quality and has out-performed different previous works on this
domain and MSCOCO dataset. We introduced, for the first time, the notion of
combining regional image features and abstracted interaction likelihood
embedding for image captioning.
"
2432,"Time-Domain Audio Source Separation Based on Wave-U-Net Combined with
  Discrete Wavelet Transform","  We propose a time-domain audio source separation method using down-sampling
(DS) and up-sampling (US) layers based on a discrete wavelet transform (DWT).
The proposed method is based on one of the state-of-the-art deep neural
networks, Wave-U-Net, which successively down-samples and up-samples feature
maps. We find that this architecture resembles that of multiresolution
analysis, and reveal that the DS layers of Wave-U-Net cause aliasing and may
discard information useful for the separation. Although the effects of these
problems may be reduced by training, to achieve a more reliable source
separation method, we should design DS layers capable of overcoming the
problems. With this belief, focusing on the fact that the DWT has an
anti-aliasing filter and the perfect reconstruction property, we design the
proposed layers. Experiments on music source separation show the efficacy of
the proposed method and the importance of simultaneously considering the
anti-aliasing filters and the perfect reconstruction property.
"
2433,"An Effective Automatic Image Annotation Model Via Attention Model and
  Data Equilibrium","  Nowadays, a huge number of images are available. However, retrieving a
required image for an ordinary user is a challenging task in computer vision
systems. During the past two decades, many types of research have been
introduced to improve the performance of the automatic annotation of images,
which are traditionally focused on content-based image retrieval. Although,
recent research demonstrates that there is a semantic gap between content-based
image retrieval and image semantics understandable by humans. As a result,
existing research in this area has caused to bridge the semantic gap between
low-level image features and high-level semantics. The conventional method of
bridging the semantic gap is through the automatic image annotation (AIA) that
extracts semantic features using machine learning techniques. In this paper, we
propose a novel AIA model based on the deep learning feature extraction method.
The proposed model has three phases, including a feature extractor, a tag
generator, and an image annotator. First, the proposed model extracts
automatically the high and low-level features based on dual-tree continues
wavelet transform (DT-CWT), singular value decomposition, distribution of color
ton, and the deep neural network. Moreover, the tag generator balances the
dictionary of the annotated keywords by a new log-entropy auto-encoder (LEAE)
and then describes these keywords by word embedding. Finally, the annotator
works based on the long-short-term memory (LSTM) network in order to obtain the
importance degree of specific features of the image. The experiments conducted
on two benchmark datasets confirm that the superiority of the proposed model
compared to the previous models in terms of performance criteria.
"
2434,Audio-Visual Decision Fusion for WFST-based and seq2seq Models,"  Under noisy conditions, speech recognition systems suffer from high Word
Error Rates (WER). In such cases, information from the visual modality
comprising the speaker lip movements can help improve the performance. In this
work, we propose novel methods to fuse information from audio and visual
modalities at inference time. This enables us to train the acoustic and visual
models independently. First, we train separate RNN-HMM based acoustic and
visual models. A common WFST generated by taking a special union of the HMM
components is used for decoding using a modified Viterbi algorithm. Second, we
train separate seq2seq acoustic and visual models. The decoding step is
performed simultaneously for both modalities using shallow fusion while
maintaining a common hypothesis beam. We also present results for a novel
seq2seq fusion without the weighing parameter. We present results at varying
SNR and show that our methods give significant improvements over acoustic-only
WER.
"
2435,"NAViDAd: A No-Reference Audio-Visual Quality Metric Based on a Deep
  Autoencoder","  The development of models for quality prediction of both audio and video
signals is a fairly mature field. But, although several multimodal models have
been proposed, the area of audio-visual quality prediction is still an emerging
area. In fact, despite the reasonable performance obtained by combination and
parametric metrics, currently there is no reliable pixel-based audio-visual
quality metric. The approach presented in this work is based on the assumption
that autoencoders, fed with descriptive audio and video features, might produce
a set of features that is able to describe the complex audio and video
interactions. Based on this hypothesis, we propose a No-Reference Audio-Visual
Quality Metric Based on a Deep Autoencoder (NAViDAd). The model visual features
are natural scene statistics (NSS) and spatial-temporal measures of the video
component. Meanwhile, the audio features are obtained by computing the
spectrogram representation of the audio component. The model is formed by a
2-layer framework that includes a deep autoencoder layer and a classification
layer. These two layers are stacked and trained to build the deep neural
network model. The model is trained and tested using a large set of stimuli,
containing representative audio and video artifacts. The model performed well
when tested against the UnB-AV and the LiveNetflix-II databases. %Results shows
that this type of approach produces quality scores that are highly correlated
to subjective quality scores.
"
2436,CNN-based fast source device identification,"  Source identification is an important topic in image forensics, since it
allows to trace back the origin of an image. This represents a precious
information to claim intellectual property but also to reveal the authors of
illicit materials. In this paper we address the problem of device
identification based on sensor noise and propose a fast and accurate solution
using convolutional neural networks (CNNs). Specifically, we propose a
2-channel-based CNN that learns a way of comparing camera fingerprint and image
noise at patch level. The proposed solution turns out to be much faster than
the conventional approach and to ensure an increased accuracy. This makes the
approach particularly suitable in scenarios where large databases of images are
analyzed, like over social networks. In this vein, since images uploaded on
social media usually undergo at least two compression stages, we include
investigations on double JPEG compressed images, always reporting higher
accuracy than standard approaches.
"
2437,"Multi-Modal Music Information Retrieval: Augmenting Audio-Analysis with
  Visual Computing for Improved Music Video Analysis","  This thesis combines audio-analysis with computer vision to approach Music
Information Retrieval (MIR) tasks from a multi-modal perspective. This thesis
focuses on the information provided by the visual layer of music videos and how
it can be harnessed to augment and improve tasks of the MIR research domain.
The main hypothesis of this work is based on the observation that certain
expressive categories such as genre or theme can be recognized on the basis of
the visual content alone, without the sound being heard. This leads to the
hypothesis that there exists a visual language that is used to express mood or
genre. In a further consequence it can be concluded that this visual
information is music related and thus should be beneficial for the
corresponding MIR tasks such as music genre classification or mood recognition.
A series of comprehensive experiments and evaluations are conducted which are
focused on the extraction of visual information and its application in
different MIR tasks. A custom dataset is created, suitable to develop and test
visual features which are able to represent music related information.
Evaluations range from low-level visual features to high-level concepts
retrieved by means of Deep Convolutional Neural Networks. Additionally, new
visual features are introduced capturing rhythmic visual patterns. In all of
these experiments the audio-based results serve as benchmark for the visual and
audio-visual approaches. The experiments are conducted for three MIR tasks
Artist Identification, Music Genre Classification and Cross-Genre
Classification. Experiments show that an audio-visual approach harnessing
high-level semantic information gained from visual concept detection,
outperforms audio-only genre-classification accuracy by 16.43%.
"
2438,Spatially Variant Laplacian Pyramids for Multi-Frame Exposure Fusion,"  Laplacian Pyramid Blending is a commonly used method for several seamless
image blending tasks. While the method works well for images with comparable
intensity levels, it is often unable to produce artifact free images for
applications which handle images with large intensity variation such as
exposure fusion. This paper proposes a spatially varying Laplacian Pyramid
Blending to blend images with large intensity differences. The proposed method
dynamically alters the blending levels during the final stage of Pyramid
Reconstruction based on the amount of local intensity variation. The proposed
algorithm out performs state-of-the-art methods for image blending both
qualitatively as well as quantitatively on publicly available High Dynamic
Range (HDR) imaging dataset. Qualitative improvements are demonstrated in terms
of details, halos and dark halos. For quantitative comparison, the no-reference
perceptual metric MEF-SSIM was used.
"
2439,"EdgeDASH: Exploiting Network-Assisted Adaptive Video Streaming for Edge
  Caching","  While edge video caching has great potential to decrease the core network
traffic as well as the users' experienced latency, it is often challenging to
exploit the caches in current client-driven video streaming solutions due to
two key reasons. First, even those clients interested in the same content might
request different quality levels as a video content is encoded into multiple
qualities to match a wide range of network conditions and device capabilities.
Second, the clients, who select the quality of the next chunk to request, are
unaware of the cached content at the network edge. Hence, it becomes imperative
to develop network-side solutions to exploit caching. This can also mitigate
some performance issues, in particular for the scenarios in which multiple
video clients compete for some bottleneck capacity. In this paper, we propose a
network-side control logic running at a WiFi AP to facilitate the use of cached
video content. In particular, an AP can assign a client station a different
video quality than its request, in case the alternative quality provides a
better utility. We formulate the quality assignment problem as an optimization
problem and develop several heuristics with polynomial complexity. Compared to
the baseline where the clients determine the quality adaptation, our proposals,
referred to as EdgeDASH, offer higher video quality, higher cache hits, and
lower stalling ratio which are essential for user's satisfaction. Our
simulations show that EdgeDASH facilitates significant cache hits and decreases
the buffer stalls only by changing the client's request by one quality level.
Moreover, from our analysis, we conclude that the network assistance provides
significant performance improvement, especially when the clients with identical
interests compete for a bottleneck link's capacity.
"
2440,Data hiding in speech signal using steganography and encryption,"  Data privacy and data security are always on highest priority in the world.
We need a reliable method to encrypt the data so that it reaches the
destination safely. Encryption is a simple yet effective way to protect our
data while transmitting it to a destination. The proposed method has state of
art technology of steganography and encryption. This paper puts forward a
different approach for data hiding in speech signals. A ten-digit number within
speech signal using audio steganography and encrypting it with a unique key for
better security. At the receiver end the same unique key is used to decrypt the
received signal and then hidden numbers are extracted. The proposed approach
performance can be evaluated by PSNR, MSE, SSIM and bit-error rate. The
simulation results give better performance compared to existing approach.
"
2441,Image Fine-grained Inpainting,"  Image inpainting techniques have shown promising improvement with the
assistance of generative adversarial networks (GANs) recently. However, most of
them often suffered from completed results with unreasonable structure or
blurriness. To mitigate this problem, in this paper, we present a one-stage
model that utilizes dense combinations of dilated convolutions to obtain larger
and more effective receptive fields. Benefited from the property of this
network, we can more easily recover large regions in an incomplete image. To
better train this efficient generator, except for frequently-used VGG feature
matching loss, we design a novel self-guided regression loss for concentrating
on uncertain areas and enhancing the semantic details. Besides, we devise a
geometrical alignment constraint item to compensate for the pixel-based
distance between prediction features and ground-truth ones. We also employ a
discriminator with local and global branches to ensure local-global contents
consistency. To further improve the quality of generated images, discriminator
feature matching on the local branch is introduced, which dynamically minimizes
the similarity of intermediate features between synthetic and ground-truth
patches. Extensive experiments on several public datasets demonstrate that our
approach outperforms current state-of-the-art methods. Code is available at
https://github.com/Zheng222/DMFN.
"
2442,"SPN-CNN: Boosting Sensor-Based Source Camera Attribution With Deep
  Learning","  We explore means to advance source camera identification based on sensor
noise in a data-driven framework. Our focus is on improving the sensor pattern
noise (SPN) extraction from a single image at test time. Where existing works
suppress nuisance content with denoising filters that are largely agnostic to
the specific SPN signal of interest, we demonstrate that a~deep learning
approach can yield a more suitable extractor that leads to improved source
attribution. A series of extensive experiments on various public datasets
confirms the feasibility of our approach and its applicability to image
manipulation localization and video source attribution. A critical discussion
of potential pitfalls completes the text.
"
2443,A Time-Frequency Perspective on Audio Watermarking,"  Existing audio watermarking methods usually treat the host audio signals of a
function of time or frequency individually, while considering them in the joint
time-frequency (TF) domain has received less attention. This paper proposes an
audio watermarking framework from the perspective of TF analysis. The proposed
framework treats the host audio signal in the 2-dimensional (2D) TF plane, and
selects a series of patches within the 2D TF image. These patches correspond to
the TF clusters with minimum averaged energy, and are used to form the feature
vectors for watermark embedding. Classical spread spectrum embedding schemes
are incorporated in the framework. The feature patches that carry the
watermarks only occupy a few TF regions of the host audio signal, thus leading
to improved imperceptibility property. In addition, since the feature patches
contain a neighborhood area of TF representation of audio samples, the
correlations among the samples within a single patch could be exploited for
improved robustness against a series of processing attacks. Extensive
experiments are carried out to illustrate the effectiveness of the proposed
system, as compared to its counterpart systems. The aim of this work is to shed
some light on the notion of audio watermarking in TF feature domain, which may
potentially lead us to more robust watermarking solutions against malicious
attacks.
"
2444,VIFB: A Visible and Infrared Image Fusion Benchmark,"  Visible and infrared image fusion is one of the most important areas in image
processing due to its numerous applications. While much progress has been made
in recent years with efforts on developing fusion algorithms, there is a lack
of code library and benchmark which can gauge the state-of-the-art. In this
paper, after briefly reviewing recent advances of visible and infrared image
fusion, we present a visible and infrared image fusion benchmark (VIFB) which
consists of 21 image pairs, a code library of 20 fusion algorithms and 13
evaluation metrics. We also carry out large scale experiments within the
benchmark to understand the performance of these algorithms. By analyzing
qualitative and quantitative results, we identify effective algorithms for
robust image fusion and give some observations on the status and future
prospects of this field.
"
2445,Multitask Emotion Recognition with Incomplete Labels,"  We train a unified model to perform three tasks: facial action unit
detection, expression classification, and valence-arousal estimation. We
address two main challenges of learning the three tasks. First, most existing
datasets are highly imbalanced. Second, most existing datasets do not contain
labels for all three tasks. To tackle the first challenge, we apply data
balancing techniques to experimental datasets. To tackle the second challenge,
we propose an algorithm for the multitask model to learn from missing
(incomplete) labels. This algorithm has two steps. We first train a teacher
model to perform all three tasks, where each instance is trained by the ground
truth label of its corresponding task. Secondly, we refer to the outputs of the
teacher model as the soft labels. We use the soft labels and the ground truth
to train the student model. We find that most of the student models outperform
their teacher model on all the three tasks. Finally, we use model ensembling to
boost performance further on the three tasks.
"
2446,"Deriving Emotions and Sentiments from Visual Content: A Disaster
  Analysis Use Case","  Sentiment analysis aims to extract and express a person's perception,
opinions and emotions towards an entity, object, product and a service,
enabling businesses to obtain feedback from the consumers. The increasing
popularity of the social networks and users' tendency towards sharing their
feelings, expressions and opinions in text, visual and audio content has opened
new opportunities and challenges in sentiment analysis. While sentiment
analysis of text streams has been widely explored in the literature, sentiment
analysis of images and videos is relatively new. This article introduces visual
sentiment analysis and contrasts it with textual sentiment analysis with
emphasis on the opportunities and challenges in this nascent research area. We
also propose a deep visual sentiment analyzer for disaster-related images as a
use-case, covering different aspects of visual sentiment analysis starting from
data collection, annotation, model selection, implementation and evaluations.
We believe such rigorous analysis will provide a baseline for future research
in the domain.
"
2447,"Multimodal active speaker detection and virtual cinematography for video
  conferencing","  Active speaker detection (ASD) and virtual cinematography (VC) can
significantly improve the remote user experience of a video conference by
automatically panning, tilting and zooming of a video conferencing camera:
users subjectively rate an expert video cinematographer's video significantly
higher than unedited video. We describe a new automated ASD and VC that
performs within 0.3 MOS of an expert cinematographer based on subjective
ratings with a 1-5 scale. This system uses a 4K wide-FOV camera, a depth
camera, and a microphone array; it extracts features from each modality and
trains an ASD using an AdaBoost machine learning system that is very efficient
and runs in real-time. A VC is similarly trained using machine learning to
optimize the subjective quality of the overall experience. To avoid distracting
the room participants and reduce switching latency the system has no moving
parts -- the VC works by cropping and zooming the 4K wide-FOV video stream. The
system was tuned and evaluated using extensive crowdsourcing techniques and
evaluated on a dataset with N=100 meetings, each 2-5 minutes in length.
"
2448,"3D Point Cloud Enhancement using Graph-Modelled Multiview Depth
  Measurements","  A 3D point cloud is often synthesized from depth measurements collected by
sensors at different viewpoints. The acquired measurements are typically both
coarse in precision and corrupted by noise. To improve quality, previous works
denoise a synthesized 3D point cloud a posteriori after projecting the
imperfect depth data onto 3D space. Instead, we enhance depth measurements on
the sensed images a priori, exploiting inherent 3D geometric correlation across
views, before synthesizing a 3D point cloud from the improved measurements. By
enhancing closer to the actual sensing process, we benefit from optimization
targeting specifically the depth image formation model, before subsequent
processing steps that can further obscure measurement errors. Mathematically,
for each pixel row in a pair of rectified viewpoint depth images, we first
construct a graph reflecting inter-pixel similarities via metric learning using
data in previous enhanced rows. To optimize left and right viewpoint images
simultaneously, we write a non-linear mapping function from left pixel row to
the right based on 3D geometry relations. We formulate a MAP optimization
problem, which, after suitable linear approximations, results in an
unconstrained convex and differentiable objective, solvable using fast gradient
method (FGM). Experimental results show that our method noticeably outperforms
recent denoising algorithms that enhance after 3D point clouds are synthesized.
"
2449,MFFW: A new dataset for multi-focus image fusion,"  Multi-focus image fusion (MFF) is a fundamental task in the field of
computational photography. Current methods have achieved significant
performance improvement. It is found that current methods are evaluated on
simulated image sets or Lytro dataset. Recently, a growing number of
researchers pay attention to defocus spread effect, a phenomenon of real-world
multi-focus images. Nonetheless, defocus spread effect is not obvious in
simulated or Lytro datasets, where popular methods perform very similar. To
compare their performance on images with defocus spread effect, this paper
constructs a new dataset called MFF in the wild (MFFW). It contains 19 pairs of
multi-focus images collected on the Internet. We register all pairs of source
images, and provide focus maps and reference images for part of pairs. Compared
with Lytro dataset, images in MFFW significantly suffer from defocus spread
effect. In addition, the scenes of MFFW are more complex. The experiments
demonstrate that most state-of-the-art methods on MFFW dataset cannot robustly
generate satisfactory fusion images. MFFW can be a new baseline dataset to test
whether an MMF algorithm is able to deal with defocus spread effect.
"
2450,AlignNet: A Unifying Approach to Audio-Visual Alignment,"  We present AlignNet, a model that synchronizes videos with reference audios
under non-uniform and irregular misalignments. AlignNet learns the end-to-end
dense correspondence between each frame of a video and an audio. Our method is
designed according to simple and well-established principles: attention,
pyramidal processing, warping, and affinity function. Together with the model,
we release a dancing dataset Dance50 for training and evaluation. Qualitative,
quantitative and subjective evaluation results on dance-music alignment and
speech-lip alignment demonstrate that our method far outperforms the
state-of-the-art methods. Project video and code are available at
https://jianrenw.github.io/AlignNet.
"
2451,Interactive Multi-User 3D Visual Analytics in Augmented Reality,"  This publication reports on a research project in which we set out to explore
the advantages and disadvantages augmented reality (AR) technology has for
visual data analytics. We developed a prototype of an AR data analytics
application, which provides users with an interactive 3D interface, hand
gesture-based controls and multi-user support for a shared experience, enabling
multiple people to collaboratively visualize, analyze and manipulate data with
high dimensional features in 3D space. Our software prototype, called DataCube,
runs on the Microsoft HoloLens - one of the first true stand-alone AR headsets,
through which users can see computer-generated images overlaid onto real-world
objects in the user's physical environment. Using hand gestures, the users can
select menu options, control the 3D data visualization with various filtering
and visualization functions, and freely arrange the various menus and virtual
displays in their environment. The shared multi-user experience allows all
participating users to see and interact with the virtual environment, changes
one user makes will become visible to the other users instantly. As users
engage together they are not restricted from observing the physical world
simultaneously and therefore they can also see non-verbal cues such as
gesturing or facial reactions of other users in the physical environment. The
main objective of this research project was to find out if AR interfaces and
collaborative analysis can provide an effective solution for data analysis
tasks, and our experience with our prototype system confirms this.
"
2452,Self-supervised learning for audio-visual speaker diarization,"  Speaker diarization, which is to find the speech segments of specific
speakers, has been widely used in human-centered applications such as video
conferences or human-computer interaction systems. In this paper, we propose a
self-supervised audio-video synchronization learning method to address the
problem of speaker diarization without massive labeling effort. We improve the
previous approaches by introducing two new loss functions: the dynamic triplet
loss and the multinomial loss. We test them on a real-world human-computer
interaction system and the results show our best model yields a remarkable gain
of +8%F1-scoresas well as diarization error rate reduction. Finally, we
introduce a new large scale audio-video corpus designed to fill the vacancy of
audio-video datasets in Chinese.
"
2453,"Efficient And Scalable Neural Residual Waveform Coding With
  Collaborative Quantization","  Scalability and efficiency are desired in neural speech codecs, which
supports a wide range of bitrates for applications on various devices. We
propose a collaborative quantization (CQ) scheme to jointly learn the codebook
of LPC coefficients and the corresponding residuals. CQ does not simply
shoehorn LPC to a neural network, but bridges the computational capacity of
advanced neural network models and traditional, yet efficient and
domain-specific digital signal processing methods in an integrated manner. We
demonstrate that CQ achieves much higher quality than its predecessor at 9 kbps
with even lower model complexity. We also show that CQ can scale up to 24 kbps
where it outperforms AMR-WB and Opus. As a neural waveform codec, CQ models are
with less than 1 million parameters, significantly less than many other
generative models.
"
2454,Looking Enhances Listening: Recovering Missing Speech Using Images,"  Speech is understood better by using visual context; for this reason, there
have been many attempts to use images to adapt automatic speech recognition
(ASR) systems. Current work, however, has shown that visually adapted ASR
models only use images as a regularization signal, while completely ignoring
their semantic content. In this paper, we present a set of experiments where we
show the utility of the visual modality under noisy conditions. Our results
show that multimodal ASR models can recover words which are masked in the input
acoustic signal, by grounding its transcriptions using the visual
representations. We observe that integrating visual context can result in up to
35% relative improvement in masked word recovery. These results demonstrate
that end-to-end multimodal ASR systems can become more robust to noise by
leveraging the visual context.
"
2455,"SBERT-WK: A Sentence Embedding Method by Dissecting BERT-based Word
  Models","  Sentence embedding is an important research topic in natural language
processing (NLP) since it can transfer knowledge to downstream tasks.
Meanwhile, a contextualized word representation, called BERT, achieves the
state-of-the-art performance in quite a few NLP tasks. Yet, it is an open
problem to generate a high quality sentence representation from BERT-based word
models. It was shown in previous study that different layers of BERT capture
different linguistic properties. This allows us to fusion information across
layers to find better sentence representation. In this work, we study the
layer-wise pattern of the word representation of deep contextualized models.
Then, we propose a new sentence embedding method by dissecting BERT-based word
models through geometric analysis of the space spanned by the word
representation. It is called the SBERT-WK method. No further training is
required in SBERT-WK. We evaluate SBERT-WK on semantic textual similarity and
downstream supervised tasks. Furthermore, ten sentence-level probing tasks are
presented for detailed linguistic analysis. Experiments show that SBERT-WK
achieves the state-of-the-art performance. Our codes are publicly available.
"
2456,Computing in Covert Domain Using Data Hiding,"  This paper proposes an idea of data computing in the covert domain (DCCD). We
show that with information hiding some data computing tasks can be executed
beneath the covers like images, audios, random data, etc. In the proposed
framework, a sender hides his source data into two covers and uploads them onto
a server. The server executes computation within the stego and returns the
covert computing result to a receiver. With the covert result, the receiver can
extract the computing result of the source data. During the process, it is
imperceptible for the server and the adversaries to obtain the source data as
they are hidden in the cover. The transmission can be done over public
channels. Meanwhile, since the computation is realized in the covert domain,
the cloud cannot obtain the knowledge of the computing result. Therefore, the
proposed idea is useful for cloud computing.
"
2457,Addressing the confounds of accompaniments in singer identification,"  Identifying singers is an important task with many applications. However, the
task remains challenging due to many issues. One major issue is related to the
confounding factors from the background instrumental music that is mixed with
the vocals in music production. A singer identification model may learn to
extract non-vocal related features from the instrumental part of the songs, if
a singer only sings in certain musical contexts (e.g., genres). The model
cannot therefore generalize well when the singer sings in unseen contexts. In
this paper, we attempt to address this issue. Specifically, we employ
open-unmix, an open source tool with state-of-the-art performance in source
separation, to separate the vocal and instrumental tracks of music. We then
investigate two means to train a singer identification model: by learning from
the separated vocal only, or from an augmented set of data where we
""shuffle-and-remix"" the separated vocal tracks and instrumental tracks of
different songs to artificially make the singers sing in different contexts. We
also incorporate melodic features learned from the vocal melody contour for
better performance. Evaluation results on a benchmark dataset called the
artist20 shows that this data augmentation method greatly improves the accuracy
of singer identification.
"
2458,Serial Speakers: a Dataset of TV Series,"  For over a decade, TV series have been drawing increasing interest, both from
the audience and from various academic fields. But while most viewers are
hooked on the continuous plots of TV serials, the few annotated datasets
available to researchers focus on standalone episodes of classical TV series.
We aim at filling this gap by providing the multimedia/speech processing
communities with Serial Speakers, an annotated dataset of 161 episodes from
three popular American TV serials: Breaking Bad, Game of Thrones and House of
Cards. Serial Speakers is suitable both for investigating multimedia retrieval
in realistic use case scenarios, and for addressing lower level speech related
tasks in especially challenging conditions. We publicly release annotations for
every speech turn (boundaries, speaker) and scene boundary, along with
annotations for shot boundaries, recurring shots, and interacting speakers in a
subset of episodes. Because of copyright restrictions, the textual content of
the speech turns is encrypted in the public version of the dataset, but we
provide the users with a simple online tool to recover the plain text from
their own subtitle files.
"
2459,Bit Allocation for Multi-Task Collaborative Intelligence,"  Recent studies have shown that collaborative intelligence (CI) is a promising
framework for deployment of Artificial Intelligence (AI)-based services on
mobile devices. In CI, a deep neural network is split between the mobile device
and the cloud. Deep features obtained at the mobile are compressed and
transferred to the cloud to complete the inference. So far, the methods in the
literature focused on transferring a single deep feature tensor from the mobile
to the cloud. Such methods are not applicable to some recent, high-performance
networks with multiple branches and skip connections. In this paper, we propose
the first bit allocation method for multi-stream, multi-task CI. We first
establish a model for the joint distortion of the multiple tasks as a function
of the bit rates assigned to different deep feature tensors. Then, using the
proposed model, we solve the rate-distortion optimization problem under a total
rate constraint to obtain the best rate allocation among the tensors to be
transferred. Experimental results illustrate the efficacy of the proposed
scheme compared to several alternative bit allocation methods.
"
2460,"PCSGAN: Perceptual Cyclic-Synthesized Generative Adversarial Networks
  for Thermal and NIR to Visible Image Transformation","  In many real world scenarios, it is difficult to capture the images in the
visible light spectrum (VIS) due to bad lighting conditions. However, the
images can be captured in such scenarios using Near-Infrared (NIR) and Thermal
(THM) cameras. The NIR and THM images contain the limited details. Thus, there
is a need to transform the images from THM/NIR to VIS for better understanding.
However, it is non-trivial task due to the large domain discrepancies and lack
of abundant datasets. Nowadays, Generative Adversarial Network (GAN) is able to
transform the images from one domain to another domain. Most of the available
GAN based methods use the combination of the adversarial and the pixel-wise
losses (like $L_1$ or $L_2$) as the objective function for training. The
quality of transformed images in case of THM/NIR to VIS transformation is still
not up to the mark using such objective function. Thus, better objective
functions are needed to improve the quality, fine details and realism of the
transformed images. A new model for THM/NIR to VIS image transformation called
Perceptual Cyclic-Synthesized Generative Adversarial Network (PCSGAN) is
introduced to address these issues. The PCSGAN uses the combination of the
perceptual (i.e., feature based) losses along with the pixel-wise and the
adversarial losses. Both the quantitative and qualitative measures are used to
judge the performance of the PCSGAN model over the WHU-IIP face and the RGB-NIR
scene datasets. The proposed PCSGAN outperforms the state-of-the-art image
transformation models, including Pix2pix, DualGAN, CycleGAN, PS2GAN, and PAN in
terms of the SSIM, MSE, PSNR and LPIPS evaluation measures. The code is
available at https://github.com/KishanKancharagunta/PCSGAN.
"
2461,Performance Analysis of Adaptive Noise Cancellation for Speech Signal,"  This paper gives a broader insight on the application of adaptive filter in
noise cancellation during various processes where signal is transmitted.
Adaptive filtering techniques like RLS, LMS and normalized LMS are used to
filter the input signal using the concept of negative feedback to predict its
nature and remove it effectively from the input. In this paper a comparative
study between the effectiveness of RLS, LMS and normalized LMS is done based on
parameters like SNR (Signal to Noise ratio), MSE (Mean squared error) and cross
correlation. Implementation and analysis of the filters are done by taking
different step sizes on different orders of the filters.
"
2462,"Blind Omnidirectional Image Quality Assessment with Viewport Oriented
  Graph Convolutional Networks","  Quality assessment of omnidirectional images has become increasingly urgent
due to the rapid growth of virtual reality applications. Different from
traditional 2D images and videos, omnidirectional contents can provide
consumers with freely changeable viewports and a larger field of view covering
the $360^{\circ}\times180^{\circ}$ spherical surface, which makes the objective
quality assessment of omnidirectional images more challenging. In this paper,
motivated by the characteristics of the human vision system (HVS) and the
viewing process of omnidirectional contents, we propose a novel Viewport
oriented Graph Convolution Network (VGCN) for blind omnidirectional image
quality assessment (IQA). Generally, observers tend to give the subjective
rating of a 360-degree image after passing and aggregating different viewports
information when browsing the spherical scenery. Therefore, in order to model
the mutual dependency of viewports in the omnidirectional image, we build a
spatial viewport graph. Specifically, the graph nodes are first defined with
selected viewports with higher probabilities to be seen, which is inspired by
the HVS that human beings are more sensitive to structural information. Then,
these nodes are connected by spatial relations to capture interactions among
them. Finally, reasoning on the proposed graph is performed via graph
convolutional networks. Moreover, we simultaneously obtain global quality using
the entire omnidirectional image without viewport sampling to boost the
performance according to the viewing experience. Experimental results
demonstrate that our proposed model outperforms state-of-the-art full-reference
and no-reference IQA metrics on two public omnidirectional IQA databases.
"
2463,Fine-Grained Instance-Level Sketch-Based Video Retrieval,"  Existing sketch-analysis work studies sketches depicting static objects or
scenes. In this work, we propose a novel cross-modal retrieval problem of
fine-grained instance-level sketch-based video retrieval (FG-SBVR), where a
sketch sequence is used as a query to retrieve a specific target video
instance. Compared with sketch-based still image retrieval, and coarse-grained
category-level video retrieval, this is more challenging as both visual
appearance and motion need to be simultaneously matched at a fine-grained
level. We contribute the first FG-SBVR dataset with rich annotations. We then
introduce a novel multi-stream multi-modality deep network to perform FG-SBVR
under both strong and weakly supervised settings. The key component of the
network is a relation module, designed to prevent model over-fitting given
scarce training data. We show that this model significantly outperforms a
number of existing state-of-the-art models designed for video analysis.
"
2464,Multi-Representation Knowledge Distillation For Audio Classification,"  As an important component of multimedia analysis tasks, audio classification
aims to discriminate between different audio signal types and has received
intensive attention due to its wide applications. Generally speaking, the raw
signal can be transformed into various representations (such as Short Time
Fourier Transform and Mel Frequency Cepstral Coefficients), and information
implied in different representations can be complementary. Ensembling the
models trained on different representations can greatly boost the
classification performance, however, making inference using a large number of
models is cumbersome and computationally expensive. In this paper, we propose a
novel end-to-end collaborative learning framework for the audio classification
task. The framework takes multiple representations as the input to train the
models in parallel. The complementary information provided by different
representations is shared by knowledge distillation. Consequently, the
performance of each model can be significantly promoted without increasing the
computational overhead in the inference stage. Extensive experimental results
demonstrate that the proposed approach can improve the classification
performance and achieve state-of-the-art results on both acoustic scene
classification tasks and general audio tagging tasks.
"
2465,"DECIBEL: Improving Audio Chord Estimation for Popular Music by Alignment
  and Integration of Crowd-Sourced Symbolic Representations","  Automatic Chord Estimation (ACE) is a fundamental task in Music Information
Retrieval (MIR) and has applications in both music performance and MIR
research. The task consists of segmenting a music recording or score and
assigning a chord label to each segment. Although it has been a task in the
annual benchmarking evaluation MIREX for over 10 years, ACE is not yet a solved
problem, since performance has stagnated and modern systems have started to
tune themselves to subjective training data. We propose DECIBEL, a new ACE
system that exploits widely available MIDI and tab representations to improve
ACE from audio only. From an audio file and a set of MIDI and tab files
corresponding to the same popular music song, DECIBEL first estimates chord
sequences. For audio, state-of-the-art audio ACE methods are used. MIDI files
are aligned to the audio, followed by a MIDI chord estimation step. Tab files
are transformed into untimed chord sequences and then aligned to the audio.
Next, DECIBEL uses data fusion to integrate all estimated chord sequences into
one final output sequence. DECIBEL improves all tested state-of-the-art ACE
methods by over 3 percent on average. This result shows that the integration of
musical knowledge from heterogeneous symbolic music representations is a
suitable strategy for addressing challenging MIR tasks such as ACE.
"
2466,"A Comparative Evaluation of Temporal Pooling Methods for Blind Video
  Quality Assessment","  Many objective video quality assessment (VQA) algorithms include a key step
of temporal pooling of frame-level quality scores. However, less attention has
been paid to studying the relative efficiencies of different pooling methods on
no-reference (blind) VQA. Here we conduct a large-scale comparative evaluation
to assess the capabilities and limitations of multiple temporal pooling
strategies on blind VQA of user-generated videos. The study yields insights and
general guidance regarding the application and selection of temporal pooling
models. In addition, we also propose an ensemble pooling model built on top of
high-performing temporal pooling models. Our experimental results demonstrate
the relative efficacies of the evaluated temporal pooling models, using several
popular VQA algorithms, and evaluated on two recent large-scale natural video
quality databases. In addition to the new ensemble model, we provide a general
recipe for applying temporal pooling of frame-based quality predictions.
"
2467,"Human Perception-Optimized Planning for Comfortable VR-Based
  Telepresence","  This paper introduces an emerging motion planning problem by considering a
human that is immersed into the viewing perspective of a remote robot. The
challenge is to make the experience both effective (such as delivering a sense
of presence) and comfortable (such as avoiding adverse sickness symptoms,
including nausea). We refer to this challenging new area as human
perception-optimized planning and propose a general multiobjective optimization
framework that can be instantiated in many envisioned scenarios. We then
consider a specific VR telepresence task as a case of human
perception-optimized planning, in which we simulate a robot that sends 360
video to a remote user to be viewed through a head-mounted display. In this
particular task, we plan trajectories that minimize VR sickness (and thereby
maximize comfort). An A* type method is used to create a Pareto-optimal
collection of piecewise linear trajectories while taking into account criteria
that improve comfort. We conducted a study with human subjects touring a
virtual museum, in which paths computed by our algorithm are compared against a
reference RRT-based trajectory. Generally, users suffered less from VR sickness
and preferred the paths created by the presented algorithm.
"
2468,"Model-based Joint Bit Allocation between Geometry and Color for
  Video-based 3D Point Cloud Compression","  Rate distortion optimization plays a very important role in image/video
coding. But for 3D point cloud, this problem has not been investigated. In this
paper, the rate and distortion characteristics of 3D point cloud are
investigated in detail, and a typical and challenging rate distortion
optimization problem is solved for 3D point cloud. Specifically, since the
quality of the reconstructed 3D point cloud depends on both the geometry and
color distortions, we first propose analytical rate and distortion models for
the geometry and color information in video-based 3D point cloud compression
platform, and then solve the joint bit allocation problem for geometry and
color based on the derived models. To maximize the reconstructed quality of 3D
point cloud, the bit allocation problem is formulated as a constrained
optimization problem and solved by an interior point method. Experimental
results show that the rate-distortion performance of the proposed solution is
close to that obtained with exhaustive search but at only 0.68% of its time
complexity. Moreover, the proposed rate and distortion models can also be used
for the other rate-distortion optimization problems (such as prediction mode
decision) and rate control technologies for 3D point cloud coding in the
future.
"
2469,"DDet: Dual-path Dynamic Enhancement Network for Real-World Image
  Super-Resolution","  Different from traditional image super-resolution task, real image
super-resolution(Real-SR) focus on the relationship between real-world
high-resolution(HR) and low-resolution(LR) image. Most of the traditional image
SR obtains the LR sample by applying a fixed down-sampling operator. Real-SR
obtains the LR and HR image pair by incorporating different quality optical
sensors. Generally, Real-SR has more challenges as well as broader application
scenarios. Previous image SR methods fail to exhibit similar performance on
Real-SR as the image data is not aligned inherently. In this article, we
propose a Dual-path Dynamic Enhancement Network(DDet) for Real-SR, which
addresses the cross-camera image mapping by realizing a dual-way dynamic
sub-pixel weighted aggregation and refinement. Unlike conventional methods
which stack up massive convolutional blocks for feature representation, we
introduce a content-aware framework to study non-inherently aligned image pair
in image SR issue. First, we use a content-adaptive component to exhibit the
Multi-scale Dynamic Attention(MDA). Second, we incorporate a long-term skip
connection with a Coupled Detail Manipulation(CDM) to perform collaborative
compensation and manipulation. The above dual-path model is joint into a
unified model and works collaboratively. Extensive experiments on the
challenging benchmarks demonstrate the superiority of our model.
"
2470,Model Watermarking for Image Processing Networks,"  Deep learning has achieved tremendous success in numerous industrial
applications. As training a good model often needs massive high-quality data
and computation resources, the learned models often have significant business
values. However, these valuable deep models are exposed to a huge risk of
infringements. For example, if the attacker has the full information of one
target model including the network structure and weights, the model can be
easily finetuned on new datasets. Even if the attacker can only access the
output of the target model, he/she can still train another similar surrogate
model by generating a large scale of input-output training pairs. How to
protect the intellectual property of deep models is a very important but
seriously under-researched problem. There are a few recent attempts at
classification network protection only. In this paper, we propose the first
model watermarking framework for protecting image processing models. To achieve
this goal, we leverage the spatial invisible watermarking mechanism.
Specifically, given a black-box target model, a unified and invisible watermark
is hidden into its outputs, which can be regarded as a special task-agnostic
barrier. In this way, when the attacker trains one surrogate model by using the
input-output pairs of the target model, the hidden watermark will be learned
and extracted afterward. To enable watermarks from binary bits to
high-resolution images, both traditional and deep spatial invisible
watermarking mechanism are considered. Experiments demonstrate the robustness
of the proposed watermarking mechanism, which can resist surrogate models
learned with different network structures and objective functions. Besides deep
models, the proposed method is also easy to be extended to protect data and
traditional image processing algorithms.
"
2471,"Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video
  Super-Resolution","  In this paper, we explore the space-time video super-resolution task, which
aims to generate a high-resolution (HR) slow-motion video from a low frame rate
(LFR), low-resolution (LR) video. A simple solution is to split it into two
sub-tasks: video frame interpolation (VFI) and video super-resolution (VSR).
However, temporal interpolation and spatial super-resolution are intra-related
in this task. Two-stage methods cannot fully take advantage of the natural
property. In addition, state-of-the-art VFI or VSR networks require a large
frame-synthesis or reconstruction module for predicting high-quality video
frames, which makes the two-stage methods have large model sizes and thus be
time-consuming. To overcome the problems, we propose a one-stage space-time
video super-resolution framework, which directly synthesizes an HR slow-motion
video from an LFR, LR video. Rather than synthesizing missing LR video frames
as VFI networks do, we firstly temporally interpolate LR frame features in
missing LR video frames capturing local temporal contexts by the proposed
feature temporal interpolation network. Then, we propose a deformable ConvLSTM
to align and aggregate temporal information simultaneously for better
leveraging global temporal contexts. Finally, a deep reconstruction network is
adopted to predict HR slow-motion video frames. Extensive experiments on
benchmark datasets demonstrate that the proposed method not only achieves
better quantitative and qualitative performance but also is more than three
times faster than recent two-stage state-of-the-art methods, e.g., DAIN+EDVR
and DAIN+RBPN.
"
2472,Learning to Shadow Hand-drawn Sketches,"  We present a fully automatic method to generate detailed and accurate
artistic shadows from pairs of line drawing sketches and lighting directions.
We also contribute a new dataset of one thousand examples of pairs of line
drawings and shadows that are tagged with lighting directions. Remarkably, the
generated shadows quickly communicate the underlying 3D structure of the
sketched scene. Consequently, the shadows generated by our approach can be used
directly or as an excellent starting point for artists. We demonstrate that the
deep learning network we propose takes a hand-drawn sketch, builds a 3D model
in latent space, and renders the resulting shadows. The generated shadows
respect the hand-drawn lines and underlying 3D space and contain sophisticated
and accurate details, such as self-shadowing effects. Moreover, the generated
shadows contain artistic effects, such as rim lighting or halos appearing from
back lighting, that would be achievable with traditional 3D rendering methods.
"
2473,BBAND Index: A No-Reference Banding Artifact Predictor,"  Banding artifact, or false contouring, is a common video compression
impairment that tends to appear on large flat regions in encoded videos. These
staircase-shaped color bands can be very noticeable in high-definition videos.
Here we study this artifact, and propose a new distortion-specific no-reference
video quality model for predicting banding artifacts, called the Blind BANding
Detector (BBAND index). BBAND is inspired by human visual models. The proposed
detector can generate a pixel-wise banding visibility map and output a banding
severity score at both the frame and video levels. Experimental results show
that our proposed method outperforms state-of-the-art banding detection
algorithms and delivers better consistency with subjective evaluations.
"
2474,Subjective Quality Assessment for YouTube UGC Dataset,"  Due to the scale of social video sharing, User Generated Content (UGC) is
getting more attention from academia and industry. To facilitate
compression-related research on UGC, YouTube has released a large-scale
dataset. The initial dataset only provided videos, limiting its use in quality
assessment. We used a crowd-sourcing platform to collect subjective quality
scores for this dataset. We analyzed the distribution of Mean Opinion Score
(MOS) in various dimensions, and investigated some fundamental questions in
video quality assessment, like the correlation between full video MOS and
corresponding chunk MOS, and the influence of chunk variation in quality score
aggregation.
"
2475,Improved Image Coding Autoencoder With Deep Learning,"  In this paper, we build autoencoder based pipelines for extreme end-to-end
image compression based on Ball\'e's approach, which is the state-of-the-art
open source implementation in image compression using deep learning. We
deepened the network by adding one more hidden layer before each strided
convolutional layer with exactly the same number of down-samplings and
up-samplings. Our approach outperformed Ball\'e's approach, and achieved around
4.0% reduction in bits per pixel (bpp), 0.03% increase in multi-scale
structural similarity (MS-SSIM), and only 0.47% decrease in peak
signal-to-noise ratio (PSNR), It also outperforms all traditional image
compression methods including JPEG2000 and HEIC by at least 20% in terms of
compression efficiency at similar reconstruction image quality. Regarding
encoding and decoding time, our approach takes similar amount of time compared
with traditional methods with the support of GPU, which means it's almost ready
for industrial applications.
"
2476,Harmonics Based Representation in Clarinet Tone Quality Evaluation,"  Music tone quality evaluation is generally performed by experts. It could be
subjective and short of consistency and fairness as well as time-consuming. In
this paper we present a new method for identifying the clarinet reed quality by
evaluating tone quality based on the harmonic structure and energy
distribution. We first decouple the quality of reed and clarinet pipe based on
the acoustic harmonics, and discover that the reed quality is strongly relevant
to the even parts of the harmonics. Then we construct a features set consisting
of the even harmonic envelope and the energy distribution of harmonics in
spectrum. The annotated clarinet audio data are recorded from 3 levels of
performers and the tone quality is classified by machine learning. The results
show that our new method for identifying low and medium high tones
significantly outperforms previous methods.
"
2477,Towards Automatic Face-to-Face Translation,"  In light of the recent breakthroughs in automatic machine translation
systems, we propose a novel approach that we term as ""Face-to-Face
Translation"". As today's digital communication becomes increasingly visual, we
argue that there is a need for systems that can automatically translate a video
of a person speaking in language A into a target language B with realistic lip
synchronization. In this work, we create an automatic pipeline for this problem
and demonstrate its impact on multiple real-world applications. First, we build
a working speech-to-speech translation system by bringing together multiple
existing modules from speech and language. We then move towards ""Face-to-Face
Translation"" by incorporating a novel visual module, LipGAN for generating
realistic talking faces from the translated audio. Quantitative evaluation of
LipGAN on the standard LRW test set shows that it significantly outperforms
existing approaches across all standard metrics. We also subject our
Face-to-Face Translation pipeline, to multiple human evaluations and show that
it can significantly improve the overall user experience for consuming and
interacting with multimodal content across languages. Code, models and demo
video are made publicly available.
  Demo video: https://www.youtube.com/watch?v=aHG6Oei8jF0
  Code and models: https://github.com/Rudrabha/LipGAN
"
2478,"Weak Texture Information Map Guided Image Super-resolution with Deep
  Residual Networks","  Single image super-resolution (SISR) is an image processing task which
obtains high-resolution (HR) image from a low-resolution (LR) image. Recently,
due to the capability in feature extraction, a series of deep learning methods
have brought important crucial improvement for SISR. However, we observe that
no matter how deeper the networks are designed, they usually do not have good
generalization ability, which leads to the fact that almost all of existing SR
methods have poor performances on restoration of the weak texture details. To
solve these problems, we propose a weak texture information map guided image
super-resolution with deep residual networks. It contains three sub-networks,
one main network which extracts the main features and fuses weak texture
details, another two auxiliary networks extract the weak texture details fallen
in the main network. Two part of networks work cooperatively, the auxiliary
networks predict and integrates week texture information into the main network,
which is conducive to the main network learning more inconspicuous details.
Experiments results demonstrate that our method's performs achieve the
state-of-the-art quantitatively. Specifically, the image super-resolution
results of our method own more weak texture details.
"
2479,"An End-to-End Visual-Audio Attention Network for Emotion Recognition in
  User-Generated Videos","  Emotion recognition in user-generated videos plays an important role in
human-centered computing. Existing methods mainly employ traditional two-stage
shallow pipeline, i.e. extracting visual and/or audio features and training
classifiers. In this paper, we propose to recognize video emotions in an
end-to-end manner based on convolutional neural networks (CNNs). Specifically,
we develop a deep Visual-Audio Attention Network (VAANet), a novel architecture
that integrates spatial, channel-wise, and temporal attentions into a visual 3D
CNN and temporal attentions into an audio 2D CNN. Further, we design a special
classification loss, i.e. polarity-consistent cross-entropy loss, based on the
polarity-emotion hierarchy constraint to guide the attention generation.
Extensive experiments conducted on the challenging VideoEmotion-8 and Ekman-6
datasets demonstrate that the proposed VAANet outperforms the state-of-the-art
approaches for video emotion recognition. Our source code is released at:
https://github.com/maysonma/VAANet.
"
2480,"A multiple attributes image quality database for smartphone camera photo
  quality assessment","  Smartphone is the superstar product in digital device market and the quality
of smartphone camera photos (SCPs) is becoming one of the dominant
considerations when consumers purchase smartphones. How to evaluate the quality
of smartphone cameras and the taken photos is urgent issue to be solved. To
bridge the gap between academic research accomplishment and industrial needs,
in this paper, we establish a new Smartphone Camera Photo Quality Database
(SCPQD2020) including 1800 images with 120 scenes taken by 15 smartphones.
Exposure, color, noise and texture which are four dominant factors influencing
the quality of SCP are evaluated in the subjective study, respectively. Ten
popular no-reference (NR) image quality assessment (IQA) algorithms are tested
and analyzed on our database. Experimental results demonstrate that the current
objective models are not suitable for SCPs, and quality metrics having high
correlation with human visual perception are highly needed.
"
2481,Region adaptive graph fourier transform for 3d point clouds,"  We introduce the Region Adaptive Graph Fourier Transform (RA-GFT) for
compression of 3D point cloud attributes. The RA-GFT is a multiresolution
transform, formed by combining spatially localized block transforms. We assume
the points are organized by a family of nested partitions represented by a
rooted tree. At each resolution level, attributes are processed in clusters
using block transforms. Each block transform produces a single approximation
(DC) coefficient, and various detail (AC) coefficients. The DC coefficients are
promoted up the tree to the next (lower resolution) level, where the process
can be repeated until reaching the root. Since clusters may have a different
numbers of points, each block transform must incorporate the relative
importance of each coefficient. For this, we introduce the
$\mathbf{Q}$-normalized graph Laplacian, and propose using its eigenvectors as
the block transform. The RA-GFT achieves better complexity-performance
trade-offs than previous approaches. In particular, it outperforms the Region
Adaptive Haar Transform (RAHT) by up to 2.5 dB, with a small complexity
overhead.
"
2482,"ASMD: an automatic framework for compiling multimodal datasets with
  audio and scores","  This paper describes an open-source Python framework for handling datasets
for music processing tasks, built with the aim of improving the reproducibility
of research projects in music computing and assessing the generalization
abilities of machine learning models. The framework enables the automatic
download and installation of several commonly used datasets for multimodal
music processing. Specifically, we provide a Python API to access the datasets
through Boolean set operations based on particular attributes, such as
intersections and unions of composers, instruments, and so on. The framework is
designed to ease the inclusion of new datasets and the respective ground-truth
annotations so that one can build, convert, and extend one's own collection as
well as distribute it by means of a compliant format to take advantage of the
API. All code and ground-truth are released under suitable open licenses.
"
2483,"Cloud Rendering-based Volumetric Video Streaming System for Mixed
  Reality Services","  Volumetric video is an emerging technology for immersive representation of 3D
spaces that captures objects from all directions using multiple cameras and
creates a dynamic 3D model of the scene. However, processing volumetric content
requires high amounts of processing power and is still a very demanding task
for today's mobile devices. To mitigate this, we propose a volumetric video
streaming system that offloads the rendering to a powerful cloud/edge server
and only sends the rendered 2D view to the client instead of the full
volumetric content. We use 6DoF head movement prediction techniques, WebRTC
protocol and hardware video encoding to ensure low-latency in different parts
of the processing chain. We demonstrate our system using both a browser-based
client and a Microsoft HoloLens client. Our application contains generic
interfaces that allow for easy deployment of various augmented/mixed reality
clients using the same server implementation.
"
2484,Soft Video Multicasting Using Adaptive Compressed Sensing,"  Recently, soft video multicasting has gained a lot of attention, especially
in broadcast and mobile scenarios where the bit rate supported by the channel
may differ across receivers, and may vary quickly over time. Unlike the
conventional designs that force the source to use a single bit rate according
to the receiver with the worst channel quality, soft video delivery schemes
transmit the video such that the video quality at each receiver is commensurate
with its specific instantaneous channel quality. In this paper, we present a
soft video multicasting system using an adaptive block-based compressed sensing
(BCS) method. The proposed system consists of an encoder, a transmission
system, and a decoder. At the encoder side, each block in each frame of the
input video is adaptively sampled with a rate that depends on the texture
complexity and visual saliency of the block. The obtained BCS samples are then
placed into several packets, and the packets are transmitted via a
channel-aware OFDM (orthogonal frequency division multiplexing) transmission
system with a number of subchannels. At the decoder side, the received BCS
samples are first used to build an initial approximation of the transmitted
frame. To further improve the reconstruction quality, an iterative BCS
reconstruction algorithm is then proposed that uses an adaptive transform and
an adaptive soft-thresholding operator, which exploits the temporal similarity
between adjacent frames to achieve better reconstruction quality. The extensive
objective and subjective experimental results indicate the superiority of the
proposed system over the state-of-the-art soft video multicasting systems.
"
2485,Trends and Advancements in Deep Neural Network Communication,"  Due to their great performance and scalability properties neural networks
have become ubiquitous building blocks of many applications. With the rise of
mobile and IoT, these models now are also being increasingly applied in
distributed settings, where the owners of the data are separated by limited
communication channels and privacy constraints. To address the challenges of
these distributed environments, a wide range of training and evaluation schemes
have been developed, which require the communication of neural network
parametrizations. These novel approaches, which bring the ""intelligence to the
data"" have many advantages over traditional cloud solutions such as
privacy-preservation, increased security and device autonomy, communication
efficiency and high training speed. This paper gives an overview over the
recent advancements and challenges in this new field of research at the
intersection of machine learning and communications.
"
2486,Transferring Cross-domain Knowledge for Video Sign Language Recognition,"  Word-level sign language recognition (WSLR) is a fundamental task in sign
language interpretation. It requires models to recognize isolated sign words
from videos. However, annotating WSLR data needs expert knowledge, thus
limiting WSLR dataset acquisition. On the contrary, there are abundant
subtitled sign news videos on the internet. Since these videos have no
word-level annotation and exhibit a large domain gap from isolated signs, they
cannot be directly used for training WSLR models. We observe that despite the
existence of a large domain gap, isolated and news signs share the same visual
concepts, such as hand gestures and body movements. Motivated by this
observation, we propose a novel method that learns domain-invariant visual
concepts and fertilizes WSLR models by transferring knowledge of subtitled news
sign to them. To this end, we extract news signs using a base WSLR model, and
then design a classifier jointly trained on news and isolated signs to coarsely
align these two domain features. In order to learn domain-invariant features
within each class and suppress domain-specific features, our method further
resorts to an external memory to store the class centroids of the aligned news
signs. We then design a temporal attention based on the learnt descriptor to
improve recognition performance. Experimental results on standard WSLR datasets
show that our method outperforms previous state-of-the-art methods
significantly. We also demonstrate the effectiveness of our method on
automatically localizing signs from sign news, achieving 28.1 for AP@0.5.
"
2487,"Cross-Modal Food Retrieval: Learning a Joint Embedding of Food Images
  and Recipes with Semantic Consistency and Attention Mechanism","  Cross-modal food retrieval is an important task to perform analysis of
food-related information, such as food images and cooking recipes. The goal is
to learn an embedding of images and recipes in a common feature space, so that
precise matching can be realized. Compared with existing cross-modal retrieval
approaches, two major challenges in this specific problem are: 1) the large
intra-class variance across cross-modal food data; and 2) the difficulties in
obtaining discriminative recipe representations. To address these problems, we
propose Semantic-Consistent and Attention-based Networks (SCAN), which
regularize the embeddings of the two modalities by aligning output semantic
probabilities. In addition, we exploit self-attention mechanism to improve the
embedding of recipes. We evaluate the performance of the proposed method on the
large-scale Recipe1M dataset, and the result shows that it outperforms the
state-of-the-art.
"
2488,"I-ViSE: Interactive Video Surveillance as an Edge Service using
  Unsupervised Feature Queries","  Situation AWareness (SAW) is essential for many mission critical
applications. However, SAW is very challenging when trying to immediately
identify objects of interest or zoom in on suspicious activities from thousands
of video frames. This work aims at developing a queryable system to instantly
select interesting content. While face recognition technology is mature, in
many scenarios like public safety monitoring, the features of objects of
interest may be much more complicated than face features. In addition, human
operators may not be always able to provide a descriptive, simple, and accurate
query. Actually, it is more often that there are only rough, general
descriptions of certain suspicious objects or accidents. This paper proposes an
Interactive Video Surveillance as an Edge service (I-ViSE) based on
unsupervised feature queries. Adopting unsupervised methods that do not reveal
any private information, the I-ViSE scheme utilizes general features of a human
body and color of clothes. An I-ViSE prototype is built following the edge-fog
computing paradigm and the experimental results verified the I-ViSE scheme
meets the design goal of scene recognition in less than two seconds.
"
2489,"Semantic Object Prediction and Spatial Sound Super-Resolution with
  Binaural Sounds","  Humans can robustly recognize and localize objects by integrating visual and
auditory cues. While machines are able to do the same now with images, less
work has been done with sounds. This work develops an approach for dense
semantic labelling of sound-making objects, purely based on binaural sounds. We
propose a novel sensor setup and record a new audio-visual dataset of street
scenes with eight professional binaural microphones and a 360 degree camera.
The co-existence of visual and audio cues is leveraged for supervision
transfer. In particular, we employ a cross-modal distillation framework that
consists of a vision `teacher' method and a sound `student' method -- the
student method is trained to generate the same results as the teacher method.
This way, the auditory system can be trained without using human annotations.
We also propose two auxiliary tasks namely, a) a novel task on Spatial Sound
Super-resolution to increase the spatial resolution of sounds, and b) dense
depth prediction of the scene. We then formulate the three tasks into one
end-to-end trainable multi-tasking network aiming to boost the overall
performance. Experimental results on the dataset show that 1) our method
achieves promising results for semantic prediction and the two auxiliary tasks;
and 2) the three tasks are mutually beneficial -- training them together
achieves the best performance and 3) the number and orientations of microphones
are both important. The data and code will be released to facilitate the
research in this new direction.
"
2490,Crossmodal learning for audio-visual speech event localization,"  An objective understanding of media depictions, such as about inclusive
portrayals of how much someone is heard and seen on screen in film and
television, requires the machines to discern automatically who, when, how and
where someone is talking. Media content is rich in multiple modalities such as
visuals and audio which can be used to learn speaker activity in videos. In
this work, we present visual representations that have implicit information
about when someone is talking and where. We propose a crossmodal neural network
for audio speech event detection using the visual frames. We use the learned
representations for two downstream tasks: i) audio-visual voice activity
detection ii) active speaker localization in video frames. We present a
state-of-the-art audio-visual voice activity detection system and demonstrate
that the learned embeddings can effectively localize to active speakers in the
visual frames.
"
2491,"Learning to Respond with Stickers: A Framework of Unifying
  Multi-Modality in Multi-Turn Dialog","  Stickers with vivid and engaging expressions are becoming increasingly
popular in online messaging apps, and some works are dedicated to automatically
select sticker response by matching text labels of stickers with previous
utterances. However, due to their large quantities, it is impractical to
require text labels for the all stickers. Hence, in this paper, we propose to
recommend an appropriate sticker to user based on multi-turn dialog context
history without any external labels. Two main challenges are confronted in this
task. One is to learn semantic meaning of stickers without corresponding text
labels. Another challenge is to jointly model the candidate sticker with the
multi-turn dialog context. To tackle these challenges, we propose a sticker
response selector (SRS) model. Specifically, SRS first employs a convolutional
based sticker image encoder and a self-attention based multi-turn dialog
encoder to obtain the representation of stickers and utterances. Next, deep
interaction network is proposed to conduct deep matching between the sticker
with each utterance in the dialog history. SRS then learns the short-term and
long-term dependency between all interaction results by a fusion network to
output the the final matching score. To evaluate our proposed method, we
collect a large-scale real-world dialog dataset with stickers from one of the
most popular online chatting platform. Extensive experiments conducted on this
dataset show that our model achieves the state-of-the-art performance for all
commonly-used metrics. Experiments also verify the effectiveness of each
component of SRS. To facilitate further research in sticker selection field, we
release this dataset of 340K multi-turn dialog and sticker pairs.
"
2492,Exploring the Role of Visual Content in Fake News Detection,"  The increasing popularity of social media promotes the proliferation of fake
news, which has caused significant negative societal effects. Therefore, fake
news detection on social media has recently become an emerging research area of
great concern. With the development of multimedia technology, fake news
attempts to utilize multimedia content with images or videos to attract and
mislead consumers for rapid dissemination, which makes visual content an
important part of fake news. Despite the importance of visual content, our
understanding of the role of visual content in fake news detection is still
limited. This chapter presents a comprehensive review of the visual content in
fake news, including the basic concepts, effective visual features,
representative detection methods and challenging issues of multimedia fake news
detection. This chapter can help readers to understand the role of visual
content in fake news detection, and effectively utilize visual content to
assist in detecting multimedia fake news.
"
2493,Estimation of Rate Control Parameters for Video Coding Using CNN,"  Rate-control is essential to ensure efficient video delivery. Typical
rate-control algorithms rely on bit allocation strategies, to appropriately
distribute bits among frames. As reference frames are essential for exploiting
temporal redundancies, intra frames are usually assigned a larger portion of
the available bits. In this paper, an accurate method to estimate number of
bits and quality of intra frames is proposed, which can be used for bit
allocation in a rate-control scheme. The algorithm is based on deep learning,
where networks are trained using the original frames as inputs, while
distortions and sizes of compressed frames after encoding are used as ground
truths. Two approaches are proposed where either local or global distortions
are predicted.
"
2494,Counterfactual Samples Synthesizing for Robust Visual Question Answering,"  Despite Visual Question Answering (VQA) has realized impressive progress over
the last few years, today's VQA models tend to capture superficial linguistic
correlations in the train set and fail to generalize to the test set with
different QA distributions. To reduce the language biases, several recent works
introduce an auxiliary question-only model to regularize the training of
targeted VQA model, and achieve dominating performance on VQA-CP. However,
since the complexity of design, current methods are unable to equip the
ensemble-based models with two indispensable characteristics of an ideal VQA
model: 1) visual-explainable: the model should rely on the right visual regions
when making decisions. 2) question-sensitive: the model should be sensitive to
the linguistic variations in question. To this end, we propose a model-agnostic
Counterfactual Samples Synthesizing (CSS) training scheme. The CSS generates
numerous counterfactual training samples by masking critical objects in images
or words in questions, and assigning different ground-truth answers. After
training with the complementary samples (ie, the original and generated
samples), the VQA models are forced to focus on all critical objects and words,
which significantly improves both visual-explainable and question-sensitive
abilities. In return, the performance of these models is further boosted.
Extensive ablations have shown the effectiveness of CSS. Particularly, by
building on top of the model LMH, we achieve a record-breaking performance of
58.95% on VQA-CP v2, with 6.5% gains.
"
2495,Hide Secret Information in Blocks: Minimum Distortion Embedding,"  In this paper, a new steganographic method is presented that provides minimum
distortion in the stego image. The proposed encoding algorithm focuses on DCT
rounding error and optimizes that in a way to reduce distortion in the stego
image, and the proposed algorithm produces less distortion than existing
methods (e.g., F5 algorithm). The proposed method is based on DCT rounding
error which helps to lower distortion and higher embedding capacity.
"
2496,"Deep Attention Fusion Feature for Speech Separation with End-to-End
  Post-filter Method","  In this paper, we propose an end-to-end post-filter method with deep
attention fusion features for monaural speaker-independent speech separation.
At first, a time-frequency domain speech separation method is applied as the
pre-separation stage. The aim of pre-separation stage is to separate the
mixture preliminarily. Although this stage can separate the mixture, it still
contains the residual interference. In order to enhance the pre-separated
speech and improve the separation performance further, the end-to-end
post-filter (E2EPF) with deep attention fusion features is proposed. The E2EPF
can make full use of the prior knowledge of the pre-separated speech, which
contributes to speech separation. It is a fully convolutional speech separation
network and uses the waveform as the input features. Firstly, the 1-D
convolutional layer is utilized to extract the deep representation features for
the mixture and pre-separated signals in the time domain. Secondly, to pay more
attention to the outputs of the pre-separation stage, an attention module is
applied to acquire deep attention fusion features, which are extracted by
computing the similarity between the mixture and the pre-separated speech.
These deep attention fusion features are conducive to reduce the interference
and enhance the pre-separated speech. Finally, these features are sent to the
post-filter to estimate each target signals. Experimental results on the
WSJ0-2mix dataset show that the proposed method outperforms the
state-of-the-art speech separation method. Compared with the pre-separation
method, our proposed method can acquire 64.1%, 60.2%, 25.6% and 7.5% relative
improvements in scale-invariant source-to-noise ratio (SI-SNR), the
signal-to-distortion ratio (SDR), the perceptual evaluation of speech quality
(PESQ) and the short-time objective intelligibility (STOI) measures,
respectively.
"
2497,"Reinforcement Learning Driven Adaptive VR Streaming with Optical Flow
  Based QoE","  With the merit of containing full panoramic content in one camera, Virtual
Reality (VR) and 360-degree videos have attracted more and more attention in
the field of industrial cloud manufacturing and training. Industrial Internet
of Things (IoT), where many VR terminals needed to be online at the same time,
can hardly guarantee VR's bandwidth requirement. However, by making use of
users' quality of experience (QoE) awareness factors, including the relative
moving speed and depth difference between the viewpoint and other content,
bandwidth consumption can be reduced. In this paper, we propose OFB-VR (Optical
Flow Based VR), an interactive method of VR streaming that can make use of VR
users' QoE awareness to ease the bandwidth pressure. The Just-Noticeable
Difference through Optical Flow Estimation (JND-OFE) is explored to quantify
users' awareness of quality distortion in 360-degree videos. Accordingly, a
novel 360-degree videos QoE metric based on PSNR and JND-OFE (PSNR-OF) is
proposed. With the help of PSNR-OF, OFB-VR proposes a versatile-size tiling
scheme to lessen the tiling overhead. A Reinforcement Learning(RL) method is
implemented to make use of historical data to perform Adaptive BitRate(ABR).
For evaluation, we take two prior VR streaming schemes, Pano and Plato, as
baselines. Vast evaluations show that our system can increase the mean PSNR-OF
score by 9.5-15.8% while maintaining the same rebuffer ratio compared with Pano
and Plato in a fluctuate LTE bandwidth dataset. Evaluation results show that
OFB-VR is a promising prototype for actual interactive industrial VR. A
prototype of OFB-VR can be found in https://github.com/buptexplorers/OFB-VR.
"
2498,Parameter-Free Style Projection for Arbitrary Style Transfer,"  Arbitrary image style transfer is a challenging task which aims to stylize a
content image conditioned on an arbitrary style image. In this task the
content-style feature transformation is a critical component for a proper
fusion of features. Existing feature transformation algorithms often suffer
from unstable learning, loss of content and style details, and non-natural
stroke patterns. To mitigate these issues, this paper proposes a parameter-free
algorithm, Style Projection, for fast yet effective content-style
transformation. To leverage the proposed Style Projection~component, this paper
further presents a real-time feed-forward model for arbitrary style transfer,
including a regularization for matching the content semantics between inputs
and outputs. Extensive experiments have demonstrated the effectiveness and
efficiency of the proposed method in terms of qualitative analysis,
quantitative evaluation, and user study.
"
2499,Dynamic Point Cloud Denoising via Manifold-to-Manifold Distance,"  3D dynamic point clouds provide a natural discrete representation of
real-world objects or scenes in motion, with a wide range of applications in
immersive telepresence, autonomous driving, surveillance, \etc. Nevertheless,
dynamic point clouds are often perturbed by noise due to hardware, software or
other causes. While a plethora of methods have been proposed for static point
cloud denoising, few efforts are made for the denoising of dynamic point
clouds, which is quite challenging due to the irregular sampling patterns both
spatially and temporally. In this paper, we represent dynamic point clouds
naturally on spatial-temporal graphs, and exploit the temporal consistency with
respect to the underlying surface (manifold). In particular, we define a
manifold-to-manifold distance and its discrete counterpart on graphs to measure
the variation-based intrinsic distance between surface patches in the temporal
domain, provided that graph operators are discrete counterparts of functionals
on Riemannian manifolds. Then, we construct the spatial-temporal graph
connectivity between corresponding surface patches based on the temporal
distance and between points in adjacent patches in the spatial domain.
Leveraging the initial graph representation, we formulate dynamic point cloud
denoising as the joint optimization of the desired point cloud and underlying
graph representation, regularized by both spatial smoothness and temporal
consistency. We reformulate the optimization and present an efficient
algorithm. Experimental results show that the proposed method significantly
outperforms independent denoising of each frame from state-of-the-art static
point cloud denoising approaches, on both Gaussian noise and simulated LiDAR
noise.
"
2500,"Viewport-Aware Deep Reinforcement Learning Approach for 360$^o$ Video
  Caching","  360$^o$ video is an essential component of VR/AR/MR systems that provides
immersive experience to the users. However, 360$^o$ video is associated with
high bandwidth requirements. The required bandwidth can be reduced by
exploiting the fact that users are interested in viewing only a part of the
video scene and that users request viewports that overlap with each other.
Motivated by the findings of recent works where the benefits of caching video
tiles at edge servers instead of caching entire 360$^o$ videos were shown, in
this paper, we introduce the concept of virtual viewports that have the same
number of tiles with the original viewports. The tiles forming these viewports
are the most popular ones for each video and are determined by the users'
requests. Then, we propose a proactive caching scheme that assumes unknown
videos' and viewports' popularity. Our scheme determines which videos to cache
as well as which is the optimal virtual viewport per video. Virtual viewports
permit to lower the dimensionality of the cache optimization problem. To solve
the problem, we first formulate the content placement of 360$^o$ videos in edge
cache networks as a Markov Decision Process (MDP), and then we determine the
optimal caching placement using the Deep Q-Network (DQN) algorithm. The
proposed solution aims at maximizing the overall quality of the 360$^o$ videos
delivered to the end-users by caching the most popular 360$^o$ videos at base
quality along with a virtual viewport in high quality. We extensively evaluate
the performance of the proposed system and compare it with that of known
systems such as LFU, LRU, FIFO, over both synthetic and real 360$^o$ video
traces. The results reveal the large benefits coming from proactive caching of
virtual viewports instead of the original ones in terms of the overall quality
of the rendered viewports, the cache hit ratio, and the servicing cost.
"
2501,"Convolutional Neural Networks for Continuous QoE Prediction in Video
  Streaming Services","  In video streaming services, predicting the continuous user's quality of
experience (QoE) plays a crucial role in delivering high quality streaming
contents to the user. However, the complexity caused by the temporal
dependencies in QoE data and the non-linear relationships among QoE influence
factors has introduced challenges to continuous QoE prediction. To deal with
that, existing studies have utilized the Long Short-Term Memory model (LSTM) to
effectively capture such complex dependencies, resulting in excellent QoE
prediction accuracy. However, the high computational complexity of LSTM, caused
by the sequential processing characteristic in its architecture, raises a
serious question about its performance on devices with limited computational
power. Meanwhile, Temporal Convolutional Network (TCN), a variation of
convolutional neural networks, has recently been proposed for sequence modeling
tasks (e.g., speech enhancement), providing a superior prediction performance
over baseline methods including LSTM in terms of prediction accuracy and
computational complexity. Being inspired of that, in this paper, an improved
TCN-based model, namely CNN-QoE, is proposed for continuously predicting the
QoE, which poses characteristics of sequential data. The proposed model
leverages the advantages of TCN to overcome the computational complexity
drawbacks of LSTM-based QoE models, while at the same time introducing the
improvements to its architecture to improve QoE prediction accuracy. Based on a
comprehensive evaluation, we demonstrate that the proposed CNN-QoE model can
reach the state-of-the-art performance on both personal computers and mobile
devices, outperforming the existing approaches.
"
2502,"FAURAS: A Proxy-based Framework for Ensuring the Fairness of Adaptive
  Video Streaming over HTTP/2 Server Push","  HTTP/2 video streaming has caught a lot of attentions in the development of
multimedia technologies over the last few years. In HTTP/2, the server push
mechanism allows the server to deliver more video segments to the client within
a single request in order to deal with the requests explosion problem. As a
result, recent research efforts have been focusing on utilizing such a feature
to enhance the streaming experience while reducing the request-related
overhead. However, current works only optimize the performance of a single
client, without necessary concerns of possible influences on other clients in
the same network. When multiple streaming clients compete for a shared
bandwidth in HTTP/1.1, they are likely to suffer from unfairness, which is
defined as the inequality in their bitrate selections. For HTTP/1.1, existing
works have proven that the network-assisted solutions are effective in solving
the unfairness problem. However, the feasibility of utilizing such an approach
for the HTTP/2 server push has not been investigated. Therefore, in this paper,
a novel proxy-based framework is proposed to overcome the unfairness problem in
adaptive streaming over HTTP/2 with the server push. Experimental results
confirm the outperformance of the proposed framework in ensuring the fairness,
assisting the clients to avoid rebuffering events and lower bitrate degradation
amplitude, while maintaining the mechanism of the server push feature.
"
2503,Personalized Taste and Cuisine Preference Modeling via Images,"  With the exponential growth in the usage of social media to share live
updates about life, taking pictures has become an unavoidable phenomenon.
Individuals unknowingly create a unique knowledge base with these images. The
food images, in particular, are of interest as they contain a plethora of
information. From the image metadata and using computer vision tools, we can
extract distinct insights for each user to build a personal profile. Using the
underlying connection between cuisines and their inherent tastes, we attempt to
develop such a profile for an individual based solely on the images of his
food. Our study provides insights about an individual's inclination towards
particular cuisines. Interpreting these insights can lead to the development of
a more precise recommendation system. Such a system would avoid the generic
approach in favor of a personalized recommendation system.
"
2504,"DRST: Deep Residual Shearlet Transform for Densely Sampled Light Field
  Reconstruction","  The Image-Based Rendering (IBR) approach using Shearlet Transform (ST) is one
of the most effective methods for Densely-Sampled Light Field (DSLF)
reconstruction. The ST-based DSLF reconstruction typically relies on an
iterative thresholding algorithm for Epipolar-Plane Image (EPI) sparse
regularization in shearlet domain, involving dozens of transformations between
image domain and shearlet domain, which are in general time-consuming. To
overcome this limitation, a novel learning-based ST approach, referred to as
Deep Residual Shearlet Transform (DRST), is proposed in this paper.
Specifically, for an input sparsely-sampled EPI, DRST employs a deep fully
Convolutional Neural Network (CNN) to predict the residuals of the shearlet
coefficients in shearlet domain in order to reconstruct a densely-sampled EPI
in image domain. The DRST network is trained on synthetic Sparsely-Sampled
Light Field (SSLF) data only by leveraging elaborately-designed masks.
Experimental results on three challenging real-world light field evaluation
datasets with varying moderate disparity ranges (8 - 16 pixels) demonstrate the
superiority of the proposed learning-based DRST approach over the
non-learning-based ST method for DSLF reconstruction. Moreover, DRST provides a
2.4x speedup over ST, at least.
"
2505,"Normalized and Geometry-Aware Self-Attention Network for Image
  Captioning","  Self-attention (SA) network has shown profound value in image captioning. In
this paper, we improve SA from two aspects to promote the performance of image
captioning. First, we propose Normalized Self-Attention (NSA), a
reparameterization of SA that brings the benefits of normalization inside SA.
While normalization is previously only applied outside SA, we introduce a novel
normalization method and demonstrate that it is both possible and beneficial to
perform it on the hidden activations inside SA. Second, to compensate for the
major limit of Transformer that it fails to model the geometry structure of the
input objects, we propose a class of Geometry-aware Self-Attention (GSA) that
extends SA to explicitly and efficiently consider the relative geometry
relations between the objects in the image. To construct our image captioning
model, we combine the two modules and apply it to the vanilla self-attention
network. We extensively evaluate our proposals on MS-COCO image captioning
dataset and superior results are achieved when comparing to state-of-the-art
approaches. Further experiments on three challenging tasks, i.e. video
captioning, machine translation, and visual question answering, show the
generality of our methods.
"
2506,Continuous QoE Prediction Based on WaveNet,"  Continuous QoE prediction is crucial in the purpose of maximizing viewer
satisfaction, by which video service providers could improve the revenue.
Continuously predicting QoE is challenging since it requires QoE models that
are capable of capturing the complex dependencies among QoE influence factors.
The existing approaches that utilize Long-Short-Term-Memory (LSTM) network
successfully model such long-term dependencies, providing the superior QoE
prediction performance. However, the inherent drawback of sequential computing
of LSTM will result in high computational cost in training and prediction
tasks. Recently, WaveNet, a deep neural network for generating raw audio
waveform, has been introduced. Immediately, it gains a great attention since it
successfully leverages the characteristic of parallel computing of causal
convolution and dilated convolution to deal with time-series data (e.g., audio
signal). Being inspired by the success of WaveNet, in this paper, we propose
WaveNet-based QoE model for continuous QoE prediction in video streaming
services. The model is trained and tested upon on two publicly available
databases, namely, LFOVIA Video QoE and LIVE Mobile Stall Video II. The
experimental results demonstrate that the proposed model outperforms the
baselines models in terms of processing time, while maintaining sufficient
accuracy.
"
2507,"Self-Supervised Light Field Reconstruction Using Shearlet Transform and
  Cycle Consistency","  The image-based rendering approach using Shearlet Transform (ST) is one of
the state-of-the-art Densely-Sampled Light Field (DSLF) reconstruction methods.
It reconstructs Epipolar-Plane Images (EPIs) in image domain via an iterative
regularization algorithm restoring their coefficients in shearlet domain.
Consequently, the ST method tends to be slow because of the time spent on
domain transformations for dozens of iterations. To overcome this limitation,
this letter proposes a novel self-supervised DSLF reconstruction method,
CycleST, which applies ST and cycle consistency to DSLF reconstruction.
Specifically, CycleST is composed of an encoder-decoder network and a residual
learning strategy that restore the shearlet coefficients of densely-sampled
EPIs using EPI reconstruction and cycle consistency losses. Besides, CycleST is
a self-supervised approach that can be trained solely on Sparsely-Sampled Light
Fields (SSLFs) with small disparity ranges ($\leqslant$ 8 pixels). Experimental
results of DSLF reconstruction on SSLFs with large disparity ranges (16 - 32
pixels) from two challenging real-world light field datasets demonstrate the
effectiveness and efficiency of the proposed CycleST method. Furthermore,
CycleST achieves ~ 9x speedup over ST, at least.
"
2508,"Edge-assisted Viewport Adaptive Scheme for real-time Omnidirectional
  Video transmission","  Omnidirectional applications are immersive and highly interactive, which can
improve the efficiency of remote collaborative work among factory workers. The
transmission of omnidirectional video (OV) is the most important step in
implementing virtual remote collaboration. Compared with the ordinary video
transmission, OV transmission requires more bandwidth, which is still a huge
burden even under 5G networks. The tile-based scheme can reduce bandwidth
consumption. However, it neither accurately obtain the field of view(FOV) area,
nor difficult to support real-time OV streaming. In this paper, we propose an
edge-assisted viewport adaptive scheme (EVAS-OV) to reduce bandwidth
consumption during real-time OV transmission. First, EVAS-OV uses a Gated
Recurrent Unit(GRU) model to predict users' viewport. Then, users were divided
into multicast clusters thereby further reducing the consumption of computing
resources. EVAS-OV reprojects OV frames to accurately obtain users' FOV area
from pixel level and adopt a redundant strategy to reduce the impact of
viewport prediction errors. All computing tasks were offloaded to edge servers
to reduce the transmission delay and improve bandwidth utilization.
Experimental results show that EVAS-OV can save more than 60\% of bandwidth
compared with the non-viewport adaptive scheme. Compared to a two-layer scheme
with viewport adaptive, EVAS-OV still saves 30\% of bandwidth.
"
2509,"JPEG Steganography and Synchronization of DCT Coefficients for a Given
  Development Pipeline","  This short paper proposes to use the statistical analysis of the correlation
between DCT coefficients to design a new synchronization strategy that can be
used for cost-based steganographic schemes in the JPEG domain. First, an
analysis is performed on the covariance matrix of DCT coefficients of
neighboring blocks after a development similar to the one used to generate
BossBase. This analysis exhibits groups of uncorrelated coefficients: 4 groups
per block and 2 groups of uncorrelated diagonal neighbors together with groups
of mutually correlated coefficients groups of 6 coefficients per blocs and 8
coefficients between 2 adjacent blocks. Using the uncorrelated groups, an
embedding scheme can be designed using only 8 disjoint lattices. The cost map
for each lattice is updated firstly by using an implicit underlying Gaussian
distribution with a variance directly computed from the embedding costs, and
secondly by deriving conditional distributions from multivariate distributions.
The covariance matrix of these distributions takes into account both the
correlations exhibited by the analysis of the covariance matrix and the
variance derived from the cost. This synchronization scheme enables to obtain a
gain of PE of 5% at QF 95 for an embedding rate close to 0.3 bnzac coefficient
using DCTR feature sets.
"
2510,Multi-channel U-Net for Music Source Separation,"  A fairly straightforward approach for music source separation is to train
independent models, wherein each model is dedicated for estimating only a
specific source. Training a single model to estimate multiple sources generally
does not perform as well as the independent dedicated models. However,
Conditioned U-Net (C-U-Net) uses a control mechanism to train a single model
for multi-source separation and attempts to achieve a performance comparable to
that of the dedicated models. We propose a multi-channel U-Net (M-U-Net)
trained using a weighted multi-task loss as an alternative to the C-U-Net. We
investigate two weighting strategies for our multi-task loss: 1) Dynamic
Weighted Average (DWA), and 2) Energy Based Weighting (EBW). DWA determines the
weights by tracking the rate of change of loss of each task during training.
EBW aims to neutralize the effect of the training bias arising from the
difference in energy levels of each of the sources in a mixture. Our methods
provide three-fold advantages compared to C-UNet: 1) Fewer effective training
iterations per epoch, 2) Fewer trainable network parameters (no control
parameters), and 3) Faster processing at inference. Our methods achieve
performance comparable to that of C-U-Net and the dedicated U-Nets at a much
lower training cost.
"
2511,"Multimodal Analytics for Real-world News using Measures of Cross-modal
  Entity Consistency","  The World Wide Web has become a popular source for gathering information and
news. Multimodal information, e.g., enriching text with photos, is typically
used to convey the news more effectively or to attract attention. Photo content
can range from decorative, depict additional important information, or can even
contain misleading information. Therefore, automatic approaches to quantify
cross-modal consistency of entity representation can support human assessors to
evaluate the overall multimodal message, for instance, with regard to bias or
sentiment. In some cases such measures could give hints to detect fake news,
which is an increasingly important topic in today's society. In this paper, we
introduce a novel task of cross-modal consistency verification in real-world
news and present a multimodal approach to quantify the entity coherence between
image and text. Named entity linking is applied to extract persons, locations,
and events from news texts. Several measures are suggested to calculate
cross-modal similarity for these entities using state of the art approaches. In
contrast to previous work, our system automatically gathers example data from
the Web and is applicable to real-world news. Results on two novel datasets
that cover different languages, topics, and domains demonstrate the feasibility
of our approach. Datasets and code are publicly available to foster research
towards this new direction.
"
2512,Forensic Analysis of Residual Information in Adobe PDF Files,"  In recent years, as electronic files include personal records and business
activities, these files can be used as important evidences in a digital
forensic investigation process. In general, the data that can be verified using
its own application programs is largely used in the investigation of document
files. However, in the case of the PDF file that has been largely used at the
present time, certain data, which include the data before some modifications,
exist in electronic document files unintentionally. Because such residual
information may present the writing process of a file, it can be usefully used
in a forensic viewpoint. This paper introduces why the residual information is
stored inside the PDF file and explains a way to extract the information. In
addition, we demonstrate the attributes of PDF files can be used to hide data.
"
2513,"FacebookVideoLive18: A Live Video Streaming Dataset for Streams Metadata
  and Online Viewers Locations","  With the advancement in personal smart devices and pervasive network
connectivity, users are no longer passive content consumers, but also
contributors in producing new contents. This expansion in live services
requires a detailed analysis of broadcasters' and viewers' behavior to maximize
users' Quality of Experience (QoE). In this paper, we present a dataset
gathered from one of the popular live streaming platforms: Facebook. In this
dataset, we stored more than 1,500,000 live stream records collected in June
and July 2018. These data include public live videos from all over the world.
However, Facebook live API does not offer the possibility to collect online
videos with their fine grained data. The API allows to get the general data of
a stream, only if we know its ID (identifier). Therefore, using the live map
website provided by Facebook and showing the locations of online streams and
locations of viewers, we extracted video IDs and different coordinates along
with general metadata. Then, having these IDs and using the API, we can collect
the fine grained metadata of public videos that might be useful for the
research community. We also present several preliminary analyses to describe
and identify the patterns of the streams and viewers. Such fine grained details
will enable the multimedia community to recreate real-world scenarios
particularly for resource allocation, caching, computation, and transcoding in
edge networks. Existing datasets do not provide the locations of the viewers,
which limits the efforts made to allocate the multimedia resources as close as
possible to viewers and to offer better QoE.
"
2514,"How deep is your encoder: an analysis of features descriptors for an
  autoencoder-based audio-visual quality metric","  The development of audio-visual quality assessment models poses a number of
challenges in order to obtain accurate predictions. One of these challenges is
the modelling of the complex interaction that audio and visual stimuli have and
how this interaction is interpreted by human users. The No-Reference
Audio-Visual Quality Metric Based on a Deep Autoencoder (NAViDAd) deals with
this problem from a machine learning perspective. The metric receives two sets
of audio and video features descriptors and produces a low-dimensional set of
features used to predict the audio-visual quality. A basic implementation of
NAViDAd was able to produce accurate predictions tested with a range of
different audio-visual databases. The current work performs an ablation study
on the base architecture of the metric. Several modules are removed or
re-trained using different configurations to have a better understanding of the
metric functionality. The results presented in this study provided important
feedback that allows us to understand the real capacity of the metric's
architecture and eventually develop a much better audio-visual quality metric.
"
2515,"Impact of the Number of Votes on the Reliability and Validity of
  Subjective Speech Quality Assessment in the Crowdsourcing Approach","  The subjective quality of transmitted speech is traditionally assessed in a
controlled laboratory environment according to ITU-T Rec. P.800. In turn, with
crowdsourcing, crowdworkers participate in a subjective online experiment using
their own listening device, and in their own working environment. Despite such
less controllable conditions, the increased use of crowdsourcing micro-task
platforms for quality assessment tasks has pushed a high demand for
standardized methods, resulting in ITU-T Rec. P.808. This work investigates the
impact of the number of judgments on the reliability and the validity of
quality ratings collected through crowdsourcing-based speech quality
assessments, as an input to ITU-T Rec. P.808 . Three crowdsourcing experiments
on different platforms were conducted to evaluate the overall quality of three
different speech datasets, using the Absolute Category Rating procedure. For
each dataset, the Mean Opinion Scores (MOS) are calculated using differing
numbers of crowdsourcing judgements. Then the results are compared to MOS
values collected in a standard laboratory experiment, to assess the validity of
crowdsourcing approach as a function of number of votes. In addition, the
reliability of the average scores is analyzed by checking inter-rater
reliability, gain in certainty, and the confidence of the MOS. The results
provide a suggestion on the required number of votes per condition, and allow
to model its impact on validity and reliability.
"
2516,"Unsupervised Cross-Modal Audio Representation Learning from Unstructured
  Multilingual Text","  We present an approach to unsupervised audio representation learning. Based
on a triplet neural network architecture, we harnesses semantically related
cross-modal information to estimate audio track-relatedness. By applying Latent
Semantic Indexing (LSI) we embed corresponding textual information into a
latent vector space from which we derive track relatedness for online triplet
selection. This LSI topic modelling facilitates fine-grained selection of
similar and dissimilar audio-track pairs to learn the audio representation
using a Convolution Recurrent Neural Network (CRNN). By this we directly
project the semantic context of the unstructured text modality onto the learned
representation space of the audio modality without deriving structured
ground-truth annotations from it. We evaluate our approach on the Europeana
Sounds collection and show how to improve search in digital audio libraries by
harnessing the multilingual meta-data provided by numerous European digital
libraries. We show that our approach is invariant to the variety of annotation
styles as well as to the different languages of this collection. The learned
representations perform comparable to the baseline of handcrafted features,
respectively exceeding this baseline in similarity retrieval precision at
higher cut-offs with only 15\% of the baseline's feature vector length.
"
2517,"A General Approach for Using Deep Neural Network for Digital
  Watermarking","  Technologies of the Internet of Things (IoT) facilitate digital contents such
as images being acquired in a massive way. However, consideration from the
privacy or legislation perspective still demands the need for intellectual
content protection. In this paper, we propose a general deep neural network
(DNN) based watermarking method to fulfill this goal. Instead of training a
neural network for protecting a specific image, we train on an image set and
use the trained model to protect a distinct test image set in a bulk manner.
Respective evaluations both from the subjective and objective aspects confirm
the supremacy and practicability of our proposed method. To demonstrate the
robustness of this general neural watermarking mechanism, commonly used
manipulations are applied to the watermarked image to examine the corresponding
extracted watermark, which still retains sufficient recognizable traits. To the
best of our knowledge, we are the first to propose a general way to perform
watermarking using DNN. Considering its performance and economy, it is
concluded that subsequent studies that generalize our work on utilizing DNN for
intellectual content protection is a promising research trend.
"
2518,From QoS Distributions to QoE Distributions: a System's Perspective,"  In the context of QoE management, network and service providers commonly rely
on models that map system QoS conditions (e.g., system response time, paket
loss, etc.) to estimated end user QoE values. Observable QoS conditions in the
system may be assumed to follow a certain distribution, meaning that different
end users will experience different conditions. On the other hand, drawing from
the results of subjective user studies, we know that user diversity leads to
distributions of user scores for any given test conditions (in this case
referring to the QoS parameters of interest). Our previous studies have shown
that to correctly derive various QoE metrics (e.g., Mean Opinion Score (MOS),
quantiles, probability of users rating ""good or better"", etc.) in a system
under given conditions, there is a need to consider rating distributions
obtained from user studies, which are often times not available. In this paper
we extend these findings to show how to approximate user rating distributions
given a QoS-to-MOS mapping function and second order statistics. Such a user
rating distribution may then be combined with a QoS distribution observed in a
system to finally derive corresponding distributions of QoE scores. We provide
two examples to illustrate this process: 1) analytical results using a Web QoE
model relating waiting times to QoE, and 2) numerical results using
measurements relating packet losses to video stall pattern, which are in turn
mapped to QoE estimates. The results in this paper provide a solution to the
problem of understanding the QoE distribution in a system, in cases where the
necessary data is not directly available in the form of models going beyond the
MOS, or where the full details of subjective experiments are not available.
"
2519,Deep Residual Neural Networks for Image in Speech Steganography,"  Steganography is the art of hiding a secret message inside a publicly visible
carrier message. Ideally, it is done without modifying the carrier, and with
minimal loss of information in the secret message. Recently, various deep
learning based approaches to steganography have been applied to different
message types. We propose a deep learning based technique to hide a source RGB
image message inside finite length speech segments without perceptual loss. To
achieve this, we train three neural networks; an encoding network to hide the
message in the carrier, a decoding network to reconstruct the message from the
carrier and an additional image enhancer network to further improve the
reconstructed message. We also discuss future improvements to the algorithm
proposed.
"
2520,"A generalized Hausdorff distance based quality metric for point cloud
  geometry","  Reliable quality assessment of decoded point cloud geometry is essential to
evaluate the compression performance of emerging point cloud coding solutions
and guarantee some target quality of experience. This paper proposes a novel
point cloud geometry quality assessment metric based on a generalization of the
Hausdorff distance. To achieve this goal, the so-called generalized Hausdorff
distance for multiple rankings is exploited to identify the best performing
quality metric in terms of correlation with the MOS scores obtained from a
subjective test campaign. The experimental results show that the quality metric
derived from the classical Hausdorff distance leads to low objective-subjective
correlation and, thus, fails to accurately evaluate the quality of decoded
point clouds for emerging codecs. However, the quality metric derived from the
generalized Hausdorff distance with an appropriately selected ranking,
outperforms the MPEG adopted geometry quality metrics when decoded point clouds
with different types of coding distortions are considered.
"
2521,Social-Sensor Composition for Tapestry Scenes,"  The extensive use of social media platforms and overwhelming amounts of
imagery data creates unique opportunities for sensing, gathering and sharing
information about events. One of its potential applications is to leverage
crowdsourced social media images to create a tapestry scene for scene analysis
of designated locations and time intervals. The existing attempts however
ignore the temporal-semantic relevance and spatio-temporal evolution of the
images and direction-oriented scene reconstruction. We propose a novel
social-sensor cloud (SocSen) service composition approach to form tapestry
scenes for scene analysis. The novelty lies in utilising images and image
meta-information to bypass expensive traditional image processing techniques to
reconstruct scenes. Metadata, such as geolocation, time and angle of view of an
image are modelled as non-functional attributes of a SocSen service. Our major
contribution lies on proposing a context and direction-aware spatio-temporal
clustering and recommendation approach for selecting a set of temporally and
semantically similar services to compose the best available SocSen services.
Analytical results based on real datasets are presented to demonstrate the
performance of the proposed approach.
"
2522,"Development and Validation of Pictographic Scales for Rapid Assessment
  of Affective States in Virtual Reality","  This paper describes the development and validation of a continuous
pictographic scale for self-reported assessment of affective states in virtual
environments. The developed tool, called Morph A Mood (MAM), consists of a 3D
character whose facial expression can be adjusted with simple controller
gestures according to the perceived affective state to capture valence and
arousal scores. It was tested against the questionnaires Pick-A-Mood (PAM) and
Self-Assessment Manikin (SAM) in an experiment in which the participants (N =
32) watched several one-minute excerpts from music videos of the DEAP database
within a virtual environment and assessed their mood after each clip. The
experiment showed a high correlation with regard to valence, but only a
moderate one with regard to arousal. No statistically significant differences
were found between the SAM ratings of this experiment and MAM, but between the
valence values of MAM and the DEAP database and between the arousal values of
MAM and PAM. In terms of user experience, MAM and PAM hardly differ.
Furthermore, the experiment showed that assessments inside virtual environments
are significantly faster than with paper-pencil methods, where media devices
such as headphones and display goggles must be put on and taken off.
"
2523,"Demonstrating Immersive Media Delivery on 5G Broadcast and Multicast
  Testing Networks","  This work presents eight demonstrators and one showcase developed within the
5G-Xcast project. They experimentally demonstrate and validate key technical
enablers for the future of media delivery, associated with multicast and
broadcast communication capabilities in 5th Generation (5G). In 5G-Xcast, three
existing testbeds: IRT in Munich (Germany), 5GIC in Surrey (UK), and TUAS in
Turku (Finland), have been developed into 5G broadcast and multicast testing
networks, which enables us to demonstrate our vision of a converged 5G
infrastructure with fixed and mobile accesses and terrestrial broadcast,
delivering immersive audio-visual media content. Built upon the improved
testing networks, the demonstrators and showcase developed in 5G-Xcast show the
impact of the technology developed in the project. Our demonstrations
predominantly cover use cases belonging to two verticals: Media & Entertainment
and Public Warning, which are future 5G scenarios relevant to multicast and
broadcast delivery. In this paper, we present the development of these
demonstrators, the showcase, and the testbeds. We also provide key findings
from the experiments and demonstrations, which not only validate the technical
solutions developed in the project, but also illustrate the potential technical
impact of these solutions for broadcasters, content providers, operators, and
other industries interested in the future immersive media delivery.
"
2524,"Pixel-BERT: Aligning Image Pixels with Text by Deep Multi-Modal
  Transformers","  We propose Pixel-BERT to align image pixels with text by deep multi-modal
transformers that jointly learn visual and language embedding in a unified
end-to-end framework. We aim to build a more accurate and thorough connection
between image pixels and language semantics directly from image and sentence
pairs instead of using region-based image features as the most recent vision
and language tasks. Our Pixel-BERT which aligns semantic connection in pixel
and text level solves the limitation of task-specific visual representation for
vision and language tasks. It also relieves the cost of bounding box
annotations and overcomes the unbalance between semantic labels in visual task
and language semantic. To provide a better representation for down-stream
tasks, we pre-train a universal end-to-end model with image and sentence pairs
from Visual Genome dataset and MS-COCO dataset. We propose to use a random
pixel sampling mechanism to enhance the robustness of visual representation and
to apply the Masked Language Model and Image-Text Matching as pre-training
tasks. Extensive experiments on downstream tasks with our pre-trained model
show that our approach makes the most state-of-the-arts in downstream tasks,
including Visual Question Answering (VQA), image-text retrieval, Natural
Language for Visual Reasoning for Real (NLVR). Particularly, we boost the
performance of a single model in VQA task by 2.17 points compared with SOTA
under fair comparison.
"
2525,"Multi-Modal Video Forensic Platform for Investigating Post-Terrorist
  Attack Scenarios","  The forensic investigation of a terrorist attack poses a significant
challenge to the investigative authorities, as often several thousand hours of
video footage must be viewed. Large scale Video Analytic Platforms (VAP) assist
law enforcement agencies (LEA) in identifying suspects and securing evidence.
Current platforms focus primarily on the integration of different computer
vision methods and thus are restricted to a single modality. We present a video
analytic platform that integrates visual and audio analytic modules and fuses
information from surveillance cameras and video uploads from eyewitnesses.
Videos are analyzed according their acoustic and visual content. Specifically,
Audio Event Detection is applied to index the content according to
attack-specific acoustic concepts. Audio similarity search is utilized to
identify similar video sequences recorded from different perspectives. Visual
object detection and tracking are used to index the content according to
relevant concepts. Innovative user-interface concepts are introduced to harness
the full potential of the heterogeneous results of the analytical modules,
allowing investigators to more quickly follow-up on leads and eyewitness
reports.
"
2526,"Comparing emotional states induced by 360$^{\circ}$ videos via
  head-mounted display and computer screen","  In recent years 360$^{\circ}$ videos have been becoming more popular. For
traditional media presentations, e.g., on a computer screen, a wide range of
assessment methods are available. Different constructs, such as perceived
quality or the induced emotional state of viewers, can be reliably assessed by
subjective scales. Many of the subjective methods have only been validated
using stimuli presented on a computer screen. This paper is using 360$^{\circ}$
videos to induce varying emotional states. Videos were presented 1) via a
head-mounted display (HMD) and 2) via a traditional computer screen.
Furthermore, participants were asked to rate their emotional state 1) in
retrospect on the self-assessment manikin scale and 2) continuously on a
2-dimensional arousal-valence plane. In a repeated measures design, all
participants (N = 18) used both presentation systems and both rating systems.
Results indicate that there is a statistically significant difference in
induced presence due to the presentation system. Furthermore, there was no
statistically significant difference in ratings gathered with the two
presentation systems. Finally, it was found that for arousal measures, a
statistically significant difference could be found for the different rating
methods, potentially indicating an underestimation of arousal ratings gathered
in retrospect for screen presentation. In the future, rating methods such as a
2-dimensional arousal-valence plane could offer the advantage of enabling a
reliable measurement of emotional states while being more embedded in the
experience itself, enabling a more precise capturing of the emotional states.
"
2527,"User Experience of Reading in Virtual Reality -- Finding Values for Text
  Distance, Size and Contrast","  Virtual Reality (VR) has an increasing impact on the market in many fields,
from education and medicine to engineering and entertainment, by creating
different applications that replicate or in the case of augmentation enhance
real-life scenarios. Intending to present realistic environments, VR
applications are including text that we are surrounded by every day. However,
text can only add value to the virtual environment if it is designed and
created in such a way that users can comfortably read it. With the aim to
explore what values for text parameters users find comfortable while reading in
virtual reality, a study was conducted allowing participants to manipulate text
parameters such as font size, distance, and contrast. Therefore two different
standalone virtual reality devices were used, Oculus Go and Quest, together
with three different text samples: Short (2 words), medium (21 words), and long
(51 words). Participants had the task of setting text parameters to the best
and worst possible value. Additionally, participants were asked to rate their
experience of reading in virtual reality. Results report mean values for
angular size (the combination of distance and font size) and color contrast
depending on the different device used as well as the varying text length, for
both tasks. Significant differences were found for values of angular size,
depending on the length of the displayed text. However, different device types
had no significant influence on text parameters but on the experiences reported
using the self-assessment manikin (SAM) scale.
"
2528,"Impact of Tactile and Visual Feedback on Breathing Rhythm and User
  Experience in VR Exergaming","  Combining interconnected wearables provides fascinating opportunities like
augmenting exergaming with virtual coaches, feedback on the execution of sports
activities, or how to improve on them. Breathing rhythm is a particularly
interesting physiological dimension since it is easy and unobtrusive to measure
and gained data provide valuable insights regarding the correct execution of
movements, especially when analyzed together with additional movement data in
real-time. In this work, we focus on indoor rowing since it is a popular sport
that's often done alone without extensive instructions. We compare a visual
breathing indication with haptic guidance in order for athletes to maintain a
correct, efficient, and healthy breathing-movement-synchronicity (BMS) while
working out. Also, user experience and acceptance of the different modalities
were measured. The results show a positive and statistically significant impact
of purely verbal instructions and purely tactile feedback on BMS and no
significant impact of visual feedback. Interestingly, the subjective ratings
indicate a strong preference for the visual modality and even an aversion for
the haptic feedback, although objectively the performance benefited most from
using the latter.
"
2529,Temporally Distributed Networks for Fast Video Semantic Segmentation,"  We present TDNet, a temporally distributed network designed for fast and
accurate video semantic segmentation. We observe that features extracted from a
certain high-level layer of a deep CNN can be approximated by composing
features extracted from several shallower sub-networks. Leveraging the inherent
temporal continuity in videos, we distribute these sub-networks over sequential
frames. Therefore, at each time step, we only need to perform a lightweight
computation to extract a sub-features group from a single sub-network. The full
features used for segmentation are then recomposed by application of a novel
attention propagation module that compensates for geometry deformation between
frames. A grouped knowledge distillation loss is also introduced to further
improve the representation power at both full and sub-feature levels.
Experiments on Cityscapes, CamVid, and NYUD-v2 demonstrate that our method
achieves state-of-the-art accuracy with significantly faster speed and lower
latency.
"
2530,Low-complexity and Reliable Transforms for Physical Unclonable Functions,"  Noisy measurements of a physical unclonable function (PUF) are used to store
secret keys with reliability, security, privacy, and complexity constraints. A
new set of low-complexity and orthogonal transforms with no multiplication is
proposed to obtain bit-error probability results significantly better than all
methods previously proposed for key binding with PUFs. The uniqueness and
security performance of a transform selected from the proposed set is shown to
be close to optimal. An error-correction code with a low-complexity decoder and
a high code rate is shown to provide a block-error probability significantly
smaller than provided by previously proposed codes with the same or smaller
code rates.
"
2531,A Simple Model for Subject Behavior in Subjective Experiments,"  In a subjective experiment to evaluate the perceptual audiovisual quality of
multimedia and television services, raw opinion scores offered by subjects are
often noisy and unreliable. Recommendations such as ITU-R BT.500, ITU-T P.910
and ITU-T P.913 standardize post-processing procedures to clean up the raw
opinion scores, using techniques such as subject outlier rejection and bias
removal. In this paper, we analyze the prior standardized techniques to
demonstrate their weaknesses. As an alternative, we propose a simple model to
account for two of the most dominant behaviors of subject inaccuracy: bias (aka
systematic error) and inconsistency (aka random error). We further show that
this model can also effectively deal with inattentive subjects that give random
scores. We propose to use maximum likelihood estimation (MLE) to jointly
estimate the model parameters, and present two numeric solvers: the first based
on the Newton-Raphson method, and the second based on alternating projection.
We show that the second solver can be considered as a generalization of the
subject bias removal procedure in ITU-T P.913. We compare the proposed methods
with the standardized techniques using real datasets and synthetic simulations,
and demonstrate that the proposed methods have advantages in better model-data
fit, tighter confidence intervals, better robustness against subject outliers,
shorter runtime, the absence of hard coded parameters and thresholds, and
auxiliary information on test subjects. The source code for this work is
open-sourced at https://github.com/Netflix/sureal.
"
2532,Deep Multimodal Feature Encoding for Video Ordering,"  True understanding of videos comes from a joint analysis of all its
modalities: the video frames, the audio track, and any accompanying text such
as closed captions. We present a way to learn a compact multimodal feature
representation that encodes all these modalities. Our model parameters are
learned through a proxy task of inferring the temporal ordering of a set of
unordered videos in a timeline. To this end, we create a new multimodal dataset
for temporal ordering that consists of approximately 30K scenes (2-6 clips per
scene) based on the ""Large Scale Movie Description Challenge"". We analyze and
evaluate the individual and joint modalities on three challenging tasks: (i)
inferring the temporal ordering of a set of videos; and (ii) action
recognition. We demonstrate empirically that multimodal representations are
indeed complementary, and can play a key role in improving the performance of
many applications.
"
2533,A Local-to-Global Approach to Multi-modal Movie Scene Segmentation,"  Scene, as the crucial unit of storytelling in movies, contains complex
activities of actors and their interactions in a physical environment.
Identifying the composition of scenes serves as a critical step towards
semantic understanding of movies. This is very challenging -- compared to the
videos studied in conventional vision problems, e.g. action recognition, as
scenes in movies usually contain much richer temporal structures and more
complex semantic information. Towards this goal, we scale up the scene
segmentation task by building a large-scale video dataset MovieScenes, which
contains 21K annotated scene segments from 150 movies. We further propose a
local-to-global scene segmentation framework, which integrates multi-modal
information across three levels, i.e. clip, segment, and movie. This framework
is able to distill complex semantics from hierarchical temporal structures over
a long movie, providing top-down guidance for scene segmentation. Our
experiments show that the proposed network is able to segment a movie into
scenes with high accuracy, consistently outperforming previous methods. We also
found that pretraining on our MovieScenes can bring significant improvements to
the existing approaches.
"
2534,Robust Wavelet-Based Watermarking Using Dynamic Strength Factor,"  In unsecured network environments, ownership protection of digital contents,
such as images, is becoming a growing concern. Different watermarking methods
have been proposed to address the copyright protection of digital materials.
Watermarking methods are challenged with conflicting parameters of
imperceptibility and robustness. While embedding a watermark with a high
strength factor increases robustness, it also decreases imperceptibility of the
watermark. Thus embedding in visually less sensitive regions, i.e., complex
image blocks could satisfy both requirements. This paper presents a new
wavelet-based watermarking technique using an adaptive strength factor to
tradeoff between watermark transparency and robustness. We measure variations
of each image block to adaptively set a strength-factor for embedding the
watermark in that block. On the other hand, the decoder uses the selected
coefficients to safely extract the watermark through a voting algorithm. The
proposed method shows better results in terms of PSNR and BER in comparison to
recent methods for attacks, such as Median Filter, Gaussian Filter, and JPEG
compression.
"
2535,Exploiting context dependence for image compression with upsampling,"  Image compression with upsampling encodes information to succeedingly
increase image resolution, for example by encoding differences in FUIF and JPEG
XL. It is useful for progressive decoding, also often can improve compression
ratio - both for lossless compression and e.g. DC coefficients of lossy.
However, the currently used solutions rather do not exploit context dependence
for encoding of such upscaling information. This article discusses simple
inexpensive general techniques for this purpose, which allowed to save on
average $0.645$ bits/difference (between $0.138$ and $1.489$) for the last
upscaling for 48 standard $512\times 512$ grayscale 8 bit images - compared to
assumption of fixed Laplace distribution. Using least squares linear regression
of context to predict center of Laplace distribution gave on average $0.393$
bits/difference savings. The remaining savings were obtained by additionally
predicting width of this Laplace distribution, also using just the least
squares linear regression.
  For RGB images, optimization of color transform alone gave mean $\approx
4.6\%$ size reduction comparing to standard YCrCb if using fixed transform,
$\approx 6.3\%$ if optimizing transform individually for each image. Then
further mean $\approx 10\%$ reduction was obtained if predicting Laplace
parameters based on context. The presented simple inexpensive general
methodology can be also used for different types of data like DCT coefficients
in lossy image compression.
"
2536,Direct Speech-to-image Translation,"  Direct speech-to-image translation without text is an interesting and useful
topic due to the potential applications in human-computer interaction, art
creation, computer-aided design. etc. Not to mention that many languages have
no writing form. However, as far as we know, it has not been well-studied how
to translate the speech signals into images directly and how well they can be
translated. In this paper, we attempt to translate the speech signals into the
image signals without the transcription stage. Specifically, a speech encoder
is designed to represent the input speech signals as an embedding feature, and
it is trained with a pretrained image encoder using teacher-student learning to
obtain better generalization ability on new classes. Subsequently, a stacked
generative adversarial network is used to synthesize high-quality images
conditioned on the embedding feature. Experimental results on both synthesized
and real data show that our proposed method is effective to translate the raw
speech signals into images without the middle text representation. Ablation
study gives more insights about our method.
"
2537,"From Artificial Neural Networks to Deep Learning for Music Generation --
  History, Concepts and Trends","  The current wave of deep learning (the hyper-vitamined return of artificial
neural networks) applies not only to traditional statistical machine learning
tasks: prediction and classification (e.g., for weather prediction and pattern
recognition), but has already conquered other areas, such as translation. A
growing area of application is the generation of creative content, notably the
case of music, the topic of this paper. The motivation is in using the capacity
of modern deep learning techniques to automatically learn musical styles from
arbitrary musical corpora and then to generate musical samples from the
estimated distribution, with some degree of control over the generation. This
paper provides a tutorial on music generation based on deep learning
techniques. After a short introduction to the topic illustrated by a recent
exemple, the paper analyzes some early works from the late 1980s using
artificial neural networks for music generation and how their pioneering
contributions have prefigured current techniques. Then, we introduce some
conceptual framework to analyze the various concepts and dimensions involved.
Various examples of recent systems are introduced and analyzed to illustrate
the variety of concerns and of techniques.
"
2538,"Music Artist Classification with WaveNet Classifier for Raw Waveform
  Audio Data","  Models for music artist classification usually were operated in the frequency
domain, in which the input audio samples are processed by the spectral
transformation. The WaveNet architecture, originally designed for speech and
music generation. In this paper, we propose an end-to-end architecture in the
time domain for this task. A WaveNet classifier was introduced which directly
models the features from a raw audio waveform. The WaveNet takes the waveform
as the input and several downsampling layers are subsequent to discriminate
which artist the input belongs to. In addition, the proposed method is applied
to singer identification. The model achieving the best performance obtains an
average F1 score of 0.854 on benchmark dataset of Artist20, which is a
significant improvement over the related works. In order to show the
effectiveness of feature learning of the proposed method, the bottleneck layer
of the model is visualized.
"
2539,Stacked Convolutional Deep Encoding Network for Video-Text Retrieval,"  Existing dominant approaches for cross-modal video-text retrieval task are to
learn a joint embedding space to measure the cross-modal similarity. However,
these methods rarely explore long-range dependency inside video frames or
textual words leading to insufficient textual and visual details. In this
paper, we propose a stacked convolutional deep encoding network for video-text
retrieval task, which considers to simultaneously encode long-range and
short-range dependency in the videos and texts. Specifically, a multi-scale
dilated convolutional (MSDC) block within our approach is able to encode
short-range temporal cues between video frames or text words by adopting
different scales of kernel size and dilation size of convolutional layer. A
stacked structure is designed to expand the receptive fields by repeatedly
adopting the MSDC block, which further captures the long-range relations
between these cues. Moreover, to obtain more robust textual representations, we
fully utilize the powerful language model named Transformer in two stages:
pretraining phrase and fine-tuning phrase. Extensive experiments on two
different benchmark datasets (MSR-VTT, MSVD) show that our proposed method
outperforms other state-of-the-art approaches.
"
2540,"Application of Just-Noticeable Difference in Quality as Environment
  Suitability Test for Crowdsourcing Speech Quality Assessment Task","  Crowdsourcing micro-task platforms facilitate subjective media quality
assessment by providing access to a highly scale-able, geographically
distributed and demographically diverse pool of crowd workers. Those workers
participate in the experiment remotely from their own working environment,
using their own hardware. In the case of speech quality assessment, preliminary
work showed that environmental noise at the listener's side and the listening
device (loudspeaker or headphone) significantly affect perceived quality, and
consequently the reliability and validity of subjective ratings. As a
consequence, ITU-T Rec. P.808 specifies requirements for the listening
environment of crowd workers when assessing speech quality. In this paper, we
propose a new Just Noticeable Difference of Quality (JNDQ) test as a remote
screening method for assessing the suitability of the work environment for
participating in speech quality assessment tasks. In a laboratory experiment,
participants performed this JNDQ test with different listening devices in
different listening environments, including a silent room according to ITU-T
Rec. P.800 and a simulated background noise scenario. Results show a
significant impact of the environment and the listening device on the JNDQ
threshold. Thus, the combination of listening device and background noise needs
to be screened in a crowdsourcing speech quality test. We propose a minimum
threshold of our JNDQ test as an easily applicable screening method for this
purpose.
"
2541,Image Co-skeletonization via Co-segmentation,"  Recent advances in the joint processing of images have certainly shown its
advantages over individual processing. Different from the existing works geared
towards co-segmentation or co-localization, in this paper, we explore a new
joint processing topic: image co-skeletonization, which is defined as joint
skeleton extraction of objects in an image collection. Object skeletonization
in a single natural image is a challenging problem because there is hardly any
prior knowledge about the object. Therefore, we resort to the idea of object
co-skeletonization, hoping that the commonness prior that exists across the
images may help, just as it does for other joint processing problems such as
co-segmentation. We observe that the skeleton can provide good scribbles for
segmentation, and skeletonization, in turn, needs good segmentation. Therefore,
we propose a coupled framework for co-skeletonization and co-segmentation tasks
so that they are well informed by each other, and benefit each other
synergistically. Since it is a new problem, we also construct a benchmark
dataset by annotating nearly 1.8k images spread across 38 categories. Extensive
experiments demonstrate that the proposed method achieves promising results in
all the three possible scenarios of joint-processing: weakly-supervised,
supervised, and unsupervised.
"
2542,Delay Sensitivity Classification of Cloud Gaming Content,"  Cloud Gaming is an emerging service that catches growing interest in the
research community as well as industry. While the paradigm shift from a game
execution on clients to streaming games from the cloud offers a variety of
benefits, the new services also require a highly reliable and low latency
network to achieve a satisfying Quality of Experience (QoE) for its users.
Using a cloud gaming service with high latency would harm the interaction of
the user with the game, leading to a decrease in playing performance and thus
frustration of players. However, the negative effect of delay on gaming QoE
depends strongly on the game content. At a certain level of delay, a slow-paced
card game is typically not as delay sensitive as a shooting game. For optimal
resource allocation and quality estimation, it is highly important for cloud
providers, game developers, and network planners to consider the impact of the
game content. This paper contributes to a better understanding of the delay
impact on QoE for cloud gaming applications by identifying game characteristics
influencing the delay perception of users. In addition, an expert evaluation
methodology to quantify these characteristics, as well as a delay sensitivity
classification based on a decision tree is presented. The ratings of 14 experts
for the quantification indicated an excellent level of agreement which
demonstrates the reliability of the proposed method. Additionally, the decision
tree reached an accuracy of 86.6 % on determining the delay sensitivity classes
which were derived from a large dataset of subjective input quality ratings
during a series of experiments.
"
2543,"Blind Quality Assessment for Image Superresolution Using Deep Two-Stream
  Convolutional Networks","  Numerous image superresolution (SR) algorithms have been proposed for
reconstructing high-resolution (HR) images from input images with lower spatial
resolutions. However, effectively evaluating the perceptual quality of SR
images remains a challenging research problem. In this paper, we propose a
no-reference/blind deep neural network-based SR image quality assessor
(DeepSRQ). To learn more discriminative feature representations of various
distorted SR images, the proposed DeepSRQ is a two-stream convolutional network
including two subcomponents for distorted structure and texture SR images.
Different from traditional image distortions, the artifacts of SR images cause
both image structure and texture quality degradation. Therefore, we choose the
two-stream scheme that captures different properties of SR inputs instead of
directly learning features from one image stream. Considering the human visual
system (HVS) characteristics, the structure stream focuses on extracting
features in structural degradations, while the texture stream focuses on the
change in textural distributions. In addition, to augment the training data and
ensure the category balance, we propose a stride-based adaptive cropping
approach for further improvement. Experimental results on three publicly
available SR image quality databases demonstrate the effectiveness and
generalization ability of our proposed DeepSRQ method compared with
state-of-the-art image quality assessment algorithms.
"
2544,"DeepFakes Evolution: Analysis of Facial Regions and Fake Detection
  Performance","  Media forensics has attracted a lot of attention in the last years in part
due to the increasing concerns around DeepFakes. Since the initial DeepFake
databases from the 1st generation such as UADFV and FaceForensics++ up to the
latest databases of the 2nd generation such as Celeb-DF and DFDC, many visual
improvements have been carried out, making fake videos almost indistinguishable
to the human eye. This study provides an exhaustive analysis of both 1st and
2nd DeepFake generations in terms of facial regions and fake detection
performance. Two different methods are considered in our experimental
framework: i) the traditional one followed in the literature and based on
selecting the entire face as input to the fake detection system, and ii) a
novel approach based on the selection of specific facial regions as input to
the fake detection system.
  Among all the findings resulting from our experiments, we highlight the poor
fake detection results achieved even by the strongest state-of-the-art fake
detectors in the latest DeepFake databases of the 2nd generation, with Equal
Error Rate results ranging from 15% to 30%. These results remark the necessity
of further research to develop more sophisticated fake detectors.
"
2545,Video Face Manipulation Detection Through Ensemble of CNNs,"  In the last few years, several techniques for facial manipulation in videos
have been successfully developed and made available to the masses (i.e.,
FaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in
video sequences with incredibly realistic results and a very little effort.
Despite the usefulness of these tools in many fields, if used maliciously, they
can have a significantly bad impact on society (e.g., fake news spreading,
cyber bullying through fake revenge porn). The ability of objectively detecting
whether a face has been manipulated in a video sequence is then a task of
utmost importance. In this paper, we tackle the problem of face manipulation
detection in video sequences targeting modern facial manipulation techniques.
In particular, we study the ensembling of different trained Convolutional
Neural Network (CNN) models. In the proposed solution, different models are
obtained starting from a base network (i.e., EfficientNetB4) making use of two
different concepts: (i) attention layers; (ii) siamese training. We show that
combining these networks leads to promising face manipulation detection results
on two publicly available datasets with more than 119000 videos.
"
2546,On the use of Benford's law to detect GAN-generated images,"  The advent of Generative Adversarial Network (GAN) architectures has given
anyone the ability of generating incredibly realistic synthetic imagery. The
malicious diffusion of GAN-generated images may lead to serious social and
political consequences (e.g., fake news spreading, opinion formation, etc.). It
is therefore important to regulate the widespread distribution of synthetic
imagery by developing solutions able to detect them. In this paper, we study
the possibility of using Benford's law to discriminate GAN-generated images
from natural photographs. Benford's law describes the distribution of the most
significant digit for quantized Discrete Cosine Transform (DCT) coefficients.
Extending and generalizing this property, we show that it is possible to
extract a compact feature vector from an image. This feature vector can be fed
to an extremely simple classifier for GAN-generated image detection purpose.
"
2547,Smartphone camera based pointer,"  Large screen displays are omnipresent today as a part of infrastructure for
presentations and entertainment. Also powerful smartphones with integrated
camera(s) are ubiquitous. However, there are not many ways in which smartphones
and screens can interact besides casting the video from a smartphone. In this
paper, we present a novel idea that turns a smartphone into a direct virtual
pointer on the screen using the phone's camera. The idea and its implementation
are simple, robust, efficient and fun to use. Besides the mathematical concepts
of the idea we accompany the paper with a small javascript project
(www.mobiletvgames.com) which demonstrates the possibility of the new
interaction technique presented as a massive multiplayer game in the HTML5
framework.
"
2548,Fast Soft Color Segmentation,"  We address the problem of soft color segmentation, defined as decomposing a
given image into several RGBA layers, each containing only homogeneous color
regions. The resulting layers from decomposition pave the way for applications
that benefit from layer-based editing, such as recoloring and compositing of
images and videos. The current state-of-the-art approach for this problem is
hindered by slow processing time due to its iterative nature, and consequently
does not scale to certain real-world scenarios. To address this issue, we
propose a neural network based method for this task that decomposes a given
image into multiple layers in a single forward pass. Furthermore, our method
separately decomposes the color layers and the alpha channel layers. By
leveraging a novel training objective, our method achieves proper assignment of
colors amongst layers. As a consequence, our method achieve promising quality
without existing issue of inference speed for iterative approaches. Our
thorough experimental analysis shows that our method produces qualitative and
quantitative results comparable to previous methods while achieving a 300,000x
speed improvement. Finally, we utilize our proposed method on several
applications, and demonstrate its speed advantage, especially in video editing.
"
2549,Music Gesture for Visual Sound Separation,"  Recent deep learning approaches have achieved impressive performance on
visual sound separation tasks. However, these approaches are mostly built on
appearance and optical flow like motion feature representations, which exhibit
limited abilities to find the correlations between audio signals and visual
points, especially when separating multiple instruments of the same types, such
as multiple violins in a scene. To address this, we propose ""Music Gesture,"" a
keypoint-based structured representation to explicitly model the body and
finger movements of musicians when they perform music. We first adopt a
context-aware graph network to integrate visual semantic context with body
dynamics, and then apply an audio-visual fusion model to associate body
movements with the corresponding audio signals. Experimental results on three
music performance datasets show: 1) strong improvements upon benchmark metrics
for hetero-musical separation tasks (i.e. different instruments); 2) new
ability for effective homo-musical separation for piano, flute, and trumpet
duets, which to our best knowledge has never been achieved with alternative
methods. Project page: http://music-gesture.csail.mit.edu.
"
2550,Combining Deep Learning Classifiers for 3D Action Recognition,"  The popular task of 3D human action recognition is almost exclusively solved
by training deep-learning classifiers. To achieve a high recognition accuracy,
the input 3D actions are often pre-processed by various normalization or
augmentation techniques. However, it is not computationally feasible to train a
classifier for each possible variant of training data in order to select the
best-performing subset of pre-processing techniques for a given dataset. In
this paper, we propose to train an independent classifier for each available
pre-processing technique and fuse the classification results based on a strict
majority vote rule. Together with a proposed evaluation procedure, we can very
efficiently determine the best combination of normalization and augmentation
techniques for a specific dataset. For the best-performing combination, we can
retrospectively apply the normalized/augmented variants of input data to train
only a single classifier. This also allows us to decide whether it is better to
train a single model, or rather a set of independent classifiers.
"
2551,MIDI-Sheet Music Alignment Using Bootleg Score Synthesis,"  MIDI-sheet music alignment is the task of finding correspondences between a
MIDI representation of a piece and its corresponding sheet music images. Rather
than using optical music recognition to bridge the gap between sheet music and
MIDI, we explore an alternative approach: projecting the MIDI data into pixel
space and performing alignment in the image domain. Our method converts the
MIDI data into a crude representation of the score that only contains
rectangular floating notehead blobs, a process we call bootleg score synthesis.
Furthermore, we project sheet music images into the same bootleg space by
applying a deep watershed notehead detector and filling in the bounding boxes
around each detected notehead. Finally, we align the bootleg representations
using a simple variant of dynamic time warping. On a dataset of 68 real scanned
piano scores from IMSLP and corresponding MIDI performances, our method
achieves a 97.3% accuracy at an error tolerance of one second, outperforming
several baseline systems that employ optical music recognition.
"
2552,MIDI Passage Retrieval Using Cell Phone Pictures of Sheet Music,"  This paper investigates a cross-modal retrieval problem in which a user would
like to retrieve a passage of music from a MIDI file by taking a cell phone
picture of a physical page of sheet music. While audio-sheet music retrieval
has been explored by a number of works, this scenario is novel in that the
query is a cell phone picture rather than a digital scan. To solve this
problem, we introduce a mid-level feature representation called a bootleg score
which explicitly encodes the rules of Western musical notation. We convert both
the MIDI and the sheet music into bootleg scores using deterministic rules of
music and classical computer vision techniques for detecting simple geometric
shapes. Once the MIDI and cell phone image have been converted into bootleg
scores, we estimate the alignment using dynamic programming. The most notable
characteristic of our system is that it does test-time adaptation and has no
trainable weights at all -- only a set of about 30 hyperparameters. On a
dataset containing 1000 cell phone pictures taken of 100 scores of classical
piano music, our system achieves an F measure score of .869 and outperforms
baseline systems based on commercial optical music recognition software.
"
2553,Towards Linking the Lakh and IMSLP Datasets,"  This paper investigates the problem of matching a MIDI file against a large
database of piano sheet music images. Previous sheet-audio and sheet-MIDI
alignment approaches have primarily focused on a 1-to-1 alignment task, which
is not a scalable solution for retrieval from large databases. We propose a
method for scalable cross-modal retrieval that might be used to link the Lakh
MIDI dataset with IMSLP sheet music data. Our approach is to modify a
previously proposed feature representation called a symbolic bootleg score to
be suitable for hashing. On a database of 5,000 piano scores containing 55,000
individual sheet music images, our system achieves a mean reciprocal rank of
0.84 and an average retrieval time of 25.4 seconds.
"
2554,"Warwick Image Forensics Dataset for Device Fingerprinting In Multimedia
  Forensics","  Device fingerprints like sensor pattern noise (SPN) are widely used for
provenance analysis and image authentication. Over the past few years, the
rapid advancement in digital photography has greatly reshaped the pipeline of
image capturing process on consumer-level mobile devices. The flexibility of
camera parameter settings and the emergence of multi-frame photography
algorithms, especially high dynamic range (HDR) imaging, bring new challenges
to device fingerprinting. The subsequent study on these topics requires a new
purposefully built image dataset. In this paper, we present the Warwick Image
Forensics Dataset, an image dataset of more than 58,600 images captured using
14 digital cameras with various exposure settings. Special attention to the
exposure settings allows the images to be adopted by different multi-frame
computational photography algorithms and for subsequent device fingerprinting.
The dataset is released as an open-source, free for use for the digital
forensic community.
"
2555,Tension Space Analysis for Emergent Narrative,"  Emergent narratives provide a unique and compelling approach to interactive
storytelling through simulation, and have applications in games, narrative
generation, and virtual agents. However the inherent complexity of simulation
makes understanding the expressive potential of emergent narratives difficult,
particularly at the design phase of development. In this paper, we present a
novel approach to emergent narrative using the narratological theory of
possible worlds and demonstrate how the design of works in such a system can be
understood through a formal means of analysis inspired by expressive range
analysis. Lastly, we propose a novel way through which content may be authored
for the emergent narrative system using a sketch-based interface.
"
2556,"Analytic Simplification of Neural Network based Intra-Prediction Modes
  for Video Compression","  With the increasing demand for video content at higher resolutions, it is
evermore critical to find ways to limit the complexity of video encoding tasks
in order to reduce costs, power consumption and environmental impact of video
services. In the last few years, algorithms based on Neural Networks (NN) have
been shown to benefit many conventional video coding modules. But while such
techniques can considerably improve the compression efficiency, they usually
are very computationally intensive. It is highly beneficial to simplify models
learnt by NN so that meaningful insights can be exploited with the goal of
deriving less complex solutions. This paper presents two ways to derive
simplified intra-prediction from learnt models, and shows that these
streamlined techniques can lead to efficient compression solutions.
"
2557,"Towards Real-Time DNN Inference on Mobile Platforms with Model Pruning
  and Compiler Optimization","  High-end mobile platforms rapidly serve as primary computing devices for a
wide range of Deep Neural Network (DNN) applications. However, the constrained
computation and storage resources on these devices still pose significant
challenges for real-time DNN inference executions. To address this problem, we
propose a set of hardware-friendly structured model pruning and compiler
optimization techniques to accelerate DNN executions on mobile devices. This
demo shows that these optimizations can enable real-time mobile execution of
multiple DNN applications, including style transfer, DNN coloring and super
resolution.
"
2558,"Upgrading the Newsroom: An Automated Image Selection System for News
  Articles","  We propose an automated image selection system to assist photo editors in
selecting suitable images for news articles. The system fuses multiple textual
sources extracted from news articles and accepts multilingual inputs. It is
equipped with char-level word embeddings to help both modeling morphologically
rich languages, e.g. German, and transferring knowledge across nearby
languages. The text encoder adopts a hierarchical self-attention mechanism to
attend more to both keywords within a piece of text and informative components
of a news article. We extensively experiment with our system on a large-scale
text-image database containing multimodal multilingual news articles collected
from Swiss local news media websites. The system is compared with multiple
baselines with ablation studies and is shown to beat existing text-image
retrieval methods in a weakly-supervised learning setting. Besides, we also
offer insights on the advantage of using multiple textual sources and
multilingual data.
"
2559,"Transformation of Mean Opinion Scores to Avoid Misleading of Ranked
  based Statistical Techniques","  The rank correlation coefficients and the ranked-based statistical tests (as
a subset of non-parametric techniques) might be misleading when they are
applied to subjectively collected opinion scores. Those techniques assume that
the data is measured at least at an ordinal level and define a sequence of
scores to represent a tied rank when they have precisely an equal numeric
value.
  In this paper, we show that the definition of tied rank, as mentioned above,
is not suitable for Mean Opinion Scores (MOS) and might be misleading
conclusions of rank-based statistical techniques. Furthermore, we introduce a
method to overcome this issue by transforming the MOS values considering their
$95\%$ Confidence Intervals. The rank correlation coefficients and ranked-based
statistical tests can then be safely applied to the transformed values. We also
provide open-source software packages in different programming languages to
utilize the application of our transformation method in the quality of
experience domain.
"
2560,Reinforcing Short-Length Hashing,"  Due to the compelling efficiency in retrieval and storage,
similarity-preserving hashing has been widely applied to approximate nearest
neighbor search in large-scale image retrieval. However, existing methods have
poor performance in retrieval using an extremely short-length hash code due to
weak ability of classification and poor distribution of hash bit. To address
this issue, in this study, we propose a novel reinforcing short-length hashing
(RSLH). In this proposed RSLH, mutual reconstruction between the hash
representation and semantic labels is performed to preserve the semantic
information. Furthermore, to enhance the accuracy of hash representation, a
pairwise similarity matrix is designed to make a balance between accuracy and
training expenditure on memory. In addition, a parameter boosting strategy is
integrated to reinforce the precision with hash bits fusion. Extensive
experiments on three large-scale image benchmarks demonstrate the superior
performance of RSLH under various short-length hashing scenarios.
"
2561,Survey on Visual Sentiment Analysis,"  Visual Sentiment Analysis aims to understand how images affect people, in
terms of evoked emotions. Although this field is rather new, a broad range of
techniques have been developed for various data sources and problems, resulting
in a large body of research. This paper reviews pertinent publications and
tries to present an exhaustive overview of the field. After a description of
the task and the related applications, the subject is tackled under different
main headings. The paper also describes principles of design of general Visual
Sentiment Analysis systems from three main points of view: emotional models,
dataset definition, feature design. A formalization of the problem is
discussed, considering different levels of granularity, as well as the
components that can affect the sentiment toward an image in different ways. To
this aim, this paper considers a structured formalization of the problem which
is usually used for the analysis of text, and discusses it's suitability in the
context of Visual Sentiment Analysis. The paper also includes a description of
new challenges, the evaluation from the viewpoint of progress toward more
sophisticated systems and related practical applications, as well as a summary
of the insights resulting from this study.
"
2562,Using Cell Phone Pictures of Sheet Music To Retrieve MIDI Passages,"  This article investigates a cross-modal retrieval problem in which a user
would like to retrieve a passage of music from a MIDI file by taking a cell
phone picture of several lines of sheet music. This problem is challenging for
two reasons: it has a significant runtime constraint since it is a user-facing
application, and there is very little relevant training data containing cell
phone images of sheet music. To solve this problem, we introduce a novel
feature representation called a bootleg score which encodes the position of
noteheads relative to staff lines in sheet music. The MIDI representation can
be converted into a bootleg score using deterministic rules of Western musical
notation, and the sheet music image can be converted into a bootleg score using
classical computer vision techniques for detecting simple geometrical shapes.
Once the MIDI and cell phone image have been converted into bootleg scores, we
can estimate the alignment using dynamic programming. The most notable
characteristic of our system is that it has no trainable weights at all -- only
a set of about 40 hyperparameters. With a training set of just 400 images, we
show that our system generalizes well to a much larger set of 1600 test images
from 160 unseen musical scores. Our system achieves a test F measure score of
0.89, has an average runtime of 0.90 seconds, and outperforms baseline systems
based on music object detection and sheet-audio alignment. We provide extensive
experimental validation and analysis of our system.
"
2563,"Analysis of Social Media Data using Multimodal Deep Learning for
  Disaster Response","  Multimedia content in social media platforms provides significant information
during disaster events. The types of information shared include reports of
injured or deceased people, infrastructure damage, and missing or found people,
among others. Although many studies have shown the usefulness of both text and
image content for disaster response purposes, the research has been mostly
focused on analyzing only the text modality in the past. In this paper, we
propose to use both text and image modalities of social media data to learn a
joint representation using state-of-the-art deep learning techniques.
Specifically, we utilize convolutional neural networks to define a multimodal
deep learning architecture with a modality-agnostic shared representation.
Extensive experiments on real-world disaster datasets show that the proposed
multimodal architecture yields better performance than models trained using a
single modality (e.g., either text or image).
"
2564,"Improving embedding efficiency for digital steganography by exploiting
  similarities between secret and cover images","  Digital steganography is becoming a common tool for protecting sensitive
communications in various applications such as crime(terrorism) prevention
whereby law enforcing personals need to remotely compare facial images captured
at the scene of crime with faces databases of known criminals(suspects);
exchanging military maps or surveillance video in hostile
environment(situations); privacy preserving in the healthcare systems when
storing or exchanging patient medical images(records); and prevent bank
customers accounts(records) from being accessed illegally by unauthorized
users. Existing digital steganography schemes for embedding secret images in
cover image files tend not to exploit various redundancies in the secret image
bit-stream to deal with the various conflicting requirements on embedding
capacity, stego-image quality, and un-detectibility. This paper is concerned
with the development of innovative image procedures and data hiding schemes
that exploit, as well as increase, similarities between secret image bit-stream
and the cover image LSB plane. This will be achieved in two novel steps
involving manipulating both the secret and the cover images,prior to embedding,
to achieve higher 0:1 ratio in both the secret image bit-stream and the cover
image LSB plane. The above two steps strategy has been exploited to use a
bit-plane(s) mapping technique, instead of bit-plane(s) replacement to make
each cover pixel usable for secret embedding. This paper will demonstrate that
this strategy produces stego-images that have minimal distortion, high
embedding efficiency, reasonably good stego-image quality and robustness
against 3 well-known targeted steganalysis tools.
"
2565,Steganography Based on Pixel Intensity Value Decomposition,"  This paper focuses on steganography based on pixel intensity value
decomposition. A number of existing schemes such as binary, Fibonacci, Prime,
Natural, Lucas, and Catalan-Fibonacci (CF) are evaluated in terms of payload
capacity and stego quality. A new technique based on a specific representation
is used to decompose pixel intensity values into 16 (virtual) bit-planes
suitable for embedding purposes. The new decomposition scheme has a desirable
property whereby the sum of all bit-planes does not exceed the maximum pixel
intensity value, i.e. 255. Experimental results demonstrate that the new
decomposition scheme offers a better compromise between payload capacity and
stego quality than other existing decomposition schemes used for embedding
messages. However, embedding in the 6th bit-plane onwards, the proposed scheme
offers better stego quality. In general, the new decomposition technique has
less effect in terms of quality on pixel value when compared to most existing
pixel intensity value decomposition techniques when embedding messages in
higher bit-planes.
"
2566,Efficient High Capacity Steganography Technique,"  Performance indicators characterizing modern steganographic techniques
include capacity (i.e. the quantity of data that can be hidden in the cover
medium), stego quality (i.e. artifacts visibility), security (i.e.
undetectability), and strength or robustness (intended as the resistance
against active attacks aimed to destroy the secret message). Fibonacci based
embedding techniques have been researched and proposed in the literature to
achieve efficient steganography in terms of capacity with respect to stego
quality. In this paper, we investigated an innovative idea that extends
Fibonacci-like steganography by bit-plane(s) mapping instead of bit-plane(s)
replacement. Our proposed algorithm increases embedding capacity using
bit-plane mapping to embed two bits of the secret message in three bits of a
pixel of the cover, at the expense of a marginal loss in stego quality. While
existing Fibonacci embedding algorithms do not use certain intensities of the
cover for embedding due to the limitation imposed by the Zeckendorf theorem,
our proposal solve this problem and make all intensity values candidates for
embedding. Experimental results demonstrate that the proposed technique double
the embedding capacity when compared to existing Fibonacci methods, and it is
secure against statistical attacks such as RS, POV, and difference image
histogram (DIH).
"
2567,"Bharatanatyam Dance Transcription using Multimedia Ontology and Machine
  Learning","  Indian Classical Dance is an over 5000 years' old multi-modal language for
expressing emotions. Preservation of dance through multimedia technology is a
challenging task. In this paper, we develop a system to generate a parseable
representation of a dance performance. The system will help to preserve
intangible heritage, annotate performances for better tutoring, and synthesize
dance performances. We first attempt to capture the concepts of the basic steps
of an Indian Classical Dance form, named Bharatanatyam Adavus, in an
ontological model. Next, we build an event-based low-level model that relates
the ontology of Adavus to the ontology of multi-modal data streams (RGB-D of
Kinect in this case) for a computationally realizable framework. Finally, the
ontology is used for transcription into Labanotation. We also present a
transcription tool for encoding the performances of Bharatanatyam Adavus to
Labanotation and test it on our recorded data set. Our primary aim is to
document the complex movements of dance in terms of Labanotation using the
ontology.
"
2568,"Fuzzy Logic Based Integration of Web Contextual Linguistic Structures
  for Enriching Conceptual Visual Representations","  Due to the difficulty of automatically mapping visual features with semantic
descriptors, state-of-the-art frameworks have exhibited poor performance in
terms of coverage and effectiveness for indexing the visual content. This
prompted us to investigate the use of both the Web as a large information
source from where to extract relevant contextual linguistic information and
bimodal visual-textual indexing as a technique to enrich the vocabulary of
index concepts. Our proposal is based on the Signal/Semantic approach for
multimedia indexing which generates multi-facetted conceptual representations
of the visual content. We propose to enrich these image representations with
concepts automatically extracted from the visual contextual information. We
specifically target the integration of semantic concepts which are more
specific than the initial index concepts since they represent the visual
content with greater accuracy and precision. Also, we aim to correct the faulty
indexes resulting from the automatic semantic tagging. Experimentally, the
details of the prototyping are given and the presented technique is tested in a
Web-scale evaluation on 30 queries representing elaborate image scenes.
"
2569,"SAIA: Split Artificial Intelligence Architecture for Mobile Healthcare
  System","  As the advancement of deep learning (DL), the Internet of Things and cloud
computing techniques for biomedical and healthcare problems, mobile healthcare
systems have received unprecedented attention. Since DL techniques usually
require enormous amount of computation, most of them cannot be directly
deployed on the resource-constrained mobile and IoT devices. Hence, most of the
mobile healthcare systems leverage the cloud computing infrastructure, where
the data collected by the mobile and IoT devices would be transmitted to the
cloud computing platforms for analysis. However, in the contested environments,
relying on the cloud might not be practical at all times. For instance, the
satellite communication might be denied or disrupted. We propose SAIA, a Split
Artificial Intelligence Architecture for mobile healthcare systems. Unlike
traditional approaches for artificial intelligence (AI) which solely exploits
the computational power of the cloud server, SAIA could not only relies on the
cloud computing infrastructure while the wireless communication is available,
but also utilizes the lightweight AI solutions that work locally on the client
side, hence, it can work even when the communication is impeded. In SAIA, we
propose a meta-information based decision unit, that could tune whether a
sample captured by the client should be operated by the embedded AI (i.e.,
keeping on the client) or the networked AI (i.e., sending to the server), under
different conditions. In our experimental evaluation, extensive experiments
have been conducted on two popular healthcare datasets. Our results show that
SAIA consistently outperforms its baselines in terms of both effectiveness and
efficiency.
"
2570,"Randomized Nested Polar Subcode Constructions for Privacy, Secrecy, and
  Storage","  We consider polar subcodes (PSCs), which are polar codes (PCs) with
dynamically-frozen symbols, to increase the minimum distance as compared to
corresponding PCs. A randomized nested PSC construction with a low-rate PSC and
a high-rate PC, is proposed for list and sequential successive cancellation
decoders. This code construction aims to perform lossy compression with side
information. Nested PSCs are used in the key agreement problem with physical
identifiers. Gains in terms of the secret-key vs. storage rate ratio as
compared to nested PCs with the same list size are illustrated to show that
nested PSCs significantly improve on nested PCs. The performance of the nested
PSCs is shown to improve with larger list sizes, which is not the case for
nested PCs considered.
"
2571,"Stego Quality Enhancement by Message Size Reduction and Fibonacci
  Bit-Plane Mapping","  An efficient 2-step steganography technique is proposed to enhance stego
image quality and secret message un-detectability. The first step is a
preprocessing algorithm that reduces the size of secret images without losing
information. This results in improved stego image quality compared to other
existing image steganography methods. The proposed secret image size reduction
(SISR) algorithm is an efficient spatial domain technique. The second step is
an embedding mechanism that relies on Fibonacci representation of pixel
intensities to minimize the effect of embedding on the stego image quality. The
improvement is attained by using bit-plane(s) mapping instead of bit-plane(s)
replacement for embedding. The proposed embedding mechanism outperforms the
binary based LSB randomly embedding in two ways: reduced effect on stego
quality and increased robustness against statistical steganalysers.
Experimental results demonstrate the benefits of the proposed scheme in terms
of: 1) SISR ratio (indirectly results in increased capacity); 2) quality of the
stego; and 3) robustness against steganalysers such as RS, and WS. Furthermore,
experimental results show that the proposed SISR algorithm can be extended to
be applicable on DICOM standard medical images. Future security standardization
research is proposed that would focus on evaluating the security, performance,
and effectiveness of steganography algorithms.
"
2572,Secure Steganography Technique Based on Bitplane Indexes,"  This paper is concerned with secret hiding in multiple image bitplanes for
increased security without undermining capacity. A secure steganographic
algorithm based on bitplanes index manipulation is proposed. The index
manipulation is confined to the first two Least Significant Bits of the cover
image. The proposed algorithm has the property of un-detectability with respect
to stego quality and payload capacity. Experimental results demonstrate that
the proposed technique is secure against statistical attacks such as pair of
value (PoV), Weighted Stego steganalyser (WS), and Multi Bitplane Weighted
Stego steganalyser (MLSB-WS).
"
2573,DWT-GBT-SVD-based Robust Speech Steganography,"  Steganography is a method that can improve network security and make
communications safer. In this method, a secret message is hidden in content
like audio signals that should not be perceptible by listening to the audio or
seeing the signal waves. Also, it should be robust against different common
attacks such as noise and compression. In this paper, we propose a new speech
steganography method based on a combination of Discrete Wavelet Transform,
Graph-based Transform, and Singular Value Decomposition (SVD). In this method,
we first find voiced frames based on energy and zero-crossing counts of the
frames and then embed a binary message into voiced frames. Experimental results
on the NOIZEUS database show that the proposed method is imperceptible and also
robust against Gaussian noise, re-sampling, re-quantization, high pass filter,
and low pass filter. Also, it is robust against MP3 compression and scaling for
watermarking applications.
"
2574,Maximum Density Divergence for Domain Adaptation,"  Unsupervised domain adaptation addresses the problem of transferring
knowledge from a well-labeled source domain to an unlabeled target domain where
the two domains have distinctive data distributions. Thus, the essence of
domain adaptation is to mitigate the distribution divergence between the two
domains. The state-of-the-art methods practice this very idea by either
conducting adversarial training or minimizing a metric which defines the
distribution gaps. In this paper, we propose a new domain adaptation method
named Adversarial Tight Match (ATM) which enjoys the benefits of both
adversarial training and metric learning. Specifically, at first, we propose a
novel distance loss, named Maximum Density Divergence (MDD), to quantify the
distribution divergence. MDD minimizes the inter-domain divergence (""match"" in
ATM) and maximizes the intra-class density (""tight"" in ATM). Then, to address
the equilibrium challenge issue in adversarial domain adaptation, we consider
leveraging the proposed MDD into adversarial domain adaptation framework. At
last, we tailor the proposed MDD as a practical learning loss and report our
ATM. Both empirical evaluation and theoretical analysis are reported to verify
the effectiveness of the proposed method. The experimental results on four
benchmarks, both classical and large-scale, show that our method is able to
achieve new state-of-the-art performance on most evaluations. Codes and
datasets used in this paper are available at {\it github.com/lijin118/ATM}.
"
2575,"Influence of Hand Tracking as a way of Interaction in Virtual Reality on
  User Experience","  With the rising interest in Virtual Reality and the fast development and
improvement of available devices, new features of interactions are becoming
available. One of them that is becoming very popular is hand tracking, as the
idea to replace controllers for interactions in virtual worlds. This experiment
aims to compare different interaction types in VR using either controllers or
hand tracking. Participants had to play two simple VR games with various types
of tasks in those games - grabbing objects or typing numbers. While playing,
they were using interactions with different visualizations of hands and
controllers. The focus of this study was to investigate user experience of
varying interactions (controller vs. hand tracking) for those two simple tasks.
Results show that different interaction types statistically significantly
influence reported emotions with Self-Assessment Manikin (SAM), where for hand
tracking participants were feeling higher valence, but lower arousal and
dominance. Additionally, task type of grabbing was reported to be more
realistic, and participants experienced a higher presence. Surprisingly,
participants rated the interaction type with controllers where both where hands
and controllers were visualized as statistically most preferred. Finally, hand
tracking for both tasks was rated with the System Usability Scale (SUS) scale,
and hand tracking for the task typing was rated as statistically significantly
more usable. These results can drive further research and, in the long term,
contribute to help selecting the most matching interaction modality for a task.
"
2576,"Unsupervised Real Image Super-Resolution via Generative Variational
  AutoEncoder","  Benefited from the deep learning, image Super-Resolution has been one of the
most developing research fields in computer vision. Depending upon whether
using a discriminator or not, a deep convolutional neural network can provide
an image with high fidelity or better perceptual quality. Due to the lack of
ground truth images in real life, people prefer a photo-realistic image with
low fidelity to a blurry image with high fidelity. In this paper, we revisit
the classic example based image super-resolution approaches and come up with a
novel generative model for perceptual image super-resolution. Given that real
images contain various noise and artifacts, we propose a joint image denoising
and super-resolution model via Variational AutoEncoder. We come up with a
conditional variational autoencoder to encode the reference for dense feature
vector which can then be transferred to the decoder for target image denoising.
With the aid of the discriminator, an additional overhead of super-resolution
subnetwork is attached to super-resolve the denoised image with photo-realistic
visual quality. We participated the NTIRE2020 Real Image Super-Resolution
Challenge. Experimental results show that by using the proposed approach, we
can obtain enlarged images with clean and pleasant features compared to other
supervised methods. We also compared our approach with state-of-the-art methods
on various datasets to demonstrate the efficiency of our proposed unsupervised
super-resolution model.
"
2577,"Nested Tailbiting Convolutional Codes for Secrecy, Privacy, and Storage","  A key agreement problem is considered that has a biometric or physical
identifier, a terminal for key enrollment, and a terminal for reconstruction. A
nested convolutional code design is proposed that performs vector quantization
during enrollment and error control during reconstruction. Physical identifiers
with small bit error probability illustrate the gains of the design. One
variant of the nested convolutional codes improves on the best known key vs.
storage rate ratio but it has high complexity. A second variant with lower
complexity performs similar to nested polar codes. The results suggest that the
choice of code for key agreement with identifiers depends primarily on the
complexity constraint.
"
2578,"Exploring the Contextual Dynamics of Multimodal Emotion Recognition in
  Videos","  Emotional expressions form a key part of user behavior on today's digital
platforms. While multimodal emotion recognition techniques are gaining research
attention, there is a lack of deeper understanding on how visual and non-visual
features can be used in better recognizing emotions for certain contexts, but
not others. This study analyzes the interplay between the effects of multimodal
emotion features derived from facial expressions, tone and text in conjunction
with two key contextual factors: 1) the gender of the speaker, and 2) the
duration of the emotional episode. Using a large dataset of more than 2500
manually annotated videos from YouTube, we found that while multimodal features
consistently outperformed bimodal and unimodal features, their performances
varied significantly for different emotions, gender and duration contexts.
Multimodal features were found to perform particularly better for male than
female speakers in recognizing most emotions except for fear. Furthermore,
multimodal features performed particularly better for shorter than for longer
videos in recognizing neutral, happiness, and surprise, but not sadness, anger,
disgust and fear. These findings offer new insights towards the development of
more context-aware emotion recognition and empathetic systems.
"
2579,"Assessing differences in flow state induced by an adaptive music
  learning software","  Technology can facilitate self-learning for academic and leisure activities
such as music learning. In general, learning to play an unknown musical song at
sight on the electric piano or any other instrument can be quite a chore. In a
traditional self-learning setting, the musician only gets feedback in terms of
what errors they can hear themselves by comparing what they have played with
the score. Research has shown that reaching a flow state creates a more
enjoyable experience during activities. This work explores whether principles
from flow theory and game design can be applied to make the beginner's musical
experience adapted to their need and create higher flow. We created and
evaluated a tool oriented around these considerations in a study with 21
participants. We found that provided feedback and difficulty scaling can help
to achieve flow and that the effects get more pronounced the more experience
with music participants have. In further research, we want to examine the
influence of our approach to learning sheet music.
"
2580,"SSIM-Based CTU-Level Joint Optimal Bit Allocation and Rate Distortion
  Optimization","  Structural similarity (SSIM)-based distortion $D_\text{SSIM}$ is more
consistent with human perception than the traditional mean squared error
$D_\text{MSE}$. To achieve better video quality, many studies on optimal bit
allocation (OBA) and rate-distortion optimization (RDO) used $D_\text{SSIM}$ as
the distortion metric. However, many of them failed to optimize OBA and RDO
jointly based on SSIM, thus causing a non-optimal R-$D_\text{SSIM}$
performance. This problem is due to the lack of an accurate R-$D_\text{SSIM}$
model that can be used uniformly in both OBA and RDO. To solve this problem, we
propose a $D_\text{SSIM}$-$D_\text{MSE}$ model first. Based on this model, the
complex R-$D_\text{SSIM}$ cost in RDO can be calculated as simpler
R-$D_\text{MSE}$ cost with a new SSIM-related Lagrange multiplier. This not
only reduces the computation burden of SSIM-based RDO, but also enables the
R-$D_\text{SSIM}$ model to be uniformly used in OBA and RDO. Moreover, with the
new SSIM-related Lagrange multiplier in hand, the joint relationship of
R-$D_\text{SSIM}$-$\lambda_\text{SSIM}$ (the negative derivative of
R-$D_\text{SSIM}$) can be built, based on which the R-$D_\text{SSIM}$ model
parameters can be calculated accurately. With accurate and unified
R-$D_\text{SSIM}$ model, SSIM-based OBA and SSIM-based RDO are unified together
in our scheme, called SOSR. Compared with the HEVC reference encoder HM16.20,
SOSR saves 4%, 10%, and 14% bitrate under the same SSIM in all-intra,
hierarchical and non-hierarchical low-delay-B configurations, which is superior
to other state-of-the-art schemes.
"
2581,Detecting Deep-Fake Videos from Appearance and Behavior,"  Synthetically-generated audios and videos -- so-called deep fakes -- continue
to capture the imagination of the computer-graphics and computer-vision
communities. At the same time, the democratization of access to technology that
can create sophisticated manipulated video of anybody saying anything continues
to be of concern because of its power to disrupt democratic elections, commit
small to large-scale fraud, fuel dis-information campaigns, and create
non-consensual pornography. We describe a biometric-based forensic technique
for detecting face-swap deep fakes. This technique combines a static biometric
based on facial recognition with a temporal, behavioral biometric based on
facial expressions and head movements, where the behavioral embedding is
learned using a CNN with a metric-learning objective function. We show the
efficacy of this approach across several large-scale video datasets, as well as
in-the-wild deep fakes.
"
2582,"MuSe 2020 -- The First International Multimodal Sentiment Analysis in
  Real-life Media Challenge and Workshop","  Multimodal Sentiment Analysis in Real-life Media (MuSe) 2020 is a
Challenge-based Workshop focusing on the tasks of sentiment recognition, as
well as emotion-target engagement and trustworthiness detection by means of
more comprehensively integrating the audio-visual and language modalities. The
purpose of MuSe 2020 is to bring together communities from different
disciplines; mainly, the audio-visual emotion recognition community
(signal-based), and the sentiment analysis community (symbol-based). We present
three distinct sub-challenges: MuSe-Wild, which focuses on continuous emotion
(arousal and valence) prediction; MuSe-Topic, in which participants recognise
domain-specific topics as the target of 3-class (low, medium, high) emotions;
and MuSe-Trust, in which the novel aspect of trustworthiness is to be
predicted. In this paper, we provide detailed information on MuSe-CaR, the
first of its kind in-the-wild database, which is utilised for the challenge, as
well as the state-of-the-art features and modelling approaches applied. For
each sub-challenge, a competitive baseline for participants is set; namely, on
test we report for MuSe-Wild a combined (valence and arousal) CCC of .2568, for
MuSe-Topic a score (computed as 0.34$\cdot$ UAR + 0.66$\cdot$F1) of 76.78 % on
the 10-class topic and 40.64 % on the 3-class emotion prediction, and for
MuSe-Trust a CCC of .4359.
"
2583,"Towards Deep Learning Methods for Quality Assessment of
  Computer-Generated Imagery","  Video gaming streaming services are growing rapidly due to new services such
as passive video streaming, e.g. Twitch.tv, and cloud gaming, e.g. Nvidia
Geforce Now. In contrast to traditional video content, gaming content has
special characteristics such as extremely high motion for some games, special
motion patterns, synthetic content and repetitive content, which makes the
state-of-the-art video and image quality metrics perform weaker for this
special computer generated content. In this paper, we outline our plan to build
a deep learningbased quality metric for video gaming quality assessment. In
addition, we present initial results by training the network based on VMAF
values as a ground truth to give some insights on how to build a metric in
future. The paper describes the method that is used to choose an appropriate
Convolutional Neural Network architecture. Furthermore, we estimate the size of
the required subjective quality dataset which achieves a sufficiently high
performance. The results show that by taking around 5k images for training of
the last six modules of Xception, we can obtain a relatively high performance
metric to assess the quality of distorted video games.
"
2584,Quadtree Driven Lossy Event Compression,"  Event cameras are emerging bio-inspired sensors that offer salient benefits
over traditional cameras. With high speed, high dynamic range, and low power
consumption, event cameras have been increasingly employed to solve existing as
well as novel visual and robotics tasks. Despite rapid advancement in
event-based vision, event data compression is facing growing demand, yet
remains elusively challenging and not effectively addressed. The major
challenge is the unique data form, \emph{i.e.}, a stream of four-attribute
events, encoding the spatial locations and the timestamp of each event, with a
polarity representing the brightness increase/decrease. While events encode
temporal variations at high speed, they omit rich spatial information, which is
critical for image/video compression. In this paper, we perform lossy event
compression (LEC) based on a quadtree (QT) segmentation map derived from an
adjacent image. The QT structure provides a priority map for the 3D space-time
volume, albeit in a 2D manner. LEC is performed by first quantizing the events
over time, and then variably compressing the events within each QT block via
Poisson Disk Sampling in 2D space for each quantized time. Our QT-LEC has
flexibility in accordance with the bit-rate requirement. Experimentally, we
show results with state-of-the-art coding performance. We further evaluate the
performance in event-based applications such as image reconstruction and corner
detection.
"
2585,"II-20: Intelligent and pragmatic analytic categorization of image
  collections","  We introduce II-20 (Image Insight 2020), a multimedia analytics approach for
analytic categorization of image collections. Advanced visualizations for image
collections exist, but they need tight integration with a machine model to
support analytic categorization. Directly employing computer vision and
interactive learning techniques gravitates towards search. Analytic
categorization, however, is not machine classification (the difference between
the two is called the pragmatic gap): a human adds/redefines/deletes categories
of relevance on the fly to build insight, whereas the machine classifier is
rigid and non-adaptive. Analytic categorization that brings the user to insight
requires a flexible machine model that allows dynamic sliding on the
exploration-search axis, as well as semantic interactions. II-20 brings 3 major
contributions to multimedia analytics on image collections and towards closing
the pragmatic gap. Firstly, a machine model that closely follows the user's
interactions and dynamically models her categories of relevance. II-20's model,
in addition to matching and exceeding the state of the art w. r. t. relevance,
allows the user to dynamically slide on the exploration-search axis without
additional input from her side. Secondly, the dynamic, 1-image-at-a-time Tetris
metaphor that synergizes with the model. It allows the model to analyze the
collection by itself with minimal interaction from the user and complements the
classic grid metaphor. Thirdly, the fast-forward interaction, allowing the user
to harness the model to quickly expand (""fast-forward"") the categories of
relevance, expands the multimedia analytics semantic interaction dictionary.
Automated experiments show that II-20's model outperforms the state of the art
and also demonstrate Tetris's analytic quality. User studies confirm that II-20
is an intuitive, efficient, and effective multimedia analytics tool.
"
2586,"PyRetri: A PyTorch-based Library for Unsupervised Image Retrieval by
  Deep Convolutional Neural Networks","  Despite significant progress of applying deep learning methods to the field
of content-based image retrieval, there has not been a software library that
covers these methods in a unified manner. In order to fill this gap, we
introduce PyRetri, an open source library for deep learning based unsupervised
image retrieval. The library encapsulates the retrieval process in several
stages and provides functionality that covers various prominent methods for
each stage. The idea underlying its design is to provide a unified platform for
deep learning based image retrieval research, with high usability and
extensibility. To the best of our knowledge, this is the first open-source
library for unsupervised image retrieval by deep learning.
"
2587,Cross-media Structured Common Space for Multimedia Event Extraction,"  We introduce a new task, MultiMedia Event Extraction (M2E2), which aims to
extract events and their arguments from multimedia documents. We develop the
first benchmark and collect a dataset of 245 multimedia news articles with
extensively annotated events and arguments. We propose a novel method, Weakly
Aligned Structured Embedding (WASE), that encodes structured representations of
semantic information from textual and visual data into a common embedding
space. The structures are aligned across modalities by employing a weakly
supervised training strategy, which enables exploiting available resources
without explicit cross-media annotation. Compared to uni-modal state-of-the-art
methods, our approach achieves 4.0% and 9.8% absolute F-score gains on text
event argument role labeling and visual event extraction. Compared to
state-of-the-art multimedia unstructured representations, we achieve 8.3% and
5.0% absolute F-score gains on multimedia event extraction and argument role
labeling, respectively. By utilizing images, we extract 21.4% more event
mentions than traditional text-only methods.
"
2588,Multi-view data capture using edge-synchronised mobiles,"  Multi-view data capture permits free-viewpoint video (FVV) content creation.
To this end, several users must capture video streams, calibrated in both time
and pose, framing the same object/scene, from different viewpoints.
New-generation network architectures (e.g. 5G) promise lower latency and larger
bandwidth connections supported by powerful edge computing, properties that
seem ideal for reliable FVV capture. We have explored this possibility, aiming
to remove the need for bespoke synchronisation hardware when capturing a scene
from multiple viewpoints, making it possible through off-the-shelf mobiles. We
propose a novel and scalable data capture architecture that exploits edge
resources to synchronise and harvest frame captures. We have designed an edge
computing unit that supervises the relaying of timing triggers to and from
multiple mobiles, in addition to synchronising frame harvesting. We empirically
show the benefits of our edge computing unit by analysing latencies and show
the quality of 3D reconstruction outputs against an alternative and popular
centralised solution based on Unity3D.
"
2589,Knowledge Enhanced Neural Fashion Trend Forecasting,"  Fashion trend forecasting is a crucial task for both academia and industry.
Although some efforts have been devoted to tackling this challenging task, they
only studied limited fashion elements with highly seasonal or simple patterns,
which could hardly reveal the real fashion trends. Towards insightful fashion
trend forecasting, this work focuses on investigating fine-grained fashion
element trends for specific user groups. We first contribute a large-scale
fashion trend dataset (FIT) collected from Instagram with extracted time series
fashion element records and user information. Further-more, to effectively
model the time series data of fashion elements with rather complex patterns, we
propose a Knowledge EnhancedRecurrent Network model (KERN) which takes
advantage of the capability of deep recurrent neural networks in modeling
time-series data. Moreover, it leverages internal and external knowledge in
fashion domain that affects the time-series patterns of fashion element trends.
Such incorporation of domain knowledge further enhances the deep learning model
in capturing the patterns of specific fashion elements and predicting the
future trends. Extensive experiments demonstrate that the proposed KERN model
can effectively capture the complicated patterns of objective fashion elements,
therefore making preferable fashion trend forecast.
"
2590,"Interval type-2 fuzzy logic system based similarity evaluation for image
  steganography","  Similarity measure, also called information measure, is a concept used to
distinguish different objects. It has been studied from different contexts by
employing mathematical, psychological, and fuzzy approaches. Image
steganography is the art of hiding secret data into an image in such a way that
it cannot be detected by an intruder. In image steganography, hiding secret
data in the plain or non-edge regions of the image is significant due to the
high similarity and redundancy of the pixels in their neighborhood. However,
the similarity measure of the neighboring pixels, i.e., their proximity in
color space, is perceptual rather than mathematical. This paper proposes an
interval type 2 fuzzy logic system (IT2 FLS) to determine the similarity
between the neighboring pixels by involving an instinctive human perception
through a rule-based approach. The pixels of the image having high similarity
values, calculated using the proposed IT2 FLS similarity measure, are selected
for embedding via the least significant bit (LSB) method. We term the proposed
procedure of steganography as IT2 FLS LSB method. Moreover, we have developed
two more methods, namely, type 1 fuzzy logic system based least significant
bits (T1FLS LSB) and Euclidean distance based similarity measures for least
significant bit (SM LSB) steganographic methods. Experimental simulations were
conducted for a collection of images and quality index metrics, such as PSNR,
UQI, and SSIM are used. All the three steganographic methods are applied on
datasets and the quality metrics are calculated. The obtained stego images and
results are shown and thoroughly compared to determine the efficacy of the IT2
FLS LSB method. Finally, we have done a comparative analysis of the proposed
approach with the existing well-known steganographic methods to show the
effectiveness of our proposed steganographic method.
"
2591,Accessibility in 360-degree video players,"  Any media experience must be fully inclusive and accessible to all users
regardless of their ability. With the current trend towards immersive
experiences, such as Virtual Reality (VR) and 360-degree video, it becomes key
that these environments are adapted to be fully accessible. However, until
recently the focus has been mostly on adapting the existing techniques to fit
immersive displays, rather than considering new approaches for accessibility
designed specifically for these increasingly relevant media experiences. This
paper surveys a wide range of 360-degree video players and examines the
features they include for dealing with accessibility, such as Subtitles, Audio
Description, Sign Language, User Interfaces, and other interaction features,
like voice control and support for multi-screen scenarios. These features have
been chosen based on guidelines from standardization contributions, like in the
World Wide Web Consortium (W3C) and the International Communication Union
(ITU), and from research contributions for making 360-degree video consumption
experiences accessible. The in-depth analysis has been part of a research
effort towards the development of a fully inclusive and accessible 360-degree
video player. The paper concludes by discussing how the newly developed player
has gone above and beyond the existing solutions and guidelines, by providing
accessibility features that meet the expectations for a widely used immersive
medium, like 360-degree video.
"
2592,White Paper: Recommendations for immersive accessibility services,"  This paper provides recommendations on how to integrate accessibility
solutions, like subtitling, audio description and sign language, with immersive
media services, with a focus on 360-degree video and spatial audio. It provides
an in-depth analysis of the features provided by state-of-the-art standard
solutions to achieve this goal, and elaborates on the finding and proposed
solutions from the EU H2020 ImAc project to address existing gaps. The proposed
solutions are described qualitatively and technically, including example
implementations. The document is intended to serve as a valuable information
source for early adopters who plan to provide accessibility services to their
portfolio with standard-compliant solutions.
"
2593,"An Extensive Study on Cross-Dataset Bias and Evaluation Metrics
  Interpretation for Machine Learning applied to Gastrointestinal Tract
  Abnormality Classification","  Precise and efficient automated identification of Gastrointestinal (GI) tract
diseases can help doctors treat more patients and improve the rate of disease
detection and identification. Currently, automatic analysis of diseases in the
GI tract is a hot topic in both computer science and medical-related journals.
Nevertheless, the evaluation of such an automatic analysis is often incomplete
or simply wrong. Algorithms are often only tested on small and biased datasets,
and cross-dataset evaluations are rarely performed. A clear understanding of
evaluation metrics and machine learning models with cross datasets is crucial
to bring research in the field to a new quality level. Towards this goal, we
present comprehensive evaluations of five distinct machine learning models
using Global Features and Deep Neural Networks that can classify 16 different
key types of GI tract conditions, including pathological findings, anatomical
landmarks, polyp removal conditions, and normal findings from images captured
by common GI tract examination instruments. In our evaluation, we introduce
performance hexagons using six performance metrics such as recall, precision,
specificity, accuracy, F1-score, and Matthews Correlation Coefficient to
demonstrate how to determine the real capabilities of models rather than
evaluating them shallowly. Furthermore, we perform cross-dataset evaluations
using different datasets for training and testing. With these cross-dataset
evaluations, we demonstrate the challenge of actually building a generalizable
model that could be used across different hospitals. Our experiments clearly
show that more sophisticated performance metrics and evaluation methods need to
be applied to get reliable models rather than depending on evaluations of the
splits of the same dataset, i.e., the performance metrics should always be
interpreted together rather than relying on a single metric.
"
2594,"Comment on ""No-Reference Video Quality Assessment Based on the Temporal
  Pooling of Deep Features""","  In Neural Processing Letters 50,3 (2019) a machine learning approach to blind
video quality assessment was proposed. It is based on temporal pooling of
features of video frames, taken from the last pooling layer of deep
convolutional neural networks. The method was validated on two established
benchmark datasets and gave results far better than the previous
state-of-the-art. In this letter we report the results from our careful
reimplementations. The performance results, claimed in the paper, cannot be
reached, and are even below the state-of-the-art by a large margin. We show
that the originally reported wrong performance results are a consequence of two
cases of data leakage. Information from outside the training dataset was used
in the fine-tuning stage and in the model evaluation.
"
2595,"Building a Manga Dataset ""Manga109"" with Annotations for Multimedia
  Applications","  Manga, or comics, which are a type of multimodal artwork, have been left
behind in the recent trend of deep learning applications because of the lack of
a proper dataset. Hence, we built Manga109, a dataset consisting of a variety
of 109 Japanese comic books (94 authors and 21,142 pages) and made it publicly
available by obtaining author permissions for academic use. We carefully
annotated the frames, speech texts, character faces, and character bodies; the
total number of annotations exceeds 500k. This dataset provides numerous manga
images and annotations, which will be beneficial for use in machine learning
algorithms and their evaluation. In addition to academic use, we obtained
further permission for a subset of the dataset for industrial use. In this
article, we describe the details of the dataset and present a few examples of
multimedia processing applications (detection, retrieval, and generation) that
apply existing deep learning methods and are made possible by the dataset.
"
2596,A Design of SDR-based Pseudo-Analog Wireless Video Transmission System,"  The pseudo-analog wireless video transmission technology can improve the
effectiveness, reliability, and robustness of the conventional digital system
in video broadcast scenarios. Although some prototypes of IEEE 802.11 series
have been developed for researchers to do simulations and experiments, they are
usually expensive and provide very limited access to the physical layer. More
importantly, these prototypes cannot be used to verify the correctness of the
new proposed pseudo-analog wireless video transmission algorithms directly due
to limited modulation modes they can support. In this paper, we present a novel
design of software radio platform (SDR)-based pseudo-analog wireless video
transceiver which is completely transparent and allows users to learn all the
implementation details. Firstly, we prove that the analog method can also
achieve the optimal performance as the digital method from the perspective of
the rate-distortion theory. Then, we describe the two hardware implementation
difficulties existed in the designing process including the data format
modification and the non-linear distortion. Next, we introduce the
implementation details of the designed transceiver. Finally, we analyze the
performance of the designed transceiver. Specifically, the results show that
the designed system can work effectively in both simulations and experiments.
"
2597,"Hardware Implementation of Adaptive Watermarking Based on Local Spatial
  Disorder Analysis","  With the increasing use of the internet and the ease of exchange of
multimedia content, the protection of ownership rights has become a significant
concern. Watermarking is an efficient means for this purpose. In many
applications, real-time watermarking is required, which demands hardware
implementation of low complexity and robust algorithm. In this paper, an
adaptive watermarking is presented, which uses embedding in different
bit-planes to achieve transparency and robustness. Local disorder of pixels is
analyzed to control the strength of the watermark. A new low complexity method
for disorder analysis is proposed, and its hardware implantation is presented.
An embedding method is proposed, which causes lower degradation in the
watermarked image. Also, the performance of proposed watermarking architecture
is improved by a pipe-line structure and is tested on an FPGA device. Results
show that the algorithm produces transparent and robust watermarked images. The
synthesis report from FPGA implementation illustrates a low complexity hardware
structure.
"
2598,"DeepFaceLab: A simple, flexible and extensible face swapping framework","  DeepFaceLab is an open-source deepfake system created by \textbf{iperov} for
face swapping with more than 3,000 forks and 13,000 stars in Github: it
provides an imperative and easy-to-use pipeline for people to use with no
comprehensive understanding of deep learning framework or with model
implementation required, while remains a flexible and loose coupling structure
for people who need to strengthen their own pipeline with other features
without writing complicated boilerplate code. In this paper, we detail the
principles that drive the implementation of DeepFaceLab and introduce the
pipeline of it, through which every aspect of the pipeline can be modified
painlessly by users to achieve their customization purpose, and it's noteworthy
that DeepFaceLab could achieve results with high fidelity and indeed
indiscernible by mainstream forgery detection approaches. We demonstrate the
advantage of our system through comparing our approach with current prevailing
systems. For more information, please visit:
https://github.com/iperov/DeepFaceLab/.
"
2599,"Compositional Few-Shot Recognition with Primitive Discovery and
  Enhancing","  Few-shot learning (FSL) aims at recognizing novel classes given only few
training samples, which still remains a great challenge for deep learning.
However, humans can easily recognize novel classes with only few samples. A key
component of such ability is the compositional recognition that human can
perform, which has been well studied in cognitive science but is not well
explored in FSL. Inspired by such capability of humans, to imitate humans'
ability of learning visual primitives and composing primitives to recognize
novel classes, we propose an approach to FSL to learn a feature representation
composed of important primitives, which is jointly trained with two parts, i.e.
primitive discovery and primitive enhancing. In primitive discovery, we focus
on learning primitives related to object parts by self-supervision from the
order of image splits, avoiding extra laborious annotations and alleviating the
effect of semantic gaps. In primitive enhancing, inspired by current studies on
the interpretability of deep networks, we provide our composition view for the
FSL baseline model. To modify this model for effective composition, inspired by
both mathematical deduction and biological studies (the Hebbian Learning rule
and the Winner-Take-All mechanism), we propose a soft composition mechanism by
enlarging the activation of important primitives while reducing that of others,
so as to enhance the influence of important primitives and better utilize these
primitives to compose novel classes. Extensive experiments on public benchmarks
are conducted on both the few-shot image classification and video recognition
tasks. Our method achieves the state-of-the-art performance on all these
datasets and shows better interpretability.
"
2600,The Hyper360 toolset for enriched 360$^\circ$ video,"  360$^\circ$ video is a novel media format, rapidly becoming adopted in media
production and consumption as part of todays ongoing virtual reality
revolution. Due to its novelty, there is a lack of tools for producing highly
engaging 360$^\circ$ video for consumption on a multitude of platforms. In this
work, we describe the work done so far in the Hyper360 project on tools for
360$^\circ$ video. Furthermore, the first pilots which have been produced with
the Hyper360 tools are presented.
"
2601,FaceFilter: Audio-visual speech separation using still images,"  The objective of this paper is to separate a target speaker's speech from a
mixture of two speakers using a deep audio-visual speech separation network.
Unlike previous works that used lip movement on video clips or pre-enrolled
speaker information as an auxiliary conditional feature, we use a single face
image of the target speaker. In this task, the conditional feature is obtained
from facial appearance in cross-modal biometric task, where audio and visual
identity representations are shared in latent space. Learnt identities from
facial images enforce the network to isolate matched speakers and extract the
voices from mixed speech. It solves the permutation problem caused by swapped
channel outputs, frequently occurred in speech separation tasks. The proposed
method is far more practical than video-based speech separation since user
profile images are readily available on many platforms. Also, unlike
speaker-aware separation methods, it is applicable on separation with unseen
speakers who have never been enrolled before. We show strong qualitative and
quantitative results on challenging real-world examples.
"
2602,"Near-duplicate video detection featuring coupled temporal and perceptual
  visual structures and logical inference based matching","  We propose in this paper an architecture for near-duplicate video detection
based on: (i) index and query signature based structures integrating temporal
and perceptual visual features and (ii) a matching framework computing the
logical inference between index and query documents. As far as indexing is
concerned, instead of concatenating low-level visual features in
high-dimensional spaces which results in curse of dimensionality and redundancy
issues, we adopt a perceptual symbolic representation based on color and
texture concepts. For matching, we propose to instantiate a retrieval model
based on logical inference through the coupling of an N-gram sliding window
process and theoretically-sound lattice-based structures. The techniques we
cover are robust and insensitive to general video editing and/or degradation,
making it ideal for re-broadcasted video search. Experiments are carried out on
large quantities of video data collected from the TRECVID 02, 03 and 04
collections and real-world video broadcasts recorded from two German TV
stations. An empirical comparison over two state-of-the-art dynamic programming
techniques is encouraging and demonstrates the advantage and feasibility of our
method.
"
2603,"Towards 5G: Joint Optimization of Video Segment Cache, Transcoding and
  Resource Allocation for Adaptive Video Streaming in a Muti-access Edge
  Computing Network","  The cache and transcoding of the multi-access edge computing (MEC) server and
wireless resource allocation in eNodeB interact and determine the quality of
experience (QoE) of dynamic adaptive streaming over HTTP (DASH) clients in MEC
networks. However, the relationship among the three factors has not been
explored, which has led to limited improvement in clients' QoE. Therefore, we
propose a joint optimization framework of video segment cache and transcoding
in MEC servers and resource allocation to improve the QoE of DASH clients.
Based on the established framework, we develop a MEC cache management mechanism
that consists of the MEC cache partition, video segment deletion, and MEC cache
space transfer. Then, a joint optimization algorithm that combines video
segment cache and transcoding in the MEC server and resource allocation is
proposed. In the algorithm, the clients' channel state and the playback status
and cooperation among MEC servers are employed to estimate the client's
priority, video segment presentation switch and continuous playback time.
Considering the above four factors, we develop a utility function model of
clients' QoE. Then, we formulate a mixed-integer nonlinear programming
mathematical model to maximize the total utility of DASH clients, where the
video segment cache and transcoding strategy and resource allocation strategy
are jointly optimized. To solve this problem, we propose a low-complexity
heuristic algorithm that decomposes the original problem into multiple
subproblems. The simulation results show that our proposed algorithms
efficiently improve client's throughput, received video quality and hit ratio
of video segments while decreasing the playback rebuffering time, video segment
presentation switch and system backhaul traffic.
"
2604,Spatiotemporal Adaptive Quantization for Video Compression Applications,"  JCT-VC HEVC HM 16 includes a Coding Unit (CU) level adaptive Quantization
Parameter (QP) technique named AdaptiveQP. It is designed to perceptually
adjust the QP in Y, Cb and Cr Coding Blocks (CBs) based only on the variance of
samples in a luma CB. In this paper, we propose an adaptive quantisation
technique that consists of two contributions. The first contribution relates to
accounting for the variance of chroma samples, in addition to luma samples, in
a CU. The second contribution relates to accounting for CU temporal information
as well as CU spatial information. Moreover, we integrate into our method a
lambda refined QP technique to reduce complexity associated multiple QP
optimizations in the Rate Distortion Optimization process. We evaluate the
proposed technique on 4:4:4, 4:2:2, 4:2:0 and 4:0:0 YCbCr test sequences, for
which we quantify the results using the Bjontegaard Delta Rate (BD-Rate)
metric. Our method achieves a maximum BD-Rate reduction of 23.1% (Y), 26.7%
(Cr) and 25.2% (Cb). Furthermore, a maximum encoding time reduction of 4.4% is
achieved.
"
2605,"Spatiotemporal Adaptive Quantization for the Perceptual Video Coding of
  RGB 4:4:4 Data","  Due to the spectral sensitivity phenomenon of the Human Visual System (HVS),
the color channels of raw RGB 4:4:4 sequences contain significant psychovisual
redundancies; these redundancies can be perceptually quantized. The default
quantization systems in the HEVC standard are known as Uniform Reconstruction
Quantization (URQ) and Rate Distortion Optimized Quantization (RDOQ); URQ and
RDOQ are not perceptually optimized for the coding of RGB 4:4:4 video data. In
this paper, we propose a novel spatiotemporal perceptual quantization technique
named SPAQ. With application for RGB 4:4:4 video data, SPAQ exploits HVS
spectral sensitivity-related color masking in addition to spatial masking and
temporal masking; SPAQ operates at the Coding Block (CB) level and the
Prediction Unit (PU) level. The proposed technique perceptually adjusts the
Quantization Step Size (QStep) at the CB level if high variance spatial data in
G, B and R CBs is detected and also if high motion vector magnitudes in PUs are
detected. Compared with anchor 1 (HEVC HM 16.17 RExt), SPAQ considerably
reduces bitrates with a maximum reduction of approximately 80%. The Mean
Opinion Score (MOS) in the subjective evaluations, in addition to the SSIM
scores, show that SPAQ successfully achieves perceptually lossless compression
compared with anchors.
"
2606,Multi-Entity and Multi-Enrollment Key Agreement with Correlated Noise,"  A basic model for key agreement with a remote (or hidden) source is extended
to a multi-user model with joint secrecy and privacy constraints over all
entities that do not trust each other after key agreement. Multiple entities
using different measurements of the same source through broadcast channels
(BCs) to agree on mutually-independent local secret keys are considered. Our
model is the proper multi-user extension of the basic model since the encoder
and decoder pairs are not assumed to trust other pairs after key agreement,
unlike assumed in the literature. Strong secrecy constraints imposed on all
secret keys jointly, which is more stringent than separate secrecy leakage
constraints for each secret key considered in the literature, are satisfied.
Inner bounds for maximum key rate, and minimum privacy-leakage and
database-storage rates are proposed for any finite number of entities. Inner
and outer bounds for degraded and less-noisy BCs are given to illustrate cases
with strong privacy. A multi-enrollment model that is used for common physical
unclonable functions is also considered to establish inner and outer bounds for
key-leakage-storage regions that differ only in the Markov chains imposed. For
this special case, the encoder and decoder measurement channels have the same
channel transition matrix and secrecy leakage is measured for each secret key
separately. We illustrate cases for which it is useful to have multiple
enrollments as compared to a single enrollment and vice versa.
"
2607,Deep Convolutional Sparse Coding Networks for Image Fusion,"  Image fusion is a significant problem in many fields including digital
photography, computational imaging and remote sensing, to name but a few.
Recently, deep learning has emerged as an important tool for image fusion. This
paper presents three deep convolutional sparse coding (CSC) networks for three
kinds of image fusion tasks (i.e., infrared and visible image fusion,
multi-exposure image fusion, and multi-modal image fusion). The CSC model and
the iterative shrinkage and thresholding algorithm are generalized into
dictionary convolution units. As a result, all hyper-parameters are learned
from data. Our extensive experiments and comprehensive comparisons reveal the
superiority of the proposed networks with regard to quantitative evaluation and
visual inspection.
"
2608,Cross-Task Transfer for Geotagged Audiovisual Aerial Scene Recognition,"  Aerial scene recognition is a fundamental task in remote sensing and has
recently received increased interest. While the visual information from
overhead images with powerful models and efficient algorithms yields
considerable performance on scene recognition, it still suffers from the
variation of ground objects, lighting conditions etc. Inspired by the
multi-channel perception theory in cognition science, in this paper, for
improving the performance on the aerial scene recognition, we explore a novel
audiovisual aerial scene recognition task using both images and sounds as
input. Based on an observation that some specific sound events are more likely
to be heard at a given geographic location, we propose to exploit the knowledge
from the sound events to improve the performance on the aerial scene
recognition. For this purpose, we have constructed a new dataset named AuDio
Visual Aerial sceNe reCognition datasEt (ADVANCE). With the help of this
dataset, we evaluate three proposed approaches for transferring the sound event
knowledge to the aerial scene recognition task in a multimodal learning
framework, and show the benefit of exploiting the audio information for the
aerial scene recognition. The source code is publicly available for
reproducibility purposes.
"
2609,"User-generated Video Quality Assessment: A Subjective and Objective
  Study","  Recently, we have observed an exponential increase of user-generated content
(UGC) videos. The distinguished characteristic of UGC videos originates from
the video production and delivery chain, as they are usually acquired and
processed by non-professional users before uploading to the hosting platforms
for sharing. As such, these videos usually undergo multiple distortion stages
that may affect visual quality before ultimately being viewed. Inspired by the
increasing consensus that the optimization of the video coding and processing
shall be fully driven by the perceptual quality, in this paper, we propose to
study the quality of the UGC videos from both objective and subjective
perspectives. We first construct a UGC video quality assessment (VQA) database,
aiming to provide useful guidance for the UGC video coding and processing in
the hosting platform. The database contains source UGC videos uploaded to the
platform and their transcoded versions that are ultimately enjoyed by
end-users, along with their subjective scores. Furthermore, we develop an
objective quality assessment algorithm that automatically evaluates the quality
of the transcoded videos based on the corrupted reference, which is in
accordance with the application scenarios of UGC video sharing in the hosting
platforms. The information from the corrupted reference is well leveraged and
the quality is predicted based on the inferred quality maps with deep neural
networks (DNN). Experimental results show that the proposed method yields
superior performance. Both subjective and objective evaluations of the UGC
videos also shed lights on the design of perceptual UGC video coding.
"
2610,End-to-End Lip Synchronisation,"  The goal of this work is to synchronise audio and video of a talking face
using deep neural network models. Existing works have trained networks on proxy
tasks such as cross-modal similarity learning, and then computed similarities
between audio and video frames using a sliding window approach. While these
methods demonstrate satisfactory performance, the networks are not trained
directly on the task. To this end, we propose an end-to-end trained network
that can directly predict the offset between an audio stream and the
corresponding video stream. The similarity matrix between the two modalities is
first computed from the features, then the inference of the offset can be
considered to be a pattern recognition problem where the matrix is considered
equivalent to an image. The feature extractor and the classifier are trained
jointly. We demonstrate that the proposed approach outperforms the previous
work by a large margin on LRS2 and LRS3 datasets.
"
2611,"Learning Spatial-Spectral Prior for Super-Resolution of Hyperspectral
  Imagery","  Recently, single gray/RGB image super-resolution reconstruction task has been
extensively studied and made significant progress by leveraging the advanced
machine learning techniques based on deep convolutional neural networks
(DCNNs). However, there has been limited technical development focusing on
single hyperspectral image super-resolution due to the high-dimensional and
complex spectral patterns in hyperspectral image. In this paper, we make a step
forward by investigating how to adapt state-of-the-art residual learning based
single gray/RGB image super-resolution approaches for computationally efficient
single hyperspectral image super-resolution, referred as SSPSR. Specifically,
we introduce a spatial-spectral prior network (SSPN) to fully exploit the
spatial information and the correlation between the spectra of the
hyperspectral data. Considering that the hyperspectral training samples are
scarce and the spectral dimension of hyperspectral image data is very high, it
is nontrivial to train a stable and effective deep network. Therefore, a group
convolution (with shared network parameters) and progressive upsampling
framework is proposed. This will not only alleviate the difficulty in feature
extraction due to high-dimension of the hyperspectral data, but also make the
training process more stable. To exploit the spatial and spectral prior, we
design a spatial-spectral block (SSB), which consists of a spatial residual
module and a spectral attention residual module. Experimental results on some
hyperspectral images demonstrate that the proposed SSPSR method enhances the
details of the recovered high-resolution hyperspectral images, and outperforms
state-of-the-arts. The source code is available at
\url{https://github.com/junjun-jiang/SSPSR
"
2612,"The Effects of Smartphones on Well-Being: Theoretical Integration and
  Research Agenda","  As smartphones become ever more integrated in peoples lives, a burgeoning new
area of research has emerged on their well-being effects. We propose that
disparate strands of research and apparently contradictory findings can be
integrated under three basic hypotheses, positing that smartphones influence
well-being by (1) replacing other activities (displacement hypothesis), (2)
interfering with concurrent activities (interference hypothesis), and (3)
affording access to information and activities that would otherwise be
unavailable (complementarity hypothesis). Using this framework, we highlight
methodological issues and go beyond net effects to examine how and when phones
boost versus hurt well-being. We examine both psychological and contextual
mediators and moderators of the effects, thus outlining an agenda for future
research.
"
2613,FrameProv: Towards End-To-End Video Provenance,"  Video feeds are often deliberately used as evidence, as in the case of CCTV
footage; but more often than not, the existence of footage of a supposed event
is perceived as proof of fact in the eyes of the public at large. This reliance
represents a societal vulnerability given the existence of easy-to-use editing
tools and means to fabricate entire video feeds using machine learning. And, as
the recent barrage of fake news and fake porn videos have shown, this isn't
merely an academic concern, it is actively been exploited. I posit that this
exploitation is only going to get more insidious. In this position paper, I
introduce a long term project that aims to mitigate some of the most egregious
forms of manipulation by embedding trustworthy components in the video
transmission chain. Unlike earlier works, I am not aiming to do tamper
detection or other forms of forensics -- approaches I think are bound to fail
in the face of the reality of necessary editing and compression -- instead, the
aim here is to provide a way for the video publisher to prove the integrity of
the video feed as well as make explicit any edits they may have performed. To
do this, I present a novel data structure, a video-edit specification language
and supporting infrastructure that provides end-to-end video provenance, from
the camera sensor to the viewer. I have implemented a prototype of this system
and am in talks with journalists and video editors to discuss the best ways
forward with introducing this idea to the mainstream.
"
2614,"Human-Perception-Oriented Pseudo Analog Video Transmissions with Deep
  Learning","  Recently, pseudo analog transmission has gained increasing attentions due to
its ability to alleviate the cliff effect in video multicast scenarios. The
existing pseudo analog systems are sorely optimized under the minimum mean
squared error criterion without taking the perceptual video quality into
consideration. In this paper, we propose a human-perception-based pseudo analog
video transmission system named ROIC-Cast, which aims to intelligently enhance
the transmission quality of the region-of-interest (ROI) parts. Firstly, the
classic deep learning based saliency detection algorithm is adopted to
decompose the continuous video sequences into ROI and non-ROI blocks. Secondly,
an effective compression method is used to reduce the data amount of side
information generated by the ROI extraction module. Then, the power allocation
scheme is formulated as a convex problem, and the optimal transmission power
for both ROI and non-ROI blocks is derived in a closed form. Finally, the
simulations are conducted to validate the proposed system by comparing with a
few of existing systems, e.g., KMV-Cast, SoftCast, and DAC-RAN. The proposed
ROIC-Cast can achieve over 4.1dB peak signal- to-noise ratio gains of ROI
compared with other systems, given the channel signal-to-noise ratio as -5dB,
0dB, 5dB, and 10dB, respectively. This significant performance improvement is
due to the automatic ROI extraction, high-efficiency data compression as well
as adaptive power allocation.
"
2615,Towards a Perceived Audiovisual Quality Model for Immersive Content,"  This paper studies the quality of multimedia content focusing on 360 video
and ambisonic spatial audio reproduced using a head-mounted display and a
multichannel loudspeaker setup. Encoding parameters following basic video
quality test conditions for 360 videos were selected and a low-bitrate codec
was used for the audio encoder. Three subjective experiments were performed for
the audio, video, and audiovisual respectively. Peak signal-to-noise ratio
(PSNR) and its variants for 360 videos were computed to obtain objective
quality metrics and subsequently correlated with the subjective video scores.
This study shows that a Cross-Format SPSNR-NN has a slightly higher linear and
monotonic correlation over all video sequences. Based on the audiovisual model,
a power model shows a highest correlation between test data and predicted
scores. We concluded that to enable the development of superior predictive
model, a high quality, critical, synchronized audiovisual database is required.
Furthermore, comprehensive assessor training may be beneficial prior to the
testing to improve the assessors' discrimination ability particularly with
respect to multichannel audio reproduction. In order to further improve the
performance of audiovisual quality models for immersive content, in addition to
developing broader and critical audiovisual databases, the subjective testing
methodology needs to be evolved to provide greater resolution and robustness.
"
2616,"Webpage Segmentation for Extracting Images and Their Surrounding
  Contextual Information","  Web images come in hand with valuable contextual information. Although this
information has long been mined for various uses such as image annotation,
clustering of images, inference of image semantic content, etc., insufficient
attention has been given to address issues in mining this contextual
information. In this paper, we propose a webpage segmentation algorithm
targeting the extraction of web images and their contextual information based
on their characteristics as they appear on webpages. We conducted a user study
to obtain a human-labeled dataset to validate the effectiveness of our method
and experiments demonstrated that our method can achieve better results
compared to an existing segmentation algorithm.
"
2617,"A Modified Fourier-Mellin Approach for Source Device Identification on
  Stabilized Videos","  To decide whether a digital video has been captured by a given device,
multimedia forensic tools usually exploit characteristic noise traces left by
the camera sensor on the acquired frames. This analysis requires that the noise
pattern characterizing the camera and the noise pattern extracted from video
frames under analysis are geometrically aligned. However, in many practical
scenarios this does not occur, thus a re-alignment or synchronization has to be
performed. Current solutions often require time consuming search of the
realignment transformation parameters. In this paper, we propose to overcome
this limitation by searching scaling and rotation parameters in the frequency
domain. The proposed algorithm tested on real videos from a well-known
state-of-the-art dataset shows promising results.
"
2618,User Attention and Behaviour in Virtual Reality Art Encounter,"  With the proliferation of consumer virtual reality (VR) headsets and creative
tools, content creators have started to experiment with new forms of
interactive audience experience using immersive media. Understanding user
attention and behaviours in virtual environment can greatly inform creative
processes in VR. We developed an abstract VR painting and an experimentation
system to study audience encounters through eye gaze and movement tracking. The
data from a user experiment with 35 participants reveal a range of user
activity patterns in art exploration. Deep learning models are used to study
the connections between behavioural data and audience background. New
integrated methods to visualise user attention as part of the artwork are also
developed as a feedback loop to the content creator.
"
2619,"A survey on Adversarial Recommender Systems: from Attack/Defense
  strategies to Generative Adversarial Networks","  Latent-factor models (LFM) based on collaborative filtering (CF), such as
matrix factorization (MF) and deep CF methods, are widely used in modern
recommender systems (RS) due to their excellent performance and recommendation
accuracy. However, success has been accompanied with a major new arising
challenge: many applications of machine learning (ML) are adversarial in
nature. In recent years, it has been shown that these methods are vulnerable to
adversarial examples, i.e., subtle but non-random perturbations designed to
force recommendation models to produce erroneous outputs.
  The goal of this survey is two-fold: (i) to present recent advances on
adversarial machine learning (AML) for the security of RS (i.e., attacking and
defense recommendation models), (ii) to show another successful application of
AML in generative adversarial networks (GANs) for generative applications,
thanks to their ability for learning (high-dimensional) data distributions. In
this survey, we provide an exhaustive literature review of 74 articles
published in major RS and ML journals and conferences. This review serves as a
reference for the RS community, working on the security of RS or on generative
models using GANs to improve their quality.
"
2620,Manifold Alignment for Semantically Aligned Style Transfer,"  Given a content image and a style image, the goal of style transfer is to
synthesize an output image by transferring the target style to the content
image. Currently, most of the methods address the problem with global style
transfer, assuming styles can be represented by global statistics, such as Gram
matrices or covariance matrices. In this paper, we make a different assumption
that local semantically aligned (or similar) regions between the content and
style images should share similar style patterns. Based on this assumption,
content features and style features are seen as two sets of manifolds and a
manifold alignment based style transfer (MAST) method is proposed. MAST is a
subspace learning method which learns a common subspace of the content and
style features. In the common subspace, content and style features with larger
feature similarity or the same semantic meaning are forced to be close. The
learned projection matrices are added with orthogonality constraints so that
the mapping can be bidirectional, which allows us to project the content
features into the common subspace, and then into the original style space. By
using a pre-trained decoder, promising stylized images are obtained. The method
is further extended to allow users to specify corresponding semantic regions
between content and style images or using semantic segmentation maps as
guidance. Extensive experiments show the proposed MAST achieves appealing
results in style transfer.
"
2621,Complexity Analysis Of Next-Generation VVC Encoding and Decoding,"  While the next generation video compression standard, Versatile Video Coding
(VVC), provides a superior compression efficiency, its computational complexity
dramatically increases. This paper thoroughly analyzes this complexity for both
encoder and decoder of VVC Test Model 6, by quantifying the complexity
break-down for each coding tool and measuring the complexity and memory
requirements for VVC encoding/decoding. These extensive analyses are performed
for six video sequences of 720p, 1080p, and 2160p, under Low-Delay (LD),
Random-Access (RA), and All-Intra (AI) conditions (a total of 320
encoding/decoding). Results indicate that the VVC encoder and decoder are 5x
and 1.5x more complex compared to HEVC in LD, and 31x and 1.8x in AI,
respectively. Detailed analysis of coding tools reveals that in LD on average,
motion estimation tools with 53%, transformation and quantization with 22%, and
entropy coding with 7% dominate the encoding complexity. In decoding, loop
filters with 30%, motion compensation with 20%, and entropy decoding with 16%,
are the most complex modules. Moreover, the required memory bandwidth for VVC
encoding/decoding are measured through memory profiling, which are 30x and 3x
of HEVC. The reported results and insights are a guide for future research and
implementations of energy-efficient VVC encoder/decoder.
"
2622,"Arbitrary-sized Image Training and Residual Kernel Learning: Towards
  Image Fraud Identification","  Preserving original noise residuals in images are critical to image fraud
identification. Since the resizing operation during deep learning will damage
the microstructures of image noise residuals, we propose a framework for
directly training images of original input scales without resizing. Our
arbitrary-sized image training method mainly depends on the pseudo-batch
gradient descent (PBGD), which bridges the gap between the input batch and the
update batch to assure that model updates can normally run for arbitrary-sized
images.
  In addition, a 3-phase alternate training strategy is designed to learn
optimal residual kernels for image fraud identification. With the learnt
residual kernels and PBGD, the proposed framework achieved the state-of-the-art
results in image fraud identification, especially for images with small
tampered regions or unseen images with different tampering distributions.
"
2623,Robust Spatial-spread Deep Neural Image Watermarking,"  Watermarking is an operation of embedding an information into an image in a
way that allows to identify ownership of the image despite applying some
distortions on it. In this paper, we presented a novel end-to-end solution for
embedding and recovering the watermark in the digital image using convolutional
neural networks. The method is based on spreading the message over the spatial
domain of the image, hence reducing the ""local bits per pixel"" capacity. To
obtain the model we used adversarial training and applied noiser layers between
the encoder and the decoder. Moreover, we broadened the spectrum of typically
considered attacks on the watermark and by grouping the attacks according to
their scope, we achieved high general robustness, most notably against JPEG
compression, Gaussian blurring, subsampling or resizing. To help us in the
models training we also proposed a precise differentiable approximation of
JPEG.
"
2624,"High-Resolution Image Inpainting with Iterative Confidence Feedback and
  Guided Upsampling","  Existing image inpainting methods often produce artifacts when dealing with
large holes in real applications. To address this challenge, we propose an
iterative inpainting method with a feedback mechanism. Specifically, we
introduce a deep generative model which not only outputs an inpainting result
but also a corresponding confidence map. Using this map as feedback, it
progressively fills the hole by trusting only high-confidence pixels inside the
hole at each iteration and focuses on the remaining pixels in the next
iteration. As it reuses partial predictions from the previous iterations as
known pixels, this process gradually improves the result. In addition, we
propose a guided upsampling network to enable generation of high-resolution
inpainting results. We achieve this by extending the Contextual Attention
module to borrow high-resolution feature patches in the input image.
Furthermore, to mimic real object removal scenarios, we collect a large object
mask dataset and synthesize more realistic training data that better simulates
user inputs. Experiments show that our method significantly outperforms
existing methods in both quantitative and qualitative evaluations. More results
and Web APP are available at https://zengxianyu.github.io/iic.
"
2625,"Deep Convolutional Neural Network-based Bernoulli Heatmap for Head Pose
  Estimation","  Head pose estimation is a crucial problem for many tasks, such as driver
attention, fatigue detection, and human behaviour analysis. It is well known
that neural networks are better at handling classification problems than
regression problems. It is an extremely nonlinear process to let the network
output the angle value directly for optimization learning, and the weight
constraint of the loss function will be relatively weak. This paper proposes a
novel Bernoulli heatmap for head pose estimation from a single RGB image. Our
method can achieve the positioning of the head area while estimating the angles
of the head. The Bernoulli heatmap makes it possible to construct fully
convolutional neural networks without fully connected layers and provides a new
idea for the output form of head pose estimation. A deep convolutional neural
network (CNN) structure with multiscale representations is adopted to maintain
high-resolution information and low-resolution information in parallel. This
kind of structure can maintain rich, high-resolution representations. In
addition, channelwise fusion is adopted to make the fusion weights learnable
instead of simple addition with equal weights. As a result, the estimation is
spatially more precise and potentially more accurate. The effectiveness of the
proposed method is empirically demonstrated by comparing it with other
state-of-the-art methods on public datasets.
"
2626,Dynamic Cache Management In Content Delivery Networks,"  The importance of content delivery networks (CDN) continues to rise with the
exponential increase in the generation and consumption of electronic media. In
order to ensure a high quality of experience, CDNs often deploy cache servers
that are capable of storing some of the popular files close to the user. Such
edge caching solutions not only increase the content availability, but also
result in higher download rates and lower latency at the user. We consider the
problem of content placement from an optimization perspective. Different from
the classical eviction-based algorithms, the present work formulates the
content placement problem from an optimization perspective and puts forth an
online algorithm for the same. In contrast to the existing optimization-based
solutions, the proposed algorithm is incremental and incurs very low
computation cost, while yielding storage allocations that are provably
near-optimal. The proposed algorithm can handle time varying content
popularity, thereby obviating the need for periodically estimating demand
distribution. Using synthetic and real IPTV data, we show that the proposed
policies outperform all the state of art caching techniques in terms of various
metrics.
"
2627,"Personalized Fashion Recommendation from Personal Social Media Data: An
  Item-to-Set Metric Learning Approach","  With the growth of online shopping for fashion products, accurate fashion
recommendation has become a critical problem. Meanwhile, social networks
provide an open and new data source for personalized fashion analysis. In this
work, we study the problem of personalized fashion recommendation from social
media data, i.e. recommending new outfits to social media users that fit their
fashion preferences. To this end, we present an item-to-set metric learning
framework that learns to compute the similarity between a set of historical
fashion items of a user to a new fashion item. To extract features from
multi-modal street-view fashion items, we propose an embedding module that
performs multi-modality feature extraction and cross-modality gated fusion. To
validate the effectiveness of our approach, we collect a real-world social
media dataset. Extensive experiments on the collected dataset show the superior
performance of our proposed approach.
"
2628,"A New Unified Method for Detecting Text from Marathon Runners and Sports
  Players in Video","  Detecting text located on the torsos of marathon runners and sports players
in video is a challenging issue due to poor quality and adverse effects caused
by flexible/colorful clothing, and different structures of human bodies or
actions. This paper presents a new unified method for tackling the above
challenges. The proposed method fuses gradient magnitude and direction
coherence of text pixels in a new way for detecting candidate regions.
Candidate regions are used for determining the number of temporal frame
clusters obtained by K-means clustering on frame differences. This process in
turn detects key frames. The proposed method explores Bayesian probability for
skin portions using color values at both pixel and component levels of temporal
frames, which provides fused images with skin components. Based on skin
information, the proposed method then detects faces and torsos by finding
structural and spatial coherences between them. We further propose adaptive
pixels linking a deep learning model for text detection from torso regions. The
proposed method is tested on our own dataset collected from marathon/sports
video and three standard datasets, namely, RBNR, MMM and R-ID of marathon
images, to evaluate the performance. In addition, the proposed method is also
tested on the standard natural scene datasets, namely, CTW1500 and MS-COCO text
datasets, to show the objectiveness of the proposed method. A comparative study
with the state-of-the-art methods on bib number/text detection of different
datasets shows that the proposed method outperforms the existing methods.
"
2629,Self-play Reinforcement Learning for Video Transmission,"  Video transmission services adopt adaptive algorithms to ensure users'
demands. Existing techniques are often optimized and evaluated by a function
that linearly combines several weighted metrics. Nevertheless, we observe that
the given function fails to describe the requirement accurately. Thus, such
proposed methods might eventually violate the original needs. To eliminate this
concern, we propose \emph{Zwei}, a self-play reinforcement learning algorithm
for video transmission tasks. Zwei aims to update the policy by
straightforwardly utilizing the actual requirement. Technically, Zwei samples a
number of trajectories from the same starting point and instantly estimates the
win rate w.r.t the competition outcome. Here the competition result represents
which trajectory is closer to the assigned requirement. Subsequently, Zwei
optimizes the strategy by maximizing the win rate. To build Zwei, we develop
simulation environments, design adequate neural network models, and invent
training methods for dealing with different requirements on various video
transmission scenarios. Trace-driven analysis over two representative tasks
demonstrates that Zwei optimizes itself according to the assigned requirement
faithfully, outperforming the state-of-the-art methods under all considered
scenarios.
"
2630,Memory Assessment of Versatile Video Coding,"  This paper presents a memory assessment of the next-generation Versatile
Video Coding (VVC). The memory analyses are performed adopting as a baseline
the state-of-the-art High-Efficiency Video Coding (HEVC). The goal is to offer
insights and observations of how critical the memory requirements of VVC are
aggravated, compared to HEVC. The adopted methodology consists of two sets of
experiments: (1) an overall memory profiling and (2) an inter-prediction
specific memory analysis. The results obtained in the memory profiling show
that VVC access up to 13.4x more memory than HEVC. Moreover, the
inter-prediction module remains (as in HEVC) the most resource-intensive
operation in the encoder: 60%-90% of the memory requirements. The
inter-prediction specific analysis demonstrates that VVC requires up to 5.3x
more memory accesses than HEVC. Furthermore, our analysis indicates that up to
23% of such growth is due to VVC novel-CU sizes (larger than 64x64).
"
2631,"DeepSonar: Towards Effective and Robust Detection of AI-Synthesized Fake
  Voices","  With the recent advances in voice synthesis, AI-synthesized fake voices are
indistinguishable to human ears and widely are applied to produce realistic and
natural DeepFakes, exhibiting real threats to our society. However, effective
and robust detectors for synthesized fake voices are still in their infancy and
are not ready to fully tackle this emerging threat. In this paper, we devise a
novel approach, named \emph{DeepSonar}, based on monitoring neuron behaviors of
speaker recognition (SR) system, \ie, a deep neural network (DNN), to discern
AI-synthesized fake voices. Layer-wise neuron behaviors provide an important
insight to meticulously catch the differences among inputs, which are widely
employed for building safety, robust, and interpretable DNNs. In this work, we
leverage the power of layer-wise neuron activation patterns with a conjecture
that they can capture the subtle differences between real and AI-synthesized
fake voices, in providing a cleaner signal to classifiers than raw inputs.
Experiments are conducted on three datasets (including commercial products from
Google, Baidu, \etc) containing both English and Chinese languages to
corroborate the high detection rates (98.1\% average accuracy) and low false
alarm rates (about 2\% error rate) of DeepSonar in discerning fake voices.
Furthermore, extensive experimental results also demonstrate its robustness
against manipulation attacks (\eg, voice conversion and additive real-world
noises). Our work further poses a new insight into adopting neuron behaviors
for effective and robust AI aided multimedia fakes forensics as an inside-out
approach instead of being motivated and swayed by various artifacts introduced
in synthesizing fakes.
"
2632,"Investigating Correlations of Automatically Extracted Multimodal
  Features and Lecture Video Quality","  Ranking and recommendation of multimedia content such as videos is usually
realized with respect to the relevance to a user query. However, for lecture
videos and MOOCs (Massive Open Online Courses) it is not only required to
retrieve relevant videos, but particularly to find lecture videos of high
quality that facilitate learning, for instance, independent of the video's or
speaker's popularity. Thus, metadata about a lecture video's quality are
crucial features for learning contexts, e.g., lecture video recommendation in
search as learning scenarios. In this paper, we investigate whether
automatically extracted features are correlated to quality aspects of a video.
A set of scholarly videos from a Mass Open Online Course (MOOC) is analyzed
regarding audio, linguistic, and visual features. Furthermore, a set of
cross-modal features is proposed which are derived by combining transcripts,
audio, video, and slide content. A user study is conducted to investigate the
correlations between the automatically collected features and human ratings of
quality aspects of a lecture video. Finally, the impact of our features on the
knowledge gain of the participants is discussed.
"
2633,"CGGAN: A Context Guided Generative Adversarial Network For Single Image
  Dehazing","  Image haze removal is highly desired for the application of computer vision.
This paper proposes a novel Context Guided Generative Adversarial Network
(CGGAN) for single image dehazing. Of which, an novel new encoder-decoder is
employed as the generator. And it consists of a feature-extraction-net, a
context-extractionnet, and a fusion-net in sequence. The feature extraction-net
acts as a encoder, and is used for extracting haze features. The
context-extraction net is a multi-scale parallel pyramid decoder, and is used
for extracting the deep features of the encoder and generating coarse dehazing
image. The fusion-net is a decoder, and is used for obtaining the final
haze-free image. To obtain more better results, multi-scale information
obtained during the decoding process of the context extraction decoder is used
for guiding the fusion decoder. By introducing an extra coarse decoder to the
original encoder-decoder, the CGGAN can make better use of the deep feature
information extracted by the encoder. To ensure our CGGAN work effectively for
different haze scenarios, different loss functions are employed for the two
decoders. Experiments results show the advantage and the effectiveness of our
proposed CGGAN, evidential improvements over existing state-of-the-art methods
are obtained.
"
2634,"Uncertainty-Aware Blind Image Quality Assessment in the Laboratory and
  Wild","  Performance of blind image quality assessment (BIQA) models has been
significantly boosted by end-to-end optimization of feature engineering and
quality regression. Nevertheless, due to the distributional shifts between
images simulated in the laboratory and captured in the wild, models trained on
databases with synthetic distortions remain particularly weak at handling
realistic distortions (and vice versa). To confront the
cross-distortion-scenario challenge, we develop a unified BIQA model and an
effective approach of training it for both synthetic and realistic distortions.
We first sample pairs of images from the same IQA databases and compute a
probability that one image of each pair is of higher quality as the supervisory
signal. We then employ the fidelity loss to optimize a deep neural network for
BIQA over a large number of such image pairs. We also explicitly enforce a
hinge constraint to regularize uncertainty estimation during optimization.
Extensive experiments on six IQA databases show the promise of the learned
method in blindly assessing image quality in the laboratory and wild. In
addition, we demonstrate the universality of the proposed training strategy by
using it to improve existing BIQA models.
"
2635,"Augmenting reality: On the shared history of perceptual illusion and
  video projection mapping","  Perceptual illusions based on the spatial correspondence between objects and
displayed images have been pursued by artists and scientists since the 15th
century, mastering optics to create crucial techniques as the linear
perspective and devices as the Magic Lantern. Contemporary video projection
mapping inherits and further extends this drive to produce perceptual illusions
in space by incorporating the required real time capabilities for dynamically
superposing the imaginary onto physical objects under fluid real world
conditions. A critical milestone has been reached in the creation of the
technical possibilities for all encompassing, untethered synthetic reality
experiences available to the plain senses, where every surface may act as a
screen and the relation to everyday objects is open to alterations.
"
2636,"Not made for each other- Audio-Visual Dissonance-based Deepfake
  Detection and Localization","  We propose detection of deepfake videos based on the dissimilarity between
the audio and visual modalities, termed as the Modality Dissonance Score (MDS).
We hypothesize that manipulation of either modality will lead to dis-harmony
between the two modalities, eg, loss of lip-sync, unnatural facial and lip
movements, etc. MDS is computed as an aggregate of dissimilarity scores between
audio and visual segments in a video. Discriminative features are learnt for
the audio and visual channels in a chunk-wise manner, employing the
cross-entropy loss for individual modalities, and a contrastive loss that
models inter-modality similarity. Extensive experiments on the DFDC and
DeepFake-TIMIT Datasets show that our approach outperforms the state-of-the-art
by up to 7%. We also demonstrate temporal forgery localization, and show how
our technique identifies the manipulated video segments.
"
2637,Deep Fusion Siamese Network for Automatic Kinship Verification,"  Automatic kinship verification aims to determine whether some individuals
belong to the same family. It is of great research significance to help missing
persons reunite with their families. In this work, the challenging problem is
progressively addressed in two respects. First, we propose a deep siamese
network to quantify the relative similarity between two individuals. When given
two input face images, the deep siamese network extracts the features from them
and fuses these features by combining and concatenating. Then, the fused
features are fed into a fully-connected network to obtain the similarity score
between two faces, which is used to verify the kinship. To improve the
performance, a jury system is also employed for multi-model fusion. Second, two
deep siamese networks are integrated into a deep triplet network for
tri-subject (i.e., father, mother and child) kinship verification, which is
intended to decide whether a child is related to a pair of parents or not.
Specifically, the obtained similarity scores of father-child and mother-child
are weighted to generate the parent-child similarity score for kinship
verification. Recognizing Families In the Wild (RFIW) is a challenging kinship
recognition task with multiple tracks, which is based on Families in the Wild
(FIW), a large-scale and comprehensive image database for automatic kinship
recognition. The Kinship Verification (track I) and Tri-Subject Verification
(track II) are supported during the ongoing RFIW2020 Challenge. Our team
(ustc-nelslip) ranked 1st in track II, and 3rd in track I. The code is
available at https://github.com/gniknoil/FG2020-kinship.
"
2638,OPAL-Net: A Generative Model for Part-based Object Layout Generation,"  We propose OPAL-Net, a novel hierarchical architecture for part-based layout
generation of objects from multiple categories using a single unified model. We
adopt a coarse-to-fine strategy involving semantically conditioned
autoregressive generation of bounding box layouts and pixel-level part layouts
for objects. We use Graph Convolutional Networks, Deep Recurrent Networks along
with custom-designed Conditional Variational Autoencoders to enable flexible,
diverse and category-aware generation of object layouts. We train OPAL-Net on
PASCAL-Parts dataset. The generated samples and corresponding evaluation scores
demonstrate the versatility of OPAL-Net compared to ablative variants and
baselines.
"
2639,Inferring Point Cloud Quality via Graph Similarity,"  We propose the GraphSIM -- an objective metric to accurately predict the
subjective quality of point cloud with superimposed geometry and color
impairments. Motivated by the facts that human vision system is more sensitive
to the high spatial-frequency components (e.g., contours, edges), and weighs
more to the local structural variations rather individual point intensity, we
first extract geometric keypoints by resampling the reference point cloud
geometry information to form the object skeleton; we then construct local
graphs centered at these keypoints for both reference and distorted point
clouds, followed by collectively aggregating color gradient moments (e.g.,
zeroth, first, and second) that are derived between all other points and
centered keypoint in the same local graph for significant feature similarity
(a.k.a., local significance) measurement; Final similarity index is obtained by
pooling the local graph significance across all color channels and by averaging
across all graphs. Our GraphSIM is validated using two large and independent
point cloud assessment datasets that involve a wide range of impairments (e.g.,
re-sampling, compression, additive noise), reliably demonstrating the
state-of-the-art performance for all distortions with noticeable gains in
predicting the subjective mean opinion score (MOS), compared with those
point-wise distance-based metrics adopted in standardization reference
software. Ablation studies have further shown that GraphSIM is generalized to
various scenarios with consistent performance by examining its key modules and
parameters.
"
2640,"Transcription-Enriched Joint Embeddings for Spoken Descriptions of
  Images and Videos","  In this work, we propose an effective approach for training unique embedding
representations by combining three simultaneous modalities: image and spoken
and textual narratives. The proposed methodology departs from a baseline system
that spawns a embedding space trained with only spoken narratives and image
cues. Our experiments on the EPIC-Kitchen and Places Audio Caption datasets
show that introducing the human-generated textual transcriptions of the spoken
narratives helps to the training procedure yielding to get better embedding
representations. The triad speech, image and words allows for a better estimate
of the point embedding and show an improving of the performance within tasks
like image and speech retrieval, even when text third modality, text, is not
present in the task.
"
2641,SiEVE: Semantically Encoded Video Analytics on Edge and Cloud,"  Recent advances in computer vision and neural networks have made it possible
for more surveillance videos to be automatically searched and analyzed by
algorithms rather than humans. This happened in parallel with advances in edge
computing where videos are analyzed over hierarchical clusters that contain
edge devices, close to the video source. However, the current video analysis
pipeline has several disadvantages when dealing with such advances. For
example, video encoders have been designed for a long time to please human
viewers and be agnostic of the downstream analysis task (e.g., object
detection). Moreover, most of the video analytics systems leverage 2-tier
architecture where the encoded video is sent to either a remote cloud or a
private edge server but does not efficiently leverage both of them. In response
to these advances, we present SIEVE, a 3-tier video analytics system to reduce
the latency and increase the throughput of analytics over video streams. In
SIEVE, we present a novel technique to detect objects in compressed video
streams. We refer to this technique as semantic video encoding because it
allows video encoders to be aware of the semantics of the downstream task
(e.g., object detection). Our results show that by leveraging semantic video
encoding, we achieve close to 100% object detection accuracy with decompressing
only 3.5% of the video frames which results in more than 100x speedup compared
to classical approaches that decompress every video frame.
"
2642,SRZoo: An integrated repository for super-resolution using deep learning,"  Deep learning-based image processing algorithms, including image
super-resolution methods, have been proposed with significant improvement in
performance in recent years. However, their implementations and evaluations are
dispersed in terms of various deep learning frameworks and various evaluation
criteria. In this paper, we propose an integrated repository for the
super-resolution tasks, named SRZoo, to provide state-of-the-art
super-resolution models in a single place. Our repository offers not only
converted versions of existing pre-trained models, but also documentation and
toolkits for converting other models. In addition, SRZoo provides
platform-agnostic image reconstruction tools to obtain super-resolved images
and evaluate the performance in place. It also brings the opportunity of
extension to advanced image-based researches and other image processing models.
The software, documentation, and pre-trained models are publicly available on
GitHub.
"
2643,"A Novel Nudity Detection Algorithm for Web and Mobile Application
  Development","  In our current web and mobile application development runtime nude image
content detection is very important. This paper presents a runtime nudity
detection method for web and mobile application development. We use two
parameters to detect the nude content of an image. One is the number of skin
pixels another is face region. A skin color model based on RGB, HSV color
spaces are used to detect skin pixels in an image. Google vision api is used to
detect the face region. By the percentage of skin regions and face regions an
image is identified nude or not. The success of this algorithm exists in
detecting skin regions and face regions. The skin detection algorithm can
detect skin 95% accurately with a low false-positive rate and the google vision
api for web and mobile applications can detect face 99% accurately with less
than 1 second time. From the experimental analysis, we have seen that the
proposed algorithm can detect 95% percent accurately the nudity of an image.
"
2644,"A New Chaos and Permutation Based Algorithm for Image and Video
  Encryption","  Images and video sequences carry large volumes of highly correlated and
redundant data. Applications like military and telecommunication require
encryption methods to protect the data from unwanted access. This requirement
in most cases needs to be realized in real-time. In this paper, we propose a
fast new Fiestal-structured approach for image and video encryption based on a
chaotic random sequence generator and a Permutation-Inverse Permutation (PIP)
pixel transform. This approach utilizes mathematical functions and transforms
with low complexity. The algorithm at the same time, ensures no drastic pay off
in terms of encryption quality. This renders the algorithm with promising scope
for real time applications and easy hardware implementation. MATLAB simulation
of the algorithm establishes its high quality of encryption in terms of
elevated entropy values and negligible correlation of the encrypted data with
the original. Simulation results also show high sensitivity to slight variation
in keys ensuring high security.
"
2645,Visual Summarization of Lecture Video Segments for Enhanced Navigation,"  Lecture videos are an increasingly important learning resource for higher
education. However, the challenge of quickly finding the content of interest in
a lecture video is an important limitation of this format. This paper
introduces visual summarization of lecture video segments to enhance
navigation. A lecture video is divided into segments based on the
frame-to-frame similarity of content. The user navigates the lecture video
content by viewing a single frame visual and textual summary of each segment.
The paper presents a novel methodology to generate the visual summary of a
lecture video segment by computing similarities between images extracted from
the segment and employing a graph-based algorithm to identify the subset of
most representative images. The results from this research are integrated into
a real-world lecture video management portal called Videopoints. To collect
ground truth for evaluation, a survey was conducted where multiple users
manually provided visual summaries for 40 lecture video segments. The users
also stated whether any images were not selected for the summary because they
were similar to other selected images. The graph based algorithm for
identifying summary images achieves 78% precision and 72% F1-measure with
frequently selected images as the ground truth, and 94% precision and 72%
F1-measure with the union of all user selected images as the ground truth. For
98% of algorithm selected visual summary images, at least one user also
selected that image for their summary or considered it similar to another image
they selected. Over 65% of automatically generated summaries were rated as good
or very good by the users on a 4-point scale from poor to very good. Overall,
the results establish that the methodology introduced in this paper produces
good quality visual summaries that are practically useful for lecture video
navigation.
"
2646,"Improving PSNR-based Quality Metrics Performance For Point Cloud
  Geometry","  An increased interest in immersive applications has drawn attention to
emerging 3D imaging representation formats, notably light fields and point
clouds (PCs). Nowadays, PCs are one of the most popular 3D media formats, due
to recent developments in PC acquisition, namely with new depth sensors and
signal processing algorithms. To obtain high fidelity 3D representations of
visual scenes a huge amount of PC data is typically acquired, which demands
efficient compression solutions. As in 2D media formats, the final perceived PC
quality plays an important role in the overall user experience and, thus,
objective metrics capable to measure the PC quality in a reliable way are
essential. In this context, this paper proposes and evaluates a set of
objective quality metrics for the geometry component of PC data, which plays a
very important role in the final perceived quality. Based on the popular PSNR
PC geometry quality metric, the novel improved PSNR-based metrics are proposed
by exploiting the intrinsic PC characteristics and the rendering process that
must occur before visualization. The experimental results show the superiority
of the best-proposed metrics over the state-of-the-art, obtaining an
improvement of up to 32% in the Pearson correlation coefficient.
"
2647,Ensemble Network for Ranking Images Based on Visual Appeal,"  We propose a computational framework for ranking images (group photos in
particular) taken at the same event within a short time span. The ranking is
expected to correspond with human perception of overall appeal of the images.
We hypothesize and provide evidence through subjective analysis that the
factors that appeal to humans are its emotional content, aesthetics and image
quality. We propose a network which is an ensemble of three information
channels, each predicting a score corresponding to one of the three visual
appeal factors. For group emotion estimation, we propose a convolutional neural
network (CNN) based architecture for predicting group emotion from images. This
new architecture enforces the network to put emphasis on the important regions
in the images, and achieves comparable results to the state-of-the-art. Next,
we develop a network for the image ranking task that combines group emotion,
aesthetics and image quality scores. Owing to the unavailability of suitable
databases, we created a new database of manually annotated group photos taken
during various social events. We present experimental results on this database
and other benchmark databases whenever available. Overall, our experiments show
that the proposed framework can reliably predict the overall appeal of images
with results closely corresponding to human ranking.
"
2648,"Are Social Networks Watermarking Us or Are We (Unawarely) Watermarking
  Ourself?","  In the last decade, Social Networks (SNs) have deeply changed many aspects of
society, and one of the most widespread behaviours is the sharing of pictures.
However, malicious users often exploit shared pictures to create fake profiles
leading to the growth of cybercrime. Thus, keeping in mind this scenario,
authorship attribution and verification through image watermarking techniques
are becoming more and more important. In this paper, firstly, we investigate
how 13 most popular SNs treat the uploaded pictures, in order to identify a
possible implementation of image watermarking techniques by respective SNs.
Secondly, on these 13 SNs, we test the robustness of several image watermarking
algorithms. Finally, we verify whether a method based on the Photo-Response
Non-Uniformity (PRNU) technique can be successfully used as a watermarking
approach for authorship attribution and verification of pictures on SNs. The
proposed method is robust enough in spite of the fact that the pictures get
downgraded during the uploading process by SNs. The results of our analysis on
a real dataset of 8,400 pictures show that the proposed method is more
effective than other watermarking techniques and can help to address serious
questions about privacy and security on SNs.
"
2649,Robust watermarking with double detector-discriminator approach,"  In this paper we present a novel deep framework for a watermarking - a
technique of embedding a transparent message into an image in a way that allows
retrieving the message from a (perturbed) copy, so that copyright infringement
can be tracked. For this technique, it is essential to extract the information
from the image even after imposing some digital processing operations on it.
Our framework outperforms recent methods in the context of robustness against
not only spectrum of attacks (e.g. rotation, resizing, Gaussian smoothing) but
also against compression, especially JPEG. The bit accuracy of our method is at
least 0.86 for all types of distortions. We also achieved 0.90 bit accuracy for
JPEG while recent methods provided at most 0.83. Our method retains high
transparency and capacity as well. Moreover, we present our double
detector-discriminator approach - a scheme to detect and discriminate if the
image contains the embedded message or not, which is crucial for real-life
watermarking systems and up to now was not investigated using neural networks.
With this, we design a testing formula to validate our extended approach and
compared it with a common procedure. We also present an alternative method of
balancing between image quality and robustness on attacks which is easily
applicable to the framework.
"
2650,Hysia: Serving DNN-Based Video-to-Retail Applications in Cloud,"  Combining \underline{v}ideo streaming and online \underline{r}etailing (V2R)
has been a growing trend recently. In this paper, we provide practitioners and
researchers in multimedia with a cloud-based platform named Hysia for easy
development and deployment of V2R applications. The system consists of: 1) a
back-end infrastructure providing optimized V2R related services including data
engine, model repository, model serving and content matching; and 2) an
application layer which enables rapid V2R application prototyping. Hysia
addresses industry and academic needs in large-scale multimedia by: 1)
seamlessly integrating state-of-the-art libraries including NVIDIA video SDK,
Facebook faiss, and gRPC; 2) efficiently utilizing GPU computation; and 3)
allowing developers to bind new models easily to meet the rapidly changing deep
learning (DL) techniques. On top of that, we implement an orchestrator for
further optimizing DL model serving performance. Hysia has been released as an
open source project on GitHub, and attracted considerable attention. We have
published Hysia to DockerHub as an official image for seamless integration and
deployment in current cloud environments.
"
2651,Automatic Photo to Ideophone Manga Matching,"  Photo applications offer tools for annotation via text and stickers.
Ideophones, mimetic and onomatopoeic words, which are common in graphic novels,
have yet to be explored for photo annotation use. We present a method for
automatic ideophone recommendation and positioning of the text on photos. These
annotations are accomplished by obtaining a list of ideophones with English
definitions and applying a suite of visual object detectors to the image. Next,
a semantic embedding maps the visual objects to the possible relevant
ideophones. Our system stands in contrast to traditional computer vision-based
annotation systems, which stop at recommending object and scene-level
annotation, by providing annotations that are communicative, fun, and engaging.
We test these annotations in Japanese and find they carry a strong preference
and increase enjoyment and sharing likelihood when compared to unannotated and
object-based annotated photos.
"
2652,"Interpreting CNN for Low Complexity Learned Sub-pixel Motion
  Compensation in Video Coding","  Deep learning has shown great potential in image and video compression tasks.
However, it brings bit savings at the cost of significant increases in coding
complexity, which limits its potential for implementation within practical
applications. In this paper, a novel neural network-based tool is presented
which improves the interpolation of reference samples needed for fractional
precision motion compensation. Contrary to previous efforts, the proposed
approach focuses on complexity reduction achieved by interpreting the
interpolation filters learned by the networks. When the approach is implemented
in the Versatile Video Coding (VVC) test model, up to 4.5% BD-rate saving for
individual sequences is achieved compared with the baseline VVC, while the
complexity of learned interpolation is significantly reduced compared to the
application of full neural network.
"
2653,The genesis of Hippachus' celestial globe,"  This paper summarises briefly and in English some of the results of the book
Hoffmann: Hipparchs Himmelsglobus, Springer, 2017 that had to be written in
German. The globe of Hipparchus is not preserved. For that reason, it has been
a source of much speculation and scientific inquiry during the last few
centuries. This study presents a new analysis of the data given in the
commentary on Aratus' poem by Hipparchus, in comparison with other contemporary
Babylonian and Greek astronomical data, as well as their predecessors in the
first millennium and their successors up to Ptolemy. The result of all these
studies are the following: i) although the data of Ptolemy and Hipparchus are
undoubtedly correlated, it is certainly also wrong to accuse Ptolemy having
simply copied and transformed it without correct citation; ii) although
Hipparchus presumably observed most of his star catalogue with his own
instruments, we cannot neglect Babylonian influences. Hipparchus was educated
in Greek astronomy but, in his time, there are traces of Babylonian influences
since at least two centuries. Since we are unable to definitely prove that
Hipparchus used Babylonian data, we are not sure if there are direct Babylonian
influences in his time or as a consequence of his education only. Finally, we
present a virtual 3D-image showing what the globe of Hipparchus might have
looked like.
"
2654,Mitigating Gender Bias in Captioning Systems,"  Image captioning has made substantial progress with huge supporting image
collections sourced from the web. However, recent studies have pointed out that
captioning datasets, such as COCO, contain gender bias found in web corpora. As
a result, learning models could heavily rely on the learned priors and image
context for gender identification, leading to incorrect or even offensive
errors. To encourage models to learn correct gender features, we reorganize the
COCO dataset and present two new splits COCO-GB V1 and V2 datasets where the
train and test sets have different gender-context joint distribution. Models
relying on contextual cues will suffer from huge gender prediction errors on
the anti-stereotypical test data. Benchmarking experiments reveal that most
captioning models learn gender bias, leading to high gender prediction errors,
especially for women. To alleviate the unwanted bias, we propose a new Guided
Attention Image Captioning model (GAIC) which provides self-guidance on visual
attention to encourage the model to capture correct gender visual evidence.
Experimental results validate that GAIC can significantly reduce gender
prediction errors with a competitive caption quality. Our codes and the
designed benchmark datasets are available at
https://github.com/CaptionGenderBias2020.
"
2655,ORD: Object Relationship Discovery for Visual Dialogue Generation,"  With the rapid advancement of image captioning and visual question answering
at single-round level, the question of how to generate multi-round dialogue
about visual content has not yet been well explored.Existing visual dialogue
methods encode the image into a fixed feature vector directly, concatenated
with the question and history embeddings to predict the response.Some recent
methods tackle the co-reference resolution problem using co-attention mechanism
to cross-refer relevant elements from the image, history, and the target
question.However, it remains challenging to reason visual relationships, since
the fine-grained object-level information is omitted before co-attentive
reasoning. In this paper, we propose an object relationship discovery (ORD)
framework to preserve the object interactions for visual dialogue generation.
Specifically, a hierarchical graph convolutional network (HierGCN) is proposed
to retain the object nodes and neighbour relationships locally, and then
refines the object-object connections globally to obtain the final graph
embeddings. A graph attention is further incorporated to dynamically attend to
this graph-structured representation at the response reasoning stage. Extensive
experiments have proved that the proposed method can significantly improve the
quality of dialogue by utilising the contextual information of visual
relationships. The model achieves superior performance over the
state-of-the-art methods on the Visual Dialog dataset, increasing MRR from
0.6222 to 0.6447, and recall@1 from 48.48% to 51.22%.
"
2656,A Dataset and Benchmarks for Multimedia Social Analysis,"  We present a new publicly available dataset with the goal of advancing
multi-modality learning by offering vision and language data within the same
context. This is achieved by obtaining data from a social media website with
posts containing multiple paired images/videos and text, along with comment
trees containing images/videos and/or text. With a total of 677k posts, 2.9
million post images, 488k post videos, 1.4 million comment images, 4.6 million
comment videos, and 96.9 million comments, data from different modalities can
be jointly used to improve performances for a variety of tasks such as image
captioning, image classification, next frame prediction, sentiment analysis,
and language modeling. We present a wide range of statistics for our dataset.
Finally, we provide baseline performance analysis for one of the regression
tasks using pre-trained models and several fully connected networks.
"
2657,"Go-CaRD -- Generic, Optical Car Part Recognition and Detection:
  Collection, Insights, and Applications","  Systems for the automatic recognition and detection of automotive parts are
crucial in several emerging research areas in the development of intelligent
vehicles. They enable, for example, the detection and modelling of interactions
between human and the vehicle. In this paper, we present three suitable
datasets as well as quantitatively and qualitatively explore the efficacy of
state-of-the-art deep learning architectures for the localisation of 29
interior and exterior vehicle regions, independent of brand, model, and
environment. A ResNet50 model achieved an F1 score of 93.67 % for recognition,
while our best Darknet model achieved an mAP of 58.20 % for detection. We also
experiment with joint and transfer learning approaches and point out potential
applications of our systems.
"
2658,"AVLnet: Learning Audio-Visual Language Representations from
  Instructional Videos","  Current methods for learning visually grounded language from videos often
rely on time-consuming and expensive data collection, such as human annotated
textual summaries or machine generated automatic speech recognition
transcripts. In this work, we introduce Audio-Video Language Network (AVLnet),
a self-supervised network that learns a shared audio-visual embedding space
directly from raw video inputs. We circumvent the need for annotation and
instead learn audio-visual language representations directly from randomly
segmented video clips and their raw audio waveforms. We train AVLnet on
publicly available instructional videos and evaluate our model on video clip
and language retrieval tasks on three video datasets. Our proposed model
outperforms several state-of-the-art text-video baselines by up to 11.8% in a
video clip retrieval task, despite operating on the raw audio instead of
manually annotated text captions. Further, we show AVLnet is capable of
integrating textual information, increasing its modularity and improving
performance by up to 20.3% on the video clip retrieval task. Finally, we
perform analysis of AVLnet's learned representations, showing our model has
learned to relate visual objects with salient words and natural sounds.
"
2659,Iterative Nadaraya-Watson Distribution Transfer for Colour Grading,"  We propose a new method with Nadaraya-Watson that maps one N-dimensional
distribution to another taking into account available information about
correspondences. We extend the 2D/3D problem to higher dimensions by encoding
overlapping neighborhoods of data points and solve the high dimensional problem
in 1D space using an iterative projection approach. To show potentials of this
mapping, we apply it to colour transfer between two images that exhibit
overlapped scene. Experiments show quantitative and qualitative improvements
over previous state of the art colour transfer methods.
"
2660,AcED: Accurate and Edge-consistent Monocular Depth Estimation,"  Single image depth estimation is a challenging problem. The current
state-of-the-art method formulates the problem as that of ordinal regression.
However, the formulation is not fully differentiable and depth maps are not
generated in an end-to-end fashion. The method uses a na\""ive threshold
strategy to determine per-pixel depth labels, which results in significant
discretization errors. For the first time, we formulate a fully differentiable
ordinal regression and train the network in end-to-end fashion. This enables us
to include boundary and smoothness constraints in the optimization function,
leading to smooth and edge-consistent depth maps. A novel per-pixel confidence
map computation for depth refinement is also proposed. Extensive evaluation of
the proposed model on challenging benchmarks reveals its superiority over
recent state-of-the-art methods, both quantitatively and qualitatively.
Additionally, we demonstrate practical utility of the proposed method for
single camera bokeh solution using in-house dataset of challenging real-life
images.
"
2661,"Generative Modelling for Controllable Audio Synthesis of Expressive
  Piano Performance","  We present a controllable neural audio synthesizer based on Gaussian Mixture
Variational Autoencoders (GM-VAE), which can generate realistic piano
performances in the audio domain that closely follows temporal conditions of
two essential style features for piano performances: articulation and dynamics.
We demonstrate how the model is able to apply fine-grained style morphing over
the course of synthesizing the audio. This is based on conditions which are
latent variables that can be sampled from the prior or inferred from other
pieces. One of the envisioned use cases is to inspire creative and brand new
interpretations for existing pieces of piano music.
"
2662,Video Moment Localization using Object Evidence and Reverse Captioning,"  We address the problem of language-based temporal localization of moments in
untrimmed videos. Compared to temporal localization with fixed categories, this
problem is more challenging as the language-based queries have no predefined
activity classes and may also contain complex descriptions. Current
state-of-the-art model MAC addresses it by mining activity concepts from both
video and language modalities. This method encodes the semantic activity
concepts from the verb/object pair in a language query and leverages visual
activity concepts from video activity classification prediction scores. We
propose ""Multi-faceted VideoMoment Localizer"" (MML), an extension of MAC model
by the introduction of visual object evidence via object segmentation masks and
video understanding features via video captioning. Furthermore, we improve
language modelling in sentence embedding. We experimented on Charades-STA
dataset and identified that MML outperforms MAC baseline by 4.93% and 1.70% on
R@1 and R@5metrics respectively. Our code and pre-trained model are publicly
available at https://github.com/madhawav/MML.
"
2663,Artificial Musical Intelligence: A Survey,"  Computers have been used to analyze and create music since they were first
introduced in the 1950s and 1960s. Beginning in the late 1990s, the rise of the
Internet and large scale platforms for music recommendation and retrieval have
made music an increasingly prevalent domain of machine learning and artificial
intelligence research. While still nascent, several different approaches have
been employed to tackle what may broadly be referred to as ""musical
intelligence."" This article provides a definition of musical intelligence,
introduces a taxonomy of its constituent components, and surveys the wide range
of AI methods that can be, and have been, brought to bear in its pursuit, with
a particular emphasis on machine learning methods.
"
2664,N=1 Modelling of Lifestyle Impact on SleepPerformance,"  Sleep is critical to leading a healthy lifestyle. Each day, most people go to
sleep without any idea about how their night's rest is going to be. For an
activity that humans spend around a third of their life doing, there is a
surprising amount of mystery around it. Despite current research, creating
personalized sleep models in real-world settings has been challenging. Existing
literature provides several connections between daily activities and sleep
quality. Unfortunately, these insights do not generalize well in many
individuals. For these reasons, it is important to create a personalized sleep
model. This research proposes a sleep model that can identify causal
relationships between daily activities and sleep quality and present the user
with specific feedback about how their lifestyle affects their sleep. Our
method uses N-of-1 experiments on longitudinal user data and event mining to
generate understanding between lifestyle choices (exercise, eating, circadian
rhythm) and their impact on sleep quality. Our experimental results identified
and quantified relationships while extracting confounding variables through a
causal framework. These insights can be used by the user or a personal health
navigator to provide guidance in improving sleep.
"
2665,"iSeeBetter: Spatio-temporal video super-resolution using recurrent
  generative back-projection networks","  Recently, learning-based models have enhanced the performance of single-image
super-resolution (SISR). However, applying SISR successively to each video
frame leads to a lack of temporal coherency. Convolutional neural networks
(CNNs) outperform traditional approaches in terms of image quality metrics such
as peak signal to noise ratio (PSNR) and structural similarity (SSIM). However,
generative adversarial networks (GANs) offer a competitive advantage by being
able to mitigate the issue of a lack of finer texture details, usually seen
with CNNs when super-resolving at large upscaling factors. We present
iSeeBetter, a novel GAN-based spatio-temporal approach to video
super-resolution (VSR) that renders temporally consistent super-resolution
videos. iSeeBetter extracts spatial and temporal information from the current
and neighboring frames using the concept of recurrent back-projection networks
as its generator. Furthermore, to improve the ""naturality"" of the
super-resolved image while eliminating artifacts seen with traditional
algorithms, we utilize the discriminator from super-resolution generative
adversarial network (SRGAN). Although mean squared error (MSE) as a primary
loss-minimization objective improves PSNR/SSIM, these metrics may not capture
fine details in the image resulting in misrepresentation of perceptual quality.
To address this, we use a four-fold (MSE, perceptual, adversarial, and
total-variation (TV)) loss function. Our results demonstrate that iSeeBetter
offers superior VSR fidelity and surpasses state-of-the-art performance.
"
2666,"Improving Locality Sensitive Hashing by Efficiently Finding Projected
  Nearest Neighbors","  Similarity search in high-dimensional spaces is an important task for many
multimedia applications. Due to the notorious curse of dimensionality,
approximate nearest neighbor techniques are preferred over exact searching
techniques since they can return good enough results at a much better speed.
Locality Sensitive Hashing (LSH) is a very popular random hashing technique for
finding approximate nearest neighbors. Existing state-of-the-art Locality
Sensitive Hashing techniques that focus on improving performance of the overall
process, mainly focus on minimizing the total number of IOs while sacrificing
the overall processing time. The main time-consuming process in LSH techniques
is the process of finding neighboring points in projected spaces. We present a
novel index structure called radius-optimized Locality Sensitive Hashing
(roLSH). With the help of sampling techniques and Neural Networks, we present
two techniques to find neighboring points in projected spaces efficiently,
without sacrificing the accuracy of the results. Our extensive experimental
analysis on real datasets shows the performance benefit of roLSH over existing
state-of-the-art LSH techniques.
"
2667,"Experimental Analysis of Locality Sensitive Hashing Techniques for
  High-Dimensional Approximate Nearest Neighbor Searches","  Finding nearest neighbors in high-dimensional spaces is a fundamental
operation in many multimedia retrieval applications. Exact tree-based indexing
approaches are known to suffer from the notorious curse of dimensionality for
high-dimensional data. Approximate searching techniques sacrifice some accuracy
while returning good enough results for faster performance. Locality Sensitive
Hashing (LSH) is a very popular technique for finding approximate nearest
neighbors in high-dimensional spaces. Apart from providing theoretical
guarantees on the query results, one of the main benefits of LSH techniques is
their good scalability to large datasets because they are external memory
based. The most dominant costs for existing LSH techniques are the algorithm
time and the index I/Os required to find candidate points. Existing works do
not compare both of these dominant costs in their evaluation. In this
experimental survey paper, we show the impact of both these costs on the
overall performance of the LSH technique. We compare three state-of-the-art
techniques on four real-world datasets, and show that, in contrast to recent
works, C2LSH is still the state-of-the-art algorithm in terms of performance
while achieving similar accuracy as its recent competitors.
"
2668,M2P2: Multimodal Persuasion Prediction using Adaptive Fusion,"  Identifying persuasive speakers in an adversarial environment is a critical
task. In a national election, politicians would like to have persuasive
speakers campaign on their behalf. When a company faces adverse publicity, they
would like to engage persuasive advocates for their position in the presence of
adversaries who are critical of them. Debates represent a common platform for
these forms of adversarial persuasion. This paper solves two problems: the
Debate Outcome Prediction (DOP) problem predicts who wins a debate while the
Intensity of Persuasion Prediction (IPP) problem predicts the change in the
number of votes before and after a speaker speaks. Though DOP has been
previously studied, we are the first to study IPP. Past studies on DOP fail to
leverage two important aspects of multimodal data: 1) multiple modalities are
often semantically aligned, and 2) different modalities may provide diverse
information for prediction. Our M2P2 (Multimodal Persuasion Prediction)
framework is the first to use multimodal (acoustic, visual, language) data to
solve the IPP problem. To leverage the alignment of different modalities while
maintaining the diversity of the cues they provide, M2P2 devises a novel
adaptive fusion learning framework which fuses embeddings obtained from two
modules -- an alignment module that extracts shared information between
modalities and a heterogeneity module that learns the weights of different
modalities with guidance from three separately trained unimodal reference
models. We test M2P2 on the popular IQ2US dataset designed for DOP. We also
introduce a new dataset called QPS (from Qipashuo, a popular Chinese debate TV
show ) for IPP. M2P2 significantly outperforms 3 recent baselines on both
datasets. Our code and QPS dataset can be found at
http://snap.stanford.edu/m2p2/.
"
2669,"A Multiparametric Class of Low-complexity Transforms for Image and Video
  Coding","  Discrete transforms play an important role in many signal processing
applications, and low-complexity alternatives for classical transforms became
popular in recent years. Particularly, the discrete cosine transform (DCT) has
proven to be convenient for data compression, being employed in well-known
image and video coding standards such as JPEG, H.264, and the recent high
efficiency video coding (HEVC). In this paper, we introduce a new class of
low-complexity 8-point DCT approximations based on a series of works published
by Bouguezel, Ahmed and Swamy. Also, a multiparametric fast algorithm that
encompasses both known and novel transforms is derived. We select the
best-performing DCT approximations after solving a multicriteria optimization
problem, and submit them to a scaling method for obtaining larger size
transforms. We assess these DCT approximations in both JPEG-like image
compression and video coding experiments. We show that the optimal DCT
approximations present compelling results in terms of coding efficiency and
image quality metrics, and require only few addition or bit-shifting
operations, being suitable for low-complexity and low-power systems.
"
2670,Capturing Video Frame Rate Variations via Entropic Differencing,"  High frame rate videos are increasingly getting popular in recent years,
driven by the strong requirements of the entertainment and streaming industries
to provide high quality of experiences to consumers. To achieve the best
trade-offs between the bandwidth requirements and video quality in terms of
frame rate adaptation, it is imperative to understand the effects of frame rate
on video quality. In this direction, we devise a novel statistical entropic
differencing method based on a Generalized Gaussian Distribution model
expressed in the spatial and temporal band-pass domains, which measures the
difference in quality between reference and distorted videos. The proposed
design is highly generalizable and can be employed when the reference and
distorted sequences have different frame rates. Our proposed model correlates
very well with subjective scores in the recently proposed LIVE-YT-HFR database
and achieves state of the art performance when compared with existing
methodologies.
"
2671,On Addressing the Impact of ISO Speed upon PRNU and Forgery Detection,"  Photo Response Non-Uniformity (PRNU) has been used as a powerful device
fingerprint for image forgery detection because image forgeries can be revealed
by finding the absence of the PRNU in the manipulated areas. The correlation
between an image's noise residual with the device's reference PRNU is often
compared with a decision threshold to check the existence of the PRNU. A PRNU
correlation predictor is usually used to determine this decision threshold
assuming the correlation is content-dependent. However, we found that not only
the correlation is content-dependent, but it also depends on the camera
sensitivity setting. \textit{Camera sensitivity}, commonly known by the name of
\textit{ISO speed}, is an important attribute in digital photography. In this
work, we will show the PRNU correlation's dependency on ISO speed. Due to such
dependency, we postulate that a correlation predictor is ISO speed-specific,
i.e. \textit{reliable correlation predictions can only be made when a
correlation predictor is trained with images of similar ISO speeds to the image
in question}. We report the experiments we conducted to validate the postulate.
It is realized that in the real-world, information about the ISO speed may not
be available in the metadata to facilitate the implementation of our postulate
in the correlation prediction process. We hence propose a method called
Content-based Inference of ISO Speeds (CINFISOS) to infer the ISO speed from
the image content.
"
2672,"Speaker Independent and Multilingual/Mixlingual Speech-Driven Talking
  Head Generation Using Phonetic Posteriorgrams","  Generating 3D speech-driven talking head has received more and more attention
in recent years. Recent approaches mainly have following limitations: 1) most
speaker-independent methods need handcrafted features that are time-consuming
to design or unreliable; 2) there is no convincing method to support
multilingual or mixlingual speech as input. In this work, we propose a novel
approach using phonetic posteriorgrams (PPG). In this way, our method doesn't
need hand-crafted features and is more robust to noise compared to recent
approaches. Furthermore, our method can support multilingual speech as input by
building a universal phoneme space. As far as we know, our model is the first
to support multilingual/mixlingual speech as input with convincing results.
Objective and subjective experiments have shown that our model can generate
high quality animations given speech from unseen languages or speakers and be
robust to noise.
"
2673,Feel The Music: Automatically Generating A Dance For An Input Song,"  We present a general computational approach that enables a machine to
generate a dance for any input music. We encode intuitive, flexible heuristics
for what a 'good' dance is: the structure of the dance should align with the
structure of the music. This flexibility allows the agent to discover creative
dances. Human studies show that participants find our dances to be more
creative and inspiring compared to meaningful baselines. We also evaluate how
perception of creativity changes based on different presentations of the dance.
Our code is available at https://github.com/purvaten/feel-the-music.
"
2674,A Study on Impacts of Multiple Factors on Video Qualify of Experience,"  HTTP Adaptive Streaming (HAS) has become a cost-effective means for
multimedia delivery nowadays. However, how the quality of experience (QoE) is
jointly affected by 1) varying perceptual quality and 2) interruptions is not
well-understood. In this paper, we present the first attempt to quantitatively
quantify the relative impacts of these factors on the QoE of streaming
sessions. To achieve this purpose, we first model the impacts of the factors
using histograms, which represent the frequency distributions of the individual
factors in a session. By using a large dataset, various insights into the
relative impacts of these factors are then provided, serving as suggestions to
improve the QoE of streaming sessions.
"
2675,"DeepQTMT: A Deep Learning Approach for Fast QTMT-based CU Partition of
  Intra-mode VVC","  Versatile Video Coding (VVC), as the latest standard, significantly improves
the coding efficiency over its ancestor standard High Efficiency Video Coding
(HEVC), but at the expense of sharply increased complexity. In VVC, the
quad-tree plus multi-type tree (QTMT) structure of coding unit (CU) partition
accounts for over 97% of the encoding time, due to the brute-force search for
recursive rate-distortion (RD) optimization. Instead of the brute-force QTMT
search, this paper proposes a deep learning approach to predict the QTMT-based
CU partition, for drastically accelerating the encoding process of intra-mode
VVC. First, we establish a large-scale database containing sufficient CU
partition patterns with diverse video content, which can facilitate the
data-driven VVC complexity reduction. Next, we propose a multi-stage exit CNN
(MSE-CNN) model with an early-exit mechanism to determine the CU partition, in
accord with the flexible QTMT structure at multiple stages. Then, we design an
adaptive loss function for training the MSE-CNN model, synthesizing both the
uncertain number of split modes and the target on minimized RD cost. Finally, a
multi-threshold decision scheme is developed, achieving desirable trade-off
between complexity and RD performance. Experimental results demonstrate that
our approach can reduce the encoding time of VVC by 44.65%-66.88% with the
negligible Bj{\o}ntegaard delta bit-rate (BD-BR) of 1.322%-3.188%, which
significantly outperforms other state-of-the-art approaches.
"
2676,"Comprehensive Information Integration Modeling Framework for Video
  Titling","  In e-commerce, consumer-generated videos, which in general deliver consumers'
individual preferences for the different aspects of certain products, are
massive in volume. To recommend these videos to potential consumers more
effectively, diverse and catchy video titles are critical. However,
consumer-generated videos seldom accompany appropriate titles. To bridge this
gap, we integrate comprehensive sources of information, including the content
of consumer-generated videos, the narrative comment sentences supplied by
consumers, and the product attributes, in an end-to-end modeling framework.
Although automatic video titling is very useful and demanding, it is much less
addressed than video captioning. The latter focuses on generating sentences
that describe videos as a whole while our task requires the product-aware
multi-grained video analysis. To tackle this issue, the proposed method
consists of two processes, i.e., granular-level interaction modeling and
abstraction-level story-line summarization. Specifically, the granular-level
interaction modeling first utilizes temporal-spatial landmark cues, descriptive
words, and abstractive attributes to builds three individual graphs and
recognizes the intra-actions in each graph through Graph Neural Networks (GNN).
Then the global-local aggregation module is proposed to model inter-actions
across graphs and aggregate heterogeneous graphs into a holistic graph
representation. The abstraction-level story-line summarization further
considers both frame-level video features and the holistic graph to utilize the
interactions between products and backgrounds, and generate the story-line
topic of the video. We collect a large-scale dataset accordingly from
real-world data in Taobao, a world-leading e-commerce platform, and will make
the desensitized version publicly available to nourish further development of
the research community...
"
2677,"Fine granularity access in interactive compression of 360-degree images
  based on rate-adaptive channel codes","  In this paper, we propose a new interactive compression scheme for
omnidirectional images. This requires two characteristics: efficient
compression of data, to lower the storage cost, and random access ability to
extract part of the compressed stream requested by the user (for reducing the
transmission rate). For efficient compression, data needs to be predicted by a
series of references that have been pre-defined and compressed. This contrasts
with the spirit of random accessibility. We propose a solution for this problem
based on incremental codes implemented by rate-adaptive channel codes. This
scheme encodes the image while adapting to any user request and leads to an
efficient coding that is flexible in extracting data depending on the available
information at the decoder. Therefore, only the information that is needed to
be displayed at the user's side is transmitted during the user's request, as if
the request was already known at the encoder. The experimental results
demonstrate that our coder obtains a better transmission rate than the
state-of-the-art tile-based methods at a small cost in storage. Moreover, the
transmission rate grows gradually with the size of the request and avoids a
staircase effect, which shows the perfect suitability of our coder for
interactive transmission.
"
2678,Audeo: Audio Generation for a Silent Performance Video,"  We present a novel system that gets as an input video frames of a musician
playing the piano and generates the music for that video. Generation of music
from visual cues is a challenging problem and it is not clear whether it is an
attainable goal at all. Our main aim in this work is to explore the
plausibility of such a transformation and to identify cues and components able
to carry the association of sounds with visual events. To achieve the
transformation we built a full pipeline named `\textit{Audeo}' containing three
components. We first translate the video frames of the keyboard and the
musician hand movements into raw mechanical musical symbolic representation
Piano-Roll (Roll) for each video frame which represents the keys pressed at
each time step. We then adapt the Roll to be amenable for audio synthesis by
including temporal correlations. This step turns out to be critical for
meaningful audio generation. As a last step, we implement Midi synthesizers to
generate realistic music. \textit{Audeo} converts video to audio smoothly and
clearly with only a few setup constraints. We evaluate \textit{Audeo} on `in
the wild' piano performance videos and obtain that their generated music is of
reasonable audio quality and can be successfully recognized with high precision
by popular music identification software.
"
2679,"QoE-Driven UAV-Enabled Pseudo-Analog Wireless Video Broadcast: A Joint
  Optimization of Power and Trajectory","  The explosive demands for high quality mobile video services have caused
heavy overload to the existing cellular networks. Although the small cell has
been proposed to alleviate such a problem, the network operators may not be
interested in deploying numerous base stations (BSs) due to expensive
infrastructure construction and maintenance. The unmanned aerial vehicles
(UAVs) can provide the low-cost and quick deployment, which can support
high-quality line-of-sight communications and have become promising mobile BSs.
In this paper, we propose a quality-of-experience (QoE)-driven UAV-enabled
pseudo-analog wireless video broadcast scheme, which provides mobile video
broadcast services for ground users (GUs). Due to limited energy available in
UAV, the aim of the proposed scheme is to maximize the minimum peak
signal-to-noise ratio (PSNR) of GUs' video reconstruction quality by jointly
optimizing the transmission power allocation strategy and the UAV trajectory.
Firstly, the reconstructed video quality at GUs is defined under the
constraints of the UAV's total energy and motion mechanism, and the proposed
scheme is formulated as a complex non-convex optimization problem. Then, the
optimization problem is simplified to obtain a tractable suboptimal solution
with the help of the block coordinate descent model and the successive convex
approximation model. Finally, the experimental results are presented to show
the effectiveness of the proposed scheme. Specifically, the proposed scheme can
achieve over 1.6dB PSNR gains in terms of GUs' minimum PSNR, compared with the
state-of-the-art schemes, e.g., DVB, SoftCast, and SharpCast.
"
2680,An Advert Creation System for 3D Product Placements,"  Over the past decade, the evolution of video-sharing platforms has attracted
a significant amount of investments on contextual advertising. The common
contextual advertising platforms utilize the information provided by users to
integrate 2D visual ads into videos. The existing platforms face many technical
challenges such as ad integration with respect to occluding objects and 3D ad
placement. This paper presents a Video Advertisement Placement & Integration
(Adverts) framework, which is capable of perceiving the 3D geometry of the
scene and camera motion to blend 3D virtual objects in videos and create the
illusion of reality. The proposed framework contains several modules such as
monocular depth estimation, object segmentation, background-foreground
separation, alpha matting and camera tracking. Our experiments conducted using
Adverts framework indicates the significant potential of this system in
contextual ad integration, and pushing the limits of advertising industry using
mixed reality technologies.
"
2681,Chroma Intra Prediction with attention-based CNN architectures,"  Neural networks can be used in video coding to improve chroma
intra-prediction. In particular, usage of fully-connected networks has enabled
better cross-component prediction with respect to traditional linear models.
Nonetheless, state-of-the-art architectures tend to disregard the location of
individual reference samples in the prediction process. This paper proposes a
new neural network architecture for cross-component intra-prediction. The
network uses a novel attention module to model spatial relations between
reference and predicted samples. The proposed approach is integrated into the
Versatile Video Coding (VVC) prediction pipeline. Experimental results
demonstrate compression gains over the latest VVC anchor compared with
state-of-the-art chroma intra-prediction methods based on neural networks.
"
2682,"A Universal Framework to Construct a Huffman-Code-Mapping-based
  Reversible Data Hiding Scheme for JPEG Images","  Huffman code mapping (HCM) is a recent technique for reversible data hiding
(RDH) in JPEG images. The existing HCM-based RDH schemes cause neither
file-size increment nor visual distortion for the marked JPEG image, which is
the superiority compared to the RDH schemes that use other techniques, such as
histogram shifting (HS). However, the embedding capacity achieved by the
HCM-based RDH schemes is much lower than the HS-based RDH schemes. Moreover,
the existing HCM-based schemes are only applicable to the JPEG images coded
with the default Huffman table. In this paper, we propose a universal framework
to design the HCM-based RDH scheme. Under this framework, the key issue of
HCM-based schemes, i.e., construct the optimal code mapping relationship, is
converted to solve a combinatorial optimization problem. The high embedding
capacity can be achieved with a slight increase in the file-size of the marked
JPEG image. In addition, the problem of applicability is also solved by
customizing the Huffman table. As a realization, we construct a new HCM-based
scheme by employing the genetic algorithm to search the nearly optimal
solution. Experiments show that the performance on the file-size preservation,
visual quality, and computational complexity is superior to recent HS-based RDH
schemes under the identical payload.
"
2683,BitMix: Data Augmentation for Image Steganalysis,"  Convolutional neural networks (CNN) for image steganalysis demonstrate better
performances with employing concepts from high-level vision tasks. The major
employed concept is to use data augmentation to avoid overfitting due to
limited data. To augment data without damaging the message embedding, only
rotating multiples of 90 degrees or horizontally flipping are used in
steganalysis, which generates eight fixed results from one sample. To overcome
this limitation, we propose BitMix, a data augmentation method for spatial
image steganalysis. BitMix mixes a cover and stego image pair by swapping the
random patch and generates an embedding adaptive label with the ratio of the
number of pixels modified in the swapped patch to those in the cover-stego
pair. We explore optimal hyperparameters, the ratio of applying BitMix in the
mini-batch, and the size of the bounding box for swapping patch. The results
reveal that using BitMix improves the performance of spatial image steganalysis
and better than other data augmentation methods.
"
2684,"FVV Live: Real-Time, Low-Cost, Free Viewpoint Video","  FVV Live is a novel real-time, low-latency, end-to-end free viewpoint system
including capture, transmission, synthesis on an edge server and visualization
and control on a mobile terminal. The system has been specially designed for
low-cost and real-time operation, only using off-the-shelf components.
"
2685,"FVV Live: A real-time free-viewpoint video system with consumer
  electronics hardware","  FVV Live is a novel end-to-end free-viewpoint video system, designed for low
cost and real-time operation, based on off-the-shelf components. The system has
been designed to yield high-quality free-viewpoint video using consumer-grade
cameras and hardware, which enables low deployment costs and easy installation
for immersive event-broadcasting or videoconferencing.
  The paper describes the architecture of the system, including acquisition and
encoding of multiview plus depth data in several capture servers and virtual
view synthesis on an edge server. All the blocks of the system have been
designed to overcome the limitations imposed by hardware and network, which
impact directly on the accuracy of depth data and thus on the quality of
virtual view synthesis. The design of FVV Live allows for an arbitrary number
of cameras and capture servers, and the results presented in this paper
correspond to an implementation with nine stereo-based depth cameras.
  FVV Live presents low motion-to-photon and end-to-end delays, which enables
seamless free-viewpoint navigation and bilateral immersive communications.
Moreover, the visual quality of FVV Live has been assessed through subjective
assessment with satisfactory results, and additional comparative tests show
that it is preferred over state-of-the-art DIBR alternatives.
"
2686,"Playback experience driven cross layer optimisation of APP, transport
  and MAC layer for video clients over long-term evolution system","  In traditional communication system, information of APP (Application) layer,
transport layer and MAC (Media Access Control)layer has not been fully
interacted,which inevitably leads to inconsistencies among TCP congestion
state, clients'requirements and resource allocation. To solve the problem, we
propose a joint optimization framework, which consists of APP layer, transport
layer and MAC layer, to improve the video clients'playback experience and
system throughput. First, a client requirement aware autonomous packet drop
strategy, based on packet importance, channel condition and playback status, is
developed to decrease the network load and the probability of rebuffering
events. Further, TCP (Transmission Control Protocol) state aware downlink and
uplink resource allocation schemes are proposed to achieve smooth video
transmission and steady ACK (Acknowledgement) feedback respectively. For
downlink scheme, maximum transmission capacity requirement for each client is
calculated based on feedback ACK information from transport layer to avoid
allocating excessive resource to the client, whose ACK feedback is blocked due
to bad uplink channel condition. For uplink scheme, information of RTO
(Retransmission Timeout) and TCP congestion window are utilized to indicate ACK
scheduling priority. The simulation results show that our algorithm can
signficantly improve the system throughput and the clients'playback continuity
with acceptable video quality.
"
2687,Bayesian Low Rank Tensor Ring Model for Image Completion,"  Low rank tensor ring model is powerful for image completion which recovers
missing entries in data acquisition and transformation. The recently proposed
tensor ring (TR) based completion algorithms generally solve the low rank
optimization problem by alternating least squares method with predefined ranks,
which may easily lead to overfitting when the unknown ranks are set too large
and only a few measurements are available. In this paper, we present a Bayesian
low rank tensor ring model for image completion by automatically learning the
low rank structure of data. A multiplicative interaction model is developed for
the low-rank tensor ring decomposition, where core factors are enforced to be
sparse by assuming their entries obey Student-T distribution. Compared with
most of the existing methods, the proposed one is free of parameter-tuning, and
the TR ranks can be obtained by Bayesian inference. Numerical Experiments,
including synthetic data, color images with different sizes and YaleFace
dataset B with respect to one pose, show that the proposed approach outperforms
state-of-the-art ones, especially in terms of recovery accuracy.
"
2688,"Estimating Blink Probability for Highlight Detection in Figure Skating
  Videos","  Highlight detection in sports videos has a broad viewership and huge
commercial potential. It is thus imperative to detect highlight scenes more
suitably for human interest with high temporal accuracy. Since people
instinctively suppress blinks during attention-grabbing events and
synchronously generate blinks at attention break points in videos, the
instantaneous blink rate can be utilized as a highly accurate temporal
indicator of human interest. Therefore, in this study, we propose a novel,
automatic highlight detection method based on the blink rate. The method trains
a one-dimensional convolution network (1D-CNN) to assess blink rates at each
video frame from the spatio-temporal pose features of figure skating videos.
Experiments show that the method successfully estimates the blink rate in 94%
of the video clips and predicts the temporal change in the blink rate around a
jump event with high accuracy. Moreover, the method detects not only the
representative athletic action, but also the distinctive artistic expression of
figure skating performance as key frames. This suggests that the
blink-rate-based supervised learning approach enables high-accuracy highlight
detection that more closely matches human sensibility.
"
2689,"Quo Vadis, Skeleton Action Recognition ?","  In this paper, we study current and upcoming frontiers across the landscape
of skeleton-based human action recognition. To begin with, we benchmark
state-of-the-art models on the NTU-120 dataset and provide multi-layered
assessment of the results. To examine skeleton action recognition 'in the
wild', we introduce Skeletics-152, a curated and 3-D pose-annotated subset of
RGB videos sourced from Kinetics-700, a large-scale action dataset. The results
from benchmarking the top performers of NTU-120 on Skeletics-152 reveal the
challenges and domain gap induced by actions 'in the wild'. We extend our study
to include out-of-context actions by introducing Skeleton-Mimetics, a dataset
derived from the recently introduced Mimetics dataset. Finally, as a new
frontier for action recognition, we introduce Metaphorics, a dataset with
caption-style annotated YouTube videos of the popular social game Dumb Charades
and interpretative dance performances. Overall, our work characterizes the
strengths and limitations of existing approaches and datasets. It also provides
an assessment of top-performing approaches across a spectrum of activity
settings and via the introduced datasets, proposes new frontiers for human
action recognition.
"
2690,An Integer Approximation Method for Discrete Sinusoidal Transforms,"  Approximate methods have been considered as a means to the evaluation of
discrete transforms. In this work, we propose and analyze a class of integer
transforms for the discrete Fourier, Hartley, and cosine transforms (DFT, DHT,
and DCT), based on simple dyadic rational approximation methods. The introduced
method is general, applicable to several block-lengths, whereas existing
approaches are usually dedicated to specific transform sizes. The suggested
approximate transforms enjoy low multiplicative complexity and the
orthogonality property is achievable via matrix polar decomposition. We show
that the obtained transforms are competitive with archived methods in
literature. New 8-point square wave approximate transforms for the DFT, DHT,
and DCT are also introduced as particular cases of the introduced methodology.
"
2691,"Image Aesthetics Prediction Using Multiple Patches Preserving the
  Original Aspect Ratio of Contents","  The spread of social networking services has created an increasing demand for
selecting, editing, and generating impressive images. This trend increases the
importance of evaluating image aesthetics as a complementary function of
automatic image processing. We propose a multi-patch method, named MPA-Net
(Multi-Patch Aggregation Network), to predict image aesthetics scores by
maintaining the original aspect ratios of contents in the images. Through an
experiment involving the large-scale AVA dataset, which contains 250,000
images, we show that the effectiveness of the equal-interval multi-patch
selection approach for aesthetics score prediction is significant compared to
the single-patch prediction and random patch selection approaches. For this
dataset, MPA-Net outperforms the neural image assessment algorithm, which was
regarded as a baseline method. In particular, MPA-Net yields a 0.073 (11.5%)
higher linear correlation coefficient (LCC) of aesthetics scores and a 0.088
(14.4%) higher Spearman's rank correlation coefficient (SRCC). MPA-Net also
reduces the mean square error (MSE) by 0.0115 (4.18%) and achieves results for
the LCC and SRCC that are comparable to those of the state-of-the-art
continuous aesthetics score prediction methods. Most notably, MPA-Net yields a
significant lower MSE especially for images with aspect ratios far from 1.0,
indicating that MPA-Net is useful for a wide range of image aspect ratios.
MPA-Net uses only images and does not require external information during the
training nor prediction stages. Therefore, MPA-Net has great potential for
applications aside from aesthetics score prediction such as other human
subjectivity prediction.
"
2692,Deep Convolutional Neural Network for Identifying Seam-Carving Forgery,"  Seam carving is a representative content-aware image retargeting approach to
adjust the size of an image while preserving its visually prominent content. To
maintain visually important content, seam-carving algorithms first calculate
the connected path of pixels, referred to as the seam, according to a defined
cost function and then adjust the size of an image by removing and duplicating
repeatedly calculated seams. Seam carving is actively exploited to overcome
diversity in the resolution of images between applications and devices; hence,
detecting the distortion caused by seam carving has become important in image
forensics. In this paper, we propose a convolutional neural network (CNN)-based
approach to classifying seam-carving-based image retargeting for reduction and
expansion. To attain the ability to learn low-level features, we designed a CNN
architecture comprising five types of network blocks specialized for capturing
subtle signals. An ensemble module is further adopted to both enhance
performance and comprehensively analyze the features in the local areas of the
given image. To validate the effectiveness of our work, extensive experiments
based on various CNN-based baselines were conducted. Compared to the baselines,
our work exhibits state-of-the-art performance in terms of three-class
classification (original, seam inserted, and seam removed). In addition, our
model with the ensemble module is robust for various unseen cases. The
experimental results also demonstrate that our method can be applied to
localize both seam-removed and seam-inserted areas.
"
2693,"An Automated and Robust Image Watermarking Scheme Based on Deep Neural
  Networks","  Digital image watermarking is the process of embedding and extracting a
watermark covertly on a cover-image. To dynamically adapt image watermarking
algorithms, deep learning-based image watermarking schemes have attracted
increased attention during recent years. However, existing deep learning-based
watermarking methods neither fully apply the fitting ability to learn and
automate the embedding and extracting algorithms, nor achieve the properties of
robustness and blindness simultaneously. In this paper, a robust and blind
image watermarking scheme based on deep learning neural networks is proposed.
To minimize the requirement of domain knowledge, the fitting ability of deep
neural networks is exploited to learn and generalize an automated image
watermarking algorithm. A deep learning architecture is specially designed for
image watermarking tasks, which will be trained in an unsupervised manner to
avoid human intervention and annotation. To facilitate flexible applications,
the robustness of the proposed scheme is achieved without requiring any prior
knowledge or adversarial examples of possible attacks. A challenging case of
watermark extraction from phone camera-captured images demonstrates the
robustness and practicality of the proposal. The experiments, evaluation, and
application cases confirm the superiority of the proposed scheme.
"
2694,Cost-Efficient Storage for On-Demand Video Streaming on Cloud,"  Video stream is converted to several formats to support the user's device,
this conversion process is called video transcoding, which imposes high storage
and powerful resources. With emerging of cloud technology, video stream
companies adopted to process video on the cloud. Generally, many formats of the
same video are made (pre-transcoded) and streamed to the adequate user's
device. However, pre-transcoding demands huge storage space and incurs a
high-cost to the video stream companies. More importantly, the pre-transcoding
of video streams could be hierarchy carried out through different storage types
in the cloud. To minimize the storage cost, in this paper, we propose a method
to store video streams in the hierarchical storage of the cloud. Particularly,
we develop a method to decide which video stream should be pre-transcoded in
its suitable cloud storage to minimize the overall cost. Experimental
simulation and results show the effectiveness of our approach, specifically,
when the percentage of frequently accessed videos is high in repositories, the
proposed approach minimizes the overall cost by up to 40 percent.
"
2695,Smartphone-based Wellness Assessment Using Mobile Environmental Sensor,"  Mental health and general wellness are becoming a growing concern in our
society. Environmental factors contribute to mental illness and have the power
to affect a person's wellness. This work presents a smartphone-based wellness
assessment system and examines if there is any correlation with one's
environment and their wellness. The introduced system was initiated in response
to a growing need for individualized and independent mental health care and
evaluated through experimentation. The participants were given an Android
smartphone and a mobile sensor board and they were asked to complete a brief
psychological survey three times per day. During the survey completion, the
board in their possession is reading environmental data. The five environmental
variables collected are temperature, humidity, air pressure, luminosity, and
noise level. Upon submission of the survey, the results of the survey and the
environmental data are sent to a server for further processing. Three
experiments with 62 participants in total have been completed. The correlation
most regularly deemed statistically significant was that of light and audio and
stress.
"
2696,Real-time Semantic Segmentation with Fast Attention,"  In deep CNN based models for semantic segmentation, high accuracy relies on
rich spatial context (large receptive fields) and fine spatial details (high
resolution), both of which incur high computational costs. In this paper, we
propose a novel architecture that addresses both challenges and achieves
state-of-the-art performance for semantic segmentation of high-resolution
images and videos in real-time. The proposed architecture relies on our fast
spatial attention, which is a simple yet efficient modification of the popular
self-attention mechanism and captures the same rich spatial context at a small
fraction of the computational cost, by changing the order of operations.
Moreover, to efficiently process high-resolution input, we apply an additional
spatial reduction to intermediate feature stages of the network with minimal
loss in accuracy thanks to the use of the fast attention module to fuse
features. We validate our method with a series of experiments, and show that
results on multiple datasets demonstrate superior performance with better
accuracy and speed compared to existing approaches for real-time semantic
segmentation. On Cityscapes, our network achieves 74.4$\%$ mIoU at 72 FPS and
75.5$\%$ mIoU at 58 FPS on a single Titan X GPU, which is~$\sim$50$\%$ faster
than the state-of-the-art while retaining the same accuracy.
"
2697,"Reversible data hiding in encrypted images based on pixel prediction and
  multi-MSB planes rearrangement","  Great concern has arisen in the field of reversible data hiding in encrypted
images (RDHEI) due to the development of cloud storage and privacy protection.
RDHEI is an effective technology that can embed additional data after image
encryption, extract additional data error-free and reconstruct original images
losslessly. In this paper, a high-capacity and fully reversible RDHEI method
based on pixel prediction and multi-MSB (most significant bit) planes
rearrangement is proposed. First, the median edge detector (MED) predictor is
used to calculate the predicted value. Next, unlike previous methods, in our
proposed method, signs of prediction errors (PEs) are represented by one bit
plane and absolute values of PEs are represented by other bit planes. Then, we
divide bit planes into uniform blocks and non-uniform blocks, and rearrange
these blocks. Finally, according to different pixel prediction schemes,
different number of additional data are embedded adaptively. The experimental
results prove that our method has higher embedding capacity compared with
state-of-the-art RDHEI methods.
"
2698,"Reversible Data Hiding in Encrypted Images Based on Bit plane
  Compression of Prediction Error","  As a technology that can prevent the information of original image and
additional information from being disclosed, the reversible data hiding in
encrypted images (RDHEI) has been widely concerned by researchers. How to
further improve the performance of RDHEI methods has become a focus of
research. To this end, this work proposes a high-capacity RDHEI method based on
bit plane compression of prediction error. Firstly, to reserve the room for
embedding information, the image owner rearranges and compresses the bit plane
of prediction error. Next, the image after reserving room is encrypted with a
serect key. Finally, the information hiding device embeds the additional
information into the reserved room. This paper makes full use of the
correlation between adjacent pixels. Experimental results show that this method
can realize the real reversibility and provide higher embedding capacity than
state-of-the-art works.
"
2699,"Learning Speech Representations from Raw Audio by Joint Audiovisual
  Self-Supervision","  The intuitive interaction between the audio and visual modalities is valuable
for cross-modal self-supervised learning. This concept has been demonstrated
for generic audiovisual tasks like video action recognition and acoustic scene
classification. However, self-supervision remains under-explored for
audiovisual speech. We propose a method to learn self-supervised speech
representations from the raw audio waveform. We train a raw audio encoder by
combining audio-only self-supervision (by predicting informative audio
attributes) with visual self-supervision (by generating talking faces from
audio). The visual pretext task drives the audio representations to capture
information related to lip movements. This enriches the audio encoder with
visual information and the encoder can be used for evaluation without the
visual modality. Our method attains competitive performance with respect to
existing self-supervised audio features on established isolated word
classification benchmarks, and significantly outperforms other methods at
learning from fewer labels. Notably, our method also outperforms fully
supervised training, thus providing a strong initialization for speech related
tasks. Our results demonstrate the potential of multimodal self-supervision in
audiovisual speech for learning good audio representations.
"
2700,"Multi-task Regularization Based on Infrequent Classes for Audio
  Captioning","  Audio captioning is a multi-modal task, focusing on using natural language
for describing the contents of general audio. Most audio captioning methods are
based on deep neural networks, employing an encoder-decoder scheme and a
dataset with audio clips and corresponding natural language descriptions (i.e.
captions). A significant challenge for audio captioning is the distribution of
words in the captions: some words are very frequent but acoustically
non-informative, i.e. the function words (e.g. ""a"", ""the""), and other words are
infrequent but informative, i.e. the content words (e.g. adjectives, nouns). In
this paper we propose two methods to mitigate this class imbalance problem.
First, in an autoencoder setting for audio captioning, we weigh each word's
contribution to the training loss inversely proportional to its number of
occurrences in the whole dataset. Secondly, in addition to multi-class,
word-level audio captioning task, we define a multi-label side task based on
clip-level content word detection by training a separate decoder. We use the
loss from the second task to regularize the jointly trained encoder for the
audio captioning task. We evaluate our method using Clotho, a recently
published, wide-scale audio captioning dataset, and our results show an
increase of 37\% relative improvement with SPIDEr metric over the baseline
method.
"
2701,"$\ell_1$SABMIS: $\ell_1$-minimization and sparse approximation based
  blind multi-image steganography scheme","  Steganography plays a vital role in achieving secret data security by
embedding it into cover media. The cover media and the secret data can be text
or multimedia, such as images, videos, etc. In this paper, we propose a novel
$\ell_1$-minimization and sparse approximation based blind multi-image
steganography scheme, termed $\ell_1$SABMIS. By using $\ell_1$SABMIS, multiple
secret images can be hidden in a single cover image. In $\ell_1$SABMIS, we
sampled cover image into four sub-images, sparsify each sub-image block-wise,
and then obtain linear measurements. Next, we obtain DCT (Discrete Cosine
Transform) coefficients of the secret images and then embed them into the cover
image\textquotesingle s linear measurements.
  We perform experiments on several standard gray-scale images, and evaluate
embedding capacity, PSNR (peak signal-to-noise ratio) value, mean SSIM
(structural similarity) index, NCC (normalized cross-correlation) coefficient,
NAE (normalized absolute error), and entropy. The value of these assessment
metrics indicates that $\ell_1$SABMIS outperforms similar existing
steganography schemes. That is, we successfully hide more than two secret
images in a single cover image without degrading the cover image significantly.
Also, the extracted secret images preserve good visual quality, and
$\ell_1$SABMIS is resistant to steganographic attack.
"
2702,"Fast Griffin Lim based Waveform Generation Strategy for Text-to-Speech
  Synthesis","  The performance of text-to-speech (TTS) systems heavily depends on
spectrogram to waveform generation, also known as the speech reconstruction
phase. The time required for the same is known as synthesis delay. In this
paper, an approach to reduce speech synthesis delay has been proposed. It aims
to enhance the TTS systems for real-time applications such as digital
assistants, mobile phones, embedded devices, etc. The proposed approach applies
Fast Griffin Lim Algorithm (FGLA) instead Griffin Lim algorithm (GLA) as
vocoder in the speech synthesis phase. GLA and FGLA are both iterative, but the
convergence rate of FGLA is faster than GLA. The proposed approach is tested on
LJSpeech, Blizzard and Tatoeba datasets and the results for FGLA are compared
against GLA and neural Generative Adversarial Network (GAN) based vocoder. The
performance is evaluated based on synthesis delay and speech quality. A 36.58%
reduction in speech synthesis delay has been observed. The quality of the
output speech has improved, which is advocated by higher Mean opinion scores
(MOS) and faster convergence with FGLA as opposed to GLA.
"
2703,"Knowledge Graph Driven Approach to Represent Video Streams for
  Spatiotemporal Event Pattern Matching in Complex Event Processing","  Complex Event Processing (CEP) is an event processing paradigm to perform
real-time analytics over streaming data and match high-level event patterns.
Presently, CEP is limited to process structured data stream. Video streams are
complicated due to their unstructured data model and limit CEP systems to
perform matching over them. This work introduces a graph-based structure for
continuous evolving video streams, which enables the CEP system to query
complex video event patterns. We propose the Video Event Knowledge Graph
(VEKG), a graph driven representation of video data. VEKG models video objects
as nodes and their relationship interaction as edges over time and space. It
creates a semantic knowledge representation of video data derived from the
detection of high-level semantic concepts from the video using an ensemble of
deep learning models. A CEP-based state optimization - VEKG-Time Aggregated
Graph (VEKG-TAG) is proposed over VEKG representation for faster event
detection. VEKG-TAG is a spatiotemporal graph aggregation method that provides
a summarized view of the VEKG graph over a given time length. We defined a set
of nine event pattern rules for two domains (Activity Recognition and Traffic
Management), which act as a query and applied over VEKG graphs to discover
complex event patterns. To show the efficacy of our approach, we performed
extensive experiments over 801 video clips across 10 datasets. The proposed
VEKG approach was compared with other state-of-the-art methods and was able to
detect complex event patterns over videos with F-Score ranging from 0.44 to
0.90. In the given experiments, the optimized VEKG-TAG was able to reduce 99%
and 93% of VEKG nodes and edges, respectively, with 5.19X faster search time,
achieving sub-second median latency of 4-20 milliseconds.
"
2704,QUALINET White Paper on Definitions of Immersive Media Experience (IMEx),"  With the coming of age of virtual/augmented reality and interactive media,
numerous definitions, frameworks, and models of immersion have emerged across
different fields ranging from computer graphics to literary works. Immersion is
oftentimes used interchangeably with presence as both concepts are closely
related. However, there are noticeable interdisciplinary differences regarding
definitions, scope, and constituents that are required to be addressed so that
a coherent understanding of the concepts can be achieved. Such consensus is
vital for paving the directionality of the future of immersive media
experiences (IMEx) and all related matters.
  The aim of this white paper is to provide a survey of definitions of
immersion and presence which leads to a definition of immersive media
experience (IMEx). The Quality of Experience (QoE) for immersive media is
described by establishing a relationship between the concepts of QoE and IMEx
followed by application areas of immersive media experience. Influencing
factors on immersive media experience are elaborated as well as the assessment
of immersive media experience. Finally, standardization activities related to
IMEx are highlighted and the white paper is concluded with an outlook related
to future developments.
"
2705,MFRNet: A New CNN Architecture for Post-Processing and In-loop Filtering,"  In this paper, we propose a novel convolutional neural network (CNN)
architecture, MFRNet, for post-processing (PP) and in-loop filtering (ILF) in
the context of video compression. This network consists of four Multi-level
Feature review Residual dense Blocks (MFRBs), which are connected using a
cascading structure. Each MFRB extracts features from multiple convolutional
layers using dense connections and a multi-level residual learning structure.
In order to further improve information flow between these blocks, each of them
also reuses high dimensional features from the previous MFRB. This network has
been integrated into PP and ILF coding modules for both HEVC (HM 16.20) and VVC
(VTM 7.0), and fully evaluated under the JVET Common Test Conditions using the
Random Access configuration. The experimental results show significant and
consistent coding gains over both anchor codecs (HEVC HM and VVC VTM) and also
over other existing CNN-based PP/ILF approaches based on Bjontegaard Delta
measurements using both PSNR and VMAF for quality assessment. When MFRNet is
integrated into HM 16.20, gains up to 16.0% (BD-rate VMAF) are demonstrated for
ILF, and up to 21.0% (BD-rate VMAF) for PP. The respective gains for VTM 7.0
are up to 5.1% for ILF and up to 7.1% for PP.
"
2706,"Transformer-XL Based Music Generation with Multiple Sequences of
  Time-valued Notes","  Current state-of-the-art AI based classical music creation algorithms such as
Music Transformer are trained by employing single sequence of notes with
time-shifts. The major drawback of absolute time interval expression is the
difficulty of similarity computing of notes that share the same note value yet
different tempos, in one or among MIDI files. In addition, the usage of single
sequence restricts the model to separately and effectively learn music
information such as harmony and rhythm. In this paper, we propose a framework
with two novel methods to respectively track these two shortages, one is the
construction of time-valued note sequences that liberate note values from
tempos and the other is the separated usage of four sequences, namely, former
note on to current note on, note on to note off, pitch, and velocity, for
jointly training of four Transformer-XL networks. Through training on a 23-hour
piano MIDI dataset, our framework generates significantly better and hour-level
longer music than three state-of-the-art baselines, namely Music Transformer,
DeepJ, and single sequence-based Transformer-XL, evaluated automatically and
manually.
"
2707,"VidCEP: Complex Event Processing Framework to Detect Spatiotemporal
  Patterns in Video Streams","  Video data is highly expressive and has traditionally been very difficult for
a machine to interpret. Querying event patterns from video streams is
challenging due to its unstructured representation. Middleware systems such as
Complex Event Processing (CEP) mine patterns from data streams and send
notifications to users in a timely fashion. Current CEP systems have inherent
limitations to query video streams due to their unstructured data model and
lack of expressive query language. In this work, we focus on a CEP framework
where users can define high-level expressive queries over videos to detect a
range of spatiotemporal event patterns. In this context, we propose: i) VidCEP,
an in-memory, on the fly, near real-time complex event matching framework for
video streams. The system uses a graph-based event representation for video
streams which enables the detection of high-level semantic concepts from video
using cascades of Deep Neural Network models, ii) a Video Event Query language
(VEQL) to express high-level user queries for video streams in CEP, iii) a
complex event matcher to detect spatiotemporal video event patterns by matching
expressive user queries over video data. The proposed approach detects
spatiotemporal video event patterns with an F-score ranging from 0.66 to 0.89.
VidCEP maintains near real-time performance with an average throughput of 70
frames per second for 5 parallel videos with sub-second matching latency.
"
2708,"Robust adaptive steganography based on dither modulation and
  modification with re-compression","  Traditional adaptive steganography is a technique used for covert
communication with high security, but the scheme is invalid in the case of
stego image is damaged by lossy channels, such as JPEG compression of channels.
To deal with such problem, robust adaptive steganography is proposed to enable
the receiver to extract the secret message from the damaged stego image.
Previous works utilise reverse engineering and compression-resistant domain
constructing to implement robust adaptive steganography. In this paper, we
adopt modification with re-compression in embedding scheme to improve the
robustness of stego sequences. To balance security and robustness, we move the
embedding domain to the low frequency region to improve the security of robust
adaptive steganography. In addition, we add an additional check code to further
reduce the average extraction error rate based on the framework of E-DMAS
(Enhancing Dither Modulation based robust Adaptive Steganography). Compared
with GMAS (Generalized dither Modulation based robust Adaptive Steganography)
and E-DMAS, Experiments show that our scheme can achieve strong robustness and
improve the security of robust adaptive steganography greatly when the channel
quality factor is known.
"
2709,"A Case Study on Video Color Transfer: Exploring User Motivations,
  Expectations, and Satisfaction","  Multimedia and creativity software products are being used to edit and
control various elements of creative media practices. These days, the technical
affordances of mobile multimedia devices and the advent of high-speed 5G
internet access mean that these abilities are simpler and more readily
available to be harnessed by mobile applications. In this paper, using a
prototype application, we discuss how potential users of such technology are
motivated to use a video recoloring application and explore the role that user
expectation and satisfaction play in this process. By exploring this topic and
focusing on the human-computer interaction, we found that color transfer
interactions are driven by several intrinsic motivations and that user
expectations and satisfaction ratings can be maintained via clear
visualizations of the processes to be undertaken. Furthermore, we reveal the
specific language that users use to communicate video recoloring when regarding
user motivations, expectations, and satisfaction. This research provides
important information for developers of state-of-art recoloring processes and
contributes to dialogues surrounding the users of mobile multimedia technology
in practice.
"
2710,"Full Quaternion Representation of Color images: A Case Study on
  QSVD-based Color Image Compression","  For many years, channels of a color image have been processed individually,
or the image has been converted to grayscale one with respect to color image
processing. Pure quaternion representation of color images solves this issue as
it allows images to be processed in a holistic space. Nevertheless, it brings
additional costs due to the extra fourth dimension. In this paper, we propose
an approach for representing color images with full quaternion numbers that
enables us to process color images holistically without additional cost in
time, space and computation. With taking auto- and cross-correlation of color
channels into account, an autoencoder neural network is used to generate a
global model for transforming a color image into a full quaternion matrix. To
evaluate the model, we use UCID dataset, and the results indicate that the
model has an acceptable performance on color images. Moreover, we propose a
compression method based on the generated model and QSVD as a case study. The
method is compared with the same compression method using pure quaternion
representation and is assessed with UCID dataset. The results demonstrate that
the compression method using the proposed full quaternion representation fares
better than the other in terms of time, quality, and size of compressed files.
"
2711,"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating
  Source Separation","  Stereophonic audio is an indispensable ingredient to enhance human auditory
experience. Recent research has explored the usage of visual information as
guidance to generate binaural or ambisonic audio from mono ones with stereo
supervision. However, this fully supervised paradigm suffers from an inherent
drawback: the recording of stereophonic audio usually requires delicate devices
that are expensive for wide accessibility. To overcome this challenge, we
propose to leverage the vastly available mono data to facilitate the generation
of stereophonic audio. Our key observation is that the task of visually
indicated audio separation also maps independent audios to their corresponding
visual positions, which shares a similar objective with stereophonic audio
generation. We integrate both stereo generation and source separation into a
unified framework, Sep-Stereo, by considering source separation as a particular
type of audio spatialization. Specifically, a novel associative pyramid network
architecture is carefully designed for audio-visual feature fusion. Extensive
experiments demonstrate that our framework can improve the stereophonic audio
generation results while performing accurate sound separation with a shared
backbone.
"
2712,"It's LeVAsa not LevioSA! Latent Encodings for Valence-Arousal Structure
  Alignment","  In recent years, great strides have been made in the field of affective
computing. Several models have been developed to represent and quantify
emotions. Two popular ones include (i) categorical models which represent
emotions as discrete labels, and (ii) dimensional models which represent
emotions in a Valence-Arousal (VA) circumplex domain. However, there is no
standard for annotation mapping between the two labelling methods. We build a
novel algorithm for mapping categorical and dimensional model labels using
annotation transfer across affective facial image datasets. Further, we utilize
the transferred annotations to learn rich and interpretable data
representations using a variational autoencoder (VAE). We present ""LeVAsa"", a
VAE model that learns implicit structure by aligning the latent space with the
VA space. We evaluate the efficacy of LeVAsa by comparing performance with the
Vanilla VAE using quantitative and qualitative analysis on two benchmark
affective image datasets. Our results reveal that LeVAsa achieves high
latent-circumplex alignment which leads to improved downstream categorical
emotion prediction. The work also demonstrates the trade-off between degree of
alignment and quality of reconstructions.
"
2713,"Multispectral Pan-sharpening via Dual-Channel Convolutional Network with
  Convolutional LSTM Based Hierarchical Spatial-Spectral Feature Fusion","  Multispectral pan-sharpening aims at producing a high resolution (HR)
multispectral (MS) image in both spatial and spectral domains by fusing a
panchromatic (PAN) image and a corresponding MS image. In this paper, we
propose a novel dual-channel network (DCNet) framework for MS pan-sharpening.
In our DCNet, the dual-channel backbone involves a spatial channel to capture
spatial information with a 2D CNN, and a spectral channel to extract spectral
information with a 3D CNN. This heterogeneous 2D/3D CNN architecture can
minimize causing spectral information distortion, which typically happens in
conventional 2D CNN models. In order to fully integrate the spatial and
spectral features captured from different levels, we introduce a multi-level
fusion strategy. Specifically, a spatial-spectral CLSTM (S$^2$-CLSTM) module is
proposed for fusing the hierarchical spatial and spectral features, which can
effectively capture correlations among multi-level features. The S$^2$-CLSTM
module attaches two fusion ways: the intra-level fusion via bi-directional
lateral connections and inter-level fusion via the cell state in the
S$^2$-CLSTM. Finally, the ideal HR-MS image is recovered by a reconstruction
module. Extensive experiments have been conducted at both simulated lower scale
and the original scale of real-world datasets. Compared with the
state-of-the-art methods, the proposed DCNet achieves superior or competitive
performance.
"
2714,"Local Geometric Distortions Resilient Watermarking Scheme Based on
  Symmetry","  As an efficient watermark attack method, geometric distortions destroy the
synchronization between watermark encoder and decoder. And the local geometric
distortion is a famous challenge in the watermark field. Although a lot of
geometric distortions resilient watermarking schemes have been proposed, few of
them perform well against local geometric distortion like random bending attack
(RBA). To address this problem, this paper proposes a novel watermark
synchronization process and the corresponding watermarking scheme. In our
scheme, the watermark bits are represented by random patterns. The message is
encoded to get a watermark unit, and the watermark unit is flipped to generate
a symmetrical watermark. Then the symmetrical watermark is embedded into the
spatial domain of the host image in an additive way. In watermark extraction,
we first get the theoretically mean-square error minimized estimation of the
watermark. Then the auto-convolution function is applied to this estimation to
detect the symmetry and get a watermark units map. According to this map, the
watermark can be accurately synchronized, and then the extraction can be done.
Experimental results demonstrate the excellent robustness of the proposed
watermarking scheme to local geometric distortions, global geometric
distortions, common image processing operations, and some kinds of combined
attacks.
"
2715,"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video
  Parsing","  In this paper, we introduce a new problem, named audio-visual video parsing,
which aims to parse a video into temporal event segments and label them as
either audible, visible, or both. Such a problem is essential for a complete
understanding of the scene depicted inside a video. To facilitate exploration,
we collect a Look, Listen, and Parse (LLP) dataset to investigate audio-visual
video parsing in a weakly-supervised manner. This task can be naturally
formulated as a Multimodal Multiple Instance Learning (MMIL) problem.
Concretely, we propose a novel hybrid attention network to explore unimodal and
cross-modal temporal contexts simultaneously. We develop an attentive MMIL
pooling method to adaptively explore useful audio and visual content from
different temporal extent and modalities. Furthermore, we discover and mitigate
modality bias and noisy label issues with an individual-guided learning
mechanism and label smoothing technique, respectively. Experimental results
show that the challenging audio-visual video parsing can be achieved even with
only video-level weak labels. Our proposed framework can effectively leverage
unimodal and cross-modal temporal contexts and alleviate modality bias and
noisy labels problems.
"
2716,Fine-Grained Image Captioning with Global-Local Discriminative Objective,"  Significant progress has been made in recent years in image captioning, an
active topic in the fields of vision and language. However, existing methods
tend to yield overly general captions and consist of some of the most frequent
words/phrases, resulting in inaccurate and indistinguishable descriptions (see
Figure 1). This is primarily due to (i) the conservative characteristic of
traditional training objectives that drives the model to generate correct but
hardly discriminative captions for similar images and (ii) the uneven word
distribution of the ground-truth captions, which encourages generating highly
frequent words/phrases while suppressing the less frequent but more concrete
ones. In this work, we propose a novel global-local discriminative objective
that is formulated on top of a reference model to facilitate generating
fine-grained descriptive captions. Specifically, from a global perspective, we
design a novel global discriminative constraint that pulls the generated
sentence to better discern the corresponding image from all others in the
entire dataset. From the local perspective, a local discriminative constraint
is proposed to increase attention such that it emphasizes the less frequent but
more concrete words/phrases, thus facilitating the generation of captions that
better describe the visual details of the given images. We evaluate the
proposed method on the widely used MS-COCO dataset, where it outperforms the
baseline methods by a sizable margin and achieves competitive performance over
existing leading approaches. We also conduct self-retrieval experiments to
demonstrate the discriminability of the proposed method.
"
2717,"Towards Multimodal MIR: Predicting individual differences from
  music-induced movement","  As the field of Music Information Retrieval grows, it is important to take
into consideration the multi-modality of music and how aspects of musical
engagement such as movement and gesture might be taken into account. Bodily
movement is universally associated with music and reflective of important
individual features related to music preference such as personality, mood, and
empathy. Future multimodal MIR systems may benefit from taking these aspects
into account. The current study addresses this by identifying individual
differences, specifically Big Five personality traits, and scores on the
Empathy and Systemizing Quotients (EQ/SQ) from participants' free dance
movements. Our model successfully explored the unseen space for personality as
well as EQ, SQ, which has not previously been accomplished for the latter. R2
scores for personality, EQ, and SQ were 76.3%, 77.1%, and 86.7% respectively.
As a follow-up, we investigated which bodily joints were most important in
defining these traits. We discuss how further research may explore how the
mapping of these traits to movement patterns can be used to build a more
personalized, multi-modal recommendation system, as well as potential
therapeutic applications.
"
2718,Interpolating GANs to Scaffold Autotelic Creativity,"  The latent space modeled by generative adversarial networks (GANs) represents
a large possibility space. By interpolating categories generated by GANs, it is
possible to create novel hybrid images. We present ""Meet the Ganimals,"" a
casual creator built on interpolations of BigGAN that can generate novel,
hybrid animals called ganimals by efficiently searching this possibility space.
Like traditional casual creators, the system supports a simple creative flow
that encourages rapid exploration of the possibility space. Users can discover
new ganimals, create their own, and share their reactions to aesthetic,
emotional, and morphological characteristics of the ganimals. As users provide
input to the system, the system adapts and changes the distribution of
categories upon which ganimals are generated. As one of the first GAN-based
casual creators, Meet the Ganimals is an example how casual creators can
leverage human curation and citizen science to discover novel artifacts within
a large possibility space.
"
2719,"Towards Social & Engaging Peer Learning: Predicting Backchanneling and
  Disengagement in Children","  Social robots and interactive computer applications have the potential to
foster early language development in young children by acting as peer learning
companions. However, studies have found that children only trust robots which
behave in a natural and interpersonal manner. To help robots come across as
engaging and attentive peer learning companions, we develop models to predict
whether the listener will lose attention (Listener Disengagement Prediction,
LDP) and the extent to which a robot should generate backchanneling responses
(Backchanneling Extent Prediction, BEP) in the next few seconds. We pose LDP
and BEP as time series classification problems and conduct several experiments
to assess the impact of different time series characteristics and feature sets
on the predictive performance of our model. Using statistics & machine
learning, we also examine which socio-demographic factors influence the amount
of time children spend backchanneling and listening to their peers. To lend
interpretability to our models, we also analyzed critical features responsible
for their predictive performance. Our experiments revealed the utility of
multimodal features such as pupil dilation, blink rate, head movements, facial
action units which have never been used before. We also found that the dynamics
of time series features are rich predictors of listener disengagement and
backchanneling.
"
2720,Subjective and Objective Quality Assessment of High Frame Rate Videos,"  High frame rate (HFR) videos are becoming increasingly common with the
tremendous popularity of live, high-action streaming content such as sports.
Although HFR contents are generally of very high quality, high bandwidth
requirements make them challenging to deliver efficiently, while simultaneously
maintaining their quality. To optimize trade-offs between bandwidth
requirements and video quality, in terms of frame rate adaptation, it is
imperative to understand the intricate relationship between frame rate and
perceptual video quality. Towards advancing progression in this direction we
designed a new subjective resource, called the LIVE-YouTube-HFR (LIVE-YT-HFR)
dataset, which is comprised of 480 videos having 6 different frame rates,
obtained from 16 diverse contents. In order to understand the combined effects
of compression and frame rate adjustment, we also processed videos at 5
compression levels at each frame rate. To obtain subjective labels on the
videos, we conducted a human study yielding 19,000 human quality ratings
obtained from a pool of 85 human subjects. We also conducted a holistic
evaluation of existing state-of-the-art Full and No-Reference video quality
algorithms, and statistically benchmarked their performance on the new
database. The LIVE-YT-HFR database has been made available online for public
use and evaluation purposes, with hopes that it will help advance research in
this exciting video technology direction. It may be obtained at
\url{https://live.ece.utexas.edu/research/LIVE_YT_HFR/LIVE_YT_HFR/index.html}
"
2721,SBAT: Video Captioning with Sparse Boundary-Aware Transformer,"  In this paper, we focus on the problem of applying the transformer structure
to video captioning effectively. The vanilla transformer is proposed for
uni-modal language generation task such as machine translation. However, video
captioning is a multimodal learning problem, and the video features have much
redundancy between different time steps. Based on these concerns, we propose a
novel method called sparse boundary-aware transformer (SBAT) to reduce the
redundancy in video representation. SBAT employs boundary-aware pooling
operation for scores from multihead attention and selects diverse features from
different scenarios. Also, SBAT includes a local correlation scheme to
compensate for the local information loss brought by sparse operation. Based on
SBAT, we further propose an aligned cross-modal encoding scheme to boost the
multimodal interaction. Experimental results on two benchmark datasets show
that SBAT outperforms the state-of-the-art methods under most of the metrics.
"
2722,"Tag2Risk: Harnessing Social Music Tags for Characterizing Depression
  Risk","  Musical preferences have been considered a mirror of the self. In this age of
Big Data, online music streaming services allow us to capture ecologically
valid music listening behavior and provide a rich source of information to
identify several user-specific aspects. Studies have shown musical engagement
to be an indirect representation of internal states including internalized
symptomatology and depression. The current study aims at unearthing patterns
and trends in the individuals at risk for depression as it manifests in
naturally occurring music listening behavior. Mental well-being scores, musical
engagement measures, and listening histories of Last.fm users (N=541) were
acquired. Social tags associated with each listener's most popular tracks were
analyzed to unearth the mood/emotions and genres associated with the users.
Results revealed that social tags prevalent in the users at risk for depression
were predominantly related to emotions depicting Sadness associated with genre
tags representing neo-psychedelic-, avant garde-, dream-pop. This study will
open up avenues for an MIR-based approach to characterizing and predicting risk
for depression which can be helpful in early detection and additionally provide
bases for designing music recommendations accordingly.
"
2723,"Rethinking Generative Zero-Shot Learning: An Ensemble Learning
  Perspective for Recognising Visual Patches","  Zero-shot learning (ZSL) is commonly used to address the very pervasive
problem of predicting unseen classes in fine-grained image classification and
other tasks. One family of solutions is to learn synthesised unseen visual
samples produced by generative models from auxiliary semantic information, such
as natural language descriptions. However, for most of these models,
performance suffers from noise in the form of irrelevant image backgrounds.
Further, most methods do not allocate a calculated weight to each semantic
patch. Yet, in the real world, the discriminative power of features can be
quantified and directly leveraged to improve accuracy and reduce computational
complexity. To address these issues, we propose a novel framework called
multi-patch generative adversarial nets (MPGAN) that synthesises local patch
features and labels unseen classes with a novel weighted voting strategy. The
process begins by generating discriminative visual features from noisy text
descriptions for a set of predefined local patches using multiple specialist
generative models. The features synthesised from each patch for unseen classes
are then used to construct an ensemble of diverse supervised classifiers, each
corresponding to one local patch. A voting strategy averages the probability
distributions output from the classifiers and, given that some patches are more
discriminative than others, a discrimination-based attention mechanism helps to
weight each patch accordingly. Extensive experiments show that MPGAN has
significantly greater accuracy than state-of-the-art methods.
"
2724,Ari: The Automated R Instructor,"  We present the ari package for automatically generating technology-focused
educational videos. The goal of the package is to create reproducible videos,
with the ability to change and update video content seamlessly. We present
several examples of generating videos including using R Markdown slide decks,
PowerPoint slides, or simple images as source material. We also discuss how ari
can help instructors reach new audiences through programmatically translating
materials into other languages.
"
2725,Kalman Filter-based Head Motion Prediction for Cloud-based Mixed Reality,"  Volumetric video allows viewers to experience highly-realistic 3D content
with six degrees of freedom in mixed reality (MR) environments. Rendering
complex volumetric videos can require a prohibitively high amount of
computational power for mobile devices. A promising technique to reduce the
computational burden on mobile devices is to perform the rendering at a cloud
server. However, cloud-based rendering systems suffer from an increased
interaction (motion-to-photon) latency that may cause registration errors in MR
environments. One way of reducing the effective latency is to predict the
viewer's head pose and render the corresponding view from the volumetric video
in advance. In this paper, we design a Kalman filter for head motion prediction
in our cloud-based volumetric video streaming system. We analyze the
performance of our approach using recorded head motion traces and compare its
performance to an autoregression model for different prediction intervals
(look-ahead times). Our results show that the Kalman filter can predict head
orientations 0.5 degrees more accurately than the autoregression model for a
look-ahead time of 60 ms.
"
2726,Efficient Adaptation of Neural Network Filter for Video Compression,"  We present an efficient finetuning methodology for neural-network filters
which are applied as a postprocessing artifact-removal step in video coding
pipelines. The fine-tuning is performed at encoder side to adapt the neural
network to the specific content that is being encoded. In order to maximize the
PSNR gain and minimize the bitrate overhead, we propose to finetune only the
convolutional layers' biases. The proposed method achieves convergence much
faster than conventional finetuning approaches, making it suitable for
practical applications. The weight-update can be included into the video
bitstream generated by the existing video codecs. We show that our method
achieves up to 9.7% average BD-rate gain when compared to the state-of-art
Versatile Video Coding (VVC) standard codec on 7 test sequences.
"
2727,"Realistic Video Summarization through VISIOCITY: A New Benchmark and
  Evaluation Framework","  Automatic video summarization is still an unsolved problem due to several
challenges. We take steps towards making automatic video summarization more
realistic by addressing them. Firstly, the currently available datasets either
have very short videos or have few long videos of only a particular type. We
introduce a new benchmarking dataset VISIOCITY which comprises of longer videos
across six different categories with dense concept annotations capable of
supporting different flavors of video summarization and can be used for other
vision problems. Secondly, for long videos, human reference summaries are
difficult to obtain. We present a novel recipe based on pareto optimality to
automatically generate multiple reference summaries from indirect ground truth
present in VISIOCITY. We show that these summaries are at par with human
summaries. Thirdly, we demonstrate that in the presence of multiple ground
truth summaries (due to the highly subjective nature of the task), learning
from a single combined ground truth summary using a single loss function is not
a good idea. We propose a simple recipe VISIOCITY-SUM to enhance an existing
model using a combination of losses and demonstrate that it beats the current
state of the art techniques when tested on VISIOCITY. We also show that a
single measure to evaluate a summary, as is the current typical practice, falls
short. We propose a framework for better quantitative assessment of summary
quality which is closer to human judgment than a single measure, say F1. We
report the performance of a few representative techniques of video
summarization on VISIOCITY assessed using various measures and bring out the
limitation of the techniques and/or the assessment mechanism in modeling human
judgment and demonstrate the effectiveness of our evaluation framework in doing
so.
"
2728,"Improved Handling of Repeats and Jumps in Audio-Sheet Image
  Synchronization","  This paper studies the problem of automatically generating piano score
following videos given an audio recording and raw sheet music images. Whereas
previous works focus on synthetic sheet music where the data has been cleaned
and preprocessed, we instead focus on developing a system that can cope with
the messiness of raw, unprocessed sheet music PDFs from IMSLP. We investigate
how well existing systems cope with real scanned sheet music, filler pages and
unrelated pieces or movements, and discontinuities due to jumps and repeats. We
find that a significant bottleneck in system performance is handling jumps and
repeats correctly. In particular, we find that a previously proposed Jump DTW
algorithm does not perform robustly when jump locations are unknown a priori.
We propose a novel alignment algorithm called Hierarchical DTW that can handle
jumps and repeats even when jump locations are not known. It first performs
alignment at the feature level on each sheet music line, and then performs a
second alignment at the segment level. By operating at the segment level, it is
able to encode domain knowledge about how likely a particular jump is. Through
carefully controlled experiments on unprocessed sheet music PDFs from IMSLP, we
show that Hierarachical DTW significantly outperforms Jump DTW in handling
various types of jumps.
"
2729,"Video compression with low complexity CNN-based spatial resolution
  adaptation","  It has recently been demonstrated that spatial resolution adaptation can be
integrated within video compression to improve overall coding performance by
spatially down-sampling before encoding and super-resolving at the decoder.
Significant improvements have been reported when convolutional neural networks
(CNNs) were used to perform the resolution up-sampling. However, this approach
suffers from high complexity at the decoder due to the employment of CNN-based
super-resolution. In this paper, a novel framework is proposed which supports
the flexible allocation of complexity between the encoder and decoder. This
approach employs a CNN model for video down-sampling at the encoder and uses a
Lanczos3 filter to reconstruct full resolution at the decoder. The proposed
method was integrated into the HEVC HM 16.20 software and evaluated on JVET UHD
test sequences using the All Intra configuration. The experimental results
demonstrate the potential of the proposed approach, with significant bitrate
savings (more than 10%) over the original HEVC HM, coupled with reduced
computational complexity at both encoder (29%) and decoder (10%).
"
2730,"Unsupervised Generative Adversarial Alignment Representation for Sheet
  music, Audio and Lyrics","  Sheet music, audio, and lyrics are three main modalities during writing a
song. In this paper, we propose an unsupervised generative adversarial
alignment representation (UGAAR) model to learn deep discriminative
representations shared across three major musical modalities: sheet music,
lyrics, and audio, where a deep neural network based architecture on three
branches is jointly trained. In particular, the proposed model can transfer the
strong relationship between audio and sheet music to audio-lyrics and
sheet-lyrics pairs by learning the correlation in the latent shared subspace.
We apply CCA components of audio and sheet music to establish new ground truth.
The generative (G) model learns the correlation of two couples of transferred
pairs to generate new audio-sheet pair for a fixed lyrics to challenge the
discriminative (D) model. The discriminative model aims at distinguishing the
input which is from the generative model or the ground truth. The two models
simultaneously train in an adversarial way to enhance the ability of deep
alignment representation learning. Our experimental results demonstrate the
feasibility of our proposed UGAAR for alignment representation learning among
sheet music, audio, and lyrics.
"
2731,Dynamic Character Graph via Online Face Clustering for Movie Analysis,"  An effective approach to automated movie content analysis involves building a
network (graph) of its characters. Existing work usually builds a static
character graph to summarize the content using metadata, scripts or manual
annotations. We propose an unsupervised approach to building a dynamic
character graph that captures the temporal evolution of character interaction.
We refer to this as the character interaction graph(CIG). Our approach has two
components:(i) an online face clustering algorithm that discovers the
characters in the video stream as they appear, and (ii) simultaneous creation
of a CIG using the temporal dynamics of the resulting clusters. We demonstrate
the usefulness of the CIG for two movie analysis tasks: narrative structure
(acts) segmentation, and major character retrieval. Our evaluation on
full-length movies containing more than 5000 face tracks shows that the
proposed approach achieves superior performance for both the tasks.
"
2732,"Comparison of Multiplexing Policies for FPS Games in terms of Subjective
  Quality","  This paper compares two policies which can be used for multiplexing the
traffic of a number of players of a First Person Shooter game. A network
scenario in which a number of players share an access network has been
simulated, in order to compare the policies in terms of a subjective quality
estimator. The first policy, namely timeout, achieves higher bandwidth savings,
while the second one, period, introduces less delay and jitter. The results
show that the difference in terms of QoE is only significant when the number of
players is small. Thus, in order to make the correct decision, the concrete
network scenario and the characteristics of the router would have to be
considered in each case, taking into account the estimation of the subjective
quality that can be expected.
"
2733,"The Blessing and the Curse of the Noise behind Facial Landmark
  Annotations","  The evolving algorithms for 2D facial landmark detection empower people to
recognize faces, analyze facial expressions, etc. However, existing methods
still encounter problems of unstable facial landmarks when applied to videos.
Because previous research shows that the instability of facial landmarks is
caused by the inconsistency of labeling quality among the public datasets, we
want to have a better understanding of the influence of annotation noise in
them. In this paper, we make the following contributions: 1) we propose two
metrics that quantitatively measure the stability of detected facial landmarks,
2) we model the annotation noise in an existing public dataset, 3) we
investigate the influence of different types of noise in training face
alignment neural networks, and propose corresponding solutions. Our results
demonstrate improvements in both accuracy and stability of detected facial
landmarks.
"
2734,Dynamic texture analysis for detecting fake faces in video sequences,"  The creation of manipulated multimedia content involving human characters has
reached in the last years unprecedented realism, calling for automated
techniques to expose synthetically generated faces in images and videos. This
work explores the analysis of spatio-temporal texture dynamics of the video
signal, with the goal of characterizing and distinguishing real and fake
sequences. We propose to build a binary decision on the joint analysis of
multiple temporal segments and, in contrast to previous approaches, to exploit
the textural dynamics of both the spatial and temporal dimensions. This is
achieved through the use of Local Derivative Patterns on Three Orthogonal
Planes (LDP-TOP), a compact feature representation known to be an important
asset for the detection of face spoofing attacks. Experimental analyses on
state-of-the-art datasets of manipulated videos show the discriminative power
of such descriptors in separating real and fake sequences, and also identifying
the creation method used. Linear Support Vector Machines (SVMs) are used which,
despite the lower complexity, yield comparable performance to previously
proposed deep models for fake content detection.
"
2735,Influencia del Buffer del Router en la Distribuc\'ion de Video P2P-TV,"  This work presents a study of the behaviour of the router buffer when
managing the traffic of P2P-TV applications, where a number of peers exchange
video content. First, a summary of the characteristics of SOPCast is presented.
Then, the results obtained in simulation tests using different buffer policies
are presented. Real traces of the application, obtained from a research
project, have been used for the tests, sharing the Internet access with
different amounts of background traffic. The results show that a similar buffer
behaviour for all the access technologies. In addition, the big amount of small
packets generated may impair the video traffic, thus avoiding the
retransmission of the contents by the application.
"
2736,Traffic Optimization for TCP-based Massive Multiplayer Online Games,"  This paper studies the use of a traffic optimization technique named TCM
(Tunneling, Compressing and Multiplexing) to reduce the bandwidth of MMORPGs
(Massively Multiplayer Online Role-Playing Games), which employ TCP to provide
a soft real-time service. In order to optimize the traffic and to improve
bandwidth efficiency, TCM can be applied when the packets of a number of
players share the same link, which occurs in some scenarios, as e.g. the
traffic between proxies and servers of game-supporting infrastructures. First,
TCP/IP headers are compressed using standard algorithms that avoid sending
repeated fields; next, a number of packets are blended into a bigger one and
finally, they are sent using a tunnel. The expected compressed header size has
been obtained using traffic traces of a real game. Next, simulations using a
traffic model of a popular MMORPG have been performed in order to estimate the
expected bandwidth savings and the reduction in packets per second. The
obtained bandwidth saving is about 60 percent. Packets per second are also
significantly reduced. In addition, the added delays are shown to be small
enough so as not to impair layers' experienced quality.
"
2737,"A Pyramid Recurrent Network for Predicting Crowdsourced Speech-Quality
  Ratings of Real-World Signals","  The real-world capabilities of objective speech quality measures are limited
since current measures (1) are developed from simulated data that does not
adequately model real environments; or they (2) predict objective scores that
are not always strongly correlated with subjective ratings. Additionally, a
large dataset of real-world signals with listener quality ratings does not
currently exist, which would help facilitate real-world assessment. In this
paper, we collect and predict the perceptual quality of real-world speech
signals that are evaluated by human listeners. We first collect a large quality
rating dataset by conducting crowdsourced listening studies on two real-world
corpora. We further develop a novel approach that predicts human quality
ratings using a pyramid bidirectional long short term memory (pBLSTM) network
with an attention mechanism. The results show that the proposed model achieves
statistically lower estimation errors than prior assessment approaches, where
the predicted scores strongly correlate with human judgments.
"
2738,Adversarial Bipartite Graph Learning for Video Domain Adaptation,"  Domain adaptation techniques, which focus on adapting models between
distributionally different domains, are rarely explored in the video
recognition area due to the significant spatial and temporal shifts across the
source (i.e. training) and target (i.e. test) domains. As such, recent works on
visual domain adaptation which leverage adversarial learning to unify the
source and target video representations and strengthen the feature
transferability are not highly effective on the videos. To overcome this
limitation, in this paper, we learn a domain-agnostic video classifier instead
of learning domain-invariant representations, and propose an Adversarial
Bipartite Graph (ABG) learning framework which directly models the
source-target interactions with a network topology of the bipartite graph.
Specifically, the source and target frames are sampled as heterogeneous
vertexes while the edges connecting two types of nodes measure the affinity
among them. Through message-passing, each vertex aggregates the features from
its heterogeneous neighbors, forcing the features coming from the same class to
be mixed evenly. Explicitly exposing the video classifier to such cross-domain
representations at the training and test stages makes our model less biased to
the labeled source data, which in-turn results in achieving a better
generalization on the target domain. To further enhance the model capacity and
testify the robustness of the proposed architecture on difficult transfer
tasks, we extend our model to work in a semi-supervised setting using an
additional video-level bipartite graph. Extensive experiments conducted on four
benchmarks evidence the effectiveness of the proposed approach over the SOTA
methods on the task of video recognition.
"
2739,L$^2$C -- Learning to Learn to Compress,"  In this paper we present an end-to-end meta-learned system for image
compression. Traditional machine learning based approaches to image compression
train one or more neural network for generalization performance. However, at
inference time, the encoder or the latent tensor output by the encoder can be
optimized for each test image. This optimization can be regarded as a form of
adaptation or benevolent overfitting to the input content. In order to reduce
the gap between training and inference conditions, we propose a new training
paradigm for learned image compression, which is based on meta-learning. In a
first phase, the neural networks are trained normally. In a second phase, the
Model-Agnostic Meta-learning approach is adapted to the specific case of image
compression, where the inner-loop performs latent tensor overfitting, and the
outer loop updates both encoder and decoder neural networks based on the
overfitting performance. Furthermore, after meta-learning, we propose to
overfit and cluster the bias terms of the decoder on training image patches, so
that at inference time the optimal content-specific bias terms can be selected
at encoder-side. Finally, we propose a new probability model for lossless
compression, which combines concepts from both multi-scale and super-resolution
probability model approaches. We show the benefits of all our proposed ideas
via carefully designed experiments.
"
2740,"The Effect of TCP Variants on the Coexistence of MMORPG and Best-Effort
  Traffic","  We study TCP flows coexistence between Massive Multiplayer Online Role
Playing Games (MMORPGs) and other TCP applications, by taking World of Warcraft
(WoW) and a file transfer application based on File Transfer Protocol (FTP) as
an example. Our focus is on the effects of the sender buffer size and FTP
cross-traffic on the queuing delay experienced by the (MMORPG) game traffic. A
network scenario corresponding to a real life situation in an ADSL access
network has been simulated by using NS2. Three TCP variants, namely TCP SACK,
TCP New Reno, and TCP Vegas, have been considered for cross-traffic. The
results show that TCP Vegas is able to maintain a constant rate while competing
with the game traffic, since it prevents packet loss and high queuing delays by
not increasing the sender window size. TCP SACK and TCP New Reno, on the other
hand, tend to continuously increase the sender window size, thus potentially
allowing higher packet loss and causing undesired delays for the game traffic.
In terms of buffer size, we have established that smaller buffers are better
for MMORPG applications, while larger buffers contribute to a higher overall
delay.
"
2741,Diet deep generative audio models with structured lottery,"  Deep learning models have provided extremely successful solutions in most
audio application fields. However, the high accuracy of these models comes at
the expense of a tremendous computation cost. This aspect is almost always
overlooked in evaluating the quality of proposed models. However, models should
not be evaluated without taking into account their complexity. This aspect is
especially critical in audio applications, which heavily relies on specialized
embedded hardware with real-time constraints. In this paper, we build on recent
observations that deep models are highly overparameterized, by studying the
lottery ticket hypothesis on deep generative audio models. This hypothesis
states that extremely efficient small sub-networks exist in deep models and
would provide higher accuracy than larger models if trained in isolation.
However, lottery tickets are found by relying on unstructured masking, which
means that resulting models do not provide any gain in either disk size or
inference time. Instead, we develop here a method aimed at performing
structured trimming. We show that this requires to rely on global selection and
introduce a specific criterion based on mutual information. First, we confirm
the surprising result that smaller models provide higher accuracy than their
large counterparts. We further show that we can remove up to 95% of the model
weights without significant degradation in accuracy. Hence, we can obtain very
light models for generative audio across popular methods such as Wavenet, SING
or DDSP, that are up to 100 times smaller with commensurate accuracy. We study
the theoretical bounds for embedding these models on Raspberry Pi and Arduino,
and show that we can obtain generative models on CPU with equivalent quality as
large GPU models. Finally, we discuss the possibility of implementing deep
generative audio models on embedded platforms.
"
2742,Ultra-light deep MIR by trimming lottery tickets,"  Current state-of-the-art results in Music Information Retrieval are largely
dominated by deep learning approaches. These provide unprecedented accuracy
across all tasks. However, the consistently overlooked downside of these models
is their stunningly massive complexity, which seems concomitantly crucial to
their success. In this paper, we address this issue by proposing a model
pruning method based on the lottery ticket hypothesis. We modify the original
approach to allow for explicitly removing parameters, through structured
trimming of entire units, instead of simply masking individual weights. This
leads to models which are effectively lighter in terms of size, memory and
number of operations. We show that our proposal can remove up to 90% of the
model parameters without loss of accuracy, leading to ultra-light deep MIR
models. We confirm the surprising result that, at smaller compression ratios
(removing up to 85% of a network), lighter models consistently outperform their
heavier counterparts. We exhibit these results on a large array of MIR tasks
including audio classification, pitch recognition, chord extraction, drum
transcription and onset estimation. The resulting ultra-light deep learning
models for MIR can run on CPU, and can even fit on embedded devices with
minimal degradation of accuracy.
"
2743,MusiCoder: A Universal Music-Acoustic Encoder Based on Transformers,"  Music annotation has always been one of the critical topics in the field of
Music Information Retrieval (MIR). Traditional models use supervised learning
for music annotation tasks. However, as supervised machine learning approaches
increase in complexity, the increasing need for more annotated training data
can often not be matched with available data. Moreover, over-reliance on
labeled data when training supervised learning models can lead to unexpected
results and open vulnerabilities for adversarial attacks. In this paper, a new
self-supervised music acoustic representation learning approach named MusiCoder
is proposed. Inspired by the success of BERT, MusiCoder builds upon the
architecture of self-attention bidirectional transformers. Two pre-training
objectives, including Contiguous Frames Masking (CFM) and Contiguous Channels
Masking (CCM), are designed to adapt BERT-like masked reconstruction
pre-training to continuous acoustic frame domain. The performance of MusiCoder
is evaluated in two downstream music annotation tasks. The results show that
MusiCoder outperforms the state-of-the-art models in both music genre
classification and auto-tagging tasks. The effectiveness of MusiCoder indicates
a great potential of a new self-supervised learning approach to understand
music: first apply masked reconstruction tasks to pre-train a transformer-based
model with massive unlabeled music acoustic data, and then finetune the model
on specific downstream tasks with labeled data.
"
2744,"LSOTB-TIR:A Large-Scale High-Diversity Thermal Infrared Object Tracking
  Benchmark","  In this paper, we present a Large-Scale and high-diversity general Thermal
InfraRed (TIR) Object Tracking Benchmark, called LSOTBTIR, which consists of an
evaluation dataset and a training dataset with a total of 1,400 TIR sequences
and more than 600K frames. We annotate the bounding box of objects in every
frame of all sequences and generate over 730K bounding boxes in total. To the
best of our knowledge, LSOTB-TIR is the largest and most diverse TIR object
tracking benchmark to date. To evaluate a tracker on different attributes, we
define 4 scenario attributes and 12 challenge attributes in the evaluation
dataset. By releasing LSOTB-TIR, we encourage the community to develop deep
learning based TIR trackers and evaluate them fairly and comprehensively. We
evaluate and analyze more than 30 trackers on LSOTB-TIR to provide a series of
baselines, and the results show that deep trackers achieve promising
performance. Furthermore, we re-train several representative deep trackers on
LSOTB-TIR, and their results demonstrate that the proposed training dataset
significantly improves the performance of deep TIR trackers. Codes and dataset
are available at https://github.com/QiaoLiuHit/LSOTB-TIR.
"
2745,From Design Draft to Real Attire: Unaligned Fashion Image Translation,"  Fashion manipulation has attracted growing interest due to its great
application value, which inspires many researches towards fashion images.
However, little attention has been paid to fashion design draft. In this paper,
we study a new unaligned translation problem between design drafts and real
fashion items, whose main challenge lies in the huge misalignment between the
two modalities. We first collect paired design drafts and real fashion item
images without pixel-wise alignment. To solve the misalignment problem, our
main idea is to train a sampling network to adaptively adjust the input to an
intermediate state with structure alignment to the output. Moreover, built upon
the sampling network, we present design draft to real fashion item translation
network (D2RNet), where two separate translation streams that focus on texture
and shape, respectively, are combined tactfully to get both benefits. D2RNet is
able to generate realistic garments with both texture and shape consistency to
their design drafts. We show that this idea can be effectively applied to the
reverse translation problem and present R2DNet accordingly. Extensive
experiments on unaligned fashion design translation demonstrate the superiority
of our method over state-of-the-art methods. Our project website is available
at: https://victoriahy.github.io/MM2020/ .
"
2746,"Musical Word Embedding: Bridging the Gap between Listening Contexts and
  Music","  Word embedding pioneered by Mikolov et al. is a staple technique for word
representations in natural language processing (NLP) research which has also
found popularity in music information retrieval tasks. Depending on the type of
text data for word embedding, however, vocabulary size and the degree of
musical pertinence can significantly vary. In this work, we (1) train the
distributed representation of words using combinations of both general text
data and music-specific data and (2) evaluate the system in terms of how they
associate listening contexts with musical compositions.
"
2747,"Music SketchNet: Controllable Music Generation via Factorized
  Representations of Pitch and Rhythm","  Drawing an analogy with automatic image completion systems, we propose Music
SketchNet, a neural network framework that allows users to specify partial
musical ideas guiding automatic music generation. We focus on generating the
missing measures in incomplete monophonic musical pieces, conditioned on
surrounding context, and optionally guided by user-specified pitch and rhythm
snippets. First, we introduce SketchVAE, a novel variational autoencoder that
explicitly factorizes rhythm and pitch contour to form the basis of our
proposed model. Then we introduce two discriminative architectures,
SketchInpainter and SketchConnector, that in conjunction perform the guided
music completion, filling in representations for the missing measures
conditioned on surrounding context and user-specified snippets. We evaluate
SketchNet on a standard dataset of Irish folk music and compare with models
from recent works. When used for music completion, our approach outperforms the
state-of-the-art both in terms of objective metrics and subjective listening
tests. Finally, we demonstrate that our model can successfully incorporate
user-specified snippets during the generation process.
"
2748,"Temporal Context Aggregation for Video Retrieval with Contrastive
  Learning","  The current research focus on Content-Based Video Retrieval requires
higher-level video representation describing the long-range semantic
dependencies of relevant incidents, events, etc. However, existing methods
commonly process the frames of a video as individual images or short clips,
making the modeling of long-range semantic dependencies difficult. In this
paper, we propose TCA (Temporal Context Aggregation for Video Retrieval), a
video representation learning framework that incorporates long-range temporal
information between frame-level features using the self-attention mechanism. To
train it on video retrieval datasets, we propose a supervised contrastive
learning method that performs automatic hard negative mining and utilizes the
memory bank mechanism to increase the capacity of negative samples. Extensive
experiments are conducted on multiple video retrieval tasks, such as
CC_WEB_VIDEO, FIVR-200K, and EVVE. The proposed method shows a significant
performance advantage (~17% mAP on FIVR-200K) over state-of-the-art methods
with video-level features, and deliver competitive results with 22x faster
inference time comparing with frame-level features.
"
2749,"Addressing the Cold-Start Problem in Outfit Recommendation Using Visual
  Preference Modelling","  With the global transformation of the fashion industry and a rise in the
demand for fashion items worldwide, the need for an effectual fashion
recommendation has never been more. Despite various cutting-edge solutions
proposed in the past for personalising fashion recommendation, the technology
is still limited by its poor performance on new entities, i.e. the cold-start
problem. In this paper, we attempt to address the cold-start problem for new
users, by leveraging a novel visual preference modelling approach on a small
set of input images. We demonstrate the use of our approach with
feature-weighted clustering to personalise occasion-oriented outfit
recommendation. Quantitatively, our results show that the proposed visual
preference modelling approach outperforms state of the art in terms of clothing
attribute prediction. Qualitatively, through a pilot study, we demonstrate the
efficacy of our system to provide diverse and personalised recommendations in
cold-start scenarios.
"
2750,Deep Multi-modality Soft-decoding of Very Low Bit-rate Face Videos,"  We propose a novel deep multi-modality neural network for restoring very low
bit rate videos of talking heads. Such video contents are very common in social
media, teleconferencing, distance education, tele-medicine, etc., and often
need to be transmitted with limited bandwidth. The proposed CNN method exploits
the correlations among three modalities, video, audio and emotion state of the
speaker, to remove the video compression artifacts caused by spatial down
sampling and quantization. The deep learning approach turns out to be ideally
suited for the video restoration task, as the complex non-linear cross-modality
correlations are very difficult to model analytically and explicitly. The new
method is a video post processor that can significantly boost the perceptual
quality of aggressively compressed talking head videos, while being fully
compatible with all existing video compression standards.
"
2751,"PAI-BPR: Personalized Outfit Recommendation Scheme with Attribute-wise
  Interpretability","  Fashion is an important part of human experience. Events such as interviews,
meetings, marriages, etc. are often based on clothing styles. The rise in the
fashion industry and its effect on social influencing have made outfit
compatibility a need. Thus, it necessitates an outfit compatibility model to
aid people in clothing recommendation. However, due to the highly subjective
nature of compatibility, it is necessary to account for personalization. Our
paper devises an attribute-wise interpretable compatibility scheme with
personal preference modelling which captures user-item interaction along with
general item-item interaction. Our work solves the problem of interpretability
in clothing matching by locating the discordant and harmonious attributes
between fashion items. Extensive experiment results on IQON3000, a publicly
available real-world dataset, verify the effectiveness of the proposed model.
"
2752,Adv-watermark: A Novel Watermark Perturbation for Adversarial Examples,"  Recent research has demonstrated that adding some imperceptible perturbations
to original images can fool deep learning models. However, the current
adversarial perturbations are usually shown in the form of noises, and thus
have no practical meaning. Image watermark is a technique widely used for
copyright protection. We can regard image watermark as a king of meaningful
noises and adding it to the original image will not affect people's
understanding of the image content, and will not arouse people's suspicion.
Therefore, it will be interesting to generate adversarial examples using
watermarks. In this paper, we propose a novel watermark perturbation for
adversarial examples (Adv-watermark) which combines image watermarking
techniques and adversarial example algorithms. Adding a meaningful watermark to
the clean images can attack the DNN models. Specifically, we propose a novel
optimization algorithm, which is called Basin Hopping Evolution (BHE), to
generate adversarial watermarks in the black-box attack mode. Thanks to the
BHE, Adv-watermark only requires a few queries from the threat models to finish
the attacks. A series of experiments conducted on ImageNet and CASIA-WebFace
datasets show that the proposed method can efficiently generate adversarial
examples, and outperforms the state-of-the-art attack methods. Moreover,
Adv-watermark is more robust against image transformation defense methods.
"
2753,Salvage Reusable Samples from Noisy Data for Robust Learning,"  Due to the existence of label noise in web images and the high memorization
capacity of deep neural networks, training deep fine-grained (FG) models
directly through web images tends to have an inferior recognition ability. In
the literature, to alleviate this issue, loss correction methods try to
estimate the noise transition matrix, but the inevitable false correction would
cause severe accumulated errors. Sample selection methods identify clean
(""easy"") samples based on the fact that small losses can alleviate the
accumulated errors. However, ""hard"" and mislabeled examples that can both boost
the robustness of FG models are also dropped. To this end, we propose a
certainty-based reusable sample selection and correction approach, termed as
CRSSC, for coping with label noise in training deep FG models with web images.
Our key idea is to additionally identify and correct reusable samples, and then
leverage them together with clean examples to update the networks. We
demonstrate the superiority of the proposed approach from both theoretical and
experimental perspectives.
"
2754,Data-driven Meta-set Based Fine-Grained Visual Classification,"  Constructing fine-grained image datasets typically requires domain-specific
expert knowledge, which is not always available for crowd-sourcing platform
annotators. Accordingly, learning directly from web images becomes an
alternative method for fine-grained visual recognition. However, label noise in
the web training set can severely degrade the model performance. To this end,
we propose a data-driven meta-set based approach to deal with noisy web images
for fine-grained recognition. Specifically, guided by a small amount of clean
meta-set, we train a selection net in a meta-learning manner to distinguish in-
and out-of-distribution noisy images. To further boost the robustness of model,
we also learn a labeling net to correct the labels of in-distribution noisy
data. In this way, our proposed method can alleviate the harmful effects caused
by out-of-distribution noise and properly exploit the in-distribution noisy
samples for training. Extensive experiments on three commonly used fine-grained
datasets demonstrate that our approach is much superior to state-of-the-art
noise-robust methods.
"
2755,"Attentive Fusion Enhanced Audio-Visual Encoding for Transformer Based
  Robust Speech Recognition","  Audio-visual information fusion enables a performance improvement in speech
recognition performed in complex acoustic scenarios, e.g., noisy environments.
It is required to explore an effective audio-visual fusion strategy for
audiovisual alignment and modality reliability. Different from the previous
end-to-end approaches where the audio-visual fusion is performed after encoding
each modality, in this paper we propose to integrate an attentive fusion block
into the encoding process. It is shown that the proposed audio-visual fusion
method in the encoder module can enrich audio-visual representations, as the
relevance between the two modalities is leveraged. In line with the
transformer-based architecture, we implement the embedded fusion block using a
multi-head attention based audiovisual fusion with one-way or two-way
interactions. The proposed method can sufficiently combine the two streams and
weaken the over-reliance on the audio modality. Experiments on the LRS3-TED
dataset demonstrate that the proposed method can increase the recognition rate
by 0.55%, 4.51% and 4.61% on average under the clean, seen and unseen noise
conditions, respectively, compared to the state-of-the-art approach.
"
2756,"Exact, Parallelizable Dynamic Time Warping Alignment with Linear Memory","  Audio alignment is a fundamental preprocessing step in many MIR pipelines.
For two audio clips with M and N frames, respectively, the most popular
approach, dynamic time warping (DTW), has O(MN) requirements in both memory and
computation, which is prohibitive for frame-level alignments at reasonable
rates. To address this, a variety of memory efficient algorithms exist to
approximate the optimal alignment under the DTW cost. To our knowledge,
however, no exact algorithms exist that are guaranteed to break the quadratic
memory barrier. In this work, we present a divide and conquer algorithm that
computes the exact globally optimal DTW alignment using O(M+N) memory. Its
runtime is still O(MN), trading off memory for a 2x increase in computation.
However, the algorithm can be parallelized up to a factor of min(M, N) with the
same memory constraints, so it can still run more efficiently than the textbook
version with an adequate GPU. We use our algorithm to compute exact alignments
on a collection of orchestral music, which we use as ground truth to benchmark
the alignment accuracy of several popular approximate alignment schemes at
scales that were not previously possible.
"
2757,"The VISIONE Video Search System: Exploiting Off-the-Shelf Text Search
  Engines for Large-Scale Video Retrieval","  In this paper, we describe VISIONE, a video search system that allows users
to search for videos using textual keywords, occurrence of objects and their
spatial relationships, occurrence of colors and their spatial relationships,
and image similarity. These modalities can be combined together to express
complex queries and satisfy user needs. The peculiarity of our approach is that
we encode all the information extracted from the keyframes, such as visual deep
features, tags, color and object locations, using a convenient textual encoding
indexed in a single text retrieval engine. This offers great flexibility when
results corresponding to various parts of the query needs to be merged. We
report an extensive analysis of the system retrieval performance, using the
query logs generated during the Video Browser Showdown (VBS) 2019 competition.
This allowed us to fine-tune the system by choosing the optimal parameters and
strategies among the ones that we tested.
"
2758,Rounded Hartley Transform: A Quasi-involution,"  A new multiplication-free transform derived from DHT is introduced: the RHT.
Investigations on the properties of the RHT led us to the concept of
weak-inversion. Using new constructs, we show that RHT is not involutional like
the DHT, but exhibits quasi-involutional property, a new definition derived
from the periodicity of matrices. Thus instead of using the actual inverse
transform, the RHT is viewed as an involutional transform, allowing the use of
direct (multiplication-free) to evaluate the inverse. A fast algorithm to
compute RHT is presented. This algorithm show embedded properties. We also
extended RHT to the two-dimensional case. This permitted us to perform a
preliminary analysis on the effects of RHT on images. Despite of some SNR loss,
RHT can be very interesting for applications involving image monitoring
associated to decision making, such as military applications or medical
imaging.
"
2759,Online Multi-modal Person Search in Videos,"  The task of searching certain people in videos has seen increasing potential
in real-world applications, such as video organization and editing. Most
existing approaches are devised to work in an offline manner, where identities
can only be inferred after an entire video is examined. This working manner
precludes such methods from being applied to online services or those
applications that require real-time responses. In this paper, we propose an
online person search framework, which can recognize people in a video on the
fly. This framework maintains a multimodal memory bank at its heart as the
basis for person recognition, and updates it dynamically with a policy obtained
by reinforcement learning. Our experiments on a large movie dataset show that
the proposed method is effective, not only achieving remarkable improvements
over online schemes but also outperforming offline methods.
"
2760,"A Unified Framework for Shot Type Classification Based on Subject
  Centric Lens","  Shots are key narrative elements of various videos, e.g. movies, TV series,
and user-generated videos that are thriving over the Internet. The types of
shots greatly influence how the underlying ideas, emotions, and messages are
expressed. The technique to analyze shot types is important to the
understanding of videos, which has seen increasing demand in real-world
applications in this era. Classifying shot type is challenging due to the
additional information required beyond the video content, such as the spatial
composition of a frame and camera movement. To address these issues, we propose
a learning framework Subject Guidance Network (SGNet) for shot type
recognition. SGNet separates the subject and background of a shot into two
streams, serving as separate guidance maps for scale and movement type
classification respectively. To facilitate shot type analysis and model
evaluations, we build a large-scale dataset MovieShots, which contains 46K
shots from 7K movie trailers with annotations of their scale and movement
types. Experiments show that our framework is able to recognize these two
attributes of shot accurately, outperforming all the previous methods.
"
2761,"Speech Driven Talking Face Generation from a Single Image and an Emotion
  Condition","  Visual emotion expression plays an important role in audiovisual speech
communication. In this work, we propose a novel approach to rendering visual
emotion expression in speech-driven talking face generation. Specifically, we
design an end-to-end talking face generation system that takes a speech
utterance, a single face image, and a categorical emotion label as input to
render a talking face video in sync with the speech and expressing the
condition emotion. Objective evaluation on image quality, audiovisual
synchronization, and visual emotion expression shows that the proposed system
outperforms a state-of-the-art baseline system. Subjective evaluation of visual
emotion expression and video realness also demonstrates the superiority of the
proposed system. Furthermore, we conduct a pilot study on human emotion
recognition of generated videos with mismatched emotions between the audio and
visual modalities, and results show that humans reply on the visual modality
more significantly than the audio modality on this task.
"
2762,"A Modular Approach for Synchronized Wireless Multimodal Multisensor Data
  Acquisition in Highly Dynamic Social Settings","  Existing data acquisition literature for human behavior research provides
wired solutions, mainly for controlled laboratory setups. In uncontrolled
free-standing conversation settings, where participants are free to walk
around, these solutions are unsuitable. While wireless solutions are employed
in the broadcasting industry, they can be prohibitively expensive. In this
work, we propose a modular and cost-effective wireless approach for
synchronized multisensor data acquisition of social human behavior. Our core
idea involves a cost-accuracy trade-off by using Network Time Protocol (NTP) as
a source reference for all sensors. While commonly used as a reference in
ubiquitous computing, NTP is widely considered to be insufficiently accurate as
a reference for video applications, where Precision Time Protocol (PTP) or
Global Positioning System (GPS) based references are preferred. We argue and
show, however, that the latency introduced by using NTP as a source reference
is adequate for human behavior research, and the subsequent cost and modularity
benefits are a desirable trade-off for applications in this domain. We also
describe one instantiation of the approach deployed in a real-world experiment
to demonstrate the practicality of our setup in-the-wild.
"
2763,"Norm-in-Norm Loss with Faster Convergence and Better Performance for
  Image Quality Assessment","  Currently, most image quality assessment (IQA) models are supervised by the
MAE or MSE loss with empirically slow convergence. It is well-known that
normalization can facilitate fast convergence. Therefore, we explore
normalization in the design of loss functions for IQA. Specifically, we first
normalize the predicted quality scores and the corresponding subjective quality
scores. Then, the loss is defined based on the norm of the differences between
these normalized values. The resulting ""Norm-in-Norm'' loss encourages the IQA
model to make linear predictions with respect to subjective quality scores.
After training, the least squares regression is applied to determine the linear
mapping from the predicted quality to the subjective quality. It is shown that
the new loss is closely connected with two common IQA performance criteria
(PLCC and RMSE). Through theoretical analysis, it is proved that the embedded
normalization makes the gradients of the loss function more stable and more
predictable, which is conducive to the faster convergence of the IQA model.
Furthermore, to experimentally verify the effectiveness of the proposed loss,
it is applied to solve a challenging problem: quality assessment of in-the-wild
images. Experiments on two relevant datasets (KonIQ-10k and CLIVE) show that,
compared to MAE or MSE loss, the new loss enables the IQA model to converge
about 10 times faster and the final model achieves better performance. The
proposed model also achieves state-of-the-art prediction performance on this
challenging problem. For reproducible scientific research, our code is publicly
available at https://github.com/lidq92/LinearityIQA.
"
2764,Content Format and Quality of Experience in Virtual Reality,"  In this paper, we investigate three forms of virtual reality content
production and consumption. Namely, 360 stereoscopic video, the combination of
a 3D environment with a video billboard for dynamic elements, and a full 3D
rendered scene. On one hand, video based techniques facilitate the acquisition
of content, but they can limit the experience of the user since the content is
captured from a fixed point of view. On the other hand, 3D content allows for
point of view translation, but real-time photorealistic rendering is not
trivial and comes at high production and processing costs. We also compare the
two extremes with an approach that combines dynamic video elements with a 3D
virtual environment. We discuss the advantages and disadvantages of these
systems, and present the result of a user study with 24 participants. In the
study, we evaluated the quality of experience, including presence, simulation
sickness and participants' assessment of content quality, of three versions of
a cinematic segment with two actors. We found that, in this context, mixing
video and 3D content produced the best experience.
"
2765,Extension of JPEG XS for Two-Layer Lossless Coding,"  A two-layer lossless image coding method compatible with JPEG XS is proposed.
JPEG XS is a new international standard for still image coding that has the
characteristics of very low latency and very low complexity. However, it does
not support lossless coding, although it can achieve visual lossless coding.
The proposed method has a two-layer structure similar to JPEG XT, which
consists of JPEG XS coding and a lossless coding method. As a result, it
enables us to losslessly restore original images, while maintaining
compatibility with JPEG XS.
"
2766,Sharp Multiple Instance Learning for DeepFake Video Detection,"  With the rapid development of facial manipulation techniques, face forgery
has received considerable attention in multimedia and computer vision community
due to security concerns. Existing methods are mostly designed for single-frame
detection trained with precise image-level labels or for video-level prediction
by only modeling the inter-frame inconsistency, leaving potential high risks
for DeepFake attackers. In this paper, we introduce a new problem of partial
face attack in DeepFake video, where only video-level labels are provided but
not all the faces in the fake videos are manipulated. We address this problem
by multiple instance learning framework, treating faces and input video as
instances and bag respectively. A sharp MIL (S-MIL) is proposed which builds
direct mapping from instance embeddings to bag prediction, rather than from
instance embeddings to instance prediction and then to bag prediction in
traditional MIL. Theoretical analysis proves that the gradient vanishing in
traditional MIL is relieved in S-MIL. To generate instances that can accurately
incorporate the partially manipulated faces, spatial-temporal encoded instance
is designed to fully model the intra-frame and inter-frame inconsistency, which
further helps to promote the detection performance. We also construct a new
dataset FFPMS for partially attacked DeepFake video detection, which can
benefit the evaluation of different methods at both frame and video levels.
Experiments on FFPMS and the widely used DFDC dataset verify that S-MIL is
superior to other counterparts for partially attacked DeepFake video detection.
In addition, S-MIL can also be adapted to traditional DeepFake image detection
tasks and achieve state-of-the-art performance on single-frame datasets.
"
2767,"PlugSonic: a web- and mobile-based platform for binaural audio and sonic
  narratives","  PlugSonic is a suite of web- and mobile-based applications for the curation
and experience of binaural interactive soundscapes and sonic narratives. It was
developed as part of the PLUGGY EU project (Pluggable Social Platform for
Heritage Awareness and Participation) and consists of two main applications:
PlugSonic Sample, to edit and apply audio effects, and PlugSonic Soundscape, to
create and experience binaural soundscapes. The audio processing within
PlugSonic is based on the Web Audio API and the 3D Tune-In Toolkit, while the
exploration of soundscapes in a physical space is obtained using Apple's ARKit.
In this paper we present the design choices, the user involvement processes and
the implementation details. The main goal of PlugSonic is technology
democratisation; PlugSonic users - whether institutions or citizens - are all
given the instruments needed to create, process and experience 3D soundscapes
and sonic narrative; without the need for specific devices, external tools
(software and/or hardware), specialised knowledge or custom development. The
evaluation, which was conducted with inexperienced users on three tasks -
creation, curation and experience - demonstrates how PlugSonic is indeed a
simple, effective, yet powerful tool.
"
2768,SENSEI: Aligning Video Streaming Quality with Dynamic User Sensitivity,"  This paper aims to improve video streaming by leveraging a simple
observation: users are more sensitive to low quality in certain parts of a
video than in others. For instance, rebuffering during key moments of a sports
video (e.g., before a goal is scored) is more annoying than rebuffering during
normal gameplay. Such dynamic quality sensitivity, however, is rarely captured
by current approaches, which predict QoE (quality-of-experience) using
one-size-fits-all heuristics that are too simplistic to understand the nuances
of video content. Instead of proposing yet another heuristic, we take a
different approach: we run a separate crowdsourcing experiment for each video
to derive users' quality sensitivity at different parts of the video. Of
course, the cost of doing this at scale can be prohibitive, but we show that
careful experiment design combined with a suite of pruning techniques can make
the cost negligible compared to how much content providers invest in content
generation and distribution. Our ability to accurately profile time-varying
user sensitivity inspires a new approach: dynamically aligning higher (lower)
quality with higher (lower) sensitivity periods. We present a new video
streaming system called SENSEI that incorporates dynamic quality sensitivity
into existing quality adaptation algorithms. We apply SENSEI to two
state-of-the-art adaptation algorithms. SENSEI can take seemingly unusual
actions: e.g., lowering bitrate (or initiating a rebuffering event) even when
bandwidth is sufficient so that it can maintain a higher bitrate without
rebuffering when quality sensitivity becomes higher in the near future.
Compared to state-of-the-art approaches, SENSEI improves QoE by 15.1% or
achieves the same QoE with 26.8% less bandwidth on average.
"
2769,"Identity-Aware Attribute Recognition via Real-Time Distributed Inference
  in Mobile Edge Clouds","  With the development of deep learning technologies, attribute recognition and
person re-identification (re-ID) have attracted extensive attention and
achieved continuous improvement via executing computing-intensive deep neural
networks in cloud datacenters. However, the datacenter deployment cannot meet
the real-time requirement of attribute recognition and person re-ID, due to the
prohibitive delay of backhaul networks and large data transmissions from
cameras to datacenters. A feasible solution thus is to employ mobile edge
clouds (MEC) within the proximity of cameras and enable distributed inference.
In this paper, we design novel models for pedestrian attribute recognition with
re-ID in an MEC-enabled camera monitoring system. We also investigate the
problem of distributed inference in the MEC-enabled camera network. To this
end, we first propose a novel inference framework with a set of distributed
modules, by jointly considering the attribute recognition and person re-ID. We
then devise a learning-based algorithm for the distributions of the modules of
the proposed distributed inference framework, considering the dynamic
MEC-enabled camera network with uncertainties. We finally evaluate the
performance of the proposed algorithm by both simulations with real datasets
and system implementation in a real testbed. Evaluation results show that the
performance of the proposed algorithm with distributed inference framework is
promising, by reaching the accuracies of attribute recognition and person
identification up to 92.9% and 96.6% respectively, and significantly reducing
the inference delay by at least 40.6% compared with existing methods.
"
2770,LogoDet-3K: A Large-Scale Image Dataset for Logo Detection,"  Logo detection has been gaining considerable attention because of its wide
range of applications in the multimedia field, such as copyright infringement
detection, brand visibility monitoring, and product brand management on social
media. In this paper, we introduce LogoDet-3K, the largest logo detection
dataset with full annotation, which has 3,000 logo categories, about 200,000
manually annotated logo objects and 158,652 images. LogoDet-3K creates a more
challenging benchmark for logo detection, for its higher comprehensive coverage
and wider variety in both logo categories and annotated objects compared with
existing datasets. We describe the collection and annotation process of our
dataset, analyze its scale and diversity in comparison to other datasets for
logo detection. We further propose a strong baseline method Logo-Yolo, which
incorporates Focal loss and CIoU loss into the state-of-the-art YOLOv3
framework for large-scale logo detection. Logo-Yolo can solve the problems of
multi-scale objects, logo sample imbalance and inconsistent bounding-box
regression. It obtains about 4% improvement on the average performance compared
with YOLOv3, and greater improvements compared with reported several deep
detection models on LogoDet-3K. The evaluations on other three existing
datasets further verify the effectiveness of our method, and demonstrate better
generalization ability of LogoDet-3K on logo detection and retrieval tasks. The
LogoDet-3K dataset is used to promote large-scale logo-related research and it
can be found at https://github.com/Wangjing1551/LogoDet-3K-Dataset.
"
2771,"Towards Modality Transferable Visual Information Representation with
  Optimal Model Compression","  Compactly representing the visual signals is of fundamental importance in
various image/video-centered applications. Although numerous approaches were
developed for improving the image and video coding performance by removing the
redundancies within visual signals, much less work has been dedicated to the
transformation of the visual signals to another well-established modality for
better representation capability. In this paper, we propose a new scheme for
visual signal representation that leverages the philosophy of transferable
modality. In particular, the deep learning model, which characterizes and
absorbs the statistics of the input scene with online training, could be
efficiently represented in the sense of rate-utility optimization to serve as
the enhancement layer in the bitstream. As such, the overall performance can be
further guaranteed by optimizing the new modality incorporated. The proposed
framework is implemented on the state-of-the-art video coding standard (i.e.,
versatile video coding), and significantly better representation capability has
been observed based on extensive evaluations.
"
2772,"ISIA Food-500: A Dataset for Large-Scale Food Recognition via Stacked
  Global-Local Attention Network","  Food recognition has received more and more attention in the multimedia
community for its various real-world applications, such as diet management and
self-service restaurants. A large-scale ontology of food images is urgently
needed for developing advanced large-scale food recognition algorithms, as well
as for providing the benchmark dataset for such algorithms. To encourage
further progress in food recognition, we introduce the dataset ISIA Food- 500
with 500 categories from the list in the Wikipedia and 399,726 images, a more
comprehensive food dataset that surpasses existing popular benchmark datasets
by category coverage and data volume. Furthermore, we propose a stacked
global-local attention network, which consists of two sub-networks for food
recognition. One subnetwork first utilizes hybrid spatial-channel attention to
extract more discriminative features, and then aggregates these multi-scale
discriminative features from multiple layers into global-level representation
(e.g., texture and shape information about food). The other one generates
attentional regions (e.g., ingredient relevant regions) from different regions
via cascaded spatial transformers, and further aggregates these multi-scale
regional features from different layers into local-level representation. These
two types of features are finally fused as comprehensive representation for
food recognition. Extensive experiments on ISIA Food-500 and other two popular
benchmark datasets demonstrate the effectiveness of our proposed method, and
thus can be considered as one strong baseline. The dataset, code and models can
be found at http://123.57.42.89/FoodComputing-Dataset/ISIA-Food500.html.
"
2773,"JQF: Optimal JPEG Quantization Table Fusion by Simulated Annealing on
  Texture Images and Predicting Textures","  JPEG has been a widely used lossy image compression codec for nearly three
decades. The JPEG standard allows to use customized quantization table;
however, it's still a challenging problem to find an optimal quantization table
within acceptable computational cost. This work tries to solve the dilemma of
balancing between computational cost and image specific optimality by
introducing a new concept of texture mosaic images. Instead of optimizing a
single image or a collection of representative images, the simulated annealing
technique is applied to texture mosaic images to search for an optimal
quantization table for each texture category. We use pre-trained VGG-16 CNN
model to learn those texture features and predict the new image's texture
distribution, then fuse optimal texture tables to come out with an image
specific optimal quantization table. On the Kodak dataset with the quality
setting $Q=95$, our experiment shows a size reduction of 23.5% over the JPEG
standard table with a slightly 0.35% FSIM decrease, which is visually
unperceivable. The proposed JQF method achieves per image optimality for JPEG
encoding with less than one second additional timing cost. The online demo is
available at https://matthorn.s3.amazonaws.com/JQF/qtbl_vis.html
"
2774,"Look, Listen, and Attend: Co-Attention Network for Self-Supervised
  Audio-Visual Representation Learning","  When watching videos, the occurrence of a visual event is often accompanied
by an audio event, e.g., the voice of lip motion, the music of playing
instruments. There is an underlying correlation between audio and visual
events, which can be utilized as free supervised information to train a neural
network by solving the pretext task of audio-visual synchronization. In this
paper, we propose a novel self-supervised framework with co-attention mechanism
to learn generic cross-modal representations from unlabelled videos in the
wild, and further benefit downstream tasks. Specifically, we explore three
different co-attention modules to focus on discriminative visual regions
correlated to the sounds and introduce the interactions between them.
Experiments show that our model achieves state-of-the-art performance on the
pretext task while having fewer parameters compared with existing methods. To
further evaluate the generalizability and transferability of our approach, we
apply the pre-trained model on two downstream tasks, i.e., sound source
localization and action recognition. Extensive experiments demonstrate that our
model provides competitive results with other self-supervised methods, and also
indicate that our approach can tackle the challenging scenes which contain
multiple sound sources.
"
2775,"Automatic Quality Assessment for Audio-Visual Verification Systems. The
  LOVe submission to NIST SRE Challenge 2019","  Fusion of scores is a cornerstone of multimodal biometric systems composed of
independent unimodal parts. In this work, we focus on quality-dependent fusion
for speaker-face verification. To this end, we propose a universal model which
can be trained for automatic quality assessment of both face and speaker
modalities. This model estimates the quality of representations produced by
unimodal systems which are then used to enhance the score-level fusion of
speaker and face verification modules. We demonstrate the improvements brought
by this quality-dependent fusion on the recent NIST SRE19 Audio-Visual
Challenge dataset.
"
2776,"DFEW: A Large-Scale Database for Recognizing Dynamic Facial Expressions
  in the Wild","  Recently, facial expression recognition (FER) in the wild has gained a lot of
researchers' attention because it is a valuable topic to enable the FER
techniques to move from the laboratory to the real applications. In this paper,
we focus on this challenging but interesting topic and make contributions from
three aspects. First, we present a new large-scale 'in-the-wild' dynamic facial
expression database, DFEW (Dynamic Facial Expression in the Wild), consisting
of over 16,000 video clips from thousands of movies. These video clips contain
various challenging interferences in practical scenarios such as extreme
illumination, occlusions, and capricious pose changes. Second, we propose a
novel method called Expression-Clustered Spatiotemporal Feature Learning
(EC-STFL) framework to deal with dynamic FER in the wild. Third, we conduct
extensive benchmark experiments on DFEW using a lot of spatiotemporal deep
feature learning methods as well as our proposed EC-STFL. Experimental results
show that DFEW is a well-designed and challenging database, and the proposed
EC-STFL can promisingly improve the performance of existing spatiotemporal deep
neural networks in coping with the problem of dynamic FER in the wild. Our DFEW
database is publicly available and can be freely downloaded from
https://dfew-dataset.github.io/.
"
2777,Analyzing Who and What Appears in a Decade of US Cable TV News,"  Cable TV news reaches millions of U.S. households each day, meaning that
decisions about who appears on the news and what stories get covered can
profoundly influence public opinion and discourse. We analyze a data set of
nearly 24/7 video, audio, and text captions from three U.S. cable TV networks
(CNN, FOX, and MSNBC) from January 2010 to July 2019. Using machine learning
tools, we detect faces in 244,038 hours of video, label each face's presented
gender, identify prominent public figures, and align text captions to audio. We
use these labels to perform screen time and word frequency analyses. For
example, we find that overall, much more screen time is given to
male-presenting individuals than to female-presenting individuals (2.4x in 2010
and 1.9x in 2019). We present an interactive web-based tool, accessible at
https://tvnews.stanford.edu, that allows the general public to perform their
own analyses on the full cable TV news data set.
"
2778,"MMM : Exploring Conditional Multi-Track Music Generation with the
  Transformer","  We propose the Multi-Track Music Machine (MMM), a generative system based on
the Transformer architecture that is capable of generating multi-track music.
In contrast to previous work, which represents musical material as a single
time-ordered sequence, where the musical events corresponding to different
tracks are interleaved, we create a time-ordered sequence of musical events for
each track and concatenate several tracks into a single sequence. This takes
advantage of the Transformer's attention-mechanism, which can adeptly handle
long-term dependencies. We explore how various representations can offer the
user a high degree of control at generation time, providing an interactive demo
that accommodates track-level and bar-level inpainting, and offers control over
track instrumentation and note density.
"
2779,WAN: Watermarking Attack Network,"  Multi-bit watermarking (MW) has been developed to improve robustness against
signal processing operations and geometric distortions. To this end, several
benchmark tools that simulate possible attacks on images to test robustness are
available. However, limitations in these general attacks exist since they
cannot exploit specific characteristics of the targeted MW. In addition, these
attacks are usually devised without consideration for visual quality, which
rarely occurs in the real world. To address these limitations, we propose a
watermarking attack network (WAN), a fully trainable watermarking benchmark
tool, that utilizes the weak points of the target MW and removes inserted
watermark and inserts inverted bit information, thereby considerably reducing
watermark extractability. To hinder the extraction of hidden information while
ensuring high visual quality, we utilize a residual dense blocks-based
architecture specialized in local and global feature learning. A novel
watermarking attack loss is introduced to break the MW systems. We empirically
demonstrate that the WAN can successfully fool a variety of MW systems.
"
2780,"SGG: Spinbot, Grammarly and GloVe based Fake News Detection","  Recently, news consumption using online news portals has increased
exponentially due to several reasons, such as low cost and easy accessibility.
However, such online platforms inadvertently also become the cause of spreading
false information across the web. They are being misused quite frequently as a
medium to disseminate misinformation and hoaxes. Such malpractices call for a
robust automatic fake news detection system that can keep us at bay from such
misinformation and hoaxes. We propose a robust yet simple fake news detection
system, leveraging the tools for paraphrasing, grammar-checking, and
word-embedding. In this paper, we try to the potential of these tools in
jointly unearthing the authenticity of a news article. Notably, we leverage
Spinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for
word-embedding) tools for this purpose. Using these tools, we were able to
extract novel features that could yield state-of-the-art results on the Fake
News AMT dataset and comparable results on Celebrity datasets when combined
with some of the essential features. More importantly, the proposed method is
found to be more robust empirically than the existing ones, as revealed in our
cross-domain analysis and multi-domain analysis.
"
2781,Detection of Gait Abnormalities caused by Neurological Disorders,"  In this paper, we leverage gait to potentially detect some of the important
neurological disorders, namely Parkinson's disease, Diplegia, Hemiplegia, and
Huntington's Chorea. Persons with these neurological disorders often have a
very abnormal gait, which motivates us to target gait for their potential
detection. Some of the abnormalities involve the circumduction of legs,
forward-bending, involuntary movements, etc. To detect such abnormalities in
gait, we develop gait features from the key-points of the human pose, namely
shoulders, elbows, hips, knees, ankles, etc. To evaluate the effectiveness of
our gait features in detecting the abnormalities related to these diseases, we
build a synthetic video dataset of persons mimicking the gait of persons with
such disorders, considering the difficulty in finding a sufficient number of
people with these disorders. We name it \textit{NeuroSynGait} video dataset.
Experiments demonstrated that our gait features were indeed successful in
detecting these abnormalities.
"
2782,Visually Aware Skip-Gram for Image Based Recommendations,"  The visual appearance of a product significantly influences purchase
decisions on e-commerce websites. We propose a novel framework VASG (Visually
Aware Skip-Gram) for learning user and product representations in a common
latent space using product image features. Our model is an amalgamation of the
Skip-Gram architecture and a deep neural network based Decoder. Here the
Skip-Gram attempts to capture user preference by optimizing user-product
co-occurrence in a Heterogeneous Information Network while the Decoder
simultaneously learns a mapping to transform product image features to the
Skip-Gram embedding space. This architecture is jointly optimized in an
end-to-end, multitask fashion. The proposed framework enables us to make
personalized recommendations for cold-start products which have no purchase
history. Experiments conducted on large real-world datasets show that the
learned embeddings can generate effective recommendations using nearest
neighbour searches.
"
2783,"Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video
  Grounding","  Spatio-temporal video grounding aims to retrieve the spatio-temporal tube of
a queried object according to the given sentence. Currently, most existing
grounding methods are restricted to well-aligned segment-sentence pairs. In
this paper, we explore spatio-temporal video grounding on unaligned data and
multi-form sentences. This challenging task requires to capture critical object
relations to identify the queried target. However, existing approaches cannot
distinguish notable objects and remain in ineffective relation modeling between
unnecessary objects. Thus, we propose a novel object-aware multi-branch
relation network for object-aware relation discovery. Concretely, we first
devise multiple branches to develop object-aware region modeling, where each
branch focuses on a crucial object mentioned in the sentence. We then propose
multi-branch relation reasoning to capture critical object relationships
between the main branch and auxiliary branches. Moreover, we apply a diversity
loss to make each branch only pay attention to its corresponding object and
boost multi-branch learning. The extensive experiments show the effectiveness
of our proposed method.
"
2784,"Regularized Two-Branch Proposal Networks for Weakly-Supervised Moment
  Retrieval in Videos","  Video moment retrieval aims to localize the target moment in an video
according to the given sentence. The weak-supervised setting only provides the
video-level sentence annotations during training. Most existing weak-supervised
methods apply a MIL-based framework to develop inter-sample confrontment, but
ignore the intra-sample confrontment between moments with semantically similar
contents. Thus, these methods fail to distinguish the target moment from
plausible negative moments. In this paper, we propose a novel Regularized
Two-Branch Proposal Network to simultaneously consider the inter-sample and
intra-sample confrontments. Concretely, we first devise a language-aware filter
to generate an enhanced video stream and a suppressed video stream. We then
design the sharable two-branch proposal module to generate positive proposals
from the enhanced stream and plausible negative proposals from the suppressed
one for sufficient confrontment. Further, we apply the proposal regularization
to stabilize the training process and improve model performance. The extensive
experiments show the effectiveness of our method. Our code is released at here.
"
2785,"Query Twice: Dual Mixture Attention Meta Learning for Video
  Summarization","  Video summarization aims to select representative frames to retain high-level
information, which is usually solved by predicting the segment-wise importance
score via a softmax function. However, softmax function suffers in retaining
high-rank representations for complex visual or sequential information, which
is known as the Softmax Bottleneck problem. In this paper, we propose a novel
framework named Dual Mixture Attention (DMASum) model with Meta Learning for
video summarization that tackles the softmax bottleneck problem, where the
Mixture of Attention layer (MoA) effectively increases the model capacity by
employing twice self-query attention that can capture the second-order changes
in addition to the initial query-key attention, and a novel Single Frame Meta
Learning rule is then introduced to achieve more generalization to small
datasets with limited training sources. Furthermore, the DMASum significantly
exploits both visual and sequential attention that connects local key-frame and
global attention in an accumulative way. We adopt the new evaluation protocol
on two public datasets, SumMe, and TVSum. Both qualitative and quantitative
experiments manifest significant improvements over the state-of-the-art
methods.
"
2786,Assessing the Quality-of-Experience of Adaptive Bitrate Video Streaming,"  The diversity of video delivery pipeline poses a grand challenge to the
evaluation of adaptive bitrate (ABR) streaming algorithms and objective
quality-of-experience (QoE) models. Here we introduce so-far the largest
subject-rated database of its kind, namely WaterlooSQoE-IV, consisting of 1350
adaptive streaming videos created from diverse source contents, video encoders,
network traces, ABR algorithms, and viewing devices. We collect human opinions
for each video with a series of carefully designed subjective experiments.
Subsequent data analysis and testing/comparison of ABR algorithms and QoE
models using the database lead to a series of novel observations and
interesting findings, in terms of the effectiveness of subjective experiment
methodologies, the interactions between user experience and source content,
viewing device and encoder type, the heterogeneities in the bias and preference
of user experiences, the behaviors of ABR algorithms, and the performance of
objective QoE models. Most importantly, our results suggest that a better
objective QoE model, or a better understanding of human perceptual experience
and behaviour, is the most dominating factor in improving the performance of
ABR algorithms, as opposed to advanced optimization frameworks, machine
learning strategies or bandwidth predictors, where a majority of ABR research
has been focused on in the past decade. On the other hand, our performance
evaluation of 11 QoE models shows only a moderate correlation between
state-of-the-art QoE models and subjective ratings, implying rooms for
improvement in both QoE modeling and ABR algorithms. The database is made
publicly available at: \url{https://ece.uwaterloo.ca/~zduanmu/waterloosqoe4/}.
"
2787,Multi-modal Cooking Workflow Construction for Food Recipes,"  Understanding food recipe requires anticipating the implicit causal effects
of cooking actions, such that the recipe can be converted into a graph
describing the temporal workflow of the recipe. This is a non-trivial task that
involves common-sense reasoning. However, existing efforts rely on hand-crafted
features to extract the workflow graph from recipes due to the lack of
large-scale labeled datasets. Moreover, they fail to utilize the cooking
images, which constitute an important part of food recipes. In this paper, we
build MM-ReS, the first large-scale dataset for cooking workflow construction,
consisting of 9,850 recipes with human-labeled workflow graphs. Cooking steps
are multi-modal, featuring both text instructions and cooking images. We then
propose a neural encoder-decoder model that utilizes both visual and textual
information to construct the cooking workflow, which achieved over 20%
performance gain over existing hand-crafted baselines.
"
2788,DTDN: Dual-task De-raining Network,"  Removing rain streaks from rainy images is necessary for many tasks in
computer vision, such as object detection and recognition. It needs to address
two mutually exclusive objectives: removing rain streaks and reserving
realistic details. Balancing them is critical for de-raining methods. We
propose an end-to-end network, called dual-task de-raining network (DTDN),
consisting of two sub-networks: generative adversarial network (GAN) and
convolutional neural network (CNN), to remove rain streaks via coordinating the
two mutually exclusive objectives self-adaptively. DTDN-GAN is mainly used to
remove structural rain streaks, and DTDN-CNN is designed to recover details in
original images. We also design a training algorithm to train these two
sub-networks of DTDN alternatively, which share same weights but use different
training sets. We further enrich two existing datasets to approximate the
distribution of real rain streaks. Experimental results show that our method
outperforms several recent state-of-the-art methods, based on both benchmark
testing datasets and real rainy images.
"
2789,Graph Neural Networks for 3D Multi-Object Tracking,"  3D Multi-object tracking (MOT) is crucial to autonomous systems. Recent work
often uses a tracking-by-detection pipeline, where the feature of each object
is extracted independently to compute an affinity matrix. Then, the affinity
matrix is passed to the Hungarian algorithm for data association. A key process
of this pipeline is to learn discriminative features for different objects in
order to reduce confusion during data association. To that end, we propose two
innovative techniques: (1) instead of obtaining the features for each object
independently, we propose a novel feature interaction mechanism by introducing
Graph Neural Networks; (2) instead of obtaining the features from either 2D or
3D space as in prior work, we propose a novel joint feature extractor to learn
appearance and motion features from 2D and 3D space. Through experiments on the
KITTI dataset, our proposed method achieves state-of-the-art 3D MOT
performance. Our project website is at
http://www.xinshuoweng.com/projects/GNN3DMOT.
"
2790,"NANCY: Neural Adaptive Network Coding methodologY for video distribution
  over wireless networks","  This paper presents NANCY, a system that generates adaptive bit rates (ABR)
for video and adaptive network coding rates (ANCR) using reinforcement learning
(RL) for video distribution over wireless networks. NANCY trains a neural
network model with rewards formulated as quality of experience (QoE) metrics.
It performs joint optimization in order to select: (i) adaptive bit rates for
future video chunks to counter variations in available bandwidth and (ii)
adaptive network coding rates to encode the video chunk slices to counter
packet losses in wireless networks. We present the design and implementation of
NANCY, and evaluate its performance compared to state-of-the-art video rate
adaptation algorithms including Pensieve and robustMPC. Our results show that
NANCY provides 29.91% and 60.34% higher average QoE than Pensieve and
robustMPC, respectively.
"
2791,"Evaluation Of Issues, Usability And Functionality Of Dietary Related
  Mobile Applications: A Systematic Literature Review","  With rapid technology advancements and increased usage of handheld devices
such as smartphones, tablets, and smartwatches, people's reliance on these
devices has grown beyond their utility as a means to communicate. Today, these
devices are also helping people make healthier lifestyle choices regarding
nutrition through different dietary applications, thereby saving expensive
visits to doctors and nutritionists. These applications provide awareness about
nutritional habits and keep track of a person's physical activity for planning
their dietary needs. However, the selection or development of the dietary
application for catering individual needs, and implementing successful
interventions toward behavioral change is a challenging process. Therefore, the
following research exercise aims to review existing nutritional applications at
length to highlight key features and problems that enhance or undermine an
application's usability and build the case for a generalized implementation
that can cater to most people's needs. The findings from this analysis will
help to inform the future development of more effective mobile apps.
Furthermore, it will also help develop standard guidelines by keeping in view
dietician's and researcher's perspective.
"
2792,ByeGlassesGAN: Identity Preserving Eyeglasses Removal for Face Images,"  In this paper, we propose a novel image-to-image GAN framework for eyeglasses
removal, called ByeGlassesGAN, which is used to automatically detect the
position of eyeglasses and then remove them from face images. Our ByeGlassesGAN
consists of an encoder, a face decoder, and a segmentation decoder. The encoder
is responsible for extracting information from the source face image, and the
face decoder utilizes this information to generate glasses-removed images. The
segmentation decoder is included to predict the segmentation mask of eyeglasses
and completed face region. The feature vectors generated by the segmentation
decoder are shared with the face decoder, which facilitates better
reconstruction results. Our experiments show that ByeGlassesGAN can provide
visually appealing results in the eyeglasses-removed face images even for
semi-transparent color eyeglasses or glasses with glare. Furthermore, we
demonstrate significant improvement in face recognition accuracy for face
images with glasses by applying our method as a pre-processing step in our face
recognition experiment.
"
2793,Low Complexity Trellis-Coded Quantization in Versatile Video Coding,"  The forthcoming Versatile Video Coding (VVC) standard adopts the
trellis-coded quantization, which leverages the delicate trellis graph to map
the quantization candidates within one block into the optimal path. Despite the
high compression efficiency, the complex trellis search with soft decision
quantization may hinder the applications due to high complexity and low
throughput capacity. To reduce the complexity, in this paper, we propose a low
complexity trellis-coded quantization scheme in a scientifically sound way with
theoretical modeling of the rate and distortion. As such, the trellis departure
point can be adaptively adjusted, and unnecessarily visited branches are
accordingly pruned, leading to the shrink of total trellis stages and
simplification of transition branches. Extensive experimental results on the
VVC test model show that the proposed scheme is effective in reducing the
encoding complexity by 11% and 5% with all intra and random access
configurations, respectively, at the cost of only 0.11% and 0.05% BD-Rate
increase. Meanwhile, on average 24% and 27% quantization time savings can be
achieved under all intra and random access configurations. Due to the excellent
performance, the VVC test model has adopted one implementation of the proposed
scheme.
"
2794,"High Efficiency Rate Control for Versatile Video Coding Based on
  Composite Cauchy Distribution","  In this work, we propose a novel rate control algorithm for Versatile Video
Coding (VVC) standard based on its distinct rate-distortion characteristics. By
modelling the transform coefficients with the composite Cauchy distribution,
higher accuracy compared with traditional distributions has been achieved.
Based on the transform coefficient modelling, the theoretically derived R-Q and
D-Q models which have been shown to deliver higher accuracy in characterizing
RD characteristics for sequences with different content are incorporated into
the rate control process. Furthermore, to establish an adaptive bit allocation
scheme, the dependency between different levels of frames is modelled by a
dependency factor to describe relationship between the reference and
to-be-coded frames. Given the derived R-Q and D-Q relationships, as well as the
dependency factor, an adaptive bit allocation scheme is developed for optimal
bits allocation. We implement the proposed algorithm on VVC Test Model (VTM)
3.0. Experiments show that due to proper bit allocation, for low delay
configuration the proposed algorithm can achieve 1.03% BD-Rate saving compared
with the default rate control algorithm and 2.96% BD-Rate saving compared with
fixed QP scheme. Moreover, 1.29% BD-Rate saving and higher control accuracy
have also been observed under the random access configuration.
"
2795,"Multi-task deep CNN model for no-reference image quality assessment on
  smartphone camera photos","  Smartphone is the most successful consumer electronic product in today's
mobile social network era. The smartphone camera quality and its image
post-processing capability is the dominant factor that impacts consumer's
buying decision. However, the quality evaluation of photos taken from
smartphones remains a labor-intensive work and relies on professional
photographers and experts. As an extension of the prior CNN-based NR-IQA
approach, we propose a multi-task deep CNN model with scene type detection as
an auxiliary task. With the shared model parameters in the convolution layer,
the learned feature maps could become more scene-relevant and enhance the
performance. The evaluation result shows improved SROCC performance compared to
traditional NR-IQA methods and single task CNN-based models.
"
2796,Quality of Service (QoS): Measurements of Video Streaming,"  Nowadays video streaming is growing over the social clouds, where end-users
always want to share High Definition (HD) videos among friends. Mostly videos
were recorded via smartphones and other HD devices and short time videos have a
big file size. The big file size of videos required high bandwidth to upload
and download on the Internet and also required more time to load in a web page
for play. So avoiding this problem social cloud compress videos during the
upload for smooth play and fast loading in a web page. Compression decreases
the video quality which also decreases the quality of experience of end users.
In this paper we measure the QoS of different standard video file formats on
social clouds; they varied from each other in resolution, audio/video bitrate,
and storage size.
"
2797,"Rate distortion optimization over large scale video corpus with machine
  learning","  We present an efficient codec-agnostic method for bitrate allocation over a
large scale video corpus with the goal of minimizing the average bitrate
subject to constraints on average and minimum quality. Our method clusters the
videos in the corpus such that videos within one cluster have similar
rate-distortion (R-D) characteristics. We train a support vector machine
classifier to predict the R-D cluster of a video using simple video complexity
features that are computationally easy to obtain. The model allows us to
classify a large sample of the corpus in order to estimate the distribution of
the number of videos in each of the clusters. We use this distribution to find
the optimal encoder operating point for each R-D cluster. Experiments with AV1
encoder show that our method can achieve the same average quality over the
corpus with $22\%$ less average bitrate.
"
2798,"Semantics Preserving Hierarchy based Retrieval of Indian heritage
  monuments","  Monument classification can be performed on the basis of their appearance and
shape from coarse to fine categories. Although there is much semantic
information present in the monuments which is reflected in the eras they were
built, its type or purpose, the dynasty which established it, etc.
Particularly, Indian subcontinent exhibits a huge deal of variation in terms of
architectural styles owing to its rich cultural heritage. In this paper, we
propose a framework that utilizes hierarchy to preserve semantic information
while performing image classification or image retrieval. We encode the learnt
deep embeddings to construct a dictionary of images and then utilize a
re-ranking framework on the the retrieved results using DeLF features. The
semantic information preserved in these embeddings helps to classify unknown
monuments at higher level of granularity in hierarchy. We have curated a large,
novel Indian heritage monuments dataset comprising of images of historical,
cultural and religious importance with subtypes of eras, dynasties and
architectural styles. We demonstrate the performance of the proposed framework
in image classification and retrieval tasks and compare it with other competing
methods on this dataset.
"
2799,Personal Food Model,"  Food is central to life. Food provides us with energy and foundational
building blocks for our body and is also a major source of joy and new
experiences. A significant part of the overall economy is related to food. Food
science, distribution, processing, and consumption have been addressed by
different communities using silos of computational approaches. In this paper,
we adopt a person-centric multimedia and multimodal perspective on food
computing and show how multimedia and food computing are synergistic and
complementary.
  Enjoying food is a truly multimedia experience involving sight, taste, smell,
and even sound, that can be captured using a multimedia food logger. The
biological response to food can be captured using multimodal data streams using
available wearable devices. Central to this approach is the Personal Food
Model. Personal Food Model is the digitized representation of the food-related
characteristics of an individual. It is designed to be used in food
recommendation systems to provide eating-related recommendations that improve
the user's quality of life. To model the food-related characteristics of each
person, it is essential to capture their food-related enjoyment using a
Preferential Personal Food Model and their biological response to food using
their Biological Personal Food Model. Inspired by the power of 3-dimensional
color models for visual processing, we introduce a 6-dimensional taste-space
for capturing culinary characteristics as well as personal preferences. We use
event mining approaches to relate food with other life and biological events to
build a predictive model that could also be used effectively in emerging food
recommendation systems.
"
2800,Dual Attention GANs for Semantic Image Synthesis,"  In this paper, we focus on the semantic image synthesis task that aims at
transferring semantic label maps to photo-realistic images. Existing methods
lack effective semantic constraints to preserve the semantic information and
ignore the structural correlations in both spatial and channel dimensions,
leading to unsatisfactory blurry and artifact-prone results. To address these
limitations, we propose a novel Dual Attention GAN (DAGAN) to synthesize
photo-realistic and semantically-consistent images with fine details from the
input layouts without imposing extra training overhead or modifying the network
architectures of existing methods. We also propose two novel modules, i.e.,
position-wise Spatial Attention Module (SAM) and scale-wise Channel Attention
Module (CAM), to capture semantic structure attention in spatial and channel
dimensions, respectively. Specifically, SAM selectively correlates the pixels
at each position by a spatial attention map, leading to pixels with the same
semantic label being related to each other regardless of their spatial
distances. Meanwhile, CAM selectively emphasizes the scale-wise features at
each channel by a channel attention map, which integrates associated features
among all channel maps regardless of their scales. We finally sum the outputs
of SAM and CAM to further improve feature representation. Extensive experiments
on four challenging datasets show that DAGAN achieves remarkably better results
than state-of-the-art methods, while using fewer model parameters. The source
code and trained models are available at https://github.com/Ha0Tang/DAGAN.
"
2801,"Joint Transmission in QoE-Driven Backhaul-Aware MC-NOMA Cognitive Radio
  Network","  In this paper, we develop a resource allocation framework to optimize the
downlink transmission of a backhaul-aware multi-cell cognitive radio network
(CRN) which is enabled with multi-carrier non-orthogonal multiple access
(MC-NOMA). The considered CRN is composed of a single macro base station (MBS)
and multiple small BSs (SBSs) that are referred to as the primary and secondary
tiers, respectively. For the primary tier, we consider orthogonal frequency
division multiple access (OFDMA) scheme and also Quality of Service (QoS) to
evaluate the user satisfaction. On the other hand in secondary tier, MC-NOMA is
employed and the user satisfaction for web, video and audio as popular
multimedia services is evaluated by Quality-of-Experience (QoE). Furthermore,
each user in secondary tier can be served simultaneously by multiple SBSs over
a subcarrier via Joint Transmission (JT). In particular, we formulate a joint
optimization problem of power control and scheduling (i.e., user association
and subcarrier allocation) in secondary tier to maximize total achievable QoE
for the secondary users. An efficient resource allocation mechanism has been
developed to handle the non-linear form interference and to overcome the
non-convexity of QoE serving functions. The scheduling and power control policy
leverage on Augmented Lagrangian Method (ALM). Simulation results reveal that
proposed solution approach can control the interference and JT-NOMA improves
total perceived QoE compared to the existing schemes.
"
2802,"Augmented Reality-Based Advanced Driver-Assistance System for Connected
  Vehicles","  With the development of advanced communication technology, connected vehicles
become increasingly popular in our transportation systems, which can conduct
cooperative maneuvers with each other as well as road entities through
vehicle-to-everything communication. A lot of research interests have been
drawn to other building blocks of a connected vehicle system, such as
communication, planning, and control. However, less research studies were
focused on the human-machine cooperation and interface, namely how to visualize
the guidance information to the driver as an advanced driver-assistance system
(ADAS). In this study, we propose an augmented reality (AR)-based ADAS, which
visualizes the guidance information calculated cooperatively by multiple
connected vehicles. An unsignalized intersection scenario is adopted as the use
case of this system, where the driver can drive the connected vehicle crossing
the intersection under the AR guidance, without any full stop at the
intersection. A simulation environment is built in Unity game engine based on
the road network of San Francisco, and human-in-the-loop (HITL) simulation is
conducted to validate the effectiveness of our proposed system regarding travel
time and energy consumption.
"
2803,"Vyaktitv: A Multimodal Peer-to-Peer Hindi Conversations based Dataset
  for Personality Assessment","  Automatically detecting personality traits can aid several applications, such
as mental health recognition and human resource management. Most datasets
introduced for personality detection so far have analyzed these traits for each
individual in isolation. However, personality is intimately linked to our
social behavior. Furthermore, surprisingly little research has focused on
personality analysis using low resource languages. To this end, we present a
novel peer-to-peer Hindi conversation dataset- Vyaktitv. It consists of
high-quality audio and video recordings of the participants, with Hinglish
textual transcriptions for each conversation. The dataset also contains a rich
set of socio-demographic features, like income, cultural orientation, amongst
several others, for all the participants. We release the dataset for public
use, as well as perform preliminary statistical analysis along the different
dimensions. Finally, we also discuss various other applications and tasks for
which the dataset can be employed.
"
2804,"Online Multi-Object Tracking and Segmentation with GMPHD Filter and
  Simple Affinity Fusion","  In this paper, we propose a highly practical fully online multi-object
tracking and segmentation (MOTS) method that uses instance segmentation results
as an input in video. The proposed method exploits the Gaussian mixture
probability hypothesis density (GMPHD) filter for online approach which is
extended with a hierarchical data association (HDA) and a simple affinity
fusion (SAF) model. HDA consists of segment-to-track and track-to-track
associations. To build the SAF model, an affinity is computed by using the
GMPHD filter that is represented by the Gaussian mixture models with position
and motion mean vectors, and another affinity for appearance is computed by
using the responses from single object tracker such as the kernalized
correlation filters. These two affinities are simply fused by using a
score-level fusion method such as Min-max normalization. In addition, to reduce
false positive segments, we adopt Mask IoU based merging. In experiments, those
key modules, i.e., HDA, SAF, and Mask merging show incremental improvements.
For instance, ID-switch decreases by half compared to baseline method. In
conclusion, our tracker achieves state-of-the-art level MOTS performance.
"
2805,"Unsupervised Single-Image Reflection Separation Using Perceptual Deep
  Image Priors","  Reflections often degrade the quality of the image by obstructing the
background scene. This is not desirable for everyday users, and it negatively
impacts the performance of multimedia applications that process images with
reflections. Most current methods for removing reflections utilize
supervised-learning models. However, these models require an extensive number
of image pairs to perform well, especially on natural images with reflection,
which is difficult to achieve in practice. In this paper, we propose a novel
unsupervised framework for single-image reflection separation. Instead of
learning from a large dataset, we optimize the parameters of two cross-coupled
deep convolutional networks on a target image to generate two exclusive
background and reflection layers. In particular, we design a new architecture
of the network to embed semantic features extracted from a pre-trained deep
classification network, which gives more meaningful separation similar to human
perception. Quantitative and qualitative results on commonly used datasets in
the literature show that our method's performance is at least on par with the
state-of-the-art supervised methods and, occasionally, better without requiring
large training datasets. Our results also show that our method significantly
outperforms the closest unsupervised method in the literature for removing
reflections from single images.
"
2806,Depth Range Reduction for 3D Range Geometry Compression,"  Three-dimensional (3D) shape measurement devices and techniques are being
rapidly adopted within a variety of industries and applications. As acquiring
3D range data becomes faster and more accurate it becomes more challenging to
efficiently store, transmit, or stream this data. One prevailing approach to
compressing 3D range data is to encode it within the color channels of regular
2D images. This paper presents a novel method for reducing the depth range of a
3D geometry such that it can be stored within a 2D image using lower encoding
frequencies (or a fewer number of encoding periods). This allows for smaller
compressed file sizes to be achieved without a proportional increase in
reconstruction errors. Further, as the proposed method occurs prior to
encoding, it is readily compatible with a variety of existing image-based 3D
range geometry compression methods.
"
2807,"Embedded Blockchains: A Synthesis of Blockchains, Spread Spectrum
  Watermarking, Perceptual Hashing & Digital Signatures","  In this paper we introduce a scheme for detecting manipulated audio and
video. The scheme is a synthesis of blockchains, encrypted spread spectrum
watermarks, perceptual hashing and digital signatures, which we call an
Embedded Blockchain. Within this scheme, we use the blockchain for its data
structure of a cryptographically linked list, cryptographic hashing for
absolute comparisons, perceptual hashing for flexible comparisons, digital
signatures for proof of ownership, and encrypted spread spectrum watermarking
to embed the blockchain into the background noise of the media. So each media
recording has its own unique blockchain, with each block holding information
describing the media segment. The problem of verifying the integrity of the
media is recast to traversing the blockchain, block-by-block, and
segment-by-segment of the media. If any chain is broken, the difference in the
computed and extracted perceptual hash is used to estimate the level of
manipulation.
"
2808,"Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression
  Grounding","  The prevailing framework for solving referring expression grounding is based
on a two-stage process: 1) detecting proposals with an object detector and 2)
grounding the referent to one of the proposals. Existing two-stage solutions
mostly focus on the grounding step, which aims to align the expressions with
the proposals. In this paper, we argue that these methods overlook an obvious
mismatch between the roles of proposals in the two stages: they generate
proposals solely based on the detection confidence (i.e., expression-agnostic),
hoping that the proposals contain all right instances in the expression (i.e.,
expression-aware). Due to this mismatch, current two-stage methods suffer from
a severe performance drop between detected and ground-truth proposals. To this
end, we propose Ref-NMS, which is the first method to yield expression-aware
proposals at the first stage. Ref-NMS regards all nouns in the expression as
critical objects, and introduces a lightweight module to predict a score for
aligning each box with a critical object. These scores can guide the
NMSoperation to filter out the boxes irrelevant to the expression, increasing
the recall of critical objects, resulting in a significantly improved grounding
performance. Since Ref-NMS is agnostic to the grounding step, it can be easily
integrated into any state-of-the-art two-stage method. Extensive ablation
studies on several backbones, benchmarks, and tasks consistently demonstrate
the superiority of Ref-NMS.
"
2809,Robust Homomorphic Video Hashing,"  The Internet has been weaponized to carry out cybercriminal activities at an
unprecedented pace. The rising concerns for preserving the privacy of personal
data while availing modern tools and technologies is alarming. End-to-end
encrypted solutions are in demand for almost all commercial platforms. On one
side, it seems imperative to provide such solutions and give people trust to
reliably use these platforms. On the other side, this creates a huge
opportunity to carry out unchecked cybercrimes. This paper proposes a robust
video hashing technique, scalable and efficient in chalking out matches from an
enormous bulk of videos floating on these commercial platforms. The video hash
is validated to be robust to common manipulations like scaling, corruptions by
noise, compression, and contrast changes that are most probable to happen
during transmission. It can also be transformed into the encrypted domain and
work on top of encrypted videos without deciphering. Thus, it can serve as a
potential forensic tool that can trace the illegal sharing of videos without
knowing the underlying content. Hence, it can help preserve privacy and combat
cybercrimes such as revenge porn, hateful content, child abuse, or illegal
material propagated in a video.
"
2810,"Detection of AI-Synthesized Speech Using Cepstral & Bispectral
  Statistics","  Digital technology has made possible unimaginable applications come true. It
seems exciting to have a handful of tools for easy editing and manipulation,
but it raises alarming concerns that can propagate as speech clones,
duplicates, or maybe deep fakes. Validating the authenticity of a speech is one
of the primary problems of digital audio forensics. We propose an approach to
distinguish human speech from AI synthesized speech exploiting the Bi-spectral
and Cepstral analysis. Higher-order statistics have less correlation for human
speech in comparison to a synthesized speech. Also, Cepstral analysis revealed
a durable power component in human speech that is missing for a synthesized
speech. We integrate both these analyses and propose a machine learning model
to detect AI synthesized speech.
"
2811,"Dynamic Context-guided Capsule Network for Multimodal Machine
  Translation","  Multimodal machine translation (MMT), which mainly focuses on enhancing
text-only translation with visual features, has attracted considerable
attention from both computer vision and natural language processing
communities. Most current MMT models resort to attention mechanism, global
context modeling or multimodal joint representation learning to utilize visual
features. However, the attention mechanism lacks sufficient semantic
interactions between modalities while the other two provide fixed visual
context, which is unsuitable for modeling the observed variability when
generating translation. To address the above issues, in this paper, we propose
a novel Dynamic Context-guided Capsule Network (DCCN) for MMT. Specifically, at
each timestep of decoding, we first employ the conventional source-target
attention to produce a timestep-specific source-side context vector. Next, DCCN
takes this vector as input and uses it to guide the iterative extraction of
related visual features via a context-guided dynamic routing mechanism.
Particularly, we represent the input image with global and regional visual
features, we introduce two parallel DCCNs to model multimodal context vectors
with visual features at different granularities. Finally, we obtain two
multimodal context vectors, which are fused and incorporated into the decoder
for the prediction of the target word. Experimental results on the Multi30K
dataset of English-to-German and English-to-French translation demonstrate the
superiority of DCCN. Our code is available on
https://github.com/DeepLearnXMU/MM-DCCN.
"
2812,"Semi-supervised Multi-modal Emotion Recognition with Cross-Modal
  Distribution Matching","  Automatic emotion recognition is an active research topic with wide range of
applications. Due to the high manual annotation cost and inevitable label
ambiguity, the development of emotion recognition dataset is limited in both
scale and quality. Therefore, one of the key challenges is how to build
effective models with limited data resource. Previous works have explored
different approaches to tackle this challenge including data enhancement,
transfer learning, and semi-supervised learning etc. However, the weakness of
these existing approaches includes such as training instability, large
performance loss during transfer, or marginal improvement.
  In this work, we propose a novel semi-supervised multi-modal emotion
recognition model based on cross-modality distribution matching, which
leverages abundant unlabeled data to enhance the model training under the
assumption that the inner emotional status is consistent at the utterance level
across modalities.
  We conduct extensive experiments to evaluate the proposed model on two
benchmark datasets, IEMOCAP and MELD. The experiment results prove that the
proposed semi-supervised learning model can effectively utilize unlabeled data
and combine multi-modalities to boost the emotion recognition performance,
which outperforms other state-of-the-art approaches under the same condition.
The proposed model also achieves competitive capacity compared with existing
approaches which take advantage of additional auxiliary information such as
speaker and interaction context.
"
2813,A Convolutional Neural Network-Based Low Complexity Filter,"  Convolutional Neural Network (CNN)-based filters have achieved significant
performance in video artifacts reduction. However, the high complexity of
existing methods makes it difficult to be applied in real usage. In this paper,
a CNN-based low complexity filter is proposed. We utilize depth separable
convolution (DSC) merged with the batch normalization (BN) as the backbone of
our proposed CNN-based network. Besides, a weight initialization method is
proposed to enhance the training performance. To solve the well known over
smoothing problem for the inter frames, a frame-level residual mapping (RM) is
presented. We analyze some of the mainstream methods like frame-level and
block-level based filters quantitatively and build our CNN-based filter with
frame-level control to avoid the extra complexity and artificial boundaries
caused by block-level control. In addition, a novel module called RM is
designed to restore the distortion from the learned residuals. As a result, we
can effectively improve the generalization ability of the learning-based filter
and reach an adaptive filtering effect. Moreover, this module is flexible and
can be combined with other learning-based filters. The experimental results
show that our proposed method achieves significant BD-rate reduction than
H.265/HEVC. It achieves about 1.2% BD-rate reduction and 79.1% decrease in
FLOPs than VR-CNN. Finally, the measurement on H.266/VVC and ablation studies
are also conducted to ensure the effectiveness of the proposed method.
"
2814,Visual Sentiment Analysis from Disaster Images in Social Media,"  The increasing popularity of social networks and users' tendency towards
sharing their feelings, expressions, and opinions in text, visual, and audio
content, have opened new opportunities and challenges in sentiment analysis.
While sentiment analysis of text streams has been widely explored in
literature, sentiment analysis from images and videos is relatively new. This
article focuses on visual sentiment analysis in a societal important domain,
namely disaster analysis in social media. To this aim, we propose a deep visual
sentiment analyzer for disaster related images, covering different aspects of
visual sentiment analysis starting from data collection, annotation, model
selection, implementation, and evaluations. For data annotation, and analyzing
peoples' sentiments towards natural disasters and associated images in social
media, a crowd-sourcing study has been conducted with a large number of
participants worldwide. The crowd-sourcing study resulted in a large-scale
benchmark dataset with four different sets of annotations, each aiming a
separate task. The presented analysis and the associated dataset will provide a
baseline/benchmark for future research in the domain. We believe the proposed
system can contribute toward more livable communities by helping different
stakeholders, such as news broadcasters, humanitarian organizations, as well as
the general public.
"
2815,Deepfake detection: humans vs. machines,"  Deepfake videos, where a person's face is automatically swapped with a face
of someone else, are becoming easier to generate with more realistic results.
In response to the threat such manipulations can pose to our trust in video
evidence, several large datasets of deepfake videos and many methods to detect
them were proposed recently. However, it is still unclear how realistic
deepfake videos are for an average person and whether the algorithms are
significantly better than humans at detecting them. In this paper, we present a
subjective study conducted in a crowdsourcing-like scenario, which
systematically evaluates how hard it is for humans to see if the video is
deepfake or not. For the evaluation, we used 120 different videos (60 deepfakes
and 60 originals) manually pre-selected from the Facebook deepfake database,
which was provided in the Kaggle's Deepfake Detection Challenge 2020. For each
video, a simple question: ""Is face of the person in the video real of fake?""
was answered on average by 19 na\""ive subjects. The results of the subjective
evaluation were compared with the performance of two different state of the art
deepfake detection methods, based on Xception and EfficientNets (B4 variant)
neural networks, which were pre-trained on two other large public databases:
the Google's subset from FaceForensics++ and the recent Celeb-DF dataset. The
evaluation demonstrates that while the human perception is very different from
the perception of a machine, both successfully but in different ways are fooled
by deepfakes. Specifically, algorithms struggle to detect those deepfake
videos, which human subjects found to be very easy to spot.
"
2816,User-assisted Video Reflection Removal,"  Reflections in videos are obstructions that often occur when videos are taken
behind reflective surfaces like glass. These reflections reduce the quality of
such videos, lead to information loss and degrade the accuracy of many computer
vision algorithms. A video containing reflections is a combination of
background and reflection layers. Thus, reflection removal is equivalent to
decomposing the video into two layers. This, however, is a challenging and
ill-posed problem as there is an infinite number of valid decompositions. To
address this problem, we propose a user-assisted method for video reflection
removal. We rely on both spatial and temporal information and utilize sparse
user hints to help improve separation. The key idea of the proposed method is
to use motion cues to separate the background layer from the reflection layer
with minimal user assistance. We show that user-assistance significantly
improves the layer separation results. We implement and evaluate the proposed
method through quantitative and qualitative results on real and synthetic
videos. Our experiments show that the proposed method successfully removes
reflection from video sequences, does not introduce visual distortions, and
significantly outperforms the state-of-the-art reflection removal methods in
the literature.
"
2817,"Deep Local and Global Spatiotemporal Feature Aggregation for Blind Video
  Quality Assessment","  In recent years, deep learning has achieved promising success for multimedia
quality assessment, especially for image quality assessment (IQA). However,
since there exist more complex temporal characteristics in videos, very little
work has been done on video quality assessment (VQA) by exploiting powerful
deep convolutional neural networks (DCNNs). In this paper, we propose an
efficient VQA method named Deep SpatioTemporal video Quality assessor (DeepSTQ)
to predict the perceptual quality of various distorted videos in a no-reference
manner. In the proposed DeepSTQ, we first extract local and global
spatiotemporal features by pre-trained deep learning models without fine-tuning
or training from scratch. The composited features consider distorted video
frames as well as frame difference maps from both global and local views. Then,
the feature aggregation is conducted by the regression model to predict the
perceptual video quality. Finally, experimental results demonstrate that our
proposed DeepSTQ outperforms state-of-the-art quality assessment algorithms.
"
2818,An optimal mode selection algorithm for scalable video coding,"  Scalable video coding (SVC) is extended from its predecessor advanced video
coding (AVC) because of its flexible transmission to all type of gadgets.
However, SVC is more flexible and scalable than AVC, but it is more complex in
determining the computations than AVC. The traditional full search method in
the standard H.264 SVC consumes more encoding time for computation. This
complexity in computation need to be reduced and many fast mode decision (FMD)
algorithms were developed, but many fail to balance in all the three measures
such as peak signal to noise ratio (PSNR), encoding time and bit rate. In this
paper, the proposed optimal mode selection algorithm based on the orientation
of pixels achieves better time saving, good PSNR and coding efficiency. The
proposed algorithm is compared with the standard H.264 JSVM reference software
and found to be 57.44% time saving, 0.43 dB increments in PSNR and 0.23%
compression in bit rate.
"
2819,Multi-modal Attention for Speech Emotion Recognition,"  Emotion represents an essential aspect of human speech that is manifested in
speech prosody. Speech, visual, and textual cues are complementary in human
communication. In this paper, we study a hybrid fusion method, referred to as
multi-modal attention network (MMAN) to make use of visual and textual cues in
speech emotion recognition. We propose a novel multi-modal attention mechanism,
cLSTM-MMA, which facilitates the attention across three modalities and
selectively fuse the information. cLSTM-MMA is fused with other uni-modal
sub-networks in the late fusion. The experiments show that speech emotion
recognition benefits significantly from visual and textual cues, and the
proposed cLSTM-MMA alone is as competitive as other fusion methods in terms of
accuracy, but with a much more compact network structure. The proposed hybrid
network MMAN achieves state-of-the-art performance on IEMOCAP database for
emotion recognition.
"
2820,Key-Point Sequence Lossless Compression for Intelligent Video Analysis,"  Feature coding has been recently considered to facilitate intelligent video
analysis for urban computing. Instead of raw videos, extracted features in the
front-end are encoded and transmitted to the back-end for further processing.
In this article, we present a lossless key-point sequence compression approach
for efficient feature coding. The essence of this predict-and-encode strategy
is to eliminate the spatial and temporal redundancies of key points in videos.
Multiple prediction modes with an adaptive mode selection method are proposed
to handle key-point sequences with various structures and motion. Experimental
results validate the effectiveness of the proposed scheme on four types of
widely used key-point sequences in video analysis.
"
2821,"Emotion-Based End-to-End Matching Between Image and Music in
  Valence-Arousal Space","  Both images and music can convey rich semantics and are widely used to induce
specific emotions. Matching images and music with similar emotions might help
to make emotion perceptions more vivid and stronger. Existing emotion-based
image and music matching methods either employ limited categorical emotion
states which cannot well reflect the complexity and subtlety of emotions, or
train the matching model using an impractical multi-stage pipeline. In this
paper, we study end-to-end matching between image and music based on emotions
in the continuous valence-arousal (VA) space. First, we construct a large-scale
dataset, termed Image-Music-Emotion-Matching-Net (IMEMNet), with over 140K
image-music pairs. Second, we propose cross-modal deep continuous metric
learning (CDCML) to learn a shared latent embedding space which preserves the
cross-modal similarity relationship in the continuous matching space. Finally,
we refine the embedding space by further preserving the single-modal emotion
relationship in the VA spaces of both images and music. The metric learning in
the embedding space and task regression in the label space are jointly
optimized for both cross-modal matching and single-modal VA prediction. The
extensive experiments conducted on IMEMNet demonstrate the superiority of CDCML
for emotion-based image and music matching as compared to the state-of-the-art
approaches.
"
2822,OCR Graph Features for Manipulation Detection in Documents,"  Detecting manipulations in digital documents is becoming increasingly
important for information verification purposes. Due to the proliferation of
image editing software, altering key information in documents has become widely
accessible. Nearly all approaches in this domain rely on a procedural approach,
using carefully generated features and a hand-tuned scoring system, rather than
a data-driven and generalizable approach. We frame this issue as a graph
comparison problem using the character bounding boxes, and propose a model that
leverages graph features using OCR (Optical Character Recognition). Our model
relies on a data-driven approach to detect alterations by training a random
forest classifier on the graph-based OCR features. We evaluate our algorithm's
forgery detection performance on dataset constructed from real business
documents with slight forgery imperfections. Our proposed model dramatically
outperforms the most closely-related document manipulation detection model on
this task.
"
2823,Hybrid Space Learning for Language-based Video Retrieval,"  This paper attacks the challenging problem of video retrieval by text. In
such a retrieval paradigm, an end user searches for unlabeled videos by ad-hoc
queries described exclusively in the form of a natural-language sentence, with
no visual example provided. Given videos as sequences of frames and queries as
sequences of words, an effective sequence-to-sequence cross-modal matching is
crucial. To that end, the two modalities need to be first encoded into
real-valued vectors and then projected into a common space. In this paper we
achieve this by proposing a dual deep encoding network that encodes videos and
queries into powerful dense representations of their own. Our novelty is
two-fold. First, different from prior art that resorts to a specific
single-level encoder, the proposed network performs multi-level encoding that
represents the rich content of both modalities in a coarse-to-fine fashion.
Second, different from a conventional common space learning algorithm which is
either concept based or latent space based, we introduce hybrid space learning
which combines the high performance of the latent space and the good
interpretability of the concept space. Dual encoding is conceptually simple,
practically effective and end-to-end trained with hybrid space learning.
Extensive experiments on four challenging video datasets show the viability of
the new method.
"
2824,RGB2LIDAR: Towards Solving Large-Scale Cross-Modal Visual Localization,"  We study an important, yet largely unexplored problem of large-scale
cross-modal visual localization by matching ground RGB images to a
geo-referenced aerial LIDAR 3D point cloud (rendered as depth images). Prior
works were demonstrated on small datasets and did not lend themselves to
scaling up for large-scale applications. To enable large-scale evaluation, we
introduce a new dataset containing over 550K pairs (covering 143 km^2 area) of
RGB and aerial LIDAR depth images. We propose a novel joint embedding based
method that effectively combines the appearance and semantic cues from both
modalities to handle drastic cross-modal variations. Experiments on the
proposed dataset show that our model achieves a strong result of a median rank
of 5 in matching across a large test set of 50K location pairs collected from a
14km^2 area. This represents a significant advancement over prior works in
performance and scale. We conclude with qualitative results to highlight the
challenging nature of this task and the benefits of the proposed model. Our
work provides a foundation for further research in cross-modal visual
localization.
"
2825,"Micro-Facial Expression Recognition Based on Deep-Rooted Learning
  Algorithm","  Facial expressions are important cues to observe human emotions. Facial
expression recognition has attracted many researchers for years, but it is
still a challenging topic since expression features vary greatly with the head
poses, environments, and variations in the different persons involved. In this
work, three major steps are involved to improve the performance of micro-facial
expression recognition. First, an Adaptive Homomorphic Filtering is used for
face detection and rotation rectification processes. Secondly, Micro-facial
features were used to extract the appearance variations of a testing
image-spatial analysis. The features of motion information are used for
expression recognition in a sequence of facial images. An effective
Micro-Facial Expression Based Deep-Rooted Learning (MFEDRL) classifier is
proposed in this paper to better recognize spontaneous micro-expressions by
learning parameters on the optimal features. This proposed method includes two
loss functions such as cross entropy loss function and centre loss function.
Then the performance of the algorithm will be evaluated using recognition rate
and false measures. Simulation results show that the predictive performance of
the proposed method outperforms that of the existing classifiers such as
Convolutional Neural Network (CNN), Deep Neural Network (DNN), Artificial
Neural Network (ANN), Support Vector Machine (SVM), and k-Nearest Neighbours
(KNN) in terms of accuracy and Mean Absolute Error (MAE).
"
2826,DualLip: A System for Joint Lip Reading and Generation,"  Lip reading aims to recognize text from talking lip, while lip generation
aims to synthesize talking lip according to text, which is a key component in
talking face generation and is a dual task of lip reading. In this paper, we
develop DualLip, a system that jointly improves lip reading and generation by
leveraging the task duality and using unlabeled text and lip video data. The
key ideas of the DualLip include: 1) Generate lip video from unlabeled text
with a lip generation model, and use the pseudo pairs to improve lip reading;
2) Generate text from unlabeled lip video with a lip reading model, and use the
pseudo pairs to improve lip generation. We further extend DualLip to talking
face generation with two additionally introduced components: lip to face
generation and text to speech generation. Experiments on GRID and TCD-TIMIT
demonstrate the effectiveness of DualLip on improving lip reading, lip
generation, and talking face generation by utilizing unlabeled data.
Specifically, the lip generation model in our DualLip system trained with
only10% paired data surpasses the performance of that trained with the whole
paired data. And on the GRID benchmark of lip reading, we achieve 1.16%
character error rate and 2.71% word error rate, outperforming the
state-of-the-art models using the same amount of paired data.
"
2827,Attention Cube Network for Image Restoration,"  Recently, deep convolutional neural network (CNN) have been widely used in
image restoration and obtained great success. However, most of existing methods
are limited to local receptive field and equal treatment of different types of
information. Besides, existing methods always use a multi-supervised method to
aggregate different feature maps, which can not effectively aggregate
hierarchical feature information. To address these issues, we propose an
attention cube network (A-CubeNet) for image restoration for more powerful
feature expression and feature correlation learning. Specifically, we design a
novel attention mechanism from three dimensions, namely spatial dimension,
channel-wise dimension and hierarchical dimension. The adaptive spatial
attention branch (ASAB) and the adaptive channel attention branch (ACAB)
constitute the adaptive dual attention module (ADAM), which can capture the
long-range spatial and channel-wise contextual information to expand the
receptive field and distinguish different types of information for more
effective feature representations. Furthermore, the adaptive hierarchical
attention module (AHAM) can capture the long-range hierarchical contextual
information to flexibly aggregate different feature maps by weights depending
on the global context. The ADAM and AHAM cooperate to form an ""attention in
attention"" structure, which means AHAM's inputs are enhanced by ASAB and ACAB.
Experiments demonstrate the superiority of our method over state-of-the-art
image restoration methods in both quantitative comparison and visual analysis.
"
2828,"A Review of Visual Descriptors and Classification Techniques Used in
  Leaf Species Identification","  Plants are fundamentally important to life. Key research areas in plant
science include plant species identification, weed classification using hyper
spectral images, monitoring plant health and tracing leaf growth, and the
semantic interpretation of leaf information. Botanists easily identify plant
species by discriminating between the shape of the leaf, tip, base, leaf margin
and leaf vein, as well as the texture of the leaf and the arrangement of
leaflets of compound leaves. Because of the increasing demand for experts and
calls for biodiversity, there is a need for intelligent systems that recognize
and characterize leaves so as to scrutinize a particular species, the diseases
that affect them, the pattern of leaf growth, and so on. We review several
image processing methods in the feature extraction of leaves, given that
feature extraction is a crucial technique in computer vision. As computers
cannot comprehend images, they are required to be converted into features by
individually analysing image shapes, colours, textures and moments. Images that
look the same may deviate in terms of geometric and photometric variations. In
our study, we also discuss certain machine learning classifiers for an analysis
of different species of leaves.
"
2829,Themes Informed Audio-visual Correspondence Learning,"  The applications of short-term user-generated video (UGV), such as Snapchat,
and Youtube short-term videos, booms recently, raising lots of multimodal
machine learning tasks. Among them, learning the correspondence between audio
and visual information from videos is a challenging one. Most previous work of
the audio-visual correspondence(AVC) learning only investigated constrained
videos or simple settings, which may not fit the application of UGV. In this
paper, we proposed new principles for AVC and introduced a new framework to set
sight of videos' themes to facilitate AVC learning. We also released the
KWAI-AD-AudVis corpus which contained 85432 short advertisement videos (around
913 hours) made by users. We evaluated our proposed approach on this corpus,
and it was able to outperform the baseline by 23.15% absolute difference.
"
2830,A Convolutional LSTM based Residual Network for Deepfake Video Detection,"  In recent years, deep learning-based video manipulation methods have become
widely accessible to masses. With little to no effort, people can easily learn
how to generate deepfake videos with only a few victims or target images. This
creates a significant social problem for everyone whose photos are publicly
available on the Internet, especially on social media websites. Several deep
learning-based detection methods have been developed to identify these
deepfakes. However, these methods lack generalizability, because they perform
well only for a specific type of deepfake method. Therefore, those methods are
not transferable to detect other deepfake methods. Also, they do not take
advantage of the temporal information of the video. In this paper, we addressed
these limitations. We developed a Convolutional LSTM based Residual Network
(CLRNet), which takes a sequence of consecutive images as an input from a video
to learn the temporal information that helps in detecting unnatural looking
artifacts that are present between frames of deepfake videos. We also propose a
transfer learning-based approach to generalize different deepfake methods.
Through rigorous experimentations using the FaceForensics++ dataset, we showed
that our method outperforms five of the previously proposed state-of-the-art
deepfake detection methods by better generalizing at detecting different
deepfake methods using the same model.
"
2831,Exploring Speech Cues in Web-mined COVID-19 Conversational Vlogs,"  The COVID-19 pandemic caused by the novel SARS-Coronavirus-2 (n-SARS-CoV-2)
has impacted people's lives in unprecedented ways. During the time of the
pandemic, social vloggers have used social media to actively share their
opinions or experiences in quarantine. This paper collected videos from YouTube
to track emotional responses in conversational vlogs and their potential
associations with events related to the pandemic. In particular, vlogs uploaded
from locations in New York City were analyzed given that this was one of the
first epicenters of the pandemic in the United States. We observed some common
patterns in vloggers' acoustic and linguistic features across the time span of
the quarantine, which is indicative of changes in emotional reactivity.
Additionally, we investigated fluctuations of acoustic and linguistic patterns
in relation to COVID-19 events in the New York area (e.g. the number of daily
new cases, number of deaths, and extension of stay-at-home order and state of
emergency). Our results indicate that acoustic features, such as
zero-crossing-rate, jitter, and shimmer, can be valuable for analyzing
emotional reactivity in social media videos. Our findings further indicate that
some of the peaks of the acoustic and linguistic indices align with COVID-19
events, such as the peak in the number of deaths and emergency declaration.
"
2832,CogTree: Cognition Tree Loss for Unbiased Scene Graph Generation,"  Scene graphs are semantic abstraction of images that encourage visual
understanding and reasoning. However, the performance of Scene Graph Generation
(SGG) is unsatisfactory when faced with biased data in real-world scenarios.
Conventional debiasing research mainly studies from the view of data
representation, e.g. balancing data distribution or learning unbiased models
and representations, ignoring the mechanism that how humans accomplish this
task. Inspired by the role of the prefrontal cortex (PFC) in hierarchical
reasoning, we analyze this problem from a novel cognition perspective: learning
a hierarchical cognitive structure of the highly-biased relationships and
navigating that hierarchy to locate the classes, making the tail classes
receive more attention in a coarse-to-fine mode. To this end, we propose a
novel Cognition Tree (CogTree) loss for unbiased SGG. We first build a
cognitive structure CogTree to organize the relationships based on the
prediction of a biased SGG model. The CogTree distinguishes remarkably
different relationships at first and then focuses on a small portion of easily
confused ones. Then, we propose a hierarchical loss specially for this
cognitive structure, which supports coarse-to-fine distinction for the correct
relationships while progressively eliminating the interference of irrelevant
ones. The loss is model-independent and can be applied to various SGG models
without extra supervision. The proposed CogTree loss consistently boosts the
performance of several state-of-the-art models on the Visual Genome benchmark.
"
2833,"SLGAN: Style- and Latent-guided Generative Adversarial Network for
  Desirable Makeup Transfer and Removal","  There are five features to consider when using generative adversarial
networks to apply makeup to photos of the human face. These features include
(1) facial components, (2) interactive color adjustments, (3) makeup
variations, (4) robustness to poses and expressions, and the (5) use of
multiple reference images. Several related works have been proposed, mainly
using generative adversarial networks (GAN). Unfortunately, none of them have
addressed all five features simultaneously. This paper closes the gap with an
innovative style- and latent-guided GAN (SLGAN). We provide a novel, perceptual
makeup loss and a style-invariant decoder that can transfer makeup styles based
on histogram matching to avoid the identity-shift problem. In our experiments,
we show that our SLGAN is better than or comparable to state-of-the-art
methods. Furthermore, we show that our proposal can interpolate facial makeup
images to determine the unique features, compare existing methods, and help
users find desirable makeup configurations.
"
2834,"Helping Users Tackle Algorithmic Threats on Social Media: A Multimedia
  Research Agenda","  Participation on social media platforms has many benefits but also poses
substantial threats. Users often face an unintended loss of privacy, are
bombarded with mis-/disinformation, or are trapped in filter bubbles due to
over-personalized content. These threats are further exacerbated by the rise of
hidden AI-driven algorithms working behind the scenes to shape users' thoughts,
attitudes, and behavior. We investigate how multimedia researchers can help
tackle these problems to level the playing field for social media users. We
perform a comprehensive survey of algorithmic threats on social media and use
it as a lens to set a challenging but important research agenda for effective
and real-time user nudging. We further implement a conceptual prototype and
evaluate it with experts to supplement our research agenda. This paper calls
for solutions that combat the algorithmic threats on social media by utilizing
machine learning and multimedia content analysis techniques but in a
transparent manner and for the benefit of the users.
"
2835,"ChoreoNet: Towards Music to Dance Synthesis with Choreographic Action
  Unit","  Dance and music are two highly correlated artistic forms. Synthesizing dance
motions has attracted much attention recently. Most previous works conduct
music-to-dance synthesis via directly music to human skeleton keypoints
mapping. Meanwhile, human choreographers design dance motions from music in a
two-stage manner: they firstly devise multiple choreographic dance units
(CAUs), each with a series of dance motions, and then arrange the CAU sequence
according to the rhythm, melody and emotion of the music. Inspired by these, we
systematically study such two-stage choreography approach and construct a
dataset to incorporate such choreography knowledge. Based on the constructed
dataset, we design a two-stage music-to-dance synthesis framework ChoreoNet to
imitate human choreography procedure. Our framework firstly devises a CAU
prediction model to learn the mapping relationship between music and CAU
sequences. Afterwards, we devise a spatial-temporal inpainting model to convert
the CAU sequence into continuous dance motions. Experimental results
demonstrate that the proposed ChoreoNet outperforms baseline methods (0.622 in
terms of CAU BLEU score and 1.59 in terms of user study score).
"
2836,A Human-Computer Duet System for Music Performance,"  Virtual musicians have become a remarkable phenomenon in the contemporary
multimedia arts. However, most of the virtual musicians nowadays have not been
endowed with abilities to create their own behaviors, or to perform music with
human musicians. In this paper, we firstly create a virtual violinist, who can
collaborate with a human pianist to perform chamber music automatically without
any intervention. The system incorporates the techniques from various fields,
including real-time music tracking, pose estimation, and body movement
generation. In our system, the virtual musician's behavior is generated based
on the given music audio alone, and such a system results in a low-cost,
efficient and scalable way to produce human and virtual musicians'
co-performance. The proposed system has been validated in public concerts.
Objective quality assessment approaches and possible ways to systematically
improve the system are also discussed.
"
2837,Using Sensory Time-cue to enable Unsupervised Multimodal Meta-learning,"  As data from IoT (Internet of Things) sensors become ubiquitous,
state-of-the-art machine learning algorithms face many challenges on directly
using sensor data. To overcome these challenges, methods must be designed to
learn directly from sensors without manual annotations. This paper introduces
Sensory Time-cue for Unsupervised Meta-learning (STUM). Different from
traditional learning approaches that either heavily depend on labels or on
time-independent feature extraction assumptions, such as Gaussian distribution
features, the STUM system uses time relation of inputs to guide the feature
space formation within and across modalities. The fact that STUM learns from a
variety of small tasks may put this method in the camp of Meta-Learning.
Different from existing Meta-Learning approaches, STUM learning tasks are
composed within and across multiple modalities based on time-cue co-exist with
the IoT streaming data. In an audiovisual learning example, because consecutive
visual frames usually comprise the same object, this approach provides a unique
way to organize features from the same object together. The same method can
also organize visual object features with the object's spoken-name features
together if the spoken name is presented with the object at about the same
time. This cross-modality feature organization may further help the
organization of visual features that belong to similar objects but acquired at
different location and time. Promising results are achieved through
evaluations.
"
2838,Temporally Guided Music-to-Body-Movement Generation,"  This paper presents a neural network model to generate virtual violinist's
3-D skeleton movements from music audio. Improved from the conventional
recurrent neural network models for generating 2-D skeleton data in previous
works, the proposed model incorporates an encoder-decoder architecture, as well
as the self-attention mechanism to model the complicated dynamics in body
movement sequences. To facilitate the optimization of self-attention model,
beat tracking is applied to determine effective sizes and boundaries of the
training examples. The decoder is accompanied with a refining network and a
bowing attack inference mechanism to emphasize the right-hand behavior and
bowing attack timing. Both objective and subjective evaluations reveal that the
proposed model outperforms the state-of-the-art methods. To the best of our
knowledge, this work represents the first attempt to generate 3-D violinists'
body movements considering key features in musical body movement.
"
2839,"Word Segmentation from Unconstrained Handwritten Bangla Document Images
  using Distance Transform","  Segmentation of handwritten document images into text lines and words is one
of the most significant and challenging tasks in the development of a complete
Optical Character Recognition (OCR) system. This paper addresses the automatic
segmentation of text words directly from unconstrained Bangla handwritten
document images. The popular Distance transform (DT) algorithm is applied for
locating the outer boundary of the word images. This technique is free from
generating the over-segmented words. A simple post-processing procedure is
applied to isolate the under-segmented word images, if any. The proposed
technique is tested on 50 random images taken from CMATERdb1.1.1 database.
Satisfactory result is achieved with a segmentation accuracy of 91.88% which
confirms the robustness of the proposed methodology.
"
2840,"Crossing You in Style: Cross-modal Style Transfer from Music to Visual
  Arts","  Music-to-visual style transfer is a challenging yet important cross-modal
learning problem in the practice of creativity. Its major difference from the
traditional image style transfer problem is that the style information is
provided by music rather than images. Assuming that musical features can be
properly mapped to visual contents through semantic links between the two
domains, we solve the music-to-visual style transfer problem in two steps:
music visualization and style transfer. The music visualization network
utilizes an encoder-generator architecture with a conditional generative
adversarial network to generate image-based music representations from music
data. This network is integrated with an image style transfer method to
accomplish the style transfer process. Experiments are conducted on
WikiArt-IMSLP, a newly compiled dataset including Western music recordings and
paintings listed by decades. By utilizing such a label to learn the semantic
connection between paintings and music, we demonstrate that the proposed
framework can generate diverse image style representations from a music piece,
and these representations can unveil certain art forms of the same era.
Subjective testing results also emphasize the role of the era label in
improving the perceptual quality on the compatibility between music and visual
content.
"
2841,A Multimodal Memes Classification: A Survey and Open Research Issues,"  Memes are graphics and text overlapped so that together they present concepts
that become dubious if one of them is absent. It is spread mostly on social
media platforms, in the form of jokes, sarcasm, motivating, etc. After the
success of BERT in Natural Language Processing (NLP), researchers inclined to
Visual-Linguistic (VL) multimodal problems like memes classification, image
captioning, Visual Question Answering (VQA), and many more. Unfortunately, many
memes get uploaded each day on social media platforms that need automatic
censoring to curb misinformation and hate. Recently, this issue has attracted
the attention of researchers and practitioners. State-of-the-art methods that
performed significantly on other VL dataset, tends to fail on memes
classification. In this context, this work aims to conduct a comprehensive
study on memes classification, generally on the VL multimodal problems and
cutting edge solutions. We propose a generalized framework for VL problems. We
cover the early and next-generation works on VL problems. Finally, we identify
and articulate several open research issues and challenges. This is the first
study that presents the generalized view of the advanced classification
techniques concerning memes classification to the best of our knowledge. We
believe this study presents a clear road-map for the Machine Learning (ML)
research community to implement and enhance memes classification techniques.
"
2842,"Features based Mammogram Image Classification using Weighted Feature
  Support Vector Machine","  In the existing research of mammogram image classification, either clinical
data or image features of a specific type is considered along with the
supervised classifiers such as Neural Network (NN) and Support Vector Machine
(SVM). This paper considers automated classification of breast tissue type as
benign or malignant using Weighted Feature Support Vector Machine (WFSVM)
through constructing the precomputed kernel function by assigning more weight
to relevant features using the principle of maximizing deviations. Initially,
MIAS dataset of mammogram images is divided into training and test set, then
the preprocessing techniques such as noise removal and background removal are
applied to the input images and the Region of Interest (ROI) is identified. The
statistical features and texture features are extracted from the ROI and the
clinical features are obtained directly from the dataset. The extracted
features of the training dataset are used to construct the weighted features
and precomputed linear kernel for training the WFSVM, from which the training
model file is created. Using this model file the kernel matrix of test samples
is classified as benign or malignant. This analysis shows that the texture
features have resulted in better accuracy than the other features with WFSVM
and SVM. However, the number of support vectors created in WFSVM is less than
the SVM classifier.
"
2843,"An enhanced performance for H.265/SHVC based on combined AEGBM3D filter
  and back-propagation neural network","  This paper deals with the latest video coding standard H265 SHVC, a scalable
extension to High Efficiency Video Coding (HEVC). HEVC introduces new coding
tools compared to its predecessor and is backward compatible with all types of
electronic gadgets. The gadgets with different display capabilities cannot be
offered the same quality video due to the constraints in transmission bandwidth
is a major problem. One solution to this problem will be the compression of the
video sequence which is focused in this paper to preserve or increase PSNR
while reducing bit-rate besides a novel method implemented in SHVC encoder. The
novel method undergoes a combined AEGBM3D (adaptive edge guided block-matching
and 3D) filtering and back-propagation technique. The technique includes an
AEGBM3D filter which avoids spatial redundancy and de-noise frames; hence
enhancement in PSNR is achieved. The obtained PSNR of the video is compared
with the set threshold PSNR to maintain PSNR above the threshold by repeated
AEGBM3D filtering. The BP technique based on the neural network machine
learning approach continually restrains the output if the input block does not
contain a feature they were trained to recognize. This frequent control over
the output produces few bits; hence reduction in bit-rate is achieved. The
simulation results show that the proposed technique delivers an average
increment of 0.16 and 0.25dB in PSNR and an average decrement of 28 and 37% in
bit-rate for 1.5 and 2 times spatial ratios respectively, compared with the
existing methods.
"
2844,PodSumm -- Podcast Audio Summarization,"  The diverse nature, scale, and specificity of podcasts present a unique
challenge to content discovery systems. Listeners often rely on text
descriptions of episodes provided by the podcast creators to discover new
content. Some factors like the presentation style of the narrator and
production quality are significant indicators of subjective user preference but
are difficult to quantify and not reflected in the text descriptions provided
by the podcast creators. We propose the automated creation of podcast audio
summaries to aid in content discovery and help listeners to quickly preview
podcast content before investing time in listening to an entire episode. In
this paper, we present a method to automatically construct a podcast summary
via guidance from the text-domain. Our method performs two key steps, namely,
audio to text transcription and text summary generation. Motivated by a lack of
datasets for this task, we curate an internal dataset, find an effective scheme
for data augmentation, and design a protocol to gather summaries from
annotators. We fine-tune a PreSumm[10] model with our augmented dataset and
perform an ablation study. Our method achieves ROUGE-F(1/2/L) scores of
0.63/0.53/0.63 on our dataset. We hope these results may inspire future
research in this direction.
"
2845,Visual Methods for Sign Language Recognition: A Modality-Based Review,"  Sign language visual recognition from continuous multi-modal streams is still
one of the most challenging fields.
  Recent advances in human actions recognition are exploiting the ascension of
GPU-based learning from massive data, and are getting closer to human-like
performances.
  They are then prone to creating interactive services for the deaf and
hearing-impaired communities.
  A population that is expected to grow considerably in the years to come.
  This paper aims at reviewing the human actions recognition literature with
the sign-language visual understanding as a scope.
  The methods analyzed will be mainly organized according to the different
types of unimodal inputs exploited, their relative multi-modal combinations and
pipeline steps.
  In each section, we will detail and compare the related datasets, approaches
then distinguish the still open contribution paths suitable for the creation of
sign language related services.
  Special attention will be paid to the approaches and commercial solutions
handling facial expressions and continuous signing.
"
2846,Frame-wise Cross-modal Match for Video Moment Retrieval,"  Video moment retrieval targets at retrieving a golden moment in a video for a
given natural language query. The main challenges of this task include 1) the
requirement of accurately localizing (i.e., the start time and the end time of)
the relevant moment in an untrimmed video stream, and 2) bridging the semantic
gap between textual query and video contents. To tackle those problems, One
mainstream approach is to generate a multimodal feature vector for the target
query and video frames (e.g., concatenation) and then use a regression approach
upon the multimodal feature vector for boundary detection. Although some
progress has been achieved by this approach, we argue that those methods have
not well captured the cross-modal interactions between the query and video
frames.
  In this paper, we propose an Attentive Cross-modal Relevance Matching (ACRM)
model which predicts the temporal bounders based on an interaction modeling
between two modalities. In addition, an attention module is introduced to
automatically assign higher weights to query words with richer semantic cues,
which are considered to be more important for finding relevant video contents.
Another contribution is that we propose an additional predictor to utilize the
internal frames in the model training to improve the localization accuracy.
Extensive experiments on two public datasetsdemonstrate the superiority of our
method over several state-of-the-art methods.
"
2847,H.264/SVC Mode Decision Based on Mode Correlation and Desired Mode List,"  The design of video encoders involves the implementation of fast mode
decision (FMD) algorithm to reduce computation complexity while maintaining the
performance of the coding. Although H.264/scalable video coding (SVC) achieves
high scalability and coding efficiency, it also has high complexity in
implementing its exhaustive computation. In this paper, a novel algorithm is
proposed to reduce the redundant candidate modes by making use of the
correlation among layers. The desired mode list is created based on the
probability to be the best mode for each block in the base layer and a
candidate mode selection in the enhancement layer by the correlations of modes
among the reference frame and current frame. Our algorithm is implemented in
joint scalable video model (JSVM) 9.19.15 reference software and the
performance is evaluated based on the average encoding time, peak signal to
noise ratio (PSNR) and bit rate. The experimental results show 41.89%
improvement in encoding time with minimal loss of 0.02dB in PSNR and 0.05%
increase in bit rate.
"
2848,"Can we trust online crowdworkers? Comparing online and offline
  participants in a preference test of virtual agents","  Conducting user studies is a crucial component in many scientific fields.
While some studies require participants to be physically present, other studies
can be conducted both physically (e.g. in-lab) and online (e.g. via
crowdsourcing). Inviting participants to the lab can be a time-consuming and
logistically difficult endeavor, not to mention that sometimes research groups
might not be able to run in-lab experiments, because of, for example, a
pandemic. Crowdsourcing platforms such as Amazon Mechanical Turk (AMT) or
Prolific can therefore be a suitable alternative to run certain experiments,
such as evaluating virtual agents. Although previous studies investigated the
use of crowdsourcing platforms for running experiments, there is still
uncertainty as to whether the results are reliable for perceptual studies. Here
we replicate a previous experiment where participants evaluated a gesture
generation model for virtual agents. The experiment is conducted across three
participant pools -- in-lab, Prolific, and AMT -- having similar demographics
across the in-lab participants and the Prolific platform. Our results show no
difference between the three participant pools in regards to their evaluations
of the gesture generation models and their reliability scores. The results
indicate that online platforms can successfully be used for perceptual
evaluations of this kind.
"
2849,"Exploring global diverse attention via pairwise temporal relation for
  video summarization","  Video summarization is an effective way to facilitate video searching and
browsing. Most of existing systems employ encoder-decoder based recurrent
neural networks, which fail to explicitly diversify the system-generated
summary frames while requiring intensive computations. In this paper, we
propose an efficient convolutional neural network architecture for video
SUMmarization via Global Diverse Attention called SUM-GDA, which adapts
attention mechanism in a global perspective to consider pairwise temporal
relations of video frames. Particularly, the GDA module has two advantages: 1)
it models the relations within paired frames as well as the relations among all
pairs, thus capturing the global attention across all frames of one video; 2)
it reflects the importance of each frame to the whole video, leading to diverse
attention on these frames. Thus, SUM-GDA is beneficial for generating diverse
frames to form satisfactory video summary. Extensive experiments on three data
sets, i.e., SumMe, TVSum, and VTW, have demonstrated that SUM-GDA and its
extension outperform other competing state-of-the-art methods with remarkable
improvements. In addition, the proposed models can be run in parallel with
significantly less computational costs, which helps the deployment in highly
demanding applications.
"
2850,Cosine Similarity of Multimodal Content Vectors for TV Programmes,"  Multimodal information originates from a variety of sources: audiovisual
files, textual descriptions, and metadata. We show how one can represent the
content encoded by each individual source using vectors, how to combine the
vectors via middle and late fusion techniques, and how to compute the semantic
similarities between the contents. Our vectorial representations are built from
spectral features and Bags of Audio Words, for audio, LSI topics and Doc2vec
embeddings for subtitles, and the categorical features, for metadata. We
implement our model on a dataset of BBC TV programmes and evaluate the fused
representations to provide recommendations. The late fused similarity matrices
significantly improve the precision and diversity of recommendations.
"
2851,"Packet Compressed Sensing Imaging (PCSI): Robust Image Transmission over
  Noisy Channels","  Packet Compressed Sensing Imaging (PCSI) is digital unconnected image
transmission method resilient to packet loss. The goal is to develop a robust
image transmission method that is computationally trivial to transmit (e.g.,
compatible with low-power 8-bit microcontrollers) and well suited for weak
signal environments where packets are likely to be lost. In other image
transmission techniques, noise and packet loss leads to parts of the image
being distorted or missing. In PCSI, every packet contains random pixel
information from the entire image, and each additional packet received (in any
order) simply enhances image quality. Satisfactory SSTV resolution (320x240
pixel) images can be received in ~1-2 minutes when transmitted at 1200 baud
AFSK, which is on par with analog SSTV transmission time. Image transmission
and reception can occur simultaneously on a computer, and multiple images can
be received from multiple stations simultaneously - allowing for the creation
of ""image nets."" This paper presents a simple computer application for Windows,
Mac, and Linux that implements PCSI transmission and reception on any KISS
compatible hardware or software modem on any band and digital mode.
"
2852,Deep Multi-Scale Feature Learning for Defocus Blur Estimation,"  This paper presents an edge-based defocus blur estimation method from a
single defocused image. We first distinguish edges that lie at depth
discontinuities (called depth edges, for which the blur estimate is ambiguous)
from edges that lie at approximately constant depth regions (called pattern
edges, for which the blur estimate is well-defined). Then, we estimate the
defocus blur amount at pattern edges only, and explore an interpolation scheme
based on guided filters that prevents data propagation across the detected
depth edges to obtain a dense blur map with well-defined object boundaries.
Both tasks (edge classification and blur estimation) are performed by deep
convolutional neural networks (CNNs) that share weights to learn meaningful
local features from multi-scale patches centered at edge locations. Experiments
on naturally defocused images show that the proposed method presents
qualitative and quantitative results that outperform state-of-the-art (SOTA)
methods, with a good compromise between running time and accuracy.
"
2853,"Training CNNs in Presence of JPEG Compression: Multimedia Forensics vs
  Computer Vision","  Convolutional Neural Networks (CNNs) have proved very accurate in multiple
computer vision image classification tasks that required visual inspection in
the past (e.g., object recognition, face detection, etc.). Motivated by these
astonishing results, researchers have also started using CNNs to cope with
image forensic problems (e.g., camera model identification, tampering
detection, etc.). However, in computer vision, image classification methods
typically rely on visual cues easily detectable by human eyes. Conversely,
forensic solutions rely on almost invisible traces that are often very subtle
and lie in the fine details of the image under analysis. For this reason,
training a CNN to solve a forensic task requires some special care, as common
processing operations (e.g., resampling, compression, etc.) can strongly hinder
forensic traces. In this work, we focus on the effect that JPEG has on CNN
training considering different computer vision and forensic image
classification problems. Specifically, we consider the issues that rise from
JPEG compression and misalignment of the JPEG grid. We show that it is
necessary to consider these effects when generating a training dataset in order
to properly train a forensic detector not losing generalization capability,
whereas it is almost possible to ignore these effects for computer vision
tasks.
"
2854,Adaptive Online Multi-modal Hashing via Hadamard Matrix,"  Hashing plays an important role in information retrieval, due to its low
storage and high speed of processing. Among the techniques available in the
literature, multi-modal hashing, which can encode heterogeneous multi-modal
features into compact hash codes, has received particular attention. Existing
multi-modal hashing methods introduce hyperparameters to balance many
regularization terms designed to make the models more robust in the hash
learning process. However, it is time-consuming and labor-intensive to set them
proper values. In this paper, we propose a simple, yet effective method that is
inspired by the Hadamard matrix, which captures the multi-modal feature
information in an adaptive manner and preserves the discriminative semantic
information in the hash codes. Our framework is flexible and involves a very
few hyper-parameters. Extensive experimental results show the method is
effective and achieves superior performance compared to state-of-the-art
algorithms.
"
2855,A Survey on Model Watermarking Neural Networks,"  Machine learning (ML) models are applied in an increasing variety of domains.
The availability of large amounts of data and computational resources
encourages the development of ever more complex and valuable models. These
models are considered intellectual property of the legitimate parties who have
trained them, which makes their protection against stealing, illegitimate
redistribution, and unauthorized application an urgent need. Digital
watermarking presents a strong mechanism for marking model ownership and,
thereby, offers protection against those threats. The emergence of numerous
watermarking schemes and attacks against them is pushed forward by both
academia and industry, which motivates a comprehensive survey on this field.
This document at hand provides the first extensive literature review on ML
model watermarking schemes and attacks against them. It offers a taxonomy of
existing approaches and systemizes general knowledge around them. Furthermore,
it assembles the security requirements to watermarking approaches and evaluates
schemes published by the scientific community according to them in order to
present systematic shortcomings and vulnerabilities. Thus, it can not only
serve as valuable guidance in choosing the appropriate scheme for specific
scenarios, but also act as an entry point into developing new mechanisms that
overcome presented shortcomings, and thereby contribute in advancing the field.
"
2856,"Semi-Supervised Learning for In-Game Expert-Level Music-to-Dance
  Translation","  Music-to-dance translation is a brand-new and powerful feature in recent
role-playing games. Players can now let their characters dance along with
specified music clips and even generate fan-made dance videos. Previous works
of this topic consider music-to-dance as a supervised motion generation problem
based on time-series data. However, these methods suffer from limited training
data pairs and the degradation of movements. This paper provides a new
perspective for this task where we re-formulate the translation problem as a
piece-wise dance phrase retrieval problem based on the choreography theory.
With such a design, players are allowed to further edit the dance movements on
top of our generation while other regression based methods ignore such user
interactivity. Considering that the dance motion capture is an expensive and
time-consuming procedure which requires the assistance of professional dancers,
we train our method under a semi-supervised learning framework with a large
unlabeled dataset (20x than labeled data) collected. A co-ascent mechanism is
introduced to improve the robustness of our network. Using this unlabeled
dataset, we also introduce self-supervised pre-training so that the translator
can understand the melody, rhythm, and other components of music phrases. We
show that the pre-training significantly improves the translation accuracy than
that of training from scratch. Experimental results suggest that our method not
only generalizes well over various styles of music but also succeeds in
expert-level choreography for game players.
"
2857,"Traffic model of LTE using maximum flow algorithm with binary search
  technique","  Inrecent time a rapid increase in the number of smart devices and user
applications have generated an intensity volume of data traffic from/to a
cellular network. So the Long Term Evaluation(LTE)network is facing some
issuesdifficulties ofthebase station and infrastructure in terms of upgrade and
configuration becausethere is no concept of BSC (Base Station Controller) of 2G
and RNC (Radio Network Controller) of 3G to control several BTS/NB. Only 4G
(LTE) all the eNBs areinterconnected for traffic flow from UE (user equipment)
to core switch. Determination of capacity of a linkof such a network is a
challenging job since each node offers its own traffic andat the same time
conveys traffic of other nodes.In this paper, we apply maximum flow algorithm
including the binary search techniqueto solve the traffic flow of radio
networkandinterconnected eNBs of the LTE network. The throughput of the LTE
network shown graphically under the QPSK and 16-QAM
"
2858,"Cuid: A new study of perceived image quality and its subjective
  assessment","  Research on image quality assessment (IQA) remains limited mainly due to our
incomplete knowledge about human visual perception. Existing IQA algorithms
have been designed or trained with insufficient subjective data with a small
degree of stimulus variability. This has led to challenges for those algorithms
to handle complexity and diversity of real-world digital content. Perceptual
evidence from human subjects serves as a grounding for the development of
advanced IQA algorithms. It is thus critical to acquire reliable subjective
data with controlled perception experiments that faithfully reflect human
behavioural responses to distortions in visual signals. In this paper, we
present a new study of image quality perception where subjective ratings were
collected in a controlled lab environment. We investigate how quality
perception is affected by a combination of different categories of images and
different types and levels of distortions. The database will be made publicly
available to facilitate calibration and validation of IQA algorithms.
"
2859,Describing Subjective Experiment Consistency by $p$-Value P-P Plot,"  There are phenomena that cannot be measured without subjective testing.
However, subjective testing is a complex issue with many influencing factors.
These interplay to yield either precise or incorrect results. Researchers
require a tool to classify results of subjective experiment as either
consistent or inconsistent. This is necessary in order to decide whether to
treat the gathered scores as quality ground truth data. Knowing if subjective
scores can be trusted is key to drawing valid conclusions and building
functional tools based on those scores (e.g., algorithms assessing the
perceived quality of multimedia materials). We provide a tool to classify
subjective experiment (and all its results) as either consistent or
inconsistent. Additionally, the tool identifies stimuli having irregular score
distribution. The approach is based on treating subjective scores as a random
variable coming from the discrete Generalized Score Distribution (GSD). The
GSD, in combination with a bootstrapped G-test of goodness-of-fit, allows to
construct $p$-value P-P plot that visualizes experiment's consistency. The tool
safeguards researchers from using inconsistent subjective data. In this way, it
makes sure that conclusions they draw and tools they build are more precise and
trustworthy. The proposed approach works in line with expectations drawn solely
on experiment design descriptions of 21 real-life multimedia quality subjective
experiments.
"
2860,"Static and Dynamic Measures of Active Music Listening as Indicators of
  Depression Risk","  Music, an integral part of our lives, which is not only a source of
entertainment but plays an important role in mental well-being by impacting
moods, emotions and other affective states. Music preferences and listening
strategies have been shown to be associated with the psychological well-being
of listeners including internalized symptomatology and depression. However,
till date no studies exist that examine time-varying music consumption, in
terms of acoustic content, and its association with users' well-being. In the
current study, we aim at unearthing static and dynamic patterns prevalent in
active listening behavior of individuals which may be used as indicators of
risk for depression. Mental well-being scores and listening histories of 541
Last.fm users were examined. Static and dynamic acoustic and emotion-related
features were extracted from each user's listening history and correlated with
their mental well-being scores. Results revealed that individuals with greater
depression risk resort to higher dependency on music with greater
repetitiveness in their listening activity. Furthermore, the affinity of
depressed individuals towards music that can be perceived as sad was found to
be resistant to change over time. This study has large implications for future
work in the area of assessing mental illness risk by exploiting digital
footprints of users via online music streaming platforms.
"
2861,"Sequential Reinforced 360-Degree Video Adaptive Streaming with
  Cross-user Attentive Network","  In the tile-based 360-degree video streaming, predicting user's future
viewpoints and developing adaptive bitrate (ABR) algorithms are essential for
optimizing user's quality of experience (QoE). Traditional single-user based
viewpoint prediction methods fail to achieve good performance in long-term
prediction, and the recently proposed reinforcement learning (RL) based ABR
schemes applied in traditional video streaming can not be directly applied in
the tile-based 360-degree video streaming due to the exponential action space.
Therefore, we propose a sequential reinforced 360-degree video streaming scheme
with cross-user attentive network. Firstly, considering different users may
have the similar viewing preference on the same video, we propose a cross-user
attentive network (CUAN), boosting the performance of long-term viewpoint
prediction by selectively utilizing cross-user information. Secondly, we
propose a sequential RL-based (360SRL) ABR approach, transforming action space
size of each decision step from exponential to linear via introducing a
sequential decision structure. We evaluate the proposed CUAN and 360SRL using
trace-driven experiments and experimental results demonstrate that CUAN and
360SRL outperform existing viewpoint prediction and ABR approaches with a
noticeable margin.
"
2862,"Micro-Facial Expression Recognition in Video Based on Optimal
  Convolutional Neural Network (MFEOCNN) Algorithm","  Facial expression is a standout amongst the most imperative features of human
emotion recognition. For demonstrating the emotional states facial expressions
are utilized by the people. In any case, recognition of facial expressions has
persisted a testing and intriguing issue with regards to PC vision. Recognizing
the Micro-Facial expression in video sequence is the main objective of the
proposed approach. For efficient recognition, the proposed method utilizes the
optimal convolution neural network. Here the proposed method considering the
input dataset is the CK+ dataset. At first, by means of Adaptive median
filtering preprocessing is performed in the input image. From the preprocessed
output, the extracted features are Geometric features, Histogram of Oriented
Gradients features and Local binary pattern features. The novelty of the
proposed method is, with the help of Modified Lion Optimization (MLO)
algorithm, the optimal features are selected from the extracted features. In a
shorter computational time, it has the benefits of rapidly focalizing and
effectively acknowledging with the aim of getting an overall arrangement or
idea. Finally, the recognition is done by Convolution Neural network (CNN).
Then the performance of the proposed MFEOCNN method is analysed in terms of
false measures and recognition accuracy. This kind of emotion recognition is
mainly used in medicine, marketing, E-learning, entertainment, law and
monitoring. From the simulation, we know that the proposed approach achieves
maximum recognition accuracy of 99.2% with minimum Mean Absolute Error (MAE)
value. These results are compared with the existing for MicroFacial Expression
Based Deep-Rooted Learning (MFEDRL), Convolutional Neural Network with Lion
Optimization (CNN+LO) and Convolutional Neural Network (CNN) without
optimization. The simulation of the proposed method is done in the working
platform of MATLAB.
"
2863,"Where is the Model Looking At?--Concentrate and Explain the Network
  Attention","  Image classification models have achieved satisfactory performance on many
datasets, sometimes even better than human. However, The model attention is
unclear since the lack of interpretability. This paper investigates the
fidelity and interpretability of model attention. We propose an Explainable
Attribute-based Multi-task (EAT) framework to concentrate the model attention
on the discriminative image area and make the attention interpretable. We
introduce attributes prediction to the multi-task learning network, helping the
network to concentrate attention on the foreground objects. We generate
attribute-based textual explanations for the network and ground the attributes
on the image to show visual explanations. The multi-model explanation can not
only improve user trust but also help to find the weakness of network and
dataset. Our framework can be generalized to any basic model. We perform
experiments on three datasets and five basic models. Results indicate that the
EAT framework can give multi-modal explanations that interpret the network
decision. The performance of several recognition approaches is improved by
guiding network attention.
"
2864,"Residual acoustic echo suppression based on efficient multi-task
  convolutional neural network","  Acoustic echo degrades the user experience in voice communication systems
thus needs to be suppressed completely. We propose a real-time residual
acoustic echo suppression (RAES) method using an efficient convolutional neural
network. The double talk detector is used as an auxiliary task to improve the
performance of RAES in the context of multi-task learning. The training
criterion is based on a novel loss function, which we call as the suppression
loss, to balance the suppression of residual echo and the distortion of
near-end signals. The experimental results show that the proposed method can
efficiently suppress the residual echo under different circumstances.
"
2865,MUSE2020 challenge report,"  This paper is a brief report for MUSE2020 challenge. We present our solution
for Muse-Wild sub challenge. The aim of this challenge is to investigate
sentiment analysis method in real-world situation. Our solutions achieve the
best CCC performance of 0.4670, 0.3571 for arousal, and valence respectively on
the challenge validation set, which outperforms the baseline system with
corresponding CCC of 0.3078 and 1506.
"
2866,Performance of AV1 Real-Time Mode,"  With COVID-19, the interest for digital interactions has raised, putting in
turn real-time (or low-latency) codecs into a new light. Most of the codec
research has been traditionally focusing on coding efficiency, while very
little literature exist on real-time codecs. It is shown how the speed at which
content is made available impacts both latency and throughput. The authors
introduce a new test set up, integrating a paced reader, which allows to run
codec in the same condition as real-time media capture. Quality measurements
using VMAF, as well as multiple speed measurements are made on encoding of HD
and full HD video sequences, both at 25 fps and 50 fps to compare the
respective performances of several implementations of the H.264, H.265, VP8,
VP9 and AV1 codecs.
"
2867,Teacher-Critical Training Strategies for Image Captioning,"  Existing image captioning models are usually trained by cross-entropy (XE)
loss and reinforcement learning (RL), which set ground-truth words as hard
targets and force the captioning model to learn from them. However, the widely
adopted training strategies suffer from misalignment in XE training and
inappropriate reward assignment in RL training. To tackle these problems, we
introduce a teacher model that serves as a bridge between the ground-truth
caption and the caption model by generating some easier-to-learn word proposals
as soft targets. The teacher model is constructed by incorporating the
ground-truth image attributes into the baseline caption model. To effectively
learn from the teacher model, we propose Teacher-Critical Training Strategies
(TCTS) for both XE and RL training to facilitate better learning processes for
the caption model. Experimental evaluations of several widely adopted caption
models on the benchmark MSCOCO dataset show the proposed TCTS comprehensively
enhances most evaluation metrics, especially the Bleu and Rouge-L scores, in
both training stages. TCTS is able to achieve to-date the best published single
model Bleu-4 and Rouge-L performances of 40.2% and 59.4% on the MSCOCO Karpathy
test split. Our codes and pre-trained models will be open-sourced.
"
2868,"Visual Semantic Multimedia Event Model for Complex Event Detection in
  Video Streams","  Multimedia data is highly expressive and has traditionally been very
difficult for a machine to interpret. Middleware systems such as complex event
processing (CEP) mine patterns from data streams and send notifications to
users in a timely fashion. Presently, CEP systems have inherent limitations to
process multimedia streams due to its data complexity and the lack of an
underlying structured data model. In this work, we present a visual event
specification method to enable complex multimedia event processing by creating
a semantic knowledge representation derived from low-level media streams. The
method enables the detection of high-level semantic concepts from the media
streams using an ensemble of pattern detection capabilities. The semantic model
is aligned with a multimedia CEP engine deep learning models to give
flexibility to end-users to build rules using spatiotemporal event calculus.
This enhances CEP capability to detect patterns from media streams and bridge
the semantic gap between highly expressive knowledge-centric user queries to
the low-level features of the multi-media data. We have built a small traffic
event ontology prototype to validate the approach and performance. The paper
contribution is threefold: i) we present a knowledge graph representation for
multimedia streams, ii) a hierarchical event network to detect visual patterns
from media streams and iii) define complex pattern rules for complex multimedia
event reasoning using event calculus
"
2869,CariMe: Unpaired Caricature Generation with Multiple Exaggerations,"  Caricature generation aims to translate real photos into caricatures with
artistic styles and shape exaggerations while maintaining the identity of the
subject. Different from the generic image-to-image translation, drawing a
caricature automatically is a more challenging task due to the existence of
various spacial deformations. Previous caricature generation methods are
obsessed with predicting definite image warping from a given photo while
ignoring the intrinsic representation and distribution for exaggerations in
caricatures. This limits their ability on diverse exaggeration generation. In
this paper, we generalize the caricature generation problem from instance-level
warping prediction to distribution-level deformation modeling. Based on this
assumption, we present the first exploration for unpaired CARIcature generation
with Multiple Exaggerations (CariMe). Technically, we propose a
Multi-exaggeration Warper network to learn the distribution-level mapping from
photo to facial exaggerations. This makes it possible to generate diverse and
reasonable exaggerations from randomly sampled warp codes given one input
photo. To better represent the facial exaggeration and produce fine-grained
warping, a deformation-field-based warping method is also proposed, which helps
us to capture more detailed exaggerations than other point-based warping
methods. Experiments and two perceptual studies prove the superiority of our
method comparing with other state-of-the-art methods, showing the improvement
of our work on caricature generation.
"
2870,"An authorship protection technology for electronic documents based on
  image watermarking","  In the field of information technology, information security technologies
hold a special place. They ensure the security of the use of information
technology. One of the urgent tasks is the protection of electronic documents
during their transfer in information systems. This paper proposes a technology
for protecting electronic documents containing digital images. The main idea is
that the electronic document authorship protection can be implemented by
digital watermark embedding in the images that are contained in this document.
The paper considers three cases of using the proposed technology: full copying
of an electronic document, copying of images contained in the document, and
copying of text. It is shown that in all three cases the authorship
confirmation can be successfully implemented. Computational experiments are
conducted with robust watermarking algorithms that can be used within the
technology. A scenario of technology implementation is proposed, which provides
for the joint use of different class algorithms.
"
2871,DeepFakesON-Phys: DeepFakes Detection based on Heart Rate Estimation,"  This work introduces a novel DeepFake detection framework based on
physiological measurement. In particular, we consider information related to
the heart rate using remote photoplethysmography (rPPG). rPPG methods analyze
video sequences looking for subtle color changes in the human skin, revealing
the presence of human blood under the tissues. In this work we investigate to
what extent rPPG is useful for the detection of DeepFake videos.
  The proposed fake detector named DeepFakesON-Phys uses a Convolutional
Attention Network (CAN), which extracts spatial and temporal information from
video frames, analyzing and combining both sources to better detect fake
videos. This detection approach has been experimentally evaluated using the
latest public databases in the field: Celeb-DF and DFDC. The results achieved,
above 98% AUC (Area Under the Curve) on both databases, outperform the state of
the art and prove the success of fake detectors based on physiological
measurement to detect the latest DeepFake videos.
"
2872,"An Empirical Study of DNNs Robustification Inefficacy in Protecting
  Visual Recommenders","  Visual-based recommender systems (VRSs) enhance recommendation performance by
integrating users' feedback with the visual features of product images
extracted from a deep neural network (DNN). Recently, human-imperceptible
images perturbations, defined \textit{adversarial attacks}, have been
demonstrated to alter the VRSs recommendation performance, e.g., pushing/nuking
category of products. However, since adversarial training techniques have
proven to successfully robustify DNNs in preserving classification accuracy, to
the best of our knowledge, two important questions have not been investigated
yet: 1) How well can these defensive mechanisms protect the VRSs performance?
2) What are the reasons behind ineffective/effective defenses? To answer these
questions, we define a set of defense and attack settings, as well as
recommender models, to empirically investigate the efficacy of defensive
mechanisms. The results indicate alarming risks in protecting a VRS through the
DNN robustification. Our experiments shed light on the importance of visual
features in very effective attack scenarios. Given the financial impact of VRSs
on many companies, we believe this work might rise the need to investigate how
to successfully protect visual-based recommenders. Source code and data are
available at
https://anonymous.4open.science/r/868f87ca-c8a4-41ba-9af9-20c41de33029/.
"
2873,"MM-Hand: 3D-Aware Multi-Modal Guided Hand Generative Network for 3D Hand
  Pose Synthesis","  Estimating the 3D hand pose from a monocular RGB image is important but
challenging. A solution is training on large-scale RGB hand images with
accurate 3D hand keypoint annotations. However, it is too expensive in
practice. Instead, we have developed a learning-based approach to synthesize
realistic, diverse, and 3D pose-preserving hand images under the guidance of 3D
pose information. We propose a 3D-aware multi-modal guided hand generative
network (MM-Hand), together with a novel geometry-based curriculum learning
strategy. Our extensive experimental results demonstrate that the 3D-annotated
images generated by MM-Hand qualitatively and quantitatively outperform
existing options. Moreover, the augmented data can consistently improve the
quantitative performance of the state-of-the-art 3D hand pose estimators on two
benchmark datasets. The code will be available at
https://github.com/ScottHoang/mm-hand.
"
2874,The Design of Tangible Digital Musical Instruments,"  Here we present guidelines that highlight the impact of haptic feedback upon
the experiences of computer musicians using Digital Musical Instruments (DMIs).
In this context, haptic feedback offers a tangible, bi-directional exchange
between a musician and a DMI. We propose that by adhering to and exploring
these guidelines the application of haptic feedback can enhance and augment the
physical and affective experiences of a musician in interactions with these
devices. It has been previously indicated that in the design of haptic DMIs,
the experiences and expectations of a musician must be considered for the
creation of tangible DMIs and that haptic feedback can be used to address the
physical-digital divide that currently exists between users of such
instruments.
"
2875,Digital Musical Instrument Analysis: The Haptic Bowl,"  This experiment is a case study that applies a HCI-informed DMI Evaluation
Framework. This framework applies existing HCI evaluation methods to the
assessment of prototype Digital Musical Instruments (DMIs). The overall study
will involve a three-part analysis - a description and categorisation of the
device, a functionality evaluation that included an examination of usability
and user experience, and finally an exploration of the device's effectiveness
as a digital instrument. Here we present the findings of the first two parts of
the framework, outlining the constituent components of the interface and
testing the functionality of the device. The final stage of analysis will
involve a longitudinal study and will be carried out in order to assess the
musical affordances of the device.
"
2876,"HCI Models for Digital Musical Instruments: Methodologies for Rigorous
  Testing of Digital Musical Instruments","  Here we present an analysis of literature relating to the evaluation
methodologies of Digital Musical Instruments (DMIs) derived from the field of
Human-Computer Interaction (HCI). We then apply choice aspects from these
existing evaluation models and apply them to an optimized evaluation for
assessing new DMIs.
"
2877,"MagGAN: High-Resolution Face Attribute Editing with Mask-Guided
  Generative Adversarial Network","  We present Mask-guided Generative Adversarial Network (MagGAN) for
high-resolution face attribute editing, in which semantic facial masks from a
pre-trained face parser are used to guide the fine-grained image editing
process. With the introduction of a mask-guided reconstruction loss, MagGAN
learns to only edit the facial parts that are relevant to the desired attribute
changes, while preserving the attribute-irrelevant regions (e.g., hat, scarf
for modification `To Bald'). Further, a novel mask-guided conditioning strategy
is introduced to incorporate the influence region of each attribute change into
the generator. In addition, a multi-level patch-wise discriminator structure is
proposed to scale our model for high-resolution ($1024 \times 1024$) face
editing. Experiments on the CelebA benchmark show that the proposed method
significantly outperforms prior state-of-the-art approaches in terms of both
image quality and editing performance.
"
2878,Learning Complete 3D Morphable Face Models from Images and Videos,"  Most 3D face reconstruction methods rely on 3D morphable models, which
disentangle the space of facial deformations into identity geometry,
expressions and skin reflectance. These models are typically learned from a
limited number of 3D scans and thus do not generalize well across different
identities and expressions. We present the first approach to learn complete 3D
models of face identity geometry, albedo and expression just from images and
videos. The virtually endless collection of such data, in combination with our
self-supervised learning-based approach allows for learning face models that
generalize beyond the span of existing approaches. Our network design and loss
functions ensure a disentangled parameterization of not only identity and
albedo, but also, for the first time, an expression basis. Our method also
allows for in-the-wild monocular reconstruction at test time. We show that our
learned models better generalize and lead to higher quality image-based
reconstructions than existing approaches.
"
2879,Actors in VR storytelling,"  Virtual Reality (VR) storytelling enhances the immersion of users into
virtual environments (VE). Its use in virtual cultural heritage presentations
helps the revival of the genius loci (the spirit of the place) of cultural
monuments. This paper aims to show that the use of actors in VR storytelling
adds to the quality of user experience and improves the edutainment value of
virtual cultural heritage applications. We will describe the Baiae dry visit
application which takes us to a time travel in the city considered by the Roman
elite as ""Little Rome (Pusilla Roma)"" and presently is only partially preserved
under the sea.
"
2880,"Combined Hapto-Visual and Auditory Rendering of Cultural Heritage
  Objects","  In this work, we develop a multi-modal rendering framework comprising of
hapto-visual and auditory data. The prime focus is to haptically render point
cloud data representing virtual 3-D models of cultural significance and also to
handle their affine transformations. Cultural heritage objects could
potentially be very large and one may be required to render the object at
various scales of details. Further, surface effects such as texture and
friction are incorporated in order to provide a realistic haptic perception to
the users. Moreover, the proposed framework includes an appropriate sound
synthesis to bring out the acoustic properties of the object. It also includes
a graphical user interface with varied options such as choosing the desired
orientation of 3-D objects and selecting the desired level of spatial
resolution adaptively at runtime. A fast, point proxy-based haptic rendering
technique is proposed with proxy update loop running 100 times faster than the
required haptic update frequency of 1 kHz. The surface properties are
integrated in the system by applying a bilateral filter on the depth data of
the virtual 3-D models. Position dependent sound synthesis is incorporated with
the incorporation of appropriate audio clips.
"
2881,Neural Generation of Blocks for Video Coding,"  Well-trained generative neural networks (GNN) are very efficient at
compressing visual information for static images in their learned parameters
but not as efficient as inter- and intra-prediction for most video content.
However, for content entering a frame, such as during panning or zooming out,
and content with curves, irregular shapes, or fine detail, generation by a GNN
can give better compression efficiency (lower rate-distortion). This paper
proposes encoding content-specific learned parameters of a GNN within a video
bitstream at specific times and using the GNN to generate content for specific
ranges of blocks and frames. The blocks to generate are just the ones for which
generation gives more efficient compression than inter- or intra- prediction.
This approach maximizes the usefulness of the information contained in the
learned parameters.
"
2882,Scalable Rendering of Variable Density Point Cloud Data,"  In this paper, we present a novel proxy-based method of the adaptive haptic
rendering of a variable density 3D point cloud data at different levels of
detail without pre-computing the mesh structure. We also incorporate features
like rotation, translation, and friction to provide a better realistic
experience to the user. A proxy-based rendering technique is used to avoid the
pop-through problem while rendering thin parts of the object. Instead of a
point proxy, a spherical proxy of a variable radius is used, which avoids the
sinking of proxy during the haptic interaction of sparse data. The radius of
the proxy is adaptively varied depending upon the local density of the point
data using kernel bandwidth estimation. During the interaction, the proxy moves
in small steps tangentially over the point cloud such that the new position
always minimizes the distance between the proxy and the haptic interaction
point (HIP). The raw point cloud data re-sampled in a regular 3D lattice of
voxels are loaded to the haptic space after proper smoothing to avoid aliasing
effects. The rendering technique is validated with several subjects, and it is
observed that this functionality supplements the user's experience by allowing
the user to interact with an object at multiple resolutions.
"
2883,"Using Sentences as Semantic Representations in Large Scale Zero-Shot
  Learning","  Zero-shot learning aims to recognize instances of unseen classes, for which
no visual instance is available during training, by learning multimodal
relations between samples from seen classes and corresponding class semantic
representations. These class representations usually consist of either
attributes, which do not scale well to large datasets, or word embeddings,
which lead to poorer performance. A good trade-off could be to employ short
sentences in natural language as class descriptions. We explore different
solutions to use such short descriptions in a ZSL setting and show that while
simple methods cannot achieve very good results with sentences alone, a
combination of usual word embeddings and sentences can significantly outperform
current state-of-the-art.
"
2884,Haptic Rendering of Cultural Heritage Objects at Different Scales,"  In this work, we address the issue of a virtual representation of objects of
cultural heritage for haptic interaction. Our main focus is to provide haptic
access to artistic objects of any physical scale to the differently-abled
people. This is a low-cost system and, in conjunction with a stereoscopic
visual display, gives a better immersive experience even to the sighted
persons. To achieve this, we propose a simple multilevel, proxy-based
hapto-visual rendering technique for point cloud data, which includes the
much-desired scalability feature which enables the users to change the scale of
the objects adaptively during the haptic interaction. For the proposed haptic
rendering technique, the proxy updation loop runs at a rate 100 times faster
than the required haptic updation frequency of 1KHz. We observe that this
functionality augments very well with the realism of the experience.
"
2885,"Network-aware Recommendations in the Wild: Methodology, Realistic
  Evaluations, Experiments","  Joint caching and recommendation has been recently proposed as a new paradigm
for increasing the efficiency of mobile edge caching. Early findings
demonstrate significant gains for the network performance. However, previous
works evaluated the proposed schemes exclusively on simulation environments.
Hence, it still remains uncertain whether the claimed benefits would change in
real settings. In this paper, we propose a methodology that enables to evaluate
joint network and recommendation schemes in real content services by only using
publicly available information. We apply our methodology to the YouTube
service, and conduct extensive measurements to investigate the potential
performance gains. Our results show that significant gains can be achieved in
practice; e.g., 8 to 10 times increase in the cache hit ratio from cache-aware
recommendations. Finally, we build an experimental testbed and conduct
experiments with real users; we make available our code and datasets to
facilitate further research. To our best knowledge, this is the first realistic
evaluation (over a real service, with real measurements and user experiments)
of the joint caching and recommendations paradigm. Our findings provide
experimental evidence for the feasibility and benefits of this paradigm,
validate assumptions of previous works, and provide insights that can drive
future research.
"
2886,MPEG Media Enablers For Richer XR Experiences,"  With the advent of immersive media applications, the requirements for the
representation and the consumption of such content has dramatically increased.
The ever-increasing size of the media asset combined with the stringent
motion-to-photon latency requirement makes the equation of a high quality of
experience for XR streaming services difficult to solve. The MPEG-I standards
aim at facilitating the wide deployment of immersive applications. This paper
describes part 13, Video Decoding Interface, and part 14, Scene Description for
MPEG Media of MPEG-I which address decoder management and the virtual scene
composition, respectively. These new parts intend to make complex media
rendering operations and hardware resources management hidden from the
application, hence lowering the barrier for XR application to become mainstream
and accessible to XR experience developers and designers. Both parts are
expected to be published by ISO at the end of 2021.
"
2887,"A Clustering-Based Method for Automatic Educational Video Recommendation
  Using Deep Face-Features of Lecturers","  Discovering and accessing specific content within educational video bases is
a challenging task, mainly because of the abundance of video content and its
diversity. Recommender systems are often used to enhance the ability to find
and select content. But, recommendation mechanisms, especially those based on
textual information, exhibit some limitations, such as being error-prone to
manually created keywords or due to imprecise speech recognition. This paper
presents a method for generating educational video recommendation using deep
face-features of lecturers without identifying them. More precisely, we use an
unsupervised face clustering mechanism to create relations among the videos
based on the lecturer's presence. Then, for a selected educational video taken
as a reference, we recommend the ones where the presence of the same lecturers
is detected. Moreover, we rank these recommended videos based on the amount of
time the referenced lecturers were present. For this task, we achieved a mAP
value of 99.165%.
"
2888,Remarks on Optimal Scores for Speaker Recognition,"  In this article, we first establish the theory of optimal scores for speaker
recognition. Our analysis shows that the minimum Bayes risk (MBR) decisions for
both the speaker identification and speaker verification tasks can be based on
a normalized likelihood (NL). When the underlying generative model is a linear
Gaussian, the NL score is mathematically equivalent to the PLDA likelihood
ratio, and the empirical scores based on cosine distance and Euclidean distance
can be seen as approximations of this linear Gaussian NL score under some
conditions. We discuss a number of properties of the NL score and perform a
simple simulation experiment to demonstrate the properties of the NL score.
"
2889,"Discriminative Sounding Objects Localization via Self-supervised
  Audiovisual Matching","  Discriminatively localizing sounding objects in cocktail-party, i.e., mixed
sound scenes, is commonplace for humans, but still challenging for machines. In
this paper, we propose a two-stage learning framework to perform
self-supervised class-aware sounding object localization. First, we propose to
learn robust object representations by aggregating the candidate sound
localization results in the single source scenes. Then, class-aware object
localization maps are generated in the cocktail-party scenarios by referring
the pre-learned object knowledge, and the sounding objects are accordingly
selected by matching audio and visual object category distributions, where the
audiovisual consistency is viewed as the self-supervised signal. Experimental
results in both realistic and synthesized cocktail-party videos demonstrate
that our model is superior in filtering out silent objects and pointing out the
location of sounding objects of different classes. Code is available at
https://github.com/DTaoo/Discriminative-Sounding-Objects-Localization.
"
2890,"TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for
  Sign Language Translation","  Sign language translation (SLT) aims to interpret sign video sequences into
text-based natural language sentences. Sign videos consist of continuous
sequences of sign gestures with no clear boundaries in between. Existing SLT
models usually represent sign visual features in a frame-wise manner so as to
avoid needing to explicitly segmenting the videos into isolated signs. However,
these methods neglect the temporal information of signs and lead to substantial
ambiguity in translation. In this paper, we explore the temporal semantic
structures of signvideos to learn more discriminative features. To this end, we
first present a novel sign video segment representation which takes into
account multiple temporal granularities, thus alleviating the need for accurate
video segmentation. Taking advantage of the proposed segment representation, we
develop a novel hierarchical sign video feature learning method via a temporal
semantic pyramid network, called TSPNet. Specifically, TSPNet introduces an
inter-scale attention to evaluate and enhance local semantic consistency of
sign segments and an intra-scale attention to resolve semantic ambiguity by
using non-local video context. Experiments show that our TSPNet outperforms the
state-of-the-art with significant improvements on the BLEU score (from 9.58 to
13.41) and ROUGE score (from 31.80 to 34.96)on the largest commonly-used SLT
dataset. Our implementation is available at
https://github.com/verashira/TSPNet.
"
2891,"Video Quality Enhancement Using Deep Learning-Based Prediction Models
  for Quantized DCT Coefficients in MPEG I-frames","  Recent works have successfully applied some types of Convolutional Neural
Networks (CNNs) to reduce the noticeable distortion resulting from the lossy
JPEG/MPEG compression technique. Most of them are built upon the processing
made on the spatial domain. In this work, we propose a MPEG video decoder that
is purely based on the frequency-to-frequency domain: it reads the quantized
DCT coefficients received from a low-quality I-frames bitstream and, using a
deep learning-based model, predicts the missing coefficients in order to
recompose the same frames with enhanced quality. In experiments with a video
dataset, our best model was able to improve from frames with quantized DCT
coefficients corresponding to a Quality Factor (QF) of 10 to enhanced quality
frames with QF slightly near to 20.
"
2892,"DialogueTRM: Exploring the Intra- and Inter-Modal Emotional Behaviors in
  the Conversation","  Emotion Recognition in Conversations (ERC) is essential for building
empathetic human-machine systems. Existing studies on ERC primarily focus on
summarizing the context information in a conversation, however, ignoring the
differentiated emotional behaviors within and across different modalities.
Designing appropriate strategies that fit the differentiated multi-modal
emotional behaviors can produce more accurate emotional predictions. Thus, we
propose the DialogueTransformer to explore the differentiated emotional
behaviors from the intra- and inter-modal perspectives. For intra-modal, we
construct a novel Hierarchical Transformer that can easily switch between
sequential and feed-forward structures according to the differentiated context
preference within each modality. For inter-modal, we constitute a novel
Multi-Grained Interactive Fusion that applies both neuron- and vector-grained
feature interactions to learn the differentiated contributions across all
modalities. Experimental results show that DialogueTRM outperforms the
state-of-the-art by a significant margin on three benchmark datasets.
"
2893,Music Classification in MIDI Format based on LSTM Mdel,"  Music classification between music made by AI or human composers can be done
by deep learning networks. We first transformed music samples in midi format to
natural language sequences, then classified these samples by mLSTM
(multiplicative Long Short Term Memory) + logistic regression. The accuracy of
the result evaluated by 10-fold cross validation can reach 90%. Our work
indicates that music generated by AI and human composers do have different
characteristics, which can be learned by deep learning networks.
"
2894,Muse: Multi-modal target speaker extraction with visual cues,"  Speaker extraction algorithm relies on the speech sample from the target
speaker as the reference point to focus its attention. Such a reference speech
is typically pre-recorded. On the other hand, the temporal synchronization
between speech and lip movement also serves as an informative cue. Motivated by
this idea, we study a novel technique to use speech-lip visual cues to extract
reference target speech directly from mixture speech during inference time,
without the need of pre-recorded reference speech. We propose a multi-modal
speaker extraction network, named MuSE, that is conditioned only on a lip image
sequence. MuSE not only outperforms other competitive baselines in terms of
SI-SDR and PESQ, but also shows superior robustness in cross-domain
evaluations.
"
2895,"MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical
  Attention","  This paper presents MAST, a new model for Multimodal Abstractive Text
Summarization that utilizes information from all three modalities -- text,
audio and video -- in a multimodal video. Prior work on multimodal abstractive
text summarization only utilized information from the text and video
modalities. We examine the usefulness and challenges of deriving information
from the audio modality and present a sequence-to-sequence trimodal
hierarchical attention-based model that overcomes these challenges by letting
the model pay more attention to the text modality. MAST outperforms the current
state of the art model (video-text) by 2.51 points in terms of Content F1 score
and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal
language understanding.
"
2896,"PiRhDy: Learning Pitch-, Rhythm-, and Dynamics-aware Embeddings for
  Symbolic Music","  Definitive embeddings remain a fundamental challenge of computational
musicology for symbolic music in deep learning today. Analogous to natural
language, music can be modeled as a sequence of tokens. This motivates the
majority of existing solutions to explore the utilization of word embedding
models to build music embeddings. However, music differs from natural languages
in two key aspects: (1) musical token is multi-faceted -- it comprises of
pitch, rhythm and dynamics information; and (2) musical context is
two-dimensional -- each musical token is dependent on both melodic and harmonic
contexts. In this work, we provide a comprehensive solution by proposing a
novel framework named PiRhDy that integrates pitch, rhythm, and dynamics
information seamlessly. PiRhDy adopts a hierarchical strategy which can be
decomposed into two steps: (1) token (i.e., note event) modeling, which
separately represents pitch, rhythm, and dynamics and integrates them into a
single token embedding; and (2) context modeling, which utilizes melodic and
harmonic knowledge to train the token embedding. A thorough study was made on
each component and sub-strategy of PiRhDy. We further validate our embeddings
in three downstream tasks -- melody completion, accompaniment suggestion, and
genre classification. Results indicate a significant advancement of the neural
approach towards symbolic music as well as PiRhDy's potential as a pretrained
tool for a broad range of symbolic music applications.
"
2897,"Revenue and Energy Efficiency-Driven Delay Constrained Computing Task
  Offloading and Resource Allocation in a Vehicular Edge Computing Network: A
  Deep Reinforcement Learning Approach","  For in-vehicle application,task type and vehicle state information, i.e.,
vehicle speed, bear a significant impact on the task delay requirement.
However, the joint impact of task type and vehicle speed on the task delay
constraint has not been studied, and this lack of study may cause a mismatch
between the requirement of the task delay and allocated computation and
wireless resources. In this paper, we propose a joint task type and vehicle
speed-aware task offloading and resource allocation strategy to decrease the
vehicl's energy cost for executing tasks and increase the revenue of the
vehicle for processing tasks within the delay constraint. First, we establish
the joint task type and vehicle speed-aware delay constraint model. Then, the
delay, energy cost and revenue for task execution in the vehicular edge
computing (VEC) server, local terminal and terminals of other vehicles are
calculated. Based on the energy cost and revenue from task execution,the
utility function of the vehicle is acquired. Next, we formulate a joint
optimization of task offloading and resource allocation to maximize the utility
level of the vehicles subject to the constraints of task delay, computation
resources and wireless resources. To obtain a near-optimal solution of the
formulated problem, a joint offloading and resource allocation based on the
multi-agent deep deterministic policy gradient (JORA-MADDPG) algorithm is
proposed to maximize the utility level of vehicles. Simulation results show
that our algorithm can achieve superior performance in task completion delay,
vehicles' energy cost and processing revenue.
"
2898,Melody Classifier with Stacked-LSTM,"  Attempts to use neural network models for music generation have been common
in recent years, and some of them have achieved good results. However, the
research on the evaluation system of machine-generated music is still at a
relatively early stage. This paper proposes a stacked-LSTM binary classifier
based on a language model, which can distinguish the human composer's work from
the machine-generated melody by learning the MIDI file's pitch, position, and
duration.
"
2899,"Audio-based Near-Duplicate Video Retrieval with Audio Similarity
  Learning","  In this work, we address the problem of audio-based near-duplicate video
retrieval. We propose the Audio Similarity Learning (AuSiL) approach that
effectively captures temporal patterns of audio similarity between video pairs.
For the robust similarity calculation between two videos, we first extract
representative audio-based video descriptors by leveraging transfer learning
based on a Convolutional Neural Network (CNN) trained on a large scale dataset
of audio events, and then we calculate the similarity matrix derived from the
pairwise similarity of these descriptors. The similarity matrix is subsequently
fed to a CNN network that captures the temporal structures existing within its
content. We train our network following a triplet generation process and
optimizing the triplet loss function. To evaluate the effectiveness of the
proposed approach, we have manually annotated two publicly available video
datasets based on the audio duplicity between their videos. The proposed
approach achieves very competitive results compared to three state-of-the-art
methods. Also, unlike the competing methods, it is very robust to the retrieval
of audio duplicates generated with speed transformations.
"
2900,"Boosting High-Level Vision with Joint Compression Artifacts Reduction
  and Super-Resolution","  Due to the limits of bandwidth and storage space, digital images are usually
down-scaled and compressed when transmitted over networks, resulting in loss of
details and jarring artifacts that can lower the performance of high-level
visual tasks. In this paper, we aim to generate an artifact-free
high-resolution image from a low-resolution one compressed with an arbitrary
quality factor by exploring joint compression artifacts reduction (CAR) and
super-resolution (SR) tasks. First, we propose a context-aware joint CAR and SR
neural network (CAJNN) that integrates both local and non-local features to
solve CAR and SR in one-stage. Finally, a deep reconstruction network is
adopted to predict high quality and high-resolution images. Evaluation on CAR
and SR benchmark datasets shows that our CAJNN model outperforms previous
methods and also takes 26.2% shorter runtime. Based on this model, we explore
addressing two critical challenges in high-level computer vision: optical
character recognition of low-resolution texts, and extremely tiny face
detection. We demonstrate that CAJNN can serve as an effective image
preprocessing method and improve the accuracy for real-scene text recognition
(from 85.30% to 85.75%) and the average precision for tiny face detection (from
0.317 to 0.611).
"
2901,"Ensemble Chinese End-to-End Spoken Language Understanding for Abnormal
  Event Detection from audio stream","  Conventional spoken language understanding (SLU) consist of two stages, the
first stage maps speech to text by automatic speech recognition (ASR), and the
second stage maps text to intent by natural language understanding (NLU).
End-to-end SLU maps speech directly to intent through a single deep learning
model. Previous end-to-end SLU models are primarily used for English
environment due to lacking large scale SLU dataset in Chines, and use only one
ASR model to extract features from speech. With the help of Kuaishou
technology, a large scale SLU dataset in Chinese is collected to detect
abnormal event in their live audio stream. Based on this dataset, this paper
proposed a ensemble end-to-end SLU model used for Chinese environment. This
ensemble SLU models extracted hierarchies features using multiple pre-trained
ASR models, leading to better representation of phoneme level and word level
information. This proposed approached achieve 9.7% increase of accuracy
compared to previous end-to-end SLU model.
"
2902,"Frame Aggregation and Multi-Modal Fusion Framework for Video-Based
  Person Recognition","  Video-based person recognition is challenging due to persons being blocked
and blurred, and the variation of shooting angle. Previous research always
focused on person recognition on still images, ignoring similarity and
continuity between video frames. To tackle the challenges above, we propose a
novel Frame Aggregation and Multi-Modal Fusion (FAMF) framework for video-based
person recognition, which aggregates face features and incorporates them with
multi-modal information to identify persons in videos. For frame aggregation,
we propose a novel trainable layer based on NetVLAD (named AttentionVLAD),
which takes arbitrary number of features as input and computes a fixed-length
aggregation feature based on feature quality. We show that introducing an
attention mechanism to NetVLAD can effectively decrease the impact of
low-quality frames. For the multi-model information of videos, we propose a
Multi-Layer Multi-Modal Attention (MLMA) module to learn the correlation of
multi-modality by adaptively updating Gram matrix. Experimental results on
iQIYI-VID-2019 dataset show that our framework outperforms other
state-of-the-art methods.
"
2903,Hit Song Prediction Based on Early Adopter Data and Audio Features,"  Billions of USD are invested in new artists and songs by the music industry
every year. This research provides a new strategy for assessing the hit
potential of songs, which can help record companies support their investment
decisions. A number of models were developed that use both audio data, and a
novel feature based on social media listening behaviour. The results show that
models based on early adopter behaviour perform well when predicting top 20
dance hits.
"
2904,"DIME: An Online Tool for the Visual Comparison of Cross-Modal Retrieval
  Models","  Cross-modal retrieval relies on accurate models to retrieve relevant results
for queries across modalities such as image, text, and video. In this paper, we
build upon previous work by tackling the difficulty of evaluating models both
quantitatively and qualitatively quickly. We present DIME (Dataset, Index,
Model, Embedding), a modality-agnostic tool that handles multimodal datasets,
trained models, and data preprocessors to support straightforward model
comparison with a web browser graphical user interface. DIME inherently
supports building modality-agnostic queryable indexes and extraction of
relevant feature embeddings, and thus effectively doubles as an efficient
cross-modal tool to explore and search through datasets.
"
2905,Color Image Segmentation Metrics,"  An automatic image segmentation procedure is an inevitable part of many image
analyses and computer vision which deeply affect the rest of the system;
therefore, a set of interactive segmentation evaluation methods can
substantially simplify the system development process. This entry presents the
state of the art of quantitative evaluation metrics for color image
segmentation methods by performing an analytical and comparative review of the
measures. The decision-making process in selecting a suitable evaluation metric
is still very serious because each metric tends to favor a different
segmentation method for each benchmark dataset. Furthermore, a conceptual
comparison of these metrics is provided at a high level of abstraction and is
discussed for understanding the quantitative changes in different image
segmentation results.
"
2906,"Hierarchical Paired Channel Fusion Network for Street Scene Change
  Detection","  Street Scene Change Detection (SSCD) aims to locate the changed regions
between a given street-view image pair captured at different times, which is an
important yet challenging task in the computer vision community. The intuitive
way to solve the SSCD task is to fuse the extracted image feature pairs, and
then directly measure the dissimilarity parts for producing a change map.
Therefore, the key for the SSCD task is to design an effective feature fusion
method that can improve the accuracy of the corresponding change maps. To this
end, we present a novel Hierarchical Paired Channel Fusion Network (HPCFNet),
which utilizes the adaptive fusion of paired feature channels. Specifically,
the features of a given image pair are jointly extracted by a Siamese
Convolutional Neural Network (SCNN) and hierarchically combined by exploring
the fusion of channel pairs at multiple feature levels. In addition, based on
the observation that the distribution of scene changes is diverse, we further
propose a Multi-Part Feature Learning (MPFL) strategy to detect diverse
changes. Based on the MPFL strategy, our framework achieves a novel approach to
adapt to the scale and location diversities of the scene change regions.
Extensive experiments on three public datasets (i.e., PCD, VL-CMU-CD and
CDnet2014) demonstrate that the proposed framework achieves superior
performance which outperforms other state-of-the-art methods with a
considerable margin.
"
2907,"INDCOR white paper 1: A shared vocabulary for IDN (Interactive Digital
  Narratives)","  COST Action 18230 INDCOR (Interactive Narrative Design for Complexity
Representations) is an interdisciplinary network of researchers and
practitioners intended to further the use of interactive digital narratives
(IDN1) to represent highly complex topics. IDN possess crucial advantages in
this regard, but more knowledge is needed to realize these advantages in broad
usage by media producers and the general public. The lack of a shared
vocabulary is a crucial obstacle on the path to a generalized, accessible body
of IDN knowledge. This white paper frames the situation from the perspective of
INDCOR and describes the creation of an online encyclopedia as a means to
overcome this issue. Two similar and successful projects (The Living Handbook
of Narratology and the Stanford Encyclopedia of Philosophy) serve as examples
for this effort, showing how community-authored encyclopedias can provide
high-quality content. The authors introduce a taxonomy based on an overarching
analytical framework (SPP model) as the foundational element of the
encyclopedia, and detail editorial procedures for the project, including a
peer-review process, designed to assure high academic quality and relevance of
encyclopedia entries. Also, a sample entry provides guidance for authors.
"
2908,Keystroke Dynamics as Part of Lifelogging,"  In this paper we present the case for including keystroke dynamics in
lifelogging. We describe how we have used a simple keystroke logging
application called Loggerman, to create a dataset of longitudinal keystroke
timing data spanning a period of more than 6 months for 4 participants. We
perform a detailed analysis of this data by examining the timing information
associated with bigrams or pairs of adjacently-typed alphabetic characters. We
show how there is very little day-on-day variation of the keystroke timing
among the top-200 bigrams for some participants and for others there is a lot
and this correlates with the amount of typing each would do on a daily basis.
We explore how daily variations could correlate with sleep score from the
previous night but find no significant relation-ship between the two. Finally
we describe the public release of this data as well including as a series of
pointers for future work including correlating keystroke dynamics with mood and
fatigue during the day.
"
2909,"Mutual Information Regularized Identity-aware Facial
  ExpressionRecognition in Compressed Video","  This paper targets to explore the inter-subject variations eliminated facial
expression representation in the compressed video domain. Most of the previous
methods process the RGB images of a sequence, while the off-the-shelf and
valuable expression-related muscle movement already embedded in the compression
format. In the up to two orders of magnitude compressed domain, we can
explicitly infer the expression from the residual frames and possible to
extract identity factors from the I frame with a pre-trained face recognition
network. By enforcing the marginal independent of them, the expression feature
is expected to be purer for the expression and be robust to identity shifts.
Specifically, we propose a novel collaborative min-min game for mutual
information (MI) minimization in latent space. We do not need the identity
label or multiple expression samples from the same person for identity
elimination. Moreover, when the apex frame is annotated in the dataset, the
complementary constraint can be further added to regularize the feature-level
game. In testing, only the compressed residual frames are required to achieve
expression prediction. Our solution can achieve comparable or better
performance than the recent decoded image-based methods on the typical FER
benchmarks with about 3 times faster inference.
"
2910,"Display object alignment may influence location recall in unexpected
  ways","  There is a presumption in human-computer interaction that laying out menus
and most other material in neat rows and columns helps users get work done. The
rule has been so implicit in the field of design as to allow for no debate.
However, the idea that perfect collinearity benefits creates an advantage for
both either search and or recall has rarely been tested. Drawing from separate
branches of cognitive literature, we tested a minimal brainstorming interface
with either aligned or eccentrically arranged layouts on 96 college students.
Incidental exact recall of recently worked locations improved in the eccentric
condition. And in both conditions there were frequent near-miss recall errors
to neighboring aligned objects and groups of objects. Further analysis found
only marginal performance advantages specifically for females with the
eccentric design. However, NASA-TLX subjective measures showed that in
eccentric, females reported higher performance, less effort, and yet also
higher frustration; while males reported lower performance with about the same
effort, and lower frustration.
"
2911,Can We Enable the Drone to be a Filmmaker?,"  Drones are enabling new forms of cinematography. However, quadrotor
cinematography requires accurate comprehension of the scene, technical skill of
flying, artistic skill of composition and simultaneous realization of all the
requirements in real time. These requirements could pose real challenge to
drone amateurs because unsuitable camera viewpoint and motion could result in
unpleasing visual composition and affect the target's visibility. In this
paper, we propose a novel autonomous drone camera system which captures action
scenes using proper camera viewpoint and motion. The key novelty is that our
system can dynamically generate smooth drone camera trajectory associated with
human movement while obeying visual composition principles. We evaluate the
performance of our cinematography system on simulation and real scenario. The
experimental results demonstrate that our system can capture more expressive
video footage of human action than that of the state-of-the-art drone camera
system. To the best of our knowledge, this is the first cinematography system
that enables people to leverage the mobility of quadrotor to autonomously
capture high-quality footage of action scene based on subject's movements.
"
2912,"ComboLoss for Facial Attractiveness Analysis with Squeeze-and-Excitation
  Networks","  Loss function is crucial for model training and feature representation
learning, conventional models usually regard facial attractiveness recognition
task as a regression problem, and adopt MSE loss or Huber variant loss as
supervision to train a deep convolutional neural network (CNN) to predict
facial attractiveness score. Little work has been done to systematically
compare the performance of diverse loss functions. In this paper, we firstly
systematically analyze model performance under diverse loss functions. Then a
novel loss function named ComboLoss is proposed to guide the SEResNeXt50
network. The proposed method achieves state-of-the-art performance on SCUT-FBP,
HotOrNot and SCUT-FBP5500 datasets with an improvement of 1.13%, 2.1% and 0.57%
compared with prior arts, respectively. Code and models are available at
https://github.com/lucasxlu/ComboLoss.git.
"
2913,"WaveTransformer: A Novel Architecture for Audio Captioning Based on
  Learning Temporal and Time-Frequency Information","  Automated audio captioning (AAC) is a novel task, where a method takes as an
input an audio sample and outputs a textual description (i.e. a caption) of its
contents. Most AAC methods are adapted from from image captioning of machine
translation fields. In this work we present a novel AAC novel method,
explicitly focused on the exploitation of the temporal and time-frequency
patterns in audio. We employ three learnable processes for audio encoding, two
for extracting the local and temporal information, and one to merge the output
of the previous two processes. To generate the caption, we employ the widely
used Transformer decoder. We assess our method utilizing the freely available
splits of Clotho dataset. Our results increase previously reported highest
SPIDEr to 17.3, from 16.2.
"
2914,"Learning Dual Semantic Relations with Graph Attention for Image-Text
  Matching","  Image-Text Matching is one major task in cross-modal information processing.
The main challenge is to learn the unified visual and textual representations.
Previous methods that perform well on this task primarily focus on not only the
alignment between region features in images and the corresponding words in
sentences, but also the alignment between relations of regions and relational
words. However, the lack of joint learning of regional features and global
features will cause the regional features to lose contact with the global
context, leading to the mismatch with those non-object words which have global
meanings in some sentences. In this work, in order to alleviate this issue, it
is necessary to enhance the relations between regions and the relations between
regional and global concepts to obtain a more accurate visual representation so
as to be better correlated to the corresponding text. Thus, a novel multi-level
semantic relations enhancement approach named Dual Semantic Relations Attention
Network(DSRAN) is proposed which mainly consists of two modules, separate
semantic relations module and the joint semantic relations module. DSRAN
performs graph attention in both modules respectively for region-level
relations enhancement and regional-global relations enhancement at the same
time. With these two modules, different hierarchies of semantic relations are
learned simultaneously, thus promoting the image-text matching process by
providing more information for the final visual representation. Quantitative
experimental results have been performed on MS-COCO and Flickr30K and our
method outperforms previous approaches by a large margin due to the
effectiveness of the dual semantic relations learning scheme. Codes are
available at https://github.com/kywen1119/DSRAN.
"
2915,A Cluster-Matching-Based Method for Video Face Recognition,"  Face recognition systems are present in many modern solutions and thousands
of applications in our daily lives. However, current solutions are not easily
scalable, especially when it comes to the addition of new targeted people. We
propose a cluster-matching-based approach for face recognition in video. In our
approach, we use unsupervised learning to cluster the faces present in both the
dataset and targeted videos selected for face recognition. Moreover, we design
a cluster matching heuristic to associate clusters in both sets that is also
capable of identifying when a face belongs to a non-registered person. Our
method has achieved a recall of 99.435% and a precision of 99.131% in the task
of video face recognition. Besides performing face recognition, it can also be
used to determine the video segments where each person is present.
"
2916,"Identification of deep breath while moving forward based on multiple
  body regions and graph signal analysis","  This paper presents an unobtrusive solution that can automatically identify
deep breath when a person is walking past the global depth camera. Existing
non-contact breath assessments achieve satisfactory results under restricted
conditions when human body stays relatively still. When someone moves forward,
the breath signals detected by depth camera are hidden within signals of trunk
displacement and deformation, and the signal length is short due to the short
stay time, posing great challenges for us to establish models. To overcome
these challenges, multiple region of interests (ROIs) based signal extraction
and selection method is proposed to automatically obtain the signal informative
to breath from depth video. Subsequently, graph signal analysis (GSA) is
adopted as a spatial-temporal filter to wipe the components unrelated to
breath. Finally, a classifier for identifying deep breath is established based
on the selected breath-informative signal. In validation experiments, the
proposed approach outperforms the comparative methods with the accuracy,
precision, recall and F1 of 75.5%, 76.2%, 75.0% and 75.2%, respectively. This
system can be extended to public places to provide timely and ubiquitous help
for those who may have or are going through physical or mental trouble.
"
2917,A Qualitative Analysis of Haptic Feedback in Music Focused Exercises,"  We present the findings of a pilot-study that analysed the role of haptic
feedback in a musical context. To examine the role of haptics in Digital
Musical Instrument (DMI) design an experiment was formulated to measure the
users' perception of device usability across four separate feedback stages:
fully haptic (force and tactile combined), constant force only, vibrotactile
only, and no feedback. The study was piloted over extended periods with the
intention of exploring the application and integration of DMIs in real-world
musical contexts. Applying a music orientated analysis of this type enabled the
investigative process to not only take place over a comprehensive period, but
allowed for the exploration of DMI integration in everyday compositional
practices. As with any investigation that involves creativity, it was important
that the participants did not feel rushed or restricted. That is, they were
given sufficient time to explore and assess the different feedback types
without constraint. This provided an accurate and representational set of
qualitative data for validating the participants' experience with the different
feedback types they were presented with.
"
2918,"GAZED- Gaze-guided Cinematic Editing of Wide-Angle Monocular Video
  Recordings","  We present GAZED- eye GAZe-guided EDiting for videos captured by a solitary,
static, wide-angle and high-resolution camera. Eye-gaze has been effectively
employed in computational applications as a cue to capture interesting scene
content; we employ gaze as a proxy to select shots for inclusion in the edited
video. Given the original video, scene content and user eye-gaze tracks are
combined to generate an edited video comprising cinematically valid actor shots
and shot transitions to generate an aesthetic and vivid representation of the
original narrative. We model cinematic video editing as an energy minimization
problem over shot selection, whose constraints capture cinematographic editing
conventions. Gazed scene locations primarily determine the shots constituting
the edited video. Effectiveness of GAZED against multiple competing methods is
demonstrated via a psychophysical study involving 12 users and twelve
performance videos.
"
2919,"MTGAT: Multimodal Temporal Graph Attention Networks for Unaligned Human
  Multimodal Language Sequences","  Human communication is multimodal in nature; it is through multiple
modalities, i.e., language, voice, and facial expressions, that opinions and
emotions are expressed. Data in this domain exhibits complex multi-relational
and temporal interactions. Learning from this data is a fundamentally
challenging research problem. In this paper, we propose Multimodal Temporal
Graph Attention Networks (MTGAT). MTGAT is an interpretable graph-based neural
model that provides a suitable framework for analyzing this type of multimodal
sequential data. We first introduce a procedure to convert unaligned multimodal
sequence data into a graph with heterogeneous nodes and edges that captures the
rich interactions between different modalities through time. Then, a novel
graph operation, called Multimodal Temporal Graph Attention, along with a
dynamic pruning and read-out technique is designed to efficiently process this
multimodal temporal graph. By learning to focus only on the important
interactions within the graph, our MTGAT is able to achieve state-of-the-art
performance on multimodal sentiment analysis and emotion recognition benchmarks
including IEMOCAP and CMU-MOSI, while utilizing significantly fewer
computations.
"
2920,"GSEP: A robust vocal and accompaniment separation system using gated
  CBHG module and loudness normalization","  In the field of audio signal processing research, source separation has been
a popular research topic for a long time and the recent adoption of the deep
neural networks have shown a significant improvement in performance. The
improvement vitalizes the industry to productize audio deep learning based
products and services including Karaoke in the music streaming apps and
dialogue enhancement in the UHDTV. For these early markets, we defined a set of
design principles of the vocal and accompaniment separation model in terms of
robustness, quality, and cost. In this paper, we introduce GSEP (Gaudio source
SEParation system), a robust vocal and accompaniment separation system using a
Gated- CBHG module, mask warping, and loudness normalization and it was
verified that the proposed system satisfies all three principles and
outperforms the state-of-the-art systems both in objective measure and
subjective assessment through experiments.
"
2921,Feature matching in Ultrasound images,"  Feature matching is an important technique to identify a single object in
different images. It helps machines to construct recognition of a specific
object from multiple perspectives. For years, feature matching has been
commonly used in various computer vision applications, like traffic
surveillance, self-driving, and other systems. With the arise of Computer-Aided
Diagnosis(CAD), the need for feature matching techniques also emerges in the
medical imaging field. In this paper, we present a deep learning-based method
specially for ultrasound images. It will be examined against existing methods
that have outstanding results on regular images. As the ultrasound images are
different from regular images in many fields like texture, noise type, and
dimension, traditional methods will be evaluated and optimized to be applied to
ultrasound images.
"
2922,A Computational Evaluation of Musical Pattern Discovery Algorithms,"  Pattern discovery algorithms in the music domain aim to find meaningful
components in musical compositions. Over the years, although many algorithms
have been developed for pattern discovery in music data, it remains a
challenging task. To gain more insight into the efficacy of these algorithms,
we introduce three computational methods for examining their output: Pattern
Polling, to combine the patterns; Comparative Classification, to differentiate
the patterns; Synthetic Data, to inject predetermined patterns. In combining
and differentiating the patterns extracted by algorithms, we expose how they
differ from the patterns annotated by humans as well as between algorithms
themselves, with rhythmic features contributing the most to the algorithm-human
and algorithm-algorithm discrepancies. Despite the difficulty in reconciling
and evaluating the divergent patterns extracted from algorithms, we identify
some possibilities for addressing them. In particular, we generate controllable
synthesised data with predetermined patterns planted into random data, thereby
leaving us better able to inspect, compare, validate, and select the
algorithms. We provide a concrete example of synthesising data for
understanding the algorithms and expand our discussion to the potential and
limitations of such an approach.
"
2923,"Comprehensive Empirical Evaluation of Deep Learning Approaches for
  Session-based Recommendation in E-Commerce","  Boosting sales of e-commerce services is guaranteed once users find more
matching items to their interests in a short time. Consequently, recommendation
systems have become a crucial part of any successful e-commerce services.
Although various recommendation techniques could be used in e-commerce, a
considerable amount of attention has been drawn to session-based recommendation
systems during the recent few years. This growing interest is due to the
security concerns in collecting personalized user behavior data, especially
after the recent general data protection regulations. In this work, we present
a comprehensive evaluation of the state-of-the-art deep learning approaches
used in the session-based recommendation. In session-based recommendation, a
recommendation system counts on the sequence of events made by a user within
the same session to predict and endorse other items that are more likely to
correlate with his/her preferences. Our extensive experiments investigate
baseline techniques (\textit{e.g.,} nearest neighbors and pattern mining
algorithms) and deep learning approaches (\textit{e.g.,} recurrent neural
networks, graph neural networks, and attention-based networks). Our evaluations
show that advanced neural-based models and session-based nearest neighbor
algorithms outperform the baseline techniques in most of the scenarios.
However, we found that these models suffer more in case of long sessions when
there exists drift in user interests, and when there is no enough data to model
different items correctly during training. Our study suggests that using hybrid
models of different approaches combined with baseline algorithms could lead to
substantial results in session-based recommendations based on dataset
characteristics. We also discuss the drawbacks of current session-based
recommendation algorithms and further open research directions in this field.
"
2924,"Short Video-based Advertisements Evaluation System: Self-Organizing
  Learning Approach","  With the rising of short video apps, such as TikTok, Snapchat and Kwai,
advertisement in short-term user-generated videos (UGVs) has become a trending
form of advertising. Prediction of user behavior without specific user profile
is required by advertisers, as they expect to acquire advertisement performance
in advance in the scenario of cold start. Current recommender system do not
take raw videos as input; additionally, most previous work of Multi-Modal
Machine Learning may not deal with unconstrained videos like UGVs. In this
paper, we proposed a novel end-to-end self-organizing framework for user
behavior prediction. Our model is able to learn the optimal topology of neural
network architecture, as well as optimal weights, through training data. We
evaluate our proposed method on our in-house dataset. The experimental results
reveal that our model achieves the best performance in all our experiments.
"
2925,Video Understanding based on Human Action and Group Activity Recognition,"  A lot of previous work, such as video captioning, has shown promising
performance in producing general video understanding. However, it is still
challenging to generate a fine-grained description of human actions and their
interactions using state-of-the-art video captioning techniques. The detailed
description of human actions and group activities is essential information,
which can be used in real-time CCTV video surveillance, health care, sports
video analysis, etc. In this study, we will propose and improve the video
understanding method based on the Group Activity Recognition model by learning
Actor Relation Graph (ARG).We will enhance the functionality and the
performance of the ARG based model to perform a better video understanding by
applying approaches such as increasing human object detection accuracy with
YOLO, increasing process speed by reducing the input image size, and applying
ResNet in the CNN layer.We will also introduce a visualization model that will
visualize each input video frame with predicted bounding boxes on each human
object and predicted ""video captioning"" to describe each individual's action
and their collective activity.
"
2926,Enactive Mandala: Audio-visualizing Brain Waves,"  We are exploring the design and implementation of artificial expressions,
kinetic audio-visual representations of real-time physiological data that
reflect emotional and cognitive state. In this work, we demonstrate a
prototype, the Enactive Mandala, which maps real-time EEG signals to modulate
ambient music and animated visual music. Transparent real-time audio-visual
feedback of brainwave qualities supports intuitive insight into the connection
between thoughts and physiological states.
"
2927,A QP-adaptive Mechanism for CNN-based Filter in Video Coding,"  Convolutional neural network (CNN)-based filters have achieved great success
in video coding. However, in most previous works, individual models are needed
for each quantization parameter (QP) band. This paper presents a generic method
to help an arbitrary CNN-filter handle different quantization noise. We model
the quantization noise problem and implement a feasible solution on CNN, which
introduces the quantization step (Qstep) into the convolution. When the
quantization noise increases, the ability of the CNN-filter to suppress noise
improves accordingly. This method can be used directly to replace the (vanilla)
convolution layer in any existing CNN-filters. By using only 25% of the
parameters, the proposed method achieves better performance than using multiple
models with VTM-6.3 anchor. Besides, an additional BD-rate reduction of 0.2% is
achieved by our proposed method for chroma components.
"
2928,"Effect of Language Proficiency on Subjective Evaluation of Noise
  Suppression Algorithms","  Speech communication systems based on Voice-over-IP technology are frequently
used by native as well as non-native speakers of a target language, e.g. in
international phone calls or telemeetings. Frequently, such calls also occur in
a noisy environment, making noise suppression modules necessary to increase
perceived quality of experience. Whereas standard tests for assessing perceived
quality make use of native listeners, we assume that noise-reduced speech and
residual noise may affect native and non-native listeners of a target language
in different ways. To test this assumption, we report results of two subjective
tests conducted with English and German native listeners who judge the quality
of speech samples recorded by native English, German, and Mandarin speakers,
which are degraded with different background noise levels and noise suppression
effects. The experiments were conducted following the standardized ITU-T Rec.
P.835 approach, however implemented in a crowdsourcing setting according to
ITU-T Rec. P.808. Our results show a significant influence of language on
speech signal ratings and, consequently, on the overall perceived quality in
specific conditions.
"
2929,"Melody Harmonization Using Orderless NADE, Chord Balancing, and Blocked
  Gibbs Sampling","  Coherence and interestingness are two criteria for evaluating the performance
of melody harmonization, which aims to generate a chord progression from a
symbolic melody. In this study, we apply the concept of orderless NADE, which
takes the melody and its partially masked chord sequence as the input of the
BiLSTM-based networks to learn the masked ground truth, to the training
process. In addition, class weighting is used to compensate for some reasonable
chord labels that are rarely seen in the training set. Consistent with the
stochasticity in training, blocked Gibbs sampling with proper numbers of
masking/generating loops is used in the inference phase to progressively trade
the coherence of the generated chord sequence off against its interestingness.
The experiments were conducted on a dataset of 18,005 melody/chord pairs. Our
proposed model outperforms the state-of-the-art system MTHarmonizer in five of
six different objective metrics based on chord/melody harmonicity and chord
progression. The subjective test results with more than 100 participants also
show the superiority of our model.
"
2930,Contrastive Unsupervised Learning for Audio Fingerprinting,"  The rise of video-sharing platforms has attracted more and more people to
shoot videos and upload them to the Internet. These videos mostly contain a
carefully-edited background audio track, where serious speech change, pitch
shifting and various types of audio effects may involve, and existing audio
identification systems may fail to recognize the audio. To solve this problem,
in this paper, we introduce the idea of contrastive learning to the task of
audio fingerprinting (AFP). Contrastive learning is an unsupervised approach to
learn representations that can effectively group similar samples and
discriminate dissimilar ones. In our work, we consider an audio track and its
differently distorted versions as similar while considering different audio
tracks as dissimilar. Based on the momentum contrast (MoCo) framework, we
devise a contrastive learning method for AFP, which can generate fingerprints
that are both discriminative and robust. A set of experiments showed that our
AFP method is effective for audio identification, with robustness to serious
audio distortions, including the challenging speed change and pitch shifting.
"
2931,"ST-GREED: Space-Time Generalized Entropic Differences for Frame Rate
  Dependent Video Quality Prediction","  We consider the problem of conducting frame rate dependent video quality
assessment (VQA) on videos of diverse frame rates, including high frame rate
(HFR) videos. More generally, we study how perceptual quality is affected by
frame rate, and how frame rate and compression combine to affect perceived
quality. We devise an objective VQA model called Space-Time GeneRalized
Entropic Difference (GREED) which analyzes the statistics of spatial and
temporal band-pass video coefficients. A generalized Gaussian distribution
(GGD) is used to model band-pass responses, while entropy variations between
reference and distorted videos under the GGD model are used to capture video
quality variations arising from frame rate changes. The entropic differences
are calculated across multiple temporal and spatial subbands, and merged using
a learned regressor. We show through extensive experiments that GREED achieves
state-of-the-art performance on the LIVE-YT-HFR Database when compared with
existing VQA models. The features used in GREED are highly generalizable and
obtain competitive performance even on standard, non-HFR VQA databases. The
implementation of GREED has been made available online:
https://github.com/pavancm/GREED
"
2932,Mining Generalized Features for Detecting AI-Manipulated Fake Faces,"  Recently, AI-manipulated face techniques have developed rapidly and
constantly, which has raised new security issues in society. Although existing
detection methods consider different categories of fake faces, the performance
on detecting the fake faces with ""unseen"" manipulation techniques is still poor
due to the distribution bias among cross-manipulation techniques. To solve this
problem, we propose a novel framework that focuses on mining intrinsic features
and further eliminating the distribution bias to improve the generalization
ability. Firstly, we focus on mining the intrinsic clues in the channel
difference image (CDI) and spectrum image (SI) from the camera imaging process
and the indispensable step in AI manipulation process. Then, we introduce the
Octave Convolution (OctConv) and an attention-based fusion module to
effectively and adaptively mine intrinsic features from CDI and SI. Finally, we
design an alignment module to eliminate the bias of manipulation techniques to
obtain a more generalized detection framework. We evaluate the proposed
framework on four categories of fake faces datasets with the most popular and
state-of-the-art manipulation techniques, and achieve very competitive
performances. To further verify the generalization ability of the proposed
framework, we conduct experiments on cross-manipulation techniques, and the
results show the advantages of our method.
"
2933,"Rule-embedded network for audio-visual voice activity detection in live
  musical video streams","  Detecting anchor's voice in live musical streams is an important
preprocessing for music and speech signal processing. Existing approaches to
voice activity detection (VAD) primarily rely on audio, however, audio-based
VAD is difficult to effectively focus on the target voice in noisy
environments. With the help of visual information, this paper proposes a
rule-embedded network to fuse the audio-visual (A-V) inputs to help the model
better detect target voice. The core role of the rule in the model is to
coordinate the relation between the bi-modal information and use visual
representations as the mask to filter out the information of non-target sound.
Experiments show that: 1) with the help of cross-modal fusion by the proposed
rule, the detection result of A-V branch outperforms that of audio branch; 2)
the performance of bi-modal model far outperforms that of audio-only models,
indicating that the incorporation of both audio and visual signals is highly
beneficial for VAD. To attract more attention to the cross-modal music and
audio signal processing, a new live musical video corpus with frame-level label
is introduced.
"
2934,Remixing Music with Visual Conditioning,"  We propose a visually conditioned music remixing system by incorporating deep
visual and audio models. The method is based on a state of the art audio-visual
source separation model which performs music instrument source separation with
video information. We modified the model to work with user-selected images
instead of videos as visual input during inference to enable separation of
audio-only content. Furthermore, we propose a remixing engine that generalizes
the task of source separation into music remixing. The proposed method is able
to achieve improved audio quality compared to remixing performed by the
separate-and-add method with a state-of-the-art audio-visual source separation
model.
"
2935,Melody-Conditioned Lyrics Generation with SeqGANs,"  Automatic lyrics generation has received attention from both music and AI
communities for years. Early rule-based approaches have~---due to increases in
computational power and evolution in data-driven models---~mostly been replaced
with deep-learning-based systems. Many existing approaches, however, either
rely heavily on prior knowledge in music and lyrics writing or oversimplify the
task by largely discarding melodic information and its relationship with the
text. We propose an end-to-end melody-conditioned lyrics generation system
based on Sequence Generative Adversarial Networks (SeqGAN), which generates a
line of lyrics given the corresponding melody as the input. Furthermore, we
investigate the performance of the generator with an additional input
condition: the theme or overarching topic of the lyrics to be generated. We
show that the input conditions have no negative impact on the evaluation
metrics while enabling the network to produce more meaningful results.
"
2936,Large-Scale MIDI-based Composer Classification,"  Music classification is a task to classify a music piece into labels such as
genres or composers. We propose large-scale MIDI based composer classification
systems using GiantMIDI-Piano, a transcription-based dataset. We propose to use
piano rolls, onset rolls, and velocity rolls as input representations and use
deep neural networks as classifiers. To our knowledge, we are the first to
investigate the composer classification problem with up to 100 composers. By
using convolutional recurrent neural networks as models, our MIDI based
composer classification system achieves a 10-composer and a 100-composer
classification accuracies of 0.648 and 0.385 (evaluated on 30-second clips) and
0.739 and 0.489 (evaluated on music pieces), respectively. Our MIDI based
composer system outperforms several audio-based baseline classification
systems, indicating the effectiveness of using compact MIDI representations for
composer classification.
"
2937,"Speech-Image Semantic Alignment Does Not Depend on Any Prior
  Classification Tasks","  Semantically-aligned $(speech, image)$ datasets can be used to explore
""visually-grounded speech"". In a majority of existing investigations, features
of an image signal are extracted using neural networks ""pre-trained"" on other
tasks (e.g., classification on ImageNet). In still others, pre-trained networks
are used to extract audio features prior to semantic embedding. Without
""transfer learning"" through pre-trained initialization or pre-trained feature
extraction, previous results have tended to show low rates of recall in $speech
\rightarrow image$ and $image \rightarrow speech$ queries.
  Choosing appropriate neural architectures for encoders in the speech and
image branches and using large datasets, one can obtain competitive recall
rates without any reliance on any pre-trained initialization or feature
extraction: $(speech,image)$ semantic alignment and $speech \rightarrow image$
and $image \rightarrow speech$ retrieval are canonical tasks worthy of
independent investigation of their own and allow one to explore other
questions---e.g., the size of the audio embedder can be reduced significantly
with little loss of recall rates in $speech \rightarrow image$ and $image
\rightarrow speech$ queries.
"
2938,"Identifying safe intersection design through unsupervised feature
  extraction from satellite imagery","  The World Health Organization has listed the design of safer intersections as
a key intervention to reduce global road trauma. This article presents the
first study to systematically analyze the design of all intersections in a
large country, based on aerial imagery and deep learning. Approximately 900,000
satellite images were downloaded for all intersections in Australia and
customized computer vision techniques emphasized the road infrastructure. A
deep autoencoder extracted high-level features, including the intersection's
type, size, shape, lane markings, and complexity, which were used to cluster
similar designs. An Australian telematics data set linked infrastructure design
to driving behaviors captured during 66 million kilometers of driving. This
showed more frequent hard acceleration events (per vehicle) at four- than
three-way intersections, relatively low hard deceleration frequencies at
T-intersections, and consistently low average speeds on roundabouts. Overall,
domain-specific feature extraction enabled the identification of infrastructure
improvements that could result in safer driving behaviors, potentially reducing
road trauma.
"
2939,Acoustic Correlates of the Voice Qualifiers: A Survey,"  Our voices are as distinctive as our faces and fingerprints. There is a
spectrum of non-disjoint traits that make our voices unique and identifiable,
such as the fundamental frequency, the intensity, and most interestingly the
quality of the speech. Voice quality refers to the characteristic features of
an individual's voice. Previous research has from time-to-time proven the
ubiquity of voice quality in making different paralinguistic inferences. These
inferences range from identifying personality traits, to health conditions and
beyond. In this manuscript, we first map the paralinguistic voice qualifiers to
their acoustic correlates in the light of the previous research and literature.
We also determine the openSMILE correlates one could possibly use to measure
those correlates. In the second part, we give a set of example paralinguistic
inferences that can be made using different acoustic and perceptual voice
quality features.
"
2940,Multimodal Metric Learning for Tag-based Music Retrieval,"  Tag-based music retrieval is crucial to browse large-scale music libraries
efficiently. Hence, automatic music tagging has been actively explored, mostly
as a classification task, which has an inherent limitation: a fixed vocabulary.
On the other hand, metric learning enables flexible vocabularies by using
pretrained word embeddings as side information. Also, metric learning has
already proven its suitability for cross-modal retrieval tasks in other domains
(e.g., text-to-image) by jointly learning a multimodal embedding space. In this
paper, we investigate three ideas to successfully introduce multimodal metric
learning for tag-based music retrieval: elaborate triplet sampling, acoustic
and cultural music information, and domain-specific word embeddings. Our
experimental results show that the proposed ideas enhance the retrieval system
quantitatively, and qualitatively. Furthermore, we release the MSD500, a subset
of the Million Song Dataset (MSD) containing 500 cleaned tags, 7 manually
annotated tag categories, and user taste profiles.
"
2941,"CNN based Multistage Gated Average Fusion (MGAF) for Human Action
  Recognition Using Depth and Inertial Sensors","  Convolutional Neural Network (CNN) provides leverage to extract and fuse
features from all layers of its architecture. However, extracting and fusing
intermediate features from different layers of CNN structure is still
uninvestigated for Human Action Recognition (HAR) using depth and inertial
sensors. To get maximum benefit of accessing all the CNN's layers, in this
paper, we propose novel Multistage Gated Average Fusion (MGAF) network which
extracts and fuses features from all layers of CNN using our novel and
computationally efficient Gated Average Fusion (GAF) network, a decisive
integral element of MGAF. At the input of the proposed MGAF, we transform the
depth and inertial sensor data into depth images called sequential front view
images (SFI) and signal images (SI) respectively. These SFI are formed from the
front view information generated by depth data. CNN is employed to extract
feature maps from both input modalities. GAF network fuses the extracted
features effectively while preserving the dimensionality of fused feature as
well. The proposed MGAF network has structural extensibility and can be
unfolded to more than two modalities. Experiments on three publicly available
multimodal HAR datasets demonstrate that the proposed MGAF outperforms the
previous state of the art fusion methods for depth-inertial HAR in terms of
recognition accuracy while being computationally much more efficient. We
increase the accuracy by an average of 1.5 percent while reducing the
computational cost by approximately 50 percent over the previous state of the
art.
"
2942,"Statistical Analysis of Signal-Dependent Noise: Application in Blind
  Localization of Image Splicing Forgery","  Visual noise is often regarded as a disturbance in image quality, whereas it
can also provide a crucial clue for image-based forensic tasks. Conventionally,
noise is assumed to comprise an additive Gaussian model to be estimated and
then used to reveal anomalies. However, for real sensor noise, it should be
modeled as signal-dependent noise (SDN). In this work, we apply SDN to splicing
forgery localization tasks. Through statistical analysis of the SDN model, we
assume that noise can be modeled as a Gaussian approximation for a certain
brightness and propose a likelihood model for a noise level function. By
building a maximum a posterior Markov random field (MAP-MRF) framework, we
exploit the likelihood of noise to reveal the alien region of spliced objects,
with a probability combination refinement strategy. To ensure a completely
blind detection, an iterative alternating method is adopted to estimate the MRF
parameters. Experimental results demonstrate that our method is effective and
provides a comparative localization performance.
"
2943,"Reliability of Power System Frequency on Times-Stamping Digital
  Recordings","  Power system frequency could be captured by digital recordings and extracted
to compare with a reference database for forensic time-stamp verification. It
is known as the electric network frequency (ENF) criterion, enabled by the
properties of random fluctuation and intra-grid consistency. In essence, this
is a task of matching a short random sequence within a long reference, and the
reliability of this criterion is mainly concerned with whether this match could
be unique and correct. In this paper, we comprehensively analyze the factors
affecting the reliability of ENF matching, including length of test recording,
length of reference, temporal resolution, and signal-to-noise ratio (SNR). For
synthetic analysis, we incorporate the first-order autoregressive (AR) ENF
model and propose an efficient time-frequency domain (TFD) noisy ENF synthesis
method. Then, the reliability analysis schemes for both synthetic and
real-world data are respectively proposed. Through a comprehensive study we
reveal that while the SNR is an important external factor to determine whether
time-stamp verification is viable, the length of test recording is the most
important inherent factor, followed by the length of reference. However, the
temporal resolution has little impact on the matching process.
"
2944,"General Data Analytics with Applications to Visual Information Analysis:
  A Provable Backward-Compatible Semisimple Paradigm over T-Algebra","  We consider a novel backward-compatible paradigm of general data analytics
over a recently-reported semisimple algebra (called t-algebra). We study the
abstract algebraic framework over the t-algebra by representing the elements of
t-algebra by fix-sized multi-way arrays of complex numbers and the algebraic
structure over the t-algebra by a collection of direct-product constituents.
Over the t-algebra, many algorithms, if not all, are generalized in a
straightforward manner using this new semisimple paradigm. To demonstrate the
new paradigm's performance and its backward-compatibility, we generalize some
canonical algorithms for visual pattern analysis. Experiments on public
datasets show that the generalized algorithms compare favorably with their
canonical counterparts.
"
2945,Visual Companion for Booklovers,"  An innumerable number of individual choices go into discovering a new book.
There are unmistakably two groups of booklovers: those who like to search
online, follow other people's latest readings, or simply react to a system's
recommendations; and those who love to wander between library stacks, lose
themselves behind bookstore shelves, or simply hide behind piles of
(un)organized books. Depending on which group a person may fall into, there are
two distinct and corresponding mediums that inform his or her choices: digital,
that provides efficient retrieval of information online, and physical, a more
tactile pursuit that leads to unexpected discoveries and promotes serendipity.
How could we possibly bridge the gap between these seemingly disparate mediums
into an integrated system that can amplify the benefits they both offer? In
this paper, we present the BookVIS application, which uses book-related data
and generates personalized visualizations to follow users in their quest for a
new book. In this new redesigned version, the app brings associative visual
connections to support intuitive exploration of easily retrieved digital
information and its relationship with the physical book in hand. BookVIS keeps
track of the user's reading preferences and generates a dataSelfie as an
individual snapshot of a personal taste that grows over time. Usability testing
has also been conducted and has demonstrated the app's ability to identify
distinguishable patterns in readers' tastes that could be further used to
communicate personal preferences in new ""shelf-browsing"" iterations. By
efficiently supplementing the user's cognitive information needs while still
supporting the spontaneity and enjoyment of the book browsing experience,
BookVIS bridges the gap between real and online realms, and maximizes the
engagement of personalized mobile visual clues.
"
2946,Watermarking Graph Neural Networks by Random Graphs,"  Many learning tasks require us to deal with graph data which contains rich
relational information among elements, leading increasing graph neural network
(GNN) models to be deployed in industrial products for improving the quality of
service. However, they also raise challenges to model authentication. It is
necessary to protect the ownership of the GNN models, which motivates us to
present a watermarking method to GNN models in this paper. In the proposed
method, an Erdos-Renyi (ER) random graph with random node feature vectors and
labels is randomly generated as a trigger to train the GNN to be protected
together with the normal samples. During model training, the secret watermark
is embedded into the label predictions of the ER graph nodes. During model
verification, by activating a marked GNN with the trigger ER graph, the
watermark can be reconstructed from the output to verify the ownership. Since
the ER graph was randomly generated, by feeding it to a non-marked GNN, the
label predictions of the graph nodes are random, resulting in a low false alarm
rate (of the proposed work). Experimental results have also shown that, the
performance of a marked GNN on its original task will not be impaired.
Moreover, it is robust against model compression and fine-tuning, which has
shown the superiority and applicability.
"
2947,"DeepOpht: Medical Report Generation for Retinal Images via Deep Models
  and Visual Explanation","  In this work, we propose an AI-based method that intends to improve the
conventional retinal disease treatment procedure and help ophthalmologists
increase diagnosis efficiency and accuracy. The proposed method is composed of
a deep neural networks-based (DNN-based) module, including a retinal disease
identifier and clinical description generator, and a DNN visual explanation
module. To train and validate the effectiveness of our DNN-based module, we
propose a large-scale retinal disease image dataset. Also, as ground truth, we
provide a retinal image dataset manually labeled by ophthalmologists to
qualitatively show, the proposed AI-based method is effective. With our
experimental results, we show that the proposed method is quantitatively and
qualitatively effective. Our method is capable of creating meaningful retinal
image descriptions and visual explanations that are clinically relevant.
"
2948,"Using a Bi-directional LSTM Model with Attention Mechanism trained on
  MIDI Data for Generating Unique Music","  Generating music is an interesting and challenging problem in the field of
machine learning. Mimicking human creativity has been popular in recent years,
especially in the field of computer vision and image processing. With the
advent of GANs, it is possible to generate new similar images, based on trained
data. But this cannot be done for music similarly, as music has an extra
temporal dimension. So it is necessary to understand how music is represented
in digital form. When building models that perform this generative task, the
learning and generation part is done in some high-level representation such as
MIDI (Musical Instrument Digital Interface) or scores. This paper proposes a
bi-directional LSTM (Long short-term memory) model with attention mechanism
capable of generating similar type of music based on MIDI data. The music
generated by the model follows the theme/style of the music the model is
trained on. Also, due to the nature of MIDI, the tempo, instrument, and other
parameters can be defined, and changed, post generation.
"
2949,"AVECL-UMONS database for audio-visual event classification and
  localization","  We introduce the AVECL-UMons dataset for audio-visual event classification
and localization in the context of office environments. The audio-visual
dataset is composed of 11 event classes recorded at several realistic positions
in two different rooms. Two types of sequences are recorded according to the
number of events in the sequence. The dataset comprises 2662 unilabel sequences
and 2724 multilabel sequences corresponding to a total of 5.24 hours. The
dataset is publicly accessible online :
https://zenodo.org/record/3965492#.X09wsobgrCI.
"
2950,Facial Keypoint Sequence Generation from Audio,"  Whenever we speak, our voice is accompanied by facial movements and
expressions. Several recent works have shown the synthesis of highly
photo-realistic videos of talking faces, but they either require a source video
to drive the target face or only generate videos with a fixed head pose. This
lack of facial movement is because most of these works focus on the lip
movement in sync with the audio while assuming the remaining facial keypoints'
fixed nature. To address this, a unique audio-keypoint dataset of over 150,000
videos at 224p and 25fps is introduced that relates the facial keypoint
movement for the given audio. This dataset is then further used to train the
model, Audio2Keypoint, a novel approach for synthesizing facial keypoint
movement to go with the audio. Given a single image of the target person and an
audio sequence (in any language), Audio2Keypoint generates a plausible keypoint
movement sequence in sync with the input audio, conditioned on the input image
to preserve the target person's facial characteristics. To the best of our
knowledge, this is the first work that proposes an audio-keypoint dataset and
learns a model to output the plausible keypoint sequence to go with audio of
any arbitrary length. Audio2Keypoint generalizes across unseen people with a
different facial structure allowing us to generate the sequence with the voice
from any source or even synthetic voices. Instead of learning a direct mapping
from audio to video domain, this work aims to learn the audio-keypoint mapping
that allows for in-plane and out-of-plane head rotations, while preserving the
person's identity using a Pose Invariant (PIV) Encoder.
"
2951,"Content-based Analysis of the Cultural Differences between TikTok and
  Douyin","  Short-form video social media shifts away from the traditional media paradigm
by telling the audience a dynamic story to attract their attention. In
particular, different combinations of everyday objects can be employed to
represent a unique scene that is both interesting and understandable. Offered
by the same company, TikTok and Douyin are popular examples of such new media
that has become popular in recent years, while being tailored for different
markets (e.g. the United States and China). The hypothesis that they express
cultural differences together with media fashion and social idiosyncrasy is the
primary target of our research. To that end, we first employ the Faster
Regional Convolutional Neural Network (Faster R-CNN) pre-trained with the
Microsoft Common Objects in COntext (MS-COCO) dataset to perform object
detection. Based on a suite of objects detected from videos, we perform
statistical analysis including label statistics, label similarity, and
label-person distribution. We further use the Two-Stream Inflated 3D ConvNet
(I3D) pre-trained with the Kinetics dataset to categorize and analyze human
actions. By comparing the distributional results of TikTok and Douyin, we
uncover a wealth of similarity and contrast between the two closely related
video social media platforms along the content dimensions of object quantity,
object categories, and human action categories.
"
2952,Robust Latent Representations via Cross-Modal Translation and Alignment,"  Multi-modal learning relates information across observation modalities of the
same physical phenomenon to leverage complementary information. Most
multi-modal machine learning methods require that all the modalities used for
training are also available for testing. This is a limitation when the signals
from some modalities are unavailable or are severely degraded by noise. To
address this limitation, we aim to improve the testing performance of uni-modal
systems using multiple modalities during training only. The proposed
multi-modal training framework uses cross-modal translation and
correlation-based latent space alignment to improve the representations of the
weaker modalities. The translation from the weaker to the stronger modality
generates a multi-modal intermediate encoding that is representative of both
modalities. This encoding is then correlated with the stronger modality
representations in a shared latent space. We validate the proposed approach on
the AVEC 2016 dataset for continuous emotion recognition and show the
effectiveness of the approach that achieves state-of-the-art (uni-modal)
performance for weaker modalities.
"
2953,A novel group based cryptosystem based on electromagnetic rotor machine,"  In this paper, an algorithm is aimed to make a cryptosystem for gray level
images based on voice features, secret sharing scheme and electromagnetic rotor
machine. Here, Shamir secret sharing (k n) threshold scheme is used to secure a
key along with voice features of (n k) users. Keystream is molded by
coefficients of a voice sample, using this key stream, rotor machines rotating
cylinders positions are initialized and internal wiring is decided by pseudo
random number of Henon chaotic map, where initial seed for chaotic system is
chosen from keystream. And furthermore, shares of key stream are distributed
among users. Speech processing is fused with electromagnetic machine to provide
authentication as well as group based encryption. Perceptual linear predication
(PLP) coefficients are utilized for formation of secret key. Simulation
experiments and statistical analysis demonstrate that the proposed algorithm is
sensitive to initial secret keystream, entropy, mean value analysis and
histogram of the encrypted image is admirable. Hence, the proposed scheme is
resistible to any vulnerable situation.
"
2954,"A multi-level approach with visual information for encrypted H.265/HEVC
  videos","  High-efficiency video coding (HEVC) encryption has been proposed to encrypt
syntax elements for the purpose of video encryption. To achieve high video
security, to the best of our knowledge, almost all of the existing HEVC
encryption algorithms mainly encrypt the whole video, such that the user
without permissions cannot obtain any viewable information. However, these
encryption algorithms cannot meet the needs of customers who need part of the
information but not the full information in the video. In many cases, such as
professional paid videos or video meetings, users would like to observe some
visible information in the encrypted video of the original video to satisfy
their requirements in daily life. Aiming at this demand, this paper proposes a
multi-level encryption scheme that is composed of lightweight encryption,
medium encryption and heavyweight encryption, where each encryption level can
obtain a different amount of visual information. It is found that both
encrypting the luma intraprediction model (IPM) and scrambling the syntax
element of the DCT coefficient sign can achieve the performance of a distorted
video in which there is still residual visual information, while encrypting
both of them can implement the intensity of encryption and one cannot gain any
visual information. The experimental results meet our expectations
appropriately, indicating that there is a different amount of visual
information in each encryption level. Meanwhile, users can flexibly choose the
encryption level according to their various requirements.
"
2955,"Learning to Respond with Your Favorite Stickers: A Framework of Unifying
  Multi-Modality and User Preference in Multi-Turn Dialog","  Stickers with vivid and engaging expressions are becoming increasingly
popular in online messaging apps, and some works are dedicated to automatically
select sticker response by matching the stickers image with previous
utterances. However, existing methods usually focus on measuring the matching
degree between the dialog context and sticker image, which ignores the user
preference of using stickers. Hence, in this paper, we propose to recommend an
appropriate sticker to user based on multi-turn dialog context and sticker
using history of user. Two main challenges are confronted in this task. One is
to model the sticker preference of user based on the previous sticker selection
history. Another challenge is to jointly fuse the user preference and the
matching between dialog context and candidate sticker into final prediction
making. To tackle these challenges, we propose a \emph{Preference Enhanced
Sticker Response Selector} (PESRS) model. Specifically, PESRS first employs a
convolutional based sticker image encoder and a self-attention based multi-turn
dialog encoder to obtain the representation of stickers and utterances. Next,
deep interaction network is proposed to conduct deep matching between the
sticker and each utterance. Then, we model the user preference by using the
recently selected stickers as input, and use a key-value memory network to
store the preference representation. PESRS then learns the short-term and
long-term dependency between all interaction results by a fusion network, and
dynamically fuse the user preference representation into the final sticker
selection prediction. Extensive experiments conducted on a large-scale
real-world dialog dataset show that our model achieves the state-of-the-art
performance for all commonly-used metrics. Experiments also verify the
effectiveness of each component of PESRS.
"
2956,Deep Cross-modal Proxy Hashing,"  Due to their high retrieval efficiency and low storage cost for cross-modal
search task, cross-modal hashing methods have attracted considerable attention.
For supervised cross-modal hashing methods, how to make the learned hash codes
preserve semantic structure information sufficiently is a key point to further
enhance the retrieval performance. As far as we know, almost all supervised
cross-modal hashing methods preserve semantic structure information depending
on at-least-one similarity definition fully or partly, i.e., it defines two
datapoints as similar ones if they share at least one common category otherwise
they are dissimilar. Obviously, the at-least-one similarity misses abundant
semantic structure information. To tackle this problem, in this paper, we
propose a novel Deep Cross-modal Proxy Hashing, called DCPH. Specifically, DCPH
first learns a proxy hashing network to generate a discriminative proxy hash
code for each category. Then, by utilizing the learned proxy hash code as
supervised information, a novel $Margin$-$SoftMax$-$like\ loss$ is proposed
without defining the at-least-one similarity between datapoints. By minimizing
the novel $Margin$-$SoftMax$-$like\ loss$, the learned hash codes will
simultaneously preserve the cross-modal similarity and abundant semantic
structure information well. Extensive experiments on two benchmark datasets
show that the proposed method outperforms the state-of-the-art baselines in
cross-modal retrieval task.
"
2957,"Unified Quality Assessment of In-the-Wild Videos with Mixed Datasets
  Training","  Video quality assessment (VQA) is an important problem in computer vision.
The videos in computer vision applications are usually captured in the wild. We
focus on automatically assessing the quality of in-the-wild videos, which is a
challenging problem due to the absence of reference videos, the complexity of
distortions, and the diversity of video contents. Moreover, the video contents
and distortions among existing datasets are quite different, which leads to
poor performance of data-driven methods in the cross-dataset evaluation
setting. To improve the performance of quality assessment models, we borrow
intuitions from human perception, specifically, content dependency and
temporal-memory effects of human visual system. To face the cross-dataset
evaluation challenge, we explore a mixed datasets training strategy for
training a single VQA model with multiple datasets. The proposed unified
framework explicitly includes three stages: relative quality assessor,
nonlinear mapping, and dataset-specific perceptual scale alignment, to jointly
predict relative quality, perceptual quality, and subjective quality.
Experiments are conducted on four publicly available datasets for VQA in the
wild, i.e., LIVE-VQC, LIVE-Qualcomm, KoNViD-1k, and CVD2014. The experimental
results verify the effectiveness of the mixed datasets training strategy and
prove the superior performance of the unified model in comparison with the
state-of-the-art models. For reproducible research, we make the PyTorch
implementation of our method available at https://github.com/lidq92/MDTVSFA.
"
2958,Multi-domain Reversible Data Hiding in JPEG,"  As a branch of reversible data hiding (RDH), reversible data hiding in JEPG
is particularly important. Because JPEG images are widely used, it is great
significance to study reversible data hiding algorithm for JEPG images. The
existing JEPG reversible data methods can be divided into two categories, one
is based on Discrete Cosine Transform (DCT) coefficients modification, the
other is based on Huffman table modification, the methods based on DCT
coefficient modification result in large file expansion and visual quality
distortion, while the methods based on entropy coding domain modification have
low capacity and they may lead to large file expansion. In order to effectively
solve the problems in these two kinds of methods, this paper proposes a
reversible data hiding in JPEG images methods based on multi-domain
modification. In this method, the secret data is divided into two parts by
payload distribution algorithm, part of the secret data is first embedded in
the DCT coefficient domain, and then the remaining secret data is embedded in
the entropy coding domain. Experimental results demonstrate that most JPEG
image files with this scheme have smaller file size increment and higher
payload than previous RDH schemes.
"
2959,Human-centric Spatio-Temporal Video Grounding With Visual Transformers,"  In this work, we introduce a novel task - Humancentric Spatio-Temporal Video
Grounding (HC-STVG). Unlike the existing referring expression tasks in images
or videos, by focusing on humans, HC-STVG aims to localize a spatiotemporal
tube of the target person from an untrimmed video based on a given textural
description. This task is useful, especially for healthcare and
security-related applications, where the surveillance videos can be extremely
long but only a specific person during a specific period of time is concerned.
HC-STVG is a video grounding task that requires both spatial (where) and
temporal (when) localization. Unfortunately, the existing grounding methods
cannot handle this task well. We tackle this task by proposing an effective
baseline method named Spatio-Temporal Grounding with Visual Transformers
(STGVT), which utilizes Visual Transformers to extract cross-modal
representations for video-sentence matching and temporal localization. To
facilitate this task, we also contribute an HC-STVG dataset consisting of 5,660
video-sentence pairs on complex multi-person scenes. Specifically, each video
lasts for 20 seconds, pairing with a natural query sentence with an average of
17.25 words. Extensive experiments are conducted on this dataset, demonstrating
the newly-proposed method outperforms the existing baseline methods.
"
2960,"OpenKinoAI: An Open Source Framework for Intelligent Cinematography and
  Editing of Live Performances","  OpenKinoAI is an open source framework for post-production of ultra high
definition video which makes it possible to emulate professional multiclip
editing techniques for the case of single camera recordings. OpenKinoAI
includes tools for uploading raw video footage of live performances on a remote
web server, detecting, tracking and recognizing the performers in the original
material, reframing the raw video into a large choice of cinematographic
rushes, editing the rushes into movies, and annotating rushes and movies for
documentation purposes. OpenKinoAI is made available to promote research in
multiclip video editing of ultra high definition video, and to allow performing
artists and companies to use this research for archiving, documenting and
sharing their work online in an innovative fashion.
"
2961,"Evoking Places from Spaces. The application of multimodal narrative
  techniques in the creation of ""U Modified""","  Multimodal diegetic narrative tools, as applied in multimedia arts practices,
possess the ability to cross the spaces that exist between the physical world
and the imaginary. Within this paper we present the findings of a
multidiscipline practice based research project that explored the potential of
an audiovisual art performance to purposefully interact with an audience's
perception of narrative place. To achieve this goal, research was undertaken to
investigate the function of multimodal diegetic practices as applied in the
context of a sonic art narrative. This project direction was undertaken to
facilitate the transformation of previous experiences of place through the
creative amalgamation and presentation of collected audio and visual footage
from real world spaces. Through the presentation of multimedia relating to
familiar geographical spatial features, the audience were affected to evoke
memories of place and to construct and manipulate their own narrative.
"
2962,Deep Sketch-Based Modeling: Tips and Tricks,"  Deep image-based modeling received lots of attention in recent years, yet the
parallel problem of sketch-based modeling has only been briefly studied, often
as a potential application. In this work, for the first time, we identify the
main differences between sketch and image inputs: (i) style variance, (ii)
imprecise perspective, and (iii) sparsity. We discuss why each of these
differences can pose a challenge, and even make a certain class of image-based
methods inapplicable. We study alternative solutions to address each of the
difference. By doing so, we drive out a few important insights: (i) sparsity
commonly results in an incorrect prediction of foreground versus background,
(ii) diversity of human styles, if not taken into account, can lead to very
poor generalization properties, and finally (iii) unless a dedicated sketching
interface is used, one can not expect sketches to match a perspective of a
fixed viewpoint. Finally, we compare a set of representative deep single-image
modeling solutions and show how their performance can be improved to tackle
sketch input by taking into consideration the identified critical differences.
"
2963,"Content-based Image Retrieval and the Semantic Gap in the Deep Learning
  Era","  Content-based image retrieval has seen astonishing progress over the past
decade, especially for the task of retrieving images of the same object that is
depicted in the query image. This scenario is called instance or object
retrieval and requires matching fine-grained visual patterns between images.
Semantics, however, do not play a crucial role. This brings rise to the
question: Do the recent advances in instance retrieval transfer to more generic
image retrieval scenarios? To answer this question, we first provide a brief
overview of the most relevant milestones of instance retrieval. We then apply
them to a semantic image retrieval task and find that they perform inferior to
much less sophisticated and more generic methods in a setting that requires
image understanding. Following this, we review existing approaches to closing
this so-called semantic gap by integrating prior world knowledge. We conclude
that the key problem for the further advancement of semantic image retrieval
lies in the lack of a standardized task definition and an appropriate benchmark
dataset.
"
2964,CNN-based driving of block partitioning for intra slices encoding,"  This paper provides a technical overview of a deep-learning-based encoder
method aiming at optimizing next generation hybrid video encoders for driving
the block partitioning in intra slices. An encoding approach based on
Convolutional Neural Networks is explored to partly substitute classical
heuristics-based encoder speed-ups by a systematic and automatic process. The
solution allows controlling the trade-off between complexity and coding gains,
in intra slices, with one single parameter. This algorithm was proposed at the
Call for Proposals of the Joint Video Exploration Team (JVET) on video
compression with capability beyond HEVC. In All Intra configuration, for a
given allowed topology of splits, a speed-up of $\times 2$ is obtained without
BD-rate loss, or a speed-up above $\times 4$ with a loss below 1\% in BD-rate.
"
2965,"iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video
  Captioning and Video Question Answering","  Most prior art in visual understanding relies solely on analyzing the ""what""
(e.g., event recognition) and ""where"" (e.g., event localization), which in some
cases, fails to describe correct contextual relationships between events or
leads to incorrect underlying visual attention. Part of what defines us as
human and fundamentally different from machines is our instinct to seek
causality behind any association, say an event Y that happened as a direct
result of event X. To this end, we propose iPerceive, a framework capable of
understanding the ""why"" between events in a video by building a common-sense
knowledge base using contextual cues to infer causal relationships between
objects in the video. We demonstrate the effectiveness of our technique using
the dense video captioning (DVC) and video question answering (VideoQA) tasks.
Furthermore, while most prior work in DVC and VideoQA relies solely on visual
information, other modalities such as audio and speech are vital for a human
observer's perception of an environment. We formulate DVC and VideoQA tasks as
machine translation problems that utilize multiple modalities. By evaluating
the performance of iPerceive DVC and iPerceive VideoQA on the ActivityNet
Captions and TVQA datasets respectively, we show that our approach furthers the
state-of-the-art. Code and samples are available at: iperceive.amanchadha.com.
"
2966,"Training Strategies and Data Augmentations in CNN-based DeepFake Video
  Detection","  The fast and continuous growth in number and quality of deepfake videos calls
for the development of reliable detection systems capable of automatically
warning users on social media and on the Internet about the potential
untruthfulness of such contents. While algorithms, software, and smartphone
apps are getting better every day in generating manipulated videos and swapping
faces, the accuracy of automated systems for face forgery detection in videos
is still quite limited and generally biased toward the dataset used to design
and train a specific detection system. In this paper we analyze how different
training strategies and data augmentation techniques affect CNN-based deepfake
detectors when training and testing on the same dataset or across different
datasets.
"
2967,An End-to-end Method for Producing Scanning-robust Stylized QR Codes,"  Quick Response (QR) code is one of the most worldwide used two-dimensional
codes.~Traditional QR codes appear as random collections of black-and-white
modules that lack visual semantics and aesthetic elements, which inspires the
recent works to beautify the appearances of QR codes. However, these works
adopt fixed generation algorithms and therefore can only generate QR codes with
a pre-defined style. In this paper, combining the Neural Style Transfer
technique, we propose a novel end-to-end method, named ArtCoder, to generate
the stylized QR codes that are personalized, diverse, attractive, and
scanning-robust.~To guarantee that the generated stylized QR codes are still
scanning-robust, we propose a Sampling-Simulation layer, a module-based code
loss, and a competition mechanism. The experimental results show that our
stylized QR codes have high-quality in both the visual effect and the
scanning-robustness, and they are able to support the real-world application.
"
2968,"Building Movie Map -- A Tool for Exploring Areas in a City -- and its
  Evaluation","  We propose a new Movie Map system, with an interface for exploring cities.
The system consists of four stages; acquisition, analysis, management, and
interaction. In the acquisition stage, omnidirectional videos are taken along
streets in target areas. Frames of the video are localized on the map,
intersections are detected, and videos are segmented. Turning views at
intersections are subsequently generated. By connecting the video segments
following the specified movement in an area, we can view the streets better.
The interface allows for easy exploration of a target area, and it can show
virtual billboards of stores in the view. We conducted user studies to compare
our system to the GSV in a scenario where users could freely move and explore
to find a landmark. The experiment showed that our system had a better user
experience than GSV.
"
2969,"Empowering Things with Intelligence: A Survey of the Progress,
  Challenges, and Opportunities in Artificial Intelligence of Things","  In the Internet of Things (IoT) era, billions of sensors and devices collect
and process data from the environment, transmit them to cloud centers, and
receive feedback via the internet for connectivity and perception. However,
transmitting massive amounts of heterogeneous data, perceiving complex
environments from these data, and then making smart decisions in a timely
manner are difficult. Artificial intelligence (AI), especially deep learning,
is now a proven success in various areas including computer vision, speech
recognition, and natural language processing. AI introduced into the IoT
heralds the era of artificial intelligence of things (AIoT). This paper
presents a comprehensive survey on AIoT to show how AI can empower the IoT to
make it faster, smarter, greener, and safer. Specifically, we briefly present
the AIoT architecture in the context of cloud computing, fog computing, and
edge computing. Then, we present progress in AI research for IoT from four
perspectives: perceiving, learning, reasoning, and behaving. Next, we summarize
some promising applications of AIoT that are likely to profoundly reshape our
world. Finally, we highlight the challenges facing AIoT and some potential
research opportunities.
"
2970,"A Block-Permutation-Based Encryption Scheme with Independent Processing
  of RGB Components","  This paper proposes a block-permutation-based encryption (BPBE) scheme for
the encryption-then-compression (ETC) system that enhances the color
scrambling. A BPBE image can be obtained through four processes, positional
scrambling, block rotation/flip, negative-positive transformation, and color
component shuffling, after dividing the original image into multiple blocks.
The proposed scheme scrambles the R, G, and B components independently in
positional scrambling, block rotation/flip, and negative-positive
transformation, by assigning different keys to each color component. The
conventional scheme considers the compression efficiency using JPEG and JPEG
2000, which need a color conversion before the compression process by default.
Therefore, the conventional scheme scrambles the color components identically
in each process. In contrast, the proposed scheme takes into account the
RGB-based compression, such as JPEG-LS, and thus can increase the extent of the
scrambling. The resilience against jigsaw puzzle solver (JPS) can consequently
be increased owing to the wider color distribution of the BPBE image.
Additionally, the key space for resilience against brute-force attacks has also
been expanded exponentially. Furthermore, the proposed scheme can maintain the
JPEG-LS compression efficiency compared to the conventional scheme. We confirm
the effectiveness of the proposed scheme by experiments and analyses.
"
2971,"Vertical-Horizontal Structured Attention for Generating Music with
  Chords","  In this paper, we propose a lightweight music-generating model based on
variational autoencoder (VAE) with structured attention. Generating music is
different from generating text because the melodies with chords give listeners
distinguished polyphonic feelings. In a piece of music, a chord consisting of
multiple notes comes from either the mixture of multiple instruments or the
combination of multiple keys of a single instrument. We focus our study on the
latter. Our model captures not only the temporal relations along time but the
structure relations between keys. Experimental results show that our model has
a better performance than baseline MusicVAE in capturing notes in a chord.
Besides, our method accords with music theory since it maintains the
configuration of the circle of fifths, distinguishes major and minor keys from
interval vectors, and manifests meaningful structures between music phrases.
"
2972,Three Patterns to Support Empathy in Computer-Mediated Human Interaction,"  We present three patterns for computer-mediated interaction which we
discovered during the design and development of a platform for remote teaching
and learning of kanji, the Chinese characters used in written Japanese. Our aim
in developing this system was to provide a basis for embodiment in remote
interaction, and in particular to support the experience of empathy by both
teacher and student. From this study, the essential elements are abstracted and
suggested as design patterns for other computer-mediated interaction systems.
"
2973,Modeling Fashion Influence from Photos,"  The evolution of clothing styles and their migration across the world is
intriguing, yet difficult to describe quantitatively. We propose to discover
and quantify fashion influences from catalog and social media photos. We
explore fashion influence along two channels: geolocation and fashion brands.
We introduce an approach that detects which of these entities influence which
other entities in terms of propagating their styles. We then leverage the
discovered influence patterns to inform a novel forecasting model that predicts
the future popularity of any given style within any given city or brand. To
demonstrate our idea, we leverage public large-scale datasets of 7.7M Instagram
photos from 44 major world cities (where styles are worn with variable
frequency) as well as 41K Amazon product photos (where styles are purchased
with variable frequency). Our model learns directly from the image data how
styles move between locations and how certain brands affect each other's
designs in a predictable way. The discovered influence relationships reveal how
both cities and brands exert and receive fashion influence for an array of
visual styles inferred from the images. Furthermore, the proposed forecasting
model achieves state-of-the-art results for challenging style forecasting
tasks. Our results indicate the advantage of grounding visual style evolution
both spatially and temporally, and for the first time, they quantify the
propagation of inter-brand and inter-city influences.
"
2974,Stochastic Model Checking for Multimedia,"  Modern distributed systems include a class of applications in which
non-functional requirements are important. In particular, these applications
include multimedia facilities where real time constraints are crucial to their
correct functioning. In order to specify such systems it is necessary to
describe that events occur at times given by probability distributions and
stochastic automata have emerged as a useful technique by which such systems
can be specified and verified.
  However, stochastic descriptions are very general, in particular they allow
the use of general probability distribution functions, and therefore their
verification can be complex. In the last few years, model checking has emerged
as a useful verification tool for large systems.
  In this paper we describe two model checking algorithms for stochastic
automata. These algorithms consider how properties written in a simple
probabilistic real-time logic can be checked against a given stochastic
automaton.
"
2975,Data sonification and sound visualization,"  This article describes a collaborative project between researchers in the
Mathematics and Computer Science Division at Argonne National Laboratory and
the Computer Music Project of the University of Illinois at Urbana-Champaign.
The project focuses on the use of sound for the exploration and analysis of
complex data sets in scientific computing. The article addresses digital sound
synthesis in the context of DIASS (Digital Instrument for Additive Sound
Synthesis) and sound visualization in a virtual-reality environment by means of
M4CAVE. It describes the procedures and preliminary results of some experiments
in scientific sonification and sound visualization.
"
2976,"A Benchmark for Image Retrieval using Distributed Systems over the
  Internet: BIRDS-I","  The performance of CBIR algorithms is usually measured on an isolated
workstation. In a real-world environment the algorithms would only constitute a
minor component among the many interacting components. The Internet
dramati-cally changes many of the usual assumptions about measuring CBIR
performance. Any CBIR benchmark should be designed from a networked systems
standpoint. These benchmarks typically introduce communication overhead because
the real systems they model are distributed applications. We present our
implementation of a client/server benchmark called BIRDS-I to measure image
retrieval performance over the Internet. It has been designed with the trend
toward the use of small personalized wireless systems in mind. Web-based CBIR
implies the use of heteroge-neous image sets, imposing certain constraints on
how the images are organized and the type of performance metrics applicable.
BIRDS-I only requires controlled human intervention for the compilation of the
image collection and none for the generation of ground truth in the measurement
of retrieval accuracy. Benchmark image collections need to be evolved
incrementally toward the storage of millions of images and that scaleup can
only be achieved through the use of computer-aided compilation. Finally, our
scoring metric introduces a tightly optimized image-ranking window.
"
2977,Open Access beyond cable: The case of Interactive TV,"  In this paper we analyze the development of interactive TV in the U.S. and
Western Europe. We argue that despite the nascent character of the market there
are important regulatory issues at stake, as exemplified by the AOL/TW merger
and the British Interactive Broadcasting case. Absent rules that provide for
non-discriminatory access to network components (including terminal equipment
specifications), dominant platform operators are likely to leverage ownership
of delivery infrastructure into market power over interactive TV services.
While integration between platform operator, service provider and terminal
vendor may facilitate the introduction of services in the short-term, the
lasting result will be a collection of fragmented ""walled gardens"" offering
limited content and applications. Would interactive TV develop under such
model, the exciting opportunities for broad-based innovation and extended
access to multiple information, entertainment and educational services opened
by the new generation of broadcasting technologies will be foregone
"
2978,Media Objects in Time - A Multimedia Streaming System,"  The widespread availability of networked multimedia potentials embedded in an
infrastructure of qualitative superior kind gives rise to new approaches in the
areas of teleteaching and internet presentation: The distribution of
professionally styled multimedia streams has fallen in the realm of
possibility. This paper presents a prototype - both model and runtime
environment - of a time directed media system treating any kind of
presentational contribution as reusable media object components. The plug-in
free runtime system is based on a database and allows for a flexible support of
static media types as well as for easy extensions by streaming media servers.
The prototypic implementation includes a preliminary Web Authoring platform.
"
2979,"Reconciling MPEG-7 and MPEG-21 Semantics through a Common Event-Aware
  Metadata Model","  The ""event"" concept appears repeatedly when developing metadata models for
the description and management of multimedia content. During the typical life
cycle of multimedia content, events occur at many different levels - from the
events which happen during content creation (directing, acting, camera panning
and zooming) to the events which happen to the physical form (acquisition,
relocation, damage of film or video) to the digital conversion, reformatting,
editing and repackaging events, to the events which are depicted in the actual
content (political, news, sporting) to the usage, ownership and copyright
agreement events and even the metadata attribution events. Support is required
within both MPEG-7 and MPEG-21 for the clear and unambiguous description of all
of these event types which may occur at widely different levels of nesting and
granularity. In this paper we first describe an event-aware model (the ABC
model) which is capable of modeling and yet clearly differentiating between all
of these, often recursive and overlapping events. We then illustrate how this
model can be used as the foundation to facilitate semantic interoperability
between MPEG-7 and MPEG-21. By expressing the semantics of both MPEG-7 and
MPEG-21 metadata terms in RDF Schema (and some DAML+OIL extensions) and
attaching the MPEG-7 and MPEG-21 class and property hierarchies to the
appropriate top-level classes and properties of the ABC model, we are
essentially able to define a single distributed machine-understandable
ontology, which will enable interoperability of data and services across the
entire multimedia content delivery chain.
"
2980,Global Platform for Rich Media Conferencing and Collaboration,"  The Virtual Rooms Videoconferencing Service (VRVS) provides a worldwide
videoconferencing service and collaborative environment to the research and
education communities. This system provides a low cost, bandwidth-efficient,
extensible means for videoconferencing and remote collaboration over networks
within the High Energy and Nuclear Physics communities (HENP). VRVS has become
a standard part of the toolset used daily by a large sector of HENP, and it is
used increasingly for other DoE/NSF-supported programs. The current features
included multi-protocol, multi-OS support for all significant video enabled
clients including: H.323, Mbone, QuickTime, MPEG2, Java Media Framework, and
other clients. The current architecture makes VRVS a distributed, highly
functional, and efficient software-only system for multipoint audio, video and
web conferencing and collaboration over global IP networks. VRVS has developed
the VRVS-AG Reflector and a specialized Web interface that enables end users to
connect to any Access Grid (AG) session, in any of the AG ""virtual venues"" from
anywhere worldwide. The VRVS system has now been running for the last five and
half years, offering to the HENP community a working and reliable tool for
collaboration within groups and among physicists dispersed world-wide. The goal
of this ongoing effort is to develop the next generation collaborative systems
running over next generation networks. The new developments area integrate
emerging standards, include all security aspects, and will extend the range of
VRVS video technologies supported to cover the latest high end standards
quality. We will focus the discussion on the new capability provides by the
latest version V3.0 and its future evolution.
"
2981,A Flexible Pragmatics-driven Language Generator for Animated Agents,"  This paper describes the NECA MNLG; a fully implemented Multimodal Natural
Language Generation module. The MNLG is deployed as part of the NECA system
which generates dialogues between animated agents. The generation module
supports the seamless integration of full grammar rules, templates and canned
text. The generator takes input which allows for the specification of
syntactic, semantic and pragmatic constraints on the output.
"
2982,"Analysis and Visualization of Index Words from Audio Transcripts of
  Instructional Videos","  We introduce new techniques for extracting, analyzing, and visualizing
textual contents from instructional videos of low production quality. Using
Automatic Speech Recognition, approximate transcripts (H75% Word Error Rate)
are obtained from the originally highly compressed videos of university
courses, each comprising between 10 to 30 lectures. Text material in the form
of books or papers that accompany the course are then used to filter meaningful
phrases from the seemingly incoherent transcripts. The resulting index into the
transcripts is tied together and visualized in 3 experimental graphs that help
in understanding the overall course structure and provide a tool for localizing
certain topics for indexing. We specifically discuss a Transcript Index Map,
which graphically lays out key phrases for a course, a Textbook Chapter to
Transcript Match, and finally a Lecture Transcript Similarity graph, which
clusters semantically similar lectures. We test our methods and tools on 7 full
courses with 230 hours of video and 273 transcripts. We are able to extract up
to 98 unique key terms for a given transcript and up to 347 unique key terms
for an entire course. The accuracy of the Textbook Chapter to Transcript Match
exceeds 70% on average. The methods used can be applied to genres of video in
which there are recurrent thematic words (news, sports, meetings,...)
"
2983,From Digital Television to Internet?,"  This paper provides a general technical overview of the Multimedia Home
Platform (MHP) specifications. MHP is a generic interface between digital
applications and user machines, whether they happen to be set top boxes,
digital TV sets or Multimedia PC's. MHP extends the DVB open standards.
Addressed are MHP architexture, System core and MHP Profiles.
"
2984,"RRL: A Rich Representation Language for the Description of Agent
  Behaviour in NECA","  In this paper, we describe the Rich Representation Language (RRL) which is
used in the NECA system. The NECA system generates interactions between two or
more animated characters. The RRL is an XML compliant framework for
representing the information that is exchanged at the interfaces between the
various NECA system modules. The full XML Schemas for the RRL are available at
http://www.ai.univie.ac.at/NECA/RRL
"
2985,An Analysis of the Skype Peer-to-Peer Internet Telephony Protocol,"  Skype is a peer-to-peer VoIP client developed by KaZaa in 2003. Skype claims
that it can work almost seamlessly across NATs and firewalls and has better
voice quality than the MSN and Yahoo IM applications. It encrypts calls
end-to-end, and stores user information in a decentralized fashion. Skype also
supports instant messaging and conferencing. This report analyzes key Skype
functions such as login, NAT and firewall traversal, call establishment, media
transfer, codecs, and conferencing under three different network setups.
Analysis is performed by careful study of Skype network traffic.
"
2986,"Self-Organizing the Abstract: Canvas as a Swarm Habitat for Collective
  Memory, Perception and Cooperative Distributed Creativity","  Past experiences under the designation of ""Swarm Paintings"" conducted in
2001, not only confirmed the possibility of realizing an artificial art (thus
non-human), as introduced into the process the questioning of creative
migration, specifically from the computer monitors to the canvas via a robotic
harm. In more recent self-organized based research we seek to develop and
profound the initial ideas by using a swarm of autonomous robots (ARTsBOT
project 2002-03), that ""live"" avoiding the purpose of being merely a simple
perpetrator of order streams coming from an external computer, but instead,
that actually co-evolve within the canvas space, acting (that is, laying ink)
according to simple inner threshold stimulus response functions, reacting
simultaneously to the chromatic stimulus present in the canvas environment done
by the passage of their team-mates, as well as by the distributed feedback,
affecting their future collective behaviour. In parallel, and in what respects
to certain types of collective systems, we seek to confirm, in a physically
embedded way, that the emergence of order (even as a concept) seems to be found
at a lower level of complexity, based on simple and basic interchange of
information, and on the local dynamic of parts, who, by self-organizing
mechanisms tend to form an lived whole, innovative and adapting, allowing for
emergent open-ended creative and distributed production. KEYWORDS: ArtSBots
Project, Swarm Intelligence, Stigmergy, UnManned Art, Symbiotic Art, Swarm
Paintings, Robot Paintings, Non-Human Art, Painting Emergence and Cooperation,
Art and Complexity, ArtBots: The Robot Talent Show.
"
2987,"On the Implicit and on the Artificial - Morphogenesis and Emergent
  Aesthetics in Autonomous Collective Systems","  Imagine a ""machine"" where there is no pre-commitment to any particular
representational scheme: the desired behaviour is distributed and roughly
specified simultaneously among many parts, but there is minimal specification
of the mechanism required to generate that behaviour, i.e. the global behaviour
evolves from the many relations of multiple simple behaviours. A machine that
lives to and from/with Synergy. An artificial super-organism that avoids
specific constraints and emerges within multiple low-level implicit
bio-inspired mechanisms. KEYWORDS: Complex Science, ArtSBots Project, Swarm
Intelligence, Stigmergy, UnManned Art, Symbiotic Art, Swarm Paintings, Robot
Paintings, Non-Human Art, Painting Emergence and Cooperation, Art and
Complexity, ArtBots: The Robot Talent Show.
"
2988,"The MC2 Project [Machines of Collective Conscience]: A possible walk, up
  to Life-like Complexity and Behaviour, from bottom, basic and simple
  bio-inspired heuristics - a walk, up into the morphogenesis of information","  Synergy (from the Greek word synergos), broadly defined, refers to combined
or co-operative effects produced by two or more elements (parts or
individuals). The definition is often associated with the holistic conviction
quote that ""the whole is greater than the sum of its parts"" (Aristotle, in
Metaphysics), or the whole cannot exceed the sum of the energies invested in
each of its parts (e.g. first law of thermodynamics) even if it is more
accurate to say that the functional effects produced by wholes are different
from what the parts can produce alone. Synergy is a ubiquitous phenomena in
nature and human societies alike. One well know example is provided by the
emergence of self-organization in social insects, via direct or indirect
interactions. The latter types are more subtle and defined as stigmergy to
explain task coordination and regulation in the context of nest reconstruction
in termites. An example, could be provided by two individuals, who interact
indirectly when one of them modifies the environment and the other responds to
the new environment at a later time. In other words, stigmergy could be defined
as a particular case of environmental or spatial synergy. The system is purely
holistic, and their properties are intrinsically emergent and autocatalytic. On
the present work we present a ""machine"" where there is no precommitment to any
particular representational scheme: the desired behaviour is distributed and
roughly specified simultaneously among many parts, but there is minimal
specification of the mechanism required to generate that behaviour, i.e. the
global behaviour evolves from the many relations of multiple simple behaviours.
"
2989,Fedora: An Architecture for Complex Objects and their Relationships,"  The Fedora architecture is an extensible framework for the storage,
management, and dissemination of complex objects and the relationships among
them. Fedora accommodates the aggregation of local and distributed content into
digital objects and the association of services with objects. This al-lows an
object to have several accessible representations, some of them dy-namically
produced. The architecture includes a generic RDF-based relation-ship model
that represents relationships among objects and their components. Queries
against these relationships are supported by an RDF triple store. The
architecture is implemented as a web service, with all aspects of the complex
object architecture and related management functions exposed through REST and
SOAP interfaces. The implementation is available as open-source soft-ware,
providing the foundation for a variety of end-user applications for digital
libraries, archives, institutional repositories, and learning object systems.
"
2990,"On the security of the Yen-Guo's domino signal encryption algorithm
  (DSEA)","  Recently, a new domino signal encryption algorithm (DSEA) was proposed for
digital signal transmission, especially for digital images and videos. This
paper analyzes the security of DSEA, and points out the following weaknesses:
1) its security against the brute-force attack was overestimated; 2) it is not
sufficiently secure against ciphertext-only attacks, and only one ciphertext is
enough to get some information about the plaintext and to break the value of a
sub-key; 3) it is insecure against known/chosen-plaintext attacks, in the sense
that the secret key can be recovered from a number of continuous bytes of only
one known/chosen plaintext and the corresponding ciphertext. Experimental
results are given to show the performance of the proposed attacks, and some
countermeasures are discussed to improve DSEA.
"
2991,On the Design of Perceptual MPEG-Video Encryption Algorithms,"  In this paper, some existing perceptual encryption algorithms of MPEG videos
are reviewed and some problems, especially security defects of two recently
proposed MPEG-video perceptual encryption schemes, are pointed out. Then, a
simpler and more effective design is suggested, which selectively encrypts
fixed-length codewords (FLC) in MPEG-video bitstreams under the control of
three perceptibility factors. The proposed design is actually an encryption
configuration that can work with any stream cipher or block cipher. Compared
with the previously-proposed schemes, the new design provides more useful
features, such as strict size-preservation, on-the-fly encryption and multiple
perceptibility, which make it possible to support more applications with
different requirements. In addition, four different measures are suggested to
provide better security against known/chosen-plaintext attacks.
"
2992,Augmented Segmentation and Visualization for Presentation Videos,"  We investigate methods of segmenting, visualizing, and indexing presentation
videos by separately considering audio and visual data. The audio track is
segmented by speaker, and augmented with key phrases which are extracted using
an Automatic Speech Recognizer (ASR). The video track is segmented by visual
dissimilarities and augmented by representative key frames. An interactive user
interface combines a visual representation of audio, video, text, and key
frames, and allows the user to navigate a presentation video. We also explore
clustering and labeling of speaker data and present preliminary results.
"
2993,Authentication with Distortion Criteria,"  In a variety of applications, there is a need to authenticate content that
has experienced legitimate editing in addition to potential tampering attacks.
We develop one formulation of this problem based on a strict notion of
security, and characterize and interpret the associated information-theoretic
performance limits. The results can be viewed as a natural generalization of
classical approaches to traditional authentication. Additional insights into
the structure of such systems and their behavior are obtained by further
specializing the results to Bernoulli and Gaussian cases. The associated
systems are shown to be substantially better in terms of performance and/or
security than commonly advocated approaches based on data hiding and digital
watermarking. Finally, the formulation is extended to obtain efficient layered
authentication system constructions.
"
2994,A hybrid MLP-PNN architecture for fast image superresolution,"  Image superresolution methods process an input image sequence of a scene to
obtain a still image with increased resolution. Classical approaches to this
problem involve complex iterative minimization procedures, typically with high
computational costs. In this paper is proposed a novel algorithm for
super-resolution that enables a substantial decrease in computer load. First, a
probabilistic neural network architecture is used to perform a scattered-point
interpolation of the image sequence data. The network kernel function is
optimally determined for this problem by a multi-layer perceptron trained on
synthetic data. Network parameters dependence on sequence noise level is
quantitatively analyzed. This super-sampled image is spatially filtered to
correct finite pixel size effects, to yield the final high-resolution estimate.
Results on a real outdoor sequence are presented, showing the quality of the
proposed method.
"
2995,"Semi-automatic vectorization of linear networks on rasterized
  cartographic maps","  A system for semi-automatic vectorization of linear networks (roads, rivers,
etc.) on rasterized cartographic maps is presented. In this system, human
intervention is limited to a graphic, interactive selection of the color
attributes of the information to be obtained. Using this data, the system
performs a preliminary extraction of the linear network, which is subsequently
completed, refined and vectorized by means of an automatic procedure. Results
on maps of different sources and scales are included.
  -----
  Se presenta un sistema semi-automatico de vectorizacion de redes de objetos
lineales (carreteras, rios, etc.) en mapas cartograficos digitalizados. En este
sistema, la intervencion humana queda reducida a la seleccion grafica
interactiva de los atributos de color de la informacion a obtener. Con estos
datos, el sistema realiza una extraccion preliminar de la red lineal, que se
completa, refina y vectoriza mediante un procedimiento automatico. Se presentan
resultados de la aplicacion del sistema sobre imagenes digitalizadas de mapas
de distinta procedencia y escala.
"
2996,Wikis in Tuple Spaces,"  We consider storing the pages of a wiki in a tuple space and the effects this
might have on the wiki experience. In particular, wiki pages are stored in
tuples with a few identifying values such as title, author, revision date,
content, etc. and pages are retrieved by sending the tuple space templates,
such as one that gives the title but nothing else, leaving the tuple space to
resolve to a single tuple. We use a tuple space wiki to avoid deadlocks,
infinite loops, and wasted efforts when page edit contention arises and examine
how a tuple space wiki changes the wiki experience.
"
2997,"A Distributed Multimedia Communication System and its Applications to
  E-Learning","  In this paper we report on a multimedia communication system including a
VCoIP (Video Conferencing over IP) software with a distributed architecture and
its applications for teaching scenarios. It is a simple, ready-to-use scheme
for distributed presenting, recording and streaming multimedia content. We also
introduce and investigate concepts and experiments to IPv6 user and session
mobility, with the special focus on real-time video group communication.
"
2998,Data Visualization on Shared Usage Multi-Screen Environment,"  The modern multimedia technologies based on the whole palette of hardware and
software facilities of real-time high-speed information processing, in a
combination with effective facilities of the remote access to information
resources, allow us to visualize diverse types of information. Data
visualization facilities &#8211; is the face of the Automated Control System on
whom often judge about their efficiency. They take a special place, providing
visualization of the diverse information necessary for decision-making by a
final control link - the person allocated by certain powers.
"
2999,"Alternative security architecture for IP Telephony based on digital
  watermarking","  Problems with securing IP Telephony systems, insufficient standardization and
lack of security mechanisms emerged the need for new approaches and solutions.
In this paper a new, alternative security architecture for voice-systems is
presented. It is based on digital watermarking: a new, flexible and powerful
technology that is increasingly gaining more and more attention. Besides known
applications e.g. to solve copyright protection problems, we propose to use
digital watermarking to secure not only transmitted audio but also signaling
protocol that IP Telephony is based on.
"
3000,"Can Small Museums Develop Compelling, Educational and Accessible Web
  Resources? The Case of Accademia Carrara","  Due to the lack of budget, competence, personnel and time, small museums are
often unable to develop compelling, educational and accessible web resources
for their permanent collections or temporary exhibitions. In an attempt to
prove that investing in these types of resources can be very fruitful even for
small institutions, we will illustrate the case of Accademia Carrara, a museum
in Bergamo, northern Italy, which, for a current temporary exhibition on
Cezanne and Renoir's masterpieces from the Paul Guillaume collection, developed
a series of multimedia applications, including an accessible website, rich in
content and educational material [www.cezannerenoir.it].
"
3001,"Cryptanalysis of an MPEG-Video Encryption Scheme Based on Secret Huffman
  Tables","  This paper studies the security of a recently-proposed MPEG-video encryption
scheme based on secret Huffman tables. Our cryptanalysis shows that: 1) the key
space of the encryption scheme is not sufficiently large against
divide-and-conquer (DAC) attack and known-plaintext attack; 2) it is possible
to decrypt a cipher-video with a partially-known key, thus dramatically
reducing the complexity of the DAC brute-force attack in some cases; 3) its
security against the chosen-plaintext attack is very weak. Some experimental
results are included to support the cryptanalytic results with a brief discuss
on how to improve this MPEG-video encryption scheme.
"
3002,Security Problems with Improper Implementations of Improved FEA-M,"  This paper reports security problems with improper implementations of an
improved version of FEA-M (fast encryption algorithm for multimedia). It is
found that an implementation-dependent differential chosen-plaintext attack or
its chosen-ciphertext counterpart can reveal the secret key of the
cryptosystem, if the involved (pseudo-)random process can be tampered (for
example, through a public time service). The implementation-dependent
differential attack is very efficient in complexity and needs only $O(n^2)$
chosen plaintext or ciphertext bits. In addition, this paper also points out a
minor security problem with the selection of the session key. In real
implementations of the cryptosystem, these security problems should be
carefully avoided, or the cryptosystem has to be further enhanced to work under
such weak implementations.
"
3003,"New security and control protocol for VoIP based on steganography and
  digital watermarking","  In this paper new security and control protocol for Voice over Internet
Protocol (VoIP) service is presented. It is the alternative for the IETF's
(Internet Engineering Task Force) RTCP (Real-Time Control Protocol) for
real-time application's traffic. Additionally this solution offers
authentication and integrity, it is capable of exchanging and verifying QoS and
security parameters. It is based on digital watermarking and steganography that
is why it does not consume additional bandwidth and the data transmitted is
inseparably bound to the voice content.
"
3004,Digital watermarking in the singular vector domain,"  Many current watermarking algorithms insert data in the spatial or transform
domains like the discrete cosine, the discrete Fourier, and the discrete
wavelet transforms. In this paper, we present a data-hiding algorithm that
exploits the singular value decomposition (SVD) representation of the data. We
compute the SVD of the host image and the watermark and embed the watermark in
the singular vectors of the host image. The proposed method leads to an
imperceptible scheme for digital images, both in grey scale and color and is
quite robust against attacks like noise and JPEG compression.
"
3005,"A Hybrid Quantum Encoding Algorithm of Vector Quantization for Image
  Compression","  Many classical encoding algorithms of Vector Quantization (VQ) of image
compression that can obtain global optimal solution have computational
complexity O(N). A pure quantum VQ encoding algorithm with probability of
success near 100% has been proposed, that performs operations 45sqrt(N) times
approximately. In this paper, a hybrid quantum VQ encoding algorithm between
classical method and quantum algorithm is presented. The number of its
operations is less than sqrt(N) for most images, and it is more efficient than
the pure quantum algorithm.
  Key Words: Vector Quantization, Grover's Algorithm, Image Compression,
Quantum Algorithm
"
3006,A constructive and unifying framework for zero-bit watermarking,"  In the watermark detection scenario, also known as zero-bit watermarking, a
watermark, carrying no hidden message, is inserted in content. The watermark
detector checks for the presence of this particular weak signal in content. The
article looks at this problem from a classical detection theory point of view,
but with side information enabled at the embedding side. This means that the
watermark signal is a function of the host content. Our study is twofold. The
first step is to design the best embedding function for a given detection
function, and the best detection function for a given embedding function. This
yields two conditions, which are mixed into one `fundamental' partial
differential equation. It appears that many famous watermarking schemes are
indeed solution to this `fundamental' equation. This study thus gives birth to
a constructive framework unifying solutions, so far perceived as very
different.
"
3007,"Fault-Tolerant Real-Time Streaming with FEC thanks to Capillary
  Multi-Path Routing","  Erasure resilient FEC codes in off-line packetized streaming rely on time
diversity. This requires unrestricted buffering time at the receiver. In
real-time streaming the playback buffering time must be very short. Path
diversity is an orthogonal strategy. However, the large number of long paths
increases the number of underlying links and consecutively the overall link
failure rate. This may increase the overall requirement in redundant FEC
packets for combating the link failures. We introduce the Redundancy Overall
Requirement (ROR) metric, a routing coefficient specifying the total number of
FEC packets required for compensation of all underlying link failures. We
present a capillary routing algorithm for constructing layer by layer steadily
diversifying multi-path routing patterns. By measuring the ROR coefficients of
a dozen of routing layers on hundreds of network samples, we show that the
number of required FEC packets decreases substantially when the path diversity
is increased by the capillary routing construction algorithm.
"
3008,"Un filtre temporel cr\'edibiliste pour la reconnaissance d'actions
  humaines dans les vid\'eos","  In the context of human action recognition in video sequences, a temporal
belief filter is presented. It allows to cope with human action disparity and
low quality videos. The whole system of action recognition is based on the
Transferable Belief Model (TBM) proposed by P. Smets. The TBM allows to
explicitly model the doubt between actions. Furthermore, the TBM emphasizes the
conflict which is exploited for action recognition. The filtering performance
is assessed on real video sequences acquired by a moving camera and under
several unknown view angles.
"
3009,Cryptanalysis of an Encryption Scheme Based on Blind Source Separation,"  Recently Lin et al. proposed a method of using the underdetermined BSS (blind
source separation) problem to realize image and speech encryption. In this
paper, we give a cryptanalysis of this BSS-based encryption and point out that
it is not secure against known/chosen-plaintext attack and chosen-ciphertext
attack. In addition, there exist some other security defects: low sensitivity
to part of the key and the plaintext, a ciphertext-only differential attack,
divide-and-conquer (DAC) attack on part of the key. We also discuss the role of
BSS in Lin et al.'s efforts towards cryptographically secure ciphers.
"
3010,Security Analysis of A Chaos-based Image Encryption Algorithm,"  The security of Fridrich Image Encryption Algorithm against brute-force
attack, statistical attack, known-plaintext attack and select-plaintext attack
is analyzed by investigating the properties of the involved chaotic maps and
diffusion functions. Based on the given analyses, some means are proposed to
strengthen the overall performance of the focused cryptosystem.
"
3011,"A Fast Block Matching Algorithm for Video Motion Estimation Based on
  Particle Swarm Optimization and Motion Prejudgment","  In this paper, we propose a fast 2-D block-based motion estimation algorithm
called Particle Swarm Optimization - Zero-motion Prejudgment(PSO-ZMP) which
consists of three sequential routines: 1)Zero-motion prejudgment. The routine
aims at finding static macroblocks(MB) which do not need to perform remaining
search thus reduces the computational cost; 2)Predictive image coding and 3)PSO
matching routine. Simulation results obtained show that the proposed PSO-ZMP
algorithm achieves over 10 times of computation less than Diamond Search(DS)
and 5 times less than the recent proposed Adaptive Rood Pattern
Searching(ARPS). Meanwhile the PSNR performances using PSO-ZMP are very close
to that using DS and ARPS in some less-motioned sequences. While in some
sequences containing dense and complex motion contents, the PSNR performances
of PSO-ZMP are several dB lower than that using DS and ARPS but in an
acceptable degree.
"
3012,A Fast Image Encryption Scheme based on Chaotic Standard Map,"  In recent years, a variety of effective chaos-based image encryption schemes
have been proposed. The typical structure of these schemes has the permutation
and the diffusion stages performed alternatively. The confusion and diffusion
effect is solely contributed by the permutation and the diffusion stage,
respectively. As a result, more overall rounds than necessary are required to
achieve a certain level of security. In this paper, we suggest to introduce
certain diffusion effect in the confusion stage by simple sequential
add-and-shift operations. The purpose is to reduce the workload of the
time-consuming diffusion part so that fewer overall rounds and hence a shorter
encryption time is needed. Simulation results show that at a similar
performance level, the proposed cryptosystem needs less than one-third the
encryption time of an existing cryptosystem. The effective acceleration of the
encryption speed is thus achieved.
"
3013,P2P IPTV Measurement: A Comparison Study,"  With the success of P2P file sharing, new emerging P2P applications arise on
the Internet for streaming content like voice (VoIP) or live video (IPTV).
Nowadays, there are lots of works measuring P2P file sharing or P2P telephony
systems, but there is still no comprehensive study about P2P IPTV, whereas it
should be massively used in the future. During the last FIFA world cup, we
measured network traffic generated by P2P IPTV applications like PPlive,
PPstream, TVants and Sopcast. In this paper we analyze some of our results
during the same games for the applications. We focus on traffic statistics and
churn of peers within these P2P networks. Our objectives are threefold: we
point out the traffic generated to understand the impact they will have on the
network, we try to infer the mechanisms of such applications and highlight
differences, and we give some insights about the users' behavior.
"
3014,Lightweight security mechanism for PSTN-VoIP cooperation,"  In this paper we describe a new, lightweight security mechanism for PSTN-VoIP
cooperation that is based on two information hiding techniques: digital
watermarking and steganography. Proposed scheme is especially suitable for
PSTN-IP-PSTN (toll-by-passing) scenario which nowadays is very popular
application of IP Telephony systems. With the use of this mechanism we
authenticate end-to-end transmitted voice between PSTN users. Additionally we
improve IP part traffic security (both media stream and VoIP signalling
messages). Exemplary scenario is presented for SIP signalling protocol along
with SIP-T extension and H.248/Megaco protocol.
"
3015,"Accommodating Sample Size Effect on Similarity Measures in Speaker
  Clustering","  We investigate the symmetric Kullback-Leibler (KL2) distance in speaker
clustering and its unreported effects for differently-sized feature matrices.
Speaker data is represented as Mel Frequency Cepstral Coefficient (MFCC)
vectors, and features are compared using the KL2 metric to form clusters of
speech segments for each speaker. We make two observations with respect to
clustering based on KL2: 1.) The accuracy of clustering is strongly dependent
on the absolute lengths of the speech segments and their extracted feature
vectors. 2.) The accuracy of the similarity measure strongly degrades with the
length of the shorter of the two speech segments. These effects of length can
be attributed to the measure of covariance used in KL2. We demonstrate an
empirical correction of this sample-size effect that increases clustering
accuracy. We draw parallels to two Vector Quantization-based (VQ) similarity
measures, one which exhibits an equivalent effect of sample size, and the
second being less influenced by it.
"
3016,Alignment of Speech to Highly Imperfect Text Transcriptions,"  We introduce a novel and inexpensive approach for the temporal alignment of
speech to highly imperfect transcripts from automatic speech recognition (ASR).
Transcripts are generated for extended lecture and presentation videos, which
in some cases feature more than 30 speakers with different accents, resulting
in highly varying transcription qualities. In our approach we detect a subset
of phonemes in the speech track, and align them to the sequence of phonemes
extracted from the transcript. We report on the results for 4 speech-transcript
sets ranging from 22 to 108 minutes. The alignment performance is promising,
showing a correct matching of phonemes within 10, 20, 30 second error margins
for more than 60%, 75%, 90% of text, respectively, on average.
"
3017,"Multimodal Meaning Representation for Generic Dialogue Systems
  Architectures","  An unified language for the communicative acts between agents is essential
for the design of multi-agents architectures. Whatever the type of interaction
(linguistic, multimodal, including particular aspects such as force feedback),
whatever the type of application (command dialogue, request dialogue, database
querying), the concepts are common and we need a generic meta-model. In order
to tend towards task-independent systems, we need to clarify the modules
parameterization procedures. In this paper, we focus on the characteristics of
a meta-model designed to represent meaning in linguistic and multimodal
applications. This meta-model is called MMIL for MultiModal Interface Language,
and has first been specified in the framework of the IST MIAMM European
project. What we want to test here is how relevant is MMIL for a completely
different context (a different task, a different interaction type, a different
linguistic domain). We detail the exploitation of MMIL in the framework of the
IST OZONE European project, and we draw the conclusions on the role of MMIL in
the parameterization of task-independent dialogue managers.
"
3018,"Document Archiving, Replication and Migration Container for Mobile Web
  Users","  With the increasing use of mobile workstations for a wide variety of tasks
and associated information needs, and with many variations of available
networks, access to data becomes a prime consideration. This paper discusses
issues of workstation mobility and proposes a solution wherein the data
structures are accessed in an encapsulated form - through the Portable File
System (PFS) wrapper. The paper discusses an implementation of the Portable
File System, highlighting the architecture and commenting upon performance of
an experimental system. Although investigations have been focused upon mobile
access of WWW documents, this technique could be applied to any mobile data
access situation.
"
3019,"Adaptive Multicast of Multi-Layered Video: Rate-Based and Credit-Based
  Approaches","  Network architectures that can efficiently transport high quality, multicast
video are rapidly becoming a basic requirement of emerging multimedia
applications. The main problem complicating multicast video transport is
variation in network bandwidth constraints. An attractive solution to this
problem is to use an adaptive, multi-layered video encoding mechanism. In this
paper, we consider two such mechanisms for the support of video multicast; one
is a rate-based mechanism that relies on explicit rate congestion feedback from
the network, and the other is a credit-based mechanism that relies on
hop-by-hop congestion feedback. The responsiveness, bandwidth utilization,
scalability and fairness of the two mechanisms are evaluated through
simulations. Results suggest that while the two mechanisms exhibit performance
trade-offs, both are capable of providing a high quality video service in the
presence of varying bandwidth constraints.
"
3020,Image compression and entanglement,"  The pixel values of an image can be casted into a real ket of a Hilbert space
using an appropriate block structured addressing. The resulting state can then
be rewritten in terms of its matrix product state representation in such a way
that quantum entanglement corresponds to classical correlations between
different coarse-grained textures. A truncation of the MPS representation is
tantamount to a compression of the original image. The resulting algorithm can
be improved adding a discrete Fourier transform preprocessing and a further
entropic lossless compression.
"
